CURIE: An Iterative Querying Approach for Reasoning About Situations
Dheeraj Rajagopal ∗ , Aman Madaan ∗ , Niket Tandon†, Yiming Yang, Shrimai Prabhumoye, Abhilasha Ravichander, Peter Clark†, Eduard Hovy
Language Technologies Institute, Carnegie Mellon University Pittsburgh, PA, USA
† Allen Institute for Artiﬁcial Intelligence Seattle, WA, USA
{dheeraj,amadaan,yiming,sprabhum,aravicha,hovy}@cs.cmu.edu {nikett, peterc}@allenai.org

arXiv:2104.00814v2 [cs.CL] 5 Apr 2021

Abstract
Recently, models have been shown to predict the effects of unexpected situations, e.g., would cloudy skies help or hinder plant growth? Given a context, the goal of such situational reasoning is to elicit the consequences of a new situation (st) that arises in that context. We propose a method to iteratively build a graph of relevant consequences explicitly in a structured situational graph (st graph) using natural language queries over a ﬁnetuned language model (M). Across multiple domains, CURIE generates st graphs that humans ﬁnd relevant and meaningful in eliciting the consequences of a new situation. We show that st graphs generated by CURIE improve a situational reasoning end task (WIQA-QA) by 3 points on accuracy by simply augmenting their input with our generated situational graphs, especially for a hard subset that requires background knowledge and multi-hop reasoning.
1 Introduction
A long-standing challenge in reasoning is to model the consequences of a novel situation in a context. Consider these questions - Would it rain more if we plant more trees?, or What would help water to boil faster? - answering these questions requires comprehending the complex events such as plant growth and water boiling, where much of the information remains implicit (by Grice’s maxim of quantity (Grice, 1975)), thus requiring inference.
Tasks that require situational reasoning are increasingly observed by machines deployed in the real world - unexpected situations are common, and machines are expected to gracefully handle them. It is also essential for tasks such as qualitative reasoning (Tandon et al., 2019; Tafjord et al., 2019a), physical commonsense reasoning
∗ authors contributed equally to this work. Ordering determined by dice rolling.

RQ1. St-Graph Generation :

Context :
Sunlight strikes chlorophyll. Sunlight trapped …
Situation (st) :
more sunlight

QA pairs:
Q1: What helps st imminently? A1 : bright skies Q2: What hurts st imminently? A2: cloudy skies Q3: What’s helped eventually ? A3: taller plants

RQ2. Example QA End-Task :
Context Situation [c] = storm End [e]= smaller rocks

bright skies

cloudy skies

more sunlight

taller plants

c’s inﬂuence on e?
accelerates (helps)

Figure 1: RQ1: CURIE generates situational graphs through iterative queries to a model, making the model’s knowledge of inﬂuences explicit (above; positive, and negative inﬂuence) iteratively. RQ2: Such graphs can improve situational reasoning QA when added to the QA input (below, where the context is a passage about erosion).

tasks (Sap et al., 2019; Bisk et al., 2020), and defeasible inference (Rudinger et al., 2020). Unlike humans, machines are not adept at such reasoning.
Prior systems that address situational reasoning take as input a context providing background information, a situation (st), and an ending, and predict the reachability from st to that ending either in a classiﬁcation setting (e.g., Tandon et al. (2019) grounds the path on at most two sentences in the context) or recently, in a story-generation setting (Qin et al., 2019), where the goal is to generate an alternate ending when the original ending and a counterfactual situation are given. However, generating effects of situations in real-world scenarios, where the ending is typically unknown is still an open challenge. We also might need st-reasoning capabilities across multiple domains (beyond stories). Further, multiple types of consequences to a situation might have to be generated (e.g, positive and negative impacts or eventual and immediate

impacts), which requires outputs in a structured form.
To address these limitations, we propose CURIEa generation framework that generalizes multiple reasoning tasks under a general situational reasoning framework. The task is illustrated in Figure 1: given some context and just a situation st (short phrase), our framework generates a situational reasoning graph (st-graph). At its core, CURIE constructs a reasoning graph based on the contextual knowledge that supports the following kinds of reasoning:
1. If st occurs, what will happen imminently/ eventually?
2. If st occurs, which imminent/ eventual effect will not happen?
3. What will support/ prevent the st?
As shown in Figure 1, our approach to this task is to iteratively compile the answers to questions 1,2,3 to construct the st-graph. Compared to a freeform text output obtained from an out-of-the-box seq-to-seq model, our approach gives more control and ﬂexibility over the graph generation process, including arbitrarily reasoning for any particular node in the graph. Downstream tasks that require reasoning about situations can compose natural language queries to construct a st-reasoning graph that can be simply augmented to their input. In this paper, we ask the following two research questions:
RQ1 Given a speciﬁc context and situation, can we iteratively generate a situational reasoning graph of potential effects?
RQ2 Can the st-graphs generated by CURIE improve performance at a downstream task?
In response, we make the following contributions: (i.) We present CURIE, the ﬁrst domain-agnostic
situational reasoning framework that takes as input some context and an st and iteratively generates a situational reasoning graph (§2). We show that our framework is effective at situational reasoning across three datasets, as validated by human evaluation and automated metrics. (ii.) We show that st graphs generated by CURIE improve a st-reasoning task (WIQA-QA) by 3 points on accuracy by simply augmenting their input with our generated situational graphs, especially for a hard subset that requires background knowledge and multi-hop reasoning (§4). (Table 2).

M

st tasks

model

st-graph

Figure 2: CURIE framework consists of two components: (i) a formulation that adapts datasets that allow st-reasoning for pretraining (ii) a method to iteratively build structured st-graphs using natural language queries over a ﬁne-tuned language model (M).

2 CURIE for Situational Reasoning
CURIE provides both a general framework for situational reasoning and a method for constructing st-reasoning graphs from pretrained language models. The overall architecture of CURIE is shown in Figure 2. CURIE framework consists of two components: (i) st-reasoning task formulation : a formulation that adapts datasets that allow situational reasoning (ii) st-graph construction : a method to ﬁne-tune language model M to generate the consequences of a situation and iteratively construct structured situational graphs (shown in ﬁgure 1). In this section, we present (i) our task formulation (§2.1), (ii) adapting existing datasets for CURIE task formulation (§2.2), (iii) the learning procedure (§2.3), and (iv) the st-graph generation via inference (§2.4).
2.1 Task Formulation
We describe the general task formulation for adapting pretraining language models to the st-reasoning task. Given a context T = {s1, s2, . . . , sN } with N sentences, and a situation st, our goal is to generate an st-graph G in this changed world.
An st-graph G(V, E) is an unweighted directed acyclic graph. A vertex v ∈ V is an event or a state such that it describes a change to the original conditions in T . Each edge eij ∈ E is labeled with an relationship rij, that indicates whether vi positively or negatively inﬂuences vj. Positive inﬂuences are represented via green edges comprising one of {entails, strengthens, helps} and negative inﬂuences represented via red edges that depict one of {contradicts, weakens, hurts}. Our relation set is general and can accommodate various st-reasoning tasks. Given two nodes vi, vk ∈ V , if a path from vi to vk has more than one edge, we describe the effect c as eventual and a direct effect as imminent.

Dataset
WIQA QUAREL DEFEAS

Original formulation
context: Wind creates waves.. Waves wash on beaches... ques: If there is storm, how will it affect bigger waves? chain: storm → stronger wind → bigger waves answer: bigger waves
context: Car rolls further on wood than on thick carpet ques: what has more resistance? (a) wood (b) the carpet simpliﬁed logical form of context, ques: distance is higher on wood → (a) friction is higher in carpet (or) (b) friction is higher in wood answer: (b) the carpet
context: Two men and a dog are standing among the green hills. hypothesis: The men are farmers. evidence type: strengthener answer: the dog is a sheep dog

st formulation
Given context and st: there is a storm Q1: What does st help imminently ? A1: stronger wind Q2: What does st help eventually ? A2: bigger waves
Given context and st: distance is higher on wood Q1: What does st entail imminently ? A1: friction is lower in wood Q2: What does st contradict imminently ? A2: friction is lower in carpet Q3: What does st entail eventually ? A3: wood has more resistance
Given context and st: dog is a sheep dog Q1: What does st strengthen imminently ? A1: The men are farmers st: men are studying tour maps Q2: What does st weaken imminently? A2: The men are farmers

st graph
storm
stronger wind
high dist on wood
low friction on
wood
sheep dog
men're farmer

big waves
friction low on carpet
wood resistance
is more
men w/ tour
map

Table 1: The datasets used by CURIE and how we re-purpose them for st reasoning graph generation task. As explained in §2.1, the green edges set depicts relation (r) (entail, strengthen, helps) and red edges depict one of (contradict, weaken, hurts). The { imminent, eventual } effects (c) are used to support multihop reasoning. DEFEAS = DEFEASIBLE, chain refers to reasoning chain. Some examples are cut to ﬁt. The key insight is that an st-graph can be decomposed into a series of QA pairs, enabling us to leverage seq-to-seq approaches for st-reasoning.

We obtain the training data for st-graph generation task by decomposing an st-graph into a set of question-answer pairs. Each question comprises of the context T , a st-vertex vs, a relation r, and the nature of the effect c. The output is an answer to the question, that corresponds to the target node vt. An example is shown in Figure 1. Compared to an end-to-end approach to graph generation, our approach gives more ﬂexibility over the generation process, enabling reasoning for any chosen node in the graph.
2.2 Generalizing Existing Datasets
Despite theoretical advances, lack of large-scale general situational reasoning datasets presents a challenge to train seq-to-seq language models. In this section, we describe how we generalize existing diverse datasets towards st-reasoning towards ﬁnetuning a language model M. If a reasoning task allows a context, a st-situation and can describe the inﬂuence of st in terms of green and/or red edges, it can be seamlessly adapted to CURIE

framework. Due to lack of existing datasets that directly support our task formulation, adapt the following three diverse datasets - WIQA, QUAREL and DEFEASIBLE for CURIE.
WIQA: WIQA task studies the effect of a perturbation in a procedural text (Tandon et al., 2019). The context T in WIQA is a procedural text describing a physical process, and st is a perturbation i.e., an external situation deviating from T , and the effect of st is either helps or hurts. An example of WIQA to st-formulation is shown in Table 1.
QUAREL: QUAREL dataset (Tafjord et al., 2019a) contains qualitative story questions where T is a narrative, and the st is a qualitative statement. T and st are also expressed in a simpler, logical form, which we make use of because it clearly highlights the reasoning challenge. The effect of st is either entails or contradicts (example in Table 1).
DEFEASIBLE: The DEFEASIBLE reasoning task (Rudinger et al., 2020) studies inference in the pres-

Research question Can we generate good st graphs? (§3)
Can we improve downstream tasks? (§4.1, §4.2)

Training dataset
WIQA-st QUAREL-st DEFEASIBLE-st
WIQA-st, WIQA-QA QUAREL-st

Test dataset
WIQA-st QUAREL-st DEFEASIBLE-st
WIQA-QA QUARTZ-QA

Task
generation generation generation
ﬁnetuned QA zero shot

Metrics
ROUGE, BLEU ROUGE, BLEU ROUGE, BLEU
accuracy accuracy

Table 2: Overview of experiments

Dataset
WIQA QUAREL DEFEASIBLE

train
119.2k 4.6k 200k

dev
34.8k 1.3k 14.9k

test
34.8k 652 15.4k

Table 3: Dataset wise statistics, we maintain the splits

ence of a counterfactual. The context T is given by a premise which describes a everyday context, and the st is an observed evidence which either strengthens or weakens the hypothesis. We adapt the original abductive setup as shown in Table 1. In addition to commonsense situations, DEFEASIBLE-st also comprises of social situations, thereby contributing to the diversity of our datasets.

2.3 Learning to Generate st-graphs

To reiterate our task formulation (§2.1), for a given

context and st, we ﬁrst specify a set of questions

and the resulting output for the questions is then

compiled to form a st-graph.

The training data thus consists of tuples (xi, yi),

with xi = (T, st , r, c)i where T denotes the con-

text, st the situation, r denotes the edge (green or

red), c signiﬁes the nature of the effect (imminent or

eventual), and yi is the output (a short sentence or a

phrase depicting the effect). The output of NQ such

questions is compiled into a graph G = {yi}1:NQ (as shown in Figure 1).

We use a pretrained language model M to es-

timate the probability of generating an answer

yi for an input xi. We ﬁrst transform the tu-

ple xi =

x

1 i

,

x2i

,

.

.

.

,

x

N i

into a single query

sequence of tokens by concatenating its compo-

nents i.e. we set xi = concat(T, st , r, c), where

concat refers to string concatenation. Let the

sequence of tokens representing the target event

be yi =

yi1

,

yi2

,

.

.

.

,

y

M i

,

where

N

and

M

are

the lengths of the query and the target event se-

quences We model the conditional probability

Algorithm 1: ITERATIVEGRAPHGEN

(IGEN): generating st graphs with CURIE

Given: CURIE language model M.
Given: Context passage T , a situation st, a set R = {(ri, ci)}Ni=Q1 made of NQ (r, c) tuples.
Result: st graph G where the ith node will
be generated with the relation ri and the effect type ci. Init: G ← ∅
for i ← 1, 2, . . . , NQ do

// Create a query

xi = concat(T, st, ri, ci);

/* Sample a node from the

language model M

*/

yi ∼ M(xi);

/* Add the sampled node

and the edge to the

graph

*/

G = G ∪ (ri, ci, yi);

end return G

pθ(yi | xi) as a series of conditional next token

distributions parameterized by θ: as pθ(yi | xi) =

M k=1

pθ (yik

|

xi,

yi1,

..,

yik−1).

2.4 Inference to Decode st-graphs

The auto-regressive factorization of the language

model pθ allows us to efﬁciently generate target

event inﬂuences for a given test input xj.

The process of decoding begins by sampling the ﬁrst token yj1 ∼ pθ(y | xj). The next token is then drawn by sampling yj2 ∼ pθ(y | xj, yj1). The process is repeated until a speciﬁed end-symbol token is drawn at the Kth step. We use nucleus

sampling (Holtzman et al., 2019) in practice. The

tokens

yj1

,

yj2

,

.

.

.

,

y

K j

−

1

are then returned as

the generated answer. To generate the ﬁnal st-

reasoning graph G, we combine all the generated

Model (M) WIQA-st
LSTM Seq-to-Seq GPT ∼(w/o T ) GPT-2 ∼(w/o T ) GPT
GPT-2 QUAREL-st
LSTM Seq-to-Seq GPT ∼(w/o T ) GPT-2 ∼(w/o T ) GPT
GPT-2 DEFEASIBLE-st LSTM Seq-to-Seq GPT ∼(w/o T ) GPT-2 ∼(w/o T ) GPT
GPT-2

BLEU
7.51 7.82 10.01 9.95 16.23
13.05 20.20 26.98 25.48 35.20
7.84 9.91 9.17 10.49 10.52

ROUGE
18.71 19.30 20.93 19.64 29.65
24.76 36.64 41.14 42.87 50.57
17.50 20.63
9.43 21.79 21.19

Table 4: Generation results for CURIE with baselines for language model M. We ﬁnd that context is essential for performance (w/o T ). We provide these baseline scores as a reference for future research.

answers {yi}1:NQ that had the same context and st pair (T, st ) over all (r, c) combinations. We can then use generated answer st ∈ {yi}1:NQ, as a new input to M as (T, st ) to recursively expand the st-graph to arbitrary depth and structures (Algorithm 1). One such instance of using CURIE st graphs for a downstream QA task is shown in §4.
3 RQ1: Establishing Baselines for st-graph Generation
This section reports on the quality of the generated st reasoning graphs and establishes strong baseline scores for st-graph generation.
We use the datasets described in section §2.2 for our experiments.
3.1 Baseline Language Models
To reiterate, CURIE is composed of (i) task formulation component and (ii) graph construction component, that uses a language model M to construct the st-graph. We want to emphasize that any language model architecture can be a candidate for M. Since our st-task formulation is novel, we establish strong baselines for the choice of language model. Our experiments include large-scale language models (LSTM and pretrained transformer) with varying

parameter size and pre-training, along with corresponding ablation studies. Our M choices are as follows:
LSTM Seq-to-Seq: We train an LSTM (Hochreiter and Schmidhu-
ber, 1997) based sequence to sequence model (Bahdanau et al., 2015) which uses global attention described in (Luong et al., 2015). We initialize the embedding layer with pre-trained 300 dimensional Glove (Pennington et al., 2014)1. We use 2 layers of LSTM encoder and decoder with a hidden size of 500. The encoder is bidirectional.
GPT: We use the original design of GPT (Radford et al., 2018) with 12 layers, 768-dimensional hidden states, and 12 attention heads.
GPT-2: We use the medium (355M) variant of GPT-2 (Radford et al., 2019) with 24 layers, 1024 hidden size, 16 attention heads.
For both GPT and GPT-2, we initialize the model with the pre-trained weights and use the implementation provided by Wolf et al. (2019).
3.2 Automated Evaluation
To evaluate our generated st-graphs, we compare them with the gold-standard reference graphs.
To compare the two graphs, we ﬁrst ﬂatten both the reference graph and the st-graph as text sequences and then compute the overlap between them. We use the standard evaluation metrics BLEU (Papineni et al., 2002), and ROUGE (Lin, 2004) 2.
Our results indicate that the task of st generation is challenging, and suggests that incorporating st-reasoning speciﬁc inductive biases might be beneﬁcial. At the same time, Table 4 shows that even strong models like GPT-2 struggle on the st-graph generation task, leaving a lot of room for model improvements in the future.
We also show ablation results for the model with respect to the context T (§2.1), by ﬁne-tuning without the context. We ﬁnd that context is essential for performance for both GPT and GPT-2 (indicated with w/o T in Table 4).
Further, we note that the gains achieved by adding context are higher for GPT-2, hinting that larger models can more effectively utilize the context.
1https://github.com/OpenNMT/OpenNMT-py 2We use Sharma et al. (2017) for calculating the overlap. https://github.com/Maluuba/nlg-eval

3.3 Human Evaluation

Task

GPT-2 GPT-2 No

(w/o T )

Preference

Relevance 23.05 46.11 Reference 11.67 31.94

30.83 56.39

Table 5: Results of human evaluation. The numbers show the percentage(%) of times a particular option was selected for each metric.

In addition to automated evaluation, we perform human evaluation on the ablation (GPT-2- w/o T and GPT-2 models) to assess the quality of generations, and the importance of grounding generations in context. Three human judges annotated 120 unique samples for relevance and reference, described next. Both models (with and without context) produced grammatically ﬂuent outputs without any noticeable differences.
Relevance: The annotators are provided with the input of a procedural text T , the st, and the relational questions. The output events generated by GPT-2 (w/o T ) and GPT-2 are also provided in random order. The annotators were asked, “Which system (A or B) is more accurate relative to the background information given in the context?” They could also pick option C (no preference).
Comparison with true event (reference): We measure how accurately each system-generated event reﬂects the reference (true) event. Here, the annotators saw only the reference sentence and the outputs of two systems (A and B) in a randomized order. We asked the annotators, “Which system’s output is closest in meaning to the reference?” The annotators could pick the options A, B, or C (no preference).
For relevance and reference comparison tasks (Table 5), we present the percentage of the count of human judges for each of the three categories. The table illustrates that GPT-2 performs better than GPT-2 (w/o T ) on both the metrics. Particularly, GPT-2 not only performs better than GPT-2 (w/o T ) but also much better than the “No Preference” option in the relevance metric. This means that GPT-2 generates target events that logically follow the passage and source events. The reference and relevance task scores together show that GPT-2 does not generate target events that are exactly similar to the reference target events, but they

are correct in the context of the passage and the source event. This can happen due to linguistic variation in the generation, as well as the ability of the source event to inﬂuence multiple target events in the context of the passage. We study this in more detail in the error analysis presented below.
3.4 Error Analysis
Table 6 shows the error analysis on 100 random samples from the validation set. We found that for about 26% of samples, the generated event inﬂuence had an exact match with the reference, and about 30% of the samples had no overlap with the reference (category Wrong in Table 6). We found that for 20% of the cases, the generated target event was correct but was expressed differently compared to the reference text (Linguistic Variability class in Table 6). Furthermore, we observed that in 17% of cases, the generated target event was not the same as the reference target event, but was relevant to the passage and the question, as shown in the Related Event category in Table 6. In 5% of the samples (Polarity), the model generates events with opposite polarity compared to the reference. A small fraction (2%) of samples had incorrect gold annotations.
3.5 Consistency Analysis
Finally, we measure if the generated st-graphs are consistent. Consider a path of length two in the generated st-graph (say, A → B → C). A consistent graph would have identical answers to what does A help eventually i.e., “C”, and what does B help imminently i.e., “C”. To analyze consistency, we manually evaluated 50 random generated lengthtwo paths, selected from WIQA-st development set. We observed that 58% of the samples had consistent output w.r.t to the generated output. We also measure consistency w.r.t. the gold standard, and observe that the system output is about 48% consistent. Despite being trained on independent samples, our st-graphs show reasonable consistency and improving consistency further is an interesting future research direction.
3.6 Discussion
In summary, our task formulation allows adapting pretrained language models for generating stgraphs that humans ﬁnd meaningful and relevant. Automated metrics show the utility of using largescale models and grounding the st-graph generation in context. We establish multiple baselines with

Error Class Description

% Question

Reference

Predicted

Polarity

The predicted polarity was wrong 5% but event was correct

What does ‘oil ﬁelds over-used’ help at eventually ?

there is not oil reﬁned

more oil is reﬁned

Linguistic Variability

The output was a linguistic variant of the reference

20% What does ‘fewer rabbits will

more

become pregnant’ hurts at imminently ? rabbits

more babies

Related Event

The output was related but different reference expected

17% What does you inhale more air from the outside hurts at imminently ?

there will be less oxygen in your blood

you develop more blood clo-ts in your veins

Wrong

The output was was completely unrelated

30% What does ‘less nutrients for plants’ hurt at eventually ?

more plants

more wine being produced

Erroneous Reference

The gold annotations were erroneous

2% What does ‘less rabbit rabbit mating’ hurt at imminently?

less rabbits

more babies

Table 6: Examples of error categories. Error analysis is only shown for the incorrect outputs.

varying levels of parameter size and pretraining to guide future research.
4 RQ2: CURIE for Downstream Tasks
In this section, we describe the approach for augmenting st graphs for downstream reasoning tasks. We ﬁrst identify the choice of tasks (st-tasks) for domain adaptive pretraining (Gururangan et al., 2020) and obtain CURIE language model M. The downstream task then provides input context, st and (relation, type) tuples of interest, and obtains the st-graphs (see Algorithm 1). We describe one such instantiation in the section §4.1.
4.1 CURIE augmented WIQA-QA
We examine the utility of CURIE-generated graphs in the WIQA-QA (Tandon et al., 2019) downstream question answering benchmark. Input to this task is a context supplied in form of a passage T , a starting event c, an ending event e, and the output is a label {helps, hurts, or no effect} depicting how the ending e is inﬂuenced by the event c.
We hypothesize that CURIE can augment c and e with their inﬂuences, giving a more comprehensive picture of the scenario compared to the context alone. We use CURIE trained on WIQA-st to augment the event inﬂuences in each sample in the QA task as additional context.
More concretely, we obtain the inﬂuence graphs for c and e by deﬁning Rfwd = {(helps, imminent), (hurts, imminent) } and Rrev = { (helped by, imminent), (hurt by, imminent)}, and using algorithm 1 as follows:
G(c) = IGEN(T, c, Rfwd) G(e) = IGEN(T, e, Rrev)
We hypothesize that WIQA-st graphs are able to generate reasoning chains that connect c to e, even

Query Type
1-hop 2-hop 3-hop
Exogenous In-para
Out-of-para
Overall

WIQA-BERT + CURIE
78.78 63.49 68.28
64.04 73.58 90.84
76.92

WIQA-BERT
71.60 62.50 59.50
56.13 79.68 89.38
73.80

Table 7: QA accuracy by number of hops, and question type. WIQA-BERT refers to the original WIQA-BERT results reported in Tandon et al. (2019), and WIQA-BERT + CURIE are the results obtained by augmenting the QA dataset with the inﬂuences generated by CURIE.

if e is not an immediate consequence of c. Following Tandon et al. (2019), we encode the input sequence concat(T, c, e) using the BERT encoder E (Devlin et al., 2019), and use the [CLS] token representation (hˆi) as our sequence representation.
We then use the same encoder E to encode the generated effects concat(G(c), G(e)), and use the [CLS] token to get a representation for augmented c and e (hˆa). Following the encoded inputs, we compute the ﬁnal loss as: li = MLP1(hˆi), and la = MLP1(hˆa) and L = α × Li + β × La, where li, la represent the logits from hˆi and hˆa respectively, and Li and La are their corresponding crossentropy losses. α and β are hyperparameters that decide the contribution of the generated inﬂuence graphs and the procedural text to the loss. We set α = 1 and β = 0.9 across experiments.
QA Evaluation Results Table 7 shows the accuracy of our method vs. the vanilla WIQA-BERT model by question type and number of hops between cf and e. We also observe from Table 7 that

augmenting the context with generated inﬂuences from CURIE leads to considerable gains over WIQABERT based model, with the largest improvement seen in 3-hop questions (questions where the e and c are at a distance of three reasoning hops in the inﬂuence graphs). The strong performance on the 3-hop question supports our hypothesis that generated inﬂuences might be able to connect two event inﬂuences that are farther apart in the reasoning chain. We also show in Table 7 that augmenting with CURIE improves performance on the difﬁcult exogenous category of questions, which requires background knowledge.
In summary, the evaluation highlights the value of CURIE as a framework for improving performance on downstream tasks that require counterfactual reasoning and serves as an evaluation of the ability of CURIE to reason about st-scenarios.

5 Related Work
Closed-domain st reasoning : In NLP, a large body of work has focused on what-if questions where the input is a context, st, and an ending, and the task is to predict the reachability from st to the ending. The most common approach (Tandon et al., 2019; Rajagopal et al., 2020; Tafjord et al., 2019a) is a classiﬁcation setting where the path is deﬁned as more or less (qualitative intensities) over the sentences in the input context (a paragraph or procedural text with ordered steps). Such models do not generalize across domains because it is difﬁcult to deal with changing vocabularies across domains. In contrast, our framework combines such diverse st-reasoning tasks under a general framework.

4.2 Zero-shot Evaluation
In addition to supervised augmentation, we also evaluate CURIE-M in a zero-shot setting. Towards this, we perform a zero-shot evaluation on QUARTZ (Tafjord et al., 2019b), a dataset for qualitative counterfactual reasoning. Each sample in QUARTZ consists of a question qi = If the top of the mountain gets hotter, the ice on the summit will:, context ki = ice melts at higher temperatures, the task is to pick the right answer from two options a1i = increase, and a2i = decrease. Since this task is setup as a qualitative binary classiﬁcation task, CURIE cannot be directly adopted to augment the QA pairs like described in Algorithm 1.
For the zero-shot setting, we use CURIE-M ﬁnetuned on QUAREL-st as our language model. For an unseen test sample (qi, a1i , a2i , ki), we select a1i as the correct answer if pθ(a1i | xi) > pθ(a2i | xi), and select a2i otherwise (here pθ stands for QUARELst). Our zero-shot CURIE-M achieves a 54% accuracy compared to supervised BERT model which achieves 54.7% accuracy. These results suggest that CURIE performs competitively at tasks while having no access to any supervision.
4.3 Discussion
In summary, we show substantial gains when a generated st-graph is fed as an additional input to the QA model. Our approach forces the model to reason about inﬂuences within a context, and then ask questions, which proves to be better than asking the questions directly.

Open-domain st reasoning : Very recently, there has been interest in st reasoning from a retrieval setting (Lin et al., 2019) and a more common generation setting, attributed partially to the rise of neural generation models (Yangfeng Ji and Celikyilmaz, 2020). Qin et al. (2019) presents generation models to generate the path from a counterfactual to an ending in a story. Another recent dataset (Rudinger et al., 2020) proposes defeasible inference in which an inference (X is a bird, therefore X ﬂies) may be weakened or overturned in light of new evidence (X is a penguin), and their dataset and task is to distinguish and generate two types of new evidence – intensiﬁers and attenuators. We make use of this dataset by reformulating their abductive reasoning setup into a deductive setup (see §2.2 for details).
Current systems make some simplifying assumptions, e.g. that the ending is known. Multiple st (e.g., more sunlight, more pollution) can happen at the same time, and these systems can only handle one situation at a time. Finally, all of these systems assume that the st happens once in a context. Our framework strengthens this line of work by dropping that assumption of an ending being given, during deductive st reasoning. In principle, our formulation is general enough to allow for multiple st and recursive reasoning as more situations unfold. Most importantly, our framework is the ﬁrst to allow for st reasoning across diverse datasets, within a realistic setting where only the context and st are known.

6 Conclusion
We present CURIE, a situational reasoning that: (i) is effective at generating st-reasoning graphs, validated by automated metrics and human evaluations, (ii) improves performance on two downstream tasks by simply augmenting their input with the generated st graphs. Further, our framework supports recursively querying for any node in the st-graph. For future work, we aim to design advanced models that seeks consistency, and another line of research to study recursive st-reasoning as a bridge between dialog and reasoning.
References
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural machine translation by jointly learning to align and translate. In 3rd International Conference on Learning Representations, ICLR 2015.
Yonatan Bisk, Rowan Zellers, Ronan LeBras, Jianfeng Gao, and Yejin Choi. 2020. Piqa: Reasoning about physical commonsense in natural language. In AAAI, pages 7432–7439.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.
H. Grice. 1975. Logic and conversation syntax and semantics. In Logic and conversation Syntax and Semantics.
Suchin Gururangan, Ana Marasovic´, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, and Noah A Smith. 2020. Don’t stop pretraining: Adapt language models to domains and tasks. arXiv preprint arXiv:2004.10964.
Sepp Hochreiter and Ju¨rgen Schmidhuber. 1997. Long short-term memory. Neural computation, 9(8):1735–1780.
Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2019. The curious case of neural text degeneration. arXiv preprint arXiv:1904.09751.
Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. In Text summarization branches out, pages 74–81.
Kevin Lin, Oyvind Tafjord, Peter Clark, and Matt Gardner. 2019. Reasoning over paragraph effects in situations. In MRQA@EMNLP.

Minh-Thang Luong, Hieu Pham, and Christopher D Manning. 2015. Effective approaches to attentionbased neural machine translation. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1412–1421.
Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on association for computational linguistics, pages 311–318. Association for Computational Linguistics.
Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. Glove: Global vectors for word representation. In Empirical Methods in Natural Language Processing (EMNLP), pages 1532–1543.
Lianhui Qin, Antoine Bosselut, Ari Holtzman, Chandra Bhagavatula, Elizabeth Clark, and Yejin Choi. 2019. Counterfactual story reasoning and generation. EMNLP.
Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018. Improving language understanding by generative pre-training. URL https://s3-us-west-2. amazonaws. com/openaiassets/researchcovers/languageunsupervised/language understanding paper. pdf.
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners. OpenAI Blog, 1(8):9.
Dheeraj Rajagopal, Niket Tandon, P. Clarke, Bhavana Dalvi, and E. Hovy. 2020. What-if i ask you to explain: Explaining the effects of perturbations in procedural text. Findings of EMNLP.
Rachel Rudinger, Vered Shwartz, Jena D. Hwang, Chandra Bhagavatula, Maxwell Forbes, Ronan Le Bras, Noah A. Smith, and Yejin Choi. 2020. Thinking like a skeptic: Defeasible inference in natural language. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 4661–4675, Online. Association for Computational Linguistics.
Maarten Sap, Ronan Le Bras, Emily Allaway, Chandra Bhagavatula, Nicholas Lourie, Hannah Rashkin, Brendan Roof, Noah A Smith, and Yejin Choi. 2019. Atomic: An atlas of machine commonsense for ifthen reasoning. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 33, pages 3027–3035.
Shikhar Sharma, Layla El Asri, Hannes Schulz, and Jeremie Zumer. 2017. Relevance of unsupervised metrics in task-oriented dialogue for evaluating natural language generation. CoRR, abs/1706.09799.
Oyvind Tafjord, Peter Clark, Matt Gardner, Wen-tau Yih, and Ashish Sabharwal. 2019a. Quarel: A dataset and models for answering questions about qualitative relationships. In Proceedings of the

AAAI Conference on Artiﬁcial Intelligence, volume 33, pages 7063–7071.
Oyvind Tafjord, Matt Gardner, Kevin Lin, and Peter Clark. 2019b. Quartz: An open-domain dataset of qualitative relationship questions. In EMNLP/IJCNLP.
Niket Tandon, Bhavana Dalvi, Keisuke Sakaguchi, Peter Clark, and Antoine Bosselut. 2019. Wiqa: A dataset for “what if...” reasoning over procedural text. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 6078–6087.
Thomas Wolf, L Debut, V Sanh, J Chaumond, C Delangue, A Moi, P Cistac, T Rault, R Louf, M Funtowicz, et al. 2019. Huggingface’s transformers: State-of-the-art natural language processing. ArXiv, abs/1910.03771.
Thomas Wolf Yangfeng Ji, Antoine Bosselut and Asli Celikyilmaz. 2020. The amazing world of generation. EMNLP tutorials.

