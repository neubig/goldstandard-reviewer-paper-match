arXiv:1902.00078v3 [q-bio.MN] 23 Sep 2019

From genome to phenome: Predicting multiple cancer phenotypes based on somatic genomic alterations via the genomic impact transformer
Yifeng Tao1, Chunhui Cai2, William W. Cohen1,† and Xinghua Lu2,3,† 1School of Computer Science, Carnegie Mellon University,
2Department of Biomedical Informatics, University of Pittsburgh, 3Department of Pharmaceutical Sciences, School of Pharmacy, University of Pittsburgh,
Pittsburgh, PA, USA †To whom correspondence should be addressed. E-mail: wcohen@cs.cmu.edu, xinghua@pitt.edu
Cancers are mainly caused by somatic genomic alterations (SGAs) that perturb cellular signaling systems and eventually activate oncogenic processes. Therefore, understanding the functional impact of SGAs is a fundamental task in cancer biology and precision oncology. Here, we present a deep neural network model with encoder-decoder architecture, referred to as genomic impact transformer (GIT), to infer the functional impact of SGAs on cellular signaling systems through modeling the statistical relationships between SGA events and diﬀerentially expressed genes (DEGs) in tumors. The model utilizes a multi-head self-attention mechanism to identify SGAs that likely cause DEGs, or in other words, diﬀerentiating potential driver SGAs from passenger ones in a tumor. GIT model learns a vector (gene embedding) as an abstract representation of functional impact for each SGA-aﬀected gene. Given SGAs of a tumor, the model can instantiate the states of the hidden layer, providing an abstract representation (tumor embedding) reﬂecting characteristics of perturbed molecular/cellular processes in the tumor, which in turn can be used to predict multiple phenotypes. We apply the GIT model to 4,468 tumors proﬁled by The Cancer Genome Atlas (TCGA) project. The attention mechanism enables the model to better capture the statistical relationship between SGAs and DEGs than conventional methods, and distinguishes cancer drivers from passengers. The learned gene embeddings capture the functional similarity of SGAs perturbing common pathways. The tumor embeddings are shown to be useful for tumor status representation, and phenotype prediction including patient survival time and drug response of cancer cell lines.∗
Keywords: Neural networks; Knowledge representation; Gene regulatory networks; Cancer.
1. Introduction
Cancer is mainly caused by the activation of oncogenes or deactivation of tumor suppressor genes (collectively called “driver genes”) as results of somatic genomic alterations (SGAs),1 including somatic mutations (SMs),2,3 somatic copy number alterations (SCNAs),4,5 DNA structure variations (SVs),6 and epigenetic changes.7 Precision oncology relies on the capability of identifying and targeting tumor-speciﬁc aberrations resulting from driver SGAs and
∗Supplemental information (SI), GIT model, pre-processed TCGA data, and gene embeddings are available at https://github.com/yifengtao/genome-transformer. c 2019 The Authors. Open Access chapter published by World Scientiﬁc Publishing Company and distributed under the terms of the Creative Commons Attribution Non-Commercial (CC BY-NC) 4.0 License.

their eﬀects on molecular and cellular phenotypes. However, our knowledge of driver SGAs and cancer pathways remains incomplete. Particularly, it remains a challenge to determine which SGAs (among often hundreds) in a speciﬁc tumor are drivers, which cellular signals or biological processes a driver SGA perturbs, and which molecular/cellular phenotypes a driver SGA aﬀects.
Current methods for identifying driver genes mainly concentrate on identifying genes that are mutated at a frequency above expectation, based on the assumption that mutations in these genes may provide oncogenic advantages and thus are positively selected.8,9 Some works further focus on the mutations perturbing conserved (potentially functional) domains of proteins as indications they may be driver events.10,11 However, these methods do not provide any information regarding the functional impact of enriched mutations on molecular/cellular phenotypes of cells. Without the knowledge of functional impact, it is diﬃcult to further determine whether an SGA will lead to speciﬁc molecular, cellular and clinical phenotypes, such as response to therapies. What’s more, while both SMs and SCNAs may activate/deactivate a driver gene, there is no well-established frequency-based method that combines diﬀerent types of SGAs to determine their functional impact.
Conventionally, an SGA event perturbing a gene in a tumor is represented as a “one-hot” vector spanning gene space, in which the element corresponding to the perturbed gene is set to “1”. This representation simply indicates which gene is perturbed, but it does not reﬂect the functional impact of the SGA, nor can it represent the similarity of distinct SGAs that perturb a common signaling pathway. We conjecture that it is possible to represent an SGA as a low-dimensional vector, in the same manner as the “word embedding”12–14 in the natural language processing (NLP) ﬁeld, such that the representation reﬂects the functional impact of a gene on biological systems, and genes sharing similar functions should be closely located in such embedding space. Here the “similar function” is broadly deﬁned, e.g., genes from the same pathway or of the same biological process.15 Motivated by this, we propose a scheme for learning “gene embeddings” for SGA-aﬀected genes, i.e., a mapping from individual genes to low-dimensional vectors of real numbers that are useful in multiple prediction tasks.
Based on the assumption that SGAs perturbing cellular signaling systems often eventually lead to changes in gene expression,16 we introduce an encoder-decoder architecture neural network model called “genomic impact transformer” (GIT) to predict DEGs and detect potential cancer drivers with the supervision of DEGs. While deep learning models are being increasingly used to model diﬀerent bioinformatics problems,17,18 to our knowledge there are few studies using the neural network to model the relationships between SGAs and molecular/cellular phenotypes in cancers. The proposed GIT model has the following innovative characteristics: (1) The encoder part of the transformer19 ﬁrst uses SGAs observed in a tumor as inputs, maps each SGA into a gene embedding representation, and combines gene embeddings of SGAs to derive a personalized “tumor embedding”. Then the decoder part decodes and translates the tumor embedding to DEGs. (2) A multi-head self-attention mechanism20,21 is utilized in the encoder, which is a technique widely used in NLP to choose the input features that signiﬁcantly inﬂuence the output. It diﬀerentiates SGAs by assigning diﬀerent weights to them so that it can potentially distinguish SGAs that have an impact on DEG from those do

(a)

Over-expressed genes

Under-expressed genes

Differentially expressed genes (DEGs)

(b) es e 1

1 et=es+ɑ1e1+ɑ2e2+ɑmem ɑ1

Tumor embedding et

e

e2

m

Gene embeddings

Cancer type embedding

ɑ

ɑ2

m

Attention weights

Tumor embedding

Multi-head self-attention

(c)

Attention weights

1

α1

α2

α3

α4 α5

...

αm

α1

α2

α3 ... αm

BRCA CNBD1 MATN2 PIK3CA PURG TP53 GATA3 ZBTB10 MRPS28

...

es

e1

e2

e3

Gene embeddings

...

Cancer type

Somatic genomic alterations (SGAs)

Cancer patient: TCGA-D8-A1JJ

α1,h

α2,h

α3,h

αm,h

sosoftfmtmaaxx

β1β,1

softmax

1,2β

β

β

β

1,h

2,h

3,h

m,h

e h heads m

...

θ1 θ2 ...θ

...

h

tanh
W0

...

e1

e2

e3

em

Gene embeddings

Fig. 1. (a) Overall architecture of GIT. An example case and its detected drivers are shown. (b)
A two-dimensional demo that shows how attention mechanism combines multiple gene embeddings of SGAs {eg}mg=1 and cancer type embedding es into a tumor embedding vector et using attention weights {αg}mg=1. (c) Calculation of attention weights {αg}mg=1 using gene embeddings {eg}mg=1.

not, i.e., detecting drivers from passengers. (3) Pooling inferred weighted impact of SGAs in a tumor produces a personalized tumor embedding, which can be used as an eﬀective feature to predict DEGs and other phenotypes. (4) Gene embeddings are pre-trained by a “Gene2Vec” algorithm and further reﬁned by the GIT, which captures the functional impact of SGAs on the cellular signaling system. Our results and analysis indicate that above innovative approaches enable us to derive powerful gene embedding and tumor embedding representations that are highly informative of molecular, cellular and clinical phenotypes.

2. Materials and methods
2.1. SGAs and DEGs pre-processing
We obtained SGA data, including SMs and SCNAs, and DEGs of 4,468 tumors consisting of 16 cancer types directly from TCGA portal.22 Details available in SI (Sec. S1).

2.2. The GIT neural network
2.2.1. GIT network structure: encoder-decoder architecture
Figure 1a shows the general structure of the GIT model with an overall encoder-decoder architecture. GIT mimics hierarchically organized cellular signaling system,23,24 in which a

neuron may potentially encode the signal of one or more signaling proteins. When a cellular signaling system is perturbed by SGAs, it often can lead to changes in measured molecular phenotypes, such as gene expression changes. Thus, for a tumor t, the set of its SGAs {g}mg=1 is connected to the GIT neural network as observed input (Fig. 1a bottom part squares). The impact of SGAs is represented as embedding vectors {eg}mg=1, which are further linearly combined to produce a tumor embedding vector et through an attention mechanism in the encoder (Fig. 1a middle part). We explicitly represent cancer type s and its inﬂuence on encoding system es of the tumor because tissue type inﬂuences which genes are expressed in cells of speciﬁc tissue as well. Finally, the decoder module, which consists of a feed-forward multi-layer perceptron (MLP),25 transforms the functional impact of SGAs and cancer type into DEGs of the tumor (Fig. 1a top part).
2.2.2. Pre-training gene embeddings using Gene2Vec algorithm
In this study, we projected the discrete binary representation of SGAs perturbing a gene into a continuous embedding space, which we call “gene embeddings” of corresponding SGAs, using a “Gene2Vec” algorithm, based on the assumption of co-occurrence pattern of SGAs in each tumor, including mutually exclusive patterns of mutations aﬀecting a common pathway.26 These gene embeddings were further updated and ﬁne-tuned by the GIT model with the supervision of aﬀected DEGs. Algorithm details available in SI (Sec. S2).
2.2.3. Encoder: multi-head self-attention mechanism
To detect the diﬀerence of functional impact of SGAs in a tumor, we designed a multi-head self-attention mechanism (Fig. 1a middle part). For all SGA-aﬀected genes {g}mg=1 and the cancer type s of a tumor t, we ﬁrst mapped them to corresponding gene embeddings {eg}mg=1 and a cancer type embedding es from a look-up table E = {eg}g∈G ∩ {es}s∈S, where eg and es are real-valued vectors. From the implementation perspective, we treated cancer types in the same way as SGAs, except the attention weight of it is ﬁxed to be “1”. The overall idea of producing the tumor embedding et is to use the weighted sum of cancer type embedding es and gene embeddings {eg}mg=1 (Fig. 1b) :
et = 1 · es + g αg · eg = 1 · es + α1 · e1 + ... + αm · em. (1) The attention weights {αg}mg=1 were calculated by employing multi-head self-attention mechanism, using gene embeddings of SGAs {eg}mg=1 in the tumor: {αg}mg=1 = FunctionAttention {eg}mg=1 ; W0, Θ (Fig. 1c). See SI (Sec. S3) for mathematical details. Overall we have three parameters {W0, Θ, E} to train in the multi-head attention module using back-propagation.27 The look-up table {eg}g∈G was initialized with Gene2Vec pre-trained gene embeddings and reﬁned by GIT here.
2.2.4. Decoder: multi-layer perceptron (MLP)
For a speciﬁc tumor t, we fed tumor embedding et into an MLP with one hidden layer as the decoder, using non-linear activation functions and fully connected layers, to produce the ﬁnal

predictions yˆ for DEGs y; (Fig. 1a top part):

yˆ = σ(W2 · ReLU(W1 · ReLU(et) + b1) + b2).

(2)

where ReLU(x) = max(0, x) is rectiﬁed linear unit, and σ(x) = (1+exp(−x))−1 is sig-

moid activation function. The output of the decoder and actual values of DEGs were

used to calculate the 2-regularized cross entropy, which was minimized during training: minW,E,Θ,b CrossEnt(y, yˆ) + 2(W, E, Θ; λ2), where W = {Wl}2l=0, cross entropy loss deﬁned as CrossEnt(y, yˆ) = − i [(1 − yi) log(1 − yˆi) + yi log yˆi], and p regularizer deﬁned as p(W; λ) = λ · l Wl p , p ∈ {1, 2}.

2.3. Training and evaluation
We utilized PyTorch (https://pytorch.org/) to train, validate and test the Gene2Vec, GIT (variants) and other conventional models (Lasso and MLPs; Section 3.1). The training, validation and test sets were split in the ratio of 0.33:0.33:0.33 and ﬁxed across diﬀerent models. The hyperparameters were tuned over the training and validation sets to get best F1 scores, trained on training and validation sets, and ﬁnally applied to the test set for evaluation if not further mentioned below. The models were trained by updating parameters using backpropagation,27 speciﬁcally, using mini-batch Adam28 with default momentum parameters. Gene2Vec used mini-batch stochastic gradient descent (SGD) instead of Adam. Dropout29 and weight decay ( p-regularization) were used to prevent overﬁtting. We trained all the models 30 to 42 epochs until they fully converged. The output DEGs were represented as a sparse binary vector. We utilized various performance metrics including accuracy, precision, recall, and F1 score, where F1 is the harmonic mean of precision and recall. The training and test were repeated for ﬁve runs get the mean and variance of evaluation metrics. We designed two metrics in the present work for evaluating the functional similarity among genes sharing similar gene embedding: “nearest neighborhood (NN) accuracy” and “GO enrichment”. See SI (Sec. S4) for the deﬁnition and meaning of them.

3. Results

3.1. GIT statistically detects real biological signals

Table 1. Performances of GIT (variants) and baseline methods.

Methods Lasso 1 layer MLP 2 layer MLP 3 layer MLP GIT - can GIT - attn GIT - init GIT

Precision 59.6±0.05 61.9±0.09 64.2±0.39 64.2±0.37 60.5±0.34 67.6±0.32 69.8±0.28 69.5±0.09

Recall 52.8±0.03 50.4±0.17 52.0±0.66 50.5±0.30 45.8±0.38 55.3±0.77 54.1±0.37 57.1±0.18

F1 score 56.0±0.01 55.6±0.07 57.4±0.28 56.5±0.19 52.1±0.29 60.8±0.35 60.9±0.16 62.7±0.08

Accuracy 74.0±0.02 74.7±0.02 75.9±0.09 75.7±0.13 73.6±0.14 77.7±0.05 78.3±0.06 78.7±0.01

The task of GIT is to predict DEGs (dependent variables) using SGAs as input (independent variables). Our results of GIT performance on both real and shuﬄed data demonstrates that GIT is able to capture real statistical relationships between SGAs and DEGs from the noisy biological data (SI: Sec. S5).
As a comparison, we also trained and tested the Lasso

(a)

(b)

(c)

Fig. 2. (a) GO enrichment of vs. number of groups in k -means clustering. (b) t-SNE visualization of gene embeddings. The diﬀerent colors represent k -means (40 clusters) clustering labels. An enlarged inset of a cluster is shown, which contains a set of closely related genes which we refer to “IFN pathway”. (c) Landscape of attention of SGAs based on attention weights and frequencies.
(multivariate regression with 1-regularization)30 and MLPs25 as baseline prediction models to predict DEGs based on SGAs. The Lasso model is appealing in our setting because, when predicting a DEG, it can ﬁlter out most of the irrelevant input variables (SGAs) and keep only the most informative ones, and it is a natural choice in our case where there are 19.8k possible SGAs. However, in comparison to MLP, it lacks the capability of portraying complex relationships between SGAs and DEGs. On the other hand, while conventional MLPs have suﬃcient power to capture complex relationships–particularly, the neurons in hidden layers may mimic signaling proteins24–they can not utilize any biological knowledge extracted from cancer genomics, nor do they explain the signaling process and distinguish driver SGAs. We employed the precision, recall, F1 score, as well as accuracy to compare GIT and traditional methods (Table 1: 1st to 4th, and last rows). One can conclude that GIT outperforms all these other conventional baseline methods for predicting DEGs in all metrics, indicating the speciﬁcally designed structure of GIT is able to soar the performance in the task of predicting DEGs from SGAs.
In order to evaluate the utility of each module (procedure) in GIT, we conducted ablation study by removing one module at a time: the cancer type input (“can”), the multi-head selfattention module (“attn”), and the initialization with pre-trained gene embeddings (“init”). The impact of each module can be detected by comparing to the full GIT model. All the modules in GIT help to improve the prediction of DEGs from SGAs in terms of overall performance: F1 score and accuracy (Table 1: 5th to last rows).
3.2. Gene embeddings compactly represent the functional impact of SGAs
We examined whether the gene embeddings capture the functional similarity of SGAs, using mainly two metrics: NN accuracy and GO enrichment (Deﬁned in SI Sec. S4). NN accuracy: By capturing the co-occurrence pattern of somatic alterations, the Gene2Vec pre-trained gene embeddings improve 36% in NN accuracy over the random chance of any pair of the genes sharing Gene Ontology (GO) annotation15 (Table 2). The ﬁne-tuned embeddings by GIT further show a one-fold increase in NN accuracy. These results indicate that the learned gene embeddings are consistent with the gene functions, and they map the discrete binary SGA representation into a meaningful and compact space. GO enrichment: We performed

clustering analysis of SGAs in embedding space using k -means clustering, and calculated GO

enrichment, and we varied the number of clusters (k ) to derive clusters with diﬀerent degrees

of granularity (Fig. 2a). As one can see, when the genes are randomly distributed in the

embedding space, they get GO enrichment of 1. However, in the gene embedding space, the

GO enrichment increases fast until the number of clusters reaches 40, indicating a strong

correlation between the clusters in embedding space and the functions of the genes.

To visualize the manifold of gene embed-

Table 2. NN accuracy with respect to GO in dif- dings, we grouped the genes into 40 clusters,

ferent gene embedding spaces.

and conducted the t-SNE31 of genes (Fig. 2b

Gene embeddings Random pairs

NN accuracy 5.3±0.36

Improvement left panel). Using PANTHER GO enrichment

–

analysis,32 12 out of 40 clusters are shown to be

Gene2Vec

7.2

36%

enriched in at least one biological process (SI

Gene2Vec + GIT 10.7

100%

Sec. S6). Most of the gene clusters are well-

deﬁned and tight located in the projected t-

SNE space. As a case study, we took a close

look at one cluster (Fig. 2b right panel), which contains a set of functionally similar genes,

such as that code a protein family of type I interferons (IFNs), which are responsible for

immune and viral response.33

3.3. Self-attention reveals impactful SGAs on cancer cell transcriptome

While it is widely ac-

Table 3.
Rank 1 2 3

Top ﬁve SGA-aﬀected genes ranked according to attention weight.

PANCAN TP53 PIK3CA RB1

BRCA HNSC LUAD TP53 TP53 STK11 PIK3CACASP8 TP53 CDH1 PIK3CAKRAS

GBM TP53 PTEN C9orf53

BLCA TP53 FGFR3 RB1

cepted that cancer is mainly caused by SGAs, but not all SGAs observed in a cancer cell are causative.1 Previous

4

PBRM1 GATA3 CYLD CYLC2 RB1 HSP90AA1 methods mainly con-

5

PTEN MED24 RB1 KEAP1 CHIC2 STAG2 centrate on searching

for SGAs with higher

than expected frequency to diﬀerentiate candidate drivers SGAs from passenger SGAs. GIT

provides a novel perspective to address the problem: identifying the SGAs that have a func-

tional impact on cellular signaling systems and eventually lead DEGs as the tumor-speciﬁc

candidate drivers. Here we compare the relationship of overall attention weights (inferred by

GIT model) and the frequencies of somatic alterations (used as the benchmark/control group)

in all the cancer types (Pan-Cancer) from our test data (Fig. 2c). In general, the attention

weights are correlated with the alteration frequencies of genes, e.g., common cancer drivers

such as TP53 and PIK3CA are the top two SGAs selected by both methods.2 However, our

self-attention mechanism assigns high weights to many of genes previously not designated

as drivers, indicating these genes are potential cancer drivers although their roles in cancer

development remain to be further studied. Table 3 lists top SGAs ranked according to GIT

attention weights in pan-cancer and ﬁve selected cancer types, where known cancer drivers

from TumorPortal3 and IntOGen34 are marked as bold font. Apart from TP53 and PIK3CA

(a)

(b)

(c)

(d)

(e)

p=0.017

p=5.1x10-8 CI=0.795

Fig. 3. (a) t-SNE of full tumor embedding et. (b) t-SNE of stratiﬁed tumor embedding (et-es). (c) PCA of tumor embedding shows internal subtype structure of BRCA tumors. Color lablels the group index of k -means clustering. (d) KM estimators of the three breast cancer groups. (e) Cox regression using tumor embeddings.
as drivers in the pan-cancer analysis,2 we also ﬁnd the top cancer drivers in speciﬁc cancer types consistent with our knowledge of cancer oncology. For example, CDH1 and GATA3 are drivers of breast invasive carcinoma (BRCA),35 CASP8 is known driver of head and neck squamous cell carcinoma (HNSC),36 STK11, KRAS, KEAP1 are known drivers of lung adenocarcinoma (LUAD),37 PTEN and RB1 are drivers of glioblastoma (GBM),38 and FGFR3, RB1, HSP90AA1, STAG2 are known drivers in urothelial bladder carcinoma (BLCA).39 In contrast, the most frequently mutated genes (control group) are quite diﬀerent from that using attention mechanism (experiment group), and only a few of them are known drivers (SI Sec. S7).
3.4. Personalized tumor embeddings reveal distinct survival proﬁles
Besides learning the speciﬁc biological function impact of SGAs on DEGs, we further examined the utility of tumor embeddings et in two perspectives: (1) Discovering patterns of tumors potentially sharing common disease mechanisms across diﬀerent cancer types; (2) Using tumor embedding to predict patient survival.
We ﬁrst used the t-SNE plot of tumor embeddings to illustrate the common disease mechanisms across diﬀerent cancer types (Fig. 3a). When cancer type embedding es is included in full tumor embedding et, which has a much higher weight than any individual gene embedding (Fig. 1b, Eq. 1) and dominates the full tumor embedding, tumor samples are clustered according to cancer types. This is not surprising as it is well appreciated that expressions of many genes are tissue-speciﬁc.40 To examine the pure eﬀect of SGAs on tumor embedding, we removed the eﬀect of tissue by subtracting cancer type embeddings es, followed by clustering tumors in the stratiﬁed tumor embedding space (Fig. 3b). It is interesting to see that each dense area (potential tumor clusters) includes tumors from diﬀerent tissues of origins, indicating SGAs in these tumors may reﬂect shared disease mechanisms (pathway perturbations) among tumors, warranting further investigations.
The second set of experiments was to test whether diﬀerences in tumor embeddings (thereby diﬀerence in disease mechanisms) are predictive of patient clinical outcomes. We conducted unsupervised k -means clustering using only breast cancer tumors from our test set, which reveals 3 three groups (Fig. 3c) with signiﬁcant diﬀerence in survival proﬁles evaluated by log-rank test41 (Fig. 3d; p-value=0.017). In addition, using tumor embeddings as input fea-

tures, we trained 1,2-regularized (elastic net)42 Cox proportional hazard models43 in a 10-fold cross-validation (CV) experiment. This led to an informative ranked list of tumors according to predicted survivals/hazards evaluated by the concordance index (CI) value (CI=0.795), indicating that the trained model is very accurate. We further split test samples into two groups divided by the median of predicted survivals/hazards, which also yields signiﬁcant separation of patients in survival proﬁles (Fig. 3e; p-value=5.1 × 10−8), indicating that our algorithm has correctly ranked the patients according to characteristics of the tumor.
As shown above, distinct SGAs may share similar embeddings if they share similar functional impact. Thus, two tumors may have similar tumor embeddings even though they do not share any SGAs, as long as the functional impact of distinct SGAs from these tumors are similar. Therefore, tumor embedding makes it easier to discover common disease mechanisms and their impact on patient survival. To further test this, we also performed clustering analysis on breast cancer tumors represented in original SGA space, followed similar survival analysis as described in the previous paragraph (SI Sec. S8).

3.5. Tumor embeddings are predictive of drug responses of cancer cell lines

Precision oncology concentrates on using patient-speciﬁc

omics data to determine optimal therapies for a patient.

1.0 0.8 TKI258

Raw SGAs

Tumor embeddings
RAF265

We set out to see if SGA data of cancer cells can be used to predict their sensitivity to anti-cancer drugs. We used the

True Positive Rate True Positive Rate

0.6 0.4 0.2 0.0 1.0 0.8 Lapatinib

AUC=0.55 AUC=0.68

AUC=0.56 AUC=0.61
Sorafenib

CCLE dataset,44 which performed drug sensitivity screening over hundreds of cancer cell lines and 24 anti-cancer drugs. The study collects genomic and transcriptomic data of these cell lines, but in general, the genomic data (except

0.6

0.4

0.2 AAUUCC==00..5693

AUC=0.50 AUC=0.58

0.00.0

0.5

1.0 0.0

0.5

1.0

False Positive Rate

False Positive Rate

the molecularly targeted genes) from a cell line are not sufﬁcient to predict sensitivity its sensitivity to diﬀerent drugs.
We discretized the response of each drug following the procedure in previous research.44,45 Since CCLE only con-

Fig. 4. ROC curves and the areas under the curve (AUCs) of Lasso models trained with original SGAs and tumor em-

tains a small subset of mutations in TCGA dataset (around 1,600 gene mutations), we retrained the GIT with this limited set of SGAs in TCGA, using default hyperparameters we set before. Cancer type input was removed as well, which

beddings representations on predicting responses to four drugs.

is not explicitly provided in CCLE dataset. The output of tumor embeddings et was then extracted as feature. We for-

mulated drug response prediction as a binary classiﬁcation

problem with 1-regularized cross entropy loss (Lasso), where the input can be raw sparse

SGAs or tanh-curved tumor embeddings tanh(et). Following previous work,44 we performed

10-fold CV experiment training Lasso using either inputs to test the drug response prediction

task of four drugs with distinct targets. Lasso regression using tumor embeddings consistently

outperforms the models trained with original SGAs as inputs (Fig. 4). Speciﬁcally, in the case

of Sorafenib, the raw mutations just give random prediction results, while the tumor embed-

ding is able to give predictable results. It should be noted that it is possible that certain

cancer cells may host SGAs along the pathways related to FGFR, RAF, EGFR, and RTK, rendering them sensitive to the above drugs. Such information can be implicitly captured and represented by the tumor embeddings, so that the information from raw SGAs are captured and pooled to enhance classiﬁcation accuracy.
4. Conclusion and Future Work
Despite the signiﬁcant advances in cancer biology, it remains a challenge to reveal disease mechanisms of each individual tumor, particularly which and how SGAs in a cancer cell lead to the development of cancer. Here we propose the GIT model to learn the general impact of SGAs, in the form of gene embeddings, and to precisely portray their eﬀects on the downstream DEGs with higher accuracy. With the supervision of DEGs, we can further assess the importance of an SGA using multi-head self-attention mechanisms in each individual tumor. More importantly, while the tumor embeddings are trained with predicting DEGs as the task, it contains information for predicting other phenotypes of cancer cells, such as patient survival and cancer cell drug sensitivity. The key advantage of transforming SGA into a gene embedding space is that it enables the detection and representation of the functional impact of SGAs on cellular processes, which in turn enables detection of common disease mechanisms of tumors even if they host diﬀerent SGAs. We anticipate that GIT, or other future models like it, can be applied broadly to gain mechanistic insights of how genomic alterations (or other perturbations) lead to speciﬁc phenotypes, thus providing a general tool to connect genome to phenome in diﬀerent biological ﬁelds and genetic diseases. One should also be careful that despite the correlation of genomic alterations and phenotypes such as survival proﬁles and drug response, the model may not fully reveal the causalities and there may exist other confounding factors not considered.
There are a few future directions for further improving the GIT model. First of all, decades of biomedical research has accumulated a rich body of knowledge, e.g., Gene Ontology and gene regulatory networks, which may be incorporated as the prior of the model to boost the performance.46 Secondly, we expect that by getting a larger corpus of tumor data with mutations and gene expressions, we will be able to train better models to minimize potential overﬁtting or variance. Lastly, more clinically oriented investigations are warranted to examine, when trained with a large volume of tumor omics data, the learned embeddings of SGAs and tumors may be applied to predict sensitivity or resistance to anti-cancer drugs based SGA data that are becoming readily available in contemporary oncology practice.
Acknowledgments
We would like to thank Yifan Xue and Michael Q. Ding for providing the processed TCGA data and discretized CCLE data. We also thank to the helpful suggestions from anonymous reviewers.
Funding
This work has been partially supported by the following NIH grants: R01LM012011, R01LM010144, and U54HG008540, and it has also been partially supported by the Grant

#4100070287 awarded by the Pennsylvania Department of Health. The content is solely the responsibility of the authors and does not necessarily represent the oﬃcial views of the above funding agencies.
References
1. B. Vogelstein, N. Papadopoulos, V. E. Velculescu et al., Cancer genome landscapes, Science 339, 1546 (2013).
2. C. Kandoth, M. D. McLellan, F. Vandin et al., Mutational landscape and signiﬁcance across 12 major cancer types, Nature 502, p. 333 (oct 2013).
3. M. S. Lawrence, P. Stojanov, C. H. Mermel et al., Discovery and saturation analysis of cancer genes across 21 tumour types, Nature 505, p. 495 (jan 2014).
4. G. Ciriello, M. L. Miller, B. A. Aksoy et al., Emerging landscape of oncogenic signatures across human cancers, Nat. Genet. 45, p. 1127 (sep 2013).
5. T. I. Zack, S. E. Schumacher, S. L. Carter et al., Pan-cancer patterns of somatic copy number alteration, Nat. Genet. 45, p. 1134 (sep 2013).
6. N. Stransky, E. Cerami, S. Schalm, J. L. Kim and C. Lengauer, The landscape of kinase fusions in cancer, Nat. Commun. 5, p. 4846 (sep 2014).
7. P. A. Jones and S. B. Baylin, The fundamental role of epigenetic events in cancer, Nat. Rev. Genet. 3, p. 415 (jun 2002).
8. N. D. Dees, Q. Zhang, C. Kandoth et al., MuSiC: identifying mutational signiﬁcance in cancer genomes., Genome Res. 22, 1589 (aug 2012).
9. M. S. Lawrence, P. Stojanov, P. Polak et al., Mutational heterogeneity in cancer and the search for new cancer-associated genes, Nature 499, p. 214 (jun 2013).
10. B. Reva, Y. Antipin and C. Sander, Predicting the functional impact of protein mutations: application to cancer genomics, Nucleic Acids Res. 39, e118 (sep 2011).
11. B. Niu, A. D. Scott, S. Sengupta et al., Protein-structure-guided discovery of functional mutations across 19 cancer types, Nat. Genet. 48, p. 827 (jun 2016).
12. T. Mikolov, I. Sutskever, K. Chen, G. Corrado and J. Dean, Distributed representations of words and phrases and their compositionality, in Proc. of NIPS , 2013.
13. J. Pennington, R. Socher and C. D. Manning, GloVe: global vectors for word representation., in Proc. of EMNLP , 2014.
14. Y. Tao, B. Godefroy, G. Genthial and C. Potts, Eﬀective feature representation for clinical text concept extraction, in Proc. of Clinical NLP Workshop, June 2019.
15. M. Ashburner, C. A. Ball, J. A. Blake et al., Gene Ontology: tool for the uniﬁcation of biology, Nature Genet. 25, p. 25 (may 2000).
16. C. Cai, G. F. Cooper, K. N. Lu et al., Systematic discovery of the functional impact of somatic genome alterations in individual tumors through tumor-speciﬁc causal inference, PLOS Comput. Biol. 15, p. e1007088 (jul 2019).
17. B. Lee, S. Min and S. Yoon, Deep learning in bioinformatics, Brief. Bioinform. 18, 851 (2016). 18. K. Lan, D. Wang, S. Fong et al., A survey of data mining and deep learning in bioinformatics,
J. Med. Syst. 42, p. 139 (2018). 19. A. Vaswani, N. Shazeer, N. Parmar et al., Attention is all you need, in Proc. of NIPS , 2017 20. D. Bahdanau, K. Cho and Y. Bengio, Neural machine translation by jointly learning to align
and translate, in Proc. of ICLR, 2015. 21. K. Xu, J. Ba, R. Kiros et al., Show, attend and tell: neural image caption generation with visual
attention, in Proc. of ICML, 07–09 Jul 2015. 22. T. C. G. A. R. Network et al., The cancer genome atlas pan-cancer analysis project, Nat. Genet.
45, p. 1113 (sep 2013).

23. L. Chen, C. Cai, V. Chen and X. Lu, Trans-species learning of cellular signaling systems with bimodal deep belief networks., Bioinformatics 31, 3008 (sep 2015).
24. L. Chen, C. Cai, V. Chen and X. Lu, Learning a hierarchical representation of the yeast transcriptomic machinery using an autoencoder model., BMC Bioinformatics 17 Suppl 1, p. 9 (jan 2016).
25. F. Rosenblatt, The perceptron: a probabilistic model for information storage and organization in the brain, Psychol. Rev. , 65 (1958).
26. F. Vandin, E. Upfal and B. J. Raphael, De novo discovery of mutated driver pathways in cancer., Genome Res. 22, 375 (feb 2012).
27. D. E. Rumelhart, G. E. Hinton and R. J. Williams, Learning representations by back-propagating errors, Nature 323, p. 533 (oct 1986).
28. D. P. Kingma and J. L. Ba, Adam: a method for stochastic optimization, in Proc. of ICLR, 2015. 29. N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever and R. Salakhutdinov, Dropout: A simple
way to prevent neural networks from overﬁtting, J. of Mach. Learn. Res. 15, 1929 (2014). 30. R. Tibshirani, Regression shrinkage and selection via the lasso, J. R. Stat. Soc. B 58, 267 (1994). 31. L. Maaten and G. Hinton, Visualizing high-dimensional data using t-SNE, J. Mach. Learn. Res.
9, 2579 (01 2008). 32. H. Mi, A. Muruganujan, J. T. Casagrande and P. D. Thomas, Large-scale gene function analysis
with the PANTHER classiﬁcation system, Nat. Protoc. 8, p. 1551 (jul 2013). 33. N. A. de Weerd and T. Nguyen, The interferons and their receptors–distribution and regulation,
Immunol. Cell Biol. 90, 483 (2012). 34. A. Gonzalez-Perez, C. Perez-Llamas, J. Deu-Pons et al., IntOGen-mutations identiﬁes cancer
drivers across tumor types, Nat. Methods 10, p. 1081 (sep 2013). 35. T. C. G. A. Network et al., Comprehensive molecular portraits of human breast tumours, Nature
490, p. 61 (sep 2012). 36. N. Stransky, A. M. Egloﬀ, A. D. Tward et al., The mutational landscape of head and neck
squamous cell carcinoma, Science 333, 1157 (aug 2011). 37. T. C. G. A. R. Network et al., Comprehensive molecular proﬁling of lung adenocarcinoma, Nature
511, p. 543 (jul 2014). 38. C. W. Brennan, R. G. W. Verhaak, A. McKenna et al., The somatic genomic landscape of
glioblastoma, Cell 155, 462 (oct 2013). 39. T. C. G. A. R. Network et al., Comprehensive molecular characterization of urothelial bladder
carcinoma, Nature 507, p. 315 (jan 2014). 40. K. A. Hoadley, C. Yau, D. M. Wolf et al., Multiplatform analysis of 12 cancer types reveals
molecular classiﬁcation within and across tissues of origin., Cell 158, 929 (aug 2014). 41. N. Mantel, Evaluation of survival data and two new rank order statistics arising in its consider-
ation, Cancer Chemoth. Rep. 50, 163 (March 1966). 42. H. Zou and T. Hastie, Regularization and variable selection via the elastic net, J. R. Stat. Soc.
B 67, 301 (2005). 43. D. R. Cox, Regression Models and Life-Tables (Springer New York, New York, NY, 1992), New
York, NY, pp. 527–541. 44. J. Barretina, G. Caponigro, N. Stransky et al., The Cancer Cell Line Encyclopedia enables
predictive modelling of anticancer drug sensitivity, Nature 483, p. 603 (mar 2012). 45. M. Q. Ding, L. Chen, G. F. Cooper, J. D. Young and X. Lu, Precision oncology beyond targeted
therapy: combining omics data with machine learning matches the majority of cancer cells to eﬀective therapeutics, Mol. Cancer Res. (2017). 46. J. Ma, M. K. Yu, S. Fong et al., Using deep learning to model the hierarchical structure and function of a cell, Nat. Methods 15, p. 290 (mar 2018).

Supplementary information S1. Data pre-processing of SGAs and DEGs We obtained SGA data, including SMs and SCNAs of 4,468 tumors consisting of 16 cancer typesa directly from TCGA portal22 and Firehose browser of the Broad Instituteb. For SMs: We considered all the non-synonymous mutation events of all genes and considered the mutation events at the gene level, where a mutated gene is deﬁned as one that contains one or more non-synonymous mutations or indels. For SCNAs: TCGA network discretizes the gene SCNA into 5 diﬀerent levels: homozygous deletion, single copy deletion, diploid normal copy, low copy number ampliﬁcation, and high copy number ampliﬁcation. We only included genes with homozygous deletion (potentially signiﬁcant loss of gene function) or high copy number ampliﬁcation (potentially signiﬁcant gain of gene function) for further analysis, and ﬁltered out the other three types of not-so-signiﬁcant SCNAs. Therefore, we collectively designated all SGAs aﬀecting a gene using the name of the gene being perturbed. Note that the preprocessing step of SMs and SCNAs excluded the obvious tumor passenger SGAs, since the functions of these mutated genes are not or only slightly perturbed. The remaining SGAs have the potential of being cancer drivers, such as oncogenes with gained functions, or tumor suppressor genes with lost functions. After processing genomic data from TCGA, we used a binary variable in a “one-hot” vector to indicate the genomic status of a gene. For example, we represented the genomic status of TP53 as 1, if it is perturbed by one or more of SM/SCNA events in a tumor.
Gene expression data were pre-processed and obtained from the Firehose browser of the Broad Institute. We determined whether a gene is diﬀerentially expressed in a tumor by comparing the gene’s expression in the tumor against a distribution of the expression values of the gene in the corresponding tissue-speciﬁc “normal” or control samples. For a given cancer type, assuming the expression of each gene (log 2 based) follows a Gaussian distribution in control sample, we calculated the p-values by determining the probability of observing an expression value from control distribution. Following the practice in previous work,16 if the p-value is equal or smaller than 0.005, the gene is considered as diﬀerentially expressed in the corresponding tumor. However, if a DEG is associated with an SCNA event aﬀecting it, we remove it from the DEG list of the tumor.
aInstead of single cancer types, we used all the available samples of various cancer types, to ﬁnd the common signaling mechanisms SGAs in cancer. In addition, the GIT model beneﬁts from the large scale dataset. The heterogeneity of diﬀerent cancer types was stratiﬁed by the additional cancer type feature as input to the model. bhttp://gdac.broadinstitute.org/

S2. Gene2Vec algorithm implementation

While gene embeddings can be directly learned using the GIT model, it has been shown in the ﬁeld of NLP that the pre-trained word embeddings can signiﬁcantly improve the performance in other related NLP tasks.12,14 Such pre-trained word embeddings can capture the knowledge of co-occurrence pattern of the words in languages and exhibit sound semantic properties: words of similar semantic meanings are close in embedding space, e.g., e“each” ≈ e“every”. We therefore propose an algorithm called “Gene2Vec” to pre-train the gene embeddings, which is closely related the skip gram word2vec12 pre-training algorithm. The biology rationale behind Gene2Vec algorithm is that we are able to portrait the co-occurrence pattern of SGAs in each tumor, i.e., mutually exclusive mutations,26 using gene embeddings and gene context embeddings.
Given the gene embedding eg of an SGA-aﬀected gene g and context embedding of any possible SGA-aﬀected gene c : V = {vc }c ∈G, where G is the set of all possible SGA-aﬀected genes, the skip gram paradigm assumes the probability that an alteration in gene c happens together with the alteration in gene g within a tumor with probability:

Pr (c ∈ Context(g) | g) =

exp (egvc) . c ∈G exp (egvc )

(S1)

We used the negative sampling (NS) technique to approximately maximize the loglikelihood of skip gram, which would otherwise be computationally expensive to optimize if directly following Eq. (S1). Algorithm 1 shows implementation of Gene2Vec.

Data: Genomic alterations in each tumor: T = Ti = {gi1, gi2, ..., gim(i)} i=1,2,...,N . Result: Pretrained gene embedding of each gene: E = {eg ∈ Rn} g∈G.

Context gene embeddings:

V = {vg ∈ Rn} g∈G.

f (g) ← Z1

N i=1

1(g

∈

Ti),

g ∈ G;

fn(g) ←

1 Z

f (g)3/4,

g ∈ G;

eg ∼ U −n0n.5 , 0n.5 n , vg ← 0n, g ∈ G;

embeddings

// Gene frequency // Normalized frequency // Initialize gene embeddings and context

while not converges do

l ← 0;

// Total loss of a mini-batch samples

for b = 1, 2, ..., batch size do

g∼f ;

// Sample a gene

gc ∼ Context(g ; T );

// Sample a context gene

gnr ∼ fn, r = 1, 2, ..., R ; l ← l + NSLoss g, gc, {gnr}Rr=1 ; E, V ; end

// Sample negative context genes // Update

(E, V) ← (E, V) − η · ∂(E∂,lV) ;

// Gradient descent

end

Function Context(g ; T )

Pc ← U ({gc | gc ∈ Ti, g ∈ Ti}i=1,2,...,N ) ; // Uniform distribution on sequence of

adjacent mutations

return Pc

Function NSLoss(g, gc, {gnr}Rr=1 ; E, V)

l ← log σ (egvgc) +

R r=1

log

σ

(−eg

vgnr

);

return l

// Negative sampling loss of one sample

Algorithm 1: Gene2Vec algorithm to pre-train the gene embeddings using skip

gram with negative sampling loss. Given the context information of somatic genomic

alterations (SGAs) in each cancer patient, i.e., whether two SGAs happened together in

a single tumor, we pre-trained the gene embeddings (and context gene embeddings) using

similar techniques to word2vec. Skip gram was used to predict the probability of co-occurred

SGAs c given a known SGA g, as explained in Equation S1. Negative sampling loss was uti-

lized to accelerate the maximization of log-likelihood in the skip gram assumption. Instead of

original mutation frequency f(g), the negative sampling frequency of SGA was sub-sampled

by scaling to f (g)3/4. In practice, the step size η in mini-batch gradient descent was decayed

after training for every epoch to converge fast and prevent overﬁtting. Note that E here is

deﬁned slightly diﬀerent from that in the main context, which contains both gene and cancer

type embeddings.

S3. Mathematical details of multi-head self-attention mechanism
For all SGA-aﬀected genes {g}mg=1 and the cancer type s of a tumor t, we ﬁrst mapped them to corresponding gene embeddings {eg}mg=1 and a cancer type embedding es from a look-up table E = {eg}g∈G ∩ {es}s∈S, where eg and es are real-valued vectors. From the implementation perspective, we treated cancer types in the same way as SGAs, except the attention weight of
it is ﬁxed to be “1”.
The overall idea of producing the tumor embedding et is to use the weighted sum of cancer type embedding es and gene embeddings {eg}mg=1 (Fig. 1b) :

et = 1 · es + g αg · eg = 1 · es + α1 · e1 + ... + αm · em.

(S2)

The attention weights {αg}mg=1 are calculated by employing multi-head self-attention mechanism, using gene embeddings of SGAs {eg}mg=1 in the tumor (Fig. 1c):

α1, α2, ..., αm = FunctionAttention(e1, e2, ..., em).

(S3)

The attention function FunctionAttention is implemented as a sub-network. In the case of single-
head attention, there is only one single head parameter θj, and the unnormalized weights {βg,j}mg=1 can be derived as follows:

βg,j = θj · tanh(W0 · eg), g = 1, 2, ..., m,

(S4)

which are further normalized to single-head weights {αg,j}mg=1:

α1,j, α2,j, ..., αm,j = softmax(β1,j, β2,j, ..., βm,j),

(S5)

where softmax function is deﬁned as : αg = exp (βg)/

m g =1

exp (βg

).

In

the

case

of

multi-head

attention,

there

exist

h

diﬀerent

parameters

Θ

=

{θ

j

}

h j=1

.

Then

multiple

attention

weights

of

each gene embedding are generated following Eq. (S4,S5) and summed up to be the ﬁnal

multi-head attention weight:

αg =

h
j=1 αg,j = αg,1 + αg,2 + ... + αg,h, g = 1, 2, ..., m.

(S6)

S4. Evaluation metrics of gene embedding space

We designed two metrics for evaluating whether the gene embedding space is fair using the Gene Ontology (GO).15 We mainly concentrated on evaluating whether SGA-aﬀected genes share GO annotations in the “biological process” domain, based on the assumption that genes involved in a common biological process will likely share common functional impact. The top 1,474 frequently altered genes (aﬀected by SGAs for more than 150 times across all the tumors in the dataset) were used for evaluation, assuming that the gene embeddings of rare SGAs may not be well learned.
NN accuracy: We ﬁrst designed a metric called “nearest neighborhood (NN) accuracy” as a measure of functional similarity among genes sharing similar gene embedding. It is deﬁned as the expectation of whether a pair of genes (g, c) that are nearest neighbors in the embedding space share at least one same GO term:

NN accuracy = Eec∈NN(eg) [1 (GO(g) ∩ GO(c) = ∅)] ,

(S7)

where 1(statement) is the indicator function; GO(g) the set of GO terms assigned to gene g;

NN(eg) the set of nearest neighbors of eg. The expectation E is approximated by iterating over

all possible pairs of genes. The higher NN accuracy, the functionally similar genes are more

close to each other in the embedding space.

GO enrichment: Apart from the NN accuracy, which only reﬂects the functional simi-

larities between two adjacent genes in embedding space, we also evaluated whether a cluster

of genes close in an embedding space share GO annotations through “GO enrichment”, which

is deﬁned as:

enrichment = EClust(eg)=Clust(ec) [1(GO(g) ∩ GO(c) = ∅)] , Eg,c∈G [1(GO(g) ∩ GO(c) = ∅)]

(S8)

where Clust(g) is the cluster that gene g belongs to. GO enrichment considers the functional similarities of genes that are close in the embedding space. The larger it is, the higher correlated are the GO functions and clusters (and it equals to 1 in random case).

S5. Performance of GIT on real and shuﬄed data
We plotted both F1 score and accuracy on the test set as the function of trained epochs (Figure S1 “real data”), which indicate that the model gains the capability of predicting DEGs as training proceeds, and ﬁnally reaches a stable state.
In order to validate that GIT is able to extract real statistical relationships between SGAs and DEGs, we randomly shuﬄed the positions of DEGs in the DEG vector of a tumor, i.e., randomly relabel DEG names, and then trained a GIT to predict DEGs from SGAs. We compared the performance of models trained with random datasets, by plotting F1 score and accuracy during the training of the models (Figure S1 “shuﬄed data”). Note that, since most DEGs in the data are zeros, a trivial solution is to call every DEG as 0, which can also achieve good overall accuracy and minimize loss, but that will result in a low F1 because of low recall. Indeed, the test F1 score in the DEG-permutation case drops to a very low value due to the same reason.

(a)

(b)

Fig. S1. The change of F1 score and accuracy on the test set as GIT trains on real data or DEG-permuted data.

S6. Enriched functions of gene clusters
See Table S1 for the enriched functions of gene clusters. Fisher’s exact test with Bonferroni correction (p-value<0.05) was implemented on genes that belong to 40 clusters. 12 clusters of genes show to be signiﬁcantly involved in at least one biological process. The genes in cluster 14, referred to as “IFN pathway”, was further analyzed as a case study in Sec. 3.2, which is involved in viral defense response, immune response and cell surface signaling.

Table S1. Enriched gene ontologies in the “biological process” domain of human beings (Homo sapiens).

Cluster ID 2 3 4
8 14 (IFN pathway)
16 23
25 30 35 36 40

Enriched gene GO:0038003 GO:0050911 GO:0007186 GO:0007156 GO:0001568 GO:0048666 GO:0009653 GO:0045995 GO:0007155 GO:0033141 GO:0002323 GO:0042100 GO:0043330 GO:0002286 GO:0060337 GO:0030183 GO:0051607 GO:0007596 GO:0006959 GO:0002250 GO:0010469 GO:0050727 GO:0003272 GO:0003179 GO:0007156 GO:0035295 GO:0051960 GO:0007399 GO:0051179 GO:0000904 GO:0007155 GO:0007275 GO:0007156 GO:0040011 GO:0035589

ontology

Enriched biological process Opioid receptor signaling pathway Detection of chemical stimulus involved in sensory perception of smell G protein-coupled receptor signaling pathway Homophilic cell adhesion via plasma membrane adhesion molecules Blood vessel development Neuron development Anatomical structure morphogenesis Regulation of embryonic development Cell adhesion Positive regulation of peptidyl-serine phosphorylation of stat protein Natural killer cell activation involved in immune response B cell proliferation Response to exogenous dsrna T cell activation involved in immune response Type i interferon signaling pathway B cell diﬀerentiation Defense response to virus Blood coagulation Humoral immune response Adaptive immune response Regulation of signaling receptor activity Regulation of inﬂammatory response Endocardial cushion formation Heart valve morphogenesis Homophilic cell adhesion via plasma membrane adhesion molecules Tube development Regulation of nervous system development Nervous system development Localization Cell morphogenesis involved in diﬀerentiation Cell adhesion Multicellular organism development Homophilic cell adhesion via plasma membrane adhesion molecules Locomotion G protein-coupled purinergic nucleotide receptor signaling pathway

p-value 2.09e-02 3.16e-31 5.27e-21 5.26e-03 4.64e-02 4.02e-02 3.17e-04 3.77e-02 4.28e-02 9.07e-30 6.02e-29 1.65e-26 1.05e-25 2.22e-24 2.93e-21 1.40e-21 2.85e-18 5.77e-14 4.82e-15 1.61e-12 2.83e-12 4.13e-02 3.61e-02 9.79e-03 4.87e-02 2.32e-03 4.73e-02 1.88e-02 1.19e-02 4.15e-02 2.93e-02 2.21e-03 1.60e-09 3.42e-02 4.50e-03

S7. Top genes by attention mechanism and mutation rates
See Table S2 for the full list of top 100 genes that are assigned by the attention mechanism. Table S3 shows the top 5 genes that are most frequently mutated in both pan-cancer and single cancer types. It serves as the control group, in comparison to the attention mechanism results (Table 3,S2; experiment group).

Table S2. List of candidate drivers whose corresponding SGAs have top 100 highest attention weights. Boldfaced genes are known drivers according to TumorPortal3 and IntOGen34
database.

Rank 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25

Gene TP53 PIK3CA RB1 PBRM1 PTEN CDH1 CASP8 KRAS SLC1A6 POMC RRN3P2 TFAM CD163 WDFY3 WDR44 CYP51A1 ADARB2 C9orf53 BAP1 TMPRSS13 SV2C MYCBP2 MED24 CYLD CYLC2

Rank 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50

Gene MUC5B LMTK3 AHNAK VHL FGFR3 PHF20 STK11 OCA2 GATA3 PCNX KRTAP4-9 LRRIQ3 MRGPRF HSP90AA1 CNTN3 WNK3 PTPRD PCDHB16 RPLP0P2 COL6A1 TTC39B PGR TBC1D4 ANKRD36C GPATCH8

Rank 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75

Gene KRTAP4-11 CYP4F11 EP400 XRN1 MBD6 AR ANKRD30BP2 PRICKLE2 RGAG1 KRT23 UGT1A1 PARP8 TMPRSS6 FMN2 CDKN2A DIP2B TBP ZNF624 FEM1B CDKN2B PDE4D ISLR2 FLRT3 ZFAT SMARCA4

Rank 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100

Gene CNTNAP3B NKRF SETD2 LAMA2 AARS SPON1 WRN LHX1 STAG2 KSR1 GCDH E2F3 PDHX CLUH PRICKLE4 GLUD2 CROCC IDH1 GRIA1 DLG5 SMURF2P1 CACNA1C KIAA1377 PTPRZ1 PCSK5

Table S3. Top ﬁve SGA-aﬀected genes for Pan-Cancer and a few selected cancer types, ranked according to alteration frequency, as the control group to GIT. The corresponding experiment group, which is the selected candidate drivers of GIT model, is shown in Table 3. The known cancer drivers according to TumorPortal3 and IntOGen34 are marked in bold font.

Rank PANCAN BRCA

HNSC

LUAD

GBM

BLCA

1

TP53

TP53

TP53

TTN

CDKN2A TTN

2

TTN

PIK3CA CDKN2A TP53

CDKN2B TP53

3

PIK3CA TTN

TTN

CSMD3 C9orf53 ARID1A

4

CSMD3 POU5F1B PIK3CA PCDHAC2 EGFR DNAH5

5

MUC4

TRPS1 LINC00969 MUC16 MTAP CDKN2A

S8. Survival analysis based on raw SGAs
SGAs alone as tumor representations are not informative of predicting survival proﬁles. See Fig. S2 for survival analysis based on raw SGAs.

(a)

(b)

(c)

p=0.37

p=0.0060 CI=0.617

Fig. S2. (a) PCA plot showing k -means clustering of BRCA tumors using their SGA vectors. Most tumors merge around the origin (Cluster 1; with a small number of SGAs), while others (Cluster 2,3; with a large number of SGAs) are outliers and far away from the origin. (b) KM estimators and log-rank test on the three BRCA tumor groups in the SGA space. (c) Cox regression using SGAs (top mutated 474 genes are used).

