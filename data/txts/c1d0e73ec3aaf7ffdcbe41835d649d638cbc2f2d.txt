Consistent Accelerated Inference via Conﬁdent Adaptive Transformers
Tal Schuster∗ Adam Fisch∗ Tommi Jaakkola Regina Barzilay Computer Science and Artiﬁcial Intelligence Laboratory Massachusetts Institute of Technology {tals,fisch,tommi,regina}@csail.mit.edu

arXiv:2104.08803v2 [cs.CL] 9 Sep 2021

Abstract

We develop a novel approach for conﬁdently accelerating inference in the large and expensive multilayer Transformers that are now ubiquitous in natural language processing (NLP). Amortized or approximate computational methods increase efﬁciency, but can come with unpredictable performance costs. In this work, we present CATs—Conﬁdent Adaptive Transformers—in which we simultaneously increase computational efﬁciency, while guaranteeing a speciﬁable degree of consistency with the original model with high conﬁdence. Our method trains additional prediction heads on top of intermediate layers, and dynamically decides when to stop allocating computational effort to each input using a meta consistency classiﬁer. To calibrate our early prediction stopping rule, we formulate a unique extension of conformal prediction. We demonstrate the effectiveness of this approach on four classiﬁcation and regression tasks.1
1 Introduction
Large pre-trained language models have become the de facto standard approach for solving natural language processing tasks (Devlin et al., 2019; Liu et al., 2019). Despite their impressive performance, however, their often massive computational burden makes them costly to run (Schwartz et al., 2019; Sharir et al., 2020). Concerns about their efﬁciency have kindled a large body of research in the ﬁeld (Sanh et al., 2020; Schwartz et al., 2020; Fan et al., 2020). For multilayered architectures such as the Transformer, a popular approach is adaptive early exiting (Schwartz et al., 2020; Xin et al., 2020a, inter alia). Early exiting takes advantage of the observation that task instances vary in complexity. In this setting, “early” classiﬁers are added on top of the simpler features of intermediate layers
*The ﬁrst two authors contributed equally. 1 https://github.com/TalSchuster/CATs

Figure 1: Our CAT model G can save computational resources by exiting early on certain inputs—while guaranteeing predictive consistency with the full model F.
in the base model, and can trigger a prediction before the full model is executed. Naively deciding when to preempt computation, however, can result in unpredictable decreases in model accuracy.
Quantifying the uncertainty in a prediction in order to decide when additional computation is needed (or not) is critical to making predictions quickly without excessively sacriﬁcing performance. In this paper, we present Conﬁdent Adaptive Transformers (CATs), a general method for increasing Transformer-based model efﬁciency while remaining conﬁdent in the quality of our predictions. Speciﬁcally, given a ﬁxed, expensive llayer model F(x), we create an amortized model G(x) that includes early classiﬁers {F1, . . . , Fl}.2 We then make G provably consistent with the original F with arbitrarily high probability (e.g., 95% of the time). This process is illustrated in Figure 1.
Our approach builds on conformal prediction (CP), a model-agnostic and distribution-free framework for creating well-calibrated predictions (Vovk et al., 2005). Concretely, suppose we have been
2We simply deﬁne the ﬁnal Fl as Fl(x) F (x) ∀x.

(Ex.1) Claim: All airports in Guyana were closed for all international passenger ﬂights until 1 May 2020. Evidence: Airports in Guyana are closed to all international passenger ﬂights until 1 May 2020.
(Ex.2) Claim: Deng Chao broke sales record for a romantic drama. Evidence: The ﬁlm was a success and broke box ofﬁce sales record for mainland-produced romance ﬁlms.

Figure 2: Conﬁdence levels given by our meta model regarding the consistency of our prediction as computation progresses. Ex.1 from the VitaminC fact veriﬁcation dataset is “easy”, and is classiﬁed consistently by all early classiﬁers Fk (Supports). The meta conﬁdence captures this, and increases with time. Ex.2 is harder—and the prediction changes (Refutes/NEI) as it propagates though the Transformer layers. Appropriately, the meta conﬁdence is low. The exact exit layer of G is determined as a function of a user-speciﬁed tolerance , see Eq. (1).

given n examples, Xi ∈ X , i = 1, . . . , n, as unlabeled calibration data, that have been drawn exchangeably from some underlying distribution P . Let Xn+1 ∈ X be a new exchangeable test example for which we would like to make a prediction. The aim of our method is to construct G such that it agrees with F with distribution-free marginal coverage at a tolerance level ∈ (0, 1), i.e.,
P G(Xn+1) = F (Xn+1) ≥ 1 − . (1)
We consider G to be -consistent if the frequency of error, G(Xn+1) = F (Xn+1), does not exceed .3 By design, this ensures that G preserves at least (1 − )-fraction of F’s original performance. Within these constraints, the remaining challenge is to make G relatively efﬁcient (e.g., a consistent, but vacuous, model is simply the identity G F).
In order to support an efﬁcient G, we need a reliable signal for inferring whether or not the current prediction is likely to be stable. Past work (e.g., Schwartz et al., 2020) rely on potentially poorly correlated metrics such as the early classiﬁer’s softmax response. We address this challenge by instead directly learning meta “consistency predictors” for each of the l − 1 early classiﬁers of our l layer model, by leveraging patterns in past predictions.4 Figure 2 demonstrates the progression of meta conﬁdence scores across layers when applied to “easy” versus “hard” instances from the VitaminC fact veriﬁcation task (Schuster et al., 2021).
3For regression, we deﬁne equality as |G(·) − F (·)| ≤ τ . 4We refer to the meta aspect of the classiﬁer, not the optimization process (i.e., not to be confused with meta-learning).

We pair the scores of our meta classiﬁer for each layer with a stopping rule that is calibrated using a unique twist on standard conformal prediction. Traditionally, CP is used to construct prediction sets that cover the desired target (e.g., Yn+1) with high probability. We invert the CP problem to ﬁrst infer the multi-label set of inconsistent layers, and then exit at the ﬁrst layer that falls in its complement. We then demonstrate that this can be reduced to setting a simple (but well-calibrated) exit threshold for the meta classiﬁer scores. Our resulting algorithm is (1) fast to compute in parallel to the main Transformer, (2) requires only unlabeled data, and (3) is statistically efﬁcient in practice, in the sense that it ﬁnds low exit layers on average while still maintaining the required predictive consistency.
We validate our method on four diverse NLP tasks—covering both classiﬁcation and regression, different label space sizes, and varying amounts of training data. We ﬁnd that it constitutes a simpleyet-effective approach to conﬁdent adaptive prediction with minimal interventions and desirable theoretical guarantees. In short, we provide:
1. A novel theoretical extension of conformal prediction to accommodate adaptive prediction;
2. An effective meta consistency classiﬁer for deriving a conﬁdent “early exiting” model;
3. A demonstration of the utility of our framework on both classiﬁcation and regression tasks, where we show signiﬁcant efﬁciency improvements, while guaranteeing high consistency.

2

2 Related Work
Adaptive computation. Reducing the computational cost of neural models has received intense interest. Adaptive approaches adjust the amount of computation per example to amortize the total inference cost (see Teerapittayanon et al., 2017; Graves, 2017; Huang et al., 2018; Kaya et al., 2019; Wang et al., 2018, inter alia). As discussed in §1, our method is inspired by the approach of Schwartz et al. (2020) and others (Liu et al., 2020; Geng et al., 2021; Zhou et al., 2020), where they preempt computation if the softmax value of any early classiﬁer is above a predeﬁned threshold. Yet unlike our approach, their model is not guaranteed to be accurate. In concurrent work, Xin et al. (2021) propose a meta conﬁdence classiﬁer similar to ours. However, as in previous work, they do not address the calibration part to guarantee consistency.
Conﬁdent prediction. A large amount of research has been dedicated towards calibrating the model posterior, pθ(yˆn+1|xn+1), such that the accuracy, yn+1 = yˆn+1, is indeed equal to the estimated probability (Niculescu-Mizil and Caruana, 2005; Gal and Ghahramani, 2016; Guo et al., 2017). In theory, these estimates could be leveraged to create conﬁdent early exits—e.g., similar to Schwartz et al. (2020). Ensuring calibrated probabilities of this form is hard, however, and existing methods often still suffer from miscalibration. Additionally, many methods exist for bounding the true error of a classiﬁer (Langford, 2005; Park et al., 2021), but do not give end-users opportunities to control it. More similar to our work, selective classiﬁcation (Geifman and El-Yaniv, 2017) allows the model to abstain from answering when not conﬁdent, in order to maintain a target error rate only over answered inputs. Our work gives a different and statistically efﬁcient technique applied to consistent prediction.
Conformal prediction. CP (Vovk et al., 2005) typically is formulated in terms of prediction sets C(Xn+1), where ﬁnite-sample, distribution-free guarantees can be given over the event that C contains Yn+1. As we discuss in §4, internally our method follows a similar approach in which we try to conservatively identify the inadmissible set of all layers that are inconsistent (and exit at the ﬁrst layer that falls in that set’s complement). Most relevant to our work, Cauchois et al. (2021) presents algorithms for conformal multi-label predictions. We leverage similar methods in our model, but formulate our solution in terms of the comple-

ment of a multi-label set of inconsistent predictions. Our work adds to several recent directions that explore CP in the context of risk-mitigating applications (Lei and Candès, 2020; Romano et al., 2020; Bates et al., 2020; Fisch et al., 2021a, inter alia), or meta-learning settings (Fisch et al., 2021b).
3 Early Exiting Transformers
In the following, we describe our dynamic early exiting model. We summarize early classiﬁcation (following previous work) for convenience (§3.1), and then present our novel meta consistency classiﬁer (§3.2). We focus on classiﬁcation and regression tasks, given a model F(x) = y. We assume that F maps the input x ∈ X into a series of feature representations before making the prediction y ∈ Y. Here, F is a multilayered Transformer (Vaswani et al., 2017) composed of l layers (although our method can be applied to any multilayer network).
For all downstream tasks we follow standard practice and assume that the input contains a [CLS] token whose representation is used for prediction. For classiﬁcation, we use a task-speciﬁc head, softmax(Wo(φ(Wph[CLS]))), where h[CLS] ∈ Rd is the hidden representation of the [CLS] token,5 φ is a nonlinear activation, and W∗ are linear projections, where Wp ∈ Rd×d and Wo ∈ R|Y|×d. Regression is treated similarly, but uses a 1-d output projection, wo · h[CLS].
3.1 Early predictors
F’s structure yields a sequence of hidden [CLS] representations, {h([1C)LS], . . . , h([lC)LS]}, where h([kC)LS] ∈ Rd is the representation after applying layer k. After each intermediate layer k < l, we train an early classiﬁcation head that is similar to the head used in F, but reduce the dimensionality of the ﬁrst projection to Wp(k) ∈ Rde×d (this is purely for efﬁciency6). The ﬁnal Fl is unchanged from F . These extra (l−1)×(de ×d+de ×|Y|) parameters are quick to tune on top of a ﬁxed F, and we can reuse F ’s training data as Dtune.7 The classiﬁer Fk(x) = softmax(Wo(k)(φ(Wp(k)h([kC)LS]))) is then used after layer k to get an early prediction candidate. Early regression is handled similarly.
3.2 Meta early exit classiﬁer
To decide when to accept the current prediction and stop computation, we require some signal as
5d varies by F . In Albert-xlarge d = 2048. 6We simply set de = 32 in all our experiments. 7Or if Dtune is unlabeled, we can use F (x) as labels.

3

Meta Feature

Description

yˆk history
pmk ax pdkiﬀ

The current prediction. The past k − 1 predictions, yˆ1:k−1 (For classiﬁcation we give pk(yˆk|x)). Prob. of the prediction, pk(yˆk|x).
Difference in prob. of top predictions, pk(yˆk|x) − argmaxyk=yˆk pk(yk|x).

Table 1: Additional meta features used as input to the
meta early exit classiﬁer, Mk. Where speciﬁed, the probability pk is taken from the model’s early softmax. pmk ax and pdkiﬀ are only used for classiﬁcation tasks.

to how likely it is that Fk(x) = F (x). Previous work relies on intrinsic measures (e.g., soft-
max response). Here, we present a meta classi-
ﬁer to explicitly estimate the consistency of an early predictor. Given ﬁxed Fk and F , we train a small binary MLP, Mk(x) ∈ R, on another unlabeled (limited) sample of task in-domain data, Dmeta. As input, we provide the current “early” hidden state φ(Wp(k)h([kC)LS]), in addition to several processed meta features, see Table 1. We then train Mk with a binary cross entropy objective, where we maximize the likelihood of predicting 1{Fk(xi) = F (xi)} for xi ∈ Dmeta.
Using the trained Fk and Mk, we deﬁne the full adaptive model G using the prediction rule

F1(x) if M1(x) > τ1,   F2(x) else if M2(x) > τ2, G(x; τ ) :=  ... (2)   Fl(x) otherwise,

where τ = (τ1, . . . , τl−1) are conﬁdence thresholds. The key challenge is to calibrate τk such that G guarantees -consistent performance per Eq. (1).

3.3 Warmup: development set calibration

A simple approach to setting τ is to optimize performance on a development set Ddev, subject to a constraint on the empirical inconsistency:

τ ∗ := minimize Edev[exit(G(X; τ ))]

(τ1,...,τl−1)

(3)

s.t. Edev[1{G(X; τ ) = F (X)}] ≥ 1 − ,

where exit(·) measures the exit layer, and Edev is simply the average over Ddev. Using a standard

error bound (Langford, 2005) over a separate split,

Dcal, we can then derive the following guarantee:

Proposition 3.1. Let Xi, i = 1, . . . , n be an i.i.d.

sample with s =

n i=1

1{G

(Xi

;

τ

)

=

F (Xi)}.

Then, up to a conﬁdence level δ, we have that

P(P(G(X; τ ) = F(X)) ≥ 1 − ˜) ≥ 1 − δ, (4)

where ˜ is the solution to Beta(s, n − s + 1) = δ, and Beta is the incomplete beta function.
A proof is given in Appendix A. Though in practice ˜ might be close to for most well-behaved distributions, unfortunately Eq. (4) does not give a fully speciﬁable guarantee as per Eq. (1). Readjusting τ based on Dcal requires correcting for multiple testing in order to remain theoretically valid, which can quickly become statistically inefﬁcient. In the next section, we provide a novel calibration approach that allows us to guarantee a target performance level with strong statistical efﬁciency.
4 Conformalized Early Exits
We now formulate the main contribution of this paper, which is a distribution-free and model-agnostic method based on CP for guaranteeing any performance bound an end-user chooses to specify.8 Our training (§3), conformal calibration (§4), and inference pipelines are summarized in Algorithm 1.
4.1 Conformal formulation
Let I(x) := {i : Fi(x) = F (x)} be the index set of layers that are inconsistent with the ﬁnal model’s prediction. To maintain -consistency, we must avoid using any of the predictions speciﬁed by this set, Fi(x) where i ∈ I(x), more than -fraction of the time for x ∈ X . In §4.2, we show how M1:l−1 can be paired with a conformal procedure to obtain calibrated thresholds τ = (τ1, . . . , τl−1) such that we obtain a conservative prediction of I(x),

C (x) := {k : Mk(x) ≤ τk},

(5)

where we ensure that I(x) ⊆ C (x) with probability at least 1 − . Proposition 4.1 states our guarantee when τ is paired with G following Eq. (2).
Proposition 4.1. Assume that examples Xi, i = 1, . . . , n + 1 are exchangeable. For any ∈ (0, 1), let the index set C (based on the ﬁrst n examples) be the output of conformal procedure satisfying

P(I(Xn+1) ⊆ C (Xn+1)) ≥ 1 − . (6)
Deﬁne K := min{j : j ∈ Cc(Xn+1)}, the ﬁrst exit layer selected by G following Eq. (2).9 Then

P(FK (Xn+1) = F (Xn+1)) ≥ 1 − . (7)

Remark 4.2. Note that Eq. (6) is stricter than necessary. Fundamentally, we only require that
8See Shafer and Vovk (2008) for a concise review of CP. 9Here Ac denotes the complement index set {i : i ∈ A}.

4

P(K ∈ Ic(Xn+1)) ≥ 1 − . Nevertheless, Eq. (6) is easier to calibrate, and leads to strong empirical results despite being theoretically conservative.
Remark 4.3. During inference we do not fully construct C ; it is only used to calibrate τ beforehand.
4.2 Conformal calibration
We now describe our conformal procedures for calibrating τ . Conformal prediction is based on hypothesis testing, where for a given input x and possible output y, a statistical test is performed to accept or reject the null hypothesis that the pairing (x, y) is correct. In our setting, we consider the null hypothesis that layer k is inconsistent, and we use Mk(x) as our test statistic. Since Mk is trained to predict 1{Fk(xi) = F (xi)}, a high value of Mk(x) indicates how “surprised” we would be if layer k was in fact inconsistent with layer l for input x. Informally, a low level of surprise indicates that the current input “conforms” to past data. To rigorously quantify the degree of conformity via the threshold τk for predictor Mk, we use a held-out set of n unlabeled, exchangeable examples, Dcal.
4.2.1 Independent calibration
As a ﬁrst approach, we construct C (x) by composing l − 1 separate tests for Fk(x) = F (x), each with signiﬁcance αk, where αk are corrected for multiple testing. Let vk(1:n,∞) denote the inﬂated empirical distribution of inconsistent layer scores,

{Mk(xi) : xi ∈ Dcal, Fk(xi) = F (xi)} ∪ {∞}.

Inﬂating the empirical distribution is critical to our
ﬁnite sample guarantee, see Appendix A. We then deﬁne τkind = Quantile 1 − αk, vk(1:n,∞) , and predict the inconsistent index set at x ∈ X as

Cind(x) = k : Mk(x) ≤ τkind . (8)

The following theorem states how to set each αk such that the quantiles τkind yield a valid Cind.

Theorem 4.4. Let αk = ωk · , where ωk is a

weighted Bonferroni correction, i.e.,

l−1 k=1

ωk

=

1.

Then Cind(Xn+1) is a valid set that satisﬁes Eq. (6).

Remark 4.5. ω1:l−1 can be tuned on a development set Ddev as long as Ddev is distinct from Dcal.

4.2.2 Shared calibration
Cind has the advantage of calibrating each layer independently. As l grows, however, αk will tend to 0 in order to retain validity (as speciﬁed by Theorem 4.4). As a result, Cind will lose statistical

Algorithm 1 Consistent accelerated inference.
Deﬁnitions: F is a multilayered classiﬁer trained on Dtrain. Dtune, Dmeta and Dscale are collections of in-domain unlabeled data points (in practice, we reuse Dtrain and divide it to 70/20/10%, respectively). Dcal has in-domain unlabeled examples not in Dtrain (In practice, we take a subset of the task’s validation set). is the user-speciﬁed consistency tolerance.

1: function TRAIN (F , Dtune, Dmeta) 2: # Learns F1...l−1 and M1...l−1 components 3: # of amortized model G for Eq. (2) (see §3.1 and §3.2). 4: Initialize G from F and add early prediction heads. 5: # (All of F’s base parameters in G are frozen.) 6: Train prediction heads F1...l−1 on Dtune. 7: Add meta early exit classiﬁers M1...l−1 to G. 8: # (All of G’s other parameters are frozen.) 9: Train meta early exit classiﬁers M1...l−1 on Dmeta. 10: Optionally apply temperature scaling using Dscale. 11: return G

12: function CALIBRATE (G, Dcal, )

13: # Sets thresholds τ of amortized model G for Eq. (2)

14: # using shared calibration (see §4.2.2).

15: M ← {∞}

16: for x ∈ Dcal do

17: S ← {}

18: # Record all inconsistent layers for input x.

19: # Keep the highest (false) conﬁdence score.

20: for k ∈ [1, l − 1] do

21:

if Fk(x) = F (x) then

22:

S ← S ∪ Mk(x)

23: M ← M ∪ max (S)

24: # Share one threshold across layers. 25: τ share ← Quantile 1 − , M
26: return [τ share] × (l − 1)

27: function PREDICT (G, τ , x)

28: # Implements Eq. (2) to exit early with conﬁdence.

29: for k ∈ [1, l − 1] do

30:

Compute the k-th prediction head of G, Fk(x).

31:

if Mk(x) > τk then

32:

return Fk(x)

33: # Fallback to prediction using full computation. 34: return Fl(x)

efﬁciency. Following a similar approach to Cauchois et al. (2021) and Fisch et al. (2021a), we compute a new test statistic, Mmax, as
Mmax(x) = max {Mk(x) : Fk(x) = F (x)}. (9)
k∈[l−1]
We discard ill-deﬁned values when Mmax(x) = max ∅. Mmax(x) reﬂects the worst-case conﬁdence across inconsistent layers for input x (i.e., where Mk(x) predicts a high consistency likelihood for layer k when layer k is, in fact, inconsistent). This worst-case statistic allows us to keep a constant signiﬁcance level , even as l grows. Let m(1:n,∞) denote the inﬂated empirical distribution,
{Mmax(xi) : xi ∈ Dcal, ∃k Fk(xi) = F (xi)} ∪ {∞}.
We then deﬁne a single threshold shared across layers, τ share = Quantile 1 − , m(1:n,∞) , and

5

Dataset |Y| Train Dev. Test F test perf.

IMDB

2 20K 5K 25K

94.0

VitaminC 3 370K 10K∗ 55K

90.6

AG News 4 115K 5K 7.6K

94.4

STS-B

∞ 5.7K 1.5K 1.4K

89.8

Table 2: Task dataset and label space sizes. The rightmost column reports either test accuracy (classiﬁcation) or Pearson-correlation (regression). ∗We downsample the 63K public development set to expedite validation.

predict the inconsistent index set at x ∈ X as

Cshare(x) = k : Mk(x) ≤ τ share

(10)

Theorem 4.6. For any number of layers l ∈ N+, Cshare(Xn+1) is a valid set that satisﬁes Eq. (6).
5 Experimental Setup
For our main results, we use an Albert-xlarge model (Lan et al., 2020) with 24 Transformer layers. Results using an Albert-base model and a RoBERTa-large model (Liu et al., 2019) are in Appendix C. See Appendix B for implementation details. We did not search across different values for the hyper-parameters of F or G as our approach is general and guarantees consistency for any F with any nonconformity measure (See Appendix C.2). Tuning the hyper-parameters could further improve the efﬁciency of G while preserving consistency.
5.1 Tasks
We evaluate our methods on three classiﬁcation tasks with varying label space size |Y| and difﬁculty: IMDB (Maas et al., 2011) sentiment analysis on movie reviews, VitaminC (Schuster et al., 2021) fact veriﬁcation with Wikipedia articles, and AG (Gulli, 2004; Zhang et al., 2015) news topic classiﬁcation. We also evaluate on the STS-B (Cer et al., 2017) semantic textual similarity regression task where Y ∈ [0, 5] ⊂ R. Dataset statistics, along with the test set performance of our original F model (Albert-xlarge), are contained in Table 2.
5.2 Baselines
In addition to our main methods discussed in §4.2, we compare to several non-CP baselines. Note that the following methods are not guaranteed to give well-calibrated performance (as our CP ones are).
Static. We use the same number of layers for all inputs. We choose the exit layer as the ﬁrst one that obtains the desired consistency on average on Dcal.
Softmax threshold. Following Schwartz et al. (2020), we exit on the ﬁrst layer where pmk ax ≥

1 − , where pmk ax denotes the maximum softmax response of our early classiﬁer. Softmax values are calibrated using temperature scaling (Guo, 2017) on another held-out (labeled) data split, Dscale.
Meta threshold. Even if perfectly calibrated, pmk ax from softmax thresholding is not measuring consistency likelihood P(G(X) = F(X) | X = x), but rather P(G(X) = Y | X = x). This is equivalent if F is an oracle, but breaks down when F is not. We also experiment with thresholding the conﬁdence value of our meta classiﬁer (§3.2) in a similar way (i.e., exiting when it exceeds 1 − ).
5.3 Evaluation
For each task, we use a proper training, validation, and test set. We use the training set to learn F and G. We perform model selection on the validation set, and report ﬁnal numbers on the test set. For all methods, we report the marginalized results over 25 random trials, where in each trial we partition the data into 80% Dcal (x1:n) and 20% Dtest (xn+1). In order to compare different methods across all tolerance levels, we plot each metric as a function of . Shaded regions show the 16-84th percentiles across trials. We report the following metrics:
Consistency. We measure the percent of inputs for which the prediction of the CAT model G is the same as the full Transformer on our test prediction, i.e., G(Xn+1) = F (Xn+1). For regression tasks, we count a prediction as consistent if it is within a small margin τ from the reference (we use τ = 0.5). As discussed in §1, if G is -consistent, we can also derive an average performance lower bound: it will be at least (1− )×F ’s average performance.10
Layers ( ). We report the computational cost of the model as the average number of Transformer layers used. Our goal is to improve the efﬁciency (i.e., use fewer layers) while preserving -consistency. We choose this metric over absolute run-time to allow for implementation-invariant comparisons, but we provide a reference analysis next, to permit easy approximate conversions.
5.4 Absolute runtime analysis
The exact run-time of G depends on the efﬁciency of the hardware, software, and implementation used. Ideally, the early and meta classiﬁers can run in parallel with the following Transformer layer (layer k + 1). As long as they are faster to compute
10In practice, the performance is likely to be higher than this lower bound, since inconsistencies with F could lead to a correct prediction when F would have otherwise been wrong.

6

(a) IMDB

(b) VitaminC

(c) AG News

Figure 3: Classiﬁcation results (dev). While both our CP-based methods give valid consistencies (above diagonal), shared calibration generally results in earlier exits. This advantage is especially pronounced at smaller tolerance levels (right-hand side), where it signiﬁcantly outperforms other approaches. Our meta-learned conﬁdence measure Mk improves over using the softmax response as a drop-in replacement, especially for tasks with larger |Y|. Note that we care more about the right-hand side behavior, (i.e., larger 1 − ), as it corresponds to higher consistency.

concurrently than a single layer, this will avoid incurring any additional time cost. An alternative naive synchronous implementation could lead to inefﬁciencies when using a small tolerance .
We provide a reference timing for the IMDB task implemented with the Transformers (Wolf et al., 2020) library, PyTorch 1.8.1 (Paszke et al., 2019), and an A100-PCIE-40GB Nvidia GPU with CUDA 11.2. A full forward path of an Albert-xlarge takes 22.32ms per input, 0.85ms ×24 for the transformer layers and 1.95ms for the embedding layer and top classiﬁer. Our early classiﬁer takes 0.20ms and the meta classiﬁer takes 0.11ms. Therefore, with a naive implementation, a CAT model G with an average exit layer less than 17.6 with the meta classiﬁer, or 19.5 without, will realize an overall reduction in wall-clock time relative to the full F.
We report example speedup times with the naive implementation in §6.3, as well as an implementation invariant multiply-accumulate operation (MACs) reduction measure. The added computational effort per layer of the early predictor and meta-classiﬁer is marginal (only 66, 304 and 1, 920 MACs, respectively). In comparison, Albert-xlarge with an input length of 256 has ∼ 3 · 1011 MACs.
6 Experimental Results
We present our main results. We experiment with both our meta classiﬁer Mk conﬁdence score (Meta, §3.2), and, for classiﬁcation tasks, the early

classiﬁer’s softmax response, pmk ax (SM), as a dropin replacement for Mk (at no additional computational cost). Appendix C reports results with other drop-in Mk replacements, in addition to results using our naive development set calibration approach (§3.3). Appendix D provides qualitative examples.
6.1 Classiﬁcation results
Figure 3 summarizes the average consistency and number of layers used by G as a function of , while Table 3 presents results for speciﬁc on task test sets. Independent calibration proves to be quite conservative due to the loss of statistical power from the loose union bound of the Bonferroni correction for large l (here l = 24). At some levels of , non-CP baselines perform competitively, however, they lack formal guarantees. Overall, for the most critical tolerance levels (small , right-hand side of the plots), our shared method leads to signiﬁcant efﬁciency gains while still maintaining the desired level of consistency (above the diagonal).
The effectiveness of our meta predictor, Mk, is most pronounced for tasks with |Y| > 2, where the drop-in softmax score (SM) becomes less indicative of consistency. Both SM and Meta are relatively well-calibrated for IMDB and VitaminC, which makes the threshold-based exit rule a competitive baseline. Still, our Shared/ Meta method provides both reliable and signiﬁcant gains.
The computational advantage of our CAT model

7

Method
1 − = 0.95:
Static Thres./ SM Thres./ Meta Indep./ Meta Shared/ SM Shared/ Meta
1 − = 0.90:
Static Thres./ SM Thres./ Meta Indep./ Meta Shared/ SM Shared/ Meta

Consist.
95.54 99.65 99.98 99.66 97.17 97.15
90.82 98.88 99.75 99.39 94.34 94.36

IMDB Acc.
(88.50)
92.88 94.01 93.96 93.82 93.24 92.71
(83.84)
89.47 93.93 93.86 93.67 91.77 90.78

Layers
18.36 16.55 17.73 15.69 12.65 10.83
14.00 14.71 15.30 14.85 10.30 9.01

VitaminC Consist. Acc.

95.51 99.83 99.73 99.07 96.87 96.91

(86.10)
89.40 90.59 90.59 89.97 88.99 89.01

92.57 99.05 99.10 98.29 93.73 93.83

(81.57)
87.80 90.27 90.31 89.42 87.00 86.89

Layers
21.00 20.07 19.67 19.60 17.58 16.79
19.00 18.91 18.45 18.50 16.40 15.33

Consist.
95.48 100.00
99.41 99.81 97.15 97.08
90.88 99.68 98.90 99.60 94.50 94.29

AG News Acc.
(89.02)
93.20 94.44 94.00 94.31 93.43 92.50
(84.33)
89.10 94.21 93.82 94.18 92.01 90.26

Layers
22.00 22.28 16.21 20.58 13.24 10.17
14.00 19.53 13.50 17.65 10.79 8.35

Table 3: Classiﬁcation results (test) for speciﬁc tolerance levels. We report the accuracy lower bound guaranteed by our CP methods in parentheses. Shared/ Meta is reliably the most efﬁcient method (and is -consistent). Greyed rows reﬂect approaches without guarantees; our CAT approaches with guarantees are presented below them.

Method
1 − = 0.95: Static Thres./ Meta Indep./ Meta Shared/ Meta
1 − = 0.90: Static Thres./ Meta Indep./ Meta Shared/ Meta

Consist.
100.00 99.87 99.29 96.42
92.51 99.19 97.77 92.65

Layers
24.00 19.19 23.60 17.64
20.00 18.53 20.26 17.29

Table 4: Test results for the STS-B regression task.

Figure 4: Dev results for the STS-B regression task.
is dependent on the average difﬁculty of the task and the implementation. As Table 3 shows, allowing up to an of 10% inconsistency, for two of the tasks we cut down the average Transformer layer to only 9 out of 24 using our Shared/ Meta model. This leads to an approximate speedup of 1.8× with a synchronous implementation and of 2.7× with a concurrent one, compared to running the full model. Moreover, Figure 5 illustrates the user’s control over available computational resources via modulating . Decreasing increases the conﬁdence level required before committing to the early classiﬁer’s prediction (thereby increasing the average number of required layers), and vice-versa.

6.2 Regression results
Table 4 and Figure 4 present results for our regression task, where we see similar trends. Here, an attractive advantage of our meta conﬁdence predictor is its generalizability to multiple task output types. Notice that the event space of 1{G(X) = F(X)} = {0, 1} always, regardless of the original Y.11 This allows it to be easily adapted to tasks beyond classiﬁcation, such as regression, where traditional softmax-based conﬁdence measures (as used in, e.g., Schwartz et al. (2020)) are absent.
6.3 Example efﬁciency gains
Following the analysis in §5.4, we compute the amortized inference time with a naive implementation and report its percentage out of the full model. As Table 5 shows, our Shared calibration is the most efﬁcient method on all four tasks. For tasks with many easy inputs (IMDB and AG News), our Shared/ Meta method can save 45% - 49% of the
11As long as equality is suitably deﬁned, e.g., for STS-B we deﬁne consistent outputs as being within τ = 0.5 away.

8

Figure 5: Distribution of exit layers per tolerance level for the IMDB task (dev set) with Shared/ Meta. Larger allows the CAT model to shift its predictions earlier by permitting for more inconsistencies with the full model F.

Method
Thres./ SM Thres./ Meta Indep./ Meta Shared/ SM Shared/ Meta

IMDB

Amortized time (100 · TG/TF ) VitaminC AG News

76.91 87.22 84.88 56.16 54.53 %

96.66 103.59 103.85
84.86 87.38 %

99.58 77.87 99.44 58.47 51.10 %

STS-B
N/A 104.01 113.00
N/A 97.56 %

MACs reduction (|F|/|G|) IMDB VitaminC AG News STS-B

1.63 1.57 1.62 2.33 ×2.66

1.27 1.30 1.30 1.46 ×1.57

1.23 1.78 1.36 2.22 ×2.87

N/A 1.30 1.18 N/A ×1.39

Table 5: Reference time speedup and model complexity reduction for 1 − = 0.90 (see Table C.2 for 0.95). We compute the amortized time with the naive synchronous implementation (§5.4). A more efﬁcient implementation can further reduce the time of G. The MACs reduction measure is implementation agnostic and expresses the ratio of computational effort saved by G. Our CAT models (non-greyed lines) not only guarantee 1 − consistency with F, but are also signiﬁcantly more efﬁcient in practice when using Shared calibration.

inference time when 1 − = 0.90. Unsurprisingly, the absolute speedup is less signiﬁcant for harder tasks, but increases with higher tolerance levels.
On VitaminC, even though the Meta measure allows exiting on earlier layers, its additional meta classiﬁers result in slightly slower inference on average at this tolerance level, compared to our Shared/ SM. With a more efﬁcient concurrent implementation, the Meta measure will be favorable.
We also compute the MACs reduction metric which is independent of the speciﬁc implementation or hardware and shows the number of multiplyaccumulate operations of the full model compared to our CAT model. As demonstrated in Table 5, our Shared/ Meta method is most effective in reducing the computational effort across all tasks for the two examined tolerance levels.
7 Conclusion
The ability to make predictions quickly without excessively degrading performance is critical to production-level machine learning systems. In fact, being capable of quantifying the uncertainty in a prediction and deciding when additional computation is needed (or not) is a key challenge for any intelligent system (e.g., see the System 1 vs. System 2 dichotomy explored in Kahneman (2011)).
In this work, we addressed the crucial challenge

of deciding when to sufﬁciently trust an early prediction of Transformer-based models by learning from their past predictions. Our Conﬁdent Adaptive Transformers (CATs) framework leverages meta predictors to accurately assess whether or not the prediction of a simple, early classiﬁer trained on an intermediate Transformer representation is likely to already be consistent with that of the full model F(X) (i.e., after all l layers of F are computed). Importantly, we develop a new conformal prediction approach for calibrating the conﬁdence of the meta classiﬁer that is (1) simple to implement, (2) fast to compute alongside the Transformer, (3) requires only unlabeled data, and (4) provides statistically efﬁcient marginal guarantees on the event that the prediction of the faster, amortized CAT model is consistent with that of the full F. Our results on multiple tasks demonstrate the generality of our approach, and its effectiveness in consistently improving computational efﬁciency— all while maintaining a reliable margin of error.
Acknowledgements
We thank the MIT NLP group for helpful discussions. TS is supported in part by DSO grant DSOCL18002. AF is supported in part by an NSF GRFP. This work is also supported in part by DSTA award DST00OECI20300823.

9

References
Stephen Bates, Anastasios Nikolas Angelopoulos, Lihua Lei, Jitendra Malik, and Michael I. Jordan. 2020. Distribution free, risk controlling prediction sets. arXiv preprint: arXiv 2101.02703.
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel HerbertVoss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Advances in Neural Information Processing Systems, volume 33, pages 1877–1901. Curran Associates, Inc.
Maxime Cauchois, Suyash Gupta, and John C. Duchi. 2021. Knowing what you know: valid and validated conﬁdence sets in multiclass and multilabel prediction. Journal of Machine Learning Research, 22(81):1–42.
Daniel Cer, Mona Diab, Eneko Agirre, Iñigo LopezGazpio, and Lucia Specia. 2017. SemEval-2017 task 1: Semantic textual similarity multilingual and crosslingual focused evaluation. In Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017), pages 1–14, Vancouver, Canada. Association for Computational Linguistics.
C. J. Clopper and E. S. Pearson. 1934. The use of conﬁdence or ﬁducial limits illustrated in the case of the binomial. Biometrika, 26(4):404–413.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.
Angela Fan, Edouard Grave, and Armand Joulin. 2020. Reducing transformer depth on demand with structured dropout. In International Conference on Learning Representations (ICLR).
Adam Fisch, Tal Schuster, Tommi Jaakkola, and Regina Barzilay. 2021a. Efﬁcient conformal prediction via cascaded inference with expanded admission. In International Conference on Learning Representations (ICLR).
Adam Fisch, Tal Schuster, Tommi Jaakkola, and Regina Barzilay. 2021b. Few-shot conformal prediction with auxiliary tasks. In International Conference on Machine Learning (ICML).

Yarin Gal and Zoubin Ghahramani. 2016. Dropout as a bayesian approximation: Representing model uncertainty in deep learning. In International Conference on Machine Learning (ICML), volume 48 of Proceedings of Machine Learning Research, pages 1050–1059. PMLR.
Yonatan Geifman and Ran El-Yaniv. 2017. Selective classiﬁcation for deep neural networks. In Advances in Neural Information Processing Systems, volume 30.
Shijie Geng, Peng Gao, Zuohui Fu, and Yongfeng Zhang. 2021. Romebert: Robust training of multiexit bert.
Alex Graves. 2017. Adaptive computation time for recurrent neural networks.
Antonio Gulli. 2004. Ag’s corpus of news articles.
Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. 2017. On calibration of modern neural networks. In International Conference on Machine Learning (ICML), volume 70, pages 1321–1330, International Convention Centre, Sydney, Australia. PMLR.
Hongyu Guo. 2017. A deep network with visual text composition behavior. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 372–377, Vancouver, Canada. Association for Computational Linguistics.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. Deep residual learning for image recognition.
Gao Huang, Danlu Chen, Tianhong Li, Felix Wu, Laurens van der Maaten, and Kilian Weinberger. 2018. Multi-scale dense networks for resource efﬁcient image classiﬁcation. In International Conference on Learning Representations (ICLR).
Daniel Kahneman. 2011. Thinking, fast and slow. Farrar, Straus and Giroux, New York.
Yigitcan Kaya, Sanghyun Hong, and Tudor Dumitras. 2019. Shallow-deep networks: Understanding and mitigating network overthinking. In International Conference on Machine Learning (ICML), volume 97, pages 3301–3310. PMLR.
Diederik P. Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. In International Conference on Learning Representations (ICLR).
Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut. 2020. Albert: A lite bert for self-supervised learning of language representations. In International Conference on Learning Representations (ICLR).
John Langford. 2005. Tutorial on practical prediction theory for classiﬁcation. Journal of Machine Learning Research, 6(10):273–306.

10

Lihua Lei and Emmanuel Candès. 2020. Conformal inference of counterfactuals and individual treatment effects.
Weijie Liu, Peng Zhou, Zhiruo Wang, Zhe Zhao, Haotang Deng, and Qi Ju. 2020. FastBERT: a selfdistilling BERT with adaptive inference time. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6035– 6044, Online. Association for Computational Linguistics.
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach.
Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. 2011. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 142–150, Portland, Oregon, USA. Association for Computational Linguistics.
Alexandru Niculescu-Mizil and Rich Caruana. 2005. Predicting good probabilities with supervised learning (icml). In International Conference on Machine Learning (ICML).
Sangdon Park, Shuo Li, Insup Lee, and Osbert Bastani. 2021. PAC conﬁdence predictions for deep neural network classiﬁers. In International Conference on Learning Representations.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. 2019. Pytorch: An imperative style, high-performance deep learning library. In Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc.
Yaniv Romano, Rina Foygel Barber, Chiara Sabatti, and Emmanuel Candès. 2020. With malice toward none: Assessing uncertainty via equalized coverage. Harvard Data Science Review.
Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2020. Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter.
Tal Schuster, Adam Fisch, and Regina Barzilay. 2021. Get your vitamin c! robust fact veriﬁcation with contrastive evidence. In North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT).
Roy Schwartz, Jesse Dodge, Noah A. Smith, and Oren Etzioni. 2019. Green ai.

Roy Schwartz, Gabriel Stanovsky, Swabha Swayamdipta, Jesse Dodge, and Noah A. Smith. 2020. The right tool for the job: Matching model and instance complexities. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6640–6651, Online. Association for Computational Linguistics.
Glenn Shafer and Vladimir Vovk. 2008. A tutorial on conformal prediction. Journal of Machine Learning Research (JMLR), 9:371–421.
Or Sharir, Barak Peleg, and Yoav Shoham. 2020. The cost of training nlp models: A concise overview. arXiv preprint: arXiv 2006.06138.
Surat Teerapittayanon, Bradley McDanel, and H. T. Kung. 2017. Branchynet: Fast inference via early exiting from deep neural networks.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems (NeurIPS).
Vladimir Vovk, Alex Gammerman, and Glenn Shafer. 2005. Algorithmic Learning in a Random World. Springer-Verlag, Berlin, Heidelberg.
Xin Wang, Fisher Yu, Zi-Yi Dou, Trevor Darrell, and Joseph E. Gonzalez. 2018. Skipnet: Learning dynamic routing in convolutional networks. In The European Conference on Computer Vision (ECCV).
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. 2020. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38–45, Online. Association for Computational Linguistics.
Ji Xin, Rodrigo Nogueira, Yaoliang Yu, and Jimmy Lin. 2020a. Early exiting BERT for efﬁcient document ranking. In Proceedings of SustaiNLP: Workshop on Simple and Efﬁcient Natural Language Processing, pages 83–88, Online. Association for Computational Linguistics.
Ji Xin, Raphael Tang, Jaejun Lee, Yaoliang Yu, and Jimmy Lin. 2020b. DeeBERT: Dynamic early exiting for accelerating BERT inference. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2246–2251, Online. Association for Computational Linguistics.
Ji Xin, Raphael Tang, Yaoliang Yu, and Jimmy Lin. 2021. BERxiT: Early exiting for BERT with better

11

ﬁne-tuning and extension to regression. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 91–104, Online. Association for Computational Linguistics.
Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015. Character-level convolutional networks for text classiﬁcation. In Advances in Neural Information Processing Systems, volume 28. Curran Associates, Inc.
Wangchunshu Zhou, Canwen Xu, Tao Ge, Julian McAuley, Ke Xu, and Furu Wei. 2020. Bert loses patience: Fast and robust inference with early exit. In Advances in Neural Information Processing Systems, volume 33, pages 18330–18341. Curran Associates, Inc.
A Proofs
We ﬁrst state the following useful lemma on inﬂated sample quantiles.
Lemma A.1. Let Quantile(α; F ) denote the α quantile of distribution F . Let V1:n denote the empirical distribution over random variables {V1, . . . , Vn}. Furthermore, assume that Vi, i = 1, . . . , n + 1 are exchangeable. Then for any α ∈ (0, 1), we have P (Vn+1 ≤ Quantile(α, V1:n ∪ {∞})) ≥ α.
Proof. This is a well-known result. Given support points v1, . . . , vn ∈ R for a discrete distribution F , let q = Quantile(α; F ). Any points vi > q do not affect this quantile, i.e., if we consider a new distribution F˜ where all points vi > q are mapped to arbitrary values also larger than q then Quantile(α; F ) = Quantile(α; F˜). Accordingly, for the exchangeable Vi, we have
Vn+1 > Quantile(α; V1:n ∪ {∞}) ⇐⇒
Vn+1 > Quantile(α; V1:(n+1)).
Equivalently, we also have that
Vn+1 ≤ Quantile(α; V1:n ∪ {∞}) ⇐⇒
Vn+1 ≤ Quantile(α; V1:(n+1)).
Given the discrete distribution over the n + 1 variables Vi, Vn+1 ≤ Quantile(α; V1:(n+1)) implies that Vn+1 is among the α(n + 1) smallest of V1:(n+1). By exchangeability, this event occurs with probability at least α(nn++11) ≥ α.
A.1 Proof of Proposition 3.1
Proof. This result is based on Clopper-Pearson conﬁdence interval for Binomial random variables (Clopper and Pearson, 1934). As the binary events 1{G(Xi; τ ) = F (Xi)} are i.i.d., the

sum s is Binomial. Directly applying a one-sided Clopper-Pearson lower bound on the true success rate, P(G(Xi; τ ) = F (Xi)), gives the result.
A.2 Proof of Proposition 4.1 Proof. We prove by simple calculation using the property assumed in Eq. (6).
P(FK (Xn+1) = F (Xn+1)) = P(min Cc(Xn+1) ∈ Ic(Xn+1)) ≥ P(Cc(Xn+1) ⊆ Ic(Xn+1)) = P(I(Xn+1) ⊆ C (Xn+1)) ≥1− .

A.3 Proof of Theorem 4.4
Proof. For a given k, let Vk(i) := Mk(Xi) denote the random meta conﬁdence values used for calibration, and Vk(n+1) := Mk(Xn+1) the random test point. For all k, Mk is trained and evaluated on separate data (Dmeta vs Dcal ∪ Dtest), preserving exchangeability. Therefore, as X1:n+1 are exchangeable, then Vk(1:n+1) are also exchangeable.
Layer k is included in Cind iff Vk(n+1) ≤ Quantile(1 − αk, Vk(1:n) ∪ {∞}). For a given k, this happens with probability at least 1 − αk by Lemma A.1. Taken over all k ∈ I(Xn+1) where |I(Xn+1)| is at most l − 1 (i.e., all early layers are inconsistent), we have
P(I(Xn+1) ⊆ Cind(Xn+1))
= 1 − P {k ∈ Cind(Xn+1)}
k∈I
≥ 1 − P(k ∈ Cind(Xn+1)
k∈I
= 1 − αk
k∈I
≥1− .

The last inequality is given by the Bonferroni con-

straint, i.e., αk = ωk · , where

l−1 i=1

ωi

=

1

A.4 Proof of Theorem 4.6

Proof. By the same argument as Theorem 4.4, the
meta scores Mk(Xi) are exchangeable. Since Mmax operates symmetrically across all Xi, M (i) = Mmax(Xi) are also exchangeable.
Let M (n+1) denote the maximum meta score
across inconsistent layers for the new test point.
By Lemma A.1, this falls below Quantile(1 −

12

, M (1:n) ∪ {∞}) with probability at least 1 − . Since M (n+1) reﬂects the maximum meta score,
this entails that the meta scores of all other incon-
sistent layers k ∈ I(Xn+1) for Xn+1 will be below Quantile(1 − , M (1:n) ∪ {∞}) if M (n+1) is, and thereby be included in Cshare(Xn+1). This gives
the bound in Eq. (6).

B Implementation Details

We implement our early exit Transformers (§3)

on top of the Transformers library (Wolf et al., 2020).12 We set de to 32 in our experiments. For

each task we ﬁx a pre-trained F and train the early

and meta classiﬁers. We reuse the same training

data that was used for F and divide it to 70/10/20%

portions for Dtune, Dscale and Dmeta, respectively.

For classiﬁcation tasks, we add the temperature

scaling step (Guo et al., 2017) after the early train-

ing to improve the calibration of the softmax. We

run the scaling for 100 steps on Dscale using an

Adam optimizer (Kingma and Ba, 2015) with a learning rate of 10−3. For the early and meta train-

ing we use the same optimizer as for F.

We ﬁx F rather than train it jointly with the new

components of G to avoid any reduction in F’s

performance (Xin et al., 2020b). This also makes

our method simple to train over any existing Trans-

former without having to retrain the whole model

which could be very costly. Training all parameters

of G jointly can lead to more efﬁcient inference as

the early representations will be better suited for

classiﬁcation (Schwartz et al., 2020; Geng et al.,

2021), but potentially with the cost of reducing

the accuracy of Fl. In the case of joint training,

our CATs will provide consistency guarantees with

respect to the jointly-trained Fl.

We implement the conformal calibration process

in Python and perform retrospective analysis with

different random splits of Dcal and Dtest. For The-

orem 4.4, we simply use the uniform Bonferroni

correction,

setting

wk

=

1 l−1

∀k. For the naive

development set calibration, we use a shared thresh-

old across all layers in order to reduce the examined

solution space in Equation 3.

C Additional Results

In this section, we provide complementary results for the experiments in the main paper. All results,

12As discussed in §3, our methods can also be applied to any multilayered model such as BERT (Devlin et al., 2019), GPT (Brown et al., 2020), ResNet (He et al., 2015), and others.

except for sections C.4 and C.5, are with an Albertxlarge model as F, similar to the main paper. However, we note that the results in these tables are based on the development sets, while the tables in the main paper report the test set results.
C.1 Naive development set calibration
For completeness, we evaluate the simple, but naive, calibration method described in §3.3. Recall that in this approach we ﬁrst tune τ on a development set, and then bound the resulting G’s accuracy using another heldout calibration split. The bound we get is static; we are not able to guarantee that it will satisfy our performance constraint in Eq. (1).
Table C.1 gives results for our models when using either the Meta or SM conﬁdence measures (which we threshold with τ ). We use half of Dcal to ﬁnd the minimal threshold that provides -consistency. Then, we evaluate the threshold on the second half of Dcal to get the empirical error. We compute the test set bound on this error with a conﬁdence of δ = 10−2. As expected, the lower bound we compute is often signiﬁcantly below 1− , as it reﬂects the uncertainty that our measured consistency is accurate. Often the measured empirical consistency is also slightly below 1 − . At a high level, the overall consistency vs. efﬁciency tradeoff is otherwise broadly similar to the one obtained by the Shared CP calibration.
C.2 Nonconformity measure comparison
The test statistic used for a conformal prediction is typically called a nonconformity measure (i.e., in our work this is Mk(x)). We experiment with different nonconformity measures as drop-in replacements for Mk(x), and report the results in Table C.2. The conformal calibration guarantees validity with any measure, even a random one, as long as they retain exchangeability. Good measures are ones that are statistically efﬁcient, and will minimize the number of layers required for prediction at the required conﬁdence level. This is a result of smaller C sets, that tightly cover the inconsistent layers (and hence are more judicious with the complement, Cc). To be consistent with previous work where softmax metrics are used (such as Schwartz et al., 2020), we use pmk ax as our non-Meta baseline in the main paper. In some settings, however, pdkiﬀ performs slightly better.
C.3 Exit layer statistics
Figure C.1 depicts the distribution of exit layers for the different tasks with three reference tolerance

13

Nonconformity measure
1 − = 0.95: SM Meta
1 − = 0.9: SM Meta

IMDB Consist. Bound

95.16 94.96

93.74 93.72

90.22 90.19

88.30 88.36

Layers
10.39 9.13
7.35 7.13

VitaminC Consist. Bound Layers

94.84 94.93

94.04 94.12

16.60 15.60

89.85 90.00

88.59 88.70

14.93 13.67

AG News Consist. Bound Layers

95.02 94.86

93.75 93.58

11.63 9.37

89.72 88.01 8.98 90.14 88.48 6.85

Table C.1: Results (dev) using the naive development set calibration method (see §3.3). This method tunes the early exit thresholds to get efﬁcient -consistent predictions on a development set, but does not guarantee that prediction will be -consistent on new data. “Consist.” measures the empirical consistency on a test set, from which we compute a guaranteed lower bound (“Bound”) to 99% conﬁdence. The bound is signiﬁcantly lower than our target 1 − , and the measured consistency in our experiments also falls slightly bellow 1 − in some cases.

Nonconformity measure
1 − = 0.95:
Random DKL (pk−1 ||pk ) H(pk ) pdkiﬀ pmk ax (SM) Meta
1 − = 0.90:
Random DKL (pk−1 ||pk ) H(pk ) pdkiﬀ pmk ax (SM) Meta

Consist.
97.23 97.36 97.28 97.28 97.28 96.99
94.52 94.48 94.49 94.49 94.49 94.40

IMDB Acc.
(88.50)
91.56 92.49 92.84 92.84 92.84 92.24
(83.84)
89.68 91.36 91.31 91.31 91.31 90.45

Layers
21.57 19.33 12.49 12.49 12.49 10.75
19.21 12.13
9.91 9.91 9.91 8.80

VitaminC Consist. Acc.

96.91 96.84 96.79
96.83 96.79 96.91

(85.17)
87.42 88.85 88.28 88.38 88.31 88.29

93.94 93.76 93.67
93.67 93.68 93.74

(80.69)
85.44 86.81 86.41 86.53 86.44 86.17

Layers
22.71 22.28 17.44 17.42 17.40 16.49
21.47 20.49 16.29 16.11 16.13 15.09

AG News Consist. Acc.

97.11 97.08 97.15
96.96 97.08 96.98

(89.02)
91.58 92.46 92.79 92.80 92.81 91.98

94.27 93.88 94.54
94.02 94.05 94.08

(84.33)
89.28 89.98 90.80 90.56 90.76 89.72

Layers
21.60 20.18 14.55 12.89 13.23 10.60
19.01 14.59 13.08 10.69 11.01
8.88

Table C.2: Results (dev) of our Shared model on the classiﬁcation tasks using different nonconformity measures. pdkiﬀ and pmk ax are deﬁned in Table 1, DKL(pk−1||pk) is the Kullback-Leibler Divergence between the previous layer’s softmax outputs and the current layer, and H(pk) is the entropy of the softmax outputs. Our CP-based Shared method provides the guaranteed consistency with any measure, even random. The beneﬁt, however, of
using a better measure is in conﬁdently exiting earlier. Our Meta measure allows the use of least Transformer
layers meeting the consistency requirement with enough conﬁdence.

levels. Reducing requires greater conﬁdence before exiting, resulting in later exits on average. We provide example inputs with their respective exit layer in Appendix D.
C.4 Albert-base results
Figure C.2 reports the classiﬁcation and regression results with an Albert-base 12-layers model. The trends are similar to the larger 24-layers version. Again, we see the efﬁcacy of our Shared conformal calibration and the Meta nonconformity scores. For example, the AG News CAT Shared/ Meta model can preserve 95% consistency while using less than 5 Transformer layers on average.

C.5 RoBERTa-large results
Figure C.3 shows the results of our methods on top of the RoBERTa-large 24-layers Transformer. One main difference between RoBERTa and Albert, is that Albert shares the same parameters across all layers, essentially applying the same function recursively, whereas RoBERTa learns different parameters per layer. Yet, our method is agnostic to such differences and, as observed in the plots, results in similar trends. The value of our Meta classiﬁer compared to the softmax response is even greater with the RoBERTa model.
D Example Predictions
Table D.1 reports examples of inputs for different tasks and the number of layers that our Albert-

14

(a) VitaminC

(b) AG News

(c) STS-B
Figure C.1: Distribution of exit layers per tolerance level (dev sets) with our Shared/ Meta Albert-xlarge model. See Figure 5 for IMDB.

Method
Thres./ SM Thres./ Meta Indep./ Meta Shared/ SM Shared/ Meta

IMDB

Amortized time (100 · TG/TF ) VitaminC AG News

85.56 99.85 89.25 67.22 63.99 %

102.12 109.93 109.57
90.41 94.97 %

112.52 91.95
114.66 69.99 60.56 %

STS-B
N/A 107.44 130.36
N/A 99.38 %

MACs reduction (|F|/|G|) IMDB VitaminC AG News STS-B

1.45 1.35 1.53 1.90 ×2.22

1.20 1.22 1.22 1.37 ×1.43

1.08 1.48 1.17 1.81 ×2.36

N/A 1.25 1.02 N/A ×1.36

Table C.2: Complementary results for Table 5 with 1 − = 0.95.

xlarge CAT with = 0.1 required. These examples suggest that “easier” inputs (e.g., containing cue phrases or having large overlaps in sentence-pair tasks) might require less layers. In contrast, more complicated inputs (e.g., using less common language or requiring numerical analysis) can lead to

additional computational effort until the desired conﬁdence is obtained.

15

(a) IMDB

(b) VitaminC

(c) AG News

(d) STS-B Figure C.2: Development set results with an Albert-base 12-layers model as F.
16

(a) IMDB

(b) VitaminC

(c) AG News

(d) STS-B Figure C.3: Development set results with an RoBERTa-large 24-layers model as F.
17

Exit Gold layer label

Input

IMDB (Maas et al., 2011)

1 Pos

Without question, ﬁlm is a powerful medium, more so now than ever before, due to the accessibility of DVD/video, which gives the ﬁlmmaker the added assurance that his story or message is going to be seen by possibly millions of people. [...]

4 Neg

This movie was obscenely obvious and predictable. The scenes were poorly written and acted even worse.

10 Pos

I think Gerard’s comments on the doc hit the nail on the head. Interesting ﬁlm, but very long. [...]

15 Pos

here in Germany it was only shown on TV one time. today, as everything becomes mainstream, it’s absolute impossible, to watch a ﬁlm like this again on the screen. maybe it’s the same in USA [...]

20 Neg

I tried to be patient and open-minded but found myself in a coma-like state. I wish I would have brought my duck and goose feather pillow... [...]

24 Neg

Hypothetical situations abound, one-time director Harry Ralston gives us the ultimate post-apocalyptic glimpse with the world dead, left in the streets, in the stores, and throughout the landscape, sans in the middle of a forgotten desert. [...]

VitaminC (Schuster et al., 2021)

3 Sup

Claim: Another movie titled The SpongeBob Movie: Sponge on the Run is scheduled for release in 2020. Evidence: A second ﬁlm titled The SpongeBob Movie : Sponge Out of Water was released in 2015, and another titled The SpongeBob Movie: Sponge on the Run is scheduled for release in 2020.

5 Sup

Claim: Julie Bishop offered a defence of her nation’s intelligence cooperation with America. Evidence: The Australian Foreign Minister Julie Bishop stated that the acts of Edward Snowden were treachery and offered a staunch defence of her nation’s intelligence co-operation with America.

10 NEI

Claim: The character Leslie hurts her head on the window in the ﬁlm 10 Cloverﬁeld Lane. Evidence: Michelle realizes Howard was right and returns his keys.

15 Sup

Claim: Halakha laws are independent of being physically present in the Land of Israel. Evidence: The codiﬁcation efforts that culminated in the Shulchan Aruch divide the law into four sections, including only laws that do not depend on being physically present in the Land of Israel.

20 Sup

Claim: Germany has recorded less than 74,510 cases of coronavirus , including under 830 deaths. Evidence: 74,508 cases have been reported with 821 deaths and approximately 16,100 recoveries.

24 NEI

Claim: For the 2015-16 school year , the undergraduate fee at USF is under $43,000. Evidence: Undergraduate tuition at USF is $44,040 for the 2016-17 school year.

AG News (Gulli, 2004; Zhang et al., 2015)

1 Business Crude Oil Rises on Speculation Cold Weather May Increase Demand Crude oil futures are headed for their biggest weekly gain in 21 months [...]

5 Sports NHL Owner Is Criticized for Talking of Replacement Players The day before the regular season was supposed to open [...]

15 World Scotch Whisky eyes Asian and Eastern European markets (AFP) AFP - A favourite tipple among connoisseurs the world over, whisky is treated with almost religious reverence on the Hebridean [...]

20 Business Arthritis drug withdrawn after trial A prescription painkiller used by more than 250,000 Australians to treat arthritis has been withdrawn from sale after a clinical trial found it doubled the risk [...]

24 Sci/Tech Airbus drops out of Microsoft appeal Aircraft builder withdraws its request to intervene in Microsoft’s antitrust appeal; Boeing also forgoes intervention.

STS-B (Cer et al., 2017)

10 0.6

Sent. 1: A child wearing blue and white shorts is jumping in the surf. Sent. 2: A girl wearing green twists something in her hands.

15 2.8

Sent. 1: Saudi Arabia gets a seat at the UN Security Council Sent. 2: Saudi Arabia rejects seat on UN Security Council

20 4.2

Sent. 1: a small bird sitting on a branch in winter. Sent. 2: A small bird perched on an icy branch.

24 3.0

Sent. 1: It depends entirely on your company and your contract. Sent. 2: It depends on your company.

Table D.1: Number of Transformer layers used for example inputs from the task’s test sets with our Shared/Meta CAT with a tolerance level of = 0.1

18

