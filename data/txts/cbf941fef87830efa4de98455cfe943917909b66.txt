Mathematical Programming https://doi.org/10.1007/s10107-021-01622-5

arXiv:2003.09174v3 [math.OC] 1 Jun 2021

Rates of superlinear convergence for classical quasi-Newton methods
Anton Rodomanov · Yurii Nesterov
Received: 30 March 2020 / Accepted: 18 January 2021 © The Author(s) 2021

Abstract We study the local convergence of classical quasi-Newton methods

for nonlinear optimization. Although it was well established a long time ago

that asymptotically these methods converge superlinearly, the corresponding

rates of convergence still remain unknown. In this paper, we address this prob-

lem. We obtain ﬁrst explicit non-asymptotic rates of superlinear convergence

for the standard quasi-Newton methods, which are based on the updating for-

mulas from the convex Broyden class. In particular, for the well-known DFP

and

BFGS

methods,

we

obtain

the

rates

of

the

form

(

nL2 µ2 k

)k/2

and

( nµLk )k/2

re-

spectively, where k is the iteration counter, n is the dimension of the problem,

µ is the strong convexity parameter, and L is the Lipschitz constant of the

gradient.

Keywords quasi-Newton methods · convex Broyden class · DFP · BFGS · superlinear convergence · local convergence · rate of convergence

Mathematics Subject Classiﬁcation 90C53 · 90C30 · 68Q25

1 Introduction
Motivation. In this work, we investigate the classical quasi-Newton algorithms for smooth unconstrained optimization, the main examples of which are the Davidon–Fletcher–Powell (DFP) method [1,2] and the Broyden–Fletcher– Goldfarb–Shanno (BFGS) method [4–8]. These algorithms are based on the idea of replacing the exact Hessian in the Newton method with some approximation, that is updated in iterations according to certain formulas, involving
Research results in this paper were obtained with support of ERC Advanced Grant 788368.
Anton Rodomanov Institute of Information and Communication Technologies, Electronics and Applied Mathematics, Catholic University of Louvain, Louvain-la-Neuve, Belgium. E-mail: anton.rodomanov@uclouvain.be
Yurii Nesterov Center for Operations Research and Econometrics, Catholic University of Louvain, Louvainla-Neuve, Belgium. E-mail: yurii.nesterov@uclouvain.be

2

Anton Rodomanov, Yurii Nesterov

only the gradients of the objective function. For an introduction into the topic, see [14] and [23, Chapter 6]; also see [25] for the treatment of quasi-Newton algorithms in the context of nonsmooth optimization and [26, 27, 32] for randomized variants of quasi-Newton methods.

One of the questions about quasi-Newton methods, that has been extensively studied in the literature, is their superlinear convergence. First theoretical results here were obtained for the methods with exact line search, ﬁrst by Powell [9], who analyzed the DFP method, and then by Dixon [10, 11], who showed that with the exact line search all quasi-Newton algorithms in the Broyden family [3] coincide. Soon after that Broyden, Dennis and Mor´e [12] considered the quasi-Newton algorithms without line search and proved the local superlinear convergence of DFP, BFGS and several other methods. Their analysis was based on the Frobenius-norm potential function. Later, Dennis and Mor´e [13] uniﬁed the previous proofs by establishing the necessary and suﬃcient condition of superlinear convergence. This condition together with the original analysis of Broyden, Dennis and Mor´e have been applied since then in almost every work on quasi-Newton methods for proving superlinear convergence (see e.g. [15, 16, 19, 21, 22, 24, 28, 30]). Finally, one should mention that an important contribution to the theoretical analysis of quasi-Newton methods has been made by Byrd, Liu, Nocedal and Yuan in the series of works [17, 18, 20], where they introduced a new potential function by combining the trace with the logarithm of determinant.

However, the theory of superlinear convergence of quasi-Newton methods is still far from being complete. The main reason for this is that all currently existing results on superlinear convergence of quasi-Newton methods are only asymptotic: they simply show that the ratio of successive residuals in the method tends to zero as the number of iterations goes to inﬁnity, without providing any speciﬁc bounds on the corresponding rate of convergence. It is therefore important to obtain some explicit and non-asymptotic rates of superlinear convergence for quasi-Newton methods.

This observation was the starting point for a recent work [31], where the

greedy analogs of the classical quasi-Newton methods have been developed.

As opposed to the classical quasi-Newton methods, which use the diﬀerence of

successive iterates for updating Hessian approximations, these methods employ

basis vectors, greedily selected to maximize a certain measure of progress. As

shown in [31], greedy quasi-Newton methods have superlinear convergence

rate

of

the

form

(1

−

µ nL

)k

2

/

2

(

nL µ

)k

,

where

k

is

the

iteration

counter,

n

is

the

dimension of the problem, µ is the strong convexity parameter, and L is the

Lipschitz constant of the gradient.

In this work, we continue the same line of research but now we study the classical quasi-Newton methods. Namely, we consider the methods, based on the updates from the convex Broyden class, which is formed by all convex combinations of the DFP and BFGS updates. For this class, we derive explicit bounds on the rate of superlinear convergence of standard quasi-Newton

Rates of superlinear convergence for classical quasi-Newton methods

3

methods without line search. In particular, for the standard DFP and BFGS

methods,

we

obtain

the

rates

of

the

form

(

nL2 µ2 k

)k/2

and

( nµLk )k/2

respectively.

Contents. This paper is organized as follows. First, in Section 2, we study

the convex Broyden class of updating rules for approximating a self-adjoint

positive deﬁnite linear operator, and establish several important properties of

this class. Then, in Section 3, we analyze the standard quasi-Newton scheme,

based on the updating rules from the convex Broyden class, as applied to

minimizing a quadratic function. We show that this scheme has the same

rate of linear convergence as that of the classical gradient method, and also a superlinear convergence rate of the form ( Qk )k/2, where Q ≥ 1 is a certain constant, related to the condition number, and depending on the method.

After that, in Section 4, we consider the general problem of unconstrained

minimization and the corresponding quasi-Newton scheme for solving it. We

show that, for this scheme, it is possible to prove absolutely the same results as

for the quadratic function, provided that the starting point is suﬃciently close

to the solution. In Section 5, we compare the rates of superlinear convergence,

that we obtain for the classical quasi-Newton methods, with the corresponding

rates of the greedy quasi-Newton methods. Section 6 contains some auxiliary

results, that we use in our analysis.

Notation. In what follows, E denotes an arbitrary n-dimensional real vec-

tor space. Its dual space, composed by all linear functionals on E, is denoted

by E∗. The value of a linear function s ∈ E∗, evaluated at point x ∈ E, is

denoted by s, x .

For a smooth function f : E → R, we denote by ∇f (x) and ∇2f (x) its

gradient and Hessian respectively, evaluated at a point x ∈ E. Note that

∇f (x) ∈ E∗, and ∇2f (x) is a self-adjoint linear operator from E to E∗.

The partial ordering of self-adjoint linear operators is deﬁned in the stan-

dard way. We write A A1 for A, A1 : E → E∗ if (A1 − A)x, x ≥ 0 for all x ∈ E, and W W1 for W, W1 : E∗ → E if s, (W1 − W )s ≥ 0 for all s ∈ E∗.
Any self-adjoint positive deﬁnite linear operator A : E → E∗ induces in the

spaces E and E∗ the following pair of conjugate Euclidean norms:

h A d=ef Ah, h 1/2, h ∈ E,

s

∗ A

d=ef

s, A−1s 1/2,

s ∈ E∗.

(1.1)

When A = ∇2f (x), where f : E → R is a smooth function with positive deﬁnite Hessian, and x ∈ E, we prefer to use notation · x and · ∗x, provided that there is no ambiguity with the reference function f .
Sometimes, in the formulas, involving products of linear operators, it is
convenient to treat x ∈ E as a linear operator from R to E, deﬁned by xα = αx, and x∗ as a linear operator from E∗ to R, deﬁned by x∗s = s, x . Likewise, any s ∈ E∗ can be treated as a linear operator from R to E∗, deﬁned by sα = αs, and s∗ as a linear operator from E to R, deﬁned by s∗x = s, x . In this case, xx∗ and ss∗ are rank-one self-adjoint linear operators from E∗ to E and from E∗ to E respectively, acting as follows:

(xx∗)s = s, x x, (ss∗)x = s, x s, x ∈ E, s ∈ E∗.

4

Anton Rodomanov, Yurii Nesterov

Given two self-adjoint linear operators A : E → E∗ and W : E∗ → E, we deﬁne the trace and the determinant of A with respect to W as follows:
W, A d=ef Tr(W A), Det(W, A) d=ef Det(W A).

Note that W A is a linear operator from E to itself, and hence its trace and

determinant are well-deﬁned real numbers (they coincide with the trace and

determinant of the matrix representation of W A with respect to an arbitrary

chosen basis in the space E, and the result is independent of the particular

choice of the basis). In particular, if W is positive deﬁnite, then W, A and

Det(W, A) are respectively the sum and the product of the eigenvalues1 of A

relative to W −1. Observe that ·, · is a bilinear form, and for any x ∈ E, we

have

Ax, x = xx∗, A .

(1.2)

When A is invertible, we also have

A−1, A = n, Det(A−1, δA) = δn.

(1.3)

for any δ ∈ R. Also recall the following multiplicative formula for the deter-

minant:

Det(W, A) = Det(W, G)Det(G−1, A),

(1.4)

which is valid for any invertible linear operator G : E → E∗. If the operator W is positive semideﬁnite, and A A1 for some self-adjoint linear operator A1 : E → E∗, then W, A ≤ W, A1 and Det(W, A) ≤ Det(W, A1). Similarly, if A is positive semideﬁnite and W W1 for some self-adjoint linear operator W1 : E∗ → E, then W, A ≤ W1, A and Det(W, A) ≤ Det(W1, A).

2 Convex Broyden class

Let A and G be two self-adjoint positive deﬁnite linear operators from E to E∗, where A is the target operator, which we want to approximate, and G is the current approximation of the operator A. The Broyden family of quasiNewton updates of G with respect to A along a direction u ∈ E \ {0}, is the following class of updating formulas, parameterized by a scalar φ ∈ R:

Broydφ(A, G, u) d=ef φ G − Auu∗GA+u,Guuu∗A +

Gu,u Au,u

+1

+ (1 − φ) G − GGuuu,∗uG + AAuuu,∗uA .

Auu∗ A Au,u

(2.1)

Note that Broydφ(A, G, u) depends on A only through the product Au. For the sake of convenience, we also deﬁne Broydφ(A, G, u) = G when u = 0.

1 Recall that, for linear operators A, B : E → E∗, a scalar λ ∈ R is called a (relative) eigenvalue of A with respect to B if Ax = λBx for some x ∈ E \ {0}. If A, B are self-adjoint and B is positive deﬁnite, it is known that there exist eigenvalues λ1, . . . , λn ∈ R and a basis x1, . . . , xn ∈ E, such that Axi = λiBxi, xi B = 1, Bxi, xj = 0 for all 1 ≤ i, j ≤ n, i = j.

Rates of superlinear convergence for classical quasi-Newton methods

5

Two important members of the Broyden family, DFP and BFGS updates, correspond to the values φ = 1 and φ = 0 respectively:

DFP(A, G, u) d=ef G − Auu∗GA+u,Guuu∗A + BFGS(A, G, u) d=ef G − GGuuu,∗uG + AAuuu,∗uA .

Gu,u Au,u

+1

AAuuu,∗uA ,

(2.2)

Thus, the Broyden family consists of all aﬃne combinations of DFP and BFGS updates:

Broydφ(A, G, u) (2=.1) φDFP(A, G, u) + (1 − φ)BFGS(A, G, u). (2.3)

The subclass of the Broyden family, corresponding to φ ∈ [0, 1], is known as the convex Broyden class (or the restricted Broyden class in some texts).
Our subsequent developments will be based on two properties of the convex Broyden class. The ﬁrst property states that each update from this class preserves the bounds on the relative eigenvalues with respect to the target operator.

Lemma 2.1 Let A, G : E → E∗ be self-adjoint positive deﬁnite linear operators such that

A ξ

G

ηA,

(2.4)

where ξ, η ≥ 1. Then, for any u ∈ E, and any φ ∈ [0, 1], we have

A ξ

Broydφ(A, G, u)

ηA.

(2.5)

Proof Suppose that u = 0 since otherwise the claim is trivial. In view of (2.3), it suﬃces to prove (2.5) only for the DFP and BFGS updates independently.
For the DFP update, we have

DFP(A, G, u) (2=.2) G − Auu∗GA+u,Guuu∗A + GAuu,,uu + 1 AAuuu,∗uA

=

IE∗ −

Auu∗ Au,u

G

IE −

uu∗ A Au,u

+ AAuuu,∗uA ,

where IE, IE∗ are the identity operators in the spaces E, E∗ respectively. Hence,

(2.4)

DFP(A, G, u)

η

=η

(2.4)

DFP(A, G, u)

1 ξ

=

1 ξ

IE∗ −

Auu∗ Au,u

A

−

Auu∗ A Au,u

IE∗ −

Auu∗ Au,u

A

−

Auu∗ A Au,u

A

IE −

uu∗ A Au,u

+ AAuuu,∗uA

+

Auu∗ A Au,u

=

ηA

−

(η

−

1)

Auu∗ A Au,u

A

IE −

uu∗ A Au,u

+ AAuuu,∗uA

+

Auu∗ A Au,u

=

1 ξ

A

+

1

−

1 ξ

Auu∗ A Au,u

ηA, 1ξ A.

6

Anton Rodomanov, Yurii Nesterov

For the BFGS update, we apply Lemma 6.1 (see Appendix):

BFGS(A, G, u) (2=.2) G − GGuuu,∗uG + AAuuu,∗uA

= ηA − (η − 1) AAuuu,∗uA

BFGS(A, G, u) (2=.2) G − GGuuu,∗uG + AAuuu,∗uA

=

1 ξ

A

+

1

−

1 ξ

Auu∗ A Au,u

(2.4) η
ηA, (2.4) 1
ξ
ξ1 A.

A − AAuuu,∗uA A − AAuuu,∗uA

+ AAuuu,∗uA
+ AAuuu,∗uA ⊓⊔

Remark 2.1 Lemma 2.1 has ﬁrst been established in [6] in a slightly stronger form and using a diﬀerent argument. It was also shown there that one of the relations in (2.5) may no longer be valid if φ ∈ R \ [0, 1].

The second property of the convex Broyden class, which we need, is re-

lated to the question of convergence of the approximations G to the target

operator A. Note that without any restrictions on the choice of the update di-

rections u, one cannot guarantee any convergence of G to A in the usual sense

(see [13, 31] for more details). However, for our goals it will be suﬃcient to

show that, independently of the choice of u, it is still possible to ensure that G

converges to A along the update directions u, and estimate the corresponding

rate of convergence.

Let us deﬁne the following measure of the closeness of G to A along the

direction u:

θ(A, G, u) d=ef

(G−A)A−1(G−A)u,u GA−1Gu,u

1/2
,

(2.6)

where, for the sake of convenience, we deﬁne θ(A, G, u) = 0 if u = 0. Note that θ(A, G, u) = 0 if and only if Gu = Au. Thus, our goal now is to establish some upper bounds on θ, which will help us to estimate the rate, at which this measure goes to zero. For this, we will study how certain potential functions change after one update from the convex Broyden class, and estimate this change from below by an appropriate monotonically increasing function of θ. We will consider two potential functions.
The ﬁrst one is a simple trace potential function, that we will use only when we can guarantee that A G:

σ(A, G) d=ef A−1, G − A ≥ 0.

(2.7)

Lemma 2.2 Let A, G : E → E∗ be self-adjoint positive deﬁnite linear operators such that

A G ηA

(2.8)

for some η ≥ 1. Then, for any φ ∈ [0, 1] and any u ∈ E, we have

σ(A, G) − σ(A, Broydφ(A, G, u)) ≥ φ η1 + 1 − φ θ2(A, G, u).

(2.9)

Rates of superlinear convergence for classical quasi-Newton methods

7

Proof We can assume that u = 0 since otherwise the claim is trivial. Denote G+ d=ef Broydφ(A, G, u) and θ d=ef θ(A, G, u). Then,

(2=.1) = =

σ(A, G) − σ(A, G+) (2=.7) A−1, G − G+
2φ GAuu,,uu − φ GAuu,,uu + 1 + (1 − φ) GAG−u1G,uu,u φ GAuu,,uu + (1 − φ) GAG−u1G,uu,u − 1 φ (GA−uA,)uu,u + (1 − φ) G(A−1−GGu,−u1)Gu,u .

(2.10)

Note that

(2.8)

(2.8)

0

G−A

(η − 1)A ηA.

Therefore2,

(G − A)A−1(G − A) η(G − A).

(2.11)

Consequently,

(G−A)u,u Au,u

(2.11)

≥

1 η

(2.8)

≥

1 η

(G−A)A−1(G−A)u,u Au,u
(G−A)A−1(G−A)u,u GA−1Gu,u

(2=.6) η1 θ2.

(2.12)

At the same time,

(G − A)A−1(G − A) = GA−1G − 2G + A (2.8) GA−1G − G = G(A−1 − G−1)G.

Hence,

G(A−1 −G−1 )Gu,u Gu,u

≥ (2.8)
≥

(G−A)A−1(G−A)u,u Gu,u
(G−A)A−1(G−A)u,u GA−1Gu,u

(2=.6) θ2.

(2.13)

Substituting now (2.12) and (2.13) into (2.10), we obtain (2.9).

⊓⊔

The second potential function is more universal since we can work with

it even if the condition A G is violated. This function was ﬁrst introduced

in [18], and is deﬁned as follows:

ψ(A, G) d=ef A−1, G − A − ln Det(A−1, G).

(2.14)

In fact, ψ is nothing else but the Bregman divergence, generated by the strictly convex function d(G) d=ef − ln Det(B−1, G), deﬁned on the set of self-adjoint
2 This is evident when G−A is non-degenerate. The general case then follows by continuity.

8

Anton Rodomanov, Yurii Nesterov

positive deﬁnite linear operators from E to E∗, where B : E → E∗ is an arbitrary ﬁxed self-adjoint positive deﬁnite linear operator. Indeed,

ψ(A, G) (1=.3) − ln Det(B−1, G) + ln Det(B−1, A) − −A−1, G − A = d(G) − d(A) − ∇d(A), G − A .

Thus, ψ(A, G) ≥ 0 and ψ(A, G) = 0 if and only if G = A. Let ω : (−1, +∞) → R be the univariate function

ω(t) d=ef t − ln(1 + t) ≥ 0.

(2.15)

Clearly, ω is a convex function, which is decreasing on (−1, 0] and increasing on [0, +∞). Also, on the latter interval, it satisﬁes the following bounds (see [29, Lemma 5.1.5]):

t2 2(1+t)

≤

t2
2(1+ 2 t)

≤

ω(t)

≤

2t+2t ,

3

t ≥ 0.

(2.16)

Thus, for large values of t, the function ω(t) is approximately linear in t, while

for small values of t, it is quadratic.

There is a close relationship between ω and the potential function ψ. In-

deed, if λ1, . . . , λn ≥ 0 are the relative eigenvalues of G with respect to A,

then

(2.14) n

(2.15) n

ψ(A, G) = (λi − 1 − ln λi) =

ω(λi − 1).

i=1

i=1

We are going to use the function ω to estimate from below the change in the potential function ψ, which is achieved after one update from the convex Broyden class, via the closeness measure θ. However, ﬁrst of all, we need an auxiliary lemma.

Lemma 2.3 For any real α ≥ β > 0, we have √
α − ln β − 1 ≥ ω( αβ − 2β + 1).

Proof Equivalently, we need to prove that √
α − 1 ≥ ω( αβ − 2β + 1) + ln β.

(2.17)

Let us show that the right-hand side of (2.17) is increasing in β. This is

evident if α ≥ 2 because ω is increasing on [0, +∞), so suppose that α < 2.

Denote

def √ t = αβ − 2β + 1 = 1 − (2 − α)β ∈ [0, 1).

(2.18)

Rates of superlinear convergence for classical quasi-Newton methods

9

Note that t is decreasing in β. Therefore, it suﬃces to prove that the right-hand side of (2.17) is decreasing in t. But

√ ω( αβ

−

2β

+

1)

+

ln

β

(2=.18)

ω(t)

+

ln

1−t2

2−α

= ω(t) + ln(1 − t2) − ln(2 − α)

(2=.15) t − ln(1 + t) + ln(1 − t2) − ln(2 − α)

= t + ln(1 − t) − ln(2 − α) (2=.15) −ω(−t) − ln(2 − α),

which is indeed decreasing in t since ω is decreasing on (−1, 0]. Thus, it suﬃces to prove (2.17) only in the boundary case β = α:
√ α − 1 ≥ ω( α2 − 2α + 1) + ln α = ω(|α − 1|) + ln α,

or, equivalently, in view of (2.15), that

ω(α − 1) ≥ ω(|α − 1|)

For α ≥ 1, this is obvious, so suppose that α ≤ 1. It now remains to justify

that

ω(−t) ≥ ω(t),

(2.19)

for all t ∈ [0, 1). But this easily follows by integration from the fact that

ddt ω(−t) = −ω′(−t) (2=.15) 1−t t ≥ 1+t t (2=.15) ω′(t)

for all t ∈ [0, 1).

⊓⊔

Now we are ready to prove the main result.

Lemma 2.4 Let A, G : E → E∗ be self-adjoint positive deﬁnite linear opera-

tors such that

1ξ A G ηA

(2.20)

for some ξ, η ≥ 1. Then, for any φ ∈ [0, 1] and any u ∈ E, we have

ψ(A, G) − ψ(A, Broydφ(A, G, u)) ≥ φ ω

θξ(3A/,2G√,uη)

+ (1 − φ)ω

θ(A,G,u) ξ

.

Proof Suppose that u = 0 since otherwise the claim is trivial. Let us denote G+ d=ef Broydφ(A, G, u) and θ d=ef θ(A, G, u). We already know that

A−1, G − G+ (2.=10) φ GAuu,,uu + (1 − φ) GAG−u1G,uu,u − 1.

Applying now Lemma 6.2, we obtain

Det(G−1, G+)

=

φ

AG−1Au,u Au,u

+ (1 − φ)

Au,u Gu,u

.

10

Anton Rodomanov, Yurii Nesterov

Thus,

ψ(A, G) − ψ(A, G+)

(2.=14) A−1, G − G+ + ln Det(A−1, G+) − ln Det(A−1, G)

(1=.4) A−1, G − G+ + ln Det(G−1, G+)

= φ GAuu,,uu + (1 − φ) GAG−u1G,uu,u − 1 + ln φ AGA−u1,Auu,u + (1 − φ) GAuu,,uu

≥ φ GAuu,,uu + ln AGA−u1,Auu,u + (1 − φ) GAG−u1G,uu,u + ln GAuu,,uu − 1

= φ GAuu,,uu − ln AGA−u1,Auu,u − 1 + (1 − φ) GAG−u1G,uu,u − ln GAuu,,uu − 1 ,

(2.21)

where we have used the concavity of the logarithm.

Denote

α1 d=ef α0 d=ef

GAuu,,uu , GAG−u1G,uu,u ,

β1 d=ef β0 d=ef

Au,u AG−1Au,u

,

GAuu,,uu .

(2.22)

Clearly, α1 ≥ β1 and α0 ≥ β0 by the Cauchy-Schwartz inequality. Also,

α1β1 α0β0

− 2β1 + 1 − 2β0 + 1

(2=.22) (2.20)
≥ (2=.6) (2=.22) (2.20)
≥

Gu,u AG−1Au,u

−2

Au,u AG−1Au,u

+1

=

(G−A)G−1(G−A)u,u AG−1Au,u

1 (G−A)A−1(G−A)u,u

η

AG−1Au,u

(2.20) ≥

1

(G−A)A−1(G−A)u,u

ξ3η

GA−1Gu,u

θ2 ξ3η

,

GAA−u1,Guu,u − 2 GAuu,,uu + 1 =

(G−A)A−1(G−A)u,u Au,u

1 (G−A)A−1(G−A)u,u

ξ2

GA−1Gu,u

(2=.6) θξ22 .

Therefore, by Lemma 2.3 and the fact that ω is increasing on [0, +∞), we have

Gu,u Au,u

− ln

Au,u AG−1Au,u

−1 ≥ ω

GAG−u1G,uu,u − ln GAuu,,uu − 1 ≥ ω

(G−A)G−1(G−A)u,u 1/2 AG−1Au,u
(G−A)A−1(G−A)u,u 1/2 Au,u

≥ ω ξ3/θ2√η ,

≥ω

θ ξ

.

Combining these inequalities with (2.21), we obtain the claim.

⊓⊔

3 Unconstrained quadratic minimization

In this section, we study the classical quasi-Newton methods, based on the updating formulas from the convex Broyden class, as applied to minimizing the quadratic function

f (x) d=ef 21 Ax, x − b, x ,

(3.1)

where A : E → E∗ is a self-adjoint positive deﬁnite operator, and b ∈ E∗.

Rates of superlinear convergence for classical quasi-Newton methods

11

Let B : E → E∗ be a self-adjoint positive deﬁnite linear operator, that we will use to initialize our methods. Denote by µ > 0 the strong convexity parameter of f , and by L > 0 the Lipschitz constant of the gradient of f , both measured with respect to B:

µB A LB.

(3.2)

Consider the following standard quasi-Newton scheme for minimizing (3.1). For the sake of simplicity, we assume that the constant L is available.

Initialization: Choose x0 ∈ E. Set G0 = LB.

For k ≥ 0 iterate: 1. Update xk+1 = xk − G−k 1∇f (xk). 2. Set uk = xk+1 − xk and choose φk ∈ [0, 1].

(3.3)

3. Compute Gk+1 = Broydφk (A, Gk, uk).

Remark 3.1 In an actual implementation of scheme (3.3), it is typical to store in memory and update in iterations the matrix Hk d=ef G−k 1 instead of Gk (or, alternatively, the Cholesky decomposition of Gk). This allows one to compute G−k+11∇f (xk) in O(n2) operations. Note that, due to a low-rank structure of the update (2.1), Hk can be updated into Hk+1 also in O(n2) operations (for speciﬁc formulas, see e.g. [14, Section 8]).

To measure the convergence rate of scheme (3.3), we look at the norm of the gradient, measured with respect to A:

λf (x) d=ef

∇f (x) ∗ (1=.1)
A

∇f (x), A−1∇f (x) 1/2.

(3.4)

The following lemma shows that the measure θ(A, Gk, uk), that we introduced in (2.6) to measure the closeness of Gk to A along the direction uk, is directly related to the progress of one step of the scheme (3.3). Note that it is
important here that the updating direction uk = xk+1 − xk is chosen as the diﬀerence of the iterates, and, for other choices of uk, this result is no longer true.

Lemma 3.1 In scheme (3.3), for all k ≥ 0, we have

λf (xk+1) = θ(A, Gk, uk)λf (xk).

(3.5)

Proof Indeed, ∇f (xk+1) (3=.1) ∇f (xk) + A(xk+1 − xk) (3=.3) −Gkuk + Auk = −(Gk − A)uk.

12

Anton Rodomanov, Yurii Nesterov

Hence, denoting θk d=ef θ(A, Gk, uk), we get

λf (xk+1) (3=.4) (Gk − A)A−1(Gk − A)uk, uk 1/2 (2=.6) θk GkA−1Gkuk, uk 1/2

(3=.3) θk ∇f (xk), A−1∇f (xk) 1/2 (3=.4) θkλf (xk).

⊓⊔

Let us show that the scheme (3.3) has global linear convergence, and that the corresponding rate is at least as good as that of the standard gradient method.
Theorem 3.1 In scheme (3.3), for all k ≥ 0, we have

A Gk Lµ A,

(3.6)

and

λf (xk) ≤

1

−

µ L

k λf (x0).

(3.7)

Proof For k = 0, (3.6) follows from the fact that G0 = LB and (3.2). For all other k ≥ 1, it follows by induction using Lemma 2.1.
Thus, we have

(3.6)

(3.6)

0

A−1 − G−k 1

1

−

µ L

A−1.

(3.8)

Therefore,

(Gk − A)A−1(Gk − A) = Gk(A−1 − G−k 1)A(A−1 − G−k 1)Gk

1

−

µ L

2 GkA−1Gk,

and so

(2.6) θ(A, Gk, uk) ≤ 1 − Lµ .

Applying now Lemma 3.5, we obtain (3.7).

⊓⊔

Now, let us establish the superlinear convergence of the scheme (3.3). First,

we do this by working with the trace potential function σ, deﬁned by (2.7).

Note that this is possible since A Gk in view of (3.6).

Theorem 3.2 In scheme (3.3), for all k ≥ 1, we have

λf (xk) ≤

1

( k−1
i=0

φi

µ L

) +1−φi 1/2

k/2

nL µk

λf (x0).

(3.9)

Proof

Denote

σi

d=ef

σ(A, Gi),

θi

d=ef

θ(A, Gi, ui),

and

pi

d=ef

φi

µ L

+ 1 − φi

for

any i ≥ 0. Let k ≥ 1 be arbitrary. From (3.6) and Lemma 2.2, it follows that

σi − σi+1 ≥ piθi2

Rates of superlinear convergence for classical quasi-Newton methods

13

for all 0 ≤ i ≤ k − 1. Summing up these inequalities, we obtain

k−1
p θ2

≤

σ −σ

(2.7) ≤σ

(3=.3) σ(A, LB) (2=.7)

A−1, LB − A

ii

0

k

0

i=0

(3.2) ≤ A−1, L A − A

(1=.3) n

L −1

≤ nL .

µ

µ

µ

(3.10)

Hence, by Lemma 3.1 and the arithmetic-geometric mean inequality,

k−1

k−1

1/2

λf (xk) = λf (x0) θi =
i=0

1

k−1 i=0

p1i /2

piθi2
i=0

λf (x0)

k−1

k/2

(3.10)

k/2

≤

1 k−1 p1/2

1 k

piθi2

λf (x0) ≤

1

nL

k−1 p1/2 µk

λf (x0). ⊓⊔

i=0 i

i=0

i=0 i

Remark

3.2

As can be seen from (3.10), the factor

nL µ

in the eﬃciency estimate

(3.9) can be improved up to A−1, LB − A = ni=1( λLi − 1), where λ1, . . . , λn

are the eigenvalues of A relative to B. This improved factor can be signiﬁcantly

smaller than the original one if the majority of the eigenvalues λi are much

larger than µ. However, for the sake of simplicity, we prefer to work directly

with constants n, L and µ. This corresponds to the worst-case analysis. The

same remark applies to all other theorems on superlinear convergence, that

will follow.

Let us discuss the eﬃciency estimate (3.9). Note that its maximal value over all φi ∈ [0, 1] is achieved at φi = 1 for all 0 ≤ i ≤ k − 1. This corresponds to the DFP method. In this case, the eﬃciency estimate (3.9) looks as follows:

λf (xk) ≤

nL2

k/2
λf (x0).

µ2 k

Hence, the moment, when the superlinear convergence starts, can be described

as follows:

nL2 µ2 k

≤1

⇐⇒

k

≥

nL2 µ2

.

In contrast, the minimal value of the eﬃciency estimate (3.9) over all φi ∈ [0, 1] is achieved at φi = 0 for all 0 ≤ i ≤ k − 1. This corresponds to the BFGS method. In this case, the eﬃciency estimate (3.9) becomes

k/2

λf (xk) ≤

nL µk

λf (x0),

(3.11)

and the moment, when the superlinear convergence begins, can be described

as follows:

nL µk

≤

1

⇐⇒

k ≥ nµL .

Thus, we see that, compared to DFP, the superlinear convergence of BFGS

starts

in

L µ

times

earlier,

and

its

rate

is

much

faster.

Let us present for the scheme (3.3) another justiﬁcation of the superlinear

convergence rate in the form (3.9). For this, instead of σ, we will work with

the potential function ω, deﬁned by (2.15). The advantage of this analysis is

that it is extendable onto general nonlinear functions.

14

Anton Rodomanov, Yurii Nesterov

Theorem 3.3 In scheme (3.3), for all k ≥ 1, we have

λf (xk) ≤

1

k−1 i=0

(φi

µ L

) +1−φi 1/2

k/2

4nL µk

λf (x0).

(3.12)

Proof

Denote

θi

d=ef

θ(A, Gi, ui),

ψi

d=ef

ψ(A, Gi),

and

pi

d=ef

φi

µ L

+ 1 − φi

for

any i ≥ 0. Let k ≥ 1 and 0 ≤ i ≤ k − 1 be arbitrary. In view of (3.6) and

Lemma 2.4, we have

(2.21) ψi − ψi+1 ≥ φiω

Lµ θi + (1 − φi)ω(θi).

(3.13)

Note that θi ≤ 1. Indeed, if ui = 0, then θi = 0 by deﬁnition. Otherwise,

θ2 (2=.6) 1 − (2Gi−A)ui,ui

i

Gi A−1 Gi ui ,ui

(3.6) ≤ 1.

Therefore,

(2.16) ω µθ ≥ µ

√θi2

≥ µ θi2 ,

Li

L 2(1+

µ L

θ

i

)

L4

(2.16) θ2

θ2

ω(θi)

≥

i
2(1+θi)

≥

i
4

,

and we conclude that

(3.13) ψi − ψi+1 ≥ 41 piθi2.

Summing this inequality and using the fact that ψk ≥ 0, we obtain

k−1
1 piθ2

≤

ψ0 − ψk ≤ ψ0 (3=.3) ψ(A, LB)

4

i

i=0

(2.=14) A−1, LB − A − ln Det(A−1, LB)

(3.2)

≤

A−1,

L µ

A

−

A

−

ln

Det(A−1,

L µ

A)

(1=.3) n Lµ − 1 − ln Lµ ≤ nµL .

(3.14)

Hence, by Lemma 3.1 and the arithmetic-geometric mean inequality,

λf (xk)

=
≤ (3.14)
≤

k−1
λf (x0)
i=0

1

k−1 i=0

p1i /2

1

k−1 i=0

p1i /2

k−1

θi =

1

k−1 i=0

p1i /2

piθi2
i=0

k−1

k/2

1 k

piθi2

λf (x0)

i=0

k/2

4nL µk

λf (x0).

1/2
λf (x0)
⊓⊔

Comparing our new eﬃciency estimate (3.12) with the previous one (3.9), we see that they diﬀer only in a constant. Thus, for the quadratic function, we do not gain anything by working with the potential function ω instead of σ. Nevertheless, our second proof is more universal, and, in contrast to the ﬁrst one, can be generalized onto general nonlinear functions, as we will see in the next section.

Rates of superlinear convergence for classical quasi-Newton methods

15

4 Minimization of general functions Consider now a general unconstrained minimization problem:

min f (x),
x∈E

(4.1)

where f : E → R is a twice diﬀerentiable function with positive deﬁnite Hessian.
To write down the standard quasi-Newton scheme for (4.1), we ﬁx some self-adjoint positive deﬁnite linear operator B : E → E∗ and a constant L > 0, that we use to deﬁne the initial Hessian approximation.

Initialization: Choose x0 ∈ E. Set G0 = LB.

For k ≥ 0 iterate:

1. Update xk+1 = xk − G−k 1∇f (xk).

2. Set uk = xk+1 − xk and choose φk ∈ [0, 1].

3. Denote Jk =

1 0

∇2f (xk

+

tuk)dt.

4. Set Gk+1 = Broydφk (Jk, Gk, uk).

(4.2)

Remark 4.1 Similarly to Remark 3.1, when implementing scheme (4.2), it is common to work directly with the inverse Hk d=ef G−k 1 instead of Gk. Also note that it is not necessary to compute Jk explicitly. Indeed, for implementing the Hessian approximation update at Step 4 (or the corresponding update for its inverse), one only needs the product

Jkuk = ∇f (xk+1) − ∇f (xk),
which is just the diﬀerence of the successive gradients.
In what follows, we make the following assumptions about the problem (4.1). First, we assume that, with respect to the operator B, the objective function f is strongly convex with parameter µ > 0 and its gradient is Lipschitz continuous with constant L, i.e.

µB ∇2f (x) LB

(4.3)

for all x ∈ E. Second, we assume that the objective function f is strongly self-concordant with some constant M ≥ 0, i.e.

∇2f (y) − ∇2f (x) M y − x z∇2f (w)

(4.4)

16

Anton Rodomanov, Yurii Nesterov

for all x, y, z, w ∈ E. The class of strongly self-concordant functions was recently introduced in [31], and contains at least all strongly convex functions with Lipschitz continuous Hessian (see [31, Example 4.1]). It gives us the the following convenient relations between the Hessians of the objective function:

Lemma 4.1 (see [31, Lemma 4.1]) Let x, y ∈ E, and let r d=ef

Then,

∇2f (x) 1+M r

∇2f (y)

(1 + M r)∇2f (x).

y − x x. (4.5)

Also, for J d=ef 01 ∇2f (x + t(y − x))dt, we have

J ∇2f (x)

1+

Mr 2

1

+

Mr 2

∇2f (x),

(4.6)

J ∇2f (y)

1+

M 2

r

1

+

Mr 2

∇2f (y).

(4.7)

As a particular example of a nonquadratic function, satisfying assump-

tions (4.3), (4.4), one can consider the regularized log-sum-exp function, de-

ﬁned by f (x) d=ef ln(

m i=1

e

ai ,x

+bi )

+

µ 2

x

2,

where

ai

∈

E∗,

bi

∈

R

for

i = 1, . . . , m, and µ > 0, x d=ef Bx, x 1/2.

Remark 4.2 Since we are interested in local convergence, it is possible to relax
our assumptions by requiring that (4.3), (4.4) hold only in some neighborhood of a minimizer x∗. For this, it suﬃces to assume that the Hessian of f is Lipschitz continuous in this neighborhood with ∇2f (x∗) being positive deﬁnite. These are exactly the standard assumptions, used in [14] and many
other works, studying local convergence of quasi-Newton methods. However,
to avoid excessive technicalities, we do not do this.

Let us now analyze the process (4.2). For measuring its convergence, we look at the local norm of the gradient:

λf (x) d=ef

∇f (x) ∗ (1=.1)
x

∇f (x), ∇2f (x)−1∇f (x) 1/2,

x ∈ E. (4.8)

First, let us estimate the progress of one step of the scheme (4.2). Recall that θ(Jk, Gk, uk) is the measure of closeness of Gk to Jk along the direction uk (see (2.6)).

Lemma 4.2 In scheme (4.2), for all k ≥ 0 and rk d=ef uk xk , we have

λf (xk+1) ≤

1

+

M rk 2

θ(Jk, Gk, uk)λf (xk).

Proof Denote θk d=ef θ(Jk, Gk, uk). In view of Taylor’s formula, ∇f (xk+1) = ∇f (xk) + Jk(xk+1 − xk) (4=.2) −(Gk − Jk)uk.

(4.9)

Rates of superlinear convergence for classical quasi-Newton methods

17

Therefore,

λf (xk+1) (4=.8) (4.7) ≤ (4=.9) (2=.6) (4=.2) (4.6) ≤ (4=.8)

∇f (xk+1), ∇2f (xk+1)−1∇f (xk+1) 1/2

1

+

M rk 2

∇f

(xk

+

1

),

J

− k

1

∇f

(xk

+

1

)

1/2

1

+

M rk 2

(Gk − Jk)Jk−1(Gk − Jk)uk, uk 1/2

1+

M rk 2

θk

GkJk−1Gkuk, uk

1/2

1+

M rk 2

θk

∇f

(xk

),

J

− k

1

∇f

(xk

)

1/2

1

+

M rk 2

1

+

M rk 2

θk ∇f (xk), ∇2f (xk)−1∇f (xk) 1/2

θkλf (xk).

⊓⊔

Our next result states that, if the starting point in scheme (4.2) is chosen
suﬃciently close to the solution, then the relative eigenvalues of the Hessian approximations Gk with respect to both the Hessians ∇2f (xk) and the integral Hessians Jk are always located between 1 and Lµ , up to some small numerical constant. As a consequence, the process (4.2) has at least the linear
convergence rate of the gradient method.

Theorem 4.1 Suppose that, in scheme (4.2),

M λf (x0) ≤ ln423 Lµ .

(4.10)

Then, for all k ≥ 0, we have

ξ1k ∇2f (xk) Gk ξk Lµ ∇2f (xk),

(4.11)

1 ξ′

Jk

Gk

ξk′

L µ

Jk

,

k

where3

ξkλf (xk) ≤

1

−

µ 2L

k λf (x0),

ξk d=ef eM

ki=−01 ri ≤ 1 + M2rk eM

k−1 i=0

ri

d=ef

ξk′

≤

32 ,

(4.12) (4.13)
(4.14)

and ri d=ef ui xi for any i ≥ 0.

Proof Note that ξ0 = 1 and G0 = LB. Therefore, for k = 0, both (4.11), (4.13) are satisﬁed. Indeed, the ﬁrst one reads ∇2f (x0) LB Lµ ∇2f (x0) and follows from (4.3), while the second one reads λf (x0) ≤ λf (x0) and is
obviously true.

3 Here we follow the standard convention that the sum over the empty set is deﬁned as zero. Thus, ξ0 = e0 = 1.

18

Anton Rodomanov, Yurii Nesterov

Now assume that k ≥ 0, and that (4.11), (4.13) have already been proved for all 0 ≤ k′ ≤ k. Combining (4.11) with (4.6), using the deﬁnition of ξk′ , we obtain (4.12). Further, denote λi d=ef λf (xi) for 0 ≤ i ≤ k. Note that

rk (4=.2) (4.11) ≤
Therefore,

G−k 1∇f (xk) xk (1=.1) ∇f (xk), Gk−1∇2f (xk)G−k 1∇f (xk) ξk ∇f (xk), ∇2f (xk)−1∇f (xk) 1/2 (4=.8) ξkλk.

1/2
(4.15)

k (4.15) k

(4.13)

k

M ri ≤ M ξiλi ≤ M λ0

1 − 2µL i

i=0

i=0

i=0

≤ 2µL M λ0 (4.≤10) ln223 .

Consequently, by the deﬁnition of ξk and ξk′ ,

ξ

≤ ξ′

≤

e

M rk 2

eM

k−1 i=0

ri

≤

eM

k

(4.16)

i=0 ri ≤

3.

k

k

2

(4.16)

Thus, (4.12), (4.14) are now proved. To ﬁnish the proof by induction, it remains to prove (4.11), (4.13) for k′ = k + 1.
We start with (4.11). Applying Lemma 2.1, using (4.12), we obtain

1 ξ′

Jk

k

Gk+1

ξk′

L µ

Jk

.

(4.17)

Consequently,

G (4.7) 1 + Mrk ξ′ L ∇2f (x ) (4.=14)

k+1

2

kµ

k+1

1

+

M rk 2

2

ξk

L µ

∇f

(xk+1

)

eMrk ξk Lµ ∇2f (xk+1) (4.=14) ξk+1 Lµ ∇2f (xk+1),

and (4.7)
Gk+1

∇2f (xk+1)

1+ Mrk ξ′

2

k

(4=.14)

∇2f (xk+1) 1+ M2rk 2ξk

∇2f (xk+1) eMrk ·ξk

(4.=14)

. ∇2f (xk+1)
ξk+1

Thus, (4.11) is proved for k′ = k + 1. It remains to prove (4.13) for k′ = k + 1. By Lemma 4.2,

λk+1 ≤

1

+

M rk 2

θk λk ,

where θk d=ef θ(Jk, Gk, uk). Note that

Hence,

(4.12)

(4.12)

−

1

−

µ ξ′ L

Jk−1

G−k 1 − Jk−1

(ξk′ − 1)Jk−1.

k

(Jk−1 − G−k 1)Jk(Jk−1 − G−k 1) ρ2kJk−1,

(4.18)

Rates of superlinear convergence for classical quasi-Newton methods

19

where Therefore,

ρk d=ef max

1

−

ξ

µ ′L

,

ξk′

−

1

k

(4.14) ≥ 0.

2.6 2 ( ) (Jk−Gk)Jk−1(Jk−Gk)uk,uk

θ = = k

JkG− k 1Jkuk ,uk

Gk(Jk−1−G− k 1)Jk(Jk−1−G− k 1)Gkuk ,uk JkG− k 1Jkuk,uk

Thus, Consequently,

(4.18)

λk+1 ≤

1

+

M rk 2

ρk λk .

(4.19) ≤ ρ2k.

ξk+1λk+1 ≤ ξk+1 1 + M2rk ρkλk (4.=14) eMrk 1 + M2rk ≤ e 3M2rk ρkξkλk (4≤.13) e 3M2rk ρk 1 − 2µL k λ0.

ρk ξk λk

It remains to show that

e

3M rk 2

ρk

≤

1

−

2µL .

Note that

ζk d=ef 3M2rk (4≤.15) 3Mξ2kλk (4.≤13) 3M2λ0

(4.10) ≤

3

ln

3 2

µ

≤

3µ

≤

µ

≤ 1.

8L

16L

5L

5

Hence,

∞
eζk ≤ ζi = 1 + ζ

∞ (4.21) ζi ≤ 1 + ζ

∞

1i

k

k

k

k

5

i=0

i=0

i=0

(4.21)

=

1

+

5ζk 4

≤ 1 + 4µL .

Also,

(4.14) ξk′ ≤

3 2

≤

43 .

Combining (4.22) and (4.23), we obtain

(4.20) (4.21) (4.22) (4.23)

e

3M rk 2

1

−

µ ξ′ L

k

≤

1

+

µ 4L

1

−

3µ 4L

≤ 1−

3 4

−

1 4

µ L

=

1 − 2µL ,

and

e

3M rk 2

(ξk′

−

1)

≤

1

+

1 4

3 2

−

1

=

√5 4

·

1 2

≤ 5 ≤ 1 ≤ 1− µ .

3 2

+

1

16

2

2L

Thus,

e

3M rk 2

ρk

(4.=19)

e

3M rk 2

max

1−

µ
′

, ξ′

−1

ξkL k

≤ 1 − 2µL ,

and (4.20) follows.

⊓⊔

Now we are ready to prove the main result of this section on the superlinear

convergence of the scheme (4.2). In contrast to the quadratic case, now we

cannot use the proof, based on the trace potential function σ, deﬁned by (2.7),

because we cannot longer guarantee that Jk Gk. However, the proof, based

on the potential function ψ, deﬁned by (2.14), still works.

20

Anton Rodomanov, Yurii Nesterov

Theorem 4.2 Suppose that the initial point x0 in scheme (4.2) is chosen

suﬃciently close to the solution, as speciﬁed by (4.10). Then, for all k ≥ 1,

we have

λf (xk) ≤

1

k−1 i=0

(φi

µ L

) +1−φi 1/2

k/2

11nL µk

λf (x0).

Proof Denote ri d=ef ui xi , θi d=ef θ(Ji, Gi, ui), ψi d=ef ψ(Ji, Gi), ψ˜i+1 d=ef

ψ(Ji, Gi+1),

and

pi

d=ef

φi

µ L

+1

−

φi

for

any

i

≥

0.

Let

k

≥

1

and

0

≤

i

≤

k

−

1

be arbitrary. By (4.12), (4.14) and Lemma 2.4, we have

ψi − ψ˜i+1 ≥ φiω

2 3

Lµ θi + (1 − φi)ω

23 θi .

(4.24)

Moreover, since

θ2 (2=.6)
i

(Gi −Ji )Ji−1 (Gi −Ji )ui ,ui Gi Ji−1 Gi ui ,ui

= 1 − (2Gi−Ji)ui,ui
Gi Ji−1 Gi ui ,ui

(4.12) ≤ 1,

we also have

ω

2 3

ω

(2.16) µθ ≥

4 9

µ L

θ√i2

≥

4 9

µ θ2 = 2 µ θ2 ≥ 1 µ θ2,

Li

2(1+

2 3

·

2 3

µ L

θ

i

)

2(1+

4 9

)

L

i

13 L i

7L i

(2.16) 2θ ≥

√ 2
3

θi2

≥

√ 2
3

≥

2 3

θ2

=

1 θ2 ≥

1 θ2.

3 i 2 1+ 23 θi 2 1+ 23 4 i 6 i 7 i

Thus,

(4.24) 1 p θ2 ≤ ψ

− ψ˜

= ψ −ψ +∆ ,

7 ii

i

i+1

i

i+1

i

where

∆i d=ef ψi+1 − ψ˜i+1 (2.=14) J −1 − J −1, Gi+1 + ln Det(J −1, Ji+1).

i+1

i

i

(4.25) (4.26)

Let us estimate
where Hence,

k−1 i=0

∆i

from

above.

Note

that

(4.6) ∇2f (xi+1)

Ji+1

M ri+1

1+ 2

(4.7)

δ1i Ji,

δi d=ef

1

+

M ri+1 2

1

+

M ri 2

.

(4.27) (4.28)

Ji−+11 − Ji−1, Gi+1

(4.27) ≤ (1 − δi−1) Ji−+11, Gi+1

(4.12) ≤ (1 − δi−1)

3L 2µ

Ji−+11, Ji+1

(1=.3)

(4.23)

3 2

nL µ

(1

−

δi−1)

≤

4nL 3µ

(1

−

δi−1),

Rates of superlinear convergence for classical quasi-Newton methods

21

and

k−1 (4.26)

k−1

k−1

∆i

≤

4nL 3µ

(1 − δi−1) +

ln

De

t

(J

− i

1

,

J

i+

1

)

i=0

i=0

i=0

k−1

=

4nL 3µ

(1 − δi−1) + ln Det(J0−1, Jk).

i=0

At the same time,

(4.29)

k−1(1 − δi−1) ≤ k−1 1 − e− M(ri+2ri+1)

i=0

i=0

(4≤.13) M λ0 k−1 1 − 2µL i ≤

i=0

k−1

k

≤

M 2

(ri + ri+1) ≤ M

ri

i=0

i=0

2µL M λ0 (4≤.10) ln223 ≤ 41 .

Thus,

k−1 (4.29)

∆i

≤

nL 3µ

+

ln

Det(J0−1,

Jk ).

i=0

Summing up (4.25) and using the fact that ψk ≥ 0, we obtain

(4.30)

k−1

(4.25)

k−1

1 7

piθi2 ≤ ψ0 − ψk +

∆i ≤

i=0

i=0

(4.2)

k−1

= ψ(J0, LB) + ∆i

k−1
ψ0 + ∆i
i=0

(2.=14) (4.30)
≤

i=0 k−1
J0−1, LB − J0 − ln Det(J0−1, LB) + ∆i
i=0

J0−1, LB − J0

+

nL 3µ

−

ln

Det(Jk−1,

LB)

(4.3) ≤

J0−1,

L µ

J0

−

J0

+

nL 3µ

(1=.3) n Lµ − 1 + n3µL ≤ 43 nµL .

(4.31)

Since (1 + t)p ≤ 1 + pt for all t ≥ −1 and 0 ≤ p ≤ 1, we further have

1+

M ri

≤

e

M ri 2

(4.13) Mλ0 ≤ e2

(4.10) ≤

2

3 1/8 2

= 32 1/4 ≤ 1 + 14 · 12 = 98 .

Therefore, by Lemma 4.2 and the arithmetic-geometric mean inequality,

k−1
λf (xk) ≤ λf (x0)
i=0

98 θi =

k−1

≤ ki=−101 pi 89 · k1 i=0 piθi2

k/2

≤

21nL 2µk

λf (x0) ≤

1

k−1 i=0

p1i /2

k/2

λf (x0)

9

k k−1 p θ2

1/2
λ

(x

)

8

ii

f0

i=0

(4.31) ≤

k/2

9 8

·

7

·

4 3

nL µk

λf (x0)

k/2

11nL µk

λf (x0).

⊓⊔

22

Anton Rodomanov, Yurii Nesterov

5 Discussion

Let us compare the rates of superlinear convergence, that we have obtained for the classical quasi-Newton methods, with those of the greedy quasi-Newton methods [31]. For brevity, we discuss only the BFGS method. Moreover, since the complexity bounds for the general nonlinear case diﬀer from those for the quadratic one only in some absolute constants (both for the classical and the greedy methods), we only consider the case, when the objective function f is quadratic.
As before, let n be the dimension of the problem, µ be the strong convexity parameter, L be the Lipschitz constant of the gradient of f , and λf (x) be the local norm of the gradient of f at the point x ∈ E (as deﬁned by (3.4)). Also, let us introduce the following condition number to simplify our notation:

Q d=ef nµL ≥ 1.

(5.1)

The greedy BFGS method [31] is essentially the classical BFGS algorithm (scheme (3.3) with φk ≡ 0) with the only diﬀerence that, at each iteration, the update direction uk is chosen greedily according to the following rule:

uk d=ef argmax GAkuu,,uu ,
u∈{e1 ,...,en }

where e1, . . . , en is a basis in E, such that B−1 =

n i=1

eie∗i .

For

this

method,

we have the following recurrence (see [31, Theorem 3.2]):

λf (xk+1) ≤ 1 − Q1 k Qλf (xk) ≤ e− Qk Qλf (xk), k ≥ 0.

Hence, its rate of superlinear convergence is described by the expression

k−1
λf (xk) ≤ λf (x0)

e−

i Q

Q

i=0

=

e−

k(k−1) 2Q

Qk

λf

(x0

)

d=ef

Ak ,

k ≥ 0. (5.2)

Although the inequality (5.2) is valid for all k ≥ 0, it is useful only when

e−

k(k−1) 2Q

Qk

≤

1

⇐⇒

k ≥ 1 + 2Q ln Q.

(5.3)

In other words, the relation (5.3) speciﬁes the moment, starting from which it becomes meaningful to speak about the superlinear convergence of the greedy BFGS method.
For the classical BFGS method, we have the following bound (see (3.11)):

λf (xk) ≤ Qk k/2 λf (x0) d=ef Bk, k ≥ 1,

and the starting moment of its superlinear convergence is described as follows:

Qk k/2 ≤ 1

⇐⇒

k ≥ Q.

(5.4)

Rates of superlinear convergence for classical quasi-Newton methods

23

Comparing (5.3) and (5.4), we see that, for the standard BFGS, the superlinear convergence may start slightly earlier than for the greedy one. However, the diﬀerence is only in the logarithmic factor.
Nevertheless, let us show that, very soon after the superlinear convergence of the greedy BFGS begins, namely, after

K d=ef 1 + 6Q ln(4Q)

(5.1) ( ≥ 7)

(5.5)

iterations, it will be signiﬁcantly faster than the standard BFGS. Indeed,

= e Q Ak

−

k

(k−1) 2Q

k

Bk

Qk k/2 = e− k(k2Q−1) (Qk)k/2

=

e−

k(k−1) 2Q

+

k 2

ln(Qk)

=

e−

k(k−1) 2Q

[1−

Q

ln(Qk) k−1

]

(5.6)

for

all

k

≥

1.

Note

that

the

function

t

→

ln t t

is

decreasing

on

[e, +∞)

(since

its logarithm ln ln t − ln t is a decreasing function of u = ln t for u ∈ [1, +∞),

which is easily veriﬁed by diﬀerentiation). Hence, for all k ≥ K, we have (using

ﬁrst that k ≤ 2(k − 1) since k ≥ 2)

Q lkn−(Q1 k) ≤ Q ln(2kQ−(1k−1)) ≤ Q ln(2KQ−(K1 −1)) (5=.5) ln(162Qln2(4lnQ()4Q)) ≤ l6nl(n4(84QQ3)) ≤ l6nl(n6(44QQ3)) = 63 llnn((44QQ)) = 12 .

Consequently, for all k ≥ K, we obtain

(5.6) k(k−1) BAkk ≤ e− 4Q

≤ 1.

Thus, after K iterations, the rate of superlinear convergence of the greedy BFGS is always better than that of the standard BFGS. Moreover, as k → ∞, the gap between these two rates grows as e−k2/Q. At the same time, the complexity of the Hessian update for the greedy BFGS method is more expensive than for the standard one.

Acknowledgements The authors are thankful to two anonymous reviewers for their valuable time and useful feedback.

References
1. W. Davidon. Variable metric method for minimization. Argonne National Laboratory Research and Development Report 5990 (1959).
2. R. Fletcher and M. Powell. A rapidly convergent descent method for minimization. Computer Journal, 6(2), 163-168 (1963).
3. C. Broyden. Quasi-Newton methods and their application to function minimization. Mathematics of Computation, 21(99), 368-381 (1967).
4. C. Broyden. The convergence of a class of double-rank minimization algorithms: 1. General considerations. IMA Journal of Applied Mathematics, 6(1), 76-90 (1970).
5. C. Broyden. The convergence of a class of double-rank minimization algorithms: 2. The new algorithm. IMA Journal of Applied Mathematics, 6(3), 222-231 (1970).

24

Anton Rodomanov, Yurii Nesterov

6. R. Fletcher. A new approach to variable metric algorithms. Computer Journal, 13(3), 317-322 (1970).
7. D. Goldfarb. A family of variable-metric methods derived by variational means. Mathematics of Computation, 24(109), 23-26 (1970).
8. D. Shanno. Conditioning of quasi-Newton methods for function minimization. Mathematics of Computation, 24(111), 647-656 (1970).
9. M. Powell. On the convergence of the variable metric algorithm. IMA Journal of Applied Mathematics, 7(1), 21-36 (1971).
10. L. Dixon. Quasi-Newton algorithms generate identical points. Mathematical Programming, 2(1), 383-387 (1972).
11. L. Dixon. Quasi Newton techniques generate identical points II: The proofs of four new theorems. Mathematical Programming, 3(1), 345-358 (1972).
12. C. Broyden, J. Dennis, and J. Mor´e. On the local and superlinear convergence of quasiNewton methods. IMA Journal of Applied Mathematics, 12(3), 223-245 (1973).
13. J. Dennis and J. Mor´e. A characterization of superlinear convergence and its application to quasi-Newton methods. Mathematics of Computation, 28(126), 549-560 (1974).
14. J. Dennis and J. Mor´e. Quasi-Newton methods, motivation and theory. SIAM Review, 19(1), 46-89 (1977).
15. A. Stachurski. Superlinear convergence of Broyden’s bounded θ-class of methods. Mathematical Programming, 20(1), 196-212 (1981).
16. A. Griewank and P. Toint. Local convergence analysis for partitioned quasi-Newton updates. Numerische Mathematik, 39(3), 429-448 (1982).
17. R. Byrd, J. Nocedal, and Y. Yuan. Global convergence of a class of quasi-Newton methods on convex problems. SIAM Journal on Numerical Analysis, 24(5), 1171-1190 (1987).
18. R. Byrd and J. Nocedal. A tool for the analysis of quasi-Newton methods with application to unconstrained minimization. SIAM Journal on Numerical Analysis, 26(3), 727-739 (1989).
19. J. Engels and H. Mart´ınez. Local and superlinear convergence for partially known quasiNewton methods. SIAM Journal on Optimization, 1(1), 42-56 (1991).
20. R. Byrd, D. Liu, and J. Nocedal. On the behavior of Broyden’s class of quasi-Newton methods. SIAM Journal on Optimization, 2(4), 533-557 (1992).
21. H. Yabe and N. Yamaki. Local and superlinear convergence of structured quasi-Newton methods for nonlinear optimization. Journal of the Operations Research Society of Japan, 39(4), 541-557 (1996).
22. Z. Wei, G. Yu, G. Yuan, and Z. Lian. The superlinear convergence of a modiﬁed BFGStype method for unconstrained optimization. Computational Optimization and Applications, 29(3), 315-332 (2004).
23. J. Nocedal and S. Wright. Numerical optimization. Springer Science & Business Media (2006).
24. H. Yabe, H. Ogasawara, and M. Yoshino. Local and superlinear convergence of quasiNewton methods based on modiﬁed secant conditions. Journal of Computational and Applied Mathematics, 205(1), 617-632 (2007).
25. A. Lewis and M. Overton. Nonsmooth optimization via quasi-Newton methods. Mathematical Programming, 141(1-2), 135-163 (2013).
26. R. Gower, D. Goldfarb, and P. Richta´rik. Stochastic block BFGS: squeezing more curvature out of data. International Conference on Machine Learning, 1869-1878 (2016).
27. R. Gower and P. Richta´rik. Randomized quasi-Newton updates are linearly convergent matrix inversion algorithms. SIAM Journal on Matrix Analysis and Applications, 38(4), 1380-1409 (2017).
28. A. Mokhtari, M. Eisen, and A. Ribeiro. IQN: An incremental quasi-Newton method with local superlinear convergence rate. SIAM Journal on Optimization, 28(2), 1670-1698 (2018).
29. Y. Nesterov. Lectures on convex optimization. Springer, 137 (2018). 30. W. Gao and D. Goldfarb. Quasi-Newton methods: superlinear convergence without line
searches for self-concordant functions. Optimization Methods and Software, 34(1), 194217 (2019). 31. A. Rodomanov, Y. Nesterov. Greedy quasi-Newton methods with explicit superlinear convergence. CORE Discussion Papers, 06 (2020).

Rates of superlinear convergence for classical quasi-Newton methods

25

32. D. Kovalev, R. Gower, P. Richta´rik, and A. Rogozin. Fast linear convergence of randomized BFGS. arXiv preprint arXiv:2002.11337 (2020).

6 Appendix Lemma 6.1 Let A, B : E → E∗ be self-adjoint linear operators such that

0 ≺ A B.

(6.1)

Then, for any u ∈ E \ {0}, we have

A − AAuuu,∗uA B − BBuuu,∗uB .

Proof Indeed, for all h ∈ E, we have

Ah, h − Au,h 2 = min Ah, h − 2α Ah, u + α2 Au, u

Au,u

α∈R

= min A(h − αu), h − αu
α∈R
(6.1) ≤ min B(h − αu), h − αu
α∈R

= min Bh, h − 2α Bh, u + α2 Bu, u
α∈R
= Bh, h − BBuu,,hu 2 . ⊓⊔

Lemma 6.2 For any self-adjoint positive deﬁnite linear operators A, G : E → E∗, any scalar φ ∈ R, and any direction u ∈ E \ {0}, we have

Det(G−1, Broydφ(A, G, u))

=

φ

AG−1 Au,u Au,u

+ (1 − φ)

Au,u Gu,u

.

(6.2)

Remark 6.1 Note that formula (6.2) is known in the literature (see e.g. [20, eq. (1.9)]), although we do not know any reference, which contains an explicit proof of this result.
Proof Denote G+ d=ef Broydφ(A, G, u),

G0

d=ef

G

−

Guu∗ G Gu,u

+

AAuuu,∗uA ,

s d=ef AAuu,u − GGuu,u .

(6.3)

Note that G+ (2=.1) G0 + φ Gu,AuuA,uuu2 ∗A + GGuuu,∗uG − Auu∗GA+u,Guuu∗A = G0 + φ Gu, u ss∗,

and

s, u = 0.

(6.4)

26

Anton Rodomanov, Yurii Nesterov

Let Q d=ef G + AAuuu,∗uA . Note that

Qu = Gu + Au,

QG−1Au = 1 + AGA−u1,Auu,u Au,

(6.5)

and G0 = Q − GGuuu,∗uG . Therefore, applying twice Lemma 6.3, we ﬁnd that

Det(G−1, Q) = 1 + AGA−u1A,uu,u ,

Det(Q−1, G0) = 1 −

GQ−1 Gu,u Gu,u

(6=.5) 1 − Gu−GGQu−,u1Au,u

= GQG−u1,Auu,u (6=.5) Gu,u 1+AuA,uG−1Au,u . Au,u

Hence,

Det(G−1, G0) (1=.4) Det(G−1, Q)Det(Q−1, G0) = GAuu,,uu .

(6.6)

Further, note that

G0u (6=.3) Au,

G0G−1Au (6=.3) AGA−u1,Auu,u Au + Au − GAuu,,uu Gu. (6.7)

So, applying Lemma 6.3 again, we obtain

Det(G−0 1,

G+)

(6=.3) (6=.3) (6=.7) (6=.7) (6=.4) (6=.3)
=

1 + φ Gu, u s, G−0 1s

1+φ 1+φ 1+φ

Gu,u Au,u
Gu,u Au,u
Gu,u Au,u

s, G−0 1Au − s, G−1Au − s, G−1Au −

Au,u Gu,u

G−0 1Gu

AG−1Au,u Au,u

G−0 1Au

AGA−u1,Auu,u u

1+φ

Gu,u Au,u

s, G−1Au

1+φ

Gu,u Au,u

Au Au,u

−

Gu Gu,u

, G−1Au

φ Gu,u AAuG,u−21Au,u + 1 − φ.

(6.8)

Consequently,

Det(G−1, G+) (1=.4) Det(G−1, G0)Det(G−0 1, G+) (6=.6) (6=.8) GAuu,,uu φ Gu,u AAuG,u−12Au,u + 1 − φ
= φ AGA−u1,Auu,u + (1 − φ) GAuu,,uu .

Au,u Gu,u

Det(G−0 1, G+)

⊓⊔

Lemma 6.3 (Determinant of rank-1 perturbation) Let A : E → E∗ be a self-adjoint positive deﬁnite linear operator, s ∈ E∗, and α ∈ R. Then,

Det(A−1, A + αss∗) = 1 + α s, A−1s .

Proof Indeed, with respect to A, the operator A + αss∗ has n − 1 unit eigen-

values and one eigenvalue 1 + α s, A−1s (corresponding to the eigenvector

A−1s).

⊓⊔

