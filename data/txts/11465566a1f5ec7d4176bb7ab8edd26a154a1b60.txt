1
Effects of Risk on Privacy Contracts for Demand-Side Management
Lillian J. Ratliff, Carlos Barreto, Roy Dong, Henrik Ohlsson, Alvaro A. Ca´rdenas, and S. Shankar Sastry,

arXiv:1409.7926v3 [math.OC] 16 Nov 2014

Abstract—As smart meters continue to be deployed around the world collecting unprecedented levels of ﬁne-grained data about consumers, we need to ﬁnd mechanisms that are fair to both, (1) the electric utility who needs the data to improve their operations, and (2) the consumer who has a valuation of privacy but at the same time beneﬁts from sharing consumption data. In this paper we address this problem by proposing privacy contracts between electric utilities and consumers with the goal of maximizing the social welfare of both. Our mathematical model designs an optimization problem between a population of users that have different valuations on privacy and the costs of operation by the utility. We then show how contracts can change depending on the probability of a privacy breach. This line of research can help inform not only current but also future smart meter collection practices.
I. INTRODUCTION
I NCREASINGLY advanced metering infrastructure (AMI) is replacing older technology in the electricity grid. Smart meters measure detailed information about consumer electricity usage every half-hour, quarter-hour, or in some cases, every ﬁve minutes. This high-granularity data is needed to support energy efﬁciency efforts as well as demand-side management. However, improper handling of this information could also lead to unprecedented invasions of consumer privacy [1]–[4].
It has been shown that energy consumption data reveals a considerable amount about consumer activities. Furthermore, energy consumption data in combination with readily available sources of information can be used to discover even more about the consumer. Authors in [5] argue and experimentally validate that a privacy breach can be broadly implemented in two steps. First, energy usage data in combination with other sensors in the home — e.g. water and gas usage — can be used to track a person’s location, their appliance usage, and match individuals to observed events. In the second step, this learned information can be combined with demographic data
L. J. Ratliff, R. Dong, H. Ohlsson, and S. S. Sastry are with the Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA, USA. e-mail: {roydong,ratliffl,ohlsson,sastry}@eecs.berkeley.edu.
C. Barreto, and A. A. Ca´rdenas are with the Department of Computer Science, University of Texas at Dallas, Richardson, TX, USA. email: {carlos.barretosuarez,alvaro.cardenas}@utdallas.edu.
The work presented is supported by the NSF Graduate Research Fellowship under grant DGE 1106400, NSF CPS:Large:ActionWebs award number 0931843, TRUST (Team for Research in Ubiquitous Secure Technology) which receives support from NSF (award number CCF-0424422), and FORCES (Foundations Of Resilient CybEr-physical Systems) CNS-1239166, the European Research Council under the advanced grant LEARN, contract 267381, a postdoctoral grant from the Sweden-America Foundation, donated by ASEA’s Fellowship Fund, and by a postdoctoral grant from the Swedish Research Council.

— e.g. number, age, sex of individuals in the residence — to identify activities, behaviors, etc.
Given that smart grid operations inherently have privacy and security risks [2], it would beneﬁt the utility company, to know the answer to the following questions: How do consumers in the population value privacy? How can we quantify privacy? How do privacy-aware policies impact smart grid operations? There have been a nuber of works making efforts to address these questions [6]–[9]. In particular, it has been shown that there is a fundamental utility-privacy tradeoff in data collection policies in smart grid operations.
A utility company that desires to conduct some smart grid operation, such as demand response or direct load control program, requires high-ﬁdelity data. They can observe consumers’ electricity usage but do not know their privacy preferences. We propose that the utility company can design a screening mechanism — in particular, a menu of contracts — to assess how consumers value privacy.
In general, contracts are essential for realizing the beneﬁts of economic exchanges including those made in smart grid operations. Contract theory has been used in energy grid applications including procurement of electric power from a strategic seller [10] and demand response programs [11], [12] among others [13]. We take a novel view point by considering privacy to be the good on which we design contracts.
We design contracts given the utility company has an arbitrary smart grid operation they want to implement yet the consumer’s preferences are unknown. In particular, based on their valuation of privacy as a good, consumers can select the quality of the service contract with the utility company. Essentially, electricity service is offered as a product line differentiated according to privacy where consumers can select the level of privacy that ﬁts their needs and wallet. The optimal contracts are incentive compatible and individually rational.
Further, we assess loss risks due to privacy breaches given the optimally designed contracts. We design new contracts when these risks are explicitly considered by the utility company. We provide a characterization of the contracts designed with and without loss risks. We show that there are inefﬁciencies when we consider losses incurred due to privacy breaches and thus, in some cases, the utility company has an incentive to offer compensation to the consumer in the event of a privacy breach, invest in security measures, and purchase insurance.
The purpose of this paper is to provide qualitative assessment of privacy contracts for demand-side management through the use of simple examples which have all the interesting properties of the larger problem such as asymmetric information. In Section II, we study a two-type model; there

2

are two types of consumers — ones that have a high valuation of privacy and ones that have a low valuation of privacy — and characterize the solution for the contract design problem. In Section III, we characterize the contract solution when the consumer is risk-adverse and the risk of a privacy breach is explicitly modeled in the contract design. In Section IV, we present an example where the utility company is interested in implementing a direct load control scheme and designs contracts with and without risk. Finally, in Section V, we provide discussion and future research directions.

II. PRIVACY CONTRACTS

In this section, we discuss the design of privacy-based contracts that are offered to consumers, who possess private information, i.e., the utility does not know the characteristics of each user. We consider a model in which there are only two classes of users and we utilize standard results from the theory of screening (see, e.g., [14], [15]) to develop a framework for designing privacy contracts. In general, the fundamental characteristics of the two-type problem extend to the any number of types including a continuum of types.
We model privacy-settings on smart meters (e.g., sampling rate) as a good. The quality of the good is either a highprivacy setting xH or a low-privacy setting xL, which can be interpreted for example as low and high sampling rates, respectively. Each consumer selects x ∈ X = {xH , xL} ⊂ R where −∞ < xL < xH < ∞. On the other hand, the consumer’s valuation of privacy is characterized by the parameter θ , commonly called the type of a user. The type of an agent is seen as a piece of private information that determines the willingness of a user to pay for a good: in our privacy setting, the type characterizes the electricity consumption privacy needs of the user. In our model, we assume θ takes only two values, i.e., θ ∈ {θL, θH } ⊂ R, where θL < θH . The type θ is distinct from the private information that is subject to a privacy breach.
The consumers type θ is related to his willingness to pay in the following way: if the utility company announces a price t for choosing x, the type-dependent consumer’s utility is equal to zero if he does not select a privacy setting x, and

Uˆ (x, θ ) − t ≥ 0

(1)

if he does select a privacy setting. The case in which the consumer does not select a privacy setting is considered the opt-out case in which consumer exercises his right to not participate. The inequality in (1) is often called the individual rationality constraint.
We have the following assumptions on the consumer’s utility function which represents its preferences:

Assumption 1. The utility function Uˆ : R × Θ → R is strictly increasing in (x, θ ) ∈ R × Θ, concave in x ∈ R, and differentiable with respect to x.

Assumption 2. The marginal gain from raising the value of
the privacy setting x is greater for type θH , i.e. Uˆ (x, θH ) − Uˆ (x, θL) is increasing in x.

Since we have only two types, the contracts offered will be indexed by the privacy settings xL and xH . Further, as we mentioned before, the consumer can opt-out by not selecting a privacy option at all. Hence, we need to constrain the mechanism design problem by enforcing the inequality given in Equation (1) for each value of θ ∈ {θL, θH }. In addition, we need to enforce incentive-compatibility constraints

Uˆ (xH , θH ) − tH ≥ Uˆ (xL, θH ) − tL

(2)

and

Uˆ (xL, θL) − tL ≥ Uˆ (xH , θL) − tH

(3)

where the ﬁrst inequality says that given the price tH a consumer of type θH should prefer the high-privacy setting xH and the second inequality says that given the price tL a consumer of type θL should prefer the low-privacy setting xL.
The utility company has unit utility

v(x,t) = −g(x) + t

(4)

where g : X → R is the unit cost experienced by the utility company with a privacy setting x, which satisﬁes the following assumption.

Assumption 3. The cost function g : R → R is a strictly increasing, convex, and differentiable function.

This assumption is reasonable since a low-privacy setting xL provides the utility company with the high-granularity data it needs to efﬁciently operate and maintain the smart grid [7]– [9].
Let the expected proﬁt of the utility company be given by

Π(tL, xL,tH , xH ) = (1 − p)v(xL,tL) + pv(xH,tH ) (5)

where p = P(θ = θH ) = 1 − P(θ = θL) ∈ (0, 1) and P(·) denotes probability. The screening problem is to design the contracts, i.e. {(tL, xL), (tH , xH )} where tL,tH ∈ R, so that the utility companies expected proﬁt is maximized. In particular, to ﬁnd the optimal pair of contracts, we solve the following optimization problem:

max Π(tL, xL,tH , xH )
{(tL,xL),(tH ,xH )}
s.t. Uˆ (xH , θH ) − tH ≥ Uˆ (xL, θH ) − tL Uˆ (xL, θL) − tL ≥ Uˆ (xH, θL) − tH Uˆ (xL, θL) − tL ≥ 0 Uˆ (xH , θH ) − tH ≥ 0
xL ≤ xH

(P-1)
(IC-1) (IC-2) (IR-1) (IR-2)

Depending on the form of Uˆ (x, θ ) and g(x) problem (P-1) can be difﬁcult to solve. Hence, we reduce the problem using characteristics of the functions and constraints. We remark that this process of reducing the constraint set in contract design with a ﬁnite number of types is well known (see, e.g., [14]– [16]) and sometimes referred to as the constraint reduction theorem.
First, we show that (IR-1) is active. Indeed, suppose not. Then, Uˆ (xL, θL) − tL > 0 so that, from the ﬁrst incentive

3

compatibility constraint (IC-1), we have

Uˆ (xH , θH ) − tH ≥ Uˆ (xL, θH ) − tL ≥ Uˆ (xL, θL) − tL > 0 (6)
where the second to last inequality holds since Uˆ (x, θ ) is increasing in θ by assumption. As a consequence, the utility company can increase the price for both types since neither incentive compatibility constraint would be active. This would lead to an increase in the utility company’s pay-off and thus, we have a contradiction.
Now, since Uˆ (xL, θL) = tL, the last inequality in (6) is equal to zero. This implies that (IR-2) is redundant. Further, this argument implies that the constraint (IC-1) is active. Indeed, again suppose not. Then,

Uˆ (xH , θH ) − tH > Uˆ (xL, θH ) − tL ≥ Uˆ (xL, θL) − tL = 0 (7)

so that it would be possible for the utility company to decrease the incentive tH without violating (IR-2).
By Assumption 2 and the fact that (IC-1) is active, we have

tH −tL = Uˆ (xH , θH )−Uˆ (xL, θH ) ≥ Uˆ (xH , θL)−Uˆ (xL, θL). (8)

This inequality implies that we can ignore (IC-2). Further, since Uˆ is increasing in (x, θ ) and by assumption θH > θL, we have that xL < xH .
Thus, we have reduced the constraint set:

tH − tL = Uˆ (xH , θH ) − Uˆ (xL, θH ),

(9)

tL = Uˆ (xL, θL).

(10)

The optimization problem (P-1) reduces to two independent optimization problems:

max{Uˆ (xL, θL) − (1 − p)g(xL) − pUˆ (xL, θH )}
xL
and

(P-2a)

max{Uˆ (xH , θH ) − g(xH)}.
xH

(P-2b)

We will denote the solution to the two optimization problems above by (xˆ∗i ,tˆi∗) and for reasons that will become apparent in the next paragraph we call it the second-best solution.

We now claim that the optimal contract satisﬁes xˆ∗L < xˆ∗H. Indeed, consider the case when the utility company knows the

type of the consumer that it faces, i.e. the solution under full

information which we refer to as the ﬁrst-best solution. We

denote the ﬁrst-best solution by (xˆ†i ,tˆi†) for i ∈ {L, H} where

the pair solves

maxUˆ (xˆi, θi) − g(xˆi)

(11)

xˆi

and tˆi† = Uˆ (xˆ†i , θi). Note that throughout the rest of the paper we will use the notation (·)† to denote the ﬁrst-best solution and (·)∗ to denote the second-best solution.
Notice that (P-2b) is exactly the optimization problem
the utility company would solve to determine the ﬁrst-best
solution for the high-type. Hence, even when there is hidden
information, the high-type will always be offered the ﬁrst-best quality and ﬁrst-best price, i.e. (xˆ∗H ,tˆH∗ ) = (xˆ†H ,tˆH† ). This is to say that the high-type receives an efﬁcient allocation.
Assumption 2 implies that the ﬁrst-best solution xˆ†i (θ ) is increasing in θ . Further, Uˆ (xˆL, θH ) −Uˆ (xˆL, θL) is increasing in

xˆL and non-negative so that xˆ†L ≥ xˆ∗L. Thus xˆ∗L ≤ xˆ†L < xˆ†H = xˆ∗H. This result also shows that when there is asymmetric
information, the low-type gets zero surplus and a quality level that is inefﬁcient when compared to the ﬁrst-best solution. On the other hand, as we have pointed out, the high-type is offered the ﬁrst-best quality and has more surplus. Further, the high-type gets positive information rent:

tˆH∗ = tˆH† − Uˆ (xˆ∗L, θH ) − Uˆ (xˆ∗L, θL) .

(12)

information rent

We will see the effects of this in the example presented in Section IV.

III. EFFECTS OF RISK ON PRIVACY CONTRACTS

In this section, we are interested in analyzing the effect of loss risk (due to privacy breaches) in contracts.
Let us consider that users might suffer privacy breaches of cost ℓ(θ ), with probability 1−η(x). Then, their expected proﬁt can be expressed as:

U(x, θ ) = Uˆ (x, θ ) − (1 − η(x))ℓ(θ ).

(13)

The characteristics of the privacy breach are summarized in the following assumption.

Assumption 4. η : R → [0, 1] (probability of avoiding a privacy breach) is strictly increasing with respect to the privacy x. The perceived loss due to a privacy breach ℓ : Θ → R≥0 is increasing with respect to the type of each user.

Roughly speaking, the higher the privacy setting, the less likely a privacy breach will occur. Furthermore, a user with high privacy needs might experience smaller costs compared to a user with low privacy settings.
The individual rationality constraints for the case where consumers have privacy risks can be expressed as

Uˆ (x, θ ) − t ≥ (1 − η(x))ℓ(θ ).

(14)

Recall that the optimal contract without risk for the low-type, (xˆ∗L,tˆL∗), satisﬁes (IR-1) with strict equality, i.e. Uˆ (xˆ∗L, θL) = tˆL∗. Thus, the optimal contract of the previous section violates (14) unless either ℓ(θL) = 0 or η(xˆ∗L) = 1. Consequently, consumers with low privacy preferences θL might do better by opting out.
On the other hand, the incentive compatibility constraint
(IC-2) can be expressed as

Uˆ (xL, θL) − tL ≥ Uˆ (xH , θL) − tH + (η(xH ) − η(xL))ℓ(θL) (15)
when we consider privacy risks. Note that since xˆ∗L < xˆ∗H, η(xˆ∗H ) − η(xˆ∗L) > 0. Hence, the inequality in (15) might not be satisﬁed by the optimal contract that does not consider risk. Consequently, consumers with low preferences θL might want to choose a high privacy contract.
Intuitively, the utility company might need to decrease the cost tL and/or increase the privacy setting xL in order to promote participation of consumers. These measures might decrease the beneﬁt and fees collected by the utility company. Hence, there is an incentive for the utility company to purchase insurance and/or invest in security.

4

In the rest of this section, we characterize the contracts with risk loss and the utility company’s proﬁt.

A. Contracts with Loss Risk

Suppose that U deﬁned in (13) satisﬁes Assumption 1. Then the analysis in Section II holds when we replace Uˆ
with U. Thus, we are going to compare the settings of contracts with and without risk, denoted as {xL, xH ,tL,tH }, and {xˆL, xˆH ,tˆL,tˆH }, respectively.
First, let us extract some inequalities that are going to be
used to compare the contracts. From (13) we can extract the
marginal utility with loss risk:

∂ U(x, θ ) = ∂ Uˆ (x, θ ) + ∂ η(x)ℓ(θ ).

(16)

∂x

∂x

∂x

Since U is strictly increasing by Assumption 1, we have

∂ U(x, θ ) > 0.

(17)

∂x

Furthermore, since ℓ(θ ) ≥ 0 and the probability of a successful attack (1 − η(x)) decreases with higher privacy settings, we

have

∂ η(x) > 0.

(18)

∂x

Hence, we can extract the following inequality from (16)

∂ U(x, θH ) ≥ ∂ Uˆ (x, θH ).

(19)

∂x

∂x

From this inequality we can infer that the presence of risk

increases the valuation that each user gives to its privacy.

Now, we proceed to analyze changes in the optimal contract

with the inclusion of loss risk. First, let us show that the

privacy setting of a user with high-type is greater in presence

of risk.

Proposition 1. The privacy policy of an agent with type θH is higher with loss risk, that is, x∗H ≥ xˆ∗H .

Proof. From (P-2a), we have the ﬁrst-order conditions for the case without risk,

∂ Uˆ (x, θH ) − g(x)

= 0,

(20)

∂x

x=xˆ∗H

and the ﬁrst-order conditions for the case with risk,

∂ (U(x, θH ) − g(x)) = 0.

(21)

∂x

x=x∗H

Thus (19) implies

0 ≥ ∂ Uˆ (x, θH ) − g(x)

.

(22)

∂x

x=x∗H

Note

that

∂ ∂x

Uˆ (x, θH ) − g(x)

is a decreasing function of x.

Hence, the optimal privacy setting without risk xˆ∗H (which

satisﬁes (20)) must be smaller than the privacy setting with

risk, i.e., x∗H ≥ xˆ∗H. This result is independent of the population

distribution p and the low type θL.

Now, we analyze the privacy settings for consumers with low-type.

Proposition 2. The privacy of low-type agents in contracts with and without loss risk (x∗L and xˆ∗L resp.) satisfy the following inequalities:

ß x∗L ≥ xˆ∗L, if p ≤ p¯,

(23)

x∗L < xˆ∗L, if p > p¯,

with p¯ = ℓℓ((θθHL)) .

Proof. From (P-2b) we get the ﬁrst-order conditions for the case without risk,

∂ Uˆ (x, θL) − pUˆ (x, θH ) ∂x

− (1 − p) ∂ g(x) = 0,

x=xˆ∗L

∂x

x=xˆ∗L

(24)

and the ﬁrst-order conditions for the case with loss risk,

∂ (U(x, θL) − pU(x, θH)) − (1 − p) ∂ g(x) = 0.

∂x

x=x∗L

∂x

x=x∗L

(25)

We use (13) to rewrite the ﬁrst term of (25) as

∂ (U(x, θL) − pU(x, θH)) = ∂ Uˆ (x, θL) − pUˆ (x, θH )

∂x

∂x

+ ∂ η(x) (ℓ(θL) − pℓ(θH)) . ∂x (26)

Now, let us consider three cases. First, if ℓ(θL)− pℓ(θH) = 0, then, from (26) we know that the contracts with and without risk have the same solution, that is, x∗L = xˆ∗L.
If ℓ(θL) − pℓ(θH) > 0, then
∂ (U(x, θL) − pU(x, θH)) > ∂ Uˆ (x, θL) − pUˆ (x, θH ) . ∂ x ∂ x (27) Then (27) and (25) imply

0>

∂

Å Uˆ (x, θL)

−

pUˆ (x, θH )

−

(1

−

p)

∂

ã g(x)

. (28)

∂x

∂x

x=x∗

L

Hence, by (24), x∗L > xˆ∗L.

Finally, if ℓ(θL) − pℓ(θH) < 0, then

∂ (U(x, θL) − pU(x, θH)) < ∂ Uˆ (x, θL) − pUˆ (x, θH ) . ∂ x ∂ x (29)
In this case, we can use the ﬁrst-order conditions in (24) and (25) and the inequality (29) to prove that x∗L < xˆ∗L.

The following result generalizes the dependence of the privacy xL with respect to p. In particular, the privacy of the low-type users is decreasing with respect to p, regardless of the presence of loss risk.
Proposition 3. The optimal privacy setting x∗L is decreasing with respect to p.
Proof. First, let us consider two distribution probabilities p, pˆ ∈ [0, 1] such that pˆ = p + ε, where ε > 0. Now, let us deﬁne x∗L(p) as optimal privacy policy that satisﬁes the ﬁrstorder conditions in (25), for a population distribution p. Also, let us consider the derivative of the objective function in (P-2b)

5

for a population distribution pˆ:

∂ f (x, pˆ) = ∂ (U(x, θL) − pˆU(x, θH ) − (1 − pˆ)g(x)) , (30)

∂x

∂x

where f (x, pˆ) is the objective function of the optimization

problem. This can be rewritten as

∂ f (x, pˆ) = ∂ (U(x, θL) − pU(x, θH) − (1 − p)g(x))

∂x

∂x

+ ε ∂ (g(x) − U(x, θH)) .

(31)

∂x

Evaluating the previous equation in x∗L(p) we ﬁnd that

∂ f (x∗ (p), pˆ) = ε ∂ (g(x) − U(x, θH))

. (32)

∂x L

∂x

x=x∗L ( p)

The previous result follows since x∗L(p) satisﬁes the ﬁrst-order conditions in (25).

Now, recall that the contract assigns higher privacy to agents with high-type, i.e., x∗H > x∗L. Hence, if we evaluate the lefthand side of (21) in x∗L(p), we ﬁnd that

∂ (U(x, θH ) − g(x))

> 0.

(33)

∂x

x=x∗L ( p)

Thus, we know that

∂ f (x∗ (p), pˆ) < 0.

(34)

∂x L

This equation indicates that the the optimal contract with a distribution pˆ satisﬁes x∗L(p) > x∗L(pˆ).

The previous result states that the optimal privacy for lowtype agents x∗L is decreasing with respect to the population distribution p. Consequently, tL∗ is also decreasing with p. Furthermore, x∗H does not depend on p since the high-type always gets an efﬁcient allocation independent of the prior on types. This applies regardless of the risk probability 1 − η(x).
Another aspect of the contract that changes with the intro-
duction of risk is the cost t. Results in Propositions 1 and 2
let us determine the impact of risk on the price t paid by each
user.

Proposition 4. The price of the contracts with and without risk ({tL∗,tH∗ } and {tˆL∗,tˆH∗ } respectively) satisfy the following inequalities:

 

tL∗ > tˆL∗ − (1 − η(xˆ∗L))ℓ(θL),

 tL∗ < tˆL∗,

 tH∗ > tˆH∗ ,

with p¯ = ℓℓ((θθHL)) .

if p < p¯

if p > p¯

if

p>

p¯, 1 −

1−η(x∗H )
∗

>

p¯

1−η (xL )

(35)

Proof. From (10) we know that the contract payment is

tL∗ = U (x∗L, θL).

(36)

Since U(·, θ ) is an increasing function in x, we can use Proposition 2 to conclude that

ß tL∗ > tˆL∗ − (1 − η(xˆ∗L))ℓ(θL), if p < p¯

(37)

tL∗ < tˆL∗,

if p > p¯

On the other hand, the price paid by high-type users is given

by

tH∗ = U (x∗H , θH ) − U (x∗L, θH ) + U (x∗L, θL).

(38)

Hence,

tH∗ =Uˆ (x∗H, θH ) − (1 − η(x∗H))ℓ(θH ) − Uˆ (x∗L, θH )

+

(1

−

η

(x

∗ L

))ℓ

(θH

)

+

Uˆ

(x

∗ L

,

θL

)

−

(1

−

η

(x

∗ L

))ℓ

(θL

)

(39)

By assumption Uˆ (·, θ ) is increasing in x so that Uˆ (x∗H , θH ) > Uˆ (xˆ∗H , θH ) since x∗H > xˆ∗H for all p by Proposition 1. Furthermore, if we deﬁne

h(x) = −(Uˆ (x, θH ) − Uˆ (x, θL)),

(40)

then from Assumption 2 we know that h(·) is decreasing in x. Hence, by Proposition 2, for p > p¯ we have x∗L < xˆ∗L so that
(39) becomes

tH∗ > Uˆ (xˆ∗H , θH ) − (1 − η(x∗H))ℓ(θH ) − Uˆ (xˆ∗L, θH )

+

(1

−

η

(x

∗ L

))ℓ

(θH

)

+

Uˆ

(xˆ∗L

,

θL

)

−

(1

−

η

(x

∗ L

))ℓ

(θL

)

(41)

= tˆH∗ + (η(x∗H) − η(x∗L))ℓ(θH ) − (1 − η(x∗L))ℓ(θL) (42)

By

assumption

1−

1−η(x∗H )
∗

>

p¯,

so

that

t∗

> tˆ∗ .

1−η (xL )

HH

Proposition 5. If p > p¯, then the information rent under the optimal contract without loss risk is higher than under the optimal contract with loss risk, i.e.

Uˆ (xˆ∗L, θH ) − Uˆ (xˆ∗L, θL) > U (x∗L, θH ) − U (x∗L, θL). (43)

Proof. Suppose that p > p¯, then by Proposition 2 we have x∗L < xˆ∗L. The information rent under {x∗L, x∗H ,tL∗,tH∗ } is given
by

U (x∗L, θH ) − U (x∗L, θL) =Uˆ (x∗L, θH ) − Uˆ (x∗L, θL)

+

(1

−

η

(x

∗ L

))(ℓ

(θL

)

−

ℓ

(θH

)).

(44)

Since ℓ(θL) < ℓ(θH ) by assumption, we have

U (x∗L, θH ) − U (x∗L, θL) < Uˆ (x∗L, θH ) − Uˆ (x∗L, θL) (45)

By Assumption 1, Uˆ is increasing in x. Hence,

Uˆ (x∗L, θH ) − Uˆ (x∗L, θL) < Uˆ (xˆ∗L, θH ) − Uˆ (xˆ∗L, θL). (46)

Thus,

U (x∗L, θH ) − U (x∗L, θL) < Uˆ (xˆ∗L, θH ) − Uˆ (xˆ∗L, θL). (47)

We can conclude that when p < p¯, the loss risk increases the privacy contract of all users. Roughly speaking, this happens because losses of users with low-type are signiﬁcant with respect to losses of high-type users. In consequence, the contract with loss risk allows users with low-type to have more privacy. On the other hand, when p > p¯ losses of low-type users are not signiﬁcant and the contract will tend to offer less privacy settings to low-type users. In this case the utility company can afford more losses due to risk in order to collect higher ﬁdelity data.
We can conclude that, regardless of the proﬁt, a population of agents with p > p¯ might be more beneﬁcial for

6

a utility company interested in collecting information from users. Roughly speaking, a favorable environment for privacy contracts is characterized by a large population of agents with high-type. In the next section we analyze the contract parameters and the utility company’s proﬁt as a function of the population distribution p.

B. Proﬁt

The proﬁt of the utility company is

Π(tL, xL,tH , xH ) = (1 − p) (−g(xL) + U (xL, θL))

+ p (−g(xH) + tH) .

(48)

Recall that xH does not depend on p and that tH is increasing with respect to p. Hence, p (−g(xH) + tH) is increasing in p. Also, note that (25) can be rewritten as

∂ (U(x, θL) − g(x))

= p ∂ (U(x, θH ) − g(x))

∂x

x=x∗L ( p)

∂x

x=x∗L ( p)

(49)

From

(33)

we

know

that

∂ ∂x

(U

(x,

θH

)

−

g(x))

x=x∗ (p).

There-

fore, U (x∗L(p), θH ) − g(x∗L(p)) is increasing in xL∗L(p). Also,

because p ≥ 0, we know that U(x∗L(p), θL) − g(x∗L(p)) is

increasing in x. Considering that x∗L(p) is decreasing in p,

we can conclude that (1 − p)(−g(x∗L(p)) + U(x∗L(p)), θL) is

decreasing in p.

Thus, Π is composed of an increasing term and a decreasing

term of p so that the maximum proﬁt might be achieved on

the boundary, i.e. p = 0 or p = 1. We explore the proﬁt of

the utility company in more detail through an example in the

following section.

where x ∈ [0, 1], i.e. their utility is proportional to both the type and quality. As in the previous section, we model the consumer’s risk aversion using the following utility:

U(x, θ ) = Uˆ (x, θ ) − (1 − η(x))ℓ(θ )

(52)

A higher privacy setting is less likely to be successfully attacked; hence, for the sake of the example, we take 1 − η(x) = m(1 − x) where m > 0 is a constant and x ∈ [0, 1] with zero corresponding to a low-privacy setting and one corresponding to a high-privacy setting.

θH −mℓ(θH ) x
ζ
θH /ζ
θL −mℓ(θL ) ζ
θL/ζ

x∗L xˆ∗L

x∗H = x†H xˆ∗H = xˆ†H x†L
xˆ†L

0

p∗ pˆ∗ 1 p

Fig. 1. Comparison between full information and asymmetric information solutions as a function of p the probability of the high-type in the population for both the case when we consider risk (gray) and when we do not consider risk (black). The general shape of the curves stay the same for different values of m; changing m from 0 to 1 only has an effect of shifting the critical value p∗ for the case with risk closer to the origin as well as causing x∗H to decrease.

IV. EXAMPLE – DIRECT LOAD CONTROL

Recall that the unit gain the utility company gets out of the privacy setting x is a function g : X → R. In this section, we discuss a particular example in which g is a metric for how access to high-granularity data affects direct load control (DLC).
In previous work, we characterized the utility–privacy tradeoff for a DLC problem of thermostatically controlled loads (TCLs) [7]. In particular, we showed that the ℓ1–norm of the error of the DLC (measured in terms of the ℓ1 distance between the actual power consumed by the TCLs and the desired power consumption) increases as a function of the sampling period, i.e. distance between samples. Empirically the relationship between sampling period and ℓ1–norm error is approximately quadratic. Hence, for this example, we let

g(x) = 1 ζ x2

(50)

2

where 0 < ζ < ∞. Note that a decreased sampling rate corresponds to a higher
privacy setting. The function g as deﬁned is increasing in x so that g(xL) < g(xH ).
Suppose that θ ∈ {θL, θH } where 0 < θL < θH . Assume that the consumer’s utility is given by

Uˆ (x, θ ) = xθ

(51)

For the case without risk the ﬁrst-best solution is given by

(xˆ† , xˆ† ) = Å θH , θL ã and (tˆ†,tˆ† ) = Ç θH2 , θL2 å . (53)

HH

ζζ

LH

ζζ

For the case with risk, the ﬁrst-best solution is given by

(x†H , x†L) = Å θH − mζ ℓ(θH) , θL − mζ ℓ(θL) ã (54)

and

(t† ,t†) = Ç θH2 − mθHℓ(θH ) , θL2 − mθLℓ(θL) å . (55)

HL

ζ

ζ

Let the utility company’s prior be deﬁned by p = P(θ = θH ) and (1 − p) = P(θ = θL). Then the optimal solution to the screening problem without risk is given by

(xˆ∗

,

xˆ∗

)

=

Å

θH

,

1

ï θL

−

p

òã

(θH − θL)

(56)

HL

ζζ

1− p

+

where [·]+ = max{·, 0}, i.e. xˆ∗L = 0 when p ≥ pˆ∗, and

tˆ∗

=

θH2

−

(θL

−

θH

)

ï θL

−

p

ò

(θH − θL)

(57)

Hζ

ζ

1− p

+

tˆ∗

=

θL

ï θL

−

p

ò

(θH − θL)

(58)

Lζ

1− p

+

Similarly, the optimal solution to the screening problem

7

when there is risk is given by

(x∗H , x∗L) = ζ1 (θH + mℓ(θH)),

1 mℓ(θL) − pmℓ(θH) − pθH + θL (59)

ζ

1− p

+

and

tH∗ = tL∗ + x∗H θH − x∗LθH + m(x∗H − x∗L)ℓ(θH )

(60)

t∗ = θL mℓ(θL) − pmℓ(θH) − pθH + θL

(61)

Lζ

1− p

+

The plots in Figures 1-4 show the fundamental properties of the contract solution and the general shapes of the curves are invariant under changes to parameters of the problem.

t θH2 −mθζH ℓ(θH ) Info. Rent tH∗

θH2

tˆ∗

ζ

Info. Rent

H

tˆL† tˆL∗ tL†

tL∗

0

p∗

pˆ∗

1p

Fig. 2. Optimal prices as a function of p for both the case with risk (gray) and without (black). The information rent as a function of p for both cases is also shown.

Π
Π† Π∗ Πˆ †

θL2/(2ζ )
θL2 −ℓ2 (θL )m2 2ζ
0

Πˆ ∗

p∗

pˆ∗

1p

Fig. 3. Proﬁt of the utility company as a function of p for both the case with risk Π(p) (gray) and without Πˆ (p) (black).

In Figure 1, we show that as the probability of the hightype being drawn from the population increases, x∗L (resp. xˆ∗L) decreases away from the optimal full information solution x†L (resp. xˆ†L). This occurs until the critical point

p∗ = θL + mℓ(θL)

Å resp.

pˆ∗

=

θL

ã .

(62)

θH + mℓ(θH)

θH

It is reasonable that as soon as the probability of the utility company facing a consumer of high-type reaches a critical

W
θH2 −ℓ2(θH )m2 2ζ
θH2 2ζ
W†

W∗

0

p∗

Wˆ † Wˆ ∗

pˆ∗

1p

Fig. 4. Social Welfare as a function of p for both the case with risk W ∗ (gray) and without risk Wˆ ∗ (black).

point, they will focus all their efforts on this type of consumer since a high-type desires a higher privacy setting which results in a degradation of the DLC scheme.
In Figure 2, we show the optimal prices for the ﬁrstand second-best problems in both the case with risk and without. We see that for p ≤ p∗ (resp. p ≤ pˆ∗) we have positive information rent for the high-type. Essentially, when the probability of the existence of a low-type is large relative to the probability of the existence of a high-type, there is a positive externality on the high-type. Thus people who value high privacy more need to be compensated more to participate in the smart grid. Further, the low-type continues to get zero surplus since the individual rationality constraint of the lowtype is always binding.
In Figure 3 and 4 respectively, we show the utility company’s expected proﬁt and social welfare

W (p,tL, xL,tH , xH ) =Π(tL, xL,tH , xH ) + p(U (xH, θH ) − tH)

+ (1 − p)(U (xL, θL) − tL),

(63)

which is the sum of expected proﬁt of the utility company
and the consumer. Notice the slope of the linear pieces of Wˆ ∗ and W ∗; in particular, Wˆ ∗(p) for p ≥ pˆ∗ is increasing at a slower rate than W ∗(p) for p ≥ p∗. Similarly, Π∗(p) for p ≥ p∗ increases at a faster rate than Πˆ ∗(p) for p ≥ pˆ∗. This is in part due to the fact that tH∗ (p)−tL∗(p) > tˆH∗ (p)−tˆL∗(p) as is shown in Figure 2. We remark that there are some values for p for which
the utility company’s proﬁt and the social welfare are lower
when risk is considered; this motivates adding compensation
or insurance as a function of the population distribution into
the contract.

V. DISCUSSION
As the capability of smart meters to collect data at high frequencies increases, we need to develop tools so that consumers and utilities beneﬁt from these advances. Implementing privacy-aware data collection policies results in a reduction in the ﬁdelity of the data and hence, a reduction in the efﬁciency of grid operations that depend on that data. This fundamental tradeoff provides an incentive for the utility company to offer new service contracts.

8

In this paper we modeled electricity service as a product line differentiated according to privacy. In this setting, consumers can self-select the level of privacy that ﬁts their needs and wallet. We derived privacy contracts both when loss risks are considered and when they are not. We characterized the optimal solution in each of the cases and provided a comparative study. We showed that loss risks decrease the level service offered to each consumer type.
We remark that people who value high privacy more, need to be compensated more to participate in the smart grid. If there are two contracts, then even consumers who do not value privacy much will have an incentive to lie. Through the screening mechanism, the consumer will report their type truthfully. The screening process is a way to do customer segmentation, the result of which can lead to targeting. In particular, using knowledge of consumer preferences, the utility company could then incentivize consumers based on their preferences to choose a low privacy setting thereby increasing the granularity of data.
Further, we showed that the utility company has an incentive to purchase insurance and invest in security when there are loss risks. We leave the questions around how much the utility company should invest in insurance versus security for future work. There are a number of open questions in the design of insurance contracts to be offered to the utility company by a third party insurer given the consumer faces loss risk. We have made initial efforts at studying insurance contracts to be offered to the consumer [17]; however, there is much to be done in understanding how the optimal contracts vary as a function of the distribution of types and the privacy metric used.
Other researchers have used contract theory for demand-side management such as DLC and demand response programs. Given that smart meters can collect data at high frequencies, it would be interesting to consider the design of contracts with multiple goods — e.g. privacy setting, DLC options — in a multidimensional screening problem. In such a setting, we may also model the consumer’s private information (type) as multidimensional vector thereby increasing the practical relevance of the model. Further, Assumption 2 is often referred to as the sorting condition. One of the major difﬁculties in extending to the multidimensional case is the lack of being able to sort or compare across the different goods and their qualities [16]; however, a potential solution is to create a partial order of the multiple goods (beneﬁts and privacy)

available to consumers.
In conclusion, there are multiple future research directions
we can explore from the model we have presented in this pa-
per. Our model provides a general a mathematical framework
for considering privacy as part of a service contract between
an electric utility and the consumer. This line of research can
help inform data collection schemes and privacy policy in the
smart grid.
REFERENCES
[1] E. L. Quinn, “Smart metering and privacy: Existing laws and competing policies,” Colorado Public Utilities Commission, Tech. Rep., 2009.
[2] M. Salehie, L. Pasquale, I. Omoronyia, and B. Nuseibeh, “Adaptive security and privacy in smart grids: A software engineering vision,” in Int. Workshop on Software Engineering for the Smart Grid, June 2012, pp. 46–49.
[3] S. Wicker and R. Thomas, “A privacy-aware architecture for demand response systems,” in In Proc. of the 44th Inter. Conf. on System Sciences, Jan 2011, pp. 1–9.
[4] G. Hart, “Residential energy monitoring and computerized surveillance via utility power ﬂows,” IEEE Technol. Soc. Mag., vol. 8, no. 2, pp. 12–16, June 1989.
[5] M. Lisovich, D. Mulligan, and S. Wicker, “Inferring personal information from demand-response systems,” IEEE Security & Privacy, vol. 8, no. 1, pp. 11–20, Jan 2010.
[6] R. Dong, L. Ratliff, H. Ohlsson, and S. S. Sastry, “Fundamental limits of nonintrusive load monitoring,” in Proc. of the 3rd ACM Int. Conf. on High Conﬁdence Networked Systems, 2013.
[7] R. Dong, A. A. Ca´rdenas, L. J. Ratliff, H. Ohlsson, and S. S. Sastry, “Quantifying the utility-privacy tradeoff in the smart grid,” arXiv, no. 1406.2568, 2014.
[8] L. Sankar, S. R. Rajagopalan, S. Mohajer, and H. V. Poor, “Smart meter privacy: A theoretical framework,” IEEE Trans. Smart Grid, vol. 4, no. 2, pp. 837–846, June 2013.
[9] S. Rajagopalan, L. Sankar, S. Mohajer, and H. Poor, “Smart meter privacy: A utility-privacy framework,” in Proc. of the 1st IEEE Int. Conf. on Smart Grid Communications, Oct 2011, pp. 190–195.
[10] H. Tavafoghi and D. Teneketzis, “Optimal energy procurement from a strategic seller with private renewable and conventional generation,” arXiv, no. 1401.5759v1, 2014.
[11] M. Fahrioglu and F. Alvarado, “Designing incentive compatible contracts for effective demand management,” IEEE Trans. on Power Syst., vol. 15, no. 4, pp. 1255–1260, Nov 2000.
[12] M. Fahrioglu, M. F. Fern, and F. L. Alvarado, “Designing cost effective demand management contracts using game theory,” IEEE Power Eng. Soc., vol. 1, 1999.
[13] T. Gedra, “Optional forward contracts for electric power markets,” IEEE Trans. Power Syst., vol. 9, no. 4, pp. 1766–1773, Nov 1994.
[14] T. A. Weber, “Optimal control theory with applications in economics,” MIT Press Books, vol. 1, 2011.
[15] P. Bolton and M. Dewatripont, Contract theory. MIT press, 2005. [16] S. Basov, “Multidimensional screening,” in Studies in Economic Theory.
Springer, 2005, vol. 22. [17] L. J. Ratliff, R. Dong, H. Ohlsson, A. A. Ca´rdenas, and S. S. Sastry,
“Privacy and customer segmentation in the smart grid,” arXiv, no. 1405.7748 (to appear at IEEE CDC 2014), 2014.

