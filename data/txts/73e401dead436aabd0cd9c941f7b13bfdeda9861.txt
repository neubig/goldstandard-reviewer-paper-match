3PC: Three Point Compressors for Communication-Efﬁcient Distributed Training and a Better Theory for Lazy Aggregation

Peter Richta´rik KAUST*

Igor Sokolov KAUST
Zhize Li KAUST

Ilyas Fatkhullin ETH AI Center & ETH Zurich
Eduard Gorbunov MIPT†

Elnur Gasanov KAUST

arXiv:2202.00998v1 [cs.LG] 2 Feb 2022

Abstract
We propose and study a new class of gradient communication mechanisms for communicationefﬁcient training—three point compressors (3PC)—as well as efﬁcient distributed nonconvex optimization algorithms that can take advantage of them. Unlike most established approaches, which rely on a static compressor choice (e.g., Top-𝐾), our class allows the compressors to evolve throughout the training process, with the aim of improving the theoretical communication complexity and practical efﬁciency of the underlying methods. We show that our general approach can recover the recently proposed state-of-the-art error feedback mechanism EF21 (Richta´rik et al., 2021) and its theoretical properties as a special case, but also leads to a number of new efﬁcient methods. Notably, our approach allows us to improve upon the state of the art in the algorithmic and theoretical foundations of the lazy aggregation literature (Chen et al., 2018). As a by-product that may be of independent interest, we provide a new and fundamental link between the lazy aggregation and error feedback literature. A special feature of our work is that we do not require the compressors to be unbiased.
1. Introduction
It has become apparent in the last decade that, other things equal, the practical utility of modern machine learning models grows with their size and with the amount of data points used in the training process. This big model and big data approach, however, comes with increased demands on the hardware, algorithms, systems and software involved in the training process.
*King Abdullah University of Science and Technology, Thuwal, Saudi Arabia. †Moscow Institute of Physics and Technology, Dolgoprudny, Russia.

1.1. Big data and the need for distributed systems

In order to handle the large volumes of data involved in training SOTA models, it is now absolutely necessary to rely on (often massively) distributed computing systems (Dean et al., 2012; Khirirat et al., 2018; Lin et al., 2018). Indeed, due to storage and compute capacity limitations, large-enough training data sets can no longer be stored on a single machine, and instead need to be distributed across and processed by an often large number of parallel workers.

In particular, in this work we consider distributed supervised learning problems of the form

[︂

𝑛

]︂

min

𝑓 (𝑥)

:=

1 𝑛

∑︀

𝑓𝑖(𝑥)

,

(1)

𝑥∈R𝑑

𝑖=1

where 𝑛 is the number of parallel workers/devices/clients, 𝑥 is a vector representing the 𝑑 parameters of a machine learning model (e.g., the weights in a neural network), and 𝑓𝑖(𝑥) is the loss of model 𝑥 on the training data stored on client 𝑖 ∈ [𝑛] := {1, 2, . . . , 𝑛}.

In some applications, as in federated learning (FL) (McMahan et al., 2016; Konecˇny´ et al., 2016b;a; McMahan et al., 2017), the training data is captured in a distributed fashion in the ﬁrst place, and there are reasons to process it in this decentralized fashion as well, as opposed to ﬁrst moving it to a centralized location, such as a datacenter, and subsequently processing it there. Indeed, FL refers to machine learning in the environment where a large collection of highly heterogeneous clients (e.g., mobile devices, smart home appliances or corporations) tries to collaboratively train a model using the diverse data stored on these devices, but without compromising the clients’ data privacy.

1.2. Big model and the need for communication reduction
While distributing the data across several workers certainly alleviates the per-client storage and compute bottlenecks, the training task is obviously not fully decomposed this way. Indeed, the 𝑛 clients still need to work together to train the

1

model, and working together means communication.
Since currently the most efﬁcient training mechanisms rely on gradient-type methods (Bottou, 2012; Kingma & Ba, 2014; Gorbunov et al., 2021), and since these operate by iteratively updating all the 𝑑 parameters describing the model, relying on big models leads to the need to communicate large-dimensional gradient vectors, which is expensive. For this reason, modern distributed methods need to rely on mechanisms that alleviate this communication burden.
Several orthogonal algorithmic approaches have been proposed in the literature to tackle this issue. One strain of methods, particularly popular in FL, is based on richer local training (e.g., LocalSGD), which typically means going beyond a single local gradient step before communication/aggregation across the workers is performed. This strategy is based on the hope that richer local training will ultimately lead to a dramatic reduction in the number of communication rounds without increasing the local computation time by much (Stich, 2020; Khaled et al., 2020; Woodworth et al., 2020). Another notable strain of methods is based on communication compression (e.g., QSGD), which means applying a lossy transformation to the communicated gradient information. This strategy is based on the hope that communication compression will lead to a dramatic reduction in the communication time within each round without affecting the number of communication rounds by much (Khirirat et al., 2018; Alistarh et al., 2018; Mishchenko et al., 2019; Li et al., 2020; Li & Richta´rik, 2020; Li & Richta´rik, 2021).
1.3. Gradient descent with compressed communication
In this work we focus on algorithms based on the latter line of work: communication compression.
Perhaps conceptually the simplest yet versatile gradientbased method for solving the distributed problem (1) employing communication compression is distributed compressed gradient descent (DCGD) (Khirirat et al., 2018). Given a sequence {𝛾𝑡} of learning rates, DCGD performs the iterations
𝑛
𝑥𝑡+1 = 𝑥𝑡 − 𝛾𝑡 𝑛1 ∑︀ 𝑔𝑖𝑡, 𝑔𝑖𝑡 = ℳ𝑡𝑖(∇𝑓𝑖(𝑥𝑡)). (2)
𝑖=1
Above, ℳ𝑡𝑖 represents any suitable gradient communication mechanism1 for mapping the possibly dense, highdimensional, and hence hard-to-communicate gradient ∇𝑓𝑖(𝑥𝑡) ∈ R𝑑 into a vector of equal dimension, but one that can hopefully be communicated using much fewer bits.
1We do not borrow the phrase “communication mechanisms” from any prior literature. We coined this phrase in order to be able to refer to a potentially arbitrary mechanism for transforming a 𝑑-dimensional gradient vector into another 𝑑dimensional vector that is easier to communicate. This allows us to step back, and critically reassess the methodological foundations of the ﬁeld in terms of the mathematical properties one should impart on such mechanisms for them to be effective.

2. Motivation and Background
Our work is motivated by several methodological, theoretical and algorithmic issues and open problems arising in the literature related to two orthogonal approaches to designing gradient communication mechanisms ℳ𝑡𝑖:

i) contractive compressors (Karimireddy et al., 2019; Stich et al., 2018; Alistarh et al., 2018; Koloskova et al., 2020; Beznosikov et al., 2020), and
ii) lazy aggregation (Chen et al., 2018; Sun et al., 2019; Ghadikolaei et al., 2021).

The motivation for our work starts with several critical observations related to these two mechanisms.

2.1. Contractive compression operators
Arguably, the simplest class of communication mechanisms is based on the (as we shall see, naive) application of contractive compression operators (or, contractive compressors for short) (Koloskova et al., 2020; Beznosikov et al., 2020). In this approach, one sets

ℳ𝑡𝑖(𝑥) ≡ 𝒞(𝑥),

(3)

where 𝒞 : R𝑑 → R𝑑 is a (possibly randomized) mapping with the property

E

[︁ ‖𝒞(𝑥)

−

𝑥‖2]︁

≤

(1

−

𝛼)

‖𝑥‖2

,

∀𝑥 ∈ R𝑑,

(4)

where 0 < 𝛼 ≤ 1 is the contraction parameter, and the expectation E [·] is taken w.r.t. the randomness inherent in 𝒞. For examples of contractive compressors (e.g., Top-𝐾 and Rand-𝐾 sparsiﬁers), please refer to Section A, and Table 1 in (Safaryan et al., 2021b; Beznosikov et al., 2020).
The algorithmic literature on contractive compressors (i.e., mappings 𝒞 satisfying (4)) is relatively much more developed, and dates back to at least 2014 with the work of Seide et al. (2014), who proposed the error feedback (EF) mechanism for ﬁxing certain divergence issues which arise empirically with the naive approach based on (3).
Despite several advances in our theoretical understanding of EF over the last few years (Stich et al., 2018; Karimireddy et al., 2019; Horva´th & Richta´rik, 2021; Tang et al., 2020; Gorbunov et al., 2020), a satisfactory grasp of EF remained elusive. Recently, Richta´rik et al. (2021) proposed EF21, which is a new algorithmic and analysis approach to error feedback, effectively ﬁxing the previous weaknesses. In particular, while previous results offered weak 𝒪(1/𝑇 2/3) rates (for smooth nonconvex problems), and did so under strong and often unrealistic assumptions (e.g., boundedness

2

Table 1 Summary of the methods ﬁtting our general 3PC framework. For each method we give the formula for the 3PC
compressor 𝒞ℎ,𝑦(𝑥), its parameters 𝐴, 𝐵, and the ratio 𝐵/𝐴 appearing in the convergence rate. Notation: 𝛼 = parameter of the contractive compressor 𝒞, 𝜔 = parameter of the unbiased compressor 𝒬, 𝐴1, 𝐵1 = parameters of three points compressor 𝒞ℎ1,𝑦(𝑥), 𝛼¯ = 1 − (1 − 𝛼1)(1 − 𝛼2), where 𝛼1, 𝛼2 are the parameters of the contractive compressors 𝒞1, 𝒞2, respectively.

Variant of 3PC (Alg. 1) EF21
(Richta´rik et al., 2021)
LAG (Chen et al., 2018) (3)
CLAG (NEW)
3PCv1 (NEW) 3PCv2 (NEW) 3PCv3 (NEW) 3PCv4 (NEW) 3PCv5 (NEW)

Alg. # Alg. 2 Alg. 3
Alg. 4 Alg. 5 Alg. 6 Alg. 7 Alg. 8 Alg. 9

𝒞ℎ,𝑦 (𝑥) =

ℎ + 𝒞(𝑥 − ℎ)

{︃ 𝑥, if (*),

ℎ, otherwise,

(*) means ‖𝑥 − ℎ‖2 > 𝜁‖𝑥 − 𝑦‖2
{︃ ℎ + 𝒞(𝑥 − ℎ), if (*),

ℎ,

otherwise,

(*) means ‖𝑥 − ℎ‖2 > 𝜁‖𝑥 − 𝑦‖2

𝑦 + 𝒞(𝑥 − 𝑦)(1)

𝑏 + 𝒞 (𝑥 − 𝑏), where 𝑏 = ℎ + 𝒬(𝑥 − 𝑦)

𝑏 + 𝒞 (𝑥 − 𝑏),

where 𝑏 = 𝒞ℎ1,𝑦 (𝑥)

𝑏 + 𝒞1 (𝑥 − 𝑏),

where 𝑏 = ℎ + 𝒞2(𝑥 − ℎ)

{︃

𝑥,

w.p. 𝑝

ℎ + 𝒞(𝑥 − 𝑦), w.p. 1 − 𝑝

𝐴 √ 1− 1−𝛼
1

𝐵
1√−𝛼 1− 1−𝛼
𝜁

𝐵 𝐴
(︁ 1−𝛼 )︁ 𝒪 𝛼2
𝒪 (𝜁)

√ 1− 1−𝛼

{︁

}︁

1√−𝛼 ,𝜁

max 1− 1−𝛼

(︁ {︁

}︁)︁

𝒪 max

1𝛼−2𝛼 ,

𝜁 𝛼

1 𝛼
1 − (1 − 𝛼)(1 − 𝐴1) √
1 − 1 − 𝛼¯ √
1− 1−𝑝

1−𝛼 (1 − 𝛼)𝜔 (1 − 𝛼)𝐵1
1√−𝛼¯ 1− 1−𝛼¯ (1−𝑝√)(1−𝛼) 1− 1−𝑝

1−𝛼
(1−𝛼)𝜔 𝛼
(1−𝛼)𝐵1 1−(1−𝛼)(1−𝐴1 )
(︁ 1−𝛼¯ )︁ 𝒪 𝛼¯2
𝒪 (︁ (1−𝑝𝑝)(21−𝛼) )︁

MARINA (Gorbunov et al., 2021)

Alg. 10

N/A(2)

𝑝 (1−𝑛𝑝)𝜔 (1−𝑛𝑝𝑝)𝜔

(1) 3PCv1 requires communication of uncompressed vectors (∇𝑓𝑖(𝑥𝑡)). Therefore, the method is impractical. We include it as an idealized version of EF21. (2) MARINA does not ﬁt the deﬁnition of three points compressor from (6). However, it satisﬁes (16) with 𝐺𝑡 = ‖𝑔𝑡 − ∇𝑓 (𝑥𝑡)‖2 and shown parameters 𝐴 and 𝐵, i.e., MARINA

can be analyzed via our theoretical framework. (3) LAG presented in our work is a (massively) simpliﬁed version of LAG considered by (Chen et al., 2018). However, we have decided to use the same name.

of the gradients), the EF21 approach offers GD-like 𝒪(1/𝑇 ) rates, with standard assumptions only.2
The heart of the EF21 method is a new communication mechanism ℳ𝑡𝑖, generated from a contractive compressor 𝒞, which ﬁxes (in a theoretically and practically superior way to the standard ﬁx offered by classical EF) the above mentioned divergence issues. Their construction is synthetic: is starts with the choice of 𝒞 preferred by the user, and then constructs a new and adaptive communication mechanism based on it. We will describe this method in Section 4.
2.2. Lazy aggregation
An orthogonal approach to applying contractive operators, whether with or without error feedback, is “skipping” communication. The basic idea of the lazy aggregation communication mechanism is for each worker 𝑖 to communicate its local gradient only if it differs “signiﬁcantly” from the last gradient communicated before.
In its simplest form, the LAG method of Chen et al. (2018) is initialized with 𝑔𝑖0 = ∇𝑓𝑖(𝑥0) for all 𝑖 ∈ [𝑛], which means that all the workers communicate their gradients at the start. In all subsequent iterations, each worker 𝑖 ∈ [𝑛] deﬁnes 𝑔𝑖𝑡+1, which may be interpreted as a “compressed” version of the true gradient ∇𝑓𝑖(𝑥𝑡+1), via the lazy aggregation rule
2The EF21 method was extended by Fatkhullin et al. (2021) to deal with stochastic gradients, variance reduction, regularizers, momentum, server compression, and partial participation. However, such extensions are not the subject of our work.

{︃

𝑡+1

∇𝑓𝑖(𝑥𝑡+1)

𝑔𝑖 = 𝑔𝑖𝑡

if ‖𝑔𝑖𝑡 − ∇𝑓𝑖(𝑥𝑡+1)‖2 > 𝜁𝐷𝑖𝑡, otherwise,

(5)

where 𝐷𝑖𝑡 := ‖∇𝑓𝑖(𝑥𝑡+1) − ∇𝑓𝑖(𝑥𝑡)‖2 and 𝜁 > 0 is the trigger.3 The smaller the trigger 𝜁, the more likely it is for

the condition ‖𝑔𝑖𝑡 − ∇𝑓𝑖(𝑥𝑡+1)‖2 > 𝜁𝐷𝑖𝑡, which triggers communication, to be satisﬁed. On the other hand, if 𝜁 is

very large, most iterations will skip communication and thus

reuse the past gradient. Since the trigger ﬁres dynamically

based on conditions that change in time, it is hard to theoret-

ically estimate how often communication skipping occurs.

In fact, there are no results on this in the literature. Nev-

ertheless, the lazy aggregation mechanism is empirically

useful when compared to vanilla GD (Chen et al., 2018).

Lazy aggregation is a much less studied and a much less understood communication mechanism than contractive compressors. Indeed, only a handful of papers offer any convergence guarantees (Chen et al., 2018; Sun et al., 2019; Ghadikolaei et al., 2021), and the results presented in the ﬁrst two of these papers are hard to penetrate. For example, no simple proof exists for the simple LAG variant presented above. The best known rate in the smooth nonconvex regime is 𝒪(1/𝑇 2/3), which differs from the 𝒪(1/𝑇 ) rate of GD.

3It is possible to replace 𝐷𝑖𝑡 by 𝑋𝑖𝑡 = 𝜁𝐿2𝑖 ‖𝑥𝑡+1 − 𝑥𝑡‖2, and our theory
will still trivially hold. This is the choice for the trigger condition made by Chen et al. (2018). One can also work with the more general choice 𝑋𝑖𝑡 = 𝜁𝑖‖𝑥𝑡+1 − 𝑥𝑡‖2;
our theory can be adapted to this trivially.

3

Table 2 Comparison of exisiting and proposed theoretically-supported methods employing lazy aggregation. In the rates for

{︁

}︁

√︀

√︀

our methods, 𝑀1 = 𝐿− + 𝐿+ 𝐵/𝐴 and 𝑀2 = max 𝐿− + 𝐿+ 2𝐵/𝐴, 𝐴/2𝜇 .

Method

Simple method?

Uses a contractive compressor 𝒞?

Strongly convex rate

PŁ nonconvex rate General nonconvex rate

LAG (Chen et al., 2018)



LAQ (Sun et al., 2019)



LENA (Ghadikolaei et al., 2021) (7)

(4)

LAG (NEW, 2022)



CLAG (NEW, 2022)





linear (9)





(1)

linear (3)





(8)

𝒪(𝐺4/𝑇 2𝜇2) (5), (6) 𝒪(𝐺4/𝑇 2𝜇2) (5), (6) 𝒪(𝐺4/3/𝑇 2/3) (6)



𝒪(exp(−𝑇 𝜇/𝑀2)) 𝒪(exp(−𝑇 𝜇/𝑀2))

𝒪(𝑀1/𝑇 )

(2)

𝒪(exp(−𝑇 𝜇/𝑀2)) 𝒪(exp(−𝑇 𝜇/𝑀2))

𝒪(𝑀1/𝑇 )

(1) They consider a speciﬁc form of quantization only. (2) Works with any contractive compressor, including low rank approximation, Top-𝐾, Rand-𝐾, quantization, and more. (3) Their Theorem 1 does not present any explicit linear rate. (4) LENA employs the classical EF mechanism, but it is not clear what is this mechanism supposed to do. (5) They consider an assumption (𝜇-quasi-strong convexity) that is slightly stronger than our PŁ assumption. Both are weaker than strong convexity. (6) They assume the local gradients to be bounded by 𝐺 (‖∇𝑓𝑖(𝑥)‖ ≤ 𝐺 for all 𝑥). We do not need such a strong assumption.
(7) They also consider the 0-quasi-strong convex case (slight generalization of convexity); we do not consider the convex case. Moreover, they consider the stochastic
case as well, we do not. We specialized all their results to the deterministic (i.e., full gradient) case for the purposes of this table. (8) Their contractive compressor depends on the trigger. (9) It is possible to specialize their method and proof so as to recover LAG as presented in our work, and to recover a rate similar to ours.

The known rates in the strongly convex regime are also highly problematic: they are either not explicit (Chen et al., 2018; Sun et al., 2019), or sublinear (Ghadikolaei et al., 2021). Furthermore, it is not clear whether an EF mechanism is needed to stabilize lazy aggregation methods, which is a necessity in the case of contractive compressors. While Ghadikolaei et al. (2021) proposed a combination of LAG and EF, their analysis leads to weak rates (see Table 2), and does not seem to point to theoretical advantages due to EF.
3. Summary of Contributions
We now summarize our main contributions:
∙ Uniﬁcation through the 3PC method. At present, the two communication mechanisms outlined above, contractive compressors and lazy aggregation, are viewed as different approaches to the same problem—reducing the communication overhead in distributed gradient-type methods— requiring different tools, and facing different theoretical challenges. We propose a uniﬁed method—which we call 3PC (Algorithm 1)—which includes EF21 (Algorithm 2) and LAG (Algorithm 3) as special cases.
∙ Several new methods. The 3PC method is much more general than either EF21 or LAG, and includes a number of new speciﬁc methods. For example, we propose CLAG, which is a combination of EF21 and LAG beneﬁting from both contractive compressors and lazy aggregation. We show experimentally that CLAG can be better than both EF21 and LAG: that is, we obtain combined beneﬁts of both approaches. We obtain a number of other new methods, such as 3PCv2, 3PCv3 and 3PCv4. We show experimentally that 3PCv2 can outperform EF21. See Table 1 for a summary of the proposed methods.
∙ Three point compressors. Our proposed method, 3PC, can be viewed as DCGD with a new class of communication

mechanisms, based on the new notion of a three point compressor (3PC)4; see Section 4 for details. By design, and in contrast to contractive compressors, our communication mechanism based on the 3PC compressor is able to “evolve” and thus improve throughout the iterations. In particular, its compression error decays, which is the key reason behind its superior theoretical properties. In summary, the properties deﬁning the 3PC compressor distill the important characteristics of a theoretically well performing communication mechanism, and this is the ﬁrst time such characteristics have been explicitly identiﬁed and formalized.
The observation that lazy aggregation is a 3PC compressor explains why error feedback is not needed to stabilize LAG and similar methods.
∙ Strong rates. We prove an 𝒪(1/𝑇 ) rate for 3PC for smooth nonconvex problems, which up to constants matches the rate of GD. Furthermore, we prove a GD-like linear convergence rate under the Polyak-Łojasiewicz condition. Our general theory recovers the EF21 rates proved by Richta´rik et al. (2021) exactly. Our rates for lazily aggregated methods (LAG and CLAG) are new, and better than the results obtained by Chen et al. (2018); Sun et al. (2019) and Ghadikolaei et al. (2021) in all regimes considered. In the general smooth nonconvex regime, only Ghadikolaei et al. (2021) obtain rates. However, they require strong assumptions (gradients bounded by a constant 𝐺), and their rate is 𝒪(𝐺4/3/𝑇 2/3), whereas we do not need such assumptions and obtain the GD-like rate 𝒪(𝑀1/𝑇 ). In the strongly convex regime, Chen et al. (2018) and Sun et al. (2019) obtain non-speciﬁc linear rates, while Ghadikolaei et al. (2021) obtain the sublinear rate 𝒪(𝐺4/𝑇 2𝜇2). In contrast, we obtain explicit GD-like linear rates under the weaker PŁ condition.
Furthermore, our variant of LAG, and our convergence theory and proofs, are much simpler than those presented in
4We use the same name for the method and the compressor on purpose.

4

(Chen et al., 2018). In fact, it is not clear to us whether the many additional features employed by Chen et al. (2018) have any theoretical or practical beneﬁts. We believe that our simple treatment can be useful for other researchers to further advance the ﬁeld.
For a detailed comparison of rates, please refer to Table 2.

4. Three Point Compressors

We now formally introduce the concept of a three point compressor (3PC).
Deﬁnition 4.1 (Three point compressor). We say that a (possibly randomized) map

𝒞ℎ,𝑦(𝑥) : R𝑑 × R𝑑 × R𝑑 → R𝑑

⏟⏞ ⏟⏞ ⏟⏞

ℎ∈

𝑦∈

𝑥∈

is a three point compressor (3PC) if there exist constants
0 < 𝐴 ≤ 1 and 𝐵 ≥ 0 such that the following relation holds for all 𝑥, 𝑦, ℎ ∈ R𝑑

E

[︁ ‖𝒞ℎ,𝑦

(𝑥)

−

𝑥‖2

]︁

≤

(1 − 𝐴) ‖ℎ − 𝑦‖2

+𝐵 ‖𝑥 − 𝑦‖2 . (6)

The vectors 𝑦 ∈ R𝑑 and ℎ ∈ R𝑑 are parameters deﬁning the compressor. Once ﬁxed, 𝒞ℎ,𝑦 : R𝑑 → R𝑑 is the compression mapping used to compress vector 𝑥 ∈ R𝑑.

4.1. Connection with contractive compressors

Note that if we set ℎ = 0 and 𝑦 = 𝑥, then inequality (6) specializes to

E

[︁ ‖𝒞0,𝑥

(𝑥)

−

𝑥‖2

]︁

≤

(1 − 𝐴) ‖𝑥‖2 ,

(7)

which is the inequality deﬁning a contractive compressor. In other words, a particular restriction of the parameters of any 3PC compressor is necessarily a contractive compressor.
However, this is not the restriction we will use to design our compression mechanism. Instead, as we shall describe next, we will choose the sequence of vectors ℎ and 𝑦 in an adaptive fashion, based on the path generated by DCGD.

4.2. Designing a communication mechanism using a 3PC compressor
We now describe our proposal for how to use a 3PC compressor to design a good communication mechanism {ℳ𝑘𝑖 } to be used within DCGD. Recall from (2) that all we need to do is to deﬁne the mapping
ℳ𝑡𝑖 : ∇𝑓𝑖(𝑥𝑡) ↦→ 𝑔𝑖𝑡.
First, we allow the initial compressed gradients {𝑔𝑖0}𝑛𝑖=1 to be chosen arbitrarily. Here are some examples of possible

choices: a) Full gradients: 𝑔𝑖0 = ∇𝑓𝑖(𝑥0) for all 𝑖 ∈ [𝑛]. The beneﬁt of this choice is that no information is loss
at the start of the process. On the other hand, the full 𝑑-
dimensional gradients need to be sent by the workers to
the server, which is potentially an expensive pre-processing step. b) Compressed gradients: 𝑔𝑖0 = 𝒞(∇𝑓𝑖(𝑥0)) for all 𝑖 ∈ [𝑛], where 𝒞 is an arbitrary compression mapping (e.g.,
a contractive compressor). While some information is lost
right at the start of the process (compared to a GD step),
the beneﬁt of this choice is that no full dimensional vectors need to be communicated. c) Zero preprocessing: 𝑔𝑖0 = 0 for all 𝑖 ∈ [𝑛].

Having

chosen

𝑔𝑖0

,

.

.

.

,

𝑔

0 𝑖

for

all

𝑖

∈

[𝑛],

it

remains

to

deﬁne the communication mechanism ℳ𝑡𝑖 for 𝑡 ≥ 1. We

will do this on-the-ﬂy as DCGD is run, with the help of the

parameters ℎ and 𝑦, which we choose adaptively. Consider

the viewpoint of a worker 𝑖 ∈ [𝑛] in iteration 𝑡 + 1, with 𝑡 ≥

0. In this iteration, worker 𝑖 wishes to compress the vector

𝑥 = ∇𝑓𝑖(𝑥𝑡+1). Let 𝑔𝑖𝑡 denote the compressed version of the vector ∇𝑓𝑖(𝑥𝑡), i.e., 𝑔𝑖𝑡 = ℳ𝑡𝑖(∇𝑓𝑖(𝑥𝑡)). We choose

𝑦 = ∇𝑓𝑖(𝑥𝑡) and ℎ = 𝑔𝑖𝑡.

With these parameter choices, we deﬁne the compressed version of 𝑥 = ∇𝑓𝑖(𝑥𝑡+1) by setting

ℳ𝑡𝑖+1(∇𝑓𝑖(𝑥𝑡+1)) (=2) 𝑔𝑖𝑡+1 := 𝒞𝑔𝑖𝑡,∇𝑓𝑖(𝑥𝑡)(∇𝑓𝑖(𝑥𝑡+1)). (8)
Our porposed 3PC method (Algorithm 1) is just DCGD with the compression mechanism described above.

4.3. The 3PC inequality

For the parameter choices made above, (6) specializes to

E [︀𝐸𝑖𝑡+1 | 𝑥𝑡, 𝑔𝑖𝑡]︀ ≤ (1 − 𝐴)𝐸𝑖𝑡 + 𝐵𝐷𝑖𝑡,

(9)

where

𝐸𝑖𝑡 := ⃦⃦𝑔𝑖𝑡 − ∇𝑓𝑖(𝑥𝑡)⃦⃦2

and 𝐷𝑖𝑡 := ⃦⃦∇𝑓𝑖(𝑥𝑡+1) − ∇𝑓𝑖(𝑥𝑡)⃦⃦2 .

This inequality has a natural interpretation. It enforces the compression error 𝐸𝑖𝑡 to shrink by the factor of 1 − 𝐴 in each communication round, subject to an additive penalty proportional to 𝐷𝑖𝑡. If the iterates converge, then the penalty will eventually vanish as well provided that the gradient
of 𝑓𝑖 is continuous. Intuitively speaking, this forces the compression error 𝐸𝑡 to improve in time.

We note that applying a simple contractive compressor in place of ℳ𝑡𝑖 does not have this favorable property, and this is what causes the convergence issues in existing literature
on this topic. This is what the EF literature was trying to
solve since 2014, and what the EF21 mechanism resolved

5

Algorithm 1 3PC (DCGD method using the 3PC communication mechanism)

1: Input: starting point 𝑥0 ∈ R𝑑 (on all workers), stepsize 𝛾 > 0, number of iterations 𝑇 , starting vectors 𝑔𝑖0 ∈ R𝑑 for

𝑖 ∈ [𝑛] (known to the server and all workers)

2:

Initialization: 𝑔0

=

1 𝑛

∑︀𝑛
𝑖=1

𝑔𝑖0

3: for 𝑡 = 0, 1, . . . , 𝑇 − 1 do

(Server aggregates initial gradient estimates)

4: Broadcast 𝑔𝑡 to all workers

5: for 𝑖 = 1, . . . , 𝑛 in parallel do

6:

𝑥𝑡+1 = 𝑥𝑡 − 𝛾𝑔𝑡

7:

Set 𝑔𝑖𝑡+1 = ℳ𝑡𝑖+1(∇𝑓𝑖(𝑥𝑡+1)) := 𝒞𝑔𝑡,∇𝑓𝑖(𝑥𝑡)(∇𝑓𝑖(𝑥𝑡+1))

𝑖

8:

Communicate 𝑔𝑖𝑡+1 to the server

9: end for

10:

Server

aggregates

received

messages:

𝑔𝑡+1

=

1 𝑛

∑︀𝑛
𝑖=1

𝑔𝑖𝑡+1

11: end for

12: Return: 𝑥ˆ𝑇 chosen uniformly at random from {𝑥𝑡}𝑇𝑡=−01

(Take a gradient-type step) (Apply 3PC to compress the latest gradient)

in 2021. However, no such progress happened in the lazy aggregation literature yet, and one of the key contributions of our work is to remedy this situation.

Lemma 4.3. The mapping (11) satisﬁes (6) with 𝐴 := 1 − (1 − 𝛼)(1 + 𝑠) and 𝐵 := max {︀(1 − 𝛼) (︀1 + 𝑠−1)︀ , 𝜁}︀,
where 𝑠 > 0 is any scalar satisfying (1 − 𝛼) (1 + 𝑠) < 1.

4.4. EF21 mechanism is a 3PC compressor

We will now show that the compression mechanism ℳ𝑡𝑖 employed in EF21 comes from a 3PC compressor. Let 𝒞 : R𝑑 → R𝑑 be a contractive compressor with contraction
parameter 𝛼, and deﬁne

𝒞ℎ,𝑦(𝑥) := ℎ + 𝒞(𝑥 − ℎ).

(10)

If we use this mapping to deﬁne a compression mechanism ℳ𝑡𝑖 via (8), use this within DCGD, we obtain the EF21 method of Richta´rik et al. (2021). Indeed, observe that
Algorithm 2 (EF21) is a special case of Algorithm 1 (3PC).

The next lemma shows that (10) is a 3PC compressor.
Lemma 4.2. The mapping (10) satisﬁes (6) with 𝐴 := 1 − (1 − 𝛼)(1 + 𝑠) and 𝐵 := (1 − 𝛼) (︀1 + 𝑠−1)︀, where 𝑠 > 0 is any scalar satisfying (1 − 𝛼) (1 + 𝑠) < 1.

The LAG method is obtained as a special case of CLAG by choosing 𝒞 to be the identity mapping (for which 𝛼 = 1).
4.6. Further 3PC compressors and methods
In Table 1 we summarize several further 3PC compressors and the new algorithms they lead to (e.g., 3PCv1–3PCv5). The details are given the in the appendix.

5. Theory

We are now ready to present our theoretical convergence results for the 3PC method (Algorithm 1), the main steps of which are

𝑛

𝑥𝑡+1 = 𝑥𝑡 − 𝛾𝑔𝑡,

𝑔𝑡

=

1 𝑛

∑︀

𝑔𝑖𝑡,

(12)

𝑖=1

4.5. LAG mechanism is a 3PC compressor

𝑔𝑖𝑡+1 = 𝒞𝑔𝑡,∇𝑓𝑖(𝑥𝑡)(∇𝑓𝑖(𝑥𝑡+1)). 𝑖

(13)

We will now show that the compression mechanism ℳ𝑡𝑖 employed in LAG comes from a 3PC compressor. In fact,
let us deﬁne CLAG, and recover LAG from it as a special case. Let 𝒞 : R𝑑 → R𝑑 be a contractive compressor with contraction parameter 𝛼. Choose a trigger 𝜁 > 0, and deﬁne

{︃

ℎ + 𝒞(𝑥 − ℎ), if ‖𝑥 − ℎ‖2 > 𝜁‖𝑥 − 𝑦‖2,

𝒞ℎ,𝑦(𝑥) :=

(11)

ℎ,

otherwise,

If we use this mapping to deﬁne a compression mechanism ℳ𝑡𝑖 via (8), use this within DCGD, we obtain our new CLAG method. Indeed, observe that Algorithm 4 (CLAG) is a
special case of Algorithm 1 (3PC).

Recall that the 3PC method is DCGD with a particular choice of the communication mechanism {ℳ𝑡𝑖} based on an arbitrary 3PC compressor 𝒞ℎ,𝑦(𝑥).
5.1. Assumptions
We rely on the following standard assumptions. Assumption 5.1. The functions 𝑓1, . . . ,𝑓𝑛 : R𝑑 → R are differentiable. Moreover, 𝑓 is lower bounded, i.e., there exists 𝑓 inf ∈ R such that 𝑓 (𝑥) ≥ 𝑓 inf for all 𝑥 ∈ R𝑑. Assumption 5.2. The function 𝑓 : R𝑑 → R is 𝐿−-smooth, i.e., it is differentibale and its gradient satisﬁes

The next lemma shows that (11) is a 3PC compressor.

‖∇𝑓 (𝑥) − ∇𝑓 (𝑦)‖ ≤ 𝐿−‖𝑥 − 𝑦‖ ∀𝑥,𝑦 ∈ R𝑑. (14)

6

Assumption 5.3. There is a constant 𝐿+ > 0 such

that

1 𝑛

∑︀𝑛
𝑖=1

‖∇𝑓𝑖

(𝑥)

−

∇𝑓𝑖

(𝑦)‖2

≤

𝐿2+ ‖𝑥 − 𝑦‖2

for

all

𝑥,𝑦 ∈ R𝑑. Let 𝐿+ be the smallest such number.

It is easy to see that 𝐿− ≤ 𝐿+. We borrow this notation for the smoothness constants from (Szlendak et al., 2021).

5.2. Convergence for general nonconvex functions

The following lemma is based on the properties of the 3PC compressor. It establishes the key inequality for the convergence analysis. The proof follows easily from the deﬁnition of a 3PC compressor and Assumption 5.3.
Lemma 5.4. Let Assumption 5.3 hold. Consider the 3PC method. Then, the sequence

𝐺𝑡 := 𝑛1 ∑𝑛︀ ‖𝑔𝑖𝑡 − ∇𝑓𝑖(𝑥𝑡)‖2 (15)
𝑖=1

for all 𝑡 ≥ 0 satisﬁes

E

[︀𝐺𝑡+1]︀

≤

(1

−

𝐴)E

[𝐺𝑡]

+

𝐵𝐿2+E

[︁ ⃦⃦𝑥𝑡+1

−

𝑥𝑡⃦⃦2]︁

.

(16)

Using this lemma and arguments from the analysis of SGD for non-convex problems (Li et al., 2021; Richta´rik et al., 2021), we derive the following result.
Theorem 5.5. Let Assumptions 5.1, 5.2, 5.3 hold. Assume that the stepsize 𝛾 of the 3PC method satisﬁes 0 ≤ 𝛾 ≤ 1/𝑀1,
√︀ where 𝑀1 = 𝐿− + 𝐿+ 𝐵/𝐴. Then, for any 𝑇 ≥ 1 we have
E [︁⃦⃦∇𝑓 (𝑥ˆ𝑇 )⃦⃦2]︁ ≤ 2𝛾Δ𝑇0 + E𝐴[𝐺𝑇0] , (17)
where 𝑥ˆ𝑇 is sampled uniformly at random from the points {𝑥0, 𝑥1, . . . , 𝑥𝑇 −1} produced by 3PC , ∆0 := 𝑓 (𝑥0)−𝑓 inf , and 𝐺0 is deﬁned in (15).

The theorem implies the following fact.
Corollary 5.6. Let the assumptions of Theorem 5.5 hold and choose the stepsize

𝛾=

1√ .

𝐿−+𝐿+ 𝐵/𝐴

Then for any 𝑇 ≥ 1 we have

(︁

√ )︁

E [︁⃦⃦∇𝑓 (𝑥ˆ𝑇 )⃦⃦2]︁ ≤ 2Δ0 𝐿−+𝑇𝐿+ 𝐵/𝐴 + E𝐴[𝐺𝑇0] .

That

is,

to

achieve

E

[︁ ⃦⃦∇𝑓 (𝑥ˆ𝑇

⃦2]︁ )⃦

≤

𝜀2

for

some

𝜀

>

0,

the 3PC method requires

(︁

√ )︁

(︂ Δ0 𝐿−+𝐿+ 𝐵/𝐴

E[𝐺0] )︂

𝑇 =𝒪

𝜀2

+ 𝐴𝜀2

(18)

iterations (=communication rounds).

5.3. Convergence under the PŁ condition
In this part we provide our main convergence result under the Polyak-Łojasiewicz (PŁ) condition. Assumption 5.7 (PŁ condition). Function 𝑓 : R𝑑 → R satisﬁes the Polyak-Łojasiewicz (PŁ) condition with parameter 𝜇 > 0, i.e.,

‖∇𝑓 (𝑥)‖2 ≥ 2𝜇 (𝑓 (𝑥) − 𝑓 *) , ∀𝑥 ∈ R𝑑, (19)

where 𝑥* := arg min𝑥∈R𝑑 𝑓 (𝑥) and 𝑓 * := 𝑓 (𝑥*).

In this setting, we get the following result.

Theorem 5.8. Let Assumptions 5.1, 5.2, 5.3, 5.7 hold. As-

sume that the stepsize 𝛾 of the 3PC method satisﬁes 0 ≤

{︁

}︁

√︀

𝛾 ≤ 1/𝑀2, where 𝑀2 = max 𝐿− + 𝐿+ 2𝐵/𝐴, 𝐴/2𝜇 .

Then, for any 𝑇 ≥ 0 and ∆0 := 𝑓 (𝑥0) − 𝑓 (𝑥*) we have

E [︀𝑓 (𝑥𝑇 )]︀ − 𝑓 * ≤ (1 − 𝛾𝜇)𝑇 (︀∆0 + 𝐴𝛾 E [︀𝐺0]︀)︀ . (20)

The theorem implies the following fact.
Corollary 5.9. Let the assumptions of Theorem 5.8 hold and choose the stepsize

{︂

}︂

𝛾 = min

1√ , 𝐴 .

𝐿−+𝐿+ 2𝐵/𝐴 2𝜇

Then to achieve E [︀𝑓 (𝑥𝑇 )]︀ − 𝑓 * ≤ 𝜀 for some 𝜀 > 0 the method requires

(︂ {︂

√

}︂

)︂

𝒪 max 𝐿−+𝐿+ 𝐵/𝐴 , 𝐴 log Δ0+E[𝐺0]𝛾/𝐴

𝜇

𝜀

(21)

iterations (=communication rounds).
5.4. Commentary
As mentioned in the contributions section, the above rates match those of GD in the considered regimes, up to constants factors, and at present constitute the new best-known rates for methods based on lazy aggregation. They recover the best known rates for error feedback since they match the rate of EF21.

6. Experiments
Now we empirically test the new variants of 3PC in two expriments. In the ﬁrst experiment, we focus on compressed lazy aggregation mechanism and study the behavior of CLAG (Algorithm 4) combined with Top-𝐾 compressor. In the second one, we compare 3PCv2 (Algorithm 6) to EF21 with Top-𝐾 on a practical task of learning a representation of MNIST dataset (LeCun et al., 2010).

7

|| f(xt)||2

101

Homogenity level: 1 3PCv2-PermK-TopK: 21

101

Hom3oPgCevn2it-PyelermveKl-:T0opK: 2 2 101

100

3PCv2-RandK-TopK: 21 3PCv2-TopK-TopK: 2 2

100

3PCv2-RandK-TopK: 21 3PCv2-TopK-TopK: 2 2

100

EF21-TopK: 2 3

EF21-TopK: 2 3

10 1

10 1

10 1

Split by labels 3PCv2-PermK-TopK: 2 2 3PCv2-RandK-TopK: 21 3PCv2-TopK-TopK: 2 2 EF21-TopK: 2 3

|| f(xt)||2 || f(xt)||2

10 2

10 2

10 2

10 3

10 3

10 3

0 10 #20Mbits /30n 40 50 0 10 #20Mbits /30n 40 50 0 10 #20Mbits /30n 40 50

Figure 1: Comparison of 3PCv2 with Perm-𝐾, Rand-𝐾 and Top-𝐾 as the ﬁrst compressor. Top-𝐾 is used as the second compressor. Number of clients 𝑛 = 100, compression level 𝐾 = 251. EF21 with Top-𝐾 is provided for the reference.

6.1. Is CLAG better than LAG and EF21?

Consider solving the non-convex logistic regression problem

[︃

]︃

min

𝑁

𝑑

𝑓 (𝑥) := 1 ∑︀ log(1 + 𝑒−𝑦𝑖𝑎⊤ 𝑖 𝑥) + 𝜆 ∑︀

𝑥2𝑗

,

𝑥∈R𝑑

𝑁 𝑖=1

𝑗=1 1+𝑥2𝑗

where 𝑎𝑖 ∈ R𝑑, 𝑦𝑖 ∈ {−1, 1} are the training data and labels, and 𝜆 > 0 is a regularization parameter, which is ﬁxed to 𝜆 = 0.1. We use four LIBSVM (Chang & Lin, 2011) datasets phishing, w6a, a9a, ijcnn1 as training data. Each dataset is shufﬂed and split into 𝑛 = 20 equal parts.

We vary two parameters of CLAG, 𝐾 and 𝜁, and report the number of bits (per worker) sent from clients to the server to achieve ‖∇𝑓 (𝑥𝑡)‖ < 10−2. For each pair (𝐾, 𝜁), we ﬁnetune the stepsize of CLAG with multiples (1, 21, 22, . . . , 211) of the theoretical stepsize. We report the results on a heatmap (see Figure 2) for the representative dataset ijcnn1. Other datasets are included in Appendix E. On the heatmap, we vary 𝜁 along rows and 𝐾 along columns. Notice that CLAG reduces to LAG when 𝐾 = 𝑑 (bottom row) and to EF21 when 𝜁 = 0 (left column).

The experiment shows that the minimum communication complexity is attained at a combination of (𝐾, 𝜁), which does not reduce CLAG to its special cases: EF21 or LAG. This empirically conﬁrms that CLAG has better communication complexity than EF21 and LAG. Additional experiments validating the performance of CLAG are reported in Appendix E

6.2. Other 3PC variants

We consider the objective

[︃

1

𝑁
∑︁

]︃
2

min

𝑓 (𝐷, 𝐸) :=

‖𝐷𝐸𝑎𝑖 − 𝑎𝑖‖ ,

𝐷∈R𝑑𝑓 ×𝑑𝑒 ,𝐸∈R𝑑𝑒×𝑑𝑓

𝑁 𝑖=1

where 𝑎𝑖 are ﬂattened represenations of images with 𝑑𝑓 = 784, 𝐷 and 𝐸 are learned parameters of the autoencoder

22 c1o7mpr1e2ssion8level3K 1

EF21

ijcnn1.bz2

3008 3872 3883 2867 4880 4872

15000

4544 3070 2691 2926 2216 3497

9152 2918 5888 7667 3724 3968

8500

6080 9267 7136 6368 4678 8038

4500

13216 6905 11176 6742 9979 6089

16896 7497 10313 9046 4892 5632 LAG 2500

0

2

8trigger 32 128 512

Figure 2: Heatmap of communication complexities of CLAG for different combination of compression levels 𝐾 and triggers 𝜁 with tuned stepsizes on ijcnn1 dataset. We contour cells corresponding to EF21 and LAG, as special cases of CLAG, by black rectangles. The red-contoured cell indicates the experiment with the smallest communication cost.

model. We ﬁx the encoding dimensions as 𝑑𝑒 = 16 and distribute the data samples across 𝑛 = 100 clients. In order to control the heterogenity of this distribution, we consider three cases. First, each client owns the same data (“homogeneity level: 1”). Second, the data is randomly split among client (“homogeneity level: 0”). Finally, we consider an extremely heterogeneous case, where the images are “split by labels”. 𝐾 is set to 𝑑/𝑛, where 𝑑 = 2 · 𝑑𝑓 · 𝑑𝑒 = 25088 is the total dimension of learning parameters 𝐷 and 𝐸. We apply three different sparsiﬁers (Top-𝐾, Rand-𝐾, Perm-𝐾) for the ﬁrst compressor of 3PCv2 (Algorithm 6) and ﬁx the second one as Top-𝐾.5 3PCv2 method communicates two sparse sequences at each communication round, while EF21 only one. To account for this, we select 𝐾1, 𝐾2 from the set {𝐾/2, 𝐾}, that is there are four possible choices for compression levels 𝐾1, 𝐾2 of two sparsiﬁers in 3PCv2. Then we select the pair which works best. We ﬁne-tune every method
5See Appendices A and E for the deﬁnitions and more detailed description.

8

with the stepsizes from the set {2−12, 2−11, . . . , 25} and select the best run based on the value of ‖∇𝑓 (𝑥𝑡)‖2 at the last iterate. The stepsize for each method is indicated in the legend of each plot.
Figure 1 demonstrates that 3PCv2 is competitive with the EF21 method and, in some cases, superior. The improvement is particularly prominent in the heterogeneous regime. Experiments with other variants, 3PCv1–3PCv5, including the experiments on a carefully designed syntetic quadratic problem, are reported in Appendix E.

References
Alistarh, D., Hoeﬂer, T., Johansson, M., Khirirat, S., Konstantinov, N., and Renggli, C. The convergence of sparsiﬁed gradient methods. In Advances in Neural Information Processing Systems (NeurIPS), 2018.

Beznosikov, A., Horva´th, S., Richta´rik, P., and Safaryan, M. On biased compression for distributed learning. arXiv preprint arXiv:2002.12410, 2020.

Bottou, L. Stochastic Gradient Descent Tricks, vol-

ume 7700 of Lecture Notes in Computer Science

(LNCS), pp. 430–445.

Springer, neural net-

works, tricks of the trade, reloaded edition, Jan-

uary 2012. URL https://www.microsoft.

com/en-[]us/research/publication/

stochastic-[]gradient-[]tricks/.

Chang, C.-C. and Lin, C.-J. LIBSVM: a library for support vector machines. ACM Transactions on Intelligent Systems and Technology (TIST), 2(3):1–27, 2011.

Chen, T., Giannakis, G., Sun, T., and Yin, W. LAG: Lazily aggregated gradient for communication-efﬁcient distributed learning. Advances in Neural Information Processing Systems, 2018.

Dean, J., Corrado, G., Monga, R., Chen, K., Devin, M., Mao, M., Senior, A., Tucker, P., Yang, K., Le, Q. V., and et al. Large scale distributed deep networks. In Advances in Neural Information Processing Systems, pp. 1223–1231, 2012.

Fatkhullin, I., Sokolov, I., Gorbunov, E., Li, Z., and Richta´rik, P. Ef21 with bells & whistles: practical algorithmic extensions of modern error feedback. arXiv preprint arXiv:2110.03294, 2021.

Ghadikolaei, H. S., Stich, S., and Jaggi, M. LENA: Communication-efﬁcient distributed learning with selftriggered gradient uploads. In International Conference on Artiﬁcial Intelligence and Statistics, pp. 3943–3951. PMLR, 2021.

Gorbunov, E., Kovalev, D., Makarenko, D., and Richta´rik, P. Linearly converging error compensated SGD. In 34th Conference on Neural Information Processing Systems (NeurIPS), 2020.
Gorbunov, E., Burlachenko, K. P., Li, Z., and Richta´rik, P. MARINA: Faster non-convex distributed learning with compression. In Meila, M. and Zhang, T. (eds.), Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pp. 3788–3798. PMLR, 18–24 Jul 2021. URL https://proceedings.mlr.press/ v139/gorbunov21a.html.
Horva´th, S. and Richta´rik, P. A better alternative to error feedback for communication-efﬁcient distributed learning. arXiv preprint arXiv:2006.11077, 2020.
Horva´th, S. and Richta´rik, P. A better alternative to error feedback for communication-efﬁcient distributed learning. In 9th International Conference on Learning Representations (ICLR), 2021.
Karimireddy, S. P., Rebjock, Q., Stich, S., and Jaggi, M. Error feedback ﬁxes SignSGD and other gradient compression schemes. In 36th International Conference on Machine Learning (ICML), 2019.
Khaled, A., Mishchenko, K., and Richta´rik, P. Tighter theory for local SGD on identical and heterogeneous data. In The 23rd International Conference on Artiﬁcial Intelligence and Statistics (AISTATS 2020), 2020.
Khirirat, S., Feyzmahdavian, H. R., and Johansson, M. Distributed learning with compressed gradients. arXiv preprint arXiv:1806.06573, 2018.
Kingma, D. P. and Ba, J. Adam: a method for stochastic optimization. In The 3rd International Conference on Learning Representations, 2014. URL https:// arxiv.org/pdf/1412.6980.pdf.
Koloskova, A., Lin, T., Stich, S., and Jaggi, M. Decentralized deep learning with arbitrary communication compression. In International Conference on Learning Representations (ICLR), 2020.
Konecˇny´, J., McMahan, H. B., Ramage, D., and Richta´rik, P. Federated optimization: distributed machine learning for on-device intelligence. arXiv:1610.02527, 2016a.
Konecˇny´, J., McMahan, H. B., Yu, F., Richta´rik, P., Suresh, A. T., and Bacon, D. Federated learning: strategies for improving communication efﬁciency. In NIPS Private Multi-Party Machine Learning Workshop, 2016b.
LeCun, Y., Cortes, C., and Burges, C. Mnist handwritten digit database. ATTLabs [Online], 2010. URL http: //yann.lecun.com/exdb/mnist.

9

Li, Z. and Richta´rik, P. A uniﬁed analysis of stochastic gradient methods for nonconvex federated optimization. arXiv preprint arXiv:2006.07013, 2020.
Li, Z. and Richta´rik, P. CANITA: Faster rates for distributed convex optimization with communication compression. In Advances in Neural Information Processing Systems, 2021. arXiv:2107.09461.
Li, Z., Kovalev, D., Qian, X., and Richta´rik, P. Acceleration for compressed gradient descent in distributed and federated optimization. In International Conference on Machine Learning (ICML), pp. 5895–5904. PMLR, 2020.
Li, Z., Bao, H., Zhang, X., and Richta´rik, P. PAGE: A simple and optimal probabilistic gradient estimator for nonconvex optimization. In International Conference on Machine Learning (ICML), pp. 6286–6295. PMLR, 2021.
Lin, Y., Han, S., Mao, H., Wang, Y., and Dally, B. Deep gradient compression: Reducing the communication bandwidth for distributed training. In International Conference on Learning Representations, 2018.
McMahan, B., Moore, E., Ramage, D., and Agu¨era y Arcas, B. Federated learning of deep networks using model averaging. arXiv preprint arXiv:1602.05629, 2016.
McMahan, H. B., Moore, E., Ramage, D., Hampson, S., and Agu¨era y Arcas, B. Communication-efﬁcient learning of deep networks from decentralized data. In Proceedings of the 20th International Conference on Artiﬁcial Intelligence and Statistics (AISTATS), 2017.
Mishchenko, K., Gorbunov, E., Taka´cˇ, M., and Richta´rik, P. Distributed learning with compressed gradient differences. arXiv preprint arXiv:1901.09269, 2019.
Nesterov, Y. et al. Lectures on convex optimization, volume 137. Springer, 2018.
Richta´rik, P., Sokolov, I., and Fatkhullin, I. EF21: A new, simpler, theoretically better, and practically faster error feedback. In Advances in Neural Information Processing Systems, 2021.
Safaryan, M., Islamov, R., Qian, X., and Richta´rik, P. FedNL: Making Newton-type methods applicable to federated learning. arXiv preprint arXiv:2106.02969, 2021a.
Safaryan, M., Shulgin, E., and Richta´rik, P. Uncertainty principle for communication compression in distributed and federated learning and the search for an optimal compressor. Information and Inference: A Journal of the IMA, 2021b.
Seide, F., Fu, H., Droppo, J., Li, G., and Yu, D. 1-bit stochastic gradient descent and its application to data-parallel

distributed training of speech DNNs. In Fifteenth Annual Conference of the International Speech Communication Association, 2014.
Stich, S. U. Local SGD converges fast and communicates little. In International Conference on Learning Representations, 2020.
Stich, S. U., Cordonnier, J.-B., and Jaggi, M. Sparsiﬁed SGD with memory. In Advances in Neural Information Processing Systems (NeurIPS), 2018.
Sun, J., Chen, T., Giannakis, G., and Yang, Z. Communication-efﬁcient distributed learning via lazily aggregated quantized gradients. Advances in Neural Information Processing Systems, 32:3370–3380, 2019.
Szlendak, R., Tyurin, A., and Richta´rik, P. Permutation compressors for provably faster distributed nonconvex optimization. arXiv preprint arXiv:2110.03300, 2021, 2021.
Tang, H., Lian, X., Yu, C., Zhang, T., and Liu, J. DoubleSqueeze: Parallel stochastic gradient descent with double-pass error-compensated compression. In Proceedings of the 36th International Conference on Machine Learning (ICML), 2020.
Woodworth, B., Patel, K. K., Stich, S. U., Dai, Z., Bullins, B., McMahan, H. B., Shamir, O., and Srebro, N. Is local SGD better than minibatch SGD? arXiv preprint arXiv:2002.07839, 2020.

10

APPENDIX

Table of Contents

1 Introduction

1

1.1 Big data and the need for distributed systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1

1.2 Big model and the need for communication reduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1

1.3 Gradient descent with compressed communication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2

2 Motivation and Background

2

2.1 Contractive compression operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2

2.2 Lazy aggregation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3

3 Summary of Contributions

4

4 Three Point Compressors

5

4.1 Connection with contractive compressors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5

4.2 Designing a communication mechanism using a 3PC compressor . . . . . . . . . . . . . . . . . . . . . . 5

4.3 The 3PC inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5

4.4 EF21 mechanism is a 3PC compressor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6

4.5 LAG mechanism is a 3PC compressor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6

4.6 Further 3PC compressors and methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6

5 Theory

6

5.1 Assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6

5.2 Convergence for general nonconvex functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7

5.3 Convergence under the PŁ condition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7

5.4 Commentary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7

6 Experiments

7

6.1 Is CLAG better than LAG and EF21? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8

6.2 Other 3PC variants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8

A Examples of Contractive Compressors

13

A.1 Top-𝐾 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

A.2 Rand-𝐾 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

A.3 cRand-𝐾 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

A.4 Perm-𝐾 and cPerm-𝐾 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

A.5 Unbiased compressors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

A.6 Further examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

B Proofs of The Main Results

14

B.1 Three Lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14

B.2 General Non-Convex Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14

B.3 PŁ Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15

C Three Point Compressor: Special Cases

17

C.1 Error Feedback 2021: EF21 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

C.2 LAG: Lazily Aggregated Gradient . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

C.3 CLAG: Compressed Lazily Aggregated Gradient (NEW) . . . . . . . . . . . . . . . . . . . . . . . . . . 21

11

C.4 3PCv1 (NEW) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 C.5 3PCv2 (NEW) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 C.6 3PCv3 (NEW) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 C.7 3PCv4 (NEW) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 C.8 3PCv5 (NEW) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31

D MARINA

34

E More Experiments

36

E.1 Learning autoencoder model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36

E.2 Solving synthetic quadratic problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39

E.3 Testing compressed lazy aggregation (CLAG) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48

12

A. Examples of Contractive Compressors
The simplest example of a contractive compressor is the identity mapping, 𝒞(𝑥) ≡ 𝑥, which satisﬁes (4) with 𝛼 = 1, and using which DCGD reduces to (distributed) gradient descent.

A.1. Top-𝐾
A typical non-trivial example of a contractive compressor is the Top-𝐾 sparsiﬁcation operator (Alistarh et al., 2018), which is a deterministic mapping characterized by a parameter 1 ≤ 𝐾 ≤ 𝑑 deﬁning the required level of sparsiﬁcation. The smaller this parameter is, the higher compression level is applied, and the smaller the contraction parameter 𝛼 becomes, which indicates that there is a larger error between the message 𝑥 we wanted to send, and the compressed message 𝒞(𝑥) we actually sent. In the extreme case 𝐾 = 𝑑, we have 𝒞(𝑥) = 𝑥, and the input vector is left intact, and hence uncompressed. In this case, 𝛼 = 1. If 𝐾 = 1, then all entries of 𝑥 are zeroed out, except for the largest entry in absolute value, breaking ties arbitrarily. This choice offers a 𝑑 : 1 compression ratio, which can be dramatic if 𝑑 is large, which is the case when working with big models. In this case, 𝛼 = 1/𝑑. The general choice of 𝐾 leaves just 𝐾 nonzero entries intact, those that are largest in absolute value (again, breaking ties arbitrarily), with the remaining 𝑑 − 𝐾 entries zeroed out. This offers a (𝑑 − 𝐾) : 1 compression ratio, with contraction factor 𝛼 = 𝐾/𝑑.

A.2. Rand-𝐾
One of the simplest randomized sparsiﬁcation operators is Rand-𝐾 (Khirirat et al., 2018). It is similar to Top-𝐾, with the exception that the 𝐾 entries that are retained are chosen uniformly at random rather than greedily. Just like in the case of Top-𝐾, the worst-case (expected) error produced by Rand-𝐾 is characterized by 𝛼 = 𝐾/𝑑. However, on inputs 𝑥 that are not worse-case, which naturally happens often throughout the training process, the empirical error of the greedy Top-𝐾 sparsiﬁer can be much smaller than that of its randomized cousin. This has been observed in practice, and this is one of the reasons why greedy compressors, such as Top-𝐾, are often preferred to their randomized counterparts.

A.3. cRand-𝐾

Contractive Rand-𝐾 operator applied to vector 𝑥 ∈ R𝑑 uniformly at random chooses 𝐾 entries out of 𝑑 but, unlike Rand-𝐾, does not scale the resulting vector. In this case, the resulting vector is no more unbiased but it still satisﬁes the deﬁnition of the contractive operator. Indeed, let 𝒮 be a set of indices of size 𝐾. Then,

[︃ 𝑑 ∑︁

]︃ 𝑑 ∑︁

𝑑 (︂ ∑︁

𝐾 )︂

(︂ 𝐾 )︂

[︀‖𝒞(𝑥) − 𝑥‖22]︀ = E

1𝑖∈/𝒮 𝑥2𝑖 = E [︀1𝑖∈/𝒮 𝑥2𝑖 ]︀ =

1−

𝑥2𝑖 = 1 −

‖𝑥‖22.

E

𝑑

𝑑

𝑖=1

𝑖=1

𝑖=1

A.4. Perm-𝐾 and cPerm-𝐾

Permutation compressor (Perm-𝐾) is described in (Szlendak et al., 2021) (case 𝑑 > 𝑛, Deﬁnition 2 in the original paper). Contractive permutation compressor (cPerm-𝐾) on top of Perm-𝐾 scales the resulting vector by factor 1+1𝜔 .

A.5. Unbiased compressors

Rand-𝐾, as deﬁned above, arises from a more general class of compressors, which we now present, by appropriate scaling.
Deﬁnition A.1 (Unbiased Compressor). We say that a randomized map 𝒬 : R𝑑 → R𝑑 is an unbiased compression operator, or simply just unbiased compressor, if there exists a constant 𝜔 ≥ 0 such that

E [𝒬(𝑥)] = 𝑥, E [︀‖𝒬(𝑥) − 𝑥‖2]︀ ≤ 𝜔‖𝑥‖2, ∀𝑥 ∈ R𝑑.

(22)

Its is well known and trivial to check that for any unbiased compressor 𝒬, the compressor 𝜔+1 1 𝒬 is contractive, with contraction parameter 𝛼 = 𝜔+1 1 . It is easy to see that the contractive Rand-𝐾 operator deﬁned above becomes unbiased once it is scaled by the factor 𝐾𝑑 .
A.6. Further examples
For further examples of contractive compressors (e.g., quantization-based, rank-based), we refer the reader to Beznosikov et al. (2020) and Safaryan et al. (2021b;a).

13

B. Proofs of The Main Results

B.1. Three Lemmas

We will rely on two lemmas, one from (Richta´rik et al., 2021), and one from (Li et al., 2021). The ﬁrst lemma will allow us to simplify the expression for the maximal allowable stepsize in our method (at the cost of being suboptimal by the factor of 2 at most), and the second forms an important step in our convergence proof. Lemma B.1 (Lemma 5 of (Richta´rik et al., 2021)). If 0 ≤ 𝛾 ≤ √𝑎1+𝑏 , then 𝑎𝛾2 + 𝑏𝛾 ≤ 1. Moreover, the bound is tight up
{︁ }︁ to the factor of 2 since √𝑎1+𝑏 ≤ min √1𝑎 , 1𝑏 ≤ √𝑎2+𝑏 .
Lemma B.2 (Lemma 2 of (Li et al., 2021)). Suppose that function 𝑓 is 𝐿−-smooth and let 𝑥𝑡+1 := 𝑥𝑡 − 𝛾𝑔𝑡, where 𝑔𝑡 ∈ R𝑑 is any vector, and 𝛾 > 0 is any scalar. Then we have

𝑓 (𝑥𝑡+1) ≤ 𝑓 (𝑥𝑡) − 𝛾 ⃦⃦∇𝑓 (𝑥𝑡)⃦⃦2 − (︂ 1 − 𝐿− )︂ ⃦⃦𝑥𝑡+1 − 𝑥𝑡⃦⃦2 + 𝛾 ⃦⃦𝑔𝑡 − ∇𝑓 (𝑥𝑡)⃦⃦2 . (23)

2

2𝛾 2

2

We now state and derive the main technical lemma.

Lemma B.3 (Lemma 5.4). Let Assumption 5.3 hold. Consider the method from (12)–(13). Then, for all 𝑡 ≥ 0 the sequence

𝑡 1 ∑𝑛︁ ⃦ 𝑡

𝑡 ⃦2

𝐺 := 𝑛

⃦𝑔𝑖 − ∇𝑓𝑖(𝑥 )⃦

(24)

𝑖=1

satisﬁes

E

[︀𝐺𝑡+1]︀

≤

(1

−

𝐴)E

[︀𝐺𝑡]︀

+

𝐵𝐿2+E

[︁ ⃦⃦𝑥𝑡+1

−

𝑥𝑡⃦⃦2]︁

.

(25)

Proof. By deﬁnition of 𝐺𝑡 and three points compressor we have

E [︀𝐺𝑡+1]︀

=
(13),(6)
≤
=

1

𝑛
∑︁

[︁ ⃦ 𝑡+1

𝑡+1 ⃦2]︁

𝑛 E ⃦𝑔𝑖 − ∇𝑓𝑖(𝑥 )⃦

𝑖=1

1 − 𝐴 ∑𝑛︁ [︁⃦ 𝑡

𝑡 ⃦2]︁ 𝐵 ∑𝑛︁ ⃦

𝑡+1

𝑡 ⃦2

𝑛

E ⃦𝑔𝑖 − ∇𝑓𝑖(𝑥 )⃦

+ 𝑛

⃦∇𝑓𝑖(𝑥 ) − ∇𝑓𝑖(𝑥 )⃦

𝑖=1

𝑖=1

𝐵

𝑛
∑︁

2

(1 − 𝐴)E [︀𝐺𝑡]︀ +

⃦ ⃦∇𝑓𝑖

(𝑥𝑡+1

)

−

∇𝑓𝑖

(𝑥𝑡

⃦ )⃦

.

𝑛 𝑖=1

Using

Assumption

5.3,

we

upper

bound

the

last

term

by

𝐵𝐿2+E

[︁ ⃦⃦𝑥𝑡+1

−

𝑥𝑡⃦⃦2]︁

and

get

the

result.

B.2. General Non-Convex Functions

Below we restate the main result for general non-convex functions and provide the full proof.

Theorem B.4 (Theorem 5.5). Let Assumptions 5.1, 5.2, 5.3 hold. Assume that the stepsize 𝛾 of the method from (12)–(13) √︀
satisﬁes 0 ≤ 𝛾 ≤ 1/𝑀, where 𝑀 = 𝐿− + 𝐿+ 𝐵/𝐴. Then, for any 𝑇 ≥ 0 we have

E [︁⃦⃦∇𝑓 (𝑥ˆ𝑇 )⃦⃦2]︁ ≤ 2∆0 + E [︀𝐺0]︀ , (26)

𝛾𝑇

𝐴𝑇

where 𝑥ˆ𝑇 is sampled uniformly at random from the points {𝑥0, 𝑥1, . . . , 𝑥𝑇 −1} produced by (12)–(13), ∆0 = 𝑓 (𝑥0) − 𝑓 inf , and 𝐺0 is deﬁned in (15).

Proof. Using Lemma B.2 and Jensen’s inequality applied of the squared norm, we get

(︂

)︂

⃦𝑛

⃦2

𝑓 (𝑥𝑡+1) (≤23) 𝑓 (𝑥𝑡) − 𝛾2 ⃦⃦∇𝑓 (𝑥𝑡)⃦⃦2 − 21𝛾 − 𝐿2− ⃦⃦𝑥𝑡+1 − 𝑥𝑡⃦⃦2 + 𝛾2 ⃦⃦⃦ 𝑛1 ∑︁ (︀𝑔𝑖𝑡 − ∇𝑓𝑖(𝑥𝑡))︀⃦⃦⃦

⃦ 𝑖=1

⃦

(≤15) 𝑓 (𝑥𝑡) − 𝛾 ⃦⃦∇𝑓 (𝑥𝑡)⃦⃦2 − (︂ 1 − 𝐿− )︂ ⃦⃦𝑥𝑡+1 − 𝑥𝑡⃦⃦2 + 𝛾 𝐺𝑡. (27)

2

2𝛾 2

2

14

Subtracting 𝑓 inf from both sides of (27) and taking expectation, we get

E [︀𝑓 (𝑥𝑡+1) − 𝑓 inf ]︀ ≤

E [︀𝑓 (𝑥𝑡) − 𝑓 inf ]︀ − 𝛾 E [︁⃦⃦∇𝑓 (𝑥𝑡)⃦⃦2]︁ 2

− (︂ 1 − 𝐿− )︂ E [︁⃦⃦𝑥𝑡+1 − 𝑥𝑡⃦⃦2]︁ + 𝛾 E [︀𝐺𝑡]︀ . (28)

2𝛾 2

2

Next, we add (28) to a 2𝛾𝐴 multiple of (16) and derive

E [︀𝑓 (𝑥𝑡+1) − 𝑓 inf ]︀ + 𝛾 E [︀𝐺𝑡+1]︀ ≤ E [︀𝑓 (𝑥𝑡) − 𝑓 inf ]︀ − 𝛾 E [︁⃦⃦∇𝑓 (𝑥𝑡)⃦⃦2]︁ − (︂ 1 − 𝐿− )︂ E [︁⃦⃦𝑥𝑡+1 − 𝑥𝑡⃦⃦2]︁

2𝐴

2

2𝛾 2

+ 𝛾2 E [︀𝐺𝑡]︀ + 2𝛾𝐴 (︁(1 − 𝐴)E [︀𝐺𝑡]︀ + 𝐵𝐿2+E [︁⃦⃦𝑥𝑡+1 − 𝑥𝑡⃦⃦2]︁)︁

= E [︀𝑓 (𝑥𝑡) − 𝑓 inf ]︀ + 𝛾 E [︀𝐺𝑡]︀ − 𝛾 E [︁⃦⃦∇𝑓 (𝑥𝑡)⃦⃦2]︁

2𝐴

2

− (︂ 1 − 𝐿− − 𝛾𝐵𝐿2+ )︂ E [︁⃦⃦𝑥𝑡+1 − 𝑥𝑡⃦⃦2]︁

2𝛾 2

2𝐴

≤ E [︀𝑓 (𝑥𝑡) − 𝑓 inf ]︀ + 𝛾 E [︀𝐺𝑡]︀ − 𝛾 E [︁⃦⃦∇𝑓 (𝑥𝑡)⃦⃦2]︁ ,

2𝐴

2

where the last inequality follows from the bound 𝛾2 𝐵𝐴𝐿2+ +𝐿−𝛾 ≤ 1, which holds because of Lemma B.1 and our assumption on the stepsize. Summing up inequalities for 𝑡 = 0, . . . , 𝑇 − 1, we get

0 ≤ E [︀𝑓 (𝑥𝑇 ) − 𝑓 inf ]︀ + 𝛾 E [︀𝐺𝑇 ]︀ ≤ E [︀𝑓 (𝑥0) − 𝑓 inf ]︀ + 𝛾 E [︀𝐺0]︀ − 𝛾 𝑇∑−︁1 E [︁⃦⃦∇𝑓 (𝑥𝑡)⃦⃦2]︁ .

2𝐴

2𝐴

2

𝑡=0

Multiplying both sides by 𝛾2𝑇 , after rearranging we obtain

𝑇∑−︁1 1 E [︁⃦⃦∇𝑓 (𝑥𝑡)⃦⃦2]︁ ≤ 2∆0 + E [︀𝐺0]︀ ,

𝑇

𝛾𝑇

𝐴𝑇

𝑡=0

where

∆0

=

𝑓 (𝑥0)

−

𝑓 inf .

It

remains

to

notice

that

the

left

hand

side

can

be

interpreted

as

E

[︁

⃦ ⃦∇

𝑓

(𝑥ˆ

𝑇

)⃦⃦2

]︁ ,

where

𝑥ˆ𝑇

is

chosen from 𝑥0, 𝑥1, . . . , 𝑥𝑇 −1 uniformly at random.

B.3. PŁ Functions

Below we restate the main result for PŁ functions and provide the full proof.

Theorem B.5 (Theorem 5.8). Let Assumptions 5.1, 5.2, 5.3, 5.7 hold. Assume that the stepsize 𝛾 of the method from (12)–

{︁

}︁

(13) satisﬁes 0 ≤ 𝛾 ≤ 1/𝑀, where 𝑀 = max

√︀ 𝐿− + 𝐿+ 2𝐵/𝐴, 𝐴/2𝜇

. Then, for any 𝑇 ≥ 0 and ∆0 = 𝑓 (𝑥0) − 𝑓 (𝑥*)

we have

E [︀𝑓 (𝑥𝑇 ) − 𝑓 (𝑥*)]︀

≤

(1 − 𝛾𝜇)𝑇

(︁ ∆0

+

𝛾

)︁ E [︀𝐺0]︀ .

(29)

𝐴

Proof. First of all, we notice that (28) holds in this case as well. Therefore, using PŁ condition we derive

(28)
E [︀𝑓 (𝑥𝑡+1) − 𝑓 inf ]︀ ≤

E [︀𝑓 (𝑥𝑡) − 𝑓 (𝑥*)]︀ − 𝛾 E [︁⃦⃦∇𝑓 (𝑥𝑡)⃦⃦2]︁ 2

− (︂ 1 − 𝐿− )︂ E [︁⃦⃦𝑥𝑡+1 − 𝑥𝑡⃦⃦2]︁ + 𝛾 E [︀𝐺𝑡]︀

2𝛾 2

2

(≤19) (1 − 𝛾𝜇)E [︀𝑓 (𝑥𝑡) − 𝑓 (𝑥*)]︀ − (︂ 1 − 𝐿− )︂ E [︁⃦⃦𝑥𝑡+1 − 𝑥𝑡⃦⃦2]︁ + 𝛾 E [︀𝐺𝑡]︀ . (30)

2𝛾 2

2

15

Next, we add (28) to a 𝐴𝛾 multiple of (16) and derive

E [︁𝑓 (𝑥𝑡+1) − 𝑓 (𝑥*) + 𝛾 𝐺𝑡+1]︁ ≤ (1 − 𝛾𝜇)E [︀𝑓 (𝑥𝑡) − 𝑓 (𝑥*)]︀ − (︂ 1 − 𝐿− )︂ E [︁⃦⃦𝑥𝑡+1 − 𝑥𝑡⃦⃦2]︁

𝐴

2𝛾 2

+ 𝛾2 E [︀𝐺𝑡]︀ + 𝐴𝛾 (︁(1 − 𝐴)E [︀𝐺𝑡]︀ + 𝐵𝐿2+E [︁⃦⃦𝑥𝑡+1 − 𝑥𝑡⃦⃦2]︁)︁

=

(1

−

𝛾𝜇)E [︀𝑓 (𝑥𝑡)

−

𝑓 (𝑥*)]︀

+

(︂ 1

−

𝐴 )︂

𝛾

E [︀𝐺𝑡]︀

2𝐴

− (︂ 1 − 𝐿− − 𝛾𝐵𝐿2+ )︂ E [︁⃦⃦𝑥𝑡+1 − 𝑥𝑡⃦⃦2]︁

2𝛾 2

𝐴

≤

[︁ (1 − 𝛾𝜇)E 𝑓 (𝑥𝑡) − 𝑓 (𝑥*) +

𝛾

]︁ 𝐺𝑡 ,

𝐴

where the last inequality follows from the bound 𝛾2 2𝐵𝐴𝐿2+ + 𝐿−𝛾 ≤ 1 and 1 − 𝐴/2 ≤ 1 − 𝛾𝜇, which holds because of our assumption on the stepsize and Lemma B.1. Unrolling the recurrence, we obtain

E [︀𝑓 (𝑥𝑇 ) − 𝑓 (𝑥*)]︀

≤

[︁ E 𝑓 (𝑥𝑇 ) − 𝑓 (𝑥*) +

𝛾

]︁ 𝐺𝑇

≤

(1 − 𝛾𝜇)𝑇

(︁ ∆0

[︁ 𝛾 +E

]︁)︁ 𝐺0 .

𝐴

𝐴

16

C. Three Point Compressor: Special Cases
In this section, we show that several known approaches to compressed communication can be viewed as special cases of our framework (12)–(13). Moreover, we design several new methods ﬁtting our scheme. Please refer to Table 1 for an overview.

C.1. Error Feedback 2021: EF21

Algorithm 2 Error Feedback 2021 (EF21)

1: Input: starting point 𝑥0, stepsize 𝛾, number of iterations 𝑇 , starting vectors 𝑔𝑖0, 𝑖 ∈ [𝑛]

2: for 𝑡 = 0,1, . . . ,𝑇 − 1 do

3: Broadcast 𝑔𝑡 to all workers

4: for 𝑖 = 1, . . . ,𝑛 in parallel do

5:

𝑥𝑡+1 = 𝑥𝑡 − 𝛾𝑔𝑡

6:

Set 𝑔𝑖𝑡+1 = 𝑔𝑖𝑡 + 𝒞(∇𝑓𝑖(𝑥𝑡+1) − 𝑔𝑖𝑡)

7: end for

8:

𝑔𝑡+1

=

1 𝑛

∑︀𝑛
𝑖=1

𝑔𝑖𝑡+1

=

𝑔𝑡

+

1 𝑛

∑︀𝑛
𝑖=1

𝒞

(∇𝑓𝑖

(𝑥𝑡+1

)

−

𝑔𝑖𝑡

)

9: end for

10: Return: 𝑥ˆ𝑇 chosen uniformly at random from {𝑥𝑡}𝑇𝑡=−01

The next lemma shows that EF21 uses a special three point compressor. Lemma C.1. The compressor

𝒞ℎ,𝑦(𝑥) := ℎ + 𝒞(𝑥 − ℎ),

(31)

satisﬁes (6) with 𝐴 := 1 − (1 − 𝛼)(1 + 𝑠) and 𝐵 := (1 − 𝛼) (︀1 + 𝑠−1)︀, where 𝑠 > 0 is such that (1 − 𝛼) (1 + 𝑠) < 1.

Proof. By deﬁnition of 𝒞ℎ,𝑦(𝑥) and 𝒞 we have

E

[︁ ‖𝒞ℎ,𝑦

(𝑥)

−

𝑥‖2

]︁

=

E

[︁ ‖𝒞

(𝑥

−

ℎ)

−

(𝑥

−

ℎ)‖2

]︁

≤ (1 − 𝛼) ‖𝑥 − ℎ‖2 = (1 − 𝛼) ‖(𝑥 − 𝑦) + (𝑦 − ℎ)‖2 ≤ (1 − 𝛼) (1 + 𝑠) ‖ℎ − 𝑦‖2 + (1 − 𝛼) (︀1 + 𝑠−1)︀ ‖𝑥 − 𝑦‖2 .

Therefore, EF21 ﬁts our framework. Using our general analysis (Theorems 5.5 and 5.8) we derive the following result.
Theorem C.2. EF21 is a special case of the method from (12)–(13) with 𝒞ℎ,𝑦(𝑥) deﬁned in (31) and 𝐴 = 𝛼 − 𝑠(1 − 𝛼) and 𝐵 = (1 − 𝛼) (︀1 + 𝑠−1)︀, where 𝑠 > 0 is such that (1 − 𝛼)(1 + 𝑠) < 1.

1. If Assumptions 5.1, 5.2, 5.3 hold and the stepsize 𝛾 satisﬁes 0 ≤ 𝛾 ≤ 1/𝑀, where 𝑀 = 𝐿− + √︁
𝐿+ (1−𝛼)(1+𝑠−1)/(𝛼−𝑠(1−𝛼)), then for any 𝑇 ≥ 0 we have

E [︁⃦⃦∇𝑓 (𝑥ˆ𝑇 )⃦⃦2]︁ ≤ 2∆0 + E [︀𝐺0]︀ , (32) 𝛾𝑇 (𝛼 − 𝑠(1 − 𝛼))𝑇
where 𝑥ˆ𝑇 is sampled uniformly at random from the points {𝑥0, 𝑥1, . . . , 𝑥𝑇 −1} produced by EF21, ∆0 = 𝑓 (𝑥0) − 𝑓 inf , and 𝐺0 is deﬁned in (15).

2. If additionaly Assumption 5.7 hold and 0

≤

𝛾

≤

1/𝑀 for 𝑀

=

{︂

√︁

}︂

max 𝐿− + 𝐿+ 2(1−𝛼)(1+𝑠−1)/(𝛼−𝑠(1−𝛼)), (𝛼−𝑠(1−𝛼))/2𝜇 , then for any 𝑇 ≥ 0 we have

(︂ E [︀𝑓 (𝑥𝑇 ) − 𝑓 (𝑥*)]︀ ≤ (1 − 𝛾𝜇)𝑇 ∆0 +

𝛾

)︂ E [︀𝐺0]︀ .

(33)

𝛼 − 𝑠(1 − 𝛼)

17

Guided by exactly the same arguments as we use in the anlysis pf 3PCv5, we consider 𝐵/𝐴 as a function of 𝑠 and optimizing this function in 𝑠 and ﬁnd the optimal value of this ratio.

Lemma C.3. The optimal value of

𝐵

(1 − 𝛼) (︀1 + 𝑠−1)︀

(𝑠) =

𝐴

(𝛼 − 𝑠(1 − 𝛼))

under the constraint 0 < 𝑠 < 𝛼/(1−𝛼) equals

𝐵

(1 − 𝛼)

4(1 − 𝛼)

𝐴 (𝑠*) = (1 − √1 − 𝛼)2 ≤ 𝛼2

and

it

is

achieved

at

𝑠*

=

−1

+

√︀ 1/(1−𝛼).

Proof. First of all, we ﬁnd the derivative of the considered function:

(︂ 𝐵 )︂′

(1 − 𝛼)𝑠2 + 2(1 − 𝛼)𝑠 − 𝛼

𝐴 (𝑠) = (1 − 𝛼) (𝛼𝑠 − 𝑠2(1 − 𝛼))2 .

√︀

√︀

The function has 2 critical points: −1 ± 1/(1−𝛼). Moreover, the derivative is non-positive for 𝑠 ∈ (0, −1 + 1/(1−𝛼)] and

√︀ negative for 𝑠 ∈ (−1 + 1/(1−𝛼), +∞). This implies that the optimal value on the interval 𝑠 ∈ (0, 𝛼/(1−𝛼)) is achieved at

√︀ 𝑠* = −1 + 1/(1−𝛼). Via simple computations one can verify that

√ Finally, since 1 − 1 − 𝛼 ≥ 𝛼/2, we have

𝐵 (𝑠*) =

(1 − 𝛼)

√

.

𝐴

(1 − 1 − 𝛼)2

𝐵

4(1 − 𝛼)

𝐴 (𝑠*) ≤ 𝛼2 .

Using this and Corollaries 5.6, 5.9, we get the following complexity results. √︀
Corollary C.4. 1. Let the assumptions from the ﬁrst part of Theorem C.2 hold, 𝑠 = 𝑠* = −1 + 1/(1−𝛼), and

1 𝛾 = 𝐿− + 𝐿+√︀(1−𝛼)/(1−√1−𝛼)2 .

Then for any 𝑇 we have

[︁

2]︁ 2∆0 (︁𝐿− + 𝐿+√︀(1−𝛼)/(1−√1−𝛼)2)︁

E [︀𝐺0]︀

E

⃦ ⃦∇

𝑓

(𝑥ˆ

𝑇

⃦ )⃦

≤

+√

,

𝑇

(1 − 1 − 𝛼)𝑇

i.e.,

to

achieve

E

[︁ ⃦ ⃦∇𝑓

(𝑥ˆ𝑇

⃦2]︁ )⃦

≤

𝜀2

for

some

𝜀

>

0

the

method

requires

⎛

∆0

(︁ 𝐿−

+

)︁ √︀ 𝐿+ (1−𝛼)/𝛼2

⎞ E [︀𝐺0]︀

𝑇 = 𝒪 ⎝ 𝜀2

+ 𝛼𝜀2 ⎠

(34)

iterations/communication rounds.

2. Let the assumptions from the second part of Theorem C.2 hold and

{︃

√ }︃

1

1− 1−𝛼

𝛾 = min 𝐿− + 𝐿+√︀2(1−𝛼)/(1−√1−𝛼)2 , 2𝜇 .

Then to achieve E [︀𝑓 (𝑥𝑇 ) − 𝑓 (𝑥*)]︀ ≤ 𝜀 for some 𝜀 > 0 the method requires

(︃

{︃

√︀

}︃

𝐿− + 𝐿+ (1−𝛼)/𝛼2

∆0 + E [︀𝐺0]︀ 𝛾/𝛼 )︃

𝒪 max

, 𝛼 log

(35)

𝜇

𝜀

iterations/communication rounds.

18

C.2. LAG: Lazily Aggregated Gradient

Algorithm 3 LAG: Lazily Aggregated Gradient

1: Input: starting point 𝑥0, stepsize 𝛾, number of iterations 𝑇 , starting vectors 𝑔𝑖0, 𝑖 ∈ [𝑛], trigger parameter 𝜁 > 0

2: for 𝑡 = 0,1, . . . ,𝑇 − 1 do

3: Broadcast 𝑔𝑡 to all workers

4: for 𝑖 = 1, . . . ,𝑛 in parallel do

5:

𝑥𝑡+1 = 𝑥𝑡 − 𝛾𝑔𝑡

{︃

𝑡+1 ∇𝑓𝑖(𝑥𝑡+1), if ‖∇𝑓𝑖(𝑥𝑡+1) − 𝑔𝑖𝑡‖2 > 𝜁‖∇𝑓𝑖(𝑥𝑡+1) − ∇𝑓𝑖(𝑥𝑡)‖2,

6: Set 𝑔𝑖 = 𝑔𝑖𝑡,

otherwise

7: end for

8:

𝑔𝑡+1

=

1 𝑛

∑︀𝑛
𝑖=1

𝑔𝑖𝑡+1

9: end for

10: Return: 𝑥ˆ𝑇 chosen uniformly at random from {𝑥𝑡}𝑇𝑡=−01

The next lemma shows that LAG is a special three point compressor. Lemma C.5. The compressor

{︃

𝑥, if ‖𝑥 − ℎ‖2 > 𝜁‖𝑥 − 𝑦‖2,

𝒞ℎ,𝑦(𝑥) :=

(36)

ℎ, otherwise,

satisﬁes (6) with 𝐴 := 1 and 𝐵 := 𝜁.

Proof. If ‖𝑥 − ℎ‖2 ≤ 𝜁‖𝑥 − 𝑦‖2, then we have

‖𝒞ℎ,𝑦(𝑥) − 𝑥‖2 = ‖ℎ − 𝑥‖2 ≤ 𝜁 ‖𝑥 − 𝑦‖2 .

Otherwise,

‖𝒞ℎ,𝑦(𝑥) − 𝑥‖2 = ‖𝑥 − 𝑥‖2 = 0 ≤ 𝜁 ‖𝑥 − 𝑦‖2 .

Therefore, LAG ﬁts our framework. Using our general analysis (Theorems 5.5 and 5.8) we derive the following result. Theorem C.6. LAG is a special case of the method from (12)–(13) with 𝒞ℎ,𝑦(𝑥) deﬁned in (36) and 𝐴 = 1 and 𝐵 = 𝜁.

√ 1. If Assumptions 5.1, 5.2, 5.3 hold and the stepsize 𝛾 satisﬁes 0 ≤ 𝛾 ≤ 1/𝑀, where 𝑀 = 𝐿− + 𝐿+ 𝜁, then for any

𝑇 ≥ 0 we have

E [︁⃦⃦∇𝑓 (𝑥ˆ𝑇 )⃦⃦2]︁ ≤ 2∆0 + E [︀𝐺0]︀ , (37)

𝛾𝑇

𝑇

where 𝑥ˆ𝑇 is sampled uniformly at random from the points {𝑥0, 𝑥1, . . . , 𝑥𝑇 −1} produced by LAG, ∆0 = 𝑓 (𝑥0) − 𝑓 inf , and 𝐺0 is deﬁned in (15).

2. If additionaly Assumption 5.7 hold and 0 ≤ 𝛾 ≤ 1/𝑀 for 𝑀 = max {︀𝐿− + 𝐿+√2𝜁, 1/2𝜇}︀, then for any 𝑇 ≥ 0 we

have

E [︀𝑓 (𝑥𝑇 ) − 𝑓 (𝑥*)]︀ ≤ (1 − 𝛾𝜇)𝑇 (︀∆0 + 𝛾E [︀𝐺0]︀)︀ .

(38)

Using this and Corollaries 5.6, 5.9, we get the following complexity results. Corollary C.7. 1. Let the assumptions from the ﬁrst part of Theorem C.6 hold, and
𝛾= 1 √ . 𝐿− + 𝐿+ 𝜁

19

Then for any 𝑇 > 1 we have

[︁

2]︁ 2∆0(𝐿 + 𝐿 √𝜁) E [︀𝐺0]︀

E

⃦ ⃦∇

𝑓

(

𝑥ˆ

𝑇

⃦ )⃦

≤

−

+

+

,

𝑇

𝑇

i.e.,

to

achieve

E

[︁ ⃦ ⃦∇𝑓

(𝑥ˆ𝑇

⃦2]︁ )⃦

≤

𝜀2

for

some

𝜀

>

0

the

method

requires

𝑇 = 𝒪 (︃ ∆0(𝐿− + 𝐿+√𝜁) + E [︀𝐺0]︀ )︃ (39)

𝜀2

𝜀2

iterations/communication rounds.

2. Let the assumptions from the second part of Theorem C.6 hold and

{︂

1

1 }︂

𝛾 = min

√, .

𝐿− + 𝐿+ 𝜁 2𝜇

Then to achieve E [︀𝑓 (𝑥𝑇 ) − 𝑓 (𝑥*)]︀ ≤ 𝜀 for some 𝜀 > 0 the method requires

𝒪 (︃ 𝐿− + 𝐿+√𝜁 log ∆0 + E [︀𝐺0]︀ 𝛾 )︃ (40)

𝜇

𝜀

iterations/communication rounds.

Proof. Both claims are straight-forward applications of Corollaries 5.6, 5.9. In the second claim, we used that

√

𝐿− + 𝐿+ 𝜁 ≥ 𝐿− ≥ 1,

𝜇

𝜇

where the second inequality holds since 𝐿− ≥ 𝜇 (Nesterov et al., 2018).

20

C.3. CLAG: Compressed Lazily Aggregated Gradient (NEW)

Algorithm 4 CLAG: Compressed Lazily Aggregated Gradient

1: Input: starting point 𝑥0, stepsize 𝛾, number of iterations 𝑇 , starting vectors 𝑔𝑖0, 𝑖 ∈ [𝑛], trigger parameter 𝜁 > 0

2: for 𝑡 = 0,1, . . . ,𝑇 − 1 do

3: Broadcast 𝑔𝑡 to all workers

4: for 𝑖 = 1, . . . ,𝑛 in parallel do

5:

𝑥𝑡+1 = 𝑥𝑡 − 𝛾𝑔𝑡

{︃

𝑡+1 𝑔𝑖𝑡 + 𝒞 (︀∇𝑓𝑖(𝑥𝑡+1) − 𝑔𝑖𝑡)︀ , if ‖∇𝑓𝑖(𝑥𝑡+1) − 𝑔𝑖𝑡‖2 > 𝜁‖∇𝑓𝑖(𝑥𝑡+1) − ∇𝑓𝑖(𝑥𝑡)‖2,

6: Set 𝑔𝑖 = 𝑔𝑖𝑡,

otherwise

7: end for

8:

𝑔𝑡+1

=

1 𝑛

∑︀𝑛
𝑖=1

𝑔𝑖𝑡+1

9: end for

10: Return: 𝑥ˆ𝑇 chosen uniformly at random from {𝑥𝑡}𝑇𝑡=−01

The next lemma shows that CLAG uses a special three points compressor. Lemma C.8. The compressor

{︃

ℎ + 𝒞(𝑥 − ℎ), if ‖𝑥 − ℎ‖2 > 𝜁‖𝑥 − 𝑦‖2,

𝒞ℎ,𝑦(𝑥) :=

(41)

ℎ,

otherwise,

satisﬁes (6) with 𝐴 := 1−(1−𝛼)(1+𝑠) and 𝐵 := max {︀(1 − 𝛼) (︀1 + 𝑠−1)︀ , 𝜁}︀, where 𝑠 > 0 is such that (1−𝛼) (1 + 𝑠) < 1.

Proof. First of all, if ‖𝑥 − ℎ‖2 ≤ 𝜁‖𝑥 − 𝑦‖2, then we have

E

[︁ ‖𝒞ℎ,𝑦

(𝑥)

−

𝑥‖2

]︁

=

‖ℎ − 𝑥‖2 ≤ 𝜁 ‖𝑥 − 𝑦‖2 .

Next, if ‖𝑥 − ℎ‖2 > 𝜁‖𝑥 − 𝑦‖2, then using the deﬁnition of 𝒞ℎ,𝑦(𝑥) and 𝒞, we derive

E

[︁ ‖𝒞ℎ,𝑦

(𝑥)

−

𝑥‖2

]︁

=

E

[︁ ‖𝒞

(𝑥

−

ℎ)

−

(𝑥

−

ℎ)‖2

]︁

≤ (1 − 𝛼) ‖𝑥 − ℎ‖2 = (1 − 𝛼) ‖(𝑥 − 𝑦) + (𝑦 − ℎ)‖2 ≤ (1 − 𝛼) (1 + 𝑠) ‖ℎ − 𝑦‖2 + (1 − 𝛼) (︀1 + 𝑠−1)︀ ‖𝑥 − 𝑦‖2 .

Therefore, CLAG ﬁts our framework. Using our general analysis (Theorems 5.5 and 5.8) we derive the following result. Theorem C.9. CLAG is a special case of the method from (12)–(13) with 𝒞ℎ,𝑦(𝑥) deﬁned in (41) and 𝐴 = 𝛼 − 𝑠(1 − 𝛼) and 𝐵 = max {︀(1 − 𝛼) (︀1 + 𝑠−1)︀ , 𝜁}︀, where 𝑠 > 0 is such that (1 − 𝛼)(1 + 𝑠) < 1.
1. If Assumptions 5.1, 5.2, 5.3 hold and the stepsize 𝛾 satisﬁes 0 ≤ 𝛾 ≤ 1/𝑀, where 𝑀 = 𝐿− + √︁
𝐿+ max{(1−𝛼)(1+𝑠−1),𝜁}/(𝛼−𝑠(1−𝛼)), then for any 𝑇 ≥ 0 we have
E [︁⃦⃦∇𝑓 (𝑥ˆ𝑇 )⃦⃦2]︁ ≤ 2∆0 + E [︀𝐺0]︀ , (42) 𝛾𝑇 (𝛼 − 𝑠(1 − 𝛼))𝑇
where 𝑥ˆ𝑇 is sampled uniformly at random from the points {𝑥0, 𝑥1, . . . , 𝑥𝑇 −1} produced by CLAG, ∆0 = 𝑓 (𝑥0) − 𝑓 inf , and 𝐺0 is deﬁned in (15).
21

2. If additionaly Assumption 5.7 hold and 0

≤

𝛾

≤

1/𝑀 for 𝑀

=

{︂

√︁

}︂

max 𝐿− + 𝐿+ 2 max{(1−𝛼)(1+𝑠−1),𝜁}/(𝛼−𝑠(1−𝛼)), (𝛼−𝑠(1−𝛼))/2𝜇 , then for any 𝑇 ≥ 0 we have

(︂ E [︀𝑓 (𝑥𝑇 ) − 𝑓 (𝑥*)]︀ ≤ (1 − 𝛾𝜇)𝑇 ∆0 +

𝛾

)︂ E [︀𝐺0]︀ .

(43)

𝛼 − 𝑠(1 − 𝛼)

Using this and Corollaries 5.6, 5.9, we get the following complexity results. √︀
Corollary C.10. 1. Let the assumptions from the ﬁrst part of Theorem C.9 hold, 𝑠 = 𝑠* = −1 + 1/(1−𝛼), and
1 𝛾 = √︂ .
𝐿− + 𝐿+ max {︁ (1−(√1−1𝛼−)𝛼)2 , 1−√𝜁1−𝛼 }︁

Then for any 𝑇 we have

(︂

√︂

)︂

{︁ 2∆0 𝐿− + 𝐿+ max

(√1−𝛼)

,

√𝜁

}︁

E

[︁ ⃦ ⃦∇𝑓

(𝑥ˆ𝑇

⃦2]︁ )⃦

≤

(1− 1−𝛼)2 1− 1−𝛼
+

E [︀𝐺0]︀

√

,

𝑇

(1 − 1 − 𝛼)𝑇

i.e.,

to

achieve

E

[︁ ⃦ ⃦∇𝑓

(𝑥ˆ𝑇

⃦2]︁ )⃦

≤

𝜀2

for

some

𝜀

>

0

the

method

requires

⎛ (︂

√︂

)︂

⎞

∆0 𝐿− + 𝐿+ max {︁ (1𝛼−2𝛼) , 𝛼𝜁 }︁

E [︀𝐺0]︀

⎜

⎟

𝑇 = 𝒪 ⎜⎝ 𝜀2

+ 𝛼𝜀2 ⎟⎠

(44)

iterations/communication rounds.

2. Let the assumptions from the second part of Theorem C.9 hold and

⎧

⎫

⎪

√⎪

⎪ ⎨

1

1−

1

−

𝛼

⎪ ⎬

𝛾 = min

,

.

⎪

√︂ {︁ 2(1−𝛼)

}︁
𝜁

2𝜇 ⎪

⎪ ⎩

𝐿−

+

𝐿+

max

√ (1− 1−𝛼)2

,

√ 1− 1−𝛼

⎪ ⎭

Then to achieve E [︀𝑓 (𝑥𝑇 ) − 𝑓 (𝑥*)]︀ ≤ 𝜀 for some 𝜀 > 0 the method requires

⎛⎧

√︂

⎫

⎞

⎪ ⎪

𝐿−

+

𝐿+

max {︁ (1−2𝛼) , 𝜁 }︁

⎪ ⎪

0 [︀ 0]︀

⎨ ⎜

𝛼 𝛼 ⎬ ∆ + E 𝐺 𝛾/𝛼 ⎟

𝒪 ⎜max

, 𝛼 log

⎟

(45)

⎝⎪ 𝜇

⎪ 𝜀⎠

⎪

⎪

⎩

⎭

iterations/communication rounds.

22

C.4. 3PCv1 (NEW) Out of theoretical curiosity, we consider the following theoretical method.

Algorithm 5 Error Feedback 2021 – gradient shift version (3PCv1)

1: Input: starting point 𝑥0, stepsize 𝛾, number of iterations 𝑇 , starting vectors 𝑔𝑖0, 𝑖 ∈ [𝑛]

2: for 𝑡 = 0,1, . . . ,𝑇 − 1 do

3: Broadcast 𝑔𝑡 to all workers

4: for 𝑖 = 1, . . . ,𝑛 in parallel do

5:

𝑥𝑡+1 = 𝑥𝑡 − 𝛾𝑔𝑡

6:

Set 𝑔𝑖𝑡+1 = ∇𝑓𝑖(𝑥𝑡) + 𝒞(∇𝑓𝑖(𝑥𝑡+1) − ∇𝑓𝑖(𝑥𝑡))

7: end for

8:

𝑔𝑡+1

=

1 𝑛

∑︀𝑛
𝑖=1

𝑔𝑖𝑡+1

9: end for

10: Return: 𝑥ˆ𝑇 chosen uniformly at random from {𝑥𝑡}𝑇𝑡=−01

3PCv1 is impractical since the the compression does not help to reduce the cost of one iteration. Indeed, the server does not know the shifts ∇𝑓𝑖(𝑥𝑡) and the workers have to send them as well at each iteration.
Nevertheless, one can consider 3PCv1 as an ideal version of EF21. To illustrate that we derive the following lemma. Lemma C.11. The compressor

𝒞ℎ,𝑦(𝑥) := 𝑦 + 𝒞(𝑥 − 𝑦),

(46)

satisﬁes (6) with 𝐴 := 1 and 𝐵 := 1 − 𝛼.

Proof. By deﬁnition of 𝒞ℎ,𝑦(𝑥) and 𝒞 we have

E

[︁ ‖𝒞ℎ,𝑦

(𝑥)

−

𝑥‖2

]︁

=

E

[︁ ‖𝒞

(𝑥

−

𝑦

)

−

(𝑥

−

𝑦

)‖2

]︁

≤ (1 − 𝛼) ‖𝑥 − 𝑦‖2 .

Therefore, 3PCv1 ﬁts our framework. Using our general analysis (Theorems 5.5 and 5.8) we derive the following result.
Theorem C.12. 3PCv1 is a special case of the method from (12)–(13) with 𝒞ℎ,𝑦(𝑥) deﬁned in (46) and 𝐴 = 1 and 𝐵 = 1 − 𝛼.

√ 1. If Assumptions 5.1, 5.2, 5.3 hold and the stepsize 𝛾 satisﬁes 0 ≤ 𝛾 ≤ 1/𝑀, where 𝑀 = 𝐿− + 𝐿+ 1 − 𝛼, then for any

𝑇 ≥ 0 we have

E [︁⃦⃦∇𝑓 (𝑥ˆ𝑇 )⃦⃦2]︁ ≤ 2∆0 + E [︀𝐺0]︀ , (47)

𝛾𝑇

𝑇

where 𝑥ˆ𝑇 is sampled uniformly at random from the points {𝑥0, 𝑥1, . . . , 𝑥𝑇 −1} produced by 3PCv1, ∆0 = 𝑓 (𝑥0) − 𝑓 inf , and 𝐺0 is deﬁned in (15).

{︁

}︁

√︀

2. If additionaly Assumption 5.7 hold and 0 ≤ 𝛾 ≤ 1/𝑀 for 𝑀 = max 𝐿− + 𝐿+ 2(1 − 𝛼), 1/2𝜇 , then for any 𝑇 ≥ 0

we have

E [︀𝑓 (𝑥𝑇 ) − 𝑓 (𝑥*)]︀ ≤ (1 − 𝛾𝜇)𝑇 (︀∆0 + 𝛾E [︀𝐺0]︀)︀ .

(48)

Using this and Corollaries 5.6, 5.9, we get the following complexity results. Corollary C.13. 1. Let the assumptions from the ﬁrst part of Theorem C.12 hold and
𝛾 = 1√ . 𝐿− + 𝐿+ 1 − 𝛼

23

Then for any 𝑇 we have

√

E [︁⃦⃦∇𝑓 (𝑥ˆ𝑇 )⃦⃦2]︁ ≤ 2∆0 (︀𝐿− + 𝐿+ 1 − 𝛼)︀ + E [︀𝐺0]︀ ,

𝑇

𝑇

i.e.,

to

achieve

E

[︁ ⃦ ⃦∇𝑓

(𝑥ˆ𝑇

⃦2]︁ )⃦

≤

𝜀2

for

some

𝜀

>

0

the

method

requires

(︃

√

)︃

∆0 (︀𝐿− + 𝐿+ 1 − 𝛼)︀ E [︀𝐺0]︀

𝑇 =𝒪

𝜀2 + 𝜀2

(49)

iterations/communication rounds.

2. Let the assumptions from the second part of Theorem C.12 hold and

{︃

}︃

1

1

𝛾 = min

,.

√︀ 𝐿− + 𝐿+ 2(1 − 𝛼)

2𝜇

Then to achieve E [︀𝑓 (𝑥𝑇 ) − 𝑓 (𝑥*)]︀ ≤ 𝜀 for some 𝜀 > 0 the method requires

𝒪 (︃ 𝐿− + 𝐿+√1 − 𝛼 log ∆0 + 𝛾E [︀𝐺0]︀ )︃ (50)

𝜇

𝜀

iterations/communication rounds.

24

C.5. 3PCv2 (NEW)

Algorithm 6 3PCv2

1: Input: starting point 𝑥0, stepsize 𝛾, number of iterations 𝑇 , starting vectors 𝑔𝑖0, 𝑖 ∈ [𝑛]

2: for 𝑡 = 0,1, . . . ,𝑇 − 1 do

3: Broadcast 𝑔𝑡 to all workers

4: for 𝑖 = 1, . . . ,𝑛 in parallel do

5:

𝑥𝑡+1 = 𝑥𝑡 − 𝛾𝑔𝑡

6:

Compute 𝑏𝑡𝑖 = 𝑔𝑖𝑡 + 𝒬(∇𝑓𝑖(𝑥𝑡+1) − ∇𝑓𝑖(𝑥𝑡))

7:

Set 𝑔𝑖𝑡+1 = 𝑏𝑡𝑖 + 𝒞 (︀∇𝑓𝑖(𝑥𝑡+1) − 𝑏𝑡𝑖)︀

8: end for

9:

𝑔𝑡+1

=

1 𝑛

∑︀𝑛
𝑖=1

𝑔𝑖𝑡+1

10: end for

11: Return: 𝑥ˆ𝑇 chosen uniformly at random from {𝑥𝑡}𝑇𝑘=−01

Lemma C.14. The compressor

𝒞ℎ,𝑦(𝑥) := 𝑏 + 𝒞 (𝑥 − 𝑏) , where 𝑏 = ℎ + 𝒬(𝑥 − 𝑦),

(51)

satisﬁes (6) with 𝐴 := 𝛼 and 𝐵 := (1 − 𝛼)𝜔.

Proof. By deﬁnition of 𝒞ℎ,𝑦(𝑥), 𝒞, and 𝒬 we have

E

[︁ ‖𝒞ℎ,𝑦

(𝑥)

−

𝑥‖2

]︁

=

E

[︁ E

[︁ ‖𝒞ℎ,𝑦

(𝑥)

−

𝑥‖2

]︁]︁ |𝑏

=

E

[︁ E

[︁ ‖𝑏

+

𝒞

(𝑥

−

𝑏)

−

𝑥‖2

]︁]︁ |𝑏

≤

E

[︁ (1

−

𝛼)

‖𝑥

−

𝑏‖2

]︁

=

(1

−

𝛼)E

[︁ ‖𝒬(𝑥

−

𝑦

)

−

(𝑥

−

ℎ)‖2

]︁

=

(1

−

𝛼)

[︁ E

[︁ ‖𝒬(𝑥

−

𝑦

)

−

(𝑥

−

𝑦

)‖2

]︁

+

‖ℎ

−

𝑦

‖2

]︁

≤ (1 − 𝛼) ‖ℎ − 𝑦‖2 + (1 − 𝛼)𝜔 ‖𝑥 − 𝑦‖2 .

Therefore, 3PCv2 ﬁts our framework. Before we formulate the main results for 3PCv2, we make several remarks on the proposed method. First of all, with 3PCv2, we need to communicate two compressed vectors: 𝒬(𝑥 − 𝑦) and 𝒞 (𝑥 − (ℎ + 𝒬(𝑥 − 𝑦))). This is similar to how the induced compressor works (Horva´th & Richta´rik, 2020), but 3PCv2 compressor is not unbiased. If we set 𝒬 ≡ 0 (this compressor is not unbiased, so the above formulas for 𝐴 and 𝐵 do not apply) and allow 𝒞 to be arbitrary, we obtain EF21 (Richta´rik et al., 2021). Next, if we set

{︃

𝑥 with probability 𝑝

𝒞(𝑥) =

,

(52)

0 with probability 1 − 𝑝

and allow 𝒬 to be arbitrary, we obtain MARINA (Gorbunov et al., 2021). Note that 𝒞 deﬁned above is biased since

E [𝒞(𝑥)]

=

𝑝𝑥,

and

the

variance

inequality

is

satisﬁed

as

an

identity:

E

[︁ ‖𝒞

(𝑥)

−

𝑥‖2

]︁

=

(1 − 𝑝) ‖𝑥‖2.

By

choosing

a different biased compressor 𝒞, e.g., Top-𝐾, we obtain a new variant of MARINA. In particular, unlike MARINA, this

compressor never needs to communicate full gradients, which can be important in some cases.

Using our general analysis (Theorems 5.5 and 5.8) we derive the following result.
Theorem C.15. 3PCv2 is a special case of the method from (12)–(13) with 𝒞ℎ,𝑦(𝑥) deﬁned in (51) and 𝐴 = 𝛼 and 𝐵 = (1 − 𝛼)𝜔.

25

√︀ 1. If Assumptions 5.1, 5.2, 5.3 hold and the stepsize 𝛾 satisﬁes 0 ≤ 𝛾 ≤ 1/𝑀, where 𝑀 = 𝐿− + 𝐿+ (1−𝛼)𝜔/𝛼, then for

any 𝑇 ≥ 0 we have

E [︁⃦⃦∇𝑓 (𝑥ˆ𝑇 )⃦⃦2]︁ ≤ 2∆0 + E [︀𝐺0]︀ , (53)

𝛾𝑇

𝛼𝑇

where 𝑥ˆ𝑇 is sampled uniformly at random from the points {𝑥0, 𝑥1, . . . , 𝑥𝑇 −1} produced by 3PCv2, ∆0 = 𝑓 (𝑥0) − 𝑓 inf , and 𝐺0 is deﬁned in (15).

{︁

}︁

√︀

2. If additionaly Assumption 5.7 hold and 0 ≤ 𝛾 ≤ 1/𝑀 for 𝑀 = max 𝐿− + 𝐿+ 2(1−𝛼)𝜔/𝛼, 𝛼/2𝜇 , then for any

𝑇 ≥ 0 we have

E [︀𝑓 (𝑥𝑇 )

−

𝑓 (𝑥*)]︀

≤

(1

−

𝛾𝜇)𝑇

(︁ ∆0

+

𝛾

)︁ E [︀𝐺0]︀ .

(54)

𝛼

Using this and Corollaries 5.6, 5.9, we get the following complexity results. Corollary C.16. 1. Let the assumptions from the ﬁrst part of Theorem C.15 hold and

1 𝛾 = √︀ .
𝐿− + 𝐿+ (1−𝛼)𝜔/𝛼

Then for any 𝑇 we have

(︁

)︁

[︁

2]︁ 2∆0 𝐿− + 𝐿+√︀(1−𝛼)𝜔/𝛼 E [︀𝐺0]︀

E

⃦ ⃦∇

𝑓

(

𝑥ˆ

𝑇

⃦ )⃦

≤

+

,

𝑇

𝛼𝑇

i.e.,

to

achieve

E

[︁ ⃦ ⃦∇𝑓

(𝑥ˆ𝑇

⃦2]︁ )⃦

≤

𝜀2

for

some

𝜀

>

0

the

method

requires

⎛

∆0

(︁ 𝐿−

+

)︁ √︀ 𝐿+ (1−𝛼)𝜔/𝛼

⎞ E [︀𝐺0]︀

𝑇 = 𝒪 ⎝ 𝜀2

+ 𝛼𝜀2 ⎠

(55)

iterations/communication rounds.

2. Let the assumptions from the second part of Theorem C.15 hold and

{︃

}︃

1

𝛼

𝛾 = min

,.

√︀ 𝐿− + 𝐿+ 2(1−𝛼)𝜔/𝛼

2𝜇

Then to achieve E [︀𝑓 (𝑥𝑇 ) − 𝑓 (𝑥*)]︀ ≤ 𝜀 for some 𝜀 > 0 the method requires

(︃

{︃

√︀

}︃

𝐿− + 𝐿+ 2(1−𝛼)𝜔/𝛼

∆0 + E [︀𝐺0]︀ 𝛾/𝛼 )︃

𝒪 max

, 𝛼 log

(56)

𝜇

𝜀

iterations/communication rounds.

26

C.6. 3PCv3 (NEW)
In this section, we introduce a new method called 3PCv3. It can be seen as a combination of any 3PC compressor with some biased compressor. We also notice that 3PCv2 cannot be obtained as a special case of 3PCv3 as ℎ + 𝒬(𝑥 − 𝑦) does not satisfy (6).

Algorithm 7 3PCv3

1: Input: starting point 𝑥0, stepsize 𝛾, number of iterations 𝑇 , starting vectors 𝑔𝑖0, 𝑖 ∈ [𝑛]

2: for 𝑡 = 0,1, . . . ,𝑇 − 1 do

3: Broadcast 𝑔𝑡 to all workers

4: for 𝑖 = 1, . . . ,𝑛 in parallel do

5:

𝑥𝑡+1 = 𝑥𝑡 − 𝛾𝑔𝑡

6: Compute 𝑏𝑡𝑖 = 𝒞𝑔1𝑖𝑡,∇𝑓𝑖(𝑥𝑡)(∇𝑓𝑖(𝑥𝑡+1))

7:

Set 𝑔𝑖𝑡+1 = 𝑏𝑡𝑖 + 𝒞 (︀∇𝑓𝑖(𝑥𝑡+1) − 𝑏𝑡𝑖)︀

8: end for

9:

𝑔𝑡+1

=

1 𝑛

∑︀𝑛
𝑖=1

𝑔𝑖𝑡+1

10: end for

11: Return: 𝑥ˆ𝑇 chosen uniformly at random from {𝑥𝑡}𝑇𝑡=−01

Lemma C.17. Consider the compressor deﬁned as

𝒞ℎ,𝑦(𝑥) := 𝑏 + 𝒞(𝑥 − 𝑏), where 𝑏 = 𝒞ℎ1,𝑦(𝑥)

(57)

and 𝒞ℎ1,𝑦(𝑥) satisﬁes (6) with some 𝐴1 and 𝐵1. Then 𝒞ℎ,𝑦(𝑥) satisﬁes (6) with 𝐴 := 1−(1−𝛼)(1−𝐴1) and 𝐵 := (1−𝛼)𝐵1.

Proof. By deﬁnition of 𝒞ℎ1,𝑦(𝑥) and 𝒞 we have

E

[︁ ‖𝒞ℎ,𝑦

(𝑥)

−

𝑥‖2

]︁

=

E

[︁ E

[︁ ‖𝑏

+

𝒞(𝑥

−

𝑏)

−

𝑥‖2

|

]︁]︁ 𝑏

≤

(1

−

𝛼)E

[︁ ‖𝑥

−

𝑏‖2

]︁

=

(1

−

𝛼)E

[︁ ⃦⃦𝒞ℎ1,𝑦

(𝑥)

−

⃦2 𝑥⃦

]︁

≤ (1 − 𝛼)(1 − 𝐴1)‖ℎ − 𝑦‖2 + (1 − 𝛼)𝐵1‖𝑥 − 𝑦‖2.

Therefore, 3PCv3 ﬁts our framework. Using our general analysis (Theorems 5.5 and 5.8) we derive the following result.
Theorem C.18. 3PCv3 is a special case of the method from (12)–(13) with 𝒞ℎ,𝑦(𝑥) deﬁned in (57) and 𝐴 := 1 − (1 − 𝛼)(1 − 𝐴1) and 𝐵 := (1 − 𝛼)𝐵1.

1. If Assumptions 5.1, 5.2, 5.3 hold and the stepsize 𝛾 satisﬁes 0 ≤ 𝛾 ≤ 1/𝑀, where 𝑀 = 𝐿− + √︀
𝐿+ (1−𝛼)𝐵1/(1−(1−𝛼)(1−𝐴1)), then for any 𝑇 ≥ 0 we have

E [︁⃦⃦∇𝑓 (𝑥ˆ𝑇 )⃦⃦2]︁ ≤ 2∆0 + E [︀𝐺0]︀ , (58) 𝛾𝑇 (1 − (1 − 𝛼)(1 − 𝐴1))𝑇

where 𝑥ˆ𝑇 is sampled uniformly at random from the points {𝑥0, 𝑥1, . . . , 𝑥𝑇 −1} produced by 3PCv3, ∆0 = 𝑓 (𝑥0) − 𝑓 inf , and 𝐺0 is deﬁned in (15).

2. If additionaly Assumption 5.7 hold and 0

≤

𝛾

≤

1/𝑀 for 𝑀

=

{︁

}︁

√︀

max 𝐿− + 𝐿+ 2(1−𝛼)𝐵1/(1−(1−𝛼)(1−𝐴1)), 1−(1−𝛼)(1−𝐴1)/2𝜇 , then for any 𝑇 ≥ 0 we have

(︂ E [︀𝑓 (𝑥𝑇 ) − 𝑓 (𝑥*)]︀ ≤ (1 − 𝛾𝜇)𝑇 ∆0 +

𝛾

)︂ E [︀𝐺0]︀ .

(59)

1 − (1 − 𝛼)(1 − 𝐴1)

27

Using this and Corollaries 5.6, 5.9, we get the following complexity results. Corollary C.19. 1. Let the assumptions from the ﬁrst part of Theorem C.18 hold and

1

𝛾 = √︁ .

𝐿− + 𝐿+

(1−𝛼)𝐵1 1−(1−𝛼)(1−𝐴1 )

Then for any 𝑇 we have

(︁

√︁

)︁

[︁

2]︁

2∆0 𝐿− + 𝐿+

(1−𝛼)𝐵1 1−(1−𝛼)(1−𝐴 )

E [︀𝐺0]︀

E

⃦ ⃦∇

𝑓

(𝑥ˆ

𝑇

⃦ )⃦

≤

1+

,

𝑇

(1 − (1 − 𝛼)(1 − 𝐴1))𝑇

i.e.,

to

achieve

E

[︁ ⃦ ⃦∇𝑓

(𝑥ˆ𝑇

⃦2]︁ )⃦

≤

𝜀2

for

some

𝜀

>

0

the

method

requires

⎛

∆0

(︁ 𝐿−

+

)︁ √︀ 𝐿+ (1−𝛼)𝜔/𝛼

⎞ E [︀𝐺0]︀

𝑇 = 𝒪 ⎝ 𝜀2

+ (1 − (1 − 𝛼)(1 − 𝐴1))𝜀2 ⎠

(60)

iterations/communication rounds.

2. Let the assumptions from the second part of Theorem C.18 hold and

⎧

⎫

𝛾 = min ⎨ 1 , 1 − (1 − 𝛼)(1 − 𝐴1) ⎬ .

√︁

⎩ 𝐿− + 𝐿+

2(1−𝛼)𝐵1 1−(1−𝛼)(1−𝐴1 )

2𝜇 ⎭

Then to achieve E [︀𝑓 (𝑥𝑇 ) − 𝑓 (𝑥*)]︀ ≤ 𝜀 for some 𝜀 > 0 the method requires

⎛ ⎧⎨ 𝐿− + 𝐿+√︁ (1−𝛼)𝐵1

⎫

⎞

⎬ ∆0 + E [︀𝐺0]︀

𝛾

𝒪 ⎝max

1−(1−𝛼)(1−𝐴1) , 1 − (1 − 𝛼)(1 − 𝐴1) log

1−(1−𝛼)(1−𝐴1 )
⎠

(61)

⎩𝜇

⎭𝜀

iterations/communication rounds.

28

C.7. 3PCv4 (NEW)
We now present another special case of 3PC compressor – 3PCv4. This compressor can be seen as modiﬁcation of 3PCv2 that uses only biased compression operators.

Algorithm 8 3PCv4

1: Input: starting point 𝑥0, stepsize 𝛾, number of iterations 𝑇 , starting vectors 𝑔𝑖0, 𝑖 ∈ [𝑛]

2: for 𝑡 = 0,1, . . . ,𝑇 − 1 do

3: Broadcast 𝑔𝑡 to all workers

4: for 𝑖 = 1, . . . ,𝑛 in parallel do

5:

𝑥𝑡+1 = 𝑥𝑡 − 𝛾𝑔𝑡

6:

Compute 𝑏𝑡𝑖 = 𝑔𝑖𝑡 + 𝒞2(∇𝑓𝑖(𝑥𝑡+1) − 𝑔𝑖𝑡)

7:

Set 𝑔𝑖𝑡+1 = 𝑏𝑡𝑖 + 𝒞1 (︀∇𝑓𝑖(𝑥𝑡+1) − 𝑏𝑡𝑖)︀

8: end for

9:

𝑔𝑡+1

=

1 𝑛

∑︀𝑛
𝑖=1

𝑔𝑖𝑡+1

10: end for

11: Return: 𝑥ˆ𝑇 chosen uniformly at random from {𝑥𝑡}𝑇𝑡=−01

Lemma C.20. Let 𝒞1 and 𝒞2 are the contracive compressors with constants 𝛼1 and 𝛼2 respectively. Then the compressor deﬁned as

𝒞ℎ,𝑦(𝑥) := ℎ + 𝒞2(𝑥 − ℎ) + 𝒞1 (𝑥 − (ℎ + 𝒞2(𝑥 − ℎ)))) ,

(62)

√ which satisﬁes (6) with 𝐴 := 1 − 1 − 𝛼¯ and 𝐵 := 1√−𝛼¯ , where 𝛼¯ := 1 − (1 − 𝛼1)(1 − 𝛼2).
1− 1−𝛼¯

Proof. Let 𝑎 := ℎ + 𝒞2(𝑥 − ℎ). Then

E

[︁ ‖𝒞ℎ,𝑦

(𝑥)

−

𝑥‖2

]︁

=

E

[︁ E

[︁ ‖𝒞ℎ,𝑦 (𝑥)

−

𝑥‖2

|

]︁]︁ 𝑎

=

E

[︁ E

[︁ ‖𝑎

+

𝒞1(𝑥

−

𝑎)

−

𝑥‖2

|

]︁]︁ 𝑎

≤

(1

−

𝛼1

)E

[︁ ‖𝑥

−

𝑎‖2

]︁

=

(1

−

𝛼1

)E

[︁ ‖𝑥

−

(ℎ

+

𝒞2

(𝑥

−

ℎ))‖2

]︁

≤

(1

−

𝛼1

)(1

−

𝛼2

)E

[︁ ‖𝑥

−

ℎ‖2

]︁

≤ (1 − 𝛼1)(1 − 𝛼2)(1 + 𝑠) ‖ℎ − 𝑦‖2 + (1 − 𝛼1)(1 − 𝛼2) (︀1 + 𝑠−1)︀ ‖𝑥 − 𝑦‖2 (63)

Optimal 𝑠 parameter can be found by direct minimization of the fraction (see Lemma C.3)

𝐵(𝑠) (1 − 𝛼¯) (︀1 + 𝑠−1)︀

=

,

𝐴(𝑠) 1 − (1 − 𝛼¯)(1 + 𝑠)

√ where 𝛼¯ := 1 − (1 − 𝛼1)(1 − 𝛼2). Using Lemma C.3 we ﬁnally obtain 𝐴(𝑠*) := 1 − 1 − 𝛼¯ and 𝐵(𝑠*) := 1√−𝛼¯
1− 1−𝛼¯

Therefore, 3PCv4 ﬁts our framework. Using our general analysis (Theorems 5.5 and 5.8) we derive the following result. √
Theorem C.21. 3PCv4 is a special case of the method from (12)–(13) with 𝒞ℎ,𝑦(𝑥) deﬁned in (51) and 𝐴 := 1 − 1 − 𝛼¯ and 𝐵 := 1−1√−1𝛼¯−𝛼¯ , where 𝛼¯ := 1 − (1 − 𝛼1)(1 − 𝛼2).

1. If Assumptions 5.1, 5.2, 5.3 hold and the stepsize 𝛾 satisﬁes 0 ≤ 𝛾 ≤ 1/𝑀, where 𝑀 = 𝐿− + 𝐿+√︀(1−𝛼¯)/(1−√1−𝛼¯)2,
then for any 𝑇 ≥ 0 we have E [︁⃦⃦∇𝑓 (𝑥ˆ𝑇 )⃦⃦2]︁ ≤ 2∆0 + E√[︀𝐺0]︀ , (64) 𝛾𝑇 (1 − 1 − 𝛼¯)𝑇

29

where 𝑥ˆ𝑇 is sampled uniformly at random from the points {𝑥0, 𝑥1, . . . , 𝑥𝑇 −1} produced by 3PCv4, ∆0 = 𝑓 (𝑥0) − 𝑓 inf , and 𝐺0 is deﬁned in (15).

2.

If additionaly Assumption 5.7 hold and 0

≤

𝛾

≤

1/𝑀

for 𝑀

=

max

{︁ 𝐿−

+

𝐿+√︀2(1−𝛼¯)/(1−√1−𝛼¯)2,

√

}︁

1− 1−𝛼¯/2𝜇 ,

then for any 𝑇 ≥ 0 we have

(︂ E [︀𝑓 (𝑥𝑇 ) − 𝑓 (𝑥*)]︀ ≤ (1 − 𝛾𝜇)𝑇 ∆0 +

𝛾 √

)︂ E [︀𝐺0]︀ .

(65)

1 − 1 − 𝛼¯

Using this and Corollaries 5.6, 5.9, we get the following complexity results. Corollary C.22. 1. Let the assumptions from the ﬁrst part of Theorem C.21 hold and

1 𝛾 = 𝐿− + 𝐿+√︀(1−𝛼¯)/(1−√1−𝛼¯)2 .

Then for any 𝑇 we have

[︁

2]︁ 2∆0 (︁𝐿− + 𝐿+√︀(1−𝛼¯)/(1−√1−𝛼¯)2)︁

E [︀𝐺0]︀

E

⃦ ⃦∇

𝑓

(𝑥ˆ

𝑇

⃦ )⃦

≤

+√

,

𝑇

(1 − 1 − 𝛼¯)𝑇

i.e.,

to

achieve

E

[︁ ⃦ ⃦∇𝑓

(𝑥ˆ𝑇

⃦2]︁ )⃦

≤

𝜀2

for

some

𝜀

>

0

the

method

requires

⎛

∆0

(︁ 𝐿−

+

)︁ √︀ 𝐿+ (1−𝛼¯)/𝛼¯2

⎞ E [︀𝐺0]︀

𝑇 = 𝒪 ⎝ 𝜀2

+ 𝛼¯𝜀2 ⎠

(66)

iterations/communication rounds.

2. Let the assumptions from the second part of Theorem C.21 hold and

{︃

√ }︃

1

1 − 1 − 𝛼¯

𝛾 = min 𝐿− + 𝐿+√︀2(1−𝛼¯)/(1−√1−𝛼¯)2 , 2𝜇 .

Then to achieve E [︀𝑓 (𝑥𝑇 ) − 𝑓 (𝑥*)]︀ ≤ 𝜀 for some 𝜀 > 0 the method requires

(︃

{︃

√︀

}︃

𝐿− + 𝐿+ (1−𝛼¯)/𝛼¯2

∆0 + E [︀𝐺0]︀ 𝛾/𝛼¯ )︃

𝒪 max

, 𝛼¯ log

(67)

𝜇

𝜀

iterations/communication rounds.

30

C.8. 3PCv5 (NEW) In this section, we consider a version of MARINA that uses biased compression instead of unbiased one.

Algorithm 9 Biased MARINA (3PCv5)

1: Input: starting point 𝑥0, stepsize 𝛾, probability 𝑝 ∈ (0,1], number of iterations 𝑇 , starting vectors 𝑔𝑖0, 𝑖 ∈ [𝑛] 2: for 𝑡 = 0,1, . . . ,𝑇 − 1 do

3: Sample 𝑐𝑡 ∼ Be(𝑝) 4: Broadcast 𝑔𝑡 to all workers

5: for 𝑖 = 1, . . . ,𝑛 in parallel do

6:

𝑥𝑡+1 = 𝑥𝑡 − 𝛾𝑔𝑡

{︃

𝑡+1

∇𝑓𝑖(𝑥𝑡+1),

if 𝑐𝑡 = 1,

7: Set 𝑔𝑖 = 𝑔𝑖𝑡 + 𝒞 (︀∇𝑓𝑖(𝑥𝑡+1) − ∇𝑓𝑖(𝑥𝑡)))︀ , if 𝑐𝑡 = 0

8: end for

9:

𝑔𝑡+1

=

1 𝑛

∑︀𝑛
𝑖=1

𝑔𝑖𝑡+1

10: end for

11: Return: 𝑥ˆ𝑇 chosen uniformly at random from {𝑥𝑡}𝑇𝑡=−01

The next lemma shows that 3PCv5 uses a special three points compressor. Lemma C.23. The compressor

{︃

𝑥,

w.p. 𝑝

𝒞ℎ,𝑦(𝑥) =

(68)

ℎ + 𝒞(𝑥 − 𝑦), w.p. 1 − 𝑝

satisﬁes (6) with 𝐴 = 𝑝 − 𝑠(1 − 𝑝) and 𝐵 = (1 − 𝑝) (︀1 + 𝑠−1)︀ (1 − 𝛼), where 𝑠 > 0 is such that (1 − 𝑝)(1 + 𝑠) < 1.

Proof. By deﬁnition of 𝒞ℎ,𝑦(𝑥) and 𝒞 we have

E

[︁ ‖𝒞ℎ,𝑦

(𝑥)

−

𝑥‖2

]︁

(=68)

(1

−

𝑝)E

[︁ ‖ℎ

+

𝒞

(𝑥

−

𝑦

)

−

𝑥‖2

]︁

=

(1

−

𝑝)E

[︁ ‖ℎ

−

𝑦

+

𝒞(𝑥

−

𝑦)

−

(𝑥

−

𝑦)‖2]︁

≤

(1

−

𝑝)(1

+

𝑠)

‖ℎ

−

𝑦‖2

+

(1

−

𝑝)

(︀1

+

𝑠−1)︀

E

[︁ ‖𝒞(𝑥

−

𝑦)

−

(𝑥

−

𝑦)‖2]︁

≤ (1 − 𝑝)(1 + 𝑠) ‖ℎ − 𝑦‖2 + (1 − 𝑝) (︀1 + 𝑠−1)︀ (1 − 𝛼) ‖𝑥 − 𝑦‖2 ,

where in the third row we use that ‖𝑎 + 𝑏‖2 ≤ (1 + 𝑠)‖𝑎‖2 + (1 + 𝑠−1)‖𝑏‖2 for all 𝑠 > 0, 𝑎,𝑏 ∈ R𝑑. Assuming (1 − 𝑝)(1 + 𝑠) < 1, we get the result.

Therefore, 3PCv5 ﬁts our framework. Using our general analysis (Theorems 5.5 and 5.8) we derive the following result. Theorem C.24. 3PCv5 is a special case of the method from (12)–(13) with 𝒞ℎ,𝑦(𝑥) deﬁned in (68) and 𝐴 = 𝑝 − 𝑠(1 − 𝑝) and 𝐵 = (1 − 𝑝) (︀1 + 𝑠−1)︀ (1 − 𝛼), where 𝑠 > 0 is such that (1 − 𝑝)(1 + 𝑠) < 1.
1. If Assumptions 5.1, 5.2, 5.3 hold and the stepsize 𝛾 satisﬁes 0 ≤ 𝛾 ≤ 1/𝑀, where 𝑀 = 𝐿− + √︁
𝐿+ (1−𝑝)(1+𝑠−1)(1−𝛼)/(𝑝−𝑠(1−𝑝)), then for any 𝑇 ≥ 0 we have
E [︁⃦⃦∇𝑓 (𝑥ˆ𝑇 )⃦⃦2]︁ ≤ 2∆0 + E [︀𝐺0]︀ , (69) 𝛾𝑇 (𝑝 − 𝑠(1 − 𝑝))𝑇
where 𝑥ˆ𝑇 is sampled uniformly at random from the points {𝑥0, 𝑥1, . . . , 𝑥𝑇 −1} produced by 3PCv5, ∆0 = 𝑓 (𝑥0) − 𝑓 inf , and 𝐺0 is deﬁned in (15).

31

2. If additionaly Assumption 5.7 hold and 0

≤

𝛾

≤

1/𝑀 for 𝑀

=

{︂

√︁

}︂

max 𝐿− + 𝐿+ 2(1−𝑝)(1+𝑠−1)(1−𝛼)/(𝑝−𝑠(1−𝑝)), (𝑝−𝑠(1−𝑝))/2𝜇 , then for any 𝑇 ≥ 0 we have

(︂ E [︀𝑓 (𝑥𝑇 ) − 𝑓 (𝑥*)]︀ ≤ (1 − 𝛾𝜇)𝑇 ∆0 +

𝛾

)︂ E [︀𝐺0]︀ .

(70)

𝑝 − 𝑠(1 − 𝑝)

Neglecting the term that depends on 𝐺0 (for simplicity, one can assume that 𝑔𝑖0 = ∇𝑓𝑖(𝑥0) for 𝑖 ∈ [𝑛]), one can notice that the smaller 𝐵/𝐴, the better the rate. Considering 𝐵/𝐴 as a function of 𝑠 and optimizing this function in 𝑠, we ﬁnd the optimal
value of this ratio.

Lemma C.25. The optimal value of

𝐵

(1 − 𝑝) (︀1 + 𝑠−1)︀ (1 − 𝛼)

(𝑠) =

𝐴

(𝑝 − 𝑠(1 − 𝑝))

under the constraint 0 < 𝑠 < 𝑝/(1−𝑝) equals

𝐵

(1 − 𝑝)(1 − 𝛼) 4(1 − 𝑝)(1 − 𝛼)

𝐴 (𝑠*) = (1 − √1 − 𝑝)2 ≤

𝑝2

and

it

is

achieved

at

𝑠*

=

−1

+

√︀ 1/(1−𝑝).

Proof. First of all, we ﬁnd the derivative of the considered function:

(︂ 𝐵 )︂′

(1 − 𝑝)𝑠2 + 2(1 − 𝑝)𝑠 − 𝑝

𝐴 (𝑠) = (1 − 𝑝)(1 − 𝛼) (𝑝𝑠 − 𝑠2(1 − 𝑝))2 .

√︀

√︀

The function has 2 critical points: −1 ± 1/(1−𝑝). Moreover, the derivative is non-positive for 𝑠 ∈ (0, −1 + 1/(1−𝑝)] and

√︀ negative for 𝑠 ∈ (−1 + 1/(1−𝑝), +∞). This implies that the optimal value on the interval 𝑠 ∈ (0, 𝑝/(1−𝑝)) is achieved at

√︀ 𝑠* = −1 + 1/(1−𝑝). Via simple computations one can verify that

√ Finally, since 1 − 1 − 𝑝 ≥ 𝑝/2, we have

𝐵

(1 − 𝑝)(1 − 𝛼)

𝐴 (𝑠*) = (1 − √1 − 𝑝)2 .

𝐵

4(1 − 𝑝)(1 − 𝛼)

𝐴 (𝑠*) ≤

𝑝2 .

Using this and Corollaries 5.6, 5.9, we get the following complexity results. √︀
Corollary C.26. 1. Let the assumptions from the ﬁrst part of Theorem C.24 hold, 𝑠 = 𝑠* = −1 + 1/(1−𝑝), and

1 𝛾 = 𝐿− + 𝐿+√︀(1−𝑝)(1−𝛼)/(1−√1−𝑝)2 .

Then for any 𝑇 we have

[︁

2]︁ 2∆0 (︁𝐿− + 𝐿+√︀(1−𝑝)(1−𝛼)/(1−√1−𝑝)2)︁

E [︀𝐺0]︀

E

⃦ ⃦∇

𝑓

(𝑥ˆ

𝑇

)

⃦ ⃦

≤

+√

,

𝑇

(1 − 1 − 𝑝)𝑇

i.e.,

to

achieve

E

[︁ ⃦ ⃦∇𝑓

(𝑥ˆ𝑇

⃦2]︁ )⃦

≤

𝜀2

for

some

𝜀

>

0

the

method

requires

⎛

∆0

(︁ 𝐿−

+

)︁ √︀ 𝐿+ (1−𝑝)(1−𝛼)/𝑝2

⎞ E [︀𝐺0]︀

𝑇 = 𝒪 ⎝ 𝜀2

+ 𝑝𝜀2 ⎠

(71)

iterations/communication rounds.

32

2. Let the assumptions from the second part of Theorem C.24 hold and

{︃

√ }︃

1

1− 1−𝑝

𝛾 = min 𝐿− + 𝐿+√︀2(1−𝑝)(1−𝛼)/(1−√1−𝑝)2 , 2𝜇 .

Then to achieve E [︀𝑓 (𝑥𝑇 ) − 𝑓 (𝑥*)]︀ ≤ 𝜀 for some 𝜀 > 0 the method requires

(︃

{︃

√︀

}︃

𝐿− + 𝐿+ (1−𝑝)(1−𝛼)/𝑝2

∆0 + E [︀𝐺0]︀ 𝛾/𝑝 )︃

𝒪 max

, 𝑝 log

(72)

𝜇

𝜀

iterations/communication rounds.

33

D. MARINA
In this section, we show that MARINA (Gorbunov et al., 2021) can be analyzed using a similar proof technique that we use for the methods based on three points compressors.

Algorithm 10 MARINA (Gorbunov et al., 2021)

1: Input: starting point 𝑥0, stepsize 𝛾, probability 𝑝 ∈ (0,1], number of iterations 𝑇

2: Initialize 𝑔0 = ∇𝑓 (𝑥0)

3: for 𝑡 = 0,1, . . . ,𝑇 − 1 do

4: Sample 𝑐𝑡 ∼ Be(𝑝) 5: Broadcast 𝑔𝑡 to all workers

6: for 𝑖 = 1, . . . ,𝑛 in parallel do

7:

𝑥𝑡+1 = 𝑥𝑡 − 𝛾𝑔𝑡

{︃

𝑡+1

∇𝑓𝑖(𝑥𝑡+1),

if 𝑐𝑡 = 1,

8: Set 𝑔𝑖 = 𝑔𝑖𝑡 + 𝒬 (︀∇𝑓𝑖(𝑥𝑡+1) − ∇𝑓𝑖(𝑥𝑡)))︀ , if 𝑐𝑡 = 0

9: end for

10:

𝑔𝑡+1

=

1 𝑛

∑︀𝑛
𝑖=1

𝑔𝑖𝑡+1

11: end for

12: Return: 𝑥ˆ𝑇 chosen uniformly at random from {𝑥𝑡}𝑇𝑡=−01

The next lemma casts MARINA to our theoretical framework.
Lemma D.1. Let Assumption 5.3 hold. Then, MARINA satisﬁes inequality (16) with 𝐺𝑡 = ‖𝑔𝑡 − ∇𝑓 (𝑥𝑡)‖2, 𝐴 = 𝑝, and 𝐵 = (1−𝑝)𝜔/𝑛.

Proof. The formula for 𝑔𝑖𝑡+1 implies that

⎧∇𝑓 (𝑥𝑡+1), ⎨ 𝑔𝑡+1 = ⎩𝑔𝑡 + 𝑛1 ∑𝑛︀ 𝒬 (︀∇𝑓𝑖(𝑥𝑡+1) − ∇𝑓𝑖(𝑥𝑡)))︀ ,
𝑖=1

if 𝑐𝑡 = 1, if 𝑐𝑡 = 0.

Using this and independence of 𝒬 (︀∇𝑓𝑖(𝑥𝑡+1) − ∇𝑓𝑖(𝑥𝑡)))︀ for 𝑖 ∈ [𝑛] and ﬁxed 𝑥𝑡,𝑥𝑡+1, we derive

E [︀𝐺𝑡+1]︀

=

E

[︁ ⃦⃦𝑔𝑡+1

−

∇𝑓

(𝑥𝑡+1)⃦⃦2]︁

⎡

⃦

𝑛

⃦2⎤

= (1 − 𝑝)E ⎣⃦⃦𝑔𝑡 + 1 ∑︁ 𝒬 (︀∇𝑓𝑖(𝑥𝑡+1) − ∇𝑓𝑖(𝑥𝑡)))︀ − ∇𝑓 (𝑥𝑡+1)⃦⃦ ⎦

⃦⃦ 𝑛 𝑖=1 ⃦⃦

⎡

⃦

𝑛

⃦2⎤

= (1 − 𝑝)E ⎣⃦⃦𝑔𝑡 − ∇𝑓 (𝑥𝑡) + 1 ∑︁ 𝒬 (︀∇𝑓𝑖(𝑥𝑡+1) − ∇𝑓𝑖(𝑥𝑡)))︀ − (︀∇𝑓 (𝑥𝑡+1) − ∇𝑓 (𝑥𝑡))︀⃦⃦ ⎦

⃦⃦ 𝑛 𝑖=1 ⃦⃦

(=22)

(1

−

𝑝)E

[︁ ⃦⃦𝑔𝑡

−

∇𝑓

(𝑥𝑡)⃦⃦2]︁

⎡ ⃦𝑛

⃦2⎤

+(1 − 𝑝)E ⎣⃦⃦ 1 ∑︁ (︀𝒬 (︀∇𝑓𝑖(𝑥𝑡+1) − ∇𝑓𝑖(𝑥𝑡)))︀ − (︀∇𝑓𝑖(𝑥𝑡+1) − ∇𝑓𝑖(𝑥𝑡))︀)︀⃦⃦ ⎦

⃦⃦ 𝑛 𝑖=1 ⃦⃦

1

−

𝑝

𝑛
∑︁

[︁

2]︁

= (1 − 𝑝)E [︀𝐺𝑡]︀ +

E

⃦ ⃦𝒬

(︀∇𝑓𝑖

(𝑥𝑡+1

)

−

∇𝑓𝑖

(𝑥𝑡

)))︀

−

(︀∇𝑓𝑖

(𝑥𝑡+1

)

−

∇𝑓𝑖

(𝑥𝑡

))︀⃦⃦

𝑛2

𝑖=1

(22)

[︀ 𝑡]︀ (1 − 𝑝)𝜔 ∑𝑛︁ [︁⃦ 𝑡+1

𝑡 ⃦2]︁

= (1 − 𝑝)E 𝐺 + 𝑛2

E ⃦∇𝑓𝑖(𝑥 ) − ∇𝑓𝑖(𝑥 )⃦ .

𝑖=1

It remains to apply Assumption 5.3 to get the result.

34

We notice that the proofs of Theorems 5.5 and 5.8 rely only on the inequality (16), the update rule 𝑥𝑡+1 = 𝑥𝑡 − 𝛾𝑔𝑡, and the fact that 𝐺𝑡 ≥ ‖𝑔𝑡 − ∇𝑓 (𝑥𝑡)‖2. Therefore, using Lemma D.1 and our general results (Theorems 5.5 and 5.8), we recover the rates for MARINA from Gorbunov et al. (2021).
Theorem D.2. 1. If Assumptions 5.1, 5.2, 5.3 hold and the stepsize 𝛾 satisﬁes 0 ≤ 𝛾 ≤ 1/𝑀, where 𝑀 = 𝐿− + √︀
𝐿+ (1−𝑝)𝜔/𝑛𝑝, then for any 𝑇 ≥ 0 we have

E [︁⃦⃦∇𝑓 (𝑥ˆ𝑇 )⃦⃦2]︁ ≤ 2∆0 + E [︀𝐺0]︀ , (73)

𝛾𝑇

𝑝𝑇

where 𝑥ˆ𝑇 is sampled uniformly at random from the points {𝑥0, 𝑥1, . . . , 𝑥𝑇 −1} produced by MARINA, ∆0 = 𝑓 (𝑥0) − 𝑓 inf , and 𝐺0 is deﬁned in (15).

{︁

}︁

√︀

2. If additionaly Assumption 5.7 hold and 0 ≤ 𝛾 ≤ 1/𝑀 for 𝑀 = max 𝐿− + 𝐿+ 2(1−𝑝)𝜔/𝑛𝑝, 𝑝/2𝜇 , then for any

𝑇 ≥ 0 we have

E

[︀𝑓 (𝑥𝑇

)

−

𝑓 (𝑥*)]︀

≤

(1

−

𝛾𝜇)𝑇

(︂ ∆0

+

𝛾

E

)︂ [︀𝐺0]︀

.

(74)

𝑝

Next, this theorem and Corollaries 5.6 and 5.9 imply the following complexity results. Corollary D.3. 1. Let the assumptions from the ﬁrst part of Theorem D.2 hold and

1 𝛾 = √︀ .
𝐿− + 𝐿+ (1−𝑝)𝜔/𝑛𝑝

Then for any 𝑇 we have

(︁

)︁

[︁

2]︁ 2∆0 𝐿− + 𝐿+√︀(1−𝑝)𝜔/𝑛𝑝 E [︀𝐺0]︀

E

⃦ ⃦∇

𝑓

(

𝑥ˆ

𝑇

⃦ )⃦

≤

+

,

𝑇

𝑝𝑇

i.e.,

to

achieve

E

[︁ ⃦ ⃦∇𝑓

(𝑥ˆ𝑇

⃦2]︁ )⃦

≤

𝜀2

for

some

𝜀

>

0

the

method

requires

⎛

∆0

(︁ 𝐿−

+

)︁ √︀ 𝐿+ (1−𝑝)𝜔/𝑛𝑝

⎞ E [︀𝐺0]︀

𝑇 = 𝒪 ⎝ 𝜀2

+ 𝑝𝜀2 ⎠

(75)

iterations/communication rounds.

2. Let the assumptions from the second part of Theorem D.2 hold and

{︃

}︃

1

𝑝

𝛾 = min

,.

√︀ 𝐿− + 𝐿+ 2(1−𝑝)𝜔/𝑛𝑝

2𝜇

Then to achieve E [︀𝑓 (𝑥𝑇 ) − 𝑓 (𝑥*)]︀ ≤ 𝜀 for some 𝜀 > 0 the method requires

(︃

{︃

√︀

}︃

𝐿− + 𝐿+ (1−𝑝)𝜔/𝑛𝑝

∆0 + E [︀𝐺0]︀ 𝛾/𝑝 )︃

𝒪 max

, 𝑝 log

(76)

𝜇

𝜀

iterations/communication rounds.

35

E. More Experiments
This section is organized as follows. We report more details on the experiment with autoencoder in Appendix E.1. In Appendix E.2, we validate the new methods 3PCv1, . . . , 3PCv5 on a synthetic quadratic problem with a careful control of heterogenity level. Finally, in Appendix E.3, we provide additional experiments with compressed lazy aggregation CLAG. We refer the reader to Appendices A and C for a formal deﬁnition of the algorithms and compressors. All methods are implemented in Python 3.8 and run on 3 different CPU cluster nodes
• AMD EPYC 7702 64-Core; • Intel(R) Xeon(R) Gold 6148 CPU @ 2.40GHz; • Intel(R) Xeon(R) Gold 6248 CPU @ 2.50GHz.
Communication between server and clients is emulated in one computing node.

E.1. Learning autoencoder model
In this set of experiments, we test the proposed optimization methods on the task of learning a representation of MNIST dataset (LeCun et al., 2010). We recall that we consider the following optimization problem

[︃

1

𝑁
∑︁

]︃
2

min

𝑓 (𝐷, 𝐸) :=

‖𝐷𝐸𝑎𝑖 − 𝑎𝑖‖ ,

𝐷∈R𝑑𝑓 ×𝑑𝑒 ,𝐸∈R𝑑𝑒×𝑑𝑓

𝑁 𝑖=1

(77)

where 𝑎𝑖 are ﬂattened represenations of images with 𝑑𝑓 = 784, 𝐷 and 𝐸 are learned parameters of the autoencoder model. We ﬁx the encoding dimensions as 𝑑𝑒 = 16 and distribute the data samples across 𝑛 = 10, 100, or 1000 clients. In order to control the heterogenity of this distribution, we use the following randomized procedure. First, split the dataset randomly into 𝑛 + 1 equal parts 𝐷0, 𝐷1, . . . , 𝐷𝑛 and ﬁx the homogenity level parameter 0 ≤ 𝑝ˆ ≤ 1. Then let the 𝑖-th client take 𝐷0 with probability 𝑝ˆ or 𝐷𝑖 otherwise. If 𝑝ˆ = 1, we are in homogeneous regime. If 𝑝ˆ = 0, all clients have different randomly shufﬂed data samples. Additionally, we study even more heterogeneous setting where we perform the split by labels. This means that the clients from 1 to 𝑛/10 own the images corresponding to the ﬁrst class, nodes from 𝑛/10 + 1 to 2𝑛/10 own the images corresponding to the second class and so on (MNIST dataset has 10 different classes).

In this section, we choose 𝐾 = 𝑑/𝑛, where 𝑑 = 2 · 𝑑𝑓 · 𝑑𝑒 = 25088 is the total dimension of learning parameters 𝐷 and 𝐸. It is argued by (Szlendak et al., 2021) that this is a suitable choice for MARINA method with Rand-𝐾 or Perm-𝐾 sparsiﬁers. Methods involving two compressor such as 3PCv2, require to communicate two sparse sequences at every communication round. To account for this, we select 𝐾1, 𝐾2 from the set {𝐾/2, 𝐾}, that is there are four possible choices for compression levels 𝐾1, 𝐾2 of two sparsiﬁers in 3PCv2. Then we select the pair which works best.
We ﬁne-tune every method with the step-sizes from the set {2−12, 2−11, . . . , 25} and select the best run based on the value of ‖∇𝑓 (𝑥𝑡)‖2 at the last iterate. The step-size for each method is indicated in the legend of each plot.

EF21 embraces different sparsiﬁers. Since Seide et al. (2014) proposed the error feedback style scheme, it has been successfully used in distributed training combined with some contractive compressor. A popular choice is Top-𝐾, which preserves the ”most important” coordinates and shows empirical superiority. However, a natural question arises:

Is the success of EF21 with Top-𝐾 attributed to a careful algorithm design or to a greedy sparsiﬁer in use?

We compare EF21 with three different compressors: Top-𝐾, cPerm-𝐾, cRand-𝐾 in Figure 3. MARINA with Perm-𝐾 is added for the reference. In all cases, Top-𝐾 demonstrates fast improvement in the ﬁrst communication rounds. When 𝑛 = 10, the randomized compressors (cPerm-𝐾 and cRand-𝐾) work best for EF21. When 𝑛 = 100 the picture is similar, but cPerm-𝐾 shows better performance than cRand-𝐾 when homogenity level is high (1 or 0.5). Finally, Top-𝐾 wins in the competition for 𝑛 = 1000.
Takeaway 1: EF21 is well designed and works well with different contractive compressors, including the randomized ones.
Takeaway 2: EF21 combined with Top-𝐾 is particularly useful if

36

|| f(xt)||2

|| f(xt)||2

Number of clients 𝑛 = 10, compression level 𝐾 = 2509.

Homogenity level: 1

Homogenity level: 0.5

Homogenity level: 0

100

EF21-TopK: 20 EF21-cPermK: 23

100

EF21-TopK: 20 EF21-cPermK: 23

100

EF21-TopK: 20 EF21-cPermK: 23

100

EF21-cRandK: 23

EF21-cRandK: 23

EF21-cRandK: 23

10 1

MARINA-PermK: 2 2 10 1

MARINA-PermK: 2 3 10 1

MARINA-PermK: 2 3 10 1

Split by labels EF21-TopK: 20 EF21-cPermK: 21 EF21-cRandK: 21 MARINA-PermK: 2 3

|| f(xt)||2

|| f(xt)||2

|| f(xt)||2

10 2

10 2

10 2

10 2

10 3 0
100 10 1 10 2 10 3
0
101 100 10 1 10 2 10 3 10 4
0

10 #20Mbits 3/ 0n 40 50
Homogenity level: 1 EF21-TopK: 2 3 EF21-cPermK: 22 EF21-cRandK: 22 MARINA-PermK: 2 2

10 3

10 3

0 10 #20Mbits 3/ 0n 40 50 0 10 #20Mbits 3/ 0n 40 50

Number of clients 𝑛 = 100, compression level 𝐾 = 251.

Homogenity level: 0.5

Homogenity level: 0

EF21-TopK: 2 3

EF21-TopK: 2 3

100

EF21-cPermK: 22 EF21-cRandK: 22

100

EF21-cPermK: 22 EF21-cRandK: 22

10 1

MARINA-PermK: 2 2 10 1

MARINA-PermK: 2 2

10 3 0
100 10 1

|| f(xt)||2

|| f(xt)||2

|| f(xt)||2

10 2

10 2

10 2

10 #20Mbits3/0n 40 50 Homogenity level: 1 EF21-TopK: 21 EF21-cPermK: 21 EF21-cRandK: 20 MARINA-PermK: 20
10 #M2b0its / n 30 40

|| f(xt)||2

10 3

10 3

0 10 #20Mbits3/0n 40 50

0 10 #20Mbits3/0n 40 50

Number of clients 𝑛 = 1000, compression level 𝐾 = 25.

Homogenity level: 0.5

101

EF21-TopK: 21

101

100

EF21-cPermK: 20 EF21-cRandK: 2 1

100

10 1

MARINA-PermK: 2 1 10 1

Homogenity level: 0 EF21-TopK: 21 EF21-cPermK: 2 1 EF21-cRandK: 2 1 MARINA-PermK: 2 1

|| f(xt)||2

10 2

10 2

10 3

10 3

10 4 0

10 #Mb2i0ts / n 30

10 4

40

0 10 #2M0bits / n30 40

|| f(xt)||2

10 3 0
101 100 10 1 10 2 10 3 10 4
0

10 #20Mbits 3/ 0n 40 50 Split by labels EF21-TopK: 2 3 EF21-cPermK: 21 EF21-cRandK: 21 MARINA-PermK: 2 2
10 #20Mbits3/0n 40 50 Split by labels EF21-TopK: 21 EF21-cPermK: 2 1 EF21-cRandK: 2 1 MARINA-PermK: 2 2
10 #2M0bits / n30 40

Figure 3: Comparison of EF21 with Top-𝐾, cPerm-𝐾 and cRand-𝐾 compressors. MARINA with Perm-𝐾 is provided for the reference.

|| f(xt)||2

• we are interested in the progress during the initial phase of training; • agressive sparsiﬁcation is applied (𝑘/𝑑 ≪ 1%) and 𝑛 is large; or • nodes own very different parts of dataset, i.e., we are in heterogeneous regime.

MARINA and greedy sparsiﬁcation (3PCv5) We now draw our attention to one of the newly proposed methods: MARINA combined with biased compression operators (named as 3PCv5 in Algorithm 9 and Table 1). According to our theory, see Table 1, 3PCv5 has the same compexity as EF21. In this experiment, we aim to validate the proposed method with greedy Top-𝐾 sparsiﬁer. We compare it to MARINA with Perm-𝐾 and Rand-𝐾 and include EF21 as a reference method. Interestingly, Top-𝐾 improves over Perm-𝐾 and Rand-𝐾 when 𝑛 = 10; in homogeneus case, the behavior of Top-𝐾 and Perm-𝐾 is similar, see Figure 4. However, this improvement vanishes when 𝑛 is increased (𝑛 = 100, 1000) and sparsiﬁcation is more agressive; MARINA with Top-𝐾 requires much smaller step-sizes to converge. In all cases, EF21 with Top-𝐾 is faster.
Other 3PC variants Motivated by the success of greedy sparsiﬁcation and favorable properties of randomized sparsiﬁers, we aim to investigate if one can combine the two in a nontrivial way and obtain even faster method. One possible way to do so is to look more closely to one of the special cases of 3PC named 3PCv2. With 3PCv2 (Algorithm 6), we have
37

|| f(xt)||2

|| f(xt)||2

Number of clients 𝑛 = 10, compression level 𝐾 = 2509.

Homogenity level: 1

Homogenity level: 0.5

Homogenity level: 0

10 1

3PCv5-TopK: 2 2 EF21-TopK: 20

10 1

3PCv5-TopK: 2 2 EF21-TopK: 20

10 1

3PCv5-TopK: 2 2 EF21-TopK: 20

10 1

MARINA-PermK: 2 2

MARINA-PermK: 2 3

MARINA-PermK: 2 3

MARINA-RandK: 2 3

MARINA-RandK: 2 3

MARINA-RandK: 2 3

|| f(xt)||2

|| f(xt)||2

|| f(xt)||2

10 2

10 2

10 2

10 2

Split by labels 3PCv5-TopK: 2 2 EF21-TopK: 20 MARINA-PermK: 2 3 MARINA-RandK: 2 3

0 10 1 10 2

10 #20Mbits 3/ 0n 40 50
Homogenity level: 1 3PCv5-TopK: 2 6 EF21-TopK: 2 3 MARINA-PermK: 2 2 MARINA-RandK: 2 2

0 10 #20Mbits 3/ 0n 40 50 0 10 #20Mbits 3/ 0n 40 50

Number of clients 𝑛 = 100, compression level 𝐾 = 251.

Homogenity level: 0.5

Homogenity level: 0

3PCv5-TopK: 2 6

3PCv5-TopK: 2 6

10 1

EF21-TopK: 2 3

10 1

EF21-TopK: 2 3

MARINA-PermK: 2 2

MARINA-PermK: 2 2

MARINA-RandK: 2 2

MARINA-RandK: 2 2

0 10 1

|| f(xt)||2

|| f(xt)||2

|| f(xt)||2

10 2

10 2

10 2

10 #20Mbits 3/ 0n 40 50
Split by labels 3PCv5-TopK: 2 6 EF21-TopK: 2 3 MARINA-PermK: 2 2 MARINA-RandK: 2 2

0
100 10 1 10 2 10 3 10 4
0

10 2#0Mbits3/0n 40 50 Homogenity level: 1 3PCv5-TopK: 2 10 EF21-TopK: 21 MARINA-PermK: 20 MARINA-RandK: 2 2
10 #M2b0its / n 30 40

|| f(xt)||2

0 10 2#0Mbits3/0n 40 50

0 10 #20Mbits3/0n 40 50

Number of clients 𝑛 = 1000, compression level 𝐾 = 25.

Homogenity level: 0.5

Homogenity level: 0

100

3PCv5-TopK: 2 10

100

3PCv5-TopK: 2 11

EF21-TopK: 21

EF21-TopK: 21

10 1

MARINA-PermK: 2 1 MARINA-RandK: 2 2

10 1

MARINA-PermK: 2 1 MARINA-RandK: 2 2

10 2

10 2

|| f(xt)||2

10 3

10 3

10 4 0

10 #M2b0its / n 30

10 4

40

0

10 #2M0bits / n30 40

|| f(xt)||2

0
100 10 1 10 2 10 3 10 4
0

10 #20Mbits3/0n 40 50 Split by labels 3PCv5-TopK: 2 11 EF21-TopK: 21 MARINA-PermK: 2 2 MARINA-RandK: 2 2
10 #2M0bits / n30 40

Figure 4: Comparison of MARINA with Perm-𝐾, Rand-𝐾 and 3PCv5 with Top-𝐾.

|| f(xt)||2

more freedom because it has two compressors. In our experiments, we consider three different sparsiﬁers (Top-𝐾, Rand-𝐾, Perm-𝐾) as for the ﬁrst compressor and ﬁx the second one as Top-𝐾, see Figure 5. For 𝑛 = 10, the performance of 3PCv2 with Rand-𝐾-Top-𝐾 and Top-𝐾-Top-𝐾 is very similar to the one of EF21 with Top𝐾. Interestingly, 3PCv2-Rand-𝐾-Top-𝐾 becomes superior for 𝑛 = 100 converging even faster than EF21. The difference is especially prominent in heterogeneous setting. Finally, EF21 shows slightly beter performance in the experiments with 1000 nodes. We can conclude that:
• 3PCv2 can outperform EF21 in some cases, for example, Appendix E.1,

• EF21 is still superior when 𝑛 is large.
However, more emprirical evidence is needed to investigate the behavior of 3PCv2 and other new methods ﬁtting 3PC framework.
38

Number of clients 𝑛 = 10, compression level 𝐾 = 2509.

Homogenity level: 1

Homogenity level: 0

Split by labels

10 1

3PCv2-PermK-TopK: 2 2 3PCv2-RandK-TopK: 20

10 1

3PCv2-PermK-TopK: 2 3 3PCv2-RandK-TopK: 20

10 1

3PCv2-PermK-TopK: 2 3 3PCv2-RandK-TopK: 20

3PCv2-TopK-TopK: 20

3PCv2-TopK-TopK: 20

3PCv2-TopK-TopK: 20

EF21-TopK: 20

EF21-TopK: 20

EF21-TopK: 20

|| f(xt)||2

|| f(xt)||2

10 2

10 2

10 2

|| f(xt)||2

|| f(xt)||2

|| f(xt)||2

0
101 100 10 1 10 2 10 3
0
100 10 1 10 2 10 3 10 4
0

10 #20Mbits /30n 40 50 0 10 #20Mbits /30n 40 50 0

Number of clients 𝑛 = 100, compression level 𝐾 = 251.

Homogenity level: 1 3PCv2-PermK-TopK: 21

101

Hom3oPgCevn2it-PyelermveKl-:T0opK: 2 2 101

3PCv2-RandK-TopK: 21 3PCv2-TopK-TopK: 2 2

100

3PCv2-RandK-TopK: 21 3PCv2-TopK-TopK: 2 2

100

EF21-TopK: 2 3

EF21-TopK: 2 3

10 1

10 1

|| f(xt)||2

|| f(xt)||2

10 2

10 2

10 #20Mbits /30n 40

10 3 50 0

10 #20Mbits /30n 40

10 3 50 0

Number of clients 𝑛 = 100, compression level 𝐾 = 25.

Homogenity level: 1

Homogenity level: 0

3PCv2-PermK-TopK: 2 1 100 3PCv2-RandK-TopK: 20 3PCv2-TopK-TopK: 21 10 1 EF21-TopK: 21
10 2

3PCv2-PermK-TopK: 20 100 3PCv2-RandK-TopK: 20 3PCv2-TopK-TopK: 21 10 1 EF21-TopK: 21
10 2

|| f(xt)||2

|| f(xt)||2

10 3

10 3

10 #20Mbits /30n 40

10 4

50

0

10 #20Mbits /30n 40

10 4

50

0

10 #20Mbits /30n 40 50 Split by labels 3PCv2-PermK-TopK: 2 2 3PCv2-RandK-TopK: 21 3PCv2-TopK-TopK: 2 2 EF21-TopK: 2 3
10 #20Mbits /30n 40 50 Split by labels 3PCv2-PermK-TopK: 20 3PCv2-RandK-TopK: 21 3PCv2-TopK-TopK: 21 EF21-TopK: 21
10 #20Mbits /30n 40 50

Figure 5: Comparison of 3PCv2 with Perm-𝐾, Rand-𝐾 and Top-𝐾 as the ﬁrst compressor. Top-𝐾 is used as the second compressor. EF21 with Top-𝐾 is provided for the reference.

E.2. Solving synthetic quadratic problem

In this experimental section we compare practical performance of the proposed methods 3PCv1, 3PCv2, 3PCv4, 3PCv5

against existing state-of-the-art methods for compressed distributed optimization MARINA and EF21. For this comparison

we set up the similar setting that was introduced in (Szlendak et al., 2021). Firstly, let us describe the experimental setup in

detail.

We

consider

the

ﬁnite

sum

function

𝑓 (𝑥)

=

1 𝑛

∑︀𝑛
𝑖=1

𝑓𝑖(𝑥),

consisting

of

synthetic

quadratic

functions

𝑓𝑖(𝑥) = 1 𝑥⊤A𝑖𝑥 − 𝑥⊤𝑏𝑖,

(78)

2

where A𝑖 ∈ R𝑑×𝑑, 𝑏𝑖 ∈ R𝑑, and A𝑖 = A⊤𝑖 is the training data that belongs to the device/worker 𝑖. In all experiments of

this

section,

we

have

𝑑

=

1000

and

generated

A𝑖

in

a

such

way

that

𝑓

is

𝜆–strongly

convex

(

i.e.,

1 𝑛

∑︀𝑛
𝑖=1

A𝑖

𝜆I for

39

𝜆 > 0) with 𝜆 = 1e−6. We now present Algorithm 11 which is used to generate these synthetic matrices (training data).

Algorithm 11 Quadratic optimization task generation (Szlendak et al., 2021)

1: Parameters: number nodes 𝑛, dimension 𝑑, regularizer 𝜆, and noise scale 𝑠.

2: for 𝑖 = 1, . . . , 𝑛 do

3: Generate random noises 𝜈𝑖𝑠 = 1 + 𝑠𝜉𝑖𝑠 and 𝜈𝑖𝑏 = 𝑠𝜉𝑖𝑏, i.i.d. 𝜉𝑖𝑠, 𝜉𝑖𝑏 ∼ 𝒩 (0, 1)

4:

Take

vector

𝑏𝑖

=

𝜈𝑖𝑠 (−1
4

+

𝜈𝑖𝑏, 0, · · ·

, 0)

∈

R𝑑

5: Take the initial tridiagonal matrix

⎛ 2 −1

0⎞

𝜈𝑠 ⎜ −1 . . . . . .

⎟

A𝑖 =

𝑖⎜ ⎜

⎟ ⎟

∈

R𝑑×𝑑

4 ⎜⎝ . . . . . . −1 ⎟⎠

0

−1 2

6: end for

7:

Take the mean of matrices A =

1 𝑛

∑︀𝑛
𝑖=1

A𝑖

8: Find the minimum eigenvalue 𝜆min(A)

9: for 𝑖 = 1, . . . , 𝑛 do

10: Update matrix A𝑖 = A𝑖 + (𝜆 − 𝜆min(A))I

11: end for

√

12: Take starting point 𝑥0 = ( 𝑑, 0, · · · , 0)

13: Output: matrices A1, · · · , A𝑛, vectors 𝑏1, · · · , 𝑏𝑛, starting point 𝑥0

We generated optimization tasks having different number of nodes 𝑛 = {10, 100, 1000} and capturing various dataheterogeneity regimes that are controlled by so-called Hessian variance6 term:
Deﬁnition E.1 (Hessian variance (Szlendak et al., 2021)). Let 𝐿± ≥ 0 be the smallest quantity such that

𝑛

1 𝑛

∑︀

‖∇𝑓𝑖(𝑥)

−

∇𝑓𝑖(𝑦)‖2

−

‖∇𝑓 (𝑥)

−

∇𝑓 (𝑦)‖2

≤

𝐿2± ‖𝑥

−

𝑦‖2 ,

∀𝑥,𝑦 ∈ R𝑑.

(79)

𝑖=1

We refer to the quantity 𝐿2± by the name Hessian variance.

From the deﬁnition , it follows that the case of similar (or even identical) functions 𝑓𝑖 relates to the small (or even 0) Hessian variance, whereas in the case of completely different 𝑓𝑖 (which relate to heterogeneous data regime) 𝐿± can be large.

In our experiments, homogeneity of each optimizations task is controlled by noise scale 𝑠 introduced in the Algorithm

11. Indeed, for the noise scale 𝑠 = 0, all matrices A𝑖 are equal, whereas with the increase of the noise scale, functions

become less “similar” and 𝐿± rises. We take noise scales 𝑠 ∈ {0.0, 0.05, 0.8, 1.6, 6.4}. A summary of the 𝐿± and 𝐿−

values corresponding to these noise scales is given in the Tables 3 and 4. For the considered quadratic problem 𝐿± can be

√︂

analytically expressed as 𝐿± =

𝜆max

(︁

1 𝑛

∑︀𝑛
𝑖=1

A2𝑖

−

(︀

1 𝑛

∑︀𝑛
𝑖=1

)︀2)︁ A𝑖 .

Table 3 Summary of the Hessian variance terms 𝐿± for different number of nodes 𝑛 various noise scales 𝑠.

𝑛 𝑠 0 0.05 0.8 1.6 6.4

10 100 1000

0 0.06 0.9 1.79 7.17 0 0.05 0.82 1.65 6.58 0 0.05 0.81 1.62 6.48

For all algorithms, at each iteration we compute the squared norm of the exact/full gradient for comparison of the methods performance. We terminate our algorithms either if they reach the certain number of iterations or the following stopping criterion is satisﬁed: ‖∇𝑓 (𝑥𝑡)‖2 ≤ 10−7.
6For more details, see the original paper Szlendak et al. (2021) introducing this concept.

40

n = 10 || f(xt)||2

Table 4 Summary of the Hessian variance terms 𝐿− for different number of nodes 𝑛 various noise scales 𝑠.

𝑛 𝑠 0 0.05 0.8 1.6 6.4

10 100 1000

1.0 1.02 1.35 1.7 3.82 1.0 1.0 0.97 0.94 0.77 1.0 1.0 0.97 0.95 0.78

103 101 10 1 10 3 10 5 10 7
0

L±avg = 0.0; Lavg = 1.0

EF21-Top100; 32x

103

EF21-cRand100; 32x

EF21-cPerm100; 32x
MARINA-Perm100; 1x 101

10 1

10 3

10 5

10 7

10

20

30

0

L±avg = 0.05; Lavg = 1.01
EEFF2211--TcRopan1d0100; 03;23x2x 103
EF21-cPerm100; 32x
MARINA-Perm100; 2x 101

10 1

10 3

10 5

10 7

10

20

30

0

L±avg = 0.84; Lavg = 1.1

EF21-Top100; 32x EF21-cRand100; 16x

103

EF21-cPerm100; 32x

MARINA-Perm100; 4x 101

10 1

10 3

10 5

10 7

10

20

30

0

L±avg = 1.69; Lavg = 1.2
EF21-Top100; 32x EF21-cRand100; 16x EF21-cPerm100; 32x MARINA-Perm100; 4x

20

40

103 101 10 1 10 3 10 5 10 7
0

L±avg = 6.74; Lavg = 1.79
EF21-Top100; 32x EF21-cRand100; 16x EF21-cPerm100; 16x MARINA-Perm100; 4x

5000

10000

103 101 10 1 10 3 10 5 10 7
0

EF21-Top10; 64x

EF21-cRand10; 256x EF21-cPerm10; 256x

103

MARINA-Perm10; 1x

101

10 1

10 3

10 5

10 7

5

10

0

EF21-Top10; 256x

EF21-cRand10; 256x EF21-cPerm10; 256x

103

MARINA-Perm10; 2x
101

10 1

10 3

10 5

10 7

2

4

6

0

EF21-Top10; 256x EF21-cRand10; 128x EF21-cPerm10; 256x MARINA-Perm10; 8x
5

103 101 10 1 10 3 10 5 10 7
0

EF21-Top10; 256x

103

EF21-cRand10; 128x

EF21-cPerm10; 64x MARINA-Perm10; 8x

101

10 1

10 3

10 5

10 7

5

10

0

EF21-Top10; 256x EF21-cRand10; 32x EF21-cPerm10; 64x MARINA-Perm10; 4x

50

100

150

103 101 10 1 10 3 10 5 10 7
0.0

EF21-Top1; 64x EF21-cRand1; 128x EF21-cPerm1; 256x MARINA-Perm1; 1x
2.5 5.0 7.5 #Mbits/n

103 101 10 1 10 3 10 5 10 7
0

EF21-Top1; 256x

EF21-cRand1; 128x

EF21-cPerm1; 256x

103

MARINA-Perm1; 4x

101

10 1

10 3

10 5

2 #Mbits/n

10 7 4 0.0

EF21-Top1; 512x EF21-cRand1; 512x EF21-cPerm1; 1024x MARINA-Perm1; 4x
2.5 5.0 7.5 #Mbits/n

103 101 10 1 10 3 10 5 10 7
0

EF21-Top1; 512x EF21-cRand1; 512x EF21-cPerm1; 512x MARINA-Perm1; 4x

2

4

#Mbits/n

103 101 10 1 10 3 10 5 10 7
0

EF21-Top1; 512x EF21-cRand1; 256x EF21-cPerm1; 256x MARINA-Perm1; 4x

10

20

#Mbits/n

Figure 6: Comparison of MARINA with Perm-𝐾, EF21 with Top-𝐾, cPerm-𝐾 and cRand-𝐾 with 𝐾 = 𝑑/𝑛 and tuned
stepsizes. By 1×, 2×, 4× (and so on) we indicate that the stepsize is set to a multiple of the largest stepsize predicted by theory. 𝐿𝑎±𝑣𝑔 and 𝐿𝑎−𝑣𝑔 are the averaged constants 𝐿± and 𝐿− per column.

n = 100 || f(xt)||2

n = 1000 || f(xt)||2

In all experiments, the stepsize of each method is set to the largest theoreticaly possible stepsize multiplied by some constant multiplier which was individually tuned in all cases within powers of 2 : {2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768} .
EF21 and different compressors Following the same order as in the section E.1 we start by comparing existing SOTA methods (MARINA with Perm-𝐾 and EF21 with Top-𝐾) against EF21 with cPerm-𝐾 and cRand-𝐾. In Figure 6, paramater 𝐾 = 𝑑/𝑛 is ﬁxed for each row. Each column corresponds to a heterogeneity levels deﬁned by the averaged 𝐿± and 𝐿− per values 𝑛 (averaged per column in the Tables 3 and 4).
These experiments shows that, in low Hessian variance regime EF21 with cPerm-𝐾 and cRand-𝐾 in some cases improves MARINA with Perm-𝐾 for 𝑛 = 10, 100, whereas for 𝑛 = 1000 MARINA with cPerm-𝐾 still dominates. Moreover, even in big Hessian variance regime EF21 methods converges faster than MARINA with cPerm-𝐾 but not as fast as EF21 with Top-𝐾. We are not aware of any prior empirical study for EF21 combined with cPerm-𝐾 or cRand-𝐾.
MARINA and different compressors In this section, we keep the same setting and compare a new method 3PCv5 with Top-𝐾 against MARINA with Perm-𝐾, Rand-𝐾 and EF21 with Top-𝐾. In Figure 7, one can see that 3PCv5 with Top-𝐾 outperforms MARINA methods only in a couple of cases for 𝑛 = 10, whereas for the most of the regimes it converges slower
41

n = 10 || f(xt)||2

n = 100 || f(xt)||2

103 101 10 1 10 3 10 5 10 7
0 103 101 10 1 10 3 10 5 10 7
0 103 101 10 1 10 3 10 5 10 7
0.0

L±avg = 0.0; Lavg = 1.0
EF21-Top100; 32x MARINA-Perm100; 1x 3PCv5-Top100; 4x MARINA-Rand100; 4x

20

40

EF21-Top10; 64x MARINA-Perm10; 1x 3PCv5-Top10; 4x MARINA-Rand10; 8x

10

20

EF21-Top1; 64x MARINA-Perm1; 1x 3PCv5-Top1; 4x MARINA-Rand1; 4x

2.5 5.0 7.5 #Mbits/n

103 L±avg = 0.05; Lavg = 1.01 EF21-Top100; 32x

MARINA-Perm100; 2x

101

3PCv5-Top100; 4x

MARINA-Rand100; 4x

10 1

10 3

10 5

10 7 0
103 101 10 1

20

40

EF21-Top10; 256x MARINA-Perm10; 2x 3PCv5-Top10; 4x MARINA-Rand10; 8x

10 3

10 5

10 7 0

5

10

103 101 10 1 10 3 10 5 10 7
0.0

EF21-Top1; 256x MARINA-Perm1; 4x 3PCv5-Top1; 4x MARINA-Rand1; 32x
2.5 5.0 7.5 #Mbits/n

L±avg = 0.84; Lavg = 1.1

103

EF21-Top100; 32x

103

MARINA-Perm100; 4x

101

3PCv5-Top100; 32x MARINA-Rand100; 4x

101

10 1

10 1

10 3

10 3

10 5

10 5

10 7 0
103 101 10 1

20

40

EF21-Top10; 256x MARINA-Perm10; 8x 3PCv5-Top10; 4x MARINA-Rand10; 8x

10 7 0
103 101 10 1

10 3

10 3

10 5

10 5

10 7 0
103 101 10 1

10 7

5

10

0

103
EF21-Top1; 512x

MARINA-Perm1; 4x

3PCv5-Top1; 4x

101

MARINA-Rand1; 16x

10 1

10 3

10 3

10 5

10 5

10 7 0.0

2.5 5.0 #Mbits/n

10 7

7.5

0

L±avg = 1.69; Lavg = 1.2
EF21-Top100; 32x MARINA-Perm100; 4x 3PCv5-Top100; 32x MARINA-Rand100; 4x

20

40

103 101 10 1 10 3 10 5 10 7
0

L±avg = 6.74; Lavg = 1.79
EF21-Top100; 32x MARINA-Perm100; 4x 3PCv5-Top100; 8x MARINA-Rand100; 4x

5000

10000

EF21-Top10; 256x

MARINA-Perm10; 8x

3PCv5-Top10; 8x

103

MARINA-Rand10; 8x

101

10 1

10 3

10 5

10 7

5

10

0

103
EF21-Top1; 512x

MARINA-Perm1; 4x

3PCv5-Top1; 8x

101

MARINA-Rand1; 16x

10 1

10 3

10 5

2

4

#Mbits/n

10 7 0

EF21-Top10; 256x MARINA-Perm10; 4x 3PCv5-Top10; 32x MARINA-Rand10; 4x

50

100

150

EF21-Top1; 512x MARINA-Perm1; 4x 3PCv5-Top1; 32x MARINA-Rand1; 8x

10

20

30

#Mbits/n

Figure 7: Comparison of MARINA with Perm-𝐾, Rand-𝐾, EF21 with Top-𝐾 and 3PCv5 with 𝐾 = 𝑑/𝑛 and tuned stepsizes. By 1×, 2×, 4× (and so on) we indicate that the stepsize is set to a multiple of the largest stepsize predicted by theory. 𝐿𝑎±𝑣𝑔 and 𝐿𝑎−𝑣𝑔 are the averaged constants 𝐿± and 𝐿− per column.

n = 1000 || f(xt)||2

than other methods.

3PCv2 beat SOTA methods in the most cases! In this series of experiments, we stick to the previous setting and append the results of the new method 3PCv2 with 2 different combinataion of compressors: Rand𝐾1-Top𝐾2 and Rand𝐾1 *Perm𝐾 -Top𝐾2, where Rand𝐾1 *Perm-𝐾 is the composition of Rand-𝐾1 and Perm-𝐾. For both methods, constants 𝐾1 and 𝐾2 were extensively tuned over the set of 9 different pairs (see Figures 10 and 12 for details). In the Figure 8 it is shown that both variants 3PCv2 methods converge quickly for 𝑛 = 100 in all heterogeneity regimes, outperforming MARINA and EF21. In the big Hessian variance regime and 𝑛 = 10, 3PCv2 also converges faster than EF21 with Top-𝐾, however, for even more homogeneous cases 3PCv2 slightly looses to EF21 with cPerm-𝐾 or cRand-𝐾. We also would like to note that we excluded 3PCv4 with Top𝐾1-Top𝐾2 from our comparison here since in practice for 𝐾 = 𝑑/𝑛 it coincides with EF21 with Top-𝐾 (see Figure 14 for more details)7
7We believe that this behaviors of 3PCv4 with Top𝐾1-Top𝐾2 takes place is due to the problem sparsity.
42

n = 10 || f(xt)||2

103 101 10 1 10 3 10 5 10 7
0

L±avg = 0.0; Lavg = 1.0
3PCv2-Rand10-Top90; 64x 3PCv2-Rand60*Perm100-Top40; 128x EF21-cPerm100; 32x EF21-Top100; 32x EF21-cRand100; 32x MARINA-Perm100; 1x 3PCv5-Top100; 4x MARINA-Rand100; 4x

20

40

103 101 10 1 10 3 10 5 10 7
0

L±avg = 0.05; Lavg = 1.01
3PCv2-Rand10-Top90; 64x 3PCv2-Rand60*Perm100-Top40; 128x EF21-cPerm100; 32x EF21-Top100; 32x EF21-cRand100; 32x MARINA-Perm100; 2x 3PCv5-Top100; 4x MARINA-Rand100; 4x

20

40

103 101 10 1 10 3 10 5 10 7
0

L±avg = 0.86; Lavg = 1.16

33PPCCvv22--RRaanndd1900-*TPoeprm901;0604-xTop10; 256x 103

EF21-cPerm100; 32x

EF21-Top100; 32x

101

EF21-cRand100; 16x

MARINA-Perm100; 4x 3PCv5-Top100; 32x

10 1

MARINA-Rand100; 4x
10 3

10 5

10 7

20

40

0

L±avg = 1.72; Lavg = 1.32
3PCv2-Rand20-Top80; 64x 3PCv2-Rand10*Perm100-Top90; 256x EF21-cPerm100; 32x EF21-Top100; 32x EF21-cRand100; 16x MARINA-Perm100; 4x 3PCv5-Top100; 32x MARINA-Rand100; 4x

10

20

103 101 10 1 10 3 10 5 10 7
0

L±avg = 6.88; Lavg = 2.29
3PCv2-Rand20-Top80; 64x 3PCv2-Rand10*Perm100-Top90; 256x EF21-cPerm100; 16x EF21-Top100; 32x EF21-cRand100; 16x MARINA-Perm100; 4x 3PCv5-Top100; 8x MARINA-Rand100; 4x

5000

10000

103 101 10 1 10 3 10 5 10 7
0

3PCv2-Rand2-Top8; 512x 3PCv2-Rand4*Perm10-Top6; 4096x EF21-cPerm10; 256x EF21-Top10; 64x EF21-cRand10; 256x MARINA-Perm10; 1x 3PCv5-Top10; 4x MARINA-Rand10; 8x

2

4

#Mbits/n

103 101 10 1 10 3 10 5 10 7
0

3PCv2-Rand2-Top8; 512x 3PCv2-Rand4*Perm10-Top6; 4096x EF21-cPerm10; 256x EF21-Top10; 256x EF21-cRand10; 256x MARINA-Perm10; 2x 3PCv5-Top10; 4x MARINA-Rand10; 8x

2

4

#Mbits/n

103 101 10 1 10 3 10 5 10 7
0

3PCv2-Rand5-Top5; 512x 3PCv2-Rand4*Perm10-Top6; 4096x EF21-cPerm10; 256x EF21-Top10; 256x EF21-cRand10; 128x MARINA-Perm10; 8x 3PCv5-Top10; 4x MARINA-Rand10; 8x

2

4

#Mbits/n

103 101 10 1 10 3 10 5 10 7
0

3PCv2-Rand1-Top9; 1024x 3PCv2-Rand3*Perm10-Top7; 8192x EF21-cPerm10; 64x EF21-Top10; 256x EF21-cRand10; 128x MARINA-Perm10; 8x 3PCv5-Top10; 8x MARINA-Rand10; 8x

2

4

#Mbits/n

103 101 10 1 10 3 10 5 10 7 0

3PCv2-Rand2-Top8; 512x 3PCv2-Rand1*Perm10-Top9; 8192x EF21-cPerm10; 64x EF21-Top10; 256x EF21-cRand10; 32x MARINA-Perm10; 4x 3PCv5-Top10; 32x MARINA-Rand10; 4x

50

100

#Mbits/n

Figure 8: Comparison of MARINA, EF21, 3PCv2 and 3PCv5 with various compressors , 𝐾 = 𝑑/𝑛 and tuned stepsizes. By 1×, 2×, 4× (and so on) we indicate that the stepsize is set to a multiple of the largest stepsize predicted by theory. 𝐿𝑎±𝑣𝑔 and 𝐿𝑎−𝑣𝑔 are the averaged constants 𝐿± and 𝐿− per column.

n = 100 || f(xt)||2

n = 10 || f(xt)||2

n = 100 || f(xt)||2

We further continue with the setting where 𝐾/𝑑 = 0.02 is ﬁxed for each 𝑛. In the Figure 9 illustrates that 3PCv2 remaines the best choice for 𝑛 = 10 and 𝑛 = 100, whereas in the homogeneous regime and 𝑛 = 1000 EF21 with cRand-𝐾 can reach the desired tolerance a bit faster. However, for big Hessian varince regime 3PCv2 as again preferable.

103 101 10 1 10 3 10 5 10 7
0

L±avg = 0.0; Lavg = 1.0
3PCv2-Rand2-Top18; 256x 3PCv2-Rand2*Perm100-Top18; 1024x EF21-Top20; 32x EF21-cRand20; 32x 3PCv5-Top20; 4x MARINA-Rand20; 4x 3PCv4-Top2-Top18; 32x
5 10 15

103 101 10 1 10 3 10 5 10 7
0

L±avg = 0.05; Lavg = 1.01
3PCv2-Rand2-Top18; 256x 3PCv2-Rand2*Perm100-Top18; 1024x EF21-Top20; 128x EF21-cRand20; 32x 3PCv5-Top20; 4x MARINA-Rand20; 4x 3PCv4-Top2-Top18; 128x
5 10 15

103 101 10 1 10 3 10 5 10 7
0

L±avg = 0.84; Lavg = 1.1
3PCv2-Rand6-Top14; 256x 3PCv2-Rand2*Perm100-Top18; 1024x EF21-Top20; 128x EF21-cRand20; 32x 3PCv5-Top20; 4x MARINA-Rand20; 4x 3PCv4-Top2-Top18; 128x
5 10 15

103 101 10 1 10 3 10 5 10 7
0

L±avg = 1.69; Lavg = 1.2
3PCv2-Rand10-Top10; 256x 3PCv2-Rand16*Perm100-Top4; 1024x EF21-Top20; 128x EF21-cRand20; 8x 3PCv5-Top20; 8x MARINA-Rand20; 4x 3PCv4-Top8-Top12; 256x

2

4

6

103 101 10 1 10 3 10 5 10 7
0

L±avg = 6.74; Lavg = 1.79
3PCv2-Rand4-Top16; 128x 3PCv2-Rand4*Perm100-Top16; 512x EF21-Top20; 128x EF21-cRand20; 16x 3PCv5-Top20; 8x MARINA-Rand20; 4x 3PCv4-Top2-Top18; 128x

2000

4000

103 101 10 1 10 3 10 5 10 7
0.0
103 101 10 1 10 3 10 5 10 7
0.0

3PCv2-Rand16-Top4; 256x 3PCv2-Rand12*Perm10-Top8; 2048x EF21-Top20; 32x EF21-cRand20; 128x 3PCv5-Top20; 4x MARINA-Rand20; 8x 3PCv4-Top2-Top18; 32x
2.5 5.0 7.5

103 101 10 1 10 3 10 5 10 7
0

3PCv2-Rand16-Top4; 256x 3PCv2-Rand2*Perm1-Top18; 8192x EF21-Top20; 32x EF21-cRand20; 512x 3PCv5-Top20; 4x MARINA-Rand20; 4x 3PCv4-Top2-Top18; 32x
2.5 5.0 7.5 #Mbits/n

103 101 10 1 10 3 10 5 10 7
0.0

3PCv2-Rand16-Top4; 256x 3PCv2-Rand12*Perm10-Top8; 2048x

103

EF21-Top20; 128x

E3PFC21v-5c-RTaonpd2200; ;41x28x 101

MARINA-Rand20; 8x

3PCv4-Top2-Top18; 128x

10 1

10 3

10 5

10 7

5

10

0.0

3PCv2-Rand16-Top4; 256x 3PCv2-Rand2*Perm1-Top18; 8192x EF21-Top20; 128x EF21-cRand20; 512x 3PCv5-Top20; 4x MARINA-Rand20; 4x 3PCv4-Top2-Top18; 128x
2.5 5.0 7.5 #Mbits/n

103 101 10 1 10 3 10 5 10 7
0.0

3PCv2-Rand10-Top10; 256x 3PCv2-Rand2*Perm10-Top18; 4096x EF21-Top20; 128x EF21-cRand20; 64x 3PCv5-Top20; 4x MARINA-Rand20; 4x 3PCv4-Top2-Top18; 256x
2.5 5.0 7.5

103 101 10 1 10 3 10 5 10 7
0.0

3PCv2-Rand18-Top2; 512x 3PCv2-Rand6*Perm1-Top14; 8192x EF21-Top20; 256x EF21-cRand20; 512x 3PCv5-Top20; 4x MARINA-Rand20; 4x 3PCv4-Top8-Top12; 256x
2.5 5.0 7.5 #Mbits/n

103 101 10 1 10 3 10 5 10 7
0

3PCv2-Rand2-Top18; 512x 3PCv2-Rand14*Perm10-Top6; 4096x EF21-Top20; 256x EF21-cRand20; 64x 3PCv5-Top20; 8x MARINA-Rand20; 4x 3PCv4-Top2-Top18; 256x
2.5 5.0 7.5

103 101 10 1 10 3 10 5 10 7
0

3PCv2-Rand16-Top4; 512x 3PCv2-Rand10*Perm1-Top10; 8192x EF21-Top20; 256x EF21-cRand20; 1024x 3PCv5-Top20; 8x MARINA-Rand20; 4x 3PCv4-Top2-Top18; 256x

2

4

#Mbits/n

103 101 10 1 10 3 10 5 10 7
0

3PCv2-Rand6-Top14; 256x 3PCv2-Rand2*Perm10-Top18; 4096x EF21-Top20; 256x EF21-cRand20; 64x 3PCv5-Top20; 32x MARINA-Rand20; 4x 3PCv4-Top2-Top18; 256x

50

100

3PCv2-Rand8-Top12; 1024x 3PCv2-Rand14*Perm1-Top6; 8192x EF21-Top20; 256x EF21-cRand20; 256x 3PCv5-Top20; 32x MARINA-Rand20; 4x 3PCv4-Top2-Top18; 256x

10

20

30

#Mbits/n

Figure 9: Comparison of MARINA, EF21, 3PCv2, 3PCv5 and 3PCv5 with various compressors , 𝐾 = 0.02𝑑 and tuned
stepsizes. By 1×, 2×, 4× (and so on) we indicate that the stepsize is set to a multiple of the largest stepsize predicted by theory. 𝐿𝑎±𝑣𝑔 and 𝐿𝑎−𝑣𝑔 are the averaged constants 𝐿± and 𝐿− per column.

n = 1000 || f(xt)||2

43

Fine-tuning of (𝐾1, 𝐾2) pairs for 3PCv2 and 3PCv4 In this section we provide with some auxillary results on the demonstration of the tuning (𝐾1, 𝐾2) pairs for 3PCv2 and 3PCv4 on different compressors. In the 𝐾 = 𝑑/𝑛 scenario (see Figure 10), in all cases the best performance of 3PCv2 with Rand𝐾1-Top𝐾2 is achieved when 𝐾2 > 𝐾1, whereas for the case when 𝐾/𝑑 = 0.02 (see Figure 11) there is a dependence on 𝑛; for 𝑛 = 10, the choice when 𝐾2 > 𝐾1 is preferable in all cases, whereas for 𝑛 = 100 and 𝑛 = 1000 it is the case only in big Hessian variance regime. At the same time, for optimal pairs (𝐾1,𝐾2) of the method 3PCv2 with Rand𝐾1*Perm𝐾-Top𝐾2 we observe that the choice is 𝐾2 > 𝐾1 (see Figures 12, 13).

n = 10 || f(xt)||2

n = 100 || f(xt)||2

10 3

L±avg = 0.0; Lavg = 1.0

10 3 L±avg = 0.05; Lavg = 1.01

10 3 L±avg = 0.86; Lavg = 1.16

10 3 L±avg = 1.72; Lavg = 1.32

10 3 L±avg = 6.88; Lavg = 2.29

3PCv2-Rand90-Top10; 32x

3PCv2-Rand90-Top10; 32x

3PCv2-Rand90-Top10; 32x

3PCv2-Rand90-Top10; 32x

3PCv2-Rand90-Top10; 32x

3PCv2-Rand80-Top20; 32x

3PCv2-Rand80-Top20; 32x

3PCv2-Rand80-Top20; 32x

3PCv2-Rand80-Top20; 32x

3PCv2-Rand80-Top20; 32x

3PCv2-Rand70-Top30; 32x

3PCv2-Rand70-Top30; 32x

3PCv2-Rand70-Top30; 32x

3PCv2-Rand70-Top30; 32x

3PCv2-Rand70-Top30; 16x

3PCv2-Rand60-Top40; 32x

3PCv2-Rand60-Top40; 32x

3PCv2-Rand60-Top40; 32x

3PCv2-Rand60-Top40; 32x

3PCv2-Rand60-Top40; 16x

3PCv2-Rand50-Top50; 32x

3PCv2-Rand50-Top50; 32x

3PCv2-Rand50-Top50; 32x

3PCv2-Rand50-Top50; 32x

3PCv2-Rand50-Top50; 32x

10 5

3PCv2-Rand40-Top60; 32x 3PCv2-Rand30-Top70; 32x

10 5

3PCv2-Rand40-Top60; 32x 3PCv2-Rand30-Top70; 32x

10 5

3PCv2-Rand40-Top60; 32x 3PCv2-Rand30-Top70; 32x

10 5

3PCv2-Rand40-Top60; 32x 3PCv2-Rand30-Top70; 32x

10 5

3PCv2-Rand40-Top60; 32x 3PCv2-Rand30-Top70; 32x

3PCv2-Rand20-Top80; 32x

3PCv2-Rand20-Top80; 32x

3PCv2-Rand20-Top80; 32x

3PCv2-Rand20-Top80; 64x

3PCv2-Rand20-Top80; 64x

3PCv2-Rand10-Top90; 64x

3PCv2-Rand10-Top90; 64x

3PCv2-Rand10-Top90; 64x

3PCv2-Rand10-Top90; 64x

3PCv2-Rand10-Top90; 64x

10 7 0
10 3
10 5

20

40

3PCv2-Rand9-Top1; 512x 3PCv2-Rand8-Top2; 256x 3PCv2-Rand7-Top3; 256x 3PCv2-Rand6-Top4; 256x 3PCv2-Rand5-Top5; 256x 3PCv2-Rand4-Top6; 256x 3PCv2-Rand3-Top7; 256x 3PCv2-Rand2-Top8; 512x 3PCv2-Rand1-Top9; 512x

10 7 0
10 3
10 5

20

40

3PCv2-Rand9-Top1; 512x 3PCv2-Rand8-Top2; 256x 3PCv2-Rand7-Top3; 256x 3PCv2-Rand6-Top4; 256x 3PCv2-Rand5-Top5; 256x 3PCv2-Rand4-Top6; 256x 3PCv2-Rand3-Top7; 256x 3PCv2-Rand2-Top8; 512x 3PCv2-Rand1-Top9; 512x

10 7 0
10 3
10 5

20

40

3PCv2-Rand9-Top1; 512x 3PCv2-Rand8-Top2; 256x 3PCv2-Rand7-Top3; 256x 3PCv2-Rand6-Top4; 256x 3PCv2-Rand5-Top5; 512x 3PCv2-Rand4-Top6; 512x 3PCv2-Rand3-Top7; 512x 3PCv2-Rand2-Top8; 512x 3PCv2-Rand1-Top9; 512x

10 7 0
10 3
10 5

10

20

3PCv2-Rand9-Top1; 256x 3PCv2-Rand8-Top2; 256x 3PCv2-Rand7-Top3; 256x 3PCv2-Rand6-Top4; 256x 3PCv2-Rand5-Top5; 512x 3PCv2-Rand4-Top6; 512x 3PCv2-Rand3-Top7; 512x 3PCv2-Rand2-Top8; 512x 3PCv2-Rand1-Top9; 1024x

10 7 0
10 3
10 5

5000

10000

3PCv2-Rand9-Top1; 128x 3PCv2-Rand8-Top2; 64x 3PCv2-Rand7-Top3; 64x 3PCv2-Rand6-Top4; 64x 3PCv2-Rand5-Top5; 128x 3PCv2-Rand4-Top6; 256x 3PCv2-Rand3-Top7; 256x 3PCv2-Rand2-Top8; 512x 3PCv2-Rand1-Top9; 512x

10 7 0

2 #Mbits/n

10 7

4

0

2 #Mbits/n

10 7

4

0

10 7

2

4

0

#Mbits/n

2 #Mbits/n

10 7

4

0

20 40 60 #Mbits/n

Figure 10: Comparison of 3PCv2 with methods with Rand𝐾1-Top𝐾2 with 𝐾1 + 𝐾2 = 𝑑/𝑛 and tuned stepsizes. By 1×, 2×, 4× (and so on) we indicate that the stepsize is set to a multiple of the largest stepsize predicted by theory. 𝐿𝑎±𝑣𝑔 and 𝐿𝑎−𝑣𝑔 are the averaged constants 𝐿± and 𝐿− per column.

44

n = 10 || f(xt)||2

n = 100 || f(xt)||2

10 3

L±avg = 0.0; Lavg = 1.0

10 3 L±avg = 0.05; Lavg = 1.01

10 3 L±avg = 0.84; Lavg = 1.1

10 3 L±avg = 1.69; Lavg = 1.2

10 3 L±avg = 6.74; Lavg = 1.79

3PCv2-Rand18-Top2; 64x

3PCv2-Rand18-Top2; 64x

3PCv2-Rand18-Top2; 64x

3PCv2-Rand18-Top2; 64x

3PCv2-Rand18-Top2; 32x

3PCv2-Rand16-Top4; 64x

3PCv2-Rand16-Top4; 64x

3PCv2-Rand16-Top4; 32x

3PCv2-Rand16-Top4; 32x

3PCv2-Rand16-Top4; 32x

3PCv2-Rand14-Top6; 32x

3PCv2-Rand14-Top6; 32x

3PCv2-Rand14-Top6; 32x

3PCv2-Rand14-Top6; 256x

3PCv2-Rand14-Top6; 32x

3PCv2-Rand12-Top8; 128x

3PCv2-Rand12-Top8; 128x

3PCv2-Rand12-Top8; 32x

3PCv2-Rand12-Top8; 256x

3PCv2-Rand12-Top8; 32x

3PCv2-Rand10-Top10; 128x

3PCv2-Rand10-Top10; 128x

3PCv2-Rand10-Top10; 128x

3PCv2-Rand10-Top10; 256x

3PCv2-Rand10-Top10; 32x

3PCv2-Rand8-Top12; 128x

3PCv2-Rand8-Top12; 128x

3PCv2-Rand8-Top12; 128x

3PCv2-Rand8-Top12; 256x

10 5

3PCv2-Rand6-Top14; 128x 10 5

3PCv2-Rand6-Top14; 128x 10 5

3PCv2-Rand6-Top14; 256x 10 5

3PCv2-Rand6-Top14; 256x 10 5

3PCv2-Rand4-Top16; 128x

3PCv2-Rand4-Top16; 128x

3PCv2-Rand4-Top16; 256x

3PCv2-Rand4-Top16; 256x

3PCv2-Rand8-Top12; 64x 3PCv2-Rand6-Top14; 64x 3PCv2-Rand4-Top16; 128x

3PCv2-Rand2-Top18; 256x

3PCv2-Rand2-Top18; 256x

3PCv2-Rand2-Top18; 256x

3PCv2-Rand2-Top18; 256x

3PCv2-Rand2-Top18; 128x

10 7 0
10 3
10 5

10 7

10

20

0

10 3
3PCv2-Rand18-Top2; 256x 3PCv2-Rand16-Top4; 256x 3PCv2-Rand14-Top6; 128x 3PCv2-Rand12-Top8; 128x 3PCv2-Rand10-Top10; 128x 3PCv2-Rand8-Top12; 128x
3PCv2-Rand6-Top14; 128x 10 5
3PCv2-Rand4-Top16; 128x 3PCv2-Rand2-Top18; 256x

10 7

10

20

0

10 3
3PCv2-Rand18-Top2; 256x 3PCv2-Rand16-Top4; 256x 3PCv2-Rand14-Top6; 128x 3PCv2-Rand12-Top8; 128x 3PCv2-Rand10-Top10; 128x 3PCv2-Rand8-Top12; 128x
3PCv2-Rand6-Top14; 128x 10 5
3PCv2-Rand4-Top16; 128x 3PCv2-Rand2-Top18; 256x

10 7

5

10

15

0

10 3
3PCv2-Rand18-Top2; 256x 3PCv2-Rand16-Top4; 256x 3PCv2-Rand14-Top6; 256x 3PCv2-Rand12-Top8; 256x 3PCv2-Rand10-Top10; 256x 3PCv2-Rand8-Top12; 256x
3PCv2-Rand6-Top14; 256x 10 5
3PCv2-Rand4-Top16; 256x 3PCv2-Rand2-Top18; 256x

2

4

3PCv2-Rand18-Top2; 256x 3PCv2-Rand16-Top4; 256x 3PCv2-Rand14-Top6; 128x 3PCv2-Rand12-Top8; 128x 3PCv2-Rand10-Top10; 256x 3PCv2-Rand8-Top12; 256x 3PCv2-Rand6-Top14; 256x 3PCv2-Rand4-Top16; 256x 3PCv2-Rand2-Top18; 512x

10 7 0
10 3
10 5

2000 4000 6000
3PCv2-Rand18-Top2; 128x 3PCv2-Rand16-Top4; 64x 3PCv2-Rand14-Top6; 64x 3PCv2-Rand12-Top8; 64x 3PCv2-Rand10-Top10; 128x 3PCv2-Rand8-Top12; 128x 3PCv2-Rand6-Top14; 256x 3PCv2-Rand4-Top16; 256x 3PCv2-Rand2-Top18; 256x

10 7 0
10 3
10 5

2

4

6

3PCv2-Rand18-Top2; 256x 3PCv2-Rand16-Top4; 256x 3PCv2-Rand14-Top6; 128x 3PCv2-Rand12-Top8; 128x 3PCv2-Rand10-Top10; 128x 3PCv2-Rand8-Top12; 128x 3PCv2-Rand6-Top14; 128x 3PCv2-Rand4-Top16; 128x 3PCv2-Rand2-Top18; 256x

10 7 0
10 3
10 5

2

4

6

3PCv2-Rand18-Top2; 256x 3PCv2-Rand16-Top4; 256x 3PCv2-Rand14-Top6; 128x 3PCv2-Rand12-Top8; 128x 3PCv2-Rand10-Top10; 128x 3PCv2-Rand8-Top12; 128x 3PCv2-Rand6-Top14; 128x 3PCv2-Rand4-Top16; 128x 3PCv2-Rand2-Top18; 256x

10 7 0
10 3
10 5

2

4

6

3PCv2-Rand18-Top2; 512x 3PCv2-Rand16-Top4; 256x 3PCv2-Rand14-Top6; 256x 3PCv2-Rand12-Top8; 256x 3PCv2-Rand10-Top10; 256x 3PCv2-Rand8-Top12; 256x 3PCv2-Rand6-Top14; 256x 3PCv2-Rand4-Top16; 256x 3PCv2-Rand2-Top18; 256x

10 7 0
10 3
10 5

2

4

6

3PCv2-Rand18-Top2; 512x 3PCv2-Rand16-Top4; 512x 3PCv2-Rand14-Top6; 256x 3PCv2-Rand12-Top8; 256x 3PCv2-Rand10-Top10; 256x 3PCv2-Rand8-Top12; 256x 3PCv2-Rand6-Top14; 256x 3PCv2-Rand4-Top16; 256x 3PCv2-Rand2-Top18; 512x

10 7 0
10 3
10 5

25 50 75
3PCv2-Rand18-Top2; 512x 3PCv2-Rand16-Top4; 512x 3PCv2-Rand14-Top6; 512x 3PCv2-Rand12-Top8; 512x 3PCv2-Rand10-Top10; 512x 3PCv2-Rand8-Top12; 1024x 3PCv2-Rand6-Top14; 1024x 3PCv2-Rand4-Top16; 1024x 3PCv2-Rand2-Top18; 512x

10 7 0

2

4

6

#Mbits/n

10 7 0

2

4

6

#Mbits/n

10 7 0

2

4

#Mbits/n

10 7

6

0

2 #Mbits/n

10 7

4

0

2

4

6

#Mbits/n

Figure 11: Comparison of 3PCv2 with methods with Rand𝐾1-Top𝐾2 with 𝐾1 + 𝐾2 = 0.02𝑑 and tuned stepsizes. By 1×, 2×, 4× (and so on) we indicate that the stepsize is set to a multiple of the largest stepsize predicted by theory. 𝐿𝑎±𝑣𝑔 and 𝐿𝑎−𝑣𝑔 are the averaged constants 𝐿± and 𝐿− per column.

n = 1000 || f(xt)||2

n = 10 || f(xt)||2

n = 100 || f(xt)||2

10 3

L±avg = 0.0; Lavg = 1.0

10 3 L±avg = 0.05; Lavg = 1.01

10 3 L±avg = 0.86; Lavg = 1.16

10 3 L±avg = 1.72; Lavg = 1.32

10 3 L±avg = 6.88; Lavg = 2.29

3PCv2-Rand90*Perm100-Top10; 128x

3PCv2-Rand90*Perm100-Top10; 128x

3PCv2-Rand90*Perm100-Top10; 256x

3PCv2-Rand90*Perm100-Top10; 256x

3PCv2-Rand90*Perm100-Top10; 32x

3PCv2-Rand80*Perm100-Top20; 128x

3PCv2-Rand80*Perm100-Top20; 128x

3PCv2-Rand80*Perm100-Top20; 128x

3PCv2-Rand80*Perm100-Top20; 128x

3PCv2-Rand80*Perm100-Top20; 64x

3PCv2-Rand70*Perm100-Top30; 128x

3PCv2-Rand70*Perm100-Top30; 128x

3PCv2-Rand70*Perm100-Top30; 128x

3PCv2-Rand70*Perm100-Top30; 128x

3PCv2-Rand70*Perm100-Top30; 64x

3PCv2-Rand60*Perm100-Top40; 128x

3PCv2-Rand60*Perm100-Top40; 128x

3PCv2-Rand60*Perm100-Top40; 128x

3PCv2-Rand60*Perm100-Top40; 128x

3PCv2-Rand60*Perm100-Top40; 128x

3PCv2-Rand50*Perm100-Top50; 64x

3PCv2-Rand50*Perm100-Top50; 64x

3PCv2-Rand50*Perm100-Top50; 128x

3PCv2-Rand50*Perm100-Top50; 128x

3PCv2-Rand50*Perm100-Top50; 128x

10 5

3PCv2-Rand40*Perm100-Top60; 64x 3PCv2-Rand30*Perm100-Top70; 128x

10 5

3PCv2-Rand40*Perm100-Top60; 64x 3PCv2-Rand30*Perm100-Top70; 128x

10 5

3PCv2-Rand40*Perm100-Top60; 128x 3PCv2-Rand30*Perm100-Top70; 128x

10 5

3PCv2-Rand40*Perm100-Top60; 128x 3PCv2-Rand30*Perm100-Top70; 128x

10 5

3PCv2-Rand40*Perm100-Top60; 128x 3PCv2-Rand30*Perm100-Top70; 128x

3PCv2-Rand20*Perm100-Top80; 128x

3PCv2-Rand20*Perm100-Top80; 128x

3PCv2-Rand20*Perm100-Top80; 128x

3PCv2-Rand20*Perm100-Top80; 128x

3PCv2-Rand20*Perm100-Top80; 128x

3PCv2-Rand10*Perm100-Top90; 128x

3PCv2-Rand10*Perm100-Top90; 128x

3PCv2-Rand10*Perm100-Top90; 128x

3PCv2-Rand10*Perm100-Top90; 256x

3PCv2-Rand10*Perm100-Top90; 256x

10 7 0
10 3
10 5

20

40

3PCv2-Rand9*Perm10-Top1; 4096x 3PCv2-Rand8*Perm10-Top2; 2048x 3PCv2-Rand7*Perm10-Top3; 4096x 3PCv2-Rand6*Perm10-Top4; 4096x 3PCv2-Rand5*Perm10-Top5; 4096x 3PCv2-Rand4*Perm10-Top6; 4096x 3PCv2-Rand3*Perm10-Top7; 4096x 3PCv2-Rand2*Perm10-Top8; 4096x 3PCv2-Rand1*Perm10-Top9; 4096x

10 7 0
10 3
10 5

20

40

3PCv2-Rand9*Perm10-Top1; 2048x 3PCv2-Rand8*Perm10-Top2; 2048x 3PCv2-Rand7*Perm10-Top3; 4096x 3PCv2-Rand6*Perm10-Top4; 4096x 3PCv2-Rand5*Perm10-Top5; 4096x 3PCv2-Rand4*Perm10-Top6; 4096x 3PCv2-Rand3*Perm10-Top7; 4096x 3PCv2-Rand2*Perm10-Top8; 4096x 3PCv2-Rand1*Perm10-Top9; 4096x

10 7 0
10 3
10 5

20
3PCv2-Rand9*Perm10-Top1; 4096x 3PCv2-Rand8*Perm10-Top2; 2048x 3PCv2-Rand7*Perm10-Top3; 4096x 3PCv2-Rand6*Perm10-Top4; 4096x 3PCv2-Rand5*Perm10-Top5; 4096x 3PCv2-Rand4*Perm10-Top6; 4096x 3PCv2-Rand3*Perm10-Top7; 4096x 3PCv2-Rand2*Perm10-Top8; 4096x 3PCv2-Rand1*Perm10-Top9; 8192x

10 7 0
10 3
10 5

5

10

3PCv2-Rand9*Perm10-Top1; 4096x 3PCv2-Rand8*Perm10-Top2; 4096x 3PCv2-Rand7*Perm10-Top3; 8192x 3PCv2-Rand6*Perm10-Top4; 8192x 3PCv2-Rand5*Perm10-Top5; 4096x 3PCv2-Rand4*Perm10-Top6; 4096x 3PCv2-Rand3*Perm10-Top7; 8192x 3PCv2-Rand2*Perm10-Top8; 8192x 3PCv2-Rand1*Perm10-Top9; 8192x

10 7 0
10 3
10 5

5000 10000 15000
3PCv2-Rand9*Perm10-Top1; 2048x 3PCv2-Rand8*Perm10-Top2; 4096x 3PCv2-Rand7*Perm10-Top3; 4096x 3PCv2-Rand6*Perm10-Top4; 4096x 3PCv2-Rand5*Perm10-Top5; 4096x 3PCv2-Rand4*Perm10-Top6; 4096x 3PCv2-Rand3*Perm10-Top7; 4096x 3PCv2-Rand2*Perm10-Top8; 4096x 3PCv2-Rand1*Perm10-Top9; 8192x

10 7 0

2

4

#Mbits/n

10 7 0

2

4

#Mbits/n

10 7 0

2

4

#Mbits/n

10 7 0

2 #Mbits/n

10 7

4

0

20 40 60 #Mbits/n

Figure 12: Comparison of 3PCv2 with methods with Rand𝐾1*Perm𝐾-Top𝐾2 with 𝐾1 + 𝐾2 = 𝑑/𝑛 and tuned stepsizes. By 1×, 2×, 4× (and so on) we indicate that the stepsize is set to a multiple of the largest stepsize predicted by theory. 𝐿𝑎±𝑣𝑔 and 𝐿𝑎−𝑣𝑔 are the averaged constants 𝐿± and 𝐿− per column.

45

n = 10 || f(xt)||2

n = 100 || f(xt)||2

10 3

L±avg = 0.0; Lavg = 1.0

10 3 L±avg = 0.05; Lavg = 1.01

10 3 L±avg = 0.84; Lavg = 1.1

10 3 L±avg = 1.69; Lavg = 1.2

10 3 L±avg = 6.74; Lavg = 1.79

3PCv2-Rand18*Perm100-Top2; 1024x

3PCv2-Rand18*Perm100-Top2; 1024x

3PCv2-Rand18*Perm100-Top2; 1024x

3PCv2-Rand18*Perm100-Top2; 1024x

3PCv2-Rand18*Perm100-Top2; 32x

3PCv2-Rand16*Perm100-Top4; 512x

3PCv2-Rand16*Perm100-Top4; 512x

3PCv2-Rand16*Perm100-Top4; 512x

3PCv2-Rand16*Perm100-Top4; 1024x

3PCv2-Rand16*Perm100-Top4; 128x

3PCv2-Rand14*Perm100-Top6; 512x

3PCv2-Rand14*Perm100-Top6; 512x

3PCv2-Rand14*Perm100-Top6; 512x

3PCv2-Rand14*Perm100-Top6; 512x

3PCv2-Rand14*Perm100-Top6; 128x

3PCv2-Rand12*Perm100-Top8; 512x

3PCv2-Rand12*Perm100-Top8; 512x

3PCv2-Rand12*Perm100-Top8; 512x

3PCv2-Rand12*Perm100-Top8; 512x

3PCv2-Rand12*Perm100-Top8; 256x

3PCv2-Rand10*Perm100-Top10; 512x

3PCv2-Rand10*Perm100-Top10; 512x

3PCv2-Rand10*Perm100-Top10; 512x

3PCv2-Rand10*Perm100-Top10; 512x

3PCv2-Rand10*Perm100-Top10; 256x

3PCv2-Rand8*Perm100-Top12; 512x

3PCv2-Rand8*Perm100-Top12; 512x

3PCv2-Rand8*Perm100-Top12; 512x

3PCv2-Rand8*Perm100-Top12; 512x

3PCv2-Rand8*Perm100-Top12; 256x

10 5

3PCv2-Rand6*Perm100-Top14; 512x 10 5

3PCv2-Rand6*Perm100-Top14; 512x 10 5

3PCv2-Rand6*Perm100-Top14; 512x 10 5

3PCv2-Rand6*Perm100-Top14; 512x 10 5

3PCv2-Rand6*Perm100-Top14; 256x

3PCv2-Rand4*Perm100-Top16; 512x

3PCv2-Rand4*Perm100-Top16; 512x

3PCv2-Rand4*Perm100-Top16; 512x

3PCv2-Rand4*Perm100-Top16; 1024x

3PCv2-Rand4*Perm100-Top16; 512x

3PCv2-Rand2*Perm100-Top18; 1024x

3PCv2-Rand2*Perm100-Top18; 1024x

3PCv2-Rand2*Perm100-Top18; 1024x

3PCv2-Rand2*Perm100-Top18; 1024x

3PCv2-Rand2*Perm100-Top18; 512x

10 7 0
10 3
10 5

2

4

6

3PCv2-Rand18*Perm10-Top2; 2048x 3PCv2-Rand16*Perm10-Top4; 2048x 3PCv2-Rand14*Perm10-Top6; 2048x 3PCv2-Rand12*Perm10-Top8; 2048x 3PCv2-Rand10*Perm10-Top10; 1024x 3PCv2-Rand8*Perm10-Top12; 2048x 3PCv2-Rand6*Perm10-Top14; 2048x 3PCv2-Rand4*Perm10-Top16; 2048x 3PCv2-Rand2*Perm10-Top18; 2048x

10 7 0
10 3
10 5

2

4

6

3PCv2-Rand18*Perm10-Top2; 2048x 3PCv2-Rand16*Perm10-Top4; 2048x 3PCv2-Rand14*Perm10-Top6; 2048x 3PCv2-Rand12*Perm10-Top8; 2048x 3PCv2-Rand10*Perm10-Top10; 1024x 3PCv2-Rand8*Perm10-Top12; 2048x 3PCv2-Rand6*Perm10-Top14; 2048x 3PCv2-Rand4*Perm10-Top16; 2048x 3PCv2-Rand2*Perm10-Top18; 2048x

10 7 0
10 3
10 5

2

4

6

3PCv2-Rand18*Perm10-Top2; 2048x 3PCv2-Rand16*Perm10-Top4; 2048x 3PCv2-Rand14*Perm10-Top6; 2048x 3PCv2-Rand12*Perm10-Top8; 2048x 3PCv2-Rand10*Perm10-Top10; 2048x 3PCv2-Rand8*Perm10-Top12; 2048x 3PCv2-Rand6*Perm10-Top14; 2048x 3PCv2-Rand4*Perm10-Top16; 2048x 3PCv2-Rand2*Perm10-Top18; 4096x

10 7 0
10 3
10 5

10 7

1

2

3

0

10 3
3PCv2-Rand18*Perm10-Top2; 4096x 3PCv2-Rand16*Perm10-Top4; 4096x 3PCv2-Rand14*Perm10-Top6; 4096x 3PCv2-Rand12*Perm10-Top8; 2048x 3PCv2-Rand10*Perm10-Top10; 2048x 3PCv2-Rand8*Perm10-Top12; 2048x
3PCv2-Rand6*Perm10-Top14; 4096x 10 5
3PCv2-Rand4*Perm10-Top16; 4096x 3PCv2-Rand2*Perm10-Top18; 4096x

2000 4000 6000
3PCv2-Rand18*Perm10-Top2; 2048x 3PCv2-Rand16*Perm10-Top4; 2048x 3PCv2-Rand14*Perm10-Top6; 2048x 3PCv2-Rand12*Perm10-Top8; 2048x 3PCv2-Rand10*Perm10-Top10; 2048x 3PCv2-Rand8*Perm10-Top12; 2048x 3PCv2-Rand6*Perm10-Top14; 2048x 3PCv2-Rand4*Perm10-Top16; 2048x 3PCv2-Rand2*Perm10-Top18; 4096x

10 7 0.0
10 3
10 5

2.5 5.0 7.5
3PCv2-Rand18*Perm1-Top2; 4096x 3PCv2-Rand16*Perm1-Top4; 4096x 3PCv2-Rand14*Perm1-Top6; 4096x 3PCv2-Rand12*Perm1-Top8; 4096x 3PCv2-Rand10*Perm1-Top10; 4096x 3PCv2-Rand8*Perm1-Top12; 4096x 3PCv2-Rand6*Perm1-Top14; 4096x 3PCv2-Rand4*Perm1-Top16; 4096x 3PCv2-Rand2*Perm1-Top18; 8192x

10 7 0.0
10 3
10 5

2.5 5.0 7.5
3PCv2-Rand18*Perm1-Top2; 4096x 3PCv2-Rand16*Perm1-Top4; 4096x 3PCv2-Rand14*Perm1-Top6; 4096x 3PCv2-Rand12*Perm1-Top8; 4096x 3PCv2-Rand10*Perm1-Top10; 4096x 3PCv2-Rand8*Perm1-Top12; 4096x 3PCv2-Rand6*Perm1-Top14; 4096x 3PCv2-Rand4*Perm1-Top16; 4096x 3PCv2-Rand2*Perm1-Top18; 8192x

10 7 0.0
10 3
10 5

2.5

5.0

7.5

3PCv2-Rand18*Perm1-Top2; 8192x 3PCv2-Rand16*Perm1-Top4; 8192x 3PCv2-Rand14*Perm1-Top6; 8192x 3PCv2-Rand12*Perm1-Top8; 8192x 3PCv2-Rand10*Perm1-Top10; 8192x 3PCv2-Rand8*Perm1-Top12; 8192x 3PCv2-Rand6*Perm1-Top14; 8192x 3PCv2-Rand4*Perm1-Top16; 8192x 3PCv2-Rand2*Perm1-Top18; 8192x

10 7 0
10 3
10 5

2

4

3PCv2-Rand18*Perm1-Top2; 8192x 3PCv2-Rand16*Perm1-Top4; 8192x 3PCv2-Rand14*Perm1-Top6; 8192x 3PCv2-Rand12*Perm1-Top8; 8192x 3PCv2-Rand10*Perm1-Top10; 8192x 3PCv2-Rand8*Perm1-Top12; 8192x 3PCv2-Rand6*Perm1-Top14; 8192x 3PCv2-Rand4*Perm1-Top16; 8192x 3PCv2-Rand2*Perm1-Top18; 8192x

10 7 0
10 3
10 5

50

100

3PCv2-Rand18*Perm1-Top2; 16384x 3PCv2-Rand16*Perm1-Top4; 8192x 3PCv2-Rand14*Perm1-Top6; 8192x 3PCv2-Rand12*Perm1-Top8; 8192x 3PCv2-Rand10*Perm1-Top10; 8192x 3PCv2-Rand8*Perm1-Top12; 8192x 3PCv2-Rand6*Perm1-Top14; 16384x 3PCv2-Rand4*Perm1-Top16; 16384x 3PCv2-Rand2*Perm1-Top18; 16384x

10 7 0

5 #Mbits/n

10 7

10

0

5 #Mbits/n

10 7

10

0.0

2.5

5.0

#Mbits/n

10 7

7.5

0.0

2.5 5.0 7.5 #Mbits/n

10 7 0

10 #Mbits/n

Figure 13: Comparison of 3PCv2 with methods with Rand𝐾1*Perm𝐾-Top𝐾2 with 𝐾1 + 𝐾2 = 0.02𝑑 and tuned stepsizes. By 1×, 2×, 4× (and so on) we indicate that the stepsize is set to a multiple of the largest stepsize predicted by theory. 𝐿𝑎±𝑣𝑔 and 𝐿𝑎−𝑣𝑔 are the averaged constants 𝐿± and 𝐿− per column.

n = 1000 || f(xt)||2

n = 10 || f(xt)||2

Figures 14 and 15 show that for the considered sparse quadratic problem in most cases the method 3PCv4 with Top𝐾1-Top𝐾2 compressors behaves as a EF21 with Top-𝐾. Only in a few cases 3PCv4 shows an improvement over EF21.

10 3

L±avg = 0.0; Lavg = 1.0

10 3 L±avg = 0.05; Lavg = 1.01

10 3 L±avg = 0.86; Lavg = 1.16

10 3 L±avg = 1.72; Lavg = 1.32

10 3 L±avg = 6.88; Lavg = 2.29

3PCv4-Top10-Top90; 32x

3PCv4-Top10-Top90; 32x

3PCv4-Top10-Top90; 32x

3PCv4-Top10-Top90; 32x

3PCv4-Top10-Top90; 32x

3PCv4-Top20-Top80; 32x

3PCv4-Top20-Top80; 32x

3PCv4-Top20-Top80; 32x

3PCv4-Top20-Top80; 32x

3PCv4-Top20-Top80; 32x

3PCv4-Top30-Top70; 32x

3PCv4-Top30-Top70; 32x

3PCv4-Top30-Top70; 32x

3PCv4-Top30-Top70; 32x

3PCv4-Top30-Top70; 32x

3PCv4-Top40-Top60; 32x

3PCv4-Top40-Top60; 32x

3PCv4-Top40-Top60; 32x

3PCv4-Top40-Top60; 32x

3PCv4-Top40-Top60; 32x

3PCv4-Top50-Top50; 32x

3PCv4-Top50-Top50; 32x

3PCv4-Top50-Top50; 32x

3PCv4-Top50-Top50; 32x

3PCv4-Top50-Top50; 32x

10 5

3PCv4-Top60-Top40; 32x 3PCv4-Top70-Top30; 32x

10 5

3PCv4-Top60-Top40; 32x 3PCv4-Top70-Top30; 32x

10 5

3PCv4-Top60-Top40; 32x 3PCv4-Top70-Top30; 32x

10 5

3PCv4-Top60-Top40; 32x 3PCv4-Top70-Top30; 32x

10 5

3PCv4-Top60-Top40; 32x 3PCv4-Top70-Top30; 32x

3PCv4-Top80-Top20; 32x

3PCv4-Top80-Top20; 32x

3PCv4-Top80-Top20; 32x

3PCv4-Top80-Top20; 32x

3PCv4-Top80-Top20; 32x

3PCv4-Top90-Top10; 32x

3PCv4-Top90-Top10; 32x

3PCv4-Top90-Top10; 32x

3PCv4-Top90-Top10; 32x

3PCv4-Top90-Top10; 32x

EF21-Top100; 32x

EF21-Top100; 32x

EF21-Top100; 32x

EF21-Top100; 32x

EF21-Top100; 32x

10 7 0
10 3
10 5

10

20

3PCv4-Top1-Top9; 64x 3PCv4-Top2-Top8; 64x 3PCv4-Top3-Top7; 64x 3PCv4-Top4-Top6; 64x 3PCv4-Top5-Top5; 64x 3PCv4-Top6-Top4; 64x 3PCv4-Top7-Top3; 64x 3PCv4-Top8-Top2; 64x 3PCv4-Top9-Top1; 64x EF21-Top10; 64x

10 7 0
10 3
10 5

10

20

3PCv4-Top1-Top9; 256x 3PCv4-Top2-Top8; 256x 3PCv4-Top3-Top7; 256x 3PCv4-Top4-Top6; 256x 3PCv4-Top5-Top5; 256x 3PCv4-Top6-Top4; 256x 3PCv4-Top7-Top3; 256x 3PCv4-Top8-Top2; 256x 3PCv4-Top9-Top1; 256x EF21-Top10; 256x

10 7 0
10 3
10 5

10 7

10

20

30

0

10 3
3PCv4-Top1-Top9; 256x

3PCv4-Top2-Top8; 256x

3PCv4-Top3-Top7; 256x

3PCv4-Top4-Top6; 256x

3PCv4-Top5-Top5; 256x

3PCv4-Top6-Top4; 256x 3PCv4-Top7-Top3; 256x

10 5

3PCv4-Top8-Top2; 256x

3PCv4-Top9-Top1; 256x

EF21-Top10; 256x

5

10

3PCv4-Top1-Top9; 256x 3PCv4-Top2-Top8; 256x 3PCv4-Top3-Top7; 256x 3PCv4-Top4-Top6; 256x 3PCv4-Top5-Top5; 256x 3PCv4-Top6-Top4; 256x 3PCv4-Top7-Top3; 256x 3PCv4-Top8-Top2; 256x 3PCv4-Top9-Top1; 256x EF21-Top10; 256x

10 7 0
10 3
10 5

5000

10000

3PCv4-Top1-Top9; 256x 3PCv4-Top2-Top8; 256x 3PCv4-Top3-Top7; 256x 3PCv4-Top4-Top6; 256x 3PCv4-Top5-Top5; 256x 3PCv4-Top6-Top4; 256x 3PCv4-Top7-Top3; 256x 3PCv4-Top8-Top2; 256x 3PCv4-Top9-Top1; 256x EF21-Top10; 256x

10 7 0

5

10

#Mbits/n

10 7 0

1

2

#Mbits/n

10 7

3

0

2 #Mbits/n

10 7 0

2 #Mbits/n

10 7

4

0

20

40

60

#Mbits/n

Figure 14: Comparison of 3PCv4 with methods with Top𝐾1-Top𝐾2 with 𝐾1 + 𝐾2 = 𝑑/𝑛 and tuned stepsizes. By 1×, 2×, 4× (and so on) we indicate that the stepsize is set to a multiple of the largest stepsize predicted by theory. 𝐿𝑎±𝑣𝑔 and 𝐿𝑎−𝑣𝑔 are the averaged constants 𝐿± and 𝐿− per column.

46

n = 100 || f(xt)||2

n = 10 || f(xt)||2

n = 100 || f(xt)||2

10 3

L±avg = 0.0; Lavg = 1.0

10 3 L±avg = 0.05; Lavg = 1.01

10 3 L±avg = 0.84; Lavg = 1.1

10 3 L±avg = 1.69; Lavg = 1.2

10 3 L±avg = 6.74; Lavg = 1.79

3PCv4-Top2-Top18; 32x

3PCv4-Top2-Top18; 128x

3PCv4-Top2-Top18; 128x

3PCv4-Top2-Top18; 256x

3PCv4-Top2-Top18; 128x

3PCv4-Top4-Top16; 32x

3PCv4-Top4-Top16; 128x

3PCv4-Top4-Top16; 128x

3PCv4-Top4-Top16; 128x

3PCv4-Top4-Top16; 128x

3PCv4-Top6-Top14; 32x

3PCv4-Top6-Top14; 128x

3PCv4-Top6-Top14; 128x

3PCv4-Top6-Top14; 128x

3PCv4-Top6-Top14; 128x

3PCv4-Top8-Top12; 32x

3PCv4-Top8-Top12; 128x

3PCv4-Top8-Top12; 128x

3PCv4-Top8-Top12; 256x

3PCv4-Top8-Top12; 128x

3PCv4-Top10-Top10; 32x

3PCv4-Top10-Top10; 128x

3PCv4-Top10-Top10; 128x

3PCv4-Top10-Top10; 256x

3PCv4-Top10-Top10; 128x

3PCv4-Top12-Top8; 32x

3PCv4-Top12-Top8; 128x

3PCv4-Top12-Top8; 128x

3PCv4-Top12-Top8; 128x

3PCv4-Top12-Top8; 128x

10 5

3PCv4-Top14-Top6; 32x 10 5

3PCv4-Top14-Top6; 128x 10 5

3PCv4-Top14-Top6; 128x 10 5

3PCv4-Top14-Top6; 128x 10 5

3PCv4-Top14-Top6; 128x

3PCv4-Top16-Top4; 32x

3PCv4-Top16-Top4; 128x

3PCv4-Top16-Top4; 128x

3PCv4-Top16-Top4; 128x

3PCv4-Top16-Top4; 128x

3PCv4-Top18-Top2; 32x

3PCv4-Top18-Top2; 128x

3PCv4-Top18-Top2; 128x

3PCv4-Top18-Top2; 256x

3PCv4-Top18-Top2; 128x

EF21-Top20; 32x

EF21-Top20; 128x

EF21-Top20; 128x

EF21-Top20; 128x

EF21-Top20; 128x

10 7 0
10 3
10 5

10

20

3PCv4-Top2-Top18; 32x 3PCv4-Top4-Top16; 32x 3PCv4-Top6-Top14; 32x 3PCv4-Top8-Top12; 32x 3PCv4-Top10-Top10; 32x 3PCv4-Top12-Top8; 32x 3PCv4-Top14-Top6; 32x 3PCv4-Top16-Top4; 32x 3PCv4-Top18-Top2; 32x EF21-Top20; 32x

10 7 0
10 3
10 5

2

4

6

3PCv4-Top2-Top18; 128x 3PCv4-Top4-Top16; 128x 3PCv4-Top6-Top14; 128x 3PCv4-Top8-Top12; 128x 3PCv4-Top10-Top10; 128x 3PCv4-Top12-Top8; 128x 3PCv4-Top14-Top6; 128x 3PCv4-Top16-Top4; 128x 3PCv4-Top18-Top2; 128x EF21-Top20; 128x

10 7 0.0
10 3
10 5

10 7

2.5

5.0

7.5

0

10 3
3PCv4-Top2-Top18; 256x 3PCv4-Top4-Top16; 128x 3PCv4-Top6-Top14; 256x 3PCv4-Top8-Top12; 256x 3PCv4-Top10-Top10; 128x 3PCv4-Top12-Top8; 128x
3PCv4-Top14-Top6; 128x 10 5
3PCv4-Top16-Top4; 128x 3PCv4-Top18-Top2; 128x EF21-Top20; 128x

1

2

3

3PCv4-Top2-Top18; 256x 3PCv4-Top4-Top16; 256x 3PCv4-Top6-Top14; 256x 3PCv4-Top8-Top12; 256x 3PCv4-Top10-Top10; 256x 3PCv4-Top12-Top8; 256x 3PCv4-Top14-Top6; 256x 3PCv4-Top16-Top4; 256x 3PCv4-Top18-Top2; 128x EF21-Top20; 256x

10 7 0
10 3
10 5

1000 2000
3PCv4-Top2-Top18; 256x 3PCv4-Top4-Top16; 256x 3PCv4-Top6-Top14; 256x 3PCv4-Top8-Top12; 256x 3PCv4-Top10-Top10; 256x 3PCv4-Top12-Top8; 256x 3PCv4-Top14-Top6; 256x 3PCv4-Top16-Top4; 256x 3PCv4-Top18-Top2; 256x EF21-Top20; 256x

10 7 0
10 3
10 5

10

20

3PCv4-Top2-Top18; 32x 3PCv4-Top4-Top16; 32x 3PCv4-Top6-Top14; 32x 3PCv4-Top8-Top12; 32x 3PCv4-Top10-Top10; 32x 3PCv4-Top12-Top8; 32x 3PCv4-Top14-Top6; 32x 3PCv4-Top16-Top4; 32x 3PCv4-Top18-Top2; 32x EF21-Top20; 32x

10 7 0
10 3
10 5

2

4

6

3PCv4-Top2-Top18; 128x 3PCv4-Top4-Top16; 128x 3PCv4-Top6-Top14; 128x 3PCv4-Top8-Top12; 128x 3PCv4-Top10-Top10; 128x 3PCv4-Top12-Top8; 128x 3PCv4-Top14-Top6; 128x 3PCv4-Top16-Top4; 128x 3PCv4-Top18-Top2; 128x EF21-Top20; 128x

10 7 0
10 3
10 5

10 7

2

4

6

0

10 3
3PCv4-Top2-Top18; 128x 3PCv4-Top4-Top16; 256x 3PCv4-Top6-Top14; 128x 3PCv4-Top8-Top12; 256x 3PCv4-Top10-Top10; 256x 3PCv4-Top12-Top8; 256x
3PCv4-Top14-Top6; 128x 10 5
3PCv4-Top16-Top4; 256x 3PCv4-Top18-Top2; 256x EF21-Top20; 256x

2

4

3PCv4-Top2-Top18; 256x 3PCv4-Top4-Top16; 256x 3PCv4-Top6-Top14; 256x 3PCv4-Top8-Top12; 256x 3PCv4-Top10-Top10; 256x 3PCv4-Top12-Top8; 256x 3PCv4-Top14-Top6; 256x 3PCv4-Top16-Top4; 256x 3PCv4-Top18-Top2; 256x EF21-Top20; 256x

10 7 0
10 3
10 5

20

40

60

3PCv4-Top2-Top18; 256x 3PCv4-Top4-Top16; 256x 3PCv4-Top6-Top14; 256x 3PCv4-Top8-Top12; 256x 3PCv4-Top10-Top10; 256x 3PCv4-Top12-Top8; 256x 3PCv4-Top14-Top6; 256x 3PCv4-Top16-Top4; 256x 3PCv4-Top18-Top2; 256x EF21-Top20; 256x

10 7 0

10

20

#Mbits/n

10 7 0

2

4

#Mbits/n

10 7

6

0

2

4

6

#Mbits/n

10 7 0

2

4

#Mbits/n

10 7 0

5

10

15

#Mbits/n

Figure 15: Comparison of 3PCv4 with methods with Top𝐾1-Top𝐾2 with 𝐾1 + 𝐾2 = 0.02𝑑 and tuned stepsizes. By 1×, 2×, 4× (and so on) we indicate that the stepsize is set to a multiple of the largest stepsize predicted by theory. 𝐿𝑎±𝑣𝑔 and 𝐿𝑎−𝑣𝑔 are the averaged constants 𝐿± and 𝐿− per column.

n = 1000 || f(xt)||2

3PCv1 The next sequence of plots compares EF21 with Top-𝐾, 3PCv1 with Top-𝐾 and classical GD. Since all methods communicates different amount of ﬂoats8 on each iteration they are compared in terms of the # communication rounds. Yet being unpractical, 3PCv1 can provide an intuition of how the intermediate method between GD and EF21 could work and what performance can be achieved in 3PCv1 by additional sending 𝑑 dimensional vector from each node to the server. Figure 16 illustrates that in low Hessian variance regime 3PCv1 with Top-𝐾 behaves as a classical GD, whereas in a more heterogeneous regime, it can loose GD in terms of the number of communication rounds.
8Each node in EF21 with Top-𝐾 send exactly 𝐾 ﬂoats on server, whereas for 3PCv1 with Top-𝐾 and GD server receives 𝑑 + 𝐾 and 𝑑 ﬂoats from each node respectively.
47

n = 10 || f(xt)||2

n = 100 || f(xt)||2

103 101 10 1 10 3 10 5 10 7
0 103 101 10 1 10 3 10 5 10 7
0 103 101 10 1 10 3 10 5 10 7
0

L±avg = 0.0; Lavg = 1.0

103

EF21-Top20; 32x

3PCv1-Top20; 2x

GD; 1x

101

L±avg = 0.05; Lavg = 1.01
EF21-Top20; 128x 3PCv1-Top20; 2x GD; 1x

10 1

10 3

10 5

10 7

5000

10000 0

103
EF21-Top20; 32x

3PCv1-Top20; 2x

GD; 1x

101

2000 4000 6000
EF21-Top20; 128x 3PCv1-Top20; 2x GD; 1x

10 1

10 3

10 5

10 7

5000

10000 0

103
EF21-Top20; 32x

3PCv1-Top20; 2x

GD; 1x

101

2000 4000 6000
EF21-Top20; 128x 3PCv1-Top20; 2x GD; 1x

10 1

10 3

10 5

10 7

5000

10000 0

communication rounds

2000 4000 6000 communication rounds

103 101 10 1 10 3 10 5 10 7
0 103 101 10 1 10 3 10 5 10 7
0 103 101 10 1 10 3 10 5 10 7
0

L±avg = 0.84; Lavg = 1.1
EF21-Top20; 128x 3PCv1-Top20; 2x GD; 1x
2000 4000 6000
EF21-Top20; 128x 3PCv1-Top20; 2x GD; 1x
2000 4000 6000
EF21-Top20; 256x 3PCv1-Top20; 2x GD; 1x
2000 4000 6000 communication rounds

103 101 10 1 10 3 10 5 10 7
0 103 101 10 1 10 3 10 5 10 7
0 103 101 10 1 10 3 10 5 10 7
0

L±avg = 1.69; Lavg = 1.2

EF21-Top20; 128x 3PCv1-Top20; 2x

103

GD; 1x

101

L±avg = 6.74; Lavg = 1.79
EF21-Top20; 128x 3PCv1-Top20; 2x GD; 1x

10 1

10 3

10 5

10 7 1000 2000 3000 0.0

103
EF21-Top20; 256x

3PCv1-Top20; 2x

GD; 1x

101

0.5

1.0

1e6

EF21-Top20; 256x 3PCv1-Top20; 4x GD; 1x

10 1

10 3

10 5

10 7

2000 4000 6000

0

103
EF21-Top20; 256x

3PCv1-Top20; 2x

GD; 1x

101

20000

40000

EF21-Top20; 256x 3PCv1-Top20; 8x GD; 1x

10 1

10 3

10 5

2500 5000 7500 communication rounds

10 7 0

5000

10000

communication rounds

Figure 16: Comparison of GD , 3PCv1 with Top-𝐾 and EF21 with Top-𝐾 for 𝐾 = 0.02𝑑 and tuned stepsizes. By 1×, 2×, 4× (and so on) we indicate that the stepsize is set to a multiple of the largest stepsize predicted by theory. 𝐿𝑎±𝑣𝑔 and 𝐿𝑎−𝑣𝑔 are the averaged constants 𝐿± and 𝐿− per column.

n = 1000 || f(xt)||2

E.3. Testing compressed lazy aggregation (CLAG)
Following Richta´rik et al. (2021), we show the performance advantages of CLAG. We recall that we are interested in solving the non-convex logistic regression problem,

1

𝑁
∑︁

⊤

𝑑
∑︁

𝑥2𝑗

min 𝑓 (𝑥) =

𝑑

𝑁

log(1 + exp(−𝑦𝑖𝑎𝑖 𝑥)) + 𝜆

1 + 𝑥2 ,

(80)

𝑥∈R 𝑖=1

𝑗=1

𝑗

where 𝑎𝑖 ∈ R𝑑, 𝑦𝑖 ∈ {−1, 1} are the training data, and 𝜆 > 0 is a regularization parameter. Parameter 𝜆 is always set to 0.1 in the experiments. We use four LIBSVM (Chang & Lin, 2011) datasets phishing, w6a, a9a, ijcnn1 as training data. A dataset has been evenly split into 𝑛 = 20 equal parts where each part represents a separate client dataset (the remainder of partition between clients has been withdrawn).
Heatmap of communication complexities of CLAG for different combinations of parameters. In our ﬁrst group of experiments (see Figures 17, 18, 19, 20), we run CLAG with Top-𝐾 compressor. The compression level 𝐾 varies evenly between 1 and 𝑑, where 𝑑 is the number of features of a chosen dataset. Trigger 𝜁 passes zero and subsequent powers of two from zero to eleven. For each combination of 𝐾 and 𝜁, we compute empirically the minimum number of bits per worker sent from clients to the server. Minimum is taken among 12 launches of CLAG with different scalings of the theoretical stepsize, scales are powers of two from zero to eleven. The stopping criterion for each launch is based on the condition: ‖∇𝑓 (𝑥)‖ < 𝛿, where 𝛿 equals to 10−4 for phishing and to 10−2 for a9a, ijcnn1 and w6a datasets. Since the algorithm may not converge with too large stepsizes, the time limit of ﬁve minutes has been set for one launch. We stress that CLAG reduces to LAG when 𝑘 = 𝑑 and to EF21 when 𝜁 = 0. The experiment shows that for the most of datasets (excluding phishing) the minimum communication complexity is attained at a combination of (𝐾, 𝜁), which does not reduce CLAG to EF21 or LAG. Thus CLAG can be consistently faster than EF21 and LAG.

48

Plots for limited communication cost. In our second group of experiments (see Figures 21, 22, 23, 24), we are in the same setup as in the previous one but this time the stopping criterion bounds the communication cost of algorithms; CLAG, LAG and EF21 stop when they ﬁrst hit the communication cost of 32 Mbits per client. Compression levels 𝐾 for each dataset at each plot correspond to 1, 25% and 50% of features. Stepsizes for each algorithm is ﬁne-tuned over the same grid as in the previous experiment. The best 𝜁 are chosen for CLAG and LAG from the same grid as in the previous experiment. The experiment exhibits again but from the different perspective the advantages of CLAG over its counterparts.

68 58 48 comp3r9ession l2e9vel K 20 10 1

EF21

phishing

12448 12704 12704 12704 12160 12736 13088 13408 13760 11136 13088 13603 12262

13696 13056 13056 13056 12416 12688 12560 12528 12512 12624 12768 12720 12960

28000 22000

13056 11776 11776 12224 12416 12224 11776 11104 11776 11136 11168 11136 11136

12384 14240 14240 15168 12476 13312 13776 13312 14332 14147 14240 13915 14240

15000

14656 15904 14656 15904 14656 13782 14656 14656 13532 13408 13408 13408 13408

19072 19072 14464 16000 14387 14464 13004 12928 12928 13081 12928 12928 12928 15168 16745 13312 17024 13312 13312 13312 13312 15168 13312 15168 15168 15168

10000

23936 13817 23936 15232 13056 28288 23936 26112 21760 23936 6528 21760 21760 LAG 7000 0 1 2 4 8 16 trig3g2er 64 128 256 512 1024 2048

Figure 17: Heatmap of communication complexities of CLAG for different combination of compression levels and triggers with ﬁne-tuned stepsizes on phishing dataset. We contour cells corresponding to EF21 and LAG, as special cases of CLAG, by black rectangles. The red-countered cell indicates the experiment with the smallest communication cost.

49

300 266 233 2c0o0mp1r6es7sio1n3l3evel10K0 67 34 1

EF21

w6a

27520 27456 27456 27456 27360 27392 27296 27232 27060 26950 26651 26139 26067 25059

27008 25920 25920 25920 27443 25593 27008 26137 25376 24451 22819 22656 22003 21622

24608 28896 28896 27073 26323 24393 23750 24179 22785 22249 20534 21070 20856 22142

25600 32000 31040 28320 22400 22080 25600 23360 22560 22080 22400 22400 22400 22400

26624 38966 29603 30241 28539 29390 30241 27900 26411 25985 26411 22580 22580 22580

25632 47008 25632 30976 25899 28571 27769 27235 25632 25632 25632 20020 20288 20288

35200 48000 28800 23040 23680 24640 24320 24320 16000 16000 16000 16000 16000 16000

31968 54336 31968 26748 24512 24512 24884 25630 24512 17056 24512 17056 17056 17056

35136 60672 35136 35136 27049 19388 20665 23644 22368 19388 21516 23219 18112 18112

38400 41280 38400 38400 34080 19200 28800 19200 19200 19200 19200 19200 28800 28800 LAG 0 1 2 4 8 16 3t2rigger64 128 256 512 1024 2048 4096

60000 45000 32000 22000 16000

Figure 18: Heatmap of communication complexities of CLAG for different combination of compression levels and triggers with ﬁne-tuned stepsizes on w6a dataset. We contour cells corresponding to EF21 and LAG, as special cases of CLAG, by black rectangles. The red-countered cell indicates the experiment with the smallest communication cost.

22 19 17 1c5ompr1e2ssion1l0evel 8K 5 3 1

EF21

ijcnn1.bz2

3008 3872 3872 3872 3883 3054 2867 4808 4880 4811 4872 3288

4544 3363 3070 2835 2691 2628 2926 4884 2216 2681 3497 3929

5984 4160 2464 2952 2568 3352 5216 2352 5128 5224 3512 3568

9152 4505 2918 3379 5888 5696 7667 8230 3724 8652 3968 8652

5184 4496 9088 3520 3568 4736 7344 5520 4768 5296 7296 6144

6080 7462 9267 9651 7136 6464 6368 6003 4678 4064 8038 9324

14624 7040 9824 8792 7688 3560 7448 10304 4592 4256 4160 10088

13216 7041 6905 12128 11176 4267 6742 3369 9979 5980 6089 9326

24416 8668 12712 4595 5142 7027 5324 6601 5537 4504 6176 4291

16896 9328 7497 4998 10313 14995 9046 4963 4892 8060 5632 10032 LAG 0 1 2 4 8 16trigger 32 64 128 256 512 1024

24000 15000 8500 4500 2500

Figure 19: Heatmap of communication complexities of CLAG for different combination of compression levels and triggers with ﬁne-tuned stepsizes on ijcnn1 dataset. We contour cells corresponding to EF21 and LAG, as special cases of CLAG, by black rectangles. The red-countered cell indicates the experiment with the smallest communication cost.

50

123 105 88 comp7r0ession l5e3vel K 35 18 1

EF21

a9a

11360 11296 11296 11296 11104 11360 11392 10880 11328 11620 11699 13502

45000

12000 13152 13670 17184 19488 21792 19459 20035 19516 19171 18912 18739

18496 18496 25328 19616 19784 19616 19672 19616 19616 19616 19616 19616 17504 17504 17504 19200 19200 18860 17504 17504 17504 17504 17504 17504

30000

30816 26336 21856 24096 19616 24096 24096 19616 19616 17376 17376 17376 26464 22944 37728 48992 40544 40544 37728 37728 28716 18016 20832 17734

20000

47616 22416 40896 47616 44256 40896 37536 37536 34344 37536 34176 34176

35424 33652 39360 47232 39360 35424 35424 33259 31488 31488 31488 31488 LAG 0 1 2 4 8 16trigger 32 64 128 256 512 1024

11000

Figure 20: Heatmap of communication complexities of CLAG for different combination of compression levels and triggers with ﬁne-tuned stepsizes on a9a dataset. We contour cells corresponding to EF21 and LAG, as special cases of CLAG, by black rectangles. The red-countered cell indicates the experiment with the smallest communication cost.We contour cells corresponding to EF21 and LAG, as special cases of CLAG, by black rectangles. The red-countered cell indicates the experiment with the smallest communication cost.

|| f(xt)||2

k = 1

k = 17

k = 34

10 2

10 4

10 6

10 8

10 10

10 12

10 14

10 16 10 18
10 20

EF21 64x
LAG 1x, = 0.0039 CLAG 64x, = 16.0

10 2

10 4

10 6

10 8

10 10

10 12

10 14

10 16 10 18
10 20

EF21 4x
LAG 1x, = 0.0039 CLAG 4x, = 16.0

10 2

10 4

10 6

10 8

10 10

10 12

10 14

10 16 10 18
10 20

EF21 4x
LAG 1x, = 0.0039 CLAG 4x, = 0.0039

0

10

20

30

#Mbits/n

0

10

20

30

#Mbits/n

0

10

20

30

#Mbits/n

Figure 21: Comparison of CLAG, LAG and EF21 with Top-𝐾 with ﬁne-tuned stepsizes on phishing dataset

51

|| f(xt)||2

|| f(xt)||2

10 1 10 2 10 3 10 4 10 5 10 6 0

k = 1
EF21 16x
LAG 4x, = 0.0039 CLAG 16x, = 256.0
20 #Mbits/n

10 1 10 2 10 3 10 4 10 5 40 10 6 0

k = 75
EF21 16x
LAG 4x, = 0.0039 10 1 CLAG 16x, = 0.0039
10 2

k = 150

10 3

20 #Mbits/n

10 4

EF21 16x

10 5

LAG 4x, = 0.0039

CLAG 16x, = 0.0039

40 10 6 0

20

40

#Mbits/n

Figure 22: Comparison of CLAG, LAG and EF21 with Top-𝐾 with ﬁne-tuned stepsizes on w6a dataset

k = 1 10 2

k = 5 10 2

k = 11 10 2

10 4

10 4

10 4

10 6

10 6

10 6

10 8

10 8

10 8

10 10

10 10

10 10

10 12 10 14

EF21 16x
LAG 1x, = 0.0039 CLAG 16x, = 256.0

10 12 10 14

EF21 16x
LAG 1x, = 0.0039 CLAG 16x, = 1.0

10 12 10 14

EF21 4x
LAG 1x, = 0.0039 CLAG 4x, = 256.0

0

10

20

30

#Mbits/n

0

10

20

30

#Mbits/n

0

10

20

30

#Mbits/n

Figure 23: Comparison of CLAG, LAG and EF21 with Top-𝐾 with ﬁne-tuned stepsizes on ijcnn1 dataset

k = 1 10 1

k = 30 10 1

k = 61 10 1

10 3

10 3

10 3

10 5

10 5

10 5

10 7

10 7

10 7

10 9

EF21 256x
LAG 1x, = 0.0039

10 9

EF21 16x
LAG 1x, = 0.0039

10 9

EF21 4x
LAG 1x, = 0.0039

10 11

CLAG 256x, = 1.0

10 11

CLAG 16x, = 1.0

10 11

CLAG 4x, = 256.0

0 10 20 30

0 10 20 30

0 10 20 30

#Mbits/n

#Mbits/n

#Mbits/n

Figure 24: Comparison of CLAG, LAG and EF21 with Top-𝐾 with ﬁne-tuned stepsizes on a9a dataset

|| f(xt)||2

52

