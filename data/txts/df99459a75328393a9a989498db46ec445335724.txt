arXiv:2006.16385v1 [cs.CR] 29 Jun 2020

On the Privacy-Utility Tradeoﬀ in Peer-Review Data Analysis
Wenxin Ding1, Nihar B. Shah1,2, Weina Wang1
Computer Science Department1, Machine Learning Department2 Carnegie Mellon University
{wenxind@andrew, nihars@cs, weinaw@cs}.cmu.edu
Abstract A major impediment to research on improving peer review is the unavailability of peer-review data, since any release of such data must grapple with the sensitivity of the peer review data in terms of protecting identities of reviewers from authors. We posit the need to develop techniques to release peer-review data in a privacy-preserving manner. Identifying this problem, in this paper we propose a framework for privacy-preserving release of certain conference peer-review data — distributions of ratings, miscalibration, and subjectivity — with an emphasis on the accuracy (or utility) of the released data. The crux of the framework lies in recognizing that a part of the data pertaining to the reviews is already available in public, and we use this information to post-process the data released by any privacy mechanism in a manner that improves the accuracy (utility) of the data while retaining the privacy guarantees. Our framework works with any privacy-preserving mechanism that operates via releasing perturbed data. We present several positive and negative theoretical results, including a polynomial-time algorithm for improving on the privacy-utility tradeoﬀ.
1 Introduction
A fair and eﬃcient peer-review process is of utmost importance to the development of scientiﬁc research. There are, however, a large number of challenges in peer review, pertaining to its fairness and eﬃciency. Consequently there is an overwhelming desire to “ﬁx” the “broken” peer review process [1, 2]. And taking heed to this call, there is a growing amount of research on this topic.
Research on improving peer review suﬀers from a considerable handicap – unavailability of data [3–6]. Concealing the identities of reviewers from authors of any paper is paramount in most peer review systems. Thus releasing any peer review data is fraught with the risk of compromising on this privacy.
As noted by Balietti et al. [3]:
“The main reason behind the lack of empirical studies on peer-review is the diﬃculty in accessing data. In fact, peer-review data is considered very sensitive, and it is very seldom released for scrutiny, even in an anonymous form.”
Although there is a large body of research on the topic of privacy in various domains, not much privacy research directly targets the application of peer review. In an inﬂuential recent paper [4] about peer review, Tomkins, Zhang and Heavlin highlight the challenges they faced in this respect and their consequent inability to release data:
“We would prefer to make available the raw data used in our study, but after some eﬀort we have not been able to devise an anonymization scheme that will simultaneously protect the identities of the parties involved and allow accurate aggregate statistical analysis. We are familiar with the literature around privacy preserving dissemination of data for statistical analysis and feel that releasing our data is not possible using current state-of-the-art techniques.”
We thus posit the need to develop techniques to help release peer-review data while ensuring that identities of reviewers of any paper are protected. With this motivation, we focus on the privacy-utility tradeoﬀ in
1

releasing certain conference peer-review data. The data to be released comprises distributions of the ratings or miscalibration or subjectivity in the peer-review process. The notion of privacy we consider is quite general – our techniques apply to any notion of privacy which operates by perturbing the data, including diﬀerential privacy. We design a framework to improve in this tradeoﬀ by improving the utility (accuracy) while retaining privacy guarantees.
Our work relies on the key the observation that a non-trivial part of conference peer-review data is already available in the public domain. We design techniques which use this publicly available information to post-process the data released by any privacy mechanism. Our approach is guided by the following four desiderata for such a post processing:
D1 Under no circumstances should the accuracy go down after applying the algorithm.
D2 Under no circumstances should the privacy guarantee be compromised after applying the algorithm.
D3 The algorithm should have a computational complexity that is polynomial in the number of reviewers and papers.1
D4 In special cases where an exact answer can be easily obtained from public data, the algorithm should also return the same answer with no error. (This is deﬁned formally in Section 4.3.1.)
Our technical contributions towards this problem are as follows. We ﬁrst argue that projecting the (noisy) output of the privacy mechanism on the convex hull of all possible true values is desirable from the perspective of the desiderata. We show that, however, such a projection is NP-hard (via reducing the -partition problem). We then design a polynomial-time computable algorithm which projects the noisy output of the privacy mechanism on a convex set containing all possible true values, and satisﬁes the four desiderata listed above. As a result of independent interest, we also prove that the more obvious approach of projecting on the set of all true values (instead of a convex set containing them) can, in fact, reduce the accuracy. Finally, we conduct synthetic simulations, which reveal that our methods can yield considerable improvements in the privacy-utility tradeoﬀ as compared to standard approaches. The code for our algorithm is available here: https://github.com/wenxind/privacy-utility-tradeoff-in-peer-review-data.
2 Related Work
This work falls in the intersection of two lines of research: peer review and privacy. Peer review: Peer review is the backbone of scientiﬁc research. There is an overwhelming desire in many domains of science and engineering for improving peer review, and consequently, there are many past works on the topic of either evaluating the eﬃcacy of peer review or improving the peer review process [8–17]. These works, however, largely focus on the journal reviewing setup that is common in non-computer-science ﬁelds, whereas our focus is on the conference reviewing setting which is more common in computer science.
The number of submissions to many computer science conferences, particularly to machine learning or artiﬁcial intelligence conferences, is growing near-exponentially and is presently in the several thousands. This rapid growth has spurred a considerable amount of recent research on peer review in computer science. These works include those on handling problems related to reviewer-assignment [18–22], miscalibration [23–25], subjectivity [26], biases [4,27], strategic behavior [3,28,29] and others [7,30–33]. In particular, as will be detailed later, our work is also useful towards releasing data pertaining to miscalibration and subjectivity, thereby helping in the understanding and mitigation of these problems.
Privacy: Privacy-preserving data analytics has been receiving rapidly increasing attention as the big-data regime emerges. There is a large body of research that investigates formal notion of privacy and quantiﬁes the tradeoﬀ between privacy and utility (see, e.g., [34–39]). Among these studies, diﬀerential privacy [34, 35] has become the de facto standard and has been applied to many areas.
Relaxations of diﬀerential privacy have also been proposed to enable more accurate data analysis [40–44]. For example, consider application scenarios such as federated learning where an individuals data may spread across multiple datasets. In such a scenario, the cumulative privacy loss of an individual needs to be
1In typical conferences, the number of papers per reviewer and the number of reviewers per paper are both constants [7].
2

constrained when each dataset releases its statistics with privacy-preserving mechanisms. The relaxation of ( , √δ)-diﬀerential privacy [40] allows the amplitude of the noise injected to each dataset to scale approximately as k with k being the number of datasets that contain a single individuals data. Such composition scalings can be further improved when the tail behavior of errors is of more interest [44].
In this paper, we investigate the privacy-utility tradeoﬀ for publishing histograms of peer-review data. Privacy-preserving release of histograms has been a major focus of the literature [40, 45–49]. To the best of our knowledge, existing techniques for improving the privacy-utility tradeoﬀ are generally inadequate for the application of peer review since they do not take into account the special structures in peer-review data. For example, as we pointed out, one special feature of peer-review data is that part of the data is already publicly available in a non-privacy-preserving form. As we discuss in the sequel, the idiosyncratic nature of the peer-review setting implies that one can design methods tailored to this application which yield a (considerable) improvement in the privacy-utility tradeoﬀ as compared to standard privacy mechanisms. We comment that the techniques we develop take inspiration from the constrained inference technique in [46], which enforces consistency among the noisy answers to multiple queries. But again, application scenarios of the approach in [46] do not possess the distinctive structures of peer-review data. We reiterate that our approach of improving accuracy is not speciﬁc to a particular privacy notion, but rather it is a post-processing framework that applies to any privacy-preserving mechanism. Such mechanisms include the widely used Laplace mechanism (which guarantees diﬀerential privacy), Gaussian mechanism [40, 41, 43], Sinh-Normal mechanism [44], as well as mechanisms that do not operate via addition of noise.
Peer review and privacy: An exception is the concurrent work [50] which considers releasing the reviewerpaper similarity matrix and source code for the reviewer assignment (whereas in contrast we consider releasing a function of the scores given by reviewers to papers). Their approach involves modifying and randomizing the reviewer-paper assignment process and their guarantees pertain to plausible deniability (that is, any reviewer may be assigned to any paper with a probability at most a certain value). On the other hand, we do not modify the peer-review process in any way, and instead use any privacy-preserving data-release mechanism coupled with post processing of the data from peer review.
3 Background and problem setting
In this section, we provide some background on the peer review setting and privacy, and describe our problem setting in more detail.
3.1 Peer review
We consider a conference peer review setting, where there are n reviewers and m papers. We index the papers as [m] = {1, 2, · · · , m} and the reviewers as [n] = {1, 2, · · · , n}.2 For simplicity we assume that the number of papers reviewed by each reviewer is the same for all reviewers – denoted as , and that the number of reviewers reviewing each paper is the same for all papers – denoted as k.3 Consequently, we have the relation n = mk. All four parameters (n, m, , k) are public knowledge.
Each review comprises a real-valued score. We assume that all papers and all associated reviews (that is, the set of scores received by each paper) are public knowledge (e.g., in conferences such as ICLR and others on the OpenReview.net review platform). The list of all reviewers is also available publicly (such a list is released by many conferences). However, importantly, the identity of which reviewer reviewed which paper is private.
We now introduce notation to describe the score given in any review. If reviewer j ∈ [n] reviews paper i ∈ [m], then we use sij ∈ R to denote the score of this review. This score is private in the sense that the identity of the reviewer who gives this score is not publicly available. However, for each paper i ∈ [m], the multiset {sij| reviewer j ∈ [n] reviews paper i} is public.
This setting can be described by a bipartite graph, as shown in Figure 1. The bipartite graph has two disjoint sets of vertices, [m] and [n] representing the sets of papers and reviewers, repectively. In private
2We follow the standard convention of using [β] to represent the set {1, 2, . . . , β} for any positive integer κ. 3Our work is also applicable to the most general setting in which diﬀerent reviewers and/or diﬀerent papers have diﬀerent loads. We discuss this in Section 4.3.3.
3

Paper 1 Paper 2 Paper 3

3

1

2

3

5

4

Ada Lovelace Alan Turing Albert Einstein

2

Paper 1

3

Paper 2 31

Paper 3

4

5

Ada Lovelace Alan Turing Albert Einstein

(a) Private data

(b) Public data

Figure 1: An illustration of the data (a) available privately to the program chairs of the conference, and (b) available to the public under increasingly popular ‘open review’ paradigms in computer science.

data (Figure 1a), an edge exists between any vertex (paper) i ∈ [m] and any vertex (reviewer) j ∈ [n] if reviewer j ∈ [n] reviews paper i ∈ [m]. We associate each edge (i, j) with the score sij. The edges (and their values) are all private. The private data is accessible to the program chairs of the conference. In public data (Figure 1b), for each vertex (paper) in [m], the weights of the edges connected to it are known publicly. However, the edges of the graph are not known. Note that in both public and private data, identities of papers and reviewers are known.
There are various quantities of interest for release that we consider in this work. An intermediate set of terms towards these quantities is the multiset {wij| reviewer j ∈ [n] reviews paper i ∈ [m]} discussed below, which we refer to as the set of weights. This multiset can be computed from the scores {sij| reviewer j ∈ [n] reviews paper i ∈ [m]}. We now discuss three such choices of {wij| reviewer j ∈ [n] reviews paper i ∈ [m]}, and subsequently describe the data we aim to release.

• Reviewer ratings. In this case, the mapping from scores to weights is simply the identity mapping:

wij = sij .

(3.1)

• Miscalibration. Miscalibration is the problem that some reviewers are strict and some are lenient [23– 25]. In order to understand the amount of miscalibration, it is instructive to see the diﬀerence between the scores given by a reviewer and the scores given by other reviewers for the same papers. To this end, we let wij denote the miscalibration in any individual review (for any paper i by any reviewer j):

1 wij = sij − k − 1 sij .
j =j

(3.2)

• Subjectivity. Subjectivity is the problem that diﬀerent reviewers place diﬀerent emphasis on the various criteria when making an overall decision for a paper [51]. Techniques such as that proposed in [26] can be used to normalize each score in a manner that mitigates the subjectivity. Speciﬁcally, the technique in [26] uses the public data to transform the score sij associated to each review into a normalized version, say, sij. We can then set wij = sij for every review, and the algorithm in this paper will help release statistics of these normalized scores. A second use case we consider is to better understand and investigate the issue of subjectivity, by releasing the amount of subjectivity present in the system, that is, the aggregate diﬀerence of reviewers’ scores and their normalized scores. Concretely in this case, after obtaining the normalized scores {sij| reviewer j ∈ [n] reviews paper i ∈ [m]}, we set wij = sij − sij for every review.
Analogous to the scores sij’s, the weights wij’s are also associated to public and private components. Note that we can use the same bipartite graphs as in Figure 1 to represent the setting with weights. In particular, the private data continues to include the edges pertaining to which reviewer reviewed which paper. The

4

private data also includes the weight wij on each edge (i, j) representing the weight that reviewer i ∈ [n] gives to paper j ∈ [m]. The private data is depicted in Figure 1a where in this interpretation, the values on the edges represent the weights. The public data, as in the case of scores, only includes the multiset of weights received by any paper, that is, the public data comprises the multisets {wij|reviewer j ∈ [n] reviews paper i} for every paper i ∈ [m]. The public data is depicted in Figure 1b where the values on the edges represent the weights.
It is very important to note the following two properties in the transformation of scores sij to weights wij for each of the aforementioned choices. First, clearly, given access to all private scores, all weights can be computed. Second, the public weights (that is, the multisets {wij|reviewer j ∈ [n] reviews paper i} for every paper i ∈ [m]) can be computed using only the publicly available score data (that is, the multisets {sij|reviewer j ∈ [n] reviews paper i} for every paper i ∈ [m]). This relation between the public (respectively, private) weights and public (respectively, private) scores allows us to interchange them in the graphs in Figure 1. For simplicity, the reader may choose to simply consider the “reviewer ratings” choice (3.1) and think of simply the scores as the corresponding weights.

For each reviewer j ∈ [n], let Yj be the set of all papers reviewed by reviewer j, that is, Yj = {i ∈ [m] | reviewer j reviews paper i}. Let yj denote the mean weight of reviewer j:

1

yj =

wij .

i∈Yj

(3.3)

Note that since the identity of the reviewer in any review is private, the values of Yj and yj in general cannot be computed from the public data.

Quantity to be released: The quantity of interest is the histogram of the mean weights per re-

viewer, represented by the sorted version of the mean-weight vector (y1, y2, ..., yn), which we denote by

θ∗

=

(θ

∗ 1

,

θ2∗

,

...,

θ

∗ n

).

Then θ1∗

≤ ... ≤ θn∗

and

the

multiset

(θ

∗ 1

,

θ2∗

,

...,

θ

∗ n

)

equals

the

multiset

(y1, y2, ..., yn).

We call θ∗ the true sorted mean-weight vector. According to the applications discussed above, the vector θ∗

can either represent the mean scores per reviewer or capture the amount of miscalibration, or subjectivity

in the reviews.

Our goal is to release θ∗, while ensuring privacy of reviewer identities. When the underlying weights are equal to the scores, the sorted mean-weight vector (that is, the histogram of scores) is commonly released by various conferences [7]. These are however usually released without any privacy considerations, and our work addresses privacy-preserving release with high accuracy. Addressing the issues of miscalibration and subjectivity is extremely important for fair and high-quality peer review [23–26, 51–53], and releasing the statistics pertaining to the amount of miscaliabraiton or subjectivity can considerably help both research and policy-design regarding these issues.
Publishing histograms of datasets in a privacy-preserving manner has been a central objective in the literature of privacy research [40, 45–49]. Histograms are typically the most frequently used statistics in oﬃcial reports, and more importantly, they form the basis for more complicated statistical analysis. To the best of our knowledge, existing techniques for improving the privacy-utility tradeoﬀ (for histograms or otherwise) are generally inadequate for the application of peer review since they do not take into account the special structures in peer-review data. Our goal is to use the speciﬁc type of publicly available data in peer review in order to improve the privacy-utility tradeoﬀ.
Finally we note that the high-level ideas behind our proposed algorithm are more general and may also be used to improve the utility of the released data for settings beyond the sorted mean-weight vector. We revisit this point later in the paper.

3.2 Privacy
To protect the privacy of reviewers, we consider privacy-preserving mechanisms that (randomly) perturb the quantities of interest. By virtue of the random perturbation, it is then hard to infer each individual reviewer’s scores given to papers from the noisy data. Speciﬁcally, we consider any privacy mechanism that

5

releases a vector r = (r1, r2, ..., rn) ∈ Rn obtained possibly by adding random noise to the true sorted mean-

weight

vector

(

θ

∗ 1

,

θ2∗

,

...,

θ

∗ n

)

∈

Rn.

An example of such a privacy mechanism is the Laplace mechanism,

which

satisﬁes

the

popular

notion

of

diﬀerential

privacy

[54, 55]

in

which

(r1, r2, ..., rn)

=

(

θ

∗ 1

,

θ2∗

,

...,

θ

∗ n

)

+

(η1, η2, ..., ηn). Here η1, η2, . . . , ηn are i.i.d. random variables drawn from a zero-mean Laplace distribution.

3.3 Utility (Accuracy)

Let t = (t1, · · · , tn) denote the ﬁnal output (after post-processing) that is released. We measure the utility or accuracy of the output in terms of its mean squared error with respect to the true value of the vector θ∗,
n
that is, E (θi∗ − ti)2 . We say that an (possibly random) output t = (t1, ..., tn) is more accurate than
i=1
another output t = (t1, ..., tn) with respect to θ∗ if

n

n

E (θi∗ − ti)2 < E (θi∗ − ti)2 .

i=1

i=1

(3.4)

3.4 Goal
Our goal is to design algorithms to process the data output by the privacy-preserving mechanism, r, before its actual release in a manner that improves the privacy-utility tradeoﬀ. Speciﬁcally, our goal is to design algorithms that satisfy the four desiderata D1–D4 listed in Section 1.

4 Theoretical Results
We present our main theoretical results in this section.

4.1 Approach
We ﬁrst derive a representation of the set of all possible values in the sorted mean-weight vector θ∗ based on the public data. For any paper i ∈ [m], we use xi1, xi2, · · · , xik to denote the k weights on edges connected to that vertex (paper) in the public data, listed in an arbitrary order. Note that the second subscript of xij does not correspond to a reviewer identity. The multiset {x11, · · · , xmk} is available publicly and for each i ∈ [m], the multiset {xi1, · · · , xik} is identical to the multiset {wij|reviewer j ∈ [n] reviews paper i}. Let G be a set of weighted bipartite graphs comprising all valid reviewer-paper weights based on the public data, that is, each member of G satisﬁes:

• It is a bipartite graph, with the vertices in the two parts corresponding to papers [m] and reviewers [n].

• All vertices in [m] are k regular and all vertices in [n] are regular.

• The k edges incident on any vertex i ∈ [m] have weights xi1, xi2,. . . , xik.

Furthermore, for any graph g ∈ G, any paper i and reviewer j, we deﬁne wij(g) equal to the weight of edge between i and j if this edge exists, and wij(g) = 0 otherwise. Then the set Θ, that comprises all possible values of the sorted mean-weight vector based on public data, is given by

1m

Θ = θ ∈ Rn | θ1 ≤ ... ≤ θn, ∃g ∈ G such that θj =

wij(g) for all j ∈ [n] .

i=1

(4.1)

Note that the true paper-reviewer graph is also a member of G and the true sorted weight vector θ∗ ∈ Θ.
Throughout this section, we consider algorithms that are based on projecting the released data on certain sets. To this end, for any set C ⊆ Rn, we deﬁne the projection of vector r on the set C as

n
argmin (θi − ri)2.
θ∈C i=1

(4.2)

6

When the privacy-preserving algorithm perturbs the true sorted mean-weight vector θ∗, the resulting noisy mean-weight vector r may not lie in the set Θ. It is thus intuitive to instead replace the resulting vector with the vector in Θ closest to it, that is, to instead output the projection (4.2) of the vector r with the choice C = Θ.
The following result shows that this intuitive approach can actually increase the error. We state and prove this result concretely in the case of additive Laplace noise, but as seen in the proof, the result is much more general.

Proposition 4.1. There exists a review setting such that the true sorted mean-weight vector θ∗, the noisy mean-weight vector r obtained by adding Laplace noise with zero mean and a ﬁxed, non-zero variance to θ∗,
and the output t of the projection (4.2) of r on the set C = Θ, are related as

n

n

E (ti − θi∗)2 > E (ri − θi∗)2 ,

i=1

i=1

(4.3)

where the expectation is taken with respect to the noise distribution.

The proposition implies that using the closest valid vector violates desideratum D1 of not reducing the accuracy. The proof of Proposition 4.1 is given in Section A.1.
Consequently, in order to ensure desideratum D1 of not reducing the accuracy is met, we project the noisy data onto a convex set that contains Θ. The following proposition (proved in Section A.2) indicates that such projection can never harm the accuracy, and is a straightforward application of the fact that projection on to convex sets is non-expansive.

Proposition 4.2. Consider any true sorted mean-weight vector θ∗, set Θ to comprise all possible true sorted

mean-weight vectors, and any arbitrary (noisy mean-weight) vector r. Let C be any closed convex set such

that Θ ⊆ C. Let t = (t1, ..., tn) be the projection of r on to set C as in (4.2). Then it must be that

n

n

(ti − θi∗)2 ≤ (ri − θi∗)2.

(4.4)

i=1

i=1

Since proposition 4.2 holds for all r, it follows that if r is obtained by randomly perturbing θ∗, then

n

n

E (ti − θi∗)2 ≤ E (ri − θi∗)2 .

i=1

i=1

(4.5)

Moreover, for two closed convex sets C1 ⊆ C2, if we have a projection on C2, then further projecting it on C1 can never increase the error and can possibly decrease the error. Our goal thus is to project the noisy data on to a (small) convex set that contains all possible true values.

4.2 NP-hardness of Projection onto Convex Hull

The smallest convex set that contains Θ is the convex hull of Θ. Observe that if we could project on

to the convex hull, then it can also be used to improve upon the projection on any other convex set.

Speciﬁcally, if t is the projection of the perturbed data r on some convex set that contains Θ, and if t is

the projection of t on convex-hull(Θ), then with an argument identical to that in Proposition 4.2 we have

n

n

that (ti − θi∗)2 ≤ (ri − θi∗)2.

i=1

i=1

Consequently, in this section we consider the goal of projecting the noisy data onto the convex hull of Θ.

In this case, the ﬁnal result we would like to output can be represented as choosing C = convex-hull(Θ) in

Equation (4.2). Unfortunately, as we show below, projection onto convex-hull(Θ) is NP-hard.

Theorem 4.3. When k = > 2, m = n and n is a multiple of , the problem of projecting noisy data onto convex-hull(Θ) is NP-hard.

We prove this result via reducing the -Partition problem to the projection problem. Given any instance of an -Partition problem, which is a multiset of integers, we can construct a conference where each paper has a weight from the multiset. We can construct a vector such that the projection result can directly answer the -Partition problem. The complete proof of Theorem 4.3 is provided in Section A.3.
Remark 4.4. The proof of Theorem 4.3 also shows that projection on to Θ is NP-hard.

7

4.3 An Eﬃcient Algorithm
In this section, we present an algorithm that meets the four desiderata D1–D4 listed in Section 1. Since we cannot eﬃciently project on to the convex hull of Θ, we must make do with a larger convex set that contains Θ. We use desideratum D4 for guidance on what constitutes a reasonably small set and associated projection.
4.3.1 Axioms deﬁning desideratum D4
Recall that desideratum D4 says that the algorithm should automatically recover the ground truth when the structure of the public data is simple enough. More concretely, we benchmark any algorithm using the following axiomatic properties:
A1 When all weights are identical, the projection should result in a vector whose entries are all the same as the weight. Formally, if xij = z ∀i ∈ [m], j ∈ [k] for some z, then the output t of the algorithm must be t1 = t2 = · · · = tn = z.
A2 When = 1 (that is, each reviewer reviews 1 paper), the projection of any noisy data should result in a sorted vector of all weights. Formally, if = 1 then the output t of the algorithm must be (t1, t2, · · · , tn) = sorted(x11, x21, · · · , xn1).
A3 When all but one papers have all zero weights, the projection of any noisy data should result in a sorted vector with (n − k) zero entries and the remaining entries equal to 1 of the weights for the paper that does not have all-zero weights. Formally, if xij = 0 ∀i ∈ {2, . . . , m}, j ∈ [k], then the output t of the algorithm must be (t1, t2, · · · , tn) = sorted( x11 , x12 , · · · , x1k , 0, · · · , 0).
4.3.2 High-level idea behind the algorithm
The main idea behind our algorithm comprises the following three steps:
I. From the public data, take all tuples of size containing weights from diﬀerent papers into consideration.
II. Use them to construct lower and upper bounds on every entry of (the unknown vector) θ∗.
III. Project the released data r on the set speciﬁed by the aforementioned lower and upper bounds, along with any other problem-speciﬁc (convex) constraints.
As one can intuitively see, these three steps imply a projection of the released data on a convex set which includes all valid values of the true data, and hence from Proposition 4.2 it will not reduce the utility (desideratum D1). Moreover, the entire algorithm uses only the public data along with the vector r released by the privacy mechanism, and hence does not compromise privacy (desideratum D2). The idea is general enough to be applied to many forms of the released data, and in what follows, we apply it to release the histogram of the true sorted mean-weight vector. Of course, the devil lies in the details of how these steps are executed, which will determine whether the designed algorithm meets desiderata D3 and D4.
4.3.3 Full algorithm description
We now describe our algorithm in full detail; we provide an illustrative example subsequently in Section 4.3.4. Recall that we use xi1, xi2, · · · , xik to represent the k weights on edges connected to any vertex (paper) i ∈ [m] in the public data. Note that since reviewer identities are not available publicly, the second subscript “j” in “xij” has no particular meaning other than capturing the fact that each paper has k weights. We use
 x11 · · · x1k   x21 · · · x2k  matrix X to display all the weights in the public data where X =  ... . . . ...  .
xm1 ... xmk I. Valid weight tuples
8

We deﬁne a weight tuple as a multiset of real values. We say that a tuple is a valid weight tuple if it consists of weights from distinct papers. In other words, a valid weight tuple contains entries of matrix X where no two entries are from the same row in X. We compute Ω as the list of all valid weight tuples. In other words, Ω contains all the possible weight tuples given by a reviewer. We sort the list Ω based on the mean weight of the weight tuples (breaking ties arbitrarily), and henceforth use the notation Ω for this sorted list.
II. Lower and upper bounds We now compute lower and upper bounds on each entry of θ∗ based only on the public data. We create a graph G which has all weight tuples in Ω as its vertices. Since each weight tuple in Ω corresponds to a vertex in graph G, we use the terms “weight tuples in Ω” and “vertices in G” interchangeably. There is an edge between two vertices if the two weight tuples do not contain weights from the same entry in X. Then for each vertex, we deﬁne its left chain and right chain as follows. Recall that Ω is a sorted list and all of its entries, which are weight tuples, are totally ordered. We use the indices of the tuples (vertices) in this ordering for the following deﬁnitions.
Deﬁnition 4.5 (Left chain). For any vertex ν in G, a left chain of ν is a simple path in G from ν to another vertex such that the indices of the vertices in this path decrease starting from ν.
Deﬁnition 4.6 (Right chain). For any vertex ν in G, a right chain of ν is a simple path in G from ν to another vertex such that the indices of the vertices in this path increase starting from ν.
We also deﬁne the length of a chain to be the number of vertices in the chain. For each vertex, we compute the length of its longest left chain and the length of its longest right chain using dynamic programming. To compute the length of the longest left chain of a vertex ν in G, we check the length of the longest left chain of all its neighbors at lower indices. Then the length of the longest left chain of ν is the maximum of these neighbors’ longest left chain lengths plus one. Similarly, to compute the length of the longest right chain of ν, we check the length of the longest right chain of all its neighbors at higher indices. The length of the longest right chain of ν is the maximum of its neighbors’ longest right chain lengths plus one. We store the length of the longest left and right chain of each vertex for subsequent use in the algorithm.
We ﬁrst present the algorithm to compute a lower bound on θi∗ for each i ∈ [n]. The computation for upper bounds is analogous to the computation for lower bounds. The algorithm for computing the lower bounds is presented in Algorithm 1.
In more detail, the algorithm uses two criteria to determine if mean of a weight tuple is a lower bound on θi∗. The criteria are
C1 The longest left chain of the tuple has length at least i.
C2 In X, after we mark the weights from each tuple considered so far, each row has at most n − i unmarked entries.
We call the n weight tuples that compute θ∗ the true weight tuples. The true weight tuple that has mean θi∗ must have i − 1 weight tuples that have smaller or equal mean to θi∗. No two reviewers give the same weight so no two true weight tuples contain weights from the same entry in X. Thus, criterion C1 is a necessary condition for a weight tuple to be the true weight tuple that computes θi∗. In addition, there are n − i entries in θ∗ whose values are no smaller than θi∗. Since no two true weight tuples contain weights from the same paper, each paper can have at most n − i unused weights for these entries. Therefore, each row of X cannot have more than n − i unmarked entries. Thus, criterion C2 is necessary for all weights to be assigned among the reviewers. For each entry i ∈ [n], we choose the valid weight tuple with the smallest mean that satisﬁes criteria C1 and C2 as the lower bound on θi∗. Hence, it is a valid lower bound.
The computation of upper bounds is similar to the above methodology and is presented in Algorithm 2. The two criteria we use to determine if mean of a tuple is an upper bound on θi∗ are
C3 The longest right chain of the tuple has length at least n − i + 1.
C4 In X, after we mark the weights from each tuple considered so far, each row has at most i − 1 unmarked entries.
9

Algorithm 1: Computation of lower bounds
Input: matrix X of weights, sorted list of weight tuples Ω Initialize i = 1, set w ∈ R as the ﬁrst tuple in Ω, and all entries of X are unmarked. while i ≤ n do
for each weight in the tuple w, ﬁnd its corresponding entry in matrix X and mark the entry if length of tuple w’s longest left chain ≥ i and number of unmarked entries on each row of X ≤ n − i then
lower bound on θi∗ = mean of all entries of tuple w i+ = 1 end if set w as the next tuple in Ω end while
Algorithm 2: Computation of upper bounds
Input: matrix X of weights, sorted list of weight tuples Ω Initialize i = n, w ∈ R as the last tuple in Ω, and all entries of X are unmarked. while i ≥ 1 do
for each weight in the tuple w, ﬁnd its corresponding entry in matrix X and mark the entry if length of tuple w’s longest right chain ≥ n − i + 1 and number of unmarked entries on each row of X ≤ i − 1 then
upper bound on θi∗ = mean of all entries of tuple w i− = 1 end if set w as the previous tuple in Ω end while

III. Projection Let Li denote the lower bound we compute on θi∗ and Ui denote the upper bound we compute on θi∗ in part II above. The ﬁnal output of our algorithm is the solution to the following optimization problem:

n
argmin (ηi − ti)2 such that Li ≤ ti ≤ Ui∀i ∈ [n],
t∈Rn i=1

n

1m k

ti =

xij ,

i=1

i=1 j=1

t1 ≤ t2 ≤ · · · ≤ tn.

(4.6)

This is a convex optimization problem with a quadratic objective and 2n linear constraints, and hence is solvable eﬃciently.

Remark 4.7 (Extension to non-uniform paper and reviewer loads). So far we have assumed that every reviewer reviews the same number of papers and every paper is reviewed by the same number of reviewers. We now discuss how to extend our algorithm to a setting where these assumptions may be violated. First, if the papers are reviewed by diﬀerent number of reviewers, the exact algorithm as described above continues to hold. Now if diﬀerent reviewers review diﬀerent numbers of papers, then we make the following modiﬁcation to the above algorithm. Let L ⊂ [m] denote the set of all paper loads on the reviewers, that is, ∈ L ⇐⇒ there is a reviewer who reviews exactly papers. Then the set Ω computed in the ﬁrst step of the algorithm includes all weight tuples of size for every ∈ L. The remainder of the algorithm remains identical to that described above. The proof of correctness in these settings follows from the same arguments (given in Section A.5) as those for the setting of uniform reviewer and paper loads. The algorithm continues to have a
10

computational complexity that is polynomial in n and m (we continue to assume that the maximum number of papers reviewed by any reviewer and the maximum number of reviews by any reviewer are constants).

4.3.4 An example

In this section, we illustrate our algorithm (described in Section 4.3.3) by means of an illustrative example.

Consider a case where n = m = 4, = k = 3. Let 3 papers among the 4 have all 0 weights and the

fourth

paper

has

weights

1,

2

and

3.

In

this

example,

we

can

infer

that

(θ

∗ 1

,

θ2∗

,

...,

θ

∗ n

)

=

(0,

31 ,

23 , 1)

regardless

of assignment. This example reﬂects axiomatic property A3 presented in Section 4.3. We show that our

algorithm for computing bounds indeed results in a convex set that contains only the vector (0, 13 , 23 , 1). And thus the projection of any noisy data onto this convex set results in (0, 13 , 23 , 1).
First, we visualize the matrix X as

paper 1 : 011 012 013 paper 2 : 021 022 023 paper 3 : 031 032 033 paper 4 : 141 242 343.

The subscripts indicate the entries of the weights in X. Some elements in Ω are: (011, 021, 031), · · · , (013, 023, 033),
(011, 012, 141), · · · , (013, 023, 141), (011, 012, 242), · · · , (011, 012, 343). After we sort Ω based on the mean of the weight tuples, we get Ω where the ﬁrst 27 tuples have mean 0, followed by 27 tuples with mean 31 , 27 tuples with mean 23 , and 27 tuples with mean 1. We construct graph G in which for instance, there is an edge between the tuples (011, 021, 031) and (012, 022, 032) since all six weights in these two tuples correspond to
diﬀerent entries in X. On the other hand, there is no edge between the tuples (011, 021, 141) and (012, 022, 141)
because they both contain weight 141. The ﬁrst tuple in Ω meets both the criteria so lower bound on θ1∗ is mean of the ﬁrst tuple, which is a tuple
with mean 0. Therefore, lower bound on θ1∗ is 0. Without loss of generality, the ﬁrst tuple is (011, 021, 031) and we mark the corresponding entries in X. Now the matrix X can be visualized as follows (where we mark
any entry when we need to):

paper 1 : 0¨11 012 013 ¨
paper 2 : 0¨21 022 023 ¨
paper 3 : 0¨31 032 033 ¨
paper 4 : 141 242 343.

To compute a lower bound on θ2∗, we start from the second tuple in Ω. Since there are 27 tuples that have mean zero, the second tuple still has mean zero. However, we do not choose any tuple that has mean zero due
to criterion C2 from the algorithm. Choosing any (0, 0, 0) tuple leaves all 3 entries of row 4 in X unmarked,
and thus will not leave row 4 with at most 2 unmarked entries. Therefore, we will only stop at the ﬁrst tuple that has mean 31 . Without loss of generality, we choose tuple (011, 021, 141) and mark the corresponding entries in X. This will leave the matrix X as

paper 1 : 0¨11 0¨12 0¨13 ¨¨ ¨
paper 2 : 0¨21 0¨22 0¨23 ¨¨ ¨
paper 3 : 0¨31 0¨32 0¨33 ¨¨ ¨
paper 4 : 1¨41 242 343. ¨

For

a

similar

reason,

we

do

not

choose

any

tuple

that

has

mean

1 3

to

be

a

lower

bound

on

θ3∗

as

it

would

not

leave row 4 of X with at most 1 unmarked entry. So we choose the ﬁrst tuple that has mean 23 and a lower

bound on θ3∗ is 32 . Lastly, a lower bound on θ4∗ is computed using the ﬁrst tuple that has mean 1.

Now we can look at the computation of upper bounds using the proposed algorithm. Upper bound on

θ4∗ is taken as mean of the last tuple, which is a tuple with mean 1. Therefore, an upper bound on θ4∗ is 1.

In addition, we mark two entries of weight 0 and one entry of weight 3. Without loss of generality, we mark

entries 011, 021, 343. Now the matrix X can be visualized as

paper 1 : 0¨11 012 013 ¨
paper 2 : 0¨21 022 023 ¨
paper 3 : 031 032 033
paper 4 : 141 242 3¨43. ¨

11

To compute an upper bound on θ3∗, we start from the second to last tuple in Ω. Since there are 27 tuples that have mean 1, the second to last tuple still has mean 1. However, we do not choose any tuple with mean
1 due to criterion C3 from the algorithm. Any (0, 0, 3) tuple does not have a right chain of length at most 2
because all tuples with value (0, 0, 3) are not connected due to the uniqueness of the weight 3. Therefore, we will only stop at the ﬁrst tuple that has mean 32 as it has a right chain of length 2. Since we have encountered all combinations of (0, 0, 3), the matrix X after we choose a tuple (0, 0, 2) becomes

paper 1 : 0¨11 0¨12 0¨13 ¨¨¨

paper 2 :

0¨21 ¨

0¨22 ¨

¨0¨23.

paper 3 : 0¨31 0¨32 0¨33

¨¨¨

paper 4 : 141 2¨42 3¨43 ¨¨

For

a

similar

reason,

we

do

not

choose

any

tuple

that

has

mean

2 3

to

be

an

upper

bound

on

θ2∗

as

it

would

not have a right chain of length at least 3. So we choose the ﬁrst tuple we encounter that has mean 31 and

an upper bound on θ2∗ is 13 . Lastly, an upper bound on θ1∗ is computed using the ﬁrst tuple that has mean 0.

Thus,

the

bounds

on

θ∗

=

(θ

∗ 1

,

θ2∗

,

...,

θ

∗ n

)

are

0

≤

θ1∗

≤

0,

1 3

≤

θ2∗

≤

13 ,

2 3

≤

θ3∗

≤

2 3

and

1

≤

θ4∗

≤

1.

Along with the conditions that θ1∗ + θ2∗ + θ3∗ + θ4∗ = 2 and θ1∗ ≤ θ2∗ ≤ θ3∗ ≤ θ4∗, the only possible value of θ∗

is (0, 13 , 23 , 1). Thus the output of our algorithm is the singleton set {(0, 13 , 23 , 1)}. Projection of any data to

the convex set {(0, 13 , 32 , 1)} results in (0, 13 , 23 , 1), which is consistent with axiomatic property A3.

4.3.5 Guarantees of Our Algorithm
In this section, we evaluate our algorithm with respect to the four desiderata listed in Section 1. We ﬁrst prove the correctness of the algorithm in terms of projection on to an appropriate set.
Theorem 4.8. The algorithm projects noisy data onto a convex set that contains all true values.
The proof of this theorem is given in Section A.5. This result, combined with Theorem 4.2, guarantees that our algorithm does not increase the error. Thus, our algorithm satisﬁes desideratum D1. In addition, since our algorithm uses only the public data for post processing, it satisﬁes desideratum D2.
We now discuss the computational complexity of our algorithm. In our setting, we assume and k to be constants. Since n · = m · k, the number of papers, m, is polynomial in the number of reviewers, n.
Theorem 4.9. The algorithm has polynomial time complexity in the number of reviewers.
So our algorithm satisﬁes desideratum D3. While the algorithm is polynomial time in n and m, it is exponential in . In practice is usually a constant, and is frequently small [7]. The proof of this theorem is given in Section A.6.
We ﬁnally visit desideratum D4 – of being able to return an exact answer when it can easily be deduced from public data.
Theorem 4.10. The algorithm satisﬁes the axiomatic properties A1, A2 and A3 deﬁned in Section 4.3.1.
We have thus shown that our proposed algorithm meets all four desiderata D1–D4.

5 Simulations
In this section, we conduct synthetic simulations to evaluate the performance of our algorithm. We synthetically generate a conference review setting in one of several ways as described below. In each of the settings, the number of reviewers equals the number of papers, and each reviewer reviews 2 papers and each paper is reviewed by two reviewers. The assignment of reviewers to papers is done uniformly at random subject to given load constraints. The weight given by any reviewer to any reviewed paper is drawn from a beta distribution. For preserving privacy, we consider the common method of adding i.i.d. Laplace noise (with mean zero and variance 2) to each component of the true sorted mean-weight vector.
We evaluate the following three methods of releasing the sorted mean-weight vector, which includes our proposed algorithm and two baselines:

12

• Noisy where Laplace noise is added but no post-processing is performed;

• Baseline projection where the noisy data is post-processed via projecting onto a convex set which

constrains the sum of all entries, the value of each entry in terms of the range of weights (0 to 1),
n
and imposes a monotonicity constraint; We project on the set {t ∈ Rn|0 ≤ ti ≤ 1∀i ∈ [n], ti =
i=1

mk

1

xij, t1 ≤ t2 ≤ · · · ≤ tn}.

i=1 j=1

• Our algorithm where the noisy data is post-processed via our algorithm described in Section 4.3.

The code for our algorithm is available at https://github.com/wenxind/privacy-utility-tradeoff-
in-peer-review-data. The simulations compute the mean squared error between the true sorted mean-weight vector θ∗ and
the output from each of these three methods, that is, ni=1(ti − θi∗)2 where t is the output of any of these algorithms. Note that in the ﬁgures, the error bars (standard error of the mean) are plotted but not visible
in most cases since they are too small.

Mean squared error

102

102

Mean squared error

101

101

100

100

10 1

10 1

10 20 #Rev3i0ewers 40 50

10 20 #Rev3i0ewers 40 50

(a) Beta(5,1)

(b) Beta(2,5)

102

102

102

Mean squared error

Mean squared error

101

101

101

100 100 100

10 1 10 20 30 40 50 10 1 10 20 30 40 50

#Reviewers

#Reviewers

10 20 #Rev3i0ewers 40 50

(c) Beta(1,3)

(d) Beta(2,2)

(e) Beta(0.5,0.5)

102 101

Mean squared error

101 100

100

10 1

10 1

2 4Value o6f a 8 10

10 20 #Rev3i0ewers 40 50

(f) Beta(a, a) with 10 reviewers (g) Beta(a, b) with a ∈ [2] and b ∈ [n]

Mean squared error

102 101 100
10 20 #Rev3i0ewers 40 50
(h) Beta(a, b) with a, b ∈ [n]

Figure 2: Simulation results. The y-axes of all plots are on a logarithmic scale.

Mean squared error

Mean squared error

13

We now describe the method for generating the weights in each simulation, and refer the reader to the corresponding plots. Note that the y-axes (representing the mean squared error) on each of the plots is on a logarithmic scale.
• In Figure 2a—2e, the number of reviewers ranges from 10 to 50. The weights are all i.i.d. and are generated from the beta distribution speciﬁed in the corresponding subcaption.
• In Figure 2f, the number of reviewers is ﬁxed at 10. On the x-axis, we vary a parameter a ∈ {0.5, 1, . . . , 10}. For each value of a, we draw all weights i.i.d. from the beta(a, a) distribution.
• In Figure 2g, we again vary the number of reviewers n on the x-axis. For any paper i ∈ [n], one weight is generated from beta(1, i) and the other weight is generated from beta(2, i) independently.
• In Figure 2h, whenever any paper i ∈ [m] is reviewed by reviewer j ∈ [n], the weight of that review is generated from beta(i, j).
All in all, these simulations reveal that our algorithm can lead to a multi-fold improvement in the utility (accuracy) while not compromising the privacy.
6 Discussion and Future Work
We take the ﬁrst steps towards designing methods for privacy-preserving release of peer-review data, and posit the need for much more research on this topic to address the important challenge of improving peer review. There are several open problems of interest. First, we propose an algorithm to improve the privacy-utility tradeoﬀ, and even though it has a polynomial time complexity in the number of reviewers, its computation time is practically infeasible for large conferences such as NeurIPS, ICML or AAAI which have 5000-10000 papers and several thousand reviewers. A useful direction of future work is to improve the computational complexity of the algorithm to make it operate in “practical time”. Second, we currently consider releasing histograms of mean scores given by each reviewer, and it is of considerable theoretical and practical interest to enable privacy-preserving release of other peer-review data, such as properties of the reviewer graph, reviewer bids, and other functions of the scores. Third, in this work we separate out the privacy component of data release from the post-processing component which improves utility. It is of interest to jointly design both components which may yield an even better tradeoﬀ. Finally, it is of interest to design methods that can utilize data from multiple conferences, while preserving the privacy in each conference, for improving the peer-review process in any subsequent conference.
14

Acknowledgments
This work was supported in part by NSF CAREER award 1942124.
References
[1] Drummond Rennie. Make peer review scientiﬁc. Nature, 535(7610):31–34, 2016.
[2] Alison McCook. Is peer review broken? submissions are up, reviewers are overtaxed, and authors are lodging complaint after complaint about the process at top-tier journals. what’s wrong with peer review? The scientist, 20(2):26–35, 2006.
[3] Stefano Balietti. Science is suﬀering because of peer reviews big problems. The Conversation, 2016.
[4] Andrew Tomkins, Min Zhang, and William D Heavlin. Reviewer bias in single-versus double-blind peer review. Proceedings of the National Academy of Sciences, 114(48):12708–12713, 2017.
[5] Flaminio Squazzoni, Petra Ahrweiler, Tiago Barros, Federico Bianchi, Aliaksandr Birukou, Harry JJ Blom, Giangiacomo Bravo, Stephen Cowley, Virginia Dignum, Pierpaolo Dondio, et al. Unlock ways to share data on peer review, 2020.
[6] Sara Schroter, Elizabeth Loder, and Fiona Godlee. Research on peer review and biomedical publication, 2020.
[7] Nihar B Shah, Behzad Tabibian, Krikamol Muandet, Isabelle Guyon, and Ulrike Von Luxburg. Design and analysis of the NIPS 2016 review process. The Journal of Machine Learning Research, 19(1):1913– 1946, 2018.
[8] Douglas P Peters and Stephen J Ceci. Peer-review practices of psychological journals: The fate of published articles. Behavioral and Brain Sciences, 5(2):187–255, 1982.
[9] Mark A Kliewer, David M DeLong, Kelly Freed, Charles B Jenkins, Erik K Paulson, and James M Provenzale. Peer review at the american journal of roentgenology: How reviewer and manuscript characteristics aﬀected editorial decisions on 196 major papers. American Journal of Roentgenology, 183(6):1545–1550, 2004.
[10] Katherine Egan Bennett, Reshma Jagsi, and Anthony Zietman. Radiation oncology authors and reviewers prefer double-blind peer review. Proceedings of the National Academy of Sciences, 115(9):E1940– E1940, 2018.
[11] Andreas F Mavrogenis, Andrew Quaile, and Marius M Scarlat. The good, the bad and the rude peerreview, 2020.
[12] Christophe Bernard. Gender bias in publishing: Double-blind reviewing as a solution? Eneuro, 5(3), 2018.
[13] Richard Snodgrass. Single- versus double-blind reviewing: An analysis of the literature. SIGMOD Record, 35:8–21, 09 2006.
[14] William A Scott. Interreferee agreement on some characteristics of manuscripts submitted to the journal of personality and social psychology. American Psychologist, 29(9):698, 1974.
[15] Duncan Lindsey. Assessing precision in the manuscript review process: A little better than a dice roll. Scientometrics, 14(1-2):75–82, 1988.
[16] John R Douceur. Paper rating vs. paper ranking. ACM SIGOPS Operating Systems Review, 43(2):117– 121, 2009.
[17] Martin Reinhart. Peer review of grant applications in biology and medicine. reliability, fairness, and validity. Scientometrics, 81(3):789–809, 2009.
15

[18] Judy Goldsmith and Robert H. Sloan. The AI conference paper assignment problem. WS-07-10:53–57, 12 2007.
[19] L. Charlin and R. S. Zemel. The Toronto Paper Matching System: An automated paper-reviewer assignment system. In ICML Workshop on Peer Reviewing and Publishing Models, 2013.
[20] Ivo Welch. Referee recommendations. The Review of Financial Studies, 27(9):2773–2804, 2014.
[21] Ivan Stelmakh, Nihar Shah, and Aarti Singh. PeerReview4All: Fair and accurate reviewer assignment in peer review. arXiv preprint arxiv:1806.06237, 2018.
[22] Ari Kobren, Barna Saha, and Andrew McCallum. Paper matching with local fairness constraints. In ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, 2019.
[23] Magnus Roos, J¨org Rothe, and Bj¨orn Scheuermann. How to calibrate the scores of biased reviewers by quadratic programming. In AAAI Conference on Artiﬁcial Intelligence, 2011.
[24] Hong Ge, Max Welling, and Zoubin Ghahramani. A Bayesian model for calibrating conference review scores, 2013.
[25] Jingyan Wang and Nihar B Shah. Your 2 is my 1, your 3 is my 9: Handling arbitrary miscalibrations in ratings. In AAMAS, 2019.
[26] Ritesh Noothigattu, Nihar B Shah, and Ariel D Procaccia. Loss functions, axioms, and peer review. arXiv preprint arXiv:1808.09057, 2018.
[27] Ivan Stelmakh, Nihar Shah, and Aarti Singh. On testing for biases in peer review. In NeurIPS, 2019.
[28] Yichong Xu, Han Zhao, Xiaofei Shi, and Nihar Shah. On strategyproof conference review. In IJCAI, 2019.
[29] Ivan Stelmakh, Nihar Shah, and Aarti Singh. Catch me if i can: Detecting strategic behaviour in peer assessment. arXiv, 2020.
[30] Guillaume Cabanac and Thomas Preuss. Capitalizing on order eﬀects in the bids of peer-reviewed conferences to secure reviews by expert referees. Journal of the Association for Information Science and Technology, 64(2):405–415, 2013.
[31] T Fiez, N Shah, and L Ratliﬀ. A SUPER* algorithm to optimize paper bidding in peer review. In ICML workshop on Real-world Sequential Decision Making: Reinforcement Learning And Beyond, 2019.
[32] N. Lawrence and C. Cortes. The NIPS Experiment. http://inverseprobability.com/2014/12/16/ the-nips-experiment, 2014. [Online; accessed 11-June-2018].
[33] Ivan Stelmakh, Nihar Shah, Aarti Singh, and Hal Daum III. Prior and prejudice: The bias against resubmissions in conference peer review. arXiv, 2020.
[34] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. In Proc. Conf. Theory of Cryptography (TCC), pages 265–284, New York, NY, 2006.
[35] Cynthia Dwork. Diﬀerential privacy. In Proc. Int. Conf. Automata, Languages and Programming (ICALP), pages 1–12, Venice, Italy, 2006.
[36] Avrim Blum, Katrina Ligett, and Aaron Roth. A learning theory approach to non-interactive database privacy. In Proc. Ann. ACM Symp. Theory of Computing (STOC), pages 609–618, Victoria, Canada, 2008.
[37] Marco Gaboardi, Emilio Jesu´s Gallego Arias, Justin Hsu, Aaron Roth, and Zhiwei Steven Wu. Dual query: Practical private query release for high dimensional data. In Int. Conf. Machine Learning (ICML), Beijing, China, 2014.
16

[38] Weina Wang, Lei Ying, and Junshan Zhang. On the relation between identiﬁability, diﬀerential privacy, and mutual-information privacy. IEEE Trans. Inf. Theory, 62(9):5018–5029, September 2016.
[39] Mark Bun, Jonathan Ullman, and Salil Vadhan. Fingerprinting codes and the price of approximate diﬀerential privacy. SIAM Journal on Computing, 47(5):1888–1938, 2018.
[40] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor. Our data, ourselves: privacy via distributed noise generation. In Proc. Annu. Int. Conf. Theory and Applications of Cryptographic Techniques (EUROCRYPT), pages 486–503, St. Petersburg, Russia, 2006.
[41] Cynthia Dwork and Guy N. Rothblum. Concentrated diﬀerential privacy. CoRR, abs/1603.01887, 2016.
[42] Mark Bun and Thomas Steinke. Concentrated diﬀerential privacy: Simpliﬁcations, extensions, and lower bounds. In Martin Hirt and Adam Smith, editors, Theory of Cryptography, pages 635–658, Berlin, Heidelberg, 2016. Springer Berlin Heidelberg.
[43] I. Mironov. Rnyi diﬀerential privacy. In 2017 IEEE 30th Computer Security Foundations Symposium (CSF), pages 263–275, 2017.
[44] Mark Bun, Cynthia Dwork, Guy N. Rothblum, and Thomas Steinke. Composable and versatile privacy via truncated cdp. In Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2018, page 7486, New York, NY, USA, 2018. Association for Computing Machinery.
[45] Shuchi Chawla, Cynthia Dwork, Frank McSherry, and Kunal Talwar. On privacy-preserving histograms. In Conf. Uncertainty in Artiﬁcial Intelligence (UAI), page 120127, 2005.
[46] Michael Hay, Vibhor Rastogi, Gerome Miklau, and Dan Suciu. Boosting the accuracy of diﬀerentially private histograms through consistency. Proceedings of the VLDB Endowment, 3(1-2):1021–1032, 2010.
[47] Chao Li, Michael Hay, Vibhor Rastogi, Gerome Miklau, and Andrew McGregor. Optimizing linear counting queries under diﬀerential privacy. In Symp. Principles Database Systems (PODS), pages 123– 134, Indianapolis, IN, 2010.
[48] Raef Bassily and Adam Smith. Local, private, eﬃcient protocols for succinct histograms. In Proc. Ann. ACM Symp. Theory of Computing (STOC), pages 127–135, Portland, OR, 2015.
[49] Victor Balcer and Salil Vadhan. Diﬀerential privacy on ﬁnite computers. Journal of Privacy and Conﬁdentiality, 9(2), Sep. 2019.
[50] Steven Jecmen, Hanrui Zhang, Ryan Liu, Nihar B. Shah, Vincent Conitzer, and Fei Fang. Mitigating manipulation in peer review via randomized reviewer assignments. arXiv, 2020.
[51] Carole J Lee. Commensuration bias in peer review. Philosophy of Science, 82(5):1272–1283, 2015.
[52] Stanley S Siegelman. Assassins and zealots: variations in peer review. Radiology, 178(3):637–642, 1991.
[53] Steven Kerr, James Tolliver, and Doretta Petree. Manuscript characteristics which inﬂuence acceptance for management and social science journals. Academy of Management Journal, 20(1):132–141, 1977.
[54] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. Journal of Privacy and Conﬁdentiality, 7(3):17–51, 2016.
[55] Cynthia Dwork and Aaron Roth. The algorithmic foundations of diﬀerential privacy. Found. Trends Theor. Comput. Sci., 9(3–4):211–407, August 2014.
[56] Heinz H Bauschke, Patrick L Combettes, et al. Convex analysis and monotone operator theory in Hilbert spaces, volume 408. Springer, 2011.
[57] Luitpold Babel, Hans Kellerer, and Vladimir Kotov. Thek-partitioning problem. Mathematical Methods of Operations Research, 47(1):59–82, 1998.
17

A Appendix: Proofs
In the appendix, we present complete proofs of the results claimed in the main text.

A.1 Proof of Proposition 4.1
We will prove the proposition using a counter example. Assume the true value θ∗ = 0 and the set of all possible values Θ = {−4, −2, 0, 2, 4}. The noisy data r = θ∗ + η where η is a Laplace random variable with probability density function η(x) = 0.5e−|x|.
Without projection, the expected error incurred by the noise is −∞∞ 0.5e−|x|x2dx = 2. But if we project the noisy data on the set Θ and get result t, the expected error after the projection is computed as 16 −−∞3 0.5e−|x|dx+4 −−31 0.5e−|x|dx+4 13 0.5e−|x|dx+16 3∞ 0.5e−|x|dx = 2.06896, which is greater than the expected error without projection. Thus, projecting on the set that contains all true values could decrease
the accuracy of data.

A.2 Proof of Proposition 4.2
It is known that projection on a closed convex set is non-expansive [56]. Since θ∗ results from a valid assignment, it is contained in Θ. Therefore it is contained in any closed convex set that contains Θ. Projection of r onto any such convex set will not increase its squared error from θ∗. Therefore, proposition 4.2 holds.

A.3 Proof of Theorem 4.3

We will prove the NP-hardness by reducing the -Partition problem, which is NP-hard [57], to the problem of projecting noisy data onto convex hull of Θ. The -Partition problem where > 2 is deﬁned as follows.

Deﬁnition A.1. -Partition problem: Given a multi-set W = {w1, w2, ..., wn} of n non-negative integers where n is a multiple of , decide if we can partition W into n subsets such that each subset has size and
the sums of all subsets are the same.

Consider any instance of the -Partition problem with W = {w1, w2, ..., wn}, where wi ≥ 0 and n is

a multiple of . Now we construct a peer-review dataset where there are n reviewers and n papers, each

reviewer reviews papers and each paper receives reviews. Note that the number of reviewers is the same

as the number of elements in W. Let each paper i has weight wi and − 1 zero weights, and a denote the

average of all elements in W, i.e.,

1n a = n wi.
i=1

(A.1)

Let v = (0, ..., 0, a, ..., a) be a vector of n entries whose last n entries all have value a. Let V = W ∪ {0, ..., 0} be the multiset containing all values of W and n · ( − 1) zeros. Then the projection problem is to project v onto the convex hull of Θ deﬁned for this peer-review dataset.
The reduction from the -Partition problem to the projection problem constructed above is as follows. If the solution to the projection problem is v itself, we return True for the -Partition problem; otherwise we return False.
We ﬁrst prove the correctness of the reduction. Suppose W can be -partitioned into n subsets of equal sums. Then we can partition V into subsets of size where these subsets are the subsets that give the -partition of W and subsets that consist of zeros. By Lemma A.2 below, this partition of V gives a valid assignment for the peer-review problem, and thus v = (0, ..., 0, a, ..., a) corresponds to a valid assignment. Therefore, the projection of v is itself. The proof of Lemma A.2 is presented in Section A.4.

Lemma A.2. In the setting described above, any -partition of the n · weights in V, i.e., any partition of V into subsets of size , can be interpreted as a valid assignment such that subset i corresponds to the weights from reviewer i given to distinct papers.

18

Next, suppose that the projection of v is itself. We show that W can be -partitioned into subsets of equal sums. We ﬁrst claim that v must correspond to a valid assignment itself. To see this, suppose v = (0, ..., 0, a, ..., a) is a convex combination of some sorted mean weight vectors. Then these vectors must all have value a for their last n entries since each of these mean weight vector is sorted. Due to the sum constraint, these mean weight vectors have to be (0, ..., 0, a, ..., a). Next we note that in the assignment given by v, each reviewer who has an average weight of a must give weights with values from W due to the pigeonhole principle. Therefore, the n subsets each of which consists of weights given by one of the last n reviewers form an -partition of W with equal sums.
Finally, we prove the eﬃciency of the reduction. Since the construction of v has O(n) time complexity and the construction of V has O(1) time complexity, the reduction has O(n) time complexity, which is polynomial in the size of the input. Thus, the reduction can be done eﬃciently, which completes the proof.
A.4 Proof of Lemma A.2
Fix , we will prove the lemma by induction on n, the number of reviewers, which is the same as the number of papers.
Base case: when n = , every reviewer reviews all papers, so any partition of the weights can be validly assigned to reviewers.
Inductive hypothesis: suppose when there are fewer than n reviewers for an n > , every partition of the weights forms a valid assignment for reviewers.
Consider when there are n reviewers and n papers. Without loss of generality, assume all weights in W are non-zero. Consider an partition of the set V. We will argue in two cases based on whether there is a subset that contains exactly one non-zero weight.
1. Case 1: In the partition, if there is a subset with exactly one non-zero weight.
Without loss of generality, assume that the subset with exactly one non-zero weight contains w1 and the subset is {w1, 0, ..., 0}. We denote the subset S1. In S1, there are − 1 zero weights and a non-zero weight w1 from W. Since paper 1 receives weights in total, we can remove S1, paper 1 and reviewer 1.
Now we are left with n − 1 reviewers and papers. The removal does not aﬀect the number of reviews received by the rest of the papers. We still have each paper getting weights. Among the weights, there is one non-zero weight from W and − 1 zero weights. By the inductive hypothesis, the rest of the subsets in the partition form a valid assignment of V \ S1. We can assign the weights to n − 1 reviewers.
We then add S1 back to the assignment. Since reviewer 1 weights to paper 1, it is not valid. We can solve this by swapping the zero weights in S1 with zeros in other subsets. We need to make − 1 swaps. We label the rest of the subsets S2, . . . , Sn where S2 is the subset that contains most non-zero weights and the labels go in decreasing order based on the number of non-zero weights contained in a subset. We look at the rest of the subsets in the order of their labels.
Since none of the rest of the subsets contain any weight from paper 1, swapping a zero weight from paper 1 into any of these subsets will nor aﬀect the validity of the subset. There are at least n−1− n−1 subsets that contain at least a zero weight. Since n > and > 2, n − 1 − n−1 = ( −1)(n−1) ≥ − 1. Thus, we have enough subsets to swap the zero weights from paper 1 in.
Then we make sure the zero weights swapped into S1 will not come from the same paper. We label the zeros in S1 with index 1, . . . , − 1. Suppose there are no subsets that do not contain any zero weights. Then when we need to swap out the zero weight at index i in S1, there are at most n − i non-zero weights in the untouched subsets due to the order we look at the subsets. There are n − i untouched subsets as well. Then there exists an untouched subset that contains i zero weights. Since at this stage S1 has already completed i − 1 swaps, we can ﬁnd a zero weight from the untouched subset to swap so that the zero weight does not come from the same paper as the zero weights from previous swaps. Note that if we have any subset that does not contain any zero weight or we skip some subsets due to conﬂict of papers, then the fraction of non-zero weights left and untouched subsets will be even smaller. So we are guaranteed to ﬁnd a proper zero weight to swap. Thus, we can make − 1 swaps
19

of the zero weights to S1 and make all subsets valid assignments of weights. Such swaps do not aﬀect the values in each subset.
Therefore, such partition can result in a valid assignment of the n · scores among n reviewers.

2. Case 2: In the partition, if there are no subsets with exactly one non-zero weight.

Since W contains n elements and there are n subsets, by pigeon hole principle, there must be a subset S1 that contains all zero weights.

Without loss of generality, we ﬁnd the subset that contains w1 and then swap w1 with a zero weight in S1. This results in S1 = {w1, 0, . . . , 0}.

Now we have a subset that contains exactly 1 weight from W. Like in case 1, we remove the subset,
reviewer 1 and paper 1. We can ﬁnd a valid assignment of the rest of the weights to n − 1 reviewers.
Then we will put S1 back to the assignment. Currently all weights in S1 are from paper 1. We identify the subset where w1 comes from, and swap w1 back into the subset with a zero weight there. Since the subset can not contain any weights from paper 1, we can safely put w1 back without having two weights from the same paper.

After the swap, S1 has − 1 zero weights from paper 1 and a zero weight from a diﬀerent paper, say paper 2. We need to make − 2 swaps for the zeros in S1. We label the rest of the subsets S2, . . . , Sn where S2 is the subset that contains most non-zero weights and the labels go in decreasing order based on the number of non-zero weights contained in a subset. We look at the rest of the subsets in the
order of their labels.

Since none of the rest of the subsets contain any weight from paper 1, swapping a zero weight from

paper 1 into any of these subsets will nor aﬀect the validity of the subset. In the worst case, there

exists

a

subset

that

contains

w1

and

there

are

at

most

n−2 −1

subsets

that

only

contains

a

zero

weight

from

paper

2

because

such

tuples

cannot

contain

w2.

Then

there

are

at

least

n−1−

n−2 −1

−1

subsets

that we can swap the zero weights in S1. Since n > and > 2, n − 1 − n−−12 − 1 = ( −2)−(n1−2) ≥ − 2.

Thus, we have enough subsets to swap the zero weights from paper 1 in.

We keep a zero weight from paper 1 in S1 and label the rest of the zero weights in S1 with index 1, . . . , − 2. Suppose there are no subsets that do not contain any zero weights. Then when we need to swap the zero weight at index i in S1, there are at most n − i non-zero weights in the untouched subsets due to the order we look at the subsets. There are n − i untouched subsets as well. Then there exists a subset that contains i + 1 zero weights. Since at this stage S1 has already completed i − 1 swaps, we can ﬁnd a zero weight to swap that does not conﬂict with the weights from previous swaps and not from paper 2 either. Note that if we have any subset that does not contain any zero weight or we skip some subsets due to conﬂict of papers, then the fraction of non-zero weights left and untouched subsets will be even smaller. So we are guaranteed to ﬁnd a proper zero weight to swap. Thus, we can make − 2 swaps of the zero weights to S1 and makes all subsets valid assignments of weights. Such swaps do not aﬀect the value in each subset.

Therefore, such partition can result in a valid assignment of the n · weights among n reviewers.

In conclusion, any -partition of V can be interpreted as a valid assignments of weights to n reviewers.

A.5 Proof of Theorem 4.8
We would like to show that the convex set contains Θ. We will show that the bounds are indeed lower and upper bounds on each entry.
We will ﬁrst show that the lower bounds computed by the algorithm are correct. Assume for the sake of contradiction, there exists an assignment such that θi∗ is less than the lower bound on θi∗ we computed, denoted as θi. We use ν to denote the tuple that results in θi∗ and use ν to denote the tuple that we choose in the algorithm that has mean θi. Since ν is a valid assignment, it is the sum of weights from distinct papers. Since Ω contains all such tuples, it contains ν. And since θi∗ < θi, we encountered ν before we encounter ν in Ω. We did not choose ν as the tuple for lower bound due to its violation of either criterion C1 or criterion C2.

20

If ν violates criterion C1, it does not have a left chain of size at least i. There cannot be i−1 weight tuples each containing weights from diﬀerent papers such that they all have mean no larger than θi∗. Otherwise they form a left chain of length i. So ν cannot have its mean appear at entry i in θ∗.
If ν violates criterion C2, there exists a row that has more than n − i unmarked entries in X. The weights of the unmarked entries have not been encountered so far, which indicates that any tuple that contains the weights from unmarked entries has mean no less than θi∗. Otherwise, we would have encountered the weight before ν and mark its entry. We know that there are n − i reviewers who has mean weight no less than θi∗. In addition, there are more than n − i weights left for at least one paper. By Pigeon Hole Principle, there exists a reviewer gives a weight tuple that contains two weights from the same paper. However, no two weights from the same paper can be in the same tuple since one reviewer cannot give 2 weights to the same paper. So ν cannot have its mean appear at entry i in θ∗.
Thus, θi∗ cannot be a value for entry i in θ∗. The value θi we computed is indeed a lower bound on that entry.
Following a similar argument, we can prove the correctness of the upper bounds from the algorithm.
A.6 Proof of Theorem 4.9
We will show that the proposed algorithm has polynomial time complexity in the number of reviewers. There are n · weights, so the size of Ω , denoted |Ω |, has size at most n· , which is of complexity O(n ). Sorting Ω has O(|Ω | log(|Ω |)) time complexity, which is still polynomial in n. There are |Ω2 | pairs of vertices to examine for edges. Therefore, constructing G is of polynomial time in n. To compute the length longest left chain and right chain of a vertex, we can make use of a dynamic programming algorithm that only requires us to loop through Ω once to compute length of longest left chain of all vertices and loop one more time to compute the length of longest right chain. For each vertex, we examine at most all its neighbors, which is of size polynomial in n. Lastly, after all preparation work, for each vertex, we take O(1) time to check criteria C1 and and C3 at most O(m) time to check criteria C2 and C4. Since m ≤ n · , both operations are polynomial in n. Thus, the proposed algorithm computes the bounds in time polynomial in n.
We will use quadratic programming to project noisy data onto the convex set and there are 2n linear constraints. This operation is also polynomial in n.
Thus, the proposed algorithm has time complexity that is polynomial in n.
A.7 Proof of Theorem 4.10
Axiomatic property A1: When all weights are the same, all weight tuples have the same mean, which equals the weight. Thus, all lower and upper bounds have the same value as the weight. The convex set contains a single vector and projection of any noisy data on such convex set will result in the vector, whose entries are all the same as the weight.
Axiomatic property A2: When = 1, there are exactly n weight tuples, each containing one weight. We will choose the same weight tuple for lower bound and upper bound on θi∗. The mean of the chosen weight tuple is the weight of rank i among all n weights. Therefore, the convex set contains exactly one vector, which is the sorted vector of all weights. Projection of any noisy data onto this convex set will result in the vector of sorted weights.
Axiomatic property A3: When all except for one paper receives all zero weights, computation of lower bound on θi∗ when i < n − k will choose a tuple whose weights are all zeros. When i ≥ n − k, computation of lower bound will choose a tuple that contains a nonzero weights due to criterion C2. Similarly, to compute an upper bound on θi∗ when i ≥ n − k, we will choose a tuple with a nonzero weight due to the criterion C3. But when i < n − k, the algorithm will choose a tuple with all zero weights. The example we present in Section 4.3.4 illustrates this process. Therefore, the convex set again contains only a vector who has n − k zero entries. Projection of any noisy data will result in this vector.
21

