EXPLAINABOARD: An Explainable Leaderboard for NLP
Pengfei Liu1†, Jinlan Fu2, Yang Xiao2, Weizhe Yuan1, Shuaichen Chang3, Junqi Dai2, Yixin Liu1, Zihuiwen Ye1, Zi-Yi Dou1, Graham Neubig1‡ 1Carnegie Mellon University, 2Fudan University, 3The Ohio State University, †pliu3@cs.cmu.edu, ‡gneubig@cs.cmu.edu

arXiv:2104.06387v2 [cs.CL] 1 Jul 2021

Abstract
With the rapid development of NLP research, leaderboards have emerged as one tool to track the performance of various systems on various NLP tasks. They are effective in this goal to some extent, but generally present a rather simplistic one-dimensional view of the submitted systems, communicated only through holistic accuracy numbers. In this paper, we present a new conceptualization and implementation of NLP evaluation: the EXPLAINABOARD, which in addition to inheriting the functionality of the standard leaderboard, also allows researchers to (i) diagnose strengths and weaknesses of a single system (e.g. what is the best-performing system bad at?) (ii) interpret relationships between multiple systems. (e.g. where does system A outperform system B? What if we combine systems A, B and C?) and (iii) examine prediction results closely (e.g. what are common errors made by multiple systems or in what contexts do particular errors occur?). So far, EXPLAINABOARD covers more than 400 systems, 50 datasets, 40 languages, and 12 tasks.1 We not only released an online platform at the website 2 but also make our evaluation tool an API with MIT Licence at Github 3 and PyPi 4 that allows users to conveniently assess their models ofﬂine. We additionally release all output ﬁles from systems that we have run or collected to motivate “output-driven” research in the future.
1 Introduction
Natural language processing (NLP) research has been and is making astounding strides forward.
1EXPLAINABOARD keeps updated and is recently upgraded by supporting (1) multilingual multi-task benchmark, (2) meta evaluation (Yuan et al., 2021) and (3) more complicated task: machine translation, which reviewers also suggested.
2http://explainaboard.nlpedia.ai/ 3https://github.com/neulab/ explainaBoard 4https://pypi.org/project/ interpret-eval/

Figure 1: Illustration of the EXPLAINABOARD concept. Compared to vanilla leaderboards, EXPLAINABOARD allows users to perform interpretable (single-system , pairwise analysis, data bias), interactive (system combination, ﬁne-grained/common error analysis), and reliable analysis (conﬁdence interval, calibration) on systems in which they are interested. “Comb.” denotes “combination” and “Errs” represents “errors”. “PER, LOC, ORG” refer to different labels.
This is true both for classical tasks such as machine translation (Sutskever et al., 2014; Wu et al., 2016), as well as for new tasks (Lu et al., 2016; Rajpurkar et al., 2016), domains (Beltagy et al., 2019), and languages (Conneau and Lample, 2019). One way this progress is quantiﬁed is through leaderboards, which report and update performance numbers of state-of-the-art systems on one or more tasks. Some prototypical leaderboards include GLUE and SuperGLUE for natural language understanding (Wang et al., 2018, 2019), XTREME and XGLUE (Hu et al., 2020; Liang et al., 2020) for multilingual understanding, the WMT shared tasks (Barrault et al., 2020) for machine translation, and GEM and GENIE for natural language generation (Gehrmann et al., 2021; Khashabi et al., 2021), among many others.
These leaderboards serve an important purpose:

they provide a standardized evaluation setup, often on multiple tasks, that eases reproducible model comparison across organizations. However, at the same time, due to the prestige imbued by a top, or high, place on a leaderboard they also can result in a singular focus on raising evaluation numbers at the cost of deeper scientiﬁc understanding of model properties (Ethayarajh and Jurafsky, 2020). In particular, we argue that, among others, the following are three major limitations of the existing leaderboard paradigm:
• Interpretability: Most existing leaderboards commonly use a single number to summarize system performance holistically. This is conducive to system ranking but at the same time, the results are opaque, making the strengths and weaknesses of systems less interpretable.
• Interactivity: Existing leaderboards are static and non-interactive, which limits the ability of users to dig deeper into the results. Thus, (1) they usually do not ﬂexibly support more complex evaluation settings (e.g. multi-dataset, multimetric, multi-language) (2) users may miss opportunities to understand the relationships between different systems. For example, where does model A outperform model B? Would the performance be further improved if we combine the Top-3 models?
• Reliability: Given the increasing role that leaderboards have taken in guiding NLP research, it is important that information expressed in them is reliable, especially on datasets with small sample sizes, but most current leaderboards do not give an idea of the reliability of system rankings.
In this paper, we describe EXPLAINABOARD (see Fig.1), a software package and hosted leaderboard that satisﬁes all of the above desiderata. It also serves as a prototype implementation of some desirable features that may be included in future leaderboards, even independent of the provided software itself. We have deployed EXPLAINABOARD for 9 different tasks and 41 different datasets, and demonstrate how it can be easily adapted to new tasks of interest.
We expect that EXPLAINABOARD will beneﬁt different steps of the research process: (i) System Developement: EXPLAINABOARD provides more detailed information regarding the submitted systems (e.g. ﬁne-grained results, conﬁdence intervals), allowing system developers to

diagnose successes and failures of their own systems, or compare their systems with baselines and understand where improvements of their proposed methods come from. This better understanding can lead to more efﬁcient and effective system improvements. Additionally, EXPLAINABOARD can help system developers uncover their systems’ advantages over others, even when these systems have not achieved state-of-the-art performance holistically. (ii) Leaderboard Organization: The EXPLAINABOARD software both provides a readymade platform for easy leaderboard development over different NLP tasks, and helps upgrade traditional leaderboards to allow for more ﬁne-grained analysis. For example, we have already established an ExplainaBoard 5 for the existing XTREME benchmark.6 (iii) Broad Analysis and Understanding: Because EXPLAINABOARD encourages system developers to provide their system outputs in an easy-to-analyze format, these will also help researchers, particularly those just starting in a particular NLP sub-ﬁeld, get a broad sense of what current state-of-the-art models can and cannot do. This not only helps them quickly track the progress of different areas, but also can allow them to understand the relative advantages of diverse systems, suggesting insightful ideas for what’s left and what’s next.7
2 ExplainaBoard
As stated above, EXPLAINABOARD extends existing leaderboards, improving their interpretability, interactivity, and reliability. It does so by providing a number of functionalities that are applicable to a wide variety of NLP tasks (as illustrated in Tab. 1). Many of these functionalities are grounded in existing research on evaluation and ﬁne-grained diagnostics.
2.1 Interpretability
Interpretable evaluation (Popovic´ and Ney, 2011; Stymne, 2011; Neubig et al., 2019; Fu et al., 2020a), is a research area that considers methods that break down the holistic performance of each system into different interpretable groups. For example, in a
5http://explainaboard.nlpedia.ai/ leaderboard/xtreme/
6https://sites.research.google/xtreme/ 7Since the ﬁrst release of EXPLAINABOARD, we have received invitations from multiple companies, startups, and researchers to collaborate, and we are working together to make it better for the community.

Aspect Functionality

Input

Output

Single-system Analysis

One model

Interpretability

Pairwise Analysis

Two models (M1,M2)

Data Bias Analysis

Multi-dataset

Interactivity

Fine-grained

Single- or

Error Analysis Pairwise-system

diagnostic results

System Combination

Multi-models (M1,M2,M3)

F 1 < l a t e x i ts h a 1 _ b a s e 6 4 = " A y 5 w a S m 5 t M P z b 0 t R 7 G a b u A 1 h m O U = " > A A A C x X i c j V H L S s N A F D 2 N r 1 p f V Z d u g l V w V Z J u d F k Q 1 G U V + 4 B a J E m n d W h e T C a F U s Q f c K u / J v 6 B / o V 3 x i m o R X R C k j P n 3 n N m 7 r 1 + G v J M O s 5 r w V p Y X F p e K a 6 W 1 t Y 3 N r f K 2 z u t L M l F w J p B E i a i 4 3 s Z C 3 n M m p L L k H V S w b z I D 1 n b H 5 2 q e H v M R M a T + F p O U t a L v G H M B z z w J F F X Z + 5 t u e J U H b 3 s e e A a U I F Z j a T 8 g h v 0 k S B A j g g M M S T h E B 4 y e r p w 4 S A l r o c p c Y I Q 1 3 G G e 5 R I m 1 M W o w y P 2 B F 9 h 7 T r G j a m v f L M t D q g U 0 J 6 B S l t H J I m o T x B W J 1 m 6 3 i u n R X 7 m / d U e 6 q 7 T e j v G 6 + I W I k 7 Y v / S z T L / q 1 O 1 S A x w o m v g V F O q G V V d Y F x y 3 R V 1 c / t L V Z I c U u I U 7 l N c E A 6 0 c t Z n W 2 s y X b v q r a f j b z p T s W o f m N w c 7 + q W N G D 3 5 z j n Q a t W d Z 2 q e 1 m r 1 A / M q I v Y w z 6 O a J 7 H q O M C D T T J e 4 B H P O H Z O r c i S 1 r j z 1 S r Y D S 7 + L a s h w + F H I 9 m < / l a t e x i t >

0

1< l a t e x i ts h a 1 _ b a s e 6 4 = " H / p n W R R 6 s C i f S S M G u 5 4 G g 3 U a C h E = " > A A A C x n i c j V H L S s N A F D 3 G V 6 2 v q k s 3 w V Z x V Z J u d F l w 0 2 V F + 4 B a J J l O 6 9 C 8 m E y U U g R / w K 1 + m v g H + h f e G V N Q i + i E J G f O v e f M 3 H v 9 J B C p c p z X B W t x a X l l t b B W X N / Y 3 N o u 7 e y 2 0 z i T j L d Y H M S y 6 3 s p D 0 T E W 0 q o g H c T y b 3 Q D 3 j H H 5 / p e O e W y 1 T E 0 a W a J L w f e q N I D A X z F F E X F b d y X S o 7 V c c s e x 6 4 O S g j X 8 2 4 9 I I r D B C D I U M I j g i K c A A P K T 0 9 u H C Q E N f H l D h J S J g 4 x z 2 K p M 0 o i 1 O G R + y Y v i P a 9 X I 2 o r 3 2 T I 2 a 0 S k B v Z K U N g 5 J E 1 O e J K x P s 0 0 8 M 8 6 a / c 1 7 a j z 1 3 S b 0 9 3 O v k F i F G 2 L / 0 s 0 y / 6 v T t S g M c W p q E F R T Y h h d H c t d M t M V f X P 7 S 1 W K H B L i N B 5 Q X B J m R j n r s 2 0 0 q a l d 9 9 Y z 8 T e T q V m 9 Z 3 l u h n d 9 S x q w + 3 O c 8 6 B d q 7 p O 1 T 2 v l e t H + a g L 2 M c B j m m e J 6 i j g S Z a 5 D 3 C I 5 7 w b D W s y M q s u 8 9 U a y H X 7 O H b s h 4 + A L B r j 3 Q = < / l a t e x i t >

2< l a t e x i ts h a 1 _ b a s e 6 4 = " L Q r c w P m S b u 6 4 6 Y 4 R u M V q V z I 3 V 4 Q = " > A A A C x n i c j V H L S s N A F D 3 G V 6 2 v q k s 3 w V Z x V Z J u d F l w 0 2 V F + 4 B a J J l O a 2 h e T C Z K K Y I / 4 F Y / T f w D / Q v v j F N Q i + i E J G f O v e f M 3 H v 9 N A w y 6 T i v C 9 b i 0 v L K a m G t u L 6 x u b V d 2 t l t Z 0 k u G G + x J E x E 1 / c y H g Y x b 8 l A h r y b C u 5 F f s g 7 / v h M x T u 3 X G R B E l / K S c r 7 k T e K g 2 H A P E n U R a V W u S 6 V n a q j l z 0 P X A P K M K u Z l F 5 w h Q E S M O S I w B F D E g 7 h I a O n B x c O U u L 6 m B I n C A U 6 z n G P I m l z y u K U 4 R E 7 p u + I d j 3 D x r R X n p l W M z o l p F e Q 0 s Y h a R L K E 4 T V a b a O 5 9 p Z s b 9 5 T 7 W n u t u E / r 7 x i o i V u C H 2 L 9 0 s 8 7 8 6 V Y v E E K e 6 h o B q S j W j q m P G J d d d U T e 3 v 1 Q l y S E l T u E B x Q V h p p W z P t t a k + n a V W 8 9 H X / T m Y p V e 2 Z y c 7 y r W 9 K A 3 Z / j n A f t W t V 1 q u 5 5 r V w / M q M u Y B 8 H O K Z 5 n q C O B p p o k f c I j 3 j C s 9 W w Y i u 3 7 j 5 T r Q W j 2 c O 3 Z T 1 8 A L L M j 3 U = < / l a t e x i t >

F 1 < l a t e x i ts h a 1 _ b a s e 6 4 = " A y 5 w a S m 5 t M P z b 0 t R 7 G a b u A 1 h m O U = " > A A A C x X i c j V H L S s N A F D 2 N r 1 p f V Z d u g l V w V Z J u d F k Q 1 G U V + 4 B a J E m n d W h e T C a F U s Q f c K u / J v 6 B / o V 3 x i m o R X R C k j P n 3 n N m 7 r 1 + G v J M O s 5 r w V p Y X F p e K a 6 W 1 t Y 3 N r f K 2 z u t L M l F w J p B E i a i 4 3 s Z C 3 n M m p L L k H V S w b z I D 1 n b H 5 2 q e H v M R M a T + F p O U t a L v G H M B z z w J F F X Z + 5 t u e J U H b 3 s e e A a U I F Z j a T 8 g h v 0 k S B A j g g M M S T h E B 4 y e r p w 4 S A l r o c p c Y I Q 1 3 G G e 5 R I m 1 M W o w y P 2 B F 9 h 7 T r G j a m v f L M t D q g U 0 J 6 B S l t H J I m o T x B W J 1 m 6 3 i u n R X 7 m / d U e 6 q 7 T e j v G 6 + I W I k 7 Y v / S z T L / q 1 O 1 S A x w o m v g V F O q G V V d Y F x y 3 R V 1 c / t L V Z I c U u I U 7 l N c E A 6 0 c t Z n W 2 s y X b v q r a f j b z p T s W o f m N w c 7 + q W N G D 3 5 z j n Q a t W d Z 2 q e 1 m r 1 A / M q I v Y w z 6 O a J 7 H q O M C D T T J e 4 B H P O H Z O r c i S 1 r j z 1 S r Y D S 7 + L a s h w + F H I 9 m < / l a t e x i t >

3< l a t e x i ts h a 1 _ b a s e 6 4 = " 9 G J B K I M K D b N / w G y h h A E N s 4 8 J 8 N 0 = " > A A A C x n i c j V H L T s J A F D 3 U F + I L d e m m E T S u S I s L X Z K 4 Y Y l R H g k S 0 w 4 D T i h t M 5 1 q C D H x B 9 z q p x n / Q P / C O 2 N J V G J 0 m r Z n z r 3 n z N x 7 / T g Q i X K c 1 5 y 1 s L i 0 v J J f L a y t b 2 x u F b d 3 W k m U S s a b L A o i 2 f G 9 h A c i 5 E 0 l V M A 7 s e T e 2 A 9 4 2 x + d 6 X j 7 l s t E R O G l m s S 8 N / a G o R g I 5 i m i L s r H 5 e t i y a k 4 Z t n z w M 1 A C d l q R M U X X K G P C A w p x u A I o Q g H 8 J D Q 0 4 U L B z F x P U y J k 4 S E i X P c o 0 D a l L I 4 Z X j E j u g 7 p F 0 3 Y 0 P a a 8 / E q B m d E t A r S W n j g D Q R 5 U n C + j T b x F P j r N n f v K f G U 9 9 t Q n 8 / 8 x o T q 3 B D 7 F + 6 W e Z / d b o W h Q F O T Q 2 C a o o N o 6 t j m U t q u q J v b n + p S p F D T J z G f Y p L w s w o Z 3 2 2 j S Y x t e v e e i b + Z j I 1 q / c s y 0 3 x r m 9 J A 3 Z / j n M e t K o V 1 6 m 4 5 9 V S 7 T A b d R 5 7 2 M c R z f M E N d T R Q J O 8 h 3 j E E 5 6 t u h V a q X X 3 m W r l M s 0 u v i 3 r 4 Q O 1 L Y 9 2 < / l a t e x i t > < l a t e x i ts h a 1 _ b a s e 6 4 = " 7 v 4 d R 4 K 9 4 Y + / + e Z 5 Z m 5 U b 0 m q d a o = " > A A A C y n i c j V H L S s N A F D 2 N r 1 p f V Z d u g q 3 i q i R F 0 G X B j Q s X F e w D 2 i L J d F q H p k m c T I R S 3 P k D b v X D x D / Q v / D O m I J a R C c k O X P u O X f m 3 u v H g U i U 4 7 z m r I X F p e W V / G p h b X 1 j c 6 u 4 v d N M o l Q y 3 m B R E M m 2 7 y U 8 E C F v K K E C 3 o 4 l 9 8 Z + w F v + 6 E z H W 3 d c J i I K r 9 Q k 5 r 2 x N w z F Q D B P E d U q d 4 f 8 9 r h 8 X S w 5 F c c s e x 6 4 G S g h W / W o + I I u + o j A k G I M j h C K c A A P C T 0 d u H A Q E 9 f D l D h J S J g 4 x z 0 K 5 E 1 J x U n h E T u i 7 5 B 2 n Y w N a a 9 z J s b N 6 J S A X k l O G w f k i U g n C e v T b B N P T W b N / p Z 7 a n L q u 0 3 o 7 2 e 5 x s Q q 3 B D 7 l 2 + m / K 9 P 1 6 I w w K m p Q V B N s W F 0 d S z L k p q u 6 J v b X 6 p S l C E m T u M + x S V h Z p y z P t v G k 5 j a d W 8 9 E 3 8 z S s 3 q P c u 0 K d 7 1 L W n A 7 s 9 x z o N m t e I 6 F f e y W q o d Z q P O Y w / 7 O K J 5 n q C G c 9 T R M F U + 4 g n P 1 o U l r Y k 1 / Z R a u c y z i 2 / L e v g A I F 6 R O A = = < / l a t e x i t >

e L e n < l a t e x i ts h a 1 _ b a s e 6 4 = " i u E u f D E I + z g h c Q 8 V L I 5 C J X y n n C j 3 Q B q U D x 7 P t G U G K o l w l Z h 0 y a I j M Q = " > A A A C x 3 i c j V H L S s N A F D 2 N r 1 x p f V Z d u Q o v g q i R u d C M W 3 C i 4 q G A f U I s k 6 b Q d N T z D Y I v h J m p R F R i L K E C f 3 Q / H A 3 r O e o 5 f d + E n i F H P + 9 h C f / e 8 G M e 4 a 0 g B l b p W E I J T y k Q h 5 y c 5 + t 4 x 5 z Z z + s b y O d u c J W H L P f E S 2 4 l R Z p b v z u l W j 0 b h n c 5 W h l c 5 S Z m X / 8 X q F r h 6 Z 2 X v V r v G f 5 K V G d 5 j u e N q R S K d R x y h l 6 1 r W e c 8 y I M X / c 4 c k t 3 1 H E T u p b j z v k h N a U w l m l P z O 5 G r z R Z T s F y z Z A H t T d g n + T a f z f i m D R M N 1 W l b v Q D x B Y l n P X v I C S i X 8 c F h q S O x Y T t u Q D O 0 7 Q F 9 3 7 p j d n z i 7 M W V F x p c N 5 g Z l e C F 2 0 8 s L W J x b V N L s D q 3 m M H W M 2 A B y k s o D H p 7 d 8 N U X j / u S 4 R B + 1 m E e T j x V F q V D f D o B Q D s T B q D I i 4 g C A J M F I A S I R Y h Q H g w r 4 A S P e G t w q k w 9 Y L S V E g i w r E o R M P x X c x T p E g h 4 r T u s s h M T d y Y i Z Q 7 N 6 y O U R V N I S 4 c V D I 7 Y A R 1 M 9 7 + o z G R + r P Z 2 q x 2 I M c D 5 W W k Z u a M L x d P H l q d / m j k 0 V x n u 1 Q 5 0 O s T U g s P e 7 Q 5 b I q l Y I s x F w r n N L 1 P Q V x U V J T y 1 v W 2 y t Z + H y / x L z H l q R t 7 M G u 9 b H c f R z / b Z I 0 C s Y K i y U B G W x o P E 7 / l s m X y 7 r 6 / Z 6 8 1 r O 8 9 + S 2 P Y R t w A q F H 8 v e g q 1 B F 4 O 9 k 6 G i d h W U d j l u 6 3 W O k z + l l F T S U d z i s t 0 y v 5 X 8 U a l U K r i Q I Q h k T x u c E R v J 1 3 m q L M C 4 n J n u d 8 N o z 5 N O r 2 U d n D 0 e b R 2 L r V s u 3 z V x 0 b / W V 9 0 X r f F l a V v K m y X c q u Z 5 N m 8 2 a h F Q 2 f S c R p d s 0 / w 7 d z b O P W 6 d 5 D w Y H r 9 9 c h O W y x Z b Z 6 a w t y K t 7 U N S U J K i W O I P 6 H 8 Z t S h w D R E / Q d 5 0 g n C 0 p e O o U 4 U B O x d V s 1 g C d i 4 7 x j B 0 O c e 8 j 4 T V N m D 7 G 0 E C P J j t d q i N I 1 1 N c p p V l o n u G 8 9 + + z G i 8 2 f 9 A J e B P P g 2 E S 2 M S A 5 = O = k < / l a t e x i t >
4

BC

0 1< l a t e x i ts h a 1 _ b a s e 6 4 = " H / p n W R R 6 s C i f S S M G u 5 4 G g 3 U a C h E = " > A A A C x n i c j V H L S s N A F D 3 G V 6 2 v q k s 3 w V Z x V Z J u d F l w 0 2 V F + 4 B a J J l O 6 9 C 8 m E y U U g R / w K 1 + m v g H + h f e G V N Q i + i E J G f O v e f M 3 H v 9 J B C p c p z X B W t x a X l l t b B W X N / Y 3 N o u 7 e y 2 0 z i T j L d Y H M S y 6 3 s p D 0 T E W 0 q o g H c T y b 3 Q D 3 j H H 5 / p e O e W y 1 T E 0 a W a J L w f e q N I D A X z F F E X F b d y X S o 7 V c c s e x 6 4 O S g j X 8 2 4 9 I I r D B C D I U M I j g i K c A A P K T 0 9 u H C Q E N f H l D h J S J g 4 x z 2 K p M 0 o i 1 O G R + y Y v i P a 9 X I 2 o r 3 2 T I 2 a 0 S k B v Z K U N g 5 J E 1 O e J K x P s 0 0 8 M 8 6 a / c 1 7 a j z 1 3 S b 0 9 3 O v k F i F G 2 L / 0 s 0 y / 6 v T t S g M c W p q E F R T Y h h d H c t d M t M V f X P 7 S 1 W K H B L i N B 5 Q X B J m R j n r s 2 0 0 q a l d 9 9 Y z 8 T e T q V m 9 Z 3 l u h n d 9 S x q w + 3 O c 8 6 B d q 7 p O 1 T 2 v l e t H + a g L 2 M c B j m m e J 6 i j g S Z a 5 D 3 C I 5 7 w b D W s y M q s u 8 9 U a y H X 7 O H b s h 4 + A L B r j 3 Q = < / l a t e x i t >

2< l a t e x i ts h a 1 _ b a s e 6 4 = " L Q r c w P m S b u 6 4 6 Y 4 R u M V q V z I 3 V 4 Q = " > A A A C x n i c j V H L S s N A F D 3 G V 6 2 v q k s 3 w V Z x V Z J u d F l w 0 2 V F + 4 B a J J l O a 2 h e T C Z K K Y I / 4 F Y / T f w D / Q v v j F N Q i + i E J G f O v e f M 3 H v 9 N A w y 6 T i v C 9 b i 0 v L K a m G t u L 6 x u b V d 2 t l t Z 0 k u G G + x J E x E 1 / c y H g Y x b 8 l A h r y b C u 5 F f s g 7 / v h M x T u 3 X G R B E l / K S c r 7 k T e K g 2 H A P E n U R a V W u S 6 V n a q j l z 0 P X A P K M K u Z l F 5 w h Q E S M O S I w B F D E g 7 h I a O n B x c O U u L 6 m B I n C A U 6 z n G P I m l z y u K U 4 R E 7 p u + I d j 3 D x r R X n p l W M z o l p F e Q 0 s Y h a R L K E 4 T V a b a O 5 9 p Z s b 9 5 T 7 W n u t u E / r 7 x i o i V u C H 2 L 9 0 s 8 7 8 6 V Y v E E K e 6 h o B q S j W j q m P G J d d d U T e 3 v 1 Q l y S E l T u E B x Q V h p p W z P t t a k + n a V W 8 9 H X / T m Y p V e 2 Z y c 7 y r W 9 K A 3 Z / j n A f t W t V 1 q u 5 5 r V w / M q M u Y B 8 H O K Z 5 n q C O B p p o k f c I j 3 j C s 9 W w Y i u 3 7 j 5 T r Q W j 2 c O 3 Z T 1 8 A L L M j 3 U = < / l a t e x i t >

3< l a t e x i ts h a 1 _ b a s e 6 4 = " 9 G J B K I M K D b N / w G y h h A E N s 4 8 J 8 N 0 = " > A A A C x n i c j V H L T s J A F D 3 U F + I L d e m m E T S u S I s L X Z K 4 Y Y l R H g k S 0 w 4 D T i h t M 5 1 q C D H x B 9 z q p x n / Q P / C O 2 N J V G J 0 m r Z n z r 3 n z N x 7 / T g Q i X K c 1 5 y 1 s L i 0 v J J f L a y t b 2 x u F b d 3 W k m U S s a b L A o i 2 f G 9 h A c i 5 E 0 l V M A 7 s e T e 2 A 9 4 2 x + d 6 X j 7 l s t E R O G l m s S 8 N / a G o R g I 5 i m i L s r H 5 e t i y a k 4 Z t n z w M 1 A C d l q R M U X X K G P C A w p x u A I o Q g H 8 J D Q 0 4 U L B z F x P U y J k 4 S E i X P c o 0 D a l L I 4 Z X j E j u g 7 p F 0 3 Y 0 P a a 8 / E q B m d E t A r S W n j g D Q R 5 U n C + j T b x F P j r N n f v K f G U 9 9 t Q n 8 / 8 x o T q 3 B D 7 F + 6 W e Z / d b o W h Q F O T Q 2 C a o o N o 6 t j m U t q u q J v b n + p S p F D T J z G f Y p L w s w o Z 3 2 2 j S Y x t e v e e i b + Z j I 1 q / c s y 0 3 x r m 9 J A 3 Z / j n M e t K o V 1 6 m 4 5 9 V S 7 T A b d R 5 7 2 M c R z f M E N d T R Q J O 8 h 3 j E E 5 6 t u h V a q X X 3 m W r l M s 0 u v i 3 r 4 Q O 1 L Y 9 2 < / l a t e x i t > < l a t e x i ts h a 1 _ b a s e 6 4 = " 7 v 4 d R 4 K 9 4 Y + / + e Z 5 Z m 5 U b 0 m q d a o = " > A A A C y n i c j V H L S s N A F D 2 N r 1 p f V Z d u g q 3 i q i R F 0 G X B j Q s X F e w D 2 i L J d F q H p k m c T I R S 3 P k D b v X D x D / Q v / D O m I J a R C c k O X P u O X f m 3 u v H g U i U 4 7 z m r I X F p e W V / G p h b X 1 j c 6 u 4 v d N M o l Q y 3 m B R E M m 2 7 y U 8 E C F v K K E C 3 o 4 l 9 8 Z + w F v + 6 E z H W 3 d c J i I K r 9 Q k 5 r 2 x N w z F Q D B P E d U q d 4 f 8 9 r h 8 X S w 5 F c c s e x 6 4 G S g h W / W o + I I u + o j A k G I M j h C K c A A P C T 0 d u H A Q E 9 f D l D h J S J g 4 x z 0 K 5 E 1 J x U n h E T u i 7 5 B 2 n Y w N a a 9 z J s b N 6 J S A X k l O G w f k i U g n C e v T b B N P T W b N / p Z 7 a n L q u 0 3 o 7 2 e 5 x s Q q 3 B D 7 l 2 + m / K 9 P 1 6 I w w K m p Q V B N s W F 0 d S z L k p q u 6 J v b X 6 p S l C E m T u M + x S V h Z p y z P t v G k 5 j a d W 8 9 E 3 8 z S s 3 q P c u 0 K d 7 1 L W n A 7 s 9 x z o N m t e I 6 F f e y W q o d Z q P O Y w / 7 O K J 5 n q C G c 9 T R M F U + 4 g n P 1 o U l r Y k 1 / Z R a u c y z i 2 / L e v g A I F 6 R O A = = < / l a t e x i t >

e L e n < l a t e x i ts h a 1 _ b a s e 6 4 = " i u E u f D E I + z g h c Q 8 V L I 5 C J X y n n C j 3 Q B q U D x 7 P t G U G K o l w l Z h 0 y a I j M Q = " > A A A C x 3 i c j V H L S s N A F D 2 N r 1 x p f V Z d u Q o v g q i R u d C M W 3 C i 4 q G A f U I s k 6 b Q d N T z D Y I v h J m p R F R i L K E C f 3 Q / H A 3 r O e o 5 f d + E n i F H P + 9 h C f / e 8 G M e 4 a 0 g B l b p W E I J T y k Q h 5 y c 5 + t 4 x 5 z Z z + s b y O d u c J W H L P f E S 2 4 l R Z p b v z u l W j 0 b h n c 5 W h l c 5 S Z m X / 8 X q F r h 6 Z 2 X v V r v G f 5 K V G d 5 j u e N q R S K d R x y h l 6 1 r W e c 8 y I M X / c 4 c k t 3 1 H E T u p b j z v k h N a U w l m l P z O 5 G r z R Z T s F y z Z A H t T d g n + T a f z f i m D R M N 1 W l b v Q D x B Y l n P X v I C S i X 8 c F h q S O x Y T t u Q D O 0 7 Q F 9 3 7 p j d n z i 7 M W V F x p c N 5 g Z l e C F 2 0 8 s L W J x b V N L s D q 3 m M H W M 2 A B y k s o D H p 7 d 8 N U X j / u S 4 R B + 1 m E e T j x V F q V D f D o B Q D s T B q D I i 4 g C A J M F I A S I R Y h Q H g w r 4 A S P e G t w q k w 9 Y L S V E g i w r E o R M P x X c x T p E g h 4 r T u s s h M T d y Y i Z Q 7 N 6 y O U R V N I S 4 c V D I 7 Y A R 1 M 9 7 + o z G R + r P Z 2 q x 2 I M c D 5 W W k Z u a M L x d P H l q d / m j k 0 V x n u 1 Q 5 0 O s T U g s P e 7 Q 5 b I q l Y I s x F w r n N L 1 P Q V x U V J T y 1 v W 2 y t Z + H y / x L z H l q R t 7 M G u 9 b H c f R z / b Z I 0 C s Y K i y U B G W x o P E 7 / l s m X y 7 r 6 / Z 6 8 1 r O 8 9 + S 2 P Y R t w A q F H 8 v e g q 1 B F 4 O 9 k 6 G i d h W U d j l u 6 3 W O k z + l l F T S U d z i s t 0 y v 5 X 8 U a l U K r i Q I Q h k T x u c E R v J 1 3 m q L M C 4 n J n u d 8 N o z 5 N O r 2 U d n D 0 e b R 2 L r V s u 3 z V x 0 b / W V 9 0 X r f F l a V v K m y X c q u Z 5 N m 8 2 a h F Q 2 f S c R p d s 0 / w 7 d z b O P W 6 d 5 D w Y H r 9 9 c h O W y x Z b Z 6 a w t y K t 7 U N S U J K i W O I P 6 H 8 Z t S h w D R E / Q d 5 0 g n C 0 p e O o U 4 U B O x d V s 1 g C d i 4 7 x j B 0 O c e 8 j 4 T V N m D 7 G 0 E C P J j t d q i N I 1 1 N c p p V l o n u G 8 9 + + z G i 8 2 f 9 A J e B P P g 2 E S 2 M S A 5 = O = k < / l a t e x i t >
4

CN03
.8 .6 .4
.2

BN WB eLen
PER LOC ORG

Error True Pred Sentence

BoEltErorrnorror

oTrTrgureue

P

red··· SBroemnwticeh nce PrevdBolStonentence

Bolton org

··· Bromwich NFvLBolton

NBFoLltonorgorg O

··· Bromwich AMNEFRvLIBCoAltNon···

N

CNANFALFL

orogrogrg

OOO

N A

CAAMANEFRLICAN MERICAN ···

··

·

NCAA org

O

NCAAMAERICAN ··· AMERICAN ···

NCAA org

O

NCAA AMERICAN ···

Performance Histogram: the input model is good at dealing with short entities, while achieving lower performance on long entities.
Performance Gap Histogram (M1−M2): M1 is better at dealing with short entities, while M2 is better at dealing with long entities.
Data Bias Chart: For the entity length attribute, the average entity length (We average the length of all test entities on a given data set.) of these datasets order by descending is BN> BC> CN03> WB. Error Table: Error analysis allows the user to print out the entities that are incorrectly predicted by the given model, as well as the true label of the entity, the mispredicted label, and the sentence where the entity is located.

0 M1 M2 M3 Comb

Ensemble Chart: The combined result of model M1, M2, and M3 is shown by the histogram with x-label value comb. The combined result is better than the single models.

Reliability Conﬁdence Calibration

One model One model

F 1 < l a t e x i ts h a 1 _ b a s e 6 4 = " A y 5 w a S m 5 t M P z b 0 t R 7 G a b u A 1 h m O U = " > A A A C x X i c j V H L S s N A F D 2 N r 1 p f V Z d u g l V w V Z J u d F k Q 1 G U V + 4 B a J E m n d W h e T C a F U s Q f c K u / J v 6 B / o V 3 x i m o R X R C k j P n 3 n N m 7 r 1 + G v J M O s 5 r w V p Y X F p e K a 6 W 1 t Y 3 N r f K 2 z u t L M l F w J p B E i a i 4 3 s Z C 3 n M m p L L k H V S w b z I D 1 n b H 5 2 q e H v M R M a T + F p O U t a L v G H M B z z w J F F X Z + 5 t u e J U H b 3 s e e A a U I F Z j a T 8 g h v 0 k S B A j g g M M S T h E B 4 y e r p w 4 S A l r o c p c Y I Q 1 3 G G e 5 R I m 1 M W o w y P 2 B F 9 h 7 T r G j a m v f L M t D q g U 0 J 6 B S l t H J I m o T x B W J 1 m 6 3 i u n R X 7 m / d U e 6 q 7 T e j v G 6 + I W I k 7 Y v / S z T L / q 1 O 1 S A x w o m v g V F O q G V V d Y F x y 3 R V 1 c / t L V Z I c U u I U 7 l N c E A 6 0 c t Z n W 2 s y X b v q r a f j b z p T s W o f m N w c 7 + q W N G D 3 5 z j n Q a t W d Z 2 q e 1 m r 1 A / M q I v Y w z 6 O a J 7 H q O M C D T T J e 4 B H P O H Z O r c i S 1 r j z 1 S r Y D S 7 + L a s h w + F H I 9 m < / l a t e x i t >

0

1< l a t e x i ts h a 1 _ b a s e 6 4 = " H / p n W R R 6 s C i f S S M G u 5 4 G g 3 U a C h E = " > A A A C x n i c j V H L S s N A F D 3 G V 6 2 v q k s 3 w V Z x V Z J u d F l w 0 2 V F + 4 B a J J l O 6 9 C 8 m E y U U g R / w K 1 + m v g H + h f e G V N Q i + i E J G f O v e f M 3 H v 9 J B C p c p z X B W t x a X l l t b B W X N / Y 3 N o u 7 e y 2 0 z i T j L d Y H M S y 6 3 s p D 0 T E W 0 q o g H c T y b 3 Q D 3 j H H 5 / p e O e W y 1 T E 0 a W a J L w f e q N I D A X z F F E X F b d y X S o 7 V c c s e x 6 4 O S g j X 8 2 4 9 I I r D B C D I U M I j g i K c A A P K T 0 9 u H C Q E N f H l D h J S J g 4 x z 2 K p M 0 o i 1 O G R + y Y v i P a 9 X I 2 o r 3 2 T I 2 a 0 S k B v Z K U N g 5 J E 1 O e J K x P s 0 0 8 M 8 6 a / c 1 7 a j z 1 3 S b 0 9 3 O v k F i F G 2 L / 0 s 0 y / 6 v T t S g M c W p q E F R T Y h h d H c t d M t M V f X P 7 S 1 W K H B L i N B 5 Q X B J m R j n r s 2 0 0 q a l d 9 9 Y z 8 T e T q V m 9 Z 3 l u h n d 9 S x q w + 3 O c 8 6 B d q 7 p O 1 T 2 v l e t H + a g L 2 M c B j m m e J 6 i j g S Z a 5 D 3 C I 5 7 w b D W s y M q s u 8 9 U a y H X 7 O H b s h 4 + A L B r j 3 Q = < / l a t e x i t >

2< l a t e x i ts h a 1 _ b a s e 6 4 = " L Q r c w P m S b u 6 4 6 Y 4 R u M V q V z I 3 V 4 Q = " > A A A C x n i c j V H L S s N A F D 3 G V 6 2 v q k s 3 w V Z x V Z J u d F l w 0 2 V F + 4 B a J J l O a 2 h e T C Z K K Y I / 4 F Y / T f w D / Q v v j F N Q i + i E J G f O v e f M 3 H v 9 N A w y 6 T i v C 9 b i 0 v L K a m G t u L 6 x u b V d 2 t l t Z 0 k u G G + x J E x E 1 / c y H g Y x b 8 l A h r y b C u 5 F f s g 7 / v h M x T u 3 X G R B E l / K S c r 7 k T e K g 2 H A P E n U R a V W u S 6 V n a q j l z 0 P X A P K M K u Z l F 5 w h Q E S M O S I w B F D E g 7 h I a O n B x c O U u L 6 m B I n C A U 6 z n G P I m l z y u K U 4 R E 7 p u + I d j 3 D x r R X n p l W M z o l p F e Q 0 s Y h a R L K E 4 T V a b a O 5 9 p Z s b 9 5 T 7 W n u t u E / r 7 x i o i V u C H 2 L 9 0 s 8 7 8 6 V Y v E E K e 6 h o B q S j W j q m P G J d d d U T e 3 v 1 Q l y S E l T u E B x Q V h p p W z P t t a k + n a V W 8 9 H X / T m Y p V e 2 Z y c 7 y r W 9 K A 3 Z / j n A f t W t V 1 q u 5 5 r V w / M q M u Y B 8 H O K Z 5 n q C O B p p o k f c I j 3 j C s 9 W w Y i u 3 7 j 5 T r Q W j 2 c O 3 Z T 1 8 A L L M j 3 U = < / l a t e x i t >

3< l a t e x i ts h a 1 _ b a s e 6 4 = " 9 G J B K I M K D b N / w G y h h A E N s 4 8 J 8 N 0 = " > A A A C x n i c j V H L T s J A F D 3 U F + I L d e m m E T S u S I s L X Z K 4 Y Y l R H g k S 0 w 4 D T i h t M 5 1 q C D H x B 9 z q p x n / Q P / C O 2 N J V G J 0 m r Z n z r 3 n z N x 7 / T g Q i X K c 1 5 y 1 s L i 0 v J J f L a y t b 2 x u F b d 3 W k m U S s a b L A o i 2 f G 9 h A c i 5 E 0 l V M A 7 s e T e 2 A 9 4 2 x + d 6 X j 7 l s t E R O G l m s S 8 N / a G o R g I 5 i m i L s r H 5 e t i y a k 4 Z t n z w M 1 A C d l q R M U X X K G P C A w p x u A I o Q g H 8 J D Q 0 4 U L B z F x P U y J k 4 S E i X P c o 0 D a l L I 4 Z X j E j u g 7 p F 0 3 Y 0 P a a 8 / E q B m d E t A r S W n j g D Q R 5 U n C + j T b x F P j r N n f v K f G U 9 9 t Q n 8 / 8 x o T q 3 B D 7 F + 6 W e Z / d b o W h Q F O T Q 2 C a o o N o 6 t j m U t q u q J v b n + p S p F D T J z G f Y p L w s w o Z 3 2 2 j S Y x t e v e e i b + Z j I 1 q / c s y 0 3 x r m 9 J A 3 Z / j n M e t K o V 1 6 m 4 5 9 V S 7 T A b d R 5 7 2 M c R z f M E N d T R Q J O 8 h 3 j E E 5 6 t u h V a q X X 3 m W r l M s 0 u v i 3 r 4 Q O 1 L Y 9 2 < / l a t e x i t > < l a t e x i ts h a 1 _ b a s e 6 4 = " 7 v 4 d R 4 K 9 4 Y + / + e Z 5 Z m 5 U b 0 m q d a o = " > A A A C y n i c j V H L S s N A F D 2 N r 1 p f V Z d u g q 3 i q i R F 0 G X B j Q s X F e w D 2 i L J d F q H p k m c T I R S 3 P k D b v X D x D / Q v / D O m I J a R C c k O X P u O X f m 3 u v H g U i U 4 7 z m r I X F p e W V / G p h b X 1 j c 6 u 4 v d N M o l Q y 3 m B R E M m 2 7 y U 8 E C F v K K E C 3 o 4 l 9 8 Z + w F v + 6 E z H W 3 d c J i I K r 9 Q k 5 r 2 x N w z F Q D B P E d U q d 4 f 8 9 r h 8 X S w 5 F c c s e x 6 4 G S g h W / W o + I I u + o j A k G I M j h C K c A A P C T 0 d u H A Q E 9 f D l D h J S J g 4 x z 0 K 5 E 1 J x U n h E T u i 7 5 B 2 n Y w N a a 9 z J s b N 6 J S A X k l O G w f k i U g n C e v T b B N P T W b N / p Z 7 a n L q u 0 3 o 7 2 e 5 x s Q q 3 B D 7 l 2 + m / K 9 P 1 6 I w w K m p Q V B N s W F 0 d S z L k p q u 6 J v b X 6 p S l C E m T u M + x S V h Z p y z P t v G k 5 j a d W 8 9 E 3 8 z S s 3 q P c u 0 K d 7 1 L W n A 7 s 9 x z o N m t e I 6 F f e y W q o d Z q P O Y w / 7 O K J 5 n q C G c 9 T R M F U + 4 g n P 1 o U l r Y k 1 / Z R a u c y z i 2 / L e v g A I F 6 R O A = = < / l a t e x i t >

e L e n < l a t e x i ts h a 1 _ b a s e 6 4 = " i u E u f D E I + z g h c Q 8 V L I 5 C J X y n n C j 3 Q B q U D x 7 P t G U G K o l w l Z h 0 y a I j M Q = " > A A A C x 3 i c j V H L S s N A F D 2 N r 1 x p f V Z d u Q o v g q i R u d C M W 3 C i 4 q G A f U I s k 6 b Q d N T z D Y I v h J m p R F R i L K E C f 3 Q / H A 3 r O e o 5 f d + E n i F H P + 9 h C f / e 8 G M e 4 a 0 g B l b p W E I J T y k Q h 5 y c 5 + t 4 x 5 z Z z + s b y O d u c J W H L P f E S 2 4 l R Z p b v z u l W j 0 b h n c 5 W h l c 5 S Z m X / 8 X q F r h 6 Z 2 X v V r v G f 5 K V G d 5 j u e N q R S K d R x y h l 6 1 r W e c 8 y I M X / c 4 c k t 3 1 H E T u p b j z v k h N a U w l m l P z O 5 G r z R Z T s F y z Z A H t T d g n + T a f z f i m D R M N 1 W l b v Q D x B Y l n P X v I C S i X 8 c F h q S O x Y T t u Q D O 0 7 Q F 9 3 7 p j d n z i 7 M W V F x p c N 5 g Z l e C F 2 0 8 s L W J x b V N L s D q 3 m M H W M 2 A B y k s o D H p 7 d 8 N U X j / u S 4 R B + 1 m E e T j x V F q V D f D o B Q D s T B q D I i 4 g C A J M F I A S I R Y h Q H g w r 4 A S P e G t w q k w 9 Y L S V E g i w r E o R M P x X c x T p E g h 4 r T u s s h M T d y Y i Z Q 7 N 6 y O U R V N I S 4 c V D I 7 Y A R 1 M 9 7 + o z G R + r P Z 2 q x 2 I M c D 5 W W k Z u a M L x d P H l q d / m j k 0 V x n u 1 Q 5 0 O s T U g s P e 7 Q 5 b I q l Y I s x F w r n N L 1 P Q V x U V J T y 1 v W 2 y t Z + H y / x L z H l q R t 7 M G u 9 b H c f R z / b Z I 0 C s Y K i y U B G W x o P E 7 / l s m X y 7 r 6 / Z 6 8 1 r O 8 9 + S 2 P Y R t w A q F H 8 v e g q 1 B F 4 O 9 k 6 G i d h W U d j l u 6 3 W O k z + l l F T S U d z i s t 0 y v 5 X 8 U a l U K r i Q I Q h k T x u c E R v J 1 3 m q L M C 4 n J n u d 8 N o z 5 N O r 2 U d n D 0 e b R 2 L r V s u 3 z V x 0 b / W V 9 0 X r f F l a V v K m y X c q u Z 5 N m 8 2 a h F Q 2 f S c R p d s 0 / w 7 d z b O P W 6 d 5 D w Y H r 9 9 c h O W y x Z b Z 6 a w t y K t 7 U N S U J K i W O I P 6 H 8 Z t S h w D R E / Q d 5 0 g n C 0 p e O o U 4 U B O x d V s 1 g C d i 4 7 x j B 0 O c e 8 j 4 T V N m D 7 G 0 E C P J j t d q i N I 1 1 N c p p V l o n u G 8 9 + + z G i 8 2 f 9 A J e B P P g 2 E S 2 M S A 5 = O = k < / l a t e x i t >
4

Error Bars: the error bars represent 95% conﬁdence intervals of the performance on the speciﬁc bucket.

Gap Output

Error: 28.6

0.0

0.5

1.0

Reliability Diagram: Conﬁdence histograms (red) and reliability diagrams (blue). that indicate the accuracy of model probability estimates

Table 1: A graphical breakdown of the functionality of EXPLAINABOARD, with examples from an NER task.

Named Entity Recognition (NER) task, we may examine the accuracy along different dimensions of a concerned entity (such as “entity frequency,” telling us how well the model does on entities that appear in the training data a certain number of times) or sentences (such as “sentence length,” telling us how well the model does on entities that appear in longer or shorter sentences) (Fu et al., 2020a). This makes it possible to understand where models do well and poorly, leading to further insights beyond those that can be gleaned by holistic evaluation numbers. Applying this to a new task involves the following steps: (i) Attribute deﬁnition: deﬁne attributes by which we can partition the test set into different groups. (ii) Bucketing: partition into different buckets based on deﬁned attributes and calculate performance w.r.t each bucket.
Generally, previous work on interpretable evaluation has been performed over single tasks, while EXPLAINABOARD allows for comprehensive eval-

uation of different types of tasks in a single software package. We concretely show several ways interpretable evaluation can be deﬁned within EXPLAINABOARD below:
F18: Single-system Analysis: What is a system good or bad at? For an individual system as input, generate a performance histogram that highlights the buckets where it performs well or poorly. For example, in Tab. 1 we demonstrate an example from NER where the input system does worse in dealing with longer entities (eLen ≥ 4).
F2: Pairwise Analysis: Where is one system better (worse) than another? Given a pair of systems, interpret where the performance gap occurs. Researchers could ﬂexibly choose two systems they are interested in (e.g. selecting two rows from the leaderboard), and EXPLAINABOARD will output a performance gap histogram to describe how the
8“F” represents “Functionality”.

performance differences change over different buckets of different attributes. Tab. 1 demonstrates how we can see one system is better than the other at longer or shorter entities.
F3: Data Bias Analysis: What are the characteristics of different evaluated datasets? The deﬁned attributes do not only help us interpret system performance, but also make it possible for users to take a closer look at characteristics of diverse datasets. For example, from Fig. 1 shows an example of analyzing differences in average entity length across several datasets.
2.2 Interactivity
EXPLAINABOARD also allows users to dig deeper, interacting with the results in more complex ways.
F4: Fine-grained Error Analysis: What are common mistakes that most systems make and where do they occur? EXPLAINABOARD provides ﬂexible ﬁne-grained error analyses based on the above-described performance evaluation:
1. Users can choose multiple systems and see their common error cases, which can be useful to identify challenging samples or even annotation errors.
2. In single-system analysis, users can choose particular buckets in the performance histogram9 and see corresponding error samples in that bucket (e.g. which long entities does the current system mispredict?).
3. In pairwise analysis, users can select a bucket, and the unique errors (e.g. system A succeeds while B fails and vice versa) of two models will be displayed.
F5: System Combination: Is there potential complementarity between different systems? System combination (Ting and Witten, 1997; González-Rubio et al., 2011; Duh et al., 2011) is a technique to improve performance by combining the output from multiple existing systems. In EXPLAINABOARD, users can choose multiple systems and obtain combined results calculated by voting over multiple base systems.10 In practice, for NER task, we use the recently proposed SPANNER (Fu
9Each bin of the performance histogram is clickable, returning an error case table.
10With the system combination button of Explainaboard, we observed the-state-of-the art performance of some tasks (e.g., NER, Chunking) can be further improved.

et al., 2021) as a combiner, and for text summarization we employed REFACTOR, a state-of-the-art ensemble approach (Liu et al., 2021). Regarding the other tasks, we adopt the majority voting method for system combination.
2.3 Reliability
The experimental conclusions obtained from the evaluation metrics are not necessarily statistically reliable, especially when the experimental results can be affected by many factors. EXPLAINABOARD also makes a step towards more reliable interpretable evaluation.
F6: Conﬁdence Analysis: To what extent can we trust the results of our system? EXPLAINABOARD can perform conﬁdence analysis over both holistic and ﬁne-grained performance metrics. As shown in Tab. 1, for each bucket, there is an error bar whose width reﬂects how reliable the performance value is. We claim this is an important feature for ﬁne-grained analysis since the numbers of test samples in each bucket are imbalanced, and with the conﬁdence interval, one could know how much uncertainty there is. In practice, we use bootstrapping method (Efron, 1992; Ye et al., 2021) to calculate the conﬁdence interval.
F7: Calibration Analysis: How well is the conﬁdence of prediction calibrated with its correctness? One commonly-cited issue with modern neural predictors is that their probability estimates are not accurate (i.e. they are poorly calibrated), often being over-conﬁdent in the correctness of their predictions (Guo et al., 2017). We also incorporate this feature into EXPLAINABOARD, allowing users to evaluate how well-calibrated their systems of interest are.
3 Tasks, Datasets and Systems
We have already added to EXPLAINABOARD 12 NLP tasks, 50 datasets, and 400 models,11 which cover many or most of top-scoring systems on these tasks.We brieﬂy describe them below, and show high-level statistics in Tab. 2.
Text Classiﬁcation Prediction of one or multiple pre-deﬁned label(s) for a given input text. The current interface includes datasets for sentiment
11265 of these models are implemented by us, as unfortunately it is currently not standard in NLP to release the system outputs that EXPLAINABOARD needs.

classiﬁcation (Pang et al., 2002), topic identiﬁcation (Wang and Manning, 2012), and intention detection (Chen et al., 2013).
Text-Span Classiﬁcation Prediction of a predeﬁned class from the input of a text and a span, such as aspect-based sentiment classiﬁcation task (Pappas and Popescu-Belis, 2014). We collect topperform system outputs from (Dai et al., 2021).
Text Pair Classiﬁcation Prediction of a class given two texts, such as the natural language inference task (Bowman et al., 2015).
Sequence Labeling Prediction of a label for each token in a sequence. The EXPLAINABOARD currently includes four concrete tasks: named entity recognition (Tjong Kim Sang and De Meulder, 2003), part-of-speech tagging (Toutanova et al., 2003), text chunking (Ando and Zhang, 2005), and Chinese word segmentation (Chen et al., 2015).
Structure Prediction Prediction of a syntactic or semantic structure from text, where EXPLAINABOARD currently covers semantic parsing tasks (Berant et al., 2013; Yu et al., 2018).
Text Generation EXPLAINABOARD also considers text generation tasks, and currently mainly focuses on conditional text generation, for example, text summarization (Rush et al., 2015; Liu and Lapata, 2019) and machine translation . System outputs on text summarization are expanded based on the previous work’s collection (Bhandari et al., 2020) as well as recently state-of-the-art systems (Liu and Liu, 2021) while outputs from machine translation are collected from the WMT20.12
4 Case Study
Here, we brieﬂy showcase the actual EXPLAINABOARD interface through a case study on analyzing state-of-the-art NER systems.
4.1 Experimental Setup
Attribute Deﬁnition We deﬁne attributes following Fu et al. (2020a) and three of them are used below: entity length, sentence length and label of entity.
Collection of Systems Outputs Currently, we collect system outputs by either implementing them by ourselves or collecting from other researchers
12http://www.statmt.org/wmt20/ metrics-task.html

Task

Data Model Attr.

Sentiment

8 40 2

Text Classiﬁcation

Topic Intention

4 18 2 132

Text-Span Classi- Aspect Sentiment 4 20 4 ﬁcation

Text Pair Classiﬁ-

NLI

267

cation

NER

3 74 9

Sequence Labeling

POS Chunking

3 14 4 3 14 9

CWS

7 64 7

Structure Pred. Semantic Parsing 4 12 4

Summarization 2 36 7

Text Generation

Translation

4 60 9

Table 2: Brief descriptions of tasks, datasets and systems that EXPLAINABOARD currently supports. “Attr.” denotes Attribute. “Pred.” denotes “Prediction”.

(Fu et al., 2020b; Schweter and Akbik, 2020; Yamada et al., 2020). Using these methods, we have gathered 74 models on six NER datasets with system output information.
4.2 Analysis using ExplainaBoard
Fig. 2 illustrates different types of results driven by four functionality buttons13 over the top-3 NER systems: LUKE (Yamada et al., 2020), FLERT (Schweter and Akbik, 2020) and FLAIR (Akbik et al., 2019). Box A breaks down the performance of the top-1 system over different attributes.14 We can intuitively observe that even the state-of-the-art system does worse on longer entities. Users can further print error cases in the longer entity bucket by clicking the corresponding bin. Box B shows the 1st system’s (LUKE) performance minus the 2nd system’s (FLERT) performance. We can see that although LUKE surpasses FLERT holistically, it performs worse when dealing with PERSON entities. Box C identiﬁes samples that all systems mispredict. Further analysis of these samples uncovers challenging patterns or annotation errors. Box D examines potential complementarity among these top-3 systems. The result shows that, by a simple voting ensemble strategy, a new state-
13As it is relatively challenging to deﬁne calibration in structure prediction tasks, this feature is currently only provided for classiﬁcation tasks. We will explore more in the future.
14Due to the page limitation, we only show three.

Figure 2: An example of the actual EXPLAINABOARD interface for NER over three top-performing systems on the CoNLL-2003 dataset. Box A shows the single-system analysis results obtained when users select the top-1 system and click the “Single Analysis” button. Box B shows the pairwise analysis results when top-2 systems are chosen and “Pair Analysis” is clicked. Users can click any bin of the histogram, which results in a ﬁne-grained error case table. Box C represents a table with common errors of these top-3 systems. Box D illustrates the combined result of the top-3 systems.

of-the-art (94.65 F1) has been achieved on the CoNLL-2003 dataset.
5 Usage
Example Use-cases To show the practical utility of EXPLAINABOARD, we ﬁrst present examples of how it has been used as an analysis tool in existing published research papers. Fu et al. (2020b) (Tab.4) utilize single-system analysis with the attribute of label consistency for NER task while Zhong et al. (2019) (Tab.4-5) use it for text summarization with attributes of density and compression. Fig.4 and Tab.3 in Fu et al. (2020a) leverage the data bias analysis and pairwise system diagnostics to interpret top-performing NER systems while Tab.4 in Fu et al. (2020c) use single and pairwise system analysis to investigate what’s next for the Chinese Word Segmentation task. Liu et al. (2021) use system combiner functionality to make ensemble analysis of summarization systems and Fig.1 in Ye et al. (2021) use reliability analysis functionality to observe how conﬁdence intervals change in different buckets of a performance histogram.

Using ExplainaBoard Researchers can use EXPLAINABOARD in different ways: (i) We maintain a website where each task-speciﬁc EXPLAINABOARD allows researchers to interact with it, interpreting systems and datasets that they are interested in from different perspectives. (ii) We also release our back-end code for different NLP tasks so that researchers could ﬂexibly use them to process their own system outputs, which can assist their research projects.
Contributing to ExplainaBoard The community can contribute to EXPLAINABOARD in several ways: (i) Submit system outputs of their implemented models. (ii) Add more informative attributes for different NLP tasks. (iii) Add new datasets or benchmarks for existing or new tasks.
6 Implications and Roadmap
EXPLAINABOARD presents a new paradigm in leaderboard development for NLP. This is just the beginning of its development, and there are many future directions.

Research Revolving on System Outputs15 Due to the ability to analyze, contrast, or combine results from many systems EXPLAINABOARD incentivizes researchers to submit their results to explainaboard to better understand them and showcase their systems’ strengths. At the same time, EXPLAINABOARD will serve as a central repository for system outputs across many tasks, allowing for future avenues of research into cross-system analysis or system combination.
Enriching ExplainaBoard with Glass-box Analysis EXPLAINABOARD currently performs blackbox analysis, solely analyzing system outputs without accessing model internals. On the other hand, there are many other glass-box interpretability tools that look at model internals, such as the AllenNLP Interpret (Wallace et al., 2019) and Language Interpretability Tool (Tenney et al., 2020). Expanding leaderboards to glass-box analysis methods (see Lipton (2018); Belinkov and Glass (2019) for a survey) is an interesting future work.
In the future, we aim to improve the applicability and usefulness by following action items: (1) Collaborate with more leaderboard organizers of diverse tasks and set up corresponding EXPLAINABOARDs for them. (2) Cover more tasks, datasets, models, as well as functionalities.
Acknowledgements
We thanks all reviewers for their valuable comments and authors who share their system outputs with us: Ikuya Yamada, Stefan Schweter, Colin Raffel, Yang Liu, Li Dong. We also thank Vijay Viswanathan, Yiran Chen, Hiroaki Hayashi for useful discussion and feedback about EXPLAINABOARD.
The work was supported in part by the Air Force Research Laboratory under agreement number FA8750-19-2-0200. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the ofﬁcial policies or endorsements, either expressed or implied, of the Air Force Research Laboratory or the U.S. Government.
15We released system outputs of EXPLAINABOARD: http://explainaboard.nlpedia.ai/download. html

References
Alan Akbik, Tanja Bergmann, and Roland Vollgraf. 2019. Pooled contextualized embeddings for named entity recognition. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 724–728, Minneapolis, Minnesota. Association for Computational Linguistics.
Rie Ando and Tong Zhang. 2005. A high-performance semi-supervised learning method for text chunking. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 1–9, Ann Arbor, Michigan. Association for Computational Linguistics.
Loïc Barrault, Magdalena Biesialska, Ondˇrej Bojar, Marta R. Costa-jussà, Christian Federmann, Yvette Graham, Roman Grundkiewicz, Barry Haddow, Matthias Huck, Eric Joanis, Tom Kocmi, Philipp Koehn, Chi-kiu Lo, Nikola Ljubešic´, Christof Monz, Makoto Morishita, Masaaki Nagata, Toshiaki Nakazawa, Santanu Pal, Matt Post, and Marcos Zampieri. 2020. Findings of the 2020 conference on machine translation (WMT20). In Proceedings of the Fifth Conference on Machine Translation, pages 1–55, Online. Association for Computational Linguistics.
Yonatan Belinkov and James Glass. 2019. Analysis methods in neural language processing: A survey. Transactions of the Association for Computational Linguistics, 7:49–72.
Iz Beltagy, Kyle Lo, and Arman Cohan. 2019. SciBERT: A pretrained language model for scientiﬁc text. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3615– 3620, Hong Kong, China. Association for Computational Linguistics.
Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013. Semantic parsing on Freebase from question-answer pairs. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1533–1544, Seattle, Washington, USA. Association for Computational Linguistics.
Manik Bhandari, Pranav Narayan Gour, Atabak Ashfaq, Pengfei Liu, and Graham Neubig. 2020. Reevaluating evaluation in text summarization. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 9347–9359, Online. Association for Computational Linguistics.
Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages

632–642, Lisbon, Portugal. Association for Computational Linguistics.
Xinchi Chen, Xipeng Qiu, Chenxi Zhu, Pengfei Liu, and Xuanjing Huang. 2015. Long short-term memory neural networks for Chinese word segmentation. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1197–1206, Lisbon, Portugal. Association for Computational Linguistics.
Zhiyuan Chen, Bing Liu, Meichun Hsu, Malu Castellanos, and Riddhiman Ghosh. 2013. Identifying intention posts in discussion forums. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1041– 1050, Atlanta, Georgia. Association for Computational Linguistics.
Alexis Conneau and Guillaume Lample. 2019. Crosslingual language model pretraining. In Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pages 7057–7067.
Junqi Dai, Hang Yan, Tianxiang Sun, Pengfei Liu, and Xipeng Qiu. 2021. Does syntax matter? a strong baseline for aspect-based sentiment analysis with roberta. In The 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.
Kevin Duh, Katsuhito Sudoh, Xianchao Wu, Hajime Tsukada, and Masaaki Nagata. 2011. Generalized minimum bayes risk system combination. In Proceedings of 5th International Joint Conference on Natural Language Processing, pages 1356–1360.
Bradley Efron. 1992. Bootstrap methods: another look at the jackknife. In Breakthroughs in statistics, pages 569–593. Springer.
Kawin Ethayarajh and Dan Jurafsky. 2020. Utility is in the eye of the user: A critique of NLP leaderboards. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 4846–4853, Online. Association for Computational Linguistics.
Jinlan Fu, Xuanjing Huang, and Pengfei Liu. 2021. Spanner: Named entity re-/recognition as span prediction. In Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP), Virtual.
Jinlan Fu, Pengfei Liu, and Graham Neubig. 2020a. Interpretable multi-dataset evaluation for named entity recognition. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6058–6069, Online. Association for Computational Linguistics.

Jinlan Fu, Pengfei Liu, and Qi Zhang. 2020b. Rethinking generalization of neural models: A named entity recognition case study. In The Thirty-Fourth AAAI Conference on Artiﬁcial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artiﬁcial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artiﬁcial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020, pages 7732–7739. AAAI Press.
Jinlan Fu, Pengfei Liu, Qi Zhang, and Xuanjing Huang. 2020c. RethinkCWS: Is Chinese word segmentation a solved task? In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 5676–5686, Online. Association for Computational Linguistics.
Sebastian Gehrmann, Tosin Adewumi, Karmanya Aggarwal, Pawan Sasanka Ammanamanchi, Aremu Anuoluwapo, Antoine Bosselut, Khyathi Raghavi Chandu, Miruna Clinciu, Dipanjan Das, Kaustubh D Dhole, et al. 2021. The gem benchmark: Natural language generation, its evaluation and metrics. arXiv preprint arXiv:2102.01672.
Jesús González-Rubio, Alfons Juan, and Francisco Casacuberta. 2011. Minimum Bayes-risk system combination. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 1268–1277, Portland, Oregon, USA. Association for Computational Linguistics.
Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. 2017. On calibration of modern neural networks. In Proceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017, volume 70 of Proceedings of Machine Learning Research, pages 1321–1330. PMLR.
Junjie Hu, Sebastian Ruder, Aditya Siddhant, Graham Neubig, Orhan Firat, and Melvin Johnson. 2020. Xtreme: A massively multilingual multitask benchmark for evaluating cross-lingual generalisation. In International Conference on Machine Learning, pages 4411–4421. PMLR.
Daniel Khashabi, Gabriel Stanovsky, Jonathan Bragg, Nicholas Lourie, Jungo Kasai, Yejin Choi, Noah A Smith, and Daniel S Weld. 2021. Genie: A leaderboard for human-in-the-loop evaluation of text generation. arXiv preprint arXiv:2101.06561.
Yaobo Liang, Nan Duan, Yeyun Gong, Ning Wu, Fenfei Guo, Weizhen Qi, Ming Gong, Linjun Shou, Daxin Jiang, Guihong Cao, et al. 2020. Xglue: A new benchmark dataset for cross-lingual pretraining, understanding and generation. arXiv preprint arXiv:2004.01401.
Zachary C Lipton. 2018. The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery. Queue, 16(3):31–57.

Yang Liu and Mirella Lapata. 2019. Text summarization with pretrained encoders. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3730–3740, Hong Kong, China. Association for Computational Linguistics.
Yixin Liu and Pengfei Liu. 2021. Simcls: A simple framework for contrastive learning of abstractive summarization. In Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACLIJCNLP), Virtual.
Yixin Liu, Dou Ziyi, and Pengfei Liu. 2021. Refsum: Refactoring neural summarization. In The 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.
Jiasen Lu, Jianwei Yang, Dhruv Batra, and Devi Parikh. 2016. Hierarchical question-image co-attention for visual question answering. In Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain, pages 289–297.
Graham Neubig, Zi-Yi Dou, Junjie Hu, Paul Michel, Danish Pruthi, and Xinyi Wang. 2019. compare-mt: A tool for holistic comparison of language generation systems. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations), pages 35–41, Minneapolis, Minnesota. Association for Computational Linguistics.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? sentiment classiﬁcation using machine learning techniques. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing (EMNLP 2002), pages 79–86. Association for Computational Linguistics.
Nikolaos Pappas and Andrei Popescu-Belis. 2014. Explaining the stars: Weighted multiple-instance learning for aspect-based sentiment analysis. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 455–466, Doha, Qatar. Association for Computational Linguistics.
Maja Popovic´ and Hermann Ney. 2011. Towards automatic error analysis of machine translation output. Computational Linguistics, 37(4):657–688.
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. SQuAD: 100,000+ questions for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2383–2392, Austin, Texas. Association for Computational Linguistics.

Alexander M. Rush, Sumit Chopra, and Jason Weston. 2015. A neural attention model for abstractive sentence summarization. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 379–389, Lisbon, Portugal. Association for Computational Linguistics.
Stefan Schweter and Alan Akbik. 2020. Flert: Document-level features for named entity recognition. arXiv preprint arXiv:2011.06993.
Sara Stymne. 2011. Blast: A tool for error analysis of machine translation output. In Proceedings of the ACL-HLT 2011 System Demonstrations, pages 56–61, Portland, Oregon. Association for Computational Linguistics.
Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. 2014. Sequence to sequence learning with neural networks. In Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems 2014, December 8-13 2014, Montreal, Quebec, Canada, pages 3104–3112.
Ian Tenney, James Wexler, Jasmijn Bastings, Tolga Bolukbasi, Andy Coenen, Sebastian Gehrmann, Ellen Jiang, Mahima Pushkarna, Carey Radebaugh, Emily Reif, et al. 2020. The language interpretability tool: Extensible, interactive visualizations and analysis for nlp models. arXiv preprint arXiv:2008.05122.
Kai Ming Ting and Ian H. Witten. 1997. Stacked generalizations: When does it work? In Proceedings of the Fifteenth International Joint Conference on Artiﬁcial Intelligence, IJCAI 97, Nagoya, Japan, August 23-29, 1997, 2 Volumes, pages 866–873. Morgan Kaufmann.
Erik F. Tjong Kim Sang and Fien De Meulder. 2003. Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition. In Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003, pages 142–147.
Kristina Toutanova, Dan Klein, Christopher D. Manning, and Yoram Singer. 2003. Feature-rich part-ofspeech tagging with a cyclic dependency network. In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, pages 252–259.
Eric Wallace, Jens Tuyls, Junlin Wang, Sanjay Subramanian, Matt Gardner, and Sameer Singh. 2019. AllenNLP interpret: A framework for explaining predictions of NLP models. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations, pages 7–12, Hong Kong, China. Association for Computational Linguistics.

Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R Bowman. 2019. Superglue: A stickier benchmark for general-purpose language understanding systems. arXiv preprint arXiv:1905.00537.
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. 2018. GLUE: A multi-task benchmark and analysis platform for natural language understanding. In Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 353–355, Brussels, Belgium. Association for Computational Linguistics.
Sida Wang and Christopher Manning. 2012. Baselines and bigrams: Simple, good sentiment and topic classiﬁcation. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 90–94, Jeju Island, Korea. Association for Computational Linguistics.
Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Łukasz Kaiser, Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian, Nishant Patil, Wei Wang, Cliff Young, Jason Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals, Greg Corrado, Macduff Hughes, and Jeffrey Dean. 2016. Google’s neural machine translation system: Bridging the gap between human and machine translation. CoRR, abs/1609.08144.
Ikuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki Takeda, and Yuji Matsumoto. 2020. LUKE: Deep contextualized entity representations with entityaware self-attention. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6442–6454, Online. Association for Computational Linguistics.
Zihuiwen Ye, Pengfei Liu, Jinlan Fu, and Graham Neubig. 2021. Towards more ﬁne-grained and reliable NLP performance prediction. In Conference of the European Chapter of the Association for Computational Linguistics (EACL), Online.
Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, Zilin Zhang, and Dragomir Radev. 2018. Spider: A largescale human-labeled dataset for complex and crossdomain semantic parsing and text-to-SQL task. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3911–3921, Brussels, Belgium. Association for Computational Linguistics.
Weizhe Yuan, Graham Neubig, and Pengfei Liu. 2021. Bartscore: Evaluating generated text as text generation. arXiv preprint arXiv:2106.11520.

Ming Zhong, Danqing Wang, Pengfei Liu, Xipeng Qiu, and Xuanjing Huang. 2019. A closer look at data bias in neural extractive summarization models. In Proceedings of the 2nd Workshop on New Frontiers in Summarization, pages 80–89, Hong Kong, China. Association for Computational Linguistics.

