arXiv:2006.00707v1 [econ.EM] 1 Jun 2020

Inﬂuence via Ethos: On the Persuasive Power of Reputation in Deliberation Online
Emaad Manzoor, George H. Chen, Dokyun Lee, Michael D. Smith
{emaad, georgechen, dokyun, mds}@cmu.edu Carnegie Mellon University
Abstract
Deliberation among individuals online plays a key role in shaping the opinions that drive votes, purchases, donations and other critical ofﬂine behavior. Yet, the determinants of opinion-change via persuasion in deliberation online remain largely unexplored. Our research examines the persuasive power of ethos – an individual’s “reputation” – using a 7-year panel of over a million debates from an argumentation platform containing explicit indicators of successful persuasion. We identify the causal effect of reputation on persuasion by constructing an instrument for reputation from a measure of past debate competition, and by controlling for unstructured argument text using neural models of language in the double machine-learning framework. We ﬁnd that an individual’s reputation signiﬁcantly impacts their persuasion rate above and beyond the validity, strength and presentation of their arguments. In our setting, we ﬁnd that having 10 additional reputation points causes a 31% increase in the probability of successful persuasion over the platform average. We also ﬁnd that the impact of reputation is moderated by characteristics of the argument content, in a manner consistent with a theoretical model that attributes the persuasive power of reputation to heuristic information-processing under cognitive overload. We discuss managerial implications for platforms that facilitate deliberative decision-making for public and private organizations online.
Keywords: Persuasion, reputation systems, double machine-learning, causal inference from text
Preliminary draft, comments are welcome.

1 Introduction
Deliberation — “an extended conversation among two or more people in order to come to a better understanding of some issue” (Nick Beauchamp, 2020) – forms the grease of societal decision-making machinery, lubricating consensus among participants via fair and informed debate. The process of opinion exchange in deliberation alleviates polarization, minority under-representation and several other drawbacks of consensus formation arising from non-deliberative processes (such as in majorityvoting without discussion) by educating potentially uninformed participants and broadening their awareness of alternative perspectives (List et al., 2013; Thompson, 2008).
An increasing amount of deliberation takes place online (Davies and Gangadharan, 2009), both on social media and on specialized platforms developed for participatory democracy1, knowledge curation2 and software planning3, among others. While going virtual broadens participation, the increased visibility of “reputation” indicators online could distort the equitability of the deliberation process. For example, (Marlow et al., 2013) ﬁnd that project managers on Github (used for open-source software development by Google, Facebook and Microsoft, among several other technology ﬁrms) use visible reputation indicators when evaluating users’ feature requests and critiquing developers’ code contributions. At the same time, this creates opportunities for ﬁrms to exploit reputation indicators when directly interacting with consumers online to promote sales and mitigate churn (as gaming giant Electronic Arts does on Reddit, for example). These opportunities also extend to philanthropic organizations engaged in curbing the spread of misinformation online.
Whether reputation indeed has persuasive power in online deliberation is thus an important concern, but one that is difﬁcult to quantify due to the difﬁculty of recognizing opinion-change and persuasion even on the rare occasions when it does occur. We overcome this challenge by assembling a dataset of deliberation from the ChangeMyView4 online argumentation platform, containing over a million debates spanning 7 years from 2013 to 2019. Strict curation by a team of over 20 moderators ensures that debates on ChangeMyView are well-informed, balanced and civil, thus satisfying the key tenets of authentic deliberation (Fishkin and Luskin, 2005). The debates in our dataset cover a variety of topics, from politics and religion to comparisons of products and brands, reﬂecting the diverse interests of over 800,000 ChangeMyView users. ChangeMyView users initiate debates by sharing opinions, engage in dyadic deliberation with other users that challenge their opinion, and (uniquely) provide explicit indicators of successful persuasion for each challenger that persuaded them to change their opinion. For every user persuaded, challengers earn reputation points that are prominently displayed with their username on the platform. The screenshot in Figure 1 illustrates the deliberation process and the nature of reputation indicators on ChangeMyView.
1For example, see the Stanford Online Deliberation Platform: https://stanforddeliberate.org/ 2For example, see Wikipedia Talk pages used to discuss Wikipedia edits: https://en.wikipedia.org/wiki/Help:Talk_pages 3For example, see Github Issues used to plan open-source projects: https://guides.github.com/features/issues/ 4http://reddit.com/r/changemyview/
1

Poster

Challenger

Reputation

Indicator of successful persuasion
Figure 1: A debate. An opinion shared by poster togtogtog (left), a response by challenger miguelguajiro (topright) and a reply by togtogtog indicating successful persuasion with the ∆ symbol (bottom-right). Displayed above miguelguajiro’s response is their reputation (110∆), which is the number ∆s earned previously.
We use this dataset to analyze whether an individual’s reputation impacts their persuasiveness in deliberation online, beyond the content of their arguments. Our identiﬁcation strategy to answer this question draws on four key components, enabled by several unique characteristics of our dataset:
I. Within-opinion variation: We exploit the availability of multiple challengers of each opinion to analyze within-opinion variation (via opinion ﬁxed-effects). This controls for unobserved characteristics of the opinion (such as the topic) and the poster (such as their agreeability) that may introduce biases arising from users endogenously selecting which opinions to challenge.
II. Approximating persuasive ability: We exploit the availability of multiple persuasion attempts for each user over time to measure and control for their past (lagged) persuasion rate, as a proxy for their unobserved persuasive ability (or skill) in each debate.
III. Instrumenting for reputation: We derive an instrument for the reputation of the challenger in each debate to address potential confounding due to unobserved challenger characteristics that vary over time, and are hence not controlled for by their past persuasion rate.
IV. Controlling for the response text: Each challenger’s response text is the primary medium through which their persuasive ability, linguistic ﬂuency and other major determinants of persuasion are observed by the poster. By controlling for the response text nonparametrically, we control for and address potential confounding arising from all such determinants.
2

We instrument for the challenger’s reputation in each debate with their average position in the sequence of responses to opinions they challenged previously (their mean past position). For a given opinion, challengers responding earlier (at lower positions) exhaust the limited space of good arguments, making it harder for challengers responding later (at higher positions) to persuade the poster5. Hence, we expect challengers with higher (worse) mean past positions to have lower reputations in the present, motivating our instrument’s relevance. While users can strategically select opinions to challenge that have fewer earlier challengers, our instrument remains exogenous after controlling for the user’s present position in each debate. To further alleviate concerns of instrument validity, we derive conservative bounds on our estimates with relaxed instrument validity assumptions using the plausibly-exogenous instrumental variable framework (Conley et al., 2012).
Text plays a key role in ensuring instrument validity. All confounders of the instrument must affect both the instrument and the debate outcome (whether the poster was persuaded). To affect the debate outcome, such confounders must operate through channels observable by the poster, the most prominent of which is the text of the challenger’s response. Hence, “controlling for” the challenger’s response text blocks the causal pathways between such confounders and the debate outcome, ensuring that they do not violate instrument validity.
To operationalize this intuition in an ideal world, we would manually annotate, measure and control for every possible characteristic of the response text that could affect the debate outcome, which is infeasible at scale. An alternative is to control for a bag-of-words6 (Harris, 1954) vector of the response text, assuming that functions of this vector capture all text characteristics that determine the debate outcome. However, the high dimensionality of bag-of-words representations introduces statistical difﬁculties that prevent consistent estimation and valid inference.
Dimensionality-reduction techniques are commonly employed to alleviate these difﬁculties, whether manually via hand-selected features, or automatically via inverse-regression (Taddy, 2013), topic-modeling (Blei et al., 2003; Roberts, Stewart, and Airoldi, 2016; Roberts, Stewart, and Nielsen, 2018) and neural text embeddings (Mikolov et al., 2013). However, these techniques provide no guarantees that the confounders present in the original text are retained in the low-dimensional text representation, which raises concerns of omitted variable bias. In addition, there is often little substantive theory to guide the manual feature selection process. Automated dimensionality reduction techniques, including supervised ones such as feature selection via LASSO (Tibshirani, 1996), could result in inconsistent estimates due to model misspeciﬁcation and invalid conﬁdence intervals due to feature selection uncertainty that is not accounted for in the inference procedure (Belloni et al., 2014).
5This resembles the mechanism of the cable news channel position instrument used to quantify the persuasive power of Fox News on voting Republican (Martin and Yurukoglu, 2017).
6A bag-of-words representation of a document is a high-dimensional vector of the frequencies of all the words it contains. Its dimensionality is the size of the vocabulary of words in the document corpus, which is typically of the order of millions.
3

We depart from the focus on dimensionality-reduction and instead incorporate the response text as a control nonparametrically, using recent advances in semiparametric inference with machine learning models. Speciﬁcally, we estimate “nuisance functions” of the response text via machine learning to predict the debate outcome, challenger reputation and instrument, and partial-out their effects in the manner of Frisch-Waugh-Lovell (Frisch and Waugh, 1933; Lovell, 1963). This procedure was introduced as early as (Robinson, 1988) for parametric nuisance functions and recently extended to nonparametric nuisance functions estimated via machine learning (Chernozhukov et al., 2018; Van der Laan and Robins, 2003). The recent extensions show that the partialling-out procedure guarantees √
n-consistent and asymptotically normal estimates, as long as each estimated nuisance function converges to the true nuisance function at the rate of n−1/4 or better.
In particular, we use a recent econometric extension of the partialling-out procedure called double machine-learning (Chernozhukov et al., 2018) to estimate a partially-linear instrumental variable speciﬁcation with text as a control. For our nuisance functions, we use neural networks with rectiﬁed linear unit (ReLU) activation functions (Nair and Hinton, 2010). These neural networks pass the input text through a series of intermediate layers, each of which learns a latent “representation” that captures textual semantics at different granularities. The networks are trained via backpropogation (Rumelhart et al., 1986) with ﬁrst-order gradient-based techniques (Kingma and Ba, 2015) to minimize classiﬁcation or regressions loss functions. Though recurrent (Hochreiter and Schmidhuber, 1997) and convolutional (Kim, 2014) neural networks are more commonly used for textual prediction tasks, neural networks with ReLU activation functions come with guaranteed n−1/4 convergence rates (Farrell et al., 2018) that enable consistent estimation and valid inference in the double machine-learning framework.
Results. We ﬁnd a signiﬁcant positive effect of reputation on persuasion. Our instrumental variable estimates indicate that having 10 additional units of reputation increases the probability of persuading a poster by 1.09 percentage points. This corresponds to a 31% increase over the platform average persuasion rate of 3.5%. Since each poster successfully persuaded increases a challenger’s reputation, the long-run effect of reputation on persuasion is compounded over time. The effect remains statistically signiﬁcant across a range of speciﬁcations, including ones where the instrument exclusion restriction is relaxed. Our ﬁndings counter the prevailing notion on the ChangeMyView platform that the persuasive power of reputation can be ignored.
The estimated effect of reputation on persuasion is the local average treatment effect (LATE) (Imbens and Angrist, 1994) in the population of compliers, comprised of debates where the challenger’s reputation (the treatment) is affected by their mean past position (the instrument). Such challengers are less persuasive at higher (later, worse) response positions and more persuasive at lower (earlier, better) response positions. Hence, we expect debates in the complier population to involve challengers with moderate to high persuasive ability, since challengers with low persuasive ability are unlikely to be any more persuasive at any response position.
4

To investigate possible mechanisms for this effect, we test the predictions of a theoretical model of persuasion with information-processing shortcuts called reference cues (Bilancini and Boncinelli, 2018). We examine how the proportional effects of a challenger’s reputation and skill vary with characteristics of the opinion and response content. Using the challenger’s response text length as a proxy for the cognitive complexity of their arguments, we ﬁnd that the reputation effect share (of the total effect magnitude of reputation and skill) increases from 82% to 89% from the ﬁrst to the fourth response length quantile. This suggests that posters rely more on reputation when the challenger’s arguments are cognitively complex. This is consistent with the theoretical prediction that individuals will rely more on low-effort heuristic processing (using reputation as a proxy for the quality of the challenger’s response) instead of high-effort systematic processing (directly evaluating the challenger’s response) when subject to greater cognitive overload.
The theoretical model also predicts that individuals will rely less on low-effort heuristic processing when they are more involved in the issue being debated. We test this prediction using the opinion text length as a proxy for the issue-involvement of the poster and ﬁnd that the reputation effect share decreases from 90% to 83% from the second to the fourth opinion length quantile. This is consistent with the prediction that more issue-involved posters will rely less on reputation. We ﬁnd similar patterns using text complexity measures (such as the Flesch-Kincaid Reading Ease) as proxies for cognitive complexity and issue-involvement, instead of the response and opinion text length. Overall, our ﬁndings are consistent with reputation serving as a reference cue and used by posters as an information-processing shortcut under cognitive overload.
We also examine how the effect of reputation on persuasion is moderated by the total number of opinion challengers. While we expect that having more challengers will increase the cognitive burden placed on the poster (and hence push them to rely more on heuristic information-processing), we ﬁnd no evidence that posters rely more on reputation as the number of opinion challengers increases. We do ﬁnd evidence that challengers with higher reputation have longer conversations with posters, which could be an important mediator of the effect of reputation on persuasion. We also ﬁnd evidence that challengers with higher reputation are more likely to attract collaboration from other (non-poster) users, although reputation continues to have a signiﬁcant (positive) direct effect on persuasion after excluding the potential effect of such collaboration.
Contributions and related work. Our research contributes to the economics of persuasion, the practitioners of which comprise over a quarter of the United States’ GDP (McCloskey and Klamer, 1995), including lawyers, judges, lobbyists, religious workers and salespeople. (Antioch et al., 2013) revises this number to 30 percent, after including marketing, advertising and political campaigning professionals. An extensive body of past work on persuasion spans the economics, marketing and political science literature (among others), and is comprised of both theoretical models (Kamenica, 2018; Kamenica and Gentzkow, 2011) and empirical analyses of the efﬁcacy of persuasive communication via ﬁeld or natural experiments (see DellaVigna and Gentzkow, 2010 for a survey).
5

Our work differs from previous empirical studies on the economics of persuasion in three ways. First, previous work focused on identifying the existence of persuasion by quantifying the causal effect of persuasive communication on some observable behavior, without the ability to observe individual-level opinion-change. Content and persuader-based moderators of persuasion were then analyzed conditional on non-zero persuasive effects having been identiﬁed (Bertrand et al., 2010; Landry et al., 2006). In our work, the explicit indicators of persuasion provided by posters allows us to sidestep the task of identifying persuasion, and directly analyze its determinants. Second, we observe attempts at persuasion made by thousands of unique individuals, in contrast with previous work. This enables a broader investigation of the impact of persuader and content characteristics, which are predicted to play an important role by belief-based persuasion models (Kamenica and Gentzkow, 2011; Mullainathan et al., 2008; Stigler, 1961). Finally, we observe repeated attempts at persuasion made by each individual that enables approximating and disentangling the impact of their persuasive ability from other factors.
More speciﬁcally, our work informs persuasive information design (Kamenica, 2018) in interactive settings by quantifying the impact of extraneous signals that could serve as low-effort informationprocessing heuristics (Chaiken, 1989; Petty and Cacioppo, 1986; Todorov et al., 2002). Such heuristics play an increasingly important role in this era of information overload (Jones et al., 2004), as emphasized by Cialdini in his seminal book on the principles of inﬂuence (Cialdini, 2007):
"Finally, each principle is examined as to its ability to produce a distinct kind of automatic, mindless compliance from people, that is, a willingness to say yes without thinking ﬁrst. The evidence suggests that the ever-accelerating pace and informational crush of modern life will make this particular form of unthinking compliance more and more prevalent in the future. It will be increasingly important for the society, therefore, to understand the how and why of automatic inﬂuence."
Interactive persuasion channels are common today, with ﬁrms adopting online channels such as live-chat to triangulate consumers’ beliefs and inﬂuence them via dialogue. Interactive channels are often preferred for defensive marketing tasks (Hauser and Shugan, 1983) such as addressing complaints and mitigating churn. Some ﬁrms invest in interaction further and embed themselves as bonaﬁde members of inﬂuential enthusiast-run online forums7. Marketing communication designed to persuade in such channels closely resembles the dyadic deliberation we examine in our work.
Our work is also related to research on the impact of certiﬁcation and reputation systems (Dranove and Jin, 2010) in markets for labor (Kokkodis and Ipeirotis, 2016; Moreno and Terwiesch, 2014), knowledge (Dev et al., 2019), and other goods and services (Hui et al., 2016; Lu and Rui, 2018; Tadelis, 2016). Consumers studied in this line of research engage in costly information-processing to evaluate
7A notable examples is gaming giant Electronic Arts (https://www.reddit.com/user/EACommunityTeam/).
6

item quality under cognitive, temporal or ﬁnancial constraints. Hence, the ﬁndings therein are interpreted using the same underlying psychological mechanisms as we employ in our work (Chaiken, 1989; Petty and Cacioppo, 1986). The distinguishing feature of our work is the focus on explicitly stated opinion-change as the outcome, as a consequence of interpersonal deliberation. Importantly, there are no monetary transactions involved and the reputation in our setting cannot be purchased at any cost; it is a truthful proxy for past persuasive ability. Thus, persuasion as exhibited in our setting is sufﬁciently different from the purchasing or hiring decisions analyzed in the literature on certiﬁcation and reputation systems to warrant separate investigation.
Our work complements studies on deliberation in online settings, such as on political forums and social media (Nick Beauchamp, 2020; Shugars and Nicholas Beauchamp, 2019). Speciﬁcally, our ﬁndings contribute to the understanding of opinion-change and polarization8 online (Quattrociocchi et al., 2016). By quantifying how an individual’s reliance on heuristic and systematic informationprocessing varies with the cognitive complexity of the persuasive message content, our ﬁndings could inform online campaigns that involve persuasive information design aimed at reducing polarization by affecting opinion-change.
Finally, our work contributes an application to the nascent study of causal inference from text, and more broadly to the literature on text as data (Gentzkow et al., 2019; Netzer et al., 2019; Toubia et al., 2019). Our setting involves text as a control (see Keith et al., 2020 for a recent survey of work in this setting). Previous approaches to accommodate text as a control (though with treatments assumed to be exogenous) include (Sridhar and Getoor, 2019) which controls for topics in the text, (Roberts, Stewart, and Nielsen, 2018) which assumes a structural topic model (Roberts, Stewart, and Airoldi, 2016) of text and controls for its sufﬁcient reduction (Taddy, 2013), and (C. Shi et al., 2019; Veitch et al., 2019) which incorporate neural language models of text in the targeted learning inference framework (Van der Laan and Rose, 2011).
Our work also links the social science literature on persuasion with the computational natural language processing literature on argument-mining (Lippi and Torroni, 2016), where online argumentation platforms have been extensively studied (Atkinson et al., 2019; Jo et al., 2018; Luu et al., 2019; Srinivasan et al., 2019; Tan et al., 2016).
Outline. We begin in Section 2 by introducing background, formalizing our conceptual framework and motivating our hypotheses. We then describe our dataset in Section 3 and detail our empirical strategy in Section 4, including a description of our estimation procedure and evidence supporting the validity of our instrument. We discuss our results in Section 5 and interpret them through the lens of a theoretical model of persuasion. We conclude by summarizing our ﬁndings, discussing managerial implications for platforms facilitating online deliberation for public and private organizations, and noting the limitations of our research in Section 6.
8https://www.wsj.com/articles/to-get-along-better-we-need-better-arguments-1531411024
7

2 Background and Conceptual Framework
The ChangeMyView online argumentation platform was created in January, 2013 to foster good-faith discussions on polarizing issues and has received praise for helping combat the proliferation of echo chambers online9. In this section, we formalize the process of deliberation on ChangeMyView and describe important platform features to motivate our empirical analyses in Section 4.
Opinion posters, opinion challengers and debates. Our unit of analysis is a debate. Each debate is associated with an opinion shared by an opinion poster, which is titled with the poster’s primary claim and contains at least 500 characters of supporting arguments. A response to the opinion by a challenger initiates a debate between the poster and challenger. Other users can (but rarely) join the ongoing discussion between a poster and a challenger with their own comments; we term such debates multi-party. Debates must follow several rules (detailed in Appendix A) enforced by over 20 moderators. Notable rules are: (i) the poster must personally hold a non-neutral opinion, (ii) the poster must engage with all challengers for at least 3 hours after sharing their opinion, and (iii) a challenger’s response must counter at least one claim made by the poster. Responses to an opinion are ordered chronologically and popularity votes on responses are hidden for the ﬁrst 24 hours after an opinion is shared. These rules mitigate popularity biases, irrelevant digressions and hostility.
Opinion selection by users. The titles of posted opinions and the identities of the posters who shared them are displayed in a paginated list on the platform’s homepage, ordered by a combination of recency and popularity votes10. A tab on the homepage also allows users to order opinions by recency only. Clicking on an opinion title opens a new page displaying the opinion text and any ongoing or concluded debates between the poster and other challengers. Users could select opinions to challenge based on various factors such as the opinion text, their own topical preferences, the poster’s identity, and the number and status of the debates between the poster and other challengers.
The ∆-system. In mid-February, 2013, ChangeMyView introduced a reputation system called the ∆-system to incentivize challenging opinions on the platform. At any point in a debate, the poster may reply to the challenger indicating that their opinion has changed using the ∆ symbol or equivalent alternatives. We term debates where the poster awarded a ∆ to the challenger as successful and opinions that led to at least one successful debate as conceded. Due to the platform rules requiring active engagement, 98% of the ∆s from the poster in our dataset were awarded within 24 hours of the opinion being posted, with over 50% being awarded within just 90 minutes. This short delay reduces concerns of opinion-change occurring due channels external to the debate. Each awarded ∆ grants the challenger a reputation point. Other non-poster users can (but rarely) also award ∆s to any challenger and contribute to their reputation. The total reputation points earned previously, if non-zero, are displayed next to the challenger’s username with all of their responses on the platform.
9“Civil discourse exists in this small corner of the internet” — The Atlantic. December 30, 2018. 10Speciﬁcally, in decreasing order of the score: sign(upvotes − downvotes)log10|upvotes − downvotes| + post-datetime/45000.
8

The poster’s decision. Consider an opinion p that is challenged by user u. The poster observes u’s username, reputation rpu and the text of their immediate response to the opinion. Based on this information, the poster may initiate a discussion with the challenger, elicit additional responses (which we do not model) and eventually award a ∆ if persuaded to change their opinion. We model the poster p’s decision to award a ∆ to challenger u as a function of an opinion-speciﬁc threshold τp and the perceived quality q˜pu of u’s response:

Ypu = I[q˜pu > τp] q˜pu = αrrpu + αqqpu

I[x] = 1 if x is true , I[x] = 0 otherwise

αr + αq = 1

(1)

Here, Ypu = 1 is the observed debate outcome if the poster awarded a ∆ to u and Ypu = 0 otherwise. The unobserved threshold τp encodes opinion-speciﬁc characteristics such as the opinion topic and the poster’s openness to persuasion. Based on (Bilancini and Boncinelli, 2018; Dewatripont and Tirole, 2005), we model the perceived quality q˜pu as a weighted linear combination of the challenger’s reputation rpu and the “true” response quality qpu, which the poster can determine by evaluating the challenger’s response at some cognitive cost. Posters choose αr and αq endogenously based on this cognitive cost and their reliance on heuristic and systematic information-processing (Chaiken, 1989; Petty and Cacioppo, 1986). If αr > 0, reputation in this model serves as a reference cue: a proxy for the true response quality that can be processed with lesser effort than evaluating qpu directly.
“True” response quality. We model the true response quality qpu as a function of the user’s “skill” spu at the time they challenged opinion p and their position tpu in the sequence of challengers of opinion p. tpu captures the overall impact of previous challengers’ responses. For example, challengers responding earlier could exhaust the limited space of good arguments, making it harder for later challengers to respond with arguments of similar quality. We formalize this as follows:

tpu =

I[u challenged opinion p before u]

u

qpu = γsspu + γttpu

(2)

We approximate u’s skill by the Laplace-smoothed (Manning et al., 2008) fraction of posters persuaded before opinion p, where p is chronologically-ordered and Sp u = 1 if u challenged opinion p :
spu = p <p Yp uSp u + 2sµ (3) p <p Sp u + 2
Here, sµ is a “prior” set to the empirical persuasion probability of users in their ﬁrst debate (≈ 1.6%). Smoothing ensures that the skill of users measured when they have challenged few opinions tends to sµ instead of to 0. A user’s skill is thus their (smoothed) lagged persuasion rate, which captures all user characteristics that affect persuasion and do not change with the their tenure on the platform.

9

Hypotheses. Based on prior analytical work (Bilancini and Boncinelli, 2018), we test three complementary hypotheses on the weights αr and αq, which reﬂect the poster’s endogenously-determined reliance on heuristic and systematic information-processing respectively:
H1. Reputation has persuasive power, αr > 0.
H2. The relative persuasive power of reputation, αrα+rαq , increases as the cognitive cost of processing the challenger’s response increases.
H3. The relative persuasive power of reputation, αrα+rαq , decreases as the involvement of the poster in the debated issue increases.
Conﬁrming (H1) indicates that reputation has persuasive power, and conﬁrming (H2) and (H3) lends support to the mechanism proposed by the model of (Bilancini and Boncinelli, 2018).

3 Data
We collect all the discussions on the ChangeMyView platform between January, 2013 and October, 2019 using a combination of the ofﬁcial Reddit API11 and the third-party PushShift API (Baumgartner et al., 2020), in full compliance with their terms of service. We exclude submissions to ChangeMyView that are not opinions using the fact that opinion titles are required to be preﬁxed with “CMV:”. The excluded submissions encompass discussions about the platform, announcements of platform changes and celebrations of milestones. We also exclude the opinions and responses posted to ChangeMyView before the reputation system became fully functional on March 1, 2013.
We extract indicators of successful persuasion from the debate text using the same extraction rules employed by ChangeMyView to programmatically parse ∆s and other alternative symbols12. We use the extracted indicators to label debate success, to reconstruct each challenger’s reputation and to measure each challenger’s skill in each debate. Figure 2 shows the empirical variation in skill with reputation in our dataset, with each point indicating the reputation and skill for each challenger measured in a single debate, colored based on the number of debates they participated in previously. At values of skill outside the low and high extremes, there is a wide variation in the reputation (r = 0.29, p < 0.001). This variation is essential to disentangle the effects of reputation and skill on persuasion.

11https://www.reddit.com/dev/api/ 12Code obtained from: https://github.com/alexames/DeltaBot
10

Figure 2: Reputation and skill

Debates by challengers who had deleted their ChangeMyView accounts before data collection appear in our dataset with the “[deleted]” placeholder username. The inability to link the debates by such challengers over time makes it impossible to measure their true reputation and skill. Assuming that such challengers have zero reputation and skill sµ (based on equation 3) is likely to attenuate our estimates due to measurement error. Hence, we exclude all 118,277 such debates from our dataset13. Our ﬁnal dataset contains 91,730 opinions (23.5% of them conceded) shared by 60,573 unique posters, which led to 1,026,201 debates (3.5% of them successful) with 143,891 unique challengers. Table 1 reports descriptive statistics of our dataset, and Figure 3 reports user-level distributions of participation and debate success. Table 2 summarizes the notation that will use in all subsequent sections.

Statistics of challengers in each debate Reputation rpu Skill spu (%) Position tpu Mean past position Zpu Number of past debates p <p Sp u
Statistics of overall dataset Number of opinions
Opinions conceded Opinions leading to more than 1 debate Number of debates Successful debates Multi-party debates Number of debates per opinion Successful debates per opinion Number of unique posters Opinions per poster Number of unique challengers Challengers with more than 1 debate Number of debates per challenger Successful debates per challenger

Mean
15.9 3.0 14.8 10.4 244.4
91,730 21,576 84,998 1,026,201 36,187 348,041
11.2 0.4 60,573 1.5 143,891 64,871 7.1 0.3

Standard Deviation
43.4 3.7 24.3 13.0 591.7

Median
1.0 1.6 8.0 7.5 24.00

(number of clusters with opinion ﬁxed-effects)

12.7

9

0.9

0

2.4

1

(number of clusters with user ﬁxed-effects)

58.5

1

3.2

0

Table 1: Descriptive Statistics. Debates from March 1, 2013 to October 10, 2019.

Number of users Number of users

105

105

104

104

103

103 102

102

101

0 100 200 300 400 500 600 700 800 900 6000
Number of debates

0 50 100 150 200 250 300 350
Number of successful debates

Figure 3: Debate participation and success. Distribution of total and successful debates per user.

13For completeness, we also report our main results including debates with deleted challengers in Appendix C.

11

Symbol
p u pu τp ρu rpu spu tpu mpu Xpu Ypu Spu Zpu

Chronological opinion index Chronological response index Tuple representing a debate: the uth response to opinion p Opinion ﬁxed-effect; captures unobserved opinion characteristics Challenger ﬁxed-effect; captures unobserved challenger characteristics Reputation of the challenger in debate pu; sum of the past ∆s earned Skill of the challenger in debate pu; smoothed lagged persuasion rate Position of the challenger in debate pu Calendar month-year ﬁxed-effect for debate pu Vector representation of the text of the challenger’s immediate response in debate pu Binary outcome of debate pu; Ypu = 1 for successful debates, Ypu = 0 otherwise Binary opinion selection indicator; Spu = 1 if u challenged opinion p, Spu = 0 otherwise Instrument (mean past position) for the challenger’s reputation in debate pu

Table 2: Summary of notation. List of recurring symbols introduced in Sections 2 and 4.

4 Empirical Strategy
4.1 Baseline Speciﬁcations
Equations (1) and (2) motivate baseline speciﬁcations that relate the observed debate outcome Ypu to the challenger’s reputation rpu, skill spu and position tpu as follows (constants omitted for brevity):

Yp∗u = τp + β1rpu + β2spu + β3tpu + pu Ypu = I[Yp∗u > 0]

E[ pu|τp, rpu, spu, tpu] = 0

Here, τp is an opinion ﬁxed-effect and pu is an error term with zero conditional mean. Since the ﬁxed-effects are at the opinion level and skill (a function of lagged dependent variables) is at the user level, these are not dynamic panel speciﬁcations, and are hence unaffected by Nickell bias (Nickell, 1981). Including the opinion ﬁxed-effects excludes 6,732 debates from the sample, which were the only responses to their respective opinions. If distributional assumptions (such as Gumbel or Gaussian) on pu hold and there are no unobserved confounders, the estimate of β1 quantiﬁes the change in the probability of persuading the poster of opinion p upon increasing the challenger’s reputation by one unit, with all else equal. In Section 5, we report estimates from logistic and linear probability models.

While the assumption of no unobserved confounding is restrictive (and relaxed in Section 4.2), the baseline speciﬁcations address two important sources of confounding. First, controlling for the challenger’s skill controls for all challenger characteristics that affect persuasion (such as their rhetorical ability and linguistic ﬂuency) and that do not vary with their tenure on ChangeMyView. To see why such characteristics confound the effect of reputation on persuasion, note that a user’s reputation largely depends on the number of posters persuaded previously: rpu ≈ p <p Yp u (since users who are not posters rarely award ∆s). Hence, any unobserved challenger characteristic that affects the outcome of every debate Ypu, Y(p−1)u, Y(p−2)u, . . . will also affect their reputation rpu ≈ Y(p−1)u + Y(p−2)u + . . . , and thus confound the effect of reputation rpu on the debate outcome Ypu.

12

No. of opinions challenged previously
Position tpu (std. deviations) User ﬁxed-effects (ρu) Month-year ﬁxed-effects (mpu) No. of debates R2

p <p Sp u

Dependent Variable: Debate Success Ypu
−1 × 10−6 (0.7 × 10−6) −0.0107 (0.0003)∗∗∗   947, 181 0.07

Note: Standard errors displayed in parentheses. ∗∗∗p < 0.001;∗∗ p < 0.01;∗ p < 0.05

Table 3: Estimated effect of past experience on debate success.

However, skill does not capture challenger characteristics that vary with their tenure on ChangeMyView. By assuming the absence of such characteristics, the baseline speciﬁcations implicitly assume that users do not learn to be more persuasive with experience on the platform. We provide empirical evidence to support this assumption by estimating the following linear probability model:
Ypu = ρu + mpu + θ1 Sp u + θ2tpu + pu
p <p
where ρu is a user ﬁxed-effect capturing all unobserved time-invariant user characteristics, mpu is a calendar month-year ﬁxed-effect capturing unobserved temporal factors, tpu is the (standardized) user’s position in the sequence of challengers of opinion p and pu is a Gaussian error term. p <p Sp u is the number of opinions that u challenged previously, serving as a measure of their past experience. θ1 is the within-user correlation between past experience and the debate outcome. If users improve with experience, we expect θ1 to be positive. However, the estimates of θ1 reported in Table 3 are small and statistically insigniﬁcant. We attribute this to users having already acquired argumentation experience outside the platform, with little to gain from additional experience on the platform.
Second, controlling for the opinion ﬁxed-effect τp addresses confounding due to users endogenously selecting which opinions to challenge. To see why opinion selection is a concern, recall the opinion selection indicator Spu that equals 1 when user u challenges opinion p. Since we estimate our speciﬁcations on observed debates, our speciﬁcations implicitly condition on Spu = 1. If the opinion selection probability P[Spu = 1] is correlated with (i) reputation, and (ii) debate success (for example, if users prefer to challenge opinions on topics that are easier to persuade in), the effect of reputation on debate success will be confounded due to endogenous sample selection (Heckman, 1979).
We characterize this confounding using the causal graph in Figure 4 based on the analyses in (Hernán et al., 2004). In causal graphs (Pearl, 2009), an edge A → B implies that A may or may not cause B, while the absence of an edge implies the stronger assumption that A does not cause B. An undirected edge ↔ implies potential causality in either direction. Observed variables are shaded and unobserved variables are unshaded.

13

rpu

Ypu

Dependent Variable: I[u challenges > 1 future opinion]

Reputation rpu (10 units)

0.0177 (0.0001)∗∗∗

User ﬁxed-effects (ρu)



Month-year ﬁxed-effects (mpu)



No. of debates

947, 181

R2

0.56

Spu

Up

Note: Standard errors displayed in parentheses.

∗∗∗p < 0.001;∗∗ p < 0.01;∗ p < 0.05

Figure 4: Opinion selection causal graph.

Table 4: Reputation/opinion selection correlation.

The shaded nodes rpu, Ypu and Spu correspond to the reputation, debate outcome and opinion selection indicator respectively. The unshaded node Up is any unobserved opinion characteristic that could directly affect both opinion selection and debate success, such as the opinion topic.

In the causal graph in Figure 4, Spu is a collider. A collider is any node C that is a common outcome in causal substructures of the form X → C ← Y . Conditioning on C opens a causal pathway between X and Y that would otherwise be blocked. If reputation is correlated with opinion selection (depicted by the undirected edge rpu ↔ Spu), conditioning on the collider Spu (which our speciﬁcations do implicitly) opens the confounding causal pathway Up → Spu ↔ rpu. This confounds the effect of reputation on the debate outcome, since Up now affects both Ypu and rpu (via Spu).

We test for correlation between rpu and Spu by estimating the following linear probability model of a user challenging more than one opinion after opinion p:

I[u challenges > 1 future opinion] = ρu + mpu + θ1rpu + pu

where ρu is a user ﬁxed-effect, mpu is a calendar month-year ﬁxed-effect and pu is a Gaussian error term. The estimate of θ1 in Table 4 suggests a signiﬁcant positive correlation between rpu and Spu. This correlation may arise either because users that were successful in the past (and hence have higher reputation) are more likely to challenge opinions in the future, or because more active users are likely to have higher reputation (a mechanical relationship). Fortunately, the opinion ﬁxed-effect τp controls for all opinion characteristics, including the unobserved Up, thus addressing potential confounding.
In summary, our baseline speciﬁcations address potential confounding due to (i) time-invariant challenger characteristics that affect persuasion, and (ii) users endogenously selecting which opinions to challenge. In the next section, we introduce speciﬁcations that instrument for the challenger’s reputation in each debate. The instrumental variable speciﬁcations inherit the robustness of the baseline speciﬁcations to confounding from time-invariant challenger characteristics and endogenous opinion selection, while further addressing potential confounding due to time-varying challenger characteristics that affect debate success.

14

4.2 Instrumental Variable Speciﬁcations

Our instrumental variable speciﬁcations address confounding due to unobserved user characteristics that affect persuasion and vary with their experience on the platform. Estimates from this speciﬁcation quantify the local average treatment effect (LATE) of reputation on debate success if instrument relevance, exogeneity, exclusion and monotonicity hold (Imbens and Angrist, 1994). In this section, we derive our instrument and provide empirical evidence to support its validity.
Our instrument is motivated by the fact that a user’s reputation largely depends on the number of posters persuaded previously, since other users who are not the poster rarely award ∆s:

rpu ≈ Yp u
p <p
From equation (2), we also know that a user’s position tpu in the sequence of challengers of opinion p is correlated with debate success Ypu. Hence, we deﬁne our instrument Zpu for the challenger’s reputation rpu as the mean past position of user u before challenging opinion p:
Zpu = p <p tp uSp u (4) p <p Sp u
where p is a chronologically-ordered opinion index, and the opinion selection indicator Sp u = 1 if user u challenged opinion p and Sp u = 0 otherwise. We expect users who were consistently late challengers of opinions in the past (and thus, have larger mean past positions) to have persuaded fewer posters on average than users who were consistently early, and hence have lower reputation in the present. Thus, we expect Zpu to be negatively correlated with rpu.
We conﬁrm this relationship with the following ﬁrst-stage regression:

rpu = τp + a1Zpu + a2spu + a3tpu + pu

(5)

where τp is an opinion ﬁxed-effect, spu is user u’s skill, tpu is user u’s position in the sequence of challengers of opinion p and pu is a zero-mean Gaussian error term.
Our ﬁrst-stage estimates in Table 5 indicate that a one unit increase in the mean past position of a user predicts a 0.18 unit decrease in their present reputation. The F-statistic on the instrument greatly exceeds the rule-of-thumb threshold (Stock and Yogo, 2005), alleviating concerns about instrument strength. Skill has a positive ﬁrst-stage correlation with reputation, which is expected since higher skilled users are likely to have persuaded more posters previously. The response position has a negative ﬁrst-stage correlation with reputation, which we expect if users are consistent in their preference to respond early or late.

15

Mean past position Zpu Skill spu (percentage) Position tpu (std. deviations) Opinion ﬁxed-effects (τp) Instrument F-Statistic No. of debates R2

Dependent Variable: Reputation rpu
−0.1833 (0.003)∗∗∗ 2.3055 (0.012)∗∗∗
−1.7354 (0.067)∗∗∗ 
3, 338.7 1, 019, 469
0.22

Note: Standard errors displayed in parentheses. ∗∗∗p < 0.001;∗∗ p < 0.01;∗ p < 0.05

Table 5: First-stage estimates. Mean past position as an instrument for reputation.

An immediate concern is users selecting opinions to challenge based on their anticipated position in the sequence of challengers, since users can observe the number of ongoing and concluded debates with the poster before deciding to challenge an opinion. We characterize this scenario using the causal graph in Figure 5, which extends the causal graph in Figure 4 with shaded nodes Zpu (for the instrument) and tpu (for the challenger’s present position). tpu affects the debate outcome Ypu, based on equation (2). Recall from Section 4.1 that our speciﬁcations implicitly condition on the collider Spu = 1. If the instrument is correlated with opinion selection (depicted by the undirected edge Zpu ↔ Spu) and users select opinions to challenge based on their anticipated position (depicted by the edge tpu → Spu), conditioning on Spu will open the confounding causal pathway tpu → Spu ↔ Zpu. Hence, it is essential to control for the challenger’s present position tpu, which could otherwise confound the instrument.
The causal graph in Figure 5 reveals a second source of instrument confounding that has received recent attention (Hughes et al., 2019; Swanson, 2019). If the instrument is correlated with opinion selection (depicted by the undirected edge Zpu ↔ Spu) and some unobserved opinion characteristic Up (such as the opinion topic) affects both opinion selection and debate success, conditioning on Spu opens the confounding causal pathway Up → Spu ↔ Zpu that violates instrument exogeneity.
We can test for correlation between the instrument and opinion selection by estimating the following linear probability model of a user challenging more than one opinion after opinion p, where ρu is a user ﬁxed-effect, mpu is a calendar month-year ﬁxed-effect and pu is a Gaussian error term:
I[u challenges > 1 future opinion] = ρu + mpu + θ1Zpu + θ2rpu + pu
The estimates of θ1 in Table 6 suggest a small but signiﬁcant negative correlation between Zpu and Spu, justifying our concerns of endogenous opinion selection violating instrument exogeneity. Fortunately (as discussed Section 4.1), the opinion ﬁxed-effect τp controls for all opinion characteristics, including unobserved Up. This alleviates concerns of instrument exogeneity being violated due to endogenous opinion selection.

16

Zpu

rpu

Y

Dependent Variable: I[u challenges > 1 future opinion]

pu

Mean past position Zpu

−0.0040 (0.00003)∗∗∗

Reputation rpu (10 units)

0.0166 (0.00012)∗∗∗

User ﬁxed-effects (ρu)



Spu

Up

Month-year ﬁxed-effects (mpu)



No. of debates

947, 181

R2

0.57

tpu

Note: Standard errors displayed in parentheses.

∗∗∗p < 0.001;∗∗ p < 0.01;∗ p < 0.05

Figure 5: Instrument confounding via opinion selection. Table 6: Instrument/opinion selection correlation.

Another plausible concern is of the instrument affecting the debate outcome via channels that do not include the user’s reputation, which violates the instrument exclusion restriction. For example, if users learn to be more persuasive from the earlier challengers of an opinion, a user with a high mean past position could be more persuasive in the present than one with a low mean past position.

We address this concern in two ways. First, note that any user
characteristic correlated with successful persuasion is likely to affect the Zpu
debate outcome through the text of their responses. Hence, controlling for the response text will block direct channels of inﬂuence between the instrument and the debate outcome. This is formalized by the causal graph on the right. Here, the reputation rpu, debate outcome Ypu, response text Xpu and instrument Zpu are observed. V contains all unobserved confounders of the instrument or reputation (or both) that affect the outcome through the text Xpu. If we decompose the text into
conceptual components a, b, c and d, it is sufﬁcient to control for a to rpu
block the Zpu ↔ V → a → Ypu causal pathway.

Xpu

d

c

V

b

a

Ypu

We operationalize this idea by estimating the following partially-linear instrumental variable speciﬁcation with endogenous rpu, as formulated by (Chernozhukov et al., 2018):

Ypu = β1rpu + β2spu + β3tpu + g(τp, Xpu) + pu Zpu = α1spu + α2tpu + h(τp, Xpu) + pu

E[ pu|Zpu, τp, spu, tpu, Xpu] = 0 E[ pu|τp, spu, tpu, Xpu] = 0

In this speciﬁcation, the high-dimensional covariates τp (the opinion ﬁxed-effects) and Xpu (a vector representation of u’s response text) have been moved into the arguments of the “nuisance functions” g(·) and h(·). As earlier, rpu is u’s reputation, spu is u’s skill, tpu is u’s position and Zpu (the instrument) is the mean past position of u before opinion p. pu and pu are error terms with zero conditional mean. β1 is the parameter of interest, quantifying the causal effect of reputation on persuasion.

17

No distributional assumptions are placed on pu and pu, and hence, this speciﬁcation does not assume any functional form (in contrast with logit, probit and linear probability models). g(·) and h(·) can be ﬂexible nonparametric functions. We discuss estimation and inference in Section 4.3.
Second, we use the “plausibly exogenous” instrumental variable framework (Conley et al., 2012) to relax the instrument exclusion restriction and include Zpu directly in the debate outcome model14:

Ypu = τp + β1rpu + β2spu + β3tpu + γZpu + pu Zpu = τp + α1spu + α2tpu + pu

E[ pu|Zpu, τp, spu, tpu] = 0 E[ pu|τp, spu, tpu] = 0

where γ = 0 encodes by how much the exclusion restriction is violated. For a ﬁxed γ and conditionally exogenous instrument, the effect of reputation on debate success can be quantiﬁed via two-stage least-squares estimation of the following regression, using Zpu as an instrument for rpu:

(Ypu − γZpu) = τp + β1rpu + β2spu + β3tpu + pu

If users indeed learn to be more persuasive from earlier challengers, we would expect γ > 0. We report estimates of β1 from the speciﬁcation above for a range of γ values in Section 5.
While instrument relevance, exogeneity and exclusion are sufﬁcient to guarantee identiﬁcation of the effect of reputation on debate success, we also require instrument monotonicity to interpret our estimate as a local average treatment effect (LATE) (Imbens and Angrist, 1994). Instrument monotonicity will be violated if there exists a subpopulation of debates where increasing the mean past position of the challenger would increase their present reputation, and decreasing their mean past position would decrease their present reputation (members of this subpopulation are called deﬁers). Such challengers are more likely to persuade a poster when they respond later. The large and preciselyestimated negative within-user correlation between the number of earlier challengers and debate success (θˆ2 = −0.0107 ± 0.0003) in Table 3 suggests that the existence of such challengers is unlikely.
The LATE is the effect of reputation on debate success for compliers, comprised of debates where the challenger’s reputation is indeed affected by their mean past position. The challengers in these debate subpopulations are more persuasive at earlier (lower) positions, and less persuasive at later (higher) positions. Hence, we expect that the compliers exclude debates with challengers having low persuasive ability, who are unlikely to be more or less persuasive in any position. We also expect challengers with moderate to high persuasive ability to beneﬁt more from an increase in their reputation than challengers with low persuasive ability, since a high reputation is unlikely to substitute for low persuasive ability. Hence, we expect the LATE to be larger than the average treatment effect of reputation on debate success.
14(Conley et al., 2012) proposes four inference strategies that incorporate plausibly exogenous instruments. The inference strategy we use relies on the fewest assumptions and provides the most conservative estimates of β1.

18

4.3 Estimation and Inference

Our baseline linear probability model and linear instrumental variable speciﬁcations can be estimated using ordinary least-squares and two-stage least squares respectively, adapted to accommodate highdimensional ﬁxed-effects (Correia, 2016). In this section, we describe how the double machine-learning framework (Chernozhukov et al., 2018) can be used to consistently estimate the effects of reputation, skill and position in the partially-linear instrumental variable speciﬁcation.
Double machine-learning extends the partialling-out procedure of Frisch-Waugh-Lovell (Frisch and Waugh, 1933; Lovell, 1963) to use ﬂexible nonparametric functions estimated via machine learning. We ﬁrst describe the basic setup assuming reputation is conditionally exogenous (given the response text), ignoring the opinion ﬁxed-effects, and ignoring the effects of skill and position. Consider the following partially-linear probability model:

Ypu = βrpu + g(Xpu) + pu rpu = h(Xpu) + pu

E[ pu|rpu, Xpu] = 0 E[ pu|Xpu] = 0

where Ypu is the debate outcome, rpu is the challenger’s reputation, Xpu is their response text and pu and pu are Gaussian error terms with zero conditional mean. g(·) and h(·) are unknown nonparametric functions. We are interested in consistently estimating and performing valid inference on β.
If g(·) and h(·) were ﬁxed and known, consistent estimation is possible by solving for β in an empirical version of the following moment condition (equivalent to ordinary least-squares estimation):

E[(Ypu − g(Xpu) − βrpu)rpu] = 0

However, g(·) is unknown and needs to be jointly estimated with β. A solution is to ﬁrst estimate g(·) on a separate subsample S of the data, and then estimate β by solving an empirical version of the moment condition above on the remaining subsample S. This procedure, called sample-splitting, eliminates the “overﬁtting-bias” introduced in the process of estimating g(·).

If g(·) is estimated via machine learning, the procedure above results in inconsistent estimates βˆ. (Chernozhukov et al., 2018) decomposes the scaled bias of βˆ into the following two terms:

√n(βˆ − β) = ( 1 n

rp2u)−1 √1n

1 rpu pu + ( n

rp2u)−1 √1n

rpu(g(Xpu) − gˆ(Xpu))

(p,u)∈S

(p,u)∈S

(p,u)∈S

(p,u)∈S

Term a

Term b

Term a converges at a n−1/2 rate to a zero-mean Gaussian. However, by virtue of g(·) being estimated via machine learning, term b will typically converge to zero at a rate slower than n−1/2 due to the slow convergence of the estimation error g(Xpu) − gˆ(Xpu). This is called the “regularization bias” of gˆ(·).

19

Double machine-learning eliminates regularization bias via a procedure called orthogonalization. β is estimated by solving an empirical version of the following “Neyman-orthogonal” moment condition:

E[((Ypu − E[Ypu|Xpu]) − β(rpu − E[rpu|Xpu]))(rpu − E[rpu|Xpu])] = 0

The empirical version of this moment condition can be solved via a procedure similar to the residualon-residuals regression of (Robinson, 1988). The procedure is as follows (where S and S are disjoint subsamples of the data, and m(·) and l(·) are nonparametric functions):
1. Estimate the conditional expectation function l(Xpu) = E[Ypu|Xpu] on S to get ˆl(·).

2. Estimate the conditional expectation function m(Xpu) = E[rpu|Xpu] on S to get mˆ (·). 3. Estimate the outcome residual Y˜pu = Ypu − ˆl(Xpu) on S.

4. Estimate the treatment residual r˜pu = rpu − mˆ (Xpu) on S. 5. Regress Y˜pu on r˜pu to obtain βˆ.

Note that we no longer need to estimate g(·), and instead need to estimate the conditional expectations l(·) and m(·) that can be arbitrary nonparametric functions of Xpu (such as neural networks). This procedure can be extended to include skill and position as controls by estimating additional conditional expectation functions to predict the challenger’s skill and position from their response text on S , estimating the residuals s˜pu and t˜pu on S, and then regressing Y˜pu on r˜pu, s˜pu and t˜pu.

The

resulting

estimate

βˆ

is

√ n-consistent

and

asymptotically

normal.

(Chernozhukov

et

al.,

2018)

shows that term b of the scaled bias of βˆ is now given by following expression:

( n1 Vp2u)−1 √1n (m(Xpu) − mˆ (Xpu)) (l(Xpu) − ˆl(Xpu))

(p,u)∈S

(p,u)∈S mˆ (·)estimation error

ˆl(·)estimation error

This contains the product of nuisance function estimation errors. Hence, orthogonalization enables

√ n-consistent

estimation

of

βˆ

as

long

as

the

product

of

the

convergence

rates

of

mˆ (·)

and

ˆl(·)

is

n−1/2.

This is more viable than requiring each nuisance function to converge at a n−1/2 rate.

If rpu is endogenous and Zpu is a valid instrument for rpu, (Chernozhukov et al., 2018) proposes the following Neyman-orthogonal moment condition to estimate β in a partially-linear instrumental variable speciﬁcation:

E[((Ypu − E[Ypu|Xpu]) − β(rpu − E[rpu|Xpu]))(Zpu − E[Zpu|Xpu])] = 0

(6)

By

a

similar

bias

derivation,

the

estimated

βˆ

is

shown

to

be

√ n-consistent

and

asymptotically

normal,

as long as the instrument is valid and the product of the nuisance function convergence rates is n−1/2.

20

We now detail our overall estimation procedure for the partially-linear instrumental variable speciﬁcation. We include the opinion ﬁxed-effect τp, skill spu and position tpu as controls. S and S are disjoint subsamples of the data, and mr(·), ms(·), mt(·), mp(·), l(·) and q(·) are nonparametric functions that we detail in the next subsection. The procedure is as follows:

1. Estimate the following conditional expectation functions on sample S :

i. l(Xpu, τp) = E[Ypu|Xpu, τp] to get ˆl(·). ii. q(Xpu, τp) = E[Zpu|Xpu, τp] to get qˆ(·).

iii. mr(Xpu, τp) = E[rpu|Xpu, τp] to get mˆ r(·). iv. ms(Xpu, τp) = E[spu|Xpu, τp] to get mˆ s(·). v. mt(Xpu, τp) = E[tpu|Xpu, τp] to get mˆ t(·).

2. Estimate the following residuals on sample S:
i. Y˜pu = Ypu − ˆl(Xpu, τp). ii. Z˜pu = Zpu − qˆ(Xpu, τp).

iii. r˜pu = rpu − mˆ r(Xpu, τp). iv. s˜pu = spu − mˆ s(Xpu, τp). v. t˜pu = tpu − mˆ t(Xpu, τp).

3. Run a two-stage least-squares regression of Y˜pu on r˜pu, s˜pu, t˜pu using Z˜pu as an instrument for r˜pu to obtain the estimated local average treatment effects of reputation, skill and position on debate success.
We partition the debates for opinions with more than one response (mirroring the data used in the speciﬁcations with opinion ﬁxed-effects) uniformly at random into an estimation subsample S containing 10% of the debates (101,946 debates) and an inference subsample S containing 90% of the debates (917,523 debates), ensuring that every opinion is represented in both S and S . In the next section, we describe how we use neural networks with rectiﬁed linear unit (ReLU) activation functions for the nonparametric functions mr(·), ms(·), mt(·), mp(·), l(·) and q(·), which have been shown to converge at n−1/4 rates (Farrell et al., 2018) that enables consistent estimation and valid inference.

4.4 Neural Models of Text as Nuisance Functions

A fully-connected neural network with h hidden layers is parameterized by matrices W 1, . . . , W h+1 and activation functions (called activations) a1, . . . , ah+1. The hidden layer sizes s1, . . . , sh are architectural hyperparameters that determine the sizes of the matrices W 1, . . . , W h+1 as follows, where D and O are the dimensionalities of the neural network input and output, respectively:
Size of W 1 = D × s1 Size of W i = si−1 × si for i = 2, . . . , h Size of W h+1 = sh × O

21

[Xpu, τp] ∈ ℝ1×D

R1 ∈ ℝ1×s1

W1 ∈ ℝD×s1 a1( ⋅ )

W2 ∈ ℝs1×1 a2( ⋅ )

Input

Hidden Layer

Output Layer

rp̂ u ∈ ℤ+ sp̂ u ∈ [0,100] tp̂ u ∈ ℝ Zp̂ u ∈ ℝ+ Yp̂ u ∈ {0,1}
Predicted Output

Figure 6: A neural network with one hidden layer (h = 1). The neural network transforms the D-dimensional input, a concatenation of the response text vector Xpu and the ﬁxed-effects indicator vector for τp, into a 1-dimensional output. W 1 and W 2 are parameters to be estimated. a1(·) and a2(·) are activation functions.

Each layer i multiplies the intermediate vector Ri−1 produced by the previous layer with W i, and applies the activation function ai(·) to produce Ri = ai(Ri−1W i). Figure 6 illustrates a neural network with one hidden layer (h = 1), input dimensionality D and output dimensionality O = 1. The neural network transforms the input, a concatenation of the response text vector Xpu and the ﬁxed-effects indicator vector for τp, into the 1-dimensional predicted output a2(a1([Xpu, τp] × W 1) × W 2).
We estimate ﬁve neural networks with rectiﬁed linear unit (ReLU) activations to predict (i) debate success Ypu ∈ {0, 1}, (ii) reputation rpu ∈ Z+, (iii) skill spu ∈ [0, 100] (as a percentage), (iv) position tpu ∈ R (standardized to have zero-mean and unit-variance) and (v) the instrument Zpu ∈ R+ from the response text Xpu and opinion ﬁxed-effects τp. Though recurrent (Hochreiter and Schmidhuber, 1997) and convolutional (Kim, 2014) neural networks are more popular for textual prediction tasks, ReLU neural networks have guaranteed n−1/4 convergence rates (Farrell et al., 2018) that we require for consistent estimation and valid inference. Hence, we set each of the hidden layer activations a1(·), . . . , ah(·) to the rectiﬁer function ai(x) = max(0, x). Since the output of each neural network is one-dimensional, we set the size of the output layer matrix W h+1 to sh × 1.
Output layer activations and loss functions. For the debate success prediction network with the binary target Ypu ∈ {0, 1}, we set the output layer activation to the logistic sigmoid function: ah+1(x) = (1 + e−x)−1 ∈ [0, 1]. For the skill prediction network with the bounded target spu ∈ [0, 100], we set the output layer activation to the scaled logistic sigmoid function: ah+1(x) = (1 + e−x)−1 × 100 ∈ [0, 100]. For the reputation and instrument prediction networks with nonnegative targets rpu ∈ Z+ and Zpu ∈ R+, we set the output layer activation to the rectiﬁer function: ah+1(x) = max(0, x). For the position prediction network with unbounded target tpu ∈ R, we set the output layer activation to the identity function: ah+1(x) = x. We estimate the parameters W 1, . . . , W h+1 for the debate success prediction network by minimizing the binary cross-entropy loss Ypulog(Yˆpu) + (1 − Ypu)log(1 − Yˆpu) (where Yˆpu is the predicted output), and for the other networks by minimizing the mean squared error.

22

Neural network input. We follow recommendations from the text-as-data literature (Gentzkow et al., 2019) and construct a term-frequency inverse-document-frequency (TF-IDF) matrix from the text of the challengers’ responses. We preprocess the text to remove links, numbers, pronouns, punctuation and text formatting symbols, and replace each word with its lower-cased stem (for example, “economically” and “economics” will be replaced by the stem “economic”). We exclude very rare words (present in less than 0.1% of the responses) and very frequent words (present in more than 99.9% of the responses), since these words will contribute negligibly towards more accurate predictions. The ﬁnal vocabulary contains 4,926 distinct words. Each row of the TF-IDF matrix corresponds to a vector Xpu ∈ R4926. We also construct an indicator vector τp ∈ {0, 1}84998 (since there are 84,998 unique opinion clusters), where only the pth element of τp is set to 1 and the rest are set to zero. The concatenation of these two vectors, [Xpu, τp] ∈ R89924, is passed as input to the neural networks.
Optimization. We train each network via backpropagation (Rumelhart et al., 1986) with the Adam gradient-based optimization algorithm (Kingma and Ba, 2015) iterating over mini-batches of the training data. We begin the optimization process by initializing the parameters using the Kaiming uniform initialization scheme (He et al., 2015), which has been shown to perform well both empirically and theoretically (Hanin and Rolnick, 2018). We perform batch-normalization (Ioffe and Szegedy, 2015) on each layer’s output after applying the activation function to prevent internal covariate shift and accelerate convergence. To prevent overﬁtting to the training data, we apply weight-decay (a form of L2-norm penalization) (Krogh and Hertz, 1992) to all the parameters, along with earlystopping (halting the training process once the out-of-sample predictive power starts decreasing with training iterations). We do not employ dropout regularization (Srivastava et al., 2014), since it reduces out-of-sample predictive power when combined with batch-normalization (Li et al., 2019).
Architectural and optimization hyperparameters. The number of hidden layers h, hidden layer sizes s1, . . . , sh, weight-decay penalty, optimization learning rate and mini-batch size are architectural and optimization hyperparameters that need to be tuned empirically. Hence, we further partition the debates in the estimation subsample S uniformly at random into a training subsample Strain containing 75% of the debates (76,459 debates) and a validation subsample Sval containing 25% of the debates (25,487 debates). During the hyperparameter tuning process, we train the neural network on Strain and evaluate its loss at each training iteration on both Strain and Sval.
We ﬁx the size of the hidden layers s1, . . . , sh to the dimensionality of the response text vector Xpu (=4,926) and tune the number of hidden layers for each neural network. Deep, ﬁxed-width ReLU networks of this type have been shown to generalize well both empirically and theoretically (Hanin, 2019; Safran and Shamir, 2017). For each neural network, we evaluate the training loss (for at most 5,000 mini-batch iterations with early-stopping) with an increasing number of hidden layers, until the training loss no longer improves. Each neural network with the number of hidden layers thus found has enough representational capacity to capture patterns in the training data, but is likely to have overﬁt the training data and suffer from poor out-of-sample predictive power.
23

Prediction target
Debate success Ypu ∈ {0, 1} Reputation rpu ∈ Z+ Skill spu ∈ [0, 100] (percentage) Position tpu ∈ R (standardized) Instrument Zpu ∈ R+

Number of Hidden layers
5 3 3 3 5

Activation Functions

Hidden Layer Output Layer

ReLU

Sigmoid

ReLU

Rectiﬁer

ReLU

Sigmoid

ReLU

Identity

ReLU

Rectiﬁer

Loss Function Binary Cross-Entropy Mean squared error Mean squared error Mean squared error Mean squared error

Table 7: Architectural hyperparameters. The input layer matrix W 1 of each neural network has size 89,924 × 4,926, where 89,924 is the dimensionality of the input vector (the vocabulary size + the number of unique opinion clusters) and 4,926 is the dimensionality of Xpu (the vocabulary size). Each of the h hidden layer matrices W 2, . . . W h has size 4,926 × 4,926, and the output layer matrix W h+1 has size 4,926 × 1.

Prediction target
Debate success Ypu ∈ {0, 1} Reputation rpu ∈ Z+ Skill spu ∈ [0, 100] (percentage) Position tpu ∈ R (standardized) Instrument Zpu ∈ R+

Learning Rate 0.0001 0.0001 0.0001 0.0001 0.0001

Batch Size 50,000 50,000 50,000 50,000 50,000

Weight-Decay 10000 10 10 10 10000

Subsample Loss

Train Validation Inference

0.148 0.155

0.152

39.801 40.406 39.842

3.672 3.764

3.707

0.658 0.789

0.796

12.389 13.370 13.217

Table 8: Optimization hyperparameters. The subsample losses on Strain, Sval and S are reported after training each neural network with the selected hyperparameters for at most 5,000 mini-batch iterations (with early-
stopping) on Strain. The binary cross-entropy subsample loss is reported for the network predicting Ypu and the root mean squared prediction error is reported for the other networks.

Hence, after having selected the number of hidden layers for each neural network via the aforementioned procedure, we evaluate the validation loss of each neural network (for at most 5,000 mini-batch iterations with early-stopping) with an increasingly large weight-decay penalty (in the logarithmicallyspaced range 0.001, 0.01, 0.1, . . . ), until the validation loss no longer improves. The ﬁnal neural network thus found will have sufﬁcient representational capacity and be sufﬁciently regularized to generalize well out-of-sample. During the process of tuning the number of hidden layers and the weight-decay penalty, we also empirically evaluate and select the values of the learning rate and mini-batch size that deliver the minimum validation loss with fast and stable convergence.
Table 7 summarizes the selected architectural hyperparameters. Table 8 summarizes the selected optimization hyperparameters and the losses on each data subsample, which reﬂect the extent to which each target is correlated with potential confounders present in response text. After ﬁxing the selected hyperparameters, we re-estimate the neural networks with on the full estimation subsample S , estimate the prediction residuals on the inference sample S and run a two-stage least-squares regression with these residuals, as described in the double machine-learning procedure in Section 4.3.

24

5 Results

Reputation rpu (10 units)
Skill spu (percentage)
Position tpu (std. deviations)
Response text (Xpu) Instrument (Zpu) Opinion ﬁxed-effects (τp) No. of debates R2

(1) 0.0006∗∗∗ (0.00003) 0.0024∗∗∗ (0.00004) −0.0479∗∗∗ (0.00265)
   1, 026, 201 0.051

Dependent Variable: Debate Success Ypu

(2)

(3)

(4)

0.0010∗∗∗ (0.00006)

0.0014∗∗∗ (0.00006)

0.0109∗∗∗ (0.00059)

0.0040∗∗∗ (0.00007)

0.0035∗∗∗ (0.00007)

0.0012∗∗∗ (0.00016)

−0.0093∗∗∗ (0.00078)

−0.0097∗∗∗ (0.00087)

−0.0078∗∗∗ (0.00075)

   1, 026, 201

   1, 019, 469

   1, 019, 469

0.012

0.203

—

(5) 0.0091∗∗∗ (0.00079) 0.0016∗∗∗ (0.00024) −0.0088∗∗∗ (0.00077)
   1, 019, 469 —

Note: Standard errors (clustered by opinion) displayed in parentheses. ∗∗∗p < 0.001;∗∗ p < 0.01;∗ p < 0.05

Table 9: Main results. Estimated effects of reputation, skill and position on debate success with a logit model without opinion ﬁxed-effects (1), linear probability models without (2) and with (3) opinion ﬁxed-effects, linear instrumental variable (4) and partially-linear instrumental variable (5) speciﬁcations. Position is standardized to have zero-mean and unit-variance. Average marginal effects and pseudo-R2 are reported for the logit model. The instrument Zpu is the mean past position of user u before they challenged opinion p.

Table 9 reports the estimated (marginal) effects of reputation, skill and position on debate success. We exclude opinion ﬁxed-effects from the logit model to prevent dropping debates for opinions where none of the challengers persuaded the poster, which is required to estimate conditional logit models (Chamberlain, 1980). For all speciﬁcations, we ﬁnd that the effects are precisely estimated, statistically signiﬁcant and have the expected signs. The estimates from the baseline speciﬁcations in columns (1) — (3) indicate that a challenger having 10 additional units of reputation is 0.06 — 0.14 percentage points more likely to persuade a poster on average, than another challenger of the same opinion with all else equal. This corresponds to a 1.7 — 4.0% increase over the platform average debate success rate of 3.5%. Keeping in mind the difﬁculty of persuasion (the average persuasion rate of a user in our dataset is 0.6%, and the median persuasion rate of a user is 0.0%), this increase is signiﬁcant.

Three additional observations are worth noting. First, we expect the estimated effect of skill to be attenuated due to measurement error in all speciﬁcations. Second, comparing columns (2) and (3), we ﬁnd that including the opinion-ﬁxed effects increases the estimated effect of reputation. This suggests that endogenous opinion selection (discussed in Section 4.1) biases the estimated effect of reputation downwards. Second, the estimated effect of reputation is an average across all challengers, including those with low (and high) persuasive ability who are unlikely to beneﬁt from additional reputation. We expect the impact of reputation to be higher for challengers with moderate persuasive ability.

25

The estimated effects from the baseline speciﬁcations in columns (1) — (3) of Table 9 may be confounded by unobserved time-varying challenger characteristics (discussed in Section 4.2). Hence, we use the challenger’s mean past position as an instrument for their reputation, and report the estimated local average treatment effects (LATEs) of reputation, skill and position on debate success with a linear instrumental variable speciﬁcation in column (4). The estimates indicate that a challenger having 10 additional units of reputation is 1.09 percentage points more likely on average to persuade a poster, than another challenger of the same opinion with all else equal. This corresponds to a 31% increase over the platform average debate success rate of 3.5%. Compared to the linear probability model estimates, the estimated LATE of reputation is 7.8 times larger. We attribute this increase to the compliers (debate subpopulations where the challenger’s reputation is indeed affected by the instrument) having challengers with moderate to high persuasive ability, who beneﬁt more from an increase in their reputation than those with low persuasive ability.
The instrument exclusion restriction will be violated if the mean response position of a challenger in the past has a direct effect on their probability of success in the present debate. This is possible if, for example, users become more persuasive by learning from the earlier responders to the opinions they challenged previously (as discussed in Section 4.2). However, the persuasive ability acquired in this manner is likely to affect debate success through the text of the challenger’s responses. Hence, we alleviate concerns of instrument exclusion being violated by controlling for the response text in a partially-linear instrumental variable speciﬁcation, and report the estimated LATEs in column (5) of Table 9. The estimated LATEs from this speciﬁcation are less precise and differ slightly from the estimates in column (4), but are statistically indistinguishable at the 5% level (using a two-tailed Z-test). This suggests that the instrument exclusion restriction is not violated by factors present in the text.
We supplement these results by reporting LATE estimates using the plausibly-exogenous methodology (Conley et al., 2012), which assumes a known direct effect γ of the instrument on debate success, for a range of γ in Table 10. If users become more persuasive by learning from earlier challengers, we expect γ > 0. Table 10 indicates that the estimated reputation LATE after correcting for exclusion restriction violations of this type is larger, in which case our linear instrumental variable speciﬁcation (without this correction) under-estimates the true LATE. For γ = −0.0002, the estimated LATE of reputation after correcting for the exclusion restriction violation becomes insigniﬁcant. This is expected, since correcting for γ = −0.0002 completely eliminates the “reduced form” effect of the instrument on debate success (reported in Appendix D). Setting the “reduced form” effect of the instrument on the outcome to zero as such necessarily renders the estimated treatment effect insigniﬁcant (Angrist and Krueger, 2001). For γ < −0.0002, the estimated LATE of reputation after correcting for exclusion restriction violations is negative, which is intuitively implausible.
In summary, our main results conﬁrm hypothesis H1 (Section 2): that reputation has persuasive power on the ChangeMyView platform. In the rest of this section, we investigate potential mechanisms that could explain the persuasive power of reputation.
26

Exclusion violation (γ) Reputation rpu (10 units)
Skill spu (percentage)
Position tpu (std. deviations)
Response text (Xpu) Instrument (Zpu) Opinion ﬁxed-effects (τp) No. of debates

−0.0004
−0.0110∗∗∗ (0.0007) 0.0062∗∗∗ (0.0002) −0.0116∗∗∗ (0.0010)
   1, 109, 469

Dependent Variable: Debate Success Ypu

−0.0002 −0.0001 +0.0001 +0.0002

−0.0001 (0.0006)

0.0054∗∗∗ (0.0006)

0.0163∗∗∗ (0.0006)

0.0218∗∗∗ (0.0007)

0.0037∗∗∗ (0.0002)

0.0025∗∗∗ −0.0001 (0.0002) (0.0002)

−0.0013∗∗∗ (0.0002)

−0.0097∗∗∗ −0.0087∗∗∗ −0.0069∗∗∗ −0.0059∗∗∗ (0.0009) (0.0008) (0.0007) (0.0007)

   1, 109, 469

   1, 109, 469

   1, 109, 469

   1, 109, 469

+0.0004
0.0327∗∗∗ (0.0008) −0.0038∗∗∗ (0.0002) −0.0040∗∗∗ (0.0006)
   1, 109, 469

Note: Standard errors (clustered by opinion) displayed in parentheses. ∗∗∗p < 0.001;∗∗ p < 0.01;∗ p < 0.05
Table 10: Results with a plausibly-exogenous instrument. Estimated effects of reputation, skill and position with a linear instrumental variable speciﬁcation and plausibly-exogenous instrument. All speciﬁcations include opinion ﬁxed-effects. Position is standardized to have zero-mean and unit-variance. The instrument Zpu is the mean past position of user u before they challenged opinion p.

Motivated by a theoretical model of persuasion with reference cues (Bilancini and Boncinelli, 2018), we investigate whether reputation serves as a reference cue (an information-processing shortcut) for the challenger’s response quality by examining patterns in the heterogeneity of the effects of reputation and skill with the content of the debate. These patterns reﬂect how the poster’s usage of heuristic and systematic information-processing (Chaiken, 1989) varies with content characteristics that affect information-processing effort. The model predicts that individuals rely more on low-effort heuristic processing than on high-effort systematic processing when subject to greater cognitive overload. In our setting, this translates to posters relying more on a challenger’s reputation than on their skill when the challenger’s response is more cognitively complex (hypothesis H2 in Section 2). The model also predicts that individuals rely less on heuristic processing than on systematic processing when they are more involved in the issue being debated (hypothesis H3 in Section 2).
We test both predictions by examining how the relative estimated effects of reputation and skill on debate success vary with the cognitive complexity of the challenger’s response and with the issue-involvement of the poster. Using the length (in characters) of the challenger’s response text and of the poster’s opinion text as proxies for cognitive complexity and issue-involvement, respectively, Table 11 reports LATE estimates of the effects of reputation and skill interacted with the response and opinion length (binned into quantiles). Note that the speciﬁcations in Table 11 do not include opinion ﬁxed-effects, which would absorb all variation in the opinion length. They include calendar month-year ﬁxed-effects, since unobserved temporal variation is no longer accounted for without the opinion ﬁxed-effects.
27

The estimated LATEs in columns (1) and (2) of Table 11 quantify how the effects of reputation and skill (separately) vary with the response length, which serves as a proxy for the cognitive complexity of the challenger’s response. The effects of both reputation and skill increase with the response length. This is expected since, with longer responses, the content explains more of the debate outcome than other factors. However, the effect of reputation increases more than that of skill from the ﬁrst to the fourth response length quantile: by +0.0133 for reputation compared to +0.0030 for skill. Measuring the share of the effect magnitude of reputation (of the sum of effect magnitudes of reputation and skill) at each response length quantile reveals that the reputation effect share increases from 82% to 89%. This is consistent with the poster’s increased reliance on reputation as a heuristic shortcut and decreased reliance on systematic evaluation of argument quality. This pattern supports hypothesis H2.
The estimates in columns (3) and (4) quantify how the effects of reputation and skill vary with the opinion length, where we assume that longer opinions are correlated with the poster being more involved in the issue being debated. The effect of reputation remains largely the same after the second opinion length quantile, while that of of skill increases signiﬁcantly in each subsequent opinion length quantile. The share of the effect magnitude of reputation (of the sum of effect magnitudes of reputation and skill) decreases from 90% to 83% from the second to the fourth opinion length quantile. This is consistent with the decreased reliance of the poster on reputation as a heuristic shortcut and the increased reliance on systematic evaluation of argument quality as the issue-involvement of the poster increases. This pattern supports hypothesis H3.
Similar trends are observed if reading complexity measures (such as the Flesch-Kincaid Reading Ease) are used to proxy for the cognitive complexity of the challenger’s response and the issueinvolvement of the poster. The negative estimated effects of skill for opinions and responses in the ﬁrst length quantile could be attributed to higher skilled users preferring to write longer responses and to challenge longer opinions. These preferences are a form of endogenous selection on the interaction terms, and will bias our estimates downwards. Since we only examine trends in the estimated effects, and do not interpret their absolute values, these biases are not a major concern.
We now examine if reputation serves as a way for cognitively-overloaded posters to select challengers to engage with. Table 12 reports the LATE estimates of reputation interacted with the total number of challengers of the opinion, binned into quantiles. The speciﬁcation in Table 12 does not include opinion ﬁxed-effects, since they absorb all variation in the number of challengers, but includes calendar month-year ﬁxed-effects and the response and opinion length as controls. We expect that, under the larger cognitive burden of having to respond to more challengers, posters would rely on reputation as a ﬁltering heuristic. However, the estimates in Table 12 indicate a decrease in the effect of reputation as the number of opinion challengers increases, which likely reﬂects the preference of reputed users for challenging opinions with fewer existing challengers. Hence, we ﬁnd no support for the hypothesis that posters use reputation to select challengers to engage with.
28

Moderator Mpu
Reputation rpu (10 units) × I[Mpu ∈ 1st quantile] × I[Mpu ∈ 2nd quantile] × I[Mpu ∈ 3rd quantile] × I[Mpu ∈ 4th quantile]
Skill spu (percentage) × I[Mpu ∈ 1st quantile] × I[Mpu ∈ 2nd quantile] × I[Mpu ∈ 3rd quantile] × I[Mpu ∈ 4th quantile]
Position tpu (std. deviations) Response Length (characters)
I[∈ 1st quantile]

Dependent Variable: Debate Success Ypu

Response Text Length

Opinion Text Length

(1)

(2)

(3)

(4)

0.0038∗∗∗ (0.0006) 0.0066∗∗∗ (0.0006) 0.0088∗∗∗ (0.0006) 0.0171∗∗∗ (0.0010) 0.0005∗∗∗ (0.0002)
−0.0074∗∗∗ (0.0008)

0.0093∗∗∗ (0.0005)
−0.0008∗∗∗ (0.0002) −0.0002 (0.0002) 0.0001 (0.0002) 0.0022∗∗∗ (0.0002) −0.0071∗∗∗ (0.0008)

−0.0007 (0.0006) 0.0114∗∗∗ (0.0007) 0.0117∗∗∗ (0.0007) 0.0126∗∗∗ (0.0008) 0.0009∗∗∗ (0.0001)
−0.0071∗∗∗ (0.0008)

0.0085∗∗∗ (0.0005)
−0.0021∗∗∗ (0.0002) 0.0012∗∗∗ (0.0002) 0.0018∗∗∗ (0.0002) 0.0025∗∗∗ (0.0002) −0.0071∗∗∗ (0.0008)

I[∈ 2nd quantile] I[∈ 3rd quantile] I[∈ 4th quantile] Opinion Length (characters) I[∈ 1st quantile]

0.0035∗∗∗
(0.0009) 0.0080∗∗∗
(0.0010) 0.0218∗∗∗
(0.0013)

0.0046∗∗∗
(0.0005) 0.0119∗∗∗
(0.0006) 0.0306∗∗∗
(0.0007)

0.0072∗∗∗
(0.0004) 0.0157∗∗∗
(0.0005) 0.0395∗∗∗
(0.0006)

0.0060∗∗∗
(0.0004) 0.0143∗∗∗
(0.0005) 0.0396∗∗∗
(0.0006)

I[∈ 2nd quantile]
I[∈ 3rd quantile]
I[∈ 4th quantile]
Response text (Xpu) Instrument (Zpu) Opinion ﬁxed-effects (τp) Month-year ﬁxed-effects No. of debates

0.0257∗∗∗ (0.0008) 0.0284∗∗∗ (0.0008) 0.0309∗∗∗ (0.0008)
   
1, 026, 201

0.0262∗∗∗ (0.0008) 0.0289∗∗∗ (0.0008) 0.0316∗∗∗ (0.0008)
   
1, 026, 201

0.0036∗ (0.0014) 0.0054∗∗∗ (0.0014) 0.0068∗∗∗ (0.0016)
   
1, 026, 201

0.0153∗∗∗ (0.0008) 0.0161∗∗∗ (0.0008) 0.0167∗∗∗ (0.0008)
   
1, 026, 201

Note: Standard errors (clustered by opinion) displayed in parentheses. ∗∗∗p < 0.001;∗∗ p < 0.01;∗ p < 0.05

Table 11: Heterogeneity with response and opinion length. Variation in the estimated LATEs of reputation, skill and position on debate success with response and opinion length (binned into quantiles).

Reputation rpu (10 units) × I[Number of opinion challengers ∈ 1st quantile] × I[Number of opinion challengers ∈ 2nd quantile] × I[Number of opinion challengers ∈ 3rd quantile] × I[Number of opinion challengers ∈ 4th quantile]
Skill spu (percentage)
Position tpu (std. deviations) Number of opinion-challengers
I[∈ 1st quantile]

Dependent Variable: Debate Success Ypu
0.0086∗∗∗ (0.0008) 0.0082∗∗∗ (0.0007) 0.0067∗∗∗ (0.0006) 0.0044∗∗∗ (0.0012)
0.0009∗∗∗ (0.0001)
−0.0055∗∗∗ (0.0008)

I[∈ 2nd quantile] I[∈ 3rd quantile] I[∈ 4th quantile] Response Length (characters) I[∈ 1st quantile]

−0.0101∗∗∗
(0.0021) −0.0178∗∗∗
(0.0019) −0.0144∗∗∗
(0.0022)

I[∈ 2nd quantile] I[∈ 3rd quantile] I[∈ 4th quantile] Opinion Length (characters) I[∈ 1st quantile]

0.0061∗∗∗
(0.0004) 0.0145∗∗∗
(0.0005) 0.0401∗∗∗
(0.0006)

I[∈ 2nd quantile]
I[∈ 3rd quantile]
I[∈ 4th quantile]
Response text (Xpu) Instrument (Zpu) Opinion ﬁxed-effects (τp) Month-year ﬁxed-effects No. of debates

0.0271∗∗∗ (0.0008) 0.0298∗∗∗ (0.0008) 0.0324∗∗∗ (0.0008)




1, 026, 201

Note: Standard errors (clustered by opinion) displayed in parentheses. ∗∗∗p < 0.001;∗∗ p < 0.01;∗ p < 0.05

Table 12: Heterogeneity with the number of opinion challengers. Variation in the estimated LATEs of reputation, skill and position with the number of opinion challengers (binned into quantiles).

Reputation rpu (10 units)
Skill spu (percentage)
Position tpu (std. deviations)
Conditional on debate success Ypu Unsuccessful debates (Ypu = 0) Successful debates (Ypu = 1)
Response text (Xpu) Instrument (Zpu) Opinion ﬁxed-effects (τp) No. of debates

Dependent Variable: Conversation Tree Length

(1)

(2)

(3)

0.8537∗∗∗ (0.025)

0.8499∗∗∗ (0.025)

0.3661∗∗ (0.138)

−0.1123∗∗∗ (0.005)

−0.1184∗∗∗ (0.005)

−0.0273 (0.027)

−1.2354∗∗∗ (0.103)

−1.1888∗∗∗ (0.100)

−2.6737∗∗∗ (0.511)

     1, 109, 469

     982, 867

     23, 157

Note: Standard errors (clustered by opinion) displayed in parentheses. ∗∗∗p < 0.001;∗∗ p < 0.01;∗ p < 0.05

Table 13: Conversation tree length as the outcome. Estimated effects of reputation, skill and position on the conversation tree length with the linear instrumental variable speciﬁcation. All speciﬁcations include opinion ﬁxed-effects. Position is standardized to have zero-mean and unit-variance. The instrument Zpu is the mean past position of user u before they challenged opinion p.

We also examine if having higher reputation leads to longer conversations with the challenger, which could mediate the effect of reputation on debate success. We estimate the effect of reputation on the conversation tree length: the maximum number of turns of dialogue in the conversation tree initiated by the challenger’s response. It equals 1 if no one responds to the challenger, and is greater than 1 otherwise. It is positively (but weakly) correlated with debate success (r = 0.13, p < 0.001).
Table 13 reports the estimated LATEs of reputation, skill and position on the conversation tree length. The estimates in column (1) indicate that having 10 additional units of reputation leads to conversations trees that are 0.85 turns longer on average,with all else equal. Since the poster must use one turn of dialogue when awarding a ∆ to the challenger, this estimate may simply reﬂect the direct effect of reputation on persuading the poster. Hence, columns (2) and (3) report the estimated LATEs separately for unsuccessful and successful debates, and ﬁnd that having 10 additional units of reputation leads to conversations trees that are 0.85 turns longer on average even for unsuccessful debates. Hence, it is plausible that reputation affects debate success via longer conversations.
The estimated LATEs also indicate that an additional percentage point of skill leads to conversation trees that are up to 0.11 turns shorter on average for both unsuccessful and successful debates. This suggests that higher skilled challengers are either quicker to abandon futile conversations, or are able to persuade the poster in fewer turns of dialogue.

31

Dependent Variable
Reputation rpu (10 units)
Skill spu (percentage)
Position tpu (std. deviations)
Only single-party debates Response text (Xpu) Instrument (Zpu) Opinion ﬁxed-effects (τp) No. of debates

I[ Debate pu is multi-party ]
(1) 0.1093∗∗∗ (0.0034) −0.0167∗∗∗ (0.0007) −0.1781∗∗∗ (0.0148)
    1, 109, 468

Debate Success Ypu
(2) 0.0062∗∗∗ (0.0006) 0.0010∗∗∗ (0.0002) −0.0021∗∗∗ (0.0003)
    667, 678

Note: Standard errors (clustered by opinion) displayed in parentheses. ∗∗∗p < 0.001;∗∗ p < 0.01;∗ p < 0.05

Table 14: Single-party vs. multi-party debates. Estimated effects of reputation, skill and position on whether a debate is multi-party in column (1), and on debate success for single-party debates only in column (2), with a linear instrumental variable speciﬁcation. All speciﬁcations include opinion ﬁxed-effects. Position is standardized to have zero-mean and unit-variance. The instrument Zpu is the mean past position of user u before they challenged opinion p.

Finally, we examine the effect of reputation on attracting collaboration from other users. Recall from Section 3 that other (non-poster) users may join an ongoing debate between the challenger and poster; we term such debates multi-party. 6.1% of multi-party debates are successful, as compared to 2.4% of non-multi-party debates, indicating a positive association between debate success and whether the debate is multi-party. If this association is causal, part of the effect of reputation on debate success may be due to attracting collaboration from other users. The estimated LATEs in column (1) of Table 14 indicate that having 10 additional units of reputation increases the probability of the debate being multi-party by 11%. The mechanism via which higher reputation challengers attract other users to join their debates may be complex. For example, higher reputation challengers may engage in longer conversations that make it easier for other users to join.
To exclude the effect of reputation that is potentially due to attracting collaboration from other users, we report the estimated LATEs of reputation, skill and position on debate success for singleparty debates only in column (2) of Table 14. The estimates share the same sign as the overall LATEs reported in Table 9, with smaller magnitudes. This could be due to single-party debates occurring on less popular topics, which are more difﬁcult to persuade in, and hence less likely to attract users who may collaborate with the challengers in ongoing debates. Nevertheless, reputation continues to have a signiﬁcant positive effect on debate success after excluding the potential effect of collaboration from other non-poster users.

32

6 Conclusion
Using a 7-year panel of over a million debates from a large online argumentation platform containing explicit indicators of successful persuasion, we quantify the persuasive power of ethos — one of the three modes of persuasion described in Aristotle’s Rhetoric — in deliberation online. Speciﬁcally, we identify the causal effect of the reputation of an opinion challenger on persuading a poster on the ChangeMyView platform, using the mean position of the challenger in past debates as an instrument for their present reputation. We address endogenous opinion selection using opinion ﬁxed-effects, and ensure instrument validity by controlling for the text of the challenger’s response using neural models of text in a partially-linear instrumental variable speciﬁcation.
We ﬁnd a statistically signiﬁcant positive effect of reputation on debate success, with 10 additional units of reputation increasing the probability of persuading the poster by 31% over the mean platform persuasion rate of 3.5%. The relative effect of the challenger’s reputation with respect to their skill increases with the cognitive complexity of their response (proxied for by the length of their response text), and decreases with the issue-involvement of the poster (proxied for by the length of the opinion text), conﬁrming the predictions of a theoretical model of persuasion where reputation serves as a reference cue (Bilancini and Boncinelli, 2018). We ﬁnd no evidence that posters use reputation as a way to select which challengers to engage with, but we do ﬁnd evidence that reputation induces longer conversations with the challenger. While we ﬁnd evidence that reputation attracts collaboration with the challenger from other users (which may in turn affect persuasion), the estimated effect of reputation continues to be positive and statistically signiﬁcant after excluding debates where such collaboration occurred. These ﬁndings suggest that reputation serves as a proxy for argument quality and validity, and is used by cognitively-overloaded posters as a low-effort information-processing heuristic to evaluate a challenger’s arguments.
Our ﬁndings have implications for a variety of platforms that facilitate deliberative decisionmaking online, including the Stanford Online Deliberation Platform15 used by government organizations to elicit public opinion, and Github used by technology ﬁrms engaged in remote collaborative software development (Marlow et al., 2013). Speciﬁcally, our results suggest that if the participants in deliberation sessions can observe characteristics of other participants, such as past organizational contributions or awards, such characteristics may serve as reference-cues that endow “reputed” participants with additional persuasive power. As a consequence, the degree of consensus within each deliberation session could increase, while distorting the average consensus opinions over a sequence of deliberation sessions towards those held by reputed participants. Such an outcome is undesirable in practice, and violates one of the key tenets of authentic deliberation (Fishkin and Luskin, 2005). In general, our ﬁndings may be of interest to online platforms that employ reputation systems and are concerned about their unintended effects (Chen, 2018; Z. Shi et al., 2020).
15https://stanforddeliberate.org/
33

The reference-cue mechanism (Bilancini and Boncinelli, 2018) supported by our ﬁndings reveals three possible managerial strategies to address this inequity. Importantly, these strategies do not rely on simply hiding all reputation indicators, since employees may desire to showcase their reputation for several justiﬁable reasons without having any intention to exploit its persuasive power. Visible indicators of reputation are also potent motivators, and hiding them completely could nullify their ability to incentivize engagement. Instead, organizations can increase the effort required to view participants’ reputation by displaying it less prominently, albeit at the cost of reducing the motivational power of reputation. Alternatively, ﬁrms can simplify the language of participants’ arguments to reduce their information-processing costs (with machine learning tools like Grammarly, for example), thus reducing the need for participants to rely on low-effort heuristics. This, however, comes at the cost of disrupting participants’ natural communication styles. Finally, ﬁrms can manipulate the perceived accuracy of reputation as an information-processing shortcut by using ambiguous reputation displays (using colors instead of numbers, for example). In contrast with the previous strategies, this strategy is simple to implement and unlikely to have negative repercussions.
Our ﬁndings also have implications for organizations directly engaged in online persuasion via dialogue, for purposes as varied as sales, addressing customer complaints (Hauser and Shugan, 1983; Ma et al., 2015), and reducing societal polarization. Since individuals online are often under information-overload, they are likely to rely on heuristic signals when faced with a persuasive message. Hence, low-reputation organizations (such as new entrants in a market, or organizations having a less favorable reputation among certain demographics) could beneﬁt from simplifying their messages to induce less cognitive overload. Alternatively, organizations could beneﬁt from acquiring reputation signals that are perceived as a proxy for their quality. However, it is important to determine which reputation signals would be perceived as accurate proxies by the organizations’ target demographic and require relatively low effort to evaluate.
The ChangeMyView argumentation platform we study provides us a rich source of online conversations containing explicit indicators of persuasion. The large scale, long timeframe and high quality of the textual data enable identifying and examining causal mechanisms that would be impossible outside of laboratory settings. However, this comes at the cost of generalizing to other online (and ofﬂine) settings. The heavily moderated, good-faith discussions on this platform are different from the typical conversations on social media platforms like Facebook and Twitter, that are dominated by hostility and groupthink. Hence, our estimates could be viewed as upper bounds on the effects of reputation and skill on persuasion, and should be validated by future research into situations were successful persuasion is considered near-impossible or completely independent of the message content. Likewise, additional investigation is needed to study the effect of reputation on conversations ofﬂine, where a host of other factors (such as physical appearances and the environmental setting) are likely to affect successful persuasion.
34

References
Angrist, Joshua and Alan B Krueger (2001). “Instrumental variables and the search for identiﬁcation: From supply and demand to natural experiments”. In: Journal of Economic perspectives 15.4, pp. 69– 85.
Antioch, Gerry et al. (2013). “Persuasion is now 30 per cent of US GDP: Revisiting McCloskey and Klamer after a quarter of a century”. In: Economic Round-up.
Atkinson, David, Kumar Bhargav Srinivasan, and Chenhao Tan (2019). “What Gets Echoed? Understanding the “Pointers” in Explanations of Persuasive Arguments”. In: EMNLP-IJCNLP.
Baumgartner, Jason, Savvas Zannettou, Brian Keegan, Megan Squire, and Jeremy Blackburn (2020). “The PushShift Reddit Dataset”. In: arXiv preprint arXiv:2001.08435.
Beauchamp, Nick (2020). “Modeling and Measuring Deliberation Online”. In: The Oxford Handbook of Networked Communication.
Belloni, Alexandre, Victor Chernozhukov, and Christian Hansen (2014). “High-dimensional methods and inference on structural and treatment effects”. In: Journal of Economic Perspectives.
Bertrand, Marianne, Dean Karlan, Sendhil Mullainathan, Eldar Shaﬁr, and Jonathan Zinman (2010). “What’s advertising content worth? Evidence from a consumer credit marketing ﬁeld experiment”. In: The Quarterly Journal of Economics.
Bilancini, Ennio and Leonardo Boncinelli (2018). “Rational attitude change by reference cues when information elaboration requires effort”. In: Journal of Economic Psychology.
Blei, David M, Andrew Y Ng, and Michael I Jordan (2003). “Latent dirichlet allocation”. In: Journal of machine Learning research.
Chaiken, Shelly (1989). “Heuristic and systematic information processing within and beyond the persuasion context”. In: Unintended thought.
Chamberlain, Gary (1980). “Analysis of Covariance with Qualitative Data”. In: The Review of Economic Studies.
Chen, Yiwei (2018). “User-Generated Physician Ratings: Evidence from Yelp”. In: Chernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duﬂo, Christian Hansen, Whitney
Newey, and James Robins (2018). “Double/debiased machine learning for treatment and structural parameters”. In: The Econometrics Journal. Cialdini, Robert B (2007). Inﬂuence: The psychology of persuasion. Collins New York. Conley, Timothy G, Christian B Hansen, and Peter E Rossi (2012). “Plausibly exogenous”. In: Review of Economics and Statistics. Correia, Sergio (2016). Linear Models with High-Dimensional Fixed Effects: An Efﬁcient and Feasible Estimator. Tech. rep. Working Paper. Davies, Todd and Seeta Gangadharan (2009). Online Deliberation: Design, Research, and Practice. Center for the Study of Language and Information.
35

DellaVigna, Stefano and Matthew Gentzkow (2010). “Persuasion: Empirical Evidence”. In: Annual Reviews of Economics.
Dev, Himel, Karrie Karahalios, and Hari Sundaram (2019). “Quantifying Voter Biases in Online Platforms: An Instrumental Variable Approach”. In: Proceedings of the ACM on Human-Computer Interaction CSCW.
Dewatripont, Mathias and Jean Tirole (2005). “Modes of communication”. In: Journal of Political Economy.
Dranove, David and Ginger Zhe Jin (2010). “Quality disclosure and certiﬁcation: Theory and practice”. In: Journal of Economic Literature.
Farrell, Max H, Tengyuan Liang, and Sanjog Misra (2018). “Deep Neural Networks for Estimation and Inference”. In: arXiv preprint arXiv:1809.09953.
Fishkin, James S and Robert C Luskin (2005). “Experimenting with a democratic ideal: Deliberative polling and public opinion”. In: Acta politica.
Frisch, Ragnar and Frederick V Waugh (1933). “Partial time regressions as compared with individual trends”. In: Econometrica.
Gentzkow, Matthew, Bryan Kelly, and Matt Taddy (2019). “Text as data”. In: Journal of Economic Literature.
Hanin, Boris (2019). “Universal function approximation by deep neural nets with bounded width and relu activations”. In: Mathematics 7.10, p. 992.
Hanin, Boris and David Rolnick (2018). “How to start training: The effect of initialization and architecture”. In: Advances in Neural Information Processing Systems, pp. 571–581.
Harris, Zellig S (1954). “Distributional structure”. In: Word. Hauser, John R and Steven M Shugan (1983). “Defensive marketing strategies”. In: Marketing Science. He, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun (2015). “Delving deep into rectiﬁers: Surpass-
ing human-level performance on imagenet classiﬁcation”. In: Proceedings of the IEEE international conference on computer vision, pp. 1026–1034. Heckman, James (1979). “Sample Selection Bias as a Speciﬁcation Error.” In: Econometrica. Hernán, Miguel A, Sonia Hernández-Díaz, and James M Robins (2004). “A structural approach to selection bias”. In: Epidemiology. Hochreiter, Sepp and Jürgen Schmidhuber (1997). “Long short-term memory”. In: Neural computation. Hughes, Rachael A, Neil M Davies, George Davey Smith, and Kate Tilling (2019). “Selection bias when estimating average treatment effects using one-sample instrumental variable analysis”. In: Epidemiology. Hui, Xiang, Maryam Saeedi, Zeqian Shen, and Neel Sundaresan (2016). “Reputation and regulations: evidence from ebay”. In: Management Science. Imbens, Guido and Joshua Angrist (1994). “Identiﬁcation and estimation of local average treatment effects”. In: Econometrica. Ioffe, Sergey and Christian Szegedy (2015). “Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift”. In: International Conference on Machine Learning, pp. 448–456.
36

Jo, Yohan, Shivani Poddar, Byungsoo Jeon, Qinlan Shen, Carolyn Rose, and Graham Neubig (2018). “Attentive Interaction Model: Modeling Changes in View in Argumentation”. In: Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pp. 103–116.
Jones, Quentin, Gilad Ravid, and Sheizaf Rafaeli (2004). “Information overload and the message dynamics of online interaction spaces: A theoretical model and empirical exploration”. In: Information systems research.
Kamenica, Emir (2018). “Bayesian persuasion and information design”. In: Annual Reviews of Economics. Kamenica, Emir and Matthew Gentzkow (2011). “Bayesian persuasion”. In: American Economic Review. Keith, Katherine A., David Jensen, and Brendan O’Connor (2020). Text and Causal Inference: A Review of
Using Text to Remove Confounding from Causal Estimates. arXiv: 2005.00649 [cs.CL]. Kim, Yoon (2014). “Convolutional Neural Networks for Sentence Classiﬁcation”. In: EMNLP. Kingma, Diederik P and Jimmy Ba (2015). “Adam: A Method for Stochastic Optimization”. In: ICLR. Kokkodis, Marios and Panagiotis G Ipeirotis (2016). “Reputation transferability in online labor mar-
kets”. In: Management Science. Krogh, Anders and John A Hertz (1992). “A simple weight decay can improve generalization”. In:
Advances in neural information processing systems, pp. 950–957. Landry, Craig E, Andreas Lange, John A List, Michael K Price, and Nicholas G Rupp (2006). “Toward
an understanding of the economics of charity: Evidence from a ﬁeld experiment”. In: The Quarterly Journal of economics. Li, Xiang, Shuo Chen, Xiaolin Hu, and Jian Yang (2019). “Understanding the disharmony between dropout and batch normalization by variance shift”. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2682–2690. Lippi, Marco and Paolo Torroni (2016). “Argumentation mining: State of the art and emerging trends”. In: ACM Transactions on Internet Technology (TOIT). List, Christian, Robert C Luskin, James S Fishkin, and Iain McLean (2013). “Deliberation, singlepeakedness, and the possibility of meaningful democracy: evidence from deliberative polls”. In: The Journal of Politics. Lovell, Michael C (1963). “Seasonal adjustment of economic time series and multiple regression analysis”. In: Journal of the American Statistical Association. Lu, Susan F and Huaxia Rui (2018). “Can we trust online physician ratings? Evidence from cardiac surgeons in Florida”. In: Management Science. Luu, Kelvin, Chenhao Tan, and Noah A Smith (2019). “Measuring Online Debaters’ Persuasive Skill from Text over Time”. In: Transactions of the Association for Computational Linguistics. Ma, Liye, Baohong Sun, and Sunder Kekre (2015). “The Squeaky Wheel Gets the Grease—An empirical analysis of customer voice and ﬁrm intervention on Twitter”. In: Marketing Science. Manning, Christopher D, Prabhakar Raghavan, and Hinrich Schütze (2008). Introduction to information retrieval. Cambridge university press.
37

Marlow, Jennifer, Laura Dabbish, and Jim Herbsleb (2013). “Impression formation in online peer production: activity traces and personal proﬁles in github”. In: CSCW.
Martin, Gregory J and Ali Yurukoglu (2017). “Bias in cable news: Persuasion and polarization”. In: American Economic Review.
McCloskey, Donald and Arjo Klamer (1995). “One quarter of GDP is persuasion”. In: The American Economic Review.
Mikolov, Tomas, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean (2013). “Distributed representations of words and phrases and their compositionality”. In: Advances in neural information processing systems.
Moreno, Antonio and Christian Terwiesch (2014). “Doing business with strangers: Reputation in online service marketplaces”. In: Information Systems Research.
Mullainathan, Sendhil, Joshua Schwartzstein, and Andrei Shleifer (2008). “Coarse thinking and persuasion”. In: The Quarterly Journal of Economics.
Nair, Vinod and Geoffrey E Hinton (2010). “Rectiﬁed linear units improve restricted boltzmann machines”. In: ICML.
Netzer, Oded, Alain Lemaire, and Michal Herzenstein (2019). “When words sweat: Identifying signals for loan default in the text of loan applications”. In: Journal of Marketing Research.
Nickell, Stephen (1981). “Biases in dynamic models with ﬁxed effects”. In: Econometrica. Pearl, Judea (2009). Causality. Cambridge university press. Petty, Richard E and John T Cacioppo (1986). “The elaboration likelihood model of persuasion”. In:
Communication and persuasion. Quattrociocchi, Walter, Antonio Scala, and Cass R Sunstein (2016). “Echo chambers on Facebook”. In:
Available at SSRN 2795110. Roberts, Margaret E, Brandon M Stewart, and Edoardo M Airoldi (2016). “A model of text for experi-
mentation in the social sciences”. In: Journal of the American Statistical Association. Roberts, Margaret E, Brandon M Stewart, and Richard A Nielsen (2018). “Adjusting for confounding
with text matching”. In: American Journal of Political Science. Robinson, Peter M (1988). “Root-N-consistent semiparametric regression”. In: Econometrica. Rumelhart, David E, Geoffrey E Hinton, and Ronald J Williams (1986). “Learning representations by
back-propagating errors”. In: Nature. Safran, Itay and Ohad Shamir (2017). “Depth-width tradeoffs in approximating natural functions with
neural networks”. In: Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, pp. 2979–2987. Shi, Claudia, David Blei, and Victor Veitch (2019). “Adapting neural networks for the estimation of treatment effects”. In: Advances in Neural Information Processing Systems. Shi, Zijun, Kannan Srinivasan, and Kaifu Zhang (2020). “Design of Platform Reputation Systems: Optimal Information Disclosure”. In: Available at SSRN: https://ssrn.com/abstract=3557086. Shugars, Sarah and Nicholas Beauchamp (2019). “Why Keep Arguing? Predicting Engagement in Political Conversations Online”. In: SAGE Open.
38

Sridhar, Dhanya and Lise Getoor (2019). “Estimating causal effects of tone in online debates”. In: Proceedings of the 28th International Joint Conference on Artiﬁcial Intelligence.
Srinivasan, Kumar Bhargav, Cristian Danescu-Niculescu-Mizil, Lillian Lee, and Chenhao Tan (2019). “Content removal as a moderation strategy: Compliance and other outcomes in the ChangeMyView community”. In: Proceedings of the ACM on Human-Computer Interaction CSCW.
Srivastava, Nitish, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov (2014). “Dropout: A Simple Way to Prevent Neural Networks from Overﬁtting”. In: Journal of Machine Learning Research 15, pp. 1929–1958.
Stigler, George J (1961). “The economics of information”. In: Journal of political economy. Stock, James H and Motohiro Yogo (2005). “Testing for weak instruments in Linear Iv regression”. In:
Andrews DWK Identiﬁcation and Inference for Econometric Models. Swanson, Sonja A (2019). “A practical guide to selection bias in instrumental variable analyses”. In:
Epidemiology. Taddy, Matt (2013). “Multinomial inverse regression for text analysis”. In: Journal of the American
Statistical Association. Tadelis, Steven (2016). “Reputation and feedback systems in online platform markets”. In: Annual
Review of Economics. Tan, Chenhao, Vlad Niculae, Cristian Danescu-Niculescu-Mizil, and Lillian Lee (2016). “Winning
arguments: Interaction dynamics and persuasion strategies in good-faith online discussions”. In: Proceedings of the 25th international conference on world wide web. Thompson, Dennis F (2008). “Deliberative democratic theory and empirical political science”. In: Annual Reviews in Political Science. Tibshirani, Robert (1996). “Regression shrinkage and selection via the lasso”. In: Journal of the Royal Statistical Society: Series B (Methodological) 58.1, pp. 267–288. Todorov, Alexander, Shelly Chaiken, and Marlone D Henderson (2002). “The heuristic-systematic model of social information processing”. In: The persuasion handbook: Developments in theory and practice. Toubia, Olivier, Garud Iyengar, Renée Bunnell, and Alain Lemaire (2019). “Extracting features of entertainment products: A guided latent dirichlet allocation approach informed by the psychology of media consumption”. In: Journal of Marketing Research. Van der Laan, Mark J and James M Robins (2003). Uniﬁed methods for censored longitudinal data and causality. Springer Science & Business Media. Van der Laan, Mark J and Sherri Rose (2011). Targeted learning: causal inference for observational and experimental data. Veitch, Victor, Dhanya Sridhar, and David M Blei (2019). “Using text embeddings for causal inference”. In: arXiv preprint arXiv:1905.12741.
39

Appendix A: Platform Rules
Rules for shared opinions: • Rule A: Explain the reasoning behind your view (500+ characters required). • Rule B: You must personally hold the view and demonstrate that you are open to it changing. • Rule C: Submission titles must adequately sum up your view. • Rule D: Posts cannot express a neutral stance, suggest harm against a speciﬁc person, or be self-promotional. • Rule E: Only post if you are willing to have a conversation with those who reply to you, and are available to do so within 3 hours after posting.
An opinion may also be removed if it violates any of the following: 1. It was posted by a brand new account on a highly controversial topic. 2. The user already has an active opinion from the last 24 hours. This is to encourage posters to stay engaged with their posts and continue discussion. 3. It’s identical in principle to another post made within 24 hours before it. 4. Anything that is clearly spam or posted by a bot/novelty account.
Opinions will never be removed based on topic or content, so long as they follow the rules above. Rules for responses to opinions:
• Rule 1: Direct responses to a submission must challenge or question at least one aspect of the submitted view.
• Rule 2: Don’t be rude or hostile to other users. • Rule 3: Refrain from accusing the poster or anyone else of being unwilling to change their view. • Rule 4: Award a delta when acknowledging a change in your view, and not for any other reason. • Rule 5: Responses must contribute meaningfully to the conversation. A response may also be removed if it violates any of the following: 1. It is a deliberate attempt to disrupt discussion. 2. Anything that is clearly spam or posted by a bot/novelty account.
40

Appendix B: Correlation Table

All correlations are signiﬁcant at p < 0.001.

(1)

(2)

(3)

(4)

(5)

(1) Reputation

1.00

—

—

—

—

(2) Skill

0.29

1.00

—

—

—

(3) Position

-0.11

-0.14

1.00

—

—

(4) Mean past position

-0.11

-0.14

0.22

1.00

—

(5) Number of past debates

0.88

0.16

-0.12

-0.10

1.00

Appendix C: Results Including Debates by Deleted Challengers

Reputation rpu (10 units)
Skill spu (percentage)
Position tpu (std. deviations)
Response text (Xpu) Instrument (Zpu) Opinion ﬁxed-effects (τp) No. of debates R2

Dependent Variable: Debate Success Ypu

(1)

(2)

(3)

(4)

0.0007∗∗∗ (0.00003)

0.0011∗∗∗ (0.00006)

0.0015∗∗∗ (0.00006)

0.0068∗∗∗ (0.00081)

0.0024∗∗∗ (0.00004)

0.0042∗∗∗ (0.00007)

0.0036∗∗∗ (0.00007)

0.0023∗∗∗ (0.00021)

−0.0446∗∗∗ (0.00246)

−0.0085∗∗∗ (0.00069)

−0.0087∗∗∗ (0.00077)

−0.0078∗∗∗ (0.00074)

   1, 144, 478

   1, 144, 478

   1, 137, 968

   1, 137, 968

0.054

0.013

0.192

—

Note: Standard errors (clustered by opinion) displayed in parentheses. ∗∗∗p < 0.001;∗∗ p < 0.01;∗ p < 0.05

Table 15: Main results. Estimated effects of reputation, skill and position on debate success with a logit model without opinion ﬁxed-effects (1), linear probability models without (2) and with (3) opinion ﬁxed-effects, linear instrumental variable (4) speciﬁcations. Position is standardized to have zero-mean and unit-variance. Average marginal effects and pseudo-R2 are reported for the logit model. The instrument Zpu is the mean past position of user u before they challenged opinion p.

41

Appendix D: Instrumental Variable Speciﬁcation Reduced-Form

Mean past position Zpu Skill spu (percentage) Position tpu (std. deviations) Opinion ﬁxed-effects (τp) No. of debates R2

Dependent Variable: Reputation Ypu
−0.0002 (0.00001)∗∗∗ 0.0037 (0.00007)∗∗∗
−0.0097 (0.00086)∗∗∗ 
1, 019, 469 0.20

Note: Standard errors displayed in parentheses. ∗∗∗p < 0.001;∗∗ p < 0.01;∗ p < 0.05

Table 16: Reduced-form estimates. Mean past position as an instrument for reputation.

42

