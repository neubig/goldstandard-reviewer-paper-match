Deterministic particle ﬂows for constraining stochastic nonlinear systems
Dimitra Maoutsa 1, 2, ∗ and Manfred Opper3, 4, † 1Department of Theoretical Computer Science, Technical University of Berlin, Marchstraße 23, 10587 Berlin, Germany
2Institute of Mathematics, University of Potsdam, Karl-Liebknecht-Str. 24/25, 14476 Potsdam, Germany 3Department of Theoretical Computer Science, Technical University of Berlin, Marchstraße 23, 10587 Berlin, Germany
4Centre for Systems Modelling and Quantitative Biomedicine, University of Birmingham, United Kingdom (Dated: December 13, 2021)
Devising optimal interventions for constraining stochastic systems is a challenging endeavour that has to confront the interplay between randomness and nonlinearity. Existing methods for identifying the necessary dynamical adjustments resort either to space discretising solutions of ensuing partial differential equations, or to iterative stochastic path sampling schemes. Yet, both approaches become computationally demanding for increasing system dimension. Here, we propose a generally applicable and practically feasible non-iterative methodology for obtaining optimal dynamical interventions for diffusive nonlinear systems. We estimate the necessary controls from an interacting particle approximation to the logarithmic gradient of two forward probability ﬂows, evolved following deterministic particle dynamics. Applied to several biologically inspired models, we show that our method provides the necessary optimal controls in settings with terminal-, transient-, or generalised collective-state constraints and arbitrary system dynamics.

arXiv:2112.05735v1 [cond-mat.stat-mech] 10 Dec 2021

INTRODUCTION
Most biological systems are continuously subjected to noise arising either from intrinsic ﬂuctuations due to inherent stochasticities of their constituents, or from external environmental variations at multiple timescales [1–4]. The stochastic nature of these inﬂuences confers on these systems complex behaviour [5–7], but also renders them remarkably unpredictable - by generating noise induced transitions [8, 9], intervening in intracellular communication [10], and compromising precision of biological functions.
Yet, concrete understanding of characteristics, properties, and functions of biological processes often requires external interventions either by precise steering of state trajectories, or by enforcing design constraints that limit their evolution. Characteristic examples of such interventions include modulating transcription pathways to decrease response time, improving stability of epigenetic states in gene regulatory networks [11], or modifying cell differentiation in multicellular organisms [12]. One then may be interested in statistical properties of constrained trajectories (e.g. for computing averages of macroscopic observables), or in obtaining precise control protocols that implement the imposed limitations.
In most settings the optimality of the imposed interventions plays critical role. Performing unreasonably strong perturbations may damage the underlying biological tissue, or result in dynamical changes that considerably deviate from physiological biological function. Translated to mathematics this implies the requirement for the interventions to induce the minimum possible deviation from the typical evolution of the unconstrained system.
Such problems can usually be posed as stochastic optimal control problems. This research area has recently attracted interest in the context of stochastic thermodynamics [13–15]
∗ dimitra.maoutsa@tu-berlin.de † manfred.opper@tu-berlin.de

and quantum control [16, 17], i.e. for estimating the free energy differences between two equilibrium states [18, 19], or for identifying optimal protocols that drive a system from one equilibrium to another in ﬁnite time [20]. Similar problems appear also often in chemistry, biology, ﬁnance, and engineering, required for computation of rare event probabilities [21, 22], state estimation of partially observed systems [23–25], or for precise manipulation of stochastic systems to target states [26, 27] with applications in artiﬁcial selection [28, 29], motor control [30], epidemiology, and more [31–36]. Albeit the prior developments, the problem of controlling nonlinear systems in the presence of random ﬂuctuations remains still considerably challenging.
Central role in (stochastic) optimal control theory plays the Hamilton-Jacobi-Belman (HJB) equation [37], a nonlinear second order partial differential equation (PDE), characterising the value function of the control problem required for obtaining the optimal controls. Existing approaches for devising optimal interventions can be broadly divided into two classes: the ﬁrst class treats the HJB equation directly, while a second class optimises the interventions iteratively by employing stochastic path sampling. Direct treating the HJB often involves space discretising PDE solvers, that in general scale poorly with system dimension [38, 39]. By introducing certain structural assumptions for the control problem in [26], Kappen proposed the Path Integral (PI-) control formalism that linearises the HJB, and via the Feynman-Kac formula reduces the solution of the stochastic control problem to the computation of a path integral. Thereafter, several methods have either treated the linearised HJB with function approximations [40], or employed path integral approximation methods [41–43]. A second class of methods optimises the interventions directly in iterative schemes. A subset of those methods were inspired by the PI-control literature, but instead of focusing on approximating the (exponentiated) value function, they directly optimise the controls by employing information theoretic metrics [21, 44–47]. In particular, the Path integral cross-entropy (PICE) method [44, 45], employs importance sampling to generate paths from a stochastic system

with a provisional control and applies appropriate reweighting to iteratevely converge to the optimal interventions.
In this paper, we borrow ideas from the inference formulation of optimal control [48–51], and take a new look at the problem by providing a sample based solution that nevertheless avoids stochastic path sampling. More precisely, we reformulate the optimal controls in terms of the solutions of two forward (ﬁltering) equations, and employ recent deterministic particle methods for propagating probability ﬂows [52], properly adapted to ﬁt our purposes. Building on the theory of time-reversed SDEs [53], we obtain an exact representation of the optimally adjusted drift of the underlying stochastic system in terms of the logarithmic gradient of two forward probability ﬂows. The latter are estimated from an interacting particle approximation to the logarithmic gradient of the density using a variational formulation developed in the ﬁeld of machine learning.
We show that we can successfully intervene in a series of biologically inspired systems in time constrained settings, subjected to terminal, path, and generalised collective state constraints. We further demonstrate how various problem parameters inﬂuence the estimated interventions, and compare our framework to the already established Path integral cross entropy method [44].

PROBABILITY FLOW OPTIMAL CONTROL: THEORETICAL BACKGROUND

A. Constraining stochastic systems with deterministic forcing

Biological and physical systems are often subjected to intrinsic or extrinsic noise sources that inﬂuence their dynamics. Characteristic examples include molecular reactions and chemical kinetics [54], populations of animal species, biological neurons [55], and evolutionary dynamics [56, 57]. Stochastic differential equations (SDEs) effectively capture the phenomenology of the dynamics of such systems by both considering deterministic and stochastic forces affecting their state variables Xt ∈ Rd following

dXt = f (Xt, t)dt + σdWt.

(1)

In Eq. (1) the drift f (·, ·) : Rd×R → Rd is a smooth typically nonlinear function that captures the deterministic part of the driving forces, while W stands for a d–dimensional vector of independent Wiener processes acting as white noise sources, representing contributions from unaccounted degrees of freedom, thermal ﬂuctuations, or external perturbations. We denote the noise strength by σ ∈ R. For the sake of brevity, we consider here additive noise, but the formalism easily generalises for multiplicative and non-isotropic noise, i.e. for a state dependent diffusion matrix σ(x, t). In the following we refer to this system as the uncontrolled system.
Under multiple independent realisations, the stochastic nature of Eq. (1) gives rise to an ensemble of trajectories starting from an initial state X0 = x0. This ensemble captures the likely evolution of the considered system at later time points. We may characterise the unfolding of this trajectory ensemble

2

in terms of a probability density pt(x) for the system state Xt, whose evolution is governed by the Fokker–Planck equation

∂pt(x)

σ2

= ∇ · −f (x, t)pt(x) + ∇pt(x)

(2)

∂t

2

= Lf pt(x),

with initial condition p0(x) = δ(x − x0), and Lf denoting the Fokker–Planck operator.
Due to the stochastic nature of the system of Eq. (1), exact pinpointing of its state at some later time point T is in general not possible. Yet, often, we desire to drive stochastic systems to predeﬁned target states within a speciﬁed time interval. Characteristic examples include designing artiﬁcial selection strategies for population dynamics [28], or triggering phenotype switches during cell fate determination [27]. Similar needs for manipulation are also relevant for non-biological, but rather technical systems, e.g. for control of robotic or artiﬁcial limbs [58, 59]. In all these settings, external system interventions become essential.
Here, we are interested in introducing constraints C to the system of Eq. (1) acting within a predeﬁned time interval [0, T ]. The set of possible constraints C comprises terminal χ(XT ), and path constraints U (x, t), for t ≤ T , depending on whether the desired limiting conditions apply for the entire interval, or only at the terminal time point. The path constraints U (x, t) : Rd × R → R penalise trajectories (paths) to render speciﬁc regions of the state space more (un)likely to be visited, while the terminal constraint χ(x) : Rd → R inﬂuences the system state XT at the ﬁnal time T .
To incorporate the constraints C into the system, we deﬁne a modiﬁed dynamics, the controlled dynamics, through a change of probability measure of the path ensemble Pf induced by its uncontrolled counterpart. More precisely, we deﬁne the path measure Q∗, induced by the controlled system, by a reweighting of paths X0:T generated from the uncontrolled one (Eq. (1)) over the time interval [0, T ] (Supplementary Information). Path weights are given by the likelihood ratio (Radon–Nikodym derivative)

dQ∗

χ(XT )

T

dPf (X0:T ) = Z exp − 0 U (Xt, t)dt , (3)

where Z is the normalising constant

T

Z = χ(XT ) exp − U (Xt, t)dt

, (4)

0 Pf

and · Pf denotes the expectation over paths of the uncontrolled system.
By a direct calculation (see Supplementary Information), we show that the inﬁnite dimensional path measure Q∗ is the
solution of the variational problem

T

Q∗ = arg min KL(Q||Pf ) +

U (Xt, t) dt

Q

0

Q

− ln χ(XT ) ,

(5)

3

where KL(Q||Pf ) stands for the relative entropy (KullbackLeibler (KL-) divergence) between the controlled and the un-
controlled path measures. It can be shown that the optimal path measure Q∗ is induced
by a time- and state- dependent perturbation u(x, t) : Rd × R → Rd of the deterministic forces f (x, t) acting on the
uncontrolled system [44]. Thus, we express the controlled
dynamics as a space- and time-dependent perturbation of the
uncontrolled system

dXt = f (Xt, t) + u(Xt, t) dt + σdWt

=

g(Xt, t) dt

+ σdWt.

(6)

To identify the optimal interventions we minimise the cost functional J

J =. min
u

T 1 u(x, t) 2 + U (x, t) dt−ln χ(XT ) .

0 2σ2

Q

(7)

The ﬁrst part of the cost functional penalises large interven-

tions u(x, t), and results from minimising the relative en-

tropy between the path measures induced by the controlled

and uncontrolled dynamics, KL(Q||Pf ). The second term

constrains the transient behaviour of the system through the

path costs U (x, t), while χ(XT ), inﬂuences only the terminal

system state.

Finding exact optimal controls for general stochastic con-

trol problems amounts to solving the Hamilton–Jacobi–

Bellman (HJB) equation (see [37]), a nonlinear, partial differ-

ential equation (PDE) that is in general computationally de-

manding to treat directly.

The control cost formulation of Eq.(7) gives rise to a clus-

ter of stochastic control problems known as Kullback-Leibler

(KL)-control [60] or Path integral (PI)-control [26, 49] in the

literature (see Supplementary Information for details). For

this class of problems the logarithmic Hopf-Cole transforma-

tion [61], ie. setting J (x, t) = − ln(ϕt(x)), linearises the

Hamilton-Jacobi Bellman equation [26], and the optimally

perturbed drift simpliﬁes into (see Supplementary Informa-

tion)

g(x, t) = f (x, t) + σ2∇ ln ϕt(x),

(8)

where the function ϕt(x) is a solution to the backward PDE

∂ϕ∂tt(x) + L†f ϕt(x) − U (x, t)ϕt(x) = 0, (9)
with terminal condition ϕT (x) = χ(x), and L†f denoting the adjoint Fokker–Planck operator. For U (x, t) ≡ 0, Eq.(9) reduces to the Kolmogorov backward equation for the uncontrolled system.
Although the controlled drift admits a well deﬁned expression in the terms of the solution of the backward partial differential equation of Eq.(9), direct solutions with space discretising schemes [38, 39] often suffer from high computational complexity with increasing dimensionality and become inefﬁcient for most practical settings. Similarly, stochastic path sampling frameworks building on the the equivalence between

path reweighting and optimal control, like the path integral cross entropy method [44, 45], follow iterative procedures that progressively converge to the optimal controls. (Note also recent neural network advances towards this direction [62, 63].)

B. Constrained ﬂows from time-reversed SDEs.

Here, to circumvent the need for backward-in-time integration of the backward PDE, we express the optimal interventions u(x, t) in terms of two forward probability ﬂows. To that end, we consider a factorisation for the path probability density qt(x) arising from the controlled system into two terms that account for past and future constraints separately [64],

qt(x) ∝ t(x)ϕt(x).

(10)

In Eq.(10), ϕt(x) fulﬁlls the backward PDE (Eq. (9)), and embodies prospective (future) constraints to the time t, while
t(x) denotes a (non–normalised) forward probability ﬂow that accounts for concurrent and retrospective (past) constraints, and is the solution of the forward PDE

∂ t(x) = Lf t(x) − U (x, t) t(x) (11) ∂t = − ∇ · f (x, t) t(x) + σ2 ∇2 t(x) − U (x, t) t(x). 2

In the absence of path constraints (U (x, t) ≡ 0), Eq.(11) reduces to the Fokker–Planck equation for the uncontrolled system. On the other hand, in the presence of path constraints (U (x, t) = 0) the resulting evolution equation becomes more complicated. By integrating Eq.(11) at time t over a small time interval δt, we obtain

t+δt(x) = eδt(Lf −U(x,t)) t(x)

(12)

= e−δtU(x,t)eδtLf t(x) + O((δt)2),

(13)

in terms of operator exponentials [65]. This formulation admits an interpretation as the concatenation of two processes: the propagation of the density described by the uncontrolled Fokker–Planck equation (Eq.(2)), followed by a multiplication of the resulting density by a factor e−δtU(x,t). This second process, is known in ﬁltering problems for stochastic dynamics [66], where the current estimate of the system state Xt results from a multiplication of the likelihood of the noisy observations e−δtU(x,t) with the density capturing the prior belief of the state Xt. Hence, we call equation Eq.(11) the forward ﬁltering equation. In turn, the factorisation of Eq.(10) is reminiscent to the representation of smoothing densities for hidden Markov models as products of forward and backward messages.
The overall factorised probability ﬂow qt(x), i.e. the probability ﬂow characterising the evolution of the constrained system state, fulﬁlls the Fokker–Planck equation

∂qt(x) = Lgqt(x) (14) ∂t = − ∇ · g(x, t)qt(x) + σ2 ∇2qt(x), 2

4

with initial condition q0(x) = 0(x), and Lg denoting the Fokker–Planck operator for the optimally adjusted drift g(x, t).
The factorisation of Eq. (10) allows for a new representation of the optimal drift g(x, t) by eliminating the backward ﬂow ϕt(x) in favour of t(x)
g(x, t) = f (x, t) + σ2 (∇ ln qt(x) − ∇ ln t(x)) . (15)
The new formulation of the optimal drift still requires the logarithmic gradient of the constrained ﬂow qt(x), and therefore does not allow for direct simulation of controlled paths. Yet, this formulation of the optimal drift turns Eq.(14) into an equation resembling a Fokker–Planck equation, but with a negative diffusion term

∂qt(x) = ∇· ∂t

σ2∇ ln (x, t)−f (x, t) qt(x) − σ2 ∇2qt(x). 2

(16) However, by introducing the backward time variable τ = T − t, and setting q˜τ (x) = qT −τ (x) we obtain a new Fokker–Planck equation with properly signed diffusion

∂q˜τ (x) = −∇ · ∂τ

σ2∇ ln

+ σ2 ∇2q˜τ (x), 2

T −τ (x) − f (x, T − τ )

q˜τ (x) (17)

with initial condition q˜0(x) ∝ T (x)χ(x). Hence, we have represented the optimal control

u∗(x, t) = σ2 ∇ ln q˜T −t(x) − ∇ ln t(x) , (18)

as the difference of the logarithmic gradients of two forward probability ﬂows ( score–functions ).
Hence, we have represented the optimal control

u∗(x, t) = σ2 ∇ ln q˜T −t(x) − ∇ ln t(x) , (19)

as the difference of the logarithmic gradients of two forward probability ﬂows (score–functions). This result suggests a possible numerical strategy for obtaining the optimal interventions: First, solve the forward ﬁltering equation for t(x) (Eq. (11)) using e.g. a particle ﬁltering approach. Then approximate the logarithmic gradients ∇ ln T −τ (x) based on a sufﬁciently large number of stochastic particle paths. After this, simulate a number of random trajectories of the SDE which corresponds to the Fokker–Planck equation (Eq. (17)) and use the trajectories to approximate the score ∇ ln q˜T −t(x). In fact, a similar approach was recently used to solve so–called Schro¨dinger bridge problems [67]. The latter can be also be understood as speciﬁc control problem for SDEs with only control energy costs (i.e. U (x) ≡ 0 and χ(x) = 1) in the cost functional (Eq.(7)), but in addition the probability densities q0(x) and qT (x) at initial and ﬁnal times are speciﬁed as extra constraints. In contrast to these

approaches, we apply and generalise a recent deterministic, particle framework for solving Fokker–Planck equations introduced by the authors in [52] to solve generic path integral control problems of the type of Eq. (7). This new technique avoids stochastic path sampling and reduces signiﬁcantly temporal ﬂuctuations, delivering thereby accurate Fokker–Planck equation solutions for relatively low number of employed particles [52]. In addition, the computation of the logarithmic gradients is already an integral part of the method for computing the deterministic particle dynamics.

C. Deterministic particle ﬂow (DPF) control

To sample the forward densities t(x) and q˜t(x), we build on the idea that a Fokker–Planck equation can be rewritten as a Liouville equation [68] for an ensemble of deterministic dynamical systems where the logarithmic gradient of the ensemble density acts as an additional force. In particular, for an SDE with drift f (x, t) and diffusion σ, we rewrite the Fokker– Planck equation (Eq.(1)) for the probability density pt(x) of the system state in the form (see [52] for details)

∂pt(x) = −∇ · ∂t

σ2 f (x, t) − 2 ∇ ln pt(x) pt(x) . (20)

For a known density pt(x), this equation describes the evolution of an ensemble of independent systems with each ensemble member following the deterministic dynamics:

dXt

σ2

= f (Xt, t) − ∇ ln pt(Xt).

(21)

dt

2

Note that here individual trajectories X0:T are distinct from solutions of the underlying SDE, since each ensemble individual follows pure deterministic dynamics.
To obtain a solution of the Fokker–Planck equation, we approximate the density pt(x) by an empirical distribution of N ensemble members (’particles’) {Xt(i)}Ni=1 via

1N

(i)

pˆt(x) ≈ N δ x − Xt .

(22)

i=1

Based on this empirical representation of the density pt(x), we approximate its logarithmic gradient with a statistical estimator ∇ˆ ln pˆt(Xt(i)), obtained from the solution variational formulation of the score function (see Supplementary Infor-
mation). Thus, we express the resulting dynamics of indi-
vidual particles in terms of a system of ordinary differential
equations (ODEs)

dXt(i) = f (X(i), t) − σ2 ∇ˆ ln pˆ (X(i)).

(23)

dt

t

2

tt

While this approach is sufﬁcient to solve control problems without path costs (U (x, t) ≡ 0), the extra sink term −U (x, t) t(x) in the forward ﬁltering PDE (Eq.(11)) in the presence of path constraints requires an additional numerical

5

optimal control

FIG. 1. Schematic of forward and time-reversed probability ﬂows for deriving state- and time-dependent dynamical interventions u(x, t). We initially sample the ﬂow t(x) for the time interval [0, T ]. By employing the logarithmic gradient (score) of t(x), we evolve the time-reversed constrained probability ﬂow q˜t(x). The optimal state- and time-dependent dynamical interventions u(x, t) result from the difference of the logarithmic gradients of the two probability ﬂows.

technique. Thus, to incorporate path costs, we employ the
formulation of the two stage process given by Eq.(12), and
combine our Fokker-Planck deterministic particle solver with a deterministic particle ﬁlter method, the ensemble transform particle ﬁlter [66]. To simulate such a two stage process for each small time interval δt, we ﬁrst propagate the particles following the dynamics of Eq.(23) to auxiliary positions Yt(i) and assign to each particle i a weight Ωi

Ωi(t) ∝ e−δtU(Yt(i),t).

(24)

To transform the weighted particles to unweighted ones, we employ the ensemble transform particle ﬁlter [66]. This method solves an Optimal Transport [69] problem to provide the minimal necessary deterministic shifts required to transform an ensemble of weighted particles into an ensemble of uniformly weighted ones, by maximising the covariance between the two ensembles (see Supplementary Information).

D. Guiding probability ﬂows to extreme terminal states
In settings where the terminal target state lies outside of the typical values of the uncontrolled system, the sampled forward ﬂow t(x) fails to provide sufﬁcient evidence in the vicinity of the terminal point. Thereby the ensuing logarithmic gradient estimation ∇ log t(x) is inaccurate.
For conservative systems and for terminal constraints deﬁned by a delta function, i.e. χ(x) = δ(x − x∗), we address this issue by proposing an additional modiﬁed forward sampling that incorporates the extreme terminal constraint in the forward dynamics. To that end, we employ a d-dimensional Brownian Bridge (BB) dynamics. Brownian bridges are essentially Brownian motions, i.e. diffusions with vanishing drift f (x) ≡ 0, with a ﬁxed terminal state x∗ (see Supplementary Information).
To maintain the correct path statistics, we employ the Girsanov’s change of measure formula to reweight the biased for-

ward paths. More precisely, we obtain the correct path probability measure of the controlled process PBf B by reweighting the Brownian bridge path measure PB0 B with the likelihood (Supplementary Information)

dPBf B

T

dPBB (X0:T ) ∝ exp − UBB(Xt)dt , (25)

0

0

with

1 UBB(x) =

f 2(x) + σ2∇ · f (x) .

(26)

2σ2

Hence, to simulate constrained paths of an SDE with drift f (x) and extreme terminal constraints, we transform the extreme terminal constraint to a path constraint UBB(x) for an appropriate Brownian bridge process that already incorporates the terminal state x∗. In particular, we employ the modiﬁed
forward equation

∂ t(x)

∂t = Lf0 t(x) − UBB(x) t(x),

(27)

that generates paths with correct statistics that reach the terminal target by imposing the path constraint UBB(x) to the Brownian bridge forward dynamics with drift f0. We term this variant of our framework guided Deterministic Particle Flow (gDPF) control.

EVALUATION OF OPTIMAL DYNAMICAL INTERVENTIONS
To illustrate our formalism in action, we computed optimal intervention protocols for biological systems by employing the proposed deterministic particle framework, and compared the obtained controls to those computed with the Path integral cross entropy method (PICE) (see Supplementary Information and [44]). We tested our method on systems of

increasing complexity and dimensionality, with conservative and non-conservative forces, as well as in settings with terminal, path, or collective state constraints.
To design the optimal interventions u(x, t) we employed the presented method in two alternative variants: i) the deterministic particle ﬂow control (DPF), where the forward density follows the dynamics of Eq. (11), and ii) the guided deterministic ﬂow control (gDPF), in which the forward density evolves according to an appropriately reweighted Brownian bridge dynamics, as described in Section D.
To evaluate the quality of the obtained controls, we considered the design of optimal interventions for artiﬁcially manipulating molecular phenotypes on adaptive landscapes (Section F), for inducing state transitions to multistable conservative and non-conservative systems (Section E), and for synchronising ﬁnite-size networks of Kuramoto phase oscillators (Section G). We quantiﬁed the quality of the identiﬁed interventions in terms of employed control energy ( u(x, t) 22), reﬂecting the optimality of the computed control, as well as in terms of deviations from terminal ((x∗ − XT )2) and path constraints (U (Xt, t)), characterising thereby the effectiveness of the devised interventions to enforce the intended constraints. Unless explicitly mentioned otherwise, all metrics were evaluated by considering 1000 independent stochastic trajectories controlled with each method.
E. Controlling state transitions of conservative and non-conservative systems.
We employed the proposed framework to devise interventions that reliably induced switching between stable states in a time constrained scheme for an one-dimensional conservative system and for a two-dimensional non-conservative one. For both settings, the unconstrained system either performs the state transition in a time unreliable way, or completely fails to reach the target, when the transition paths to that state strongly deviate from typical trajectories (Figure 2).
For the one-dimensional bistable system (f (x) = 4 x − x3) starting from the stable state at x0 = −1, we provided optimal interventions under the objective of driving the system towards a predeﬁned target x∗ at time T = 1. We applied both variants of the presented method DPF (Section C) and
gDPF (Section D) , and explored two complementary scenarios: one with typical, x∗ = 0 (Figure 2a.-d.), and one with extreme, x∗ = 1 (Figure 2e.-h.), target states for the uncontrolled system at time T . Notice that the state x∗ = 0 is unstable, but outside of the basin of attraction of the initial state x0.
Identiﬁed interventions successfully drive the system to target states. For the typical target state x∗ = 0, all three employed methods (DPF: magenta, gDPF: yellow, PICE: grey) successfully biased the controlled system towards the target x∗ (Figure 2a.). In fact, the distributions of simulated independent controlled trajectories delivered by each framework completely agreed throughout the entire time interval [0, T ] (Figure 2b.).
Considering the control energy dissipated by each method,

6
DPF, on average, provided slightly larger interventions (Figure 2c.). Yet, both variants of our approach (DPF and gDPF) induced control trajectories that were consistently more exact in reaching the terminal state (Figure 2c.).
Comparing the distributions of terminal errors, DPF was both more accurate in reaching the target, as mediated by a smaller average value over the 1000 realisations (grey bar), but also more precise, as indicated by the smaller dispersion of terminal errors around the average. This demonstrates that although DPF slightly overestimated the required controls, it provided sufﬁcient force to lead the trajectories faithfully onto the target. In contrast, PICE relatively underestimated the necessary interventions, resulting in more energy efﬁcient controls that nevertheless moderately deviated from the target.
Importantly, these results suggest that a single iteration of either variants of the proposed method (DPF or gDPF) provide comparable controls to the iterative PICE framework (grey).
For the extreme terminal state x∗ = 1, the guided probability ﬂow deterministic control (gDPF) and the path integral cross entropy method (PICE) successfully pushed the system to the target (Figure 2e.)). The distributions of controlled trajectories (Figure 2f.) from the two frameworks showed complete agreement, while the control costs and terminal state precision were qualitatively similar to those obtained for the typical target state.
Notice that the deterministic particle ﬂow control (DPF), the simple variant of our method, is inappropriate for this setting for a reasonable number of employed particles representing the forward ﬂow. Since the target is an extreme system state for time T , it is highly unlikely that particles representing the forward ﬂow t(x) will reach the target x∗. Thus the estimation of logarithmic gradients of the forward ﬂow t(x) in the vicinity of the target will be inaccurate, since the particles will not provide sufﬁcient evidence for gradient estimation in that region.
Departing from gradient systems, onward we consider triggering transitions between stable states in a time reliable way for a non-conservative system. To that end, we employed DPF for controlling a two dimensional phenomenological model of the function of a cell fate division module of a gene regulatory network [70] with self-excitation and cross inhibition (see Supplementary Information). We applied our method to induce transitions to the system between its co-existing stable states.
Similar to the conservative setting examined previously, the DPF successfully mediated the necessary interventions for the transition between the stable states (Figure 3 a.). We considered three noise conditions with σ = {1., 1.25, 1.5} and compared again the deterministic particle ﬂow control (DPF) with the path integral cross entropy method (PICE). The transient statistics computed over 1000 controlled trajectories for each framework agreed for all noise conditions (Figure 3b.) and Supplementary Information Figure).
Control costs and terminal error precision were comparable for the two approaches, with DPF performing slightly better in terms of dissipated control energy for increasing noise strength (Figure 3c.). Both methods had comparable control

7

a.

b.

c.

d.

e.

f.

g.

h.

FIG. 2. Equivalence of dynamical interventions delivered by deterministic particle ﬂow control (DPF), guided deterministic particle
ﬂow control (gDPF), and PICE, for typical (upper) and extreme (lower) terminal conditions. (upper) (a.) Controlled trajectories
simulated by employing dynamical interventions delivered by deterministic particle ﬂow control (magenta), guided deterministic particle ﬂow
control (orange), and path integral cross entropy method (grey). All trajectories started from initial point x0 = −1 (left silver circle) and reached the target x∗ = 0 at time T = 1. (b.) Transient mean µt and standard deviation σt over 1000 independent trajectories controlled with each framework.(c.) Total control energy u(x, t) 2, and (d.) deviation from terminal point for 1000 independent controlled trajectories
with interventions computed according to each framework. Grey horizontal lines in (c.) and (d.) denote mean values over all realisations.
The proposed methods result in slightly more expensive control costs, but are more consistent in precisely reaching the terminal state. (lower) Same as upper row for target x∗ = 1 only for gDPF and PICE. Here DPF is not applicable since the forward probability ﬂow does not reach the extreme target point x∗ = 1.

accuracy in reaching the target that deteriorated moderately for increasing noise amplitude. However, while DPF was considerable more accurate and precise for the low noise conditions, for larger noise amplitudes the accuracy of both methods in reaching the terminal point x∗ became comparable (Figure 3d.).
Taken together, DPF (and gDPF where necessary) successfully provided the necessary controls for reaching the targets in both conservative and non-conservative systems and under various noise conditions. The provided interventions where on par with the established iterative PICE framework in terms of dissipated control energy, and moderately more precise in reaching the target.
F. Evolutionary control through artiﬁcial selection.
Building upon the evolutionary stochastic control formalism recently introduced by Nourmohammad et. al [28], we employed deterministic particle ﬂow control to devise artiﬁcial selection protocols for molecular phenotypes that optimally drive evolution to desired phenotypic states. In this setting experimentally imposed path constraints become relevant for preventing undesirable outcomes on covarying

phenotypes.

For an evolving population, the main evolutionary drivers comprise ﬁtness and mutation forces that continuously adjust the composition of phenotypes in the population, while genetic drift perturbs the whole process stochastically. We described the evolution of the mean phenotypes dx of the population by the overdamped Langevin equation [71]

dx = C · ∇F (x)dt + σdW,

(28)

with F (x) denoting the adaptive ﬁtness landscape in the presence of natural selection [72], and σ the noise amplitude that rescales the genetic drift, i.e. the stochastic term, according to the population size n and the covariance matrix C, σ = C1/2n−1 . The gradient of the landscape f (x) = C · ∇F (x) captures the adaptive pressures under natural selection.
In contrast to commonly employed assumptions of spherically symmetric adaptive landscapes, to demonstrate the richness of our method and supported by empirical ﬁndings [73], we considered an asymmetric rugged landscape [74]. Such landscapes may arise in small sized populations with small variance and multi-modal ﬁtness functions for each individual [75]. For simplicity we consider the covariance matrix C constant, given the much smaller timescales upon which its

8

a.

b.

c.

d.

FIG. 3. Optimal interventions effectively drive the non-conservative system to the target state for different noise amplitudes. (a.) Individual trajectory controlled by DPF (green-yellow) starting from stable state x0 = (1.996, 0.4) successfully reaches the target x∗ = (1, 1) at T = 0.5, while the uncontrolled trajectory (grey) fails to leave the basin of attraction of x0. (b.) Agreement between controlled densities of 1000 independent controlled trajectories driven by DPF (magenta) and PICE (grey) for noise amplitude σ = 1.5. (c.) Dissipated control energy, and (d.) terminal error for increasing noise strength σ for the two control frameworks. For increasing noise DPF delivers more efﬁcient, but moderately less precise controls than PICE.a
a Further parameters: particle number: N = 600 inducing point number: M = 20.

FIG. 4. The phenotypic landscape .
ﬂuctuations unfold [76], and its weak dependency on the evolutionary selection strength [77].
The dynamics of Eq.(28) describe the evolution of populations in the presence of natural selection towards an evolutionary optimum, captured by the maximum of the adaptive landscape, adhering thereby to physiological and environmental constraints.
To study the outcomes and dynamics of adaptive evolution, intervention protocols are required that drive phenotypes towards non-evolutionary optimum states x∗, or through evolutionary trajectories that deviate from landscape gradients. These interventions are implemented through artiﬁcial selection, which, following [28], we formulate as a time- and statedependent perturbation u(x, t) to the natural selection, and apply DPF to obtain the necessary controls.
Single-objective and multi-objective directed evolution.

For a system with multiple covarying phenotypes evolving on the landscape F (x, y) = ((1 − x)2 + (y − x2)2) (Figure 4), changes along one phenotypic axis are often accompanied by changes along covarying phenotypic traits as dictated by the landscape gradient. Thus attempts to bias and enhance selective forces towards a speciﬁc phenotype, may lead to undesired variations along the covarying traits. To demonstrate this, we controlled phenotypic trajectories initiated at state x0 = (−1, 1) with target state x∗ = (1, 1). The designed interventions by DPF with only terminal constraints χ(x) = δ(x − x∗) successfully drove the system to the intended target (Figure 5a.-b.). Nevertheless, although the initial and terminal state along the second dimension remained the same, as expected, without introducing additional path constraints, the phenotypic trait along the second dimension (y) underwent considerable transient ﬂuctuations as indicated by the non-constant mean of the simulated paths (µqˆt ), as well as by the increasing dispersion of paths from the mean, as captured by the standard deviation σqˆt (Figure 5b.).
To limit the ﬂuctuations along the covarying second phenotypic trait, we introduced path constraints
U ((x, y), t) = 103 (y − 1)2
that penalised transient deviations from the intended value of the second trait y (Figure 5e.). The necessary interventions, identiﬁed by DPF with path constraints, successfully controlled the system towards the predeﬁned target, reducing thereby considerably the ﬂuctuations along the second axis (Figure 5e. and f.). Compared to the path integral control framework (PICE), for both scenarios, our method delivered results with comparable dissipated control energy and considerably more precise in terms of terminal errors (Figure 5e. and f.).
Evaluating the performance of both methods for increasing particle number N employed for the estimation of the re-

9

FIG. 5. Deterministic particle ﬂow (DPF) control provides optimal interventions to drive evolution to target state (grey cross). (a.) A controlled trajectory starting from phenotypic state (−1, 1) reaches the target state (1, 1) at time T = 0.7 (blue-yellow line), while an uncontrolled trajectory remains in the vicinity of initial state during the same time interval (orange line). (b.) Mean and standard deviation of the marginal densities of 1000 controlled trajectories employing interventions computed with our framework DPF (purple) and with PICE (grey). Orange line indicates mean of 1000 uncontrolled trajectories, while shaded area captures the associated standard deviation. For estimating the controls we employed N = 400 particles for DPF, and Npice = 500 for PICE. (c.) Comparison of (upper) (logarithmic) control energy u(x, t) 22, and (lower) deviation from the terminal point XT − x∗ 2 for each controlled trajectory with interventions computed according to DPF (magenta) and PICE (grey). (d.) (Logarithmic) control energy (upper) improves moderately, and terminal error (lower) remains constant for increasing particle number N . The number of inducing points in the logarithmic gradient estimation conveys negligible difference in control energy and terminal error (inducing point number magenta: M = 50, green: M = 100 ). Grey line indicates the performance of PICE in the same setting. (e.-h.) Same as (a.-d.) with additional path constraint U ((x, y), t) = (y − 1)2.

quired interventions u(x, t), revealed that DPF provided controls on par with PICE already for N = 500 particles and, by design, only with a single iteration. More precisely, the proposed method presented a relatively stable performance for increasing particle number, with small improvement in terms of exerted control energy, whereas the path integral cross entropy method improved substantially when more particles where employed in the computations, and consequently matched in performance our approach. Considering the deviation from the terminal state, DPF was consistently more precise and accurate in reaching the target as indicated both by considerably smaller terminal errors (Figure 5d. and h.), and by smaller deviations of individual terminal states around the average (Supplementary Figure 5). Both the exerted control energy and terminal error do not show considerable improvement for increasing inducing point number employed in the logarithmic gradient estimator (magenta for M = 50; green for M = 100).

G. Controlling collective states: synchronisation control of stochastic Kuramoto oscillators
To further demonstrate the generalisability of the proposed framework, we considered a system where the constraints do not explicitly penalise exact regions of the state space, but rather pertain the collective state of a system of interacting stochastic units. Speciﬁcally, we applied our method for synchronising ﬁnite size networks of stochastic Kuramoto phase oscillators (see Supplementary Information for details). We performed systematic studies on a prototypical network of two interacting oscillators (Fig. 6 , Fig. 7, and Fig. 8), and a network of K = 6 (Fig. 9 and Fig. 10) heterogeneous oscillators with all-to-all uniform coupling (Supplementary Information).
To accommodate synchronisation control with our framework, we considered a time constrained setting where we applied DPF for an interval [0, T ] (time units). An alternative ’online’ approach described in the Supplementary Information alternates computation of controls within small time intervals with simulation of controlled trajectories over those intervals.
We implemented the synchronisation constraint as a path

10

a.

b.

c.

FIG. 6. Synchronisation control of two coupled Kuramoto phase oscillators. (a.) Evolution of phases (θi) of two controlled (purple) and two uncontrolled (green) Kuramoto oscillators mutually coupled with coupling J = 1.2 and noise amplitude σ = 1.0. (b.) Evolution of Kuramoto phase-coherence order parameter R for the controlled (purple) oscillators indicates a fast transition to synchrony (R=1), while, the identical uncontrolled oscillators become progressively incoherent, indicated by a strongly ﬂuctuating order parameter (green). The orange line denotes the expected long time average value of the order parameter for non-interacting oscillators considering ﬁnite size scaling effects. The grey line marks the level of R = 1 indicating a completely synchronous state. (c.) Control input provided to each oscillator.

constraint that promotes synchrony without any further requirement for the terminal state, and characterised the level of synchronisation in terms of the Kuramoto order parameter for phase coherence R(θ, t) (Supplementary Information)
R(t) = 1 | K eiθj(t)|. (29) K
j=1
To that end, we employed the following path constraint that promotes order parameter values closer to 1, i.e. closer to a synchronous state
U (θt) = β (1 − R(θt, t)) dt,
with θt ∈ RK denoting the vector of oscillator phases, and β ∈ R a scaling constant.
For all considered networks of interacting Kuramoto oscillators we applied interventions ui(θt, t) on the phases θ = {θi}Ki=1 of all network nodes. Further considerations of optimally selecting a subset of nodes to control were out of the scope of the current article.
For a prototypical network of K = 2 interacting oscillators with weak coupling (J = 1.2), DPF induced rapid synchrony, whereas the uncontrolled oscillators became progressively incoherent as indicated both by observing their phases (Figure 6a.) and the transient values of their phase-coherent order parameter R (Figure 6b.). DPF provided fairly strong control inputs at the beginning of the simulation to fully align the phases of the oscillators (Figure 6c.), and subsequently delivered only moderate controls to maintain synchrony counteracting the effect of noise.
DPF successfully induced synchrony for different levels of coupling and under two different noise conditions σ = {0.5, 1.0} (Figure 7a.). For strongly coupled oscillators

where the uncontrolled network progressively synchronises solely due to the interactions, DPF synchronised the oscillators faster - indicated by earlier reaching the order parameter R = 1 value compared to their uncontrolled counterparts - and prevented spontaneous desynchronsation events that occurred in the uncontrolled networks especially in the presence of strong noise (Figure 7b.).
To quantify these effects further, we analysed the onset of synchronisation tsyn and the percentage of time spent in the synchronised state of the examined controlled and uncontrolled networks for increasing coupling J.
For each network realisation, we deﬁned the onset of synchronisation tsyn as the ﬁrst time point when the phasecoherence order parameter exceeded the value R ≥ 0.99 and remained above that value for a minimal duration of τ s = 20 × dt = 0.02 time units. For uncontrolled networks with weak couplings we considered only the subset of realisations that reached the synchronous state (indicated as a ratio by the grey annotations in Figure 8a.). To quantify the robustness of synchronisation in each network, we estimated the percentage of time the network remained synchronised after the synchronisation onset by counting the time points when the order parameter spontaneously exceeded the R = 0.99 threshold after tsyn.
For both noise conditions and independent of coupling strength J, networks controlled by DPF reached the synchronous state considerably faster than their uncontrolled counterparts (Figure 8a.), and consistently remained synchronised for the entire simulation, as mediated by the percentage of time spent in the synchronised state after the synchronisation onset tsyn. More precisely, while a subset of uncontrolled weakly coupled networks synchronised for at least τ s = 20 time units, as expected due to the presence of noise they failed to remain in that synchronised state as indicated in

11

a.

b.

FIG. 7. Synchronisation control a network of two coupled Kuramoto phase oscillators for different coupling strengths. (a.) Time averaged phase-coherence order parameter (R) of controlled (purple) and uncontrolled (green) networks under different noise conditions (σ = 0.5 - triangles, σ = 1.0 - circles). The proposed method (DPF) effectively synchronises the controlled oscillators already for vanishing coupling strength between them. (b.) Evolution of Kuramoto order parameter R for networks with coupling J = 2.0 and two noise conditions (σ = 0.5 - (upper), σ = 1.0 - (lower)) for controlled (purple) and uncontrolled (green) oscillators. The control induces fast transition to synchrony (R=1), while the identical uncontrolled oscillators either synchronise slower (for low noise), or become only partially synchronised (for strong noise). Individual lines indicate evolution of the order parameter in 20 realisations of the network starting from same initial conditions and from a single computation of the required controls for each setting (where relevant). Dotted black lines denote the mean over the 20 realisations. a
a Further parameters: particle number N = 2000, inducing point number: M = 80, natural frequencies: ωi = 0, initial condition: θi ∼ N (3, 0.52) , T = 1.5.

Figure 8b. For stronger couplings desynchronisation was less pronounced, yet still more frequent than in their controlled counterparts.
For K = 6 interacting heterogeneous oscillators and for network charachteristics (coupling strength J = 1. and noise amplitude σ = 1.0) that render the uncontrolled system only partially synchronisable (Figure 9 b.(lower)), state feedback control delivered by DPF successfully drove the oscillators to a fully synchronised state (Figure 9 b.(upper)). As indicated by the evolution of the Kuramoto order parameter for each of the 20 realisations shown in Figure 9 b., our framework not only delivered sufﬁcient controls to rapidly synchronise the oscillators, but also provided the necessary interventions to maintain the phase synchronisation (Figure 9 c.). In fact, as indicated by the non-ﬂuctuating order parameter R for most realisations, only 2 network instances underwent spontaneous noise-induced desynchronisations late in the simulations, which nevertheless were partially recovered.
Similar to the smaller network, the six oscillator network was successfully synchronised for a range of coupling strengths (Figure 10a.) and for both noise conditions. Com-

pared to the identical uncontrolled networks, the networks controlled by DPF exhibited consistently larger order parameter values. Although some networks underwent spontaneous desynchronisations, these were quickly efﬁciently recovered (Figure 10b.).
DISCUSSION
In this work, we introduced a novel methodological framework for identifying optimal dynamical interventions for constraining diffusive systems. Distinctively from previous work [26, 27, 44, 78] that devises optimal control protocols by employing iterative optimisation procedures, here, we obtained the required interventions in a deterministic and noniterative way. In particular, we showed that splitting the time-resolved constraining information into retrospective and prospective parts, allows for a representation of the optimal interventions in terms of the difference of logarithmic gradients (scores) of two forward probability ﬂows. By introducing statistical estimators for the logarithmic gradients of the

12

a.

b.

FIG. 8. Onset of synchronisation and percentage of time in synchronised state after synchrony onset reveal the effectiveness of
deterministic particle ﬂow control to induce robust synchronisation on a network of K = 2 oscillators . (a.) Onset of synchronisation for controlled (purple) and uncontrolled (green) networks quantiﬁed as the ﬁrst time tsyn the phase-coherence order parameter exceeds R ≥ 0.99 and remains over that value for duration τ s = 20 × dt = 0.02 time units. Grey annotations denote the percentage of the examined networks that reached the synchronous state for duration τ s. Absence of annotation indicates that all examined networks reached synchrony. (b.) Percentage of simulation time the networks spontaneously spent in synchronised state (R ≥ 0.99) after synchrony onset tsyn. Both ﬁgures consider two different noise conditions (σ = 0.5 - triangles, σ = 1.0 - circles). a
a Further parameters: particle number N = 2000, inducing point number: M = 80, T = 1.5. For each noise condition dots denote average over 3 control
computations with different initial conditions with 20 controlled trajectories for each (60 total controlled trajectories for each point).

empirical probability densities, and by employing novel advances for deterministic evolution of sample based probability ﬂows [52, 66], we proposed an efﬁcient, non-parametric approximation of the optimal controls.
We demonstrated the feasibility and potential of our framework on a battery of diverse biologically inspired systems and challenging settings of increasing complexity and dimensionality. More precisely, we employed the proposed deterministic particle ﬂow control (DPF) to induce switches between stable states on multi-stable systems (Section E), to devise artiﬁcial selection protocols on phenotypic landscapes by implementing constraints for co-varying phenotypes (Section F), and to induce synchronisation on networks of stochastic phase oscillators.
We compared our approach against the recently proposed Path integral cross entropy method [44], which approximates time dependent controls by an iterative optimisation based on stochastic path sampling. Our results suggest that our oneshot, deterministic framework is on par with the iterative path integral cross entropy method in terms of control efﬁciency, and more precise and accurate in terms of deviation from terminal target states.
Moreover, through the nonparametric estimation of the logarithmic gradients, our method is inherently model agnostic, being able, in principle, to approximate the logarithmic gradi-

ent of arbitrary distributions, and therefore estimate external interventions of arbitrary functional form. In turn, the path integral cross entropy method requires an a priori selection of the number of basis functions employed in the approximation, implicitly constraining the class of control functions that may be implemented. In fact, inappropriate choice of basis function parameters results in numerical instabilities in the form of non converging matrix inversions and diverging trajectories during the optimisation, before the algorithm converges to an optimum. We found that this effect could not be mitigated by adjusting the learning rate or other parameters to smaller values. The trade off, however, pertains the nature of our approximation, which as a kernel method, is more expensive compared to basis functions during the actual evaluation of the identiﬁed controls.
In this work, we propagated probability densities by employing recent advances for solving Fokker–Planck equations in terms of deterministic particle dynamics. However, in principle, any particle ﬁltering algorithm employing stochastic particle dynamics may be combined with the logarithmic gradient density estimator to obtain a numerical approximation of the time-reversed drift of Eq. (19) at each time step. Numerical experiments of such a method showed, that the stochastic ﬂuctuations of the particles lead to fairly noisy control estimates over time. Hence, here, taking advantage of the fact that

a.

c.

b.

d.

FIG. 9. Synchronisation control of a ﬁnite-size network of K = 6 interacting Kuramoto phase oscillators. (a.) Evolution of phases θ of a controlled network, and (b.) an identical uncontrolled network. The phases of the oscillators quickly synchronise when controlled by DPF and remain synchronised throughout the entire simulation interval [0, T = 0.5]. In the absence of control the phases of the oscillators become increasingly incoherent. (c.) Evolution of Kuramoto order parameter capturing phase coherence R for the controlled (purple) oscillator network indicates a rapid transition to complete synchrony (R = 1) for all 20 realisations (individual purple lines). The order parameter of identical uncontrolled networks ﬂuctuates strongly indicating partial incoherence (green). The orange line denotes the expected long time average value of the order parameter if the oscillators were non-interacting considering ﬁnite size scaling effects. For visual clarity, the grey line marks the level of R = 1 indicating a completely synchronous state. (d.) Control energy spent on all K = 6 oscillators for a single control realisation.a
a Further parameters: coupling strength J = 1., noise amplitude σ = 1, particle number N = 3000, inducing point number M = 300, discretisation time step dt = 10−3, T = 0.5.
the deterministic sampling framework of [52] already employs the logarithmic gradient estimator as a building block, we integrated this method into the computation of the optimal interventions.
Although the representation of constrained densities with particles is computationally more efﬁcient compared to solutions of discretised PDEs, control representations for regions of the state space where the particles do not provide sufﬁcient evidence for the underlying density, will be inaccurate. While the probability density functions for the regions of the state space unoccupied by particles are expected to have vanishing values, with inadequate number of particles, the estimated logarithmic gradient of the related densities might be inaccurate in those regions. Yet, due to the deterministic nature of our approach, our framework provides better representation of the underlying densities compared to a pure stochastic path sampling.
We expressed the optimal interventions as a time and space dependent perturbation of the uncontrolled dynamics that are obtained from the logarithmic gradient of a backward

13
PDE. This formulation results from linearising the HamiltonJacobi-Bellman equation (Supplementary Information). An equivalent formulation for optimal drift adjustment for constraining diffusion processes has been derived in the ﬁeld of statistical mechanics by applying the Doob’s h-transform [22, 64, 79–81]. This formulation agrees with the one employed here in the absence of path constraints. In that case, the optimal interventions may be obtained from the logarithmic gradient of the solution of the backward Kolmogorov equation. However, the solution of the backward Kolmogorov equation is known in closed form only for trivial systems, may be cumbersome to obtain for general multidimensional systems, while the ensuing computation of the logarithmic gradient of the solution may run into numerical instabilities . Here, by representing the densities with particles, and by directly estimating the logarithmic gradients of the particle density, we provided an efﬁcient and feasible solution for obtaining the necessary drift adjustments.
The present work proposes a method for controlling stochastic systems by manipulating their dynamical variables. However, often such a scenario might be insufﬁcient. Interventions in biological systems may have limited access to the the system’s state variables, or only system parameters might be accessible for control. In these settings, an extension of the path integral control framework that additionally considers the system parameters is required. Existing methods that consider parameter optimisation are limited to properly function only in weak noise settings [27] due to large deviations arguments employed in their derivation.
We successfully employed the proposed method for synchronisation control of networks of coupled stochastic Kuramoto oscillators. However, when path constraints are required, the DPF solves an optimal transport problem at every time step to implement the path constraints as a deterministic particle resampling. This computation employs the Earth Mover’s distance (EMD) for an ensemble of N particles, which scales rather unfavorably for increasing particle number as O(N 3 log N ). Here, for the networked systems that required large number of particles, we employed an alternative solution for computing the EMD, the network simplex solver [82, 83], which has computational complexity that scales as O(N 2), providing thereby a considerable speedup in the calculations. Yet, we still consider this necessary particle shifting a computational bottleneck for our framework. Future developments will focus on incorporating this step into the forward particle dynamics and thus will scale more favourably with particle number, enabling thereby the control of systems of higher dimensionality.
Moreover, considering the topic of network synchronisation, we considered out of the scope of the present paper to explore the possibility of controlling only a subset of network nodes. Previous attempts to solve the same problem in a stochastic setting have considered only the synchronisation of two coupled identical Kuramoto oscillators [84], while, here, we considered networks up to six oscillators with differing natural frequencies. Insights from network control theory for nonlinear systems coupled with the proposed framework may provide a more control-energy efﬁcient approach

14

a.

b.

FIG. 10. Synchronisation control of a network of six heterogeneous Kuramoto phase oscillators for different coupling strengths. (a.) Time averaged phase-coherence order parameter (R) of controlled (purple) and uncontrolled (green) networks under different noise conditions (σ = 1.0 - triangles, σ = 1.5 - circles). The proposed method (DPF) effectively synchronises the controlled oscillators already for weak coupling. (b.) Evolution of Kuramoto order parameter R for networks with coupling J = 3.0 and two noise conditions (σ = 1.0 - (upper), σ = 1.5 - (lower)) for controlled (purple) and uncontrolled (green) oscillators. The control induces fast transition to synchrony (R = 1), while the identical uncontrolled oscillators either synchronise slower (for low noise), or become only partially synchronised (for strong noise). Individual lines indicate evolution of the order parameter in 20 realisations of the network starting from same initial conditions and from a single computation of the required controls for each setting (where relevant). Dotted black lines denote the mean over the 20 realisations. a
a Further parameters: particle number N = 3000, inducing point number: M = 300, natural frequencies: ωi = 0, initial condition: θi ∼ N (3, 0.52), natural frequencies: ωi ∼ N (0, 1), T =0.5. Each point in (a.) denotes the mean over 20 realisations of a single control computation.

for network synchronisation. Additionally, further systematic studies that will explore various network topologies, coupling schemes, and intrinsic parameter heterogeneities, will provide additional insight on the properties of our method to induce robust synchronisation to networks of interacting stochastic phase oscillators.
The proposed framework is further relevant for several computational or applied settings, where marginal densities of constrained diffusive systems are required, i.e. for state estimation of such systems between two successive state observations, or for computing the transition probabilities in extreme event calculations. In those settings, only the constrained path distribution qt(x) is required instead of the precise dynamical interventions. Although not explicitly demonstrated here, DPF is also applicable for computing averages over constrained densities or functionals over constrained paths. Since the reverse time sampled ﬂow q˜t(x) already provides a good representation of the constrained density, averages over functions evaluated on the paths of qt(x) already provide accurate estimates of the computed quantities.
More broadly, the ﬁeld of simulation based inference [85, 86] has developed dramatically in the past years due to ex-

panding computational capacities offered by current computing devises able to simulate models considered demanding in the past. These methods perform inference for models with intractable likelihoods (like sparsely observed stochastic systems) requiring frameworks for accurate and efﬁcient simulation of detailed dynamical models that provide dynamical trajectories of candidate models to perform inference. Thereby, our approach, by providing direct samplings of dynamically constrained diffusion processes will enable efﬁcient inference of such systems.
We employed the proposed framework on a prototypical scenario of devising artiﬁcial selection protocols for molecular phenotypes inspired by [28]. The nascent ﬁeld of continuous culturing [87, 88] for studying adaptive evolution has created a growing demand for devising efﬁcient and precise stochastic control frameworks that may be integrated in advanced open-source continuous culturing platforms like eVOLVER [29] to manipulate and control cell culture growth and phenotyping. These platforms enable real time monitoring of cell cultures and administer exact custom perturbations in the form of selection pressures, or by adjusting the constant nutrient feed input to the culture. By providing accurate in-

terventions that implement arbitrary state constraints the proposed DPF control is suitable to be integrated in such a platform.
The clearest advantage of our framework is its noniterative, non-parametric, and deterministic nature, providing

15
thereby computational advantages compared to existing control methods [44, 89]. Moreover, the proposed formulation for the optimal interventions generalises beyond particle systems and may be easily implemented by neural networks.

[1] Jonathan M Raser and Erin K O’shea. Noise in gene expression: origins, consequences, and control. Science, 309(5743):2010– 2013, 2005.
[2] Peter S Swain, Michael B Elowitz, and Eric D Siggia. Intrinsic and extrinsic contributions to stochasticity in gene expression. Proceedings of the National Academy of Sciences, 99(20): 12795–12800, 2002.
[3] Jeff Hasty, Joel Pradines, Milos Dolnik, and James J Collins. Noise-based switches and ampliﬁers for gene expression. Proceedings of the National Academy of Sciences, 97(5):2075– 2080, 2000.
[4] Thomas B Kepler and Timothy C Elston. Stochasticity in transcriptional regulation: origins, consequences, and mathematical representations. Biophysical journal, 81(6):3116–3136, 2001.
[5] Jordi Garc´ıa-Ojalvo and Jose´ Sancho. Noise in spatially extended systems. Springer Science & Business Media, 2012.
[6] Avigdor Eldar and Michael B Elowitz. Functional roles for noise in genetic circuits. Nature, 467(7312):167–173, 2010.
[7] Michael L Simpson, Chris D Cox, Michael S Allen, James M McCollum, Roy D Dar, David K Karig, and John F Cooke. Noise in biological circuits. Wiley Interdisciplinary Reviews: Nanomedicine and Nanobiotechnology, 1(2):214–225, 2009.
[8] William J Blake, Mads Kærn, Charles R Cantor, and James J Collins. Noise in eukaryotic gene expression. Nature, 422 (6932):633–637, 2003.
[9] Werner Horsthemke. Noise induced transitions. In Nonequilibrium dynamics in chemical systems, pages 150–160. Springer, 1984.
[10] Tianshou Zhou, Luonan Chen, and Kazuyuki Aihara. Molecular communication through stochastic synchronization induced by extracellular ﬂuctuations. Physical Review Letters, 95(17): 178103, 2005.
[11] Domitilla Del Vecchio, Aaron J Dy, and Yili Qian. Control theory meets synthetic biology. Journal of The Royal Society Interface, 13(120):20160380, 2016.
[12] Phuc Nguyen, Nicholas A Pease, and Hao Yuan Kueh. Scalable control of developmental timetables by epigenetic switching networks. Journal of the Royal Society Interface, 18(180): 20210109, 2021.
[13] David A Sivak and Gavin E Crooks. Thermodynamic metrics and optimal paths. Physical Review Letters, 108(19):190602, 2012.
[14] Patrick R Zulkowski, David A Sivak, Gavin E Crooks, and Michael R DeWeese. Geometry of thermodynamic control. Physical Review E, 86(4):041148, 2012.
[15] Alex Gomez-Marin, Tim Schmiedl, and Udo Seifert. Optimal protocols for minimal work processes in underdamped stochastic thermodynamics. The Journal of chemical physics, 129(2): 024114, 2008.
[16] Herschel Rabitz, Regina de Vivie-Riedle, Marcus Motzkus, and Karl Kompa. Whither the future of controlling quantum phenomena? Science, 288(5467):824–828, 2000.
[17] Alexander N Pechen and David J Tannor. Are there traps in quantum control landscapes? Physical Review Letters, 106(12):

120402, 2011. [18] DA Hendrix and C Jarzynski. A “fast growth” method of
computing free energy differences. The Journal of Chemical Physics, 114(14):5974–5981, 2001. [19] Michael R Shirts, Eric Bair, Giles Hooker, and Vijay S Pande. Equilibrium free energies from nonequilibrium measurements using maximum-likelihood methods. Physical Review Letters, 91(14):140601, 2003. [20] Tim Schmiedl and Udo Seifert. Optimal ﬁnite-time processes in stochastic thermodynamics. Physical Review Letters, 98(10): 108301, 2007. [21] Carsten Hartmann and Christof Schu¨tte. Efﬁcient rare event simulation by optimal nonequilibrium forcing. Journal of Statistical Mechanics: Theory and Experiment, 2012(11):P11004, 2012. [22] Raphae¨l Chetrite and Hugo Touchette. Variational and optimal control representations of conditioned and driven processes. Journal of Statistical Mechanics: Theory and Experiment, 2015 (12):P12001, 2015. [23] Jin Won Kim and Prashant G Mehta. An optimal control derivation of nonlinear smoothing equations. In Proceedings of the Workshop on Dynamics, Optimization and Computation held in honor of the 60th birthday of Michael Dellnitz, pages 295–311. Springer, 2020. [24] Jose Casadiego, Dimitra Maoutsa, and Marc Timme. Inferring network connectivity from event timing patterns. Physical review letters, 121(5):054101, 2018. [25] Emanuel Todorov. Efﬁcient computation of optimal actions. Proceedings of the National Academy of Sciences of the United States of America, 106(28):11478–11483, 2009. [26] Hilbert J Kappen. Linear theory for control of nonlinear stochastic systems. Physical Review Letters, 95(20):200201, 2005. [27] Daniel K Wells, William L Kath, and Adilson E Motter. Control of stochastic and induced switching in biophysical networks. Physical Review X, 5(3):031036, 2015. [28] Armita Nourmohammad and Ceyhun Eksin. Optimal evolutionary control for artiﬁcial selection on molecular phenotypes. Physical Review X, 11(1):011044, 2021. [29] Ziwei Zhong, Brandon G Wong, Arjun Ravikumar, Garri A Arzumanyan, Ahmad S Khalil, and Chang C Liu. Automated continuous evolution of proteins in-vivo. ACS synthetic biology, 9(6):1270–1276, 2020. [30] Ta-Chu Kao, Mahdieh S Sadabadi, and Guillaume Hennequin. Optimal anticipatory control as a theory of motor preparation: a thalamo-cortical circuit model. Neuron, 109(9):1567–1581, 2021. [31] Alexandre Iolov, Susanne Ditlevsen, and Andre´ Longtin. Stochastic optimal control of single neuron spike trains. Journal of Neural Engineering, 11(4):046004, 2014. [32] Stephen H Scott. Optimal feedback control and the neural basis of volitional motor control. Nature Reviews Neuroscience, 5(7): 532–545, 2004. [33] Espen Bernton, Jeremy Heng, Arnaud Doucet, and Pierre E

Jacob. Schro¨dinger Bridge Samplers. arXiv preprint arXiv:1912.13170, 2019. [34] Francisco Vargas, Pierre Thodoroff, Neil D Lawrence, and Austen Lamacraft. Solving Schro¨dinger Bridges via Maximum Likelihood. arXiv preprint arXiv:2106.02081, 2021. [35] Ioannis Exarchos and Evangelos A Theodorou. Stochastic optimal control via forward and backward stochastic differential equations and importance sampling. Automatica, 87:159–165, 2018. [36] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456, 2020. [37] Richard Bellman. Dynamic programming and Lagrange multipliers. Proceedings of the National Academy of Sciences of the United States of America, 42(10):767, 1956. [38] Jochen Garcke and Axel Kro¨ner. Suboptimal feedback control of PDEs by solving HJB equations on adaptive sparse grids. Journal of Scientiﬁc Computing, 70(1):1–28, 2017. [39] Mario Annunziato and Alﬁo Borz`ı. A Fokker–Planck control framework for multidimensional stochastic processes. Journal of Computational and Applied Mathematics, 237(1):487–507, 2013. [40] Matanya B Horowitz, Anil Damle, and Joel W Burdick. Linear Hamilton Jacobi Bellman equations in high dimensions. In 53rd IEEE Conference on Decision and Control, pages 5880–5887. IEEE, 2014. [41] Hilbert J Kappen. Path integrals and symmetry breaking for optimal control theory. Journal of statistical mechanics: theory and experiment, 2005(11):P11011, 2005. [42] Bart Van Den Broek, Wim Wiegerinck, and Bert Kappen. Graphical model inference in optimal control of stochastic multi-agent systems. Journal of Artiﬁcial Intelligence Research, 32:95–122, 2008. [43] Konrad Rawlik, Marc Toussaint, and Sethu Vijayakumar. Path integral control by reproducing kernel Hilbert space embedding. In Twenty-Third International Joint Conference on Artiﬁcial Intelligence, 2013. [44] Hilbert Johan Kappen and Hans Christian Ruiz. Adaptive importance sampling for control and inference. Journal of Statistical Physics, 162(5):1244–1266, 2016. [45] Wei Zhang, Han Wang, Carsten Hartmann, Marcus Weber, and Christof Schuette. Applications of the cross-entropy method to importance sampling and optimal control of diffusions. SIAM Journal on Scientiﬁc Computing, 36(6):A2654–A2672, 2014. [46] Evangelos Theodorou, Freek Stulp, Jonas Buchli, and Stefan Schaal. An iterative path integral stochastic optimal control approach for learning robotic tasks. IFAC Proceedings Volumes, 44(1):11594–11601, 2011. [47] Sep Thijssen and HJ Kappen. Path integral control and statedependent feedback. Physical Review E, 91(3):032104, 2015. [48] Emanuel Todorov. General duality between optimal control and estimation. In 2008 47th IEEE Conference on Decision and Control, pages 4286–4292. IEEE, 2008. [49] Hilbert J Kappen, Vicenc¸ Go´mez, and Manfred Opper. Optimal control as a graphical model inference problem. Machine Learning, 87(2):159–182, 2012. [50] Sergey Levine. Reinforcement learning and control as probabilistic inference: Tutorial and review. arXiv preprint arXiv:1805.00909, 2018. [51] Hagai Attias. Planning by probabilistic inference. In International Workshop on Artiﬁcial Intelligence and Statistics, pages 9–16. PMLR, 2003. [52] Dimitra Maoutsa, Sebastian Reich, and Manfred Opper. In-

16
teracting particle solutions of Fokker–Planck equations through gradient–log–density estimation. Entropy, 22(8):802, 2020. [53] Brian DO Anderson. Reverse-time diffusion equation models. Stochastic Processes and their Applications, 12(3):313– 326, 1982. [54] Daniel T Gillespie and Linda R Petzold. Improved leap-size selection for accelerated stochastic simulation. The Journal of Chemical Physics, 119(16):8229–8234, 2003. [55] Antti Saarinen, Marja-Leena Linne, and Olli Yli-Harja. Stochastic differential equation model for cerebellar granule cell excitability. PLoS Computational Biology, 4(2):e1000004, 2008. [56] Russell Lande, Steinar Engen, Bernt-Erik Saether, et al. Stochastic population dynamics in ecology and conservation. Oxford University Press on Demand, 2003. [57] Naoyuki Takahata, Kazushige Ishii, and Hirotsugu Matsuda. Effect of temporal ﬂuctuation of selection coefﬁcient on gene frequency in a population. Proceedings of the National Academy of Sciences, 72(11):4541–4545, 1975. [58] Emanuel Todorov. Stochastic optimal control and estimation methods adapted to the noise characteristics of the sensorimotor system. Neural computation, 17(5):1084–1108, 2005. [59] Emanuel Todorov. Optimality principles in sensorimotor control. Nature neuroscience, 7(9):907–915, 2004. [60] Emanuel Todorov. Linearly-solvable Markov decision problems. In Advances in neural information processing systems, pages 1369–1376, 2007. [61] Wendell H Fleming. Exit probabilities and optimal stochastic control. Applied Mathematics and Optimization, 4(1):329–346, 1977. [62] Nicolas Macris and Raffaele Marino. Solving non-linear Kolmogorov equations in large dimensions by using deep learning: a numerical comparison of discretization schemes. arXiv preprint arXiv:2012.07747, 2020. [63] Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew Stuart, and Anima Anandkumar. Fourier neural operator for parametric partial differential equations. International Conference on Learning Representations, 2020. [64] Satya N Majumdar and Henri Orland. Effective Langevin equations for constrained stochastic processes. Journal of Statistical Mechanics: Theory and Experiment, 2015(6):P06039, 2015. [65] Note1. In the second equality, we considered that for small δt the commutator of the two operators Lf and U (x, t) is negligible. [66] Sebastian Reich. A nonparametric ensemble transform method for Bayesian inference. SIAM Journal on Scientiﬁc Computing, 35(4):A2013–A2024, 2013. [67] Valentin De Bortoli, James Thornton, Jeremy Heng, and Arnaud Doucet. Diffusion Schr\” odinger Bridge with Applications to Score-Based Generative Modeling. arXiv preprint arXiv:2106.01357, 2021. [68] Crispin W.. Gardiner. Stochastic Methods: A Handbook for the Natural and Social Sciences. Springer., 2009. [69] Ce´dric Villani. Optimal transport: old and new, volume 338. Springer, 2009. [70] Sui Huang, Yan-Ping Guo, Gillian May, and Tariq Enver. Bifurcation dynamics in lineage-commitment in bipotent progenitor cells. Developmental Biology, 305(2):695–713, 2007. [71] Russell Lande. Natural selection and random genetic drift in phenotypic evolution. Evolution, pages 314–334, 1976. [72] Ronald Aylmer Fisher. The genetical theory of natural selection. The Clarendon Press, 1930. [73] Joel G Kingsolver, Hopi E Hoekstra, Jon M Hoekstra, David

Berrigan, Sacha N Vignieri, CE Hill, Anhthu Hoang, Patricia Gibert, and Peter Beerli. The strength of phenotypic selection in natural populations. The American Naturalist, 157(3):245– 261, 2001. [74] N.H. Barton, D.E. Briggs, J.A. Eisen, D.B. Goldstein, and N.H. Patel. Evolution. Cold Spring Harbor Laboratory Series. Cold Spring Harbor Laboratory Press, 2007. ISBN 9780879696849. URL https://books.google.de/ books?id=mMDFQ32oMI8C. [75] Michael C Whitlock. Variance-induced peak shifts. Evolution, 49(2):252–259, 1995. [76] Armita Nourmohammad, Stephan Schiffels, and Michael La¨ssig. Evolution of molecular phenotypes under stabilizing selection. Journal of Statistical Mechanics: Theory and Experiment, 2013(01):P01012, 2013. [77] Torsten Held, Armita Nourmohammad, and Michael La¨ssig. Adaptive evolution of molecular phenotypes. Journal of Statistical Mechanics: Theory and Experiment, 2014(9):P09029, 2014. [78] Nikolas Nu¨sken and Lorenz Richter. Solving high-dimensional Hamilton–Jacobi–Bellman PDEs using neural networks: perspectives from the theory of controlled diffusions and measures on path space. Partial Differential Equations and Applications, 2(4):1–48, 2021. [79] Henri Orland. Generating transition paths by Langevin bridges. The Journal of chemical physics, 134(17):174114, 2011. [80] Alain Mazzolo. Constrained Brownian processes and constrained Brownian bridges. Journal of Statistical Mechanics: Theory and Experiment, 2017(2):023203, 2017. [81] Juraj Szavits-Nossan and Martin R Evans. Inequivalence of nonequilibrium path ensembles: the example of stochastic bridges. Journal of Statistical Mechanics: Theory and Experiment, 2015(12):P12008, 2015.

17
[82] Nicolas Bonneel, Michiel Van De Panne, Sylvain Paris, and Wolfgang Heidrich. Displacement interpolation using lagrangian mass transport. In Proceedings of the 2011 SIGGRAPH Asia Conference, pages 1–12, 2011.
[83] Re´mi Flamary, Nicolas Courty, Alexandre Gramfort, Mokhtar Zahdi Alaya, Aure´lie Boisbunon, Stanislas Chambon, Laetitia Chapel, Adrien Corenﬂos, Kilian Fatras, Nemo Fournier, et al. POT: Python optimal transport. Journal of Machine Learning Research, 22(78):1–8, 2021.
[84] Jr-Shin Li, Wei Zhang, and Shuo Wang. Optimal Control and Stochastic Synchronization of Phase Oscillators. IFACPapersOnLine, 48(18):83–88, 2015.
[85] Johann Brehmer. Simulation-based inference in particle physics. Nature Reviews Physics, 3(5):305–305, 2021.
[86] Kyle Cranmer, Johann Brehmer, and Gilles Louppe. The frontier of simulation-based inference. Proceedings of the National Academy of Sciences of the United States of America, 117(48): 30055–30062, 2020.
[87] Uri Alon. An introduction to systems biology: design principles of biological circuits. CRC press, 2019.
[88] David Gresham and Maitreya J Dunham. The enduring utility of continuous culturing in experimental evolution. Genomics, 104(6):399–405, 2014.
[89] Martin Hairer, Andrew M Stuart, and Jochen Voss. Sampling conditioned diffusions. Trends in stochastic analysis, 353:159– 186, 2009. ACKNOWLEDGMENTS
We thank Sebastian Reich for insightful discussions during the early development of this work. This research has been partially funded by Deutsche Forschungsgemeinschaft (DFG)-SFB1294/ 1-318763901.

