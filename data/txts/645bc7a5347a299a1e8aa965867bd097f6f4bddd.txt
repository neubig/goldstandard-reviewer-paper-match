RMM: A Recursive Mental Model for Dialogue Navigation

Homero Roman Roman1 Yonatan Bisk1,2 Jesse Thomason3 Asli Celikyilmaz1 Jianfeng Gao1 1Microsoft Research 2Carnegie Mellon University 3University of Washington

horomanr@microsoft.com

ybisk@cs.cmu.edu

arXiv:2005.00728v2 [cs.CL] 6 Oct 2020

Abstract
Language-guided robots must be able to both ask humans questions and understand answers. Much existing work focuses only on the latter. In this paper, we go beyond instruction following and introduce a two-agent task where one agent navigates and asks questions that a second, guiding agent answers. Inspired by theory of mind, we propose the Recursive Mental Model (RMM). The navigating agent models the guiding agent to simulate answers given candidate generated questions. The guiding agent in turn models the navigating agent to simulate navigation steps it would take to generate answers. We use the progress agents make towards the goal as a reinforcement learning reward signal to directly inform not only navigation actions, but also both question and answer generation. We demonstrate that RMM enables better generalization to novel environments. Interlocutor modelling may be a way forward for human-agent dialogue where robots need to both ask and answer questions.
1 Introduction
A key challenge for embodied language is moving beyond instruction following to instruction generation, which can require understanding the listener. The turn-based dialogue paradigm raises a myriad of new research questions, from grounded versions of traditional problems like co-reference resolution (Das et al., 2017a) to explicitly modeling theory of mind in order to consider the listener’s ability to understand generated instructions (Bisk et al., 2020). In this paper, we develop end-to-end dialogue agents to navigate photorealistic, indoor scenes to reach goal rooms. We train agents using the human-human Collaborative Vision-andDialogue Navigation (CVDN) (Thomason et al., 2019) dataset. CVDN dialogues are turn-based, with a navigator following guide instructions and asking questions when needed.

Should I head forward?

RMM’

Yes, all the way down the hall

RMM’’

Should I turn left here?

…

Humans RMM
Baseline

RMM

Figure 1: The RMM agent recursively models conversations with instances of itself to choose the right questions to ask (and answers to give) to reach the goal.
Modeling turn-based dialogues involves four core challenges: C1 A navigator deciding when to ask a question. C2 Generating navigator questions. C3 Generating guide question answers. C4 Generating navigator actions.
Prior work has addressed individual components of turn-based dialogue modeling. This work is the ﬁrst to train navigator and guide agents to perform end-to-end, collaborative dialogues with question generation (C2), question answering (C3), and navigation (C4) conditioned on dialogue history.
Theory of mind (Gopnik and Wellman, 1992) posits that efﬁcient questions and answers build on a shared world of experiences and referents. To communicate efﬁciently, people model both a listener’s mental state and the effects of their actions on the world. Modeling future worlds in navigation (Anderson et al., 2019) and control (Paxton et al., 2019) are open research questions, and we approximate solutions through a Recursive Mental Model (RMM) of a conversational partner. Our agent spawns instances of itself to simulate the ef-

fects of dialogue acts before asking a question or generating an answer to estimate their effects on navigation. Viewed as a single system, the agents cooperatively search through the space of dialogues to efﬁciently perform embodied navigation.
2 Related Work and Background
We build on research in multimodal navigation and the wider literature involving goal oriented dialogue. Table 1 summarizes how our work differs from existing work in vision-and-language navigation and task-oriented dialogue modelling.
Instruction Following tasks an embodied agent with interpreting natural language instructions and visual observations to reach a goal (Jayannavar et al., 2020; Wang et al., 2019; Ma et al., 2019; Anderson et al., 2018; Chen and Mooney, 2011). These instructions describe step-by-step actions the agent needs to take, and can involve the creation of speaker models for data augmentation that provide additional instructions (Fried et al., 2018). This paradigm has been extended to longer trajectories and outdoor environments (Chen et al., 2019), as well as to agents in the real world (Chai et al., 2018; Tellex et al., 2014). In this work, we focus on the the simulated, photorealistic indoor environments of the MatterPort dataset (Chang et al., 2017), and go beyond instruction following alone to a twoagent dialogue setting.
Navigation Dialogues task a navigator and a guide to cooperate to ﬁnd a destination. Previous work includes substantial information asymmetry between the navigator and guide (de Vries et al., 2018; Narayan-Chen et al., 2019). Information asymmetry can take the form of the navigator seeing a bird’s eye, abstract semantic map while the guide sees egocentric simulation frames (de Vries et al., 2018), affecting the kind of dialog possible when low-level visual cues cannot be grounded by the navigator. Other work only investigates the navigation portion of the dialogue without considering text question generation and answering (Thomason et al., 2019). Going beyond models that perform navigation from dialogue history alone (Wang et al., 2020; Zhu et al., 2020; Hao et al., 2020), or decide when to ask navigator questions but do so as a simple “help” ﬂag with oracle responses (Chi et al., 2020; Nguyen et al., 2019), in this work we train two agents: a navigator agent that asks questions, and a guide agent that answers those questions.

Representative Work
Anderson et al. (2018) Fried et al. (2018) Narayan-Chen et al. (2019) Nguyen and Daume´ III (2019) Chi et al. (2020) Thomason et al. (2019)
RMM

C1 C2 C3 C4



















Table 1: Previous work has addressed subsets of the four key challenges for turn-based navigation dialogues by training single-turn agents. No prior work has tackled generating navigator questions (C2); by doing so, our work becomes the ﬁrst to train two agents jointly on multi-turn dialogues where agents both produce and consume task-relevant language. We eschew only the challenge of deciding when to ask questions (C1), using a ﬁxed heuristic instead.

Multimodal Dialogue takes several forms. In Visual Dialogue (Das et al., 2017a), an agent answers a series of questions about an image that may require dialogue context. Reinforcement learning gives strong performance on this task (Das et al., 2017b), and such paradigms have been extended to producing multi-domain visual dialogue agents (Ju et al., 2019). GuessWhat (de Vries et al., 2017) presents a similar paradigm, where agents use visual properties of objects to reason about which referent meets various constraints. Identifying visual attributes can also lead to emergent communication between pairs of learning agents (Cao et al., 2018).
Goal Oriented Dialogue systems can help a user achieve a predeﬁned goal, from booking ﬂights to learning kitchen tasks (Gao et al., 2019; Vlad Serban et al., 2015; Bordes and Weston, 2017; Chai et al., 2018). Modeling goal-oriented dialogue requires skills that go beyond language modeling, such as asking questions to clearly deﬁne a user request, querying knowledge bases, and interpreting results from queries as options to complete a transaction. Many recent task oriented systems are data-driven and trained end-to-end using semisupervised or transfer learning methods (Ham et al., 2020; Mrksic et al., 2017). However, these datadriven approaches may lack grounding between the text and the environment state. Reinforcement learning-based dialogue modeling (Su et al., 2016; Peng et al., 2017; Liu et al., 2017) can improve completion rate and user experience by helping ground conversational data to environments.

3 Task and Data
Our work creates a two-agent dialogue task, building on the CVDN dataset (Thomason et al., 2019) of human-human dialogues. In that dataset, a human N avigator and Guide collaborate to ﬁnd a goal room containing a target object. The N avigator moves through the environment, and the Guide views this navigation until the N avigator asks a question in natural language (C1, C2). Then, the Guide can see the next few steps a shortest path planner would take towards the goal, and produces a natural language response (C3). Dialogue continues until the N avigator arrives at the goal (C4). We model this dialogue between two agents:
1. Questioner (Q) & Navigator (N ) 2. Guide (G) We split the ﬁrst agent into its two roles: question asking (C2) and navigation (C4). As input, the agents receive the same data as their human counterparts in CVDN. Speciﬁcally, both agents (and all three roles) have access to the entire dialogue and visual navigation histories, in addition to a textual description of the target object (e.g., a plant). The N avigator uses this information to execute on a sequence of actions composed of: forward, left, right, look up, look down, and stop. The Questioner asks for speciﬁc guidance from the Guide. The Guide is presented with the navigation and dialogue histories as well as the next ﬁve shortest path steps to the goal, given as a sequence of image observations those steps produce. Agents are trained on human-human dialogues of natural language questions and answers from CVDN. Individual question-answer exchanges in that dataset are underspeciﬁed and rarely provide simple step-by-step instructions like “straight, straight, right, ...”. Instead, exchanges rely on assumptions of world knowledge and shared context (Frank and Goodman, 2012; Grice et al., 1975), which manifest as instructions rich with visuallinguistic co-references such as should I go back to the room I just passed or continue on?
The CVDN release does not provide any baselines or evaluations for the interactive dialogue setting we present, and instead focuses solely on navigation (C4). We use the same metric as that work, “Goal Progress” in meters—the distance reduction between the N avigator’s starting position and ending position with respect to the goal location.
Dialogue navigation proceeds by iterating through the three roles until either the N avigator

Algorithm 1: Dialogue Navigation

loc = p0;

hist = t0;

a ∼ N (hist);

loc, hist = update(a, loc, hist);

while a = STOP and len(hist) < 20 do

q ∼ Q(hist, loc) ;

// Question

s = path(loc, goal, horizon = 5) ;

o ∼ O(hist, loc, q, s) ;

// Answer

hist ← hist + (q, o);

for a ∈ N (hist) do

loc ← loc + a ;

// Move

hist ← hist + a;

end

end

return (goal − t0) − (loc − t0)

chooses to stop or a maximum number of turns are played (Algorithm 1). In addition to “Goal Progress”, we report BLEU scores (Papineni et al., 2002) for evaluating the generation of questions and answers by comparing against human questions and answers. Note, in our dialogue setting, Goal Progress also implicitly measures the utility of generated language and is therefore complementary to BLEU when evaluating utility versus ﬂuency.
4 Models
We introduce the Recursive Mental Model (RMM) as an initial approach to our new full dialogue CVDN task formulation. Key to this approach is allowing component models (N avigator, Questioner, and Guide) to learn from each other and roll out possible dialogues and trajectories. We compare our model to a traditional sequence-to-sequence baseline, and we explore data augmentation using the Speaker-Follower method (Fried et al., 2018).
4.1 Sequence-to-Sequence Architecture
The underlying architecture, shown in Figure 2, is shared across all approaches. The core dialogue tasks are navigation action decoding and language generation for asking and answering questions. We present three sequence-to-sequence (Bahdanau et al., 2015) models to perform as N avigator, Questioner, and Guide. The models rely on an LSTM (Hochreiter and Schmidhuber, 1997) encoder for the dialogue history. To encode visual observations, our models take the penultimate ResNet (He et al., 2015) layer as the image observation. Future work may explore different and more nuanced encoding architectures.

DeDc oedceorde rd0 < l a t e x i t s h a 1 _ b a s e 6 4 = " d t r S u f l F J l p t I O t t g q n K D i F 9 F R c = " > A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R b B U 9 m t g l 6 E o h d P U s F + S L s s 2 W z a h i b Z J c k K Z e m v 8 O J B E a / + H G / + G 9 N 2 D 9 r 6 Y O D x 3 g w z 8 8 K E M 2 1 c 9 9 s p r K y u r W 8 U N 0 t b 2 z u 7 e + X 9 g 5 a O U 0 V o k 8 Q 8 V p 0 Q a 8 q Z p E 3 D D K e d R F E s Q k 7 b 4 e h m 6 r e f q N I s l g 9 m n F B f 4 I F k f U a w s d J j F L j o C g 2 D u 6 B c c a v u D G i Z e D m p Q I 5 G U P 7 q R T F J B Z W G c K x 1 1 3 M T 4 2 d Y G U Y 4 n Z R 6 q a Y J J i M 8 o F 1 L J R Z U + 9 n s 4 A k 6 s U q E + r G y J Q 2 a q b 8 n M i y 0 H o v Q d g p s h n r R m 4 r / e d 3 U 9 C / 9 j M k k N V S S + a J + y p G J 0 f R 7 F D F F i e F j S z B R z N 6 K y B A r T I z N q G R D 8 B Z f X i a t W t U 7 q 9 b u z y v 1 6 z y O I h z B M Z y C B x d Q h 1 t o Q B M I C H i G V 3 h z l P P i v D s f 8 9 a C k 8 8 c w h 8 4 n z 8 0 2 o 9 d < / l a t e x i t >

=d 0 < l a t e x i t s h a 1 _ b a s e 6 4 = " d t r S u f l F J l p t I O t t g q n K D i F 9 F R c = " > A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R b B U 9 m t g l 6 E o h d P U s F + S L s s 2 W z a h i b Z J c k K Z e m v 8 O J B E a / + H G / + G 9 N 2 D 9 r 6 Y O D x 3 g w z 8 8 K E M 2 1 c 9 9 s p r K y u r W 8 U N 0 t b 2 z u 7 e + X 9 g 5 a O U 0 V o k 8 Q 8 V p 0 Q a 8 q Z p E 3 D D K e d R F E s Q k 7 b 4 e h m 6 r e f q N I s l g 9 m n F B f 4 I F k f U a w s d J j F L j o C g 2 D u 6 B c c a v u D G i Z e D m p Q I 5 G U P 7 q R T F J B Z W G c K x 1 1 3 M T 4 2 d Y G U Y 4 n Z R 6 q a Y J J i M 8 o F 1 L J R Z U + 9 n s 4 A k 6 s U q E + r G y J Q 2 a q b 8 n M i y 0 H o v Q d g p s h n r R m 4 r / e d 3 U 9 C / 9 j M k k N V S S + a J + y p G J 0 f R 7 F D F F i e F j S z B R z N 6 K y B A r T I z N q G R D 8 B Z f X i a t W t U 7 q 9 b u z y v 1 6 z y O I h z B M Z y C B x d Q h 1 t o Q B M I C H i G V 3 h z l P P i v D s f 8 9 a C k 8 8 c w h 8 4 n z 8 0 2 o 9 d < / l a t e x i t >

= hN

hN

EnEcondceorder

ResNReetsNet

"# '# AtteAntdtend

d t < l a t e x i t s h a 1 _ b a s e 6 4 = " p f 2 I q h h B V I 4 l W / U O 7 7 w v p j q 9 e R s = " > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e i F 4 8 V 7 Q e 0 o W w 2 m 3 b p Z h N 2 J 0 I p / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k E p h 0 H W / n c L a + s b m V n G 7 t L O 7 t 3 9 Q P j x q m S T T j D d Z I h P d C a j h U i j e R I G S d 1 L N a R x I 3 g 5 G t z O / / c S 1 E Y l 6 x H H K / Z g O l I g E o 2 i l h 7 C P / X L F r b p z k F X i 5 a Q C O R r 9 8 l c v T F g W c 4 V M U m O 6 n p u i P 6 E a B Z N 8 W u p l h q e U j e i A d y 1 V N O b G n 8 x P n Z I z q 4 Q k S r Q t h W S u / p 6 Y 0 N i Y c R z Y z p j i 0 C x 7 M / E / r 5 t h d O 1 P h E o z 5 I o t F k W Z J J i Q 2 d 8 k F J o z l G N L K N P C 3 k r Y k G r K 0 K Z T s i F 4 y y + v k l a t 6 l 1 U a / e X l f p N H k c R T u A U z s G D K 6 j D H T S g C Q w G 8 A y v 8 O Z I 5 8 V 5 d z 4 W r Q U n n z m G P 3 A + f w B U E o 3 T < / l a t e x i t >

d t < l a t e x i t s h a 1 _ b a s e 6 4 = " p f 2 I q h h B V I 4 l W / U O 7 7 w v p j q 9 e R s = " > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e i F 4 8 V 7 Q e 0 o W w 2 m 3 b p Z h N 2 J 0 I p / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k E p h 0 H W / n c L a + s b m V n G 7 t L O 7 t 3 9 Q P j x q m S T T j D d Z I h P d C a j h U i j e R I G S d 1 L N a R x I 3 g 5 G t z O / / c S 1 E Y l 6 x H H K / Z g O l I g E o 2 i l h 7 C P / X L F r b p z k F X i 5 a Q C O R r 9 8 l c v T F g W c 4 V M U m O 6 n p u i P 6 E a B Z N 8 W u p l h q e U j e i A d y 1 V N O b G n 8 x P n Z I z q 4 Q k S r Q t h W S u / p 6 Y 0 N i Y c R z Y z p j i 0 C x 7 M / E / r 5 t h d O 1 P h E o z 5 I o t F k W Z J J i Q 2 d 8 k F J o z l G N L K N P C 3 k r Y k G r K 0 K Z T s i F 4 y y + v k l a t 6 l 1 U a / e X l f p N H k c R T u A U z s G D K 6 j D H T S g C Q w G 8 A y v 8 O Z I 5 8 V 5 d z 4 W r Q U n n z m G P 3 A + f w B U E o 3 T < / l a t e x i t >

I< l a t e x i t s h a 1 _ b a s e 6 4 = " m C k A j n w p s H B N 5 G V Z j Z G o + A f i 3 t o = " > A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 9 F j 0 o r e K 9 g P a U D b b T b t 0 s w m 7 E 6 G E / g Q v H h T x 6 i / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S K Q w 6 L r f z s r q 2 v r G Z m G r u L 2 z u 7 d f O j h s m j j V j D d Y L G P d D q j h U i j e Q I G S t x P N a R R I 3 g p G N 1 O / 9 c S 1 E b F 6 x H H C / Y g O l A g F o 2 i l h 7 s e 9 k p l t + L O Q J a J l 5 M y 5 K j 3 S l / d f s z S i C t k k h r T 8 d w E / Y x q F E z y S b G b G p 5 Q N q I D 3 r F U 0 Y g b P 5 u d O i G n V u m T M N a 2 F J K Z + n s i o 5 E x 4 y i w n R H F o V n 0 p u J / X i f F 8 M r P h E p S 5 I r N F 4 W p J B i T 6 d + k L z R n K M e W U K a F v Z W w I d W U o U 2 n a E P w F l 9 e J s 1 q x T u v V O 8 v y r X r P I 4 C H M M J n I E H l 1 C D W 6 h D A x g M 4 B l e 4 c 2 R z o v z 7 n z M W 1 e c f O Y I / s D 5 / A E q 8 I 2 4 < / l a t e x i t > t

PAIretcvtaiiPooArtnuecsvt1aiiootnus < l a t e x i t s h a 1 _ b a s e 6 4 = " m C k A j n w p s H B N 5 G V Z j Z G o + A f i 3 t o = " > A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 9 F j 0 o r e K 9 g P a U D b b T b t 0 s w m 7 E 6 G E / g Q v H h T x 6 i / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S K Q w 6 L r f z s r q 2 v r G Z m G r u L 2 z u 7 d f O j h s m j j V j D d Y L G P d D q j h U i j e Q I G S t x P N a R R I 3 g p G N 1 O / 9 c S 1 E b F 6 x H H C / Y g O l A g F o 2 i l h 7 s e 9 k p l t + L O Q J a J l 5 M y 5 K j 3 S l / d f s z S i C t k k h r T 8 d w E / Y x q F E z y S b G b G p 5 Q N q I D 3 r F U 0 Y g b P 5 u d O i G n V u m T M N a 2 F J K Z + n s i o 5 E x 4 y i w n R H F o V n 0 p u J / X i f F 8 M r P h E p S 5 I r N F 4 W p J B i T 6 d + k L z R n K M e W U K a F v Z W w I d W U o U 2 n a E P w F l 9 e J s 1 q x T u v V O 8 v y r X r P I 4 C H M M J n I E H l 1 C D W 6 h D A x g M 4 B l e 4 c 2 R z o v z 7 n z M W 1 e c f O Y I / s D 5 / A E q 8 I 2 4 < / l a t e x i t >

< l a t e x i t s h a 1 _ b a s e 6 4 = " 7 S 5 A J e A l b d v 4 K S t b x z M L y z u T e d I = " > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B i y W p g h 6 L X j x W s B / Q h r L Z b t q l m 0 3 Y n Q g l 9 E d 4 8 a C I V 3 + P N / + N 2 z Y H b X 0 w 8 H h v h p l 5 Q S K F Q d f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o Z e J U M 9 5 k s Y x 1 J 6 C G S 6 F 4 E w V K 3 k k 0 p 1 E g e T s Y 3 8 3 8 9 h P X R s T q E S c J 9 y M 6 V C I U j K K V 2 r S f 4 Y U 3 7 Z c r b t W d g 6 w S L y c V y N H o l 7 9 6 g 5 i l E V f I J D W m 6 7 k J + h n V K J j k 0 1 I v N T y h b E y H v G u p o h E 3 f j Y / d 0 r O r D I g Y a x t K S R z 9 f d E R i N j J l F g O y O K I 7 P s z c T / v G 6 K 4 Y 2 f C Z W k y B V b L A p T S T A m s 9 / J Q G j O U E 4 s o U w L e y t h I 6 o p Q 5 t Q y Y b g L b + 8 S l q 1 q n d Z r T 1 c V e q 3 e R x F O I F T O A c P r q E O 9 9 C A J j A Y w z O 8 w p u T O C / O u / O x a C 0 4 + c w x / I H z + Q P w d Y 9 O < / l a t e x i t >

< l a t e x i t s h a 1 _ b a s e 6 4 = " 7 S 5 A J e A l b d v 4 K S t b x z M L y z u T e d I = " > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B i y W p g h 6 L X j x W s B / Q h r L Z b t q l m 0 3 Y n Q g l 9 E d 4 8 a C I V 3 + P N / + N 2 z Y H b X 0 w 8 H h v h p l 5 Q S K F Q d f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o Z e J U M 9 5 k s Y x 1 J 6 C G S 6 F 4 E w V K 3 k k 0 p 1 E g e T s Y 3 8 3 8 9 h P X R s T q E S c J 9 y M 6 V C I U j K K V 2 r S f 4 Y U 3 7 Z c r b t W d g 6 w S L y c V y N H o l 7 9 6 g 5 i l E V f I J D W m 6 7 k J + h n V K J j k 0 1 I v N T y h b E y H v G u p o h E 3 f j Y / d 0 r O r D I g Y a x t K S R z 9 f d E R i N j J l F g O y O K I 7 P s z c T / v G 6 K 4 Y 2 f C Z W k y B V b L A p T S T A m s 9 / J Q G j O U E 4 s o U w L e y t h I 6 o p Q 5 t Q y Y b g L b + 8 S l q 1 q n d Z r T 1 c V e q 3 e R x F O I F T O A c P r q E O 9 9 C A J j A Y w z O 8 w p u T O C / O u / O x a C 0 4 + c w x / I H z + Q P w d Y 9 O < / l a t e x i t >

1

[!! […!!!…"]

d T < l a t e x i t s h a 1 _ b a s e 6 4 = " 0 p f 0 L G o k F U d C N n 2 e z 6 R B S q I m x T c = " > A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 9 F j 0 4 r F i v 6 A N Z b O Z t E s 3 m 7 C 7 E U r p T / D i Q R G v / i J v / h u 3 b Q 7 a + m D g 8 d 4 M M / O C V H B t X P f b W V v f 2 N z a L u w U d / f 2 D w 5 L R 8 c t n W S K Y Z M l I l G d g G o U X G L T c C O w k y q k c S C w H Y z u Z n 7 7 C Z X m i W y Y c Y p + T A e S R 5 x R Y 6 X H s N / o l 8 p u x Z 2 D r B I v J 2 X I U e + X v n p h w r I Y p W G C a t 3 1 3 N T 4 E 6 o M Z w K n x V 6 m M a V s R A f Y t V T S G L U / m Z 8 6 J e d W C U m U K F v S k L n 6 e 2 J C Y 6 3 H c W A 7 Y 2 q G e t m b i f 9 5 3 c x E N / 6 E y z Q z K N l i U Z Q J Y h I y + 5 u E X C E z Y m w J Z Y r b W w k b U k W Z s e k U b Q j e 8 s u r p F W t e J e V 6 s N V u X a b x 1 G A U z i D C / D g G m p w D 3 V o A o M B P M M r v D n C e X H e n Y 9 F 6 5 q T z 5 z A H z i f P y O S j b M = < / l a t e x i t >
!"]

d T < l a t e x i t s h a 1 _ b a s e 6 4 = " 0 p f 0 L G o k F U d C N n 2 e z 6 R B S q I m x T c = " > A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 9 F j 0 4 r F i v 6 A N Z b O Z t E s 3 m 7 C 7 E U r p T / D i Q R G v / i J v / h u 3 b Q 7 a + m D g 8 d 4 M M / O C V H B t X P f b W V v f 2 N z a L u w U d / f 2 D w 5 L R 8 c t n W S K Y Z M l I l G d g G o U X G L T c C O w k y q k c S C w H Y z u Z n 7 7 C Z X m i W y Y c Y p + T A e S R 5 x R Y 6 X H s N / o l 8 p u x Z 2 D r B I v J 2 X I U e + X v n p h w r I Y p W G C a t 3 1 3 N T 4 E 6 o M Z w K n x V 6 m M a V s R A f Y t V T S G L U / m Z 8 6 J e d W C U m U K F v S k L n 6 e 2 J C Y 6 3 H c W A 7 Y 2 q G e t m b i f 9 5 3 c x E N / 6 E y z Q z K N l i U Z Q J Y h I y + 5 u E X C E z Y m w J Z Y r b W w k b U k W Z s e k U b Q j e 8 s u r p F W t e J e V 6 s N V u X a b x 1 G A U z i D C / D g G m p w D 3 V o A o M B P M M r v D n C e X H e n Y 9 F 6 5 q T z 5 z A H z i f P y O S j b M = < / l a t e x i t >

hN < l a t e x i t s h a 1 _ b a s e 6 4 = " Y b t m B R l b o Z 8 I E 3 o 5 a J i e 7 3 V b Y Q Y = " > A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 9 F j 0 4 k k q 2 g 9 o Q 9 l s N + 3 S z S b s T o Q S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O y u r a + s b m 4 W t 4 v b O 7 t 5 + 6 e C w a e J U M 9 5 g s Y x 1 O 6 C G S 6 F 4 A w V K 3 k 4 0 p 1 E g e S s Y 3 U z 9 1 h P X R s T q E c c J 9 y M 6 U C I U j K K V H o a 9 u 1 6 p 7 F b c G c g y 8 X J S h h z 1 X u m r 2 4 9 Z G n G F T F J j O p 6 b o J 9 R j Y J J P i l 2 U 8 M T y k Z 0 w D u W K h p x 4 2 e z U y f k 1 C p 9 E s b a l k I y U 3 9 P Z D Q y Z h w F t j O i O D S L 3 l T 8 z + u k G F 7 5 m V B J i l y x + a I w l Q R j M v 2 b 9 I X m D O X Y E s q 0 s L c S N q S a M r T p F G 0 I 3 u L L y 6 R Z r X j n l e r 9 R b l 2 n c d R g G M 4 g T P w 4 B J q c A t 1 a A C D A T z D K 7 w 5 0 n l x 3 p 2 P e e u K k 8 8 c w R 8 4 n z 8 g k o 2 x < / l a t e x i t >

hN < l a t e x i t s h a 1 _ b a s e 6 4 = " Y b t m B R l b o Z 8 I E 3 o 5 a J i e 7 3 V b Y Q Y = " > A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 9 F j 0 4 k k q 2 g 9 o Q 9 l s N + 3 S z S b s T o Q S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O y u r a + s b m 4 W t 4 v b O 7 t 5 + 6 e C w a e J U M 9 5 g s Y x 1 O 6 C G S 6 F 4 A w V K 3 k 4 0 p 1 E g e S s Y 3 U z 9 1 h P X R s T q E c c J 9 y M 6 U C I U j K K V H o a 9 u 1 6 p 7 F b c G c g y 8 X J S h h z 1 X u m r 2 4 9 Z G n G F T F J j O p 6 b o J 9 R j Y J J P i l 2 U 8 M T y k Z 0 w D u W K h p x 4 2 e z U y f k 1 C p 9 E s b a l k I y U 3 9 P Z D Q y Z h w F t j O i O D S L 3 l T 8 z + u k G F 7 5 m V B J i l y x + a I w l Q R j M v 2 b 9 I X m D O X Y E s q 0 s L c S N q S a M r T p F G 0 I 3 u L L y 6 R Z r X j n l e r 9 R b l 2 n c d R g G M 4 g T P w 4 B J q c A t 1 a A C D A T z D K 7 w 5 0 n l x 3 p 2 P e e u K k 8 8 c w R 8 4 n z 8 g k o 2 x < / l a t e x i t >

<T<ATRA>RP>laPnlta<nNt <ANVA>Vfo>rwfoarrwda?r<dO? R<OAR>AY>esYes
(a) Dialogue and action histories combined with the current observation are used to predict the next navigation action.

DDeeccooddeerr EEnnccooddeerr

w< l a t e x i t s h a 1 _ b a s e 6 4 = " y u G y f G z G 4 L f d n 9 9 v X T g 9 T 6 I P f z 4 = " > A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k o N 6 K X j x W M G 2 h D W W z n b Z L N 5 u w u 1 F K 6 G / w 4 k E R r / 4 g b / 4 b t 2 0 O 2 v p g 4 P H e D D P z w k R w b V z 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j p o 5 T x d B n s Y h V O 6 Q a B Z f o G 2 4 E t h O F N A o F t s L x 7 c x v P a L S P J Y P Z p J g E N G h 5 A P O q L G S / 9 T L + L R X r r h V d w 6 y S r y c V C B H o 1 f + 6 v Z j l k Y o D R N U 6 4 7 n J i b I q D K c C Z y W u q n G h L I x H W L H U k k j 1 E E 2 P 3 Z K z q z S J 4 N Y 2 Z K G z N X f E x m N t J 5 E o e 2 M q B n p Z W 8 m / u d 1 U j O 4 C j I u k 9 S g Z I t F g 1 Q Q E 5 P Z 5 6 T P F T I j J p Z Q p r i 9 l b A R V Z Q Z m 0 / J h u A t v 7 x K m h d V r 1 a 9 v q 9 V 6 j d 5 H E U 4 g V M 4 B w 8 u o Q 5 3 0 A A f G H B 4 h l d 4 c 6 T z 4 r w 7 H 4 v W g p P P H M M f O J 8 / J 8 W O 7 w = = < / l a t e x i t > i

w< l a t e x i t s h a 1 _ b a s e 6 4 = " y u G y f G z G 4 L f d n 9 9 v X T g 9 T 6 I P f z 4 = " > A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k o N 6 K X j x W M G 2 h D W W z n b Z L N 5 u w u 1 F K 6 G / w 4 k E R r / 4 g b / 4 b t 2 0 O 2 v p g 4 P H e D D P z w k R w b V z 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j p o 5 T x d B n s Y h V O 6 Q a B Z f o G 2 4 E t h O F N A o F t s L x 7 c x v P a L S P J Y P Z p J g E N G h 5 A P O q L G S / 9 T L + L R X r r h V d w 6 y S r y c V C B H o 1 f + 6 v Z j l k Y o D R N U 6 4 7 n J i b I q D K c C Z y W u q n G h L I x H W L H U k k j 1 E E 2 P 3 Z K z q z S J 4 N Y 2 Z K G z N X f E x m N t J 5 E o e 2 M q B n p Z W 8 m / u d 1 U j O 4 C j I u k 9 S g Z I t F g 1 Q Q E 5 P Z 5 6 T P F T I j J p Z Q p r i 9 l b A R V Z Q Z m 0 / J h u A t v 7 x K m h d V r 1 a 9 v q 9 V 6 j d 5 H E U 4 g V M 4 B w 8 u o Q 5 3 0 A A f G H B 4 h l d 4 c 6 T z 4 r w 7 H 4 v W g p P P H M M f O J 8 / J 8 W O 7 w = = < / l a t e x i t > i

AttenAd ttend

w< l a t e x i t s h a 1 _ b a s e 6 4 = " b l X 3 D 2 d a 4 r w r w T e L 2 n u q I 4 2 3 r n 4 = " > A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 s S R S U G 9 F L x 4 r 2 A 9 o Q 9 l s J + 3 S z S b s b p Q S + i O 8 e F D E q 7 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d l Z W 1 9 Y 3 N g t b x e 2 d 3 b 3 9 0 s F h U 8 e p Y t h g s Y h V O 6 A a B Z f Y M N w I b C c K a R Q I b A W j 2 6 n f e k S l e S w f z D h B P 6 I D y U P O q L F S 6 6 m X 8 X N v 0 i u V 3 Y o 7 A 1 k m X k 7 K k K P e K 3 1 1 + z F L I 5 S G C a p 1 x 3 M T 4 2 d U G c 4 E T o r d V G N C 2 Y g O s G O p p B F q P 5 u d O y G n V u m T M F a 2 p C E z 9 f d E R i O t x 1 F g O y N q h n r R m 4 r / e Z 3 U h F d + x m W S G p R s v i h M B T E x m f 5 O + l w h M 2 J s C W W K 2 1 s J G 1 J F m b E J F W 0 I 3 u L L y 6 R 5 U f G q l e v 7 a r l 2 k 8 d R g G M 4 g T P w 4 B J q c A d 1 a A C D E T z D K 7 w 5 i f P i v D s f 8 9 Y V J 5 8 5 g j 9 w P n 8 A B C W P Y Q = = < / l a t e x i t > i

1w< l a t e x i t s h a 1 _ b a s e 6 4 = " b l X 3 D 2 d a 4 r w r w T e L 2 n u q I 4 2 3 r n 4 = " > A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 s S R S U G 9 F L x 4 r 2 A 9 o Q 9 l s J + 3 S z S b s b p Q S + i O 8 e F D E q 7 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B F c G 9 f 9 d l Z W 1 9 Y 3 N g t b x e 2 d 3 b 3 9 0 s F h U 8 e p Y t h g s Y h V O 6 A a B Z f Y M N w I b C c K a R Q I b A W j 2 6 n f e k S l e S w f z D h B P 6 I D y U P O q L F S 6 6 m X 8 X N v 0 i u V 3 Y o 7 A 1 k m X k 7 K k K P e K 3 1 1 + z F L I 5 S G C a p 1 x 3 M T 4 2 d U G c 4 E T o r d V G N C 2 Y g O s G O p p B F q P 5 u d O y G n V u m T M F a 2 p C E z 9 f d E R i O t x 1 F g O y N q h n r R m 4 r / e Z 3 U h F d + x m W S G p R s v i h M B T E x m f 5 O + l w h M 2 J s C W W K 2 1 s J G 1 J F m b E J F W 0 I 3 u L L y 6 R 5 U f G q l e v 7 a r l 2 k 8 d R g G M 4 g T P w 4 B J q c A d 1 a A C D E T z D K 7 w 5 i f P i v D s f 8 9 Y V J 5 8 5 g j 9 w P n 8 A B C W P Y Q = = < / l a t e x i t > i

1w< l a t e x i t s h a 1 _ b a s e 6 4 = " y u G y f G z G 4 L f d n 9 9 v X T g 9 T 6 I P f z 4 = " > A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k o N 6 K X j x W M G 2 h D W W z n b Z L N 5 u w u 1 F K 6 G / w 4 k E R r / 4 g b / 4 b t 2 0 O 2 v p g 4 P H e D D P z w k R w b V z 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j p o 5 T x d B n s Y h V O 6 Q a B Z f o G 2 4 E t h O F N A o F t s L x 7 c x v P a L S P J Y P Z p J g E N G h 5 A P O q L G S / 9 T L + L R X r r h V d w 6 y S r y c V C B H o 1 f + 6 v Z j l k Y o D R N U 6 4 7 n J i b I q D K c C Z y W u q n G h L I x H W L H U k k j 1 E E 2 P 3 Z K z q z S J 4 N Y 2 Z K G z N X f E x m N t J 5 E o e 2 M q B n p Z W 8 m / u d 1 U j O 4 C j I u k 9 S g Z I t F g 1 Q Q E 5 P Z 5 6 T P F T I j J p Z Q p r i 9 l b A R V Z Q Z m 0 / J h u A t v 7 x K m h d V r 1 a 9 v q 9 V 6 j d 5 H E U 4 g V M 4 B w 8 u o Q 5 3 0 A A f G H B 4 h l d 4 c 6 T z 4 r w 7 H 4 v W g p P P H M M f O J 8 / J 8 W O 7 w = = < / l a t e x i t > i

w< l a t e x i t s h a 1 _ b a s e 6 4 = " y u G y f G z G 4 L f d n 9 9 v X T g 9 T 6 I P f z 4 = " > A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k o N 6 K X j x W M G 2 h D W W z n b Z L N 5 u w u 1 F K 6 G / w 4 k E R r / 4 g b / 4 b t 2 0 O 2 v p g 4 P H e D D P z w k R w b V z 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j p o 5 T x d B n s Y h V O 6 Q a B Z f o G 2 4 E t h O F N A o F t s L x 7 c x v P a L S P J Y P Z p J g E N G h 5 A P O q L G S / 9 T L + L R X r r h V d w 6 y S r y c V C B H o 1 f + 6 v Z j l k Y o D R N U 6 4 7 n J i b I q D K c C Z y W u q n G h L I x H W L H U k k j 1 E E 2 P 3 Z K z q z S J 4 N Y 2 Z K G z N X f E x m N t J 5 E o e 2 M q B n p Z W 8 m / u d 1 U j O 4 C j I u k 9 S g Z I t F g 1 Q Q E 5 P Z 5 6 T P F T I j J p Z Q p r i 9 l b A R V Z Q Z m 0 / J h u A t v 7 x K m h d V r 1 a 9 v q 9 V 6 j d 5 H E U 4 g V M 4 B w 8 u o Q 5 3 0 A A f G H B 4 h l d 4 c 6 T z 4 r w 7 H 4 v W g p P P H M M f O J 8 / J 8 W O 7 w = = < / l a t e x i t > i

a t < l a t e x i t s h a 1 _ b a s e 6 4 = " x o P 2 Q Z j v P Y 3 3 6 0 M B 4 r b u i k A M d M Q = " > A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 s S R S U W 9 F L x 4 r 2 A 9 o Q 9 l s N + 3 S z S b s T o Q S + i O 8 e F D E q 7 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O y u r a + s b m 4 W t 4 v b O 7 t 5 + 6 e C w a e J U M 9 5 g s Y x 1 O 6 C G S 6 F 4 A w V K 3 k 4 0 p 1 E g e S s Y 3 U 3 9 1 h P X R s T q E c c J 9 y M 6 U C I U j K K V W r S X 4 f n l p F c q u x V 3 B r J M v J y U I U e 9 V / r q 9 m O W R l w h k 9 S Y j u c m 6 G d U o 2 C S T 4 r d 1 P C E s h E d 8 I 6 l i k b c + N n s 3 A k 5 t U q f h L G 2 p Z D M 1 N 8 T G Y 2 M G U e B 7 Y w o D s 2 i N x X / 8 z o p h t d + J l S S I l d s v i h M J c G Y T H 8 n f a E 5 Q z m 2 h D I t 7 K 2 E D a m m D G 1 C R R u C t / j y M m l e V L x q 5 e a h W q 7 d 5 n E U 4 B h O 4 A w 8 u I I a 3 E M d G s B g B M / w C m 9 O 4 r w 4 7 8 7 H v H X F y W e O 4 A + c z x / 5 G 4 9 a < / l a t e x i t >

It5⇤+1 < l a t e x i t s h a 1 _ b a s e 6 4 = " n D K n o e / J t r u K A y s t y a r Z R p 6 W A 5 o = " > A A A B 8 H i c b V B N S w M x E M 3 W r 1 q / q h 6 9 B I s g C m V X C u q t 6 E V v F e y H t G v J p t k 2 N M k u y a x Q l v 4 K L x 4 U 8 e r P 8 e a / M W 3 3 o K 0 P B h 7 v z T A z L 4 g F N + C 6 3 0 5 u a X l l d S 2 / X t j Y 3 N r e K e 7 u N U y U a M r q N B K R b g X E M M E V q w M H w V q x Z k Q G g j W D 4 f X E b z 4 x b X i k 7 m E U M 1 + S v u I h p w S s 9 H D 7 e N J N 4 d Q b d 4 s l t + x O g R e J l 5 E S y l D r F r 8 6 v Y g m k i m g g h j T 9 t w Y / J R o 4 F S w c a G T G B Y T O i R 9 1 r Z U E c m M n 0 4 P H u M j q / R w G G l b C v B U / T 2 R E m n M S A a 2 U x I Y m H l v I v 7 n t R M I L / y U q z g B p u h s U Z g I D B G e f I 9 7 X D M K Y m Q J o Z r b W z E d E E 0 o 2 I w K N g R v / u V F 0 j g r e 5 X y 5 V 2 l V L 3 K 4 s i j A 3 S I j p G H z l E V 3 a A a q i O K J H p G r + j N 0 c 6 L 8 + 5 8 z F p z T j a z j / 7 A + f w B 5 z y P 2 A = = < / l a t e x i t >

at ⇤4 < l a t e x i t s h a 1 _ b a s e 6 4 = " 9 8 M 7 2 Q 9 j 3 D d R P + x J V o b n 7 O D G a 2 o = " > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B i y W R g n o r e v F Y w X 5 A G 8 p m u 2 m X b j Z h d y K U 0 B / h x Y M i X v 0 9 3 v w 3 b t s c t P X B w O O 9 G W b m B Y k U B l 3 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j l o l T z X i T x T L W n Y A a L o X i T R Q o e S f R n E a B 5 O 1 g f D f z 2 0 9 c G x G r R 5 w k 3 I / o U I l Q M I p W a t N + h h e 1 a b 9 c c a v u H G S V e D m p Q I 5 G v / z V G 8 Q s j b h C J q k x X c 9 N 0 M + o R s E k n 5 Z 6 q e E J Z W M 6 5 F 1 L F Y 2 4 8 b P 5 u V N y Z p U B C W N t S y G Z q 7 8 n M h o Z M 4 k C 2 x l R H J l l b y b + 5 3 V T D K / 9 T K g k R a 7 Y Y l G Y S o I x m f 1 O B k J z h n J i C W V a 2 F s J G 1 F N G d q E S j Y E b / n l V d K 6 r H q 1 6 s 1 D r V K / z e M o w g m c w j l 4 c A V 1 u I c G N I H B G J 7 h F d 6 c x H l x 3 p 2 P R W v B y W e O 4 Q + c z x / 3 l o 9 Z < / l a t e x i t > I t +2 < l a t e x i t s h a 1 _ b a s e 6 4 = " d n c z f X o 6 3 L o d E i 2 I o 7 7 1 T v X T S J A = " > A A A B 8 H i c b V B N S w M x E M 3 6 W e t X 1 a O X Y B F E o e y W g n o r e t F b B f s h 7 V q y a b Y N T b J L M i u U p b / C i w d F v P p z v P l v T N s 9 a O u D g c d 7 M 8 z M C 2 L B D b j u t 7 O 0 v L K 6 t p 7 b y G 9 u b e / s F v b 2 G y Z K N G V 1 G o l I t w J i m O C K 1 Y G D Y K 1 Y M y I D w Z r B 8 H r i N 5 + Y N j x S 9 z C K m S 9 J X / G Q U w J W e r h 9 P O 2 m c F Y e d w t F t + R O g R e J l 5 E i y l D r F r 4 6 v Y g m k i m g g h j T 9 t w Y / J R o 4 F S w c b 6 T G B Y T O i R 9 1 r Z U E c m M n 0 4 P H u N j q / R w G G l b C v B U / T 2 R E m n M S A a 2 U x I Y m H l v I v 7 n t R M I L / y U q z g B p u h s U Z g I D B G e f I 9 7 X D M K Y m Q J o Z r b W z E d E E 0 o 2 I z y N g R v / u V F 0 i i X v E r p 8 q 5 S r F 5 l c e T Q I T p C J 8 h D 5 6 i K b l A N 1 R F F E j 2 j V / T m a O f F e X c + Z q 1 L T j Z z g P 7 A + f w B 6 M G P 2 Q = = < / l a t e x i t >

a t < l a t e x i t s h a 1 _ b a s e 6 4 = " 0 F w Y k 9 F 8 t T 8 g C L q e b q 7 j A b y s c M M = " > A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 s S R a U G 9 F L x 4 r 2 A 9 o Q 9 l s N + 3 S z S b s T o Q S + i O 8 e F D E q 7 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O y u r a + s b m 4 W t 4 v b O 7 t 5 + 6 e C w a e J U M 9 5 g s Y x 1 O 6 C G S 6 F 4 A w V K 3 k 4 0 p 1 E g e S s Y 3 U 3 9 1 h P X R s T q E c c J 9 y M 6 U C I U j K K V W r S X 4 f n l p F c q u x V 3 B r J M v J y U I U e 9 V / r q 9 m O W R l w h k 9 S Y j u c m 6 G d U o 2 C S T 4 r d 1 P C E s h E d 8 I 6 l i k b c + N n s 3 A k 5 t U q f h L G 2 p Z D M 1 N 8 T G Y 2 M G U e B 7 Y w o D s 2 i N x X / 8 z o p h t d + J l S S I l d s v i h M J c G Y T H 8 n f a E 5 Q z m 2 h D I t 7 K 2 E D a m m D G 1 C R R u C t / j y M m l e V L x q 5 e a h W q 7 d 5 n E U 4 B h O 4 A w 8 u I I a 3 E M d G s B g B M / w C m 9 O 4 r w 4 7 8 7 H v H X F y W e O 4 A + c z x / 2 E Y 9 Y < / l a t e x i t >

It⇤3+3 < l a t e x i t s h a 1 _ b a s e 6 4 = " k h m 1 W i 1 m q A N 4 B w S 1 L m A F u F 6 6 E u U = " > A A A B 8 H i c b V B N S w M x E J 3 1 s 9 a v q k c v w S K I Q t n V g n o r e t F b B f s h 7 V q y a b Y N T b J L k h X K 0 l / h x Y M i X v 0 5 3 v w 3 p u 0 e t P X B w O O 9 G W b m B T F n 2 r j u t 7 O w u L S 8 s p p b y 6 9 v b G 5 t F 3 Z 2 6 z p K F K E 1 E v F I N Q O s K W e S 1 g w z n D Z j R b E I O G 0 E g + u x 3 3 i i S r N I 3 p t h T H 2 B e 5 K F j G B j p Y f b x + N O a k 7 O R p 1 C 0 S 2 5 E 6 B 5 4 m W k C B m q n c J X u x u R R F B p C M d a t z w 3 N n 6 K l W G E 0 1 G + n W g a Y z L A P d q y V G J B t Z 9 O D h 6 h Q 6 t 0 U R g p W 9 K g i f p 7 I s V C 6 6 E I b K f A p q 9 n v b H 4 n 9 d K T H j h p 0 z G i a G S T B e F C U c m Q u P v U Z c p S g w f W o K J Y v Z W R P p Y Y W J s R n k b g j f 7 8 j y p n 5 a 8 c u n y r l y s X G V x 5 G A f D u A I P D i H C t x A F W p A Q M A z v M K b o 5 w X 5 9 3 5 m L Y u O N n M H v y B 8 / k D 6 k a P 2 g = = < / l a t e x i t >

a t < l a t e x i t s h a 1 _ b a s e 6 4 = " P j 7 + j l 4 a s d g R V m j T s R D U o 4 i T t y o = " > A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 s S S l o N 6 K X j x W s B / Q h r L Z b t q l m 0 3 Y n Q g l 9 E d 4 8 a C I V 3 + P N / + N 2 z Y H b X 0 w 8 H h v h p l 5 Q S K F Q d f 9 d t b W N z a 3 t g s 7 x d 2 9 / Y P D 0 t F x y 8 S p Z r z J Y h n r T k A N l 0 L x J g q U v J N o T q N A 8 n Y w v p v 5 7 S e u j Y j V I 0 4 S 7 k d 0 q E Q o G E U r t W k / w 8 v q t F 8 q u x V 3 D r J K v J y U I U e j X / r q D W K W R l w h k 9 S Y r u c m 6 G d U o 2 C S T 4 u 9 1 P C E s j E d 8 q 6 l i k b c + N n 8 3 C k 5 t 8 q A h L G 2 p Z D M 1 d 8 T G Y 2 M m U S B 7 Y w o j s y y N x P / 8 7 o p h t d + J l S S I l d s s S h M J c G Y z H 4 n A 6 E 5 Q z m x h D I t 7 K 2 E j a i m D G 1 C R R u C t / z y K m l V K 1 6 t c v N Q K 9 d v 8 z g K c A p n c A E e X E E d 7 q E B T W A w h m d 4 h T c n c V 6 c d + d j 0 b r m 5 D M n 8 A f O 5 w / 0 j I 9 X < / l a t e x i t >

It⇤2+4 < l a t e x i t s h a 1 _ b a s e 6 4 = " i + 9 B 3 C H T d O C 5 m I 7 m W g 5 p E W u 7 E 1 s = " > A A A B 8 H i c b V B N S w M x E M 3 W r 1 q / q h 6 9 B I s g C m V X C u q t 6 E V v F e y H t G v J p t k 2 N M k u y a x Q l v 4 K L x 4 U 8 e r P 8 e a / M W 3 3 o K 0 P B h 7 v z T A z L 4 g F N + C 6 3 0 5 u a X l l d S 2 / X t j Y 3 N r e K e 7 u N U y U a M r q N B K R b g X E M M E V q w M H w V q x Z k Q G g j W D 4 f X E b z 4 x b X i k 7 m E U M 1 + S v u I h p w S s 9 H D 7 e N J N 4 b Q y 7 h Z L b t m d A i 8 S L y M l l K H W L X 5 1 e h F N J F N A B T G m 7 b k x + C n R w K l g 4 0 I n M S w m d E j 6 r G 2 p I p I Z P 5 0 e P M Z H V u n h M N K 2 F O C p + n s i J d K Y k Q x s p y Q w M P P e R P z P a y c Q X v g p V 3 E C T N H Z o j A R G C I 8 + R 7 3 u G Y U x M g S Q j W 3 t 2 I 6 I J p Q s B k V b A j e / M u L p H F W 9 i r l y 7 t K q X q V x Z F H B + g Q H S M P n a M q u k E 1 V E c U S f S M X t G b o 5 0 X 5 9 3 5 m L X m n G x m H / 2 B 8 / k D 6 8 u P 2 w = = < / l a t e x i t >

at ⇤ 1 < l a t e x i t s h a 1 _ b a s e 6 4 = " 7 S 5 A J e A l b d v 4 K S t b x z M L y z u T e d I = " > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B i y W p g h 6 L X j x W s B / Q h r L Z b t q l m 0 3 Y n Q g l 9 E d 4 8 a C I V 3 + P N / + N 2 z Y H b X 0 w 8 H h v h p l 5 Q S K F Q d f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o Z e J U M 9 5 k s Y x 1 J 6 C G S 6 F 4 E w V K 3 k k 0 p 1 E g e T s Y 3 8 3 8 9 h P X R s T q E S c J 9 y M 6 V C I U j K K V 2 r S f 4 Y U 3 7 Z c r b t W d g 6 w S L y c V y N H o l 7 9 6 g 5 i l E V f I J D W m 6 7 k J + h n V K J j k 0 1 I v N T y h b E y H v G u p o h E 3 f j Y / d 0 r O r D I g Y a x t K S R z 9 f d E R i N j J l F g O y O K I 7 P s z c T / v G 6 K 4 Y 2 f C Z W k y B V b L A p T S T A m s 9 / J Q G j O U E 4 s o U w L e y t h I 6 o p Q 5 t Q y Y b g L b + 8 S l q 1 q n d Z r T 1 c V e q 3 e R x F O I F T O A c P r q E O 9 9 C A J j A Y w z O 8 w p u T O C / O u / O x a C 0 4 + c w x / I H z + Q P w d Y 9 O < / l a t e x i t > I t +5 < l a t e x i t s h a 1 _ b a s e 6 4 = " Y / Z d Z W f d 9 i C H g 6 j e H F 7 9 M g m l P c 4 = " > A A A B 8 H i c b V B N S w M x E J 3 1 s 9 a v q k c v w S K I Q t m V i n o r e t F b B f s h 7 V q y a b Y N T b J L k h X K 0 l / h x Y M i X v 0 5 3 v w 3 p u 0 e t P X B w O O 9 G W b m B T F n 2 r j u t 7 O w u L S 8 s p p b y 6 9 v b G 5 t F 3 Z 2 6 z p K F K E 1 E v F I N Q O s K W e S 1 g w z n D Z j R b E I O G 0 E g + u x 3 3 i i S r N I 3 p t h T H 2 B e 5 K F j G B j p Y f b x + N O a k 7 O R p 1 C 0 S 2 5 E 6 B 5 4 m W k C B m q n c J X u x u R R F B p C M d a t z w 3 N n 6 K l W G E 0 1 G + n W g a Y z L A P d q y V G J B t Z 9 O D h 6 h Q 6 t 0 U R g p W 9 K g i f p 7 I s V C 6 6 E I b K f A p q 9 n v b H 4 n 9 d K T H j h p 0 z G i a G S T B e F C U c m Q u P v U Z c p S g w f W o K J Y v Z W R P p Y Y W J s R n k b g j f 7 8 j y p n 5 a 8 c u n y r l y s X G V x 5 G A f D u A I P D i H C t x A F W p A Q M A z v M K b o 5 w X 5 9 3 5 m L Y u O N n M H v y B 8 / k D 7 V C P 3 A = = < / l a t e x i t >

a t < l a t e x i t s h a 1 _ b a s e 6 4 = " A b Z P 0 o 7 V V g u V O G d p F n 5 w r R U y K C o = " > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m k o N 6 K X j x W t B / Q h r L Z b t q l m 0 3 Y n Q g l 9 C d 4 8 a C I V 3 + R N / + N 2 z Y H b X 0 w 8 H h v h p l 5 Q S K F Q d f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o Z e J U M 9 5 k s Y x 1 J 6 C G S 6 F 4 E w V K 3 k k 0 p 1 E g e T s Y 3 8 7 8 9 h P X R s T q E S c J 9 y M 6 V C I U j K K V H m g f + + W K W 3 X n I K v E y 0 k F c j T 6 5 a / e I G Z p x B U y S Y 3 p e m 6 C f k Y 1 C i b 5 t N R L D U 8 o G 9 M h 7 1 q q a M S N n 8 1 P n Z I z q w x I G G t b C s l c / T 2 R 0 c i Y S R T Y z o j i y C x 7 M / E / r 5 t i e O V n Q i U p c s U W i 8 J U E o z J 7 G 8 y E J o z l B N L K N P C 3 k r Y i G r K 0 K Z T s i F 4 y y + v k t Z F 1 a t V r + 9 r l f p N H k c R T u A U z s G D S 6 j D H T S g C Q y G 8 A y v 8 O Z I 5 8 V 5 d z 4 W r Q U n n z m G P 3 A + f w B S E o 3 Y < / l a t e x i t >

(b) Guide Bi-LSTM over the path is attended to during decoding for answer generation.

Figure 2: Our backbone Seq2Seq architectures are provided visual observations and portions of the dialogue history when taking actions or asking/answering questions.

Navigation Action Decoding (C4) Initially, the dialogue context is just a target object tO category, for example “plant.” The goal room contains an instance of that category. As questions are asked and answered, the dialogue context grows. Following prior work (Anderson et al., 2018; Thomason et al., 2019), dialogue history words w words are embedded as 256 dimensional vectors and passed through an LSTM to produce u context vectors and a ﬁnal hidden state hN . The hidden state hN is used to initialize the LSTM decoder. At every timestep the decoder is updated with the previous action at−1 and current image observation It. The hidden state is used to attend over the language u and predict the next action at (Figure 2a).
We pretrain the N avigator on the navigation task alone before ﬁne-tuning in the full dialogue setting that we introduce. The next action is sampled from the model’s predicted logits, and the episode ends when either a stop action is sampled or 80 actions are taken (Thomason et al., 2019).
Speaker Models (C2 & C3) To generate questions and answers, we train sequence-to-sequence models (Figure 2b) where an encoder takes in a sequence of images and a decoder produces a sequence of word tokens. At each decoding timestep, the decoder attends over the input images to predict the next word of the question or answer. This model is also initialized via training on CVDN dialogues. In particular, question asking (Questioner) encodes the images of the current viewpoint where a question is asked, and then decodes the question tokens produced by the human N avigator. Question answering (Guide) encodes images of the next ﬁve steps the shortest path planner would take towards the goal, then decodes the language tokens pro-

duced by the human Guide. Pretraining initializes the lexical embeddings and attention alignments before ﬁne-tuning in the collaborative, turn-taking setting we introduce in this paper.
Conditioning Context We deﬁne three levels of dialogue context given as input to our N avigator agents in order to evaluate how well they utilize the generated conversations. We compare agents’ ability to navigate to the goal room given:

tO

the target object present in the goal room;

QAi-1 additionally the previous question-andanswer exchange;

QA1:i-1 additionally the entire dialogue history.

We constrain the Questioner and Guide speaker
models to condition on ﬁxed contexts. The Questioner model takes as input the current visual observation It and the target object tO. The Guide model takes the visual observations It∗+1:t+5 of the next ﬁve steps of navigation according to a
shortest path planner, the target object tO, and the last question Qi−1 generated by the Questioner.1

4.2 Recursive Mental Model
We introduce the Recursive Mental Model agent (RMM),2 which is trained with reinforcement learning to propagate feedback from navigation error through all three component models: N avigator, Questioner, and Guide. In this way, the training signal for question generation includes the training
1This limits phenomena like co-reference, but dramatically reduces the model’s input space. Handling arbitrarily long contexts with limited training data is left to future work.
2https://github.com/HomeroRR/rmm

How this looks like for Vision-Dialog Navigation

Start

N< l a t e x i t s h a 1 _ b a s e 6 4 = " A i z T e X p l B v n 9 P W e W H A X H z W a q l V Y = " > A A A B 8 n i c b V D L S g M x F L 1 T X 7 W + q i 7 d B I v g q s x U Q Z d F N 6 6 k g n 3 A d C i Z N N O G Z p I h y Q h l 6 G e 4 c a G I W 7 / G n X 9 j p p 2 F t h 4 I H M 6 5 l 5 x 7 w o Q z b V z 3 2 y m t r W 9 s b p W 3 K z u 7 e / s H 1 c O j j p a p I r R N J J e q F 2 J N O R O 0 b Z j h t J c o i u O Q 0 2 4 4 u c 3 9 7 h N V m k n x a K Y J D W I 8 E i x i B B s r + f 0 Y m z H B P L u f D a o 1 t + 7 O g V a J V 5 A a F G g N q l / 9 o S R p T I U h H G v t e 2 5 i g g w r w w i n s 0 o / 1 T T B Z I J H 1 L d U 4 J j q I J t H n q E z q w x R J J V 9 w q C 5 + n s j w 7 H W 0 z i 0 k 3 l E v e z l 4 n + e n 5 r o O s i Y S F J D B V l 8 F K U c G Y n y + 9 G Q K U o M n 1 q C i W I 2 K y J j r D A x t q W K L c F b P n m V d B p 1 7 6 L e e L i s N W + K O s p w A q d w D h 5 c Q R P u o A V t I C D h G V 7 h z T H O i / P u f C x G S 0 6 x c w x / 4 H z + A I V d k W g = < / l a t e x i t >

Q< l a t e x i t s h a 1 _ b a s e 6 4 = " 1 Z + a i 4 R 7 a Y 9 T O k p Y l + O c U g K E e J U = " > A A A B 8 n i c b V D L S g M x F L 1 T X 7 W + q i 7 d B I v g q s x U Q Z d F N y 5 b s A + Y D i W T Z t r Q T D I k G a E M / Q w 3 L h R x 6 9 e 4 8 2 / M t L P Q 1 g O B w z n 3 k n N P m H C m j e t + O 6 W N z a 3 t n f J u Z W / / 4 P C o e n z S 1 T J V h H a I 5 F L 1 Q 6 w p Z 4 J 2 D D O c 9 h N F c R x y 2 g u n 9 7 n f e 6 J K M y k e z S y h Q Y z H g k W M Y G M l f x B j M y G Y Z + 3 5 s F p z 6 + 4 C a J 1 4 B a l B g d a w + j U Y S Z L G V B j C s d a + 5 y Y m y L A y j H A 6 r w x S T R N M p n h M f U s F j q k O s k X k O b q w y g h F U t k n D F q o v z c y H G s 9 i 0 M 7 m U f U q 1 4 u / u f 5 q Y l u g 4 y J J D V U k O V H U c q R k S i / H 4 2 Y o s T w m S W Y K G a z I j L B C h N j W 6 r Y E r z V k 9 d J t 1 H 3 r u q N 9 n W t e V f U U Y Y z O I d L 8 O A G m v A A L e g A A Q n P 8 A p v j n F e n H f n Y z l a c o q d U / g D 5 / M H i e y R a w = = < / l a t e x i t >

⇠< l a t e x i t s h a 1 _ b a s e 6 4 = " J 2 z T x m e v O y e S D 2 l c 2 e l L M W y d M G 4 = " > A A A B 7 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 i R b B U 9 m t g h 6 L X j x W s B / Q X U o 2 z b a h S X a b Z I W y 9 E 9 4 8 a C I V / + O N / + N a b s H b X 0 w 8 H h v h p l 5 Y c K Z N q 7 7 7 R T W 1 j c 2 t 4 r b p Z 3 d v f 2 D 8 u F R S 8 e p I r R J Y h 6 r T o g 1 5 U z S p m G G 0 0 6 i K B Y h p + 1 w d D f z 2 0 9 U a R b L R z N J a C D w Q L K I E W y s 1 P E 1 E / 4 p G v f K F b f q z o F W i Z e T C u R o 9 M p f f j 8 m q a D S E I 6 1 7 n p u Y o I M K 8 M I p 9 O S n 2 q a Y D L C A 9 q 1 V G J B d Z D N 7 5 2 i c 6 v 0 U R Q r W 9 K g u f p 7 I s N C 6 4 k I b a f A Z q i X v Z n 4 n 9 d N T X Q T Z E w m q a G S L B Z F K U c m R r P n U Z 8 p S g y f W I K J Y v Z W R I Z Y Y W J s R C U b g r f 8 8 i p p 1 a r e Z b X 2 c F W p 3 + Z x F O E E z u A C P L i G O t x D A 5 p A g M M z v M K b M 3 Z e n H f n Y 9 F a c P K Z Y / g D 5 / M H V h G P g Q = = < / l a t e x i t >

q

⇠< l a t e x i t s h a 1 _ b a s e 6 4 = " f b 1 O 4 i h h j 0 X w Z q j A Q X c J B s v G E + U = " > A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 i R b R U 9 m t g h 6 L X j x W s B / S X U o 2 z b a h S X Z N s k J Z + i u 8 e F D E q z / H m / / G t N 2 D V h 8 M P N 6 b Y W Z e m H C m j e t + O Y W l 5 Z X V t e J 6 a W N z a 3 u n v L v X 0 n G q C G 2 S m M e q E 2 J N O Z O 0 a Z j h t J M o i k X I a T s c X U / 9 9 i N V m s X y z o w T G g g 8 k C x i B B s r 3 f u a C f 8 Q P Z z 0 y h W 3 6 s 6 A / h I v J x X I 0 e i V P / 1 + T F J B p S E c a 9 3 1 3 M Q E G V a G E U 4 n J T / V N M F k h A e 0 a 6 n E g u o g m x 0 8 Q c d W 6 a M o V r a k Q T P 1 5 0 S G h d Z j E d p O g c 1 Q L 3 p T 8 T + v m 5 r o M s i Y T F J D J Z k v i l K O T I y m 3 6 M + U 5 Q Y P r Y E E 8 X s r Y g M s c L E 2 I x K N g R v 8 e W / p F W r e m f V 2 u 1 5 p X 6 V x 1 G E A z i C U / D g A u p w A w 1 o A g E B T / A C r 4 5 y n p 0 3 5 3 3 e W n D y m X 3 4 B e f j G 7 j S j 7 I = < / l a t e x i t >

q0

⇠< l a t e x i t s h a 1 _ b a s e 6 4 = " L X Q z 5 S L + B w p t I b A N C V D N N T K C a s U = " > A A A B 8 X i c b V B N T w I x E J 3 F L 8 Q v 1 K O X K j F 4 I r t o o k e i F 4 + Y y E d k N 6 R b C j S 0 3 b X t m p A N / 8 K L B 4 3 x 6 r / x 5 r + x w B 4 U f M k k L + / N Z G Z e G H O m j e t + O 7 m V 1 b X 1 j f x m Y W t 7 Z 3 e v u H / Q 1 F G i C G 2 Q i E e q H W J N O Z O 0 Y Z j h t B 0 r i k X I a S s c 3 U z 9 1 h N V m k X y 3 o x j G g g 8 k K z P C D Z W e v A 1 E / 4 x e i y X u 8 W S W 3 F n Q M v E y 0 g J M t S 7 x S + / F 5 F E U G k I x 1 p 3 P D c 2 Q Y q V Y Y T T S c F P N I 0 x G e E B 7 V g q s a A 6 S G c X T 9 C p V X q o H y l b 0 q C Z + n s i x U L r s Q h t p 8 B m q B e 9 q f i f 1 0 l M / y p I m Y w T Q y W Z L + o n H J k I T d 9 H P a Y o M X x s C S a K 2 V s R G W K F i b E h F W w I 3 u L L y 6 R Z r X j n l e r d R a l 2 n c W R h y M 4 g T P w 4 B J q c A t 1 a A A B C c / w C m + O d l 6 c d + d j 3 p p z s p l D + A P n 8 w c b y 4 / j < / l a t e x i t >

q00

G< l a t e x i t s h a 1 _ b a s e 6 4 = " A w s m y h s 2 O h 7 2 g e O 5 w z l q r u T I J j g = " > A A A B 8 n i c b V D L S g M x F L 1 T X 7 W + q i 7 d B I v g q s x I Q d 0 V X e i y g n 3 A d C i Z N N O G Z p I h y Q h l 6 G e 4 c a G I W 7 / G n X 9 j p p 2 F t h 4 I H M 6 5 l 5 x 7 w o Q z b V z 3 2 y m t r W 9 s b p W 3 K z u 7 e / s H 1 c O j j p a p I r R N J J e q F 2 J N O R O 0 b Z j h t J c o i u O Q 0 2 4 4 u c 3 9 7 h N V m k n x a K Y J D W I 8 E i x i B B s r + f 0 Y m z H B P L u b D a o 1 t + 7 O g V a J V 5 A a F G g N q l / 9 o S R p T I U h H G v t e 2 5 i g g w r w w i n s 0 o / 1 T T B Z I J H 1 L d U 4 J j q I J t H n q E z q w x R J J V 9 w q C 5 + n s j w 7 H W 0 z i 0 k 3 l E v e z l 4 n + e n 5 r o K s i Y S F J D B V l 8 F K U c G Y n y + 9 G Q K U o M n 1 q C i W I 2 K y J j r D A x t q W K L c F b P n m V d C 7 q X q N + / d C o N W + K O s p w A q d w D h 5 c Q h P u o Q V t I C D h G V 7 h z T H O i / P u f C x G S 0 6 x c w x / 4 H z + A H 1 M k W k = < / l a t e x i t >

⇠< l a t e x i t s h a 1 _ b a s e 6 4 = " e o e A x 2 m N w I B K V g f H p d Y 5 N F C b 5 v s = " > A A A B 7 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 i R b B U 9 m V g n o r e v F Y w X 5 A d y n Z N N u G J t l t k h X K 0 j / h x Y M i X v 0 7 3 v w 3 p u 0 e t P X B w O O 9 G W b m h Q l n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H L R 2 n i t A m i X m s O i H W l D N J m 4 Y Z T j u J o l i E n L b D 0 d 3 M b z 9 R p V k s H 8 0 k o Y H A A 8 k i R r C x U s f X T P i n a N A r V 9 y q O w d a J V 5 O K p C j 0 S t / + f 2 Y p I J K Q z j W u u u 5 i Q k y r A w j n E 5 L f q p p g s k I D 2 j X U o k F 1 U E 2 v 3 e K z q 3 S R 1 G s b E m D 5 u r v i Q w L r S c i t J 0 C m 6 F e 9 m b i f 1 4 3 N d F 1 k D G Z p I Z K s l g U p R y Z G M 2 e R 3 2 m K D F 8 Y g k m i t l b E R l i h Y m x E Z V s C N 7 y y 6 u k d V n 1 a t W b h 1 q l f p v H U Y Q T O I M L 8 O A K 6 n A P D W g C A Q 7 P 8 A p v z t h 5 c d 6 d j 0 V r w c l n j u E P n M 8 f S X u P f w = = < / l a t e x i t >

g

⇠< l a t e x i t s h a 1 _ b a s e 6 4 = " 9 u 7 L 5 P 9 s i R + Z T M Z B n E r J C c i x W 2 E = " > A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 i R b R U 9 m V g n o r e v F Y w X 5 I d y n Z N N u G J t k l y Q p l 6 a / w 4 k E R r / 4 c b / 4 b 0 3 Y P 2 v p g 4 P H e D D P z w o Q z b V z 3 2 y m s r K 6 t b x Q 3 S 1 v b O 7 t 7 5 f 2 D l o 5 T R W i T x D x W n R B r y p m k T c M M p 5 1 E U S x C T t v h 6 H b q t 5 + o 0 i y W D 2 a c 0 E D g g W Q R I 9 h Y 6 d H X T P j H a H D W K 1 f c q j s D W i Z e T i q Q o 9 E r f / n 9 m K S C S k M 4 1 r r r u Y k J M q w M I 5 x O S n 6 q a Y L J C A 9 o 1 1 K J B d V B N j t 4 g k 6 t 0 k d R r G x J g 2 b q 7 4 k M C 6 3 H I r S d A p u h X v S m 4 n 9 e N z X R V Z A x m a S G S j J f F K U c m R h N v 0 d 9 p i g x f G w J J o r Z W x E Z Y o W J s R m V b A j e 4 s v L p H V R 9 W r V 6 / t a p X 6 T x 1 G E I z i B c / D g E u p w B w 1 o A g E B z / A K b 4 5 y X p x 3 5 2 P e W n D y m U P 4 A + f z B 6 w y j 7 A = < / l a t e x i t >

g0

⇠< l a t e x i t s h a 1 _ b a s e 6 4 = " O U Y L w 2 Y W p l u p X d Y b X p s D p T w x i N A = " > A A A B 8 X i c b V B N S w M x E J 3 1 s 9 a v q k c v 0 S L 1 V H a l o N 6 K X j x W s B / Y X U o 2 z b a h S X Z J s k J Z + i + 8 e F D E q / / G m / / G t N 2 D t j 4 Y e L w 3 w 8 y 8 M O F M G 9 f 9 d l Z W 1 9 Y 3 N g t b x e 2 d 3 b 3 9 0 s F h S 8 e p I r R J Y h 6 r T o g 1 5 U z S p m G G 0 0 6 i K B Y h p + 1 w d D v 1 2 0 9 U a R b L B z N O a C D w Q L K I E W y s 9 O h r J v w T N K h U e q W y W 3 V n Q M v E y 0 k Z c j R 6 p S + / H 5 N U U G k I x 1 p 3 P T c x Q Y a V Y Y T T S d F P N U 0 w G e E B 7 V o q s a A 6 y G Y X T 9 C Z V f o o i p U t a d B M / T 2 R Y a H 1 W I S 2 U 2 A z 1 I v e V P z P 6 6 Y m u g o y J p P U U E n m i 6 K U I x O j 6 f u o z x Q l h o 8 t w U Q x e y s i Q 6 w w M T a k o g 3 B W 3 x 5 m b Q u q l 6 t e n 1 f K 9 d v 8 j g K c A y n c A 4 e X E I d 7 q A B T S A g 4 R l e 4 c 3 R z o v z 7 n z M W 1 e c f O Y I / s D 5 / A E P I Y / h < / l a t e x i t >

g00

⇠< l a t e x i t s h a 1 _ b a s e 6 4 = " e o e A x 2 m N w I B K V g f H p d Y 5 N F C b 5 v s = " > A A A B 7 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 i R b B U 9 m V g n o r e v F Y w X 5 A d y n Z N N u G J t l t k h X K 0 j / h x Y M i X v 0 7 3 v w 3 p u 0 e t P X B w O O 9 G W b m h Q l n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H L R 2 n i t A m i X m s O i H W l D N J m 4 Y Z T j u J o l i E n L b D 0 d 3 M b z 9 R p V k s H 8 0 k o Y H A A 8 k i R r C x U s f X T P i n a N A r V 9 y q O w d a J V 5 O K p C j 0 S t / + f 2 Y p I J K Q z j W u u u 5 i Q k y r A w j n E 5 L f q p p g s k I D 2 j X U o k F 1 U E 2 v 3 e K z q 3 S R 1 G s b E m D 5 u r v i Q w L r S c i t J 0 C m 6 F e 9 m b i f 1 4 3 N d F 1 k D G Z p I Z K s l g U p R y Z G M 2 e R 3 2 m K D F 8 Y g k m i t l b E R l i h Y m x E Z V s C N 7 y y 6 u k d V n 1 a t W b h 1 q l f p v H U Y Q T O I M L 8 O A K 6 n A P D W g C A Q 7 P 8 A p v z t h 5 c d 6 d j 0 V r w c l n j u E P n M 8 f S X u P f w = = < / l a t e x i t >

g

⇠< l a t e x i t s h a 1 _ b a s e 6 4 = " 9 u 7 L 5 P 9 s i R + Z T M Z B n E r J C c i x W 2 E = " > A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 i R b R U 9 m V g n o r e v F Y w X 5 I d y n Z N N u G J t k l y Q p l 6 a / w 4 k E R r / 4 c b / 4 b 0 3 Y P 2 v p g 4 P H e D D P z w o Q z b V z 3 2 y m s r K 6 t b x Q 3 S 1 v b O 7 t 7 5 f 2 D l o 5 T R W i T x D x W n R B r y p m k T c M M p 5 1 E U S x C T t v h 6 H b q t 5 + o 0 i y W D 2 a c 0 E D g g W Q R I 9 h Y 6 d H X T P j H a H D W K 1 f c q j s D W i Z e T i q Q o 9 E r f / n 9 m K S C S k M 4 1 r r r u Y k J M q w M I 5 x O S n 6 q a Y L J C A 9 o 1 1 K J B d V B N j t 4 g k 6 t 0 k d R r G x J g 2 b q 7 4 k M C 6 3 H I r S d A p u h X v S m 4 n 9 e N z X R V Z A x m a S G S j J f F K U c m R h N v 0 d 9 p i g x f G w J J o r Z W x E Z Y o W J s R m V b A j e 4 s v L p H V R 9 W r V 6 / t a p X 6 T x 1 G E I z i B c / D g E u p w B w 1 o A g E B z / A K b 4 5 y X p x 3 5 2 P e W n D y m U P 4 A + f z B 6 w y j 7 A = < / l a t e x i t > ⇠< l a t e x i t s h a 1 _ b a s e 6 4 = " O U Y L w 2 Y W p l u p X d Y b X p s D p T w x i N A = " > A A A B 8 X i c b V B N S w M x E J 3 1 s 9 a v q k c v 0 S L 1 V H a l o N 6 K X j x W s B / Y X U o 2 z b a h S X Z J s k J Z + i + 8 e F D E q / / G m / / G t N 2 D t j 4 Y e L w 3 w 8 y 8 M O F M G 9 f 9 d l Z W 1 9 Y 3 N g t b x e 2 d 3 b 3 9 0 s F h S 8 e p I r R J Y h 6 r T o g 1 5 U z S p m G G 0 0 6 i K B Y h p + 1 w d D v 1 2 0 9 U a R b L B z N O a C D w Q L K I E W y s 9 O h r J v w T N K h U e q W y W 3 V n Q M v E y 0 k Z c j R 6 p S + / H 5 N U U G k I x 1 p 3 P T c x Q Y a V Y Y T T S d F P N U 0 w G e E B 7 V o q s a A 6 y G Y X T 9 C Z V f o o i p U t a d B M / T 2 R Y a H 1 W I S 2 U 2 A z 1 I v e V P z P 6 6 Y m u g o y J p P U U E n m i 6 K U I x O j 6 f u o z x Q l h o 8 t w U Q x e y s i Q 6 w w M T a k o g 3 B W 3 x 5 m b Q u q l 6 t e n 1 f K 9 d v 8 j g K c A y n c A 4 e X E I d 7 q A B T S A g 4 R l e 4 c 3 R z o v z 7 n z M W 1 e c f O Y I / s D 5 / A E P I Y / h < / l a t e x i t >

g0 g00

⇠< l a t e x i t s h a 1 _ b a s e 6 4 = " e o e A x 2 m N w I B K V g f H p d Y 5 N F C b 5 v s = " > A A A B 7 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 i R b B U 9 m V g n o r e v F Y w X 5 A d y n Z N N u G J t l t k h X K 0 j / h x Y M i X v 0 7 3 v w 3 p u 0 e t P X B w O O 9 G W b m h Q l n 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H L R 2 n i t A m i X m s O i H W l D N J m 4 Y Z T j u J o l i E n L b D 0 d 3 M b z 9 R p V k s H 8 0 k o Y H A A 8 k i R r C x U s f X T P i n a N A r V 9 y q O w d a J V 5 O K p C j 0 S t / + f 2 Y p I J K Q z j W u u u 5 i Q k y r A w j n E 5 L f q p p g s k I D 2 j X U o k F 1 U E 2 v 3 e K z q 3 S R 1 G s b E m D 5 u r v i Q w L r S c i t J 0 C m 6 F e 9 m b i f 1 4 3 N d F 1 k D G Z p I Z K s l g U p R y Z G M 2 e R 3 2 m K D F 8 Y g k m i t l b E R l i h Y m x E Z V s C N 7 y y 6 u k d V n 1 a t W b h 1 q l f p v H U Y Q T O I M L 8 O A K 6 n A P D W g C A Q 7 P 8 A p v z t h 5 c d 6 d j 0 V r w c l n j u E P n M 8 f S X u P f w = = < / l a t e x i t >

g

⇠< l a t e x i t s h a 1 _ b a s e 6 4 = " 9 u 7 L 5 P 9 s i R + Z T M Z B n E r J C c i x W 2 E = " > A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 i R b R U 9 m V g n o r e v F Y w X 5 I d y n Z N N u G J t k l y Q p l 6 a / w 4 k E R r / 4 c b / 4 b 0 3 Y P 2 v p g 4 P H e D D P z w o Q z b V z 3 2 y m s r K 6 t b x Q 3 S 1 v b O 7 t 7 5 f 2 D l o 5 T R W i T x D x W n R B r y p m k T c M M p 5 1 E U S x C T t v h 6 H b q t 5 + o 0 i y W D 2 a c 0 E D g g W Q R I 9 h Y 6 d H X T P j H a H D W K 1 f c q j s D W i Z e T i q Q o 9 E r f / n 9 m K S C S k M 4 1 r r r u Y k J M q w M I 5 x O S n 6 q a Y L J C A 9 o 1 1 K J B d V B N j t 4 g k 6 t 0 k d R r G x J g 2 b q 7 4 k M C 6 3 H I r S d A p u h X v S m 4 n 9 e N z X R V Z A x m a S G S j J f F K U c m R h N v 0 d 9 p i g x f G w J J o r Z W x E Z Y o W J s R m V b A j e 4 s v L p H V R 9 W r V 6 / t a p X 6 T x 1 G E I z i B c / D g E u p w B w 1 o A g E B z / A K b 4 5 y X p x 3 5 2 P e W n D y m U P 4 A + f z B 6 w y j 7 A = < / l a t e x i t >

g0

⇠< l a t e x i t s h a 1 _ b a s e 6 4 = " O U Y L w 2 Y W p l u p X d Y b X p s D p T w x i N A = " > A A A B 8 X i c b V B N S w M x E J 3 1 s 9 a v q k c v 0 S L 1 V H a l o N 6 K X j x W s B / Y X U o 2 z b a h S X Z J s k J Z + i + 8 e F D E q / / G m / / G t N 2 D t j 4 Y e L w 3 w 8 y 8 M O F M G 9 f 9 d l Z W 1 9 Y 3 N g t b x e 2 d 3 b 3 9 0 s F h S 8 e p I r R J Y h 6 r T o g 1 5 U z S p m G G 0 0 6 i K B Y h p + 1 w d D v 1 2 0 9 U a R b L B z N O a C D w Q L K I E W y s 9 O h r J v w T N K h U e q W y W 3 V n Q M v E y 0 k Z c j R 6 p S + / H 5 N U U G k I x 1 p 3 P T c x Q Y a V Y Y T T S d F P N U 0 w G e E B 7 V o q s a A 6 y G Y X T 9 C Z V f o o i p U t a d B M / T 2 R Y a H 1 W I S 2 U 2 A z 1 I v e V P z P 6 6 Y m u g o y J p P U U E n m i 6 K U I x O j 6 f u o z x Q l h o 8 t w U Q x e y s i Q 6 w w M T a k o g 3 B W 3 x 5 m b Q u q l 6 t e n 1 f K 9 d v 8 j g K c A y n c A 4 e X E I d 7 q A B T S A g 4 R l e 4 c 3 R z o v z 7 n z M W 1 e c f O Y I / s D 5 / A E P I Y / h < / l a t e x i t >

g00

N< l a t e x i t s h a 1 _ b a s e 6 4 = " A i z T e X p l B v n 9 P W e W H A X H z W a q l V Y = " > A A A B 8 n i c b V D L S g M x F L 1 T X 7 W + q i 7 d B I v g q s x U Q Z d F N 6 6 k g n 3 A d C i Z N N O G Z p I h y Q h l 6 G e 4 c a G I W 7 / G n X 9 j p p 2 F t h 4 I H M 6 5 l 5 x 7 w o Q z b V z 3 2 y m t r W 9 s b p W 3 K z u 7 e / s H 1 c O j j p a p I r R N J J e q F 2 J N O R O 0 b Z j h t J c o i u O Q 0 2 4 4 u c 3 9 7 h N V m k n x a K Y J D W I 8 E i x i B B s r + f 0 Y m z H B P L u f D a o 1 t + 7 O g V a J V 5 A a F G g N q l / 9 o S R p T I U h H G v t e 2 5 i g g w r w w i n s 0 o / 1 T T B Z I J H 1 L d U 4 J j q I J t H n q E z q w x R J J V 9 w q C 5 + n s j w 7 H W 0 z i 0 k 3 l E v e z l 4 n + e n 5 r o O s i Y S F J D B V l 8 F K U c G Y n y + 9 G Q K U o M n 1 q C i W I 2 K y J j r D A x t q W K L c F b P n m V d B p 1 7 6 L e e L i s N W + K O s p w A q d w D h 5 c Q R P u o A V t I C D h G V 7 h z T H O i / P u f C x G S 0 6 x c w x / 4 H z + A I V d k W g = < / l a t e x i t >

}
<latexitsha1_base64="z9I03uDaA3bS8qEriCB/zLQ+3nM=">AAAB6XicbVBNS8NAEJ3Ur1q/qh69LBbBU0mqoMeiF49V7Ae0oWy2m3bpZhN2J0IJ/QdePCji1X/kzX/jts1BWx8MPN6bYWZekEhh0HW/ncLa+sbmVnG7tLO7t39QPjxqmTjVjDdZLGPdCajhUijeRIGSdxLNaRRI3g7GtzO//cS1EbF6xEnC/YgOlQgFo2ilh960X664VXcOskq8nFQgR6Nf/uoNYpZGXCGT1Jiu5yboZ1SjYJJPS73U8ISyMR3yrqWKRtz42fzSKTmzyoCEsbalkMzV3xMZjYyZRIHtjCiOzLI3E//zuimG134mVJIiV2yxKEwlwZjM3iYDoTlDObGEMi3srYSNqKYMbTglG4K3/PIqadWq3kW1dn9Zqd/kcRThBE7hHDy4gjrcQQOawCCEZ3iFN2fsvDjvzseiteDkM8fwB87nD5/ajWs=</latexit>

mq ,agx < l a t e x i t s h a 1 _ b a s e 6 4 = " 3 x d x q r n r x B + X A W L C A e Y o T 8 k P k l E = " > A A A B / X i c b V D L S s N A F J 3 U V 6 2 v + N i 5 G S x C B S m J F N R d 0 Y U u K 9 g H N C F M J p N 2 6 C Q T Z y Z i D c V f c e N C E b f + h z v / x m m b h b Y e u H A 4 5 1 7 u v c d P G J X K s r 6 N w s L i 0 v J K c b W 0 t r 6 x u W V u 7 7 Q k T w U m T c w Z F x 0 f S c J o T J q K K k Y 6 i S A o 8 h l p + 4 P L s d + + J 0 J S H t + q Y U L c C P V i G l K M l J Y 8 c 8 + J 0 I O X 3 R 3 3 R v C q U X F w w N W R Z 5 a t q j U B n C d 2 T s o g R 8 M z v 5 y A 4 z Q i s c I M S d m 1 r U S 5 G R K K Y k Z G J S e V J E F 4 g H q k q 2 m M I i L d b H L 9 C B 5 q J Y A h F 7 p i B S f q 7 4 k M R V I O I 1 9 3 R k j 1 5 a w 3 F v / z u q k K z 9 y M x k m q S I y n i 8 K U Q c X h O A o Y U E G w Y k N N E B Z U 3 w p x H w m E l Q 6 s p E O w Z 1 + e J 6 2 T q l 2 r n t / U y v W L P I 4 i 2 A c H o A J s c A r q 4 B o 0 Q B N g 8 A i e w S t 4 M 5 6 M F + P d + J i 2 F o x 8 Z h f 8 g f H 5 A 1 5 t l I o = < / l a t e x i t >

GP (·)

Goal

Figure 3: RTohlleouRt ecursive Mental Model allows for each sampled gReenceurrsaitvieoMn etontaslpMawodnela new dialogue and corre-
sponding trajectory to the goal. The dialogue that leads
to the most goal progress is followed by the agent.

signal for answer generation, which in turn is derived from the training signal from navigation error. The agent’s progress towards the goal in the environment informs the dialogue itself; each model educates the others (Figure 3).
Each model among the N avigator, Questioner, and Guide may sample N trajectories or generations of max length L. These samples in turn are considered recursively by the RMM agent, leading to N T possible dialogue trajectories, where T is at most the maximum trajectory length. To prevent unbounded exponential growth during training, each model is limited to a maximum number of total recursive calls per run. Search techniques, such as frontiers (Ke et al., 2019), could be employed in future work to guide the agent.
Training In the dialogue task we introduce, the agents begin only knowing the name of the target object. The N avigator agent must move towards the goal room containing the target object, and can ask questions using the Questioner model. The Guide agent answers those questions given a privileged view of the next steps in the shortest path to the goal rendered as visual observations.
We deﬁne two different loss functions to learn the parameters θ of the N avigator agent. We learn a policy πθ(τ |tO) which maximizes the loglikelihood of the shortest path trajectory τ given target object tO present in the goal room (Eq. 1). The action decoder at = fθD (zt, It) takes language encoder zt = fθE (w1:t) as input along with the image observations It at time t. Dialogue context at time t, w1:t is input to the language encoder. The cross entropy loss is deﬁned as:
T
JCE(θ) = − log πθ(at|It, tO, w1:t) (1)
t=1
Our second N avigator RL agent loss is standard policy gradient based Advantage Actor Critic (Sut-

ton and Barto, 1998) minimizing a k-step TD3 error of the critic, JRL(θ):

= − T Aπ log πθ(at|It, tO, w1:t) + 12 T (Aπ)2

t=1

t=1

(2)

Aπ=rt+1+V π(It+1)-V π(It) is the advantage function in Eq. 2, where rt+1 is the reward measured by the goal progress and the V π denotes the statevalue (critic) model. The ﬁrst term in Eq. 2 is the
actor loss, while the second term is the critic (value)
loss of the advantage actor critic loss function. The
overall system is trained end-to-end using sum of the RL agent loss of the navigator agent JRL(θ) and the cross entropy loss between the ground truth and the generated trajectories, JCE(θ). The speaker model parameters are also updated via the
sum of the standard question/answer generation cross entropy and the composite N avigator agent loss from the branch with the max goal progress.

Inference During training, exact environmental feedback—the remaining distance to the goal—can be used to evaluate samples and trajectories. This information is not available during inference, so we instead rely on the navigator’s conﬁdence to determine which of several sampled paths should be explored. For every question-answer pair sampled, the agent rolls forward ﬁve navigation actions per sequence, and the trajectory sequence with the highest probability is used for the next timestep. This heuristic does not guarantee that the model is progressing towards the goal, but empirically conﬁdence-based estimation enables progress.

4.3 Dialogue Gameplay
As is common in dialogue settings, there are several moving pieces and a growing notion of state throughout training and evaluation. In addition to the N avigator, Questioner, and Guide, the N avigator agent also needs to determine when to invoke the Questioner model to get supervision from the Guide (C1). We leave this component— when to ask questions—for future work and set a ﬁxed number of steps before asking a question. We invoke the Questioner model after every 4 navigation steps based on the human average of 4.5 steps between questions in CVDN.
Setting a maximum trajectory length is required due to computational constraints as the the lan-
3Temporal Difference

guage context w1:j grows. Following Thomason

et al. (2019), we use a maximum navigation length

of 80 steps, leading to a maximum of

80 4

=

20

question-answer exchanges per dialogue.

We use a single model for question and answer

generation, and indicate the role of spans of text by

prepending <NAV> (Questioner navigation ques-

tions) or <ORA> (Guide answers based on oracle

views) tags (Figure 2a) to condition the generation

task. During roll outs the model is reinitialized to

prevent information sharing via the hidden units.

4.4 Training Details
We initialize the N avigator, Questioner, and Guide agents as encoder-decoder LSTM models with 512 hidden dimensions. The N avigator encoder is a forward LSTM, while the Questioner and Guide speaker models use bi-LSTM encoders. We use the 512 dimensional penultimate ResNet layer for image observations It, embed words w in 256 dimensions, and embed actions in 32 dimensions. The models observe a word history up to 160 tokens, and can decode up to 80 actions per episode. The value/critic module is a linear layer with relu and dropout on top of the hidden state.
We optimize the N avigator models with the Adam optimizer (Kingma and Ba, 2015) with a learning rate of 0.0001 with weight decay 0.0005. For the Questioner and Guide models, we use an RMSProp optimizer with learning rate 0.0001.
Models are pretrained on CVDN data with batches of size 100 for 20, 000 iterations. During self-play, models are trained with batches of 10, for RMM with N = 3, or 100 else for 5, 000 iterations. A dropout rate of 0.5 is used during all training. All N avigator models are trained using student sampling (Anderson et al., 2018). In RMMN=3, one action sequence is produced via argmax decoding, while the other two via sampling (no temperature). The same is true for language decoding but with a temperature of 0.6. Exploration of how sampler strategies effect performance is left for future work.

Data Augmentation (DA) Navigation agents can beneﬁt from generated language instructions (Fried et al., 2018). We augment the baseline model’s navigation training data in a fashion similar to the rollouts of RMMN=3 to create a more direct comparison between the baseline and RMM. We choose a CVDN conversation and sample three action trajectory rollouts, two by sampling an action at each timestep, and one by taking the argmax

Val Unseen Val Seen

Model

Goal Progress (m) ↑ BLEU ↑

tO QAi-1 QA1:i-1 S+tOoprpacinleg QAi-1 QA1:i-1

Seq2Seq

20.1 10.5 15.0 22.9 0.9 0.8

Seq2Seq + DA 20.1 10.5 10.0 14.2 1.3 1.3

RMMN =1

18.7 10.0 13.3 20.4 3.3 3.0

RMMN =3

18.9 11.5 14.0 16.8 3.4 3.6

Shortest Path ———– 32.8 ———–

Seq2Seq

6.8 4.7 4.6 6.3 0.5 0.5

Seq2Seq + DA 6.8 5.6 4.4 6.5 1.3 1.1

RMMN =1

6.1 6.1 5.1 6.0 2.6 2.8

RMMN =3

7.3 5.5 5.6 8.9 2.9 2.9

Shortest Path ———– 29.3 ————

Table 2: Dialogue results on CVDN. Data Augmentation adds noisy training data for the model. Goal progress evaluates the quality of the inferred navigation trajectory, while BLEU scores estimate the quality of the generated questions and answers. Evaluations conditioning on the entire dialogue history are highlighted in gray with the best results in blue.

action at each timestep. We evaluate those trajectories’ progress towards the conversation goal location and keep the best for augmentation. We give the visual observations of the chosen path to the pretrained Questioner model to produce a relevant instruction. This trajectory paired with a generated language instruction is added to the training data, and we downweight the contributions of these noisier pairs to the overall loss, so loss = λ ∗ generations + (1 − λ) ∗ human. The choice of λ affects the ﬂuency of the language generated; we use λ = 0.1.
5 Results
In Table 2 we present dialogue results for our RMM agent and competitive baselines. We report two main results and four ablations for seen and unseen house evaluations; the former are novel dialogues in houses seen at training time, while the latter are novel dialogues in novel houses.
Full Evaluation The full evaluation paradigm conditions navigation on the entire dialogue history QA1:i-1 in addition to the original target object tO. We present two conditions for RMM (N = 1 and N = 3). Recall that N indicates the number of trajectories (N avigator) or generations (Questioner, Guide) explored in our recursive calls. N = 1 corresponds to taking the single maximum prediction while N = 3 allows the agent to sample alternatives (Section 4.2). While low, the BLEU scores are better for RMM-based agents across settings.

A challenge for navigation agents is knowing when to stop. Following previous work (Anderson et al., 2018), we additionally report Oracle Success Rates measuring the best goal progress the agents achieve along the trajectory.
In unseen environments, the RMM-based agents make the most progress towards the goal and beneﬁt from exploration at during inference (N = 3), and this result holds when considering Oracle Success. In seen environments, by contrast, the RMM-based agents perform slightly less well than the baseline sequence-to-sequence models on goal progress. This effect may be a consequence of environment bias in navigation simulations where houses are seen at both training and inference time with overlapping paths (Zhang et al., 2020).
Ablations We also include two simpler results: tO, where the agent is only provided the target object and explores based on this simple goal, and QAi-1 where the agent is only provided the previous question-answer pair. Both of these settings simplify the learning and evaluation by focusing the agent on search and less ambiguous language, respectively. There are two results to note.
First, given only tO the RMM trained model with sampling generalizes best to unseen environments. In this setting, during inference all models have the same limited information, so the RL loss and exploration have better equipped RMM to generalize.
Second, several trends invert between the seen and unseen scenarios. Speciﬁcally, the simplest model with the least information performs best overall in seen houses. This high performance coupled with weak language appears to indicate the models are learning a different (perhaps search based) strategy rather than how to utilize dialogue. In the QAi-1 and QA1:i-1 settings, the agent generates a question-answer pair before navigating, so the relative strength of the RMM model’s communication becomes clear. We analyze the generated language and navigation behavior of our models.
6 Analysis
We analyze the lexical diversity and effectiveness of generated questions by the RMM.
6.1 Lexical Diversity
Both RMM and Data Augmentation introduce new language by exploring and the environment and generating dialogues. In the case of RMM, an RL loss is used to update the models based on the most

Lexical Frequency Count

104 103 102 101 100
0

DA RMM Human

200 Ind4e0x0of Word 600

800

Figure 4: Log-frequency of words generated by human speakers as compared to the Data Augmentation (DA) and our Recursive Mental Model (RMM) models.

successful dialogue. Using Data Augmentation, the best generations are simply appended to the dataset for one epoch and weighted appropriately for standard, supervised training. The augmentation strategy leads to small boost in BLEU performance and goal progress in several settings (Table 2), but the language appears to collapse to repetitive and generic interactions. We see this manifest rather dramatically in Figure 4, where the DA is limited to only 22 lexical types. In contrast, RMM continues to produce over 500 unique lexical types, much closer to the nearly 900 used by humans.
Human Evaluation We collected human judgements comparing human dialogs with generated dialogs from the baseline and RMM agents on 254 randomly selected episodes from the unseen validation set. While RMM uses an RL objective to inform its language generation and achieves higher progress towards the goal in this setting (Table 2), it is rated as equally or more grammatical (57%) and as equally or more ﬂuent (60%) than the baseline agent, suggesting that RMM’s generated language has not devolved into a “neuralese” to achieve better task performance. Human dialogs were rated as equally or more grammatical and ﬂuent than RMM (89%/83%) and the baseline (88%/80%).
6.2 Effective Questions
The dialogue paradigm allows us to assess the efﬁcacy of speech acts in accomplishing goals. In a sense, the best question elicits the answer that maximizes the progress towards the goal room. If agents are truly effective at modeling one other, we expect the number of dialogue acts to be minimal.
Human conversations in CVDN always reach the goal location, and usually with only 3-4 questions, as shown in Figure 5a. We see that the relationship between questions and progress is roughly linear,

Ave Percent Goal Progress Made Percent Goal Progress

100

80

20

60

15

40

10

20

5

00

20

40

60

80

100

0

Percent Dialogue Questions Asked and Goal Guesses So Far

Baseline DA RMM

5 Number o1f0Questions 15

20

(a) Human goal progress as dialogues unfold. As humans ask questions and make goal guesses, they roughly linearly make progress towards the goal location.

(b) Model goal progress against the number of questions. DA

and RMM generated dialogues progress (ending below 25% of

Target: Fir make slower but consistent
total goal progress).

e

Extin

Figure 5: Effectiveness of human dialogues (left) versus our models (right) at reaching the goal location. The slopes indicate the effectiveness of each dialogue exchange in reaching the target.

excusing the occasional lost and confused human teams. The ﬁnal human-human question is often simply conﬁrmation that navigation has arrived successfully to the goal room.
In Figure 5b, we plot dialogues for the Baseline, Data Augmentation, and RMM agents against percent goal progress. The RMM consistently outperforms the other two agents in terms of goal progress for each dialogue act. We see an increase in progress for the ﬁrst 10 to 15 questions before RMM levels off. By contrast, the Baseline and Data Augmentation agents exhibit shallower curves and fail to reach the same level of performance.
6.3 Example Dialogue
While Figure 1 shows a cherry-picked RMM trajectory from an unseen validation house, Figure 6 gives a lemon-picked RMM trajectory. We discuss the successes and failures of a lemon-picked— showcasing model failure—trajectory in Figure 6. As with all CVDN instances, there are multiple target object candidates (here, “ﬁre extinguisher”) but only one valid goal room. Agents can become distracted by objects of the target instance in nongoal rooms. When the Guide is shown the next few shortest path steps to communicate, those steps are towards the goal room. As can be seen in Figure 6, the learned agents have difﬁculty in deciding when to stop and begin retracing their steps, and in this case never arrived to the correct goal room.
The learned models’ generated language is of different levels of quality, with RMM language much more coherent and verbose than Data Augmentation language. Figure 7 shows generated conversations along with the Goal Progress (GP) at each point when a question was asked. Note that the generation procedure for all models use the same sam-

Humans RMM
Baseline
Figure 6: Trajectories in an unseen environment attempting to ﬁnd a target “ﬁre extinguisher.” The red stop-sign is the goal room, while the black stop-sign is a non-goal room containing ﬁre extinguishers. The white trajectory is the human path from CVDN, black is the Baseline model, and green is our RMMN=3.
pler, and they start training from the same checkpoint, so the relatively coherent nature of the RMM as compared to the simple repetitiveness of the Data Augmentation is entirely due to the recursive calls and RL loss. No model uses length penalties or other generation tricks to avoid degeneration.
7 Conclusions and Future Work
We present a two-agent task paradigm for cooperative vision-and-dialogue navigation (CVDN). Existing work in vision-and-language navigation is largely limited to navigation only (C4), sometimes with limited additional instructions (C4,C3). By contrast, this work requires navigation (C4), question asking (C2), and question answering (C3) components for learned, end-to-end dialogue. We ﬁnd that simple speaker models are insufﬁcient for the dialogue setting, and demonstrate promising results from a recursive RL formulation with turn taking informed by theory of mind.

DA Human

Conversation Do I go in between the ropes to my right or straight forward? Should I proceed down the hall to the left of turn right? Should I go through the open doors that are the closest to me? should i go into the room? should i go into the room? should i head forward or bedroom the next hallway in front of me? should i turn left here?
lots of sink in this house, or wrong did. ok which way do i go

GP

straight forward through the next room

0

head down the hall to your right into the next room 13.3

You are in the goal room

29.1

you are in the goal room.

5.7

you are in the goal room.

0.0

yes, all the way down the small hall.

4.0

head into the house, then you will ﬁnd a doorway 5.7 at the goal staircase. go through the doors before those two small exit chairs, about half way down the hall. go down the hallway, take a left and go down the 8.8 next hallway and up the stairs on the right.

Figure 7: Dialogue samples for Figure 6 with corresponding Goal Progress – see appendix for complete outputs.

RMMN =3

There are several limitations to the models presented in this paper. We consider only agent-agent models, while the long-term goal of human-agent communication will require both human-in-theloop training and evaluation. Future work using RMM-style modelling inspired by theory of mind will likely need to explicitly model the human interlocutor due to perceptual and communication differences (Liu and Chai, 2015), rather than assuming the interlocutor can be modeled as a copy of oneself as in this paper. Such modeling may incorporate world knowledge for richer notions of common ground, for example by explicitly detecting scene objects rather than using a ﬁxed visual embedding (Zhang et al., 2020). Additionally, we currently require the N avigator agent to ask questions after a ﬁxed number of steps, while determining when to ask questions is a complex problem in itself (C1) (Chi et al., 2020). Furthermore, we use a ﬁxed branching factor, while a dynamic branching factor in non-parametric learning setting can incorporate the uncertainty of the policy model.
We hope this task paradigm will inspire future research on learning agent-agent, task-oriented communication with an eye towards human-agent cooperation and language-guided robots.
Acknowledgements
We thank the anonymous reviewers and the AC for the questions they raised and their helpful commentary, which strengthened the presentation of our task and models. This work was funded in part by ARO grant (W911NF-16-1-0121).

References
Peter Anderson, Ayush Shrivastava, Devi Parikh, Dhruv Batra, and Stefan Lee. 2019. Chasing ghosts: Instruction following as bayesian state tracking. In Thirty-third Conference on Neural Information Processing Systems (NeurIPS).
Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark Johnson, Niko Sunderhauf, Ian Reid, Stephen Gould, and Anton van den Hengel. 2018. Visionand-language navigation: Interpreting visuallygrounded navigation instructions in real environments. In Computer Vision and Pattern Recognition (CVPR).
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural machine translation by jointly learning to align and translate. In International Conference on Learning Representations (ICLR).
Yonatan Bisk, Ari Holtzman, Jesse Thomason, Jacob Andreas, Yoshua Bengio, Joyce Chai, Mirella Lapata, Angeliki Lazaridou, Jonathan May, Aleksandr Nisnevich, Nicolas Pinto, and Joseph Turian. 2020. Experience Grounds Language. ArXiv.
Antoine Bordes and Jason Weston. 2017. Learning end-to-end goal-oriented dialog. In International Conference on Learning Representations (ICLR).
Kris Cao, Angeliki Lazaridou, Marc Lanctot, Joel Z Leibo, Karl Tuyls, and Stephen Clark. 2018. Emergent communication through negotiation. In International Conference on Learning Representations (ICLR).
Joyce Y Chai, Qiaozi Gao, Lanbo She, Shaohua Yang, Sari Saba-Sadiya, and Guangyue Xu. 2018. Language to action: Towards interactive task learning with physical agents. In International Joint Conference on Artiﬁcial Intelligence (IJCAI).
Angel Chang, Angela Dai, Thomas Funkhouser, Maciej Halber, Matthias Nießner, Manolis Savva, Shuran Song, Andy Zeng, and Yinda Zhang. 2017. Matterport3d: Learning from rgb-d data in indoor en-

vironments. In International Conference on 3D Vision.
David Chen and Raymond J Mooney. 2011. Learning to interpret natural language navigation instructions from observations. In Conference on Artiﬁcial Intelligence (AAAI).
Howard Chen, Alane Suhr, Dipendra Misra, Noah Snavely, and Yoav Artzi. 2019. Touchdown: Natural language navigation and spatial reasoning in visual street environments. In Computer Vision and Pattern Recognition (CVPR).
Ta-Chung Chi, Mihail Eric, Seokhwan Kim, Minmin Shen, and Dilek Hakkani-tur. 2020. Just ask: An interactive learning framework for vision and language navigation. In Conference on Artiﬁcial Intelligence (AAAI).
Abhishek Das, Satwik Kottur, Khushi Gupta, Avi Singh, Deshraj Yadav, Jose´ M.F. Moura, Devi Parikh, and Dhruv Batra. 2017a. Visual Dialog. In Computer Vision and Pattern Recognition (CVPR).
Abhishek Das, Satwik Kottur, Jose´ M.F. Moura, Stefan Lee, and Dhruv Batra. 2017b. Learning cooperative visual dialog agents with deep reinforcement learning. In International Conference on Computer Vision (ICCV).
Michael C. Frank and Noah D. Goodman. 2012. Predicting pragmatic reasoning in language games. Science, 336(6084):998–998.
Daniel Fried, Ronghang Hu, Volkan Cirik, Anna Rohrbach, Jacob Andreas, Louis-Philippe Morency, Taylor Berg-Kirkpatrick, Kate Saenko, Dan Klein, and Trevor Darrell. 2018. Speaker-follower models for vision-and-language navigation. In Neural Information Processing Systems (NeurIPS).
Jianfeng Gao, Michel Galley, and Lihong Li. 2019. Neural approaches to conversational AI. Foundations and Trends in Information Retrieval.
Alison Gopnik and Henry M Wellman. 1992. Why the child’s theory of mind really is a theory. Mind ‘I&’ Language, 7 (1-2):145–171.
Herbert Paul Grice, P Cole, and J J Morgan. 1975. Logic and conversation. Syntax and Semantics, volume 3: Speech Acts, pages 41–58.
Donghoon Ham, Jeong-Gwan Lee, and Youngsoo Jang andKee Eung Kim. 2020. End-to-end neural pipeline for goal-oriented dialogue system using gpt2. In Conference on Association for the Advancement of Artiﬁcial Intelligence (AAAI).
Weituo Hao, Chunyuan Li, Xiujun Li, Lawrence Carin, and Jianfeng Gao. 2020. Towards Learning a Generic Agent for Vision-and-Language Navigation via Pre-training. In Computer Vision and Pattern Recognition (CVPR).

Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. Deep residual learning for image recognition. arxiv:1512.03385.
Sepp Hochreiter and Ju¨rgen Schmidhuber. 1997. Long short-term memory. Neural Computation, 9(8):1735–1780.
Prashant Jayannavar, Anjali Narayan-Chen, and Julia Hockenmaier. 2020. Learning to execute instructions in a Minecraft dialogue. In Association for Computational Linguistics (ACL).
Da Young Ju, Kurt Shuster, Y-Lan Boureau, and Jason Weston. 2019. All-in-one image-grounded conversational agents. ArXiv, abs/1912.12394.
Liyiming Ke, Xiujun Li, Yonatan Bisk, Ari Holtzman, Zhe Gan, Jingjing Liu, Jianfeng Gao, Yejin Choi, and Siddhartha Srinivasa. 2019. Tactical rewind: Self-correction via backtracking in visionand-language navigation. In Computer Vision and Pattern Recognition (CVPR).
Diederik P Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. In International Conference on Learning Representations.
Bing Liu, Go¨khan Tu¨r, Dilek Hakkani-Tu¨r, Pararth Shah, and Larry P. Heck. 2017. End-to-end optimization of task-oriented dialogue model with deep reinforcement learning. CoRR, abs/1711.10712.
Changsong Liu and Joyce Yue Chai. 2015. Learning to mediate perceptual differences in situated humanrobot dialogue. In Proceedings of the 29th AAAI Conference on Artiﬁcial Intelligence, pages 2288– 2294.
Chih-Yao Ma, Zuxuan Wu, Ghassan AlRegib, Caiming Xiong, and Zsolt Kira. 2019. The regretful agent: Heuristic-aided navigation through progress estimation. In Computer Vision and Pattern Recognition (CVPR).
Nikola Mrksic, Diarmuid O´ Se´aghdha, Tsung-Hsien Wen, Blaise Thomson, and Steve J. Young. 2017. Neural belief tracker: Data-driven dialogue state tracking. In Association for Computational Linguistics (ACL).
Anjali Narayan-Chen, Prashant Jayannavar, and Julia Hockenmaier. 2019. Collaborative dialogue in Minecraft. In Association for Computational Linguistics (ACL).
Khanh Nguyen and Hal Daume´ III. 2019. Help, anna! visual navigation with natural multimodal assistance via retrospective curiosity-encouraging imitation learning. In Empirical Methods in Natural Language Processing (EMNLP).
Khanh Nguyen, Debadeepta Dey, Chris Brockett, and Bill Dolan. 2019. Vision-based navigation with language-based assistance via imitation learning with indirect intervention. In Computer Vision and Pattern Recognition (CVPR).

Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Association for Computational Linguistics (ACL).
Chris Paxton, Yonatan Bisk, Jesse Thomason, Arunkumar Byravan, and Dieter Fox. 2019. Prospection: Interpretable plans from language by predicting the future. In Proceedings of the International Conference on Robotics and Automation (ICRA).
Baolin Peng, Xiujun Li, Lihong Li, Jianfeng Gao, Asli Celikyilmaz, Sungjin Lee, and Kam-Fai Wong. 2017. Composite task-completion dialogue system via hierarchical deep reinforcement learning. In Empirical Methods in Natural Language Processing (EMNLP).
Pei-Hao Su, Milica Gasic, Nikola Mrksic, Lina Maria Rojas-Barahona, Stefan Ultes, David Vandyke, Tsung-Hsien Wen, and Steve J. Young. 2016. Online active reward learning for policy optimisation in spoken dialogue systems. In Proceedings of the Association for Computational Linguistics (ACL).
R. S. Sutton and A. G. Barto. 1998. Reinforcement learning: An introduction. MIT press Cambridge.
Stefanie Tellex, Ross A Knepper, Adrian Li, Thomas M. Howard, Daniela Rus, and Nicholas Roy. 2014. Asking for help using inverse semantics. In Robots: Science and Systems (RSS).
Jesse Thomason, Michael Murray, Maya Cakmak, and Luke Zettlemoyer. 2019. Vision-and-dialog navigation. Conference on Robot Learning (CoRL).
I. Vlad Serban, R. Lowe, P. Henderson, L. Charlin, and J. Pineau. 2015. A Survey of Available Corpora for Building Data-Driven Dialogue Systems. ArXiv.
Harm de Vries, Kurt Shuster, Dhruv Batra, Devi Parikh, Jason Weston, and Douwe Kiela. 2018. Talk the walk: Navigating new york city through grounded dialogue. arXiv:1807.03367.
Harm de Vries, Florian Strub, Sarath Chandar, Olivier Pietquin, Hugo Larochelle, and Aaron C. Courville. 2017. Guesswhat?! visual object discovery through multi-modal dialogue. In Computer Vision and Pattern Recognition (CVPR).
Xin Wang, Qiuyuan Huang, Asli Celikyilmaz, Jianfeng Gao, Dinghan Shen, Yuan-Fang Wang, William Yang Wang, and Lei Zhang. 2019. Reinforced Cross-Modal Matching and Self-Supervised Imitation Learning for Vision-Language Navigation. In Computer Vision and Pattern Recognition (CVPR).
Xin Wang, Vihan Jain, Eugene Ie, William Yang Wang, Zornitsa Kozareva, and Sujith Ravi. 2020. Environment-agnostic Multitask Learning for Natural Language Grounded Navigation. arXiv:2003.00443.

Yubo Zhang, Hao Tan, and Mohit Bansal. 2020. Diagnosing the environment bias in vision-and-language navigation. In International Joint Conference on Artiﬁcial Intelligence (IJCAI).
Yi Zhu, Fengda Zhu, Zhaohuan Zhan, Bingqian Lin, Jianbin Jiao, Xiaojun Chang, and Xiaodan Liang. 2020. Vision-Dialog Navigation by Exploring Cross-modal Memory. In Computer Vision and Pattern Recognition (CVPR).

A Appendix
A.1 Additional Reproducibility details 1. Hardware: Single NVIDIA P100 GPU

2. Training times: Setting Iterations Average time

Pretraining 20K

Baseline

5k

Data Aug 5k

RMM1

5k

RMM3

5k

273m 1,622m 1,161m 4,205m 6,590m

3. Model parameters:

Speaker

3.5M

Action Decoding 4.7M

4. Hyperparameters:

Bounds for temperature sampling [0.1-2.0]

Bounds for lambda DA contribution [0.1-1.0]

Trials for temperature sampling [0.1, 1.0, 2.0]

Trials for lambda DA contribution [0.1, 0.25, 0.5, 0.75, 1.0]

Method for choice

Grid search

A.2 Human Evaluation details
The table below shows the full results of the human evaluation on a randomly selected subset of 245 unseen environment dialogues. Questions asked:

Q1 Which dialog is more grammatically correct? Q2 Which dialog is more ﬂuent? Q3 Do the two dialogues seem to have the same goal?

Model

% Favored % Same Goal

Q1 Q2

Q3

RMM

35.0 37.0 Same 49.6

Baseline

42.5 39.8 Diff 50.4

No Difference 22.4 23.2

RMM

11.0 17.3 Same 44.9

Human

76.8 67.7 Diff 55.1

No Difference 12.2 15.0

Baseline

12.2 20.1 Same 45.7

Human

78.0 63.8 Diff 54.3

No Difference 9.8 16.1

Baseline

Human

A.3 Conversation Examples
Full human and baseline conversations for Figure 6.
Conversation
Do I go in between the ropes to my right or straight forward? straight forward through the next room Should I proceed down the hall to the left of turn right? head down the hall to your right into the next room Should I go through the open doors that are the closest to me? You are in the goal room
ok now which way ? keep going forward and then into a bedroom on your left . it ’ s to the left of the bed . do i continue going to the right into the living room ? go into the door in front of you , then an right , the bathroom ’ s there . do i keep going to the right into the living room ? it looks like that is the goal room . should i go into the laundry room to my right , or do i need to go in ? i see many ways to tell . you just go around . you ’ re in the right room . ok now which way ? go into the room near you . that should be the goal okay i see any set of stairs . should i go up them ? turn right , then another right , the bathroom ’ s there . ok . can you go more directions . i see many rooms on this ﬂoor . turn right , then another right , the bathroom ’ s there . should i go the room ? or into the door to my left ? turn right , then another right , the bathroom ’ s there . should i stay in this room or go out ? turn right , then another right , the bathroom ’ s there . ok , should i go in this direction ? turn right , go past the pool table , into the room just towards the stairs . that should be the goal . should i go left toward the room , or past the painting and straight ? or to my right ? turn right , then another right , the bathroom ’ s there . should i take a left here in the room ? that is the goal room should i stay in this room or go out ? you see the front , that is the room . its goal room the room ? or into the door to my left ? go up the stairs in front of you , then to your left , you ’ ll see a bathroom . i think that bathroom is the goal should i go left toward the room , or past the painting and straight ? or to my right ? go towards the table in front of me of the hallway after take a right , then make a left into the sitting room . should i go to the right towards the blue painting ? continue going up , go to the bedroom should i go into the door on the left , or keep going forward ? go into the bedroom near you . that should be the goal do i need to go up ? go out in the room , make a right past the blue painting and go up the stairs ok now which way ? go up the spiral stairs again when you ’ go into that bedroom straight ahead . should i go outside ? a bathroom on pretty left , go in it and then into the bathroom in that bedroom

GP 0
13.31 29.05
4.0 5.7 8.8 7.5 4.0 0.4
0 4.0 8.8 9.9 7.5 5.7 8.8 13.3 9.3 9.3 11.1 8.8 7.5 8.8

Data Augmentation and RMM conversations for Figure 6.

Conversation

GP

DA

should i go into the room?

5.66

you are in the goal room.

should i go into the room?

0.03

you are in the goal room.

. . . (repeats until maximum trajectory length is reached)

RMM

should i head forward or bedroom the next hallway in front of me ?

4.0

yes , all the way down the small hall .

should i turn left here ?

5.7

head into the house , then you will ﬁnd a doorway at the goal staircase . go through the doors before those two

small exit chairs , about half way down the hall .

lots of sink in this house , or wrong did . ok which way do i go

8.8

go down the hallway , take a left and go down the next hallway and up the stairs on the right .

right place now ?

7.5

turn left and when you reach to the bathroom . before these go up the stairs on your left , and walk passed the

mirror and chairs on the left into hallway across from the stairs

do i go left , right , or up the stairs ?

4.0

turn to your left and keep going straight

do i make a right turn or shall i enter the room to my left ?

0.4

turn left to go down the hall , then that ﬁre bed has that

left or continue ?

0

yes , go past the dining table and take an immediate right . head through the small door to the left of the window

before those two way doors behind you , go up the second small set of stairs .

should i go downstairs or turn left ?

4.0

go to the right and go to the front doorway .

should i go down the stairs or stay on this ﬂoor ?

8.8

take a left towards the bathroom , then take a left before it and go all the way down the hall

do i go up these is to the right or right of the steps ?

9.9

go to the left side of the staircase and turn left in the doorway before the two small ofﬁce chairs , about half way

down the hall .

should i turn left , go straight into the living room , or up the stairs ?

7.5

turn to your right and go straight down the hall

do i go out into the hallway ?

5.7

go left down the hall where the ofﬁce ﬂoor . and pass the second door after a right and table .

ok , should i go right or left next ?

8.8

go back to the staircase . go through the doorway you and before the hallway on the right .

do i make a left turn or shall i enter the room to my left ?

13.3

go down the hall and turn right into the bedroom

should i go to the left or the right ?

9.3

yes , go out of this room , turn right and go down the white hall before the staircase stairs , then go down the way

down that way you get .

ok i was a in by this ofﬁce painting , or i just in the second hallway in front of me ?

9.3

okay .

which way do i go in , or do i head up the stairs ?

11.1

go all the way to the one of the staircase . turn left in the doorway before the two two ofﬁce chairs , about half

way down the hall .

ok wrong far which way do i go

8.8

right then at the top of the stairs .

left or continue ?

7.5

yes . go down the hall and stop at the landing of the stairs .

