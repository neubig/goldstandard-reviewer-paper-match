Mitigating Manipulation in Peer Review via Randomized Reviewer Assignments

Steven Jecmen Carnegie Mellon University
sjecmen@cs.cmu.edu

Hanrui Zhang Duke University hrzhang@cs.duke.edu

Ryan Liu Carnegie Mellon University ryanliu@andrew.cmu.edu

Nihar B. Shah Carnegie Mellon University
nihars@cs.cmu.edu

Vincent Conitzer Duke University conitzer@cs.duke.edu

Fei Fang Carnegie Mellon University
feif@cs.cmu.edu

arXiv:2006.16437v2 [cs.AI] 23 Oct 2020

Abstract
We consider three important challenges in conference peer review: (i) reviewers maliciously attempting to get assigned to certain papers to provide positive reviews, possibly as part of quid-pro-quo arrangements with the authors; (ii) “torpedo reviewing,” where reviewers deliberately attempt to get assigned to certain papers that they dislike in order to reject them; (iii) reviewer de-anonymization on release of the similarities and the reviewer-assignment code. On the conceptual front, we identify connections between these three problems and present a framework that brings all these challenges under a common umbrella. We then present a (randomized) algorithm for reviewer assignment that can optimally solve the reviewer-assignment problem under any given constraints on the probability of assignment for any reviewer-paper pair. We further consider the problem of restricting the joint probability that certain suspect pairs of reviewers are assigned to certain papers, and show that this problem is NP-hard for arbitrary constraints on these joint probabilities but eﬃciently solvable for a practical special case. Finally, we experimentally evaluate our algorithms on datasets from past conferences, where we observe that they can limit the chance that any malicious reviewer gets assigned to their desired paper to 50% while producing assignments with over 90% of the total optimal similarity. Our algorithms still achieve this similarity while also preventing reviewers with close associations from being assigned to the same paper.
1 Introduction
Peer review, the evaluation of work by others working in the same ﬁeld as the producer of the work or with similar competencies, is a critical component of scientiﬁc research. It is regarded favorably by a signiﬁcant majority of researchers and is seen as being essential to both improving the quality of published research and validating the legitimacy of research publications [1–3]. Due to the wide adoption of peer review in the publication process in academia, the peer-review process can be very high-stakes for authors, and the integrity of the process can signiﬁcantly inﬂuence the careers of the authors (especially due to the prominence of a “rich get richer” eﬀect in academia [4]).
However, there are several challenges that arise in peer review relating to the integrity of the review process. In this work, we address three such challenges for peer review in academic conferences where a number of papers need to be assigned to reviewers at the same time.
(1) Untruthful favorable reviews. In order to achieve a good reviewer assignment, peer review systems must solicit some information about their reviewers’ knowledge and interests. This inherently presents opportunities for manipulation, since reviewers can lie about their interests and expertise. For example, reviewers often are expected to bid on the papers they are interested in reviewing before an assignment
1

algorithm is run to determine the paper assignment. This system can be manipulated, and in fact this is known to have happened in at least one ACM conference [5]:
“Another SIG community has had a collusion problem where the investigators found that a group of PC members and authors colluded to bid and push for each other’s papers violating the usual conﬂict-of-interest rules.”
The problem of manipulation is not limited to the bidding system, as practically anything used to determine paper assignments (e.g., self-reported area of expertise, list of papers the reviewer has published) can potentially be manipulated; in more extreme cases, authors have been known to entirely falsify reviewer identities to get a desired reviewer assignment [6, 7]. In some cases, unethical authors may enter into deals with potential reviewers for their paper, where the reviewer agrees to attempt to get assigned to the author’s paper and give it a favorable review in exchange for some outside reward (e.g., as part of a quid-pro-quo arrangement for the reviewer’s own paper in another publication venue). To preserve the integrity of the reviewing process and maintain community trust, the paper assignment algorithm should guarantee the mitigation of these kinds of arrangements.
(2) Torpedo reviewing. In “torpedo reviewing,” unethical reviewers attempt to get assigned to papers they dislike with the intent of giving them an overly negative review and blocking the paper from publication. This can have wide-reaching consequences [8]:
“If a research direction is controversial in the sense that just 2-or-3 out of hundreds of reviewers object to it, those 2 or 3 people can bid for the paper, give it terrible reviews, and prevent publication. Repeated indeﬁnitely, this gives the power to kill oﬀ new lines of research to the 2 or 3 most close-minded members of a community, potentially substantially retarding progress for the community as a whole.”
One special case of torpedo reviewing has been called “rational cheating,” referring to reviewers negatively reviewing papers that compete with their own authored work [9, 10]. The high-stakes atmosphere of academic publishing can exacerbate this problem [11]:
“The cutthroat attitude that pervades the system results in ludicrous rejections for personal reasons— if the reviewer feels that the paper threatens his or her own research or contradicts his or her beliefs, for example.”
A paper assignment algorithm should guarantee to authors that their papers are unlikely to have been torpedo-reviewed.
(3) Reviewer de-anonymization in releasing assignment data. For transparency and research purposes, conferences may wish to release the paper-reviewer similarities and the paper assignment algorithm used after the conference. However, if the assignment algorithm is deterministic, this would allow for authors to fully determine who reviewed their paper, breaking the anonymity of the reviewing process. Even when reviewer and paper names are removed, identities can still be discovered (as in the case of the Netﬂix Prize dataset [12]). Consequently, a rigorous guarantee of anonymity is needed in order to release the data.
Although these challenges may seem disparate, we address all of them under a common umbrella framework. Our contributions are as follows:
• Conceptual: We formulate problems concerning the three aforementioned issues in peer review, and propose a framework to address them through the use of randomized paper assignments (Section 3).
• Theoretical: We design computationally eﬃcient, randomized assignment algorithms that optimally assign reviewers to papers subject to given restrictions on the probability of assigning any particular reviewer-paper pair (Section 4). We further consider the more complex case of preventing suspicious pairs of reviewers from being assigned to the same paper (Section 5). We show that ﬁnding the optimal assignment subject to arbitrary constraints on the probabilities of reviewer-reviewer-paper assignments is NP-hard. In the practical special case where the program chairs want to prevent pairs of reviewers within the same
2

subset of some partition of the reviewer set (for example, reviewers at the same academic institution or with the same geographical area of residence) from being assigned to the same paper, we present an algorithm that ﬁnds the optimal randomized assignment with this guarantee.
• Empirical: We test our algorithms on datasets from past conferences and show their practical eﬀectiveness (Section 6). As a representative example, on data reconstructed from ICLR 2018, our algorithms can limit the chance of any reviewer-paper assignment to 50% while achieving 90.8% of the optimal total similarity. Our algorithms can continue to achieve this similarity while also preventing reviewers with close associations from being assigned to the same paper. We further demonstrate, using the ICLR 2018 dataset, that our algorithm successfully prevents manipulation of the assignment by a simulated malicious reviewer.
All of the code for our algorithms and our empirical results is freely available online.1
2 Related Literature
Many paper assignment algorithms for conference peer review have been proposed in past work. The widely-used Toronto Paper Matching System (TPMS) [13] computes a similarity score for each reviewer-paper pair based on analysis of the reviewers’ past work and bids, and then aims to maximize the total similarity of the resulting assignment. The framework of “compute similarities and maximize total similarity” (and similar variants) encompasses many paper assignment algorithms, where similarities can be computed in various ways from automated and manual analysis and reviewer bids [14–20]. We treat the bidding process and computation of similarities as given, and focus primarily on adjusting the optimization problem to address the three aforementioned challenges. Some work has considered other optimization objectives such as fairness [21, 22]. We also consider a similar fairness objective in a variant of our algorithm. On a related front, there are also a number of recent works [23–35] which deal with various other aspects of peer review.
Much prior work has studied the issue of preventing or mitigating strategic behavior in peer review. This work usually focuses on the incentives reviewers have to give poor reviews to other papers in the hopes of increasing their own paper’s chances of acceptance [36–40]. Unlike the issues we deal with in this paper, these works consider only reviewers’ incentives to get their own paper accepted and not other possible incentives. We instead consider arbitrary incentives for a reviewer to give an untruthful review, such as a personal dislike for a research area or misincentives brought about by author-reviewer collusion. Instead of aiming to remove reviewer incentives to write untruthful reviews, our work focuses on mitigating the eﬀectiveness of manipulating the reviewer assignment process.
A concurrent work [41] considers a diﬀerent set of problems in releasing data in peer review while preserving reviewer anonymity. The data to be released here are some function of the scores and the reviewer-assignment, whereas we look to release the similarities and the assignment code. Moreover, the approach and techniques in [41] are markedly diﬀerent—they consider post-processing the data for release using techniques such as diﬀerential privacy, whereas we consider randomizing the assignment for plausible deniability.
Outside of peer review, there is a line of prior work focused on detecting and mitigating manipulation in online reviews (such as those on Yelp or Amazon). These works typically make assumptions that are not applicable or require data that is not available in our setting. Several of these works analyze the graph of user reviews in order to detect fraudulent reviewers [42]. For example, [43] detects fraud from the review graph by assuming that products are trying to maximize the number of positive reviews they get, whereas in our setting it is important to mitigate the eﬀectiveness of just a single author-paper collusion since the number of reviews per paper is ﬁxed and small. Additionally, some of these works [44–46] are based on estimating the “true quality” of each item from the review graph, which is not possible in peer review since paper evaluations are subjective. Another direction of prior work uses machine learning to detect malicious behavior. Some research [47] detects fraud from reviewer statistics such as rating variance or number of ratings, but in the peer review setting, there is so little data for each reviewer that such features would be highly noisy or completely uninformative. Other works [48] attempt to detect malicious reviews from the review text, but in our setting, malicious reviews may not diﬀer stylistically from genuine reviews. Finally, some work in recommender systems focuses on making product recommendations resistant to malicious
1https://github.com/theryanl/mitigating_manipulation_via_randomized_reviewer_assignment/
3

reviews [49]; however, in peer review, the paper acceptance process must be done by hand since it must take into account reviewer opinions, arguments, and the reviewer discussion.
Randomized assignments have been used to address the problem of fair division of indivisible goods such as jobs or courses [50, 51], as well as in the context of Stackelberg security games [52]. The paper [25] uses randomization to address the issue of miscalibration in ratings, such as those given to papers in peer review. To the best of our knowledge, the use of randomized reviewer-paper assignments to address the issues of malicious reviewers or reviewer de-anonymization in peer review has not been studied previously. Work on randomized assignments often references the well-known Birkhoﬀ-von Neumann theorem [53, 54] or a generalization in order to demonstrate how to implement a randomized assignment as a lottery over deterministic assignments. The paper [55] proposes a broad generalization of the Birkhoﬀ-von Neumann theorem that we use in our work.
3 Background and Problem Statements
We ﬁrst deﬁne the standard paper assignment problem, followed by our problem setting. In the standard paper assignment setting, we are given a set R of n reviewers and a set P of d papers, along with desired reviewer load k (that is, the maximum number of papers any reviewer should be assigned) and desired paper load (that is, the exact number of reviewers any paper should be assigned to).2 An assignment of papers to reviewers is a bipartite matching between the sets that obeys the load constraints on all reviewers and papers. In addition, we are given a similarity matrix S ∈ Rn×d where Srp denotes how good of a match reviewer r is for paper p. These similarities can be derived from the reviewers’ bids on papers, prior publications, conﬂicts of interest, etc.
The standard problem of ﬁnding a maximum sum-similarity assignment [13, 14, 16, 18, 20] is then written as an integer linear program. The decision variables M ∈ {0, 1}n×d specify the assignment, where Mrp = 1 if and only if reviewer r is assigned to paper p. The objective is to maximize r∈R p∈P SrpMrp subject to the load constraints p∈P Mrp ≤ k, ∀r ∈ R and r∈R Mrp = , ∀p ∈ P. Since the constraint matrix of the linear program (LP) relaxation of this problem is totally unimodular, the solution to the LP relaxation will be integral and so this problem can be solved as an LP. This method of assigning papers has been used by various conferences such as NeurIPS, ICML, ICCV, and SIGKDD (among others) [13, 18], as well as by popular conference management systems EasyChair (easychair.org) and HotCRP (hotcrp.com).
Now, suppose there exists a reviewer who wishes to get assigned to a speciﬁc paper for some malicious reason and manipulates their similarities in order to do so. When the assignment algorithm is deterministic, as in previous work [13, 14,16–18,20], a malicious reviewer who knows the algorithm may be able to eﬀectively manipulate it in order to get assigned to the desired paper. To address this issue, we aim to provide a guarantee that regardless of the reviewer bids and similarities, this reviewer-paper pair has only a limited probability of being assigned.
Consider now the challenge of preserving anonymity in releasing conference data. If a conference releases its similarity matrix and its deterministic assignment algorithm, then anyone could reconstruct the full paper assignment. Interestingly, this problem can be solved in the same way as the malicious reviewer problems described above. If the assignment algorithm provides a guarantee that each reviewer-paper pair has only a limited probability of being assigned, then no reviewer’s identity can be discovered with certainty.
With this motivation, we now consider M as stochastic and aim to ﬁnd a randomized assignment, a probability distribution over deterministic assignments. This naturally leads to the following problem formulation.
Deﬁnition 1 (Pairwise-Constrained Problem). The input to the problem is a similarity matrix S and a matrix Q ∈ [0, 1]n×d. The goal is to ﬁnd a randomized assignment of papers to reviewers (i.e., a distribution
of M ) that maximizes E r∈R p∈P SrpMrp subject to the constraints P[Mrp = 1] ≤ Qrp, ∀r ∈ R, p ∈ P.
Since a randomized assignment is a distribution over deterministic assignments, all assignments M in the support of the randomized assignment must still obey the load constraints p∈P Mrp ≤ k, ∀r ∈ R and
r∈R Mrp = , ∀p ∈ P. The optimization objective is the expected sum-similarity across all paper-reviewer
2For ease of exposition, we assume that all reviewer and paper loads are equal. In practice, program chairs may want to set diﬀerent loads for diﬀerent reviewers or papers; all of our algorithms and guarantees still hold for this case (as does our code).
4

pairs, the natural analogue of the deterministic sum-similarity objective. In practice, the matrix Q is provided by the program chairs of the conference; all entries can be set to a constant value if the chairs have no special prior information about any particular reviewer-paper pair.
To prevent dishonest reviews of papers, program chairs may want to do more than just control the probability of individual paper-reviewer pairs. For example, suppose that we have three reviewers assigned per paper (a very common arrangement in computer science conferences). We might not be particularly concerned about preventing any single reviewer from being assigned to some paper, since even if that reviewer dishonestly reviews the paper, there are likely two other honest reviewers who can overrule the dishonest one. However, it would be much worse if we have two reviewers dishonestly reviewing the same paper, since they could likely overrule the sole honest reviewer.
A second issue is that there may be dependencies within certain pairs of reviewers that cannot be accurately represented by constraints on individual reviewer-paper pairs. For example, we may have two reviewers a and b who are close collaborators, each of which we are not individually very concerned about assigning to paper p. However, we may believe that in the case where reviewer a has entered into a quid-pro-quo deal to dishonestly review paper p, reviewer b is likely to also be involved in the same deal. Therefore, one may want to strictly limit the probability that both reviewers a and b are assigned to paper p, regardless of the limits on the probability that either reviewer individually is assigned to paper p.
With this motivation, we deﬁne the following generalization of the Pairwise-Constrained Problem.
Deﬁnition 2 (Triplet-Constrained Problem). The input to the problem is a similarity matrix S, a matrix Q ∈ [0, 1]n×d, and a 3-dimensional tensor T ∈ [0, 1]n×n×d. The goal is to ﬁnd a randomized assignment
of papers to reviewers that maximizes E r∈R p∈P SrpMrp subject to the constraints P[Mrp = 1] ≤ Qrp, ∀r ∈ R, p ∈ P and P[Map = 1 ∧ Mbp = 1] ≤ Tabp, ∀a, b ∈ R s.t. a = b, p ∈ P.
The randomized assignments that solve these problems can be used to address all three challenges we identiﬁed earlier:
• Untruthful favorable reviews: By guaranteeing a limit on the probability that any malicious reviewer or any malicious pairs of reviewers can be assigned to the paper they want, we mitigate the eﬀectiveness of any unethical deals between reviewers and authors by capping the probability that such a deal can be upheld. This guarantee holds regardless of how extreme a reviewers’ manipulation of the assignment is and without any assumptions on reviewers’ exact incentives. The entries of Q can be set by the program chairs based on their assessment of the risk of allowing the corresponding reviewer-paper pair; for example, an entry can be set low if the reviewer and author have collaborated in the past. The entries of T can be set similarly based on known associations between reviewers.
• Torpedo reviewing: By limiting the probability that any reviewer or pair of reviewers can be assigned to a paper they wish to torpedo, we make it much more diﬃcult for a small group of reviewers to shut down a new research direction or to take out competing papers.
• Reviewer de-anonymization in releasing assignment data: To allow for the release of similarities and the assignment algorithm after a conference, all of the entries in Q can simply be set to some reasonable constant value. Even if reviewer and paper names are fully identiﬁed through analysis of the similarities, only the distribution over assignments can be recovered and not the speciﬁc assignment that was actually used. This guarantees that for each paper, no reviewer’s identity can be identiﬁed with high conﬁdence, since every reviewer has only a limited chance to be assigned to that paper.
In Sections 4 and 5, we consider the Pairwise-Constrained Problem and Triplet-Constrained Problem respectively. We also consider several related problems in the appendices.
• We extend our results to an objective based on fairness, which we call the stochastic fairness objective, in Appendix A. Following the max-min fairness concept, we aim to maximize the minimum expected similarity assigned to any paper under the randomized assignment: minp∈P E r∈R SrpMrp . We present a version of the Pairwise-Constrained Problem using this objective and an algorithm to solve it, as well as experimental results.
5

• We address an alternate version of the Pairwise-Constrained Problem in Appendix B which uses the probabilities with which any reviewer may intend to untruthfully review any paper, along with other problems using these probabilities.

4 Randomized Assignment with Reviewer-Paper Constraints
In this section we present our main algorithm to solve the Pairwise-Constrained Problem (Deﬁnition 1), thereby addressing the challenges identiﬁed earlier. Before delving into the details of the algorithm, the following theorem states our main result.
Theorem 1. There exists an algorithm which returns an optimal solution to the Pairwise-Constrained Problem in poly(n, d) time.
We describe the algorithm, thereby proving this result, in the next two subsections. Our algorithm that realizes this result has two parts. In the ﬁrst part, we ﬁnd an optimal “fractional assignment matrix,” which gives the marginal probabilities of individual reviewer-paper assignments. The second part of the algorithm then samples an assignment, respecting the marginal probabilities speciﬁed by this fractional assignment.

4.1 Finding the Fractional Assignment
Deﬁne a fractional assignment matrix as a matrix F ∈ [0, 1]n×d that obeys the load constraints p∈P Frp ≤ k for all reviewers r ∈ R and r∈R Frp = for all papers p ∈ P. Note that any deterministic assignment can be represented by a fractional assignment matrix with all entries in {0, 1}. Any randomized assignment is associated with a fractional assignment matrix where Frp is the marginal probability that reviewer r is assigned to paper p. Furthermore, randomized assignments associated with the same fractional assignment matrix have the same expected sum-similarity. The paper [55] proves an extension of the Birkhoﬀ-von Neumann theorem which shows that all fractional assignment matrices are implementable, i.e., they are associated with at least one randomized assignment. On the other hand, any probability matrix not obeying the load constraints cannot be implemented by a lottery over deterministic assignments, since all deterministic assignments do obey the constraints. Therefore, ﬁnding the optimal randomized assignment is equivalent to solving the following LP, which we call LP1:

arg max
F ∈Rn×d
subject to

SrpFrp
p∈P r∈R
0 ≤ Frp ≤ 1
Frp ≤ k
p∈P
Frp =
r∈R
Frp ≤ Qrp

(1)

∀r ∈ R, ∀p ∈ P

(2)

∀r ∈ R

(3)

∀p ∈ P

(4)

∀r ∈ R, ∀p ∈ P.

(5)

LP1 has O(dn) variables and O(dn) constraints. Using techniques from [56], LP1 can be solved in O((dn)2.055) time.

4.2 Implementing the Probabilities
LP1 only ﬁnds the optimal marginal assignment probabilities F (where F now refers to a solution to LP1). It remains to show whether and how these marginal probabilities can be implemented as a randomization over deterministic paper assignments. The paper [55] provides a method for sampling a deterministic assignment from a fractional assignment matrix, which completes our algorithm once applied to the optimal solution of LP1. Here we propose a simpler version of the sampling algorithm. Pseudocode for the algorithm is presented as Algorithm 1; we describe the algorithm in detail below. In Appendix C, we present a supplementary algorithm to compute the full distribution over deterministic assignments, which [55] does not. Knowing

6

Algorithm 1 Sampling algorithm for the Pairwise-Constrained Problem.

Input: Fractional assignment matrix F , reviewer set R, paper set P Ouput: Deterministic assignment matrix M Algorithm:

1: Construct vertex set V ← R ∪ P ∪ {s} ∪ {t}
2: Construct directed edge set E ← {(r, p)|∀r ∈ R, p ∈ P} ∪ {(s, r)|∀r ∈ R} ∪ {(p, t)|∀p ∈ P}  1 if e ∈ R × P 
3: Construct capacity function h : E → Z as h(e) ← k if e ∈ {s} × R

 

if e ∈ P × {t}

 Frp 

if e = (r, p) ∈ R × P

4: Construct initial ﬂow function f : E → R as f (e) ← p∈P Frp if e = (s, r) ∈ {s} × R

 

r∈R Frp

if e = (p, t) ∈ P × {t}

5: while ∃e ∈ E such that f (e) ∈ Z do

6: Find a cycle of edges (ignoring direction) C = {e1, . . . , ek} such that f (ei) ∈ Z, ∀i ∈ [k]

7: A ← {e ∈ C| e is directed in the same direction as e1 along the cycle}

8: B ← C \ A

9: α ← min (mine∈A f (e), mine∈B h(e) − f (e)) 10: for e ∈ A do

11:

f1(e) ← f (e) − α

12: end for

13: for e ∈ B do

14:

f1(e) ← f (e) + α

15: end for

16: β ← min (mine∈A h(e) − f (e), mine∈B f (e)) 17: for e ∈ A do

18:

f2(e) ← f (e) + β

19: end for

20: for e ∈ B do

21:

f2(e) ← f (e) − β

22: end for

23: γ ← α+β β 24: With probability γ, f ← f1; else f ← f2

25: end while

26: Mrp = f ((r, p)), ∀(r, p) ∈ R × P

the full distribution may be useful in order to compute other properties of the randomized assignment not calculable from F directly.
We begin by constructing a directed graph G = (V, E) for our problem, along with a capacity function h : E → Z (Lines 1-3). First, construct one vertex for each reviewer, one vertex for each paper, and source and destination vertices s, t. Add an edge from the source vertex to each reviewer’s vertex with capacity k. Add an edge from each paper’s vertex to the destination vertex with capacity . Finally, add an edge from each reviewer to each paper with capacity 1. We also construct a ﬂow function f : E → R, which obeys the ﬂow conservation constraints e∈E∩(V ×{v}) f (e) = e∈E∩({v}×V ) f (e), ∀v ∈ V \ {s, t} and the capacity constraints f (e) ≤ h(e), ∀e ∈ E (Line 4). A (possibly fractional) assignment F can be represented as a ﬂow on this graph, where the ﬂow from reviewer i to paper j corresponds to the probability reviewer i is assigned to paper j and the other ﬂows are set uniquely by ﬂow conservation. Due to the load constraints on assignments, the ﬂows on the edges from the papers to the destination must be equal to those edges’ capacities and the ﬂows on the edges from the source to the reviewers must be less than or equal to the capacities.
The algorithm then proceeds in an iterative manner, modifying the ﬂow function f on each iteration. On each iteration, we ﬁrst check if there exists a “fractional edge,” an edge with non-integral ﬂow. If no such edge exists, our current assignment is integral and so we can stop iterating. If there does exist a fractional

7

edge, we then ﬁnd an arbitrary cycle of fractional edges, ignoring direction (Line 6); this can be done by starting at any fractional edge and walking along fractional edges until a previously-visited vertex is returned to. On ﬁnding a cycle, we randomly modify the ﬂow on each of the edges in the cycle in order to guarantee that at least one of the ﬂows becomes integral. In what follows, we ﬁrst prove that such a cycle of fractional edges can always be found. We then show how to modify the ﬂows in order to guarantee the implementation of the marginal assignment probabilities.
We now show that a directionless cycle of fractional edges must exist whenever one fractional edge exists. Initially, by the properties of F , the total ﬂow on each edge going into vertex t is integral; further, the algorithm only ever changes the ﬂow on edges with non-integral ﬂow. Therefore, the total ﬂow going into t is always integral. By ﬂow conservation, the total ﬂow leaving s is also always integral. So, if there is a fractional edge adjacent to s, there must also be another fractional edge adjacent to s. As already stated, there are no fractional edges adjacent to t. Finally, for each vertex v ∈ V \ {s, t}, by ﬂow conservation, there can never be only one fractional edge adjacent to v. Therefore, every vertex that is adjacent to a fractional edge must also be adjacent to another fractional edge. This proves that a directionless cycle of fractional edges must exist if one fractional edge exists.
We now show how to modify the ﬂow on the edges in this cycle. We can keep pushing ﬂow in some direction on this cycle (pushing negative ﬂow if the edge is directed backwards) until some edge is at capacity or has 0 ﬂow. Call this amount of additional ﬂow α, and the resulting ﬂow f1. We can do the same thing in the other direction on the cycle, calling the additional ﬂow β and the resulting ﬂow f2. Both f1 and f2 must have at least one more integral edge than f , since some edge is at capacity. Further, both f1 and f2 obey the ﬂow conservation and capacity constraints. Deﬁning γ ← α+β β , we set f ← f1 with probability γ and f ← f2 with probability 1 − γ (Lines 23-24).
Once all edges are integral (after the ﬁnal iteration), we construct the sampled deterministic assignment M from the ﬂow on the reviewer-paper edges (Line 26). Since f obeys the capacity constraints on all edges, M obeys the load constraints and so is in fact an assignment. Since on each iteration the initial ﬂow f satisﬁes f (e) = γf1(e) + (1 − γ) f2(e), ∀e ∈ E, the expected ﬁnal ﬂow on each edge is always equal to the current ﬂow on that edge. Since the expectation of a Bernoulli random variable is exactly the probability it equals one, each ﬁnal reviewer-paper assignment Mrp has been chosen with the desired marginal probabilities Frp.
Each iteration of this algorithm takes O(d + n) time to ﬁnd a cycle in the O(d + n) vertices (if a list of fractional edges adjacent to each vertex is maintained), and it can take O(dn) iterations to terminate since one edge becomes integral every iteration. Therefore, the sampling algorithm is overall O(dn(d + n)).
The time complexity of our full algorithm, including both LP1 and the sampling algorithm, is dominated by the complexity of solving the LP. Since standard paper assignment algorithms such as TPMS can be implemented by solving an LP of the same size, our algorithm is comparable in complexity. If a conference currently does solve an LP to ﬁnd their assignment, whatever LP solver a conference currently uses for their paper assignment algorithm could be used in our algorithm as well.
5 Randomized Assignment with Constraints on Pairs of Reviewers
We now turn to the problem of controlling the probabilities that certain pairs of reviewers are assigned to the same paper, deﬁned in Section 3 as the Triplet-Constrained Problem (Deﬁnition 2). In the following subsections, we ﬁrst show that the problem of ﬁnding an optimal randomized assignment given arbitrary constraints on the maximum probabilities of each reviewer-reviewer-paper grouping is NP-hard. We then show that, for the practical special case of restrictions on reviewers from the same subset of a partition of R (such as the same primary academic institution or geographical area of residence), an optimal randomized assignment can be found eﬃciently.
5.1 NP-Hardness of Arbitrary Constraints
As described in Section 3, solving the Triplet-Constrained Problem would allow the program chairs of a conference maximum ﬂexibility in how they control the probabilities of the assignments of pairs of reviewers. Unfortunately, as the following theorem shows, this problem cannot be eﬃciently solved.
8

Theorem 2. The Triplet-Constrained Problem is NP-hard, by reduction from 3-Dimensional Matching.
3-Dimensional Matching is an NP-complete decision problem that takes as input three sets X, Y, Z of size s as well as a collection of tuples in X × Y × Z; the goal is to ﬁnd a choice of s tuples out of the collection such that no elements of any set are repeated [57]. Our reduction maps sets X ∪ Y to R and Z to P, and constructs T ∈ {0, 1}n×n×d to allow only the assignments where the corresponding tuples are allowable in the 3-Dimensional Matching instance. The full proof is stated in Appendix D.
Theorem 2 implies a more fundamental result about the feasible region of implementable reviewer-reviewerpaper probability tensors, that is, the tensors G ∈ [0, 1]n×n×d where entry Gijp represents the marginal probability that both reviewers i and j are assigned to paper p under some randomized assignment. We can represent any deterministic assignment by a 3-dimensional tensor M ∈ {0, 1}n×n×d where Mijp = 1 if and only if both reviewers i and j are assigned to paper p. Just as in the earlier case of fractional assignment matrices, the set of implementable probability tensors is a polytope with deterministic assignment tensors at the vertices (since any implementable probability tensor is a convex combination of deterministic assignment tensors). For fractional reviewer-paper assignment matrices, this polytope was deﬁned by a small number (O(dn)) of linear inequalities, despite the fact that it has a large number of vertices (factorial in d and n). However, this is no longer the case for reviewer-reviewer-paper probabilities.
Corollary 1. The polytope of implementable reviewer-reviewer-paper probabilities is not expressible in a polynomial (in n and d) number of linear inequality constraints (assuming P = N P ).
The proof of this result is also stated in Appendix D.
5.2 Constraints on Disjoint Reviewer Sets
Since the most general problem of arbitrary constraints on reviewer-reviewer-paper triples is NP-hard, we must restrict ourselves to tractable special cases of interest. One such special case arises when the program chairs of a conference can partition the reviewers in such a way that they wish to prevent any two reviewers within the same subset from being assigned to the same paper. For example, reviewers can be partitioned by their primary academic institution. Since reviewers at the same institution are likely closely associated, program chairs may believe that placing them together as co-reviewers is more risky than would be implied by our concern about either reviewer individually. In this case, there may not even be any concern about the reviewers’ motivations; the concern may simply be that the reviewers’ opinions would not be suﬃciently independent. Other partitions of interest could be the reviewer’s geographical area of residence or research sub-ﬁeld, as each of these deﬁnes a “community” of reviewers that may be more closely associated. This special case corresponds to instances of the Triplet-Constrained Problem where Tabp = 0 if reviewers a and b are in the same subset, and Tabp = 1 otherwise.
We formally deﬁne this problem as follows:
Deﬁnition 3 (Partition-Constrained Problem). The input to the problem is a similarity matrix S, a matrix Q ∈ [0, 1]n×d, and a partition of the reviewer set into subsets I1, . . . , Im ⊆ R. The goal is to ﬁnd a randomized assignment of papers to reviewers that maximizes E r∈R p∈P SrpMrp subject to the constraints that P[Mrp = 1] ≤ Qrp, ∀r ∈ R, p ∈ P, and P[Map = 1 ∧ Mbp = 1] = 0, ∀a, b ∈ Ii, ∀i ∈ [m].
For this special case of the Triplet-Constrained Problem, we show that the problem is eﬃciently solvable, as stated in the following theorem.
Theorem 3. There exists an algorithm which returns an optimal solution to the Partition-Constrained Problem in poly(n, d) time.
We present the algorithm that realizes this result in the following subsections, thus proving the theorem. The algorithm has two parts: it ﬁrst ﬁnds a fractional assignment matrix F meeting certain requirements, and then samples an assignment while respecting the marginal assignment probabilities given by F and additionally never assigning two reviewers from the same subset to the same paper. For ease of exposition, we ﬁrst present the sampling algorithm, and then present an LP which ﬁnds the optimal fractional assignment matrix meeting the necessary requirements.
9

5.2.1 Partition-Constrained Sampling Algorithm
The sampling algorithm we present in this section takes as input a fractional assignment matrix F and samples an assignment while respecting the marginal assignment probabilities given by F . The sampling algorithm is based on the following lemma:
Lemma 1. Consider any fractional assignment matrix F and any partition of R into subsets I1, . . . , Im.
(i) There exists a sampling algorithm that implements the marginal assignment probabilities given by F and runs in O(dn(d + n)) time such that, for all papers p ∈ P and subsets I ∈ {I1, . . . , Im} where r∈I Frp ≤ 1, the algorithm never samples an assignment assigning two reviewers from subset I to paper p.
(ii) For any sampling algorithm that implements the marginal assignment probabilities given by F , for all papers p ∈ P and subsets I ∈ {I1, . . . , Im} where r∈I Frp > 1, the expected number of pairs of reviewers from subset I assigned to paper p is strictly positive.
The sampling algorithm which realizes Lemma 1 has an additional helpful property, which holds simultaneously for all papers and subsets. We state the property in the following corollary and make use of it later:
Corollary 2. For any fractional assignment matrix F , the sampling algorithm that realizes Lemma 1 minimizes the expected number of pairs of reviewers from subset I assigned to paper p simultaneously for all papers p ∈ P and subsets I ∈ {I1, . . . , Im} among all sampling algorithms implementing the marginal assignment probabilities given by F .
We present the sampling algorithm that realizes these results here, and prove the guarantees stated in Lemma 1 and Corollary 2 in Appendix E. This algorithm is a modiﬁcation of the sampling algorithm from Theorem 1 presented earlier as Algorithm 1.
We ﬁrst provide some high-level intuition about the modiﬁcations to Algorithm 1. For any fractional assignment matrix F , for any subset I and paper p, the expected number of reviewers from subset I assigned to paper p is r∈I Frp. This is equal to the initial load from subset I on paper p in Algorithm 1 (that is, the sum of the ﬂow on all edges from reviewers in subset I to paper p). Note that at Algorithm 1’s conclusion, when all edges are integral, the load from subset I on paper p is equal to the number of reviewers from subset I assigned to paper p. Therefore, if the fractional assignment F is such that the initial expected number of reviewers from subset I assigned to paper p is no greater than 1 (as stated in part (i) of Lemma 1), we want to keep the load from subset I on paper p close to its initial value so that the ﬁnal number of reviewers from subset I assigned to paper p is also no greater than 1. With this reasoning, we modify Algorithm 1 so that in each iteration, it ensures that the total load on each paper from each subset is unchanged if originally integral and is never moved past the closest integer in either direction if originally fractional.
The algorithm realizing Lemma 1 and Corollary 2 is obtained by changing three lines in Algorithm 1, as follows:
• Line 6 is replaced with the subroutine in Algorithm 2.
• Line 9 is changed to: α ← min (mine∈A f (e), mine∈B h(e) − f (e), mint∈D1 t − t , mint∈D2 t − t).
• Line 16 is changed to: β ← min (mine∈A h(e) − f (e), mine∈B f (e), mint∈D1 t − t, mint∈D2 t − t ).
The primary modiﬁcation we make to Algorithm 1 is replacing Line 6 with the subroutine in Algorithm 2. In each iteration, when we look for an undirected cycle of fractional edges in the graph, we now choose the cycle carefully rather than arbitrarily. We ﬁnd a cycle by starting from an arbitrary fractional edge in the graph and walk along adjacent fractional edges (ignoring direction) until we repeat a previously-visited vertex. As we do this, whenever we take a fractional edge from a reviewer in subset I into paper p, there are two cases.
• Case 1: If there exists a diﬀerent fractional edge from paper p to subset I (Line 8 in Algorithm 2), we take this edge next. Note that if the total load from subset I on paper p is integral, such an edge must exist.
10

Algorithm 2 Loop-ﬁnding subroutine (replacing Line 6 in Algorithm 1).

1: Construct the set of undirected edges EU ← E ∪ {(v, u) | (u, v) ∈ E}

2: Construct the undirected ﬂow function fU : EU → R as fU ((u, v)) ← f ((u, v)) if (u, v) ∈ E f ((v, u)) otherwise

3: Find arbitrary edge (u, v) ∈ E such that f ((u, v)) ∈ Z

4: C ← {(u, v)}

5: D1 ← {}, D2 ← {}

6: while v has not previously been visited do

7: Visit v

8: if u ∈ R and v ∈ P then

9:

Set I ∈ {I1, . . . , Im} such that u ∈ I

10:

if ∃w ∈ I \ {u} such that (v, w) ∈ EU and fU ((v, w)) ∈ Z then

11:

Find such a w

12:

else

13:

For some J ∈ {I1, . . . , Im} \ {I} such that r∈J f ((r, v)) ∈ Z, ﬁnd w ∈ J such that (v, w) ∈ EU

and fU ((v, w)) ∈ Z

14:

D1 ← D1 ∪ { r∈I f ((r, v))} (corresponding to (u, v))

15:

D2 ← D2 ∪ { r∈J f ((r, v))} (corresponding to (v, w))

16:

end if

17: else

18:

Find w ∈ V \ {u} such that (v, w) ∈ EU and fU ((v, w)) ∈ Z

19: end if

20: C ← C ∪ {(v, w)}

21: u ← v

22: v ← w

23: end while

24: Set e1 as the ﬁrst edge in C leaving v 25: Set e−1 as the last edge in C (entering v) 26: Remove edges preceding e1 from C, and remove the corresponding elements from D1 and D2 27: if v ∈ P and ∃I ∈ {I1, . . . , Im} such that e1 ∈ {v} × I and e−1 ∈ I × {v} then 28: Remove the elements corresponding to e1 and e−1 from D1 and D2
29: end if

30: if e1 ∈ E then 31: Swap D1 and D2 32: end if

33: Replace each edge in C from EU with the corresponding edge from E

• Case 2: Otherwise (Line 12 in Algorithm 2), we must take a fractional edge from paper p to some other subset J. In this case, the total load from subset I on paper p must not be integral. We choose the subset J so that the total load from subset J on paper p is also not integral. Such a subset must exist since the total load on paper p is always integral. We keep track of both the total load from I and from J on p, for every occurrence of this case along the cycle (Lines 14 and 15 in Algorithm 2).
In Case 1, no matter how much ﬂow is pushed on the cycle, the total load from subset I on paper p will be preserved exactly. However, due to Case 2, we must modify the choice of how much ﬂow to push on the cycle to ensure that the loads are preserved as desired. Speciﬁcally, we only push ﬂow in a given direction on the cycle until the total load for either subset I or J on paper p is integral, for any I, J, p found in Case 2. The total loads from each subset on each paper found in Case 2 are saved in either set D1 or set D2 depending on the direction of the corresponding edges in the cycle, and each subset-paper pair with an edge corresponding to an element of D1 or D2 has only that one edge in the cycle. If the total (fractional) load from subset I on paper p is t, then only t − t additional ﬂow can be added to any edge from subset I to paper p before the load becomes integral; similarly, only t − t ﬂow can be removed from any edge before the load becomes integral. This leads to the stated changes to Lines 9 and 16 in Algorithm 1.
11

Therefore, on each iteration, we push ﬂow until either the ﬂow on some edge is integral (as in the original algorithm), or until the total load on some paper from some subset is integral. This implies that the algorithm still terminates in a ﬁnite number of iterations. In addition, by the end of the algorithm, the total load on each paper from each subset is preserved exactly if originally integral and rounded in either direction if originally fractional, as desired.
The time complexity of this modiﬁed algorithm is identical to that of the original algorithm from Theorem 1, since ﬁnding a cycle takes the same amount of time (if a fractional adjacency list for each subset is used) and only a maximum of O(n) extra iterations are performed (if an subset’s total load becomes integral rather than an edge’s ﬂow). Therefore, the algorithm is overall O(dn(d + n)).

5.2.2 Finding the Optimal Partition-Constrained Fractional Assignment
Lemma 1 provides necessary and suﬃcient conditions for the fractional assignment matrices for which it is possible to prevent all pairs of same-subset reviewers from being assigned to the same paper. Therefore, to ﬁnd an optimal fractional assignment with this property, we just need to add md constraints to LP1. We call this new LP LP2:

arg max

SrpFrp

(6)

F ∈Rn×d p∈P r∈R

subject to Constraints (2–5) from LP1 and

Frp ≤ 1

∀I ∈ {I1, . . . , Im}, ∀p ∈ P.

(7)

r∈I

The solution to LP2 when paired with the sampling algorithm from Section 5.2.1 never assigns two reviewers from the same subset to the same paper. Furthermore, since any fractional assignment F not obeying Constraint (7) will have a strictly positive probability of assigning two reviewers from the same subset to the same paper, LP2 ﬁnds the optimal fractional assignment with this guarantee. This completes the algorithm for the Partition-Constrained Problem.
Additionally, Corollary 2 shows that the sampling algorithm from Section 5.2.1 is optimal in the expected number of same-subset reviewer pairs, for any fractional assignment. If the guarantee of entirely preventing same-subset reviewer pairs is not strictly required, Constraint (7) in LP2 can be loosened (constraining the subset loads to a higher value) without removing it entirely. For the resulting fractional assignment F , the sampling algorithm from Section 5.2.1 still minimizes the expected number of pairs of reviewers from any subset on any paper, as compared to any other sampling algorithm implementing F . Since the subset loads are still constrained, the expected number of same-subset reviewer pairs will be lower than in the solution to the Pairwise-Constrained Problem (at the cost of some expected sum-similarity). We examine this tradeoﬀ experimentally in Section 6.

6 Experiments
We test our algorithms on several real-world datasets. The ﬁrst real-world dataset is a similarity matrix recreated from ICLR 2018 data in [36]; this dataset has n = 2435 reviewers and d = 911 papers. We also run experiments on similarity matrices created from reviewer bid data for three AI conferences from PrefLib dataset MD-00002 [58], with sizes (n = 31, d = 54), (n = 24, d = 52), and (n = 146, d = 176) respectively. For all three PrefLib datasets, we transformed “yes,” “maybe,” and “no response” bids into similarities of 4, 2, and 1 respectively, as is often done in practice [30]. As done in [36], we set loads k = 6 and = 3 for all datasets since these are common loads for computer science conferences (except on the PrefLib2 dataset, for which we set k = 7 for feasibility).
We run all experiments on a computer with 8 cores and 16 GB of RAM, running Ubuntu 18.04 and using Gurobi 9.0.2 [59] to solve the LPs. Our algorithm for the Pairwise-Constrained Problem takes an average of 41 seconds to complete on ICLR; our algorithm for the Partition-Constrained Problem takes an average of 45 seconds. As expected, the running time is dominated by the time taken to solve the LP.

12

0.04 0.02 0.00 0.02 0.04
0

Sum-similarity (% of optimal) Sum-similarity (% of optimal)

ICLR

PrefLib1

100 80 60 40 20 0 0.2 0.4 0.6 0.8 1.0
Maximum probability of each assignment

PrefLib2

PrefLib3

100

80

60

40

20

0 1.0 1.2 1.4 1.6 1.8 2.0 Max. expected same-subset reviewers/paper

(a) Pairwise-Constrained Problem

(b) Partition-Constrained Problem with three random subsets

2

Figure 1: Ex4perimental results 6on four conference d8atasets.

6.1 Quality of Resulting Assignments
We ﬁrst study our algorithm for the Pairwise-Constrained Problem, as described in Section 4. In this setting, program chairs must make a tradeoﬀ between the quality of the output assignments and guarding against malicious reviewers or reviewer de-anonymization by setting the values of the maximum-probability matrix Q. We investigate this tradeoﬀ on real datasets. All results in this section are averaged over 10 trials with error bars plotted representing the standard error of the mean, although they are sometimes not visible since the variance is very low.
In Figure 1a, we set all entries of the maximum-probability-matrix Q equal to the same constant value q0 (varied on the x-axis), and observe how the sum-similarity value of the assignment computed via our algorithm from Section 4 changes as q0 increases from 0.1 to 1 with an interval of 0.1. We report the sum-similarity as a percentage of the unconstrained optimal solution’s objective. This unconstrained optimal solution maximizes sum-similarity through a deterministic assignment as is popularly done today [14–20], and does not address the aforementioned challenges. We see that our algorithm trades oﬀ the maximum probability of an assignment gracefully against the sum-similarity on all datasets. For instance, with q0 = 0.5, our algorithm achieves 90.8% of the optimal objective value on the ICLR dataset. In practice, this would allow the program chairs of a conference to limit the chance that any malicious reviewer is assigned to their desired paper to 50% without suﬀering a signiﬁcant loss of assignment quality. When q0 is too small, a feasible assignment may not exist in some datasets (e.g., q0 = 0.1 for PrefLib2).
We next test our algorithm for the Partition-Constrained Problem discussed in Section 5.2. In this algorithm, program chairs can navigate an additional tradeoﬀ between the number of same-subset reviewers assigned to the same paper and the assignment quality; we investigate this tradeoﬀ here. On ICLR, we ﬁx q0 = 0.5 and randomly assign reviewers to subsets of size 15, using this as our partition of R (since the dataset does not include any reviewer information). Each subset represents a group of reviewers with close associations, such as reviewers from the same institution. Our algorithm is able to achieve 100% of the optimal objective for the Pairwise-Constrained Problem with q0 = 0.5 while preventing any pairs of reviewers from the same subset from being assigned to the same paper.
Since our algorithm achieves the full possible objective in this setting, we now run experiments with a considerably more restrictive partition constraint. In Figure 1b, we show an extreme case where we randomly assign reviewers to 3 subsets of equal size (sizes 811, 11, 8 and 48 on ICLR and the PrefLib datasets, respectively, with the remainder assigned to a dummy fourth subset), again ﬁxing q0 = 0.5. We then gradually loosen the constraints on the expected number of same-subset reviewers assigned to the same paper by increasing the constant in Constraint (7) from 1 to 2 in increments of 0.1, shown on the x-axis. We plot the sum-similarity objective of the resulting assignment, expressed as a percentage of the optimal

13

Assignment probability Assignment probability

Our randomized assignment algorithm (Q=0.5)

0.04

Standard assignment algorithm Standard assignment algorithm, no manipulation

1.0 0.02

1.0

0.8

0.8

0.6 0.00

0.6

0.4

0.4

0.2 0.02

0.2

0.0 02.00421 22 2R3evi2e4we2r5ran2k6 27 28 29

0.0 20 21 22 2R3evi2e4we2r5ran2k6 27 28 29

(a)0Bidding scale2γ = 2

4

6

(b) 8Bidding scale γ = 4

Figure 2: Eﬀectiveness of bidding manipulation on the ICLR dataset. One malicious reviewer manipulates their bids to get assigned to a target paper. The probability of the malicious reviewer-target paper assignment varies on the y-axis as the rank of the malicious reviewer’s pre-bid similarity with the target paper changes on the x-axis.

non-partition-constrained solution’s objective (i.e., the solution to the Pairwise-Constrained Problem with q0 = 0.5). Even in this extremely constrained case with only a few subsets, we still achieve 99.1% of the non-partition-constrained objective while entirely preventing same-subset reviewer pairs on ICLR.
In Appendix F, we present results for additional experiments on synthetic similarities, where we ﬁnd results qualitatively similar to those presented here. We also run experiments for a fairness objective, which we present in Appendix A.
6.2 Eﬀectiveness at Preventing Manipulation
We now describe experiments evaluating the eﬀectiveness of our algorithm at preventing manipulation on the ICLR dataset against a simulated reviewer bidding model. We assume that there is one malicious reviewer who is attempting to maximize their chances of being assigned to a target paper solely through bidding (and not through other means). Since the ICLR similarities are reconstructed purely from the text similarity with each reviewers’ past work and do not contain any bidding, we supplement them with synthetic bids. Speciﬁcally, each reviewer r chooses a bid brp ∈ {−1, 0, 1} for each paper p, indicating “not interested,” “neutral,” or “interested” respectively. Based on the similarity function used in the NeurIPS 2016 conference [30], we compute the ﬁnal similarity between reviewer r and paper p as Srp = γbrp Srp, where Srp is the text similarity from the ICLR dataset and γ is a ﬁxed scale parameter.
In our experiment, the malicious reviewer bids 1 on their target paper and −1 on all other papers. The other (honest) reviewers bid according to a simple randomized model constructed to match characteristics of the bidding observed in NeurIPS 2016 [30]. We divide the reviewers uniformly at random into three groups. The ﬁrst group contains 20% of the reviewers, who all bid 0 on all papers. The second group contains 50% of the reviewers, who bid non-zero on a low number of papers. These reviewers consider each paper within the 10% of papers that have highest text similarity with them, and independently choose to bid non-zero on each one with probability 0.016. If a paper is selected to bid non-zero, the bid is chosen from {−1, 1} with uniform probability. The third group contains 30% of the reviewers, who bid non-zero on a high number of papers. They follow the same bidding procedure as the second group, but bid with probability 0.24.
The results of this experiment are shown in Figure 2. We choose a target paper uniformly at random, and choose the malicious reviewer to be the reviewer with the xth highest text similarity with that paper (varying x on the x-axis). Note that the x-axis is on a log-scale. We then have all reviewers bid in the manner described

14

above, and compute the assignment with either the standard deterministic assignment algorithm described in Section 3 or our randomized assignment algorithm for the Pairwise-Constrained Problem, setting all entries of Q to 0.5. We then observe the probability that the malicious reviewer is assigned to the target paper (that is, the probability with which the manipulation is successful), which is in {0, 1} for the deterministic algorithm but can be non-integral for our algorithm. For each point on the x-axis, we average results over 50 choices of target paper, giving an overall success rate for the manipulation under a uniform choice of papers (reported on the y-axis, with error bars plotted representing the standard error of the mean). For comparison, we also plot the case where only the honest reviewers bid and the malicious reviewer does not bid.
There are three key takeaways from this experiment. First, we see that when a reviewer does not bid, their assignment probability is low for any reviewer not ranked in the top 4 for that paper in terms of the text similarity. Second, when the malicious reviewer does bid, the manipulation has a high success rate under the standard assignment algorithm. For example, the 8th ranked reviewer for any paper is never assigned if they do not bid, but with bids they can manipulate in order to guarantee their assignment. Moreover, even the 100th ranked reviewer has a has a decent probability (above 0.25) of getting assigned the target paper if the reviewer bids maliciously. This indicates that manipulation from reviewers is quite powerful in standard assignment algorithms, potentially compromising the integrity of the assignment. Third, our algorithm always limits the probability of successful manipulation to the desired level of 0.5, reﬂecting the theoretical guarantees presented earlier in the paper. For malicious reviewers who have low text similarity with the target paper (e.g., reviewers from a diﬀerent subject area), our algorithm occasionally gives the manipulation a marginally higher probability to succeed as compared to the standard assignment algorithm since the set of possible reviewers for each paper is larger. However, manipulation from these low-similarity reviewers is unlikely to succeed in the ﬁrst place (with probability below the desired limit of 0.5), and it is envisaged to be easier for program chairs to manually spot unusual bids from reviewers outside of a paper’s subject area.
7 Discussion
We have presented here a framework and a set of algorithms for addressing three challenges of practical importance to the peer review process: untruthful favorable reviews, torpedo reviewing, and reviewer deanonymization on the release of assignment data. By design, our algorithms are quite ﬂexible to the needs of the program chairs, depending on which challenges they are most concerned with addressing. Our empirical evaluations demonstrate some of the tradeoﬀs that can be made between total similarity and maximum probability of each paper-reviewer pair or between total similarity and number of reviewers from the same subset on the same paper. The exact parameters of the algorithm can be set based on how the program chairs weigh the relative importance of each of these factors. Note that an empirical evaluation of exactly how much our algorithm reduces manipulation in a real conference is not possible, since the ground truth of which reviewers were manipulating their assignments is not known.
This work leads to a number of open problems of interest. First, since the general Triplet-Constrained Problem is NP-hard, we considered one special structure—the Partition-Constrained Problem—of practical relevance. A direction for future research is to ﬁnd additional special cases under which optimizing over constraints on the probabilities of reviewer-pair-to-paper assignments is feasible. For example, there may be a known network of reviewers where program chairs wish to prevent connected reviewers from being assigned to the same paper. A second problem of interest is to develop methods to detect potentially malicious reviewer-paper pairs before papers are assigned (e.g., based on the bids). Finally, this work does not address the problem of reviewers colluding with each other to give dishonest favorable reviews after being assigned to each others’ papers; we leave this issue for future work.
Acknowledgments
The research of Steven Jecmen and Nihar Shah was supported in part by NSF CAREER 1942124. The research of Steven Jecmen and Fei Fang was supported in part by NSF Award IIS-1850477. The research of Hanrui Zhang and Vincent Conitzer was supported in part by NSF Award IIS-1814056.
15

References
[1] Adrian Mulligan, Louise Hall, and Ellen Raphael. Peer review in a changing world: An international study measuring the attitudes of researchers. Journal of the Association for Information Science and Technology, 64(1):132–161, 2013.
[2] David Nicholas, Anthony Watkinson, Hamid R Jamali, Eti Herman, Carol Tenopir, Rachel Volentine, Suzie Allard, and Kenneth Levine. Peer review: Still king in the digital age. Learned Publishing, 28(1):15–21, 2015.
[3] Mark Ware. Peer review: Beneﬁts, perceptions and alternatives. Publishing Research Consortium, 4:1–20, 2008.
[4] Robert K Merton. The Matthew eﬀect in science. Science, 159:56–63, 1968.
[5] T. N. Vijaykumar. Potential organized fraud in ACM/IEEE computer architecture conferences. https: //medium.com/@tnvijayk/potential-organized-fraud-in-acm-ieee-computer-architectureconferences-ccd61169370d, 2020 (accessed August 17, 2020).
[6] Cat Ferguson, Adam Marcus, and Ivan Oransky. Publishing: The peer-review scam. Nature News, 515(7528):480, 2014.
[7] Jian Gao and Tao Zhou. Retractions: Stamp out fake peer review. Nature, 546(7656):33–33, 2017.
[8] John Langford. Bidding problems. https://hunch.net/?p=407, 2008 (accessed June 16, 2020).
[9] Edward F Barroga. Safeguarding the integrity of science communication by restraining ’rational cheating’ in peer review. Journal of Korean Medical Science, 29(11):1450–1452, 2014.
[10] Mario Paolucci and Francisco Grimaldo. Mechanism change in a simulation of peer review: From junk support to elitism. Scientometrics, 99(3):663–688, 2014.
[11] Jef Akst. I hate your paper. Many say the peer review system is broken. Here’s how some journals are trying to ﬁx it. The Scientist, 24(8):36, 2010.
[12] Arvind Narayanan and Vitaly Shmatikov. How to break anonymity of the Netﬂix Prize dataset. arXiv preprint arXiv:cs/0610105, 2006.
[13] Laurent Charlin and Richard Zemel. The Toronto Paper Matching System: An automated paper-reviewer assignment system. 2013.
[14] Laurent Charlin, Richard S Zemel, and Craig Boutilier. A framework for optimizing paper matching. arXiv preprint arXiv:1202.3706, 2012.
[15] Cheng Long, Raymond Chi-Wing Wong, Yu Peng, and Liangliang Ye. On good and fair paper-reviewer assignment. In 2013 IEEE 13th International Conference on Data Mining, pages 1145–1150. IEEE, 2013.
[16] Judy Goldsmith and Robert H Sloan. The AI conference paper assignment problem. In Proc. AAAI Workshop on Preference Handling for Artiﬁcial Intelligence, Vancouver, pages 53–57, 2007.
[17] Wenbin Tang, Jie Tang, and Chenhao Tan. Expertise matching via constraint-based optimization. In 2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology, volume 1, pages 34–41. IEEE, 2010.
[18] Peter A Flach, Sebastian Spiegler, Bruno Golénia, Simon Price, John Guiver, Ralf Herbrich, Thore Graepel, and Mohammed J Zaki. Novel tools to streamline the conference review process: Experiences from SIGKDD’09. ACM SIGKDD Explorations Newsletter, 11(2):63–67, 2010.
[19] Jing Wu Lian, Nicholas Mattei, Renee Noble, and Toby Walsh. The conference paper assignment problem: Using order weighted averages to assign indivisible goods. In Thirty-Second AAAI Conference on Artiﬁcial Intelligence, 2018.
16

[20] Ari Kobren, Barna Saha, and Andrew McCallum. Paper matching with local fairness constraints. In ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, 2019.
[21] N. Garg, T. Kavitha, A. Kumar, K. Mehlhorn, and J. Mestre. Assigning papers to referees. Algorithmica, 58(1):119–136, Sep 2010.
[22] Ivan Stelmakh, Nihar B. Shah, and Aarti Singh. PeerReview4All: Fair and accurate reviewer assignment in peer review. arXiv preprint arXiv:1806.06237, 2018.
[23] Hong Ge, Max Welling, and Zoubin Ghahramani. A Bayesian model for calibrating conference review scores. http://mlg.eng.cam.ac.uk/hong/unpublished/nips-review-model.pdf, 2013 (accessed June 29, 2020).
[24] Ritesh Noothigattu, Nihar B Shah, and Ariel D Procaccia. Loss functions, axioms, and peer review. arXiv preprint arXiv:1808.09057, 2018.
[25] Jingyan Wang and Nihar B Shah. Your 2 is my 1, your 3 is my 9: Handling arbitrary miscalibrations in ratings. In AAMAS, 2019.
[26] T Fiez, N Shah, and L Ratliﬀ. A SUPER* algorithm to optimize paper bidding in peer review. In Conference on Uncertainty in Artiﬁcial Intelligence (UAI), 2020.
[27] Magnus Roos, Jörg Rothe, and Björn Scheuermann. How to calibrate the scores of biased reviewers by quadratic programming. In AAAI Conference on Artiﬁcial Intelligence, 2011.
[28] Ivan Stelmakh, Nihar Shah, and Aarti Singh. On testing for biases in peer review. In NeurIPS, 2019.
[29] N. Lawrence and C. Cortes. The NIPS experiment. http://inverseprobability.com/2014/12/16/ the-nips-experiment, 2014 (accessed June 29, 2020).
[30] Nihar B Shah, Behzad Tabibian, Krikamol Muandet, Isabelle Guyon, and Ulrike Von Luxburg. Design and analysis of the NIPS 2016 review process. The Journal of Machine Learning Research, 19(1):1913–1946, 2018.
[31] Andrew Tomkins, Min Zhang, and William D. Heavlin. Reviewer bias in single- versus double-blind peer review. Proceedings of the National Academy of Sciences, 114(48):12708–12713, 2017.
[32] Dongyeop Kang, Waleed Ammar, Bhavana Dalvi, Madeleine van Zuylen, Sebastian Kohlmeier, Eduard H. Hovy, and Roy Schwartz. A dataset of peer reviews (PeerRead): Collection, insights and NLP applications. arXiv preprint arXiv:1804.09635, 2018.
[33] Emaad Manzoor and Nihar B Shah. Uncovering latent biases in text: Method and application to peer review. In INFORMS Workshop on Data Science, 2020.
[34] Ivan Stelmakh, Nihar Shah, Aarti Singh, and Hal Daumé III. Prior and prejudice: The bias against resubmissions in conference peer review. arXiv, 2020.
[35] Ivan Stelmakh, Nihar Shah, and Aarti Singh. Catch me if I can: Detecting strategic behaviour in peer assessment. arXiv, 2020.
[36] Yichong Xu, Han Zhao, Xiaofei Shi, Jeremy Zhang, and Nihar B. Shah. On strategyproof conference peer review. arXiv preprint arXiv:1806.06266, 2018.
[37] Haris Aziz, Omer Lev, Nicholas Mattei, Jeﬀrey S Rosenschein, and Toby Walsh. Strategyproof peer selection using randomization, partitioning, and apportionment. Artiﬁcial Intelligence, 275:295–309, 2019.
[38] David Kurokawa, Omer Lev, Jamie Morgenstern, and Ariel D Procaccia. Impartial peer review. In Twenty-Fourth International Joint Conference on Artiﬁcial Intelligence, 2015.
17

[39] Anson Kahng, Yasmine Kotturi, Chinmay Kulkarni, David Kurokawa, and Ariel D Procaccia. Ranking wily people who rank each other. In Thirty-Second AAAI Conference on Artiﬁcial Intelligence, 2018.
[40] Ron Holzman and Hervé Moulin. Impartial nominations for a prize. Econometrica, 81(1):173–196, 2013.
[41] Wenxin Ding, Nihar B., and Weina Wang. On the privacy-utility tradeoﬀ in peer-review data analysis. arXiv, 2020.
[42] Leman Akoglu, Hanghang Tong, and Danai Koutra. Graph based anomaly detection and description: A survey. Data mining and knowledge discovery, 29(3):626–688, 2015.
[43] Bryan Hooi, Hyun Ah Song, Alex Beutel, Neil Shah, Kijung Shin, and Christos Faloutsos. FRAUDAR: Bounding graph fraud in the face of camouﬂage. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 895–904, 2016.
[44] Srijan Kumar, Bryan Hooi, Disha Makhija, Mohit Kumar, Christos Faloutsos, and VS Subrahmanian. REV2: Fraudulent user prediction in rating platforms. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining, pages 333–341, 2018.
[45] Guan Wang, Sihong Xie, Bing Liu, and S Yu Philip. Review graph based online store review spammer detection. In 2011 IEEE 11th International Conference on Data Mining, pages 1242–1247. IEEE, 2011.
[46] Leman Akoglu, Rishi Chandy, and Christos Faloutsos. Opinion fraud detection in online reviews by network eﬀects. ICWSM, 13(2-11):29, 2013.
[47] Zhihai Yang, Lin Xu, Zhongmin Cai, and Zongben Xu. Re-scale AdaBoost for attack detection in collaborative ﬁltering recommender systems. Knowledge-Based Systems, 100:74–88, 2016.
[48] Myle Ott, Yejin Choi, Claire Cardie, and Jeﬀrey T Hancock. Finding deceptive opinion spam by any stretch of the imagination. arXiv preprint arXiv:1107.4557, 2011.
[49] Mingdan Si and Qingshan Li. Shilling attacks against collaborative recommender systems: A review. Artiﬁcial Intelligence Review, 53(1):291–319, 2020.
[50] Aanund Hylland and Richard Zeckhauser. The eﬃcient allocation of individuals to positions. Journal of Political economy, 87(2):293–314, 1979.
[51] Anna Bogomolnaia and Hervé Moulin. A new solution to the random assignment problem. Journal of Economic theory, 100(2):295–328, 2001.
[52] Dmytro Korzhyk, Vincent Conitzer, and Ronald Parr. Complexity of computing optimal Stackelberg strategies in security resource allocation games. In Twenty-Fourth AAAI Conference on Artiﬁcial Intelligence, 2010.
[53] Garrett Birkhoﬀ. Three observations on linear algebra. Univ. Nac. Tacuman, Rev. Ser. A, 5:147–151, 1946.
[54] John Von Neumann. A certain zero-sum two-person game equivalent to the optimal assignment problem. Contributions to the Theory of Games, 2(0):5–12, 1953.
[55] Eric Budish, Yeon-Koo Che, Fuhito Kojima, and Paul Milgrom. Implementing random assignments : A generalization of the Birkhoﬀ-von Neumann theorem. 2009.
[56] Shunhua Jiang, Zhao Song, Omri Weinstein, and Hengjie Zhang. Faster dynamic matrix inverse for faster LPs. arXiv preprint arXiv:2004.07470, 2020.
[57] Richard M Karp. Reducibility among combinatorial problems. In Complexity of computer computations, pages 85–103. Springer, 1972.
18

ICLR

PrefLib1

PrefLib2

PrefLib3

Stochastic fairness (% of optimal)

0.04

100

0.02

80

60

0.00

40

20

0.02

0 0.2 0.4 0.6 0.8 1.0

Maximum probability of each assignment

0.04

Figure 3: Experimental results for the Fair Pairwise-Constrained Problem.

0

2

4

6

8

[58] Nicholas Mattei and Toby Walsh. PrefLib: A library of preference data http://preflib.org. In

Proceedings of the 3rd International Conference on Algorithmic Decision Theory (ADT 2013), Lecture

Notes in Artiﬁcial Intelligence. Springer, 2013.

[59] LLC Gurobi Optimization. Gurobi optimizer reference manual, 2020.

[60] Naveen Garg, Telikepalli Kavitha, Amit Kumar, Kurt Mehlhorn, and Julián Mestre. Assigning papers to referees. Algorithmica, 58(1):119–136, 2010.

[61] Thomas H Cormen, Charles E Leiserson, Ronald L Rivest, and Cliﬀord Stein. Introduction to algorithms. MIT press, 2009. Chapter 26.3.

[62] Eﬁm A Dinic. Algorithm for solution of a problem of maximum ﬂow in networks with power estimation. In Soviet Math. Doklady, volume 11, pages 1277–1280, 1970.

Appendices

A Stochastic Fairness Objective
An alternate objective to the sum-similarity objective has been studied in past work [21, 22], aiming to improve the fairness of the assignment with respect to the papers. Rather than maximizing the sum-similarity across all papers, this objective maximizes the minimum total similarity assigned to any paper:

arg max
M ∈Rn×d
subject to

min SrpMrp
p∈P r∈R
Mrp ∈ {0, 1}
Mrp ≤ k
p∈P
Mrp =
r∈R

∀r ∈ R, ∀p ∈ P ∀r ∈ R
∀p ∈ P.

Due to the minimum in the objective, this problem is NP-hard [60]; the paper [22] presents an algorithm to ﬁnd an approximate solution.

19

In our setting of randomized assignments, we consider an analogous fairness objective, which we call the
stochastic fairness objective: minp∈P E r∈R SrpMrp . The problem involving this objective is deﬁned as follows.

Deﬁnition 4 (Fair Pairwise-Constrained Problem). The input to the problem is a similarity matrix S and a matrix Q ∈ [0, 1]n×d. The goal is to ﬁnd a randomized assignment of papers to reviewers that maximizes
minp∈P E r∈R SrpMrp subject to the constraints that P[Mrp = 1] ≤ Qrp, ∀r ∈ R, p ∈ P.
This problem deﬁnition is identical to that of the Pairwise-Constrained Problem (Deﬁnition 1), with the exception that the objective to maximize is now the stochastic fairness objective rather than the sumsimilarity. Note that this objective is not equal to the “expected fairness” (i.e., E minp∈P r∈R SrpMrp ), but by Jensen’s inequality it is an upper bound on the expected fairness.
Fortunately, this problem is solvable eﬃciently, as the following theorem states.

Theorem 4. There exists an algorithm which returns an optimal solution to the Fair Pairwise-Constrained Problem in poly(n, d) time.

We now present our algorithm for solving the Fair Pairwise-Constrained Problem, thereby proving the theorem. It proceeds in a similar manner as the algorithm for the Pairwise-Constrained Problem presented in Section 4.
The algorithm ﬁrst ﬁnds an optimal fractional assignment matrix, since the stochastic fairness objective depends only on the marginal probabilities in the fractional assignment matrix. The optimal fractional assignment is found by the following LP, which we call LP3:

arg max
F ∈Rn×d,x∈R
subject to

x 0 ≤ Frp ≤ 1

(8)

∀r ∈ R, ∀p ∈ P

(9)

Frp ≤ k
p∈P

∀r ∈ R

(10)

Frp =
r∈R
Frp ≤ Qrp

∀p ∈ P

(11)

∀r ∈ R, ∀p ∈ P

(12)

x ≤ SrpFrp
r∈R

∀p ∈ P.

(13)

For any F , the optimal value of x is always minp∈P r∈R SrpFrp, the stochastic fairness of F . For a ﬁxed x, the feasible region of F in LP3 is exactly the space of fractional assignment matrices with stochastic fairness no less than x. Therefore, LP3 will ﬁnd an optimal fractional assignment matrix for the stochastic fairness objective.
Once an optimal fractional assignment matrix has been found, it only remains to sample a deterministic assignment from it. This is done with the sampling algorithm described in Section 4.2, just as in the Pairwise-Constrained Problem.
We now present some empirical results for this algorithm on the four conference datasets described in Section 6. We set all entries of Q equal to the same constant value q0 (varied on the x-axis), and observe how the stochastic fairness objective of the assignment changes as q0 increases from 0.1 to 1 with an interval of 0.1. Since the expectation is inside a minimum in the objective, the objective cannot be estimated without bias by averaging together the stochastic fairness of sampled deterministic assignments. Due to this diﬃculty, we plot the exact objective of our randomized assignment (i.e., the optimal objective value of LP3) rather than averaging over multiple samples, and report the objective as a percentage of the unconstrained optimal solution’s objective (that is, the algorithm’s solution when q0 = 1). As Figure 3 shows, our algorithm ﬁnds a randomized assignment achieving 92.7% of the optimal fairness objective on the ICLR dataset when q0 = 0.5.

B Bad-Assignment Probability Problem Variants
An input to both the Pairwise-Constrained Problem (Deﬁnition 1) and the Partition-Constrained Problem (Deﬁnition 3) is the matrix Q, where Qrp denotes the maximum probability with which reviewer r should be

20

assigned to paper p. In practice, program chairs can set the values in this matrix based on their own beliefs about each reviewer-paper pair. However, it may be diﬃcult for program chairs to translate their beliefs about the risk of assigning any reviewer-paper pair into appropriate values for Q. In this appendix, we deﬁne alternate versions of these problems that allow the program chairs to codify their beliefs in a diﬀerent way.
Deﬁne the assignment of reviewer r to paper p as “bad” if reviewer r intends to untruthfully review paper p (either because they intend to give a dishonest favorable review or because they intend to torpedo-review). Further deﬁne a matrix W ∈ [0, 1]n×d of bad-assignment probabilities, where Wrp represents the probability that the assignment of reviewer r to paper p would be a bad assignment; we assume that the events of each reviewer-paper assignment being bad are all independent of each other. The “true value” of W may not be known, but it can be set based on the program chairs’ beliefs about the reviewers and authors or potentially estimated based on some data from prior conferences. The problem variants we present in the following subsections make use of these bad-assignment probabilities.
We ﬁrst consider the problem of limiting the probabilities of bad reviewer-paper assignments. We then consider the problem of limiting the probabilities that bad pairs of reviewers are assigned to the same paper.

B.1 Handling Bad Reviewer-Paper Assignments

We deﬁne an alternate version of the Pairwise-Constrained Problem using the bad-assignment probabilities:

Deﬁnition 5 (Bad-Assignment Probability Pairwise-Constrained Problem). The input to the problem is a similarity matrix S, a matrix W ∈ [0, 1]n×d of bad-assignment probabilities, and a value λ ∈ [0, 1]. The goal

is to ﬁnd a randomized assignment of papers to reviewers that maximizes E the constraints that WrpP[Mrp = 1] ≤ λ, ∀r ∈ R, p ∈ P.

r∈R p∈P SrpMrp subject to

WrpP[Mrp = 1] is exactly the probability that both (i) reviewer r is assigned to paper p and (ii) this assignment is bad, so the constraints in the problem limit this at λ for all r ∈ R and p ∈ P. This version of the Pairwise-Constrained Problem may be useful in practice if program chairs ﬁnd it easier to set the values of W than they would for Q.
We now show how to solve the Bad-Assignment Probability Pairwise-Constrained Problem, by translating it to the original Pairwise-Constrained Problem. Suppose that we have access to the matrix F of marginal assignment probabilities that occur under some randomized assignment. The randomized assignment obeys our constraints if and only if FrpWrp ≤ λ, ∀r ∈ R, p ∈ P. This observation leads to the following method of solving the Bad-Assignment Probability Pairwise-Constrained Problem:

• Transform the given instance of the Bad-Assignment Probability Pairwise-Constrained Problem into an instance of the Pairwise-Constrained Problem by constructing a matrix of maximum probabilities Q where

Qrp = min {λ/Wrp, 1} ∀r ∈ R, p ∈ P.

• Solve the Pairwise-Constrained Problem using the algorithm from Theorem 1, described in Section 4.

B.2 Handling Bad Pairs of Reviewers
Here, we ﬁrst present an alternative version of the Partition-Constrained Problem and show how to solve it. We then present a diﬀerent approach to handling the issue of bad reviewer pairs.

B.2.1 Constraints on Disjoint Reviewer Sets
In the same way as done above for the Pairwise-Constrained Problem, we deﬁne an alternate version of the Partition-Constrained Problem:
Deﬁnition 6 (Bad-Assignment Probability Partition-Constrained Problem). The input to the problem is a similarity matrix S, a matrix W ∈ [0, 1]n×d of bad-assignment probabilities, a value λ ∈ [0, 1], and a partition of the reviewer set into subsets I1, . . . , Im ⊆ R. The goal is to ﬁnd a randomized assignment of papers to reviewers that maximizes E r∈R p∈P SrpMrp subject to the constraints that WrpP[Mrp = 1] ≤ λ, ∀r ∈ R, p ∈ P and P[Map = 1 ∧ Mbp = 1] = 0, ∀a, b ∈ Ii, ∀i ∈ [m].

21

Just as for the Bad-Assignment Probability Pairwise-Constrained Problem, we solve this problem by ﬁrst transforming an instance of this problem into an equivalent instance of the Partition-Constrained Problem, done by constructing a matrix of maximum probabilities Q where Qrp = min (λ/Wrp, 1) , ∀r ∈ R, p ∈ P. We then solve this instance using the algorithm in Section 5.2.

B.2.2 Constraints on the Expected Number of Bad Reviewers
The Bad-Assignment Probability Partition-Constrained Problem requires a partition of the reviewer set and prevents pairs of reviewers from being assigned to the same paper if they are in the same subset of this partition. Alternatively, one may want to prevent pairs of reviewers from being assigned to the same paper based on whether W indicates that they are both likely to be bad assignments on this paper, rather than based on some partition of the reviewer set. In this way, we now present an alternative approach to handling the issue of bad reviewer pairs, which does not require a partition of the reviewer set. Rather than explicitly constraining the probabilities of certain same-subset reviewer-reviewer-paper triples as in the Bad-Assignment Partition-Constrained Problem, we limit the expected number of bad reviewers on each paper.
The following problem states this goal:
Deﬁnition 7 (Bad-Assignment Probability Expectation-Constrained Problem). The input to the problem is a similarity matrix S, a matrix W ∈ [0, 1]n×d of bad-assignment probabilities, a value λ ∈ [0, 1], and a value µ ∈
R. The goal is to ﬁnd a randomized assignment of papers to reviewers that maximizes E r∈R p∈P SrpMrp subject to the constraints that WrpP[Mrp = 1] ≤ λ, ∀r ∈ R, p ∈ P and r∈R WrpE[Mrp] ≤ µ, ∀p ∈ P.
We now present the algorithm that optimally solves this problem. The following LP, LP4, ﬁnds a fractional assignment with expected number of bad reviewers on each paper no greater than µ:

arg max
F ∈Rn×d
subject to

SrpFrp
p∈P r∈R
0 ≤ Frp ≤ 1
Frp ≤ k
p∈P
Frp =
r∈R
FrpWrp ≤ λ
FrpWrp ≤ µ
r∈R

(14)

∀r ∈ R, ∀p ∈ P

(15)

∀r ∈ R

(16)

∀p ∈ P

(17)

∀r ∈ R, ∀p ∈ P

(18)

∀p ∈ P.

(19)

Constraints (15-17) deﬁne the space of fractional assignment matrices, Constraint (18) ensures that the probability of each bad assignment occurring is limited at λ, and Constraint (19) ensures that the expected number of bad reviewer-paper assignments for each paper is at most µ. Therefore, LP4 ﬁnds the optimal fractional assignment for the Bad-Assignment Probability Expectation-Constrained Problem. This fractional assignment can then be sampled from using the sampling algorithm in Section 4.2.
The above approach to controlling bad reviewer pairs is not directly comparable to the approach taken earlier when solving the Bad-Assignment Probability Partition-Constrained Problem. The Bad-Assignment Probability Expectation-Constrained Problem indirectly restricts pairs of reviewers from being assigned to the same paper based on whether W indicates that they are both likely to be bad assignments on that paper, instead of based on a partition of the reviewer set. This could be advantageous if the sets of likely-bad reviewers for each paper (as given by the probabilities in W ) are not expressed well by any partition of the reviewer set. However, handling suspicious reviewer pairs through constraining the expected number of bad reviewers per paper is weaker than directly constraining the probabilities of certain reviewer-reviewer-paper triples (as in the Bad-Assignment Probability Partition-Constrained Problem). First, it provides a guarantee only in expectation, and does not guarantee anything about the probabilities of the events we wish to avoid (that is, bad reviewer pairs being assigned to a paper). In addition, we here are assuming that the event of paper p and reviewer r being a bad assignment is independent of this event for all other reviewer-paper

22

pairs; so, this method cannot address the issue of associations between reviewers, such as their presence at the same academic institution.

C Decomposition Algorithm for the Pairwise-Constrained Problem
In Section 4, we provided the sampling algorithm that realizes Theorem 1, thus solving the PairwiseConstrained Problem (Deﬁnition 1). We here provide a decomposition algorithm to compute a full distribution over deterministic assignments for a given fractional assignment matrix (which the prior work [55] does not). For simplicity, we assume here that all reviewer loads are met with equality (that is, p∈P Frp = k for all r ∈ R); the extension to the case when reviewer loads are met with inequality is simple.
We ﬁrst deﬁne certain concepts necessary for the algorithm. We then present a subroutine of the algorithm and prove its correctness. We then present the overall algorithm and prove its correctness. Finally, we analyze the time complexity of the algorithm.

Preliminaries: We deﬁne here three concepts used in the algorithm and its proof.
• A capacitated matching instance consists of a set of papers P, a set of reviewers R, and a capacity function h : P ∪ R → Z. A solution to (P, R, h) is a matrix F ∈ [0, 1]n×d, where for any p ∈ P,

Frp = h(p),
r∈R

and for any r ∈ R,

Frp = h(r).
p∈P

The solution F is integral if Frp ∈ {0, 1} for all p ∈ P and r ∈ R.

• For any R and P, a maximum matching on a set S ⊆ R × P subject to capacities h is a set M ⊆ S such that r∈R I[(r, p) ∈ M ] ≤ h(p), ∀p ∈ P and p∈P I[(r, p) ∈ M ] ≤ h(r), ∀r ∈ R, and |M | is maximized.
• For any R and P, a perfect matching on a set S ⊆ R × P subject to capacities h is a maximum matching on S subject to h that additionally satisﬁes r∈R I[(r, p) ∈ M ] = h(p), ∀p ∈ P and p∈P I[(r, p) ∈ M ] = h(r), ∀r ∈ R.

Decomposition subroutine: The following procedure, a subroutine of the overall algorithm, takes an instance (P, R, h) and a solution to that instance F as input, and outputs an integral solution F0 to (P, R, h) with weight α0 and a fractional solution F to (P, R, h) with strictly fewer fractional entries than F . Moreover, F , F0, α0, and F satisfy F = α0F0 + (1 − α0)F .
1. Let E ⊆ R × P be E = {(r, p) | Frp ∈ (0, 1)}, and let M0 ⊆ R × P be M0 = {(r, p) | Frp = 1}. With this, deﬁne capacity function h as, for any p ∈ P,

h (p) = h(p) − |{(r, p) | r ∈ R} ∩ M0|

and for any r ∈ R,

h (r) = h(r) − |{(r, p) | p ∈ P} ∩ M0|.

2. Find a maximum matching M ⊆ E on E subject to capacity constraints h .

3. Set F0 as

(F0)rp = I [(r, p) ∈ M ∪ M0] , ∀r ∈ R, p ∈ P.

Set F as

1 Frp = (1 − α0) (Frp − α0(F0)rp), ∀r ∈ R, p ∈ P.

Set α0 = min({Frp | (r, p) ∈ M } ∪ {1 − Frp | (r, p) ∈ E \ (M ∪ M0)}).

23

We prove the correctness of this subroutine in Lemma 3. Before we do, we restate a result from prior work [55] that we use in the proof, using our own notation.

Lemma 2 ( [55, Thm. 1]). For any (P, R, h) and any solution F to (P, R, h), there exists some z ∈ Z, integral

solutions {F1, . . . , Fz} to (P, R, h), and α lying on the z-dimensional simplex, such that F =

z i=1

αiFi.

Now, the following lemma proves the correctness of the subroutine.

Lemma 3. The decomposition subroutine ﬁnds F0, α0, and F , such that (i) F0 is an integral solution to (P, R, h), (ii) F is a fractional solution to (P, R, h), (iii) F has strictly fewer fractional entries than F , and (iv) F = α0F0 + (1 − α0)F .

Proof. We ﬁrst consider (i). The key step is to show that the maximum matching M found in step 2 is a perfect matching with respect to h , or equivalently, to show there is a perfect matching on E with respect to h . Consider the capacitated matching instance (P, R, h ), and the solution F where

Frp if Frp < 1 Frp = 0 otherwise.

F is a solution to (P, R, h ) by the construction of h . By Lemma 2, F is a convex combination of integral

solutions to (P, R, h ). For some z, let {F1, . . . , Fz} and α be such a decomposition of F , where each Fi is

an integral solution to (R, P, h ) and αi is its associated weight. For each i ∈ [z], let Mi ⊆ R × P be the set

of (r, p) pairs where (Fi)rp = 1. Since Fi is a solution to (R, P, h ), Mi is a perfect matching with respect

to h . By the deﬁnition of F , (r, p) ∈ E if and only if Frp > 0. Now since F =

z i=1

αiFi,

E

=

z i=1

Mi.

Since each Mi is a perfect matching with respect to h , E contains a perfect matching with respect to h and

so the maximum matching M found is in fact a perfect matching with respect to h . Therefore, M ∪ M0 is a

perfect matching with respect to h by the deﬁnition of h . Therefore, F0 is an integral solution to (P, R, h).

For (ii), by the construction of F , all capacity constraints hold with equality. We only need to show

that Frp ∈ [0, 1] for any (r, p). Consider any (r, p). There are 3 cases. If (r, p) ∈ M0, then Frp = 1. If

(r, p) ∈ M ∪ M0, then the choice of α0 ensures that

1

1

Frp = (1 − α0) Frp ≤ (1 − (1 − Frp)) Frp = 1

and 1
Frp = (1 − α0) Frp ≥ Frp ≥ 0. If (r, p) ∈ M , the choice of α0 ensures that

1

1

Frp = (1 − α0) (Frp − α0) ≥ (1 − α0) (Frp − Frp) = 0

and 1
Frp = (1 − α0) (Frp − α0) ≤ Frp ≤ 1.
As a result, F is a solution to (P, R, h). For (iii), the choice of α0 ensures that at least one of the inequalities above achieves equality. That is,
there exists (r, p) where Frp ∈ (0, 1) such that Frp ∈ {0, 1}. Finally, (iv) holds by the construction of F0 and F .

Overall algorithm: Using the above subroutine, the overall algorithm proceeds in the following recursive

way. It takes as input a capacitated matching instance (P, R, h) and a solution to that instance F . It

outputs integral solutions {F1, . . . , Fz} to (P, R, h) and α lying on the z-dimensional simplex, such that

F=

z i=1

αiFi.

1. If F is integral, return solution {F } and weight 1.

24

2. Otherwise, decompose F into F0 (with weight α0) and F using the above subroutine.

3. Recursively call this algorithm with (P, R, h) and F as input, decomposing F into solutions {F1, . . . , Fz} with weights α.

4. Deﬁne β = (1 − α0)α. Return the solutions {F0, F1, . . . , Fz} with weights (α0, β1, . . . , βz).

We now prove the correctness of this algorithm.

Theorem 5. The decomposition algorithm correctly outputs integral solutions {F1, . . . , Fz} to (P, R, h) and

α lying on the z-dimensional simplex, such that F =

z i=1

αiFi.

Proof. We prove this statement by induction. If the algorithm returns in step 1, the theorem’s statement

holds. Now, assume that the theorem’s statement holds for the decomposition returned by the recursive call

to the algorithm in step 3, so that the following all hold: {F1, . . . , Fz} are integral solutions to (P, R, h), α

lies on the z-dimensional simplex, and F =

z i=1

αiFi.

By

Lemma

3,

F0

is

an

integral

solution

to

(P, R, h),

so the z + 1 solutions returned in step 4 are integral solutions to (P, R, h). Since α0 ∈ [0, 1], β ∈ [0, 1]z, and

α0 +

z i=1

βz

=

1,

the

weights

returned

in

step

4

lie

on

the

z

+1

dimensional

simplex.

Finally,

by

Lemma

3,

F = α0F0 + (1 − α0)F
z
= α0F0 + (1 − α0) αiFi
i=1 z
= α0F0 + βiFi.
i=1

Therefore, the theorem’s statement holds for the output of the algorithm in step 4. By induction, this proves the desired statement.

This decomposition algorithm can be used as part of the algorithm that solves the Pairwise-Constrained Problem, substituting for the sampling algorithm described in Section 4.2. It ﬁnds the full decomposition of the fractional assignment matrix into deterministic assignments rather than sampling a deterministic assignment. The capacity function h used as the original input to the algorithm is deﬁned as h(r) = k, ∀r ∈ R and h(p) = , ∀p ∈ P, and the input solution F is exactly the fractional assignment matrix found as the solution to LP1. The output integral solutions represent deterministic assignments, and the corresponding weights represent the probability with which each assignment should be chosen.

Time complexity: Since F has at least one fewer fractional entry than F , the recursive procedure has depth O(dn) and therefore makes O(dn) calls to the decomposition subroutine. In each call, the bottleneck is ﬁnding a maximum matching on E subject to capacities h. This can be solved as a max-ﬂow problem on a graph with O(d + n) vertices and O(dn) edges [61]. Using Dinic’s algorithm [62], the computation of each matching takes O(dn(d + n)2) time, giving an overall time complexity of O(d2n2(d + n)2).

D Proofs of Theorem 2 and Corollary 1
Proof of Theorem 2: We ﬁrst deﬁne a decision variant of the Triplet-Constrained Problem, called “Arbitrary-Constraint Feasibility.” An instance of this problem is deﬁned by the paper and reviewer loads and k, and a 3-dimensional tensor T ∈ [0, 1]n×n×d. For all i, j ∈ R, i = j and for all p ∈ P, Tijp denotes the maximum probability that both reviewers i and j are assigned to paper p. The question is: does there exist a randomized assignment that obeys the constraints given by T ? We next show that Arbitrary-Constraint Feasibility is NP-hard by a reduction from 3-Dimensional Matching.
An instance of 3-Dimensional Matching consists of three sets X, Y, Z of size s, and a collection of tuples in X × Y × Z. It asks whether there exists a selection of s tuples that includes each element of X, Y, and Z at most once. This problem is known to be NP-complete [57].
Given such an instance of 3-Dimensional Matching, we construct an instance of Arbitrary-Constraint Feasibility. Set loads of = 2 reviewers per paper and k = 1 paper per reviewer. Consider |X| + |Y | reviewers

25

(one for each element of X ∪ Y ) and |Z| papers (one for each element of Z). Deﬁne the tensor T to have Tijp equal to 1 if (i, j, p) is one of the tuples, and 0 otherwise.
We now show that a 3-Dimensional Matching instance is a yes instance (that is, the answer to it is “yes”) if and only if the corresponding Arbitrary-Constraint Feasibility instance is a yes instance, thus proving that solving Arbitrary-Constraint Feasibility in polynomial time would allow us to solve 3-Dimensional Matching in polynomial time. If there exists a feasible reviewer-paper assignment in the corresponding Arbitrary-Constraint Feasibility instance, then we would answer yes for the original 3-Dimensional Matching instance; otherwise, if there does not exist a feasible reviewer-paper assignment, then we would answer no for the original 3-Dimensional Matching instance.
If the 3-Dimensional Matching instance is a yes (that is, there exists a valid selection of s tuples), then consider the paper assignment that assigns the corresponding reviewers and paper within each triple in the matching. Each paper has exactly 2 reviewers and each reviewer has exactly 1 paper, so this is a deterministic assignment. Since it includes only the triples in the matching instance, it obeys the probability constraints of T , so the Arbitrary-Constraint Feasibility instance is a yes.
If the 3-Dimensional Matching instance is a no, then all choices of s tuples include some element of X, Y , or Z twice. If some element of Z is chosen twice, then there must exist another element of Z that is not included in any tuple. Therefore, any assignment of reviewer pairs to papers must either (a) include some reviewer-pair-to-paper assignment disallowed by T (i.e., an assignment not in the collection of tuples), (b) make less than s assignments of pairs to papers (and thus not assign to some paper), or (c) assign a reviewer twice or not assign some paper. So, no deterministic reviewer-paper assignment can meet the constraints of T . Now consider any randomized assignment, and select an arbitrary deterministic assignment in support of the randomized assignment. This deterministic assignment does not meet the constraints of T , so it must assign some reviewer r to some paper p that T requires to have probability 0. Therefore, since this deterministic assignment is in support, the randomized assignment assigns reviewer r to paper p with non-zero probability, thereby violating the constraints of T . Therefore, no randomized assignment can meet the constraints of T . Therefore, the Arbitrary-Constraint Feasibility instance is a no. This proves that Arbitrary-Constraint Feasibility is NP-hard.
Since even telling if the feasible region of randomized assignments is non-empty is NP-hard, optimizing any objective over this region is also NP-hard. Therefore, the Triplet-Constrained Problem is NP-hard.
Proof of Corollary 1: Suppose that the polytope of implementable reviewer-reviewer-paper probabilities could be expressed in a polynomial number of linear inequality constraints (with the reviewer-reviewer-paper probabilities as variables). An LP could then be constructed with these inequalities as well as the inequalities given by a tensor T of maximum reviewer-reviewer-paper probabilities. Solving this LP with any linear objective would then ﬁnd a feasible point, solving Arbitrary-Constraint Feasibility. Since LPs can be solved in time polynomial in the number of variables and constraints, this is a contradiction unless P = N P .
E Proof of Lemma 1 and Corollary 2
In Section 5.2.1, we described the sampling algorithm that realizes Lemma 1 and Corollary 2. Here, we present proofs of these results.
Proof of Lemma 1: We ﬁrst prove part (i) of the lemma. Consider any subset I and any paper p, and recall that in Section 5.2.1 we showed that the algorithm presented there has the property that the total load on each paper from each subset is preserved exactly if originally integral and rounded in either direction if originally fractional. If the total load from subset I on paper p is less than or equal to 1 originally (i.e.,
r∈I Frp ≤ 1), then this algorithm will only ever sample assignments with either 0 or 1 reviewers, so it never samples a integral assignment that assigns two reviewers from subset I to paper p.
We now prove part (ii) of the lemma. Suppose that the total load from subset I on paper p is originally strictly greater than 1 (i.e., r∈I Frp > 1). Let X denote a random variable that represents the number of reviewers from subset I on paper p, that is, X = r∈I Mrp. Hence, we have E[X] = r∈I Frp > 1. Suppose that we implement the marginal probabilities F as a distribution over deterministic assignments that places zero mass on any deterministic assignment where X ≥ 2. Since X is integral in any deterministic assignment,
26

all of the mass must be placed on deterministic assignments where X ≤ 1. Since E[X] > 1, this is impossible. Therefore, F cannot be implemented without having some probability of placing two reviewers from subset I on paper p, so the expected number of pairs of reviewers from subset I assigned to paper p must be non-zero for any sampling algorithm.

Proof of Corollary 2: We now show that the distribution sampled from by the algorithm realizing

Lemma 1 minimizes the expected number of pairs of reviewers from each subset assigned to each paper.

Consider any subset I and paper p, and again let X denote a random variable that represents the number of

reviewers from subset I on paper p. The expected number of pairs of reviewers from subset I assigned to

paper p is E X2 = 12 E[X2] − 12 E[X]. Since E[X] is ﬁxed for a given F , we must only show that our chosen

decomposition minimizes E[X2].

Let f be the probability mass function of X under the distribution of X produced by our sampling

algorithm, so that f (i) = P [X = i] for i ∈ {0, . . . , |I|}. Let f be the probability mass function of X

under any diﬀerent distribution produced by some sampling algorithm, so that ∃i ∈ {0, . . . , |I|} such that

f (i) = f (i). Since both f and f are produced by sampling algorithms, they must respect the marginal

assignment probabilities given by F .

First, assume that E[X] = µ is integral. E[X] = r∈I Frp, so µ is equal to the total load from subset I on paper p. From Section 5.2.1, our sampling algorithm preserves exactly the loads from any subset on

any paper that are originally integral, meaning that it will always assign exactly µ reviewers from subset I

to paper p. In other words, our sampling algorithm always gives the distribution of X where f (µ) = 1 and

f (i) = 0 for i = µ. Since all distributions of X have the same expectation, that f (i) > 0 for some i = µ. For this distribution, we have that

|I | i=0

f

(i)i

=

µ;

we

also

know

|I |

|I |−µ

|I |−µ

Ef [X2] = f (i)i2 =

f (µ + ∆)(µ + ∆)2 = µ2 +

f (µ + ∆)∆2 > µ2 = Ef [X2].

i=0

∆=−µ

∆=−µ

Now, suppose that E[X] = µ is not integral. From Section 5.2.1, our sampling algorithm rounds to a neighboring integer the loads from any subset on any paper that are originally not integral, meaning that it will always assign exactly µ or µ reviewers from subset I to paper p. In other words, our sampling algorithm only places probability mass on outcomes X = µ or X = µ , so f (i) = 0 for i ∈ { µ , µ }. There is only one way to do this so that E[X] = µ; exactly f ( µ ) = µ − µ and f ( µ ) = µ − µ. Then under this distribution, via some algebraic simpliﬁcations,

Ef [X2] = f ( µ ) µ 2 + f ( µ ) µ 2

= − µ 2 + µ − µ + 2 µ µ.

(20)

Under any other distribution of X giving the probability mass function f ,

|I |
Ef [X2] = f (i)i2

i=0

|I|− µ

=

f ( µ + ∆)( µ

+ ∆)2

+2 µ

|I|− µ

(f ( µ

|I|− µ
+ ∆)∆) +

∆=− µ

∆=− µ

∆=− µ

|I|− µ

= µ 2 + 2 µ (µ − µ ) +

f ( µ + ∆)∆2 .

∆=− µ

f ( µ + ∆)∆2

(21)

We want to show that Ef [X2] > Ef [X2]. From (20) and (21), it remains to show that

|I |
f (i)(i − µ )2 > µ − µ.
i=0

27

Sum-similarity (% of optimal) Runtime (sec)
Sum-similarity (% of optimal)

Community, g=3 Community, g=6
100 80 60 40 20 0 0.2 0.4 0.6 0.8 1.0
Maximum probability of each assignment

Community, g=9 Community, g=12

Uniform random

100

80

60

40

20

0 1.0 1.5 2.0 2.5 3.0 Max. expected same-subset reviewers/paper

(a) Pairwise-Constrained Problem

(b) Partition-Constrained Problem

600

0

2

4

6

8

400

200

0 1000 2000 3000 4000 5000 Problem size
(c) Runtime on Pairwise-Constrained Problem Figure 4: Experimental results on synthetic simulations.

Note that because f (i) = f (i) for some i, there exists some j ∈ { µ , µ } such that f (j) > 0. Further, (i − µ )2 ≥ ( µ − i) for all integers i and (i − µ )2 > ( µ − i) for all integers i ∈ { µ , µ }. Therefore,

|I |

|I |

|I |

f (i)(i − µ )2 > f (i)( µ − i) = µ − f (i)i = µ − µ.

i=0

i=0

i=0

Therefore, Ef [X2] > Ef [X2] as desired, so f is the probability mass function corresponding to the distribution of X which minimizes E[X2] (uniquely, since the inequality is strict). This concludes the proof that our algorithm minimizes E[X2] and therefore minimizes the expected number of pairs from the same subset
assigned to the same paper.

F Synthetic Simulations
We now present experimental results on synthetic simulations. All results are averaged over 10 trials with error bars plotted representing the standard error of the mean, although error bars are sometimes not visible since the variance is low. All experiments were run on a computer with 8 cores and 16 GB of RAM, running Ubuntu 18.04 and solving the LPs with Gurobi 9.0.2 [59].

28

We consider two diﬀerent simulations. First, we consider a simulated “community model” as used in past work [26]. In this model, n = d = 360 and k = = 3; it is further parameterized by a group size g. For all i ∈ {0, g, 2g, . . . , n}, reviewers i through i + g − 1 have similarity 1 with papers i through i + g − 1 and similarity 0 with all other papers. We consider four diﬀerent group sizes g: 3, 6, 9, 12. We also consider a uniform random simulation, where each entry of the similarity matrix is independently and uniformly drawn from [0, 1), ﬁxing n = d = 1000 and k = = 3.
In Figure 4a, we examine the performance of our algorithm for the Pairwise-Constrained Problem. For each simulation, we set all entries of Q to a constant q0 and observe the sum-similarity as we vary q0 (on the x-axis). The objective value is reported here as a percentage of the optimal unconstrained solution’s objective, as was done in Section 6. For the community models, the group size makes a large diﬀerence as to what an acceptable value of q0 is. For example, with group size 6 and q0 = 0.5, our algorithm will always assign all good reviewers to all papers; however, for any lower value of q0 it can no longer do this and so the objective deteriorates rapidly. Note that since our algorithm is optimal, this deterioration is due to the problem being overconstrained for low values of q0 and not due to an issue with the algorithm. For the uniform random simulation, our algorithm performs very well, since there are likely many reviewers with high similarity for each paper.
We also examine the performance of our algorithm for the Partition-Constrained Problem in Figure 4b. For each simulation, we ﬁx q0 = 0.5 and gradually loosen Constraint (7) in LP2 by increasing the constant from 1 to 3 in increments of 0.2, shown on the x-axis. We plot the sum-similarity objective of the resulting assignment, reported as a percentage of the optimal non-partition-constrained solution’s objective (that is, the solution to the Pairwise-Constrained Problem with q0 = 0.5). For the community model simulations, we assign all reviewers in each group to the same subset of the partition. Since all of the reviewers who can review each paper well are in the same subset, this presents a highly constrained problem (which our algorithm is solving optimally). As expected, our algorithm trades oﬀ the number of same-subset reviewer pairs assigned to the same paper and the sum-similarity objective rather poorly (as would any other algorithm). Since q0 = 0.5, there is no diﬀerence between the cases with group size 6 or greater. For the uniform random simulation, we assign random subsets of size 100. Since there are likely many reviewers with high similarity for each paper in diﬀerent subsets, our algorithm again performs very well.
In Figure 4c, we show the runtime of our algorithm for the Pairwise-Constrained Problem on the various simulations, ﬁxing q0 = 0.5 and varying n = d on the x-axis. The runtime of our algorithm is similar across the diﬀerent simulations. Our algorithm solves the uniform random simulation case with n = d = 5000 in just over 10 minutes.
29

