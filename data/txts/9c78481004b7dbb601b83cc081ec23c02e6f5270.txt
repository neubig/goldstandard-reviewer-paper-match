Stability of Gradient Learning Dynamics in Continuous Games: Scalar Action Spaces
Benjamin J. Chasnov∗, Daniel Calderone∗, Behc¸et Ac¸ıkmes¸e, Samuel A. Burden, Lillian J. Ratliff

arXiv:2011.03650v1 [cs.GT] 7 Nov 2020

Abstract— Learning processes in games explain how players grapple with one another in seeking an equilibrium. We study a natural model of learning based on individual gradients in twoplayer continuous games. In such games, the arguably natural notion of a local equilibrium is a differential Nash equilibrium. However, the set of locally exponentially stable equilibria of the learning dynamics do not necessarily coincide with the set of differential Nash equilibria of the corresponding game. To characterize this gap, we provide formal guarantees for the stability or instability of such ﬁxed points by leveraging the spectrum of the linearized game dynamics. We provide a comprehensive understanding of scalar games and ﬁnd that equilibria that are both stable and Nash are robust to variations in learning rates.
I. INTRODUCTION
The study of learning in games is experiencing a resurgence in the control theory [19], [21], [22], optimization [11], [13], and machine learning [4]–[6], [8], [14] communities. Partly driving this resurgence is the prospect for gametheoretic analysis to yield machine learning algorithms that generalize better or are more robust. Towards understanding the optimization landscape in such formulations, dynamical systems theory is emerging as a principal tool for analysis and ultimately synthesis [1]–[3], [11], [12]. A predominant learning paradigm used across these different domains is gradient-based learning. Updates in large decision spaces can be performed locally with minimal information, while still guaranteeing local convergence in many problems [5], [13].
One of the primary means to understand the optimization landscape of games is the eigenstructure and spectrum of the Jacobian of the learning dynamics in a neighborhood of a stationary point. In particular, for a zero-sum continuous game (f, −f ) with some continuously-differentiable f , the Nash equilibria are saddle points of the function f . As the example in Fig. 1 demonstrates, not all saddle points are relevant. Loosely speaking, the equilibrium conditions for the game correspond to constraints on the curvature directions of the cost function and hence, on the eigenstructure of the Jacobian nearby equilibria.
The local stability of a hyperbolic ﬁxed point in a nonlinear system can be assessed by examining the eigenstructure of the linearized dynamics [9], [20]. However, in a
B. Chasnov, S. Burden, and L. Ratliff are with the Department of Electrical and Computer Engineering, University of Washington, Seattle, WA 98115 {bchasnov,sburden,ratliffl}@uw.edu
D. Calderone and B. Ac¸ıkmes¸e are with the Department of Aeronautics and Astronautics, University of Washington, Seattle, WA 98115 {djcal,behcet}@uw.edu
∗ Denotes equal contribution. Funding for this work is provided by NSF Award #1836819 and NIH 5T90DA032436-09.

f (x, y) y
x

f˜(x, y)

y x

(a) Natural game coordinates.

(b) Rotated coordinates.

Fig. 1. Cost landscape is crucial to understanding dynamics. The zero-

sum game deﬁned by f (x, y) = 21 x2 − 81 y2 has a Nash equilibrium at

the origin, which is a stable saddle point of gradient√play (1). If the cost

function is rotated to f˜(x, y) = 1 x2 + 11 y2 − 5 3 xy—a rotation by

π

—then

the

origin

is

no

longer

32
a Nash

32
equilibrium,

16
and

is

unstable

under

3

gradient play.

game context there are extra constraints coming from the underlying game—that is, players are constrained to move only along directions over which they have control. They can only control their individual actions, as opposed to the entire state of the dynamical system corresponding to the learning rules being applied by the agents. It has been observed in earlier work that not all stable attractors of gradient play are local Nash equilibria and not all local Nash equilibria are stable attractors of gradient play [11]. Furthermore, changes in players’ learning rates—which corresponds to scaling rows of the Jacobian—can change an equilibrium from being stable to unstable and vice versa [5].
To summarize, there is a subtle but extremely important difference between game dynamics and traditional nonlinear dynamical systems: alignment conditions are important for distinguishing between equilibria that have game-theoretic meaning versus those which are simply stable attractors of learning rules, and features of learning dynamics such as learning rates can play an important role in shaping not only equilibria but also alignment properties. Motivated by this observation along with the recent resurgence of applications of learning in games in control, optimization, and machine learning, in this paper we provide an in-depth analysis of the spectral properties of gradient-based learning in two-player continuous games.
Contributions. This paper characterizes the spectral properties of structured 2×2 matrices and analyzes the stability of equilibria in continuous games. Having a complete algebraic understanding of the spectrum of the game Jacobian is fundamental to understanding when Nash equilibria coincide with stable equilibria. Many of our results are geometric in

nature and are accompanied by diagrams. It is known that the quadratic numerical range of a block
operator matrix contains the operator’s (point) spectrum [23]. Thus, it serves as an important tool for quantifying the spectrum of two-player game dynamics. The method for obtaining the quadratic numerical range is by reducing a block matrix to 2 × 2 matrices.
Towards this end, we decompose the 2 × 2 game Jacobian into coordinates that reﬂect the interaction between the players. The decomposition provides insights on games and vector ﬁelds in general, which permits us to provide a complete characterization of the stability of equilibria in twoplayer gradient learning dynamics.
Organization. In Section II, we describe the gradientbased learning paradigm and analyze the spectral properties of block operator matrices using the quadratic numerical range [23]. In Section III, we analyze the spectral properties of two-player continuous games on scalar action spaces. Our main results are on general-sum games, with insights drawn from speciﬁc classes of games. In Section IV, we certify the stability of Nash and non-Nash equilibria in two-player scalar games. A key ﬁnding is that in the scalar case, equilibria that are both stable and Nash are robust to variations in learning rates; in the vector case, they are not. We provide an example in Section V and conclude in Section VI.
II. PRELIMINARIES
This section contains game-theoretic preliminaries, mathematical formalism, and a description of the gradient-based learning paradigm studied in this paper.
A. Game-Theoretic Preliminaries
A 2-player continuous game G = (f1, f2) is a collection of costs deﬁned on X = X1 × X2 where player (agent) i ∈ I = {1, 2} has cost fi : X → R. In this paper, the results apply to games with sufﬁciently smooth costs fi ∈ Cr(X, R) for some r ≥ 0. Agent i’s set of feasible actions is the didimensional precompact set Xi ⊆ Rdi . The notation x−i denotes the action of player i’s competitor; that is, x−i = xj where j ∈ I\{i}.1
The most common and arguably natural notion of an equilibrium in continuous games is due to Nash [16].
Deﬁnition 1 (Local Nash equilibrium): A joint action proﬁle x = (x1, x2) ∈ W1 × W2 ⊂ X1 × X2 is a local Nash equilibrium on W1 × W2 if, for each player i ∈ I, fi(xi, x−i) ≤ fi(xi, x−i), ∀xi ∈ Wi. A local Nash equilibrium can equivalently be deﬁned as in terms of best response maps: xi ∈ arg miny fi(y, x−i). From this perspective, local optimality conditions for players’ optimization problems give rise to the notion of a differential Nash equilibrium [18], [19]; non-degenerate differential Nash are known to be generic and structurally stable amongst local Nash equilibria in sufﬁciently smooth games [17]. Let Difi denote the derivative of fi with respect to xi and, analogously, let Di(Difi) ≡ Di2fi be player i’s individiaul Hessian.
1For 2-player games, x−1 = x2 and x−2 = x1.

Deﬁnition 2: For continuous game G = (f1, f2) where fi ∈ C2(X1 × X2, R), a joint action proﬁle (x1, x2) ∈ X1 × X2 is a differential Nash equilibrium if Difi(x1, x2) = 0 and Di2fi(x1, x2) > 0 for each i ∈ I. A differential Nash equilibrium is a strict local Nash equilib-
rium [18, Thm. 1]. Furthermore, the conditions Difi(x) = 0 and Di2fi(x) ≥ 0 are necessary for a local Nash equilibrium [18, Prop. 2].
Learning processes in games, and their study, arose as one
of the explanations for how players grapple with one another
in seeking an equilibrium [7]. In the case of sufﬁciently
smooth games, gradient-based learning is a natural learning rule for myopic players2.

B. Gradient-based Learning as a Dynamical System
At time t, a myopic agent i updates its current action xi(t) by following the gradient of its individual cost fi given the decisions of its competitors x−i. The synchronous adaptive process that arises is the discrete-time dynamical system

xi(t + 1) = xi(t) − γiDifi(xi(t), x−i(t))

(1)

for each i ∈ I where Difi is the gradient of player i’s cost with respect to xi and γi is player i’s learning rate.
a) Stability: Recall that a matrix A is called Hurwitz
if its spectrum lies in the open left-half complex plane C◦−. Furthermore, we often say such a matrix is stable in particular when A corresponds to the dynamics of a linear system x˙ = Ax or the linearization of a nonlinear system around a ﬁxed point of the dynamics.3
It is known that (1) will converge locally asymptotically
to a differential Nash equilibrium if the local linearization is
a contraction [5]. Let

g(x) = (D1f1(x), D2f2(x))

(2)

be the vector of individual gradients and let Dg(x) be its Jacobian—i.e., the game Jacobian. Further, let σp(A) ⊂ C denote the point spectrum (or spectrum) of the matrix A, and ρ(A) its spectral radius. Then, x is locally exponentially stable if and only if ρ(I − ΓDg(x)) < 1, where Γ = blockdiag(γ1Id1 , γ2Id2 ) is a diagonal matrix and Idi is the identity matrix of dimension di. The map I − ΓDg(x) is the local linearization of (1). Hence, to study stability (and, in turn, convergence) properties it is useful to analyze the spectrum of not only the map I − ΓDg(x) but also Dg(x) itself.
For instance, when γ = γ1 = γ2, the spectral mapping theorem tells us that ρ(I −γDg(x)) = maxλ∈σp(Dg(x)) |1−γλ| so that understanding the spectrum of Dg(x) is imperative for understanding convergence of the discrete time update. On the other hand, when γ1 = γ2, we write the local linearization as I −γ1ΛDg(x) where Λ = blockdiag(Id1 , τ Id2 )

2A mypoic player effectively believes it cannot inﬂuence its opponent’s
future behavior, and reacts only to local information about its cost. 3The Hartman-Grobman theorem [20] states that around any hyperbolic
ﬁxed point of a nonlinear system, there is a neighborhood on which the nonlinear system is stable if the spectrum of Jacobian lies in C◦−.

and τ = γ2/γ1 is the learning rate ratio. Again, via the spectral mapping theorem, when I − γ1ΛDg(x) is a contraction for different choices of learning rate γ1 is determined by the spectrum of ΛDg(x). Hence, given a ﬁxed point x (i.e., g(x) = 0), we study the stability properties of the limiting continuous time dynamical system—i.e., x˙ = −g(x) when γ1 = γ2 and x˙ = −Λg(x) otherwise. From here forward, we will simply refer to the system x˙ = −Λg(x) and point out when Λ = Id1+d2 if not clear from context.
b) Partitioning the Game Jacobian: Let x = (x1, x2) be a joint action proﬁle such that g(x) = 0. Towards better understanding the spectral properties of Dg(x) (respectively, ΛDg(x)), we partition Dg(x) into blocks:

J (x) = −D12f1(x) −D12f1(x) = J11 J12 . (3)

−D21f2(x) −D22f2(x)

J21 J22

A differential Nash equilibrium (the second order conditions
of which are sufﬁcient for a local Nash equilibrium) is such that J11 < 0 and J22 < 0. On the other hand, as noted above, J is Hurwitz or stable if its point spectrum σp(J) ⊂ C◦−. Moreover, since the diagonal blocks are symmetric, J is similar to the matrix in Fig 2. For the remainder of the paper, we will study the Dg at a given ﬁxed point x as
deﬁned in (3).

J(x, y) ∼

Fig. 2. Similarity: the game Jacobian in (3) is similar to a matrix with diagonal blockdiagonals.

c) Classes of Games: Different classes of games can be characterized via J. For instance, a zero-sum game, where f1 ≡ −f2, is such that J12 = −J21. On the other hand, a game G = (f1, f2) is a potential game if and only if D12f1 ≡ D21f2 [15, Thm. 4.5], which implies that J12 = J21.

C. Spectrum of Block Matrices
One useful tool for characterizing the spectrum of a block operator matrix is the numerical range and quadratic numerical range, both of which contain the operator’s spectrum [23] and therefore all of its eigenvalues. The numerical range of J is deﬁned by
W (J ) = { J z, z : z ∈ Cd1+d2 , z 2 = 1},

and is convex. Given a block operator J, let

Jv,w = J11v, v J12w, v

(4)

J21v, w J22w, w

where v ∈ Cd1 and w ∈ Cd2 . The quadratic numerical range of J, deﬁned by

W 2(J ) =

σp (Jv,w ),

(5)

v ∈S1 ,w∈S2

is the union of the spectra of (4) where σp(·) denotes the (point) spectrum of its argument and Si = {z ∈ Cdi :
z 2 = 1}. It is, in general, a non-convex subset of C.

W 2(J )

σp(J ) σp(J11) σp(J22)
Re(λ)

Fig. 3. Spectrum of a stable equilibrium that is not Nash. The spectrum of J, J11, and J22 in Example 1 are contained in the numerical range (convex dashed region) and quadratic numerical range (non-convex region) of J. The eigenvalues of J are in the left plane, hence the ﬁxed point is stable under gradient play (1). However, the ﬁrst player’s J11 is indeﬁnite, hence the ﬁxed point is not a Nash equilibrium.

The quadratic numerical range (5) is equivalent to the set of solutions of the characteristic polynomial
λ2 − λ( J11v, v + J22w, w ) + J11v, v J22w, w (6)
− J12v, w J21w, v = 0
for v ∈ S1 and w ∈ S2. We use the notation Jx, y = x∗Jy to denote the inner product. Note that W 2(J) is a subset of W (J) and, as previously noted, contains σp(J). Albeit non-convex, W 2(J) provides a tighter characterization of the spectrum4.
Example 1: Consider the game Jacobian of the zero-sum game (f, −f ) deﬁned by cost f : R2 × R2 → R,
f (x, y) = − 21 x21 + 52 x22 + 7y1x1 − 3y2x2 − 2y12 − 6y22.
The numerical range, quadratic numerical range, spectrum and diagonal entries of J, deﬁned using the origin as the ﬁxed point, are plotted in Fig. 3. In this example, the origin is not a differential Nash equilibrium since D12f1(0, 0) is indeﬁnite, yet it is an exponentially stable equilibrium of x˙ = −g(x) since all the eigenvalues of J are all negative.
Observing that the quadratic numerical range for a block 2 × 2 matrix J derived from a game on a ﬁnite dimensional Euclidean space reduces to characterizing the spectrum of 2 × 2 matrices, we ﬁrst characterize stability properties of scalar 2-player continuous games.

III. STABILITY OF 2-PLAYER SCALAR GAMES
We characterize the stability of differential Nash equilibria in 2-player scalar continuous games. Consider a game (f1, f2) with action spaces X1, X2 ⊆ R. Let x be a ﬁxed point of (2) such that g(x) = 0. We decompose its game Jacobian (3) into components that reﬂect the dynamic interaction between the players.

A. Jacobian Decomposition: 2 × 2 case Consider the decomposition of a R2×2 game Jacobian

a b m −z h p

J(x) = c d = z m + p −h

(7)

4There are numerous computational approaches for estimating the numerical ranges W (·) and W 2(·) (see, e.g., [10, Sec. 6]).

where m = 12 (a + d), h = 21 (a − d), p = 12 (b + c), z = 21 (c−b). Let tr(J) be its trace, det(J) be its determinant, and disc(J) be the discriminant of its characteristic polynomial.5
Several directly veriﬁable quantities are stated. Statement 1: Given a matrix J ∈ R2×2 and its spectrum
σp(J) = {λ1, λ2}, the above decomposition gives rise to the following conditions:

tr(J) = λ1 + λ2 = a + d = 2m,

det J = λ1λ2 = ad − bc = (m2 + z2) − (h2 + p2),

disc J = (λ1 + λ2)2 − 4λ1λ2 = 4(h2 + p2 − z2),

λ1,2

=

1 2

tr(J) ∓

disc(J) = m ∓

h2 + p2 − z2.

The change of coordinates from (a, b, c, d) to (m, h, p, z)

in Statement 1 provides important insights into linear vector

ﬁelds and, in particular, to games. The stability of vector ﬁeld
x˙ = Jx is given by the trace and determinant conditions. Proposition 1: The matrix J ∈ R2×2 is stable if and only
if m2 + z2 > h2 + p2 and m < 0.
Proof: Statement 1 and direct computation show that
these conditions are equivalent to λ1 + λ2 < 0 and λ1λ2 > 0, well-known conditions for stability of 2 × 2 systems

(illustrated in Fig. 5b).

B. Discussion of Decomposition
The purpose of the decomposition into the alternative coordinates is to geometrically—and thus more directly— assess the conditions for stability of a differential Nash equilibrium.
a) Relationship to complex plane: Fig. 4 plots the coordinates of m, z, h, p relative to each other to illustrate the decomposition in Statement 1. If h = 0, p = 0, then the eigenvalues of J are λ1,2 = m ∓ zi. Fig. 4a corresponds to a plot of eigenvalues in the complex plane. Stability is given by the familiar open-left half plane condition: σp(J) ⊂ C◦−. If h = 0 or p = 0 a circular region in the center of the plane expands the values of m, z for which the eigenvalues of the matrix are purely real. Fig. 4b shows that the eigenvalues are purely real if and only if z2 ≤ h2 + p2.
b) Effect of rotation in game vector ﬁelds: Note the similarity between (7) and the well-known symmetric/skewsymmetric (Helmholtz) decomposition

a b m+h p

0 −z

J(x) = c d = p m − h + z 0 . (8)

Assuming that m < 0, from Proposition 1 we can see that increasing the rotational component of the Jacobian helps stability. Increasing the relative magnitude of p, the non-rotational interaction term hurts stability. If there is no rotational component, ie. J is symmetric, p’s negative impact on stability can be seen directly from the Schur complement6. In this case J is stable iff J < 0 and thus stability requires that both the diagonals and the Schur complement

5The characteristic polynomial of J is λ → det(J − λI) and its discriminant is tr(J)2 − 4 det(J) for J ∈ R2×2.
6The Schur complements of the matrix in (3) are J11 − J12J2−21J21 (where J22 is invertible) and J22 − J21J1−11J12 (where J11 is invertible).

m + zi

(m, z) Imaginary

m − zi Stable

Real (h, p)
Imaginary Stable

(a) The complex plane. (b) A representation of the m, z, h, p coordinates.

Fig. 4. Visualization of Statement 1: If h and p are zero, then the eigenvalues of J are λ1,2 = m ∓ zi. If h and/or p are non-zero, then a circle centered around the origin with radius h2 + p2 is excluded from left-half stability region.

tr(J

|λ2|

)=

0

det(J )

|λ1|

> 0,

tr(J) < 0

disc(J ) = 0

det(J ) tr(J )

λ1, λ2 ∈ R

(a)

Level sets of (b) Real or imaginary

det(J) = λ1λ2.

eigenvalues.

Fig. 5. Visualization of Proposition 1: y˙ = J(x)y is stable ⇐⇒ det(J) > 0 and tr(J) < 0.

are negative: a < 0, d < 0, and a − p2d−1 < 0. If d < 0, increasing p can only increase the Schur complement.
C. Types of Games
The decomposition also provides a natural classiﬁcation of 2-player scalar games into four types based on speciﬁc coordinates being zero, as illustrated in Fig. 7.
a) Potential games (z = 0): The point (m, z) lives on the horizontal axis in Fig. 7a, thus stable ﬁxed points are a subset of Nash equilibria. Since z = 0, Proposition 1 indicates that increasing p, the interaction term between the players, and increasing h, the difference in curvature between the two players both only hurt stability.
b) Zero-sum games (p = 0): The point (h, p) lives on the horizontal axis in Fig. 7b, thus all Nash equilibria are stable, but not all stable ﬁxed points are Nash. The magnitude of the interaction term z helps stability and may make a ﬁxed point stable even if it is not Nash.
c) Hamiltonian games (m = 0): The point (m, z) lives on the vertical axis in Fig. 7c, thus no strict Nash equilibria can exist. At best these games are marginally stable if |z| is large enough relative to the magnitude of (h, p).
d) Matching-curvature games, (h = 0): The point (h, p) lives on the vertical axis in Fig. 7d, so any stable point is also a Nash. Any ﬁxed point with a, d having the same sign can be rescaled to have matching curvature γ1a = γ2d by a choice of non-uniform learning rates γ1, γ2 > 0.

Nash b,c (d, c)

(m, z)

z,p Stable

z

Nash

mh p a,d

m,h

(–|h|, p)

(a, b)

(a) Geometry of decomposi- (b) Change of coordinates re-

tion in (7).

veals regions of stability.

Fig. 6. Decomposition of a general scalar game. The rows vectors of J are
plotted in (a) and the same matrix with a change of coordinates is plotted in (b). Nash regions (m < −|h|) and stability regions (m < 0, m2 + z2 > h2 + p2) are visible. Their set differences characterize the conditions for a
stable non-Nash and unstable Nash equilibria.

z=0

p=0

m=0

h=0

(a) Potential: (b) Zero-sum: Stable ⊂ Nash. Stable ⊃ Nash

(c) Hamiltonian: (d) Matching: marginally stable Stable ⊂ Nash. at best.

Fig. 7. Stability and Nash for different classes of games. (a) Potential games: symmetric interaction term only hurts stability. (b) Zero-sum games: rotation can compensate for unhappy player. (c) Hamiltonian games: players have zero total curvature, a + d = 0. (d) Matching curvature, a = d: there are no stable non-Nash equilibria.

(m, z)

(m, z)

(h, p)

(h, p)

(a) γ1 > γ2

(b) γ1 < γ2

Fig. 8. Time-scale separation affects stability. The learning rate ratio τ =

γ2/γ1

>

0

affects

the

stability

of

the

game

dynamics.

The

factor

β

=

τ −1 τ +1

expands or shrinks the region for stability. The condition m < 0 becomes

m < βh. Note that −1 ≤ β ≤ 1 for τ ≥ 0.

IV. CERTIFICATES FOR STABILITY OF GAME DYNAMICS
A. Stability: Uniform Learning Rates
For a game G = (f1, f2), let the set of differential Nash equilibria be denoted DNE(G) and let the stable points of x˙ = −g(x) be S(G). Let DNE(G) and S(G) be their respective complements. The intersections of these sets characterize the stability/instability of Nash/non-Nash equilibria.
Theorem 1 (Certiﬁcates for 2-Player Scalar Games): Consider a game G = (f1, f2) on X1 × X2 ⊆ R2. Let x be a ﬁxed point of (2) and let m, h, p, z be deﬁned by (7). The following equivalences hold:
(i) x ∈ DNE(G) ∩ S(G) ⇐⇒ {m < −|h|} ∧ {m2 + z2 > h2 + p2}.
(ii) x ∈ DNE(G) ∩ S(G) ⇐⇒ {m < −|h|} ∧ {m2 + z2 ≤ h2 + p2}.
(iii) x ∈ DNE(G) ∩ S(G) ⇐⇒ {0 > m ≥ −|h|} ∧ {m2 + z2 > h2 + p2}.

(iv) x ∈ DNE(G) ∩ S(G) ⇐⇒ {{0 > m ≥ −|h|} ∧ {m2 + z2 ≤ h2 + p2}} ∨ {m ≥ 0}.
The contributions to the stability of a non-Nash equilibrium or the instability of a Nash equilibrium are stated in (ii) and (iii). We illustrate the geometry of these two cases with the shaded regions in Fig. 6b.

B. Stability: Non-Uniform Learning Rates
Consider players updating their actions according to gradient play as deﬁned in (1) with individual learning rates γ1, γ2 > 0, not necessarily equal. We study how the players’ ratio τ = γ2/γ1 affects the stability of ﬁxed point x under the learning dynamics by analyzing the game Jacobian

ab

J(x) = τ c τ d .

(9)

Learning rates do not affect whether a ﬁxed point is a Nash equilibrium. They do, however, affect whether it is stable.
Corollary 1 (Stability in General-Sum Scalar Games): Consider a game G = (f1, f2) on X1 × X2 ⊆ R2 and a ﬁxed point x. Suppose players perform gradient play (1) with learning rate ratio τ = γ2/γ1. Then, the following are true.
(i) If a Nash equilibrium is stable for some τ , then it is stable for all τ .
(ii) If a non-Nash equilibrium is stable, then there exists some τ that makes it unstable.
(iii) If a ﬁxed point is non-Nash, the determinant of its game Jacobian is positive and m < |h|, then there exists some τ that makes it stable.
Proof: To prove (i), we observe that if m < −|h|, then m ≤ βh for all β such that |β| < 1. Choose −1 ≤ β = ττ−+11 ≤ 1 for τ ≥ 0. To prove (ii), choose τ < ad . Without loss of generality, assume a < 0 and d > 0. Then, it directly follows that a + τ d < 0. To prove (iii), note that a matrix J is stable if and only if the determinant of J is positive and m < 0. Hence, without loss of generality, let d < 0. Then there is a learning rate τ such that τ |d| > |a| so that m < 0.

Stable Nash equilibria in scalar games are robust to variations in learning rates and non-Nash equilibria are not. For continuous games with vector action spaces, Corollary 1(i) no longer holds, demonstrating that Nash equilibria are not robust, in general, to variations in learning rates.

V. AN ILLUSTRATIVE EXAMPLE

We demonstrate our main results below and in Fig. 9.
Example 2 (Nonlinear torus game): Consider a game G = (f1, f2) deﬁned on S1 × S1 with costs

f1(x, y)

=

2 a

cos

a2 x

+ a2 cos

a2 x + by

,

f2(x, y)

=

2 d

cos

d2 y

+ d2 cos

d2 y + cx

.

There is a ﬁxed point of the learning dynamics at the origin.

Its linearized game Jacobian is J(0) =

ab cd

. First, to show

Corollary 1(i), we start with an unstable, Nash ﬁxed point

of a potential game (a = −0.4, b = 1, c = 1, d = −1).

We decrease p = 21 (b + c) until it becomes stable (b =

0.2, c = 0.2). Then, we decrease τ from 1 to 0.1 while
maintaining stability. Second, to show Corollary 1(ii), we
start with an unstable, non-Nash ﬁxed point of a zero-sum game (a = 0.4, b = −0.2, c = 0.2, d = −1). We increase z = 12 (c − b) until it becomes stable (b = −1, c = 1). Then, we decrease τ from 1 to 0.01 making it unstable again. Third,
to show Corollary 1(iii), we start with an unstable, non-Nash ﬁxed point of a Hamiltonian game (a = 0.5, b = 0.1, c = 0.5, d = −0.5). We increase the interaction term z = 21 (c−b) until it becomes marginally stable (b = −0.5, c = 1.1). Then, we increase τ slightly from 1 to 2, making the ﬁxed point
stable.
VI. CONCLUSION
We characterize the local stability and Nash optimality
of ﬁxed points of 2-player general-sum gradient learning
dynamics. Our results give valuable insights into the in-
teraction of algorithms in settings most accurately modeled
as games, for example, when agents lack trust or reliable
communication. In the sequel, we characterize continuous
games deﬁned on vector action spaces.
REFERENCES
[1] David Balduzzi, Wojiech M Czarnecki, Thomas W Anthony, Ian M Gemp, Edward Hughes, Joel Z Leibo, Georgios Piliouras, and Thore Graepel. Smooth markets: A basic mechanism for organizing gradientbased learners. Proc. Inter. Conf. Learning Representations, 2020.
[2] Hugo Berard, Gauthier Gidel, Amjad Almahairi, Pascal Vincent, and Simon Lacoste-Julien. A closer look at the optimization landscapes of generative adversarial networks. Proc. Inter. Conf. Learning Representations, 2020.
[3] Victor Boone and Georgios Piliouras. From Darwin to Poincare´ and von Neumann: Recurrence and Cycles in Evolutionary and Algorithmic Game Theory. In Inter. Conf. Web and Internet Economics, pages 85–99, 2019.
[4] Jingjing Bu, Lillian J Ratliff, and Mehran Mesbahi. Global convergence of policy gradient for sequential zero-sum linear quadratic dynamic games. arXiv preprint arXiv:1911.04672, 2019.
[5] Benjamin Chasnov, Lillian Ratliff, Eric Mazumdar, and Samuel Burden. Convergence Analysis of Gradient-Based Learning in Continuous Games. In Proc. Uncertainty in Artiﬁcial Intelligence, 2019.
[6] Tanner Fiez, Benjamin Chasnov, and Lillian J Ratliff. Implicit Learning Dynamics in Stackelberg Games: Equilibria Characterization, Convergence Analysis, and Empirical Study. Proc. Inter. Conf. Machine Learning, 2020.
[7] Drew Fudenberg, Fudenberg Drew, David K Levine, and David K Levine. The theory of learning in games. MIT press, 1998.
[8] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative Adversarial Nets. In Advances in Neural Information Processing Systems, 2014.
[9] Hassan K Khalil. Nonlinear systems theory. Prentice Hall, 2002. [10] Heinz Langer, A Markus, V Matsaev, and C Tretter. A new concept
for block operator matrices: the quadratic numerical range. Linear algebra and its applications, 330(1-3):89–112, 2001. [11] Eric Mazumdar, Lillian J Ratliff, and Shankar Sastry. On gradientbased learning in continuous games. SIAM Journal on Mathematics of Data Science, 2(1):103–131, 2020. [12] Panayotis Mertikopoulos, Christos Papadimitriou, and Georgios Piliouras. Cycles in adversarial regularized learning. In Proc. 29th Ann. ACM-SIAM Symp. Discrete Algorithms, pages 2703–2717. SIAM, 2018. [13] Panayotis Mertikopoulos and Zhengyuan Zhou. Learning in games with continuous action sets and unknown payoff functions. Mathematical Programming, 173(1-2):465–507, 2019. [14] Luke Metz, Ben Poole, David Pfau, and Jascha Sohl-Dickstein. Unrolled generative adversarial networks. Proc. Inter. Conf. Learning Representations, 2017.

(a) Potential game: a Nash goes from unstable to stable, and remains stable with time-scale separation.
(b) Zero-sum game: a non-Nash goes from unstable to stable, and destabilizes with decreasing τ .
(c) Hamiltonian game: a non-Nash goes from unstable to marginally stable, and stabilizes with increasing τ . Fig. 9. Demonstration of Corollary 1: vector ﬁeld plots of the three scenarios from Example 2.
[15] Dov Monderer and Lloyd S Shapley. Potential games. Games and economic behavior, 14(1):124–143, 1996.
[16] John Nash. Non-cooperative games. Ann. Math., pages 286–295, 1951.
[17] L. J. Ratliff, S. A. Burden, and S. S. Sastry. Genericity and structural stability of non-degenerate differential Nash equilibria. In Proc. Amer. Control Conf., pages 3990–3995, 2014.
[18] Lillian J Ratliff, Samuel A Burden, and S Shankar Sastry. Characterization and computation of local Nash equilibria in continuous games. In Proc. 51st Ann. Allerton Conf. Communication, Control, and Computing, pages 917–924. IEEE, 2013.
[19] Lillian J Ratliff, Samuel A Burden, and S Shankar Sastry. On the Characterization of Local Nash Equilibria in Continuous Games. IEEE Trans Automa. Control, 61(8):2301–2307, 2016.
[20] S. Shankar Sastry. Nonlinear systems: analysis, stability, and control. Springer-Verlag New York, 1999.
[21] Yujie Tang and Na Li. Distributed zero-order algorithms for nonconvex multi-agent optimization. In Proc. 57th Allerton Conf. Communication, Control, and Computing, pages 781–786, 2019.
[22] T. Tatarenko and M. Kamgarpour. Learning Nash Equilibria in Monotone Games. In Proc. IEEE Conf. Decision and Control, pages 3104–3109, 2019.
[23] Christiane Tretter. Spectral theory of block operator matrices and applications. World Scientiﬁc, 2008.

