arXiv:2201.11308v1 [cs.CR] 27 Jan 2022

Calibration with Privacy in Peer Review
Wenxin Ding Gautam Kamath ○r Weina Wang ○r Nihar B. Shah∗
Abstract
Reviewers in peer review are often miscalibrated: they may be strict, lenient, extreme, moderate, etc. A number of algorithms have previously been proposed to calibrate reviews. Such attempts of calibration can however leak sensitive information about which reviewer reviewed which paper. In this paper, we identify this problem of calibration with privacy, and provide a foundational building block to address it. Speciﬁcally, we present a theoretical study of this problem under a simpliﬁed-yet-challenging model involving two reviewers, two papers, and an MAP-computing adversary. Our main results establish the Pareto frontier of the tradeoﬀ between privacy (preventing the adversary from inferring reviewer identity) and utility (accepting better papers), and design explicit computationally-eﬃcient algorithms that we prove are Pareto optimal.
1 Introduction
It is well known that scores provided by people are frequently miscalibrated. In the application of peer review, reviewers may be strict, lenient, extreme, moderate, etc. This leads to unfairness in peer review, for instance, disadvantaging papers that happen to go to strict reviewers [1]: “the existence of disparate categories of reviewers creates the potential for unfair treatment of authors. Those whose papers are sent by chance to assassins/demoters are at an unfair disadvantage, while zealots/pushovers give authors an unfair advantage.”
A number of algorithms [2–8] are proposed in the literature to address the problem of miscalibration. There are two key challenges, however, towards any attempts of calibration using such algorithms:
Challenge #1: The calibration algorithms may leak information about which reviewer reviewed which paper. Here is an example showing how a na¨ıve attempt at calibration can compromise privacy. Consider an adversary trying to guess the reviewer of a paper between two possibilities – reviewer X or reviewer Y. The review for the paper is lukewarm, and for simplicity suppose this is the only review. We consider the “open review” model where all submitted papers, reviews, and ﬁnal decisions are public (but reviewer identities are not). Also suppose it is known that reviewer X is strict but reviewer Y is not. Then the conference will not accept the paper unless the conference performs a calibration using this information and the reviewer is X. The acceptance of the paper will provide the adversary with the necessary information to infer the reviewer as X.
Challenge #2: The bottleneck of a small number of samples (reviews) per reviewer. Many conferences have each reviewer reviewing only a handful papers (typically 1 to 6 papers), as well as have each paper reviewed by a handful of reviewers. As a consequence, it is often hard to decipher the miscalibration of any reviewer, particularly since human miscalibration can be quite complex [9]. Indeed, program chairs of conferences have tried to use some algorithms to calibrate reviewers’ scores, but have found the outcomes to be unsatisfactory. For instance, John Langford, the program chair of the ICML 2012 conference says that “We experimented with reviewer normalization and generally found it signiﬁcantly harmful” [10].
Our focus on this paper is challenge #1 of privacy. Towards challenge # 2, we assume that the conference has exogenous information about the miscalibration of reviewers, such as reviewers’ calibration information
∗Wenxin Ding is at the University of Chicago (wenxind@uchicago.edu), Gautam Kamath is at the University of Waterloo (g@csail.mit.edu), and Weina Wang and Nihar B. Shah are at Carnegie Mellon University ({weinaw, nihars}@cs.cmu.edu).
1

from other conferences where they have reviewed. (Appendix A presents simulations illustrating beneﬁts of calibration with exogeneous information.) Tackling the problem of privacy in calibration that we identify is quite challenging in full generality. In this paper, our goal is to initiate research towards this grander goal by providing a foundational building block for it. We consider a simpliﬁed–yet highly challenging–model with two reviewers, two papers, and (exogenously) known miscalibration functions where an adversary attempts to guess the reviewer assignment based on maximum a posteriori (MAP) computation. We provide a comprehensive analysis under this model. Our contributions are summarized as follows:
• We identify the problem of privacy in calibration, and we initiate a theoretical study with the formulation of a problem that incorporates various key challenges of the more general setting.
• We provide explicit computationally-eﬃcient algorithms for calibration with privacy that optimally trades oﬀ the error of the conference (in terms of accepting the better paper) and the error of the adversary (in terms of guessing the reviewer).
• We establish the structure of the Pareto optimal curve between the two aforementioned desiderata. We observe that interestingly, there is a linear tradeoﬀ between the two errors up to a certain point, after which the error of the adversary does not decrease even if the conference adds more randomness in its protocols.
2 Related Work
Peer review is extensively used for evaluating scientiﬁc papers and grant proposals. However, conference peer review also incurs various challenges such as miscalibration [2–8, 11, 12], biases [13–15], subjectivity [16–18], dishonesty [19–24], and others. See [25] for a survey.
The problem of miscalibration is well recognized in the literature. A common approach to design calibration algorithms is to assume a certain model of miscalibration, and under the assumed model, estimate the calibrated scores (or the model parameters) from the scores given by reviewers. This line of literature [2–8] assumes aﬃne models for miscalibration: they assume that each paper has some “true” real-valued quality and that the score provided by any reviewer is some aﬃne transform (plus noise) of this true quality. In our formulation (detailed subsequently in Section 3) we also assume papers have true qualities, and a part of our work also assumes aﬃne miscalibrations.
A second line of literature [26–28] recognizes the problem of miscalibration, and takes the approach of using only the ranking of papers induced by the scores given by any individual reviewer, or alternatively, asking each reviewer to only provide a ranking of the papers they are reviewing. Using rankings alone thus gets rid of any miscalibrations, but on the downside, can lose some information contained in scores. Moreover, a recent work [11] showed that under certain settings, scores can yield more information than rankings even if the miscalibration is adversarial.
Notably, these works consider addressing miscalibration using data from within the conference at hand, and moreover do not consider the issue of compromise of privacy.
We assume an “open review” model where all submitted papers and all reviews are available publicly, but where information of who reviews which paper is not. Such an open review model is gaining increasing popularity: see, for instance, openreview.net and scipost.org. This model is followed in the ICLR conference as well as other venues. In a survey [29] at the ICLR 2013 conference, researchers felt that this open review model leads to beneﬁts of more accountability of authors (in terms of not submitting below-par papers) as well as reviewers (in terms of giving high-quality reviews). The publicly available data has resulted in another beneﬁt: it has yielded a rich dataset for research on peer review [14, 21, 30–33]. A downside of the open review approach is that if a rejected paper is resubmitted elsewhere, the (publicly available) knowledge of previous rejection may bias the reviewer [34].
Our work considers explicitly randomized assignments and decisions. In practice, the assignments and decision protocols are typically deterministic (although some variations naturally arise due to human involvement in various parts of the peer-review process). The assignment of reviewers to papers is done by
2

Notation i ∈ {1, 2} j ∈ {1, 2} θi∗ ∈ R θi ∈ R A1 and A2 si ∈ R βj : R → R j ∈R fj : R → R
EC ∈ [0, 1] EA ∈ [0, 1]

Meaning Index for paper Index for reviewer True quality of paper i Estimated quality of paper i The two possible assignments Score received by paper i; S = [s1, s2] Calibration function of reviewer j Noise of reviewer j Marginal probability density function of score given by reviewer j, that is, distribution of βj(θ∗) where θ∗ ∼ N (0, 1) Error of the conference Error of the adversary
Table 1: Summary of the main notation used in the paper.

solving a certain optimization problem [35–40] involving similarities computed between each reviewer-paper pair [37, 41–43]. Decisions are arrived at after discussions between the reviewers. That said, there are notable instances where randomization has been explicitly used in practice in peer review: randomization can help mitigate dishonest behavior [23] and can help make more fair decisions for borderline papers or grants [44, 45]. A recent survey of researchers ﬁnds support for randomized decisions [46]. Finally, the algorithms in the theoretical work [11] comparing scores and rankings in the context of miscalibration also employ randomization.
Issues of privacy in peer review also arise when releasing data to researchers. The program chairs of the WSDM 2017 conference performed a remarkable controlled experiment to test for biases in peer review, and in their paper [13] they point out privacy-related concerns in releasing data: “We would prefer to make available the raw data used in our study, but after some eﬀort we have not been able to devise an anonymization scheme that will simultaneously protect the identities of the parties involved and allow accurate aggregate statistical analysis. We are familiar with the literature around privacy preserving dissemination of data for statistical analysis and feel that releasing our data is not possible using current state-of-the-art techniques.” We are aware of two past works which deal with privacy in peer review [23, 47]. In particular, both papers consider privacy-preserving release of peer-review data. The paper [47] provides an algorithm to optimize utility when releasing histograms of certain functions of the review scores. The paper [23] uses randomized assignments to guarantee privacy of the reviewer-paper assignment when data pertaining to similarities between reviewerpaper pairs is released.
Diﬀerential privacy [48] is a popular rigorous notion of data privacy. Roughly speaking, an algorithm is diﬀerentially private if its distribution over outputs is similar when provided with “neighboring” inputs. In our problem with two papers and two reviewers, one can consider neighboring inputs to be those that diﬀer only in the assignment. We provide a tight characterization of the adversary’s ability to determine which of the two possible assignments is the true one. Thus, it may be a useful building block towards more complex private calibration schemes. We note that our calibration algorithms are related to a form of randomized response [49], the canonical algorithm for local diﬀerential privacy [49–51]. Though diﬀerential privacy is not the focus of our work, we further elaborate on this connection in Appendix B.
3 Problem Formulation and Preliminaries
In this section, we present the formal problem speciﬁcation. We will introduce some notation in this section, and this notation is also summarized in Table 1.

3

Papers and reviewers. We consider a setting with two reviewers and two papers. Each paper i ∈ {1, 2} has some latent true quality θi∗ ∈ R. We assume that the qualities θ1∗ and θ2∗ are drawn i.i.d. according to the standard normal distribution (and hence we have θ1∗ = θ2∗ with probability 1).
Reviewer assignment. Each reviewer reviews one paper and each paper is reviewed by one reviewer. There are thus two possible assignments: we let A1 denote the assignment of reviewer 1 to paper 1 and reviewer 2 to paper 2, and A2 denote the assignment of reviewer 1 to paper 2 and reviewer 2 to paper 1. We assume that the assignment is chosen uniformly at random from these two possibilities. We assume that the true assignment is known (only) to the conference. We let A denote a random variable representing the assignment. Finally, in our exposition we will refer to the realization of A as the “true” assignment (and the unrealized assignment as the “wrong” assignment).
Miscalibration and reviewer scores. For each paper i ∈ {1, 2}, we let si denote the score received by by paper i. Note that this notation is not indexed by the reviewer for brevity since each paper receives exactly one review. For convenience, we deﬁne the vector S = [s1, s2]. Following the popular “open review” model (OpenReview.net, scipost.org), we assume that the scores s1 and s2 are known publicly.1
Following [11], we assume that each reviewer j ∈ {1, 2} has a function βj : R → R which captures their miscalibration. If reviewer j ∈ {1, 2} reviews paper i ∈ {1, 2}, we assume that the reviewer provides a score si ∈ R given as:
si = βj (θi∗) + j ,
where j is a zero-mean Gaussian random variable independent of everything else. We assume that 1 and 2 are identically distributed. The value of the noise is unknown but its distribution is publicly known. We call βj the reviewer’s miscalibration function for reviewer j. We assume that the functions β1 and β2 are increasing and invertible. In one part of our work, we further make an assumption that the miscalibration functions are aﬃne, and we detail this subsequently in the associated section. As discussed previously, our aim is to use exogenous information about the reviewer miscalibrations in order to mitigate the miscalibration, and to this end, we assume that the functions β1 and β2 are known publicly.
For any reviewer j, we let fj denote the marginal probability density function of the ﬁnal score given by that reviewer, that is, fj is the distribution of βj(θ∗) where θ∗ ∼ N (0, 1).
Conference’s error. The goal of the conference is to accept the paper with the higher true quality argmaxi∈{1,2} θi∗. Note that even if the noise terms were zero, simply choosing the paper with higher score (i.e., argmaxi∈{1,2} si) may be erroneous due to the miscalibration of the reviewers. The conference can however calibrate the scores, that is, use the information about the miscalibration functions of the reviewers and the knowledge of the assignment to potentially make a better decision. In our analysis, we will measure the conference’s performance towards its goal in terms of two types of errors:
(a) Per-instance error: For any given S = [s1, s2], the per-instance error of the conference is deﬁned as EC ([s1, s2]) := Pr(conference accepts lower-quality paper | S = [s1, s2]).
(b) Average-case error: The average-case error of the conference is the per-instance error averaged over the distribution of the scores: s1 s2 EC ([s1, s2])fS([s1, s2]) where fS is the p.d.f. of the joint distribution of S = [s1, s2].
In conjunction with the goal of minimizing the error, the conference must also ensure that information about which reviewer reviewed which paper is not leaked.
1Even if the conference operates in a non-open-review setting where the scores are not public, our guarantees on privacy and conference’s error continue to hold. However, our algorithm may not be optimal and the suboptimality may depend on assumptions about the adversary’s knowledge of the scores.
4

Privacy. We assume that the protocols followed by the conference are public. A challenge for the conference is that performing calibration may leak information about the assignment. As a simple example, suppose that reviewer 1 is known to be strict and reviewer 2 is known to be lenient. Suppose that paper 1 is reviewed by reviewer 1 and paper 2 by reviewer 2. Suppose paper 2 receives a higher score than paper 1, but the conference decides to accept paper 1 after performing calibration. This decision leaks information that paper 2 was reviewed by the lenient reviewer, that is, by reviewer 2. Note that this issue of compromise of privacy arises whether or not the reviewer miscalibration functions are known to the conference.
To formalize the notion of privacy, we assume an adversary in the process. The goal of the adversary is to guess the assignment. In addition to knowing the scores received by both papers, the miscalibration functions of both reviewers, the noise distributions, and the ﬁnal decision of the conference, the adversary also knows the calibration strategy used by the conference to make the decision.
The adversary does not know the assignment, and aims to guess the assignment. We consider an adversary with no additional information, in which case, we assume it predicts the assignment via maximum a posteriori (MAP) estimation. Formally, if the conference decides to accept paper P ∈ {1, 2}, then the adversary computes:
argmax Pr(A = A | S = [s1, s2], paper P accepted by the conference),
A∈{A1 ,A2 }
where A is the random variable representing the assignment. We make no assumptions on the computational power of the adversary and aim to guarantee privacy assuming they can compute the aforementioned argmax.
As in the case of the conference’s error, we also measure the error of the adversary in two ways:
(a) Per-instance error: For any given S = [s1, s2], the per-instance error of the adversary is deﬁned as EA([s1, s2]) := Pr(adversary guesses wrong assignment | S = [s1, s2]).
(b) Average-case error: The average-case error of the adversary is the per-instance error averaged over the distribution of the scores: s1 s2 EA([s1, s2])fS([s1, s2]) where fS is the p.d.f. of the joint distribution of S = [s1, s2].
Goal. Our goal is to design methods to decide which paper to accept in a manner that simultaneously minimizes the conference’s error and maximizes the adversary’s error. The methods will inherently rely on calibrating reviewer decisions to accept the better paper, and hence we sometimes refer to them as the calibration strategy.
The two aforementioned objectives may conﬂict with one another: a decision that reduces the chances of accepting the lower quality paper via calibration can also leak more information about the assignment. In this work, we thus establish the Pareto frontier of this tradeoﬀ. We deﬁne the Pareto frontier as the set of all points of the (conference’s error, adversary’s error) tradeoﬀ such that the adversary’s error cannot be increased without increasing the conference’s error. We call a calibration strategy Pareto optimal if for any given threshold on conference’s error, it maximizes the adversary’s error while ensuring that the conference’s error does not exceed the given threshold.
4 Main Results
In what follows, we present results for two settings: (1) a noiseless setting, where the noise in the reviewerprovided scores is zero; and (2) a noisy setting, where the noise in a reviewer score has a positive variance. We begin by a few preliminaries which we subsequently use to derive and present our main results.
4.1 Preliminaries
We now formalize the calibration strategies that a conference can follow in a general form, and then derive a speciﬁc form that can be used without loss of optimality. Our subsequent results will then use this form of the calibration strategies.
5

At a high level, the calibration strategies introduce a certain amount of randomness in the acceptance decisions. In the example in the ‘privacy’ paragraph earlier in this section, suppose the conference does the calibration, and then tosses a coin. With probability 0.9, it accepts the paper it thinks is better and otherwise it accepts the other paper. This randomness ensures that an adversary who observes that paper 1 is accepted cannot be certain that paper 1 was reviewed by reviewer 1, due to the possibility that paper 1 was reviewed by the lenient reviewer 2 but was still accepted due to the randomness. However, due to the randomness introduced, the conference incurs an error in terms of accepting the paper which it thought was actually better. There is thus a tradeoﬀ between the conference’s error and the adversary’s error, and our goal is to design calibration strategies that are optimal with respect to this tradeoﬀ.
Let us now formalize the notion of a calibration strategy. The conference observes the scores S = [s1, s2] and the assignment A. Given these values, a generic calibration strategy is speciﬁed by a function g : S ×A → [0, 1] — the conference accepts accept paper 1 with probability g(S, A) and accepts paper 2 otherwise. Note that the function g is publicly known but its realization is known only to the conference. For any function g used by the conference, the conference’s error is then given by
EC (S, A) = (1 − g(S, A1)) Pr(A = A1|θ1∗ > θ2∗, S) + (1 − g(S, A2)) Pr(A = A2|θ1∗ > θ2∗, S) Pr(θ1∗ > θ2∗|S)
+ g(S, A1) Pr(A = A1|θ1∗ < θ2∗, S) + g(S, A2) Pr(A = A2|θ1∗ < θ2∗, S) Pr(θ1∗ < θ2∗|S).
Having speciﬁed this general form of calibration strategy, we now discuss a speciﬁc variant. If one did not care about the privacy, then the conference’s error can be minimized via maximum a posteriori (MAP) estimation: given scores S and the assignment A, the conference accepts paper 1 if Pr(θ1∗ > θ2∗|S, A) > 0.5 and accepts paper 2 otherwise (breaking ties uniformly at random). Now under our scenario also involving privacy, consider the following class of calibration strategies. The strategy is governed by a function h : S ×A → [0, 1]. Given S = [s1, s2] and the assignment A:
• With probability h(S, A), the conference executes MAP estimation under scores S and the (true) assignment A,
• otherwise (with probability 1 − h(S, A)), the conference executes MAP estimation under scores S and the wrong assignment {A1, A2}\A.
As before, we assume that function h is known publicly but its realization or the random bits are not. A calibration strategy is Pareto optimal if any other strategy that incurs a lower conference error must
also induce a lower error of the adversary, and any other strategy that induces a higher error of the adversary must also incur a higher conference error. The Pareto frontier is the set of all (conference error, adversary error) pairs achieved by Pareto optimal strategies. The following proposition states that without loss of optimality, one can restrict attention to the class of strategies speciﬁed by functions h.
Proposition 4.1. For any values of error of the conference and error of the adversary (EC, EA) achieved by a calibration strategy g, there exists a function h such that under h, the error of the conference is no larger than EC and the error of the adversary is no smaller than EA.
The proof of this proposition is available in Appendix C.1. Hence, without loss of Pareto optimality, any generic calibration strategy g can be replaced with a strategy involving the calibration function h. Thus, in the sequel we restrict attention to calibration strategies using function h.
4.2 Noiseless Setting
We ﬁrst study the noiseless setting where the noise in the reviewer-provided scores is zero, that is, where 1 = 2 = 0. Observe that in this setting the conference can obtain the true qualities of the papers from the scores by inverting the reviewer functions. We ﬁrst explicitly characterize the Pareto frontier for per-instance errors of the conference and the adversary. Based on this characterization, we then design Pareto optimal strategies for conference calibration with respect to the per-instance error and the average-case error.
6

Error of adversary

min{𝑓! 𝑠! 𝑓" 𝑠" , 𝑓" 𝑠! 𝑓! 𝑠" } 𝑓! 𝑠! 𝑓" 𝑠" + 𝑓" 𝑠! 𝑓!(𝑠")
x

Legend: Pareto optimal curve in
x Part 1 of Theorem 4.1
Part 2 of Theorem 4.1

0.5
min{𝑓! 𝑠! 𝑓" 𝑠" , 𝑓" 𝑠! 𝑓! 𝑠" } 𝑓! 𝑠! 𝑓" 𝑠" + 𝑓" 𝑠! 𝑓!(𝑠")
Error of conference
Figure 1: Pareto frontier for per-instance errors in the noiseless setting.

4.2.1 Pareto Frontier for Per-Instance Errors

In the following theorem, we present the main result of this section establishing the Pareto frontier for per-instance errors in the noiseless setting.

Theorem 4.2. Consider the peer-review system in the noiseless setting. The Pareto frontier of (per-instance error of the conference, per-instance error of the adversary) with scores S = [s1, s2] is given as follows.

(1) If s1 ≥ max{β2(β1−1(s2)), β1(β2−1(s2))} or s1 ≤ min{β2(β1−1(s2)), β1(β2−1(s2))}, then the Pareto frontier consists of a single point (0, minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} ).

(2)

Otherwise,

if

min{

β

2

(β

− 1

1

(

s2

))

,

β1

(β

− 2

1

(

s2

))

}

<

s1

<

max{

β

2

(β

− 1

1

(

s2

))

,

β1

(

β

−1 2

(s2

))

},

then

the

Pareto

frontier of conference error and adversary error is a line segment of slope 1 starting from the origin

(0, 0) to

, . min{f1(s1)f2(s2),f2(s1)f1(s2)} min{f1(s1)f2(s2),f2(s1)f1(s2)}

f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

The proof of Theorem 4.2 is provided in Appendix C.2. The Pareto frontier established in Theorem 4.2

is illustrated in Figure 1.

We now unpack the result of Theorem 4.2, beginning with part (1). Recall that in this noiseless setting,

given scores S = [s1, s2] and knowing the reviewers’ miscalibration functions, the conference can estimate

the qualities of papers under each assignment. We use θi ∈ R to denote the estimated quality of paper i.

If the conference estimates the qualities assuming that A1 was the actual assignment, we get θ1 = β1−1(s1)

and θ2 = β2−1(s2). If the conference estimates the qualities assuming that A2 was the actual assignment,

we get θ1 = β2−1(s1) and θ2 = β1−1(s2).

If

s1

≥

max

{β

2

(β

− 1

1

(s2

))

,

β1

(β

− 2

1

(

s2

))

},

then

θ1

≥

θ2

under both

assignments

(and

hence

paper

1

should

be

accepted).

Similarly,

if

s1

≤

min

{β

2

(β

−1 1

(s2

)),

β1

(β

− 2

1

(s2

))}

,

then

θ1 ≤ θ2 under both assignments (and hence paper 2 should be accepted). Therefore, under the condition of

part (1) of the theorem, the same paper has higher estimated quality under both assignments, and hence that

paper will be accepted irrespective of the function h. Thus, under this condition, the Pareto optimal curve

comprises just a single point where the conference has zero error, and the adversary obtains no additional

information from the acceptance decision as compared to the scores S = [s1, s2]. The error of the adversary is minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} when it guesses the assignment using only the scores and not the decision.
Let us now discuss part (2) of Theorem 4.2. For scores S = [s1, s2] that do not satisfy the condition

in part (1), the conference would accept diﬀerent papers when performing MAP calibration under the two

possible assignments. In this case, the function h does inﬂuence the outcomes. The Pareto frontier includes

7

Algorithm 1: Conference calibration with per-instance error in the noiseless setting

Input: scores S = [s1, s2], maximum allowable per-instance error of the conference EC ([s1, s2])

if

s1

≥

max

{β

1

(β

− 2

1

(s2

)),

β2

(β

− 1

1

(s2

))}

then

accept paper 1

else

if

s1

≤

min{

β

1

(β

− 2

1

(

s2

))

,

β2

(

β

−1 1

(s2

))

}

then

accept paper 2

else if EC ([s1, s2]) ≥ minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} then

choose q1, q2 ∈ [0, 1] such that f1(s1)f2(s2)q1 + f2(s1)f1(s2)q2 = max {f1(s1)f2(s2), f2(s1)f1(s2)}

else choose q1, q2 ∈ [0, 1] such that EC ([s1, s2]) = 1 − f1f(s11(s)f12)f(s22(s)q21)++ff22((ss11))ff11((ss22))q2

end if

the origin since the conference can ensure zero error in this noiseless setting, but this zero-error acceptance

decision will also perfectly reveal the assignment to the adversary since the zero-error decisions would be

diﬀerent under the two assignments. Then in the proof, we ﬁnd the maximum per-instance error of the

adversary given per-instance error of the conference. We ﬁnd that the adversary’s error no longer increases

if the conference is allowed an error greater than minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} . At this value of the conference’s error, the maximum per-instance error of the adversary is also minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} . We further show in the proof of the theorem that the Pareto frontier is precisely the line segment joining these two points.

Therefore, the Pareto frontier for scores satisfy the condition is a line segment from the origin to the point

, min{f1(s1)f2(s2),f2(s1)f1(s2)} min{f1(s1)f2(s2),f2(s1)f1(s2)}

f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

as shown in Figure 1.

4.2.2 Optimal Calibration Strategy under Per-Instance Errors
In the previous section, we characterized the fundamental tradeoﬀ between the conference’s per-instance error and the adversary’s per-instance error through the Pareto frontier. In this section, we design an explicit calibration strategy that achieves per-instance errors on the Pareto frontier, and is thus optimal for per-instance errors.
Since S is a ﬁxed realization in the analysis of per-instance errors, to simplify the notation we deﬁne

q1 = h(S, A1) and q2 = h(S, A2).

Under this notation, q1 is the probability with which the conference calibrates under the true assignment when the true assignment is A1, and q2 is the probability with which the conference calibrates under the true assignment when the true assignment is A2. Therefore, from Proposition 4.1, given the maximum allowable error of the conference EC , our goal is to ﬁnd values of q1 and q2 that are Pareto optimal. We present our proposed algorithm for this setting as Algorithm 1.

Theorem 4.3. The calibration algorithm described in Algorithm 1 ensures the maximum per-instance error of the adversary for any given value of the maximum allowable per-instance error EC ([s1, s2]) for the conference, and is hence Pareto optimal.

The proof of Theorem 4.3 is presented in Appendix C.3.

If

s1

≥

max{

β

1

(β

− 2

1

(

s2

))

,

β2

(

β

− 1

1

(s2

))

}

or

s1

≤

min{

β

1

(β

− 2

1

(

s2

))

,

β2

(

β

− 1

1

(

s2

))

},

we

are

in

part

(1)

of

Theorem

4.2.

Under scores that satisfy this

condition, the conference is guaranteed to accept the higher-quality paper and thus has zero error. The error

of the adversary is also ﬁxed because the adversary makes its guess based on the scores only.

Otherwise, for a Pareto optimal calibration strategy, the errors of the conference and the adversary

should stay on the Pareto frontier as in Figure 1. When EC ([s1, s2]) ≥ minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} , the conference should choose q1 and q2 such that its per-instance error is minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} since further sacriﬁce of accuracy cannot increase the per-instance error of the adversary as indicated by the Pareto

8

Algorithm 2: Conference calibration with average-case error in the noiseless setting Input: maximum allowable average-case error of the conference EC Let ζ = error of the conference for adopting Algorithm 1 with EC ([s1, s2]) = 1 for all [s1, s2] if EC > ζ then
the desired conference error is Pareto ineﬃcient and operate at EC = ζ else if EC = ζ then
run Algorithm 1 with EC ([s1, s2]) = 1 else if EC < ζ then
toss a coin that has probability EζC of head if coin toss outcome is head then
run Algorithm 1 with EC ([s1, s2]) = 1 else
calibrate under true assignment end if end if
frontier. On the other hand, if EC ([s1, s2]) < minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} , the conference can choose q1 and q2 that yields the maximum allowable per-instance error. Since EC ([s1, s2]) < minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} and EC ([s1, s2]) = 1 − f1f(s11(s)f12)f(s22(s)q21)++ff22((ss11))ff11((ss22))q2 , we can conclude that f1(s1)f2(s2)q1 + f2(s1)f1(s2)q2 > max {f1(s1)f2(s2), f2(s1)f1(s2)} and the adversary has the same per-instance error under this condition. Therefore, in Algorithm 1, the error of the adversary is the same as the error of the conference and the errors are always on the Pareto frontier.
4.2.3 Optimal Calibration Strategy under Average-case Error
In the previous section, we designed an optimal strategy under per-instance errors. In this section, we design a calibration strategy that achieves optimal average-case errors for the conference with respect to the average-case error of the adversary. Unlike for per-instance error, we do not have a closed form expression for average-case error. We present our proposed algorithm as Algorithm 2. We now present our main result of this subsection, following which we discuss more details of the algorithm this result.
Theorem 4.4. The calibration algorithm described in Algorithm 2 ensures the maximum average-case error of the adversary for any given value of the maximum allowable average-case error EC for the conference, and is hence Pareto optimal.
The proof of Theorem 4.4 is provided in Appendix C.4. In Algorithm 2, running Algorithm 1 with EC ([s1, s2]) = 1 is a strategy that yields no error when the same paper has higher estimated quality under both assignments and otherwise, error of the conference equals error of the adversary. Moreover, both per-instance error of the conference and per-instance error of the adversary is minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} . That is, the maximum per-instance error for the adversary. Thus, this strategy is Pareto optimal for any score pair and is also Pareto optimal under its average-error since the error of the adversary is maximized under such average-error of the conference. In proof for optimality of Algorithm 2, we take advantage of the fact that the Pareto frontier is either a point where the conference has no error or an increasing line with slope 1. Under this fact, the optimal average-case error of the conference is where the conference has zero error when the adversary guesses the assignment based on the scores only and has the same error as the adversary otherwise. Therefore, Algorithm 2 makes use of Algorithm 1 with EC ([s1, s2]) = 1 and on average, the error of the conference and the adversary matches the Pareto optimality for the conference.
9

4.3 Noisy Setting
We now study the noisy setting. We consider both reviewers’ miscalibration functions β1 and β2 to be aﬃne and both reviewers’ noises 1 and 2 to be Gaussian. Furthermore, the distributions of the noise are the same for both reviewers with mean zero and some known variance σ2. Formally, we assume:
β1(θ∗) = a1θ∗ + b1, β2(θ∗) = a2θ∗ + b2, 1 ∼ N (0, σ2), and 2 ∼ N (0, σ2).
As we will see below, the presence of noise makes the analysis much more complex, even when we assume aﬃne miscalibration, as compared to the noiseless setting.

4.3.1 Pareto Frontier for Per-Instance Errors

We begin by establishing the Pareto frontier for per-instance errors in the noisy case. Let Φ denote the cumulative distribution function of the standard normal distribution. Also deﬁne notation Φ1 and Φ2 as:

Φ1 = Φ

a2(a21 + σ2)(s2 − b2) − a1(a22 + σ2)(s1 − b1) σ2(a21 + a22 + 2σ2)(a21 + σ2)(a22 + σ2)

Φ2 = Φ a1(a22 + σ2)(s2 − b1) − a2(a21 + σ2)(s1 − b2) . σ2(a21 + a22 + 2σ2)(a21 + σ2)(a22 + σ2)

(4.1a) (4.1b)

Theorem 4.5. Consider the peer-review system in the noisy setting. The Pareto frontier of (per-instance error of the conference, per-instance error of the adversary) with scores S = [s1, s2] is as follows.

(1) If s1 ≥ max

+ b , + b a2(a21+σ2)(s2−b2)

a1 (a22 +σ 2 )(s2 −b1 )

a1 (a22 +σ 2 )

1

a2 (a21 +σ 2 )

2

then the Pareto frontier consists of a single point.

or s1 ≤ min

+ b , + b , a2(a21+σ2)(s2−b2)

a1 (a22 +σ 2 )(s2 −b1 )

a1 (a22 +σ 2 )

1

a2 (a21 +σ 2 )

2

Speciﬁcally, when s1 ≥ max

+ b , + b , a2(a21+σ2)(s2−b2)

a1 (a22 +σ 2 )(s2 −b1 )

a1 (a22 +σ 2 )

1

a2 (a21 +σ 2 )

2

ference error and adversary error is the point f1(fs11()sf12)(fs22()sΦ21)++ff22((ss11))ff11((ss22))Φ2 ,

And similarly, when s1 ≤ min

+ b , + b a2(a21+σ2)(s2−b2)

a1 (a22 +σ 2 )(s2 −b1 )

a1 (a22 +σ 2 )

1

a2 (a21 +σ 2 )

2

point

, . f1(s1)f2(s2)(1−Φ1)+f2(s1)f1(s2)(1−Φ2) min{f1(s1)f2(s2),f2(s1)f1(s2)}

f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

the Pareto frontier of con. min{f1 (s1 )f2 (s2 ),f2 (s1 )f1 (s2 )}
f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )
, the Pareto frontier is the

(2) If min

+ b , + b a2(a21+σ2)(s2−b2)

a1 (a22 +σ 2 )(s2 −b1 )

a1 (a22 +σ 2 )

1

a2 (a21 +σ2 )

2

then the Pareto frontier is an increasing line.

< s1 < max

+ b , + b , a2(a21+σ2)(s2−b2)

a1 (a22 +σ 2 )(s2 −b1 )

a1 (a22 +σ2 )

1

a2 (a21 +σ2 )

2

The proof of Theorem 4.5 is provided in Appendix C.5. We now unpack this result and specify precisely

the Pareto frontier in both parts of the theorem.

Given scores S = [s1, s2] and knowing the reviewers’ miscalibration functions, the conference can estimate the qualities of papers under each assignment. Under assignment A1, we have Pr(θ1∗ > θ2∗|A = A1, S = [s1, s2]) = 1 − Φ1. And under assignment A2, we have Pr(θ1∗ > θ2∗|A = A2, S = [s1, s2]) = 1 − Φ2.

Let us now consider part (1) of Theorem 4.5. If the condition speciﬁed in the statement of the theorem

is

satisﬁed,

then

we

know

that

either

(Φ1

≤

1 2

,

Φ2

≤

12 )

in

which

case

paper

1

has

a

higher

estimated

quality

under

either

assignment,

or

(Φ1

≥

1 2

,

Φ2

≥

12 )

in

which

paper

2

has

a

higher

estimated

quality

under

either

assignment. Thus, if the condition in part (1) is met, the same paper has higher estimated quality under

both assignments and hence the decision does not depend on h. Thus, for such pair of scores, the Pareto

optimal situation is where the conference has minimum error and the adversary guesses the assignment based

on the scores alone.

Let us now move to part (2) of Theorem 4.5, and consider parameters that satisfy the condition stated

therein. Under this condition, the conference would accept diﬀerent papers by calibrating under diﬀerent

assignments, and the function h needs to be carefully designed. We study the Pareto frontier for scores in

the range.

10

Error of the adversary

%1 ,1 %2 ,2 %1 ,1 %2 ,2 + %2 ,1 %1(,2)

1 : /! 0! /" 0" Φ! + /" 0! /! 0" (1 − Φ") /! 0! /" 0" + /" 0! /!(0")
2 : /! 0! /" 0" (Φ!+2Φ" − 1) + /" 0! /! 0" (1 − Φ") /! 0! /" 0" + /" 0! /!(0")

1

2

0.5 Error of the

conference

Figure 2: A Pareto frontier in the noisy setting of part (2) of Theorem 4.5 in the case that f1(s1)f2(s2) <

f2(s1)f1(s2)

and

Φ1

<

1 2

<

Φ2

with

0

<

Φ2

−

1 2

<

1 2

− Φ1.

The

notations

Φ1

and

Φ2

are

deﬁned

in

(4.1).

We

consider

a

speciﬁc

case

where

f1(s1)f2(s2)

<

f2(s1)f1(s2),

Φ1

<

1 2

and

Φ2

>

1 2

with

0

<

Φ2 −

1 2

<

1 2

−

Φ1.

All other cases can be derived in a similar fashion to the proof in Appendix C.5.

The

Pareto frontier with these assumptions are shown in Figure 2. We ﬁrst ﬁnd the maximum per-instance

error of the adversary given per-instance error of the conference. We ﬁnd that the adversary’s error no longer increases if the conference increase its error larger than f1(s1)f2(sf21)((Φs11)+f22(Φs22−)+1f)+2(fs21()sf11)(fs12()s2)(1−Φ2) in this case. The maximum per-instance error of the adversary is f1(s1)ff21((ss21))+ff22((ss21))f1(s2) . Therefore, the Pareto

frontier for scores satisfy the condition is an increasing line from f1(s1f)f12(s(1s2)f)Φ2(1s+2)f+2(fs21()sf11)(fs12()s(21)−Φ2) , 0 to

, . f1(s1)f2(s2)(Φ1+2Φ2−1)+f2(s1)f1(s2)(1−Φ2)

f1 (s1 )f2 (s2 )

f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

We show the Pareto frontier in the case described above in Figure 2. In all other cases, the shape

of the Pareto frontier is the same as Figure 2 but has diﬀerent coordinates. The relationship between
f1(s1)f2(s2) and f2(s1)f1(s2) combining with the values of Φ1 and Φ2 and their distance to 12 , we have eight diﬀerent combinations of these values. In all eight cases, the Pareto frontier contains either a single

point or an increasing line depending on the scores. Moreover, the maximum error of the adversary is minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} in all cases.

4.3.2 Optimal Calibration Strategy under Per-Instance Errors
In the previous section, we characterized the fundamental tradeoﬀ between the conference’s per-instance error and the adversary’s per-instance error through the Pareto frontier. In this section, we design a calibration strategy that achieves per-instance errors on the Pareto frontier, meaning that the strategy is optimal under per-instance errors.
Since S is a ﬁxed realization in the analysis of per-instance errors, to simplify the notation we deﬁne (similar to Section 4.2.2):
q1 = h(S, A1) and q2 = h(S, A2).
Under this notation, given the maximum allowable error of the conference EC, our goal is to ﬁnd values of q1 and q2 that maximize the error of the adversary EA. We continue to use the notations Φ1 and Φ2 introduced in 4.1.
We present our proposed algorithm as Algorithm 3.
Theorem 4.6. The calibration algorithm described in Algorithm 3 ensures the maximum per-instance error of the adversary for any given value of the maximum allowable per-instance error EC ([s1, s2]) for the conference, and is hence Pareto optimal.

11

Algorithm 3: Conference calibration with per-instance error in the noisy setting

Input: scores S = [s1, s2], maximum allowable per-instance error of the conference EC ([s1, s2])

if s1 > max

+ b , + b a2(a21+σ2)(s2−b2)

a1 (a22 +σ 2 )(s2 −b1 )

a1 (a22 +σ 2 )

1

a2 (a21 +σ 2 )

2

then

accept paper 1

else if s1 < min

+ b , + b a2(a21+σ2)(s2−b2)

a1 (a22 +σ 2 )(s2 −b1 )

a1 (a22 +σ2 )

1

a2 (a21 +σ2 )

2

then

accept paper 2

else if EC ([s1, s2]) < f1(s1f)f12(s(1s2)f)Φ2(1s+2)f+2(fs21()sf11)(fs12()s(21)−Φ2) then

error conference of cannot be achieved

else if EC ([s1, s2]) ≥ f1(s1)f2(sf21)((Φs11)+f22(Φs22−)+1f)+2(fs21()sf11)(fs12()s2)(1−Φ2) then

choose q1 = 1, q2 = (f2(s1f)1f(1s(1s)2f)2−(sf21)(+s1f)2f(2s(1s)2f)1)((s12−) 2Φ2)

else

choose q1 = 1, q2 = EC ([s1,s2])·(f1(s1)f2(s2)+f2(s1)f1(s2))−(1f−12(sΦ12))ff22((ss21))(f11−(Φs21))−f2(s1)f1(s2)Φ2−(2Φ1−1)f1(s1)f2(s2)

end if

The proof of Theorem 4.6 is provided in Appendix C.6. For a moment, consider the case of f1(s1)f2(s2) <

f2(s1)f1(s2)

and

Φ1

<

1 2

<

Φ2

with

0

<

Φ2

−

1 2

<

1 2

− Φ1,

for

a

Pareto

optimal

calibration

strategy,

the

error of the conference and the adversary should stay on the Pareto frontier as in Figure 2. If the required

error of the conference is less than f1(s1f)f12(s(1s2)f)Φ2(1s+2)f+2(fs21()sf11)(fs12()s(21)−Φ2) , then due to the noise, there is no feasible calibration strategy that satisﬁes this requirement. Otherwise, the error of the conference and the error of

the adversary adhere to the Pareto frontier.

Algorithm 3 follows directly from the Pareto frontier established in Theorem 4.5. The calibration prob-

abilities q1 and q2 are chosen such that the error of the conference and the error of the adversary lie

on the Pareto frontier. The ﬁrst two cases of Algorithm 3 correspond to part (1) of Theorem 4.5 where

the same paper has higher estimated quality under both assignments. In the noisy case, there is a mini-

mum value for the per-instance error of the conference. Therefore, in the third case of Algorithm 3, when

the maximum allowable per-instance error of the conference is too small, the conference cannot achieve

such error. If EC ([s1, s2]) ≥ f1(s1)f2(sf21)((Φs11)+f22(Φs22−)+1f)+2(fs21()sf11)(fs12()s2)(1−Φ2) , the error of the conference should be f1(s1)f2(sf21)((Φs11)+f22(Φs22−)+1f)+2(fs21()sf11)(fs12()s2)(1−Φ2) to stay Pareto optimal since further sacriﬁce of accuracy cannot increase error of the adversary. And for the rest of the per-instance error of the conference, we choose q1 and

q2 such that the errors of the conference and the adversary stay on the Pareto frontier in Figure 2.

5 Discussion
Our work is only a starting point towards addressing the important problem of calibration with privacy in its full generality. Several challenges need to be addressed in future work in order to design practical algorithms with guarantees for calibration and privacy. There are open problems pertaining to relaxations of assumptions made in this paper such as that of two reviewers and papers, homogeneity and knowledge of the noise variance, etc. An important open problem pertains to challenge #2 discussed in the introduction, in conjunction with challenge #1. Instead of assuming precise exogenous knowledge of the reviewers’ miscalibration functions, consider having some access to data from other conferences. Then how can one obtain and use meaningful estimates of reviewer miscalibrations from past conferences while guaranteeing privacy of the current as well as past conferences (“federated learning for calibration”)? In any of these endeavors, one may aim to uncover precise fundamental limits and optimal algorithms, or perhaps design algorithms that are readily applicable in practice with some basic theoretical guarantees.

12

Acknowledgments
This work was supported by NSF CAREER award 1942124, NSF grant CIF 1763734, an NSERC Discovery Grant, and a Google Research Scholar Award. Most of this research was done when Wenxin Ding was at Carnegie Mellon University.
References
[1] S. S. Siegelman. “Assassins and zealots: Variations in peer review”. In: Radiology 178.3 (1991), pp. 637– 642.
[2] P. Flach, S. Spiegler, B. Gol´enia, S. Price, J. Guiver, R. Herbrich, T. Graepel, and M. Zaki. “Novel Tools to Streamline the Conference Review Process: Experiences from SIGKDD’09”. In: SIGKDD Explor. Newsl. 11.2 (May 2010), pp. 63–67.
[3] H. Ge, M. Welling, and Z. Ghahramani. A Bayesian model for calibrating conference review scores. 2013.
[4] M. Roos, J. Rothe, and B. Scheuermann. “How to Calibrate the Scores of Biased Reviewers by Quadratic Programming”. In: AAAI Conference on Artiﬁcial Intelligence. 2011.
[5] M. Roos, J. Rothe, J. Rudolph, B. Scheuermann, and D. Stoyan. “A statistical approach to calibrating the scores of biased reviewers: The linear vs. the nonlinear model”. In: Multidisciplinary Workshop on Advances in Preference Handling. 2012.
[6] S. R. Paul. “Bayesian methods for calibration of examiners”. In: British Journal of Mathematical and Statistical Psychology 34.2 (1981), pp. 213–223.
[7] Y. Baba and H. Kashima. “Statistical Quality Estimation for General Crowdsourcing Tasks”. In: KDD. 2013.
[8] R. S. MacKay, R. Kenna, R. J. Low, and S. Parker. “Calibration with conﬁdence: A principled method for panel assessment”. In: Royal Society Open Science 4.2 (2017).
[9] L. Brenner, D. Griﬃn, and D. J. Koehler. “Modeling patterns of probability calibration with random support theory: Diagnosing case-based judgment”. In: Organizational Behavior and Human Decision Processes 97.1 (2005), pp. 64–81.
[10] J. Langford. ICML acceptance statistics. http://hunch.net/?p=2517 [Online; accessed 14-May-2021]. 2012.
[11] J. Wang and N. B. Shah. “Your 2 is My 1, Your 3 is My 9: Handling Arbitrary Miscalibrations in Ratings”. In: AAMAS. 2019.
[12] N. Shah, B. Tabibian, K. Muandet, I. Guyon, and U. Von Luxburg. “Design and Analysis of the NIPS 2016 Review Process”. In: JMLR 19.1 (2018), pp. 1913–1946.
[13] A. Tomkins, M. Zhang, and W. D. Heavlin. “Reviewer bias in single-versus double-blind peer review”. In: Proceedings of the National Academy of Sciences 114.48 (2017), pp. 12708–12713.
[14] E. Manzoor and N. B. Shah. “Uncovering Latent Biases in Text: Method and Application to Peer Review”. In: AAAI. 2021.
[15] I. Stelmakh, N. Shah, and A. Singh. “On Testing for Biases in Peer Review”. In: NeurIPS. 2019. [16] C. J. Lee. “Commensuration bias in peer review”. In: Philosophy of Science 82.5 (2015), pp. 1272–1283. [17] R. Noothigattu, N. B. Shah, and A. D. Procaccia. “Loss Functions, Axioms, and Peer Review”. In:
arXiv preprint arXiv:1808.09057 (2018). [18] M. J. Mahoney. “Publication prejudices: An experimental study of conﬁrmatory bias in the peer review
system”. In: Cognitive therapy and research 1.2 (1977), pp. 161–175.
13

[19] S. Balietti, R. L. Goldstone, and D. Helbing. “Peer review and competition in the Art Exhibition Game”. In: Proceedings of the National Academy of Sciences 113.30 (2016), pp. 8414–8419.
[20] I. Stelmakh, N. Shah, and A. Singh. “Catch Me if I Can: Detecting Strategic Behaviour in Peer Assessment”. In: arXiv (2020).
[21] Y. Xu, H. Zhao, X. Shi, and N. Shah. “On Strategyproof Conference Review”. In: IJCAI. 2019.
[22] M. L. Littman. “Collusion rings threaten the integrity of computer science research”. In: Communications of the ACM 64.6 (2021), pp. 43–44.
[23] S. Jecmen, H. Zhang, R. Liu, N. B. Shah, V. Conitzer, and F. Fang. “Mitigating Manipulation in Peer Review via Randomized Reviewer Assignments”. In: NeurIPS. 2020.
[24] R. Wu, C. Guo, F. Wu, R. Kidambi, L. van der Maaten, and K. Weinberger. “Making Paper Reviewing Robust to Bid Manipulation Attacks”. In: arXiv:2102.06020 (2021).
[25] N. B. Shah. Systemic Challenges and Solutions on Bias and Unfairness in Peer Review. Preprint http://www.cs.cmu.edu/~nihars/preprints/Shah_Survey_PeerReview.pdf. July 2021.
[26] I. Mitliagkas, A. Gopalan, C. Caramanis, and S. Vishwanath. “User rankings from comparisons: Learning permutations in high dimensions”. In: Allerton Conference. 2011.
[27] A. Ammar and D. Shah. “Eﬃcient rank aggregation using partial data”. In: SIGMETRICS. 2012.
[28] Y. Freund, R. D. Iyer, R. E. Schapire, and Y. Singer. “An Eﬃcient Boosting Algorithm for Combining Preferences”. In: Journal of Machine Learning Research 4 (2003), pp. 933–969.
[29] D. Soergel, A. Saunders, and A. McCallum. “Open Scholarship and Peer Review: A Time for Experimentation”. In: (2013).
[30] D. Kang, W. Ammar, B. Dalvi, M. van Zuylen, S. Kohlmeier, E. Hovy, and R. Schwartz. “A dataset of peer reviews (peerread): Collection, insights and nlp applications”. In: arXiv preprint arXiv:1804.09635 (2018).
[31] D. Tran, A. Valtchanov, K. Ganapathy, R. Feng, E. Slud, M. Goldblum, and T. Goldstein. “An Open Review of OpenReview: A Critical Analysis of the Machine Learning Conference Review Process”. In: arXiv preprint arXiv:2010.05137 (2020).
[32] H. Bharadhwaj, D. Turpin, A. Garg, and A. Anderson. “De-anonymization of authors through arXiv submissions during double-blind review”. In: arXiv preprint arXiv:2007.00177 (2020).
[33] W. Yuan, P. Liu, and G. Neubig. “Can We Automate Scientiﬁc Reviewing?” In: arXiv preprint arXiv:2102.00176 (2021).
[34] I. Stelmakh, N. Shah, A. Singh, and H. Daum´e III. “Prior and Prejudice: The Novice Reviewers’ Bias against Resubmissions in Conference Peer Review”. In: CSCW. 2021.
[35] J. Goldsmith and R. H. Sloan. “The AI conference paper assignment problem”. In: Proc. AAAI Workshop on Preference Handling for Artiﬁcial Intelligence, Vancouver. 2007, pp. 53–57.
[36] C. J. Taylor. “On the optimal assignment of conference papers to reviewers”. In: (2008).
[37] L. Charlin and R. S. Zemel. “The Toronto Paper Matching System: An automated paper-reviewer assignment system”. In: ICML Workshop on Peer Reviewing and Publishing Models. 2013.
[38] N. Garg, T. Kavitha, A. Kumar, K. Mehlhorn, and J. Mestre. “Assigning Papers to Referees”. In: Algorithmica 58.1 (Sept. 2010), pp. 119–136.
[39] I. Stelmakh, N. Shah, and A. Singh. “PeerReview4All: Fair and Accurate Reviewer Assignment in Peer Review”. In: JMLR (2021).
[40] A. Kobren, B. Saha, and A. McCallum. “Paper Matching with Local Fairness Constraints”. In: ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2019.
[41] D. Mimno and A. McCallum. “Expertise Modeling for Matching Papers with Reviewers”. In: KDD. 2007.
14

[42] T. Fiez, N. Shah, and L. Ratliﬀ. “A SUPER* Algorithm to Optimize Paper Bidding in Peer Review”. In: Conference on Uncertainty in Artiﬁcial Intelligence. 2020.
[43] R. Meir, J. Lang, J. Lesca, N. Kaminsky, and N. Mattei. “A market-inspired bidding scheme for peer review paper assignment”. In: Games, Agents, and Incentives Workshop at AAMAS. 2020.
[44] M. Liu, V. Choy, P. Clarke, A. Barnett, T. Blakely, and L. Pomeroy. “The acceptability of using a lottery to allocate research funding: A survey of applicants”. In: Research integrity and peer review 5.1 (2020), pp. 1–7.
[45] D. S. Chawla. “Swiss funder draws lots to make grant decisions”. In: Nature (2021). [46] A. Philipps. “Research funding randomly allocated? A survey of scientists’ views on peer review and
lottery”. In: Science and Public Policy (2021). [47] W. Ding, N. B. Shah, and W. Wang. “On the Privacy-Utility Tradeoﬀ in Peer-Review Data Analysis”.
In: AAAI Privacy-Preserving Artiﬁcial Intelligence (PPAI-21) workshop. 2020. [48] C. Dwork, F. McSherry, K. Nissim, and A. Smith. “Calibrating noise to sensitivity in private data
analysis”. In: Journal of Privacy and Conﬁdentiality 7.3 (2016), pp. 17–51. [49] S. L. Warner. “Randomized Response: A Survey Technique for Eliminating Evasive Answer Bias”. In:
Journal of the American Statistical Association 60.309 (1965), pp. 63–69. [50] A. Evﬁmievski, J. Gehrke, and R. Srikant. “Limiting Privacy Breaches in Privacy Preserving Data
Mining”. In: Proceedings of the 22nd ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems. PODS ’03. New York, NY, USA: ACM, 2003, pp. 211–222. [51] S. P. Kasiviswanathan, H. K. Lee, K. Nissim, S. Raskhodnikova, and A. Smith. “What Can We Learn Privately?” In: SIAM Journal on Computing 40.3 (2011), pp. 793–826.
Appendices
A Simulations: Correcting miscalibration with and without exogeneous information
In the introduction section in the main text, we discussed two ways of reducing miscalibration: one where only the current conferences’ data is used and another where miscalibration parameters of reviewers are obtained exogenously (e.g., from previous conferences). In this section, we conduct a simulation-based study to understand the performance of these approaches: What is the reduction in error if correcting for miscalibration? What if the reviewer-calibration parameters are known?
Our main results in the main text was focused on privacy and considered a setting with two reviewers and two papers. In this section we consider a larger number of reviewers and papers. The methods we simulate in this more general setting do not consider privacy.
We ﬁrst describe the simulation setting, and then discuss the results. The code for the simulations is available here: https://github.com/wenxind/calibration-with-privacy-in-peer-review.
Conference review setup: We consider 100 reviewers and 100 papers. We assign reviewers to papers uniformly at random with 3 reviewers per paper and 3 papers per reviewer.
Miscalibration model: We assume each reviewer has a linear miscalibration function: the miscalibration function fj of reviewer j is given by fj(θ∗) = ajθ∗ + bj where θ∗ is the true quality of the paper being reviewed. For every paper i, its true quality θi∗ is drawn from a Gaussian distribution with mean 0 and variance 1 independent of all else. The scalars aj in the reviewers’ miscalibration functions are i.i.d. exponential random variables with rate 1. The biases bj are i.i.d. Gaussian random variables with mean 0
15

Kendall-tau distance Messy middle error

0.25 0.20 0.15 0.10 0.05 0.00 0.0

No calibration Within-conference calibration Calibration with known parameters
0.1 Var0ia.n2ce o0f .n3oise 0.4 0.5
(a) Kendall-τ distance.

0.4 0.3 0.2 0.1 0.0 0.0

No calibration Within-conference calibration Calibration with known parameters
0.1 Var0ia.n2ce o0f .n3oise 0.4 0.5
(b) Messy middle error.

Figure 3: A simulation of the review process where the reviewers are miscalibrated.

and variance 0.5. The score given by any reviewer j to any paper i is then given as θi∗ is ajθi∗ + bj + ij where ij is a Gaussian random variable with mean 0, whose variance is varied in the plots.
Calibration methods: We consider the following three methods to calibrate the decisions.

• No calibration: The score for each paper is the mean score of the 3 review scores.

• Within-conference calibration: For each reviewer, we compute the mean score and standard deviation of the 3 review scores given by the reviewer and normalize the 3 scores by subtracting mean and dividing standard deviation. Then the score for each paper is the mean score of the 3 normalized review scores.

• Calibration with known parameters: We assume that the miscalibration parameters of the reviewers are

known (exogeneously). Then we estimate the quality of each paper via maximum likelihood estimation

as follows. For any paper i, let Ri denote the set of reviewers for paper i. Then the estimate of the

score for any paper i is

j∈Ri aj (sji−bj )
2

where

sji

denotes

the

score

given

by

reviewer

j

to

paper

i.

j∈Ri aj

For each paper, we then take a mean of the calibrated scores across all its reviewers. The papers are then ranked according to these mean scores; we call this the estimated ranking.
Error metrics: We consider two ways of measuring the error between the ranking of the papers in terms of their true scores and the ranking of the papers in terms of their estimated scores.

• Kendall tau distance: Given two rankings of the papers, the Kendall tau distance between the two ranking is numtobtearl onfumdibsceorrodfanptaiprsairs .
• Messy middle error: Given two rankings of the 100 papers, suppose that the conference wishes to accept the top 25 papers. Then we consider papers 11-40 as those that are marginal accepts, and we measure the error as the fraction of these papers which are (erroneously) rejected. In other words, the messy middle error equals number of papers whose true ranking is betw3e0en 11–40 that are wrongly accepted/rejected .
Results: The results of the simulations are shown in Figure 3. Each point depicts the mean from 100 iterations of these simulations. The error bars are too small to be visible. We see that correcting for miscalibration even without access to the parameters can lead to signiﬁcant reduction in the error as compared to not correcting for the miscalibration. Furthermore, if the parameters were known (e.g., from other conferences) then it can lead to multi-fold further reductions in the error.

16

B Connection to Local Diﬀerential Privacy
In this section, we discuss the connections between our algorithm and diﬀerential privacy (DP). We recall the deﬁnition of DP:
Deﬁnition B.1 ([48]). An algorithm M : X n → Y is -diﬀerentially private (DP) if, for all X, X ∈ X n which diﬀer in one entry (often called neighboring databases) and S ⊆ Y , we have that
Pr[M (X) ∈ S] ≤ e Pr[M (X ) ∈ S].
Roughly speaking, a procedure involving n users is -locally diﬀerentially private if each user applies an -DP algorithm to their single datapoint and shares only the result with other users or a data curator. The most familiar LDP algorithm is (binary) randomized response.
Deﬁnition B.2. Binary randomized response with parameter γ is an algorithm M : {0, 1} → {0, 1}, which, given input x, outputs x with probability 1+1γ , and outputs 1 − x with probability 1+γγ .
The following claim is immediate from the deﬁnition of diﬀerential privacy and randomized response.
Proposition B.3. Binary randomized response with parameter e is -DP.
We now relate randomized response to the algorithms proposed in our setting. The private information for our calibration problem consists solely of the reviewer assignment A, which takes one of two diﬀerent values (i.e., reviewer 1 is assigned to paper 1 and reviewer 2 is assigned to paper 2, or vice versa). These two reviewer assignments can be considered to be “neighboring” datasets, as mentioned in Deﬁnition B.1. All other information (paper scores S and reviewer calibration functions) are assumed to be public.
As argued in Proposition 4.1, it is without loss of optimality to solely consider strategies of the form h, in which the conference calibrates according to the true assignment with probability h(S, A) and according to the false assignment otherwise. This can be rephrased into the language of randomized response by considering the assignment A to be the input bit to binary randomized response, in which it is preserved with probability h(S, A) (in the language of Deﬁnition B.2, h(S, A) = 1+1γ ) and ﬂipped otherwise, and then the conference calibrates with the resulting assignment.
We caution that this connection does not directly imply that our algorithms are diﬀerentially private. This is because the probability h(S, A) is selected in a data-dependent way, whereas diﬀerential privacy requires it to be data independent. Nevertheless, our work provides tight guarantees on the probability that an MAP adversary can determine the true assignment.
C Appendix: Proofs
In the appendix, we present complete proofs of the results claimed in the main text.
C.1 Proof of Proposition 4.1
The most generic calibration strategy can be represented using a function g such that for any given score and assignment, g outputs a probability for accepting paper 1. In other words, the conference accepts paper 1 with probability g(S, A) and accepts paper 2 with probability 1 − g(S, A). We propose a calibration strategy using function h instead of g, where h outputs a probability that the conference calibrates under the true assignment by accepting the paper with higher estimated quality under the true assignment.
Calibrating using the calibration strategy of function h diﬀers from calibrating using the calibration strategy of function g only when the same paper has higher estimated quality under both assignments by the MAP. Since otherwise, when calibrating under the true assignment and calibrating assuming the wrong assignment lead to accepting diﬀerent papers, either paper can have arbitrary non-zero probability of being accepted (their probabilities sum to 1) by adjusting the output of h(S, A1) and h(S, A2). Then it is the same calibration strategy as using function g.
17

Note that the adversary makes its guess using the MAP argmax{A=A1orA=A2} Pr(A = A|D = P, S = [s1, s2]) where D is the random variable for the decision made by the conference (acceptance of paper) and
P is the paper being accepted. By expanding the probability expression, we have that

argmax Pr(A = A|D = P, S = [s1, s2])
A=A1 orA=A2

= argmax Pr(A = A, D = P |S = [s1, s2]) A=A1orA=A2 Pr(D = P |S = [s1, s2])

= argmax Pr(D = P |A = A, S = [s1, s2]) Pr(A = A|S = [s1, s2])

A=A1 orA=A2

Pr(D = P |S = [s1, s2])

= argmax Pr(D = P |A = A, S = [s1, s2]) Pr(A = A|S = [s1, s2]).
A=A1 orA=A2

If the same paper has higher estimated quality under both assignments, and the conference accepts the believed higher-quality paper, then the adversary guesses the assignment based on the scores only. Because the adversary knows the calibration strategy used by the conference, if P is the paper that has higher quality under both assignments, then Pr(D = P |A = A, S = [s1, s2]) = 1 for both A = A1 and A = A2. Therefore, the MAP used by the adversary simpliﬁes to argmaxA=A1orA=A2 Pr(A = A|S = [s1, s2]). In this case, the conference does not have extra privacy leakage by accepting P since the adversary is making its guess based on the information that is already public (the scores). In addition, if the conference has non-zero probability of accepting the other paper, its utility decreases by accepting the lower-quality paper. Even if the conference accepts the lower-quality paper, the error of the adversary remains unchanged as it can use the scores to guess the assignment without being aﬀected by the conference decision. Thus, there is no need for the conference to have non-zero probability for accepting the paper that has lower-quality under both assignments.
In conclusion, calibrating using the calibration strategy of function h instead of the calibration strategy of function g does not reduce the optimally of the conference. Therefore, we consider the calibration strategy with function h in our analysis.

C.2 Proof of Theorem 4.2

To ﬁnd the Pareto frontier of per-instance error of the adversary against per-instance error of the conference,

we ﬁrst derive expressions for per-instance error of the conference and the adversary. We ﬁnd a ﬁxed

expression for the error of the conference and calculate the maximum per-instance error of the adversary

in diﬀerent cases. We then analyze the relation between the errors and complete plots for maximum per-

instance error of the adversary for any per-instance error of conference. Finally, we derive the Pareto frontier

from the plots.

In the noiseless setting, the conference uses the inverse functions of reviewers’ miscalibration functions

and the scores to exactly compute the quality of the papers. If the conference estimates the qualities

assuming that A1 was the actual assignment, we get θ1 = β1−1(s1) and θ2 = β2−1(s2). If the conference

estimates the qualities assuming that A2 was the actual assignment, we get θ1 = β2−1(s1) and θ2 = β1−1(s2).

If

s1

>

max

{β

2

(β

− 1

1

(s2

))

,

β1

(β

− 2

1

(

s2

))

},

then

θ1

>

θ2

under

both

assignments

(and

hence

paper

1

should

be accepted).

Similarly,

if

s1

<

min

{β

2

(

β

−1 1

(s2

)),

β1

(β

− 2

1

(s2

))}

,

then

θ1

<

θ2

under

both

assignments

and hence paper 2 should be accepted.

Therefore,

when

s1

>

max

{β

2

(β

− 1

1

(s2

)),

β1

(β

− 2

1

(s2

))

}

or

s1

<

min

{β

2

(

β

−1 1

(s2

))

,

β1

(

β

−1 2

(s2

))}

,

which

is

a

subset

of

part

(1)

of

Theorem

4.2,

the

same

paper

has

higher

estimated quality under both assignments, and hence that paper will be accepted irrespective of the function

h. Thus, under this condition, the Pareto optimal curve comprises just a single point where the conference has

zero error, and the adversary obtains no additional information from the acceptance decision as compared

to the scores S = [s1, s2]. The error of the adversary is minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} when it guesses the assignment using only the scores and not the decision.

For the rest scores, the conference uses function h to decide acceptance of paper. Since S is a ﬁxed

18

realization in the analysis, we simplify the calibration strategy for the conference as
q1 = h(S, A1) q2 = h(S, A2).
We now consider the rest scores in part (1) of the theorem. If s1 = β2(β1−1(s2)), the conference accepts each paper uniform at random if calibrating under A1 and accepts paper 1 if calibrating under A2. Since paper 1 has higher or equal quality than paper 2, the conference only has error when paper 2 is accepted and A = A2.

Pr(conference accepts lower-quality paper|S = [s1, s2]) = Pr(conference accepts lower-quality paper|S = [s1, s2], D = P1) Pr(D = P1|S = [s1, s2])
+ Pr(conference accepts lower-quality paper|S = [s1, s2], D = P2) Pr(D = P2|S = [s1, s2]) = Pr(conference accepts lower-quality paper|S = [s1, s2], D = P2) Pr(D = P2|S = [s1, s2]).
Given that the conference accepts P2, the probability of the conference making error is the probability Pr(A = A2|S = [s1, s2]).

Pr(D = P2|S = [s1, s2])

= Pr(D = P2|S = [s1, s2], A = A1) Pr(A = A1|S = [s1, s2])

+ Pr(D = P2|S = [s1, s2], A = A2) Pr(A = A2|S = [s1, s2])

1

1

= 2 q1 Pr(A = A1|S = [s1, s2]) + 2 (1 − q2) Pr(A = A2|S = [s1, s2]).

For the adversary, if paper 1 is accepted, it gains no information on the assignment other than the scores so its error is minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} . Otherwise, it guesses A = A1 and its error is Pr(A = A2|S = [s1, s2]). Note that error of the adversary does not exceed minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} since in the worst case for the adversary, it guesses the assignment solely based on the scores and ignore the conference decision.

Pr(adversary guesses assignment wrong|S = [s1, s2])

= Pr(adversary guesses assignment wrong|S = [s1, s2], D = P1) Pr(D = P1|S = [s1, s2])

+ Pr(adversary guesses assignment wrong|S = [s1, s2], D = P2) Pr(D = P2|S = [s1, s2])

= min{f1(s1)f2(s2), f2(s1)f1(s2)} (1 − 1 q1) Pr(A = A1|S = [s1, s2]) + ( 1 + 1 q2) Pr(A = A2|S = [s1, s2])

f1(s1)f2(s2) + f2(s1)f1(s2)

2

22

1

1

+ Pr(A = A2|S = [s1, s2]) 2 q1 Pr(A = A1|S = [s1, s2]) + 2 (1 − q2) Pr(A = A2|S = [s1, s2])

Therefore, we can minimize the error of the conference to 0 by choosing q1 = 0 and q2 = 1, which results in the conference always accepts paper 1. Then error of the adversary is minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} , which is maximized. Further increase of error of the conference cannot increase error of the adversary. So the Pareto

optimal point is (0, minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} ). The same argument works when s1 = β1(β2−1(s2)).

In

the

noiseless

setting

where

min{

β

2

(

β

−1 1

(s2

))

,

β1

(

β

−1 2

(s2

))

}

<

s1

<

max

{β

2

(

β

−1 1

(s2

))

,

β1

(

β

−1 2

(s2

))}

,

which is part (2) of Theorem 4.2, we ﬁrst ﬁnd the maximum per-instance error of the adversary given

per-instance error of the conference in this range. We will show the proof with the assumptions that β2(β1−1(s2)) > β1(β2−1(s2)) and f1(s1)f2(s2) > f2(s1)f1(s2). The proof follows the same procedure for other values of β2(β1−1(s2)), β1(β2−1(s2)), f1(s1)f2(s2), and f2(s1)f1(s2).

19

When the scores satisfy β1(β2−1(s2)) < s1 < β2(β1−1(s2)), the conference always accepts the higherquality paper if it calibrates under the true assignment, and the conference always accepts the lower-quality paper if it calibrates assuming the wrong assignment. But the conference can calibrate assuming the wrong assignment for the purpose of misleading the adversary. We use A to denote the random variable for the assignment, D to denote the random variable for the conference decision and S is the scores. In addition, we use C to denote the calibration status. If the conference calibrates under the true assignment then C = T . Otherwise, C = F .
Therefore, the error of the conference is computed as

Pr(conference accepts lower-quality paper|S = [s1, s2])

= Pr(C = F |S = [s1, s2])

= Pr(C = F, A = A1|S = [s1, s2]) + Pr(C = F, A = A2|S = [s1, s2])

= Pr(C = F |A = A1, S = [s1, s2]) Pr(A = A1|S = [s1, s2])

+ Pr(C = F |A = A2, S = [s1, s2])P (A = A2|S = [s1, s2])

=(1 − q1) ·

f1(s1)f2(s2)

+ (1 − q2) ·

f2(s1)f1(s2)

f1(s1)f2(s2) + f2(s1)f1(s2)

f1(s1)f2(s2) + f2(s1)f1(s2)

=1 − f1(s1)f2(s2)q1 + f2(s1)f1(s2)q2 . f1(s1)f2(s2) + f2(s1)f1(s2)

The adversary uses MAP to guess the assignment. If the two assignments have the same a posteriori
probability, then the adversary makes a random guess between the assignments where either assignment has probability 21 of being guessed. When making a guess, the adversary observes the scores and the conference decision. So the adversary ﬁnds argmax{A=A1orA=A2} Pr(A = A|D = P, S = [s1, s2]) where P is the paper being accepted. Following Section C.1, the adversary ﬁnds

argmax Pr(A = A|D = P, S = [s1, s2])
A=A1 orA=A2
= argmax Pr(D = P |A = A, S = [s1, s2]) Pr(A = A|S = [s1, s2])
A=A1 orA=A2
= argmax (Pr(D = P |A = A, S = [s1, s2], C = T ) Pr(C = T |A = A, S = [s1, s2])
A=A1 orA=A2
+ Pr(D = P |A = A, S, C = F ) Pr(C = F |A = A, S = [s1, s2])) · Pr(A = A|S = [s1, s2]) = argmax (Pr(D = P |A = A, S = [s1, s2], C = T ) · h(S = [s1, s2], A = A)
A=A1 orA=A2
+ Pr(D = P |A = A, S = [s1, s2], C = F ) · (1 − h(S = [s1, s2], A = A))) · Pr(A = A|S = [s1, s2])
Under our assumptions of β2(β1−1(s2)) > β1(β2−1(s2)) and f1(s1)f2(s2) > f2(s1)f1(s2), paper 1 has higher estimated quality under A1 and paper 2 has higher estimated quality under A2. Suppose paper 1 is accepted, i.e., D = P1. The value of the above expression under A = A1 is
(Pr(D = P1|A = A1, S = [s1, s2], C = T ) · h(S = [s1, s2], A = A1) + Pr(D = P1|A = A1, S = [s1, s2], C = F ) · (1 − h(S = [s1, s2], A = A1))) · Pr(A = A1|S = [s1, s2]) =(q1 + 0) · f1(s1)f2(s2) =f1(s1)f2(s2)q1.
On the other hand, suppose paper 1 is accepted, the value of the above expression under A = A2 is
(Pr(D = P1|A = A2, S = [s1, s2], C = T ) · h(S = [s1, s2], A = A2) + Pr(D = P1|A = A2, S = [s1, s2], C = F ) · (1 − h(S = [s1, s2], A = A2))) · Pr(A = A2|S = [s1, s2]) =(0 + (1 − q2)) · f1(s1)f2(s2) =f2(s1)f1(s2)(1 − q2).

20

Therefore, when the conference accepts paper 1, if f1(s1)f2(s2)q1 > f2(s1)f1(s2)(1 − q2), then the adversary guesses A = A1. Otherwise, it guesses A = A2 except that when f1(s1)f2(s2)q1 = f2(s1)f1(s2)(1 − q2), it makes a random guess assigning probability 21 to each assignment. Similarly, if paper 2 is accepted, the adversary compares f1(s1)f2(s2)(1 − q1) and f2(s1)f1(s2)q2 where it guesses A = A1 when f1(s1)f2(s2)(1 − q1) > f2(s1)f1(s2)q2. There are 2 papers and 2 possible assignments, so we have 4 scenarios combining decisions and assignments.
1. Scenario 1: A = A1 and D = P1 This scenario happens with probability Pr(A = A1, D = P1|S = [s1, s2]) = f1(s1)ff12((ss12))f+2f(2s(2s)1q1)f1(s2) . In this scenario, the adversary guesses wrong if f1(s1)f2(s2)q1 < f2(s1)f1(s2)(1 − q2).
2. Scenario 2: A = A1 and D = P2 This scenario happens with probability Pr(A = A1, D = P2|S = [s1, s2]) = f1(sf11)(fs21()sf22)(+s2f)2((1s−1)qf11)(s2) . In this scenario, the adversary guesses wrong if f1(s1)f2(s2)(1 − q1) < f2(s1)f1(s2)q2.
3. Scenario 3: A = A2 and D = P1 This scenario happens with probability Pr(A = A1, D = P1|S = [s1, s2]) = f1(sf12)(fs21()sf21)(+s2f)2((1s−1)qf21)(s2) . In this scenario, the adversary guesses wrong if f1(s1)f2(s2)q1 > f2(s1)f1(s2)(1 − q2).
4. Scenario 4: A = A2 and D = P2 This scenario happens with probability Pr(A = A1, D = P2|S = [s1, s2]) = f1(s1)ff22((ss12))f+1f(2s(2s)1q2)f1(s2) . In this scenario, the adversary guesses wrong if f1(s1)f2(s2)(1 − q1) > f2(s1)f1(s2)q2.
To compute the error of the adversary, we need to compare f1(s1)f2(s2) and f2(s1)f1(s2). So as in our assumptions, f1(s1)f2(s2) > f2(s1)f1(s2). From the above 4 scenarios, 2 of them compare f1(s1)f2(s2)q1 with f2(s1)f1(s2)(1−q2) and 2 of them compare f1(s1)f2(s2)q1 with f1(s1)f2(s2)−f2(s1)f1(s2)q2. To analyze the error of the adversary, we consider 5 cases of the value of f1(s1)f2(s2)q1 separated by f2(s1)f1(s2)(1 − q2) and f1(s1)f2(s2) − f2(s1)f1(s2)q2. For each case, we refer to the 4 scenarios of (A, D) above. Also note that EC ([s1, s2]) = 1 − f1f(s11(s)f12)f(s22(s)q21)++ff22((ss11))ff11((ss22))q2 as computed above.
• If f1(s1)f2(s2)q1 < f2(s1)f1(s2) − f2(s1)f1(s2)q2, the adversary guesses wrong in scenarios 1 and 4. Error of the adversary EA([s1, s2]) is f1f(s11(s)f12)f(s22(s)q21)++ff22((ss11))ff11((ss22))q2 . Since EC ([s1, s2]) = 1− f1f(s11(s)f12)f(s22(s)q21)++ff22((ss11))ff11((ss22))q2 , the relation between error of the adversary and error of the conference is EA([s1, s2]) = 1 − EC ([s1, s2]). For 0 ≤ f1(s1)f2(s2)q1 < f2(s1)f1(s2) − f2(s1)f1(s2)q2, EC ([s1, s2]) ∈ ( f1(s1)ff21((ss21))+ff22((ss21))f1(s2) , 1].
• If f1(s1)f2(s2)q1 = f2(s1)f1(s2) − f2(s1)f1(s2)q2, the adversary makes random guess in scenarios 1 and 3 and guesses wrong in scenario 4. Error of the adversary EA([s1, s2]) is f1(s1)ff22((ss21))+ff12((ss21))f1(s2) and error of the conference EC ([s1, s2]) is . f1 (s1 )f2 (s2 )
f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )
• If f2(s1)f1(s2) − f2(s1)f1(s2)q2 < f1(s1)f2(s2)q1 < f1(s1)f2(s2) − f2(s1)f1(s2)q2, the adversary guesses wrong in scenarios 3 and 4. Error of the the adversary EA([s1, s2]) is f1(s1)ff22((ss21))+ff12((ss21))f1(s2) , which is constant. In this case, since error of the conference EC ([s1, s2]) = 1 − f1f(s11(s)f12)f(s22(s)q21)++ff22((ss11))ff11((ss22))q2 , we can ﬁnd that EC ([s1, s2]) ranges from ( f1(s1)ff22((ss21))+ff12((ss21))f1(s2) to f1(s1)ff21((ss21))+ff22((ss21))f1(s2) ).
• If f1(s1)f2(s2)q1 = f1(s1)f2(s2) − f2(s1)f1(s2)q2, the adversary makes random guess in scenarios 2 and 4 and guesses wrong in scenario 3. Error of the adversary EA([s1, s2]) is f1(s1)ff22((ss21))+ff12((ss21))f1(s2) and error of the conference EC ([s1, s2]) is also f1(s1)ff22((ss21))+ff12((ss21))f1(s2) .
21

Error of the adversary

' %+'

'

0.5

%+'

Error of the 1 conference

(a) Maximum per-instance error of the adversary given perinstance error of the conference when u > v.

% %+'

Error of the adversary

%

0.5

%+'

Error of the 1 conference

(b) Maximum per-instance error of the adversary given perinstance error of the conference when u ≤ v

Figure 4: Relation between error of the adversary and error of the conference with u = f1(s1)f2(s2) and v = f2(s1)f1(s2).

• If f1(s1)f2(s2)q1 > f1(s1)f2(s2) − f2(s1)f1(s2)q2, the adversary guesses wrong in scenarios 2 and 3.
Error of the adversary EA([s1, s2]) is 1 − f1f(s11(s)f12)f(s22(s)q21)++ff22((ss11))ff11((ss22))q2 , which is the same as the error of the conference EC ([s1, s2]). The relation between error of the adversary and error of the conference is EA([s1, s2]) = EC ([s1, s2]). For 1 ≥ f1(s1)f2(s2)q1 > f1(s1)f2(s2) − f2(s1)f1(s2)q2, EC ([s1, s2]) ∈ [0, f1(s1)ff22((ss21))+ff12((ss21))f1(s2) ).
Therefore, the relation between error of the adversary and error of the conference when f1(s1)f2(s2) > f2(s1)f1(s2) is of the shape of a trapezoid in [0, 1] with the three line segments of the slope +1, 0, and -1 as in Figure 4a. Note that the relation between the per-instance errors does not change with the relation between values of f1(s1)f2(s2) and f2(s1)f1(s2). So Figure 4a is the relation between the errors when u > v. Similarly, Figure 4b is the relation between the errors when u ≤ v.
From Figure 4 we see that the conference should keep its per-instance error less than minu{+uv,v} to stay optimal. Because if the error of the conference is greater than minu{+uv,v} , increasing its error does not increase the error of the adversary and thus is not optimal. Thus, the Pareto frontier of per-instance error of the adversary against error of the conference is the ﬁrst line segment with slope 1 in both Figure 4a and Figure 4b when min{β2(β1−1(s2)), β1(β2−1(s2))} < s1 < max{β2(β1−1(s2)), β1(β2−1(s2))}.
C.3 Proof of Theorem 4.3
We prove that Algorithm 1 is optimal for each instance of scores S = [s1, s2] with desired error of the conference EC ([s1, s2]) in the noiseless setting.

22

From Theorem 4.2 we know that if a paper has higher estimated quality under both assignments, the

conference should accept the paper. This is the optimal calibration strategy for the conference.

Otherwise

when

min{β

2

(β

− 1

1

(s2

))

,

β1

(β

− 2

1

(s2

))

}

<

s1

<

max

{β

2

(β

− 1

1

(s2

))

,

β1

(β

− 2

1

(

s2

))

},

we

use

the

Pareto frontier in Theorem 4.2 to explain the optimality of our algorithm. Suppose f1(s1)f2(s2) ≤ f2(s1)f1(s2),

then the endpoint on the Pareto frontier has both error of the conference and error of the adversary being

f1(s1)ff21((ss21))+ff22((ss21))f1(s2) . If EC ([s1, s2]) < f1(s1)ff21((ss21))+ff22((ss21))f1(s2) , we maximize the error of the adversary by operating on the Pareto frontier. If EC ([s1, s2]) ≥ f1(s1)ff21((ss21))+ff22((ss21))f1(s2) , we operate at the endpoint where

error of the adversary is maximum and error of the conference is no larger than the desired EC ([s1, s2]). The

endpoint is the point with minimum error of the conference such that error of the adversary is maximum.

Therefore, it is optimal for the conference.

Similarly, if f1(s1)f2(s2) > f2(s1)f1(s2), the algorithm is also optimal by maximizing error of the adver-

sary under desired error of the conference following the Pareto frontier. Algorithm 1 follows the procedure

by choosing the corresponding q1 and q2 for each point on the Pareto frontier and thus is optimal for the

conference.

C.4 Proof of Theorem 4.4

Algorithm 1 with EC ([s1, s2]) = 1 operates on the endpoint of the Pareto frontier when min{β2(β1−1(s2)), β1(β2−1(s2))} <

s1

<

max

{β

2

(

β

−1 1

(s2

))

,

β1

(

β

−1 2

(s2

))}

.

We

use

ζ

to

denote

the

error

of

running

Algorithm

1

with

EC ([s1, s2])

=

1 for all [s1, s2]. Then we have Algorithm 2 that has a maximum allowable average-case error of the conference

EC as input.

If EC ≥ ζ, we operate at EC = ζ by running Algorithm 1 with EC ([s1, s2]) = 1. From Theorem 4.3

we know that Algorithm 1 with EC ([s1, s2]) = 1 is Pareto optimal for all score pairs such that the error of

the adversary is maximized and no smaller error of the conference can achieve the same privacy guarantee.

Increasing the error of the conference will not increase the error of the adversary. Thus, it is Pareto optimal

for the allowable average-case error of the conference.
If EC < ζ, the coin toss ensures that the average-case error of the conference is ζ · EζC + 0 · (1 − EζC ) = EC . If we use η to denote the average-case error of the adversary when the conference always calibrates under the true assignment, then the average-case error of the adversary when the conference

runs Algorithm 1 with EC ([s1, s2]) = 1 is ζ + η. Because when the conference always calibrates un-

der

the

true

assignment,

the

adversary

only

makes

error

when

s1

≤

min

{β

2

(

β

−1 1

(s2

)),

β1

(β

− 2

1

(s2

))}

or

s1

≥

max

{β

2

(β

−1 1

(s2

)),

β1

(β

− 2

1

(s2

))}

.

And if the conference adopts Algorithm 1 with EC ([s1, s2]) = 1,

the adversary has error η when s1 ≤ min{β2(β1−1(s2)), β1(β2−1(s2))} or s1 ≥ max{β2(β1−1(s2)), β1(β2−1(s2))}

and

has

error

ζ

when

min

{

β

2

(

β

−1 1

(s2

))

,

β1

(

β

−1 2

(s2

))

}

<

s1

<

max{

β

2

(

β

−1 1

(s2

))

,

β1

(

β

−1 2

(s2

))

}

.

Therefore,

the

average-case

error

of

the

adversary

is

(η

+ ζ) ·

EC ζ

+η

· (1 −

EζC )

=

EC

+ η.

From Theorem 4.3 we know

that when the conference has per-instance error EC, the maximum per-instance error of the adversary is

EC if min{β2(β1−1(s2)), β1(β2−1(s2))} < s1 < max{β2(β1−1(s2)), β1(β2−1(s2))}. In addition, a Pareto optimal strategy when s1 ≤ min{β2(β1−1(s2)), β1(β2−1(s2))} or s1 ≥ max{β2(β1−1(s2)), β1(β2−1(s2))} has error of the

adversary being η and error of the conference being 0. Therefore, for the average-case error of the conference

being EC, the average-case error of the adversary is no larger than EC + η. Therefore Algorithm 2 is Pareto

optimal.

C.5 Proof of Theorem 4.5

To ﬁnd the Pareto frontier of per-instance error of the adversary against per-instance error of the conference

in the noisy setting, we ﬁrst ﬁnd the maximum per-instance error of the adversary given per-instance error

of the conference in this range.

Prior to computing the errors, we compute the posterior distribution of the quality of the papers given the

assignment and scores. We have θ1∗|{S = [s1, s2], A = A1} ∼ N

, a1(s1−b1) σ2
a2+σ2 a2+σ2

and θ1∗|{S = [s1, s2], A =

1

1

A2} ∼ N

, a2(s1−b2) σ2
a2+σ2 a2+σ2

.

Similarly, θ2∗|{S = [s1, s2], A = A1} ∼ N

, a2(s2−b2) σ2
a2+σ2 a2+σ2

2

2

2

2

and θ2∗|{S =

23

[s1, s2], A = A2} ∼ N a1a(21s+2−σb21) , a21σ+2σ2 . We show calculation for one of the posterior distribution. Note that in continuous space, the probability is taken as the density of the corresponding distribution.
Pr(θ1∗ = t|S = [s1, s2], A = A1) = Pr(S = [s1, s2]|θ1∗ = t, A = A1) · Pr(θ1∗ = t|A = A1)
Pr(S = [s1, s2]|A = A1)

Then we separately compute each term in the equation above. Note that s1|{θ1∗ = t, A = A1} ∼ N (a1t + b1, σ2) and s1|A = A1 ∼ N (b1, a21 + σ2). Since s2 is independent of θ1∗ given that A = A1, s2|{θ1∗ = t, A = A1} and s2|A = A1 have the same distribution. In addition, θ∗ and A are independent.

Pr(S = [s1, s2]|θ1∗ = t, A = A1)

= Pr(S[1] = s1|θ1∗ = t, A = A1) · Pr(S[2] = s2|A = A1)

1

− 1 s1−(a1t+b1) 2

=√ e 2

σ

· Pr(S[2] = s2|A = A1)

2πσ

Pr(θ2∗ = t|A = A1)

1 =√

e

−

1 2

t

2

2π

Pr(S = [s1, s2]|A = A1)

= Pr(S[1] = s1|A = A1) · Pr(S[2] = s2|A = A1)

=√ 2π

1

− 12

e

a21 + σ2

√s1 −b1 a2 +σ2 1

2
· Pr(S[2] = s2|A = A1)

Therefore, combining the terms we get

Pr(θ1∗ = t|S = [s1, s2], A = A1)

√1

e−

1 2

= 2πσ

s1−(a1 t+b1) σ

2

· Pr(S[2] = s2|A = A1) · √1

e

−

1 2

t

2

2π

2

−1

√ √1

2
e

2π a21+σ2

√s1 −b1 a2 +σ2 1

· Pr(S[2] = s2|A = A1)

1 =√
2π

a21 + σ2 e− 12 σ2

√ s1−(a1t+b1) 2+t2− σ

2 s1 −b1
a2 +σ2 1

1 =√
2π

a21

+

σ2

−
e

1 2

σ2

t− a1a(2s+ 1−σ2b1)
1

. 2 a2+σ2

·

1 σ2

The other three posteriors are computed in a similar fashion. Given the posterior distribution of the qualities, we can compute the posterior probability that one paper
has higher quality than the other.

24

Pr(θ1∗ > θ2∗|A = A1, S = [s1, s2])

= Pr N

a1(s1 − b1) σ2

a2 + σ2 , a2 + σ2

1

1

>N

a2(s2 − b2) σ2

a2 + σ2 , a2 + σ2

2

2

a1(s1 − b1) a2(s2 − b2) σ2

σ2

= Pr N a2 + σ2 − a2 + σ2 , a2 + σ2 + a2 + σ2 > 0

1

2

1

2

= Pr

a1(s1 − b1) a2(s2 − b2)

a2 + σ2 − a2 + σ2 +

1

2

σ2

σ2

a2 + σ2 + a2 + σ2 N (0, 1) > 0

1

2

= Pr

N (0, 1) > a2(a21 + σ2)(s2 − b2) − a1(a22 + σ2)(s1 − b1) σ2(a21 + a22 + 2σ2)(a21 + σ2)(a22 + σ2)

=1 − Φ

a2(a21 + σ2)(s2 − b2) − a1(a22 + σ2)(s1 − b1) σ2(a21 + a22 + 2σ2)(a21 + σ2)(a22 + σ2)

We use Φ to denote the cumulative distribution function of standard Gaussian distribution. Similarly, we can compute that

Pr(θ1∗ ≤ θ2∗|A = A1, S = [s1, s2]) = Φ

a2(a21 + σ2)(s2 − b2) − a1(a22 + σ2)(s1 − b1) σ2(a21 + a22 + 2σ2)(a21 + σ2)(a22 + σ2)

Pr(θ1∗ > θ2∗|A = A2, S = [s1, s2]) = 1 − Φ

a1(a22 + σ2)(s2 − b1) − a2(a21 + σ2)(s1 − b2) σ2(a21 + a22 + 2σ2)(a21 + σ2)(a22 + σ2)

Pr(θ1∗ ≤ θ2∗|A = A2, S = [s1, s2]) = Φ

a1(a22 + σ2)(s2 − b1) − a2(a21 + σ2)(s1 − b2) σ2(a21 + a22 + 2σ2)(a21 + σ2)(a22 + σ2)

For simplicity, let Φ1 = Φ

√ a2 (a21 +σ 2 )(s2 −b2 )−a1 (a22 +σ 2 )(s1 −b1 )
σ 2 (a21 +a22 +2σ 2 )(a21 +σ 2 )(a22 +σ 2 )

and Φ2 = Φ

√ . a1(a22+σ2)(s2−b1)−a2(a21+σ2)(s1−b2)
σ 2 (a21 +a22 +2σ 2 )(a21 +σ2 )(a22 +σ 2 )

Since the conference does calibration using the posterior probabilities, the values of Φ1 and Φ2 determines

the conference decision. By Proposition 4.1, we know that the conference should accept the paper with

higher estimated quality under both assignments without any calibration. Therefore, if Φ1 and Φ2 are both

less than 12 , the conference should accept paper 1. Similarly, if Φ1 and Φ2 are both greater than 12 , the

conference

should

accept

paper

2.

Otherwise,

when

Φ1 −

1 2

and

Φ2 −

1 2

have

diﬀerent

signs,

the

conference

should do calibration with function h. As before, since S is a ﬁxed realization in the analysis, we simplify

the calibration strategy for the conference as

q1 = h(S, A1) q2 = h(S, A2).

We ﬁrst consider part (1) of the theorem. If s1 > max a2(aa211+(aσ222+)(σs22)−b2) + b1, a1(aa222+(aσ212+)(σs22)−b1) + b2 ,

which

is

when

Φ1

≤

1 2

and

Φ2

≤

12 ,

the

conference

accepts

paper

1

and

the

adversary

guesses

the

assignment

based on the scores only. Then the error of the conference is the probability that paper 2 has higher quality.

Pr(θ1∗ < θ2∗|S = [s1, s2]) = Pr(θ1∗ < θ2∗|A = A1, S = [s1, s2]) · Pr(A = A1|S = [s1, s2])
+ Pr(θ1∗ < θ2∗|A = A2, S = [s1, s2]) · Pr(A = A2|S = [s1, s2])

=Φ1 ·

f1(s1)f2(s2)

+ Φ2 ·

f2(s1)f1(s2)

f1(s1)f2(s2) + f2(s1)f1(s2)

f1(s1)f2(s2) + f2(s1)f1(s2)

25

Similarly, if s1 < min a2(aa211+(aσ222+)(σs22)−b2) + b1, a1(aa222+(aσ212+)(σs22)−b1) + b2 , which is when Φ1 ≥ 12 and Φ2 ≥ 12 , the conference accepts paper 2 and the error of the conference is the probability that paper 1 has higher
quality.

Pr(θ1∗ > θ2∗|S = [s1, s2]) = Pr(θ1∗ > θ2∗|A = A1, S = [s1, s2]) · Pr(A = A1|S = [s1, s2])
+ Pr(θ1∗ > θ2∗|A = A2, S = [s1, s2]) · Pr(A = A2|S = [s1, s2])

=(1 − Φ1) ·

f1(s1)f2(s2)

+ (1 − Φ2) ·

f2(s1)f1(s2)

f1(s1)f2(s2) + f2(s1)f1(s2)

f1(s1)f2(s2) + f2(s1)f1(s2)

In both cases, error of the adversary is minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} , which is the error when the adversary guesses the assignment based on scores only.
We now consider the rest scores in part (1) of the theorem. If s1 = max a2(aa211+(aσ222+)(σs22)−b2) + b1, a1(aa222+(aσ212+)(σs22)−b1) + b2 , without loss of generality, we assume max a2(aa211+(aσ222+)(σs22)−b2) + b1, a1(aa222+(aσ212+)(σs22)−b1) + b2 = β2(β1−1(s2)), then the conference accepts each paper uniform at random if calibrating under A1 and accepts paper 1 if calibrat-
ing under A2. Since paper 1 has higher or equal quality than paper 2, the conference only has error when
paper 2 is accepted and A = A2.

Pr(conference accepts lower-quality paper|S = [s1, s2])
= Pr(conference accepts lower-quality paper|S = [s1, s2], D = P1) Pr(D = P1|S = [s1, s2])
+ Pr(conference accepts lower-quality paper|S = [s1, s2], D = P2) Pr(D = P2|S = [s1, s2]) = Pr(θ1∗ < θ2∗|S = [s1, s2]) Pr(D = P1|S = [s1, s2])
+ Pr(θ1∗ > θ2∗|S = [s1, s2]) Pr(D = P2|S = [s1, s2]).
Note that in this case, Pr(θ1∗ < θ2∗|S = [s1, s2]) < Pr(θ1∗ > θ2∗|S = [s1, s2]). By similar calculation as in Appendix C.3, we have

1

1

Pr(D = P1|S = [s1, s2]) = 2 (1 − q1) Pr(A = A1|S = [s1, s2]) + 2 q2 Pr(A = A2|S = [s1, s2])

1

1

Pr(D = P2|S = [s1, s2]) = 2 q1 Pr(A = A1|S = [s1, s2]) + 2 (1 − q2) Pr(A = A2|S = [s1, s2]).

Error of the conference is then a convex combination of Pr(θ1∗ < θ2∗|S = [s1, s2]) and Pr(θ1∗ > θ2∗|S = [s1, s2]) and is minimized when the weight of Pr(θ1∗ > θ2∗|S = [s1, s2]) is 0.
For the adversary, if paper 1 is accepted, it gains no information on the assignment other than the scores so its error is minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} . Otherwise, it guesses A = A1 and its error is Pr(A = A2|S = [s1, s2]). Note that error of the adversary does not exceed minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} since in the worst case for the adversary, it guesses the assignment solely based on the scores and ignore the conference decision.

Pr(adversary guesses assignment wrong|S = [s1, s2])

= Pr(adversary guesses assignment wrong|S = [s1, s2], D = P1) Pr(D = P1|S = [s1, s2])

+ Pr(adversary guesses assignment wrong|S = [s1, s2], D = P2) Pr(D = P2|S = [s1, s2])

= min{f1(s1)f2(s2), f2(s1)f1(s2)} (1 − 1 q1) Pr(A = A1|S = [s1, s2]) + ( 1 + 1 q2) Pr(A = A2|S = [s1, s2])

f1(s1)f2(s2) + f2(s1)f1(s2)

2

22

1

1

+ Pr(A = A2|S = [s1, s2]) 2 q1 Pr(A = A1|S = [s1, s2]) + 2 (1 − q2) Pr(A = A2|S = [s1, s2])

26

Therefore, we can minimize the error of the conference to 0 by choosing q1 = 0 and q2 = 1, which results

in the conference always accepts paper 1. Then error of the adversary is minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} , which is

maximized. Further increase of error of the conference cannot increase error of the adversary. So the Pareto

optimal point is (Φ1 · f1(s1)ff21((ss21))+ff22((ss21))f1(s2) + Φ2 · f1(s1)ff22((ss21))+ff12((ss21))f1(s2) , minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} ). The

same argument follows when s1 = min a2(aa211+(aσ222+)(σs22)−b2) + b1, a1(aa222+(aσ212+)(σs22)−b1) + b2 .

We then look at part (2) of the theorem where the scores lie in the region min a2(aa211+(aσ222+)(σs22)−b2) + b1, a1(aa222+(aσ212+)(σs22)−b1) + b2 <

s1 < max a2(aa211+(aσ222+)(σs22)−b2) + b1, a1(aa222+(aσ212+)(σs22)−b1) + b2 . We will then show the proof with the assumptions

that

f1(s1)f2(s2)

<

f2(s1)f1(s2)

and

Φ1

=

1 2

− ϕ1

and

Φ2

=

1 2

+ ϕ2

with

0

<

ϕ2

<

ϕ1.

The

analysis

is

of

the

same

procedure

for

diﬀerent

assumptions

on

the

values

of

f1(s1)f2(s2),

f2(s1)f1(s2),

Φ1

and

Φ2

with

Φ1

−

1 2

and

Φ2 −

1 2

having

diﬀerent

signs.

The

notations

are

of

the

same

meaning

as

in

Section

C.3.

In

the

noisy

set-

ting, even if the conference calibrates under the true assignment, there is still possibility to accept the lower-

quality paper due to the noise in the scores given by the reviewers. Note that with the assumptions and when

min

+ b , + b a2(a21+σ2)(s2−b2)

a1 (a22 +σ 2 )(s2 −b1 )

a1 (a22 +σ 2 )

1

a2 (a21 +σ 2 )

2

< s1 < max

+ b , + b , a2(a21+σ2)(s2−b2)

a1 (a22 +σ 2 )(s2 −b1 )

a1 (a22 +σ2 )

1

a2 (a21 +σ2 )

2

the conference accepts paper 1 if calibrates under A1 and accepts paper 2 if calibrates under A2 by the

assumptions on Φ1 and Φ2. So we have

Pr(conference accepts lower-quality paper|S = [s1, s2])
= Pr(conference accepts P1, θ1∗ < θ2∗|S = [s1, s2]) + Pr(conference accepts P2, θ1∗ > θ2∗|S = [s1, s2]) = Pr(conference accepts P1|θ1∗ < θ2∗, S = [s1, s2]) · Pr(θ1∗ < θ2∗|S = [s1, s2])
+ Pr(conference accepts P2|θ1∗ > θ2∗, S = [s1, s2]) · Pr(θ1∗ > θ2∗|S = [s1, s2]).

We then expand each of the two terms.

Pr(conference accepts P1|θ1∗ < θ2∗, S = [s1, s2])

= Pr(conference accepts P1, A = A1|θ1∗ < θ2∗, S = [s1, s2]) + Pr(conference accepts P1, A = A2|θ1∗ < θ2∗, S = [s1, s2])

= Pr(conference accepts P1|A = A1, θ1∗ < θ2∗, S = [s1, s2]) · P (A = A1|θ1∗ < θ2∗, S = [s1, s2])

+ Pr(conference accepts P1|A = A2, θ1∗ < θ2∗, S = [s1, s2]) · Pr(A = A2|θ1∗ < θ2∗, S = [s1, s2])

= Pr(C = T |A = A1, θ1∗ < θ2∗, S = [s1, s2]) Pr(A = A1|θ1∗ < θ2∗, S = [s1, s2])

+ Pr(C = F |A = A2, θ1∗ < θ2∗, S = [s1, s2]) Pr(A = A2|θ1∗ < θ2∗, S = [s1, s2])

=q1 Pr(A = A1|θ1∗ < θ2∗, S = [s1, s2]) + (1 − q2) Pr(A = A2|θ1∗ < θ2∗, S = [s1, s2])

Pr(A = A1, θ1∗ < θ2∗|S = [s1, s2])

Pr(A = A2, θ1∗ < θ2∗|S = [s1, s2])

=q1 Pr(θ∗ < θ∗|S = [s1, s2]) + (1 − q2) Pr(θ∗ < θ∗|S = [s1, s2])

1

2

1

2

Pr(θ1∗ < θ2∗|A = A1, S = [s1, s2]) · Pr(A = A1|S = [s1, s2])

=q1

Pr(θ∗ < θ∗|S = [s1, s2])

1

2

Pr(θ1∗ < θ2∗|A = A2, S = [s1, s2]) · Pr(A = A2|S = [s1, s2])

+ (1 − q2)

Pr(θ∗ < θ∗|S = [s1, s2])

.

1

2

Similarly,

Pr(conference accepts P2|θ1∗ > θ2∗, S = [s1, s2])

Pr(θ1∗ > θ2∗|A = A1, S = [s1, s2]) · Pr(A = A1|S = [s1, s2])

=(1 − q1)

Pr(θ∗ > θ∗|S = [s1, s2])

1

2

Pr(θ1∗ > θ2∗|A = A2, S = [s1, s2]) · Pr(A = A2|S = [s1, s2])

+ q2

Pr(θ∗ > θ∗|S = [s1, s2])

1

2

27

Therefore, we have

Pr(conference accepts lower-quality paper|S = [s1, s2])

=q1 Pr(θ1∗ < θ2∗|A = A1, S = [s1, s2]) · Pr(A = A1|S = [s1, s2]) + (1 − q2) Pr(θ1∗ < θ2∗|A = A2, S = [s1, s2]) · Pr(A = A2|S = [s1, s2]) + (1 − q1) Pr(θ1∗ > θ2∗|A = A1, S = [s1, s2]) · Pr(A = A1|S = [s1, s2]) + q2 Pr(θ1∗ > θ2∗|A = A2, S = [s1, s2]) · Pr(A = A2|S = [s1, s2])

= f1(s1)f2(s2)

· (q1Φ1 + (1 − q1)(1 − Φ1))

f1(s1)f2(s2) + f2(s1)f1(s2)

+ f2(s1)f1(s2) · ((1 − q2)Φ2 + q2(1 − Φ2)). f1(s1)f2(s2) + f2(s1)f1(s2)

Under

the

assumptions

that

Φ1

=

1 2

− ϕ1

and

Φ2

=

1 2

+ ϕ2

where

0

<

ϕ2

<

ϕ1

and

f1(s1)f2(s2)

<

f2(s1)f1(s2), we analyze the per-instance error of the adversary similar to the procedure in Section C.2.

There are 4 scenarios combining the decision and the true assignment.

1. Scenario 1: A = A1 and D = P1
This scenario happens with probability Pr(A = A1, D = P1|S = [s1, s2]) = f1(s1)ff12((ss12))f+2f(2s(2s)1q1)f1(s2) . In this scenario, the adversary guesses wrong if q1f1(s1)f2(s2) < (1 − q2)f2(s1)f1(s2).

2. Scenario 2: A = A1 and D = P2
This scenario happens with probability Pr(A = A1, D = P1|S = [s1, s2]) = f1(sf11)(fs21()sf22)(+s2f)2((1s−1)qf11)(s2) . In this scenario, the adversary guesses wrong if (1 − q1)f1(s1)f2(s2) < q2f2(s1)f1(s2).

3. Scenario 3: A = A2 and D = P1
This scenario happens with probability Pr(A = A1, D = P1|S = [s1, s2]) = f1(sf12)(fs21()sf21)(+s2f)2((1s−1)qf21)(s2) . In this scenario, the adversary guesses wrong if q1f1(s1)f2(s2) > (1 − q2)f2(s1)f1(s2).

4. Scenario 4: A = A2 and D = P2
This scenario happens with probability Pr(A = A1, D = P1|S = [s1, s2]) = f1(s1)ff22((ss12))f+1f(2s(2s)1q2)f1(s2) . In this scenario, the adversary guesses wrong if (1 − q1)f1(s1)f2(s2) > q2f2(s1)f1(s2).

To compute the error of the adversary, we need to compare f1(s1)f2(s2) and f2(s1)f1(s2). So we suppose f1(s1)f2(s2) < f2(s1)f1(s2). From the above 4 scenarios, 2 of them compare f1(s1)f2(s2)q1 with f2(s1)f1(s2)(1 − q2) and 2 of them compare f1(s1)f2(s2)q1 with f1(s1)f2(s2) − f2(s1)f1(s2)q2. To analyze the error of the adversary, we consider 5 cases of the value of f1(s1)f2(s2)q1 separated by f2(s1)f1(s2)(1 − q2) and f1(s1)f2(s2) − f2(s1)f1(s2)q2. We refer to the 4 scenarios of (A, D) above.

• If q1f1(s1)f2(s2) < f1(s1)f2(s2) − q2f2(s1)f1(s2), the adversary guesses wrong in scenarios 1 and 4. Error of the adversary EA([s1, s2]) is q1ff11((ss11))ff22((ss22))++fq22f(s21(s)f11)f(s12(s)2) .

• If q1f1(s1)f2(s2) = f1(s1)f2(s2) − q2f2(s1)f1(s2), the adversary makes random guess in scenarios 2

and 4 and guesses wrong in scenario 1. Error of the adversary EA([s1, s2]) is f1(s1)qf12f(1s(2s)1+)ff22((ss12))f1(s2) +

( + ) = . 1

(1−q1 )f1 (s1 )f2 (s2 )

2 f1(s1)f2(s2)+f2(s1)f1(s2)

q2 f2 (s1 )f1 (s2 ) f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

f1 (s1 )f2 (s2 ) f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

• If f1(s1)f2(s2) − q2f2(s1)f1(s2) < q1f1(s1)f2(s2) < f2(s1)f1(s2) − q2f2(s1)f1(s2), the adversary guesses wrong in scenarios 1 and 2. Error of the adversary EA([s1, s2]) is f1(s1)ff21((ss21))+ff22((ss21))f1(s2) .

• If q1f1(s1)f2(s2) = f2(s1)f1(s2) − q2f2(s1)f1(s2), the adversary makes random guess in scenarios 1

and 3 and guesses wrong in scenario 2. Error of the adversary EA([s1, s2]) is f1(s(11)−f2q(1s)2f)1+(sf12)(fs21()sf21)(s2) +

( + ) = . 1

q1 f1 (s1 )f2 (s2 )

2 f1(s1)f2(s2)+f2(s1)f1(s2)

(1−q2 )f2 (s1 )f1 (s2 ) f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

f1 (s1 )f2 (s2 ) f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

28

• If q1f1(s1)f2(s2) > f2(s1)f1(s2) − q2f2(s1)f1(s2), the adversary guesses wrong in scenarios 2 and 3. Error of the adversary EA([s1, s2]) is 1 − q1ff11((ss11))ff22((ss22))++fq22f(s21(s)f11)f(s12(s)2) .
To ﬁnd the maximum error of the adversary given error of the conference, we solve an optimization problem. In order to formulate the optimization problem, we can combine the 5 cases above into 3 cases for simplicity.

• If q1f1(s1)f2(s2) ≤ f1(s1)f2(s2)−q2f2(s1)f1(s2), error of the adversary EA([s1, s2]) is q1ff11((ss11))ff22((ss22))++qf22f(s21(s)f11)f(s12(s)2) .
• If f1(s1)f2(s2) − q2f2(s1)f1(s2) ≤ q1f1(s1)f2(s2) ≤ f2(s1)f1(s2) − q2f2(s1)f1(s2), error of the adversary EA([s1, s2]) is f1(s1)ff21((ss21))+ff22((ss21))f1(s2) .

• If q1f1(s1)f2(s2) ≥ f2(s1)f1(s2)−q2f2(s1)f1(s2), error of the adversary EA([s1, s2]) is 1− q1ff11((ss11))ff22((ss22))++qf22f(s21(s)f11)f(s12(s)2) .

We let T (EC ) = EC (u + v) − u · (1 − Φ1) − v · Φ2 to be a function that takes the error of the conference as input.

• Maximize q1ff11((ss11))ff22((ss22))++fq22f(s21(s)f11)f(s12(s)2) subject to EC ([s1, s2])(f1(s1)f2(s2) + f2(s1)f1(s2)) − f1(s1)f2(s2) · (1 − Φ1) − f2(s1)f1(s2) · Φ2 = f1(s1)f2(s2)(2Φ1 − 1)q1 + f2(s1)f1(s2) · (1 − 2Φ2)q2 and q1f1(s1)f2(s2) ≤ f1(s1)f2(s2) − q2f2(s1)f1(s2).
The maximum occurs at q1f1(s1)f2(s2) = f1(s1)f2(s2) − q2f2(s1)f1(s2). Then the intersection of the two lines is q1 = 1 − (2Φ1−(21Φ)u1−+T2Φ(E2C−(2[)su1,s2])) and q2 = (2Φ1−(21Φ)u1−+T2Φ(E2C−(2[s)v1,s2])) .

– If the intersection point can be reached, q1, q2 ∈ [0, 1], (2Φ1 − 1)u ≤ T (EC ([s1, s2])) ≤ (1 − 2Φ2)u,

then error of the conference EC ([s1, s2]) ranges from f1(s1)ff12((ss12))f+2(fs22()sΦ1)1f1(s2) + f1(s1)ff22((ss12))f+1(fs22()sΦ1)2f1(s2)

to + . f1(s1)f2(s2)(2−Φ1−2Φ2)
f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

f2 (s1 )f1 (s2 )Φ2 f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

Error of the adversary EA([s1, s2]) is f1(s1)ff21((ss21))+ff22((ss21))f1(s2) .

– If the intersection point can not be reached and T (EC ([s1, s2])) < (2Φ1 − 1)u, then no q1, q2 are qualiﬁed for the constraints.

– If the intersection point can not be reached and T (EC ([s1, s2])) > (1 − 2Φ2)u.

∗ If (1 − 2Φ2)u < T (EC ([s1, s2])) ≤ 0 then the maximum is reached when q1 = 0 and q2 = T ((E1C−(2[sΦ12,s)v2])) .

Error

of

the

conference

EC ([s1, s2])

ranges

from

(2−Φ1 −2Φ2 )u+Φ2 v u+v

(when

T (EC ([s1, s2]))

=

(1 − 2Φ2)u)

to

(1−Φ1 )u+Φ2 v u+v

(when

T (EC ([s1, s2])) = 0).

Error of the adversary EA([s1, s2]) is (T1(−E2CΦ([2s)1(,us+2]v))) , ranges from u+u v (when T (EC ([s1, s2])) =

(1 − 2Φ2)u) to 0 (when T (EC ([s1, s2])) = 0).

∗ If T (EC ([s1, s2])) > 0 then no q1, q2 are qualiﬁed for the constraints.

• Error of the adversary EA([s1, s2]) is f1(s1)ff21((ss21))+ff22((ss21))f1(s2) subject to f1(s1)f2(s2) − q2f2(s1)f1(s2) ≤ q1f1(s1)f2(s2) ≤ f2(s1)f1(s2) − q2f2(s1)f1(s2).

From Figure 5 we can see that error of the conference EC ([s1, s2]) has its extremes at q1 = 0, q2 =

u v

and

q1

=

1, q2

=

1−

uv .

Therefore, error of the conference ranges from (2−Φ1−u2+Φv2)u+Φ2v to

(Φ1+2Φ2−u1+)uv+(1−Φ2)v .

• Maximize 1− q1ff11((ss11))ff22((ss22))++qf22f(s21(s)f11)f(s12(s)2) subject to EC ([s1, s2])(f1(s1)f2(s2)+f2(s1)f1(s2))−f1(s1)f2(s2)· (1 − Φ1) − f2(s1)f1(s2) · Φ2 = f1(s1)f2(s2)(2Φ1 − 1)q1 + f2(s1)f1(s2) · (1 − 2Φ2)q2 and q1f1(s1)f2(s2) ≥ f2(s1)f1(s2) − q2f2(s1)f1(s2).
The maximum occurs at q1f1(s1)f2(s2) = f2(s1)f1(s2) − q2f2(s1)f1(s2). Then the intersection of the two lines is q1 = (1−2Φ(22−)v2−ΦT1−(E2CΦ(2[s)u1,s2])) and q2 = T (EC((2[s−12,sΦ21])−)−2Φ(22Φ)v1−1)v .

29

!!
1
% '

Line to maximize/minimize intersection

'

!"

1%

Figure 5: A diagram illustrates the optimization problem in this case.

– If the intersection point can be reached, q1, q2 ∈ [0, 1], (1 − 2Φ2)v − (2 − 2Φ1 − 2Φ2)u ≤ T (EC ([s1, s2])) ≤ (1−2Φ2)v, then error of the conference EC ([s1, s2]) ranges from f1(sf11)(fs21()sf22)(+s2f)2((1s−1)Φf11)(s2) + f1(sf12)(fs21()sf21)(+s2f)2((1s−1)Φf21)(s2) (when T (EC ([s1, s2])) = (1−2Φ2)v) to ff11((ss11))ff22((ss22))+(Φf21(+s21)Φf21−(s12)) + f1(sf12)(fs21()sf21)(+s2f)2((1s−1)Φf21)(s2) (when T (EC ([s1, s2])) = (1 − 2Φ2)v − (2 − 2Φ1 − 2Φ2)u).
Error of the adversary EA([s1, s2]) is f1(s1)ff21((ss21))+ff22((ss21))f1(s2) .
– If the intersection point can not be reached and T (EC ([s1, s2])) > (1 − 2Φ2)v, then no q1, q2 are qualiﬁed for the constraints.

– If the intersection point can not be reached and T (EC ([s1, s2])) < (1 − 2Φ2)v − (2 − 2Φ1 − 2Φ2)u.

∗ If (2Φ1 −1)u+(1−2Φ2)v ≤ T (EC ([s1, s2])) < (1−2Φ2)v −(2−2Φ1 −2Φ2)u then the maximum

is reached when q1 = 1 and q2 = T (EC ([s1(1,s−22])Φ)−2)(v2Φ1−1)u .

Error

of

the

conference

EC ([s1, s2])

ranges

from

(Φ1 +2Φ2 −1)u+(1−Φ2 )v u+v

(when

T (EC ([s1, s2]))

=

(1−2Φ2)v−(2−2Φ1 −2Φ2)u)

to

Φ1 u+(1−Φ2 )v u+v

(when

T (EC ([s1, s2]))

=

(2Φ1 −1)u+(1−2Φ2)v).

Error of the adversary EA([s1, s2]) is 1 − T (EC ([s1(,1s−2]2)Φ)+2()2(u−+2vΦ)1−2Φ2)u , ranges from u+u v (when

T (EC ([s1, s2])) = (1 − 2Φ2)v − (2 − 2Φ1 − 2Φ2)u) to 0 (when T (EC ([s1, s2])) = (2Φ1 − 1)u +

(1 − 2Φ2)v).

∗ If T (EC ([s1, s2])) < (2Φ1 − 1)u + (1 − 2Φ2)v then no q1, q2 are qualiﬁed for the constraints.

Therefore,

the

relation

between

error

of

the

adversary

and

error

of

the

conference

when

Φ1

=

1 2

− ϕ1

and

Φ2

=

1 2

+ ϕ2

where

0

<

ϕ2

<

ϕ1

and

f1(s1)f2(s2)

<

f2(s1)f1(s2)

is

of

the

shape

of

a

trapezoid

in

[0, 1]

as

in

Figure 6. Note that the relation between the per-instance errors does not change with the relation between

values of f1(s1)f2(s2) and f2(s1)f1(s2) or with the values of Φ1 and Φ2.
From Figure 6 we see that the conference should keep its per-instance error between uΦ1+uv+(1v−Φ2) and u(Φ1+2Φ2u−+1v)+v(1−Φ2) to stay optimal. The conference cannot have its error less than uΦ1+uv+(1v−Φ2) due to the reviewers’ noise. If error of the conference is greater than u(Φ1+2Φ2u−+1v)+v(1−Φ2) , increasing its error does not increase error the adversary and thus is not optimal. Thus, the Pareto frontier of per-instance error of

the adversary against error of the conference is the ﬁrst line segment with positive slope in Figure 6 when

min

+ b , + b a2(a21+σ2)(s2−b2)

a1 (a22 +σ 2 )(s2 −b1 )

a1 (a22 +σ 2 )

1

a2 (a21 +σ 2 )

2

< s1 < max

+ b , + b . a2(a21+σ2)(s2−b2)

a1 (a22 +σ 2 )(s2 −b1 )

a1 (a22 +σ 2 )

1

a2 (a21 +σ 2 )

2

30

Error of the adversary

% %+'

1

2 0.5 3

4 Error of the

conference

Figure 6: Maximum per-instance error of the adversary given per-instance error of the conference when

u

<

v,

Φ1

=

1 2

− ϕ1

and

Φ2

=

1 2

+ ϕ2

with

0

<

ϕ2

<

ϕ1.

The

coordinates

in

the

plot

are:

○1

=

uΦ1+uv+(1v−Φ2) ,

○2 = u(Φ1+2Φ2u−+1v)+v(1−Φ2) , ○3 = u(2−Φ1−u+2Φv 2)+vΦ2 , ○4 = u(1−uΦ+1)v+vΦ2 .

C.6 Proof of Theorem 4.6

We prove that Algorithm 3 is optimal for each instance of scores S = [s1, s2] with desired error of the

conference

EC ([s1, s2])

in

the

noisy

setting.

We

carry

the

assumptions

from

Section

C.5

that

Φ1

=

1 2

− ϕ1

and

Φ2

=

1 2

+

ϕ2

where

0

<

ϕ2

<

ϕ1

and

f1(s1)f2(s2)

<

f2(s1)f1(s2).

From Proposition 4.1 we know that if a paper has higher estimated quality under both assignments, the

conference should accept the paper. This is the optimal calibration strategy for the conference.
Otherwise when the scores are in the region min a2(aa211+(aσ222+)(σs22)−b2) + b1, a1(aa222+(aσ212+)(σs22)−b1) + b2 < s1 < max a2(aa211+(aσ222+)(σs22)−b2) + b1, a1(aa222+(aσ212+)(σs22)−b1) + b2 , we use the Pareto frontiers analyze the optimality of our algorithm. Theorem 4.5 shows that the Pareto frontier in the noiseless setting within this region. The

analysis is similar to the one in the noiseless setting in Section C.3.

Suppose f1(s1)f2(s2) < f2(s1)f1(s2), then the endpoint on the Pareto frontier has error of the adversary being f1(s1)ff21((ss21))+ff22((ss21))f1(s2) and error of the conference being f1(s1)f2(Φf11+(s21Φ)f22−+1f)+2(fs21()sf11)(fs12()s2)(1−Φ2) . If f1(s1f)f12(s(1s2)f)Φ2(1s+2)f+2(fs21()sf11)(fs12()s(21)−Φ2) ≤ EC ([s1, s2]) < f1(s1)f2(sf21)((Φs11)+f22(Φs22−)+1f)+2(fs21()sf11)(fs12()s2)(1−Φ2) , we maximize the error of the adversary by operating on the Pareto frontier. If EC ([s1, s2]) ≥ f1(s1)f2(sf21)((Φs11)+f22(Φs22−)+1f)+2(fs21()sf11)(fs12()s2)(1−Φ2) , we operate at the endpoint where error of the adversary is maximum and error of the conference is no larger

than the desired EC ([s1, s2]). The endpoint is the point with minimum error of the conference such that

error of the adversary is maximum. Therefore, it is optimal for the conference.

Algorithm 3 follows the procedure by choosing the corresponding q1 and q2 for each point on the Pareto

frontier and thus is optimal for the conference.

31

