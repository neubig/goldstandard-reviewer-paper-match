arXiv:2111.09459v2 [math.PR] 9 May 2022

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS
SEWOONG OH, SOUMIK PAL, RAGHAV SOMANI, AND RAGHAVENDRA TRIPATHI
Abstract. Wasserstein gradient ﬂows on probability measures have found a host of applications in various optimization problems. They typically arise as the continuum limit of exchangeable particle systems evolving by some mean-ﬁeld interaction involving a gradienttype potential. However, in many problems, such as in multi-layer neural networks, the so-called particles are edge weights on large graphs whose nodes are exchangeable. Such large graphs are known to converge to continuum limits called graphons as their size grow to inﬁnity. We show that the Euclidean gradient ﬂow of a suitable function of the edgeweights converges to a novel continuum limit given by a curve on the space of graphons that can be appropriately described as a gradient ﬂow or, more technically, a curve of maximal slope. Several natural functions on graphons, such as homomorphism functions and the scalar entropy, are covered by our set-up, and the examples have been worked out in detail.

1. Introduction
Let x1, x2, . . . , xn be n vectors in Rd. Let fn : Rd n → R be a permutation invariant function of those n variables. Here permutation invariant means fn(x1, . . . , xn) = fn(xπ1, . . . , xπn) where π is any permutation of the set [n] := {1, 2, . . . , n}. Throughout this text we will denote the symmetric group on the ﬁnite set [n] as Sn. Consider the Cauchy problem

(1)

x˙ i(t) = −∇ifn(x1(t), . . . , xn(t)), i ∈ [n],

with given initial conditions xi(0), i ∈ [n]. Here ∇i refers to the partial derivative with respect to the i-th variable. The solution of this problem (which exists and is unique when, say, ∇fn is Lipschitz) is often called the gradient ﬂow of fn. A natural question that appears in several applications is whether the solution to the above Cauchy problem has a scaling limit as n goes to inﬁnity.

Sewoong Oh, Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle WA 98195, USA, Email: sewoong@cs.washington.edu
Soumik Pal, Department of Mathematics, University of Washington, Seattle WA 98195, USA, Email: soumikpal@gmail.com
Raghav Somani, Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle WA 98195, USA, Email: raghavs@cs.washington.edu
Raghavendra Tripathi, Department of Mathematics, University of Washington, Seattle WA 98195, USA, Email: raghavt@uw.edu
Date: May 11, 2022. 2000 Mathematics Subject Classiﬁcation. 05C60,05C80,68R10,60K35. Key words and phrases. gradient ﬂows, graphons, optimal transport, exchangeability. This research is partially supported by the following grants. Pal is supported by NSF grant DMS-2052239 and a PIMS CRG (PIHOT). Pal and Oh are supported by NSF grant DMS-2134012. Oh is supported by NSF grant CCF-2019844. Many thanks to Persi Diaconis and Stefan Steinerberger for helpful conversations and references and the PIMS Kantorovich Initiative for facilitating this collaboration. The authors are listed in alphabetical order.
1

2 GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS

In order for such a limit to exist, it is imperative that there is some consistency over the

dimension parameter n. The permutation invariance of fn oﬀers a resolution. In fact, if xi,

i ∈ [n], is thought of as positions of particles in space, fn can be thought of as a function

acting

on

the

empirical

distribution

µn

:=

1 n

n i=1

δxi

.

Here µn is a discrete probability

measure that puts mass 1/n on the positions of each of the n particles, represented by the

delta mass δ·.

For any metric space (Ω, d), denote its Borel sigma algebra as B(Ω) and the set of all

Borel probability measures as P(Ω). Consider Rd with the usual Euclidean metric and let

F : P(Rd) → R be a suitable function. The function F induces a sequence of permutation

invariant functions fn as above by the deﬁnition

fn (x1, . . . , xn) := F (µn) , n ∈ N .

For such an fn, the evolution (1) can be thought of as an evolution on the space of probability

measures by deﬁning

1n µn(t) := n δxi(t),
i=1

t≥0.

Now the following question makes sense. Suppose that the sequence of initial measures µn(0) converges to a limiting probability measure µ(0) where the convergence is typically in the
sense of weak convergence of probability measures. Does the sequence of curves (µn(t), t ≥ 0) converge to some limiting curve on P(Rd) possibly after rescaling time?
The answer to the above, under suitable assumptions on F , is the so-called Wasserstein gradient ﬂow [Vil03, San15] of F on the metric space P Rd equipped with the Wasserstein-2 metric, W2. There is now a general theory of curves of maximal slopes (AKA gradient ﬂows) developed for functions on metric spaces which may lack a diﬀerentiable structure [AGS08].
The Wasserstein space is a prominent example that has been thoroughly studied [AGS08,
San17]. Recently there has been a surge in interest in the application of the above convergence
of gradient ﬂows in the context of single hidden layer neural networks, see [SMN18, CB18,
RVE18, SMM19, CCP19, AOY19, NP20, SS20a, SS20b, TR20, BC21].
However, we are interested in optimization problems where the arguments can be thought
of as weights attached to the edges of a large dense graph. Let G = (V, E) be a graph
with |V | = n many vertices, labeled by [n]. For {i, j} ∈ E one has an associated variable
Wij = Wji that we take it to be real-valued in this article. For all the applications we consider, we can take Wij = 0 if {i, j} ∈ E. Thus our variables can be arranged in an n × n symmetric matrix (Wij, i, j ∈ [n]). The set of n × n matrices will be denoted by R[n](2). Now let fn : R[n](2) → R ∪ {∞} be a function of such matrices. The crucial diﬀerence from the previous set-up is that we want fn to satisfy a permutation invariance property with respect to relabeling the vertices of G: for every π ∈ Sn,

fn Wπiπj , i, j ∈ [n] = fn (Wij, i, j ∈ [n]) .

That is, the function value does not change if we permute the rows and the columns of the matrix (Wij, i, j ∈ [n]) by the same permutation. In other words, such functions are invariant under graph isomorphisms of G. We call such functions invariant. One can now ask the same question as before. Consider the gradient ﬂow Cauchy problem

(2)

W˙ ij(t) = −∇ijfn (Wij(t), i, j ∈ [n]) , i, j ∈ [n] ,

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS 3
with given (Wij(0), i, j ∈ [n]). Is there a suitable scaling limit as n goes to inﬁnity? The objective of this paper is to provide conditions for which the answer is yes.
We restrict ourselves to the case where the edge weights (Wij, i, j ∈ [n]) all lie in the bounded interval [−1, 1]. Without loss of generality, we can take our graph to be the complete graph with its weighted adjacency matrix (Wij, i, j ∈ [n]). Just like empirical distributions of particle systems converge to probability measures, these graph adjacency matrices with bounded edge weights, identiﬁed up to graph isomorphisms, converge to a limiting object called graphons [LS06, BCL+08, BCL+12]. This is intimately connected with the theory of exchangeable arrays in probability theory [Ald81, Ald82, Hoo82, Kal89]. For a deﬁnitive modern account of exchangeable arrays and their connections with the limits of large graphs, the reader is referred to [DJ08, Aus08, Aus12, Aus15]. The theory of graph limits and graphons has found applications in many ﬁelds including extremal graph theory, combinatorics, data analysis, biology. We refer the reader to [DGKR15, LZ17, BG20, BEFLY21] and references therein for further details.
Let us deﬁne graphons rigorously. A kernel is a Borel measurable function W : [0, 1](2) → [−1, 1] that is symmetric, i.e., W (x, y) = W (y, x). Two kernels are identiﬁed if they are equal almost everywhere. We will denote the set of all kernels by W. Let U, V ∈ W. We say U ∼= V if there exists a measure preserving transform ϕ and ψ on [0, 1] and a kernel W such that U (x, y) = W (ϕ(x), ϕ(y)) and V (x, y) = W (ψ(x), ψ(y)) almost everywhere.
Deﬁnition 1.1 (Graphons). Equivalence class of functions in W under (∼=) are called graphons and we denote the set of graphons by W := W/∼=.
For a kernel W ∈ W, we denote its equivalence class as [W ] := {U ∈ W | U ∼= W }. See Section 2 for more details. The set of graphons W will be endowed with two diﬀerent metrics. One, called the invariant L2 metric [Lov12, Jan16, BCCH18], δ2, plays a similar role as the W2 metric does on probability measures. The metric space (W, δ2) is a geodesic space (Theorem 3.5). Our gradient ﬂows will be with respect to this metric. The other, called the cut metric, δ , is more traditional [BCL+08, Lov12] and is important here for the topology that it generates and will play the role of the metric of weak convergence of probability measures. Thus, although our gradient ﬂows will be deﬁned with respect to the invariant L2 metric δ2, the various convergence statements will be with respect to the cut metric δ .
To state our main results we need a set-up that is similar to particle systems and their limiting probability measures. Every ﬁnite k × k symmetric matrix with entries in [−1, 1] identiﬁed up to the same permutation on rows and columns can be embedded in the space of block graphons Wk ⊆ W (see Section 2 for details). Thus, any function F : W → R ∪ {∞} induces a sequence of functions Fk : Wk → R ∪ {∞}, k ≥ 2, by restriction, and a sequence of invariant functions fk, k ≥ 2 on such k × k symmetric matrices with entries in [−1, 1].
The ﬁrst pertinent question is that given F : W → R ∪ {∞} and [U0] in the proper eﬀective domain eﬀ-Dom(F ) := {[U ] ∈ W | F ([U ]) < ∞} of F (see [AGS08, equation 1.2.1]), under what assumptions on F a “gradient ﬂow” of F on (W, δ2) exists starting at [U0] ∈ W. On a general metric space, a gradient ﬂow curve (i.e., a curve of maximal slope [AGS08, Deﬁnition 1.3.2]) is obtained by showing that the limits of the solutions of implicit Euler iterations (see Section 4) exist and satisfy added assumptions. The existence of the limit of the sequence of

4 GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS

such implicit Euler iterations requires the local slope of F , deﬁned as

(F ([V ]) − F ([W ]))+

(3)

|∂F |([V ]) := lim sup

.

[W ]∈W,

δ2([W ], [V ])

δ2([W ],[V ])→0

In practice, however, evaluating the local slope is not easy. We introduce the concept of Fr´echet-like derivative in Section 4.2 and show that for functions that have Fr´echet-like derivative, the local slope |∂F | admits a more amenable expression in terms of L2-norm of the Fr´echet-like derivative. Moreover, under a λ-semiconvexity assumption, just the existence of Fr´echet-like derivative suﬃces for the existence of a curve of maximal slope (see Theorem 4.14).
Since (W, δ2) is a geodesic space, one can talk about λ-semiconvex functions for λ ∈ R over geodesics and generalized geodesics (see Section 2 and Section 3). Theorem 1.2 shows that
under suitable assumptions on a semiconvex function F , the gradient ﬂow of F on (W, δ2) can be obtained as the time-scaled limit of the Euclidean gradient ﬂows of fk on k × k symmetric
δ
matrices. That is, suppose we have a sequence of block graphons ([Uk,0] ∈ Wk)k∈N −→ [U0] ∈
W and let ω be the gradient ﬂow of F on (W, δ2) starting at [U0] ∈ W. Then the gradient ﬂows ω(k) of Fk starting at [Uk,0] ∈ Wk converges, in δ to ω uniformly over compact intervals. The next argument shows that ω(k) is a time-scaling of the Euclidean gradient ﬂow of fk.
The Euclidean gradient ﬂow of the function fk over k × k symmetric matrices can be approximated via the implicit Euler method. Starting from Wk,τ ∈ [−1, 1][k](2) with a step size of τ > 0, the next iterate of the implicit Euler method, say Wk,τ,+, is obtained as

1

2

(4)

Wk,τ,+ ∈ arg min fk(Wk) + 2τ Wk − Wk,τ 2 .

Wk ∈[−1,1][k](2)

Let K be the natural embedding map from k × k symmetric matrices in [−1, 1][k](2) to the space of block kernels Wk (deﬁnition 2.5). Since the function fk is permutation invariant, setting [Uk,τ ] = [K(Wk,τ )], equation (4) is equivalent to obtaining







k2

1k

2

[Uk] ∈ a[Urkg]∈mWikn Fk([Uk]) + 2τ Wk∈[−m1i,1n][k](2) , k2 i,j=1 (Wk)i,j − (Wk,τ )i,j 

[Uk ]=[K (Wk )]

k2 2

(5)

= arg min Fk([Uk]) + 2τ δ2([Uk], [Uk,τ ]) ,

[Uk ]∈Wk

via the substitution [Uk] = [K(Wk)]. Equation (5) is precisely the implicit Euler iteration for gradient ﬂow on (Wk, δ2) with a step size of τ /k2 (see Section 4.1). Since iterations of the form in equation (4) converge to the Euclidean gradient ﬂow as τ → 0, its image via the
map W → [K(W )] in equation (5) converges to the gradient ﬂow on (Wk, δ2) as τ → 0.

Theorem 1.2 (Convergence of Gradient Flows). Suppose F satisﬁes the following conditions:
(1) F is continuous in δ . (2) F is λ-semiconvex (deﬁnition 2.15) along generalized geodesics on (W, δ2) (deﬁni-
tion 3.6), for some λ ∈ R.

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS 5

Consider the gradient ﬂow of F on each Wk, ω(k) : [0, ∞) → Wk, starting at some [Uk,0]
δ
for k ∈ N \ {1}. Assume that the sequence ([Uk,0])k∈N −→ [U0], and |∂F |([U0]) < ∞ and lim supk→∞|∂ F |([Uk,0]) ≤ G < ∞, for some G ≥ 0. Then for any T ∈ R+,

(6)

lim sup sup δ ω(k)(t), ω(t) = 0 ,

k→∞ t∈[0,T ]

where ω is the unique minimizing movement curve [AGS08, Deﬁnition 2.0.6, page 42] on W for the function F starting at [U0]. In addition, if the conditions for the existence of curves of maximal slope (Theorem 4.4 or Theorem 4.14) hold, then ω is a curve of maximal slope.

Remark 1.3. Condition 2 in Theorem 1.2 is satisﬁed, in particular, if the invariant extension f : W → R ∪ {∞} of F is λ-semiconvex on (W, d2) (see Section 2.1, and Deﬁnition 2.16).

To elucidate our results, consider the (scalar) entropy function E : W → R ∪ {∞} (see [CV11] for an application to the large deviations of Erdo˝s-R´enyi random graphs):

11

(7)

E([W ]) :=

h(W (x, y)) dx dy ,

00

where h : R → R ∪ {∞} is the convex entropy function h(p) := p log p + (1 − p) log(1 − p), if 0 < p < 1, h(0) = h(1) = 0, and h(p) = ∞, otherwise.

The function E is lower semicontinuous in the cut metric [CV11, Lemma 2.1]. However, for

a given ∈ (0, 1/2), if we restrict the domain of E to be all [W ] ∈ W such that ≤ W ≤ 1− ,

a.e., then E is δ -continuous on this restricted domain. E can be shown to be convex along

generalized geodesics and its local slope can be computed easily (see Section 5 for all the

details). The Fr´echet-like derivative of this function at any graphon [W ] is given by another

graphon that is “coupled” with [W ] (see Deﬁnition 4.8)

(8) DWE([W ])(x, y) = log 1 −WW(x(,xy,)y) , (x, y) ∈ [0, 1]2 .

Thus, starting from a graphon [U0] such that < U0 < 1 − , a.e., the gradient ﬂow ω

evolves every coordinate of the graphon ω(t) by the velocity −DWE(ωt) (see Section 4.2). But the expression in equation (8) is positive for any W (x, y) > 1/2 and negative for any

W (x, y) < 1/2. Thus, the gradient ﬂow converges, as t → ∞, to the constant graphon

ω∞ ≡ 1/2, a.e., which is the unique minimizer of the function E. Restrict the domain of

the scalar entropy function on k × k symmetric matrices A with entries in [ , 1 − ]. Deﬁne

Ek(A) := k−2

k i=1

k j=1

h(Aij

).

Then

Theorem

1.2

further

says

the

following.

If

ω(k)

is

an

Euclidean gradient ﬂow of Ek, and if δ - limk→∞ ω(k)(0) = [U0] ∈ W, then (ω(k), k ≥ 2)

converges, uniformly in the cut metric on compact sets [0, T ] for T > 0, as k → ∞, to the

curve ω described above.

More nontrivial examples have been worked out in Section 5. This includes the case

when F is any (simple) graph homomorphism function that features prominently in the

theory of graph convergence to graphons. Our examples also cover the gradient ﬂow of any

linear combination of the scalar entropy function and homomorphism functions that are of

particular interest in the study of exponential random graph models (see [Cha17, CD13,

KY17, EG18, GK20]) and in the large deviation principle of dense random graphs [CV11,

Cha17, LZ15, CD20] where one is interested in optimizing the so-called rate function. For

example, see [Che16, Section 5.4.1] where the author is interested in computing the maximum

6 GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS

x1

xi+1

x0

xi

xb

···

···

yˆ(x0)

db

d0

di

d1

di+1

Figure 1. Finite width Neural Network with multiple hidden layers.

likelihood estimate for a model of exponential random graphs analyzed in [CD13]. Since graphs are discrete, the optimization is more amenable to analytical tools on the limiting graphon space. But the space of graphons is inﬁnite dimensional and the author uses gradient descent on discretized block graphons to perform the gradient descent. Our results show that the method is consistent as the discretization gets ﬁner and ﬁner and provides a mathematical justiﬁcation to the algorithm in [Che16].
It follows from the general theory in [AGS08] that a curve of maximal slope is absolutely
continuous in (W, δ2) (see deﬁnition 2.8). It is well-known in optimal transport that an absolutely continuous curve in W2 has an associated continuity equation [San15, Theorem 5.14].
An absolutely continuous curve in (W, δ2) gives us a family of continuity equations, not just one continuity equation. This is a consequence of exchangeability, and a partially analogous result to the Wasserstein case has been proved in Theorem 6.1.

1.1. Extensions and future directions. A more complicated example of the previous set-
up is a neural network (NN) with multiple hidden layers. See Figure 1, where the NN consists of b hidden layers, an initial input x0 ∈ Rd0, and a terminal output yˆ(x0) ∈ R (say), and an intermediate sequence of transformations

x0 → x1 ∈ Rd1 → x2 ∈ Rd2 → · · · → xb ∈ Rdb → yˆ .
Each transformation involves a matrix Ai+1 ∈ R , di+1×di a vector βi+1 ∈ Rdi+1, and the transformation is deﬁned as

(9)

xi+1 = σ(Ai+1xi + βi+1) ,

for all i ∈ {0} ∪ [b − 1], where the function σ : R → R acts coordinate-wise. Finally, take yˆ
to be just the average of elements in xb. Given some probability model µ on Rd0 × R, the goal is to minimize the risk function R,
given by quadratic loss here for speciﬁcity,

(10)

R (Ai, βi, i ∈ [b − 1]) := E(X,Y )∼µ (Y − yˆ(X))2 ,

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS 7
where the minimization is over all choices of the sequence of matrices Ai and vectors βi, i ∈ [b − 1]. Let us ignore the vectors βi from our discussion. The entries of the matrix Ai+1 can be thought of as associated with the edges of the bipartite graph connecting the nodes in layers i and i + 1. The output R in equation (10) does not depend on the labeling of the nodes in either layer, in the sense that if we relabel the nodes and correspondingly permute the rows and columns of Ai+1 the output R remains the same. Therefore the risk function R can be thought of as a function of edge weights of a sequence of bipartite graphs that is invariant under vertex relabeling. A gradient descent algorithm on the NN tries to compute the Euclidean gradient ﬂow with respect to these edge weights to reach the minimum value of R. One can again ask the question: as the number of vertices in each layer goes to inﬁnity, is there a scaling limit for the gradient ﬂow of R? This is a multivariate generalization of our set-up in this paper. Instead of a single graph we have a sequence of b graphs, all bipartite, and successive graphs share vertices. Nevertheless, if we assume that all the dimensions d0, . . . , db go to inﬁnity at the same rate while the edge weights remain bounded, the sequence of b matrices converge in the space of graphons in the cut metric topology [LS06, Lov12]. Although we do not take up this multivariate extension in this paper, it serves as an inspiration for our current work.
One may also wonder if our theory applies to hydrodynamic limits of natural stochastic gradient ﬂows of random graphs or matrices [Cra16, AdHR21]. This is what happens, for example, to particle systems diﬀusing according to the Fokker-Planck/Smoluchowski equations [JKO98]. The theory developed here does not cover this case of noisy gradient ﬂows since the technology needed there are quite diﬀerent. This construction is left for our upcoming work.
1.2. Organization of the paper. Section 2 develops the background material on graphons, the invariant L2 metric, and the topology of the cut metric. It also discusses concepts from the general theory of gradient ﬂow on metric spaces that are required here. Section 3 establishes the set of graphons as a geodesic metric space and describes its absolutely continuous curves. Section 4 shows existence of curves of maximal slopes, deﬁnes one of our key tools, Fr´echetlike derivatives, and proves Theorem 1.2 in Section 4.4. Section 5 works out explicit classes of functions on graphons for which we can compute Fr´echet-like derivatives and gradient ﬂows. This includes the well-known graph homomorphism functions and scalar entropy and their linear combinations. Parallels are drawn to the well-known classes of functions studied in optimal transport: potential energy, interaction energy, and internal energy. Finally in Section 6 we discuss continuity equations.
2. Background material
In Section 2.1, we introduce the required metric on graphons and other properties related to graphons. The material in this section is mostly borrowed from [Lov12, Jan16]. In Section 2.2, we introduce the necessary terminology to talk about the gradient ﬂow on a metric space. The material in that subsection is taken from [AGS08].
2.1. Graphons and Metrics on Graphons. Recall that a kernel W : [0, 1]2 → [−1, 1] is a Borel measurable, symmetric function. On the space of kernels, W, we have the usual L2 norm, · 2, that is, W 22 := [0,1]2|W (x, y)|2 dx dy. We also deﬁne the cut norm, denoted
· , on W as follows.

8 GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS
Deﬁnition 2.1 (Cut norm). The cut norm · : W → R+ is deﬁned as

W := sup

W (x, y) dx dy = sup

W (x, y)f (x)g(y) dx dy ,

S,T ⊆[0,1] S×T

f ∞, g ∞≤1 [0,1]2

for all W ∈ W where S and T are Borel measurable subsets of [0, 1], and f and g are Borel measurable functions on [0, 1].

The cut norm was ﬁrst introduced in [FK99] in the context of matrices and was later extended to kernels in [BCL+08]. The cut norm is used to deﬁne a metric called the cut
metric, δ , on the space of graphons. In the following deﬁnitions we use T to denote the
set of all measure preserving maps ϕ : [0, 1] → [0, 1], and I to denote the set of all invertible
measure preserving maps ϕ : [0, 1] → [0, 1]. Given a kernel W ∈ W and a measure preserving transformation ϕ ∈ T , one can deﬁne W ϕ ∈ W as W ϕ(x, y) := W (ϕ(x), ϕ(y)) for all x, y ∈ [0, 1]. Although our kernels are functions with domains [0, 1]2, it will be occasionally helpful
later to consider a more general probability space than [0, 1]. Let (Ω, µ) be a probability
space, let ϕ : (Ω, µ) → [0, 1] be a measure preserving map and let W ∈ W be a kernel. We can deﬁne W ϕ as a kernel on Ω2 as

(11)

W ϕ(ω1, ω2) := W (ϕ(ω1), ϕ(ω2)) .

For any k ∈ N, let Vk := {Vi}i∈[k] be a partition of [0, 1] into intervals of equal length, for example Vi := (i/k, (i + 1)/k] for i ∈ [k − 1] and V0 := [0, 1/k]. For every permutation π ∈ Sk we can deﬁne an invertible measure preserving map π˜ : [0, 1] → [0, 1] such that π˜ is an aﬃne
map from Vi to Vπ(i) for each i ∈ [k]. We denote the set of all such maps by the set Ik.

Deﬁnition 2.2 (Cut metric [BCL+08, Section 3.2]). The cut metric δ : W × W → R+ is deﬁned as

(12) δ ([W0], [W1]) := inf W0ϕ0 − W1ϕ1 = inf W0 − W1ϕ = lim min W0 − W1π˜ ,

ϕ0,ϕ1∈T

ϕ∈I

k→∞ π˜∈Ik

for all [W0], [W1] ∈ W, where the latter two equalities are due to [BCL+08, Lemma 3.5].

It is worth pointing that δ naturally extends to kernels, but it only deﬁnes a pseudometric
on W. In fact, δ (W1, W2) = 0 if and only if there exists U ∈ W and measure preserving transforms ϕ1, ϕ2 : [0, 1] → [0, 1] such that Wi(x, y) = U ϕi(x, y), for i ∈ [2]. The kernels W1, W2 in this case are said to be weakly isomorphic. In other words, graphons can be deﬁned as the class of kernels identiﬁed up to weak isomorphism. We can also deﬁne the
so-called invariant L2 metric on W.

Deﬁnition 2.3 (Invariant L2 metric [BCCH18, Jan16]). The invariant L2 metric δ2 : W ×

W → R+ is deﬁned as

(13)

δ2([W0], [W1]) := inf W0ϕ1 − W1ϕ2 2 = inf W0 − W1ϕ 2 ,

ϕ1,ϕ2∈T

ϕ∈I

for all [W0], [W1] ∈ W, where · 2 : L2([0, 1]2) → R+ is the usual L2-norm, and the second equality is a consequence of [Lov12, Theorem 8.13].

We denote the metrics induced by the cut norm and the L2-norm as d and d2 respectively. The space (W, δ ) is a compact metric space [LS07], [Lov12, Section 9.3] while the metric space (W, δ2) is complete and separable, but not compact. It is clear that convergence in δ2

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS 9
implies the convergence in δ , that is, the topology generated by δ is weaker than the topology generated by δ2. The following Lemma says that the metric δ2 is lower semicontinuous with respect to δ . Lemma 2.4. [Lov12, Lemma 14.16] The metric δ2 is sequentially δ -lower semicontinuous,
δ
i.e., if sequences ([Un])n∈N, ([Vn])n∈N ⊂ W, and [U ], [V ] ∈ W such that ([Un])n∈N −→ [U ] and
δ
([Vn])n∈N −→ [V ], then lim infn→∞ δ2([Un], [Vn]) ≥ δ2([U ], [V ]).
As we mentioned in the Introduction (Section 1), the gradient ﬂow on the space of graphons will be with respect to the invariant L2 metric, but the convergence statements will be with respect to the topology generated by the cut metric.
Let us mention in passing that the invariant L2 metric is closely related to the popular Gromov-Wasserstein metric [M´em11] used to compare two metric measure spaces or there sample equivalents [DSS+20]. This can be seen by considering [0, 1] as a metric measure space where the measure is the Lebesgue measure and, for a given bounded metric d, one deﬁnes a graphon W (x, y) = d(x, y). Then the Gromov-Wasserstein distance (for p = 2) between ([0, 1], Leb, d) and ([0, 1], Leb, d ), for two distances d and d , is the same as computing the invariant L2 distance between the corresponding graphons. In this vein also see the unpublished article [Stu12] which constructs gradient ﬂows on the space of metric measure spaces in a spirit that is quite similar to ours.
2.1.1. Block Graphons, Matrices and Graphons. For any k ∈ N, we deﬁne the set of kernels Wk ⊂ W which contain kernels which are constant a.e. over sets in Vk × Vk. The set Wk can be naturally identiﬁed with a convex subset of the ﬁnite dimensional vector space of symmetric k × k matrices. Since this identiﬁcation will be used often, we make it a deﬁnition.
Deﬁnition 2.5 (Kernels and ﬁnite symmetric matrices). For any k ∈ N, and a symmetric matrix A ∈ [−1, 1][k](2), the kernel K(A) corresponds to the element in Wk which takes the constant value Ai,j on Vi × Vj. The inverse map from Wk to [−1, 1][k](2) is denoted by Mk.
Kernels in Wk can be thought of as adjacency matrices of vertex labeled graphs with edge weights. For a ﬁnite graph G = (V, E) with vertices labeled as [k] and associated weights with every edge with weight w({i, j}) ∈ [−1, 1] for {i, j} ∈ E, we can construct its adjacency matrix A ∈ [−1, 1][k](2) by deﬁning
Ai,j := w({i, j})1{{i, j} ∈ E} , i, j ∈ [k] .
Thus, we can also map vertex labeled graphs with weights associated with its edges to kernels by considering K(A) ∈ Wk. Naturally, we can also deﬁne Wk := Wk/∼= for each k ∈ N. Given a graphon [W ] ∈ W and k ∈ N, we can obtain a k × k exchangeable symmetric array as described in the following deﬁnition.
Deﬁnition 2.6 (Sampling random graphs from graphons). Starting with a graphon [W ] ∈ W, we can sample a random graph Gk[W ] of size k ∈ N as follows. Consider any representative element W ∈ [W ] and sample k i.i.d. elements {Ui}ki=1 uniformly at random from [0, 1], and assign edge weight W (Ui, Uj) to edge {i, j} for all (i, j) ∈ [k](2). By an abuse of notation, we also denote the exchangeable symmetric k × k weighted adjacency matrix of this random graph by Gk[W ]. The distinction will be apparent from the context. In either case, Gk[W ] is measurable with respect to σ({Ui}ki=1). We deﬁne a map Bk : W → Wk as Bk := [ · ] ◦ K ◦ Gk. Thus, Bk[W ] is the block graphon obtained by sampling k random ‘vertices’ from [W ].

10 GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS

Deﬁnition 2.7 (Extensions to Lp kernels for p ∈ [1, ∞]). Sometimes in our text, we will

consider kernels and matrices whose entries are not necessarily in [−1, 1], but are rather

elements in L2 [0, 1]2 or L∞ [0, 1]2 . For any k ∈ N, just like we deﬁned Wk, we can restrict

our attention to the subset of functions Lpk([0, 1](2)) ⊂ Lp([0, 1](2)) for every p ∈ [1, ∞] which

contain symmetric measurable step functions over Vk × Vk. Using the equivalence relation

∼=, just like we deﬁned W and Wk, we can similarly deﬁne Lp([0, 1]2) := Lp([0, 1]2)/∼= and

Lpk([0, 1]2)

:=

L

p k

([0,

1]2

)

/∼=

for

any

p

∈

[1, ∞].

When it is clear from the context, we will

also call the elements in L∞ graphons. For simplicity, we use K and Mk for k ∈ N from deﬁnition 2.5 even when the kernels are in Lp [0, 1]2 for p ∈ [1, ∞].

2.2. Gradient Flows on metric spaces. The theory of gradient ﬂow on a general metric space is well-developed by now and can be found in [AGS08]. Since our goal is to deﬁne
gradient ﬂows on (W, δ2), the deﬁinitions below are sometimes not the most general versions as given in [AGS08] but adapted to our particular setting.

Deﬁnition 2.8 (Absolutely continuous curves). For a metric space (X, d), a curve
ω : [0, 1] → X is p-absolutely continuous with respect to the metric d if there exists m ∈ Lp([0, 1]) such that for all 0 ≤ r < s ≤ 1

s

(14)

d(ω(r), ω(s)) ≤ m(t) dt .

r

The set of p-absolutely continuous curves on any metric space (X, d) will be denoted as ACp(X, d), and we will refer to 1-absolutely continuous curves simply as absolutely continuous
curves and denote the set of such curves by AC(X, d).

Deﬁnition 2.9 (Metric derivative). For a metric space (X, d), the metric derivative |ω |(t) of a curve ω : [0, 1] → (X, d) at t ∈ (0, 1) is deﬁned as
(15) |ω |(t) := lim d(ω(s), ω(t)) , s→t |s − t|
provided this limit exists.

If ω ∈ AC(X, d), then the limit in equation (15) exists for a.e. t ∈ (0, 1) and |ω | ∈ L1([0, 1]) [AGS08, Theorem 1.1.2]. In other words, every absolutely continuous curve in a metric space has metric derivative deﬁned almost everywhere. And conversely, if the metric derivative |ω |(t) exists for a.e. t ∈ (0, 1) and |ω | ∈ L1([0, 1]), then ω is absolutely continuous.
We now need to deﬁne some notion for the derivative of a function F : X → R∪{∞}. On a metric space the usual notion of derivative can not be deﬁned. However, the following [AGS08, Deﬁnition 1.2.4] acts as a substitute in many situations of interest.

Deﬁnition 2.10 (Local slope). The local slope |∂F |(v) of F : X → R ∪ {+∞} on a metric space (X, d), at v ∈ eﬀ-Dom(F ) is deﬁned as

(F (v) − F (w))+

(16)

|∂F |(v) := lim sup

.

w∈X,

d(v, w)

d(v,w)→0

The deﬁnition below is narrower than Deﬁnition 1.3.2 in [AGS08] since we restrict our choice of upper gradient in that deﬁnition to the local slope [AGS08, Theorem 1.2.5].

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS 11

Deﬁnition 2.11 (Curves of maximal slope). On a metric space (X, d), any locally absolutely

continuous map ω : (a, b) → X is a curve of maximal slope for the function F : X → R∪{+∞} with respect to its local slope, if F ◦ ω = G a.e. for some non-increasing map G on (a, b),

and the inequality

(17) G (t) ≤ − 1 |ω |2(t) − 1 (|∂F |(ω(t)))2

2

2

holds for a.e. t ∈ (a, b).

On a general metric space, a curve of maximal slope can be referred to as a gradient ﬂow although the concept of gradient itself is absent. See [AGS08, Section 1.3] for the intuition.

Deﬁnition 2.12 (Length). Given the metric space (X, d), and a curve ω : [0, 1] → X, the length of ω is deﬁned as

n−1

(ω) := sup

d(ω(tk), ω(tk+1)) n ∈ N, 0 = t0 < t1 < · · · < tn = 1 .

k=0

It is clear from the deﬁnition of length that for any absolutely continuous curve ω : [0, 1] → (X, d) such that ω(0) = x, ω(1) = y, and we have (ω) ≥ d(x, y). Given x, y ∈ (X, d) it is natural to ask if there is an absolutely continuous curve ω from x to y that achieves the length (ω) = d(x, y). Such a curve is called a geodesic between x and y. If there exists a geodesic ω between any two points x, y ∈ (X, d), we say that (X, d) is a geodesic metric space. In a geodesic metric space, notions like convexity and semiconvexity make sense. We make those precise in the following deﬁnitions.

Deﬁnition 2.13 (Geodesic metric space). A metric space (X, d) is called a geodesic metric space if for all x, y ∈ X
d(x, y) = min{ (ω) | ω ∈ AC(X, d), ω(0) = x, ω(1) = y} .

Deﬁnition 2.14 (Constant speed geodesics). On a metric space (X, d), a curve ω : [0, 1] → X is a constant speed geodesic if for all 0 ≤ r ≤ s ≤ 1,

(18)

d(ω(r), ω(s)) = d(ω(0), ω(1))(s − r) .

Note that if a curve ω satisﬁes equation (18), then ω is clearly Lipschitz and hence absolutely continuous. It is easy to see that such a curve ω is indeed a geodesic and the metric derivative |ω |(t) = d(ω(0), ω(1)). This justiﬁes the name ‘constant speed geodesic’. It is also worth pointing that every geodesic admits a reparametrization that makes it a constant speed geodesic [San15, Box 5.1].
We now make precise the notion of convexity in metric spaces. On a metric space, we ﬁrst deﬁne convexity (and semiconvexity) along curves. If a function is convex (or semiconvex) along every constant speed geodesic, then we call it convex with respect to the metric.

Deﬁnition 2.15 (λ-semiconvexity along curves w.r.t. a metric). On a metric space (X, d),

a function F : X → R ∪ {∞} is said to be λ-semiconvex with respect to the metric d along a curve ω : [0, 1] → X for some λ ∈ R, if

(19)

(F

◦

ω)(t)

≤

(1

−

t)(F

◦

ω)(0)

+

t(F

◦

ω)(1)

−

1 λt(1

−

t)d2(ω(0),

ω(1))

,

2

for all t ∈ [0, 1]. Particularly, if the above inequality holds for λ = 0, then we say that F is

convex with respect to the metric d along the curve ω.

12 GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS
Deﬁnition 2.16 (λ-geodesic semiconvexity w.r.t. a metric). On a metric space (X, d), a function F : X → R ∪ {∞} is λ-geodesically semiconvex with respect to the metric d, if for any v0, v1 ∈ eﬀ-Dom(F ) there exists a constant speed geodesic ω : [0, 1] → X on (X, d) (deﬁnition 2.14) with ω(0) = v0 and ω(1) = v1 such that F is λ-semiconvex on ω with respect to the metric d for some λ ∈ R (deﬁnition 2.15).

3. Preliminaries
We collect some important results in this section that are used in the proof of our main theorem but are also of independent interest.
Let (Wt)t∈[0,1] be an absolutely continuous curve in (W, d2). It is easily seen that (ωt := [Wt])t∈[0,1] is an absolutely continuous in (W, δ2). In Theorem 3.1, we show that every absolutely continuous curve in (W, δ2) can be obtained this way.

Theorem 3.1. Let ω ∈ AC(W, δ2). Then there exists (Wt)t∈[0,1] ∈ AC(W, d2) such that ω(t) = [Wt] for all t ∈ [0, 1].
The proof requires a strengthening of [Lov12, Theorem 8.13], [Jan13, Theorem 6.16] that we state and prove below. Before we begin the proof, we deﬁne some notations. For any probability measure µ on some space Ω, and a kernel W on Ω, we deﬁne

W 22,Ω,µ := |W (x, y)|2µ(dx)µ(dy) . Ω2
Let π, ρ : [0, 1]2 → [0, 1] be the usual coordinate projection maps. Note that if W is a kernel on [0, 1], then W π and W ρ are kernels on Ω = [0, 1]2 (see (11)).
In the following discussion, we always equip [0, 1] with the Lebesgue measure, often without explicitly mentioning.

Lemma 3.2. Let ω1, . . . , ωn ∈ W. Then there exist W1, . . . , Wn ∈ W such that [Wi] = ωi and Wi − Wi+1 2 = δ2(ωi, ωi+1) for every i ∈ [n].

Proof. Let Ui ∈ ωi for i ∈ [n]. From [Lov12, Theorem 8.13] there exist probability measures µi on [0, 1]2 for i ∈ [n − 1] such that each µi is a coupling of Lebesgue measures satisfying

(20)

δ2(ωi, ωi+1) = Uiπ − Uiρ+1 2,[0,1]2,µi .

Let πi : [0, 1]n → [0, 1] be the usual projection map on the i-th coordinate. By the gluing lemma [Vil03, Lemma 7.6], there exists a measure µ˜ on [0, 1]n such that (πi, πi+1) µ˜ = µi.
Therefore we have

(21)

Uiπ − Uiρ+1 2,[0,1]2,µ =

Uiπi

−

U πi+1 i+1

2,[0,1]n,µ˜ .

i

Let η : [0, 1] → ([0, 1]n, µ˜) be a measure preserving bijection and let ϕi := πi ◦ η. Then ϕi : [0, 1] → [0, 1] is measure preserving and therefore we obtain

(22)

Uiπi

−

U πi+1 i+1

2,[0,1]n,µ˜ =

Uiϕi

−

U ϕi+1 i+1

2,[0,1] .

Combining equations (20), (21) and (22), and taking Wi = Uiϕi for all i ∈ [n], yields δ2(ωi, ωi+1) = Wi − Wi+1 2. This completes the proof.

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS 13

Proof of Theorem 3.1. Assume (possibly after a reparametrization) that the curve ω is Lipschitz with Lipschitz constant L ≥ 0. Let n ∈ N. From Lemma 3.2, there exists Wi(/nn) ∈ AC(W, d2) such that Wi(/nn) = ωi/n for all i ∈ {0} ∪ [n], and

Wi(/nn) − W((in+)1)/n = δ2(ωi/n, ω(i+1)/n) , 2
for all i ∈ [n − 1]. For each n ∈ N, let us deﬁne the curve W (n) : [0, 1] → W as W (n)(t) := (1 − nt + i)Wi(/nn) + (nt − i)W((in+)1)/n ,

when t ∈ [i/n, (i + 1)/n] for some i ∈ [n − 1]. Note that W (n) : [0, 1] → (W, d2) is also Lipschitz with constant L and therefore the family W (n) n∈N is equicontinuous w.r.t. d2.
The set W ⊆ L2[0, 1]2 is weak-∗ compact. Since W (n) n∈N is equicontinuous w.r.t. d2, it will also be equicontinuous w.r.t. the weak-∗ topology. It follows from Ascoli’s theorem [Mun00, Theorem 47.1] (possibly after passing to a subsequence and relabeling) that W (n) n∈N converges uniformly in weak-∗ to W for some W : [0, 1] → W and hence
W (n)(t) − W (n)(s), W (t) − W (s) → W (t) − W (s) 22 .
By the Cauchy–Schwarz inequality, we obtain
W (t) − W (s) 2 ≤ lim inf W (n)(t) − W (n)(s) 2 ≤ L|t − s| . n→∞
That is, W is a Lipschitz curve in (W, d2).

Since every absolutely continuous curve in a Hilbert space is diﬀerentiable a.e. (Radon–

Nikody´m property) [Huf77, page 30, Theorem 5], it follows that if (Wt, 0 ≤ t ≤ 1) is an

absolutely continuous curve in (W, d2), then there exists a family Wt ∈ L2([0, 1](2)), for a.e.

t ∈ [0, 1], such that Wt − W0 =

t 0

Ws

d

s.

Thus, as an easy consequence of the proof of Theorem 3.1, we obtain the following corollary.

Corollary 3.3. If ω ∈ AC(W, δ2), then |ω |(t) = Wt 2 for a.e. t ∈ (0, 1), where (Wt)t∈[0,1] ∈ AC(W, d2) is obtained as in Theorem 3.1.

Lemma 3.4. The invariant L2 metric between two graphons [U ], [V ] ∈ W satisﬁes

s

(23)

δ2([U ], [V ]) = min Wt 2 dt ,

r

for any 0 ≤ r < s ≤ 1, where the minimum is taken over (Wt)t∈[r,s] ∈ AC(W, d2) with domain [r, s] such that Wr ∈ [U ] and Ws ∈ [V ].

Proof. Let (Wt)t∈[r,s] ⊆ AC(W, d2) be such that Wr ∈ [U ] and Ws ∈ [V ]. Applying Jensen’s inequality, we obtain

s

s

(24)

Wt 2 dt ≥

Wt dt = Ws − Wr 2 ≥ δ2([U ], [V ]) .

r

r

2

Following deﬁnition 2.3, there exists ϕ1, ϕ2 ∈ T such that

(25)

δ2([U ], [V ]) = U ϕ1 − V ϕ2 2 .

14 GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS

Therefore, we can deﬁne an curve (Wt)t∈[r,s] ∈ AC(W, d2) as Wr := U ϕ1, Ws := V ϕ2 and Wt := ((s − t)Wr + (t − r)Ws)/(s − r) for t ∈ (r, s). Since for any r ≤ a < b ≤ s we have

(26) Wb − Wa 2 = Wss−−Wr r 2 · (b − a) = U ϕ1s−−Vr ϕ2 2 · (b − a) ,

therefore (Wt)t∈[r,s] ∈ AC(W, d2) and Wt = (U ϕ1 − V ϕ2)/(s − r) exists for all t ∈ (r, s). With this choice of (Wt)t∈[r,s] ∈ AC(W, d2), from equation (25) we get

s

(27)

Wt 2 dt = U ϕ1 − V ϕ2 2 = δ2([U ], [V ]) .

r

Combining equation (24) and equation (27) completes the proof.

We now show that (W, δ2) is a geodesic space. Therefore, the usual notions of geodesic convexity and semiconvexity makes sense in (W, δ2).

Theorem 3.5. The space (W, δ2) is a geodesic metric space.

Proof. Recall that (see the remark after the deﬁnition 2.12) for any ω ∈ AC(W, δ2) such that ω(0) = [U ], and ω(1) = [V ], we have

(28)

(ω) ≥ δ2(ω(0), ω(1)) = δ2([U ], [V ]) .

Given [U ], [V ] ∈ W, it suﬃces to construct ω∗ ∈ W such that ω∗(0) = [U ], ω∗(1) = [V ], and

(29)

(ω∗) ≤ δ2([U ], [V ]) .

Note that there exist U , V ∈ W such that δ2([U ], [V ]) = U − V 2. Deﬁne ω∗ as ω∗(t) := [Wt] where Wt := (1 − t)U + tV for all t ∈ [0, 1]. The curve ω∗ ∈ AC(W, δ2) since

(30)

δ2([Ws], [Wr]) ≤ Ws − Wr 2 = U − V · (s − r) ,

2

for all 0 ≤ r < s ≤ 1. Now observe that

(ω∗) = sup ≤ sup

n−1
δ2 [Wtk ], Wtk+1 n ∈ N, 0 = t0 < t1 · · · < tn = 1
k=0 n−1
U − V (tk+1 − tk) dt n ∈ N, 0 = t0 < t1 · · · < tn = 1 2 k=0

(31)

= U − V = δ2(ω∗(0), ω∗(1)) .

2

This completes the proof.

The proof of Theorem 1.2, as we will see, does not necessarily require geodesic convexity

of the function F . Following [AGS08, Assumption 4.0.1], and the deﬁnition of the potential

function in equation (35), the function F only needs to be convex along the curves along

which

δ

2 2

([W

]

,

·

)

is

convex

for

every

[W ] ∈ W.

The

construction

of

such

curves

as

shown

in

the proof of Lemma 3.7 can be put into a deﬁnition as follows.

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS 15

Deﬁnition 3.6 (Generalized geodesics on (W, δ2)). For all [W ], [W0], [W1] ∈ W, consider

the construction of an absolutely continuous curve ϑ as follows. From Lemma 3.2, we can

therefore obtain ϕ, ϕ0, ϕ1 ∈ T such that

(32)

δ2([W ], [W0]) = W ϕ − W0ϕ0 2 , and δ2([W ], [W1]) = W ϕ − W1ϕ1 2 .

The curve ϑ := ([Wt])t∈[0,1], where Wt := (1 − t)W0ϕ0 + tW1ϕ1 for every t ∈ [0, 1], is called a generalized geodesic between the graphons [W0] and [W1], with respect to δ2.

From the construction, we can see that any geodesic between [W0], [W1] ∈ W is also a generalized geodesic between them. Next, we show that there exists a generalized geodesic ϑ between two graphons such that the function δ22([W ], · ) is convex along ϑ for every [W ] ∈ W.

Lemma 3.7. If [W ], [W0], [W1] ∈ W, then there exists ϑ ∈ AC(W, δ2) such that ϑ(0) = [W0],

ϑ(1) = [W1],

and

δ

2 2

([W

],

·

)/2

is

1-semiconvex

over

ϑ

w.r.t.

δ2.

Proof. From Lemma 3.2 we obtain ϕ, ϕ0, ϕ1 ∈ T such that

(33)

δ2([W ], [W0]) = W ϕ − W0ϕ0 2 , and

Deﬁning Wt := (1 − t)W0ϕ0 + tW1ϕ1, we get that that

δ2([W ], [W1]) =

W ϕ − W1ϕ1 2 .

δ22([W ], [Wt]) ≤

W ϕ − (1 − t)W0ϕ0 − tW1ϕ1

2 2

= (1 − t)

W ϕ − W0ϕ0

22 + t

W ϕ − W1ϕ1

22 − t(1 − t)

W0ϕ0 − W1ϕ1

2 2

= (1 − t)δ22([W ], [W0]) + tδ22([W ], [W1]) − t(1 − t)

W0ϕ0 − W1ϕ1

2 2

(34)

≤ (1 − t)δ22([W ], [W0]) + tδ22([W ], [W1]) − t(1 − t)δ22([W0], [W1]) .

This implies that δ22([W ], · )/2 is 1-semiconvex along ϑ := ([Wt])t∈[0,1] w.r.t. δ2.

4. Gradient Flows on Graphons

The goal of this section is to prove Theorem 1.2. We begin by arguing the existence of gradient ﬂows.

4.1. Implicit Euler method, Generalized Minimizing Movements and Existence of gradient ﬂows. Given F : W → R ∪ {∞}, a step size τ > 0 and [U ] ∈ W, deﬁne a functional ΦF (τ, [U ]; · ) : W → R ∪ {∞} given by (35) ΦF (τ, [U ]; [V ]) := F ([V ]) + 21τ δ22([V ], [U ]) ,

and a set-valued resolvent operator Jτ on W as

(36)

Jτ ([U ]) := arg min ΦF (τ, [U ]; · ) , for [U ] ∈ W.

W

For a sequence τ := (τn)n∈N of positive time steps with |τ | := supn∈N τn < ∞, we can associate a partition of the time interval (0, ∞) as

Pτ := Iτn := (tτn−1, tnτ ] n∈N ,

τn = tnτ − tτn−1 ,

if t0τ = 0 and limn→∞ tnτ = ∞. Given such a sequence τ and [Uτ,0] ∈ W, we can obtain a sequence ([Uτ,n])n∈N by iteratively solving for [Uτ,n], by setting

(37)

[Uτ ,n] ∈ Jτn([Uτ ,n−1]) ,

16 GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS

provided Jτn([Uτ,n−1]) is non-empty for every n ∈ N.

Deﬁnition 4.1 (Discrete solution). Given the sequence ([Uτ,n])n∈N as above, interpolate the discrete points by piece-wise constant left-continuous functions [Uτ ] : [0, ∞) → W, deﬁned as

(38)

[Uτ ](0) := [Uτ,0] , [Uτ ](t) := [Uτ,n] , t ∈ (tn−1, tn] .

We call [Uτ ] to be a discrete solution corresponding to the partition Pτ .

The following deﬁnition is taken from [AGS08, Deﬁnition 2.0.6].

Deﬁnition 4.2 (Generalized minimizing movements). For a function F , its corresponding
functional ΦF as deﬁned in equation (35), and an initial datum [U0] ∈ W, we say that a curve ω : R+ → W is a generalized minimizing movement (GMM) for ΦF starting from [U0] ∈ W if there exists a sequence of sequences (τ k)k∈N with limk→∞|τ k| = 0 and a corresponding sequence of discrete solutions ([Uτk])k∈N deﬁned as in Deﬁnition 4.1 such that for all t ∈ R+,

(39) lim F ([Uτk,0]) = F ([U0]) , lim sup δ2([Uτk,0], [U0]) < ∞ , δ - lim [Uτk ](t) = ω(t) .

k→∞

k→∞

k→∞

There is a related deﬁnition of minimizing movement (MM) curves that can be found in [AGS08, Deﬁnition 2.0.6] where the conditions in equation (39) need to hold for all sequences of partitions with vanishing norm. The set of all minimizing movements and gen-
eralized minimizing movements on the metric space (W, δ2) with respect to the metric δ starting from [U0] ∈ eﬀ-Dom(F ) are denoted by MMδ2,δ (ΦF , [U0]) and GMMδ2,δ (ΦF , [U0]) respectively. From their deﬁnitions it can be veriﬁed that the set of minimizing movements is contained in the set of generalized minimizing movements. See [AGS08, Deﬁnition 2.0.6]
for the precise diﬀerence between them. Since (W, δ2) is a bounded metric space, the second conditions in equation (39) and [AGS08, equation 2.0.10] are trivially satisﬁed.

Lemma 4.3. If F : W → R ∪ {∞} is sequentially δ -lower semicontinuous, then
(1) for every τ > 0 and [U ] ∈ W, we have infW ΦF (τ, [U ]; · ) > −∞, where ΦF is deﬁned in equation (35), and
(2) if ([Un])n∈N ⊂ W with supn∈N F ([Un]) < ∞, then ([Un])n∈N admits a δ -converging subsequence.
Proof. Since (W, δ ) is a compact metric space [LS07], from the Weierstrass Theorem [San15, Box 1.1], both arg minW F and arg minW ΦF (τ, [U ]; · ) exist for all τ > 0 and [U ] ∈ W. Thus the minimums are greater than −∞, and every sequence admits a δ -converging subsequence.

From Lemma 2.4 we know that the topology induced by δ2 is sequentially δ -lower semicontinuous. This with Lemma 4.3 shows that the assumptions in [AGS08, Proposition 2.2.3] are satisﬁed, guaranteeing that GMMδ2,δ (ΦF , [U0]) is non-empty. If |∂F | is δ -lower semicontinuous and F is δ -continuous on the sublevel sets of |∂F |, then it follows from [AGS08, Theorem 2.3.1] that every element ω ∈ GMMδ2,δ (ΦF , [U0]), for [U0] ∈ eﬀ-Dom(F ), is a curve of maximal slope. For the sake of clarity, we record the above discussion as a theorem.
Theorem 4.4 (Existence of curves of maximal slope). Suppose F : W → R ∪ {∞} satisﬁes the following conditions.
(1) F is δ -lower semicontinuous on eﬀ-Dom(F ).

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS 17

(2) Its local slope |∂F | is δ -lower semicontinuous in eﬀ-Dom(F ). (3) F is δ -continuous on the sublevel sets of |∂F |.
Then every curve ω ∈ GMMδ2,δ (ΦF , [U0]) for [U0] ∈ eﬀ-Dom(F ) is a curve of maximal slope.

In practice, it is diﬃcult to compute |∂F | or to ascertain its δ -lower semicontinuity. This makes it diﬃcult to apply Theorem 4.4 on natural examples. Later in Theorem 4.14 we show that, when f admits a Fr´echet-like derivative that is λ-semiconvex on (W, d2), the existence of a curve of maximal slope follows without δ -lower semicontinuity of |∂F |.
We now deﬁne Jτ(k) to be the resolvent operator on Wk, which is deﬁned as
(40) Jτ(k)([U ]) := arg min F + 21τ δ22([U ], · ) , Wk

for any τ > 0, [U ] ∈ Wk and k ∈ N. We end this section by proving Lemma 4.5 that will not only play a crucial role in the proof of Theorem 1.2, but also is of independent interest.
The following Lemma essentially shows Γ-convergence of the penalized functionals ΦF , restricted to Wk, as k → ∞.

Lemma 4.5. Fix some δ -continuous function F : W → R ∪ {∞} and some step size τ > 0.
δ
Consider a sequence ([Uk] ∈ Wk)k∈N such that ([Uk])k∈N −→ [U ] for some [U ] ∈ W. For each k ∈ N, let Uk+,τ ∈ arg minWk ΦF (τ, [Uk]; · ). Suppose U∞+,τ is any δ -limit point of the sequence Uk+,τ k∈N. Then U∞+,τ ∈ arg minW ΦF (τ, [U ]; · ).
δ
Proof. Note that for any sequence of graphons ([Wk])k∈N such that ([Wk])k∈N −→ [W ] for some [W ] ∈ W, by Lemma 2.4 we have

(41)

lim inf δ2([Uk], [Wk]) ≥ δ2([U ], [W ]) .

k→∞

We now construct a recovery sequence of graphons ([Wk∗] ∈ Wk)k∈N ⊂ W such that

(42)

lim

δ

2

([Uk

]

,

[W

∗ k

])

=

δ2([U ], [W ]) ,

and

lim δ ([Wk∗], [W ]) = 0 .

k→∞

k→∞

To do so, we will ﬁrst obtain ϕ, ψ ∈ T from deﬁnition 2.3 and [Jan13, Theorem 6.16] such that

(43) δ2([U ], [W ]) = U ϕ − W ψ 2 . Since δ ([Uk], [U ]) → 0, using [Lov12, Theorem 11.59] we can ﬁnd (ϕk ∈ Ik)k∈N such that

(44)

lim Ukϕk − U ϕ = 0 .

k→∞

We now deﬁne a sequence of kernels (Zk ∈ Wk)k∈N as Zk := Ukϕk − E[U ϕ | Fk] ,

where

Fk := σ{(i/k, (i + 1)/k] × (j/k, (j + 1)/k] | i, j ∈ {0} ∪ [k − 1]} , k ∈ N .

Note that Zk ≤ Ukϕk − U ϕ

+ U ϕ − E[U ϕ | Fk]

≤ Ukϕk − U ϕ

+ U ϕ − E[U ϕ | Fk] 2 .

18 GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS

Note that for any V ∈ W, the martingale sequence (E[V | Fk] ∈ Wk)k∈N converges to V ∈ W in L2 [0, 1]2 . Using L2 convergence of the martingales E[U ϕ | Fk] and equation (44) we conclude that

(45)

Zk → 0 ,

as k → ∞. The sequence of kernels (Wk∗ ∈ Wk)k∈N can now be deﬁned as Wk∗ := E W ψ Fk + Zk .

It follows that

Wk∗ − W ψ ≤ E W ψ Fk − W ψ + Zk ≤ E W ψ Fk − W ψ 2 + Zk
Using L2 convergence of the martingales, and equation (45) we obtain (Wk∗)ψk −W ψ and therefore have

. →0

(46)

lim sup δ ([Wk∗], [W ]) = 0 .

k→∞

Moreover,

Ukϕk − Wk∗ 22 = E[U ϕ | Fk] − E W ψ Fk

2 2

(47) ≤ U ϕ − W ψ 22 = δ22([U ], [W ])

(using equation (43)) ,

where the last inequality follows from [Lov12, Equation 9.7]. From equation (47) and Lemma 2.4 we obtain

(48)

lim δ2([Uk], [Wk∗]) = δ2([U ], [W ]) .

k→∞

Now, by the deﬁnition of Uk+,τ , we have

(49) F Uk+,τ + 21τ δ22 [Uk], Uk+,τ ≤ F ([Wk∗]) + 21τ δ22([Uk], [Wk∗]) .

Taking lim infk→∞ on both sides of equation (49), and from equation (41), equation (42) and the δ -continuity of F , we get

F U∞+,τ

+ 21τ δ22 [U ], U∞+,τ

≤ lim inf F Uk+,τ k→∞

+ lim inf 1 δ2 [U ], U +

k→∞ 2τ 2 k

k,τ

(50) ≤ lim inf F ([W ∗]) + lim inf 1 δ2([U ], [W ∗]) = F ([W ]) + 1 δ2([U ], [W ]) .

k→∞

k

k→∞ 2τ 2 k

k

2τ 2

Since [W ] ∈ W was arbitrary, this completes the proof.

4.2. Fr´echet-like derivatives and local slope. Recall that given a function F : W → R ∪ {∞}, we can deﬁne an invariant function f : W → R ∪ {∞} such that f = F ◦ [ · ].

Deﬁnition 4.6 (Fr´echet-like derivative on W). Suppose f : W → R ∪ {∞} is an invariant function. Let V ∈ eﬀ-Dom(f ). The Fr´echet-like derivative at V is given by any φ ∈ L∞([0, 1](2)) that satisﬁes the following condition,

f (W ) − f (V ) − ( φ, W − φ, V )

(51)

lim

=0,

W ∈W,

W −V 2

W −V 2→0

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS 19

where · , · is the usual inner product on L2 [0, 1]2 . If f admits a Fr´echet-like derivative at every V ∈ eﬀ-Dom(f ), we denote the map that takes V to the corresponding φ by DWf . In that case we say that f is Fr´echet diﬀerentiable.

In [DGKR15], the authors consider Gaˆteuax and Fr´echet derivatives of functions on graphons with respect to the cut metric. However, as they remark [DGKR15, Remark 2.18, page 195], such a notion of Fr´echet derivative is too weak to cover natural functions such as homomorphism densities.
The next lemma says that the action of DWf is ‘consistent’ over all kernels in [V ] ∈ eﬀ-Dom(F ). In other words, we can project DWf to obtain DWF : eﬀ-Dom(F ) → L∞([0, 1]2) as DWF ([V ]) := [DWf (V )] for V ∈ W.
Lemma 4.7. Let f : W → R ∪ {∞} be an invariant function. Let V ∈ eﬀ-Dom(f ) and let V = V ϕ for some ϕ ∈ T . If φ = DWf (V ) and φ = DWf (V ), then φ = φϕ a.e. In particular, this implies that DW f (V ) ∈ L∞([0, 1](2)) if it exists, is unique.

Proof. Let φ = DW f (V ) and φ = DW f (V ). Let (Vn)n∈N ⊂ W be a sequence of kernels such that Vn − V 2 → 0 and hence Vnϕ − V 2 → 0 as n → ∞. We observe that

lim
n→∞

φ − φϕ, Vnϕ − φ − φϕ, V ϕ Vnϕ − V ϕ 2

 f (V ) − f (V ) − φ, V − V

f (Vnϕ) − f (V ϕ) − φ, Vnϕ − V ϕ 

= lim  n

n

−

ϕ



n→∞

Vn − V 2

Vn − V ϕ 2

f (Vn) − f (V ) − φ, Vn − V

f (Vnϕ) − f (V ϕ) − φ, Vnϕ − V ϕ

(52) = lim n→∞

Vn − V 2

− lim n→∞

Vnϕ − V ϕ 2

=0.

Our goal is to show that φ − φϕ = 0 a.e. Let A+ := {φ − φϕ > 0} and A− := {φ − φϕ < 0}.
It suﬃces to show that |A±| = 0. Let A := {V = 1} ∩ A+ and B := {V < 1} ∩ A+. We
claim that A and B have measure 0. If not, we deﬁne Vn := V + n1 χB for all n ∈ N (if B has positive measure). Clearly Vn − V 2 → 0 as n → ∞, and therefore by equation (52) we obtain

φ − φϕ, χB = 0 =⇒ φ − φϕ (x, y) dx dy = 0 ,
B
which is a contradiction. Hence, we must have that B has 0 measure. Similarly, taking Vn := V − n1 χA for all n ∈ N shows that A has measure 0. Since A+ = A ∪ B, it follows that A+ has measure zero. The exact same argument also shows that A− has 0 measure. In other words, φ − φϕ = 0 a.e.
Speciﬁcally, if we set ϕ = id, i.e., φ and φ both satisfy the limit identity in equation (51), then φ = φ a.e., i.e., DW f is a unique element in L∞([0, 1](2)).

Let F : W → R∪{∞} and let f : W → R∪{∞} be the invariant extension of F . Lemma 4.7 justiﬁes saying F has Fr´echet-like derivative if f has a Fr´echet-like derivative. Note that the Lemma 4.7 says that not only can the Fr´echet-like derivative be thought of as a graphon, but also the two graphons [DWf (V )] and [V ] are ‘coupled’ in the sense that they are two sets of

20 GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS

“edge weights” associated with the edges of the same exchangeable continuum “graph”. We make a formal deﬁnition to capture this relationship.

Deﬁnition 4.8 (Coupled graphons). For any r ∈ N, we deﬁne the set [W1] [W2] · · · [Wr] ⊆ Wr with initial labeling (W1, W2, . . . , Wr) ∈ Wr as

(53) r [Wi] := {(Wiϕ)ri=1 | ϕ ∈ T } . i=1

Without loss of generality, we will always refer to the elements in ri=1[Wi] with the initial labeling (Wi)ri=1 unless speciﬁed. Since we can also relabel elements in L∞([0, 1]2) (i.e., apply the map V → V ϕ, for V ∈ L∞([0, 1]2) and ϕ ∈ T ), we can generalize Deﬁnition 4.8 to tuples with elements in L∞([0, 1]2) ⊃ W. That is, we can consider sets of the form

(54) r [Vi] := {(Viϕ)ri=1 | ϕ ∈ T } , i=1
with initial labeling Vi ∈ L∞([0, 1]2) r . Therefore, from Lemma 4.7, if V ∈ [V ] ∈ W, and i=1
φ = DWf (V ), then (V, φ) ∈ [V ] [φ]. For (V, φ) ∈ [V ] [φ], we deﬁne the set GV ⊆ [0, 1]2 as

(55)

GV := {|V | < 1} ∪ {V = 1, φ > 0} ∪ {V = −1, φ < 0} .

Since (V, φ) ∈ [V ] [φ], the set GV is well deﬁned on W. For any ϕ ∈ T , GV ϕ = (GV )ϕ := {(ϕ(x), ϕ(y)) ∈ [0, 1]2 | (x, y) ∈ GV }.
The next theorem gives an expression for the local slope of F in terms of its Fr´echet-like
derivative.

Theorem 4.9. For every invariant function f : W → R ∪ {∞} with projection F : W →

R ∪ {∞}, assume that for each [V ] ∈ W the Fr´echet-like derivative DWf (V ) exists for all V ∈ [V ], then the local slope (Deﬁnition 2.10) of F at [V ] satisﬁes

(56)

|∂F |([V ]) = η ([V ]) := sup ( φ, V

− φ, W )+ =

φ1

,

F

W ∈W

V −W 2

GV 2

where V ∈ [V ], and φ = DWf (V ). {U ∈ W | |U | < 1 a.e.} ∩ eﬀ-Dom(f ).

In particular, |∂F |([V ]) =

φ 2 if V ∈

Proof. Fixing [V ] ∈ eﬀ-Dom(F ), we verify using Lemma 4.7 that ηF is well deﬁned on W. If V2 = V1ϕ for V1 ∈ [V ] for some ϕ ∈ T , and φ1 = DW f (V1) then DW f (V2) = φϕ1 =: φ2, and

( φ1, V1 − W )+

( φϕ1 , V1ϕ − φϕ1 , W ϕ )+

( φ2, V2 − φ2, W )+

(57) sup
W ∈W

V1 − W 2

= sup
W ∈W

V1ϕ − W ϕ 2

= sup
W ∈W

. W − V2 2

We will now break the proof of the claim into two parts:

(1) (58) (59)

For any ε > 0, let us consider [W ] ∈ W such that δ2([V ], [W ]) < δε/2 for some δε > 0

such that if ε → 0, then δε → 0. From Deﬁnition 2.2, there exists ϕ ∈ I such that δ2([V ], [W ]) < W ϕ − V 2 ≤ δ2([V ], [W ]) + δε/2, or equivalently

δε/2 > δ2([V ], [W ]) ≥ W ϕ − V 2 − δε/2 > 0 .

From assumption if we choose W ϕ ∈ W, since W ϕ − V 2 < δε we will have

f (W ϕ) − f (V ) − ( φ, W ϕ − φ, V )

−ε ≤

≤ε,

Wϕ −V 2

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS 21

where φ = DW(V ). Using equations (59) and equation (58), we get

(F ([V ]) − F ([W ]))+ (F ([V ]) − F ([W ]))+

≤

δ2([V ], [W ])

W ϕ − V 2 − δε/2

≤ ( φ, V − φ, W ϕ + ε W ϕ − V 2)+ W ϕ − V 2 − δε/2

( φ, V − φ, W ϕ )+

≤

+ε

Wϕ −V 2

Wϕ −V 2 W ϕ − V 2 − δε/2

(60)

≤ (η ([V ]) + ε) W ϕ − V 2 ,

F

W ϕ − V 2 − δε/2

for some V ∈ [V ]. Taking ε → 0 in equation (60) we get

(61)

|∂F |([V ]) ≤ ηF ([V ]) .

(2) When ηF ([V ]) > 0, for all ε ∈ (0, ηF ([V ])), by the deﬁnition of ηF ([V ]), for any V ∈ [V ] and φ = DW(V ), there exists W ∈ W such that

φ, V − φ, W (62) 0 < ε < ηF ([V ]) ≤ V − W 2 + ε .

Let Wt := (1 − t)V + tW for all t ∈ [0, 1]. Since W is a convex subset of L2([0, 1](2)), the curve (Wt)t∈[0,1] ⊆ W. Since Wt − V 2 → 0 as t → 0, by assumption we have

lim f (Wt) − f (V ) − ( φ, Wt − φ, V ) = 0

t→0

Wt − V 2

=⇒ lim f (Wt) − f (V ) − t( φ, W − φ, V ) = 0

t→0

t W −V 2

=⇒ lim f (V ) − f (Wt) = φ, V − φ, W ≥ ηF ([V ]) − ε > 0

t→0 t W − V 2

V −W 2

f (V ) − f (Wt)

(f (V ) − f (Wt))+

=⇒ lim

= lim

≥ ηF ([V ]) − ε

t→0 Wt − V 2

t→0 t W − V 2

(F ([V ]) − f ([Wt]))+

(63)

=⇒ lim

≥ ηF ([V ]) − ε .

t→0 δ2([Wt], [V ])

Therefore, we have a curve ([Wt])t∈[0,1] → [V ] along which equation (63) holds for every ε > 0. When ηF ([V ]) = 0, equation (63) trivially holds for ε = 0.

Combining the two parts, we ﬁnd that |∂F |([V ]) = ηF ([V ]). For any n ∈ N and δn > 0, let Aδn := {|V | < δn} ∪ {V = 1, φ > 0} ∪ {V = −1, φ < 0}.
Note that for any tn > 0 and δn > 0, deﬁne Wn := V − tnφ1Aδn and

(64)

( φ, V

− φ, Wn )+ =

φ1

.

V − Wn 2

Aδn 2

Let (δn)n∈ be a sequence in (0, 1) such that limn→∞ δn = 1. Since φ ∈ L∞ [0, 1]2 , for every

N

1A ∈ W for each n ∈ N. It follows from

δn > 0, there exists tn > 0 such that Wn = V − tnφ δn

22 GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS

equation (64) that

(65)

ηF ([V ]) ≥ lim sup φ1Aδn 2 = φ1GV 2 ,

n→∞

where the last equality follows from the dominated convergence theorem and the fact that
1Aδn → 1GV a.e. as δn → 1.
For any W ∈ W, deﬁne W = W on GV and W = V otherwise. Note that

φ, V − W = φ(V − W ) dλ[0,1]2 +

φ(V − W ) dλ[0,1]2

GV

[0,1]2\GV

= φ(V − W ) dλ[0,1]2 +

φ(V − W ) dλ[0,1]2

GV

[0,1]2\GV

(66)

≤ φ(V − W ) dλ[0,1]2 = φ(V − W ) dλ[0,1]2 = φ, V − W ,

GV

where λ[0,1]2 is the Lebesgue measure on [0, 1]2, and the inequality above follows from the

fact that φ(V − W ) ≤ 0 on [0, 1]2 \ GV . Using that V − W 2 ≤ V − W 2, we obtain

+

( φ, V − φ, W )+

φ, V − φ, W

≤

.

V −W 2

V −W

2

It therefore follows that (67)

( φ, V − φ, W )+

ηF ([V ]) := sup
W

, V −W 2

where the supremum is taken over W ∈ W such that W = V on [0, 1]2 \ GV . For any such
W , we obtain by the Cauchy–Schwarz inequality that φ, V − W ≤ φ1GV 2 V − W 2.
Therefore, it follows from that

(68)

ηF ([V ]) ≤ φ1GV 2 .

Combining equations (65) and (68), the conclusion follows.

We can deﬁne a similar expression for the set valued function G when eﬀ-Dom(f ) is a cubic domain. As an example, when eﬀ-Dom(f ) = {W ∈ W |a ≤ W ≤ b} for some −1 ≤ a ≤ b ≤ 1 (see Section 5.1.1 for a discussed example), we can deﬁne G as

(69) GV = {a < V < b} ∪ {V = b, φ > 0} ∪ {V = a, φ < 0} , V ∈ eﬀ-Dom(f ) ,

for (V, φ := DWf (V )) ∈ [V ] [φ]. Theorem 4.9 continues to hold when V ∈ eﬀ-Dom(f ) ⊂ W whenever eﬀ-Dom(f ) is a cubic domain. In this case, the set valued function G is deﬁned as described above and the proof of Theorem 4.9 can be modiﬁed accordingly.

Remark 4.10. Theorem 4.9 has an important consequence that will be used later. As the
metric derivative of a gradient ﬂow is given by its local slope at each point, Theorem 4.9 says that if ω is a gradient ﬂow of F , then its local slope is given by the L2-norm of its Fr´echet-like
derivative, i.e., |∂ F |(ωt) = φ(ωt)1Gωt 2 = DW F (ωt)1Gωt 2 for all t > 0. Here for any
t > 0,
DW F (ωt)1Gωt := DW f (Ut)1GUt ϕ ∈ L∞([0, 1]2) ϕ ∈ T ,
for Ut ∈ ωt. Since the L2-norm is invariant under measure preserving transformations [Jan13, Lemma 5.5], the L2-norms of graphons are well-deﬁned.

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS 23

Lemma 4.11. Let the function F : W → R ∪ {∞} be obtained by the projection of an
invariant function f : W → R ∪ {∞}. Let us consider ω ∈ AC(W, δ2), and let (Wt)t∈[0,1] ∈ AC(W, d2) be its representative curve such that Wt = −ηF ([Wt])Nt for a.e. t ∈ [0, 1] for some Nt ∈ L∞([0, 1]2) satisfying Nt 2 = 1 and φt, Nt = ηF ([Wt]). Then, ω is a curve of maximal slope on (W, δ2).

Proof. Since the curve (Wt)t∈[0,1] ∈ AC(W, d2) the metric derivative of (Wt)t∈[0,1] with respect to the metric d2 at t ∈ (0, 1) is given by

(70)

lim Wt+h − Wt 2 = W = η ([W ])N = |η ([W ])| .

h→0

|h|

t2

F

t t2

F

t

That is, the metric derivative of (Wt)t∈[0,1] ∈ AC(W, d2) equals the upper gradient. Moreover, by the absolute continuity of the curve, from deﬁnition 4.6 we get that for a.e. t ∈ (0, 1),

d f (Wt) = lim f (Wt+h) − f (Wt)

dt

h→0

h

= lim φt, Wt+h − φt, Wt + o( Wt+h − Wt 2)

h→0

h

(71)

= φt, Wt + 0 = − φt, Nt ηF ([Wt]) = −ηF2 ([Wt]) ,

where φt = DW f (Wt). Therefore, (Wt)t∈[0,1] satisﬁes deﬁnition 2.11 and is a curve of maximal slope on (W, d2), and ω is a curve of maximal slope on (W, δ2).

4.2.1. Fr´echet-like derivative and gradient ﬂow. Let us consider a well-deﬁned gradient ﬂow
(i.e., curve of maximal slope) ω ∈ AC(W, δ2) with domain [0, T ], of a function F : W → R ∪ {∞} which is the projection of an invariant function f : W → R ∪ {∞}, for some T ∈ R+. The curve ω is then determined by the local slope, that is characterized as

( φt, Ut − φt, W )+ (72) |∂ F |(ω(t)) = ηF (ω(t)) = Wsu∈pW Ut − W 2 ,

by Theorem 4.9 for every t ∈ [0, T ], where [Ut] [φt] has an initial labelling of (Ut, DW f (Ut) = φt). Since the operator supW ∈W can be factorized into sup[W ]∈W supW ∈[W ],

the upper gradient |∂F | is well deﬁned from Theorem 4.9. Since (W, δ ) is compact [LS07], for

every t ∈ [0, T ] there exists [W ∗] ∈ W such that W ∗ ∈ W maximizes W → ( φt,Ut − φt,W )+ ,

t

t

W −Ut 2

and [Wt∗] ω(t) has an initial labeling of (Wt∗, Ut) for some Ut ∈ ω(t). Then, for every

t ∈ [0, T ], the “velocity” of the gradient ﬂow at ω(t) should be proportional to the graphons

obtained via the kernel Wt∗ − Ut, in the sense that v∞(ω(t)) Kω(t)(Wt∗ − Ut) has an initial

labelling of Vt, Kω(t)(Wt∗ − Ut) , for Vt ∈ v∞(ω(t)) satisfying Vt = Kω(t)(Wt∗ − Ut), for some

Kω(t) ∈ R+. By the deﬁning property of gradient ﬂow, it must be true that

(73)

Vt 2 = |ω |(t) ,

24 GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS

and further since |ω |(t) = ηF (ω(t)) = |∂F |(ω(t)), we obtain

(74)

∗

( φt, Ut − φt, Wt∗ )+

Kω(t) Wt − Ut 2 =

W∗ −U

t

t2

( φt, Ut − φt, Wt∗ )+

=⇒ Kω(t) =

W∗ −U 2

t

t2

( φt, Ut − φt, Wt∗ )+

∗

=⇒ Vt =

W∗ −U 2

· (Wt − Ut) = ηF (ω(t))

t

t2

Wt∗ − Ut

W∗ −U .

t

t2

Therefore, ω(t) v∞(ω(t))

ηF (ω(t))

Wt∗ −Ut
∗

Wt −Ut 2

W × L∞([0, 1]2) × L∞([0, 1]2) has an

initial labelling of Ut, Vt, ηF (ω(t)) WW∗t∗−−UUt , where ﬁxing any Ut ∈ ω(t), the kernel Wt∗ ∈ W

t

t2

maximizes W → ( φt,Ut − φt,W )+ . W −Ut 2

Remark 4.12. An important consequence of the above discussion is that if ω is a gradient ﬂow of F then there exists an absolutely continuous curve (Wt)t∈[0,T ] ∈ AC(L2([0, 1]2)) such
that [Wt] = ωt, |ω |(t) = DW f (Wt)1GWt 2 and W (t) = −DW f (Wt)1GWt , for each t ∈ (0, T ].

Theorem 4.13. Let f : W → R ∪ {∞} be a λ-semiconvex invariant function such that
the Fr´echet-like derivative, φ(W ) = DWf (W ), exists for all W ∈ eﬀ-Dom(f ). Let
(Wt)t∈[0,1] ∈ AC(W, d2) be an absolutely continuous curve satisfying W (t) = −φt1GWt = −DW f (W (t))1GWt for a.e. t ∈ [0, 1]. Then, ([Wt])t∈[0,1] is the unique minimizing movement
curve (MM) satisfying the following EVI inequality

(75) 12 ddt d22(W (t), V ) + λ2 W (t) − V 22 + f (W (t)) ≤ f (V ) ,

for every V ∈ eﬀ-Dom(f ).

Proof. The curve Wt is a curve of maximal slope follows from Lemma 4.11. We now show
that it satisﬁes the EVI inequality. For t ≥ 0, let φt := DWf (W (t)). Fix U ∈ W and deﬁne the function gU : W → R ∪ {∞} by gU (V ) := f (V ) − λ U − V 22/2, for V ∈ eﬀ-Dom(f ).
We ﬁrst observe that DW gW (t)(W (t)) = φt. To see this, note that

lim f (W (s)) − f (W (t)) − φt, W (s) − W (t) = 0

s→t

W (s) − W (t) 2

(76) =⇒ lim gW (t)(W (s)) − gW (t)(W (t)) − φt, W (s) − W (t) = 0 .

s→t

W (s) − W (t) 2

The conclusion, that is DWgW (t)(W (t)) = φt, now follows from the uniqueness of Fr´echet-like derivatives (Lemma 4.7). Since f is λ-semiconvex on W, gU is convex. In particular,

(77)

gW (t)(V ) ≥ gW (t)(W (t)) + φt, V − W (t) , V ∈ eﬀ-Dom(f ) .

From equation (66) and using the fact that W (t) = φt, we obtain

φt, V − W (t) ≤ φt1G

d , V − Wt = − W (t), V − W (t)

W (t)

dt

(78) = 21 ddt W (t) − V 22 = 12 ddt d22(W (t), V ) ,

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS 25

where the second equality follows from the reﬂexivity of L2([0, 1]2). Plugging equations (76) and (78) in equation (77) and rearranging, we get
(79) 21 ddt d22(W (t), V ) + λ2 W (t) − V 22 + f (W (t)) ≤ f (V ) ,
for all V ∈ eﬀ-Dom(f ). Using equation (79) it follows from [AGS08, Theorem 4.0.4] that the curve ([Wt])t∈[0,1] is the unique curve in MMδ2,δ (ΦF , [W0]).

Theorem 4.14. Let F : W → R ∪ {∞} be a real valued function such that the Fr´echet-
like derivative DWF ([W ]) exists for all [W ] ∈ eﬀ-Dom(F ). Let f : W → R ∪ {∞} be its invariant extension. If f is λ-semiconvex w.r.t. d2, then there exists a curve maximal slope
for F starting at every [W0] ∈ eﬀ-Dom(F ).

Proof. Fix [W0] ∈ eﬀ-Dom(F ) and deﬁne

t
Wt := W0 − φ(Ws)1GWs ds ,
0

t ∈ (0, 1] .

By construction, we have that (Wt)t∈[0,1] is an absolutely continuous curve in (W, δ2) and
Wt = −φ(Wt)1GWt for all t ∈ [0, 1]. It follows from Theorem 4.13 that (Wt)t∈[0,1] is a min-
imizing movement. It follows from the deﬁnition of minimizing movements (see Section 4.1

and [AGS08, Deﬁnition 2.0.6]) that there exists a sequence of discrete solutions in W that converges to ([Wt])t∈[0,1] in δ . Since W is closed in · , Wt ∈ W for all t ∈ [0, 1].

Set ωt = [Wt] for t ∈ [0, 1]. Then ω ∈ AC(W, δ2). From Theorem 4.9, we know that
for any t ∈ [0, 1], ηF ([Wt]) = φ(Wt)1GWt 2 and therefore we have Wt = −ηf (Wt)Nt where Nt := φ(Wt)1GWt / φ(Wt)1GWt 2. It follows from Lemma 4.11 that ω is a curve of maximal
slope on (W, δ2).

4.3. Finite dimensional Fr´echet-like derivatives and upper gradients. Recall the partition Vk := {Vi}i∈[k] deﬁned in Section 2.1. Given an invariant function f : W → R∪{∞}, we can restrict its domain to kernels in Wk and still consider the Fr´echet-like derivative DWk f : Wk ∩ eﬀ-Dom(f ) → L∞ k ([0, 1](2)).
There are two equivalent ways of doing this. First, suppose the Fr´echet-like derivative of
f at V is given by DWf (V ) = φ. Then deﬁne DWkf (V ) = φk by conditional expectations as

(80)

φk(x, y) :=

Vi×Vj φ(x, y) dλ[0,1]2 (x, y) , Vi×Vj dλ[0,1]2 (x, y)

where λ[0,1]2 is the Lebesgue measure on [0, 1]2, whenever x ∈ Vi and y ∈ Vj for some i, j ∈ [k] (the object φk is referred to as a ‘quotient’ obtained by a ‘stepping’ of φ in [BCL+08, Section
3.3] and [Lov12, Section 9.2.1] respectively). Since φ = DWf (V ), by the Tower Property of
conditional expectations we immediately obtain that when W ∈ Wk,

(81)

φk, W − φk, V = φ, W − φ, V ,

which implies

(82) lim f (W ) − f (V ) − ( φk, W − φk, V ) = 0 .

W ∈Wk,

W −V 2

W −V 2→0

26 GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS

The second method of deﬁning φk is to relate it to the Euclidean gradient over k×k symmetric matrices. This is done in Lemma 4.16 below.
In any case, we can deﬁne ηF,k : Wk ∩eﬀ-Dom(F ) → R+ for the function F : W → R∪{∞}

as follows. If V ∈ [V ] ∈ Wk ∩ eﬀ-Dom(F ), then

( φk, V − φk, W )+

(83)

ηF,k([V ]) := sup

.

W ∈Wk

V −W 2

We can also deﬁne the local slope |∂kF | : Wk ∩ eﬀ-Dom(F ) → R+ restricted to Wk as (F ([V ]) − F ([W ]))+
(84) |∂kF |([V ]) := lim sup δ2([W ], [V ]) , [W ]∈Wk, δ2([W ],[V ])→0

for [V ] ∈ Wk∩eﬀ-Dom(F ). Then, by a similar argument as shown in the proof of Theorem 4.9, we have the following corollary.

Corollary 4.15. Let f : W → R∪{∞} be an invariant function with projection F : W → R∪ {∞}. Assume that for [V ] ∈ Wk ∩ eﬀ-Dom(F ) the Fr´echet-like derivative DWf (V ) exists for all V ∈ [V ]. Then the local slope (Deﬁnition 2.10) of F at [V ] satisﬁes |∂kF |([V ]) = ηF,k([V ]).
4.4. Convergence of Gradient ﬂows on Graphons. In Section 1 we discussed that implicit Euler iteration on Wk can be viewed as the time scaling of the backward Euler iteration on the Euclidean space of k × k symmetric matrices. The following lemma complements that discussion by saying that the gradient ﬂow on Wk can be obtained from the Euclidean gradient ﬂow on the space of k × k symmetric matrices.
To set the stage, let f : W → R ∪ {∞} be an invariant function. Consider its restriction to Wk, viewed as the space of k × k symmetric matrices: fk := f ◦ K. This is a function on a closed convex subset of an Euclidean space. Suppose the function fk is C1 up to the boundary then we show that the Euclidean gradient and the Fr´echet-like derivative are equal.
Lemma 4.16. Let k ∈ N. Let f : W → R ∪ {+∞} be an invariant function that is Fr´echet diﬀerentiable according to Deﬁnition 4.6, that is, DWkf (V ) exists for every V ∈ Wk. If fk := f ◦ K is diﬀerentiable up to the boundary of [−1, 1][k](2), then for every V ∈ Wk,
k2(∇fk ◦ Mk)(V ) = (Mk ◦ DWk f )(V ) ,
where (∇fk)i,j := ∂ i,jfk for all (i, j) ∈ [k](2), and Mk is as deﬁned in Deﬁnition 2.5.
Proof. Since fk is assumed to be diﬀerentiable on a ﬁnite dimensional Euclidean space, ∇fk is its Fr´echet derivative as well. By composing with Mk, which scales distances by a constant, we get k2(∇fk ◦ Mk) is a Fr´echet-like derivative on Wk. We have already shown in equation (82) that DWkf is also a Fr´echet-like derivative on Wk. We are done by arguing that Fr´echet-like derivatives are unique by following an argument very similar to that of Lemma 4.7.

Let k ∈ N, and (Wk,t = Wk(t) ∈ Wk ∩ eﬀ-Dom(f ))t∈R+ be the Euclidean coordinate gradient ﬂow of f . This may be obtained by suitably scaling the solution of the diﬀerential equation
d (85) dt Mk(Wk(t)) = −(∇fk ◦ Mk)(Wk(t)) , Wk(0) = Wk,0 ∈ Wk ∩ eﬀ-Dom(f ) ,

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS 27

until the process hits the boundary when one or more entries is ±1. At the boundary, however, the gradient might push the process outside [−1, 1][k]2 and it needs some care to have a proper deﬁnition. Instead, we consider the Euclidean gradient ﬂow as the limit of implicit Euler iterations. This deﬁnition is valid everywhere and is equivalent to the previous one on Euclidean spaces.
As a consequence of Lemma 4.16, we obtain that the Euclidean coordinate-wise gradient descent on Wk is the gradient ﬂow on Wk. We are now ready to prove Theorem 1.2. For completeness, we reproduce the theorem statement below.

Theorem 4.17 (Convergence of Gradient Flows). Suppose F satisﬁes the following conditions:

(1) F is continuous in δ ,
(2) F is λ-semiconvex (deﬁnition 2.15) along generalized geodesics on (W, δ2) (deﬁnition 3.6), for some λ ∈ R.

Consider the gradient ﬂow of F on each Wk, ω(k) : [0, ∞) → Wk, starting at some [Uk,0]
δ
for k ∈ N \ {1}. Assume that the sequence ([Uk,0])k∈N −→ [U0], and |∂F |([U0]) < ∞ and lim supk→∞|∂ F |([Uk,0]) ≤ G < ∞, for some G ≥ 0. Then for any T ∈ R+,

(86)

lim sup sup δ ω(k)(t), ω(t) = 0 ,

k→∞ t∈[0,T ]

where ω is the unique minimizing movement curve [AGS08, Deﬁnition 2.0.6, page 42] on W for the function F starting at [U0] [AGS08, Theorem 4.0.4]. In addition, if the conditions for the existence of curves of maximal slope (Theorem 4.4 or Theorem 4.14) hold, then ω is also a curve of maximal slope.
Proof. By increasing the constant G suitably, we may assume that

(87)

max sup|∂F |([Uk,0]), |∂F |([U0]) ≤ G < ∞ .

k≥2

Fix T > 0 and let τ m be a sequence of positive time steps such that |τ m| = T /m. Since
F : W → R∪{∞} is δ -continuous and δ2([U ], · ) : W → R∪{∞} is δ -lower semicontinuous, the functional ΦF (τ, [U ]; · ) is δ -lower semicontinuous. From Lemma 3.7, it follows that ΦF satisﬁes [AGS08, Assumption 4.0.1] and hence by [AGS08, Proposition 4.0.4] we have that

ω(k)(t) = δ - lim

J (k)

m
([U

]) ,

m→∞ t/m

k,0

ω(t) = δ - lim Jt/m m([U0]) , m→∞

exist and are unique for all k ∈ N and t ∈ [0, T ]. Let [Uk,τm] : (0, 1) → W be the discrete solution (deﬁnition 4.1) of the implicit Euler
method with the sequence τ m and initial point [Uk,0], for each k ∈ N. Inductively applying the Lemma 4.5, we obtain [Uτm] : [0, T ] → W such that [Uτm] is the discrete solution of the implicit Euler method with the sequence τ m and initial point [U0] ∈ W. Passing to a
δ
subsequence and relabeling, we may assume that [Uk,τm] −→ [Uτm] uniformly on [0, T ] as k∈N
k → ∞, that is, for any ﬁxed sequence of step sizes τ m, we have δ [Uk,τm](t), [Uτm](t) → 0
uniformly over t ∈ [0, T ] as k → ∞.

28 GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS
For every t ∈ [0, T ] we have

(88)

δ2 [Uk,τm](t), ω(k)(t) < γ(|τ m|, λ, t; T, |∂ Fk|([Uk,0])) ,

(89)

δ2 [Uτm](t), ω(t) < γ(|τ m|, λ, t; T, |∂ F |([U0])) ,

for every k ∈ N where γ : {(τ, λ, t, T ) ∈ R++ × R × R++ × R++ | τ λ > −1, τ ≤ T, t ≤ T } × (0, ∞) → R+ is deﬁned as

 √τG ,

if λ = 0 ,

 

2

(90) γ(τ, λ, t; T, G) := √1+1+2|λλτ|T · √τG2 · exp − ln 1+τλτ t , if λ < 0 ,

 1 + 2λT · √τG2 · exp − ln 1+τλτ t , if λ > 0 ,

by [AGS08, Equation 4.0.6, Theorem 4.0.9, Theorem 4.0.10], and the uniform bound in equation (87). Note that γ is independent of k. Using the triangle inequality, we get

δ ω(k)(t), ω(t) ≤ δ ω(k)(t), [Uk,τ m](t) + δ [Uk,τ m](t), [Uτ m](t) + δ [Uτ m](t), ω(t) ≤ δ2 ω(k)(t), [Uk,τ m](t) + δ [Uk,τ m](t), [Uτ m](t) + δ2 [Uτ m](t), ω(t)

(91)

≤ 2γ(|τ m|, λ, t; T, G) + δ [Uk,τm](t), [Uτm](t) ,

for all k ∈ N and t ∈ [0, T ] by equations (88) and (89).
It is clear that γ(|τ m|, λ, t; T, G) → 0 uniformly on [0, T ] as |τ m| → 0. Therefore, we conclude from equation (91) that δ ω(k)(t), ω(t) → 0 uniformly on t ∈ [0, T ] as k → ∞.

Remark 4.18. The proof of the Theorem 1.2 can be carried as long as we have the uniform estimates in equation (88). In particular, if ∇fk ◦ Mk are uniformly Lipschitz, and there is a constant m ∈ R+ such that

m

2

fk(B) ≤ fk(A) +

∇fk(A), B − A

+ 2

B−A F ,

for all A, B ∈ [−1, 1][k](2), where fk := (f ◦ K) |[−1,1][k](2) , then [But16, Theorem 212A] guarantees a uniform estimate in (88) and therefore the conclusion of the theorem remains valid.

5. Examples of Gradient Flows on Graphons
In this section we ﬁnd some natural classes of examples of functions on graphons with Fr´echet-like derivatives. For any kernel [W ] ∈ W and any k ∈ N, sample {Zi}i∈[k] i.i.d. uniformly from [0, 1]. Let Gk[W ] = Wk((Zi)ki=1) := (W (Zi, Zj))(i,j)∈[k](2) ∈ [−1, 1][k](2). Let ρk([W ]) denote the probability law, Law(Gk[W ]), of Gk[W ].
Consider the functions Fk : W → R ∪ {∞} deﬁned through the function composition Fk = Hk ◦ ρk, for diﬀerent choices of Hk : P([−1, 1][k](2)) → R ∪ {∞}. Since ρk produce distributions over exchangeable k × k arrays, the function Fk is well-deﬁned over W.

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS 29

5.1. Linear functions. Let Hk : P([−1, 1][k](2)) → R ∪ {∞} be deﬁned as a linear function such that Fk takes the form

(92)

Fk([W ]) = fk, ρk([W ]) :=

fk(z)ρk([W ])(dz) ,

[−1,1][k](2)

for all [W ] ∈ W such that supp(ρk([W ])) ⊆ eﬀ-Dom(fk), where fk : [−1, 1][k](2) → R ∪ {∞} satisﬁes fk ∈ L1(ρk) and ∇fk ∈ L∞(ρk). Let fk be continuously diﬀerentiable on an open set containing supp(ρk). Suppose at each X0 ∈ [−1, 1][k](2), fk admits the following ﬁrst-order
Taylor expansion. For any ε > 0 there is some δε > 0 such that

(93)

|fk(X) − fk(X0) − ∇fk(X0), X − X0 | ≤ ε X − X0 2 ,

for any X ∈ [−1, 1][k](2) satisfying X − X0 2 ≤ δε, where · , · : R[k](2) × R[k](2) → R and · 2 are the standard Frobenius inner product and Frobenius norm over R[k](2) respectively.
Otherwise, there is a constant C0 such that

sup |fk(X) − fk(X0) − ∇fk(X0), X − X0 | ≤ C0 .
X,X0

Under these conditions, the function Fk admits a Fr´echet-like derivative as shown below. By change of variables, note that

(94)

Fk([W ]) = EWk∼ρk([W ])[fk(Wk)] = E{Zi∼Uni[0,1]}ki=1 (fk ◦ Wk) (Zi)ki=1 .

For two diﬀerent graphons [V ], [W ] ∈ W, consider their representative kernels V and W .
Since kernels are identiﬁed a.e. on [0, 1]2, we may take W (x, x) = V (x, x), a.e. on [0, 1]. Now
use the same sequence of uniform random variables (Zi)ki=1 to obtain a coupling of ρk([V ]) and ρk([W ]). This is used implicitly in the following derivation and, hence, we will skip referring to the random variables {Zi}ki=1 from here on. As a consequence of this coupling,

k

E

Vk − Wk

2 2

=

E (V (Zi, Zj) − W (Zi, Zj))2

i=1 j=i

(95) = k(k − 1) (V (x, y) − W (x, y))2 dx dy = k(k − 1) V − W 22 . [0,1]2

The ﬁrst equality is using the fact that the diagonal terms of Vk − Wk are all zeroes. Hence
E[ Vk − Wk 2] ≤ k V − W 2, by the Cauchy-Schwartz inequality. By the assumed Taylor approximation above, for any ε > 0,

|fk(Vk) − fk(Wk) − ∇fk(Wk), Vk − Wk |

(96)

≤ ε Vk − Wk 21{ Vk − Wk 2 ≤ δε} + C01{ Vk − Wk 2 > δε} .

Taking expectations on both sides,

|E[fk(Vk)] − E[fk(Wk)] − E[ ∇fk(Wk), Vk − Wk ]|

≤ εE[ Vk − Wk 2] + C0E[1{ Vk − Wk 2 > δε}] ≤ εk

≤ εk V − W + C0 k2 V − W 2 ,

2 δε2

2

V −W

2 + C0P{

Vk − Wk

2 > δε}

30 GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS

by Markov’s inequality. As V − W 2 approaches zero, it is now clear that, for any ε > 0,

(97) lim sup |E[fk(Vk)] − E[fk(Wk)] − E[ ∇fk(Wk), Vk − Wk ]| ≤ ε .

V ∈W, V −W 2→0

V −W 2

Since ε is arbitrary, the above lim sup must be zero. By the deﬁnition of Fr´echet-like derivatives (deﬁnition 4.6), we want to obtain some φ ∈
L∞([0, 1](2)) such that

(98)

E[ ∇fk(Wk), Vk − Wk ] = φ, V − W .

Let Uk := Vk − Wk (also similarly measurable with respect to {Zi}ki=1), and let us denote by A(Z) := (∇fk ◦ Wk)((Zi)ki=1). Then observe that

kk

E[ ∇fk(Wk), Vk − Wk ] =

E (A(Z))ij(Uk(Z))ij

i=1 j=1

k

k

=

E E (A(Z))ij(Uk(Z))ij Zi, Zj

i=1,j=1

=

E E (A(Z))ijU (Zi, Zj) Zi, Zj

i=1 j=i

k

=

E E (A(Z))ij Zi, Zj U (Zi, Zj)

i=1 j=i

k

=

E (A(Z))ij (Zi, Zj) = (x, y) U (x, y) dx dy

i=1 j=i [0,1]2

kk

(99) =

E (A(Z))ij (Zi, Zj) = (x, y)

[0,1]2 i=1 j=1

U (x, y) dx dy .

Notice that, including the term i = j above makes no diﬀerence in the integral. Therefore, if we choose φ ∈ L∞ [0, 1]2 to be deﬁned as

(100)

kk

φ(x, y) :=

E

i=1 j=1

(∇fk ◦ Wk) (Z ) ∈[k]

Zi = x, Zj = y ,
ij

for (x, y) ∈ [0, 1](2), then the required equality in equation (98) is satisﬁed. And the action of the Fr´echet-like derivative φ on a kernel, say U ∈ W, is

(101)

E[ ∇fk ◦ Wk, Gk[U ] ] := E (∇fk ◦ Wk) (Zi)i∈[k] , U (Zi)i∈[k] .

Lemma 5.1. If fk is λ-semiconvex on the convex set [−1, 1][k]2, then Fk is geodesically (or, generalized geodesically) k(k − 1)λ-semiconvex on W.

Proof. We only work out the proof for geodesically semiconvex. The argument for the gen-
eralized geodesic is similar. Since fk is λ-semiconvex, for some λ ∈ R, means if, for any pair X0, X1 ∈ [−1, 1][k]2, one
draws the curve Xt := (1 − t)X0 + tX1, then along that curve

(102)

λ

2

fk(Xt) ≤ (1 − t)fk(X0) + tfk(X1) −

t(1 − t) 2

X1 − X0

2,

∀ t ∈ [0, 1] .

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS 31

On the other hand, if [W0] and [W1] are two graphons, consider the constant-speed geodesic
([Wt], 0 ≤ t ≤ 1) joining the two. It has a representation in the space of kernels given by the
line segment (Wt = (1 − t)W0 + tW1, 0 ≤ t ≤ 1), where the kernels W0 and W1 are optimally coupled (see Theorem 3.1 for details). Now use the same set {Zi}ki=1 of i.i.d. Uni[0, 1] random variables as above to get a process (Wt,k)k∈N of random matrices with distributions (ρk([Wt]))k∈N respectively, for each t ∈ [0, 1]. Note that Wt,k = (1 − t)W0,k + tW1,k, t ∈ [0, 1], k ∈ N. Hence applying equation (102) to this line segment and then taking expectations with respect to the joint law of (Zi)ki=1, we get

λ Fk([Wt]) ≤ (1 − t)Fk([W0]) + tFk([W1]) − 2 t(1 − t)E

Now by equation (95), E

W1,k − W0,k

2 2

= k(k − 1) W1 − W0

Putting it back together we get

W1,k − W0,k

2 2

.

2 2

=

k(k

−

1)δ

2 2

([W

1

]

,

[W

0

]).

(103)

Fk([Wt]) ≤ (1 − t)Fk([W0]) + tFk([W1]) − k(k −2 1)λ t(1 − t)δ22([W1], [W0]) .

This proves that Fk is k(k − 1)λ-semiconvex.

5.1.1. Scalar Entropy function. The scalar entropy function E : W → R∪{∞}, deﬁned in (7), is a prominent example of a linear function for k = 2. If

(104)



h(x(1,2)) , if x(1,2) ∈ (0, 1) , 

f2 x(i,j) (i,j)∈[2]2 := 0 ,

if x(1,2) ∈ {0, 1} ,

∞ ,

otherwise ,

then from equations (92) and (94) it holds that

(105)

F2([W ]) = f2, ρ2([W ]) = E{Zi∼Uni[0,1]}2i=1[(f2 ◦ W2)(Z1, Z2)] = E{Zi∼Uni[0,1]}2i=1 [h(W (Z1, Z2))] = E ([W ]) ,

for [W ] ∈ W. Since, h(p)/p is bounded when ≤ p ≤ 1 − for some ∈ (0, 1/2), it follows
that E restricted to W := {[W ] ∈ W | ≤ W ≤ 1 − a.e.}, is continuous with respect to the weak-∗ topology on L2([0, 1]2). Since this is a weaker topology than the one generated
by δ , by [Lov12, Lemma 8.22], it follows that E restricted to W is δ -continuous. Since h (p) = 1/(p(1 − p)) ≥ 4, it follows that h is 4-semiconvex on R. Let E : W →
R ∪ {∞} be the invariant extension of E such that E(W ) := E([W ]) for all W ∈ W. Then for any W0, W1 ∈ W, deﬁning Wt := (1 − t)W0 + tW1 for t ∈ [0, 1], we have

(106)

11

E(Wt) =

h(Wt(x, y)) dx dy

00

11

4

2

≤

(1 − t)h(W0(x, y)) + th(W1(x, y)) − t(t − 1)(W0 − W1) (x, y)

00

2

1

2

= (1 − t)E(W0) + tE(W1) − 2 4t(1 − t) W0 − W1 2 ,

dx dy

which implies that E is 4-semiconvex on (W, d2). From Remark 1.3 it follows that E is 4-semiconvex along generalized geodesics on (W, δ2).

32 GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS

Suppose W is valued in (0, 1) a.e.. Then,

(107)

11

W (z1, z2)

E[ ∇f2 ◦ W2, G2[U ] ] = 0 0 log 1 − W (z1, z2) U (z1, z2) dz1 dz2 ,

for all U ∈ W. By the characterization of the Fr´echet-like derivative in equation (101) we get that φE = DW f2(W ) is given by

(108)

W (x, y) φE (x, y) = log 1 − W (x, y) ,

for a.e. (x, y) ∈ [0, 1](2). If [W ] ∈ W for some ∈ (0, 1/2), then by Theorem 4.9 the local
slope of entropy |∂E|([W ]) is given by |∂E|([W ]) = φE 2. Note that W is closed in W and since W → W 2 is δ -lower semicontinuous [Lov12,
Lemma 14.15], it follows that the local slope of entropy, |∂E|, is also δ -lower semicontinuous
on W . Following Remark 4.12, we conclude that starting from [W0] ∈ W the gradient ﬂow of E ﬂows with the velocity −DWE([W0]) at [W0] if < W0 < 1 − a.e. Consider the ﬂow Wt(x, y) obtained by solving

(109)

Wt(x, y) Wt (x, y) = − log 1 − Wt(x, y) ,

for each x, y ∈ [0, 1], with initial condition [W0] ∈ W . Then it follows that (ωt := [Wt])t∈R+ is a gradient ﬂow of E starting from [W0].

5.1.2. Homomorphism functions. For k ∈ N \ {1} we can consider interactions such as the homomorphism functions that are continuous in the cut-metric:





(110)

HF ([W ]) := E

W (Zi, Zj) =

fk(z)ρk(dz) ,

{i,j}∈E(F )

[−1,1][k](2)

where F is a simple graph with |V (F )| = k, E(F ) = {ei}mi=1, {Zi}i∈[k] are i.i.d. uniformly in
[0, 1], and fk x(i,j) (i,j)∈[k](2) = {i,j}∈E(F ) x(i,j). In particular, the function fk is a monomial for every simple graph F . Let hF : W → R be the invariant extension of HF such that hF := HF ◦ [ · ]. Since

(111)

(∇fk(X))(p,q) = 1E(F ){p, q} ·

X(i,j) ,

{i,j}∈E(F )\{{p,q}}

for p, q ∈ [k], the action of the Fr´echet-like derivative φHF = DWhF (W ) on U ∈ W according to equation (101) is given by

(112)

m

−1

m

E[ ∇fk ◦ Wk, Gk[U ] ] = E W (Zer ) · U (Ze ) ·

W (Zer ) ,

=1 r=1

r= +1

where Ze := Ze(1), Ze(2) for all e ∈ E(F ). Following a similar approach to equation (99), we obtain that φHF satisﬁes

m

m

m

(113) φHF (x, y) = E

W (Zer ) Ze = (x, y) = tx,y(Fe , W ) , x, y ∈ [0, 1] ,

=1 r=1,r=

=1

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS 33

where Fe is the graph obtained by removing the edge e from F and tx,y(Fe, W ) is the homomorphism density of a partially labeled graph deﬁned in [Lov12, Section 7.4] as





tx,y(Fe, W ) := E

W (Zf ) Ze = (x, y) .

f ∈E(Fe)

Note that for ﬁxed W and Fe, we can think of (x, y) → tx,y(Fe, W ) as a bounded measurable function on [0, 1]2. We now show that the kernel valued map W → t(·,·)(Fe, W ) is continuous with respect to · . To this end, let W, W ∈ W and consider any product function
f (x)g(y) where f ∞, g ∞ ≤ 1. Note that

tx,y(Fe, W ) =

W (xi, xj)

dx .

[0,1]k−2 {i,j}∈E(Fe)

∈V (Fe)\e

For each edge {m, n} ∈ E(Fe), consider the integral

Imn :=

(W (xm, xn) − W (xm, xn))

W (xi, xj)

dx f (x)g(y) dx dy .

[0,1]k

{i,j}∈E(Fe)\{m,n}

∈V (Fe)\e

It follows from [Lov12, Lemma 8.10] (or see the second last display in the proof of [Lov12, Lemma 10.24]) that |Imn| ≤ W − W . From the same references above, it follows that

(tx,y(Fe, W ) − tx,y(Fe, W ))f (x)g(y) dx dy ≤

|Imn| ≤ |E(Fe)| W − W .

[0,1]2

{m,n}∈E(Fe)

Taking supremum over Borel measurable functions f, g such that f ∞, g ∞ ≤ 1, we get that W → t(·,·)(Fe, W ) is Lipschitz continuous with respect to · . Since |tx,y(Fe, W )| ≤ 1
for W ∈ W, it follows that φHF (W ) ∞ ≤ |E(F )|, that is, φHF is uniformly bounded on W. For example, when F is a triangle, the velocity φHF follows from equation (113) as
φHF (x, y) = 3 01 W (x, z)W (z, y) dz, for a.e. x, y ∈ [0, 1], i.e., thrice the ‘operator product’ of W with itself [Lov12, Section 7.4] (denoted by W ◦ W ). If F is a path on 3 vertices
and 2 edges, then φHF (x, y) = 01 W (x, z) dz + 01 W (y, z) dz = deg(x) + deg(y), where deg(x) := 01 W (x, z) dz for all x ∈ [0, 1].
Obtaining the expression for the Fr´echet-like derivative in equation (113), given a gradient
ﬂow ω of HF , we can compute the velocity of the gradient ﬂow as DW HF (ωt)1Gωt for t > 0.
The Hessian of the function fk can be easily computed as

∂ f x(i,j)x(p,q) k =

x(a,b) ,

{a,b}∈E(F )\{{i,j},{p,q}}

if {i, j} = {p, q} are both edges in E(F ), and zero otherwise. Since every x(i,j) ∈ [−1, 1] for all (i, j) ∈ [k](2), every entry of the Hessian is uniformly
bounded in [−1, 1] and hence Hess(fk) op ≤ k(k − 1)/2. Therefore, fk is (−k(k − 1)/2)semiconvex w.r.t. d2. It follows from Lemma 5.1 that homomorphism function HF is (−k2(k− 1)2/2)-semiconvex w.r.t. δ2. In fact, since Hess(fk)({i, j}, {p, q}) is non-zero only when
{i, j}, {p, q} ∈ E(F ), it follows that Hess(fk) op ≤ m(m − 1) ≤ m. This would yield that HF is (−mk(k − 1))-semiconvex w.r.t. δ2. This is useful when F is sparse.

34 GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS

5.1.3. Linear combination of Entropy and Homomorphism function. Let β ∈ R and let F be a ﬁnite simple graph with k ∈ N vertices and m ∈ N edges. Deﬁne the function G =
Gβ,F := E + βHF on the set Wε. The function G is of particular interest in the theory
of exponential graph models (see Section 1). The function G is δ -continuous on Wε and since E is 4-semiconvex and HF is λ-semiconvex w.r.t. δ2, it follows that G is also (4 + βλ)semiconvex w.r.t. δ2 for some λ ∈ R that we estimate in Section 5.1.2. The gradient ﬂow of G, therefore, exists and the Fr´echet-like derivative φG = DWG(W ) = φE + βφHF . Since E is 4-semiconvex and HF is (−k2(k − 1)2/2)-semiconvex w.r.t. δ2, it follows that Gβ,F is (4 − βk2(k − 1)2/2)-semiconvex w.r.t. δ2. Therefore, Gβ,F is at least 0-semiconvex (i.e., convex) w.r.t. δ2 when β ≤ 8/k2(k − 1)2. Since the behavior of gradient ﬂows are drastically diﬀerent between convex and non-convex functions, β ≤ 8/k2(k − 1)2 guarantees exponential
rates of convergence of the gradient ﬂow curve. See [AGS08, Theorem 4.0.4, part (iv)].

5.2. Interaction energy. In the optimal transport literature, linear functionals of probability measures are often called potential energy [San15, page 249]. Inspired by similar deﬁnitions, one can deﬁne interaction energy. Let fk : [−1, 1][k](2) × [−1, 1][k](2) → R be a function deﬁned on pairs of k ×k symmetric matrices with entries in [−1, 1]. Given a graphon
[W ] ∈ W, as before let ρk = Law(Gk[W ]). This deﬁnes a function Fk : W → R ∪ {∞} given by

Fk([W ]) :=

fk(z, z )ρk(dz)ρk(dz ) .

[−1,1][k](2) [−1,1][k](2)

Although it looks diﬀerent than before, this is also a particular case of (101) as shown below. Deﬁne two independent sequences of i.i.d. Uni[0, 1] random variables: (Z1, . . . , Zk) and (Z1, . . . , Zk), and consider the corresponding matrices

Wk := (W (Zi, Zj))(i,j)∈[k](2) , and Wk := (W (Zi, Zj))(i,j)∈[k](2) .

Then Wk and Wk are i.i.d. samples from ρk and Fk([W ]) = E[fk(Wk, Wk)]. On the other hand, one can concatenate (Zi)ki=1 and (Zi)ki=1 to construct a single vector (Z1, . . . , Zk, Z1, . . . , Zk) of dimension 2k and consider the corresponding 2k × 2k symmetric matrix W2k whose block diagonal components are Wk and Wk. By deﬁning f¯k(W2k) := fk(Wk, Wk), we represent Fk([W ]) = E f¯2k(W2k) = f¯2k(w)ρ2k(dw) and the Taylor approximation formula (101) continues to hold.
An example of interaction energy is given by “variance of homomorphism functions”. As
before, let F be a simple graph and Wk, Wk be i.i.d. sampled (k × k) symmetric matrices from a graphon [W ]. Consider the function

(114)



2





1

Fk([W ]) := 2 E

W (Ze) −

W (Ze)  = Var

W (Ze) ,

e∈E(F )

e∈E(F )

e∈E(F )

by symmetry, where Ze := Ze(1), Ze(2) and Ze := (Ze(1), Ze(2)) for all e ∈ E(F ). In fact, the above identity holds for whenever we take fk(z, z ) = (gk(z) − gk(z ))2, for any function gk on [−1, 1][k]2 that is square-integrable w.r.t. ρk. Unfortunately this particular function Fk in (114) is continuous in δ2 but not in the cut metric. See [Jan13, Theorem 10.15]. Hence, although the curve of maximal slope exists due to the existence of Fr´echet-like derivatives, this
particularly natural example does not satisfy the assumptions of our convergence theorem.

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS 35

U1 ← Z1

1

U2 ← Z2

U4 ← Z4

2

4

3 U3 ← Z3
(a) F .

Z1 1
2 Z2
3 Z3
(b) F1.

U5 ← Z1

1 Z4

2

4

U6 ← Z2 3

U7 ← Z3

(c) F2.

Figure 2. An illustration for the assignment of random variables {Ui}ki=1+1 k2.

A similar but slightly diﬀerent example of interaction which does satisfy our conditions can be constructed as follows. For a simple graph F with k vertices, consider its simple subgraphs F1 and F2 with k1 and k2 vertices respectively, such that every vertex and edge in F is contained in at least one of the subgraphs. Pool all the uniform random variables {Zi}ki=1 1 ∪ {Zi}ki=2 1 to get a single set of k1 + k2 ≥ k i.i.d. Uni[0, 1] random variables {Ui}ik=1+1 k2 such that {Ui}ki=1 1 = {Zi}ki=1 1 and {Ui}ki=k1+1 = Zj j∈V (F )\V (F1). Refer to Figure 2 for an
illustration. We can then deﬁne IF1,F2( · ; F ) : W → R ∪ {∞} as



  



IF1,F2([W ]; F ) := logE

W (Zi, Zj) + logE

W (Zi, Zj)

{i,j}∈E(F1)

{i,j}∈E(F2)





(115)

− 2 logE

W (Ui, Uj) ,

{i,j}∈E(F )

for some ∈ (0, 1). Each of the terms in the expression in equation (115) is the logarithm of the homomorphism densities of a simple graph. Logarithms of homomorphisms are well studied in graph theory and, in particular, related to the max-cut problem (see [Lov12, Remark 5.4, Example 5.18]).
We can construct a graph F1F2 by forming the disjoint union of F1 and F2, identifying the vertices of the same label, adding all the edges between vertices with the same label according to [Lov12, Section 4.2]. F1F2 can have multiple edges. Then, using [Lov12, Proposition 7.1] for the homomorphism density as a simple graph parameter, we get that the determinant of the connection matrix of the homomorphism density

(116)

HF1F1([W ])HF2F2([W ]) − HF21F2([W ]) ≥ 0 , i.e., HF1F1H([W2 ])H([WF2F])2([W ]) ≥ 1 . F1 F2

By the assumption that each vertex and edge of F is contained in at least one of the subgraphs,
if we identify the multiple edges between the same pair of vertices in F1F2 we get back F (see Figure 2). Since H is a simple graph parameter, we have HF1F2 = HF , HF1F1 = HF1 and HF2F2 = HF2, by deﬁnition. Thus, taking logarithms in the ﬁnal expression of (116), we get IF1,F2( · ; F ) ≥ 0. It is exactly zero if F1 and F2 are vertex disjoint. Thus, one may think that IF1,F2( · ; F ) measures the dependence of the two subgraphs on the homomorphism density.

36 GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS
We can similarly construct higher order interactions by considering multiple subgraphs instead of just two. In that case, one may consider the logarithm of the determinant of the connection matrix of the homomorphism density and deﬁne I suitably.
The argument in Section 5.1.2 shows that this function satisfy all our conditions. The computation for its Fr´echet-like derivative also follows from Section 5.1.2 followed by the application of the chain rule for derivatives. Logarithms of determinants of matrices play an important role in displacement convexity of Wasserstein optimal transport (see [McC97, proof of Theorem 2.2]). It is an interesting coincidence that they also appear in this context.

5.3. Internal energy. Similar to potential and interaction energies, one can deﬁne nonlinear functions of ρk corresponding to what are called ‘internal energies’ in the optimal transport literature. Let u be a real-valued function on [0, ∞) such that u(0) = 0. For a probability measure ρ on an Euclidean space, deﬁne the function

U (ρ) :=

[−1,1][k](2) u(ρ(z)) dz , ∞,

if ρ is absolutely continuous , otherwise .

Here we have used the standard abuse of notation in optimal transport literature of denoting an absolutely continuous measure and its density by the same notation. This deﬁnes a nonlinear function on graphons in the following manner. For 1 ≤ l ≤ k, consider a function Gk,l : [−1, 1][k]2 → [−1, 1]l that selects a particular subset of length l from the upper-diagonal elements of a k × k matrix. Consider the pushforward ρk,l([W ]) := (Gk,l) (ρk([W ])). Since
ρk is generated by k i.i.d. Uni[0, 1] random variables, and l ≤ k, it is easy to come up with examples where ρk,l has a density. For example, take W (x, y) = sin(x + y), k = 3, l = 2, and Gk,l(A) = (A1,2, A1,3). Thus (Gk,l ◦ Gk)([W ]) = (sin(Z1 + Z2), sin(Z1 + Z3)). This random
vector has a density. Thus, the function U (ρk,l([W ])) for [W ] ∈ W has a non-empty domain. A prominent example of such functions is the diﬀerential entropy for which u(x) = x log x where one computes the diﬀerential entropy of ρk,l([W ]).
Such functions cannot have Fr´echet-like derivatives since a necessary condition for its existence is that the function must be continuous in L2. On the other hand, one cannot expect a discrete to continuum convergence as considered here. Even in the case of Wasserstein gradient ﬂows, gradient ﬂow of entropy is obtained by adding Brownian noise to particles and not by taking limits of Euclidean gradient ﬂows.

5.4. A computational example from extremal graph theory. Mantel’s theorem [Man07] (a special case of Tur´an’s theorem) states that the maximum number of edges in an n-vertex triangle-free graph is n2/4. Further, any Hamiltonian graph with at least n2/4 edges must either be the complete bipartite graph Kn/2,n/2 or it must be pancyclic [Bon71].
One can computationally “verify” this result by simulating gradient ﬂows of linear com-
binations of homomorphism functions over (W, δ2). For example, consider minimizing
H − H−/10 over W0, where and − are the triangle and the edge graph respectively. Thus graphons with small function values have small triangle density and large edge density. We set n = 128, step-size τ = 10−3 and perform forward Euler iterations starting from an initial graphon W0(n) ∈ Wn as shown in Figure 3a. Figure 3 shows instances of the iterative
process after 103, 1.5 × 103, 2.5 × 103, 5 × 103 and 104 many steps. We see in Figure 3f that after 104 iteration, the kernel W1(0n4) is close to the one corresponding to a complete bipartite

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS 37

(a) W0(128)

(b) W1(01328)

(c) W1(.152×81)03

(d) W2(.152×81)03

(e) W5(×12180)3

(f) W1(01428)

Figure 3. A gradient descent simulation over H − H−/10.

graph as one would expect from Mantel’s theorem. Our Theorem 1.2 implies that one should expect a similar evolution for all large values of n.

6. Continuity Equations

It is well-known that any absolutely continuous curve in the Wasserstein space can be

represented as the solution of a continuity equation [San15, Section 5.3]. Something partially

analogous is true for graphons, although the presence of the boundary of W makes the

situation more delicate and we can only characterize AC curves via the continuity equation

until it hits the boundary.

Suppose we are given some ω : [0, 1] → W in AC(W, δ2). From Theorem 3.1, we obtain

(Wt)t∈[0,1] ∈ AC(W, d2) such that ω(t) = [Wt] for all t ∈ [0, 1]. It follows from the Radon-

Nikody´m property that there exists vt := Wt ∈ L2([0, 1](2)), for a.e. t ∈ [0, 1], such that

Wt − W0 =

t 0

Ws

d

s.

Let {Ui}∞ i=1 be i.i.d.

uniformly from [0, 1] and deﬁne measurable

functions Wk,t : [0, 1]k → [−1, 1][k](2) as

(117)

Wk,t (ui)ki=1 := (Wt(ui, uj ))(i,j)∈[k](2) ,

for every k ≥ 2. Deﬁne a vector ﬁeld vk,t : [−1, 1][k](2) → R[k](2) as

(118)

vk,t(z) := E (Wt (Ui, Uj))(i,j)∈[k](2) Wk,t (Un)kn=1 = z .

Theorem 6.1. Let k ≥ 2, and ρk,t = Law(Gkω(t)) (see Deﬁnition 2.6). Then, for a.e.
t ∈ [0, 1], the continuity equation ∂ tρk,t +∇·(vk,tρk,t) = 0 holds weakly with Dirichlet boundary conditions. By that we mean, for any continuously diﬀerentiable test function f on [−1, 1][k]2,

38 GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS
vanishing at the boundary,
∂ t f (z) dρk,t(z) − ∇f (z)vk,t(z) dρk,t(z) = 0 ,
holds for t a.e. in [0, 1]. Proof. By deﬁnition, ρk,t is the law of the random symmetric matrix Wk,t((Ui)ki=1). Fix a smooth real valued function f ∈ C1([−1, 1][k](2), R) vanishing at the boundary of [−1, 1][k]2. By the change of variables

(119)

[−1,1][k](2) f (z)ρk,t(z) dz = [0,1]k f (Wt(ui, uj ))(i,j)∈[k](2) dλ[0,1]k (ui)ki=1 ,

where λ[0,1]k is the Lebesgue measure on [0, 1]k. Note that vk,t ∈ L2(ρk,t). Taking time derivative on both sides of equation (119) for t in
the set of full measure where Wt is deﬁned,

∂t

f (z)ρk,t(z) dz =

[−1,1][k](2)

∂ tf (Wt(ui, uj ))(i,j)∈[k](2) dλ[0,1]k (ui)ki=1
[0,1]k

=

(∇f ◦ Wt,k) (ui)ki=1 , (Wt (ui, uj ))(i,j)∈[k](2) dλ[0,1]k (ui)ki=1

[0,1]k

(120)

=

∇f (z),

(Wt (ui, uj ))(i,j)∈[k](2) dµz(ui)ki=1 dz ,

[−1,1][k](2)

{ | } (ui)ki=1∈[0,1]k Wk,t=z

where {µz}z∈[−1,1][k](2) is the disintegration of λ[0,1]k , with respect to the function Wk,t. By
deﬁnition of vt,k, the above expression is exactly equal to [−1,1][k](2) ∇f (z), vk,t(z)ρk,t(z) dz. This completes the proof.

The formula (118) has a martingale property that is worth mentioning.
Let us consider any v ∈ L1([0, 1](2)). Then for any k ∈ N, given [W ] ∈ W and any of its representatives W ∈ [W ], we can deﬁne Wk : [0, 1]k → [−1, 1][k](2) as

Wk (u )k=1 := (W (ui, uj))(i,j)∈[k](2) ,

and vk : [−1, 1][k](2) → R[k](2) as

(121)

vk(z)(i, j) = E v(Ui, Uj) Wk (U )k=1 = z ,

where {Ui}i∈N are i.i.d. uniformly from [0, 1]. Intuitively, formula (121) means that we average the edge weights from v over all embeddings of the vertex labeled weighted graph z in the graphon W . Since Wk−1 = Tkk−1 ◦ Wk, we have that σ(Wk−1) ⊆ σ(Wk), which deﬁned a ﬁltration (Fk := σ(Wk))k∈N.
First we show that vk is a function of the graphon and not its kernel representative.
Lemma 6.2. For any ϕ ∈ T , we have vkϕ(Wkϕ) = vk(Wk), for all k ∈ N, where vϕ(x, y) := v(ϕ(x), ϕ(y)) for all (x, y) ∈ [0, 1](2).

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS 39

Proof. For any ϕ ∈ T , given {Ui}i∈N, let us deﬁne Vi := ϕ(Ui) for all i ∈ N. Since ϕ λ[0,1] =
λ[0,1], {Vi}i∈N is a set of i.i.d. uniform random variables in [0, 1]. Using this, observe that for any (i, j) ∈ [k](2),

vkϕ(Wkϕ)(i, j) = E vϕ(Ui, Uj) Wkϕ (U )k=1 = E v(ϕ(Ui), ϕ(Uj)) Wk ϕ(U )k=1

(122)

= E v(Vi, Vj) Wk (V )k=1 = vk(Wk)(i, j) ,

holds, completing the proof.
Proposition 6.3. For every i, j ∈ N, the process (vk(Wk)(i, j))∞ k=max{i,j} is a martingale with respect to the ﬁltration (Fk)k∈N.
Proof. Follows from the tower property, since, for k ≥ max{i, j},

vk(Wk)(i, j) = E[v(Ui, Uj) | Wk] = E[E[v(Ui, Uj) | Wk+1] | Wk] = E[vk+1(Wk+1(i, j)) | Wk] ,

completing the proof.

As an example, consider the continuity equation for the scalar entropy. From equation (108) it follows that the velocity of gradient ﬂow for scalar entropy function satisﬁes

(123)

W (x, y)

v([W ])(x, y) = − log

,

1 − W (x, y)

(x, y) ∈ [0, 1]2 ,

if 0 < W < 1 a.e. Let {Ui}∞ i=1 be i.i.d. random variables in Uni[0, 1], then using equation (121) we can compute the velocities appearing in the continuity equation in this case as

vk(z)(i, j) = E v(Ui, Uj) Wk (U )k=1 = z

= −E log W (Ui, Uj) 1 − W (Ui, Uj)

k

z(i, j)

Wk (U ) =1 = z = − log 1 − z(i, j) .

Unfortunately, for our other examples, the velocity ﬁelds do not have closed form expressions since they are averages over all possible embeddings of a labeled weighted graph in a graphon.

[AdHR21] [AGS08]
[Ald81] [Ald82] [AOY19] [Aus08] [Aus12] [Aus15] [BC21]

References
Siva Athreya, Frank den Hollander, and Adrian R¨ollin. Graphon-valued stochastic processes from population genetics. The Annals of Applied Probability, 31(4):1724 – 1745, 2021. Luigi Ambrosio, Nicola Gigli, and Giuseppe Savar´e. Gradient Flows: In Metric Spaces and in the Space of Probability Measures. Second Edition. Lectures in Mathematics. ETH Zu¨rich. Birkh¨auser Verlag AG, 2008. David J Aldous. Representations for partially exchangeable arrays of random variables. Journal of Multivariate Analysis, 11(4):581–598, 1981. David J Aldous. On exchangeability and conditional independence. Exchangeability in probability and statistics (Rome, 1981), pages 165–170, 1982. Dyego Arau´jo, Roberto I Oliveira, and Daniel Yukimura. A mean-ﬁeld limit for certain deep neural networks. arXiv preprint arXiv:1906.00193, 2019. Tim Austin. On exchangeable random variables and the statistics of large graphs and hypergraphs. Probability Surveys, 5:80–145, 2008. Tim Austin. Exchangeable random arrays. In Notes for IAS workshop, 2012. Tim Austin. Exchangeable random measures. Annales de l’Institut Henri Poincar´e, Probabilit´es et Statistiques, 51(3):842 – 861, 2015. Francis Bach and Lena¨ıc Chizat. Gradient descent on inﬁnitely wide neural networks: Global convergence and generalization. arXiv preprint arXiv:2110.08084, 2021.

40 GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS

[BCCH18]
[BCL+08]
[BCL+12]
[BEFLY21]
[BG20] [Bon71] [But16] [CB18]
[CCP19] [CD13] [CD20] [Cha17] [Che16] [Cra16] [CV11] [DGKR15] [DJ08] [DSS+20] [EG18] [FK99] [GK20] [Hoo82] [Huf77]

Christian Borgs, Jennifer T. Chayes, Henry Cohn, and Nina Holden. Sparse exchangeable graphs and their limits via graphon processes. Journal of Machine Learning Research, 18(210):1–71, 2018. Christian Borgs, Jennifer T Chayes, L´aszl´o Lov´asz, Vera T S´os, and Katalin Vesztergombi. Convergent sequences of dense graphs I: Subgraph frequencies, metric properties and testing. Advances in Mathematics, 219(6):1801–1851, 2008. Christian Borgs, Jennifer T Chayes, L´aszl´o Lov´asz, Vera T S´os, and Katalin Vesztergombi. Convergent sequences of dense graphs II. multiway cuts and statistical physics. Annals of Mathematics, pages 151–219, 2012. Omri Ben-Eliezer, Eldar Fischer, Amit Levi, and Yuichi Yoshida. Ordered graph limits and their applications. In 12th Innovations in Theoretical Computer Science Conference (ITCS 2021). Schloss Dagstuhl-Leibniz-Zentrum fu¨r Informatik, 2021. Bhaswar B Bhattacharya and Shirshendu Ganguly. Upper tails for edge eigenvalues of random graphs. SIAM Journal on Discrete Mathematics, 34(2):1069–1083, 2020. J Adrian Bondy. Pancyclic graphs i. Journal of Combinatorial Theory, Series B, 11(1):80–84, 1971. John Charles Butcher. Numerical methods for ordinary diﬀerential equations. John Wiley & Sons, 2016. L´ena¨ıc Chizat and Francis Bach. On the global convergence of gradient descent for overparameterized models using optimal transport. In Proceedings of the 32nd International Conference on Neural Information Processing Systems, NIPS’18, page 3040–3050, Red Hook, NY, USA, 2018. Curran Associates Inc. Jos´e Antonio Carrillo, Katy Craig, and Francesco S Patacchini. A blob method for diﬀusion. Calculus of Variations and Partial Diﬀerential Equations, 58(2):1–53, 2019. Sourav Chatterjee and Persi Diaconis. Estimating and understanding exponential random graph models. The Annals of Statistics, 41(5):2428–2461, 2013. Nicholas Cook and Amir Dembo. Large deviations of subgraph counts for sparse Erd˝os–R´enyi graphs. Advances in Mathematics, 373:107289, 2020. Sourav Chatterjee. Large deviations for random graphs: E´cole d’E´t´e de Probabilit´es de SaintFlour XLV-2015, volume 2197. Springer, 2017. Bobbie G. Chern. Large deviations approximation to normalizing constants in exponential models. PhD thesis, Stanford University, 2016. Harry Crane. Dynamic random networks and their graph limits. The Annals of Applied Probability, 26(2):691 – 721, 2016. Sourav Chatterjee and SR Srinivasa Varadhan. The large deviation principle for the Erd˝os-R´enyi random graph. European Journal of Combinatorics, 32(7):1000–1017, 2011. Peter Diao, Dominique Guillot, Apoorva Khare, and Bala Rajaratnam. Diﬀerential calculus on graphon space. Journal of Combinatorial Theory, Series A, 133:183–227, 2015. Persi Diaconis and Svante Janson. Graph limits and exchangeable random graphs. Rendiconti di Matematica e delle sue Applicazioni, 28(1):33–61, 2008. Pinar Demetci, Rebecca Santorella, Bj¨orn Sandstede, William Staﬀord Noble, and Ritambhara Singh. Gromov-Wasserstein optimal transport to align single-cell multi-omics data. bioRxiv, 2020. Ronen Eldan and Renan Gross. Exponential random graphs behave like mixtures of stochastic block models. The Annals of Applied Probability, 28(6):3698–3735, 2018. Alan Frieze and Ravi Kannan. Quick approximation to matrices and applications. Combinatorica, 19(2):175–220, 1999. Saeid Ghafouri and Seyed Hossein Khasteh. A survey on exponential random graph models: an application perspective. PeerJ Computer Science, 6:e269, 2020. David N Hoover. Row-column exchangeability and a generalized model for probability. Exchangeability in probability and statistics (Rome, 1981), pages 281–291, 1982. R.E. Huﬀ. The Radon-Nikody´m property for Banach-spaces — a survey of geometric aspects. In Klaus-Dieter Bierstedt and Benno Fuchssteiner, editors, Functional Analysis: Surveys and Recent Results, volume 27 of North-Holland Mathematics Studies, pages 1–13. North-Holland, 1977.

GRADIENT FLOWS ON GRAPHONS: EXISTENCE, CONVERGENCE, CONTINUITY EQUATIONS 41

[Jan13] [Jan16] [JKO98] [Kal89] [KY17] [Lov12] [LS06] [LS07] [LZ15] [LZ17] [Man07] [McC97] [M´em11] [Mun00] [NP20] [RVE18]
[San15]
[San17] [SMM19]
[SMN18] [SS20a] [SS20b] [Stu12] [TR20]
[Vil03]

Svante Janson. Graphons, cut norm and distance, couplings and rearrangements. NYJM Monographs, 4, 2013. Svante Janson. Graphons and cut metric on sigma-ﬁnite measure spaces. arXiv preprint arXiv:1608.01833, 2016. Richard Jordan, David Kinderlehrer, and Felix Otto. The variational formulation of the Fokker– Planck equation. SIAM Journal on Mathematical Analysis, 29(1):1–17, 1998. Olav Kallenberg. On the representation theorem for exchangeable arrays. Journal of Multivariate Analysis, 30(1):137–154, 1989. Richard Kenyon and Mei Yin. On the asymptotics of constrained exponential random graphs. Journal of Applied Probability, 54(1):165–180, 2017. L´aszl´o Lov´asz. Large Networks and Graph Limits, volume 60 of Colloquium publications. American Mathematical Society, 2012. L´aszl´o Lov´asz and Bal´azs Szegedy. Limits of dense graph sequences. Journal of Combinatorial Theory, Series B, 96(6):933–957, 2006. L´aszl´o Lov´asz and Bal´azs Szegedy. Szemer´edi’s lemma for the analyst. Geometric And Functional Analysis, 17:252–270, 2007. Eyal Lubetzky and Yufei Zhao. On replica symmetry of large deviations in random graphs. Random Structures & Algorithms, 47(1):109–146, 2015. L´aszl´o Mikl´os Lov´asz and Yufei Zhao. On derivatives of graphon parameters. Journal of Combinatorial Theory Series A, 145(C):364–368, January 2017. Willem Mantel. Problem 28. Wiskundige Opgaven, 10(60-61):320, 1907. Robert J McCann. A convexity principle for interacting gases. Advances in Mathematics, 128(1):153–179, 1997. Facundo M´emoli. Gromov–Wasserstein distances and the metric approach to object matching. Found. Comput. Math, 11:417–487, 2011. James R Munkres. Topology. Prentice Hall Upper Saddle River, 2000. Phan-Minh Nguyen and Huy Tuan Pham. A rigorous framework for the mean ﬁeld limit of multilayer neural networks. arXiv preprint arXiv:2001.11443, 2020. Grant M Rotskoﬀ and Eric Vanden-Eijnden. Parameters as interacting particles: long time convergence and asymptotic error scaling of neural networks. In Proceedings of the 32nd International Conference on Neural Information Processing Systems, pages 7146–7155, 2018. Filippo Santambrogio. Optimal Transport for Applied Mathematicians: Calculus of Variations, PDEs, and Modeling, volume 87 of Progress in Nonlinear Diﬀerential Equations and Their Applications. Springer International Publishing, 2015. Filippo Santambrogio. {Euclidean, metric, and Wasserstein} gradient ﬂows: an overview. Bulletin of Mathematical Sciences, 7(1):87–154, 2017. Mei Song, Theodor Misiakiewicz, and Andrea Montanari. Mean-ﬁeld theory of two-layers neural networks: dimension-free bounds and kernel limit. In Conference on Learning Theory, pages 2388–2464. PMLR, 2019. Mei Song, Andrea Montanari, and P Nguyen. A mean ﬁeld view of the landscape of two-layers neural networks. Proceedings of the National Academy of Sciences, 115:E7665–E7671, 2018. Justin Sirignano and Konstantinos Spiliopoulos. Mean ﬁeld analysis of neural networks: A central limit theorem. Stochastic Processes and their Applications, 130(3):1820–1852, 2020. Justin Sirignano and Konstantinos Spiliopoulos. Mean ﬁeld analysis of neural networks: A law of large numbers. SIAM Journal on Applied Mathematics, 80(2):725–752, 2020. Karl-Theodor Sturm. The space of spaces: curvature bounds and gradient ﬂows on the space of metric measure spaces. Available at arXiv:1208.0434v1, 2012. Belinda Tzen and Maxim Raginsky. A mean-ﬁeld theory of lazy training in two-layer neural nets: entropic regularization and controlled McKean-Vlasov dynamics. arXiv preprint arXiv:2002.01987, 2020. C´edric Villani. Topics in Optimal Transportation, volume 58 of Graduate Studies in Mathematics. American Mathematical Society, 2003.

