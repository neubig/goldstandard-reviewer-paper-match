arXiv:2006.11909v2 [stat.ML] 19 Nov 2020

Two-Sample Testing on Ranked Preference Data
and the Role of Modeling Assumptions
Charvi Rastogi1, Sivaraman Balakrishnan2, Nihar Shah1,3, Aarti Singh1 Machine Learning Department1, Department of Statistics2, Computer Science Department3
Carnegie Mellon University Email: {crastogi@cs, siva@stat, nihars@cs, aarti@cs}.cmu.edu
Abstract
A number of applications require two-sample testing on ranked preference data. For instance, in crowdsourcing, there is a long-standing question of whether pairwise-comparison data provided by people is distributed identically to ratings-converted-to-comparisons. Other applications include sports data analysis and peer grading. In this paper, we design two-sample tests for pairwise-comparison data and ranking data. For our two-sample test for pairwise-comparison data, we establish an upper bound on the sample complexity required to correctly test whether the distributions of the two sets of samples are identical. Our test requires essentially no assumptions on the distributions. We then prove complementary lower bounds showing that our results are tight (in the minimax sense) up to constant factors. We investigate the role of modeling assumptions by proving lower bounds for a range of pairwise-comparison models (WST, MST, SST, parameterbased such as BTL and Thurstone). We also provide tests and associated sample complexity bounds for the problem of two-sample testing with partial (or total) ranking data. Furthermore, we empirically evaluate our results via extensive simulations as well as three real-world data sets consisting of pairwise-comparisons and rankings. By applying our two-sample test on real-world pairwise-comparison data, we conclude that ratings and rankings provided by people are indeed distributed diﬀerently.
1 Introduction
Data in the form of pairwise-comparisons, or more generally partial or total rankings, arises in a wide variety of settings. For instance, when eliciting data from people (say, in crowdsourcing), there is a long-standing debate over the diﬀerence between two methods of data collection: asking people to compare pairs of items or asking people to provide numeric scores to the items. A natural question here is whether people implicitly generate pairwise-comparisons using a fundamentally diﬀerent mechanism than ﬁrst forming numeric scores and then converting them to a comparison. Thus, we are interested in testing if the data obtained from pairwise-comparisons is distributed identically to if the numeric scores were converted to pairwise-comparisons (Raman and Joachims, 2014; Shah et al., 2016). As another example consider sports and online games, where a match between two players or two teams is a pairwise-comparison between them (Herbrich et al., 2007; Hvattum and Arntzen, 2010; Van Der Maas and Wagenmakers, 2005). Again, a natural question that arises here is whether the relative performance of the teams has changed signiﬁcantly across a certain period of time (e.g., to design an appropriate rating system (Cattelan et al., 2013)). A third example is peer grading where students are asked to compare pairs of homeworks (Shah et al., 2013) or rank a batch of homeworks (Lamon et al., 2016; Raman and Joachims, 2014). A question of interest here is whether a certain group of students (female/senior/...) grade very diﬀerently as compared to another group (male/junior/...) (Shah et al., 2018). Additionally, consumer preferences as pairwise-comparisons or partial (or total) rankings can be
1

used to investigate whether a certain group (married/old/...) make signiﬁcantly diﬀerent choices about purchasing products as opposed to another group (single/young/...) (Cavagnaro and Davis-Stober, 2014; Regenwetter et al., 2011).
Each of the aforementioned problems involves two-sample testing, that is, testing whether the distribution of the data from two populations is identical or not. With this motivation, in this paper we consider the problem of two-sample testing on preference data in the form of pairwise-comparisons and, more generally, partial and total rankings. First, we focus our eﬀorts on preference data in the form of pairwise-comparisons. Speciﬁcally, consider a collection of items (e.g., teams in a sports league). The data we consider comprises comparisons between pairs of these items, where the outcome of a comparison involves one of the items beating the other. In the two-sample testing problem, we have access to two sets of such pairwise-comparisons, obtained from two diﬀerent sources (e.g., the current season in a sports league forming one set of pairwise-comparisons and the previous season forming a second set). The goal is to test whether the underlying distributions (winning probabilities) in the two sets of data are identical or diﬀerent. Similarly, when the data comprises of partial or total rankings over a collection of items from two diﬀerent sources, our goal is to test whether the distributions over total rankings for the two sources are identical or not. Speciﬁcally, we consider the case where a partial ranking is deﬁned as a total ranking over some subset of the collection of items.
Contributions. We now outline the contributions of this paper; the theoretical contributions for the pairwise-comparison setting are also summarized in Table 1.
• First, we present a test for two-sample testing with pairwise-comparison data and associated upper bounds on its minimax sample complexity. Our test makes essentially no assumptions on the outcome probabilities of the pairwise-comparisons.
• Second, we prove information-theoretic lower bounds on the critical testing radius for this problem. Our bounds show that our test is minimax optimal for this problem.
• As a third contribution, we investigate the role of modeling assumptions: What if one could assume one of the popular models (e.g., BTL, Thurstone, parameter-based, SST, MST, WST) for pairwisecomparison outcomes? We show that our test is minimax optimal under WST and MST models. We also provide an information-theoretic lower bound under the SST and parameter-based models. Conditioned on the planted clique hardness conjecture, we prove a computational lower bound for the SST model with a single observation per pair of items, which matches the sample complexity upper bound attained by our test, up to logarithmic factors.
• Fourth, we conduct experiments on two real-world pairwise-comparison data sets. Our test detects a statistically signiﬁcant diﬀerence between the distributions of directly-elicited pairwise-comparisons and converting numeric scores to comparison data. On the other hand, from the data available for four European football leagues over two seasons, our test does not detect any statistically signiﬁcant diﬀerence between the relative performance of teams across two consecutive seasons.
• Finally, we present algorithms for two-sample testing on partial (or total) ranking data for two partial ranking models—namely, the Plackett-Luce model and a more general marginal probability based model. We provide upper bounds on sample complexity for the test for the Plackett-Luce model controlling both the Type I and Type II error. Moreover, our test for the marginal probability based model controls the Type I error. We apply our test to a real-world data set on sushi preferences. Our test ﬁnds a statistically signiﬁcant diﬀerence in sushi preferences across sections of diﬀerent demographics based on age, gender and region of residence.
Related literature. The problem of two-sample testing on ranked preference data is at the intersection of two rich areas of research—two-sample testing and analyzing ranked preference data. The
2

Model (M) Model-free WST and MST SST
Parameter-based

Upper Bound

for k > 1, (Thm. 1)

2M ≤ c k1d

2M ≤ c k1d

2M ≤ c k1d

2M ≤ c k1d

Lower Bound 2M > c I(kk>d 1) + I(k 4= 1) (Prop. 4) 2M > c k1d (Thm. 3) 2M > c kd13/2
2M > c kd13/2 (Thm. 5)

Computational Lower Bound 2M > c I(kk>d 1) + I(k 4= 1)

2M > c k1d

for k

=

1,

2 M

>

c

kd(log log(d))2 (Thm. 6)

2M > c kd13/2

Table 1. This table summarizes our results for two-sample testing of pairwise-comparison data (introduced formally in Equation 1), for common pairwise-comparison models. Here, d denotes the number of items, and we obtain k samples (comparisons) per pair of items from each of the two populations. In this work, we provide upper and lower bounds on the critical testing radius M, deﬁned in (3). The upper bound in Theorem 1 is due to the test in Algorithm 1 which is computationally eﬃcient. We note that the constant c varies from result to result.

problem of two-sample testing has a long history in statistics, and classical tests include the t-test and Pearson’s χ2 test (see for instance Lehmann and Romano, 2005 and references therein). More recently, non-parametric tests (Gretton et al., 2012a,b; Rosenbaum, 2005; Kim et al., 2020b; Szekely and Rizzo, 2004) have gained popularity but these can perform poorly in structured, high-dimensional settings. The minimax perspective on hypothesis testing which we adopt in this work originates in the work of Ingster (1994) (and was developed further in Ingster (1997); Ingster and Suslina (2003); Ingster (1994)). Several recent works have studied the minimax rate for two-sample testing for high-dimensional multinomials (Balakrishnan and Wasserman, 2018, 2019; Chan et al., 2014; Valiant and Valiant, 2017; Valiant, 2011), and testing for sparsity in regression (Carpentier et al., 2018; Collier et al., 2017), we build on some of these ideas in our work. We also note the work of Mania et al. (2018) who propose a kernel-based two-sample test for distributions over total rankings.
The analysis of pairwise-comparison data is a rich ﬁeld of study, dating back at least 90 years to the seminal work of Louis Thurstone (1927) and subsequently Bradley and Terry (1952) and Luce (1959). Along with this, Plackett (1975) and Luce (1959) worked on the now-well-known Plackett-Luce model for partial and total rankings. In the past two decades, motivated by crowdsourcing and other applications, there is signiﬁcant interest in studying such data in a high-dimensional setting, that is, where the number of items d is not a ﬁxed constant. A number of papers (Shah et al., 2016; Chen and Suh, 2015; Negahban et al., 2012; Rajkumar and Agarwal, 2014; Szörényi et al., 2015; Guiver and Snelson, 2009; Maystre and Grossglauser, 2015, and references therein) in this space analyze parameter-based models such as the BTL and the Thurstone models for pairwise-comparison data and the Plackett-Luce model for partial (or total) ranking data. Here the goal is usually to estimate the parameters of the model or the underlying ranking of the items. The papers (Ailon, 2012; Braverman and Mossel, 2008; Chatterjee and Mukherjee, 2019; Chen et al., 2018; Falahatgar et al., 2017; Rajkumar et al., 2015, and references therein) also study ranking from pairwise-comparisons, under some diﬀerent assumptions.
Of particular interest is the paper by Aldous (2017) which uses the BTL model to make match predictions in sports, and also poses the question of analyzing the average change in the performance of teams over time. While this paper suggests some simple statistics to test for change, designing principled tests is left as an open problem. To this end, we provide a two-sample test without any assumptions and with rigorous guarantees, and also use it subsequently to conduct such a test on real-world data.
A recent line of work (Heckel et al., 2019; Shah et al., 2017; Shah and Wainwright, 2018) focuses on the role of the modeling assumptions in estimation and ranking from pairwise-comparisons. We study

3

the role of modeling assumptions from the perspective of two-sample testing and prove performance guarantees for some pairwise-comparison models.
Organization. The remainder of this paper is organized as follows. In Section 2, we formally describe the problem setup and provide some background on the minimax perspective on hypothesis testing. We also provide a detailed description of the pairwise-comparison models studied in this work. In Section 3 we present our minimax optimal test for pairwise-comparison data and present the body of our main technical results for the pairwise-comparison setting with brief proof sketches and defer technical aspects of the proofs to Section 6. Then, in Section 4 we extend our results for the two-sample testing problem on partial (or total) ranking data. We describe two partial ranking models and provide testing algorithms and associated sample complexity bounds. The corresponding proofs are in Section 6. In Section 5, we present our ﬁndings from implementing our testing algorithms on three real-world data sets. Furthermore, we present results of simulations on synthetic data which validate our theoretical ﬁndings. We conclude with a discussion in Section 7.

2 Background and problem formulation for pairwise-comparison setting
In this section, we provide a more formal statement of the problem of two-sample testing using pairwisecomparison data along with background on hypothesis testing and the associated deﬁnition of risk, and various types of ranking models.

2.1 Problem statement

Our focus in this paper is on the two-sample testing problem where the two sets of samples come

from two potentially diﬀerent populations. Here, we describe the model of the data we consider in

our work. Speciﬁcally, consider a collection of d items. The two sets of samples comprise outcomes

of comparisons between various pairs of these items. In the ﬁrst set of samples, the outcomes are

governed by an unknown matrix P ∈ [0, 1]d×d. The (i, j)th entry of matrix P is denoted as pij, and

any comparison between items i and j results in i beating j with probability pij, independent of

other outcomes. We assume there are no ties. Analogously, the second set of samples comprises

outcomes of pairwise-comparisons between the d items governed by a (possibly diﬀerent) unknown

matrix Q ∈ [0, 1]d×d, wherein item i beats item j with probability qij, the (i, j)th entry of matrix Q. For any pair (i, j) of items, we let kipj and kiqj denote the number of times a pair of items (i, j)

is compared in the ﬁrst and second set of samples respectively. Let Xij denote the number of times

item i ∈ [d] beats item j ∈ [d] in the ﬁrst set of samples, and let Yij denote the analogous quantity in

the second set of samples. It follows that Xij and Yij are Binomial random variables independently

distributed

as

Xij

∼

Bin(kipj , pij )

and

Yij

∼

Bin(k

q ij

,

qij

)

.

We

adopt

the

convention

of

setting

Xij

=

0

when kipj = 0, and Yij = 0 when kiqj = 0, and kipi = kiqi = 0.

Our results apply to both the symmetric and asymmetric settings of pairwise-comparisons:

Symmetric setting: The literature on the analysis of pairwise-comparison data frequently considers a symmetric setting where “i vs. j” and “j vs. i” have an identical meaning. Our results apply to this setting, for which we impose the additional constraints that pji = 1 − pij and qji = 1 − qij for all (i, j) ∈ [d]2. In addition, for every 1 ≤ i ≤ j ≤ d, we set kjpi = kjqi = 0 (and hence Xji = Yji = 0), and let kipj, kiqj, Xij and Yij represent the comparisons between the pair of items (i, j) .

Asymmetric setting: Our results also apply to an asymmetric setting where “i vs. j” may have a diﬀerent meaning as compared to “j vs. i”. For instance, in a setting of sports where “i vs. j” could

4

indicate i as the home team and j as the visiting team. This setting does not impose the restrictions described in the symmetric setting above.

Hypothesis test. Consider any class M of pairwise-comparison probability matrices, and any parameter > 0. Then,the goal is to test the hypotheses

H0 : P = Q

1

(1)

H1 : d |||P − Q|||F ≥ ,

where P, Q ∈ M.

2.2 Hypothesis testing and risk
We now provide a brief background on hypothesis tests and associated terminology. In hypothesis testing, the Type I error is deﬁned as the probability of rejecting the null hypothesis H0 when the null hypothesis H0 is actually true, an upper bound on the Type I error is denoted by α; the Type II error is deﬁned as the probability of failing to reject the null when the alternate hypothesis H1 is actually true, an upper bound on Type II error is denoted by β. The performance of the testing algorithm is evaluated by measuring its Type I error and its power, which is deﬁned as one minus the Type II error.
Consider the hypothesis testing problem deﬁned in (1). We deﬁne a test φ as φ : {kipj, kiqj, Xij, Yij}(i,j)∈[d]2 → {0, 1}. Let P0 and P1 denote the distribution of the input variables under the null and under the alternate respectively. Here, we assume that the variables kipj and kiqj are ﬁxed for all (i, j) ∈ [d2]. Let M0 and M1( ) denote the set of matrix pairs (P, Q) that satisfy the null condition and the alternate condition in (1) respectively. Then, we deﬁne the minimax risk (Ingster, 1994, 1997; Ingster and Suslina, 2003; Ingster, 1994) as

RM = inf{ sup P0(φ = 1) + sup P1(φ = 0)},

(2)

φ (P,Q)∈M0

(P,Q)∈M1( )

where the inﬁmum is over all {0, 1}-valued tests φ. It is common to study the minimax risk via a coarse lens by studying instead the critical radius or the minimax separation. The critical radius is the smallest value for which a hypothesis test has non-trivial power to distinguish the null from the alternate. Formally, we deﬁne the critical radius as

M = inf{ : RM ≤ 1/3}.

(3)

The constant 1/3 is arbitrary; we could use any speciﬁed constant in (0, 1). In this paper, we focus on providing tight bounds on the critical radius.

2.3 A range of pairwise-comparison models
A model for the pairwise-comparison probabilities is a set of matrices in [0, 1]d×d. In the context of our problem setting, assuming a model means that the matrices P and Q are guaranteed to be drawn from this set. In this paper, the proposed test and the associated guarantees do not make any assumptions on the pairwise-comparison probability matrices P and Q. In other words, we allow P and Q to be any arbitrary matrices in [0, 1]d×d. However, there are a number of models which are popular in the literature on pairwise-comparisons, and we provide a brief overview of them here. We analyze the role of these modeling assumptions in our two-sample testing problem. In what follows, we let M ∈ [0, 1]d×d denote a generic pairwise-comparison probability matrix, with Mij representing the probability that item i ∈ [d] beats item j ∈ [d]. The models impose conditions on the matrix M .

5

• Parameter-based models: A parameter-based model is associated with some known, non-decreasing function f : R → [0, 1] such that f (θ) = 1 − f (−θ) ∀ θ ∈ R. We refer to any such function f as being “valid”. The parameter-based model associated to a given valid function f is given by

Mij = f (wi − wj) for all pairs (i, j),

(4)

for some unknown vector w ∈ Rd that represents the notional qualities of the d items. It is typically
assumed that the vector w satisﬁes the conditions i∈[d] wi = 0 and that w ∞ is bounded above by a known constant.

1 – Bradley-Terry-Luce (BTL) model: This is a speciﬁc parameter-based model with f (θ) = 1 + e−θ . – Thurstone model: This is a speciﬁc parameter-based model with f (θ) = Φ(θ), where Φ is the
standard Gaussian CDF.

• Strong stochastic transitivity (SST): The model assumes that the set of items [d] is endowed with an unknown total ordering π, where π(i) < π(j) implies that item i is preferred to item j. A matrix M ∈ [0, 1]d×d is said to follow the SST model if it satisﬁes the shifted-skew-symmetry condition Mij = 1 − Mji for every pair i, j ∈ [d] and the condition

Mi ≥ Mj for every i, j ∈ [d] such that π(i) < π(j) and for every ∈ [d].

(5)

• Moderate stochastic transitivity (MST): The model assumes that the set of items [d] is endowed with an unknown total ordering π. A matrix M ∈ [0, 1]d×d is said to follow the MST model if it satisﬁes
Mij = 1 − Mji for every pair i, j ∈ [d] and the condition

Mi ≥ min{Mij, Mj } for every i, j, ∈ [d] such that π(i) < π(j) < π( ).

(6)

• Weak stochastic transitivity (WST): The model assumes that the set of items [d] is endowed with an unknown total ordering π. A matrix M ∈ [0, 1]d×d is said to follow the WST model if it satisﬁes Mij = 1 − Mji for every pair i, j ∈ [d] and the condition
Mij ≥ 1 for every i, j ∈ [d] such that π(i) < π(j). (7) 2
Model hierarchy: There is a hierarchy between these models, that is, {BTL, Thurstone} ⊂ parameterbased ⊂ SST ⊂ MST ⊂ WST ⊂ model-free

3 Main results for pairwise-comparison setting
We now present our main theoretical results for pairwise-comparison data.
3.1 Test and guarantees
Our ﬁrst result provides an algorithm for two-sample testing in the problem (1), and associated upper bounds on its sample complexity. Importantly, we do not make any modeling assumptions on the probability matrices P and Q. First we consider a per-pair ﬁxed-design setup in Theorem 1 where for every pair of items (i, j), the sample sizes kipj, kiqj are equal to k. Following that, in Corollary 2, we consider a random-design setup wherein for every pair of items (i, j), the sample sizes kipj, kiqj are drawn i.i.d. from some distribution D supported over non-negative integers. Our test is presented in Algorithm 1. The test statistic (8) is designed such that it has an expected value of zero under the null and a large expected value under the alternate. The following theorem characterizes the performance of this test, thereby establishing an upper bound on the sample complexity of this two-sample testing problem in a random-design setting.

6

Input: Samples Xij, Yij denoting the number of times item i beat item j in the observed kipj, kiqj pairwise-comparisons from populations denoted by probability matrices P, Q respectively.
Test Statistic:

d d kiqj (kiqj − 1)(Xi2j − Xij ) + kipj (kipj − 1)(Yi2j − Yij ) − 2(kipj − 1)(kiqj − 1)Xij Yij

T=

Iij

p

q

p

q

(8)

i=1 j=1

(kij − 1)(kij − 1)(kij + kij )

where Iij = I(kipj > 1) × I(kiqj > 1). Output: If T ≥ 11d, where 11d is the threshold, then reject the null.
Algorithm 1: Two-sample test with pairwise-comparisons for model-free setting

Theorem 1. Consider the testing problem in (1) with M as the class of all pairwise probability matrices. Suppose the number of (per pair) comparisons between the two populations is ﬁxed, kipj = kiqj = k (for all i = j in the asymmetric setting and all i < j in the symmetric setting). There is a constant c > 0 such that for any > 0, if k > 1 and 2 ≥ c 1 , then the sum of Type I error and Type II error of
kd Algorithm 1 is at most 31 .

The proof is provided in Section 6.2. Theorem 1 provides a guarantee of correctly distinguishing

between

the

null

and

the

alternate

with

probability

at

least

23 .

The

value

2 3

is

closely

tied

to

the

speciﬁc

threshold used in the test above. More generally, for any speciﬁed constant ν ∈ (0, 1), the test achieves

a probability of error at most ν by setting the threshold as d 24(2 − ν) , with the same order of sample ν
complexity as in Theorem 1. Moreover, if the sample complexity is increased by some factor R, then

running Algorithm 1 on R independent instances of the data and taking the majority answer results

in error probability that decreases exponentially with R as (exp(−2R)), while the sample complexity

increases only linearly in R. One can thus have a very small probability of error of, for instance, d−50

with k = O d12 . Later, in Proposition 4, we show that under the ﬁxed k condition, kipj = kiqj = k, we

have that k > 1 is necessary for our two-sample testing problem. It is also interesting to note that the

estimation rate to test the hypotheses in (1) is k = O

log(d)
2

while the rate for our testing algorithm

is k = O

1 d2

.

Now, we consider the random-design setup wherein for every pair of items (i, j), the sample sizes kipj, kiqj are drawn i.i.d. from some distribution D supported over non-negative integers. Let µ and σ

denote the mean and standard deviation of distribution D respectively, and let p1 := PrZ∼D(Z = 1).

We assume that D has a ﬁnite mean and that

µ ≥ c1p1; µ ≥ c2σ,

(9)

for some constants c1 > 1 and c2 > 1. Many commonly occurring distributions obey these properties, for instance, Binomial distribution, Poisson distribution, geometric distribution and discrete uniform distribution, with appropriately chosen parameters.

Corollary 2. Consider the testing problem in (1) with M as the class of all pairwise probability matrices. Suppose the number of comparisons in the two populations kipj, kiqj are drawn i.i.d. from some distribution D that satisﬁes (9) (for all i = j in the asymmetric setting and all i < j in the symmetric setting). There is a constant c > 0 such that if 2 ≥ c max{ 1 , 1 }, then the sum of Type I error and
µd d2
Type II error of Algorithm 1 is at most 31 .

7

The proof of Corollary 2 is in Section 6.1. In Corollary 2, we see that the even under the random-design

setup, our test achieves the same testing rate as in the per-pair ﬁxed-design setup considered in

Theorem 1, for µ ≤ d. We now evaluate the performance of Algorithm 1 when kipj, kiqj are drawn i.i.d. from one of the

following commonly occurring distributions. Consider any arbitrary matrices P and Q. We specialise

Corollary 2 to these distributions by stating the sample complexity that guarantees that the probability

of

error

is

at

most

1 3

in

the

two-sample

testing

problem

(1),

wherein

constant

c

may

depend

on

c1, c2

for

each distribution. Note that, as in Corollary 2, we assume 2d2 ≥ c where c is some positive constant

• Binomial distribution (kipj, kiqj i∼id Bin(n, a)) : Suﬃcient condition n ≥ c max{ ad1 2 , a1 }.

• Poisson distribution (kipj, kiqj i∼id Poisson(λ)) : Suﬃcient condition λ ≥ c max{ d12 , 1}.

• Geometric Distribution (kipj, kiqj i∼id Geometric(a)): Suﬃcient condition a1 ≥ c max{ d12 , 1}.

• Discrete Uniform Distribution (kipj, kiqj i∼id Unif(0, n)): Suﬃcient condition n ≥ c max{ d12 , 1}.

Next, we note that a sharper but non-explicit threshold in Algorithm 1 can be obtained using the permutation test method to control the Type I error. We detail this approach in Algorithm 2.

Input : Samples Xij, Yij denoting the number of times item i beat item j in the observed kipj, kiqj pairwise-comparisons from populations denoted by probability matrices P, Q respectively. Signiﬁcance level α ∈ (0, 1). Iteration count γ.

(1) Compute the test statistic T deﬁned in (8).

(2) For ← 1 to γ :

(i) Repeat this step independently for all i = j in the asymmetric setting and for all i < j in the symmetric setting. Collect the (kipj + kiqj) samples together and reassign kipj of the samples chosen uniformly at random to P and the rest to Q.

Compute the new values of Xij and Yij based on this reassignment.

(ii) Using the new values of Xij and Yij, recompute the test statistic in (8).

Denote the computed test statistic as T .

Output : Reject the null if p =

γ =1

1 γ

1

(T

− T ) < α.

Algorithm 2: Permutation test with pairwise-comparisons for model-free setting.

More generally, the results in Theorem 1 and Corollary 2 (and the following converse results in Theorem 3 and Proposition 4) also apply to the two-sample testing problem of comparing two Bernoulli matrices (or vectors) P and Q, wherein each entry of the matrices (or vectors) is a Bernoulli parameter. In this problem, we want to test whether two Bernoulli matrices are identical or not, and we have access to some observations of some (or all) of the underlying Bernoulli random variables.
We conclude this section with a proof sketch for Theorem 1; the complete proof is provided in Section 6.1 and 6.2.

Proof Sketch for Theorem 1. The test statistic T is designed to ensure that EH0 [T ] = 0 for any arbitrary pairwise probability matrices P, Q such that P = Q, and for any values of {kipj, kiqj}1≤i,j≤d. We lower bound the expected value of T under the alternate hypothesis as EH1 [T ] ≥ ckd2 2 (Lemma 10). Next, we show that the variance of T is upper bounded under the null by 24d2 and under the alternate by 24d2 + 4kd2 2 (Lemma 11). These lemmas allow us to choose a suitable threshold value of 11d.
Finally, using Chebyshev’s inequality comparing the square of expectation with the variance, we obtain
the desired upper bound on the sample complexity with guarantees on both Type I and Type II errors.

8

3.2 Converse results and the role of modeling assumptions
In this section we look at the role of modeling assumptions on the pairwise-comparison probability matrices in the two-sample testing problem in (1).

Lower bound for MST, WST, and model-free classes. Having established an upper bound on the rate of two-sample testing without modeling assumptions on the pairwise-comparison probability matrices P, Q, we show matching lower bounds that hold under the MST class. The WST and model-free classes are both supersets of MST, and hence the following guarantees automatically apply to them as well.
Theorem 3. Consider the testing problem in (1) with M as the class of matrices described by the MST model. Suppose we have k comparisons for each pair (i, j) from each population. There exists a constant c > 0, such that the critical radius M is lower bounded as 2M > kcd .
The lower bound on the rate matches the rate derived for Algorithm 1 in Theorem 1, thereby establishing the minimax optimality of our algorithm (up to constant factors). The MST class is a subset of the WST model class. This proves that Algorithm 1 is simultaneously minimax optimal under the MST and WST modeling assumptions in addition to the model-free setting. We provide a proof sketch for Theorem 3 in Section 3.2.1; the complete proof is in Section 6.3.3.

Necessity of µ > p1. Recall that the upper bound derived in Theorem 1 under the model-free setting holds under the assumption that k > 1 and, similarly, Corollary 2 holds under the assumption that µ ≥ c1p1 with c1 > 1, as stated in (9). We now state a negative result for the case µ ≤ p1, which implies that kipj, kiqj ≤ 1 ∀ (i, j) under the random-design setup and k ≤ 1 under the per-pair ﬁxed-design setup.

Proposition 4. Consider the testing problem in (1) with M as the class of all pairwise probability

matrices. Suppose we have at most one comparison for each pair (i, j) from each population (for all

i = j in the asymmetric setting and all i < j in the symmetric setting). Then, for any value of ≤ 12 ,

the minimax risk deﬁned in (2) is at least 12 , thus,

2 M

≥

14 .

We provide some intuition for this result here. If kipj = kiqj ≤ 1 ∀ (i, j), then at best one has access to ﬁrst order information of each entry of P and Q, that is, one has access to only Pr(Xij = 1), Pr(Yij = 1), Pr(Xij = 1, Yij = 1) for each pair (i, j). This observation allows us to construct a case wherein the null and the alternate cannot be distinguished from each other by any test, due to the inaccessibility of
higher order information of the underlying Bernoulli random variables. The complete proof is provided
in Section 6.3.2.

Lower bound for parameter-based class. We now prove an information-theoretic lower bound for our two-sample testing problem wherein the probability matrices follow the parameter-based model.
Theorem 5. Consider the testing problem in (1). Consider any arbitrary non-decreasing function f : R → [0, 1] such that f (θ) = 1 − f (−θ) ∀ θ ∈ R, with M as the parameter-based class of probability matrices associated to the given function. Suppose we have k comparisons for each pair (i, j) from each population. There exists a constant c > 0, such that the critical radius M is lower bounded as 2M > kdc3/2 .
This lower bound also applies to probability matrices in the SST class described in (5). We provide a brief proof sketch in Section 3.2.1; the complete proof is in Section 6.3.4.

9

Computational lower bound for SST class. Given the polynomial gap between Theorem 1 and Theorem 5, it is natural to wonder whether there is another polynomial-time testing algorithm for testing under the SST and/or parameter-based modeling assumption. We answer this question in the negative, for the SST model and single observation model (k = 1), conditionally on the average-case hardness of the planted clique problem (Jerrum, 1992; Kučera, 1995). In informal terms, the planted clique conjecture asserts that√there is no polynomial-time algorithm that can detect the presence of a planted clique of size κ = o( d) in an Erdős-Rényi random graph with d nodes. We construct SST matrices that are similar to matrices in the planted clique problem and as a direct consequence of the planted clique conjecture, we have the following result.
Theorem 6. Consider the testing problem in (1) with M as the class of matrices described by the SST model. Suppose the planted clique conjecture holds. Suppose we have one comparison for each pair (i, j) from each population. Then there exists a constant c > 0 such that for polynomial-time testing algorithms the critical radius M is lower bounded as 2M > d(log locg(d))2 .
Thus, for k = 1, the computational lower bound on the testing rate for the SST model matches the rate derived for Algorithm 1 (up to logarithmic factors). The proof of Theorem 6 is provided in Section 6.3.5. We devote the rest of this section to a sketch of the proofs of Theorem 3 and Theorem 5.

3.2.1 Proof sketches for Theorem 3 and Theorem 5

To prove the information-theoretic lower bound under the diﬀerent modeling assumptions, we construct

a null and alternate belonging to the corresponding class of probability matrices. The bulk of our

technical eﬀort is devoted to upper bounding the chi-square divergence between the probability measure

under the null and the alternate. We then invoke Le Cam’s lower bound for testing to obtain a lower

bound on the minimax risk which gives us the information-theoretic lower bound. We now look at the

constructions for the two modeling assumptions.

Lower bound construction for MST class (Section 6.3.3). We construct a null and alternate such that

under the null P = Q = [ 12 ]d×d and under the alternate P = [ 12 ]d×d and Q ∈ Θ with d1 |||P − Q|||F = .

For this, we deﬁne a parameter η ∈ [0, 12 ] and then deﬁne Θ as a set of matrices in which the upper

right

quadrant

has

exactly

one

entry

equal

to

1 2

+η

in

each

row

and

each

column

and

the

remaining

entries above the diagonal are 12 . The entries below the diagonal follow from the shifted-skew-symmetry

condition. We consider the alternate where Q is chosen uniformly at random from the set Θ of

probability matrices in MST class.

Lower bound construction for parameter-based class (Section 6.3.4). The construction is same as the

construction given above except we deﬁne a diﬀerent set Θ of probability matrices. According to

the parameter-based model, the matrices P and Q depend on the vectors wp ∈ Rd and wq ∈ Rd

respectively. Now, for simplicity in this sketch, suppose that d is even. We set wp = [0, · · · , 0], which

ﬁxes

pij

=

1 2

∀

(i, j).

Consider

a

collection

of

vectors

each

with

half

the

entries

as

δ

and

the

other

half

as −δ, thereby ensuring that i∈[d] wi = 0. We set δ to ensure that each of the probability matrices

induced by this collection of vectors obey d1 |||P − Q|||F = . We then consider the setting where Q is chosen uniformly at random from the set of pairwise-comparison probability matrices induced by the

collection of values of wQ.

4 Two-sample testing with partial or total ranking data
In this section, we extend our work from the previous sections to two-sample testing for ranking data. We focus on the two-sample testing problem where the two sets of samples from two potentially diﬀerent populations comprise of partial or total rankings over various subsets of d items. Speciﬁcally, we consider the case where a partial ranking is deﬁned as a total ranking over some subset of d items. Let λP and λQ be two unknown probability distributions over the set of all d-length rankings. We observe

10

two sets of partial or total rankings, one set from each of two populations. The partial rankings in the ﬁrst set are assumed to be drawn i.i.d. according to λP , and the partial rankings in second set are drawn i.i.d. according to λQ. Each sample obtained is a ranking over a subset of items of size ranging from 2 to d. Henceforth, we use the term total ranking to specify a ranking over all d items. We assume there are no ties.

Hypothesis test Our goal is to test the hypothesis,
H0 : λP = λQ (10) H1 : λP = λQ.
In the sequel, we consider this hypothesis testing problem under certain modeling assumptions on λP and λQ.

4.1 Models
We now describe two partial ranking models that we analyse subsequently.

Marginal probability based model This is a non-parametric partial ranking model that is entirely speciﬁed by the probability distribution over all total rankings, given by λP in the ﬁrst population and λQ in the second population. The distribution λ deﬁnes the partial ranking model for the corresponding population as follows. Let Sd denote the set of all total rankings over the d items. Consider some subset of items Ω ⊆ [d] of size m ∈ {2, · · · , d}, and let τΩ be a ranking of the items in this set. Then, we deﬁne a set of all total rankings that obey the partial ranking τΩ as

S(τΩ) = {τ ∈ Sd : τ (τΩ−1(1)) < τ (τΩ−1(2)) < · · · < τ (τΩ−1(m))}.

(11)

The marginal probability based partial ranking model gives the probability of a partial ranking τΩ as

P(τΩ) =

λ(τ ),

τ ∈S(τΩ)

(12)

where λ represents λP or λQ for the corresponding population. This model deﬁnes the probability of a partial ranking similarly to the non-parametric choice model described in Farias et al. (2013). In fact, their choice model deﬁned over sets of size 2 is the same as our model over partial rankings of size 2. Our model has the desired property that given a partial ranking over the set Ω containing item i and item j, the marginal probability that item i is ranked higher than item j, denoted by P(i j), does not depend on other items in set Ω. Subsequently, the marginal probability is expressed as

P(i j|Ω) =

λ(τ )

τ ∈S(τΩ),τ (i)<τ (j)

=

λ(τ )

τ ∈Sd,τ (i)<τ (j)

Now, for the two populations we deﬁne the marginal probability of pairwise-comparisons over items
(i, j) as pij and qij for all pairs (i, j) with i < j. Note that this model has the property that pij = 1 − pji and qij = 1 − qji for all (i, j). We also note that the Plackett-Luce model described next is a subset of this model.

11

Plackett-Luce model This model introduced by Luce (1959) and Plackett (1975) is a commonly
used parametric model for ranking data. In this model, each item has a notional quality parameter
wi ∈ R, ∀ i ∈ [d]. Under the Plackett-Luce model, the partial rankings in each population are generated according to the corresponding underlying quality parameters, namely wiP∈[d] and wiQ∈[d]. The weight parameters completely deﬁne the probability distribution λ over the set of all total rankings. In this
model, a partial (or total) ranking τ is generated in a sequential manner where each item in a ranking
is viewed as chosen from the set of items ranked lower. The probability of choosing an item i from any set S ⊆ [d] is given by (i ∈exSp)(ewxip)(wi ) . To explain the sequential generation procedure, we show an example here,

P(i1 i2 · · · i ) =

exp(wij ) .

j=1 j =j exp(wij )

An important property of the Plackett-Luce model is that the marginal probability that item i is
ranked higher than item j, P(i j) does not depend on the other items in the ranking, in fact, P(i j) = (exp(wexi)p+(wexip) (wj)) . For each pair (i, j), we denote the marginal probability P(i j) corresponding to the parameters wiP∈[d] as pij. Similarly, we denote the marginal probability P(i j) corresponding to the parameters wiQ∈[d] as qij. These pairwise marginal probabilities pij and qij are collected in pairwise-comparison probability matrices P and Q respectively.
Finally, with this notation, we specialise the hypothesis testing problem in (10) for the two partial
ranking models described above, in terms of the pairwise probability matrices P and Q. For any given
parameter > 0, we deﬁne the two-sample testing problem as

H0 : P = Q

1

(13)

H1 : d |||P − Q|||F ≥ .

We note that under the Plackett-Luce model, the null condition in (10) is equivalent to the null condition in (13). Moreover, under the Plackett-Luce model, diﬀerence in two probability distributions λP and λQ is captured by diﬀerence in the pairwise probability matrices P and Q. Thus, we specialise the alternate condition in (10) in terms of scaled Frobenius distance between the pairwise probability matrices, P and Q, denoted by the parameter , to get the alternate condition in (13). Furthermore, under the marginal probability based model, the null condition in (10) implies P = Q whereas the converse is not true. That is, there exist pairs of probability distributions over the set of all d-length rankings λP and λQ, that follow the marginal probability based model with λP = λQ, such that their corresponding pairwise probability matrices P and Q are equal. Thus, under the marginal probability based model, by conducting a test for the hypothesis testing problem in (13) that controls the Type I error at level α, we get control over Type I error at level α for the hypothesis testing problem in (10).

We are now ready to describe our main results for two-sample testing with partial (or total) ranking data.

4.2 Main results
Our testing algorithms for ranking data build upon the test statistic in Algorithm 1. To test for diﬀerence in probability distributions λP and λQ, we ﬁrst use a rank breaking method to convert the data into pairwise-comparisons, on which we apply the test statistic in (8). Given a rank breaking method, denoted by R, and rankings from the two populations, SPi and SQi for i ∈ [N ], then the rank breaking algorithm yields pairwise-comparison data as R(SPi∈[N] ) = {kipj, Xij}(i,j)∈[d]2 and, similarly, R(SQi∈[N] ) = {kiqj , Yij }(i,j)∈[d]2 . Here, kipj , kiqj , Xij , Yij represent the pairwise-comparison data as deﬁned

12

in Section 2.1. Now, we describe three rank breaking methods that we subsequently use in our testing algorithms, Algorithm 3 and Algorithm 4.

1. Random disjoint: In this method, denoted by RR, given a set of N partial (or total) rankings,

we randomly break each ranking up into pairwise-comparisons such that no item is in more than

one pair. In this method, each m-length ranking yields

m 2

pairwise-comparisons.

2. Deterministic disjoint: We use this rank breaking method, denoted by RD, when we have N

total rankings. In this method, we deterministically break each ranking into pairwise-comparisons

so that no item is in more than one pair. So, we get

d 2

pairwise-comparisons from each total

ranking. First, we want the number of samples to be divisible by d, so we throw away (N mod d)

rankings chosen randomly. Then arbitrarily without looking at the data, partition the remaining

rankings into

N d

disjoint subsets each containing d rankings. Within each subset, we convert

the d rankings into d

d 2

pairwise-comparisons deterministically such that we observe at least one

comparison between each pair (i, j) ∈ [d] with i < j. We keep exactly one pairwise-comparison

for each pair in a subset. In this manner, we get to observe exactly

N d

comparisons between

each pair of items.

3. Complete: In this method, denoted by RC, given a set of N partial (or total) rankings, we
break each ranking into all possible pairwise-comparisons for that ranking. In this method, each m-length ranking yields m2 pairwise-comparisons.

Now, equipped with the rank breaking methods, we describe our ﬁrst result which provides an algorithm (Algorithm 3) for the two-sample testing problem in (13) for the Plackett-Luce model, and associated upper bounds on its sample complexity.
Input : Two sets SP and SQ of m-length partial rankings, where 2 ≤ m ≤ d. The two sets of partial rankings, SP and SQ correspond to pairwise probability matrices P and Q respectively, according to the Plackett-Luce model. Rank breaking method, R ∈ {RR, RD, RC}. (1) Using the rank breaking method get

{kipj , Xij }(i,j)∈[d]2,i<j ← R(SP ); {kiqj , Yij }(i,j)∈[d]2,i<j ← R(SQ).

(2) Execute Algorithm 1.
Algorithm 3: Two-sample testing with partial ranking data for Plackett-Luce model.
We note that both Algorithm 3 and Algorithm 4, deﬁned in this section, can be used with any of the three rank breaking methods described. The subsequent guarantees provided depend on the rank breaking method used, as we see in Theorem 7 and Theorem 8. In our results for two-sample testing under the Plackett-Luce modeling assumption, we consider two cases. In the ﬁrst case, for some m ∈ {2, · · · , d − 1}, each sample is a ranking of some m items chosen uniformly at random from the set of d items. In the second case, the samples comprise of total rankings, that is, m = d. The following two theorems characterize the performance of Algorithm 3 thereby establishing an upper bound on the sample complexity of the two-sample testing problem deﬁned in (13). In these theorems we use the disjoint rank breaking methods so that the pairwise-comparisons created from a ranking are independent.

Theorem 7. Consider the testing problem in (13) where pairwise probability matrices P and Q follow the Plackett-Luce model. Suppose we have N samples, where for some m ∈ {2, · · · , d−1}, each sample is
a ranking of some m items chosen uniformly at random from the set of d items. Then, there are positive constants c, c0, c1 and c2 such that if N ≥ c d2 lomg(d) dc02 and ≥ c1d−c2 , then Algorithm 3 with the “Random disjoint” rank breaking method will correctly distinguish between P = Q and d1 |||P − Q|||F ≥ , with probability at least 23 .

13

The proof of Theorem 7 is provided in Section 6.4. The lower bound assumption on in Theorem 7 is to ensure that the suﬃcient number of pairwise comparisons needed after applying the random disjoint rank breaking algorithm, is not very large. Theorem 7 is a combined result of the random disjoint rank breaking algorithm and the result in Theorem 1. When we have total rankings, Algorithm 3 with the “Deterministic disjoint” rank breaking method yields an improvement in the sample complexity by a logarithmic factor. We state this formally in the following theorem.

Theorem 8. Consider the testing problem in (13) where pairwise probability matrices P and Q follow

the Plackett-Luce model. Suppose we have N samples of total rankings from each population. Then,

c there are positive constants c, c1 and c2 such that if N ≥ 2d

and ≥ c1d−c2 , then Algorithm 3

d2

with the “Deterministic disjoint” rank breaking method will correctly distinguish between P = Q and

d1 |||P − Q|||F ≥ , with probability at least 23 .

The proof of Theorem 8 is provided in Section 6.5. These two results provide an upper bound on the

sample complexity when using partial (and total) rankings for the two-sample testing problem in (13)

under

the

Plackett-Luce

model.

In

Theorem

7

and

Theorem

8

the

lower

bound

of

2 3

on

probability

of success is tied to the speciﬁc threshold used in Algorithm 1 in the same manner as described for

Theorem 1. Speciﬁcally, for any constant ν ∈ (0, 1), Algorithm 3 can achieve a probability of error at

most ν with the same order of sample complexity as mentioned in Theorem 7 and Theorem 8.

Algorithm 3 addresses the problem of two-sample testing under the Plackett-Luce model. Now,

we provide a permutation test based algorithm for the more general, non-parametric model, namely,

marginal probability based model. The permutation test method described in Algorithm 4 gives a

sharper (implicit) threshold than that in Algorithm 3. Note that Algorithm 4 doesn’t require any

assumptions on the length of the partial-ranking data, the partial-ranking data in each population can

be of varying lengths. Moreover, as we will see in Theorem 9, the Type I error guarantee of Algorithm 4

holds even if the pairwise-comparisons created from the rank breaking method are dependent, hence

the guarantee does not depend on the choice of the rank breaking method.

The key diﬀerence between the permutation testing algorithm for pairwise-comparison data, de-

scribed in Section 3.1, and the permutation testing algorithm for partial ranking data, described in

Algorithm 4, is the shuﬄing step. In our partial ranking based setup, each ranking sample is obtained

independent of all else while the pairwise-comparisons obtained from a rank are not necessarily indepen-

dent of each other. Hence, in the partial ranking based permutation testing algorithm (Algorithm 4),

we re-distribute ranking samples between the two populations and not the pairwise-comparisons.

Input : Two sets of partial rankings SP and SQ from two populations corresponding to the probability distributions λP and λQ. Signiﬁcance level α ∈ (0, 1). Rank breaking method, R ∈ {RR, RD, RC}. Iteration count γ. (1) Using the rank breaking method get

{kipj , Xij }(i,j)∈[d]2,i<j ← R(SP ); {kiqj , Yij }(i,j)∈[d]2,i<j ← R(SQ).

(2) Compute the test statistic T deﬁned in (8).

(3) {Repeat γ times} Put the samples in SP and SQ together and reassign the samples at

random such that the number of samples assigned to each population is the same as before.

Repeat Step 1 and Step 2. Denote the computed test statistic as T for the th iteration.

Output : Reject the null if p =

γ =1

1 γ

1

(T

− T ) < α.

Algorithm 4: Two-sample testing algorithm with partial ranking data for marginal probability

based model.

We now show that Algorithm 4 controls the Type I error of the two-sample testing problem in (10) under the more general, marginal probability based partial ranking model. This result relies on considerably

14

weaker assumptions than Theorem 7 and Theorem 8. In particular, we do not assume that each ranking is of the same length. We only assume that the (sub)set of items ranked in each sample from each population is sampled independently from the same distribution. Speciﬁcally, let there be any probability distribution over all non-empty subsets of [d]. Then, the set of items ranked in each sample for each population is sampled i.i.d. from this distribution. Moreover, the number of samples from the two populations need not be equal.
Theorem 9. Consider any probability distributions λP and λQ and the two-sample testing problem in (10). Suppose we have partial ranking data from each population such that the sets of items ranked in each sample in each population is sampled i.i.d. from any probability distribution over all non-empty subsets of [d]. Suppose the partial ranking data follows the marginal probability based model. Then, for any signiﬁcance level α ∈ (0, 1) the permutation testing method of Algorithm 4 has Type I error at most α.
The proof of Theorem 9 is provided in Section 6.6. Recall that the Plackett-Luce model is a special case of the marginal probability based model, and hence as a direct corollary, the guarantees for Algorithm 4 established in Theorem 9 also apply to the Plackett-Luce model.

5 Experiments
In this section, we present results from experiments on simulated and real-world data sets, to gain a further understanding of the problem of two-sample testing on pairwise-comparison data.

5.1 Pairwise-comparison data
We now describe real-world experiments and synthetic simulations we conduct for two-sample testing on pairwise-comparison data. In these experiments, we use the test statistic we designed in Algorithm 1 along with the permutation testing method as described in Algorithm 2 to obtain an implicit value of the threshold and control Type I error.

5.1.1 Synthetic simulations

We conduct two sets of experiments via synthetic simulations. The ﬁrst set of experiments empirically

evaluates the dependence of the power of our test (Algorithm 1) with respect to individual problem

parameters. In each of the simulations, we set the signiﬁcance level to be 0.05. Speciﬁcally, given

the problem parameters n, a, d and , we consider the random-design setting with kipj, kiqj i∼id Bin(n, a).

We consider the asymmetric and model-free setting, ﬁx P = [ 12 ]d×d and set Q = P + ∆ where ∆ is

sampled

uniformly

at

random

from

the

set

of

all

matrices

in

[− 12 ,

12 ]d×d

with

1 d

|||∆

|||F

=

. In Figure 1a,

b and c, we vary the parameter d, and a respectively, keeping the other parameters ﬁxed. Recall

that

our

results

in

Theorem

1

and

Corollary

2

predict

the

sample

complexity

as

n

=

Θ(

1 ad

2

).

To

test

this

theoretical

prediction,

we

set

the

sample

size

n

(on

the

x-axis)

as

n

=

1 ad

2

,

and

plot

the

power

of

the test on the y-axis. Each plot point in Figure 1 is obtained by averaging over 400 iterations of the

experiment, and the threshold for the test is obtained by running the permutation test method over

5000 iterations. Observe that, interestingly in each ﬁgure, the curves across all values of the varied

parameters nearly coincide, thereby validating the sample complexity predicted by our theoretical

results.

The second set of experiments empirically investigates the role of the underlying pairwise-comparison

models in two-sample testing with our test (Algorithm 1). We consider the random-design setup in the

symmetric setting with kipj, kiqj i∼id Bin(n, a) ∀ i < j. We generate the matrices P and Q in three ways:

model-free, BTL and SST. In the model-free setting, we generate P and Q in a manner similar to the

ﬁrst set of simulations above, with the additional constraints ∆ji = 1 − ∆ij ∀ i ≤ j. For the BTL

15

Power Power
Power Power

1.0

1.0

1.0

0.8

0.8

0.8

0.6

0.4

d= 10

d= 20

0.2

d= 30 d= 50

0.00.0 0.5 1.0 1.5 2.0 2.5 3.0
Rescaled sample size n = 1/ad 2

0.6

0.4

= 0.005 = 0.015

= 0.05

0.2

= 0.15

= 0.22

0.00.0 0.5 1.0 1.5 2.0 2.5 3.0
Rescaled sample size n = 1/ad 2

0.6

0.4

a= 0.001

a= 0.01

0.2

a= 0.1

a= 1

0.00.0 0.5 1.0 1.5 2.0 2.5 3.0
Rescaled sample size n = 1/ad 2

(a) Varying d

(b) Varying

(c) Varying a

Figure 1. Power of the testing algorithm versus the scaling factor of the sample size parameter n = ad1 2 . We use Algorithm 2 which uses the test statistic in (8) with the permutation testing method. The test is conducted at a signiﬁcance level of 0.05 (indicated by the horizontal line at y = 0.05). Unless speciﬁed otherwise, the parameters are ﬁxed as d = 20, = 0.05, a = 1.

1.0

0.8

0.6

0.4

BTL

SST

0.2

Model-free

0.0 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0
Rescaled sample size n = 1/ad 2

Figure 2. Power of our test (Algorithm 2) under three diﬀerent models for pairwise-comparisons: BTL, SST and the model-free setting. The parameters of the problem are set as d = 20, 2 = 0.05, a = 1 and
the test is conducted at a signiﬁcance level of 0.05 (indicated by the horizontal line at y = 0.05).

and SST models, we ﬁx P = [ 12 ]d×d. For the BTL model, we choose wp according to the construction in Section 6.3.4 to obtain Q. For the SST model, we set Q = P + ∆, where matrix ∆ is generated

as follows. We generate ∆ by arranging d2 random variables uniformly distributed over [0, 1], in a row-wise decreasing and column-wise increasing order in the upper triangle matrix (∆ij = 1 − ∆ji)

and

normalizing

to

make

1 d

|||∆

|||F

=

.

This construction ensures that ∆ lies in the SST class, and

since matrix P is a constant matrix, Q is also guaranteed to lie in the SST class. The results of the

simulations are shown in Figure 2. The results show that in the settings simulated, the power of the

testing algorithm is identical in all the models considered. This leaves an open question whether there

exists a tighter information-theoretic lower bound for the SST and the parameter-based model that

matches the upper bound derived for the test in Algorithm 1 or if there exists a test statistic for these

models with a better rate.

5.1.2 Real-world data In this section, we describe the results of our experiments on two real-world data sets. In these experiments, we use Algorithm 2 to obtain a p-value for the experiment.
16

Ordinal versus cardinal An important question in the ﬁeld of crowdsourcing and data-elicitation from people is whether pairwise-comparisons provided by people (ordinal responses) are distributed similarly to if they provide ratings (cardinal responses) which are then converted to pairwise-comparisons (Shah et al., 2016; Raman and Joachims, 2014). In this section, we use the permutation based two-sample test described in Algorithm 2 to address this question. We use the data set from Shah et al. (2016) comprising six diﬀerent experiments on the Amazon Mechanical Turk crowdsourcing platform. In each experiment, workers are asked to either provide ratings for the set of items in that experiment (age for photo given, number of spelling mistakes in a paragraph, distance between two cities, relevance of web-based search results, quality of taglines for a product, frequency of a piano sound clip) or provide pairwise-comparisons. The number of items in each experiment ranged from 10 to 25. For each of the six experiments, there were 100 workers, and each worker was assigned to either the ordinal or the cardinal version of the task uniformly at random. The ﬁrst set of samples corresponds to the elicited ordinal responses and the second set of samples are obtained by converting the elicited ratings to ordinal data. We have a total of 2017 ordinal responses and 1671 cardinal-converted-to-ordinal responses. More details about the data set and experiment are provided in the appendix.
Using Algorithm 2, we test for diﬀerence in the two resulting distributions for the entire data set (d = 74). We observe that the test rejects the null with a p-value of 0.003, thereby concluding a statistically signiﬁcant diﬀerence between the ordinal and the cardinal-converted-to-ordinal data.
European football leagues In the second data set, we investigate whether the relative performances of the teams (in four European football leagues: English Premier League, Bundesliga, Ligue 1, La Liga) changed signiﬁcantly from the 2016-17 season to the 2017-18 season. The leagues are designed such that each pair of teams plays twice in a season (one home, one away game), so we have at most two pairwise-comparisons per pair within a league (we do not consider the games that end in a draw). Each league has 15-17 common teams across two consecutive seasons. This gives a total of 801 and 788 pairwise-comparisons in the 2016-17 and 2017-18 seasons respectively. More details about the experiment are provided in the appendix.
Using the test statistic of Algorithm 1 with permutation testing, we test for a diﬀerence in the two resulting distributions for the entire data set (d = 67). We observe that the test fails to reject the null with a p-value of 0.971, that is, it does not recognize any signiﬁcant diﬀerence between the relative performance of the European football teams in 2017-18 season and the 2016-17 season from the data available. Running the test for each league individually also fails to reject the null.
5.2 Partial and total ranking data
We now describe the experiments we conducted on real-world data for two-sample testing on partial (and total) ranking data. In these experiments, we use the test statistic (8) along with the permutation testing method, as explained in Algorithm 4.
For our experiments, we use the “Sushi preference data set” Kamishima (2003), in which subjects rank diﬀerent types of sushi according to their preferences. The data set contains two sets of ranking data. In the ﬁrst set, the subjects are asked to provide a total ranking over 10 items (popular types of sushi). In this set, all subjects are asked to rank the same 10 objects. This set contains 5000 such total rankings.
In the second set of ranking data, a total of 100 types of sushi are considered. We ﬁrst describe how the 100 types are chosen. The authors in Kamishima (2003) surveyed menu data from 25 sushi restaurants found on the internet. For each type of sushi sold at the restaurant, they counted the number of restaurants that oﬀered the item. From these counts, they derived the probabilities that each item would be supplied. By eliminating unfamiliar or low frequency items, they came up with a list of 100 items. Each subject in this set is asked to rank a subset of 10 items randomly selected from the 100 items, according to the probability distribution described above. This set contains responses from 5000 subjects.
17

1.0

1.0

0.8

0.8

Empirical power

Empirical power

0.6

0.6

0.4

Random disjoint breaking

Complete breaking

0.2

Kendall's kernel Mallows' kernel

0.0
0 100 2N00umb3e0r0of sa4m00ples5p0e0r gr6o0u0p 700 800

0.4 0.2 0.0
0 100 2N00umb3e0r0of sa4m00ples5p0e0r gr6o0u0p 700 800

(a) Grouping by gender

(b) Grouping by age

1.0

1.0

0.8

0.8

Empirical power

Empirical power

0.6

0.6

0.4

0.4

0.2

0.2

0.0
0 100 2N00umb3e0r0of sa4m00ples5p0e0r gr6o0u0p 700 800

0.0
0 100 2N00umb3e0r0of sa4m00ples5p0e0r gr6o0u0p 700 800

(c) Grouping by primary region of residence until 15 years old

(d) Grouping by current region of residence

Figure 3. Empirical power of our test statistic T with the permutation testing method described in Algorithm 4 in testing for diﬀerence in sushi preference from the ﬁrst set of responses with d = 10. The responses obtained comprise of total rankings from each subject. Test results are shown for diﬀerences between demographic division based on the information available. Two diﬀerent rank breaking methods are used for our algorithm, namely, “Random Disjoint” and “Complete”. We also show the results for kernel-based two-sample testing with Kendall’s kernel and Mallows’ kernel as in Mania et al. (2018). The x-axis shows the number of samples (total rankings) from each group used to conduct the test and the y-axis shows the empirical power of our test. The test is conducted at a signiﬁcance level of 0.05 (indicated by the horizontal line at y = 0.05). Empirical power is computed as an average over 100 trials.

In addition, this data set contains demographic information about all the subjects, including their
(a) Gender {Male, Female}
(b) Age {Above 30, Below 30}
(c) Current region of residence {East, West}
(d) Primary region of residence until 15 years old {East, West}.
Using our testing algorithm, we test for a diﬀerence in preferences across the two sections within each demographic mentioned above. In the ﬁrst set of experiments, we implement the permutation testing method with our test statistic (8) on the ﬁrst set of ranking data with d = 10 for each demographic division. We show the results in Figure 3 for two rank-breaking methods, namely, “Random Disjoint” and “Complete”. In addition, we show the results of two kernel-based two-sample testing methods

18

1.2

Random disjoint breaking

1.0

Complete breaking

1.2

Random disjoint breaking

1.0

Complete breaking

Empirical power

Empirical power

0.8

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0.0
0 250 5N00umb7e5r0of s1a0m0p0les12p5e0r gr1o5u0p0 1750 2000

0.0
0 200 40N0um6b0e0r of8s0a0mp1le0s00per1g20ro0up1400 1600

(a) Grouping by gender

1.2

Random disjoint breaking

1.0

Complete breaking

(b) Grouping by age

1.2

Random disjoint breaking

1.0

Complete breaking

Empirical power

Empirical power

0.8

0.8

0.6

0.6

0.4

0.4

0.2

0.2

0.0
0 200 40N0um6b0e0r of8s0a0mp1le0s00per1g20ro0up1400 1600

0.0
0 200 4N0u0mbe6r00of sa8m0p0les1p0e0r0gro1u2p00 1400 1600

(c) Grouping by primary region of residence until 15 years old

(d) Grouping by current region of residence

Figure 4. Empirical power of our test statistic T with the permutation testing method described in Algorithm 4 in testing for diﬀerence in sushi preference from the ﬁrst set of responses with d = 100. Test results are shown for diﬀerences between demographic division based on the information available. Two diﬀerent rank breaking methods are used, namely, “Random Disjoint” and “Complete”. The x-axis shows the number of samples (total rankings) from each sub-group used to conduct the test and the y-axis shows the empirical power of our test. The test is conducted at a signiﬁcance level of 0.05 (indicated by the horizontal line at y = 0.05). Empirical power is computed as an average over 100 iterations.

for total rankings designed in Mania et al. (2018), namely, Kendall’s kernel and Mallows’ kernel. We randomly sub-sampled n samples from each sub-group of subjects and used 200 permutations to determine the rejection threshold for the permutation test. In these experiments, we show the empirical power of our testing method, which is the fraction of times our test rejected the null in a total of 100 trials. We show all the results of using this method on the sushi data set in Figure 3. Across each demographic division, our test detects a statistically signiﬁcant diﬀerence in distribution over sushi preferences for the 10 types of sushi included. Moreover, our testing algorithm with “Complete” rank breaking method performs competitively with the kernel-based two-sample testing methods introduced in Mania et al. (2018).
We note that since our testing algorithms also work with partial ranking data, our testing algorithms are much more general than the testing algorithms in Mania et al. (2018), as we demonstrate in our next set of experiments on the second sushi preference data set. We use Algorithm 4 to test if the preferences of the subjects in the second sushi data set also varies across the diﬀerent demographics. Recall that this data set has d = 100 items in total but each ranking only ranks a subset of 10 items. The other details of the experiment are the same as the previous experiment. The results are shown
19

in Figure 4. Again, across each demographic, our test detects a statistically signiﬁcant diﬀerence in distribution over sushi preferences for the 100 types of sushi included.
6 Proofs
This section is devoted to the proofs of our main results. In Section 6.1 and Section 6.2, we prove the positive results from Section 3.1, and in Section 6.3 we prove the converse results from Section 3.2. Lastly, Sections 6.4-6.6 are devoted to proofs of results under the partial (or total) ranking setting mentioned in Section 4.2.
Throughout these and other proofs, we use the notation c, c , c0, c1 and so on to denote positive constants whose values may change from line to line.
6.1 Proof of Corollary 2
In this section we present the complete proof of Corollary 2. We ﬁrst present the proof for the random-design setup described in Corollary 2 and then specialise the proof in Section 6.2 to the per-pair ﬁxed-design setup in Theorem 1. To prove our result, we analyse the expected value and the variance of the test statistic T in Algorithm 1 in the following two lemmas. Recall that under the random-design setup kipj, kiqj are distributed independently and identically according to some distribution D that satisﬁes the conditions in (9).
Lemma 10. For T as deﬁned in Algorithm 1, with kipj, kiqj i∼id D, under the null EH0 [T ] = 0 and under the alternate,
EH1 [T ] ≥ cµ|||P − Q|||2F.

The proof of Lemma 10 is provided in Section 6.1.1. Now, with a view to applying Chebyshev’s concentration inequality, we bound the variance of T .

Lemma 11. For T as deﬁned in Algorithm 1, with kipj, kiqj i∼id D, where D obeys the conditions described in (9), under the null

VarH0 [T ] ≤ 24d2,

and under the alternate,

VarH1 [T ] ≤ 24d2 + 8µ|||P − Q|||2F + c µ2|||P − Q|||2F

where c > 0 is a constant.

The proof for Lemma 11 is provided in Section 6.1.2. We now have to control Type I error and Type II
error. Using one-sided Chebyshev’s inequality for the test statistic T , which has EH0 [T ] = 0, we derive an upper bound on Type I error as follows

PH (T ≥ t) ≤ VarH0 [T ] .

(14)

0

VarH0 [T ] + t2

Observe that if t = 11d then the Type I error is upper bounded by 16 . In addition, if Type I error is required to be at most ν, then we set the threshold equal to d 24(1 − ν) . We now move to controlling
ν the Type II error of the testing algorithm. We again invoke Chebyshev’s inequality as follows

PH (T < t) ≤

VarH1 [T ]

.

(15)

1

VarH1 [T ] + (EH1 [T ] − t)2

20

To guarantee that Type II error is at most 16 , we substitute the bounds on EH1 [T ], VarH0 [T ], VarH1 [T ] from Lemma 10 and Lemma 11 in (15) to get the suﬃcient condition

5(24d2 + 8µ|||P − Q|||2F + c µ2|||P − Q|||2F) ≤ (cµ|||P − Q|||2F − 11d)2 40µ|||P − Q|||2F + 22cdµ|||P − Q|||2F + 5c µ2|||P − Q|||2F ≤ c2µ2|||P − Q|||4F + d2.

This condition yields

40 + 22cd + 5c µ ≤ c2µ|||P − Q|||2F. (16)

Recall that under the alternate d1 |||P − Q|||F ≥ . According to the ﬁnal condition derived here (16), under the regime µ > d, we have control over total probability of error if 2d2 ≥ c for some constant c > 0. Under the regime µ ≤ d, the condition (16) simpliﬁes as

2≥ c ,

(17)

µd

where c > 0 is some constant. This gives the suﬃcient condition to control total probability of error

(sum

of

Type

I

error

and

Type

II

error)

to

be

at

most

1 3

under

the

setting

where

kipj , kiqj

i∼id

D.

6.1.1 Proof of Lemma 10

We now prove the bounds on the expected value of the test statistic deﬁned in Algorithm 1. Recall

that

for

each

(i, j),

given

kipj , kiqj ,

we

have

Xij

∼

Bin(

k

p ij

,

pij

)

and

Yij

∼

Bin

(k

q ij

,

qij

)

.

Also,

kipj , kiqj

i∼id

D

wherein

E[kipj ]

=

µ, Var[kipj]

=

σ

2

,

Pr(

k

p ij

=

1)

=

p1

and

D

obeys

(9).

We

denote

the

vector

of

kipj

and

kiqj for all (i, j) by kp and kq respectively. Now, the conditional expectation of T is expressed as

pq

d d Iij kipj kiqj

2

E [ T | k , k ] = i=1 j=1 kipj + kiqj (pij − qij ) .

(18)

Using the law of total expectation, we have

E [ T ] = E [ E [ T | kp, kq ] ]

dd

=

E

i=1 j=1

Iij kipj kiqj

2

kipj + kiqj (pij − qij )

=E

Iij kipj kiqj kipj + kiqj

|||P − Q|||2F

Clearly, EH0 [T ] = 0. To ﬁnd a lower bound for EH1 [T ], we ﬁrst note that

Iij kipj kiqj E kipj + kiqj

=E ≥E

I0ij kipj kiqj kipj + kiqj
I0ij kipj kiqj kipj + kiqj

− 2 P(kipj = 1, kiqj = k) k +k 1 + 12 P(kipj = 1, kiqj = 1)
k∈[d]
− 2p1.

(19)

where I0ij = I(kipj > 0) × I(kiqj > 0). Furthermore, we see that for any event E,

I0ij kipj kiqj E kipj + kiqj

≥E

I0ij kipj kiqj kipj + kiqj | E

Pr(E).

(20)

21

We deﬁne the event E as

p ≤ µ + cσ, and

µ − cσ ≤ kiqj (21)

µ − cσ ≤ kij ≤ µ + cσ

with some constant c > 1 such that µ − cσ > 0. Using Chebyshev’s inequality, we get that Pr(E) ≥

(1 −

1 c2

)2

.

Finally,

we

combine

(19),

(20)

and

(21),

to

get

Iij kipj kiqj

(µ − cσ)2

12

E kp + kq ≥ 2(µ + cσ) 1 − c2 − 2p1.

(22)

ij

ij

Since D obeys the conditions in (9), we have µ ≥ c1p1 and µ ≥ c2σ. Therefore, there is a constant c > 0 that depends on c1, c2, such that E[T ] ≥ cµ|||P − Q|||2F. This proves Lemma 10.

6.1.2 Proof of Lemma 11
To analyse the variance of the test statistic T , we note that pairwise-comparisons for each pair are obtained independently. This allows us to compute the variance for each pair (i, j) separately, as variance of sum is equal to the sum of variances. The following analysis of the variance of the test statistic T applies under both the null and the alternate. The law of total variance states that

Var[T ] = E[ Var[T |kp, kq] ] + Var[ E[T |kp, kq] ].

(23)

We evaluated the term Var[T |kp, kq], present in the expression above, in Wolfram Mathematica. We show the output here,

pq

d d 2Iij kipj (kipj − 1)kiqj (kiqj − 1)

Var[T |k , k ] ≤ i=1 j=1 (kipj − 1)2(kiqj − 1)2(kipj + kiqj )2

kiqj (kiqj − 1)p4ij (3 − 2kipj )

+ 2p3ij kiqj (kiqj − 1)(−2 + 2qij kipj − 2qij + kipj )

+ 2pij qij (kipj − 1)(kiqj − 1)(1 + 2qi2j kipj − qij − 2qij kipj + qij kiqj )

+ p2ij (kiqj − 1)(2qij (kipj − 1)(kipj − 1 − 2kiqj ) + kipj − 2qi2j (kipj − 1)(kipj + kiqj − 1))

− qi2j (qij − 1)kipj (kipj − 1)(1 − 3qij + 2qij kiqj )

dd

8Iij

≤ i=1 j=1 (kipj + kiqj )2

kipj (kipj − 1)(kiqj − 1)(2pij (pij − qij )2)

+ kiqj (kiqj − 1)(kipj − 1)(2qij (pij − qij )2)

+ 2pij qij (kipj − 1)(kiqj − 1)(1 − pij )(1 − qij )

+ p2ij kiqj (kiqj − 1)(1 − pij )2 + qi2j kipj (kipj − 1)(1 − qij )2 .

(24)

Applying the trivial upper bound pij ≤ 1, qij ≤ 1 ∀ (i, j), we get

dd

Var[T |kp, kq] ≤

8Iij

i=1 j=1

kipj kiqj

2

(kipj + kiqj ) (pij − qij ) + 3

(25)

Following this, we evaluate the ﬁrst term on the right hand side of (23) as

pq

2

2 Iij kipj kiqj

E[ Var[T |k , k ] ] ≤ 24d + 8|||P − Q|||FE p q .

(26)

kij + kij

22

To further simplify the upper bound in (26), we observe that

Iij kipj kiqj E kipj + kiqj

≤ 21 E[max{kipj, kiqj}].

(27)

We

exploit

the

independence

of

kipj , kiqj

to

get

the

CDF

of

max

{k

p ij

,

kiqj

}

as

P(max

{k

p ij

,

kiqj

}

≤

x)

=

P(kipj

≤

x)P(kiqj

≤

x).

Through the CDF, we derive the PDF as

P(max{kipj, kiqj} = x) = P(max{kipj, kiqj} ≤ x) − P(max{kipj, kiqj} ≤ x − 1)

= P(kipj ≤ x)2 − P(kipj ≤ x − 1)2

= P(kipj = x)(P(kipj ≤ x) + P(kipj ≤ x − 1))

≤ 2P(kipj = x)

(28)

We substitute this inequality in (27) to get

Iij kipj kiqj E kipj + kiqj

≤ µ.

(29)

As a result, following from (26), we have E[ Var[T |kp, kq] ] ≤ 24d2 + 8µ|||P − Q|||2F. (30)

Now, the remaining (second) term on the right hand side of (23) is

dd

Var[ E[T |kp, kq] ] =

Var

i=1 j=1

Iij kipj kiqj (kipj + kiqj )

(pij − qij )4

≤ Var

Iij kipj kiqj (kipj + kiqj )

dd
(pij − qij )2
i=1 j=1

≤ Var

Iij kipj kiqj (kipj + kiqj )

|||P − Q|||2F.

(31) (32)

To bound the variance term in the previous equation, we see that

Iij kp kq

 Iij kp kq

2

Iij kp kq

2

Var

ij ij

p

q

= E

ij ij

p

q

−E

ij ij

p

q

(kij + kij )

(kij + kij )

(kij + kij )

(a) 1 ≤ 4E

max{kipj , kiqj } 2 − cµ2

(≤b) 21 E[(kipj )2] − cµ2 = 1 (µ2 + σ2) − cµ2
2

(c)
≤

1 +

1

−c

µ2 = c µ2,

(33)

2 2c22

23

where inequality (a) follows from (22), inequality (b) follows similarly to the result in (28), and inequality (c) is a result of (9). Thus, the upper bound in (32) becomes
Var[ E[T |kp, kq] ] ≤ c µ2|||P − Q|||2F. (34)
Finally, we put together the terms in (23) by combining (30) and (34) to get the desired upper bound on the variance of the test statistic under the alternate hypothesis, which is
Var[T ] ≤ 24d2 + 8µ|||P − Q|||2F + c µ2|||P − Q|||2F. (35)
Additionally, to obtain the upper bound on the variance of the test statistic under the null, we substitute |||P − Q|||F as zero in (35). This completes the proof of Lemma 11.

6.2 Proof of Theorem 1
In this proof, we ﬁrst specialise the statements of Lemma 10 and Lemma 11 to the per-pair ﬁxed-design setup where kipj = kiqj = k ∀ (i, j) ∈ [d], for some positive integer k > 1. Under this setting, following from (18), we have

d d1

1

[T ] =

I(k > 1)k(pij − qij)2 = k|||P − Q|||2F.

(36)

E

2

2

i=1 j=1

Similarly, we note that in (23) we have that Var[ E[T |kp, kq] ] = 0, which in combination with (26) implies that

Var[T ] ≤ 24d2 + 4k|||P − Q|||2F. (37)

Now, invoking Chebyshev’s inequality as described in (14) and (15) to control Type I and Type II error at level 16 , we set the threshold as 11d to get the suﬃcient condition as

2≥ c

(38)

kd

for some positive constant c. This proves Theorem 1.

6.3 Proof of converse results
In this section we prove all the claims made in Section 3.2. We begin with some background.

6.3.1 Preliminaries for proof of lower bound
We begin by brieﬂy introducing the lower bound technique applied in Theorem 3 and Theorem 5. The main objective of the proof is to construct a set of null and alternate such that the minimax risk of testing deﬁned in (2) is lower bounded by a constant. To lower bound the minimax risk, we analyse the χ2 distance between the resulting distributions of the null and the alternate. We construct the null and alternate as follows. Let P0 = [ 12 ]d×d. Under the null, we ﬁx P = Q = P0 and under the alternate, P = P0, Q ∈ Θ where Θ is a set of matrices from the model class M to be deﬁned subsequently. We assume a uniform probability measure over Θ. The set Θ is chosen such that d1 |||P0 − Q|||F = for all Q ∈ Θ.
In our problem setup, we observe matrices X, Y wherein each element is the outcome of k observations of the corresponding Bernoulli random variable. For each pair (i, j), we have Xij ∼ Bin(k, pij), Yij ∼ Bin(k, qij). For simplicity of notation, we will denote the matrix distribution corresponding to the pairwise-comparison probability matrix P0 by P0, that is, X ∼ P0 when P = P0, and Y ∼ P0 when

24

Q = P0. For the case where Yij ∼ Bin(k, qij) and Q ∼ Unif(Θ), we denote the resulting matrix distribution as Y ∼ PΘ. We now have all the parts required to derive the χ2 divergence between the
null and the alternate deﬁned in this section.

The χ2 divergence between the distribution of X, Y under the null and the distirbution of X, Y under the alternate is given by

χ2((X, Y )H0 , (X, Y )H1 ) = χ2(XH0 , XH1 ) + χ2(YH0 , YH1 ) + χ2(XH0 , XH1 )χ2(YH0 , YH1 ) = χ2(P0, P0) + χ2(P0, PΘ) + χ2(P0, P0)χ2(P0, PΘ) = χ2(P0, PΘ).

(39)

This reduces our two-sample testing problem into a goodness of ﬁt testing problem for the given model class, where the null distribution is given by P0 and the alternate distribution is given by PΘ. This goodness of ﬁt testing problem is written as

H0 : P = P0 (40) H1 : P ∼ Unif(Θ),

where P0 = 12 d×d. Continuing with the reduction in (39) and (40), Le Cam’s method for testing states that the minimax
risk (2) for the hypothesis testing problem in (40), is lower bounded as (Lemma 3 in Collier et al. (2017))

RM ≥ 1 1 − χ2(P0, PΘ) . (41) 2
Therefore, if the χ2 divergence is upper bounded by some constant c < 1, then no algorithm √can correctly distinguish between the null and the alternate with probability of error less than 12 (1 − c). Consequently, by deriving the value of corresponding to c = 19 , we will get the desired lower bound on the critical radius deﬁned in (3) for the two-sample testing problem in (1).
We now delve into the technical part of the proof in which we derive the χ2 divergence between P0 and PΘ. For a probability distribution P0 and a mixture probability measure PΘ, we know (from Lemma 7 in Carpentier et al. (2018)) that

χ2(P0, PΘ) = E(Q,Q )∼Unif(Θ)

dPQdPQ − 1. dP0

(42)

Here E(Q,Q )∼Unif(Θ) denotes the expectation with respect to the distribution of the pair (Q, Q ) where Q and Q are sampled independently and uniformly at random from the set Θ (with replacement).
According to the null and alternate construction described in the beginning of this section, recall that X ∼ P0 implies that Xij ∼ Bin(k, 12 ) ∀ (i, j). Similarly X ∼ PQ implies that Xij ∼ Bin(k, qij) ∀ (i, j). With this information, we simplify the χ2 divergence as

χ2(P0, PΘ) = E(Q,Q )∼Unif(Θ)


dd


v∈V i=1 j=1

k

qvij (1 − q )k−vij

k

 (q )vij (1 − q )k−vij

vij ij

ij

vij ij

ij

− 1. (43)

vkij ( 12 )k 

where V ∈ Rd(d−1) is the set of all possible vectors with each element belonging to the set {0, 1, · · · , k}. There are (k + 1)d(d−1) such vectors. We further simplify the summation over V as

dd
χ2(P0, PΘ) = E(Q,Q )∼Unif(Θ)
i=1 j=1

k k qij (1 − qij )k− (qij ) (1 − qij )k− =0 ( 12 )k

− 1.

(44)

25

This gives us the χ2 divergence for the construction deﬁned in terms of the elements of the matrices in

the set Θ. Later, we will see that the set Θ designed for the diﬀerent modeling assumptions considered

(namely,

MST

and

parameter-based)

consist

solely

of

matrices

with

entries

from

the

set

{

1 2

−

η,

1 2

,

1 2

+

η}.

This information enables us to further simplify the expression for χ2(P0, PΘ).

Consider a pair of matrices (Q, Q ) sampled uniformly at random from the set Θ. Let an agreement

be deﬁned as the occurrence of

1 2

+

η

(or

1 2

−

η)

in

the

same

position

in

Q

and

Q

and a disagreement

is deﬁned as the occurrence of

1 2

+

η

in

Q

or

Q

in the same position as

1 2

−

η

in

Q

or Q respectively.

Next, we deﬁne two statistics b1 and b2 that quantify the number of agreements and disagreements,

respectively, in the matrix pair (Q, Q ) as shown here

dd

b1(Q, Q ) =

1 1 + , {

qij

=q

ij

=

1 2

+η

}

{

q

ij

=q

ij

=

1 2

−

η

}

i=1 j=1

dd

b2(Q, Q ) =

1 1 1 1 + . {

qij

=

1 2

+η

}

{q

ij

=

1 2

−

η

}

{

q

ij

=

1 2

−η

}

{

qij

=

1 2

+η

}

i=1 j=1

(45)

Using these deﬁnitions, we state the following Lemma to analyse χ2(P0, PΘ) in (44).

Lemma 12. Consider two pairwise-comparison probability matrices Q and Q with qij ∈ { 12 −η, 21 , 12 +η}

and

qij

∈

{ 12

− η,

12 ,

1 2

+ η}.

Suppose

b1(Q, Q

)

=

b1

and

b2(Q, Q

)

=

b2.

Then,

we

have

dd i=1 j=1

k k qij (1 − qij )k− (qij ) (1 − qij )k− =0 ( 12 )k

≤ (1 + 4η2)k(b1−b2).

(46)

The proof is provided at the end of this subsection. Using Lemma 12 and (44), we get an upper bound on the χ2 divergence as

χ2(P0, PΘ) ≤ E(Q,Q )∼Unif(Θ) (1 + 4η2)k(b1−b2) − 1.

(47)

We conclude the background section on the converse results here. We will use the equations discussed in this section to derive the lower bound for the diﬀerent modeling assumptions in Theorem 3 and Theorem 5 in their respective proofs.

Proof of Lemma 12 Let

dd
G(Q, Q ) =
i=1 j=1

k k qij (1 − qij )k− (qij ) (1 − qij )k− =0 ( 12 )k

− 1.

(48)

Let g(qij, qij) denote the summation in the equation above, that is

k
g(qij , qij ) = 2k
=0

k qij (1 − qij )k− (qij ) (1 − qij )k− .

(49)

Notice

that

if

qij

=

1 2

or

qij

=

1 2

then

g(qij , qij )

=

1.

Additionally,

g( 12

+ η,

1 2

+ η)

=

g( 12

− η,

1 2

− η)

and

g 1 + η, 1 + η =2k k

1

2k

+η

1

2k−2

−η

22

2

2

=0

=0

=2k 1 + 2η2 k k k 2
=0

1

η

2 + 1 + 2η2

2

1

η

k−

2 + 1 − 2η2

2

=(1 + 4η2)k.

(50)

26

Also,

note

that

g( 12

+

η,

1 2

−

η)

=

g( 21

−

η,

1 2

+

η)

and

g( 1 − η, 1 + η) = 2k k

k

1 (

−

η)

1 (

+

η)k−

1 (

+

η)

1 (

−

η)k−

22

2

2

2

2

=0

= ( 1 − 2η2)k k k 2
=0

= (1 − 4η2)k.

(51)

Therefore, if the pair of matrices Q, Q have b1 agreements and b2 disagreements, then using (50), (51) we get

G(Q, Q ) =g

11

b1

+ η, + η g

22

11

b2

+ η, − η

22

= (1 + 4η2)kb1 (1 − 4η2)kb2

≤ (1 + 4η2)k(b1−b2).

This proves Lemma 12.

6.3.2 Proof of Proposition 4

In this section, we provide a construction of the null and the alternate in (1) under the model-free
assumption that proves the statement of Proposition 4. To this end, let P0 be a pairwise probability matrix with the (i, j)th element denoted by pij for all i, j ∈ [d]. We will provide more details about P0 subsequently. Consider the case where under the null P = Q = P0 and under the alternate P = P0 and
Q ∼ Bernoulli(P0). Under this notation, we have that under the alternate qij ∼ Bernoulli(pij). We choose P0 such that for all i, j ∈ [d] we have 0 ≤ pij ≤ 21 . With this, we argue that under the alternate construction, for any realization of Q, we have

dd

|||P0 − Q|||2F ≥

p2ij .

i=1 j=1

In this manner, by choosing an appropriate P0, we construct the alternate for any given which satisfy

the conditions in the two-sample testing problem in (1). Note that the maximum value of |||P0 − Q|||2F

attainable

in

this

construction

is

when

pij

=

1 2

for

all

(i, j)

∈

[d].

In

this

setting,

|||P0

− Q|||2F

=

d42 ,

for

all realizations of Q. Thus, in our construction, the parameter is at most 12 .

Now, in Proposition 4, we consider the case where we have one pairwise-comparison for each pair in

each population, that is, kipj = kiqj = 1 ∀ i, j ∈ [d]. Recall that the observed matrices corresponding

to the two populations are denoted by X and Y which are distributed as X ∼ Bernoulli(P ) and

Y ∼ Bernoulli(Q). Now, for our construction, we see that X is distributed identically under the null

and the alternate as X ∼ Bernoulli(P0), and Y is distributed as Y ∼ Bernoulli(P0) under the null and

Y ∼ Bernoulli(Q) under the alternate. Thus, to distinguish between the null and the alternate, we

must be able to distinguish between the product distribution P0 := Bernoulli(P0) × Bernoulli(P0) and

the product distribution P1 := Bernoulli(P0) × Bernoulli(Q) where Q ∼ Bernoulli(P0).

For the setting with one comparison per pair, we have access to only ﬁrst order statistics for

matrices X and Y . Since the Bernoulli parameters for all pairs (i, j) are independently chosen under

the model-free setting, we look at the ﬁrst order statistics of any pair (i, j), which are given by

Pr(Xij = 1), Pr(Yij = 1), Pr(Xij = 1, Yij = 1). Now, observe that under both the distributions P0 and

P1 we have that

Pr(Xij = 1) = pij; , Pr(Yij = 1) = pij; Pr(Xij = 1, Yij = 1) = p2ij.

27

Since the ﬁrst order statistics under both distributions P0 and P1 are identical, we conclude that no algorithm can distinguish between these distributions with a probability of error less than half. In turn, the minimax risk deﬁned in (2) is at least half. This proves Proposition 4.

6.3.3 Proof of Theorem 3

In this section, we establish a lower bound on the critical radius (3) for the two-sample testing problem

deﬁned in (1) under the assumption of the MST class as stated in Theorem 3. First, we provide a

construction for the null and the alternate in Section 6.3.1. In this construction, we set P = Q = P0

under the null and P = P0, Q ∼ Unif(Θ) under the alternate where Θ is a set of matrices belonging to

the MST class. To complete the description of the construction, we now describe the set Θ for the

MST class of pairwise-comparison probability matrices. The probability matrices in Θ correspond to a

ﬁxed ranking of items. Each matrix in Θ is such that the upper right quadrant has exactly one element

in

each

row

and

each

column

equal

to

1 2

+η

for

some

η

∈

(0,

21 ).

The

rest

of

the

elements

above

the

diagonal are half. The elements below the diagonal follow from the shifted-skew-symmetry condition

imposed on MST probability matrices. It can be veriﬁed that all matrices Q ∈ Θ lie in the MST class.

Note

that

the

set

Θ

has

(d/2)!

matrices.

Since

each

matrix

has

a

total

of

d

elements

equal

to

1 2

± η,

we

get that d12 |||P0 − Q|||2F = 2 = ηd2 . This implies 2 ≤ 41d .

Now, to derive bounds on the minimax risk according to (41), we analyse the χ2 divergence between P0 and PΘ. From the analysis of χ2(P0, PΘ) in Section 6.3.1, speciﬁcally (47), we have that

χ2(P0, PΘ) ≤ E(Q,Q )∼Unif(Θ) (1 + 4η2)k(b1−b2) − 1

where b1 and b2 are the number of agreements and disagreements between the matrices Q, Q , as

deﬁned in (45). Now, to compute the χ2 divergence, we want to ﬁnd the probability that two matrices

picked uniformly at random from Θ have i agreements in the upper right quadrant(the total number

of agreements is 2i due to shifted-skew-symmetry). Given a matrix Q from set Θ, for i agreements,

we want to choose a matrix Q ∈ Θ such that exactly i of the perturbed elements share the same

position as in Q. There are d/i2 ways of choosing the i elements. Now that the i elements have their

position

ﬁxed,

we

have

to

ﬁnd

the

number

of

ways

we

can

rearrange

the

remaining

d 2

−i

elements

such

that none of them share a position with the remaining perturbed elements in Q. This problem is the

same as reshuﬄing and matching envelopes with letters such that no letter matches with originally

intended envelope. The number of ways to rearrange a set of i objects in such a manner is given by

i!( 21!

−

1 3!

+

·

·

·

+

(−1)i

1 i!

).

Thus

the

number

of

ways

of

rearrangement

for

d 2

−i

items

is

upper

bounded

by

1 2

(d/2

−

i)!.

Thus,

the

probability

of

2i

agreements

is

upper

bounded

as

P(b1 = 2i) ≤ (d/2)! (d/2 − i)! ≤ 1 . (52) (d/2 − i)!i! 2(d/2)! 2(i)!

Then, we further simplify (47) as

χ2(P0, PΘ) ≤ E(Q,Q )∼Unif(Θ) (1 + 4η2)k(b1−b2) − 1
≤ E(Q,Q )∼Unif(Θ) (1 + 4η2)kb1 − 1
d/2
≤ P(b1 = 2i)(1 + 4η2)2ki − 1.
i=0

(53)

28

c Notice that if we choose k = 4η2 with some constant c ∈ (0, 1) then we have that

k
(1 + 4η2)k =

k (4η2)

=0

k
≤ 1 + (4η2k)

=1

k

≤1+ c

=1

≤1+c,

where c is some positive constant. Using this, we show that the χ2 divergence in (53) is upper bounded c
by a constant for k ≤ η2 , as follows

d/2
χ2(P0, PΘ) ≤ P(b1 = 2i)(1 + 4η2)2ki − 1

i=0

d/2
≤ P(b1 = 2i)(1 + c )2i − 1

i=0

d/2

d/2

= P(b1 = 2i) − 1 + P(b1 = 2i)((1 + c )2i − 1)

i=0

i=0

d/2

(a)
≤

1 ((1 + c )2i − 1)

i=0 2(i!)





1

∞1

≤ exp((1 + c )2) − exp(1) +



2

i!

i=d/2

≤c ,

where c is some positive constant. The inequality (a) follows from (52). This proves that there exists

a constant c, such that if k ≤ c = c , then the χ2 divergence is upper bounded by 1 . According to

η2 d 2

9

(41), this implies that the minimax risk is at least 13 . This establishes the lower bound on the critical testing radius for two-sample testing under the MST modeling assumption as 2M > c k1d and proves Theorem 3.

6.3.4 Proof of Theorem 5

Consider any arbitrary non-decreasing function f : R → [0, 1] such that f (θ) = 1 − f (−θ) ∀ θ ∈ R. In

order to prove the lower bound on testing radius stated in Theorem 5, we construct a set of matrices Θ

based on the parameter-based pairwise-comparison probability model described in (4) associated to the

given function f . Observe that f (0) = 12 . Recall that under the parameter-based model the sum of all

weights is ﬁxed as

d i=1

wi

=

0.

We

use

the

weight

parameter

to

deﬁne

the

construction

for

the

lower

bound.

Recall the null and alternate construction described in Section 6.3.1 to prove the lower bound.

Accordingly, we set P = Q = P0 under the null and P = P0, Q ∼ Unif(Θ) under the alternate where

29

Θ is a set of matrices belonging to the parameter-based class. The weights wP0 = [0, · · · , 0] ∈ Rd correspond to the pairwise probability matrix P0 = [ 12 ]d×d. Now for creating the set Θ, consider a collection of weight vectors wΘ each with half the entries as δ and the other half as −δ, thereby ensuring

that i∈[d] wi = 0. We set δ to ensure that each of the probability matrices induced by this collection

of vectors obey d1 |||P0 − Q|||F = . We deﬁne the set of matrices Θ as the set of pairwise-comparison

probability matrices induced by the collection of values of wΘ. Clearly, there are

d d/2

matrices in Θ.

A

similar

argument

holds

for

odd

d

wherein

d−1 2

elements

of

the

weight

vector

are

δ

and

d−1 2

elements

are −δ. Since f is monotonic, f (−2δ) ≤ f (0) ≤ f (2δ) and we have that f (2δ) = 1 − f (−2δ), we deﬁne

f (−2δ)

=

1 2

−

η

and

f (2δ)

=

1 2

+

η

for

some

0

<

η

≤

12 .

Similar to the proof of Theorem 3, we use (47) to bound the χ2 divergence between the null and
the alternate constructed. We ﬁrst note that if we sample two matrices Q and Q uniformly at random (with replacement) from Θ, then if the number of agreements is i22 then the number of disagreements is equal to (d−2i)2 . The probability of i22 agreements is given by

i2

(d − i)2

P b1 = 2 , b2 = 2

d/2 d/2
= i/2 i/2 .
d d/2

Following from (44), the χ2 divergence is

χ2(P0, PΘ) = E(Q,Q )∼Unif(Θ) (1 + 4η2)k(b1−b2) − 1

d
≤
i=0

d/2 d/2 i/2 i/2
d d/2

(1 + 4η2)k(i2−(d−i)2)/2 − 1.

For

ease

of

presentation,

we

replace

d 2

by

z

and

i 2

by

, to get

z
χ2(P0, PΘ) ≤

zz
2z (1 + 4η2)2k(2 z−z2) − 1

=0 z

z
≤
=0

1z 2

z (1 + 4η2)2k(2 z−z2) − 1

z
≤

1 z z exp(8η2k(2 z − z2)) − 1.

2

=0

Here, we see that the summation in the ﬁnal expression is equal to the expectation of exp(8η2k(2 z − z2)) over the random variable where ∼ Bin(z, 12 ). So,

χ2(P0, PΘ) ≤ E exp(8η2k(2 z − z2)) − 1

∞ (8η2kz)i

≤

E (2 − z)i − 1,

(54)

i!

i=0

where E [(2 − z)i] is the scaled centered ith moment of Bin(z, 12 ). To get the expression for the centered

30

moments, we ﬁrst ﬁnd the moment generating function of the random variable = 2 − z, as

E e(2 −z)t = e−ztE e2 t

= e−zt = e−zt

zz
=0

1 e2t 2

1 + 1 e2t z 22

e−t + et z =
2

= (cosh t)z.

1 z− 2

Then, we have

i di(cosh t)z

E (2 − z) = dti

,

t=0

which is the ith derivative of (cosh t)z evaluated at t = 0. This leads to the fact that for odd i, E[(2 − z)i] = 0 and for even i, E[(2 − z)i] ≤ (i/i!2)! zi/2. Using this with (54), we get

∞
χ2(P0, PΘ) ≤ ci(64η4k2z3)i
i=1

(55)

where ci = (i/12)! , that is, ci is decreasing as i increases. Thus, we see that if k ≤ c then there is a small enough c such that the χ2 divergence is upper η2d3/2
bounded by 19 . In this construction, we have 2 = η2/2, therefore, using (41), the lower bound for two-sample testing under the parameter-based modeling assumption is given as 2 = Ω 1 . This
kd3/2 proves Theorem 5.

6.3.5 Proof of Theorem 6

To prove Theorem 6, we use the conjectured average-case hardness of the planted clique problem. In

informal terms, the planted clique conjecture asserts that it is hard to detect the presence of a planted

clique in an Erdös-Rényi random graph. In order to state it more precisely, let G(d, κ) be a random

graph on d vertices constructed in one of the following two ways:

H0

:

Every

edge

is

included

in

G(d, κ)

independently

with

probability

1 2

H1 : Every edge is included in G(d, κ) independently with probability 12 . In addition, a set of κ

vertices is chosen uniformly at random and all edges with both endpoints in the chosen set are added

to G.

√

The planted clique conjecture then asserts that when κ = o( d), then there is no polynomial-time

algorithm that can correctly distinguish between H0 and H1 with an error probability that is strictly

bounded below 12 . We complete the proof by identifying a subclass of SST matrices and showing that any testing algorithm that can distinguish between the subclass of SST matrices and the all half matrix,

can also be used to detect a planted clique in an Erdös-Rényi random graph.

Consider the null with P = Q = [ 12 ]d×d and the alternate such that P = [ 12 ]d×d and Q is chosen uniformly at random from set Θ. The set of probability matrices Θ contains all (d × d) matrices with

the upper left and lower right quadrant equal to all half, the upper right quadrant is all half except a

(κ × κ) planted clique (i.e., a (κ, κ) submatrix with all entries equal to one). Then we have 2 = κ2/2d2.

31

The bottom left quadrant follows from the skew symmetry property. Recall that we observe one sample

per pair of items (i > j). This testing problem is reduced to a goodness-of-ﬁt testing problem as shown

in (39) and (40).

Consider the set of d2 × d2 matrices comprising the top right d2 × d2 sub-matrix of every matrix in Θ. We claim that this set is identical to the set of all possible matrices in the planted clique problem

with

d 2

vertices

and

a

planted

clique

of

size

κ.

Indeed,

the

null

contains

the

all-half

matrix

corresponding

to the absence of a planted clique, and the alternate contains all symmetric matrices that have all

entries equal to half except for a (κ, κ) all-ones sub-matrix corresponding to the planted clique. We

√

choose

the

parameter

κ

=

d log log(d)

so

that

any

constant

multiple

of

it

will

be

within

the

hardness

regime of planted clique (for suﬃciently large values of d). Now, we leverage the planted clique hardness

conjecture to state that the null in our construction cannot be distinguished from the alternate by any

polynomial-time algorithm with probability of error less than 12 . This implies that for polynomial-time

testing it is necessary that 2 ≥

c . This proves Theorem 6.

d(log log(d))2

6.4 Proof of Theorem 7

Bounding the Type I error. In this proof, we ﬁrst bound the Type I error and subsequently bound

the Type II error. To bound the probability of error of Algorithm 3, we study the distribution of the

test statistic T under the null and the alternate. Algorithm 3 uses the test statistic deﬁned in (8). To

understand the distribution of the test statistic, we ﬁrst look at the distribution of Xij and Yij.

In Algorithm 3, we break the partial ranks into disjoint pairwise-comparisons. Under the Plackett-

Luce model disjoint pairwise-comparisons obtained from the same partial ranking are mutually inde-

pendent. Additionally, since the Plackett-Luce model obeys the property of independence of irrelevant

alternatives, the probability of observing item i being ranked ahead of item j in a partial ranking is

independent of the other items being ranked in that partial ranking. Thus, for any pair of items (i, j),

the probability of i beating j, conditioned on the event that the pair (i, j) was observed, is always equal

to pij for the population corresponding to pairwise probability matrix P and qij for the population

corresponding to pairwise probability matrix Q. This holds true irrespective of which other items

are involved in that partial (or total) ranking. With this in mind, we identify the distribution of Xij

conditioned on kipj

as Xij | kipj

∼

Bin(

k

p ij

,

pij

)

.

Similarly, we have Yij | kiqj

∼ Bin(kiqj , qij ).

Let kp, kq

denote the vector of kipj, kiqj for all (i, j), i < j. The conditional expectation of T is

p q j−1 d Iij kipj kiqj

2

E[T | k , k ] = i=1 j=1 kipj + kiqj (pij − qij ) .

Under the null we have pij = qij. Clearly, using the law of total expectation, we see that EH0 [T ] = E[ E[T | kp, kq] ] = 0. We now upper bound the variance of T under the null. Recall from (23) and (24) that

j−1 d

VarH0 [T ] ≤

8Iij

i=1 j=1

≤ 24d2.

kipj kiqj

2

(kipj + kiqj ) (pij − qij ) + 3

+ Var[ E[T |kp, kq] ]

(56)

Now, we have the information to bound the Type I error. To get a bound on the Type I error with threshold t, we use the one sided Chebyshev’s inequality,

PH (T ≥ t) ≤ VarH0 [T ] .

(57)

0

VarH0 [T ] + t2

Using the bound in (56) and (57), we observe that if t = 11d then the Type I error is at most 16 . This concludes the proof that Algorithm 3 controls the Type I error of the test (13) at level 16 .

32

Bounding the Type 2 error. We now analyse the Type II error of Algorithm 3, that is, the

probability of our algorithm failing to reject the null, under the alternate. We consider two cases

depending on whether the pairwise-comparison data created through the rank breaking method has at

least k pairwise-comparisons per pair (i, j), i < j, or not, for some positive integer k. We will deﬁne k

later in the proof. Let the case where the pairwise-comparisons created in each population have at

least k comparisons of each pair be denoted by C1 and let the associated Type II error be denoted by

β1. Let the Type II error associated with the remaining case be denoted by β2. Our objective is to

provide an upper bound on the total Type II error which is β = P(C1)β1 + (1 − P(C1))β2.

First, we derive a bound on P(C1). To start, we note that the probability of observing a speciﬁc pair

from

a

total

ranking

is

1 d

if

d

is

odd

and

1 d−1

if

d

is

even.

Recall

that

for

a

given

m,

each

sample

is

a

ranking of some m items chosen uniformly at random from the set of d items. Under this setting, we see

that the probability that “Random disjoint” rank breaking yields a speciﬁc pairwise-comparison from a

m-length

partial

ranking

is

m d(d−1)

if

m

is

even

and

m−1 d(d−1)

if

m

is

odd.

Henceforth,

in

this

proof,

we

assume that m is even. The proof follows similarly for odd m. Thus, the number of pairwise-comparisons

observed of any pair (i, j) is a binomial random variable with Bernoulli parameter d(dm−1) . Consequently,

if we have N samples from each population, then for the population corresponding to the pairwise probability matrix P , for all pairs (i, j) we have kipj ∼ Bin(N, d(dm−1) ). Similarly for the population corresponding to pairwise probability matrix Q, for all pairs (i, j) we have kiqj ∼ Bin(N, d(dm−1) ). Now,

we are equipped to compute the probability of case C1. We divide the samples available in each

population into k sections of equal sizes. Let the samples in each population be indexed from 1 to N

then we assign the ﬁrst

N k

into the ﬁrst section and so on. Now, we know that the probability of

observing a pair (i, j) at least once in one such section is given by 1 − (1 − d(dm−1) ) Nk . Using this, we

get the following union bound,

N
P(kipj ≥ k) ≥ 1 − k 1 − d(dm− 1) k .

The same inequality holds for kiqj for all (i, j). Then, the probability that all pairs of items had at least k pairwise-comparisons in both populations is lower bounded as

2kd(d − 1)

m

N k

P(C1) ≥ 1 − 2

1 − d2

≥ 1 − kd2 exp

Nm −

kd2

We

see

that,

if

N

=

ckd2

log(d)/m

for

some

positive

constant

c,

then

P(C1)

≥

1

−

k dc−2

.

Conditioned on the case C1, we invoke Theorem 1 to control the Type II error. Recall that Theorem 1

asserts that there is a constant c0 > 0 such that if we have k pairwise-comparisons of each pair (i, j) from

each

population

where

k

≥

max{c0

1 d2

,

2}

then

the

Type

II

error

of

Algorithm

1

for

the

testing

problem

(13) is upper bounded by 112 . To apply this result to Algorithm 3 conditioned on case C1, we keep k

pairwise-comparisons for each pair where k = 2

c0

1 d2

.

Observe that, since we assume

≥ c1d−c2 for

some positive constants c1 and c2, we get the inequality k ≤ c1dc2 for some positive constants c1 and

c2. Under this inequality, we get that there exist positive constants c, c1 and c2 such that P(C1) > 11/12.

Next, we observe that the Type II error conditioned on the complement of C1 is at most 1. Therefore, the total probability of failing to reject the null under the alternate is given by

β = P(C1)β1 + (1 − P(C1))β2 1 11
≤ + =. 12 12 6

33

d2 log(d) c0 This concludes the proof that for some constant C > 0, if N ≥ C m d 2 , then the probability of error of Algorithm 3 is at most 13 .

6.5 Proof of Theorem 8

The proof of Theorem 8 follows similarly to the proof of Theorem 7. Both theorems establish the

performance of Algorithm 3 for the two-sample testing problem stated in (13). The diﬀerence lies in

the assumption on the partial ranking data available and consequently in the rank breaking algorithm

used. In Theorem 8, we assume we have total ranking data that is then deterministically converted to

pairwise-comparisons in the following manner. We have a total of N total rankings available from each

population. We divide these into subsets each containing d rankings as described in the “Deterministic

disjoint” rank breaking method. Notice that we can break the ranking data available in a section into

pairwise-comparisons such that we observe each unique pair of items at least one time. We prove this

statement at the end of the section. We repeat this breaking technique for all subsets. Consequently,

we get k =

N

1 ≥2 c

pairwise-comparisons for all pairs (i, j) from each population. With this in

d

d2

mind, we apply Theorem 1 to obtain the desired result.

Finally, to complete the proof we show that it is indeed possible to break d total rankings such that

we observe each of d2 unique pairs at least once. We use a mathematical induction based argument. As a ﬁrst step we observe that our hypothesis is true for d = 2. In the inductive step, we assume that

the hypothesis is true for all natural numbers d ∈ {2, · · · , r}. Now, we wish to prove the hypothesis

is true for d = r + 1. First, consider the case where r is even. We divide the set of r items into two

groups with r/2 items in each. From the inductive step we know that our hypothesis is true for d = r/2.

Consequently, we get 2 r/22 unique pairs from within the two groups which use r/2 total rankings. Next, we arrange the items in group one in a list against the items in group two and make pairs by

choosing the items in ith position in both the lists. This gives the breaking for one total ranking. We

do this r/2 times, each time cyclically shifting the ﬁrst list by one item. This step gives r2/4 unique

pairs that are diﬀerent from the pairs obtained in the previous step and uses r/2 total rankings. This

proves our hypothesis for d = r for even r. To prove our hypothesis for odd r, we prove our hypothesis

for r + 1 which is even using the same method described in the previous step. We complete our proof

by noting that if the hypothesis is true for even r then it must be true for r − 1. This concludes our

proof of Theorem 8

6.6 Proof of Theorem 9
The idea of the proof is to show that under the null hypothesis, a ranking sample sourced from the ﬁrst population is mutually independent of and identically distributed as a ranking sample sourced from the second population. If this statement is true, then shuﬄing the population labels of ranking data, does not alter the distribution of the test statistic (8). This in turn controls the Type I error of the permutation test method.
Under the null, for some distribution λ over all total rankings, we have that λP = λQ = λ. This implies that under the marginal probability based model, the probability of any given partial ranking over a set of items is the same for both the populations. Speciﬁcally, conditioned on the set of items being ranked, each partial ranking in each population is sampled independently and identically, according to the distribution λ. Recall that the set of items being ranked in each population is sampled independently and identically from some distribution over all non-empty subsets in [d]. Consequently, each ranking sample is independent of all other ranking samples obtained from the two populations. Moreover, using the law of total probability over all the non-empty subsets in [d], we get that each ranking sample obtained in each population is identically distributed. With this, we conclude that shuﬄing the population labels of ranking data does not alter the distribution of the test statistic. Thus, for a permutation test with γ iterations, the p-value of the test is distributed uniformly over

34

{0, 1/γ, 2/γ, · · · , 1}. Hence, for any given signiﬁcance level α ∈ (0, 1), by applying a threshold of α on the p-value of the test, we are guaranteed to have Type I error at most α.
7 Discussion and open problems
We conclude with a discussion focused on open problems in this area. We provide algorithms for two-sample testing on pairwise-comparison and ranking data to distinguish between two potentially diﬀerent populations (in terms of their underlying distributions). Through our analysis, we see that our testing algorithm for pairwise-comparison data is simultaneously minimax optimal under the model-free setting as well as the MST and WST model. There is a gap between the testing rate of our algorithm and our information-theoretic lower bound for the SST and parameter-based models, and closing this gap is an open problem of interest. Second, in the future, our work may help in studying two-sample testing problems pertaining to more general aspects of data from people such as function evaluations (Xu et al., 2020; Noothigattu et al., 2018), issues of calibration Wang and Shah (2019), and strategic behavior (Xu et al., 2019). Thirdly, in practice we use the permutation method to calibrate our tests, ensuring valid Type I error control even when the distribution of the test statistic is diﬃcult to characterize analytically (for instance, in the setting with partial rank data). Understanding the power of tests calibrated via the permutation method is an active area of research (Kim et al., 2020a) and it would be interesting to understand this in the context of the tests developed in our work. Finally, the literature on analyzing pairwise-comparison data builds heavily on probability models from social choice theory (some are described in this work). A natural related question (that has received some recent attention (Seshadri and Ugander, 2019)) is the design of goodness-of-ﬁt hypothesis tests, that is, testing whether given pairwise-comparison data obeys certain modeling assumptions.
Acknowledgments
This work was supported in part by NSF grants DMS 1713003, CCF 1763734, 1755656 and CAREER 1942124.
35

Appendix A. Additional details of experiments
We now provide more details about the experiments described in Section 5.1.2.
Ordinal versus cardinal
The data set from Shah et al. (2016) used in the “Ordinal versus cardinal” experiment comprises of six diﬀerent experiments on Amazon Mechanical Turk crowdsourcing platform. We describe each experiment brieﬂy here.
• Photo age: There are 10 objects in this experiment wherein each object is a photograph of a diﬀerent face. The worker is either shown pairs of photos together and asked to identify the older of the two or they provide the numeric age for each photo. There are a total of 225 ordinal responses and 275 cardinal-converted-to-ordinal responses.
• Spelling mistakes: There are 8 objects in this experiment wherein each object is a paragraph of text in English possibly with some spelling mistakes. The worker is either shown pairs of paragraphs and asked to identify the paragraph with more spelling mistakes or they are asked to provide the count of spelling mistakes for all 8 paragraphs. There are a total of 184 ordinal responses and 204 cardinal-converted-to-ordinal responses.
• Distances between cities: There are 16 objects in this experiment wherein each object is a pair of cities (no two objects share a common city). The worker is either shown two pairs of cities at a time and asked to identify the pair that is farther from each other, or they are asked to estimate the distances for the 16 pairs of cities. There are a total of 408 ordinal responses and 392 cardinal-converted-to-ordinal responses.
• Search results: There are 20 objects in this experiment wherein each object is the result of an internet based search query of the word "internet". The worker is either asked to compare pairs of results based on their relevance or they are shown all the results and asked to rate the relevance of each result on a scale of 0-100. There are a total of 630 ordinal responses and 370 cardinal-converted-to-ordinal responses.
• Taglines: There are 10 objects in this experiment wherein each object is a tagline for a product described to the worker. The worker is either asked to compare the quality of pairs of taglines or they are asked to provide ratings for each tagline on a scale of 0-10. There are a total of 305 ordinal responses and 195 cardinal-converted-to-ordinal responses.
• Piano : There are 10 objects in this experiment wherein each object is a sound clip of a piano key played at a certain frequency. The worker is either given pairs of sound clips and asked to identify the clip with the higher frequency or they are asked to estimate the frequency of the 10 clips. There are a total of 265 ordinal responses and 235 cardinal-converted-to-ordinal responses.
In our main experiment, we combine the data from all the experiments described above and test for statistically signiﬁcant diﬀerence between the underlying distributions for ordinal responses and ordinal-converted-to-cardinal responses. We also test for diﬀerence in each individual experiment (which however have smaller sample sizes), the results are provided in Table 2. We observe that the qualitatively more subjective experiments (photo age, search results, taglines) have a lower p-value, which indicates that the ordinal responses are more diﬀerent from cardinal-converted-to-ordinal responses in a more subjective setting.
36

Experiment Combined Age Spellings Distances Search results Taglines Piano

p-value

0.003 0.001 0.657

0.75

0.187

0.0829 0.514

Table 2. p-value of two-sample test comparing the distribution of ordinal responses and the distribution of cardinal-converted-to-ordinal responses in the experiments described above

European football leagues

In this experiment, we obtain the match scores for four diﬀerent European football leagues (English Premier League, Bundesliga, Ligue 1, La Liga) across two seasons (2016-2017, 2017-2018). There were 17 teams that played the two seasons in each of EPL, La Liga, Ligue 1 and 16 teams in Bundesliga. To test for statistically signiﬁcant diﬀerence between the relative performance of the participating teams in the two consecutive seasons we combined the data from all four leagues. We also tested for diﬀerence in each individual league, the results are displayed in Table 3. From the 2016-2017 season we have 202 pairwise-comparisons in EPL, 170 pairwise-comparisons in Bundesliga, 215 pairwise-comparisons in La Liga, and 201 pairwise-comparisons in Ligue 1. From the 2017-2018 season we have 214 pairwisecomparisons in EPL, 178 pairwise-comparisons in Bundesliga, 208 pairwise-comparisons in La Liga, and 201 pairwise-comparisons in Ligue 1. From the number of comparisons available our test does not detect any signiﬁcant diﬀerence between the relative performance of teams in European football leagues over two consecutive seasons.

League Combined EPL Bundesliga La Liga Ligue 1

p-value 0.971 0.998 0.691

0.67 0.787

Table 3. p-value of two-sample test comparing relative performance of teams in a football league over two consecutive seasons.

References
Ailon, N. (2012). An active learning algorithm for ranking from pairwise preferences with an almost optimal query complexity. Journal of Machine Learning Research, 13:137–164.
Aldous, D. (2017). Elo ratings and the sports model: A neglected topic in applied probability? Statistical Science, 32(4):616–629.
Balakrishnan, S. and Wasserman, L. (2018). Hypothesis testing for high-dimensional multinomials: A selective review. Ann. Appl. Stat., 12(2):727–749.
Balakrishnan, S. and Wasserman, L. (2019). Hypothesis testing for densities and high-dimensional multinomials: Sharp local minimax rates. Ann. Statist., 47(4):1893–1927.
Bradley, R. A. and Terry, M. E. (1952). Rank analysis of incomplete block designs: I. The method of paired comparisons. Biometrika, pages 324–345.
Braverman, M. and Mossel, E. (2008). Noisy sorting without resampling. In Proceedings of the nineteenth annual ACM-SIAM symposium on Discrete algorithms, pages 268–276.
Carpentier, A., Collier, O., Comminges, L., Tsybakov, A. B., and Wang, Y. (2018). Minimax rate of testing in sparse linear regression. arXiv preprint arXiv:1804.06494.
Cattelan, M., Varin, C., and Firth, D. (2013). Dynamic Bradley–Terry modelling of sports tournaments. Journal of the Royal Statistical Society: Series C (Applied Statistics), 62(1):135–150.
Cavagnaro, D. R. and Davis-Stober, C. P. (2014). Transitive in our preferences, but transitive in diﬀerent ways: An analysis of choice variability. Decision, 1(2):102.
37

Chan, S. O., Diakonikolas, I., Valiant, P., and Valiant, G. (2014). Optimal algorithms for testing closeness of discrete distributions. In Proceedings of the twenty-ﬁfth annual ACM-SIAM symposium on Discrete algorithms, pages 1193–1203. SIAM.
Chatterjee, S. and Mukherjee, S. (2019). Estimation in tournaments and graphs under monotonicity constraints. IEEE Transactions on Information Theory, 65(6):3525–3539.
Chen, X., Gopi, S., Mao, J., and Schneider, J. (2018). Optimal instance adaptive algorithm for the top-k ranking problem. IEEE Transactions on Information Theory, 64(9):6139–6160.
Chen, Y. and Suh, C. (2015). Spectral MLE: Top-k rank aggregation from pairwise comparisons. In International Conference on Machine Learning, pages 371–380.
Collier, O., Comminges, L., and Tsybakov, A. B. (2017). Minimax estimation of linear and quadratic functionals on sparsity classes. The Annals of Statistics, 45(3):923–958.
Falahatgar, M., Orlitsky, A., Pichapati, V., and Suresh, A. T. (2017). Maximum selection and ranking under noisy comparisons. In 34th International Conference on Machine Learning, pages 1088–1096.
Farias, V. F., Jagabathula, S., and Shah, D. (2013). A nonparametric approach to modeling choice with limited data. Management science, 59(2):305–322.
Gretton, A., Borgwardt, K., Rasch, M., Schölkopf, B., and Smola, A. (2012a). A kernel two-sample test. Journal of Machine Learning Research, 13:723–773.
Gretton, A., Sejdinovic, D., Strathmann, H., Balakrishnan, S., Pontil, M., Fukumizu, K., and Sriperumbudur, B. K. (2012b). Optimal kernel choice for large-scale two-sample tests. In Pereira, F., Burges, C. J. C., Bottou, L., and Weinberger, K. Q., editors, Advances in Neural Information Processing Systems, volume 25, pages 1205–1213. Curran Associates, Inc.
Guiver, J. and Snelson, E. (2009). Bayesian inference for plackett-luce ranking models. In Proceedings of the 26th Annual International Conference on Machine Learning, ICML ’09, page 377–384, New York, NY, USA. Association for Computing Machinery.
Heckel, R., Shah, N. B., Ramchandran, K., and Wainwright, M. J. (2019). Active ranking from pairwise comparisons and when parametric assumptions do not help. The Annals of Statistics, 47(6):3099–3126.
Herbrich, R., Minka, T., and Graepel, T. (2007). Trueskill: A Bayesian skill rating system. In Advances in neural information processing systems, pages 569–576.
Hvattum, L. M. and Arntzen, H. (2010). Using Elo ratings for match result prediction in association football. International Journal of forecasting, 26(3):460–470.
Ingster, Y. I. (1994). Minimax detection of a signal in p metrics. Journal of Mathematical Sciences, 68(4):503–515.
Ingster, Y. I. (1997). Adaptive chi-square tests. Zapiski Nauchnykh Seminarov POMI, 244:150–166.
Ingster, Y. I. and Suslina, I. A. (2003). Nonparametric Goodness-of-Fit Testing Under Gaussian Models. Lecture Notes in Statistics. Springer.
Jerrum, M. (1992). Large cliques elude the metropolis process. Random Struct. Algorithms, 3:347–360.
Kamishima, T. (2003). Nantonac collaborative ﬁltering: recommendation based on order responses. In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 583–588.
38

Kim, I., Balakrishnan, S., and Wasserman, L. (2020a). Minimax optimality of permutation tests.
Kim, I., Balakrishnan, S., and Wasserman, L. (2020b). Robust multivariate nonparametric tests via projection-averaging. To appear in The Annals of Statistics.
Kučera, L. (1995). Expected complexity of graph partitioning problems. Discrete Appl. Math., 57(2-3):193–212.
Lamon, A., Comroe, D., Fader, P., McCarthy, D., Ditto, R., and Huesman, D. (2016). Making WHOOPPEE: A collaborative approach to creating the modern student peer assessment ecosystem. In EDUCAUSE.
Lehmann, E. L. and Romano, J. P. (2005). Testing statistical hypotheses. Springer Texts in Statistics. Springer, third edition.
Luce, R. D. (1959). Individual choice behavior: A theoretical analysis. New York: Wiley.
Mania, H., Ramdas, A., Wainwright, M. J., Jordan, M. I., and Recht, B. (2018). On kernel methods for covariates that are rankings. Electronic Journal of Statistics, 12(2):2537–2577.
Maystre, L. and Grossglauser, M. (2015). Fast and accurate inference of plackett-luce models. In Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 1, NIPS’15, page 172–180, Cambridge, MA, USA. MIT Press.
Negahban, S., Oh, S., and Shah, D. (2012). Iterative ranking from pair-wise comparisons. In Advances in neural information processing systems, pages 2474–2482.
Noothigattu, R., Shah, N. B., and Procaccia, A. D. (2018). Loss functions, axioms, and peer review. arXiv preprint arXiv:1808.09057.
Plackett, R. L. (1975). The analysis of permutations. Journal of the Royal Statistical Society, 24(2):193– 202.
Rajkumar, A. and Agarwal, S. (2014). A statistical convergence perspective of algorithms for rank aggregation from pairwise data. In International Conference on Machine Learning, pages 118–126.
Rajkumar, A., Ghoshal, S., Lim, L.-H., and Agarwal, S. (2015). Ranking from stochastic pairwise preferences: Recovering condorcet winners and tournament solution sets at the top. In International Conference on Machine Learning, pages 665–673.
Raman, K. and Joachims, T. (2014). Methods for ordinal peer grading. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 1037–1046. ACM.
Regenwetter, M., Dana, J., and Davis-Stober, C. P. (2011). Transitivity of preferences. Psychological review, 118(1):42.
Rosenbaum, P. R. (2005). An exact distribution-free test comparing two multivariate distributions based on adjacency. Journal of the Royal Statistical Society Series B, 67:515–530.
Seshadri, A. and Ugander, J. (2019). Fundamental limits of testing the independence of irrelevant alternatives in discrete choice. In Proceedings of the 2019 ACM Conference on Economics and Computation, EC ’19, page 65?66, New York, NY, USA. Association for Computing Machinery.
Shah, N. B., Balakrishnan, S., Bradley, J., Parekh, A., Ramchandran, K., and Wainwright, M. J. (2016). Estimation from pairwise comparisons: Sharp minimax bounds with topology dependence. The Journal of Machine Learning Research, 17(1):2049–2095.
39

Shah, N. B., Balakrishnan, S., Guntuboyina, A., and Wainwright, M. J. (2017). Stochastically transitive models for pairwise comparisons: Statistical and computational issues. IEEE Transactions on Information Theory, 63(2):934–959.
Shah, N. B., Bradley, J. K., Parekh, A., Wainwright, M., and Ramchandran, K. (2013). A case for ordinal peer-evaluation in moocs. In NeurIPS Workshop on Data Driven Education, pages 1–8.
Shah, N. B., Tabibian, B., Muandet, K., Guyon, I., and Von Luxburg, U. (2018). Design and analysis of the NIPS 2016 review process. The Journal of Machine Learning Research, 19(1):1913–1946.
Shah, N. B. and Wainwright, M. J. (2018). Simple, robust and optimal ranking from pairwise comparisons. Journal of Machine Learning Research, 18(199):1–38.
Szekely, G. J. and Rizzo, M. L. (2004). Testing for equal distributions in high dimensions. InterStat. Szörényi, B., Busa-Fekete, R., Paul, A., and Hüllermeier, E. (2015). Online rank elicitation for Plackett-
Luce: A dueling bandits approach. In Advances in Neural Information Processing Systems, pages 604–612. Thurstone, L. L. (1927). A law of comparative judgment. Psychological Review, 34(4):273. Valiant, G. and Valiant, P. (2017). An automatic inequality prover and instance optimal identity testing. SIAM Journal on Computing, 46(1):429–455. Valiant, P. (2011). Testing symmetric properties of distributions. SIAM Journal on Computing, 40(6):1927–1968. Van Der Maas, H. L. and Wagenmakers, E.-J. (2005). A psychometric analysis of chess expertise. American Journal of Psychology, 118(1):29–60. Wang, J. and Shah, N. B. (2019). Your 2 is my 1, your 3 is my 9: Handling arbitrary miscalibrations in ratings. In Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems, pages 864–872. International Foundation for Autonomous Agents and Multiagent Systems. Xu, Y., Balakrishnan, S., Singh, A., and Dubrawski, A. (2020). Regression with comparisons: Escaping the curse of dimensionality with ordinal information. Journal of Machine Learning Research, 21(162):1–54. Xu, Y., Zhao, H., Shi, X., and Shah, N. B. (2019). On strategyproof conference peer review. In Proceedings of the Twenty-Eighth International Joint Conference on Artiﬁcial Intelligence, IJCAI-19, pages 616–622. International Joint Conferences on Artiﬁcial Intelligence Organization.
40

