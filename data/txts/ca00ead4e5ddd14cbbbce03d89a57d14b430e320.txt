Privacy and Customer Segmentation in the Smart Grid
Lillian J. Ratliff, Roy Dong, Henrik Ohlsson, Alvaro A. Ca´rdenas and S. Shankar Sastry

arXiv:1405.7748v1 [math.OC] 29 May 2014

Abstract— In the electricity grid, networked sensors which record and transmit increasingly high-granularity data are being deployed. In such a setting, privacy concerns are a natural consideration. We present an attack model for privacy breaches, and, using results from estimation theory, derive theoretical results ensuring that an adversary will fail to infer private information with a certain probability, independent of the algorithm used. We show utility companies would beneﬁt from less noisy, higher frequency data, as it would improve various smart grid operations such as load prediction. We provide a method to quantify how smart grid operations improve as a function of higher frequency data. In order to obtain the consumer’s valuation of privacy, we design a screening mechanism consisting of a menu of contracts to the energy consumer with varying guarantees of privacy. The screening process is a means to segment customers. Finally, we design insurance contracts using the probability of a privacy breach to be offered by third-party insurance companies.
I. INTRODUCTION
Increasingly advanced metering infrastructure (AMI) is replacing older technology in the electricity grid. Smart meters send detailed information about consumer electricity usage over a network every half-hour, quarter-hour, or in some cases, every ﬁve minutes. This high-granularity data is needed to support energy efﬁciency efforts as well as demand-side management. However, improper handling of this information could also lead to unprecedented invasions of consumer privacy [1], [2].
Given that smart grid operations inherently have privacy and security risks [2], it would beneﬁt the utility company, to know the answer to the following questions: How do consumers in the population value privacy? How can we quantify privacy? How do privacy-aware policies impact smart grid operations? In this paper we address these questions as well as expose new directions for future research on privacy and customer segmentation in the smart grid.
Using our results on the fundamental limits of nonintrusive load monitoring [3], we are able to come up with probabilities for the success of an attack by an adversarial agent independent of the algorithm. Then using these probabilities we can design a screening mechanism consisting of a menu of contracts to be offered to consumers. One set of contracts to be offered by the utility company assess how the consumer values privacy thereby revealing his preferences. Based on their valuation of privacy as a good,
L. J. Ratliff, R. Dong, H. Ohlsson, and S. S. Sastry are with Faculty of Electrical Engineering and Computer Sciences, University of California, Berkeley, Berkeley, CA, 94707, USA {ratliffl, roydong, ohlsson, sastry}@eecs.berkeley.edu
A. A. Ca´rdenas is with the Department of Computer Science, University of Texas, Dallas, Dallas, TX 75080, USA alvaro.cardenas@utdallas.edu

consumers can select the quality of the service contract with the utility company. Essentially, electricity service is offered as a product line differentiated according to privacy where consumers can select the level of privacy that ﬁts their needs and wallet. The screening process is a way to do customer segmentation the result of which can lead to targeting.
In particular, using knowledge of consumer preferences, the utility company could then incentivize consumers based on their preferences to choose a low privacy setting which helps increase the granularity of data for use by the utility company for programs like demand response, direct load control, etc. In addition, third-party insurance companies can design insurance contracts. Insurance allows the consumer to protect himself in the event of a privacy breach, i.e. she will be compensated for any experienced loss.
The paper is organized as follows. In Section II we review the problem of non-intrusive load monitoring (NILM) and show how NILM leads to our novel privacy metric. We show in an example that the probability of an adversary successfully implementing a privacy breach decreases with a decrease in sampling rate. We discuss the impact of sampling rate on smart grid operations in Section III. In Section IV we use the privacy metric to design a screening mechanism that consists of privacy contracts between the consumer and the utility company. Similarly, in Section V we use the privacy metric to design insurance contracts. Finally, in Section VI we summarize the results and discuss future research directions.
II. PRIVACY GUARANTEES
In this section, we discuss our metric for privacy, and guarantees of privacy under this metric. For this paper, we restrict the scope of our analysis to data collection policies. Another important aspect of privacy is how data retention policies can alter privacy and smart grid performance. Such a topic is reserved for future research.
A. Nonintrusive Load Monitoring
Our formulation of privacy builds on recent research into nonintrusive load monitoring (NILM) algorithms, ﬁrst proposed by Hart [4]. The goal of NILM is to use the aggregate power consumption signal, which can be measured by metering infrastructures without the placement of additional sensors inside the home, and make inferences on the load proﬁle. For example, the problem of energy disaggregation is to recover the power consumption signals of individual devices [5]. Another example would be to detect when devices switch on and off, which is often referred to as eventbased NILM [6].

There are many approaches to the design of NILM algorithms, including but not limited to hidden Markov models (HMMs) [7], [8], [9], sparse coding methods [10], and dynamical systems approaches [11]. These methods vary in the prior information required; some are completely unsupervised and nonparametric, while others require a large amount of disaggregated data to build a dictionary. However, in our recent work, we provided a unifying framework for modeling all of these algorithms [3].
To the best of our knowledge, every approach to energy disaggregation gives devices a certain kind of model, be it an HMM, dictionary, or dynamical system. Most of these approaches have an input space: for HMMs, the input is a sequence of latent state transitions; for the sparse approaches, it is a sparse vector corresponding to the most representative elements in the dictionary, and in dynamical systems, it is an input signal to the systems.
In all these approaches, a ﬁxed input yields a probability distribution on the device’s power consumption; this distribution is often assumed to be Gaussian. Finally, note that in all the mentioned frameworks, recovering the input is almost the same as recovering the device’s power consumption signal.
Other NILM formulations also can fall into this framework. For example, in event-based NILM, if the task is to determine whether or not the air conditioner is in use, we can consider the probability distribution across aggregate power consumption signals when the air conditioner is on and when the air conditioner is off. In this case, whether or not the air conditioner is on serves as an input.
In our framework, NILM algorithms are abstracted as measurable functions operating on the aggregate power consumption signal, and we ask whether or not the algorithms can successfully distinguish between inputs. For a more comprehensive treatment of this topic, we refer the reader to [3].
B. Privacy Metric
Now, we are ready to introduce our metric of privacy. One of the common theoretical deﬁnitions for a privacy metric is the notion of differential privacy [12], [13]. While differential privacy has many attractive properties, it is most useful when we want to share data via a trusted third party aggregator, or by injecting noise in the original messages sent to a third party; however, for many practical, regulatory, dispute resolution, performance, or business reasons, there will always be several cases where we need to get access to the raw data, and in these cases differential privacy will not help us identify a good security mechanism to prevent raw data from being compromised. In contrast, we ﬁx a deﬁnition of a privacy breach where the user has a set of possible inputs, and he wishes to keep the true input private. For example, the deﬁnition of privacy breach might be whether or not an adversary knows if the user is doing dishes in the dishwasher, watching TV, or exercising on a treadmill in the evening. This notion of equivocation is related to recent work in privacy who measures

privacy not with differential privacy but with equivocation

metrics [14].

We also assume a powerful adversary that knows the

probability distribution of the energy consumption of digital

signals, and their prior probability for being active in an ag-

gregated signal. As an observation, we assume the adversary

has access to the aggregate power consumption signal, but

not the device-level signals, for a building.

More formally, suppose there are two inputs u1 and u2. For

each input, the aggregate power consumption signal follows

distributions F1 and F2, respectively. In this paper, we assume

these distributions to be Gaussian; however, we consider the

general case in [3].

Suppose the distributions have means µ1 and µ2, and

both distributions have the same covariance σ 2I. Let a =

σ −2 (µ0 − µ1)

and

b=

1 2σ 2

µ1

2 2

−

µ2

2 2

.

Suppose

the

adversary uses any estimator uˆ and suppose the events {u =

u1} and {u = u2} are equally likely. Then, the probability

of our adversary successfully distinguishing two inputs is

bounded by

1

−

1 a

(aT µ0 + b)

P(uˆ = u) ≤ 1 − erf

2√

(1)

2

2σ 2

where erf is the Gauss error function. More details can be found in [3].

III. SMART GRID OPERATIONS
In Section II, we developed a metric for privacy. If privacy is the only thing of concern, a trivial solution is to record nothing transmit nothing. However, the utility company has other objectives than just preserving the privacy of its consumers. Hence, privacy issues arise because the sensitive data has other uses. Such polices as noise injection or varying the sampling rate can be employed to protect against privacy breaches while still allowing the utility company to operate.
In advanced metering infrastructures, the data is used to improve the performance of smart grid operations. How smart grid operations degrade under different metering policies is an active topic of research; for preliminary investigations, see [15], [16]. Intuitively, the performance will degrade as fewer samples are collected or more noise is added. We attempt to quantify this degradation. In this section, we develop an direct load control example to demonstrate how smart grid operations performance is affected by different sampling rates.

A. Direct Load Control
The problem of direct load control has recently been studied as viable option to improve smart grid operations [17], [18].
Generator output is generally determined by two processes: unit commitment and economic dispatch. Unit commitment is done in advance, and sets the generator ramping schemes. Economic dispatch is done online, and determines the output levels of generators that are already online to meet total demand.

When the demand exceeds the output capacity of all online generators, economic dispatch schemes will use generators with quick ramp-up times to ensure stability of the power grid. These generators are very inefﬁcient. One goal of direct load control (DLC) as an economic dispatch scheme is to reduce the deviation of actual demand from the forecasted demand.
Consider the direct load control model:

xk+1 = xk + uk + µk + dk

(2)

Here, xk ∈ R represents the power consumption of a unit at time k, where a unit can be a household, an HVAC system for a building, or a sector of the power grid. uk ∈ R represents the direct load control signal at time k. µk ∈ R represents the afﬁne term which generates our nominal demands at time k; if uk ≡ 0 and dk ≡ 0, then µk creates our forecasted demand. Finally, dk represents the disturbance at time k. In this model, disturbances from the nominal demand persist, and DLC policies must be employed to return the power consumption to the nominal demand.
Now, consider different sampling rates. That is, we suppose our controller is only able to receive measurements every N time steps. However, it is still able to issue control commands at every time step. We wish to design a controller that makes use of the available measurements to optimally issue control commands to a sector of the power grid.
The subsampled system can be modeled in a Markov jump linear system (MJLS) framework. To deﬁne optimality, we consider the H∞ norm of MJLSs, as deﬁned in [19], [20]. In our application, the H∞ norm represents a worst case estimate of how much the true power consumption will deviate from the power consumption used for unit commitment. This worst case estimate is a function of the uncertainty in the load forecast.
Recent results in the analysis of MJLS gives us the optimal H∞ controller for subsampled scalar systems [16]. Thus, we can analyze how the performance of direct load control is affected by different sampling schemes. For example, Figure 1 gives us the performance for equidistant sampling. Thus, the formulation allows us to quantify the value of a higher sampling rate to the utility company.

IV. PRIVACY CONTRACTS
In this section, we discuss how the utility company can design a screening mechanism in order to assess the consumer’s unknown type. This is a mechanism design problem with asymmetric information. The utility company designs a screening mechanism whose contracting device is the privacy setting offered to the consumer. This screening process can be thought of as customer segmentation since it will extract each consumer’s type after which the consumers can be grouped according to their type.
We consider a model in which there are only two types and we utilize standard results from the theory of screening (see, e.g., [21]) to develop a framework for designing privacy contracts. We remark that as a result of the screening process the utility company will know how each consumer values

H∞ norm

H∞ norm under equidistant sampling scheme
70

60

50

40

30

20

10

0

0

10

20

30

40

50

60

70

80

90

100

Sampling interval N

Fig. 1. The H∞ norm for the equidistant sampling scheme as a function of the sampling interval N. A higher sampling interval N corresponds to a
lower sampling frequency, i.e. the utility company receives less data.

privacy and can leverage that in the design of incentives aimed at inducing the consumer to select a privacy setting more desirable from the perspective of the utility company.

A. Two Types: High-Privacy and Low-Privacy Settings

We model privacy-settings on smart meters as a good.

The quality of the good is either a high-privacy setting

qH or a low-privacy setting qL. The consumer can choose

either a high privacy setting or a low privacy setting, i.e. the

consumer selects q ∈ Q = {qH, qL} ⊂ R where qL ≤ qH and

−∞ < qL < qH < ∞. The consumer’s valuation of privacy

is his type which takes values θ ∈ {θ , θ } ⊂ R where θ

represents how much the consumer values high-privacy over

low-privacy and θ < θ . We assume that type θ is distinct

from the private information itself; by this we mean that

how much the consumer values privacy is not also private

information. We note here that these types implicitly make

use of the probabilities presented in Section II.

The consumers type θ is related to his willingness to pay

in the following way: if the utility company announces a

price t for choosing q, the type-dependent consumer’s utility

is equal to zero if he does not select a privacy setting q, and

it is

U(q, θ ) − t ≥ 0

(3)

if he does select a privacy setting. The case in which the consumer does not select a privacy setting is considered the opt-out case in which consumer exercises his right to not participate. The inequality in (3) is often called the individual rationality constraint and in the design of the privacy contracts we will enforce it in order to make sure that all consumers will opt-in. The function U : R × Θ → R is assumed to be strictly increasing in (q, θ ), concave in q, and represents the consumer’s preferences.
Since we have only two types, the contracts offered will be indexed by the privacy settings qL and qH . Further, as we mentioned the consumer can opt-out by not selecting a privacy option at all. Hence, we need to constrain the

mechanism design problem by enforcing the inequality given in Equation (3) for each value of θ ∈ {θ , θ }. In addition, we need to enforce incentive-compatibility constraints

U (qH, θ ) − tH ≥ U (qL, θ ) − tL

(4)

and

U (qL, θ ) − tL ≥ U (qH, θ ) − tH

(5)

where the ﬁrst inequality says that given the price tH a consumer of type θ should prefer the high-privacy setting qH and the second inequality says that given the price tL a consumer of type θ should prefer the low-privacy setting qL.
The utility company has unit utility

v(q,t) = −g(q) + t

(6)

where we assume that the function g : Q → R is the unit cost to the utility company for the privacy setting q. We assume that it is a strictly increasing, continuous function which is reasonable because, as we have mentioned in Section III, a low-privacy setting qL provides the utility company with the high-granularity data it needs to efﬁciently operate and maintain the smart grid. For example, recall Section III-A in which we show that the performance of DLC degrades with decreases in sampling rate.
The screening problem is to design the contracts, i.e. {(tL, qL), (tH , qH)} where tL,tH ∈ R, so that the utility companies expected proﬁt is maximized where the expected proﬁt is
Π(tL, qL,tH , qH ) = (1 − p)v(qL,tL) + pv(qH,tH ) (7)

where p = P(θ = θ ) = 1 − P(θ = θ ) ∈ (0, 1) where P(·) denotes probability.
To ﬁnd the optimal pair of contracts, we solve the following optimization problem:

max Π(tL, qL,tH , qH )
{(tL,qL),(tH ,qH )}
s.t. U (qH, θ ) − tH ≥ U (qL, θ ) − tL U (qL, θ ) − tL ≥ U (qH, θ ) − tH U (qL, θ ) − tL ≥ 0 U (qH, θ ) − tH ≥ 0 qL ≤ qH

(P-1)
(IC-1) (IC-2) (IR-1) (IR-2)

Depending on the form of U(q, θ ) and g(q) problem (P-1) can be difﬁcult to solve. So, we examine the constraints and try to eliminate as many as we can.
First, we show that (IR-1) is active. Indeed, suppose not. Then, U(qL, θ ) − tL > 0 so that, from the ﬁrst incentive compatibility constraint (IC-1), we have

U (qH, θ ) − tH ≥ U (qL, θ ) − tL ≥ U (qL, θ ) − tL > 0 (8)

where the second to last inequality holds since U(q, θ ) is increasing in θ by assumption. As a consequence, the utility company could increase the price for both types since
neither incentive compatibility constraint would be active. This would lead to an increase in the utility company’s payoff, i.e. a contradiction. Now, since U(qL, θ ) = tL, the last

inequality in (8) is equal to zero. This implies that (IR-2) is redundant. Further, this argument implies that the constraint (IC-1) is active. Indeed, again suppose not. Then,

U (qH, θ ) − tH > U (qL, θ ) − tL ≥ U (qL, θ ) − tL = 0 (9)

so that it would be possible for the utility company to decrease the incentive tH without violating (IR-2).
Now, let us assume that the marginal gain from raising the value of the privacy setting q is greater for type θ , i.e. U(q, θ ) − U(q, θ ) is increasing in q. Then, since (IC-1) is active, we have

tH − tL = U (qH, θ ) −U (qL, θ ) ≥ U (qH, θ ) −U (qL, θ ). (10)

This inequality implies that we can ignore (IC-2). Further, since U is increasing in (q, θ ) and we have assumed that θ > θ , we can remove the constraint qL ≤ qH. We have reduced the constraint set to

tH − tL = U (qH, θ ) − U (qL, θ )

(11)

tL = U (qL, θ )

(12)

Thus, the optimization problem becomes

ß max p(U(qH, θ ) − g(qH) − U(qL, θ ) + U(qL, θ ))
(qL,qH )
™ (1 − p)(U(qL, θ ) − g(qL))

(P-2)

This reduces further to two independent optimization problems:

max{U(qH, θ ) − g(qH)}
qH
max{−p(U(qL, θ ) − U(qL, θ ))+
qL
(1 − p)(U(qL, θ ) − g(qL))}

(P-3a) (P-3b)

B. Direct Load Control Example

Recall that the unit gain the utility company gets out of the privacy setting q is a function g : Q → R. In this section, we discuss a particular example in which g is a metric for how access to high-granularity data affects direct load control. In Section III-A, Figure 1 shows how that as you decrease the sampling rate (increase the sampling interval) the performance degrades, i.e. the H∞ norm increases, and it degrades in a linear way. Hence, this motivates a choice for g such that g(qL) > g(qH) and decreases in a linear way. Hence, for this example, let

g(q) = ζ q

(13)

where 0 < ζ < ∞. Note that a decreased sampling rate corresponds to a higher privacy setting. The function g as deﬁned is increasing in q so that g(qL) > g(qH).
Assume that the consumer’s utility is given by

U(q, θ ) = 1 (q¯2 − (q − q¯)2)θ

(14)

2

where q ∈ [0, q¯] so that it is proportional to how close they are to the maximum privacy setting q¯, and their type θ . Suppose

that θ ∈ {θ , θ } where 0 < θ < θ . Note that at θ the utility is 21 q¯2 and at θ the utility is zero. U satisﬁes the assumption that it is increasing. Let p = P(θ = θ ). Then, the optimal
solutions to the screening problem are

(q∗

, q∗)

=

Ç q¯

−

ζ

ñ , q¯

+

(1

−

p)ζ

ô

å

(15)

HL

θ

(pθ − θ ) +

where q∗L = 0 when the probability p is greater than the critical point p∗ = θ /θ . The optimal prices tH∗ ,tL∗ can be found by plugging (q∗H, q∗L) into (11) and (12). If the utility company knew the types, then the optimal solution would be

(q†H, q†L) = Åq¯ − θζ , q¯ − θζ ã (16)

In Figure 2, we show that as the probability of the high-

q

q¯ − ζ
θ

q¯

−

ζ θ

q∗H = q†H q†L

q∗L

0

p0

1p

Fig. 2. Comparison between full information and asymmetric information solutions as a function of p the probability of the high-type in the population.

type being drawn from the population increases, q∗L decreases away from the optimal full information solution q†L. This occurs until p = p0 = θ /θ which is the critical probability. After p0, q∗L = 0 and remains there until p = 1.
The social welfare is deﬁned to be sum of the pay-off to
the utility company and to the consumer. The social welfare is given by

Ψ∗(p) = Π(tL∗, q∗L,tH∗ , q∗H) + p(U (q∗H, θ ) − tH∗ ). (17)

Let

ϕ = (1 − p)

1

Ç q¯2

−

Å

(1

−

p)ζ

ã2

å

θ

2

pθ − θ

−

ζ

Å q¯

−

(1

−

p)ζ

ã

.

(18)

pθ − θ

Then,

Ψ∗(

p)

=

−

pζ

Å q¯

−

ζ

ã



θ

ϕ,

+  p Å 12 Åq¯2 − (1p−θ−p)θζ

p ≤ p0

2ã

ã

(θ − θ ) , p > p0

(19)

The social welfare reaches a critical point at p0 beyond which the utility company will exclude the low-type from the market and only provide privacy contracts to the hightype. This is called the shutdown solution. It is reasonable

that as soon as the probability of the utility company facing a consumer of high-type reaches a critical point, they will focus all their efforts on this type of consumer since a high-type desires a higher privacy setting which results in a degradation of the DLC scheme.
We remark that people who value high privacy more need to be compensated more to participate in the smart grid. If there are two contracts, then even consumers who do not value privacy much will have an incentive to lie. Through the screening mechanism, the consumer will report his type truthfully.
V. PRIVACY INSURANCE CONTRACTS
In this section, we will design an insurance contract, to be offered by a third-party company to the consumer, that uses the probability η that an adversary will fail to infer private information about the consumer. In the previous section we designed contracts to get consumers to allow for lower privacy settings; in this section we design insurance contracts that allow consumers to purchase protection against attacks given they know the probability of a successful attack occurring. The analysis that follows is well known in the economics literature (see, e.g., [22], [23], [24]). Using the theory of insurance contracts when there is asymmetric information and the probability that an adversary can gain access to consumers’ private information, we analyze both the consumer’s choice on how much insurance to invest in as well as the insurer’s decision about which contracts to offer to a population with both high- and low-risk consumers.
A. Analysis of Consumer’s Decision
Let us start by analyzing the decision the consumer would make about selecting an amount of insurance given knowledge of η. Let the consumer’s utility function be denoted by U˜ : R → R and assume that U˜ is increasing, twice differentiable and strictly concave. Let us suppose that the consumer is risk-averse which means that the consumer, who makes a decision under uncertainty, will try to minimize the impact of the uncertainty on her decision.
In addition, suppose the consumer has initial wealth y, runs the risk of loss ℓ with probability 1 − η. In the context of our problem, wealth represents private information that can be gained through analysis of consumer energy consumption data and loss represents exposure of this private information. Recall that 1 − η is the probability with which an adversarial agent could gain access to private information about a consumer through access to their consumption data.
The consumer must decide how much insurance to buy. Let the cost of one unit of insurance be c and suppose that the insurer pays the consumer β in the event that an adversary attacks them resulting in an exposure of private information where β is the amount of insurance the consumer agrees to buy. Then the consumer wants to solve the following optimization problem:
max{ηU˜ (y − β c) + (1 − η)U˜ (y + (1 − c)β − ℓ)} (P-4)
β ≥0

Suppose that β ∗ is a local optimum, then there Lagrange multiplier λ such that
 0 = −λ+−(1η−cU˜η′()y(1−−βc∗)cU)˜ ′(y + (1 − c)β ∗ − ℓ) 0 = λβ∗
 0 ≥ β ∗ 0≥λ

exists a (20)

These conditions are the Karush-Khun-Tucker (KKT) necessary conditions. Combining the ﬁrst and the last condition, we get

0 ≥ −ηcU˜ ′(y − β ∗c) + (1 − η)(1 − c)U˜ ′(y + (1 − c)β ∗ − ℓ) (21)
We analyze the consumer’s decision by considering two cases and we present the results in the following propositions.

Proposition 1: Suppose that the consumer is offered privacy insurance at the rate c = 1 − η, i.e. at a rate equal to the probability of a successful attack. Then the consumer will choose to purchase an amount of insurance equal to the loss, i.e. β ∗ = ℓ.
Proof: Since c = 1 − η, (21) reduces to

0 ≥ η(1 − η) U˜ ′(y + ηβ ∗ − ℓ) − U˜ ′(y − β ∗(1 − η)) (22)

and since (1 − η)η ≥ 0 this again reduces to

0 ≥ U˜ ′(y + ηβ ∗ − ℓ) − U˜ ′(y − β ∗(1 − η)) (23)

Recall that we assumed U˜ to a be a concave function and
that a function is strictly concave if and only if its derivative U˜ ′ is decreasing. Hence,

U˜ ′(z) < U˜ ′(z − ℓ)

(24)

since ℓ > 0. This fact along with (23) implies that β ∗ > 0. Now, we claim that β ∗ = ℓ. Indeed, suppose that 0 < β ∗ < ℓ, then from (23) we have

U˜ ′(y˜ − ℓ) ≤ U˜ ′(y˜ − β ∗)

(25)

where y˜ = y + ηβ ∗. This inequality violates (24). On the other hand, suppose that 0 ≤ ℓ ≤ β ∗, then from (24) we have

U˜ ′(y˜ − β ∗) > U˜ ′(y˜ − ℓ)

(26)

but this violates the KKT inequality (23). Hence, β ∗ = ℓ which is to say that the consumer will purchase an amount of insurance equal to the loss of privacy she would endure under an attack.

Proposition 2: Suppose that the consumer is offered in-
surance at the rate c > 1 − η, i.e. at a rate higher than the
probability of a successful attack. Then the consumer will not purchase the full insurance, i.e. β ∗ < ℓ.

Proof: Suppose that the consumer is offered privacy insurance at a rate c > 1 − η and that the optimal choice for the consumer is β ∗ = ℓ ≥ 0. Then, ﬁrst-order optimality conditions imply that

− ηU˜ ′(y − ℓc)c + (1 − η)U˜ ′(y − ℓc)(1 − c) = 0 (27)

However, since c > 1 − η and U˜ is increasing, from (21) we

have

(−ηc + (1 − η)(1 − c))U˜ ′(y − ℓc) < 0

(28)

so that, in fact, the optimal β has to be less than the loss experienced, i.e. β ∗ < ℓ.

B. Analysis of the Insurer’s Decision

Let us now consider the case of a third-party insurance company offering offering privacy insurance to the consumer which protects them against losses due to attacks. In a way, insurance allows the consumer to hedge their bet against selecting a contract with a low-privacy setting.

We consider a similar setup as before: the consumer’s utility function U˜ is strictly concave, increasing and twice differentiable and for the sake of analysis we assume that U˜ (0) = 0. We consider a scenario in which the insurer faces two types: high-risk consumer θh and low-risk consumer θl. That is to say we are assuming that there is a portion of the population that is more likely to be attacked, i.e. the risky consumers, possibly because they engage in high-risk behavior or due to the fact that they selected a low-privacy setting contract with the utility company. The consumer again has an initial amount of private information with value y and with probability 1 − η j some of her private information is exposed resulting in a loss ℓ where j = h, l indicates the consumer’s type. We assume that 1 − ηl < 1 − ηh.
We will assume that the insurer has a prior over the distribution of types. In particular, we assume that the risky type θh occurs in the population with probability p and that p > 0.
Suppose we are given an insurance contract (αa, αn) where αa is the compensation to the consumer given that a successful attack occurred and αn is the neutral case (no attack). Let X be a random variable representing the consumer’s wealth such that with probability 1 − ηi it takes value y − ℓ + αa and with probability ηi it takes value y − αn. Then, the consumers expected utility is

E[U˜ (X )] = (1 − ηi)U˜ (y − ℓ + αa) + ηiU˜ (y − αn) (29)

Note that in the previous subsection we analyzed the consumer’s decision given a insurance contract of the form

αa = (1 − c)β , αn = β c

(30)

The insurer is a monopolist whose expected cost is

Π(αah

,

αnh

,

αal

,

αnl

)

=

p

Ä −(1

−

ηh)αah

+

ηhαnh

ä

+

(1

−

p)

Ä −(1

−

ηl

)αal

+

ηl

αnl

ä

(31)

In the case of asymmetric information, i.e. the insurer does not know the consumer’s type, the optimization problem he

must solve is

max Π(αah, αnh, αal , αnl )
{(αaj,αnj)} j=h,l

(P-5)

s.t. (1 − ηi)U˜ (y − ℓ + αai) + ηiU˜ (y − αni )

≥ (1 − ηi)U˜ (y − ℓ + αaj) + ηiU˜ (y − αnj),

i, j ∈ {h, l}, i = j

(IC)

(1 − ηi)U˜ (y − ℓ + αai ) + ηiU˜ (y − αni )

≥ (1 − ηi)U˜ (y − ℓ) + ηiU˜ (y), i ∈ {h, l} (IR)

Constraints labeled (IC) are the incentive compatibility constraints and constraints (IR) are the individual rationality constraints. Both are similar to those presented in Section IV-A. Incentive compatibility ensures that the consumer will report their type truthfully and the individual rationality constraint ensures that the consumer will participate.

Following a similar reasoning as in Section IV-A, we can reduce the optimization problem (P-5) by reasoning about the constraint set deﬁned by (IC) and (IR). In particular, we argued that the high-privacy type’s incentive compatibility constraint was active and that the low-privacy type’s individual rationality constraint was active. In addition, we showed the other two constraints (IC-2) and (IR-1) could be removed. Now, in the insurance case, since 1 − ηl < 1 − ηh, the incentive compatibility constraint for the risk type is active and the individual rationality constraint for the safe type is active, i.e. the constraint set for (P-5) becomes

(1 − ηh)U˜ (y − ℓ + αah) + ηhU˜ (y − αnh) = (1 − ηh)U˜ (y − ℓ + αal ) + ηhU˜ (y − αnl )
(1 − ηl)U˜ (y − ℓ + αal ) + ηlU˜ (y − αnl ) = (1 − ηl)U˜ (y − ℓ) + ηlU˜ (y)

(IC-h) (IR-l)

Let us try to restate the problem in a way which allows us to characterize the solutions. Since we have assumed that U˜ is
strictly concave, increasing and twice differentiable, we can deﬁne W be its inverse, where W ′ > 0 and W ′′ > 0. Further,
deﬁne

U˜ai = U˜ (y − ℓ + αai ) and U˜ni = U˜ (y − αni ).

(32)

The transformed utility is

Π(U˜ah,U˜nh,U˜al ,U˜nl ) = p − ηhW (U˜nh) − (1 − ηh)W (U˜ah) + x − (1 − ηh)ℓ + (1 − p) − ηlW (U˜nl) − (1 − ηl)W (U˜al) + x − (1 − ηl)ℓ (33)

Then problem (P-5) becomes

max Π(U˜ah,U˜nh,U˜al,U˜nl )
{(U˜ai ,U˜ni )}i=h,l

(P-6)

s.t. (1 − ηh)U˜ah + ηhU˜nh = (1 − ηh)U˜al + ηhU˜nl

(1 − ηl)U˜al + ηlU˜nl = (1 − ηl)U˜ (y − ℓ) + ηlU˜ (y)

The Lagrangian of the optimization problem is
L(U˜ah,U˜nh,U˜al ,U˜nl , λ1, λ2) = Π(U˜ah,U˜nh,U˜al ,U˜nl) + λ1((1 − ηh)U˜ah + ηhU˜nh − (1 − ηh)U˜al − ηhU˜nl ) + λ2((1 − ηl)U˜al + ηlU˜nl − (1 − ηl)U˜ (y − ℓ)). (34)

Proposition 3: Given the probabilities 1 − η j, j = h, l that the consumer of type j will experience a privacy breach, if the insurer solves the optimization problem (P-6), then the

high-risk consumer will be fully insured and the low-risk

consumer will not be fully insured. Proof: We ﬁrst show that the risky type will be fully

insured. Taking the derivative of the Lagrangian with respect to U˜ah and U˜nh we get the following two equations:

0 = −p(1 − ηh)W ′(U˜ah) + λ1(1 − ηh)

(35)

0 = −pηhW ′(U˜nh) + λ1ηh

(36)

Solving for λ1 in the ﬁrst equation and plugging it into the second, we get U˜ah = U˜nh so that ℓ − αah = αnh, i.e. the
amount the high-risk type pays for insurance is equal to the

compensation minus the loss in the event of a privacy breach.

Thus, the high-risk type will be fully insured.

Now, we show that the low-risk type will not be fully

insured. Taking the derivative of the Lagrangian with respect to U˜al and U˜nl , we get

0 = −(1 − ηl)(1 − p)W ′(U˜al ) − λ1(1 − ηh) + λ2(1 − ηl) (37)

0 = −(1 − p)ηlW ′(U˜nl ) − λ1ηh + λ2ηl

(38)

From (35), we solved for λ1 = pW ′(U˜ah). By plugging in λ1 into (37), solving for λ2 and plugging both λ1 and λ2 into
(38), we get the following expression:

0

=W

′

(U˜

h

)

p

Å −ηh

+

ηl

1

−

ηh

ã

a

1 − ηl

+ ηl(1 − p)(W ′(U˜al) − W ′(U˜nl ))

(39)

Since ηl > ηh and W ′ is increasing by assumption, the above equation implies that

U˜nl − U˜al > 0

(40)

and hence the low-risk type does not fully insure. The above proposition tells us that in order to keep the highrisk type from masking as a low-risk type, the insurer must make the contract for the low-risk type unappealing to the high-risk type.
We remark that the analysis in this section can be applied to the case where the utility company is purchasing insurance as well. In particular, if the utlity company has not invested in a lot of security or tjeu are not following the best practices recommendations, e.g. NIST-IR 7628 [25], then they are engaging in risky behavior. The insurance company will not know a propri whether or not the utility company is high-risk type. Through the design of insurance contracts the insurance company can asses the utility’s type while offering contracts that maximize their own utilty.

VI. CONCLUSION
Utilizing our results on the fundamental limits of nonintrusive load monitoring, we provide a novel upper bound on the probability of a successful privacy breach. Under the privacy metering policy in which sampling rate variation is used, we study how the performance of direct load control degrades using the H∞ norm. This provided us with a metric for understanding how sampling rate affects the quality of direct load control. Using this metric along with the upper bound on the probability for a successful privacy breach, we design a screening mechanism for the problem of obtaining the consumer’s type when there is asymmetric information. Further, we design insurance contracts using the probability of successful privacy breach given that in the population of consumers there is both high-risk and low-risk consumers.
This work opens up a number of questions in the area of privacy metrics as well as customer segmentation and targeting. We considered only two-type models in both the design of contracts. We are currently looking at the theory for a continuum of types. The screening problem with a continuum of types results in a problem that resembles a partial differential equation constrained optimal control problem. We are developing numerical techniques to solve this problem. We also assumed that the utility company and private insurer knew the distribution of types in the population. We are currently developing algorithms for learning these probabilities using data-drive techniques. In addition, we considered that the utility would offer a contract solely based on privacy settings whereas in reality the contract would normally contain additional items such as maximum power consumption, rate, etc. Consumers in the population may value these goods differently. In this setting, the screening problem would be come multi-dimensional [26]. We are exploring this in the context of privacy-aware incentive design for behavior modiﬁcation.
REFERENCES
[1] E. L. Quinn, “Smart metering and privacy: Existing laws and competing policies,” Colorado Public Utilities Commission, Tech. Rep., 2009.
[2] M. Salehie, L. Pasquale, I. Omoronyia, and B. Nuseibeh, “Adaptive security and privacy in smart grids: A software engineering vision,” in International Workshop on Software Engineering for the Smart Grid, June 2012, pp. 46–49.
[3] R. Dong, L. Ratliff, H. Ohlsson, and S. S. Sastry, “Fundamental limits of nonintrusive load monitoring,” Proceedings of the 3rd ACM International Conference on High Conﬁdence Networked Systems, 2013.
[4] G. Hart, “Nonintrusive appliance load monitoring,” Proceedings of the IEEE, vol. 80, no. 12, pp. 1870–1891, 1992.
[5] J. Z. Kolter and M. J. Johnson, “Redd: A public data set for energy disaggregation research,” in Workshop on Data Mining Applications in Sustainability (SIGKDD), San Diego, CA, 2011.
[6] K. Anderson, A. Ocneanu, D. Benitez, D. Carlson, A. Rowe, and M. Berges, “BLUED: a fully labeled public dataset for Event-Based Non-Intrusive load monitoring research,” in Proceedings of the 2nd KDD Workshop on Data Mining Applications in Sustainability, Beijing, China, Aug. 2012.
[7] J. Z. Kolter and T. Jaakkola, “Approximate inference in additive factorial HMMs with application to energy disaggregation,” in Proceedings of the International Conference on Artiﬁcial Intelligence and Statistics, 2012, pp. 1472–1482.

[8] M. J. Johnson and A. S. Willsky, “Bayesian nonparametric hidden semi-Markov models,” The Journal of Machine Learning Research, vol. 14, no. 1, pp. 673–701, 2013.
[9] O. Parson, S. Ghosh, M. Weal, and A. Rogers, “Nonintrusive load monitoring using prior models of general appliance types,” in 26th AAAI Conference on Artiﬁcial Intelligence, 2012.
[10] J. Z. Kolter, S. Batra, and A. Y. Ng, “Energy disaggregation via discriminative sparse coding,” in Neural Information Processing Systems, 2010.
[11] R. Dong, L. J. Ratliff, H. Ohlsson, and S. Sastry, “Energy disaggregation via adaptive ﬁltering,” in Proceedings of the 51st Annual Allerton Conference on Communication, Control, and Computing, Oct 2013, pp. 173–180.
[12] C. Dwork, “Differential privacy,” in Proceedings of the International Colloquium on Automata, Languages and Programming. Springer, 2006, pp. 1–12.
[13] J. Le Ny and G. Pappas, “Differentially private ﬁltering,” IEEE Transactions on Automatic Control, vol. 59, no. 2, pp. 341–354, 2014.
[14] R. Shokri, G. Theodorakopoulos, J. Le Boudec, and J. Hubaux, “Quantifying location privacy,” in Security and Privacy (SP), 2011 IEEE Symposium on. IEEE, 2011, pp. 247–262.
[15] A. A. Ca´rdenas, S. Amin, G. Schwartz, R. Dong, and S. S. Sastry, “A game theory model for electricity theft detection and privacyaware control in AMI systems,” in Proceedings of the 50th Allerton Conference on Communication, Control, and Computing, 2012, pp. 1830–1837.
[16] R. Dong, A. A. Ca´rdenas, H. Ohlsson, and S. S. Sastry, “Privacy-aware sampling policies for advanced metering infrastructures,” ArXiV, 2014.
[17] D. Callaway and I. Hiskens, “Achieving controllability of electric loads,” Proceedings of the IEEE, vol. 99, no. 1, pp. 184–199, Jan 2011.
[18] J. Mathieu, S. Koch, and D. Callaway, “State estimation and control of electric loads to manage real-time energy imbalance,” IEEE Transactions on Power Systems, vol. 28, no. 1, pp. 430–440, 2013.
[19] P. Seiler and R. Sengupta, “An H-inﬁnity approach to networked control,” IEEE Transactions on Automatic Control, vol. 50, no. 3, pp. 356–364, March 2005.
[20] H. Ishii, “H-inﬁnity control with limited communication and message losses,” Systems & Control Letters, vol. 57, no. 4, pp. 322 – 331, 2008.
[21] T. A. Weber, “Optimal control theory with applications in economics,” MIT Press Books, vol. 1, 2011.
[22] M. Rothschile and J. Stiglitz, “Equilibrium in competitive insurance markets: An essay on the economics of imperfect information,” The Quarterly Journal of Economics, vol. 90, no. 4, pp. 629–6459, 1976.
[23] G. D. Jaynes, “Equilibria in monopolistically competitive insurance markets,” Journal of Economic Theory, vol. 19, no. 2, pp. 394 – 422, 1978.
[24] M. Mussa and S. Rosen, “Monopoly and product quality,” Journal of Economic Theory, vol. 18, no. 2, pp. 301 – 317, 1978.
[25] Smart Grid Interoperability Panel Cyber Security Working Group and others, “Introduction to NISTIR 7628 guidelines for smart grid cyber security,” Tech. Rep., 2010.
[26] S. Basov, “Multidimensional screening,” in Studies in Economic Theory. Springer, 2005, vol. 22.

