EIGEN: Event Inﬂuence GENeration using Pre-trained Language Models
Aman Madaan ∗ , Dheeraj Rajagopal ∗ , Yiming Yang, Abhilasha Ravichander, Eduard Hovy, Shrimai Prabhumoye
Language Technologies Institute, Carnegie Mellon University Pittsburgh, PA, USA
{amadaan,dheeraj,yiming,aravicha,ehovy,sprabhum}@cs.cmu.edu

arXiv:2010.11764v1 [cs.CL] 22 Oct 2020

Abstract
Reasoning about events and tracking their inﬂuences is fundamental to understanding processes. In this paper, we present EIGEN - a method to leverage pre-trained language models to generate event inﬂuences conditioned on a context, nature of their inﬂuence, and the distance in a reasoning chain. We also derive a new dataset for research and evaluation of methods for event inﬂuence generation. EIGEN outperforms strong baselines both in terms of automated evaluation metrics (by 10 ROUGE points) and human judgments on closeness to reference and relevance of generations. Furthermore, we show that the event inﬂuences generated by EIGEN improve the performance on a “what-if” Question Answering (WIQA) benchmark (over 3% F1), especially for questions that require background knowledge and multi-hop reasoning.
1 Introduction
Humans are adept at anticipating and reasoning about events and their causal effects (inﬂuences) on other events. Consider these questions - Would it rain more if we plant more trees?, What would help the water in boiling faster? - answering these questions requires the ability to comprehend the complex processes of plant growth and water boiling and the capacity to reason about how various events inﬂuence each other in these processes that are typically implicit in text. Hence, reasoning about events and inﬂuences remains a signiﬁcant challenge for machines. Understanding such events and tracing their inﬂuence chains is essential for end tasks like question answering (QA) (Tandon et al., 2019), process tracking (Dalvi et al., 2018), reasoning about qualitative relationships (Tafjord et al., 2019), and physical commonsense reasoning (Sap et al., 2019; Bisk et al., 2020).
∗ authors contributed equally to this work.

Previous approaches have studied event understanding in the context of event extraction (Chambers and Jurafsky, 2008; Yang et al., 2019; Wang et al., 2019), temporal event reasoning (Ning et al., 2018; Vashishtha et al., 2019), and QuestionAnswering (Tandon et al., 2019; Dalvi et al., 2018). However, these systems are primarily extractive — they reason about events already mentioned in the text, limiting their ability to be integrated to downstream tasks that require implicit reasoning about events. The task of generating novel event inﬂuence in unseen contexts is still an open challenge.
Meanwhile, promising evidence from recent work attests to the ability of pretrained language models (PLM) to encode a wide-range of knowledge from their pretraining corpus (Bosselut et al., 2019; Petroni et al., 2019; Davison et al., 2019), enabling their successful adaptation in downstream tasks (Yang et al., 2020; Kumar et al., 2020; Guan et al., 2020). Motivated by these successes, we investigate whether we can adapt PLM for the novel task of event inﬂuence generation and determine empirically whether the generated event inﬂuences lead to downstream performance gains. Such an exploration entails two major challenges: i) lack of large-scale stand-alone datasets to study event inﬂuences, and ii) a framework to leverage PLM to adapt them for event inﬂuence generation.
In this work, we address these challenges by ﬁrst deriving a large corpus based on WIQA (Tandon et al., 2019) dataset that can be used for the generation of event inﬂuences conditioned on context, relationship between the events, and the distance between them in a reasoning chain. Next, we propose our framework, EIGEN, that takes a context and an event, and generates its inﬂuences both in forward and backward directions. An example use of our framework is shown in Figure 1. In the ﬁgure, nodes represent the event inﬂuences and the

Figure 1: An overview of our methodology. The procedural text describes the process of photosynthesis. For this example, we generate the inﬂuence graph for the event more sunlight. The inﬂuence graph is generated for the relation types - helps, hurt by, helped by and hops = {1, 2}. A sample output inﬂuence graph shows the generated events - bright skies, cloudy skies, plants trap sunlight, and plants grow taller

edges represent the nature of the inﬂuence (relation) between them. These relations can either be positive (when one event helps the occurrence of another) or negative (when one event hurts the occurrence of another). The distance between any given pair of nodes (in terms of number of edges traversed) is denoted by hop.
EIGEN ﬁne-tunes a PLM to generate novel event inﬂuences for unseen contexts using masked language modeling. We show empirically that our framework generates high quality inﬂuences for an event, both in terms of automated metrics (by ∼ 10 ROUGE) and human metrics — relevance and proximity to the reference text. Together, the overall framework can be seamlessly integrated into any downstream task. In one such instance, we show how the event inﬂuences generated from EIGEN can be easily augmented to a downstream QA task and improve its performance without any need for modifying the underlying model architecture. In summary, our contributions are:
1. We propose the task of event inﬂuence generation and derive a large-scale dataset for the same.
2. We propose EIGEN, a framework to generate targeted inﬂuence nodes for an event. Our experiments show that EIGEN outperforms strong baselines in both automated and human evaluation.
3. We also validate our approach by augment-

ing generated inﬂuences to a downstream QA dataset, improving over the state of the art by 3% in overall accuracy, and by 8% on the subset of questions that require implicit eventinﬂuence reasoning 1.
2 Related Work
Event Inﬂuences: There has been immense interest in understanding event chains in stories and news corpora in both unsupervised (Chambers and Jurafsky, 2008) and supervised (Rudinger et al., 2015; Liu et al., 2018) settings. Such approaches aim to extract the event chains that are explicitly mentioned in the input text and are unyielding towards implicit event reasoning. Events and their inﬂuences have also been studied in restricted domains such as cooking recipes (Kiddon et al., 2016; Bosselut et al., 2018), and in general procedural text (Dalvi et al., 2018) as a classiﬁcation task over a restricted set of events. Tandon et al. (2019) introduce the WIQA dataset, which relaxes this restriction by collecting event perturbations over general procedures, where the goal is to predict the inﬂuence between two given events (positive, negative or no-effect), while also providing explicit annotations for capturing the inﬂuences over multiple reasoning hops. Albeit being resourceful, restricted task formulation limits use of these datasets to adapt for event inﬂuence generation task. To
1Code and data available at https://github.com/ dheerajrajagopal/EIGEN.

overcome this challenge, we derive a large-scale event-inﬂuence dataset from WIQA (discussed in Section §3).
Language Models for Knowledge Generation: The use of large scale neural networks to generate knowledge has been studied under various task settings. Sap et al. (2019) use LSTM-based encoder-decoder architectures to generate generalpurpose social commonsense knowledge. These methods were then improved by replacing LSTMs with large-scale pre-trained transformer language models. Bosselut et al. (2019) proposed COMET, which ﬁne-tunes GPT (Radford et al., 2018) on ATOMIC (Sap et al., 2019) and conceptnet (Speer et al., 2017) for knowledge-completion task. An extension to this work by incorporating structural and semantic constraints was proposed by Malaviya et al. (2019). Similar to Bosselut et al. (2019), we leverage pre-trained language models for the conditional generation of events. However, unlike COMET, we i) condition our generations on a larger context and hop-information, and ii) provide a framework for recursively generating event inﬂuence graphs for a given process and an event. Additionally, unlike COMET, a dataset that can be used for our task is not readily available, and hence we outline a method for adapting existing datasets for our task as an additional contribution.
3 Event Inﬂuence Generation
EIGEN is a framework for generating ﬁne-grained event inﬂuences for a given context, conditioned on the relation and the hop information. EIGEN leverages a pretrained language model to learn to generate novel event inﬂuences over multiple hops. In this section, we present (i) our task formulation (section §3.1), (ii) the dataset collection process (section §3.2) and (iii) the learning procedure (§3.3).
3.1 Task
We formalize the event inﬂuence generation task as follows: Given an input tuple (P, ns, r, h), where (i) P is a procedural passage P that describes the steps in a process, (ii) ns is an event in P for which the inﬂuences are to be generated, (iii) r is an inﬂuence relation that describes the nature of the inﬂuence and, (iv) h is the hop length (distance) between the event ns and its inﬂuence in a reasoning chain,

our task is to generate a target event nt such that ns −→r nt at hop h in the context of P . We focus on 4 broad classes of event inﬂuence relations r between events ns and nt: (1) helps: ns positively inﬂuences nt (ns −+→ nt) (2) hurts: ns negatively inﬂuences nt (ns −−→ nt) (3) helped-by: ns is positively inﬂuenced by nt (ns ←+− nt), and (4) hurt-by: ns is negatively inﬂuenced by nt (ns ←−− nt).
We show an example of our task in Figure 1, where we generate the inﬂuences for the event more sunlight in the context of photosynthesis. In this example, for the relation hurt-by, and a hop-length h = 1, we aim to generate the text cloudy skies (nt). Similarly, given h = 2 and a relation helps, the system generates the target event plants grow taller. Note that the generation of a node refers to the generation of text tokens describing the node.
3.2 Dataset
Lack of datasets remains a challenge for studying the task of event inﬂuence generation. To address this challenge, we adapt WIQA (Tandon et al., 2019) to generate a large-scale event inﬂuence generation dataset. WIQA consists of a set of procedural passages, each accompanied by a humancurated inﬂuence graph. The inﬂuence graph captures the interactions between the events and their inﬂuences and external perturbations in the context of the process described by the passage. Although these graphs can be subjective, WIQA has high inter-annotator agreement2, motivating our choice to leverage these graphs.
We decompose the inﬂuence graphs to create our generation dataset. An inﬂuence graph for a passage P is denoted by by G = (V, E), where V denotes the set of vertices and E the set of edges. The nodes n ∈ V represent the events, and the edges represent the relationship (helps or hurts) between them. Each edge ns −→r nt ∈ G contributes a sample for our training data, composed of tuples of the form xi = (P, ns, r, h) and yi = nt.
For creating multi-hop training samples for our task, we exploit the transitive compositionality of the inﬂuence relations. For example, if (na −+→ nb) ∧ (nb −+→ nc) ≡ (na −+→ nc). Similarly, (na −+→ nb) ∧ (nb −−→ nc) ≡ (na −−→ nc). In
20.6 Krippendorff’s alpha

summary, ns −−→ nt if the path from ns to nt has an odd number of hurts edges, and ns −+→ nt otherwise. For example, cloudy skies −−→ plants grow taller in Figure 1.
We also augment the dataset with inverse inﬂu-
ences, where our goal is to capture event inﬂuence in the reverse direction. For example, if na −+→ nb, then nb ←+− na. After augmentation, our dataset captures diverse inﬂuences with respect to the re-
lations and hops as described in section §3.1. A
detailed dataset statistic is shown in Table 1.

Split Relation Type 1-Hop 2-Hop 3-Hop Total

train helps train hurts train is helped by train is hurt by

8723 13081
8723 13081

13085 13088 13085 13088

5815 5815 5815 5815

119.2k

test helps test hurts test is helped by test is hurt by

1382 2073 1382 2073

2075 2075 2075 2075

922 922 18.8k 922 922

dev helps dev hurts dev is helped by dev is hurt by

2547 3824 1697

3824 2547

3823 3824

1697 1697

34.8k

3824 3823 1697

Table 1: Breakdown of number of samples by relation type, distance, and split. We maintain the same traindev-test split as the WIQA dataset.

Although our dataset uses relationship types from Table 1, our framework makes no relationspeciﬁc assumptions and is generally applicable to a broader range of relationships.
3.3 Learning to Generate Inﬂuences
As discussed in section §3.1, the training data consist of samples (xi, yi), where xi = (Pi, ns, ri, hi) and yi is the corresponding target node nt. In our dataset, each procedural passage is used to create multiple training examples from variations in ns, ri, hi. For instance, Figure 1 shows four such training samples, where one example is as follows: xi = (Pi = procedural text describing photosynthesis , ns = more sunlight , ri = helps , hi = 1-hop ), and yi = plants trap sunlight.
EIGEN uses a language model to estimate the probability of generating an end node nt for an input xi. We ﬁrst transform the 4-tuple xi into a single query sequence of tokens by concatenating its components i.e. we set xi = Pi ns ri hi, where stands for string concatenation. Let the

sequence of tokens representing the target event be

yi =

y

1 i

,

yi2

,

.

.

.

,

y

M i

,

where

N

and

M

are

the

lengths of the query and the target event sequences.

We model the conditional probability pθ(yi | xi)

as a series of conditional next token distributions

parameterized by θ:

M
pθ(yi | xi) = pθ(yik | xi, yi1, .., yik−1)
k=1

EIGEN parameterizes pθ using the GPT-2 (Rad-

ford et al., 2019) pretrained language model. GPT-

2 is based on the popular transformer architec-

ture (Vaswani et al., 2017), which consists of a

series of transformer blocks. Each transformer

block consists of two operations: a masked ver-

sion of the multi-headed self-attention (Vaswani

et al., 2017) followed by a feed-forward network

(FFN). Each of these operations is surrounded by a

residual connection (He et al., 2016), and followed

by a layer normalization (Ba et al., 2016) operation.

The auto-regressive factorization of the language

model pθ allows us to efﬁciently generate target

event inﬂuences for a given test input xj. Each to-

ken in yj is generated by sampling yj1 ∼ pθ(y | xj).

The next token is then drawn by sampling yj2 ∼

pθ(u | xj, yj1). The process is repeated until a spec-

iﬁed end-symbol token is drawn at the Kth step.

The tokens

yj1

,

yj2

,

.

.

.

,

y

K j

−

1

are then returned as

the generated target event inﬂuence.

4 Experiments
Setup: We use the dataset described in section §3.2 for training the model. The dataset statistics by relation type and hop information are shown in Table 1. EIGEN is based on the GPT-2 implementation by Wolf et al. (2019).3, and uses nucleus sampling (Holtzman et al., 2019) for decoding output sequences over the ﬁne-tuned language model. As discussed in ( §3.3), we concatenate the 4-tuple xi = (Pi, ns, ri, hi) in a single sequence of tokens. xi was concatenated using the template: “P what does ns ri at hi?”. All of our experiments were done on a single Nvidia GeForce RTX 2080 Ti. The models were ﬁne-tuned for 5 epochs for all the variants.

4.1 Baselines
LSTM Seq-to-Seq: We train an LSTM (Hochreiter and Schmidhuber, 1997) based sequence to sequence model (Bahdanau et al., 2015) which uses
3Details of hyper-parameters in the Appendix A.2

Model
GPT-2 w/o Fine-tuning* LSTM Seq-to-Seq
COMET EIGEN

BLEU-1
7.66 17.65 20.63 28.97

BLEU-2
3.05 7.51 10.01 16.23

BLEU-3
1.56 5.16 7.12 11.69

BLEU-4
0.91 4.26 5.93 9.74

METEOR
4.79 7.69 8.82 12.85

ROUGE
7.85 18.71 20.93 29.65

Polarity
8.25 70.22 71.97 77.24

Table 2: Generation Quality for EIGEN and the baseline. BLEU-n refers to geometric average of BLEU scores calculated upto n-grams. *- indicates that this baseline model is not ﬁne-tuned on our dataset.

global attention described in (Luong et al., 2015). We use pre-trained Glove (Pennington et al., 2014) to initialize the word embedding.4
GPT-2 w/o Fine-tuning: The pretrained GPT2 (Radford et al., 2019) without any additional ﬁne-tuning serves as another baseline. The goal of this baseline is to understand the extent to which GPT-2 without ﬁne-tuning could encode event inﬂuence information.5
COMET: COMET (Bosselut et al., 2019) aims to perform knowledge base completion for commonsense knowledge bases by employing pretrained language models. Unlike EIGEN, COMET does not use any context or hop information. Although COMET’s architecture was based on GPT (Radford et al., 2018), our implementation adapts COMET to use GPT-2 for a fair comparison, and also supplement each event input with hop-information. More concretely, we set xi = (ns, ri, hi), with the goal of generating yi = nt.
4.2 Automated Evaluation
For evaluating the predicted event inﬂuences, we use the standard evaluation metrics BLEU (Papineni et al., 2002), METEOR (Denkowski and Lavie, 2011), and ROUGE (Lin, 2004) 6. To complement the above mentioned metrics, we also use polarity, which captures the direction of change captured by an inﬂuence (increasing, decreasing, neutral). For example, an event inﬂuence “more sunlight” has the polarity “increasing”, whereas an event “less rain” has the polarity “decreasing”. We calculate the percentage of generated event inﬂuences that have the same polarity as the reference. For example, if both the reference event and the predicted target event are about an ‘increase,’ then we count their polarity to be the same. Otherwise, we count
4https://github.com/OpenNMT/OpenNMT-py 5GPT-2 implementation from Wolf et al. (2019) 6We use Sharma et al. (2017) for calculating these metrics. https://github.com/Maluuba/nlg-eval

their polarity to be different. We used a small set of hand-curated keywords to detect polarity 7.
Table 2 shows that EIGEN outperforms the baselines on all metrics. Furthermore, the results emphasize that the pre-trained models can’t generate event inﬂuences without being ﬁne-tuned on the task. EIGEN outperforms COMET in all the metrics by a considerable margin, (by about 8 ROUGE points), reinforcing the importance of generating knowledge that is grounded in context.
Table 3 breaks down the performance of EIGEN by relation type and the number of hop between the source and the target nodes. From Table 3, we observe that the best performance is obtained on nodes generated at 1-hop with helps relation. The 1-hop nodes generated with a hurts relation perform worse, indicating that generating negative inﬂuences is a harder task. Table 3 also highlights that the 3-hop generations score higher than the 2-hop relations for help and hurts relations. On further inspection, we found that this was an artifact from the human-curated inﬂuence graphs. Each inﬂuence graph had a maximum hop length of 3, and the end nodes are always of the form “more X” or “less X”, where X is a concept mentioned in the passage. Due to this templated nature of leaf nodes in the inﬂuence graph, the task becomes relatively less challenging compared to 1-hop and 2-hop inﬂuences.
4.3 Human Evaluation
In addition to automated evaluation, we also compare EIGEN with COMET for assessing the generation quality using human judgments. Three human judges annotated 120 unique samples for relevance and reference, described next. We also compared the output of the two systems for ﬂuency and found that both the systems produce ﬂuent outputs. This indicates that pretrained language models are effective in generative grammatically correct out-
7This list of 22 words is included in the Appendix.

Relation
Helps Helps Helps Hurts Hurts Hurts

Hop
1-hop 2-hop 3-hop 1-hop 2-hop 3-hop

BLEU-1
33.32 25.99 32.25 28.67 25.03 32.72

BLEU-2
20.54 13.77 17.82 16.79 13.15 18.08

BLEU-3
15.47 9.20
14.88 11.71
8.63 15.03

BLEU-4
13.16 7.44
13.59 9.46 6.74
13.65

METEOR
14.88 11.78 14.00 13.04 11.41 14.46

ROUGE
34.19 26.71 33.55 29.37 26.09 34.19

Polarity
82.56 73.88 80.04 77.23 74.12 81.02

Table 3: Generation Quality of EIGEN by Relation Type and Node Distance

put, even though the utility of the output may vary greatly.

Task
Relevance Reference

EIGEN
46.11 31.94

No Preference
30.83 56.39

COMET
23.06 11.67

Table 4: Results of human evaluation. The numbers show the percentage(%) of times a particular option was selected for each metric.

Relevance: The annotators are provided with the input of a procedural text, the source event, and the relational questions. The outputs generated by COMET and EIGEN are also provided in random order. The annotators were asked, “Which system (A or B) is more accurate relative to the background information given in the context?” They could also pick option C (no preference).
Comparison with true event (reference): We measure how accurately each system-generated event reﬂects the reference (true) event. Here, the annotators saw only the reference sentence and the outputs of two systems (A and B) in a randomized order. We asked the annotators, “Which system’s output is closest in meaning to the reference?” The annotators could pick the options A, B, or C (no preference).
For relevance and reference comparison tasks (Table 4), we present the percentage of count of human judges for each of the three categories. The table illustrates that EIGEN performs better than COMET on both the metrics. Particularly, EIGEN not only performs better than COMET but also much better than the “No Preference” option in the relevance metric. This means that EIGEN generates target events that logically follow the passage and source events. We note that the automated metrics may not capture the relevance and correctness of

the generated target events. The reference and relevance task scores together show that EIGEN does not generate target events that are exactly similar to the reference target events, but they are correct in the context of the passage and the source event. This can happen due to linguistic variation in the generation, as well as the ability of the source event to inﬂuence multiple target events in the context of the passage. We study this in more detail in the error analysis presented below.
4.4 Error Analysis
Table 5 shows the error analysis on 100 random samples from the validation set. We found that for about 26% of samples, the generated event inﬂuence had an exact match with the reference, and about 30% of the samples had no overlap with the reference (category Wrong in Table 5). We found that for 20% of the cases, the generated target event was correct but was expressed differently compared to the reference text (Linguistic Variability) class in Table 5). Furthermore, we observed that in 17% of cases, the generated target event was not the same as the reference target event, but it was relevant to the passage and the question, as shown in the Related Event category in Table 5. In 5% of the samples (Polarity), the model generates events with opposite polarity compared to the reference. A small fraction (2%) of samples had incorrect gold annotations.
4.5 Ablations and Discussion
Table 6 shows the ablation results by removing each of paragraph, reverse edges and hop information from the 4-tuple xi = (Pi, ns, ri, hi) ( §3.1). These ablations are performed to get an insight into the contribution of each component in the input xi to the generation task. In line with the expectation, the model with access to all the input components performs the best on almost all of our evaluation metrics. We also observe that the context

Error Class Description

% Question

Reference Predicted

Polarity

The predicted polarity was wrong 5% but event was correct

What does ‘oil ﬁelds over-used’ help at 2-hop ?

there is not oil reﬁned

more oil is reﬁned

Linguistic The output was a

20% What does ‘fewer rabbits will

more

Variability linguistic variant of the reference

become pregnant’ hurts at 1-hop ? rabbits

more babies

Related Event

The output was related but different reference expected

17% What does you inhale more air from the outside hurts at 1 hop ?

there will be less oxygen in your blood

you develop more blood clo-ts in your veins

Wrong

The output was was completely unrelated

30% What does ‘less nutrients for plants’ hurt at 2-hop ?

more plants

more wine being produced

Erroneous Reference

The gold annotations were erroneous

2% What does ‘less rabbit rabbit mating’ hurt at 1-hop?

less rabbits

more babies

Table 5: Examples of error categories. Error analysis is only shown for the incorrect outputs.

information was the best indicator of model performance gains. Our ablation results re-emphasizes that grounding event inﬂuence in the context of the passage is crucial for the generation of target events.
5 Downstream QA
In this section, we examine the utility of EIGENgenerated graphs in a downstream question answering task on the WIQA benchmark.
5.1 The QA Task
WIQA (Tandon et al., 2019) is a dataset for procedural understanding, that comprises of “what-if” questions to reason about the effects of one event perturbation on another in the context of a process. Speciﬁcally, each question in WIQA consists of a context paragraph P and two input events nc and ne. The task is to predict how nc affects ne, where the result is one of: {helps, hurts, and no effect}.
5.2 Using EIGEN to augment QA data
We use EIGEN to augment the event inﬂuences in each sample in the QA task as additional context. Concretely, for the given context P , and the event inﬂuences nc and ne, we generate forward inﬂuences for nc and reverse inﬂuences for ne using EIGEN. This scheme is intended to generate reasoning chains that connect nc to ne, even if ne is not an immediate consequence of nc. Concretely, we query EIGEN with four inputs: (P, nc, helps, 1-hop), (P, nc, hurts, 1-hop), and (P, ne, helped by, 1-hop), (P, ne, hurt by, 1-hop). The generated event inﬂuences are then concatenated to form a ﬂattened list of sentences xg.
Following Tandon et al. (2019), we encode the input sequence P nc ne using the BERT encoder

E (Devlin et al., 2019), and use the [CLS] token representation (hˆi) as our sequence representation. We then use the same encoder E to encode the generated inﬂuences xg nc ne, and use the [CLS] token to get a representation for augmented inﬂuences (hˆa). Following the encoded inputs, we compute the ﬁnal loss as follows:
li = MLP1(hˆi) la = MLP2(hˆa)
L = α × Li + β × La
where li, la represent the logits from hˆi and hˆa respectively, and Li and La are their corresponding cross-entropy losses. α and β are hyperparameters that decide the contribution of the generated inﬂuence graphs and the procedural text to the loss. For our experiments, we set α = 1 and β = 0.9.
5.3 QA Evaluation Results
Tables 7, 8, and 9 show the results from our experiments on the WIQA QA dataset. BERT refers to the results from the original BERT based implementation by Tandon et al. (2019), and BERT + EIGEN are the results obtained by augmenting the QA dataset with the inﬂuences generated by EIGEN as described above. Further, Tables 8 and 9 show the accuracy of our method vs. the vanilla BERT model by question type and number of hops between nc and ne. We observe from Table 8 that augmenting the context with generated inﬂuences from EIGEN leads to considerable gains over BERT based model, with the largest improvement seen in 3-hop questions. The strong performance on the 3-hop question supports our hypothesis that generated inﬂuences might be able to connect two event inﬂuences that are farther apart in the reasoning

Para Rev Hop BLEU-1 BLEU-2 BLEU-3 BLEU-4 METEOR ROUGE Polarity

           

20.20 19.96 20.63 26.19 27.51 26.05 28.97

9.48 9.19 10.01 14.08 15.64 14.23 16.23

6.63 6.49 7.12 10.06 11.68 10.10 11.69

5.46 5.41 5.93 8.52 10.02 8.45 9.74

8.83 8.58 8.28 11.85 12.42 11.87 12.85

20.49 20.39 20.93 26.78 27.81 27.10 29.65

73.75 72.80 71.97 74.67 76.76 75.68 77.24

Table 6: Ablation experiments to understand the contribution of each of paragraph, reverse edges and hop information to the generation of the target event.

Model
BERT + EIGEN
BERT

Accuracy
76.92 73.80

Table 7: QA Accuracy

Query Type
1-hop 2-hop 3-hop

BERT + EIGEN
78.78 63.49 68.28

BERT
71.60 62.50 59.50

Table 8: QA accuracy by number of hops

chain. We also show in Table 9 that augmenting with EIGEN improves performance on the difﬁcult exogenous category of questions, which requires background knowledge. In summary, the evaluation highlights the value of EIGEN as a framework for improving performance on downstream tasks that require event-based background reasoning and serves as an evaluation of the ability of EIGEN to generate targeted inﬂuences.

6 Conclusion
We deﬁne the problem of event-inﬂuence reasoning as a generation task conditioned on context, particularly exploring the efﬁcacy of large scale pre-trained language models for the task. We use human-curated event inﬂuence graphs to train a model to generate targeted event inﬂuences grounded in a context. Our experiments with ablations and error analysis provide insights into how to effectively adapt pretrained language models for event inﬂuence generation and opens up exciting avenues for further research. Our method outperforms strong baselines on both automated and human evaluations. Furthermore, generated inﬂuences improve performance on the benchmark

Question Type
Exogenous In-para Out-of-para

BERT + EIGEN
64.04 73.58 90.84

BERT
56.13 79.68 89.38

Table 9: QA accuracy by question type

WIQA QA task without architectural changes to the model. Future work would extend the generalizability of this method to understand more complex and volatile event inﬂuences, such as events in news articles and stock markets.

Acknowledgments
This material is based on research sponsored in part by the Air Force Research Laboratory under agreement number FA8750-19-2-0200, and in part by grants from National Science Foundation Secure and Trustworthy Computing program (CNS1330596, CNS-15-13957, CNS-1801316, CNS1914486). The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the ofﬁcial policies or endorsements, either expressed or implied, of the Air Force Research Laboratory, the NSF, or the U.S. Government.

References
Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. 2016. Layer normalization. arXiv preprint arXiv:1607.06450.
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural machine translation by jointly learning to align and translate. In 3rd Inter-

national Conference on Learning Representations, ICLR 2015.
Yonatan Bisk, Rowan Zellers, Ronan LeBras, Jianfeng Gao, and Yejin Choi. 2020. Piqa: Reasoning about physical commonsense in natural language. In AAAI, pages 7432–7439.
Antoine Bosselut, Corin Ennis, Omer Levy, Ari Holtzman, Dieter Fox, and Yejin Choi. 2018. Simulating action dynamics with neural process networks. In International Conference on Learning Representations.
Antoine Bosselut, Hannah Rashkin, Maarten Sap, Chaitanya Malaviya, Asli C¸ elikyilmaz, and Yejin Choi. 2019. Comet: Commonsense transformers for automatic knowledge graph construction. In ACL.
Nathanael Chambers and Dan Jurafsky. 2008. Unsupervised learning of narrative event chains. In Proceedings of ACL-08: HLT, pages 789–797, Columbus, Ohio. Association for Computational Linguistics.
Bhavana Dalvi, Lifu Huang, Niket Tandon, Wen-tau Yih, and Peter Clark. 2018. Tracking state changes in procedural text: a challenge dataset and models for process paragraph comprehension. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1595–1604, New Orleans, Louisiana. Association for Computational Linguistics.
Joe Davison, Joshua Feldman, and Alexander Rush. 2019. Commonsense knowledge mining from pretrained models. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLPIJCNLP), pages 1173–1178, Hong Kong, China. Association for Computational Linguistics.
Michael Denkowski and Alon Lavie. 2011. Meteor 1.3: Automatic metric for reliable optimization and evaluation of machine translation systems. In Proceedings of the sixth workshop on statistical machine translation, pages 85–91. Association for Computational Linguistics.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.
Jian Guan, Fei Huang, Zhihao Zhao, Xiaoyan Zhu, and Minlie Huang. 2020. A knowledge-enhanced pretraining model for commonsense story generation. Transactions of the Association for Computational Linguistics, 8:93–108.

Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770– 778.
Sepp Hochreiter and Ju¨rgen Schmidhuber. 1997. Long short-term memory. Neural computation, 9(8):1735–1780.
Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2019. The curious case of neural text degeneration. arXiv preprint arXiv:1904.09751.
Chloe´ Kiddon, Luke Zettlemoyer, and Yejin Choi. 2016. Globally coherent text generation with neural checklist models. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 329–339.
Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980.
Varun Kumar, Ashutosh Choudhary, and Eunah Cho. 2020. Data augmentation using pre-trained transformer models. arXiv preprint arXiv:2003.02245.
Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. In Text summarization branches out, pages 74–81.
Fei Liu, Trevor Cohn, and Timothy Baldwin. 2018. Narrative modeling with memory chains and semantic supervision. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 278– 284, Melbourne, Australia. Association for Computational Linguistics.
Minh-Thang Luong, Hieu Pham, and Christopher D Manning. 2015. Effective approaches to attentionbased neural machine translation. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1412–1421.
Chaitanya Malaviya, Chandra Bhagavatula, Antoine Bosselut, and Yejin Choi. 2019. Exploiting structural and semantic context for commonsense knowledge base completion. arXiv preprint arXiv:1910.02915.
Qiang Ning, Zhili Feng, Hao Wu, and Dan Roth. 2018. Joint reasoning for temporal and causal relations. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2278–2288.
Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on association for computational linguistics, pages 311–318. Association for Computational Linguistics.

Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. Glove: Global vectors for word representation. In Empirical Methods in Natural Language Processing (EMNLP), pages 1532–1543.
Fabio Petroni, Tim Rockta¨schel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. 2019. Language models as knowledge bases? In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLPIJCNLP), pages 2463–2473.
Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018. Improving language understanding by generative pre-training. URL https://s3-us-west-2. amazonaws. com/openaiassets/researchcovers/languageunsupervised/language understanding paper. pdf.
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners. OpenAI Blog, 1(8):9.

text. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 6078–6087.

Siddharth Vashishtha, Benjamin Van Durme, and

Aaron Steven White. 2019.

Fine-grained

temporal relation extraction. arXiv preprint

arXiv:1902.01390.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems, pages 5998–6008.

Rui Wang, Deyu Zhou, and Yulan He. 2019. Open event extraction from online text using a generative adversarial network. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 282–291, Hong Kong, China. Association for Computational Linguistics.

Rachel Rudinger, Pushpendre Rastogi, Francis Ferraro, and Benjamin Van Durme. 2015. Script induction as language modeling. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1681–1686.

Thomas Wolf, L Debut, V Sanh, J Chaumond, C Delangue, A Moi, P Cistac, T Rault, R Louf, M Funtowicz, et al. 2019. Huggingface’s transformers: State-of-the-art natural language processing. ArXiv, abs/1910.03771.

Maarten Sap, Ronan Le Bras, Emily Allaway, Chandra Bhagavatula, Nicholas Lourie, Hannah Rashkin, Brendan Roof, Noah A Smith, and Yejin Choi. 2019. Atomic: An atlas of machine commonsense for ifthen reasoning. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 33, pages 3027–3035.
Shikhar Sharma, Layla El Asri, Hannes Schulz, and Jeremie Zumer. 2017. Relevance of unsupervised metrics in task-oriented dialogue for evaluating natural language generation. CoRR, abs/1706.09799.

Sen Yang, Da wei Feng, Linbo Qiao, Zhigang Kan, and D. Li. 2019. Exploring pre-trained language models for event extraction and generation. In ACL.
Yiben Yang, Chaitanya Malaviya, Jared Fernandez, Swabha Swayamdipta, Ronan Le Bras, Ji-Ping Wang, Chandra Bhagavatula, Yejin Choi, and Doug Downey. 2020. G-daug: Generative data augmentation for commonsense reasoning. arXiv preprint arXiv:2004.11546.

Robyn Speer, Joshua Chin, and Catherine Havasi. 2017. Conceptnet 5.5: An open multilingual graph of general knowledge. In Thirty-First AAAI Conference on Artiﬁcial Intelligence.

Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: a simple way to prevent neural networks from overﬁtting. The journal of machine learning research, 15(1):1929–1958.

Oyvind Tafjord, Peter Clark, Matt Gardner, Wen-tau Yih, and Ashish Sabharwal. 2019. Quarel: A dataset and models for answering questions about qualitative relationships. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 33, pages 7063–7071.

Niket Tandon, Bhavana Dalvi, Keisuke Sakaguchi, Peter Clark, and Antoine Bosselut. 2019. Wiqa: A dataset for “what if...” reasoning over procedural

A Appendix
A.1 Polarity Words Increasing words helps, more, higher, increase, increases, stronger, faster, greater, longer, larger, helping
Decreasing words hurts, less, lower, decrease, decreases, weaker, slower, smaller, hurting, softer, fewer
A.2 Hyperparameters Seq-to-Seq: We use 2 layers of LSTM encoder and decoder with a hidden size of 500, word embedding size of 300. The encoder is bidirectional. We use Glove embedding of 300 dimensions.
EIGEN: EIGEN ﬁne-tunes GPT-2 (Radford et al., 2019), allowing us to re-use the same hyperparameters as with small adjustments in the recommended range. We use the medium (355M) variant of GPT-2 for our experiments with 24layer, 1024-hidden, 16-heads, 345M parameters (https://huggingface.co/transformers/ pretrained_models.html). We use the weights released by Radford et al. (2019). We use Adam (Kingma and Ba, 2014) for optimization with a learning rate of 5e−05. All the dropouts (Srivastava et al., 2014) were set to 0.1 We found the best hyperparameter settings by searching the space using the following hyperparameters.
1. weight decay = { 0.1, 0.01, 0.05 }
2. embedding dropout = {0.1, 0.2, 0.3 }
3. learning rate = {1e-05, 2e-05, 5e-05, 1e-06}

