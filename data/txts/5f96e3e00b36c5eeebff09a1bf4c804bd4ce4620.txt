Quickest Bayesian and non-Bayesian detection of false data injection attack in remote state estimation

arXiv:2010.15785v3 [eess.SY] 16 Jan 2022

Akanshu Gupta Abhinava Sikdar Arpan Chattopadhyay

Abstract—In this paper, quickest detection of false data injection attack on remote state estimation is considered. A set of N sensors make noisy linear observations of a discrete-time linear process with Gaussian noise, and report the observations to a remote estimator. The challenge is the presence of a few potentially malicious sensors which can start strategically manipulating their observations at a random time in order to skew the estimates. The quickest attack detection problem for a known linear attack scheme in the Bayesian setting with a Geometric prior on the attack initiation instant is posed as a constrained Markov decision process (MDP), in order to minimize the expected detection delay subject to a false alarm constraint, with the state involving the probability belief at the estimator that the system is under attack. State transition probabilities are derived in terms of system parameters, and the structure of the optimal policy is derived analytically. It turns out that the optimal policy amounts to checking whether the probability belief exceeds a threshold. Next, generalized CUSUM based attack detection algorithm is proposed for the non-Bayesian setting where the attacker chooses the attack initiation instant in a particularly adversarial manner. It turns out that computing the statistic for the generalised CUSUM test in this setting relies on the same techniques developed to compute the state transition probabilities of the MDP. Numerical results demonstrate signiﬁcant performance gain under the proposed algorithms against competing algorithms.
Index Terms—Secure estimation, CPS security, false data injection attack, quickest detection, Markov decision process.
I. INTRODUCTION
Networked estimation and control of physical processes and systems are indispensable components of cyber-physical systems (CPS) that involve integration of sensing, computation, communication and control to realize the ultimate combining of the physical systems and the cyber world. The applications of CPS are many-fold: intelligent transportation systems, smart grids, networked monitoring and control of industrial processes, environmental monitoring, disaster management, etc. These applications heavily depend on reliable estimation of a physical process or system via sensor observations collected over a wireless network [2]. However, malicious attacks on these sensors pose a major security threat to CPS. One such common attack is a denial-of-service (DoS) attack where the
Akanshu Gupta is currently with Microsoft India. Work done while at Indian Institute of Technology, Delhi. Email: akanshu3299@gmail.com
Abhinava Sikdar is with the Department of Computer Science, Columbia University. Email: as6413@columbia.edu
Arpan Chattopadhyay is with the Department of Electrical Engineering and the Bharti School of Telecom Technology and Management, IIT Delhi. Email: arpanc@ee.iitd.ac.in
This work was supported by the faculty seed grant and professional development allowance of Arpan Chattopadhyay at IIT Delhi.
The conference precursor [1] of this work was accepted in IEEE International Symposium on Information Theory (ISIT), 2021.

Fig. 1. False data injection attack in centralized remote estimation.
attacker attempts to block system resources (e.g., wireless jamming attack [3]). Contrary to DoS, we focus on false data injection (FDI) attacks which is a speciﬁc class of integrity or deception attacks, where the sensor observations are modiﬁed before they are sent to the remote estimator [4], [5]. The attacker can modify the information by breaking the cryptography of the packets or by physically manipulating the sensors (e.g., placing a cooler near a temperature sensor).
Recently, the problem of FDI attack and its countermeasures has received signiﬁcant attention [6]. The literature in this area can be classiﬁed into two categories: (i) FDI on centralized systems, and (ii) FDI on distributed systems. In a distributed system, various entities such as sensors, estimators, controllers and actuators are connected via a multi-hop wireless network, and FDI on one such component propagates to other components over time via the network.
There has been a vast literature on FDI in centralized systems, particularly in the remote estimation setting. Such works include several attempts to characterize and design attack schemes: undetectable linear deception attack [7] in single sensor context, and also conditions for undetectable FDI attack [8]. The attack strategy to steer the control of CPS to a desired value under attack detection constraint is provided in [9]. Literature on attack detection considered a number of models and approaches; e.g., attack detection schemes for noiseless systems [10], comparing the observations from a few known safe sensors against potentially malicious sensor observations [11] to tackle the attack of [7], coding of output of sensors along with χ2 detector [12], Gaussian mixture model based detection and secure state estimation [13], and the innovation vector based attack detection and secure estimation schemes [14]. There have also been a number of works on secure estimation: see [15] for bounded noise case, [16] for sparsity models to characterize the location switching attack in a noiseless system and state recovery constraints, [17]

for noiseless systems, [18]–[20] for linear Gaussian process and linear observation with Gaussian noise. Attack detection, estimation and control for power systems are addressed in [21]–[23]. Attack-resilient control under FDI for noiseless systems is discussed in [24].
Though relatively new, FDI on distributed systems is also increasingly being investigated; see [25] for attack detection and secure estimation, [26] for attack detection in networked control system via dynamic watermarking, [27] for distributed Krein space based attack detection in discrete time-varying systems, and [28] for distribured attack detection in power systems. On the other hand, attack design for distributed CPS is also being investigated; see [29] for linear attack design against distributed state estimation to push all nodes’ estimates to a desired target under a given attack detection constraint, [30] for attack design to maximize the networkwide estimation error via simple Gaussian noise addition, [31] for conditions for perfect attack in a distributed control system and design algorithms for perfect and non-perfect attacks, etc.
While there have been several schemes (such as [11] and the χ2 detector) to detect FDI attack in a multi-sensor setting, the optimal attack detector is not yet known even for the centralized systems. Moreover, the popular χ2 detector fails if the attacker judiciously injects false data in such a way that the innovation sequence of the Kalman state estimator remains constant over time. In light of this issue, our main contributions in this paper are as follows:
1) In a multi-sensor setting with some safe and some potentially unsafe sensors, for the linear attack of [7] with known attack parameters, we develop an optimal Bayesian attack detector that minimizes the mean delay in attack detection subject to a constraint on the false alarm probability. The problem is formulated as a partially observable Markov decision process (POMDP), and the optimal policy turns out to be a simple threshold policy on the belief probability that an attack has already been launched.
2) Though POMDP based Bayesian change detection techniques exist in the literature [32], our problem involves a far more complicated state that consists of the belief and the collection of past Kalman innovations; this occurs primarily because of the temporal dependence of innovation sequence after the attack and the uncertainty in the attack initiation instant. Also, we do not apply Shiryaev’s test directly because that would be optimal only for α → 0 and not necessarily for all α, where α is the probability of false alarm.
3) Computing the belief probability recursively is a challenging problem due to the complicated temporal dependence of the innovation sequence available to the estimator, and we solve this by modeling the postattack state estimation process as a Kalman ﬁlter with a modiﬁed process and observation model. Our results in Section III explicitly show how to compute the true post-attack innovation distribution.
4) In order to reduce computational complexity, we propose a sub-optimal algorithm called QUICKDET whose structure is motivated by the optimal policy derived

from the POMDP formulation. QUICKDET applies a constant threshold rule on the belief, while the POMDP formulation yields a time-varying threshold. We provide a simulation-based technique to optimize this constant threshold, by using tools from simultaneous perturbation stochastic approximation (SPSA [33]) and two timescale stochastic approximation [34]. Numerical results show that this sub-optimal algorithm signiﬁcantly outperforms competing algorithms. 5) The Bayesian quickest FDI detection algorithm is also extended to the case where the attacker can launch an attack using multiple possible linear attack strategies. 6) In the non-Bayesian setting, we adapt the generalized CUSUM test from the literature for quickest detection of FDI. It turns out that the test statistic for generalized CUSUM in our problem can be computed by using the same tools developed in Section III.
The rest of the paper is organized as follows. The system model is described in Section II. Section III develops the necessary theory for calculating the state transition probabilities for the POMDP formulation. POMDP formulation for FDI attack detection in the Bayesian setting with known linear attack parameters is provided in Section IV. Quickest attack detection algorithm for the non-Bayesian setting is provided in Section V. Numerical results are provided in Section VI, followed by the conclusions in Section VII. All proofs are provided in the appendices.
II. SYSTEM MODEL
In this paper, bold capital letters, bold small letters, and capital letters with caligraphic font will denote matrices, vectors and sets respectively. For any two square matrices M1 and M2, the block diagonalization operator is deﬁned by Blkdiag(M1, M2) =. M1 0 . Also, the transpose of a
0 M2 matrix M is denoted by M .

A. Sensing and estimation model We consider a set of sensors N =. {1, 2, · · · , N } sensing
a discrete-time process {xk}k≥1 which is a linear Gaussian process with the following dynamics:

xk+1 = Axk + wk

(1)

where xk ∈ Rq×1 is vector-valued, A ∈ Rq×q is the process matrix, and wk ∼ N (0, Q) is the Gaussian process noise i.i.d. across k. The observation made by sensor i at time k is:

yk,i = Cixk + vk,i

(2)

where Ci is a matrix of appropriate dimensions and vk,i ∼

N (0, Ri) is the Gaussian observation noise at sensor i at

time k, which is i.i.d. across k and independent across i. We

assume

that

(A,

Q

1 2

)

is

stabilizable

and

(A,

Ci)

is

detectable

for all i ∈ N . The complete observation from all sensors at time k is denoted by yk =. (yk,1, yk,2, · · · , yk,N ) which can be written as:

yk = Cxk + vk

(3)

where C =. (C1, C2, · · · , CN ) is the equivalent observation matrix and vk is the zero mean Gaussian observation noise
with covariance matrix Blkdiag(R1, R2, · · · , RN ).

B. Process estimation under no attack
For the model in (3), a standard Kalman ﬁlter [35] is used to estimate xˆk from {yj}j≤k in order to minimize the mean squared error (MSE):

xˆk+1|k = Axˆk

Pk+1|k = APkA + Q Kk+1 = Pk+1|kC (CPk+1|kC + R)−1

xˆk+1 = xˆk+1|k + Kk+1(yk+1 − Cxˆk+1|k)

Pk+1 = (I − Kk+1C)Pk+1|k,

(4)

where xˆk+1 = E(xk+1|y0, y1, · · · , yk+1) is the MMSE

estimate and Pk+1 is the the error covariance matrix for this

estimate. From [35], we know that limk→∞ Pk+1|k = P exists

and is the unique ﬁxed point to the Riccati equation which is

basically

the

Pk+1|k

iteration.

Let

us

also .

deﬁne

the

innovation

vector from sensor i at time k as.zk,i = yk,i − Cixˆk|k−1, and

the collective innovation as zk = yk − Cxˆk|k−1. It is well-

known [35] that {zk}k≥1 is a zero-mean Gaussian sequence

independent across time and whose steady-state covariance matrix is Σz =. (CPC + R). Hence, in most cases, the residue-based χ2 detector is used at the remote estimator’s side

for any attack or anomaly detection, which has the following

mathematical form:

τ

H1

zkΣ−z 1zk ≷ η

(5)

k=τ −J+1

H0

where the null Hypothesis H0 represents no attack or anomaly, and H1 represents the presence of attack or anomaly. Here J is a pre-speciﬁed window size and η is a pre-speciﬁed threshold
which can be tuned to control the false alarm probability.

C. FDI attack
If a sensor i is under FDI attack, the observation sent to the remote estimator from this sensor becomes:

y˜k,i = Cixk + vk,i + ek,i

(6)

where ek,i is the false data injected by sensor i at time k. Consequently, (3) is modiﬁed to:

y˜k = Cxk + vk + ek

(7)

Let us recall linear attacks for the single sensor case [7] where, at time k, the malicious sensor modiﬁes the innovation as z˜k = T zk + bk, where T is a square matrix and bk ∼ N (0, Σb) is i.i.d. Gaussian random vector sequence. The authors of [7] had shown that z˜k ∼ N (0, Σz˜) under steady state, where Σz˜ = T ΣzT + Σb. Hence, by ensuring Σz˜ = Σz, one can preserve the distribution of {z˜k}k≥1 in the single sensor case, and hence the detection probability will remain same even under FDI, under the χ2 detector. It was
also shown in [7] that inverting the sign of the innovation (i.e.,

T = −I and bk = 0) maximizes the MSE. Obviously, T = I and bk = 0 imply that there is no attack.
In this paper, we assume that there is a set of sensors S ⊂ N which are safe, i.e., the sensor belonging to S can not be attacked. Let the set of potentially unsafe sensors be denoted by A =. N − S. Clearly, a general T matrix as the single sensor case will not be useful here; instead, we assume that T = Blkdiag(TS , TA) = Blkdiag(Blkdiag({Ti}i∈S ), Blkdiag({Ti}i∈A)) where Ti is an identity matrix of appropriate dimension if i ∈ S. Also, for i ∈ S, the added noise bk,i = 0 for all time k ≥ 1, and, for i ∈ A, we have bk,i ∼ N (0, Σbi ) i.i.d. across k. Consequently, the modiﬁed innovation at node i ∈ A at time k is given by:

z˜k,i = Tizk,i + bk,i

(8)

We deﬁne zk,A, z˜k,A, yk,A, y˜k,A, CA the components of

zk, z˜k, yk, y˜k, C coming from sensors of A; similar notation

is used for the components corresponding to the safe sensors S

also. We also deﬁne by x˜k the estimate at time k generated by

a Kalman ﬁlter under FDI attack. The history available to the remote estimator at time k is denoted by Hk =. {z˜j : j ≤ k}.

We

also

deﬁne

x˜k

as

the

estimate

of

xk

by .

applying

a

standard Kalman ﬁlter on Hk. Also, let x˜k|a = E(xk|Hk, a)

denote the MMSE estimate of xk given Hk and the event a

that attack has already happened.

For the multi-sensor setting, [11] proposed an attack de-

tection algorithm under the presence of a few known safe

sensors. Unfortunately, the detection algorithm of [11] and

other detection algorithms from the literature do not have any

optimality proof. On the other hand, if the attacker ensures

a constant z˜k for all k such that

τ k=τ

−J

+1

z˜k

Σ−z˜ 1z˜k

<

η,

then the χ2 detector fails. These inadequacies in the literature

motivate the quickest attack detection problem formulation in

this paper.

III. RECOVERING TRUE INNOVATION AND ESTIMATES FROM FDI ATTACKED OBSERVATIONS
In this section, we will develop a technique for computing x˜k|a under the assumption that the attack initiation instant t is known; this will also yield the statistics of z˜k. These results are necessary to calculate the state transition probabilities of the POMDP formulation in Section IV. These results also show that linear attack changes the distribution of innovations and estimates in a multi-sensor scenario with a few safe sensors. Throughout this section, we assume that T is known to the remote estimator.

A. Computing x˜k|a The innovation from the unsafe sensors for k ≥ t is:

z˜k,A = TA(yk,A − CAAx˜k−1) + bk

=⇒ TA−1z˜k,A = (yk,A + TA−1bk) − CAAx˜k−1

= y˜˜k,A − CAAx˜k−1

(9)

where y˜˜k,A =. yk,A + TA−1bk, k ≥ t. It is important to note that, for k ≥ t, the estimator does

not observe yk,A. However, after attack, the estimator can calculate y˜˜k,A from (9), since the estimator knows z˜k,A. Hence,

we can deﬁne a new observation model for the estimator as follows:

y˜˜k,S = CS xk + vk,S = yk,S

y˜˜k,A = CAxk + vk,A + TA−1bk

.=v˜˜k,A

=⇒ y˜˜k = Cxk + v˜˜k

(10)

where the observation noise from sensors belonging to A

becomes v˜˜ =. v + T −1b , y˜˜ =. y˜˜k,S , v˜˜ =.

k,A

k,A

Ak k

y˜˜k,A k

v˜˜k,S , and the covariance matrix of v˜˜ becomes R˜˜ =.

v˜˜k,A

k

RS

0

0 RA + TA−1ΣbTA−1 .

It is to be noted that the estimator can use this model only

for k ≥ t, when it knows that event a is true, i.e., an attack

has already happened. Basically, for k ≥ t, the estimator can

compute x˜k|a by using a standard Kalman ﬁlter under this

new observation model. In this connection, we would also

like to point out the connection between the innovation for

this modiﬁed observation model and the innovation for the

original observation model, both under attack:

z˜˜k,S = yk,S − CS Ax˜k−1|a

= yk,S − CS Ax˜k−1 + CS A(x˜k−1 − x˜k−1|a)

= z˜k,S + CS A(x˜k−1 − x˜k−1|a)

z˜˜k,A = y˜˜k,A − CAAx˜k−1|a

= TA−1z˜k,A + CAA(x˜k−1 − x˜k−1|a)

(11)

Now, x˜k|a can be computed via using standard Kalman ﬁlter equations:

P˜˜k|k−1 = AP˜˜k−1A + Q

K˜˜ k = P˜˜k|k−1C (CP˜˜k|k−1C + R˜˜ )−1

x˜ = Ax˜

+ K˜˜ z˜˜k,S

k|a

k−1|a

k z˜˜k,A

P˜˜k = (I − K˜˜ kC)P˜˜k|k−1

(12)

Note that, since this modiﬁed observation model makes sense only for k ≥ t, the distribution of z˜˜k for k ≥ t depends
on t.

B. Computing the conditional distribution of z˜k

From (11), we can write :

z˜k,S = z˜˜k,S + CS A(x˜k−1|a − x˜k−1)

(13)

The innovation sequences z˜˜k,S and z˜˜k,A are Gaussian noise with zero mean and covariance CS P˜˜k|k−1CS + R˜˜ S and CAP˜˜k|k−1CA + R˜˜ A respectively. Hence, the con-
ditional distribution of z˜k,S will be N (CS A(x˜k−1|a − x˜k−1), CS P˜˜k|k−1CS + R˜˜ S ) given all necessary quantities involved, where R˜˜ S = RS . Using (11), conditional distribution of z˜k,A is N (TACAA(x˜k−1|a − x˜k−1), TA(CAP˜˜k|k−1CA +

R˜˜ A)TA), where R˜˜ A = RA + TA−1ΣbTA−1. Under stability, P˜˜k|k−1 will converge to a limit P˜˜ .
IV. ATTACK DETECTION FOR KNOWN LINEAR ATTACK: BAYESIAN SETTING
In Section III, we have shown that the distribution of the innovation changes under a linear attack. In this section, we provide a quickest change detection algorithm for detecting a linear attack with known T matrix. Motivated by the theory of [36], we formulate the problem as a partially observable Markov decision process (POMDP, see [37, Chapter 5]) and derive the optimal attack detection policy.

A. Problem statement
We assume that the discrete time starts at k = 0, and the attack begins at a random time t which is modeled as a geometrically distributed random variable with mean θ1 , where θ ∈ (0, 1) is known to the remote estimator. Clearly, θ denotes the probability that, given that no attack has started up to time k, the attacker launches an attack at time (k + 1). This assumption allows us to formulate the quickest attack detection problem as a POMDP.
The two hypotheses considered here are the following: H0: there is no attack. H1: there is an attack.
At each k ≥ 0, the remote estimator computes zk (or z˜k provided that there is an attack). At some (possibly random) time τ , the estimator decides to stop collecting observations yk (or y˜k provided that there is an attack), and declares that an attack has been launched on A. This stopping time τ is determined by a policy (a sequence of decision rules) µ = {µk}k≥0, where µk is a function that takes the history of observations available to the estimator at time k and decides whether to declare that an attack has been launched. Clearly, τ < t denotes the event of a false alarm.
We seek to minimize the expected delay in detecting an attack subject to a constraint on the false alarm probability:

min Eµ[(τ − t)+] s.t. Pµ(τ < t) ≤ α

(14)

µ

This constrained problem can be relaxed using a Lagrange multiplier λ > 0 to obtain the following unconstrained problem:

L(µ) = Eµ[(τ − t)+ + λ1{τ<t}]

(15)

The following standard results tells us how to choose λ:

Theorem 1. Let us consider (14) and its relaxed version (15). If there exists a λ∗ ≥ 0 and a policy µ∗(λ∗) such that, (i) µ∗(λ∗) is an optimal policy for (14) under λ∗, and (ii) the constraint in (15) is met with equality under µ∗(λ∗), then µ∗(λ∗) is an optimal policy for the constrained problem (14).

B. POMDP formulation
Let us deﬁne the belief probability of the estimator that an attack has been launched at or before time k, as πk =

P(t ≤ k|z˜1, z˜2, . . . , z˜k), where z˜k = zk if t > k. Under this notation, (15) can be rewritten as:

τ −1

τ −1

L(µ) = Eµ[ 1(t≤k) + λ1{τ<t}] = Eµ[ πk + λ(1 − πτ )] (16)

k=0

k=0

For change detection, typically πk is a sufﬁcient statistic [38] for decision-making at time k, but that does not hold in

our problem due to temporal dependence of the innovation

after an attack is launched. Hence, we formulate a POMDP

with state at time k given by (πk, z˜1, z˜2, . . . , z˜k), with the understanding that z˜k = zk if t > k. The set of possible control actions is given by U = {0, 1}, where action 0

represents continuing to collect observations, and action 1

stands for stopping and declaring H1. Further, based on (16), the single stage cost at time k is:

ck(πk, z˜1, z˜2, . . . , z˜k, uk) =

πk λ(1 − πk)

if uk = 0 if uk = 1

C. Recursive calculation of πk
We need to compute πk from πk−1 recursively, in order to be able to calculate state transitions. However, after attack, z˜k sequence ceases to be i.i.d. across k, which makes this recursive calculation non-trivial. Note that, the joint probability density of the innovations computed at the estimator:
p(z˜1, . . . , z˜k)
= p(z˜1)p(z˜2|z˜1) . . . p(z˜k|z˜1, . . . , z˜k−1) Let us deﬁne pc(z˜i) =. p(z˜i|Hi−1). Now, using Bayes rule, we can write:

πk = = =
where,

p(z˜1, . . . , z˜k|t ≤ k) × P(t ≤ k)
p(z˜1, . . . , z˜k) P(t ≤ k)Πki=1pc(z˜i|t ≤ k)
P(t ≤ k)Πki=1pc(z˜i|t ≤ k) + P(t > k)Πki=1pc(z˜i|t > k) βk (17)
βk + 1

P(t ≤ k)Πki=1pc(z˜i|t ≤ k) βk = P(t > k)Πki=1pc(z˜i|t > k)

P(t ≤ k − 1)pc(z˜k|t ≤ k)Πki=−11pc(z˜i|t ≤ k)

= fk(θ)

k−1

P(t > k − 1)pc(z˜k|t > k)Πi=1 pc(z˜i|t > k − 1)

(18)

and,

1 − (1 − θ)k

fk(θ) = (1 − θ)(1 − (1 − θ)k−1)

(19)

Now, note that:

Πki=−11pc(z˜i|t ≤ k) = p(z˜1, . . . , z˜k−1|t ≤ k)

= p(z˜1, . . . , z˜k−1|t ≤ k − 1)P(t ≤ k − 1|t ≤ k)

+p(z˜1, . . . , z˜k−1|t = k)P(t = k|t ≤ k)

1 − (1 − θ)k−1 = 1 − (1 − θ)k p(z˜1, . . . , z˜k−1|t ≤ k − 1)

θ(1 − θ)k−1 k−1

+ 1 − (1 − θ)k Πi=1 p(zi)

(20)

where the product form in the last line comes from the fact that innovations are i.i.d. before the attack is launched. Clearly, (20) allows us to calculate the numerator of (18). Similarly, in order to calculate the denominator of (18), we note that:

Πki=−11pc(z˜i|t > k − 1) = Πki=−11p(zi)

(21)

This again holds because innovations are i.i.d. before the attack is launched.
Using (20) and (21) in (18) and upon simpliﬁcation, we obtain:

βk = pc(z˜k|t ≤ k) βk−1 + θ pc(z˜k|t > k) (1 − θ) (1 − θ)

= pc(z˜k|t ≤ k)

πk−1 + θ (22)

pc(z˜k|t > k) (1 − θ)(1 − πk−1) (1 − θ)

Obviously, πk can be calculated from βk using (17). It is important to note that, using the results from Section III-B, pc(z˜k|t ≤ k) can be computed as:

k

pc(z˜k|t ≤ k) = pc(z˜k|t = i)Pc(t = i|t ≤ k)

(23)

i=0

p(z˜1, . . . , z˜k−1|t = i)P(t = i|t ≤ k) Pc(t = i|t ≤ k) = k
p(z˜1, . . . , z˜k−1|t = j)P(t = j|t ≤ k)
j=0
p(z˜1, . . . , z˜k−1|t = i) = Πkj=−11pc(z˜j |t = i)
Here pc(z˜k|t = i) is basically the distribution of z˜k which has already been calculated in Section III-B assuming that t = i. However, for each i ∈ {0, 1, . . . , k}, we need to run a separate Kalman ﬁlter to calculate pc(z˜k|t = i), as described in III-B. On the other hand, pc(z˜k|t > k) is simply the unconditional distribution of zk under no attack, since the innovations are independent of each other under no attack. Hence, results from Section III-B can be directly used to calculate βk and hence πk recursively.

D. Bellman equation, value function and policy structure

Since the state transition is dependent on observation

history, the optimal policy will be non-stationary, and the

optimal value function will also be dependent on time. Let

J

∗ k

(π

k

,

z˜1

,

z˜2

,

.

.

.

,

z˜k

)

denote

the

optimal

cost-to-go

starting .

from a state (πk, z˜1, z˜2, . . . , z˜k) at time k, with J∗(π0) =

J0∗(π0). Also, let Ψk be a function such that, given uk = 0,

we have πk+1 = Ψk(πk, z˜1, z˜2, · · · , z˜k). Hence,

The Bellman equation for (15) is given by:

J

∗ k

(π

k

,

z˜1

,

z˜2

,

.

.

.

,

z˜k

)

= min{λ(1 − πk), πk +

E[J

∗ k+1

(Ψk

(π

k

,

z˜1

,

z˜2

,

.

.

.

,

z˜k

),

z˜1

,

z˜2

,

.

.

.

,

z˜k

+1

)|

z˜1:

k

]

}

(24)

The ﬁrst term in the minimization of (24) is the cost of

stopping and declaring H1, and the second term is the cost

of continuing observation, which involves a single-stage cost

πk and an expected cost-to-go from the next step where the

expectation .

is

taken

over

the

distribution

of

z˜k+1

conditioned

on z˜1:k = (z˜1, . . . , z˜k).

Let us consider an N -horizon problem which is same as problem (15) except that, at time N , the detector must stop and declare H1. Let the analogues of Jk∗ (for various values of k) and J∗ for this N -horizon problem be denotes by Jk(N)∗ and J (N)∗, respectively.
Lemma 1. J(N)∗(π) is concave in π ∈ [0, 1].
Proof: See Appendix A. Proof is based on outline from [39].
Theorem 2. J∗(π) is concave in π.
Proof: The proof follows from Lemma 1 and the fact that limit of a sequence of concave functions is concave.
The next theorem describes the optimal policy for the unconstrained problem (15).
Theorem 3. The optimal policy for the constrained problem (15) is a threshold policy. At time k, if the state is (πk, z˜1, z˜2, . . . , z˜k), then the optimal action is to stop and declare H1 if πk > Γk(z˜1:k) for a threshold Γk(z˜1:k) ∈ [0, 1], and to continue collecting observations if πk < Γk(z˜1:k). If πk = Γk(z˜1:k), either action is optimal.
Proof: See Appendix B.
E. Computational complexity and the QUICKDET algorithm
Due to the time-inhomogeneous state transition, problem (15) cannot be solved by standard techniques such as value iteration. On the other hand, the optimal threshold Γk(z˜1:k) at time k depends not only on k but also the history of innovations z˜1:k. Further, the presence of Jk∗+1 in the Bellman equation (24) makes even a fairly discretized version of the problem computationally very heavy to solve in an online fashion. These problems can be alleviated by setting a constant threshold, i.e., Γk(z˜1:k) = Γ for all k ≥ 1, z˜1:k. Deﬁnitely, this will yield a suboptimal solution, but as will be seen later, we can achieve much better performance than the competing algorithms in the literature by carefully choosing Γ.
1) The QUICKDET algorithm: Motivated by Theorem 3 along with the need for a constant threshold Γ to reduce computational complexity, here we describe outline of an algorithm QUICKDET. The two key components of QUICKDET, apart from the threshold structure, are the choices of the optimal Γ∗ to minimize the objective in the unconstrained problem (15) within the class of stationary threshold policies, and λ∗ to meet the constraint in (14) with equality as per Theorem 1. These parameters are set via some off-line precomputation involving two timescale stochastic approximation [34], wherein we update λ in the slower timescale, and Γ in the faster timescale.
In the pre-computation phase, we generate various sample paths P0, P1, · · · of the process, observation and attack dynamics as per our discussed system model. The iterations start with some initial iterates Γ(0) and λ(0). For sample path Pn, a threshold policy with constant threshold Γ(n) is used for attack detection on the state and modiﬁed observation sequence, and it is observed whether this policy generates a false alarm for sample path Pn; if it does not generate a false alarm, then

the detection delay τn is recorded. Let 1F A(n) and 1D(n) be

the indicators of false alarm and attack detection for sample

path Pn.

Let {a(n)}n≥0, {b(n)}n≥0 and {δ(n)}n≥0 be three non-

negative sequences satisfying the following properties: (i)

∞ n=0 a(n) = ∞, ∞ n=0 b2(n)

∞ n=0 b(n) = ∞, (ii) ∞ n=0 a2(n) <

<

∞,

(iii)

limn→∞

b(n) a(n)

=

0, (iv)

limn→∞ δ(n) = 0, and (v) ∞ n=0 aδ22((nn)) < ∞. The ﬁrst two

conditions are standard requirements for stochastic approxima-

tion. Condition (iii) ensures the necessary timescale separation.

The last two conditions are required for the convergence of the

Γ(n) update via stochastic gradient descent (SGD), adapted

from the theory of simultaneous perturbation stochastic ap-

proximation (SPSA, see [33]). Let Γ+(n) = Γ(n) + δ(n) and Γ−(n) = Γ(n) − δ(n)

be two perturbations of Γ(n) in opposite directions. Let
d+n = τn1D(n)+λ(n)1F A(n)|Γ+(n) be the cost incurred along
sample path Pn if a threshold policy with a constant threshold Γ+(n) is used along sample path Pn; let us deﬁne d−n is a

similar way.

The following updates are made:

d+n − d−n 1 Γ(n + 1) = [Γ(n) − a(n) × 2δ(n) ]0
λ(n + 1) = [λ(n) + b(n) × (1F A(n) − α)]∞ 0 (25)

The Γ(n) update in (25) is a stochastic gradient descent algo-
rithm used to minimize the expected cost along sample path Pn, for λ = λ(n). This algorithm runs in a faster timescale. The λ(n) update runs at a slower timescale to ensure that the false alarm probability equals α. The faster timescale iterate Γ(n) views the λ(n) iterate as quasi-static, while the λ(n) iterate views the Γ(n) iterate as almost equilibriated.
The iterates are projected onto desired intervals to ensure
boundedness.
Using standard arguments, we can prove that
(Γ(n), λ(n)) → {(Γ, λ) ∈ [0, 1] × [0, ∞) : E(1F A) =
α, ∇ΓE(d)|λ = 0}. In practice, if (Γ(n), λ(n)) → (Γ∗, λ∗), then this Γ∗ is used in the real attack detector on ﬁeld.

F. Extension to multiple attack matrices
1) Calculation of transition probabilities: Here we assume that the attack matrix T is unknown but belongs to a known ﬁnite set T , and that I ∈ T . We assume an initial prior distribution on {T ∈ T : T = I}. The detector maintains a belief probability πkT for hypothesis T , and the total number of hypotheses is |T |. In this case, the posterior belief probability of attack becomes πk = 1−πkI . Here, πkT for T = I is deﬁned as the belief at time k that the attack has already begun, and that the attacker uses T :

πkT =. p(t ≤ k, T |z˜1, . . . , z˜k) = p(t ≤ k|z˜1, . . . , z˜k, T ) p(T |z˜1, . . . , z˜k) .=πk|T
where πk|T = βkβ|kT|T+1 (similar to (17)) is the conditional belief on attack having already started given that the attacker

uses T , and this βk|T can be calculated in the same way as in Section IV-C for each T ∈ T . Posterior probability distribution over T , i.e., p(T |z˜1, . . . , z˜k, t ≤ k) for T = I, can be calculated as given below:

p(T |z˜1, . . . , z˜k) = p(z˜k|z˜1, . . . , z˜k−1, T )p(T |z˜1, . . . , z˜k−1)
T ∈T p(z˜k|z˜1, . . . , z˜k−1, T )p(T |z˜1, . . . , z˜k−1) = pc(z˜k|T )p(T |z˜1, . . . , z˜k−1)
T ∈T pc(z˜k|T )p(T |z˜1, . . . , z˜k−1)
Here p(T |z˜1, . . . , z˜k−1) is known through the iterative calculation, where the ﬁrst iteration will depend on prior distribution on attack matrices T ∈ T . The probability pc(z˜k|T ) is the distribution of innovation given the history and attack matrix T :
pc(z˜k|T ) = pc(z˜k|T , t ≤ k)p(t ≤ k|z˜1, . . . , z˜k−1, T ) + pc(z˜k|T , t > k)p(t > k|z˜1, . . . , z˜k−1, T )
= pc(z˜k|T , t ≤ k)(πk−1|T + (1 − πk−1|T )θ) + pc(z˜k|T , t > k)(1 − πk−1|T )(1 − θ) (26)
Now, by using (22), we can write:
βk|T = pc(z˜k|T , t ≤ k)(πk−1|T + (1 − πk−1|T )θ) pc(z˜k|T , t > k)(1 − θ)(1 − πk−1|T )
Hence,

βk|T pc(z˜k|T , t > k)(1 − θ)(1 − πk−1|T ) (27)
= pc(z˜k|T , t ≤ k)(πk−1|T + (1 − πk−1|T )θ)
Finally, (26) can be simpliﬁed by substituting (27) resulting the following expression:

pc(z˜k|T ) = pc(z˜k|T , t > k)(1 − πk−1|T )(1 + βk|T )(1 − θ)

Now, pc(z˜k|T , t > k) becomes the unconditional distribution of the innovation under no attack. On the other hand, πk−1|T is known from the previous iteration, and βk|T can be calculated as in Section IV-C. Thus, we can calculate pc(z˜k|T ) and consequently p(T |z˜1, . . . , z˜k) and πk|T for all T ∈ T .
However, the time complexity of algorithm in multiple attack matrix case increases |T | times compared to the binary hypothesis testing case, since we would need to maintain separate set of Kalman ﬁlters for each attack matrix T .
2) Policy structure: For (14), we can still compute the belief probability that the attack has begun:

πk = p(t ≤ k|z˜1, z˜2, . . . , z˜k)

=

p(t ≤ k, T |z˜1, z˜2, . . . , z˜k)

T ∈T

=

πkT

T ∈T

Similar to Theorem 3, the optimal Policy structure for multiple

attack matrices will still be a threshold policy. We also

note that, arg maxπk|T yields the maximum likelihood (ML)

T ∈T

detection

of

T,

and

arg

m

axπ

T k

can

be

used

for

maximum

T ∈T

aposteriori (MAP) detection of the attacker’s strategy.

V. ATTACK DETECTION IN THE NON-BAYESIAN SETTING
In this section, we consider the situation where the distribution of the attack initiation instant t is not known. This eliminates the possibility of solving the problem via MDP formulation. Hence, we use the popular generalised CUSUM algorithm proposed by Lai [40] for change detection, and demonstrate how the results in Section III-B can be used in computing the generalised CUSUM statistic.
The basic CUSUM Algorithm was developed heuristically by Page [41], but was later analysed rigorously in [42], [43], [44] and [40]. In our non-Bayesian FDI detection setting, under no attack (i.e., t = ∞), the false alarm rate (FAR) is the inverse of the mean time to false alarm F AR(τ ) = E∞1(τ) . With little abuse of notation where the stopping time τ also represents a stopping rule for the detector, we focus on the following set of detection/stopping rules:

Dα = {τ : F AR(τ ) ≤ α}

(28)

Since ﬁnding a uniformly powerful test that minimizes detection delay over Dα is not possible, we study two important minimax formulations developed by Lorden [42] and Pollak [45].
Lordan’s Problem: For a given α, ﬁnd τ ∈ Dα to minimize worst average detection delay W ADD(τ ) deﬁned as:
W ADD(τ ) = supn≥1esssupEn[(τ − n)+|z˜1, . . . , z˜n−1] (29)
Pollak’s Problem: For a given α, ﬁnd τ ∈ Dα to minimize cumulative average detection delay CADD(τ ) deﬁned as :

CADD(τ ) = supn≥1En[τ − n|τ ≥ n]

(30)

It was proved in [46, Section IV] that W ADD(τ ) ≥

CADD(τ ). Lai [40] studied both Lorden’s and Pollak’s

problem in non-i.i.d. setting, and showed that under some addi-

tional condition, the basic CUSUM algorithm is asymptotically

optimal as α → 0.

Let us deﬁne pc(z˜i|t = k) (adapted to our problem setting where innovations are i.i.d. across time before attack), the

associated log-likelihood ratio, and the corresponding running

sum of the log-likelihood ratios as follows:

pc(z˜i|t = k) =. p(z˜i|z˜0. · · · , z˜i−1, t = k)

.

pc(z˜i|t = k)

Li,k = log

p(z˜i|t = ∞)

n

Sn =. max1≤k≤n Li,k

(31)

i=k

.=Sn,k

Here Sn,k represents the cumulative sum of likelihood ratio up to time n assuming that the attack started at t = k. Obviously, Sn,k can be written recursively as follows:
Sn,k = max{0, Sn−1,k + log pc(z˜n|t = k) } p(z˜n|t = ∞)
Remark 1. It is important to note that, pc(z˜i|t = k) for i ≥ k can be computed by using the theory developed in Section III-B.

Fig. 2. Mean delay versus probability of false alarm (PFA) comparison among QUICKDET and three other detectors.

Fig. 3. Variation of threshold Γ with probability of false alarm (PFA) for QUICKDET.

The generalized CUSUM algorithm for non i.i.d. observations involve the following stopping time:

τg = inf{n ≥ 1 : Sn ≥ b}

(32)

for some threshold b. It was proved in [40] that, as α → 0, under some regularity conditions,

E∞[τg] ≥ eb b
CADD(τg) ≤ W ADD(τg) ≤ I (1 + o(1)) as b → ∞
for a constant I. Hence, If we set b = |logα|, then
1 F AR(τg) = E∞[τg] ≤ α
|logα| W ADD(τg) ≤ I (1 + o(1)) (33) Thus, τg is ﬁrst-order asymptotically optimal detection rule within Dα.

VI. NUMERICAL RESULTS
Since multiple sensor observations can be viewed as parts of a single imaginary sensor’s observation, we assume that

Fig. 4. Mean detection delay versus FAR performance comparison in the non-Bayesian setting.

there is one safe sensor and one unsafe sensor, and the sign of the innovation coming from the unsafe sensor is inverted, i.e., TA = −I. In this section, we ﬁrst compare the performance of QUICKDET against three other detectors:
• χ2 detector: This detector is as described in Section II, except that η is optimized in an off-line pre-computation phase (as in QUICKDET) to meet the false alarm constraint with equality:

η(n + 1) = [η(n) + a(n) × (1F A(n) − α)]∞ 0

The limit η∗ of this iteration is used in the real detector on ﬁeld. We choose J = 3 in our simulation. • DET: This is an adaptation of the DET algorithm in

[18]. It requires the detector to run two separate parallel Kalman ﬁlters for the safe and unsafe sensors. Let xˆk,S and xˆk,A be the estimates declared by two blind Kalman ﬁlters using observations from the safe sensor and from

the unsafe sensor, respectively. This detector declares an attack at time j if jk=j−J+1(xˆk,A −xˆk,S ) Σ−1(xˆk,A − xˆk,S ) > η where η can be optimized as in the χ2 detector to meet the false alarm constraint with equality, and Σ
is the steady state covariance matrix of (xˆk,A − xˆk,S ) under no attack. We choose J = 3 in our simulation.
• SAFE: This is the detection algorithm taken from [11],

with the threshold optimized as before to meet the false

alarm constraint.

We consider a process with dimension q = 2. The A, Q, 10
RA and RS matrices are all chosen to be 0 1 , CA =

0.5 0

0 0.5

0 1 and CS = 1 0 . The probability of launching an

attack at a time, θ, is chosen to be 0.05, and we generate 10000

sample paths for the pre-computation phase of QUICKDET. Prior belief probability of attack π0 is set to 0 for all the sample paths.

Figure 2 compares the mean detection delay of QUICKDET, DET, χ2 and SAFE detectors, for various values of false alarm
probability α. We observe that QUICKDET outperforms all

other detectors, and the performance margin is very high w.r.t. SAFE and χ2 detectors. It is important to note that, though

QUICKDET is a suboptimal detector motivated by the optimal detector of Theorem 3, it uses the knowledge of the matrix TA which the other three algorithms do not use. Hence, given the knowledge of TA (the attacker’s strategy), it is always better to use QUICKDET. It is also observed that DET’s performance is not far from that of QUICKDET, which means that DET can be used as a potential alternative to QUICKDET in case the knowledge of TA is not available apriori. These observations have been veriﬁed through numerous simulation experiments under various problem instances.
Since the probability of attack detection is 1 in all of our simulations, we do not compare ROC curves of the detectors. However, detection delay comparison of Figure 2 is a reasonable alternative to the ROC plots.
Figure 3 shows that the threshold Γ in QUICKDET decreases with the false alarm constraint α, which supports the intuition that a larger Γ results in less frequent up-crossing of Γ by the belief probability, and consequently a smaller false alarm probability.
Figure 4 compares the performance of generalised CUSUM test with the other three algorithms in terms of mean detection delay versus FAR in the non-Bayesian detection setting. It is observed that here again generalised CUSUM (G-CUSUM) signiﬁcantly outperforms the other three algorithms.

VII. CONCLUSION
In this paper, we provided an algorithm for quickest detection of FDI attack on remote estimation in the Bayesian and non-Bayesian setting. Theoretical proof of optimality was provided wherever required, and numerical results demonstrated clear superiority of the proposed algorithms against other competing algorithms. However, there remain a number of open questions: (i) how to handle a nonlinear attack scheme? (ii) how to handle unknown attack strategy? (iii) how to perform distrbuted quickest detection in a multihop network setting? We plan to address these issues in our future research endeavours.

APPENDIX A PROOF OF LEMMA 1

Under action uk−1 = 0 and for πk−1 = π, the recursion for π can be written in a more elementary form as:

πnext = pc(z˜k|t ≤ k)(π + (1 − π)θ) (34) p(z˜k|z˜1, z˜2, . . . , z˜k−1)

Note that, JN(N)∗(π) = λ(1 − π) is concave in π. Now JN(N−)1∗(π) = min{λ(1 − π), π + E[JN(N)∗(πnext)]} which is

minimum of two linear functions and hence concave in π.

As induction hypothesis, let us assume that Jk(N)∗(π) is con-

cave in π, and we would like to show that Jk(N−1)∗(π) is concave

in

π.

Since

Jk(N−1)∗(π)

=

min{λ(1

−

π

),

E[J

(N k

)∗

(π

next

)]}

,

it

would sufﬁce to show that E[Jk(N)∗(πnext)] is concave in π.

Let us deﬁne a function:

Φk(π, z˜1:k) = Jk(N)∗

pc(z˜k|t ≤ k)(π(1 − θ) + θ) pc (z˜k )

pc (z˜k )

where z˜1:k represents z˜1, z˜2, . . . , z˜k. Since . . . d(z˜k) is a linear operator and E[Jk(N)∗(πnext)] = Φk(π, z˜1:k)d(z˜k), it is sufﬁcient to show that Φk(π, z˜1:k) is concave in π. Since Jk(N)∗(π) is assumed to be concave in π, we can write:
Jk(N)∗(π) = (x,iyn)f∈V (xπ + y) (35)
where V = {(x, y) ∈ R2 : xπ + y ≥ Jk(N)∗(π) ∀ π ∈ [0, 1]}. Hence,

Φk(π, z˜1:k)

(N)∗ pc(z˜k|t ≤ k)(π(1 − θ) + θ)

= Jk

pc (z˜k )

pc (z˜k )

= inf pc(z˜k|t ≤ k)(π(1 − θ) + θ) x + y pc(z˜k)

(x,y)∈V

pc (z˜k )

= inf {[pc(z˜k|t ≤ k)(1 − θ)x]π + xθpc(z˜k|t ≤ k) + ypc(z˜k)}
(x,y)∈V

Since inﬁmum of linear functions is a concave function,
Φk(π, z˜1:k) and hence E[Φk(π, z˜1:k)] are concave in π. Hence, Jk(N−1)∗(π), which is minimum of two concave functions, is concave in π. Since, we have already proved that JN(N)∗(π) and JN(N−)1∗(π) is concave in π, by backward induction, we can claim that J (N)∗(π) is concave in π.

Let us deﬁne:

APPENDIX B PROOF OF THEOREM 3

g(πk) = λ(1 − πk) hk(πk, z˜1, z˜2, · · · , z˜k) = πk + E[Jk∗+1(Ψk(πk, z˜1, z˜2, · · · , z˜k))]
Clearly g(0) = λ and g(1) = 0. Now note that,

hk(0, z˜1, z˜2, · · · , z˜k)

= Ez˜ |z˜ ...z˜ J ∗ θpc(z˜k+1|t ≤ k + 1) k+1 1 k k+1 p(z˜k+1|z˜k . . . z˜1)

≤ J ∗ θ × Ez˜ |z˜ ...z˜ pc(z˜k+1|t ≤ k + 1)

k+1

k+1 1 k p(z˜k+1|z˜k . . . z˜1)

= Jk∗+1(θ)

≤ λ(1 − θ)

<λ

where the ﬁrst inequality follows from Jensen’s inequality. Also, note that, hk(1, z˜1, z˜2, · · · , z˜k) = 1 + E[Jk∗+1(πk+1)] ≥ 1 for any k ≥ 1. From the fact that hk(1, z˜1, z˜2, · · · , z˜k) − g(1) > 0 and hk(0, z˜1, z˜2, · · · , z˜k) − g(0) < 0 for all k ≥ 1, by using the intermediate value theorem for contin-
uous functions, we get that there exists Γk(z˜1:k) ∈ (0, 1) such that hk(Γk(z˜1:k), z˜1:k) = g(Γk(z˜1:k)). Further, since hk(π, z˜1:k)−g(π) is a concave function, hk(1, z˜1:k)−g(1) > 0 and hk(0, z˜1:k) − g(0) < 0, the value of Γk(z˜1:k) is unique for each k ≥ 1. Hence the optimal stopping time τ ∗ is given
by τ ∗ = inf{k ≥ 1 : πk ≥ Γk(z˜1:k)}

where Γk(z˜1:k) is given by Γk(z˜1:k) + E[Jk∗+1(Ψk+1(Γk(z˜1:k), z˜1 . . . z˜k))]
= λ(1 − Γk(z˜1:k))

REFERENCES
[1] Akanshu Gupta, Abhinava Sikdar, and Arpan Chattopadhyay. Quickest detection of false data injection attack in remote state estimation. In 2021 IEEE International Symposium on Information Theory (ISIT), pages 3068–3073, 2021.
[2] Arpan Chattopadhyay and Urbashi Mitra. Dynamic sensor subset selection for centralized tracking of an iid process. IEEE Transactions on Signal Processing, 2020.
[3] Yanpeng Guan and Xiaohua Ge. Distributed attack detection and secure estimation of networked cyber-physical systems against false data injection attacks and jamming attacks. IEEE Transactions on Signal and Information Processing over Networks, 4(1):48–59, 2018.
[4] Yilin Mo and Bruno Sinopoli. Secure control against replay attacks. In Communication, Control, and Computing, 2009. Allerton 2009. 47th Annual Allerton Conference on, pages 911–918. IEEE, 2009.
[5] Yilin Mo, Rohan Chabukswar, and Bruno Sinopoli. Detecting integrity attacks on scada systems. IEEE Transactions on Control Systems Technology, 22(4):1396–1407, 2014.
[6] Derui Ding, Qing-Long Han, Xiaohua Ge, and Jun Wang. Secure state estimation and control of cyber-physical systems: A survey. IEEE Transactions on Systems, Man, and Cybernetics: Systems, 51(1):176– 190, 2020.
[7] Ziyang Guo, Dawei Shi, Karl Henrik Johansson, and Ling Shi. Optimal linear cyber-attack on remote state estimation. IEEE Transactions on Control of Network Systems, 4(1):4–13, 2017.
[8] Yuan Chen, Soummya Kar, and José MF Moura. Optimal attack strategies subject to detection constraints against cyber-physical systems. IEEE Transactions on Control of Network Systems, 2017.
[9] Yuan Chen, Soummya Kar, and José MF Moura. Cyber physical attacks with control objectives and detection constraints. In Decision and Control (CDC), 2016 IEEE 55th Conference on, pages 1125–1130. IEEE, 2016.
[10] Fabio Pasqualetti, Florian Dörﬂer, and Francesco Bullo. Attack detection and identiﬁcation in cyber-physical systems. IEEE Transactions on Automatic Control, 58(11):2715–2729, 2013.
[11] Yuzhe Li, Ling Shi, and Tongwen Chen. Detection against linear deception attacks on multi-sensor remote state estimation. IEEE Transactions on Control of Network Systems, 2017.
[12] Fei Miao, Quanyan Zhu, Miroslav Pajic, and George J Pappas. Coding schemes for securing cyber-physical systems against stealthy data injection attacks. IEEE Transactions on Control of Network Systems, 4(1):106–117, 2017.
[13] Ziyang Guo, Dawei Shi, Daniel E Quevedo, and Ling Shi. Secure state estimation against integrity attacks: A gaussian mixture model approach. IEEE Transactions on Signal Processing, 67(1):194–207, 2018.
[14] Shaunak Mishra, Yasser Shoukry, Nikhil Karamchandani, Suhas N Diggavi, and Paulo Tabuada. Secure state estimation against sensor attacks in the presence of noise. IEEE Transactions on Control of Network Systems, 4(1):49–59, 2017.
[15] Miroslav Pajic, Insup Lee, and George J Pappas. Attack-resilient state estimation for noisy dynamical systems. IEEE Transactions on Control of Network Systems, 4(1):82–92, 2017.
[16] Chensheng Liu, Jing Wu, Chengnian Long, and Yebin Wang. Dynamic state recovery for cyber-physical systems under switching location attacks. IEEE Transactions on Control of Network Systems, 4(1):14– 22, 2017.
[17] Yorie Nakahira and Yilin Mo. Attack-resilient h2, h-inﬁnity, and l1 state estimator. IEEE Transactions on Automatic Control, 2018.
[18] Arpan Chattopadhyay and Urbashi Mitra. Security against false data injection attack in cyber-physical systems. IEEE Transactions on Control of Network Systems, 2019.
[19] Arpan Chattopadhyay, Urbashi Mitra, and Erik G Ström. Secure estimation in v2x networks with injection and packet drop attacks. In 2018 15th International Symposium on Wireless Communication Systems (ISWCS), pages 1–6. IEEE, 2018.
[20] Arpan Chattopadhyay and Urbashi Mitra. Attack detection and secure estimation under false data injection attack in cyber-physical systems. In 2018 52nd Annual Conference on Information Sciences and Systems (CISS), pages 1–6. IEEE, 2018.
[21] Kebina Manandhar, Xiaojun Cao, Fei Hu, and Yao Liu. Detection of faults and attacks including false data injection attack in smart grid using kalman ﬁlter. IEEE transactions on control of network systems, 1(4):370–379, 2014.
[22] Gaoqi Liang, Junhua Zhao, Fengji Luo, Steven R Weller, and Zhao Yang Dong. A review of false data injection attacks against modern power systems. IEEE Transactions on Smart Grid, 8(4):1630–1638, 2017.

[23] Qie Hu, Dariush Fooladivanda, Young Hwan Chang, and Claire J Tomlin. Secure state estimation and control for cyber security of the nonlinear power systems. IEEE Transactions on Control of Network Systems, 2017.
[24] Hamza Fawzi, Paulo Tabuada, and Suhas Diggavi. Secure estimation and control for cyber-physical systems under adversarial attacks. IEEE Transactions on Automatic Control, 59(6):1454–1467, 2014.
[25] Yanpeng Guan and Xiaohua Ge. Distributed attack detection and secure estimation of networked cyber-physical systems against false data injection attacks and jamming attacks. IEEE Transactions on Signal and Information Processing over Networks, 4(1):48–59, 2017.
[26] Bharadwaj Satchidanandan and Panganamala R Kumar. Dynamic watermarking: Active defense of networked cyber–physical systems. Proceedings of the IEEE, 105(2):219–240, 2016.
[27] Xiaohua Ge, Qing-Long Han, Maiying Zhong, and Xian-Ming Zhang. Distributed krein space-based attack detection over sensor networks under deception attacks. Automatica, 109:108557, 2019.
[28] Florian Dörﬂer, Fabio Pasqualetti, and Francesco Bullo. Distributed detection of cyber-physical attacks in power networks: A waveform relaxation approach. In 2011 49th Annual Allerton Conference on Communication, Control, and Computing (Allerton), pages 1486–1491. IEEE, 2011.
[29] Moulik Choraria, Arpan Chattopadhyay, Urbashi Mitra, and Erik Strom. Optimal deception attack on networked vehicular cyber physical systems. In 2019 53rd Asilomar Conference on Signals, Systems, and Computers, pages 1131–1135. IEEE, 2019.
[30] Ashkan Moradi, Naveen KD Venkategowda, and Stefan Werner. Coordinated data-falsiﬁcation attacks in consensus-based distributed kalman ﬁltering. In 2019 IEEE 8th International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP), pages 495– 499. IEEE, 2019.
[31] An-Yang Lu and Guang-Hong Yang. Malicious attacks on state estimation against distributed control systems. IEEE Transactions on Automatic Control, 65(9):3911–3918, 2019.
[32] H Vincent Poor and Olympia Hadjiliadis. Quickest detection, volume 40. Cambridge University Press Cambridge, 2009.
[33] J.C. Spall. Multivariate stochastic approximation using a simultaneous perturbation gradient approximation. IEEE Transactions on Automatic Control, 37(3):332–341, 1992.
[34] Vivek S. Borkar. Stochastic approximation: a dynamical systems viewpoint. Cambridge University Press, 2008.
[35] Brian DO Anderson and John B Moore. Optimal ﬁltering. Englewood Cliffs, 21:22–95, 1979.
[36] H Vincent Poor and Olympia Hadjiliadis. Quickest detection. Cambridge University Press, 2008.
[37] D.P. Bertsekas. Dynamic Programming and Optimal Control, Vol. I. Athena Scientiﬁc, 2007.
[38] L.E. L. Theory of Point Estimation. Wiley series in probability and mathematical statistics. John Wiley and sons, 1983.
[39] K. Premkumar and A. Kumar. Optimal sleep-wake scheduling for quickest intrusion detection using wireless sensor networks. In IEEE INFOCOM 2008 - The 27th Conference on Computer Communications, pages 1400–1408, 2008.
[40] Tze Leung Lai. Information bounds and quick detection of parameter changes in stochastic systems. IEEE Transactions on Information Theory, 44(7):2917–2929, 1998.
[41] E. S. PAGE. CONTINUOUS INSPECTION SCHEMES. Biometrika, 41(1-2):100–115, 06 1954.
[42] G. Lorden. Procedures for Reacting to a Change in Distribution. The Annals of Mathematical Statistics, 42(6):1897 – 1908, 1971.
[43] George V. Moustakides. Optimal Stopping Times for Detecting Changes in Distributions. The Annals of Statistics, 14(4):1379 – 1387, 1986.
[44] Y. Ritov. Decision Theoretic Optimality of the Cusum Procedure. The Annals of Statistics, 18(3):1464 – 1469, 1990.
[45] Moshe Pollak. Optimal Detection of a Change in Distribution. The Annals of Statistics, 13(1):206 – 227, 1985.
[46] Venugopal V. Veeravalli and Taposh Banerjee. Quickest change detection, 2012.

