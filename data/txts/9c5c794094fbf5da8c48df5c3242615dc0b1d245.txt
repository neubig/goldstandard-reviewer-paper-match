Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

arXiv:1811.12359v4 [cs.LG] 18 Jun 2019

Francesco Locatello 1 2 Stefan Bauer 2 Mario Lucic 3 Gunnar Rätsch 1 Sylvain Gelly 3 Bernhard Schölkopf 2 Olivier Bachem 3

Abstract
The key idea behind the unsupervised learning of disentangled representations is that real-world data is generated by a few explanatory factors of variation which can be recovered by unsupervised learning algorithms. In this paper, we provide a sober look at recent progress in the ﬁeld and challenge some common assumptions. We ﬁrst theoretically show that the unsupervised learning of disentangled representations is fundamentally impossible without inductive biases on both the models and the data. Then, we train more than 12 000 models covering most prominent methods and evaluation metrics in a reproducible large-scale experimental study on seven different data sets. We observe that while the different methods successfully enforce properties “encouraged” by the corresponding losses, well-disentangled models seemingly cannot be identiﬁed without supervision. Furthermore, increased disentanglement does not seem to lead to a decreased sample complexity of learning for downstream tasks. Our results suggest that future work on disentanglement learning should be explicit about the role of inductive biases and (implicit) supervision, investigate concrete beneﬁts of enforcing disentanglement of the learned representations, and consider a reproducible experimental setup covering several data sets.
1. Introduction
In representation learning it is often assumed that real-world observations x (e.g., images or videos) are generated by
1ETH Zurich, Department for Computer Science 2MaxPlanck Institute for Intelligent Systems 3Google Research, Brain Team. Correspondence to: Francesco Locatello <francesco.locatello@tuebingen.mpg.de>, Olivier Bachem <bachem@google.com>.
Proceedings of the 36 th International Conference on Machine Learning, Long Beach, California, PMLR 97, 2019. Copyright 2019 by the author(s).

a two-step generative process. First, a multivariate latent random variable z is sampled from a distribution P (z). Intuitively, z corresponds to semantically meaningful factors of variation of the observations (e.g., content + position of objects in an image). Then, in a second step, the observation x is sampled from the conditional distribution P (x|z). The key idea behind this model is that the high-dimensional data x can be explained by the substantially lower dimensional and semantically meaningful latent variable z which is mapped to the higher-dimensional space of observations x. Informally, the goal of representation learning is to ﬁnd useful transformations r(x) of x that “make it easier to extract useful information when building classiﬁers or other predictors” (Bengio et al., 2013).
A recent line of work has argued that representations that are disentangled are an important step towards a better representation learning (Bengio et al., 2013; Peters et al., 2017; LeCun et al., 2015; Bengio et al., 2007; Schmidhuber, 1992; Lake et al., 2017; Tschannen et al., 2018). They should contain all the information present in x in a compact and interpretable structure (Bengio et al., 2013; Kulkarni et al., 2015; Chen et al., 2016) while being independent from the task at hand (Goodfellow et al., 2009; Lenc & Vedaldi, 2015). They should be useful for (semi-)supervised learning of downstream tasks, transfer and few shot learning (Bengio et al., 2013; Schölkopf et al., 2012; Peters et al., 2017). They should enable to integrate out nuisance factors (Kumar et al., 2017), to perform interventions, and to answer counterfactual questions (Pearl, 2009; Spirtes et al., 1993; Peters et al., 2017).
While there is no single formalized notion of disentanglement (yet) which is widely accepted, the key intuition is that a disentangled representation should separate the distinct, informative factors of variations in the data (Bengio et al., 2013). A change in a single underlying factor of variation zi should lead to a change in a single factor in the learned representation r(x). This assumption can be extended to groups of factors as, for instance, in Bouchacourt et al. (2018) or Suter et al. (2018). Based on this idea, a variety of disentanglement evaluation protocols have been proposed leveraging the statistical relations between the learned

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

representation and the ground-truth factor of variations. Disentanglement is then measured as a particular structural property of these relations (Higgins et al., 2017a; Kim & Mnih, 2018; Eastwood & Williams, 2018; Kumar et al., 2017; Chen et al., 2018; Ridgeway & Mozer, 2018).
State-of-the-art approaches for unsupervised disentanglement learning are largely based on Variational Autoencoders (VAEs) (Kingma & Welling, 2014): One assumes a speciﬁc prior P (z) on the latent space and then uses a deep neural network to parameterize the conditional probability P (x|z). Similarly, the distribution P (z|x) is approximated using a variational distribution Q(z|x), again parametrized using a deep neural network. The model is then trained by minimizing a suitable approximation to the negative log-likelihood. The representation for r(x) is usually taken to be the mean of the approximate posterior distribution Q(z|x). Several variations of VAEs were proposed with the motivation that they lead to better disentanglement (Higgins et al., 2017a; Burgess et al., 2017; Kim & Mnih, 2018; Chen et al., 2018; Kumar et al., 2017; Rubenstein et al., 2018). The common theme behind all these approaches is that they try to enforce a factorized aggregated posterior x Q(z|x)P (x)dx, which should encourage disentanglement.
Our contributions. In this paper, we challenge commonly held assumptions in this ﬁeld in both theory and practice. Our key contributions can be summarized as follows:
• We theoretically prove that (perhaps unsurprisingly) the unsupervised learning of disentangled representations is fundamentally impossible without inductive biases both on the considered learning approaches and the data sets.
• We investigate current approaches and their inductive biases in a reproducible large-scale experimental study1 with a sound experimental protocol for unsupervised disentanglement learning. We implement six recent unsupervised disentanglement learning methods as well as six disentanglement measures from scratch and train more than 12 000 models on seven data sets.
• We release disentanglement_lib2, a new library to train and evaluate disentangled representations. As reproducing our results requires substantial computational effort, we also release more than 10 000 trained models which can be used as baselines for future research.
• We analyze our experimental results and challenge common beliefs in unsupervised disentanglement learning: (i) While all considered methods prove effective at ensuring that the individual dimensions of the aggregated posterior (which is sampled) are not correlated, we observe that the
1Reproducing these experiments requires approximately 2.52 GPU years (NVIDIA P100).
2https://github.com/google-research/ disentanglement_lib

dimensions of the representation (which is taken to be the mean) are correlated. (ii) We do not ﬁnd any evidence that the considered models can be used to reliably learn disentangled representations in an unsupervised manner as random seeds and hyperparameters seem to matter more than the model choice. Furthermore, good trained models seemingly cannot be identiﬁed without access to ground-truth labels even if we are allowed to transfer good hyperparameter values across data sets. (iii) For the considered models and data sets, we cannot validate the assumption that disentanglement is useful for downstream tasks, for example through a decreased sample complexity of learning.
• Based on these empirical evidence, we suggest three critical areas of further research: (i) The role of inductive biases and implicit and explicit supervision should be made explicit: unsupervised model selection persists as a key question. (ii) The concrete practical beneﬁts of enforcing a speciﬁc notion of disentanglement of the learned representations should be demonstrated. (iii) Experiments should be conducted in a reproducible experimental setup on data sets of varying degrees of difﬁculty.
2. Other related work
In a similar spirit to disentanglement, (non-)linear independent component analysis (Comon, 1994; Bach & Jordan, 2002; Jutten & Karhunen, 2003; Hyvarinen & Morioka, 2016) studies the problem of recovering independent components of a signal. The underlying assumption is that there is a generative model for the signal composed of the combination of statistically independent non-Gaussian components. While the identiﬁability result for linear ICA (Comon, 1994) proved to be a milestone for the classical theory of factor analysis, similar results are in general not obtainable for the nonlinear case and the underlying sources generating the data cannot be identiﬁed (Hyvarinen & Pajunen, 1999). The lack of almost any identiﬁability result in nonlinear ICA has been a main bottleneck for the utility of the approach (Hyvarinen et al., 2018) and partially motivated alternative machine learning approaches (Desjardins et al., 2012; Schmidhuber, 1992; Cohen & Welling, 2015). Given that unsupervised algorithms did not initially perform well on realistic settings most of the other works have considered some more or less explicit form of supervision (Reed et al., 2014; Zhu et al., 2014; Yang et al., 2015; Kulkarni et al., 2015; Cheung et al., 2015; Mathieu et al., 2016; Narayanaswamy et al., 2017; Suter et al., 2018). (Hinton et al., 2011; Cohen & Welling, 2014) assume some knowledge of the effect of the factors of variations even though they are not observed. One can also exploit known relations between factors in different samples (Karaletsos et al., 2015; Goroshin et al., 2015; Whitney et al., 2016; Fraccaro et al.,

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

2017; Denton & Birodkar, 2017; Hsu et al., 2017; Yingzhen & Mandt, 2018) or explicit inductive biases (Locatello et al., 2018). This is not a limiting assumption especially in sequential data, i.e., for videos. We focus our study on the setting where factors of variations are not observable at all, i.e. we only observe samples from P (x).

3. Impossibility result

The ﬁrst question that we investigate is whether unsupervised disentanglement learning is even possible for arbitrary generative models. Theorem 1 essentially shows that without inductive biases both on models and data sets the task is fundamentally impossible. The proof is provided in Appendix A.

Theorem 1. For d > 1, let z ∼ P denote any distribution

which admits a density p(z) =

d i=1

p(zi

).

Then, there

exists an inﬁnite family of bijective functions f : supp(z) →

supp(z) such that ∂f∂iu(ju) = 0 almost everywhere for all

i and j (i.e., z and f (z) are completely entangled) and

P (z ≤ u) = P (f (z) ≤ u) for all u ∈ supp(z) (i.e., they

have the same marginal distribution).

Consider the commonly used “intuitive” notion of disentanglement which advocates that a change in a single groundtruth factor should lead to a single change in the representation. In that setting, Theorem 1 implies that unsupervised disentanglement learning is impossible for arbitrary generative models with a factorized prior3 in the following sense: Assume we have p(z) and some P (x|z) deﬁning a generative model. Consider any unsupervised disentanglement method and assume that it ﬁnds a representation r(x) that is perfectly disentangled with respect to z in the generative model. Then, Theorem 1 implies that there is an equivalent generative model with the latent variable zˆ = f (z) where zˆ is completely entangled with respect to z and thus also r(x): as all the entries in the Jacobian of f are non-zero, a change in a single dimension of z implies that all dimensions of zˆ change. Furthermore, since f is deterministic and p(z) = p(zˆ) almost everywhere, both generative models have the same marginal distribution of the observations x by construction, i.e., P (x) = p(x|z)p(z)dz = p(x|zˆ)p(zˆ)dzˆ. Since the (unsupervised) disentanglement method only has access to observations x, it hence cannot distinguish between the two equivalent generative models and thus has to be entangled to at least one of them.
This may not be surprising to readers familiar with the causality and ICA literature as it is consistent with the following argument: After observing x, we can construct
3Theorem 1 only applies to factorized priors; however, we expect that a similar result can be extended to non-factorizing priors.

inﬁnitely many generative models which have the same marginal distribution of x. Any one of these models could be the true causal generative model for the data, and the right model cannot be identiﬁed given only the distribution of x (Peters et al., 2017). Similar results have been obtained in the context of non-linear ICA (Hyvarinen & Pajunen, 1999). The main novelty of Theorem 1 is that it allows the explicit construction of latent spaces z and zˆ that are completely entangled with each other in the sense of (Bengio et al., 2013). We note that while this result is very intuitive for multivariate Gaussians it also holds for distributions which are not invariant to rotation, for example multivariate uniform distributions.
While Theorem 1 shows that unsupervised disentanglement learning is fundamentally impossible for arbitrary generative models, this does not necessarily mean it is an impossible endeavour in practice. After all, real world generative models may have a certain structure that could be exploited through suitably chosen inductive biases. However, Theorem 1 clearly shows that inductive biases are required both for the models (so that we ﬁnd a speciﬁc set of solutions) and for the data sets (such that these solutions match the true generative model). We hence argue that the role of inductive biases should be made explicit and investigated further as done in the following experimental study.
4. Experimental design
Considered methods. All the considered methods augment the VAE loss with a regularizer: The β-VAE (Higgins et al., 2017a), introduces a hyperparameter in front of the KL regularizer of vanilla VAEs to constrain the capacity of the VAE bottleneck. The AnnealedVAE (Burgess et al., 2017) progressively increase the bottleneck capacity so that the encoder can focus on learning one factor of variation at the time (the one that most contribute to a small reconstruction error). The FactorVAE (Kim & Mnih, 2018) and the β-TCVAE (Chen et al., 2018) penalize the total correlation (Watanabe, 1960) with adversarial training (Nguyen et al., 2010; Sugiyama et al., 2012) or with a tractable but biased Monte-Carlo estimator respectively. The DIP-VAE-I and the DIP-VAE-II (Kumar et al., 2017) both penalize the mismatch between the aggregated posterior and a factorized prior. Implementation details and further discussion on the methods can be found in Appendix B and G.
Considered metrics. The BetaVAE metric (Higgins et al., 2017a) measures disentanglement as the accuracy of a linear classiﬁer that predicts the index of a ﬁxed factor of variation. Kim & Mnih (2018) address several issues with this metric in their FactorVAE metric by using a majority vote classiﬁer on a different feature vector which accounts for a corner case in the BetaVAE metric. The Mutual Information Gap (MIG) (Chen et al., 2018) measures for each factor of vari-

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

ation the normalized gap in mutual information between the highest and second highest coordinate in r(x). Instead, the Modularity (Ridgeway & Mozer, 2018) measures if each dimension of r(x) depends on at most a factor of variation using their mutual information. The Disentanglement metric of Eastwood & Williams (2018) (which we call DCI Disentanglement for clarity) computes the entropy of the distribution obtained by normalizing the importance of each dimension of the learned representation for predicting the value of a factor of variation. The SAP score (Kumar et al., 2017) is the average difference of the prediction error of the two most predictive latent dimensions for each factor. Implementation details and further descriptions can be found in Appendix C.
Data sets. We consider four data sets in which x is obtained as a deterministic function of z: dSprites (Higgins et al., 2017a), Cars3D (Reed et al., 2015), SmallNORB (LeCun et al., 2004), Shapes3D (Kim & Mnih, 2018). We also introduce three data sets where the observations x are stochastic given the factor of variations z: Color-dSprites, Noisy-dSprites and Scream-dSprites. In Color-dSprites, the shapes are colored with a random color. In Noisy-dSprites, we consider white-colored shapes on a noisy background. Finally, in Scream-dSprites the background is replaced with a random patch in a random color shade extracted from the famous The Scream painting (Munch, 1893). The dSprites shape is embedded into the image by inverting the color of its pixels. Further details on the preprocessing of the data can be found in Appendix H.
Inductive biases. To fairly evaluate the different approaches, we separate the effect of regularization (in the form of model choice and regularization strength) from the other inductive biases (e.g., the choice of the neural architecture). Each method uses the same convolutional architecture, optimizer, hyperparameters of the optimizer and batch size. All methods use a Gaussian encoder where the mean and the log variance of each latent factor is parametrized by the deep neural network, a Bernoulli decoder and latent dimension ﬁxed to 10. We note that these are all standard choices in prior work (Higgins et al., 2017a; Kim & Mnih, 2018).
We choose six different regularization strengths, i.e., hyperparameter values, for each of the considered methods. The key idea was to take a wide enough set to ensure that there are useful hyperparameters for different settings for each method and not to focus on speciﬁc values known to work for speciﬁc data sets. However, the values are partially based on the ranges that are prescribed in the literature (including the hyperparameters suggested by the authors).
We ﬁx our experimental setup in advance and we run all the considered methods on each data set for 50 different random seeds and evaluate them on the considered metrics. The full details on the experimental setup are provided in the Appendix G. Our experimental setup, the limitations of this

study, and the differences with previous implementations are extensively discussed in Appendices D-F.

5. Key experimental results
In this section, we highlight our key ﬁndings with plots speciﬁcally picked to be representative of our main results. In Appendix I, we provide the full experimental results with a complete set of plots for different methods, data sets and disentanglement metrics.

5.1. Can current methods enforce a uncorrelated aggregated posterior and representation?

While many of the considered methods aim to enforce a factorizing and thus uncorrelated aggregated posterior (e.g., regularizing the total correlation of the sampled representation), they use the mean vector of the Gaussian encoder as the representation and not a sample from the Gaussian encoder. This may seem like a minor, irrelevant modiﬁcation; however, it is not clear whether a factorizing aggregated posterior also ensures that the dimensions of the mean representation are uncorrelated. To test the impact of this, we compute the total correlation of both the mean and the sampled representation based on ﬁtting Gaussian distributions for each data set, model and hyperparameter value (see Appendix C and I.2 for details).

Figure 1 (left) shows the total correlation based on a ﬁtted Gaussian of the sampled representation plotted against the regularization strength for each method except AnnealedVAE on Color-dSprites. We observe that the total correlation of the sampled representation generally decreases with the regularization strength. One the other hand, Figure 1 (right) shows the total correlation of the mean representation plotted against the regularization strength. It is evident that the total correlation of the mean representation generally increases with the regularization strength. The only exception is DIP-VAE-I for which we observe that the total correlation

VAE

β-VAE

FactorVAE

β-TCVAE

DIP-VAE-I

DIP-VAE-II

Value

0.12

Metric = TC (sampled)

0.8

Metric = TC (mean)

0.10

0.7

0.6

0.08

0.5

0.06

0.4

0.04

0.3

0.2

0.02

0.1

0.00

0.0

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

Regularization strength

Regularization strength

Figure 1. Total correlation based on a ﬁtted Gaussian of the sampled (left) and the mean representation (right) plotted against regularization strength for Color-dSprites and approaches (except AnnealedVAE). The total correlation of the sampled representation decreases while the total correlation of the mean representation increases as the regularization strength is increased.

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

of the mean representation is consistently low. This is not surprising as the DIP-VAE-I objective directly optimizes the covariance matrix of the mean representation to be diagonal which implies that the corresponding total correlation (as we measure it) is low. These ﬁndings are conﬁrmed by our detailed experimental results in Appendix I.2 (in particular Figures 8-9) which considers all different data sets. Furthermore, we observe largely the same pattern if we consider the average mutual information between different dimension of the representation instead of the total correlation (see Figures 27-28 in Appendix J).
Implications. Overall, these results lead us to conclude with minor exceptions that the considered methods are effective at enforcing an aggregated posterior whose individual dimensions are not correlated but that this does not seem to imply that the dimensions of the mean representation (usually used for representation) are uncorrelated.
Dataset = Noisy-dSprites BetaVAE Score (A) 100 80 44 41 46 37 FactorVAE Score (B) 80 100 49 52 25 38
MIG (C) 44 49 100 76 6 42 DCI Disentanglement (D) 41 52 76 100 -8 38
Modularity (E) 46 25 6 -8 100 13 SAP (F) 37 38 42 38 13 100 (A) (B) (C) (D) (E) (F)
Figure 2. Rank correlation of different metrics on Noisy-dSprites. Overall, we observe that all metrics except Modularity seem mildly correlated with the pairs BetaVAE and FactorVAE, and MIG and DCI Disentanglement strongly correlated with each other.
5.2. How much do the disentanglement metrics agree?
As there exists no single, common deﬁnition of disentanglement, an interesting question is to see how much different proposed metrics agree. Figure 2 shows the Spearman rank correlation between different disentanglement metrics on Noisy-dSprites whereas Figure 12 in Appendix I.3 shows the correlation for all the different data sets. We observe that all metrics except Modularity seem to be correlated strongly on the data sets dSprites, Color-dSprites and Scream-dSprites and mildly on the other data sets. There appear to be two pairs among these metrics that capture particularly similar notions: the BetaVAE and the FactorVAE score as well as the MIG and DCI Disentanglement.
Implication. All disentanglement metrics except Modularity appear to be correlated. However, the level of correlation changes between different data sets.
5.3. How important are different models and hyperparameters for disentanglement?
The primary motivation behind the considered methods is that they should lead to improved disentanglement. This

Value Value

Model = FactorVAE Dataset = Cars3D

1.00 Metric = FactorVAE Score 0.95 0.90 0.85 0.80 0.75 0.70 0.65 0.60 0 1 2 3 4 5
Model

1.00 Metric = FactorVAE Score 0.95 0.90 0.85 0.80 0.75 0.70 0.65 0.60 0.0 0.2 0.4 0.6 0.8 1.0
Regularization strength

Figure 3. (left) FactorVAE score for each method on Cars3D. Models are abbreviated (0=β-VAE, 1=FactorVAE, 2=β-TCVAE, 3=DIP-VAE-I, 4=DIP-VAE-II, 5=AnnealedVAE). The variance is due to different hyperparameters and random seeds. The scores are heavily overlapping. (right) Distribution of FactorVAE scores for FactorVAE model for different regularization strengths on Cars3D. In this case, the variance is only due to the different random seeds. We observe that randomness (in the form of different random seeds) has a substantial impact on the attained result and that a good run with a bad hyperparameter can beat a bad run with a good hyperparameter.

raises the question how disentanglement is affected by the model choice, the hyperparameter selection and randomness (in the form of different random seeds). To investigate this, we compute all the considered disentanglement metrics for each of our trained models.
In Figure 3 (left), we show the range of attainable FactorVAE scores for each method on Cars3D. We observe that these ranges are heavily overlapping for different models leading us to (qualitatively) conclude that the choice of hyperparameters and the random seed seems to be substantially more important than the choice of objective function. These results are conﬁrmed by the full experimental results on all the data sets presented in Figure 13 of Appendix I.4: While certain models seem to attain better maximum scores on speciﬁc data sets and disentanglement metrics, we do not observe any consistent pattern that one model is consistently better than the other. At this point, we note that in our study we have ﬁxed the range of hyperparameters a priori to six different values for each model and did not explore additional hyperparameters based on the results (as that would bias our study). However, this also means that speciﬁc models may have performed better than in Figure 13 (left) if we had chosen a different set of hyperparameters.
In Figure 3 (right), we further show the impact of randomness in the form of random seeds on the disentanglement scores. Each violin plot shows the distribution of the FactorVAE metric across all 50 trained FactorVAE models for each hyperparameter setting on Cars3D. We clearly see that randomness (in the form of different random seeds) has a substantial impact on the attained result and that a good run with a bad hyperparameter can beat a bad run with a good hyperparameter in many cases. Again, these ﬁndings

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Value

β-VAE FactorVAE

β-TCVAE DIP-VAE-I

DIP-VAE-II AnnealedVAE

Dataset = Shapes3D

0.95 Dataset = Cars3D | Metric = FactorVAE Score Reconstruction -30 -4 59 22 -21 27

Metric = DCI Disentanglement dSprites (I) 100 95 65 65 34 64 46 Color-dSprites (II) 95 100 61 60 21 63 47

0.90

TC (sampled) 1 5 -11 -8 -11 -2 Noisy-dSprites (III) 65 61 100 68 17 64 59

0.85

Scream-dSprites (IV) 65 60 68 100 36 93 69

0.80

KL -14 -1 -38 -31 -11 -29

SmallNORB (V) 34 21 17 36 100 21 -9

0.75 0.70
0.0 0.2 0.4 0.6 0.8 1.0 Regularization strength

ELBO -38 -9 48 9 -25 15 (A) (B) (C) (D) (E) (F)

Cars3D (VI) 64 63 64 93 21 100 85 Shapes3D (VII) 46 47 59 69 -9 85 100
(I) (II) (III) (IV) (V) (VI) VII

Figure 4. (left) FactorVAE score vs hyperparameters for each score on Cars3d. There seems to be no model dominating all the others and for each model there does not seem to be a consistent strategy in choosing the regularization strength. (center) Unsupervised scores vs disentanglement metrics on Shapes3D. Metrics are abbreviated ((A)=BetaVAE Score, (B)=FactorVAE Score, (C)=MIG , (D)=DCI Disentanglement, (E)=Modularity, (F)=SAP). The unsupervised scores we consider do not seem to be useful for model selection. (right) Rank-correlation of DCI disentanglement metric across different data sets. Good hyperparameters only seem to transfer between dSprites and Color-dSprites but not in between the other data sets.

are consistent with the complete set of plots provided in Figure 14 of Appendix I.4.
Finally, we perform a variance analysis by trying to predict the different disentanglement scores using ordinary least squares for each data set: If we allow the score to depend only on the objective function (treated as a categorical variable), we are only able to explain 37% of the variance of the scores on average (see Table 5 in Appendix I.4 for further details). Similarly, if the score depends on the Cartesian product of objective function and regularization strength (again categorical), we are able to explain 59% of the variance while the rest is due to the random seed.
Implication. The disentanglement scores of unsupervised models are heavily inﬂuenced by randomness (in the form of the random seed) and the choice of the hyperparameter (in the form of the regularization strength). The objective function appears to have less impact.
5.4. Are there reliable recipes for model selection?
In this section, we investigate how good hyperparameters can be chosen and how we can distinguish between good and bad training runs. In this paper, we advocate that that model selection should not depend on the considered disentanglement score for the following reasons: The point of unsupervised learning of disentangled representation is that there is no access to the labels as otherwise we could incorporate them and would have to compare to semi-supervised and fully supervised methods. All the disentanglement metrics considered in this paper require a substantial amount of ground-truth labels or the full generative model (for example for the BetaVAE and the FactorVAE metric). Hence, one may substantially bias the results of a study by tuning hyperparameters based on (supervised) disentanglement metrics. Furthermore, we argue that it is not sufﬁcient to ﬁx a set of hyperparameters a priori and then show that one of those hyperparameters and a speciﬁc random seed achieves a good disentanglement score as it amounts to showing the

existence of a good model, but does not guide the practitioner in ﬁnding it. Finally, in many practical settings, we might not even have access to adequate labels as it may be hard to identify the true underlying factor of variations, in particular, if we consider data modalities that are less suitable to human interpretation than images.
In the remainder of this section, we hence investigate and assess different ways how hyperparameters and good model runs could be chosen. In this study, we focus on choosing the learning model and the regularization strength corresponding to that loss function. However, we note that in practice this problem is likely even harder as a practitioner might also want to tune other modeling choices such architecture or optimizer.
General recipes for hyperparameter selection. We ﬁrst investigate whether we may ﬁnd generally applicable “rules of thumb” for choosing the hyperparameters. For this, we plot in Figure 4 (left) the FactorVAE score against different regularization strengths for each model on the Cars3D data set whereas Figure 16 in Appendix I.5 shows the same plot for all data sets and disentanglement metrics. The values correspond to the median obtained values across 50 random seeds for each model, hyperparameter and data set. Overall, there seems to be no model consistently dominating all the others and for each model there does not seem to be a consistent strategy in choosing the regularization strength to maximize disentanglement scores. Furthermore, even if we could identify a good objective function and corresponding hyperparameter value, we still could not distinguish between a good and a bad training run.
Model selection based on unsupervised scores. Another approach could be to select hyperparameters based on unsupervised scores such as the reconstruction error, the KL divergence between the prior and the approximate posterior, the Evidence Lower BOund or the estimated total correlation of the sampled representation (mean representation gives similar results). This would have the advantage that

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Table 1. Probability of outperforming random model selection on a different random seed. A random disentanglement metric and data set is sampled and used for model selection. That model is then compared to a randomly selected model: (i) on the same metric and data set, (ii) on the same metric and a random different data set, (iii) on a random different metric and the same data set, and (iv) on a random different metric and a random different data set. The results are averaged across 10 000 random draws.

Dataset = dSprites BetaVAE Score 18 65 28 28 67 78 75 76 50 50 FactorVAE Score 13 49 13 12 58 73 71 71 43 46
MIG 18 63 20 -1 71 86 86 87 62 47 DCI Disentanglement 19 65 18 4 75 94 94 94 62 54
Modularity -3 -9 15 18 -6 -17 -19 -13 -19 -14 SAP 12 64 20 12 71 77 74 75 56 49

LR10 LR100 LR1000 LR10000 GBT10 GBT100 GBT1000 GBT10000 Efficiency (LR) Efficiency (GBT)

Random metric Same metric

Random data set
54.9% 59.3%

Same data set
62.6% 80.7%

Figure 5. Rank correlations between disentanglement metrics and downstream performance (accuracy and efﬁciency) on dSprites.

we could select speciﬁc trained models and not just good hyperparameter settings whose median trained model would perform well. To test whether such an approach is fruitful, we compute the rank correlation between these unsupervised metrics and the disentanglement metrics and present it in Figure 4 (center) for Shapes3D and in Figure 16 of Appendix I.5 for all the different data sets. While we do observe some correlations, no clear pattern emerges which leads us to conclude that this approach is unlikely to be successful in practice.
Hyperparameter selection based on transfer. The ﬁnal strategy for hyperparameter selection that we consider is based on transferring good settings across data sets. The key idea is that good hyperparameter settings may be inferred on data sets where we have labels available (such as dSprites) and then applied to novel data sets. Figure 4 (right) shows the rank correlations obtained between different data sets for the DCI disentanglement (whereas Figure 17 in Appendix I.5 shows it for all data sets). We ﬁnd a strong and consistent correlation between dSprites and Color-dSprites. While these results suggest that some transfer of hyperparameters is possible, it does not allow us to distinguish between good and bad random seeds on the target data set.
To illustrate this, we compare such a transfer based approach to hyperparameter selection to random model selection as follows: First, we sample one of our 50 random seeds, a random disentanglement metric and a data set and use them to select the hyperparameter setting with the highest attained score. Then, we compare that selected hyperparameter setting to a randomly selected model on either the same or a random different data set, based on either the same or a random different metric and for a randomly sampled seed. Finally, we report the percentage of trials in which this transfer strategy outperforms or performs equally well as random model selection across 10 000 trials in Table 1. If we choose the same metric and the same data set (but a different random seed), we obtain a score of 80.7%. If we aim to transfer for the same metric across data sets, we achieve around 59.3%. Finally, if we transfer both across metrics and data sets, our performance drops to 54.9%.

Implications. Unsupervised model selection remains an unsolved problem. Transfer of good hyperparameters between metrics and data sets does not seem to work as there appears to be no unsupervised way to distinguish between good and bad random seeds on the target task.
5.5. Are these disentangled representations useful for downstream tasks in terms of the sample complexity of learning?
One of the key motivations behind disentangled representations is that they are assumed to be useful for later downstream tasks. In particular, it is argued that disentanglement should lead to a better sample complexity of learning (Bengio et al., 2013; Schölkopf et al., 2012; Peters et al., 2017). In this section, we consider the simplest downstream classiﬁcation task where the goal is to recover the true factors of variations from the learned representation using either multi-class logistic regression (LR) or gradient boosted trees (GBT).
Figure 5 shows the rank correlations between the disentanglement metrics and the downstream performance on dSprites. We observe that all metrics except Modularity seem to be correlated with increased downstream performance on the different variations of dSprites and to some degree on Shapes3D but not on the other data sets. However, it is not clear whether this is due to the fact that disentangled representations perform better or whether some of these scores actually also (partially) capture the informativeness of the evaluated representation. Furthermore, the full results in Figure 19 of Appendix I.6 indicate that the correlation is weaker or inexistent on other data sets (e.g. Cars3D).
To assess the sample complexity argument we compute for each trained model a statistical efﬁciency score which we deﬁne as the average accuracy based on 100 samples divided by the average accuracy based on 10 000 samples. Figure 6 show the sample efﬁciency of learning (based on GBT) versus the FactorVAE Score on dSprites. We do not observe that higher disentanglement scores reliably lead to a higher sample efﬁciency. This ﬁnding which appears to be consistent with the results in Figures 20-23 of Appendix I.6.

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Efficiency (GBT)

Dataset = dSprites

β-VAE FactorVAE

β-TCVAE DIP-VAE-I

DIP-VAE-II AnnealedVAE

Metric = FactorVAE Score

0.64

0.56

0.48

0.40

0.2

0.4

0.6

0.8

1.0

Value

Figure 6. Statistical efﬁciency of the FactorVAE Score for learning a GBT downstream task on dSprites.

Implications. While the empirical results in this section are negative, they should also be interpreted with care. After all, we have seen in previous sections that the models considered in this study fail to reliably produce disentangled representations. Hence, the results in this section might change if one were to consider a different set of models, for example semi-supervised or fully supervised one. Furthermore, there are many more potential notions of usefulness such as interpretability and fairness that we have not considered in our experimental evaluation. Nevertheless, we argue that the lack of concrete examples of useful disentangled representations necessitates that future work on disentanglement methods should make this point more explicit. While prior work (Steenbrugge et al., 2018; Laversanne-Finot et al., 2018; Nair et al., 2018; Higgins et al., 2017b; 2018) successfully applied disentanglement methods such as β-VAE on a variety of downstream tasks, it is not clear to us that these approaches and trained models performed well because of disentanglement.
6. Conclusions
In this work we ﬁrst theoretically show that the unsupervised learning of disentangled representations is fundamentally impossible without inductive biases. We then performed a large-scale empirical study with six state-of-the-art disentanglement methods, six disentanglement metrics on seven data sets and conclude the following: (i) A factorizing aggregated posterior (which is sampled) does not seem to necessarily imply that the dimensions in the representation (which is taken to be the mean) are uncorrelated. (ii) Random seeds and hyperparameters seem to matter more than the model but tuning seem to require supervision. (iii) We did not observe that increased disentanglement implies a decreased sample complexity of learning downstream tasks. Based on these ﬁndings, we suggest three main directions for future research:

Inductive biases and implicit and explicit supervision. Our theoretical impossibility result in Section 3 highlights the need of inductive biases while our experimental results indicate that the role of supervision is crucial. As currently there does not seem to exist a reliable strategy to choose hyperparameters in the unsupervised learning of disentangled representations, we argue that future work should make the role of inductive biases and implicit and explicit supervision more explicit. We would encourage and motivate future work on disentangled representation learning that deviates from the static, purely unsupervised setting considered in this work. Promising settings (that have been explored to some degree) seem to be for example (i) disentanglement learning with interactions (Thomas et al., 2017), (ii) when weak forms of supervision e.g. through grouping information are available (Bouchacourt et al., 2018), or (iii) when temporal structure is available for the learning problem. The last setting seems to be particularly interesting given recent identiﬁability results in non-linear ICA (Hyvarinen & Morioka, 2016).
Concrete practical beneﬁts of disentangled representations. In our experiments we investigated whether higher disentanglement scores lead to increased sample efﬁciency for downstream tasks and did not ﬁnd evidence that this is the case. While these results only apply to the setting and downstream task used in our study, we are also not aware of other prior work that compellingly shows the usefulness of disentangled representations. Hence, we argue that future work should aim to show concrete beneﬁts of disentangled representations. Interpretability and fairness as well as interactive settings seem to be particularly promising candidates to evaluate usefulness. One potential approach to include inductive biases, offer interpretability, and generalization is the concept of independent causal mechanisms and the framework of causal inference (Pearl, 2009; Peters et al., 2017).
Experimental setup and diversity of data sets. Our study also highlights the need for a sound, robust, and reproducible experimental setup on a diverse set of data sets in order to draw valid conclusions. We have observed that it is easy to draw spurious conclusions from experimental results if one only considers a subset of methods, metrics and data sets. Hence, we argue that it is crucial for future work to perform experiments on a wide variety of data sets to see whether conclusions and insights are generally applicable. This is particularly important in the setting of disentanglement learning as experiments are largely performed on toy-like data sets. For this reason, we released disentanglement_lib, the library we created to train and evaluate the different disentanglement methods on multiple data sets. We also released more than 10 000 trained models to provide a solid baseline for future methods and metrics.

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Acknowledgements
The authors thank Ilya Tolstikhin, Paul Rubenstein and Josip Djolonga for helpful discussions and comments. This research was partially supported by the Max Planck ETH Center for Learning Systems and by an ETH core grant (to Gunnar Rätsch). This work was partially done while Francesco Locatello was at Google Research Zurich.
References
Arcones, M. A. and Gine, E. On the bootstrap of u and v statistics. The Annals of Statistics, pp. 655–674, 1992.
Bach, F. R. and Jordan, M. I. Kernel independent component analysis. Journal of machine learning research, 3(Jul): 1–48, 2002.
Bengio, Y., LeCun, Y., et al. Scaling learning algorithms towards ai. Large-scale kernel machines, 34(5):1–41, 2007.
Bengio, Y., Courville, A., and Vincent, P. Representation learning: A review and new perspectives. IEEE transactions on pattern analysis and machine intelligence, 35(8): 1798–1828, 2013.
Bouchacourt, D., Tomioka, R., and Nowozin, S. Multi-level variational autoencoder: Learning disentangled representations from grouped observations. In AAAI, 2018.

Cohen, T. S. and Welling, M. Transformation properties of learned visual representations. In International Conference on Learning Representations, 2015.
Comon, P. Independent component analysis, a new concept? Signal processing, 36(3):287–314, 1994.
Denton, E. L. and Birodkar, v. Unsupervised learning of disentangled representations from video. In Advances in Neural Information Processing Systems, pp. 4414–4423, 2017.
Desjardins, G., Courville, A., and Bengio, Y. Disentangling factors of variation via generative entangling. arXiv preprint arXiv:1210.5474, 2012.
Eastwood, C. and Williams, C. K. I. A framework for the quantitative evaluation of disentangled representations. In International Conference on Learning Representations, 2018.
Fraccaro, M., Kamronn, S., Paquet, U., and Winther, O. A disentangled recognition and nonlinear dynamics model for unsupervised learning. In Advances in Neural Information Processing Systems, pp. 3601–3610, 2017.
Goodfellow, I., Lee, H., Le, Q. V., Saxe, A., and Ng, A. Y. Measuring invariances in deep networks. In Advances in neural information processing systems, pp. 646–654, 2009.

Burgess, C. P., Higgins, I., Pal, A., Matthey, L., Watters, N., Desjardins, G., and Lerchner, A. Understanding disentangling in beta-vae. In Workshop on Learning Disentangled Representations at the 31st Conference on Neural Information Processing Systems, 2017.
Chen, T. Q., Li, X., Grosse, R. B., and Duvenaud, D. K. Isolating sources of disentanglement in variational autoencoders. In Advances in Neural Information Processing Systems, pp. 2615–2625, 2018.
Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., and Abbeel, P. Infogan: Interpretable representation learning by information maximizing generative adversarial nets. In Advances in Neural Information Processing Systems, pp. 2172–2180, 2016.
Cheung, B., Livezey, J. A., Bansal, A. K., and Olshausen, B. A. Discovering hidden factors of variation in deep networks. In Workshop at International Conference on Learning Representations, 2015.

Goroshin, R., Mathieu, M. F., and LeCun, Y. Learning to linearize under uncertainty. In Advances in Neural Information Processing Systems, pp. 1234–1242, 2015.
Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., Botvinick, M., Mohamed, S., and Lerchner, A. betavae: Learning basic visual concepts with a constrained variational framework. In International Conference on Learning Representations, 2017a.
Higgins, I., Pal, A., Rusu, A., Matthey, L., Burgess, C., Pritzel, A., Botvinick, M., Blundell, C., and Lerchner, A. Darla: Improving zero-shot transfer in reinforcement learning. In International Conference on Machine Learning, pp. 1480–1490, 2017b.
Higgins, I., Sonnerat, N., Matthey, L., Pal, A., Burgess, C. P., Bošnjak, M., Shanahan, M., Botvinick, M., Hassabis, D., and Lerchner, A. Scan: Learning hierarchical compositional visual concepts. In International Conference on Learning Representations, 2018.

Cohen, T. and Welling, M. Learning the irreducible representations of commutative lie groups. In International Conference on Machine Learning, pp. 1755–1763, 2014.

Hinton, G. E., Krizhevsky, A., and Wang, S. D. Transforming auto-encoders. In International Conference on Artiﬁcial Neural Networks, pp. 44–51. Springer, 2011.

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Hsu, W.-N., Zhang, Y., and Glass, J. Unsupervised learning of disentangled and interpretable representations from sequential data. In Advances in Neural Information Processing Systems, pp. 1878–1889, 2017.
Hyvarinen, A. and Morioka, H. Unsupervised feature extraction by time-contrastive learning and nonlinear ica. In Advances in Neural Information Processing Systems, pp. 3765–3773, 2016.
Hyvarinen, A. and Pajunen, P. Nonlinear independent component analysis: Existence and uniqueness results. Neural Networks, 12(3):429–439, 1999.
Hyvarinen, A., Sasaki, H., and Turner, R. E. Nonlinear ica using auxiliary variables and generalized contrastive learning. arXiv preprint arXiv:1805.08651, 2018.
Jutten, C. and Karhunen, J. Advances in nonlinear blind source separation. In Proc. of the 4th Int. Symp. on Independent Component Analysis and Blind Signal Separation (ICA2003), pp. 245–256, 2003.
Karaletsos, T., Belongie, S., and Rätsch, G. Bayesian representation learning with oracle constraints. arXiv preprint arXiv:1506.05011, 2015.
Kim, H. and Mnih, A. Disentangling by factorising. In Proceedings of the 35th International Conference on Machine Learning, pp. 2649–2658, 2018.
Kingma, D. P. and Welling, M. Auto-encoding variational bayes. In International Conference on Learning Representations, 2014.
Kulkarni, T. D., Whitney, W. F., Kohli, P., and Tenenbaum, J. Deep convolutional inverse graphics network. In Advances in neural information processing systems, pp. 2539–2547, 2015.
Kumar, A., Sattigeri, P., and Balakrishnan, A. Variational inference of disentangled latent concepts from unlabeled observations. In International Conference on Learning Representations, 2017.
Lake, B. M., Ullman, T. D., Tenenbaum, J. B., and Gershman, S. J. Building machines that learn and think like people. Behavioral and Brain Sciences, 40, 2017.
Laversanne-Finot, A., Pere, A., and Oudeyer, P.-Y. Curiosity driven exploration of learned disentangled goal spaces. In Conference on Robot Learning, pp. 487–504, 2018.
LeCun, Y., Huang, F. J., and Bottou, L. Learning methods for generic object recognition with invariance to pose and lighting. In Computer Vision and Pattern Recognition, 2004. CVPR 2004. Proceedings of the 2004 IEEE Computer Society Conference on, volume 2, pp. II–104. IEEE, 2004.

LeCun, Y., Bengio, Y., and Hinton, G. Deep learning. nature, 521(7553):436, 2015.
Lenc, K. and Vedaldi, A. Understanding image representations by measuring their equivariance and equivalence. In IEEE conference on computer vision and pattern recognition, pp. 991–999, 2015.
Locatello, F., Vincent, D., Tolstikhin, I., Rätsch, G., Gelly, S., and Schölkopf, B. Competitive training of mixtures of independent deep generative models. arXiv preprint arXiv:1804.11130, 2018.
Mathieu, M. F., Zhao, J. J., Zhao, J., Ramesh, A., Sprechmann, P., and LeCun, Y. Disentangling factors of variation in deep representation using adversarial training. In Advances in Neural Information Processing Systems, pp. 5040–5048, 2016.
Munch, E. The scream, 1893.
Nair, A. V., Pong, V., Dalal, M., Bahl, S., Lin, S., and Levine, S. Visual reinforcement learning with imagined goals. In Advances in Neural Information Processing Systems, pp. 9209–9220, 2018.
Narayanaswamy, S., Paige, T. B., Van de Meent, J.-W., Desmaison, A., Goodman, N., Kohli, P., Wood, F., and Torr, P. Learning disentangled representations with semisupervised deep generative models. In Advances in Neural Information Processing Systems, pp. 5925–5935, 2017.
Nguyen, X., Wainwright, M. J., and Jordan, M. I. Estimating divergence functionals and the likelihood ratio by convex risk minimization. IEEE Transactions on Information Theory, 56(11):5847–5861, 2010.
Pearl, J. Causality. Cambridge university press, 2009.
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., and Duchesnay, E. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825–2830, 2011.
Peters, J., Janzing, D., and Schölkopf, B. Elements of causal inference: foundations and learning algorithms. MIT press, 2017.
Reed, S., Sohn, K., Zhang, Y., and Lee, H. Learning to disentangle factors of variation with manifold interaction. In International Conference on Machine Learning, pp. 1431–1439, 2014.
Reed, S. E., Zhang, Y., Zhang, Y., and Lee, H. Deep visual analogy-making. In Advances in Neural Information Processing Systems, pp. 1252–1260, 2015.

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Ridgeway, K. and Mozer, M. C. Learning deep disentangled embeddings with the f-statistic loss. In Advances in Neural Information Processing Systems, pp. 185–194, 2018.
Rubenstein, P. K., Schoelkopf, B., and Tolstikhin, I. Learning disentangled representations with wasserstein autoencoders. In Workshop at International Conference on Learning Representations, 2018.
Schmidhuber, J. Learning factorial codes by predictability minimization. Neural Computation, 4(6):863–879, 1992.
Schölkopf, B., Janzing, D., Peters, J., Sgouritsa, E., Zhang, K., and Mooij, J. On causal and anticausal learning. In International Conference on Machine Learning, pp. 1255–1262, 2012.
Spirtes, P., Glymour, C., and Scheines, R. Causation, prediction, and search. Springer-Verlag. (2nd edition MIT Press 2000), 1993.
Steenbrugge, X., Leroux, S., Verbelen, T., and Dhoedt, B. Improving generalization for abstract reasoning tasks using disentangled feature representations. In Workshop on Relational Representation Learning at Conference on Neural Information Processing Systems, 2018.
Sugiyama, M., Suzuki, T., and Kanamori, T. Density-ratio matching under the bregman divergence: a uniﬁed framework of density-ratio estimation. Annals of the Institute of Statistical Mathematics, 64(5):1009–1044, 2012.
Suter, R., Miladinovic´, Ð., Bauer, S., and Schölkopf, B. Interventional robustness of deep latent variable models. arXiv preprint arXiv:1811.00007, 2018.
Thomas, V., Bengio, E., Fedus, W., Pondard, J., Beaudoin, P., Larochelle, H., Pineau, J., Precup, D., and Bengio, Y. Disentangling the independently controllable factors of variation by interacting with the world. In Workshop on Learning Disentangled Representations at the 31st Conference on Neural Information Processing Systems, 2017.
Tschannen, M., Bachem, O., and Lucic, M. Recent advances in autoencoder-based representation learning. arXiv preprint arXiv:1812.05069, 2018.
Watanabe, S. Information theoretical analysis of multivariate correlation. IBM Journal of research and development, 4(1):66–82, 1960.
Whitney, W. F., Chang, M., Kulkarni, T., and Tenenbaum, J. B. Understanding visual concepts with continuation learning. In Workshop at International Conference on Learning Representations, 2016.

Yang, J., Reed, S. E., Yang, M.-H., and Lee, H. Weaklysupervised disentangling with recurrent transformations for 3d view synthesis. In Advances in Neural Information Processing Systems, pp. 1099–1107, 2015.
Yingzhen, L. and Mandt, S. Disentangled sequential autoencoder. In International Conference on Machine Learning, pp. 5656–5665, 2018.
Zhu, Z., Luo, P., Wang, X., and Tang, X. Multi-view perceptron: a deep model for learning face identity and view representations. In Advances in Neural Information Processing Systems, pp. 217–225, 2014.

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations
A. Proof of Theorem 1
Proof. To show the claim, we explicitly construct a family of functions f using a sequence of bijective functions. Let d > 1 be the dimensionality of the latent variable z and consider the function g : supp(z) → [0, 1]d deﬁned by

gi(v) = P (zi ≤ vi) ∀i = 1, 2, . . . , d.

Since P admits a density p(z) = i p(zi), the function g is bijective and, for almost every v ∈ supp(z), it holds that ∂g∂iv(iv) = 0 for all i and ∂g∂iv(jv) = 0 for all i = j. Furthermore, it is easy to see that, by construction, g(z) is a independent d-dimensional uniform distribution. Similarly, consider the function h : (0, 1]d → Rd deﬁned by
hi(v) = ψ−1(vi) ∀i = 1, 2, . . . , d,

where ψ(·) denotes the cumulative density function of a standard normal distribution. Again, by deﬁnition, h is bijective with ∂h∂iv(iv) = 0 for all i and ∂h∂iv(jv) = 0 for all i = j. Furthermore, the random variable h(g(z)) is a d-dimensional standard normal distribution.

Let A ∈ Rd×d be an arbitrary orthogonal matrix with Aij = 0 for all i = 1, 2, . . . , d and j = 1, 2, . . . , d. An inﬁnite family

of such matrices can be constructed using a Householder transformation: Choose an arbitrary α ∈ (0, 0.5) and consider

√ the vector v with v1 = α and vi =

1−α for i = 2, 3, . . . , d. By construction, we have vT v = 1 and both vi = 0 and

d−1

vi =

1 2

for

all

i

=

1, 2, . . . , d.

Deﬁne

the

matrix

A

=

Id

−

2vvT

and

note

that

Aii

=

1

−

2vi2

=

0

for

all

1, 2, . . . , d

as

well as Aij = −vivj = 0 for all i = j. Furthermore, A is orthogonal since

AT A = Id − 2vvT T Id − 2vvT = Id − 4vvT + 4v(vT v)vT = Id.

Since A is orthogonal, it is invertible and thus deﬁnes a bijective linear operator. The random variable Ah(g(z)) ∈ Rd is hence an independent, multivariate standard normal distribution since the covariance matrix AT A is equal to Id.
Since h is bijective, it follows that h−1(Ah(g(z))) is an independent d-dimensional uniform distribution. Deﬁne the function f : supp(z) → supp(z)
f (u) = g−1(h−1(Ah(g(u))))

and note that by deﬁnition f (z) has the same marginal distribution as z under P , i.e., P (z ≤ u) = P (f (z) ≤ u) for all u. Finally, for almost every u ∈ supp(z), it holds that

∂fi(u) =

Aij · ∂hj∂(vgj(u)) · ∂g∂ju(ju)

= 0,

∂uj

∂hi(h− i 1(Ah(g(u))) · ∂gi(g−1(h−1(Ah(g(u)))))

∂vi

∂vi

as claimed. Since the choice of A was arbitrary, there exists an inﬁnite family of such functions f .

B. Unsupervised learning of disentangled representations with VAEs
Variants of variational autoencoders (Kingma & Welling, 2014) are considered the state-of-the-art for unsupervised disentanglement learning. One assumes a speciﬁc prior P (z) on the latent space and then parameterizes the conditional probability P (x|z) with a deep neural network. Similarly, the distribution P (z|x) is approximated using a variational distribution Q(z|x), again parametrized using a deep neural network. One can then derive the following approximation to the maximum likelihood objective,

max Ep(x)[Eqφ(z|x)[log pθ(x|z)] − DKL(qφ(z|x) p(z))]

(1)

φ,θ

which is also know as the evidence lower bound (ELBO). By carefully considering the KL term, one can encourage various properties of the resulting presentation. We will brieﬂy review the main approaches.

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Bottleneck capacity. Higgins et al. (2017a) propose the β-VAE, introducing a hyperparameter in front of the KL regularizer of vanilla VAEs. They maximize the following expression:
Ep(x)[Eqφ(z|x)[log pθ(x|z)] − βDKL(qφ(z|x) p(z))]
By setting β > 1, the encoder distribution will be forced to better match the factorized unit Gaussian prior. This procedure introduces additional constraints on the capacity of the latent bottleneck, encouraging the encoder to learn a disentangled representation for the data. Burgess et al. (2017) argue that when the bottleneck has limited capacity, the network will be forced to specialize on the factor of variation that most contributes to a small reconstruction error. Therefore, they propose to progressively increase the bottleneck capacity, so that the encoder can focus on learning one factor of variation at the time:
Ep(x)[Eqφ(z|x)[log pθ(x|z)] − γ|DKL(qφ(z|x) p(z)) − C|]
where C is annealed from zero to some value which is large enough to produce good reconstruction. In the following, we refer to this model as AnnealedVAE.

Penalizing the total correlation. Let I(x; z) denote the mutual information between x and z and note that the second term in equation 1 can be rewritten as

Ep(x)[DKL(qφ(z|x) p(z))] = I(x; z) + DKL(q(z) p(z)).

Therefore, when β > 1, β-VAE penalizes the mutual information between the latent representation and the data, thus constraining the capacity of the latent space. Furthermore, it pushes q(z), the so called aggregated posterior, to match the prior and therefore to factorize, given a factorized prior. Kim & Mnih (2018) argues that penalizing I(x; z) is neither necessary nor desirable for disentanglement. The FactorVAE (Kim & Mnih, 2018) and the β-TCVAE (Chen et al., 2018) augment the VAE objective with an additional regularizer that speciﬁcally penalizes dependencies between the dimensions of the representation:

d
Ep(x)[Eqφ(z|x)[log pθ(x|z)] − DKL(qφ(z|x) p(z))] − γDKL(q(z) q(zj)).
j=1

This last term is also known as total correlation (Watanabe, 1960). The total correlation is intractable and vanilla Monte Carlo

approximations require marginalization over the training set. (Kim & Mnih, 2018) propose an estimate using the density

ratio trick (Nguyen et al., 2010; Sugiyama et al., 2012) (FactorVAE). Samples from

d j=1

q(zj

)

can

be

obtained

shufﬂing

samples from q(z) (Arcones & Gine, 1992). Concurrently, Chen et al. (2018) propose a tractable biased Monte-Carlo

estimate for the total correlation (β-TCVAE).

Disentangled priors. Kumar et al. (2017) argue that a disentangled generative model requires a disentangled prior. This approach is related to the total correlation penalty, but now the aggregated posterior is pushed to match a factorized prior. Therefore

Ep(x)[Eqφ(z|x)[log pθ(x|z)] − DKL(qφ(z|x) p(z))] − λD(q(z) p(z)),

where D is some (arbitrary) divergence. Since this term is intractable when D is the KL divergence, they propose to match the moments of these distribution. In particular, they regularize the deviation of either Covp(x)[µφ(x)] or Covqφ [z] from the identity matrix in the two variants of the DIP-VAE. This results in maximizing either the DIP-VAE-I objective

Ep(x)[Eqφ(z|x)[log pθ(x|z)] − DKL(qφ(z|x) p(z))] − λod

Covp(x)[µφ(x)] 2ij − λd

i=j

i

Covp(x)[µφ(x)] ii − 1 2

or the DIP-VAE-II objective

Ep(x)[Eqφ(z|x)[log pθ(x|z)] − DKL(qφ(z|x) p(z))] − λod

Covqφ [z] 2ij − λd

i=j

i

Covqφ [z] ii − 1 2 .

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations
C. Implementation of metrics
All our metrics consider the expected representation of training samples (except total correlation for which we also consider the sampled representation as described in Section 5).

BetaVAE metric. Higgins et al. (2017a) suggest to ﬁx a random factor of variation in the underlying generative model and to sample two mini batches of observations x. Disentanglement is then measured as the accuracy of a linear classiﬁer that predicts the index of the ﬁxed factor based on the coordinate-wise sum of absolute differences between the representation vectors in the two mini batches. We sample two batches of 64 points with a random factor ﬁxed to a randomly sampled value across the two batches and the others varying randomly. We compute the mean representations for these points and take the absolute difference between pairs from the two batches. We then average these 64 values to form the features of a training (or testing) point. We train a Scikit-learn logistic regression with default parameters on 10 000 points. We test on 5000 points.

FactorVAE metric Kim & Mnih (2018) address several issues with this metric by using a majority vote classiﬁer that predicts the index of the ﬁxed ground-truth factor based on the index of the representation vector with the least variance. First, we estimate the variance of each latent dimension by embedding 10 000 random samples from the data set and we exclude collapsed dimensions with variance smaller than 0.05. Second, we generate the votes for the majority vote classiﬁer by sampling a batch of 64 points, all with a factor ﬁxed to the same random value. Third, we compute the variance of each dimension of their latent representation and divide by the variance of that dimension we computed on the data without interventions. The training point for the majority vote classiﬁer consists of the index of the dimension with the smallest normalized variance. We train on 10 000 points and evaluate on 5000 points.

Mutual Information Gap. Chen et al. (2018) argue that the BetaVAE metric and the FactorVAE metric are neither general nor unbiased as they depend on some hyperparameters. They compute the mutual information between each ground truth factor and each dimension in the computed representation r(x). For each ground-truth factor zk, they then consider the two dimensions in r(x) that have the highest and second highest mutual information with zk. The Mutual Information Gap (MIG) is then deﬁned as the average, normalized difference between the highest and second highest mutual information of each factor with the dimensions of the representation. The original metric was proposed evaluating the sampled representation. Instead, we consider the mean representation, in order to be consistent with the other metrics. We estimate the discrete mutual information by binning each dimension of the representations obtained from 10 000 points into 20 bins. Then, the score is computed as follows:

1K 1 K k=1 Hzk

I(vjk , zk) − max I(vj, zk)
j=jk

Where zk is a factor of variation, vj is a dimension of the latent representation and jk = arg maxj I(vj, zk).

Modularity. Ridgeway & Mozer (2018) argue that two different properties of representations should be considered, i.e., Modularity and Explicitness. In a modular representation each dimension of r(x) depends on at most a single factor of variation. In an explicit representation, the value of a factor of variation is easily predictable (i.e. with a linear model) from r(x). They propose to measure the Modularity as the average normalized squared difference of the mutual information of the factor of variations with the highest and second-highest mutual information with a dimension of r(x). They measure Explicitness as the ROC-AUC of a one-versus-rest logistic regression classiﬁer trained to predict the factors of variation. In this study, we focus on Modularity as it is the property that corresponds to disentanglement. For the modularity score, we sample 10 000 points for which we obtain the latent representations. We discretize these points into 20 bins and compute the mutual information between representations and the values of the factors of variation. These values are stored in a matrix m. For each dimension of the representation i, we compute a vector ti as:

ti,f = θi if f = arg maxg mi,g 0 otherwise

where θi = maxg mig. The modularity score is the average over the dimensions of the representation of 1 − δi where:

δi =

f (mif − tif )2 θi2(N − 1)

and N is the number of factors.

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

DCI Disentanglement. Eastwood & Williams (2018) consider three properties of representations, i.e., Disentanglement,

Completeness and Informativeness. First, Eastwood & Williams (2018) compute the importance of each dimension of

the learned representation for predicting a factor of variation. The predictive importance of the dimensions of r(x) can

be computed with a Lasso or a Random Forest classiﬁer. Disentanglement is the average of the difference from one of

the entropy of the probability that a dimension of the learned representation is useful for predicting a factor weighted by

the relative importance of each dimension. Completeness, is the average of the difference from one of the entropy of the

probability that a factor of variation is captured by a dimension of the learned representation. Finally, the Informativeness

can be computed as the prediction error of predicting the factors of variations. We sample 10 000 and 5000 training and

test points respectively. For each factor, we ﬁt gradient boosted trees from Scikit-learn with the default setting. From

this model, we extract the importance weights for the feature dimensions. We take the absolute value of these weights

and use them to form the importance matrix R, whose rows correspond to factors and columns to the representation.

To compute the disentanglement score, we ﬁrst subtract from 1 the entropy of each column of this matrix (we treat the

columns as a distribution by normalizing them). This gives a vector of length equal to the dimensionality of the latent space.

Then, we compute the relative importance of each dimension by ρi = i ρi(1 − H(Ri)).

j Rij /

ij Rij and the disentanglement score as

SAP score. Kumar et al. (2017) propose to compute the R2 score of the linear regression predicting the factor values from each dimension of the learned representation. For discrete factors, they propose to train a classiﬁer. The Separated Attribute Predictability (SAP) score is the average difference of the prediction error of the two most predictive latent dimensions for each factor. We sample 10 000 points for training and 5000 for testing. We then compute a score matrix containing the prediction error on the test set for a linear SVM with C = 0.01 predicting the value of a factor from a single latent dimension. The SAP score is computed as the average across factors of the difference between the top two most predictive latent dimensions.

Downstream task. We sample training sets of different sizes: 10, 100, 1000 and 10 000 points. We always evaluate on 5000 samples. We consider as a downstream task the prediction of the values of each factor from r(x). For each factor we ﬁt a different model and report then report the average test accuracy across factors. We consider two different models. First, we train a cross validated logistic regression from Scikit-learn with 10 different values for the regularization strength (Cs = 10) and 5 folds. Finally, we train a gradient boosting classiﬁer from Scikit-learn with default parameters.

Total correlation based on ﬁtted Gaussian. We sample 10 000 points and obtain their latent representation r(x) by either sampling from the encoder distribution of by taking its mean. We then compute the mean µr(x) and covariance matrix Σr(x) of these points and compute the total correlation of a Gaussian with mean µr(x) and covariance matrix Σr(x), i.e.,

 DKL N (µr(x), Σr(x))


N (µr(x)j , Σr(x)jj )
j

where j indexes the dimensions in the latent space. We choose this approach for the following reasons: In this study, we compute statistics of r(x) which can be either sampled from the probabilistic encoder or taken to be its mean. We argue that estimating the total correlation as in (Kim & Mnih, 2018) is not suitable for this comparison as it consistently underestimate the true value (see Figure 7 in (Kim & Mnih, 2018)) and depends on a non-convex optimization procedure (for ﬁtting the discriminator). The estimate of (Chen et al., 2018) is also not suitable as the mean representation is a deterministic function for the data, therefore we cannot use the encoder distribution for the estimate. Furthermore, we argue that the total correlation based on the ﬁtted Gaussian provides a simple and robust way to detect if a representation is not factorizing based on the ﬁrst two moments. In particular, if it is high, it is a strong signal that the representation is not factorizing (while a low score may not imply the opposite). We note that this procedure is similar to the penalty of DIP-VAE-I. Therefore, it is not surprising that DIP-VAE-I achieves a low score for the mean representation.

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations
D. Experimental conditions and guiding principles.
In our study, we seek controlled, fair and reproducible experimental conditions. We consider the case in which we can sample from a well deﬁned and known ground-truth generative model by ﬁrst sampling the factors of variations from a distribution P (z) and then sampling an observation from P (x|z). Our experimental protocol works as follows: During training, we only observe the samples of x obtained by marginalizing P (x|z) over P (z). After training, we obtain a representation r(x) by either taking a sample from the probabilistic encoder Q(z|x) or by taking its mean. Typically, disentanglement metrics consider the latter as the representation r(x). During the evaluation, we assume to have access to the whole generative model, i.e. we can draw samples from both P (z) and P (x|z). In this way, we can perform interventions on the latent factors as required by certain evaluation metrics. We explicitly note that we effectively consider the statistical learning problem where we optimize the loss and the metrics on the known data generating distribution. As a result, we do not use separate train and test sets but always take i.i.d. samples from the known ground-truth distribution. This is justiﬁed as the statistical problem is well deﬁned and it allows us to remove the additional complexity of dealing with overﬁtting and empirical risk minimization.
E. Limitations of our study.
While we aim to provide a useful and fair experimental study, there are clear limitations to the conclusions that can be drawn from it due to design choices that we have taken. In all these choices, we have aimed to capture what is considered the state-of-the-art inductive bias in the community.
On the data set side, we only consider images with a heavy focus on synthetic images. We do not explore other modalities and we only consider the toy scenario in which we have access to a data generative process with uniformly distributed factors of variations. Furthermore, all our data sets have a small number of independent discrete factors of variations without any confounding variables.
For the methods, we only consider the inductive bias of convolutional architectures. We do not test fully connected architectures or additional techniques such as skip connections. Furthermore, we do not explore different activation functions, reconstruction losses or different number of layers. We also do not vary any other hyperparameters other than the regularization weight. In particular, we do not evaluate the role of different latent space sizes, optimizers and batch sizes. We do not test the sample efﬁciency of the metrics but simply set the size of the train and test set to large values.
Implementing the different disentanglement methods and metrics has proven to be a difﬁcult endeavour. Few “ofﬁcial” open source implementations are available and there are many small details to consider. We take a best-effort approach to these implementations and implemented all the methods and metrics from scratch as any sound machine learning practitioner might do based on the original papers. When taking different implementation choices than the original papers, we explicitly state and motivate them.
F. Differences with previous implementations.
As described above, we use a single choice of architecture, batch size and optimizer for all the methods which might deviate from the settings considered in the original papers. However, we argue that uniﬁcation of these choices is the only way to guarantee a fair comparison among the different methods such that valid conclusions may be drawn in between methods. The largest change is that for DIP-VAE and for β-TCVAE we used a batch size of 64 instead of 400 and 2048 respectively. However, Chen et al. (2018) shows in Section H.2 of the Appendix that the bias in the mini-batch estimation of the total correlation does not signiﬁcantly affect the performances of their model even with small batch sizes. For DIP-VAE-II, we did not implement the additional regularizer on the third order central moments since no implementation details are provided and since this regularizer is only used on speciﬁc data sets.
Our implementations of the disentanglement metrics deviate from the implementations in the original papers as follows: First, we strictly enforce that all factors of variations are treated as discrete variables as this corresponds to the assumed ground-truth model in all our data sets. Hence, we used classiﬁcation instead of regression for the SAP score and the disentanglement score of (Eastwood & Williams, 2018). This is important as it does not make sense to use regression on true factors of variations that are discrete (e.g., shape on dSprites). Second, wherever possible, we resorted to using the default, well-tested Scikit-learn (Pedregosa et al., 2011) implementations instead of using custom implementations with potentially hard to set hyperparameters. Third, for the Mutual Information Gap (Chen et al., 2018), we estimate the discrete

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Table 2. Encoder and Decoder architecture for the main experiment.

Encoder
Input: 64 × 64× number of channels 4 × 4 conv, 32 ReLU, stride 2 4 × 4 conv, 32 ReLU, stride 2 4 × 4 conv, 64 ReLU, stride 2 4 × 4 conv, 64 ReLU, stride 2 FC 256, F2 2 × 10

Decoder
Input: R10 FC, 256 ReLU FC, 4 × 4 × 64 ReLU 4 × 4 upconv, 64 ReLU, stride 2 4 × 4 upconv, 32 ReLU, stride 2 4 × 4 upconv, 32 ReLU, stride 2 4 × 4 upconv, number of channels, stride 2

Table 3. Model’s hyperparameters. We allow a sweep over a single hyperparameter for each model.

Model β-VAE AnnealedVAE
FactorVAE DIP-VAE-I
DIP-VAE-II β-TCVAE

Parameter
β cmax iteration threshold γ γ λod λd λod λd β

Values
[1, 2, 4, 6, 8, 16] [5, 10, 25, 50, 75, 100] 100000 1000 [10, 20, 30, 40, 50, 100] [1, 2, 5, 10, 20, 50] 10λod [1, 2, 5, 10, 20, 50] λod [1, 2, 4, 6, 8, 10]

mutual information (as opposed to continuous) on the mean representation (as opposed to sampled) on a subset of the samples (as opposed to the whole data set). We argue that this is the correct choice as the mean is usually taken to be the representation. Hence, it would be wrong to consider the full Gaussian encoder or samples thereof as that would correspond to a different representation. Finally, we ﬁx the number of sampled train and test points across all metrics to a large value to ensure robustness.
G. Main experiment hyperparameters
In our study, we ﬁx all hyperparameters except one per each model. Model speciﬁc hyperparameters can be found in Table 3. The common architecture is depicted in Table 2 along with the other ﬁxed hyperparameters in Table 4a. For the discriminator in FactorVAE we use the architecture in Table 4b with hyperparameters in Table 4c. All the hyperparameters for which we report single values were not varied and are selected based on the literature.
H. Data sets and preprocessing
All the data sets contains images with pixels between 0 and 1. Color-dSprites: Every time we sample a point, we also sample a random scaling for each channel uniformly between 0.5 and 1. Noisy-dSprites: Every time we sample a point, we ﬁll the background with uniform noise. Scream-dSprites: Every time we sample a point, we sample a random 64 × 64 patch of The Scream painting. We then change the color distribution by adding a random uniform number to each channel and divide the result by two. Then, we embed the dSprites shape by inverting the colors of each of its pixels.

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

(a) Hyperparameters common to each of the considered methods.

Parameter
Batch size Latent space dimension Optimizer Adam: beta1 Adam: beta2 Adam: epsilon Adam: learning rate Decoder type Training steps

Values
64 10 Adam 0.9 0.999 1e-8 0.0001 Bernoulli 300000

Table 4. Other ﬁxed hyperparameters.
(b) Architecture for the discriminator in FactorVAE.
Discriminator
FC, 1000 leaky ReLU FC, 1000 leaky ReLU FC, 1000 leaky ReLU FC, 1000 leaky ReLU FC, 1000 leaky ReLU FC, 1000 leaky ReLU FC, 2

(c) Parameters for the discriminator in FactorVAE.

Parameter
Batch size Optimizer Adam: beta1 Adam: beta2 Adam: epsilon Adam: learning rate

Values
64 Adam 0.5 0.9 1e-8 0.0001

I. Detailed experimental results
Given the breadth of the experimental study, we summarized our key ﬁndings in Section 5 and presented ﬁgures that we picked to be representative of our results. This section contains a self-contained presentation of all our experimental results. In particular, we present a complete set of plots for the different methods, data sets and disentanglement metrics.
I.1. Can one achieve a good reconstruction error across data sets and models?
First, we check for each data set that we manage to train models that achieve reasonable reconstructions. Therefore, for each data set we sample a random model and show real samples next to their reconstructions. The results are depicted in Figure 7. As expected, the additional variants of dSprites with continuous noise variables are harder than the original data set. On Noisy-dSprites and Color-dSprites the models produce reasonable reconstructions with the noise on Noisy-dSprites being ignored. Scream-dSprites is even harder and we observe that the shape information is lost. On the other data sets, we observe that reconstructions are blurry but objects are distinguishable. SmallNORB seems to be the most challenging data set.
I.2. Can current methods enforce a uncorrelated aggregated posterior and representation?
We investigate whether the considered unsupervised disentanglement approaches are effective at enforcing a factorizing and thus uncorrelated aggregated posterior. For each trained model, we sample 10 000 images and compute a sample from the corresponding approximate posterior. We then ﬁt a multivariate Gaussian distribution over these 10 000 samples by computing the empirical mean and covariance matrix. Finally, we compute the total correlation of the ﬁtted Gaussian and report the median value for each data set, method and hyperparameter value.
Figure 8 shows the total correlation of the sampled representation plotted against the regularization strength for each data set and method except AnnealedVAE. On all data sets except SmallNORB, we observe that plain vanilla variational autoencoders (i.e. the β-VAE model with β = 1) exhibit the highest total correlation. For β-VAE and β-TCVAE, it can be clearly seen that the total correlation of the sampled representation decreases on all data sets as the regularization strength (in the form of β) is increased. The two variants of DIP-VAE exhibit low total correlation across the data sets except DIP-VAE-I which incurs a slightly higher total correlation on SmallNORB compared to a vanilla VAE. Increased regularization in the DIP-VAE objective also seems to lead a reduced total correlation, even if the effect is not as pronounced as for β-VAE and β-TCVAE. While FactorVAE achieves a low total correlation on all data sets except on SmallNORB, we observe that the total correlation does not seem to decrease with increasing regularization strength. We further observe that AnnealedVAE (shown in Figure 25) is much more sensitive to the regularization strength. However, on all data sets except Scream-dSprites (on which AnnealedVAE performs poorly), the total correlation seems to decrease with increased regularization strength.
While many of the considered methods aim to enforce a factorizing aggregated posterior, they use the mean vector of the Gaussian encoder as the representation and not a sample from the Gaussian encoder. This may seem like a minor, irrelevant modiﬁcation; however, it is not clear whether a factorizing aggregated posterior also ensures that the dimensions of the mean representation are uncorrelated. To test whether this is true, we compute the mean of the Gaussian encoder for the same 10 000 samples, ﬁt a multivariate Gaussian and compute the total correlation of that ﬁtted Gaussian. Figure 9 shows

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

(a) DIP-VAE-I trained on dSprites.

(b) β-VAE trained on Noisy-dSprites.

(c) FactorVAE trained on Color-dSprites.

(d) FactorVAE trained on Scream-dSprites.

(e) AnneaeledVAE trained on Shapes3D.

(f) β-TCVAE trained on SmallNORB.

(g) Reconstructions for a DIP-VAE-II trained on Cars3D.
Figure 7. Reconstructions for different data sets and methods. Odd columns show real samples and even columns their reconstruction. As expected, the additional variants of dSprites with continuous noise variables are harder than the original data set. On Noisy-dSprites and Color-dSprites the models produce reasonable reconstructions with the noise on Noisy-dSprites being ignored. Scream-dSprites is even harder and we observe that the shape information is lost. On the other data sets, we observe that reconstructions are blurry but objects are distinguishable.

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

TC (sampled)

Model

VAE

β-VAE

FactorVAE

β-TCVAE

DIP-VAE-I

DIP-VAE-II

0.05

Dataset = dSprites

0.12

Dataset = Color-dSprites

0.040

Dataset = Noisy-dSprites

0.06 Dataset = Scream-dSprites

0.04

0.10

0.035

0.05

0.030

0.03

0.08

0.025

0.04

0.06

0.020

0.03

0.02

0.04

0.015

0.02

0.01

0.010 0.02

0.01

0.005

0.00

0.00

0.000

0.00

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

0.014

Dataset = SmallNORB

0.30

Dataset = Cars3D

0.25

Dataset = Shapes3D

Regularization strength

0.012

0.25

0.20

0.010

0.20

0.15

0.008

0.15

0.10

0.006

0.10

0.004

0.05

0.05

0.002

0.00

0.00

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

Regularization strength

Regularization strength

Regularization strength

TC (sampled)

Figure 8. Total correlation of sampled representation plotted against regularization strength for different data sets and approaches (except AnnealedVAE). The total correlation of the sampled representation decreases as the regularization strength is increased.

TC (mean)

Model

VAE

β-VAE

FactorVAE

β-TCVAE

DIP-VAE-I

DIP-VAE-II

1.4

Dataset = dSprites

0.8

Dataset = Color-dSprites

1.6

Dataset = Noisy-dSprites

0.6

Dataset = Scream-dSprites

1.2

0.7

1.4

0.5

1.0 0.6 1.2 0.4

0.8 0.5 1.0

0.4

0.8

0.3

0.6

0.3

0.6

0.2

0.4

0.2

0.4

0.2

0.1

0.2

0.1

0.0

0.0

0.0

0.0

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

4.0

Dataset = SmallNORB

1.2

Dataset = Cars3D

0.8

Dataset = Shapes3D

Regularization strength

3.5

1.0

0.7

3.0

0.6

2.5

0.8

0.5

2.0

0.6

0.4

1.5

0.4

0.3

1.0

0.2

0.5

0.2

0.1

0.0

0.0

0.0

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

Regularization strength

Regularization strength

Regularization strength

TC (mean)

Figure 9. Total correlation of mean representation plotted against regularization strength for different data sets and approaches (except AnnealedVAE). The total correlation of the mean representation does not necessarily decrease as the regularization strength is increased.

log TC (mean)

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Model

β-VAE

FactorVAE

β-TCVAE

DIP-VAE-I

DIP-VAE-II

AnnealedVAE

4

Dataset = dSprites

2

Dataset = Color-dSprites

4

Dataset = Noisy-dSprites

Dataset = Scream-dSprites

2122

0

0

1

0

0

2222 3

4

4

4

4

656

6

6

8

7

8

7 6 5 4 3 2 1 7 6 5 4 3 2 1 8 6 4 20 2 4

6

Dataset = SmallNORB

4

Dataset = Cars3D

4

Dataset = Shapes3D

7654321 log TC (sampled)

4

2

2

2

0

0

0

2

2

2

4

4

4

6

6

6

8

8 6 4 2 0 2 4 8 6 4 2 0 2 4 7 6 5 4 3 2 10 1

log TC (sampled)

log TC (sampled)

log TC (sampled)

log TC (mean)

Figure 10. Log total correlation of mean vs sampled representations. For a large number of models, the total correlation of the mean representation is higher than that of the sampled representation.

the total correlation of the mean representation plotted against the regularization strength for each data set and method except AnnealedVAE. We observe that, for β-VAE and β-TCVAE, increased regularization leads to a substantially increased total correlation of the mean representations. This effect can also be observed for for FactorVAE, albeit in a less extreme fashion. For DIP-VAE-I, we observe that the total correlation of the mean representation is consistently low. This is not surprising as the DIP-VAE-I objective directly optimizes the covariance matrix of the mean representation to be diagonal which implies that the corresponding total correlation (as we compute it) is low. The DIP-VAE-II objective which enforces the covariance matrix of the sampled representation to be diagonal seems to lead to a factorized mean representation on some data sets (for example Shapes3D and Cars3d), but also seems to fail on others (dSprites). For AnnealedVAE (shown in Figure 26), we overall observe mean representations with a very high total correlation. In Figure 10, we further plot the log total correlations of the sampled representations versus the mean representations for each of the trained models. It can be clearly seen that for a large number of models, the total correlation of the mean representations is much higher than that of the sampled representations. The same trend can be seen computing the average discrete mutual information of the representation. In this case, the DIP-VAE-I exhibit increasing mutual information in both the mean and sampled representation. This is to be expected as DIP-VAE-I enforces a variance of one for the mean representation. We remark that as the regularization terms and hyperparameter values are different for different losses, one should not draw conclusions from comparing different models at nominally the same regularization strength. From these plots one can only compare the effect of increasing the regularization in the different models.
Implications. Overall, these results lead us to conclude with minor exceptions that the considered methods are effective at enforcing an aggregated posterior whose individual dimensions are not correlated but that this does not seem to imply that the dimensions of the mean representation (usually used for representation) are uncorrelated.
I.3. How much do existing disentanglement metrics agree?
As there exists no single, common deﬁnition of disentanglement, an interesting question is to see how much different proposed metrics agree. Figure 11 shows pairwise scatter plots of the different considered metrics on dSprites where each point corresponds to a trained model, while Figure 12 shows the Spearman rank correlation between different disentanglement metrics on different data sets. Overall, we observe that all metrics except Modularity seem to be correlated strongly on the data sets dSprites, Color-dSprites and Scream-dSprites and mildly on the other data sets. There appear to be two pairs among these metrics that capture particularly similar notions: the BetaVAE and the FactorVAE score as well as the

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

FactorVAE Score BetaVAE Score

0.8 0.4 1.0 0.5

Modularity DCI Disentanglement MIG

0.0

Model

β-VAE

FactorVAE

0.6

β-TCVAE DIP-VAE-I

DIP-VAE-II

AnnealedVAE

0.0

1.0 0.8 0.6

SAP

0.0 0.5 1.0
BetaVAE Score

0.6 FactorVAE Score

0.0 0.6 0.0

0.8

MIG DCI Disentanglement Modularity

0.0 0.1 SAP

Figure 11. Pairwise scatter plots of different disentanglement metrics on dSprites. All the metrics except Modularity appear to be correlated. The strongest correlation seems to be between MIG and DCI Disentanglement.

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Dataset = dSprites BetaVAE Score 100 82 81 84 1 81 FactorVAE Score 82 100 72 77 -5 67
MIG 81 72 100 93 -5 83 DCI Disentanglement 84 77 93 100 -14 84
Modularity 1 -5 -5 -14 100 -10 SAP 81 67 83 84 -10 100

Dataset = Color-dSprites BetaVAE Score 100 76 80 87 9 79 FactorVAE Score 76 100 68 76 2 62
MIG 80 68 100 91 1 82 DCI Disentanglement 87 76 91 100 -7 82
Modularity 9 2 1 -7 100 -7 SAP 79 62 82 82 -7 100

Dataset = Noisy-dSprites BetaVAE Score 100 80 44 41 46 37 FactorVAE Score 80 100 49 52 25 38
MIG 44 49 100 76 6 42 DCI Disentanglement 41 52 76 100 -8 38
Modularity 46 25 6 -8 100 13 SAP 37 38 42 38 13 100

Dataset = Scream-dSprites BetaVAE Score 100 95 94 92 47 95 FactorVAE Score 95 100 95 89 49 90
MIG 94 95 100 95 50 87 DCI Disentanglement 92 89 95 100 44 87
Modularity 47 49 50 44 100 41 SAP 95 90 87 87 41 100

BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP
BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP
BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP
BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP

Dataset = SmallNORB BetaVAE Score 100 63 56 45 -60 39 FactorVAE Score 63 100 34 39 -69 2
MIG 56 34 100 79 -50 76 DCI Disentanglement 45 39 79 100 -42 58
Modularity -60 -69 -50 -42 100 -28 SAP 39 2 76 58 -28 100

Dataset = Cars3D BetaVAE Score 100 37 22 38 29 13 FactorVAE Score 37 100 66 60 39 40
MIG 22 66 100 67 52 43 DCI Disentanglement 38 60 67 100 57 27
Modularity 29 39 52 57 100 18 SAP 13 40 43 27 18 100

Dataset = Shapes3D BetaVAE Score 100 76 24 54 46 57 FactorVAE Score 76 100 44 49 23 66
MIG 24 44 100 67 9 70 DCI Disentanglement 54 49 67 100 52 58
Modularity 46 23 9 52 100 17 SAP 57 66 70 58 17 100

BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP
BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP
BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP

Figure 12. Rank correlation of different metrics on different data sets. Overall, we observe that all metrics except Modularity seem to be strongly correlated on the data sets dSprites, Color-dSprites and Scream-dSprites and mildly on the other data sets. There appear to be two pairs among these metrics that capture particularly similar notions: the BetaVAE and the FactorVAE score as well as the Mutual Information Gap and DCI Disentanglement.
Mutual Information Gap and DCI Disentanglement.
Implication. All disentanglement metrics except Modularity appear to be correlated. However, the level of correlation changes between different data sets.
I.4. How important are different models and hyperparameters for disentanglement?
The primary motivation behind the considered methods is that they should lead to improved disentanglement scores. This raises the question how disentanglement is affected by the model choice, the hyperparameter selection and randomness (in the form of different random seeds). To investigate this, we compute all the considered disentanglement metrics for each of our trained models. In Figure 13, we show the range of attainable disentanglement scores for each method on each data set. We observe that these ranges are heavily overlapping for different models leading us to (qualitatively) conclude that the choice of hyperparameters and the random seed seems to be substantially more important than the choice of objective function. While certain models seem to attain better maximum scores on speciﬁc data sets and disentanglement metrics, we do not observe any consistent pattern that one model is consistently better than the other. Furthermore, we note that in our study we have ﬁxed the range of hyperparameters a priori to six different values for each model and did not explore additional hyperparameters based on the results (as that would bias our study). However, this also means that speciﬁc models may have performed better than in Figure 13 if we had chosen a different set of hyperparameters. In Figure 14, we further show the impact of randomness in the form of random seeds on the disentanglement scores. Each violin plot shows the distribution of the disentanglement metric across all 50 trained models for each model and hyperparameter setting on Cars3D. We clearly see that randomness (in the form of different random seeds) has a substantial impact on the attained result and that a good run with a bad hyperparameter can beat a bad run with a good hyperparameter in many cases.
Finally, we perform a variance analysis by trying to predict the different disentanglement scores using ordinary least squares for each data set: If we allow the score to depend only on the objective function (categorical variable), we are only able to explain 37% of the variance of the scores on average. Similarly, if the score depends on the Cartesian product of objective function and regularization strength (again categorical), we are able to explain 59% of the variance while the rest is due to the random seed. In Table 5, we report the percentage of variance explained for the different metrics in each data set

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Value Value Value Value Value Value Value

Dataset = dSprites

Dataset = Color-dSprites

Dataset = Noisy-dSprites

Dataset = Scream-dSprites

1.0 Metric = BetaVAE Score
0.9
0.8
0.7
0.6
0.5
0.4
0.9
0.8
0.7
0.6
0.5 1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 1.0
0.9
0.8
0.7
0.6
0.5
0.4 1.005 1.000 0.995 0.990 0.985 0.980 0.975 0.970 0.965
1.1 1.0 0.9 0.8 0.7 0.6 0.5 0.4 0 1 2 3 4 5
Model

1.0 Metric = FactorVAE Score 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0 0.1 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 1.00 0.95 0.90 0.85 0.80 0.75 0.70 0.65 0.60
1.0
0.8
0.6
0.4
0.2 0 1 2 3 4 5 Model

0.5

Metric = MIG

0.4

0.3

0.2

0.1

0.0

0.1 0.40 0.35 0.30 0.25 0.20 0.15 0.10 0.05 0.00 0.05 0.30
0.25
0.20
0.15
0.10
0.05
0.00
0.05 0.30
0.25
0.20
0.15
0.10
0.05
0.00
0.05 0.35 0.30 0.25 0.20 0.15 0.10 0.05 0.00 0.05 0.30
0.25
0.20
0.15
0.10
0.05
0.00
0.05 1.0

0.8

0.6

0.4

0.2

0.0

0.2 0 1 2 3 4 5 Model

0.6 Metric = DCI Disentanglement 1.00

0.5

0.95

0.4

0.90

0.3

0.85

0.80

0.2

0.75

0.1

0.70

0.0

0.65

0.1

0.60

0.6

1.00

0.5

0.95

0.4

0.90

0.3 0.85
0.2

0.1

0.80

0.0

0.75

0.1

0.70

0.35

1.0

0.30

0.25

0.9

0.20

0.8

0.15

0.10

0.7

0.05

0.6

0.00

0.05

0.5

0.35

0.95

0.30

0.90

0.25

0.85

0.20

0.80

0.15

0.75

0.10

0.70

0.05

0.65

0.00

0.60

0.05

0.55

0.40

1.05

0.35

1.00

0.30

0.95

0.25

0.90

0.20

0.85

0.15

0.80

0.10

0.75

0.05

0.70

0.00

0.65

0.6

1.00

Metric = Modularity

0.5

0.95

0.4

0.90

0.3

0.85

0.2

0.80

0.1

0.75

0.0 1.2 1.0 0.8 0.6 0.4 0.2 0.0 0 1 2 3 4 5
Model

0.70 1.05 1.00 0.95 0.90 0.85 0.80 0.75 0.70 0.65 0 1 2 3 4 5
Model

0.10

Metric = SAP

0.08

0.06

0.04

0.02

0.00

0.02 0.10

0.08

0.06

0.04

0.02

0.00

0.02 0.07 0.06 0.05 0.04 0.03 0.02 0.01 0.00 0.01 0.08 0.07 0.06 0.05 0.04 0.03 0.02 0.01 0.00 0.01 0.20

0.15

0.10

0.05

0.00

0.05 0.06 0.05 0.04 0.03 0.02 0.01 0.00 0.01 0.30 0.25 0.20 0.15 0.10 0.05 0.00 0.05 0 1 2 3 4 5
Model

Dataset = SmallNORB

Dataset = Cars3D

Dataset = Shapes3D

Figure 13. Score for each method for each score (column) and data set (row). Models are abbreviated (0=β-VAE, 1=FactorVAE, 2=βTCVAE, 3=DIP-VAE-I, 4=DIP-VAE-II, 5=AnnealedVAE). The scores are heavily overlapping and we do not observe a consistent pattern. We conclude that hyperparameters matter more than the model choice.

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Model = β-VAE

Model = β-TCVAE

Value

Value

Model = FactorVAE

Value

Metric = BetaVAE Score 1.000

0.995

0.990

0.985

1.005 1.000 0.995 0.990 0.985 0.980 0.975 0.970 0.965
1.0005

1.0000

0.9995

0.9990

0.9985

0.9980 0.0006 +9.995e 1

0.0005

0.0004

0.0003

0.0002

0.0001

0.0000 1.0002 1.0000 0.9998 0.9996 0.9994 0.9992 0.9990 0.9988 1.005 1.000 0.995 0.990 0.985 0.980 0.975 0.970

0.0 0.2 0.4 0.6 0.8 1.0 Regularization strength

1.00 Metric = FactorVAE Score 0.95 0.90 0.85 0.80 0.75 0.70 0.65 0.60 1.00 0.95 0.90 0.85 0.80 0.75 0.70 0.65 0.60 1.00 0.95 0.90 0.85 0.80 0.75 0.70 0.65 1.00 0.95 0.90 0.85 0.80 0.75 0.70 0.65 1.00 0.95 0.90 0.85 0.80 0.75 0.70 0.65 0.60 1.00 0.95 0.90 0.85 0.80 0.75 0.70 0.65 0.0 0.2 0.4 0.6 0.8 1.0
Regularization strength

0.20

Metric = MIG

0.15

0.10

0.05

0.00

0.05
0.16 0.14 0.12 0.10 0.08 0.06 0.04 0.02 0.00
0.30
0.25
0.20
0.15
0.10
0.05
0.00
0.05
0.16 0.14 0.12 0.10 0.08 0.06 0.04 0.02 0.00
0.16 0.14 0.12 0.10 0.08 0.06 0.04 0.02 0.00 0.02
0.14 0.12 0.10 0.08 0.06 0.04 0.02 0.00 0.02 0.0 0.2 0.4 0.6 0.8 1.0
Regularization strength

0.50 Metric = DCI Disentanglement 0.45 0.40 0.35 0.30 0.25 0.20 0.15 0.10 0.05 0.50 0.45 0.40 0.35 0.30 0.25 0.20 0.15 0.10 0.6
0.5
0.4
0.3
0.2
0.1
0.0 0.45 0.40 0.35 0.30 0.25 0.20 0.15 0.10 0.05 0.40 0.35 0.30 0.25 0.20 0.15 0.10 0.05 0.00 0.35 0.30 0.25 0.20 0.15 0.10 0.05 0.00 0.0 0.2 0.4 0.6 0.8 1.0
Regularization strength

1.00 Metric = Modularity
0.95
0.90
0.85
0.80
0.75 0.98 0.96 0.94 0.92 0.90 0.88 0.86 0.84 0.82 0.80 1.00
0.95
0.90
0.85
0.80
0.75 0.95
0.90
0.85
0.80
0.75
0.70 1.00 0.95 0.90 0.85 0.80 0.75 0.70 1.00 0.95 0.90 0.85 0.80 0.75 0.70 0.0 0.2 0.4 0.6 0.8 1.0
Regularization strength

0.05

Metric = SAP

0.04

0.03

0.02

0.01

0.00

0.01 0.06 0.05 0.04 0.03 0.02 0.01 0.00 0.01 0.035 0.030 0.025 0.020 0.015 0.010 0.005 0.000 0.005 0.06 0.05 0.04 0.03 0.02 0.01 0.00 0.01 0.05

0.04

0.03

0.02

0.01

0.00

0.01
0.035 0.030 0.025 0.020 0.015 0.010 0.005 0.000 0.005 0.0 0.2 0.4 0.6 0.8 1.0
Regularization strength

Value

Model = DIP-VAE-I

Value

Model = DIP-VAE-II

Value

Model = AnnealedVAE

Figure 14. Distribution of scores for different models, hyperparameters and regularization strengths on Cars3D. We clearly see that randomness (in the form of different random seeds) has a substantial impact on the attained result and that a good run with a bad hyperparameter can beat a bad run with a good hyperparameter in many cases.

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Table 5. Variance of the disentanglement scores explained by the objective function or its cartesian product with the hyperparameters. The variance explained is computed regressing using ordinary least squares.
(a) Percentage of variance explained regressing the disentanglement scores on the different data sets from the objective function only.

BetaVAE Score DCI Disentanglement FactorVAE Score MIG Modularity SAP

Cars3D

1%

Color-dSprites

30%

Noisy-dSprites

17%

Scream-dSprites

89%

Shapes3D

31%

SmallNORB

68%

dSprites

29%

36%

26% 34%

37% 13%

39%

52% 26%

23% 29%

21%

17% 11%

41% 6%

50%

76% 45%

60% 56%

21%

14% 20%

26% 10%

71%

58% 71%

62% 62%

41%

47% 26%

29% 31%

(b) Percentage of variance explained regressing the disentanglement scores on the different data sets from the Cartesian product of objective function and regularization strength.

BetaVAE Score DCI Disentanglement FactorVAE Score MIG Modularity SAP

Cars3D

4%

Color-dSprites

69%

Noisy-dSprites

26%

Scream-dSprites

93%

Shapes3D

61%

SmallNORB

87%

dSprites

59%

69%

42% 59%

51% 17%

80%

61% 76%

40% 56%

42%

25% 29%

50% 20%

74%

83% 66%

68% 75%

78%

53% 59%

49% 35%

89%

81% 88%

72% 82%

77%

54% 72%

39% 56%

considering the regularization strength or not.
Implication. The disentanglement scores of unsupervised models are heavily inﬂuenced by randomness (in the form of the random seed) and the choice of the hyperparameter (in the form of the regularization strength). The objective function appears to have less impact.
I.5. Are there reliable recipes for model selection?
In this section, we investigate how good hyperparameters can be chosen and how we can distinguish between good and bad training runs. In this paper, we advocate that model selection should not depend on the considered disentanglement score for the following reasons: The point of unsupervised learning of disentangled representation is that there is no access to the labels as otherwise we could incorporate them and would have to compare to semi-supervised and fully supervised methods. All the disentanglement metrics considered in this paper require a substantial amount of ground-truth labels or the full generative model (for example for the BetaVAE and the FactorVAE metric). Hence, one may substantially bias the results of a study by tuning hyperparameters based on (supervised) disentanglement metrics. Furthermore, we argue that it is not sufﬁcient to ﬁx a set of hyperparameters a priori and then show that one of those hyperparameters and a speciﬁc random seed achieves a good disentanglement score as it amounts to showing the existence of a good model, but does not guide the practitioner in ﬁnding it. Finally, in many practical settings, we might not even have access to adequate labels as it may be hard to identify the true underlying factor of variations, in particular, if we consider data modalities that are less suitable to human interpretation than images.
In the remainder of this section, we hence investigate and assess different ways how hyperparameters and good model runs could be chosen. In this study, we focus on choosing the learning model and the regularization strength corresponding to that loss function. However, we note that in practice this problem is likely even harder as a practitioner might also want to tune other modeling choices such architecture or optimizer.
General recipes for hyperparameter selection. We ﬁrst investigate whether we may ﬁnd generally applicable “rules of thumb” for choosing the hyperparameters. For this, we plot in Figure 15 different disentanglement metrics against different regularization strengths for each model and each data set. The values correspond to the median obtained values across

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Table 6. Probability of outperforming random model selection on a different random seed. A random disentanglement metric and data set is sampled and used for model selection. That model is then compared to a randomly selected model: (i) on the same metric and data set, (ii) on the same metric and a random different data set, (iii) on a random different metric and the same data set, and (iv) on a random different metric and a random different data set. The results are averaged across 10 000 random draws.

Random different metric Same metric

Random different data set
54.9% 59.3%

Same data set
62.6% 80.7%

50 random seeds for each model, hyperparameter and data set. There seems to be no model dominating all the others and for each model there does not seem to be a consistent strategy in choosing the regularization strength to maximize disentanglement scores. Furthermore, even if we could identify a good objective function and corresponding hyperparameter value, we still could not distinguish between a good and a bad training run.
Model selection based on unsupervised scores. Another approach could be to select hyperparameters based on unsupervised scores such as the reconstruction error, the KL divergence between the prior and the approximate posterior, the Evidence Lower Bound or the estimated total correlation of the sampled representation. This would have the advantage that we could select speciﬁc trained models and not just good hyperparameter settings whose median trained model would perform well. To test whether such an approach is fruitful, we compute the rank correlation between these unsupervised metrics and the disentanglement metrics and present it in Figure 16. While we do observe some correlations, no clear pattern emerges which leads us to conclude that this approach is unlikely to be successful in practice.
Hyperparameter selection based on transfer. The ﬁnal strategy for hyperparameter selection that we consider is based on transferring good settings across data sets. The key idea is that good hyperparameter settings may be inferred on data sets where we have labels available (such as dSprites) and then applied to novel data sets. To test this idea, we plot in Figure 18 the different disentanglement scores obtained on dSprites against the scores obtained on other data sets. To ensure robustness of the results, we again consider the median across all 50 runs for each model, regularization strength, and data set. We observe that the scores on Color-dSprites seem to be strongly correlated with the scores obtained on the regular version of dSprites. Figure 17 further shows the rank correlations obtained between different data sets for each disentanglement scores. This conﬁrms the strong and consistent correlation between dSprites and Color-dSprites. While these result suggest that some transfer of hyperparameters is possible, it does not allow us to distinguish between good and bad random seeds on the target data set.
To illustrate this, we compare such a transfer based approach to hyperparameter selection to random model selection as follows: We ﬁrst randomly sample one of our 50 random seeds and consider the set of trained models with that random seed. First, we sample one of our 50 random seeds, a random disentanglement metric and a data set and use them to select the hyperparameter setting with the highest attained score. Then, we compare that selected hyperparameter setting to a randomly selected model on either the same or a random different data set, based on either the same or a random different metric and for a randomly sampled seed. Finally, we report the percentage of trials in which this transfer strategy outperforms or performs equally well as random model selection across 10 000 trials in Table 6. If we choose the same metric and the same data set (but a different random seed), we obtain a score of 80.7%. If we aim to transfer for the same metric across data sets, we achieve around 59.3%. Finally, if we transfer both across metrics and data sets, our performance drops to 54.9%.
Implications. Unsupervised model selection remains an unsolved problem. Transfer of good hyperparameters between metrics and data sets does not seem to work as there appears to be no unsupervised way to distinguish between good and bad random seeds on the target task.
I.6. Are these disentangled representations useful for downstream tasks in terms of the sample complexity of learning?
One of the key motivations behind disentangled representations is that they are assumed to be useful for later downstream tasks. In particular, it is argued that disentanglement should lead to a better sample complexity of learning (Bengio et al., 2013; Schölkopf et al., 2012; Peters et al., 2017). In this section, we consider the simplest downstream classiﬁcation task

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Dataset = dSprites

Dataset = Color-dSprites

Dataset = Noisy-dSprites

Dataset = Scream-dSprites

Value

Value

Value

Value

Value

Value

Metric = BetaVAE Score
0.85
0.80
0.75
0.70
0.65 0.0 0.2 0.4 0.6 0.8 1.0
0.90 0.85 0.80 0.75 0.70 0.65 0.60
0.0 0.2 0.4 0.6 0.8 1.0
0.75
0.70
0.65
0.60 0.0 0.2 0.4 0.6 0.8 1.0
0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1
0.0 0.2 0.4 0.6 0.8 1.0 0.90 0.85 0.80 0.75 0.70 0.65 0.60 0.55 0.50
0.0 0.2 0.4 0.6 0.8 1.0 0.00025 +9.998e 1
0.00020
0.00015
0.00010
0.00005
0.00000 0.0 0.2 0.4 0.6 0.8 1.0
1.00 0.95 0.90 0.85 0.80 0.75 0.70 0.65
0.0 0.2 0.4 0.6 0.8 1.0 Regularization strength

Model 0.80 Metric = FactorVAE Score
0.75 0.70 0.65 0.60 0.55 0.50 0.45
0.0 0.2 0.4 0.6 0.8 1.0 0.80 0.75 0.70 0.65 0.60 0.55 0.50
0.0 0.2 0.4 0.6 0.8 1.0 0.60
0.55
0.50
0.45
0.40
0.35 0.0 0.2 0.4 0.6 0.8 1.0
0.8 0.7 0.6 0.5 0.4 0.3 0.2
0.0 0.2 0.4 0.6 0.8 1.0 0.70 0.65 0.60 0.55 0.50 0.45 0.40 0.35 0.30
0.0 0.2 0.4 0.6 0.8 1.0 0.95
0.90
0.85
0.80
0.75
0.70 0.0 0.2 0.4 0.6 0.8 1.0
1.0 0.9 0.8 0.7 0.6 0.5 0.4
0.0 0.2 0.4 0.6 0.8 1.0 Regularization strength

β-VAE

FactorVAE

β-TCVAE

DIP-VAE-I

DIP-VAE-II

AnnealedVAE

0.40

Metric = MIG

0.35

0.30

0.25

0.20

0.15

0.10

0.05

0.00 0.0 0.2 0.4 0.6 0.8 1.0

0.5 Metric = DCI Disentanglement 0.90 Metric = Modularity

0.08

Metric = SAP

0.07

0.4

0.88

0.06

0.3

0.86

0.05

0.04

0.2

0.84

0.03

0.1

0.82

0.02

0.01

0.0

0.80

0.00

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

0.40

0.45

0.92

0.08

0.35

0.40

0.90

0.07

0.30

0.35

0.06

0.25

0.30

0.88

0.05

0.20

0.25

0.86

0.04

0.20

0.15

0.15

0.84

0.03

0.10

0.10

0.02

0.05

0.05

0.82

0.01

0.00

0.00

0.80

0.00

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

0.08

0.16

0.020

0.07

0.14

0.018

0.06

0.12

0.85

0.016

0.05

0.10

0.014

0.04

0.08

0.80

0.012

0.010

0.03

0.06

0.008

0.02

0.04

0.75

0.006

0.01

0.02

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

0.004 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

0.25

0.25

0.80

0.06

0.20

0.20

0.05

0.75

0.04

0.15

0.15

0.10 0.10 0.70 0.03 0.02

0.05

0.05

0.65

0.01

0.00 0.0 0.2 0.4 0.6 0.8 1.0
0.30
0.25
0.20
0.15
0.10
0.05
0.00 0.0 0.2 0.4 0.6 0.8 1.0
0.16 0.14 0.12 0.10 0.08 0.06 0.04 0.02
0.0 0.2 0.4 0.6 0.8 1.0 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0
0.0 0.2 0.4 0.6 0.8 1.0 Regularization strength

0.00 0.0 0.2 0.4 0.6 0.8 1.0
0.40
0.35
0.30
0.25
0.20
0.15
0.10 0.0 0.2 0.4 0.6 0.8 1.0
0.45 0.40 0.35 0.30 0.25 0.20 0.15 0.10
0.0 0.2 0.4 0.6 0.8 1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2
0.0 0.2 0.4 0.6 0.8 1.0 Regularization strength

0.00 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

1.00

0.16

0.95

0.14

0.12

0.90

0.10

0.85

0.08

0.06

0.80

0.04

0.75

0.02

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

0.96

0.020

0.94

0.018

0.92

0.016

0.90

0.014

0.88

0.012

0.86

0.010

0.84

0.008

0.82

0.006

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

0.98 0.96 0.94 0.92 0.90 0.88 0.86 0.84 0.82
0.0 0.2 0.4 0.6 0.8 1.0 Regularization strength

0.11 0.10 0.09 0.08 0.07 0.06 0.05 0.04 0.03
0.0 0.2 0.4 0.6 0.8 1.0 Regularization strength

Value

Figure 15. Score vs hyperparameters for each score (column) and data set (row). There seems to be no model dominating all the others and for each model there does not seem to be a consistent strategy in choosing the regularization strength.

Dataset = SmallNORB

Dataset = Cars3D

Dataset = Shapes3D

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Reconstruction 2

Dataset = dSprites

Dataset = Color-dSprites

Dataset = Noisy-dSprites

3 37 28 -5 11 Reconstruction 12 18 46 34 -6 20 Reconstruction -4 -12 37 27 4 6

Dataset = Scream-dSprites Reconstruction -9 -18 -15 -10 -35 -7

TC (sampled) -1 22 5 11 -12 10 TC (sampled) 11 35 7 18 -8 13 TC (sampled) 11 22 -2 6 -11 11 TC (sampled) -21 -25 -25 -25 -17 -20

KL -57 -51 -73 -78 31 -56

KL -68 -53 -73 -80 21 -61

KL 28 22 -43 -42 32 -6

KL -53 -46 -47 -48 -9 -55

ELBO -8 -5 28 17 2 4

ELBO 5 13 40 26 -3 15

ELBO 13 -0 31 20 19 9

ELBO -14 -24 -20 -14 -34 -13

BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP
BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP
BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP
BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP

Dataset = SmallNORB

Dataset = Cars3D

Dataset = Shapes3D

Reconstruction -83 -73 -59 -54 69 -38 Reconstruction -19 9 42 20 38 12 Reconstruction -30 -4 59 22 -21 27

TC (sampled) -12 41 -21 -2 -12 -46 TC (sampled) -18 -6 -3 -14 2 0 TC (sampled) 1 5 -11 -8 -11 -2

KL 20 49 -19 -18 -22 -39

KL -14 -10 -46 -45 -40 -5

KL -14 -1 -38 -31 -11 -29

ELBO -79 -57 -72 -65 61 -55

ELBO -24 5 35 12 29 11

ELBO -38 -9 48 9 -25 15

BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP
BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP
BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP

Figure 16. Rank correlation between unsupervised scores and supervised disentanglement metrics. The unsupervised scores we consider do not seem to be useful for model selection.

Metric = BetaVAE Score dSprites 100 83 -22 54 -11 34 21 Color-dSprites 83 100 -24 69 -28 39 38 Noisy-dSprites -22 -24 100 -24 -14 16 -16 Scream-dSprites 54 69 -24 100 -6 63 72 SmallNORB -11 -28 -14 -6 100 -3 13 Cars3D 34 39 16 63 -3 100 65 Shapes3D 21 38 -16 72 13 65 100

dSprites Color-dSprites Noisy-dSprites Scream-dSprites
SmallNORB Cars3D
Shapes3D

Metric = FactorVAE Score 100 91 4 61 4 61 13 91 100 13 61 3 68 12 4 13 100 -20 62 34 -22 61 61 -20 100 -16 51 50 4 3 62 -16 100 30 -38 61 68 34 51 30 100 34 13 12 -22 50 -38 34 100

Metric = MIG dSprites 100 94 75 59 3 80 58 Color-dSprites 94 100 75 54 -10 85 65 Noisy-dSprites 75 75 100 55 -23 74 68 Scream-dSprites 59 54 55 100 28 64 18 SmallNORB 3 -10 -23 28 100 -23 -48 Cars3D 80 85 74 64 -23 100 68 Shapes3D 58 65 68 18 -48 68 100

dSprites Color-dSprites Noisy-dSprites Scream-dSprites
SmallNORB Cars3D
Shapes3D dSprites
Color-dSprites Noisy-dSprites Scream-dSprites
SmallNORB Cars3D
Shapes3D dSprites
Color-dSprites Noisy-dSprites Scream-dSprites
SmallNORB Cars3D
Shapes3D

dSprites Color-dSprites Noisy-dSprites Scream-dSprites
SmallNORB Cars3D
Shapes3D

Metric = DCI Disentanglement 100 95 65 65 34 64 46 95 100 61 60 21 63 47 65 61 100 68 17 64 59 65 60 68 100 36 93 69 34 21 17 36 100 21 -9 64 63 64 93 21 100 85 46 47 59 69 -9 85 100

Metric = Modularity dSprites 100 86 78 -17 -6 -55 2 Color-dSprites 86 100 71 -11 -4 -32 30 Noisy-dSprites 78 71 100 3 5 -57 10 Scream-dSprites -17 -11 3 100 -45 -6 25 SmallNORB -6 -4 5 -45 100 21 -25 Cars3D -55 -32 -57 -6 21 100 31 Shapes3D 2 30 10 25 -25 31 100

Metric = SAP dSprites 100 86 27 63 17 51 35 Color-dSprites 86 100 39 65 10 43 43 Noisy-dSprites 27 39 100 -3 -34 21 2 Scream-dSprites 63 65 -3 100 38 24 68 SmallNORB 17 10 -34 38 100 -16 -2 Cars3D 51 43 21 24 -16 100 -4 Shapes3D 35 43 2 68 -2 -4 100

dSprites Color-dSprites Noisy-dSprites Scream-dSprites
SmallNORB Cars3D
Shapes3D dSprites
Color-dSprites Noisy-dSprites Scream-dSprites
SmallNORB Cars3D
Shapes3D dSprites
Color-dSprites Noisy-dSprites Scream-dSprites
SmallNORB Cars3D
Shapes3D

Figure 17. Rank-correlation of different disentanglement metrics across different data sets. Good hyperparameters only seem to transfer between dSprites and Color-dSprites but not in between the other data sets.

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Dataset = dSprites

Dataset = Color-dSprites

Dataset = Noisy-dSprites

Dataset = Scream-dSprites

Metric value

Metric value

Metric value

Metric value

0.9 Metric = BetaVAE Score

Model Metric = FactorVAE Score

0.75 0.8

0.60 0.7

0.45

0.6

0.6

0.7

0.8

0.9

0.45 0.60 0.75

0.9

0.75 0.8

0.7

0.60

0.6

0.45

0.6

0.7

0.8

0.9

0.45 0.60 0.75

0.80

0.56

0.72

0.48

0.64

0.40

0.56

0.6

0.7

0.8

0.9

0.45 0.60 0.75

0.8

0.75 0.6

0.50 0.4

0.25

0.2

0.6

0.7

0.8

0.9

0.45 0.60 0.75

0.75

0.60

0.45 0.60

0.6 0.7 0.8 0.9 0.30 0.45 0.60 0.75 +9.96e 1
0.006 0.88
0.004 0.80

0.002 0.72

0.6

0.7

0.8

0.9

0.45 0.60 0.75

1.0

0.90 0.75
0.6

0.7

0.8

dSprites

0.8

0.6

0.9 0.4 0.45

0.60 0.75 dSprites

β-VAE
0.4 0.3 0.2 0.1 0.0
0.0
0.30
0.15
0.00 0.0
0.075 0.050 0.025 0.000
0.0
0.2
0.1
0.0 0.0
0.3 0.2 0.1 0.0
0.0 0.16 0.12 0.08 0.04
0.0 0.6 0.4 0.2 0.0
0.0

FactorVAE Metric = MIG
0.1 0.2 0.3 0.1 0.2 0.3 0.1 0.2 0.3 0.1 0.2 0.3 0.1 0.2 0.3 0.1 0.2 0.3 0.1 0.2 0.3
dSprites

β-TCVAE

DIP-VAE-I

DIP-VAE-II

Metric = DCI Disentanglement 0.92 0.45

0.88 0.30

0.84 0.15
0.80 0.00 0.4 0.00 0.15 0.30 0.45
0.92 0.45

0.88 0.30

0.84 0.15
0.80 0.00 0.4 0.00 0.15 0.30 0.45 0.16

AnnealedVAE Metric = Modularity
0.80 0.84 0.88
0.80 0.84 0.88

0.075 0.050 0.025 0.000 0.92 0.000 0.075 0.050 0.025 0.000 0.92 0.000 0.024

Metric = SAP 0.025 0.050 0.075 0.025 0.050 0.075

0.12
0.08
0.04 0.4 0.00 0.15 0.30 0.45
0.3

0.88 0.016
0.80 0.008
0.72 0.000
0.80 0.84 0.88 0.92 0.000 0.025 0.050 0.075 0.80

0.2 0.1 0.0 0.4 0.00 0.15 0.30 0.45 0.4 0.3 0.2 0.1 0.4 0.00 0.15 0.30 0.45 0.5 0.4 0.3 0.2 0.1 0.4 0.00 0.15 0.30 0.45
0.75
0.50

0.75

0.050

0.70 0.025
0.65 0.000
0.60 0.80 0.84 0.88 0.92 0.000 0.025 0.050 0.075 0.16
0.96 0.12

0.88

0.08

0.80

0.04

0.00 0.80 0.84 0.88 0.92 0.000 0.025 0.050 0.075

0.96

0.024

0.92 0.016

0.88 0.008

0.84

0.000 0.80 0.84 0.88 0.92 0.000 0.025 0.050 0.075

1.00

0.12

0.95
0.08 0.90

0.25 0.4 0.00 0.15 0.30 0.45
dSprites

0.85 0.80 0.80

0.84 0.88 dSprites

0.04 0.92 0.000 0.025 0.050 0.075
dSprites

Metric value

Metric value

Metric value

Figure 18. Disentanglement scores on dSprites vs other data sets. Good hyperparameters only seem to transfer consistently from dSprites to Color-dSprites.

Dataset = SmallNORB

Dataset = Cars3D

Dataset = Shapes3D

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Dataset = dSprites LR10 18 13 18 19 -3 12

Dataset = Color-dSprites LR10 1 -11 -1 -5 15 -7

Dataset = Noisy-dSprites LR10 28 19 18 12 27 9

Dataset = Scream-dSprites LR10 61 65 60 55 48 60

LR100 65 49 63 65 -9 64

LR100 63 43 63 65 2 55

LR100 53 33 -0 -11 55 15

LR100 83 79 77 75 46 81

LR1000 28 13 20 18 15 20

LR1000 32 12 15 18 19 16

LR1000 60 40 2 -5 58 18

LR1000 86 79 80 80 41 84

LR10000 28 12 -1 4 18 12

LR10000 24 1 -1 5 23 8

LR10000 57 40 -8 -16 58 17

LR10000 89 83 82 82 43 87

GBT10 67 58 71 75 -6 71

GBT10 68 57 71 75 -4 71

GBT10 19 14 26 25 19 14

GBT10 67 68 68 65 41 64

GBT100 78 73 86 94 -17 77

GBT100 81 68 87 93 -5 77

GBT100 26 37 64 85 -19 28

GBT100 85 78 85 93 37 80

GBT1000 75 71 86 94 -19 74

GBT1000 76 66 84 89 -5 69

GBT1000 -1 20 52 75 -36 15

GBT1000 83 78 85 94 35 79

GBT10000 76 71 87 94 -13 75

GBT10000 72 61 82 84 5 66

GBT10000 -6 15 43 65 -35 8

GBT10000 81 75 82 92 33 78

Efficiency (LR) 50 43 62 62 -19 56 Efficiency (LR) 38 36 59 54 -15 43 Efficiency (LR) -14 -12 13 16 -18 -4 Efficiency (LR) -69 -63 -65 -67 -39 -67

Efficiency (GBT) 50 46 47 54 -14 49 Efficiency (GBT) 36 34 32 41 -21 41 Efficiency (GBT) 33 26 32 36 6 25 Efficiency (GBT) -71 -65 -72 -82 -28 -69

BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP
BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP
BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP
BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP

Dataset = SmallNORB LR10 -19 -21 -12 -4 29 -12

LR10 27

Dataset = Cars3D 7 -27 -3 -23 -3

LR10 55

LR100 1 -2 -41 -53 22 -45

LR100 4 -10 -39 -25 -44 -12

LR100 73

LR1000 24 23 -18 -29 0 -30

LR1000 12 -9 -44 -20 -49 -15

LR1000 44

LR10000 60 53 14 3 -33 -9

LR10000 19 -3 -40 -12 -43 -13

LR10000 42

GBT10 -46 -46 -26 -26 53 -21

GBT10 15 10 -6 4 -8 -8

GBT10 60

GBT100 63 39 83 86 -43 62

GBT100 13 27 44 52 17 8

GBT100 43

GBT1000 69 56 80 87 -56 53

GBT1000 37 57 64 80 45 21

GBT1000 53

GBT10000 74 63 77 82 -61 49

GBT10000 0 -13 -23 -32 -22 -1

GBT10000 59

Efficiency (LR) -49 -58 -59 -64 58 -38 Efficiency (LR) -17 -7 -2 -18 -2 4 Efficiency (LR) 14

Efficiency (GBT) -55 -77 -29 -34 64 0 Efficiency (GBT) 8 26 40 53 23 6 Efficiency (GBT) 23

Dataset = Shapes3D 38 -14 11 19 14 56 -1 30 30 32 11 -47 -1 38 -14 7 -52 -6 33 -16 56 51 71 42 55 36 71 96 50 50 42 56 97 55 49 46 48 94 55 49 40 66 35 -11 49 21 77 80 38 45

BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP
BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP
BetaVAE Score FactorVAE Score
MIG DCI Disentanglement
Modularity SAP

Figure 19. Rank-correlation between the metrics and the performance on downstream task on different data sets. We observe some correlation between most disentanglement metrics and downstream performance. However, the correlation varies across data sets.
where the goal is to recover the true factors of variations from the learned representation using either multi-class logistic regression (LR) or gradient boosted trees (GBT). Our goal is to investigate the relationship between disentanglement and the average classiﬁcation accuracy on these downstream tasks as well as whether better disentanglement leads to a decreased sample complexity of learning.
To compute the classiﬁcation accuracy for each trained model, we sample true factors of variations and observations from our ground truth generative models. We then feed the observations into our trained model and take the mean of the Gaussian encoder as the representations. Finally, we predict each of the ground-truth factors based on the representations with a separate learning algorithm. We consider both a 5-fold cross-validated multi-class logistic regression as well as gradient boosted trees of the Scikit-learn package. For each of these methods, we train on 10, 100, 1000 and 10 000 samples. We compute the average accuracy across all factors of variation using an additional set 10 000 randomly drawn samples.
Figure 19 shows the rank correlations between the disentanglement metrics and the downstream performance for all considered data sets. We observe that all metrics except Modularity seem to be correlated with increased downstream performance on the different variations of dSprites and to some degree on Shapes3D. However, it is not clear whether this is due to the fact that disentangled representations perform better or whether some of these scores actually also (partially) capture the informativeness of the evaluated representation. Furthermore, the correlation is weaker or inexistent on other data sets (e.g., Cars3D). Finally, we report in Figure 24 the rank correlation between unsupervised scores computed after training on the mean and sampled representation and downstream performance. Depending on the data set, the rank correlation ranges from from mildly negative, to mildly positive. In particular, we do not observe enough evidence supporting the claim that decreased total correlation of the aggregate posterior proves beneﬁcial for downstream task performance.
To assess the sample complexity argument we compute for each trained model a statistical efﬁciency score which we deﬁne as the average accuracy based on 100 samples divided by the average accuracy based on 10 000 samples for either the logistic regression or the gradient boosted trees. The key idea is that if disentangled representations lead to sample efﬁciency, then they should also exhibit a higher statistical efﬁciency score. We remark that this score differs from the deﬁnition of sample complexity commonly used in statistical learning theory. The corresponding results are shown in Figures 20 and 21 where we plot the statistical efﬁciency versus different disentanglement metrics for different data sets and models and in Figure 19 where we show rank correlations. Overall, we do not observe conclusive evidence that models with higher disentanglement scores also lead to higher statistical efﬁciency. We note that some AnnealedVAE models seem to exhibit a high statistical efﬁciency on Scream-dSprites and to some degree on Noisy-dSprites. This can be explained by the fact that these models

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Dataset = dSprites

Dataset = Color-dSprites

Dataset = Noisy-dSprites

Dataset = Scream-dSprites

Efficiency (LR)

Efficiency (LR)

Model

β-VAE

FactorVAE

β-TCVAE

DIP-VAE-I

DIP-VAE-II

AnnealedVAE

1.0 Metric = BetaVAE Score

1.0 Metric = FactorVAE Score

1.0

Metric = MIG

1.0 Metric = DCI Disentanglement 1.0 Metric = Modularity

1.0

Metric = SAP

0.8

0.8

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.6

0.8

1.0 0.2 0.4 0.6 0.8 1.0

0.0

0.2

0.4

0.4

0.4

0.4

0.0 0.2 0.4 0.6 0.6 0.7 0.8 0.9 1.0

0.00 0.04 0.08

0.90

0.90

0.90

0.90

0.90

0.90

0.75

0.75

0.75

0.75

0.75

0.75

0.60

0.60

0.60

0.60

0.60

0.60

0.60 0.75 0.90

0.2 0.4 0.6 0.8 1.0

0.0

0.2

0.4

0.0 0.2 0.4 0.6 0.7

0.8

0.9

1.0

0.00 0.04 0.08

1.0

1.0

1.0

1.0

1.0

1.0

0.8

0.8

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.6

0.6

0.4 0.25 0.50 0.75 1.00 0.4 0.0 0.3 0.6

0.4 0.0 0.1 0.2 0.3 0.4 0.00 0.15 0.30 0.4 0.60 0.75 0.90

0.4 0.00 0.03 0.06

Efficiency (LR)

Efficiency (LR)

0.90

0.90

0.90

0.90

0.90

0.90

0.75

0.75

0.75

0.75

0.75

0.75

0.25 0.50 0.75

0.2 0.4 0.6 0.8

0.0 0.1 0.2 0.3

0.00

0.15

0.30

0.60

0.75

0.90

0.00

0.04

0.08

1.0

1.0

1.0

1.0

1.0

1.0

Efficiency (LR)

0.8

0.8

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.6

0.4

0.6

0.8

1.0 0.2 0.4 0.6 0.8

0.00

0.15

0.30

0.0 0.1 0.2 0.3 0.4

0.75

0.90

0.8

0.8

0.8

0.8

0.8

0.6
0.00 0.08 0.16 0.8

Efficiency (LR)

0.6

0.6

0.6

0.6

0.6

0.6

0.4

0.4

0.4

0.4

0.4

0.4

Efficiency (LR)

0.2 0.97 0.98 0.99 1.00

0.2

0.2

0.2

0.6 0.7 0.8 0.9 1.0

0.0 0.1 0.2 0.3 0.0

1.00

1.00

1.00

1.00

0.75

0.75

0.75

0.75

0.50

0.50

0.50

0.50

0.4 0.6 0.8 1.0 Value

0.3

0.6

0.9

Value

0.0

0.4

0.8

0.0

Value

0.2

0.4

0.4

0.8

Value

0.2

0.6 0.7

0.8

0.9

1.00

0.75

0.50

1.2

0.75

0.90

Value

1.0 0.2 0.000 0.025 0.050 1.00 0.75 0.50 0.0 0.1 0.2 0.3 Value

Figure 20. Statistical efﬁciency (accuracy with 100 samples ÷ accuracy with 10 000 samples) based on a logistic regression versus disentanglement metrics for different models and data sets. We do not observe that higher disentanglement scores lead to higher statistical efﬁciency.

Dataset = SmallNORB

Dataset = Cars3D

Dataset = Shapes3D

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Dataset = dSprites

Dataset = Color-dSprites

Dataset = Noisy-dSprites

Dataset = Scream-dSprites

Efficiency (GBT)

Efficiency (GBT)

Efficiency (GBT)

Metric = BetaVAE Score 0.64

Model Metric = FactorVAE Score
0.64

β-VAE
0.64

FactorVAE Metric = MIG

β-TCVAE

DIP-VAE-I

DIP-VAE-II

Metric = DCI Disentanglement

AnnealedVAE Metric = Modularity

0.64

0.64

0.64

Metric = SAP

0.56

0.56

0.56

0.56

0.56

0.56

0.48

0.48

0.48

0.48

0.48

0.48

0.40

0.40

0.40

0.40

0.40

0.40

0.4

0.6

0.8

1.0 0.2 0.4 0.6 0.8 1.0

0.0

0.2

0.4

0.0 0.2 0.4 0.6 0.6 0.7 0.8 0.9 1.0

0.00 0.04 0.08

0.7

0.7

0.7

0.7

0.7

0.7

0.6

0.6

0.6

0.6

0.6

0.6

0.5

0.5

0.5

0.5

0.5

0.5

0.4

0.4

0.4

0.60 0.75 0.90

0.2 0.4 0.6 0.8 1.0

0.0

0.2

0.4

0.4

0.4

0.4

0.0 0.2 0.4 0.6 0.7

0.8

0.9

1.0

0.00 0.04 0.08

1.00

1.00

1.00

1.00

1.00

1.00

0.75

0.75

0.75

0.75

0.75

0.75

0.50

0.50

0.50

0.50

0.50

0.50

0.25 0.50 0.75 1.00

0.0

0.3

0.6

1.0

1.0

0.0 0.1 0.2 0.3

0.00

0.15

0.30

0.60 0.75 0.90

1.0

1.0

1.0

0.00 0.03 0.06 1.0

0.8

0.8

0.8

0.8

0.8

0.8

0.6

0.6

0.6

0.6

0.6

0.6

0.4 0.25 0.50 0.75 0.80

0.4 0.2 0.4 0.6 0.8 0.4 0.0

0.80

0.80

0.72

0.72

0.72

0.64

0.64

0.64

0.56

0.56

0.56

0.4

0.6

0.8

1.0 0.2 0.4 0.6 0.8

0.00

0.60

0.60

0.60

0.1 0.2 0.3 0.4 0.00 0.15 0.30 0.4 0.60 0.75 0.90

0.80

0.80

0.72

0.72

0.64

0.64

0.56

0.56

0.15

0.30

0.0 0.1 0.2 0.3 0.4

0.75

0.90

0.60

0.60

0.4 0.00 0.04 0.80 0.72 0.64 0.56
0.00 0.08 0.60

0.08 0.16

Efficiency (GBT)

Efficiency (GBT)

Efficiency (GBT)

0.45

0.45

0.45

0.45

0.45

0.45

0.30

0.30

0.30

0.30

0.30

0.30

0.97 0.98 0.99 1.00

0.6 0.7 0.8 0.9 1.0

0.0 0.1 0.2 0.3 0.0

0.2

0.4

0.6 0.7

0.8

0.9

1.0

0.000 0.025 0.050

1.00

1.00

1.00

1.00

1.00

1.00

Efficiency (GBT)

0.75

0.75

0.75

0.75

0.75

0.75

0.50 0.4 0.6 0.8 1.0 Value

0.50 0.3

0.6

0.9

Value

0.50

0.0

0.4

0.8

Value

0.50 0.0

0.4

0.8

Value

0.50

1.2

0.75

0.90

Value

0.50 0.0 0.1 0.2 0.3 Value

Figure 21. Statistical efﬁciency (accuracy with 100 samples ÷ accuracy with 10 000 samples) based on gradient boosted trees versus disentanglement metrics for different models and data sets. We do not observe that higher disentanglement scores lead to higher statistical efﬁciency (except for DCI Disentanglement and Mutual Information Gap on Shapes3D and to some extend in Cars3D).

Dataset = SmallNORB

Dataset = Cars3D

Dataset = Shapes3D

Value

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Bottom 33% (DCI Disentanglement)

Middle 33% (DCI Disentanglement)

Top 33% (DCI Disentanglement)

0.8

Dataset = Cars3D

0.8

Dataset = Color-dSprites

0.6

Dataset = Noisy-dSprites

0.40

Dataset = Scream-dSprites

0.7

0.7

0.5

0.35

0.6

0.6

0.4

0.30

0.5

0.5

0.25

0.4

0.4

0.3

0.3

0.3

0.20 0.2

0.2

0.2

0.15

0.1

0.1

0.1

0.10

0.0

1.2

Dataset = Shapes3D

0.0

0.8

Dataset = SmallNORB

0.0

0.8

Dataset = dSprites

0.05 GBT10 GBT100 GBT1000 GBT10000 Metric

1.0

0.7

0.7

0.8

0.6

0.6

0.5

0.5

0.6

0.4

0.4

0.4

0.3

0.3

0.2

0.2

0.2

0.1

0.0 GBT10 GBT100 GBT1000 GBT10000 0.1 GBT10 GBT100 GBT1000 GBT10000 0.0 GBT10 GBT100 GBT1000 GBT10000

Metric

Metric

Metric

Figure 22. Downstream performance for three groups with increasing DCI Disentanglement scores.

Value

have low downstream performance and that hence the accuracy with 100 samples is similar to the accuracy with 10 000 samples. We further observe that DCI Disentanglement and MIG seem to be lead to a better statistical efﬁciency on the the data set Shapes3D for gradient boosted trees. Figures 22 and 23 show the downstream performance for three groups with increasing levels of disentanglement (measured in DCI Disentanglement and MIG respectively). We observe that indeed models with higher disentanglement scores seem to exhibit better performance for gradient boosted trees with 100 samples. However, considering all data sets, it appears that overall increased disentanglement is rather correlated with better downstream performance (on some data sets) and not statistical efﬁciency. We do not observe that higher disentanglement scores reliably lead to a higher sample efﬁciency.
Implications. While the empirical results in this section are negative, they should also be interpreted with care. After all, we have seen in previous sections that the models considered in this study fail to reliably produce disentangled representations. Hence, the results in this section might change if one were to consider a different set of models, for example semi-supervised or fully supervised one. Furthermore, there are many more potential notions of usefulness such as interpretability and fairness that we have not considered in our experimental evaluation. Nevertheless, we argue that the lack of concrete examples of useful disentangled representations necessitates that future work on disentanglement methods should make this point more explicit. While prior work (Steenbrugge et al., 2018; Laversanne-Finot et al., 2018; Nair et al., 2018; Higgins et al., 2017b; 2018) successfully applied disentanglement methods such as β-VAE on a variety of downstream tasks, it is not clear to us that these approaches and trained models performed well because of disentanglement.

Value

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

Bottom 33% (MIG)

Middle 33% (MIG)

Top 33% (MIG)

0.8

Dataset = Cars3D

0.8 Dataset = Color-dSprites

0.6 Dataset = Noisy-dSprites

0.40 Dataset = Scream-dSprites

0.7

0.7

0.5

0.35

0.6

0.6

0.4

0.30

0.5

0.5

0.25

0.4

0.4

0.3

0.3

0.3

0.20 0.2

0.2

0.2

0.15

0.1

0.1

0.1

0.10

0.0

1.2

Dataset = Shapes3D

0.0

0.8

Dataset = SmallNORB

0.0

0.8

Dataset = dSprites

0.05 GBT10 GBT100 GBT1000 GBT10000 Metric

1.0

0.7

0.7

0.8

0.6

0.6

0.5

0.5

0.6

0.4

0.4

0.4

0.3

0.3

0.2

0.2

0.2

0.1

0.0 GBT10 GBT100 GBT1000 GBT10000 0.1 GBT10 GBT100 GBT1000 GBT10000 0.0 GBT10 GBT100 GBT1000 GBT10000

Metric

Metric

Metric

Figure 23. Downstream performance for three groups with increasing MIG scores.

Value

Dataset = Cars3D LR10 -13 -55 65 -32 -80 15

Dataset = Color-dSprites LR10 -28 16 1 30 9 -9

Dataset = dSprites LR10 -18 21 -17 19 20 -21

Dataset = Noisy-dSprites LR10 -7 14 3 23 21 -1

LR100 -6 -40 67 -9 -66 28

LR100 -18 17 -31 7 22 -67

LR100 -14 1 -24 -9 8 -52

LR100 11 -2 30 10 9 40

LR1000 -11 -47 85 -5 -85 33 LR1000 -31 -15 17 2 -21 -22 LR1000 -36 -17 10 -7 -13 -13 LR1000 8 -4 36 9 3 46

LR10000 -14 -50 85 -10 -88 32 LR10000 -28 -47 45 -16 -52 -0 LR10000 -39 -54 48 -34 -54 11 LR10000 7 -19 49 -4 -15 57

GBT10 -5 -15 31 -4 -37 3

GBT10 17 19 -28 2 22 -59 GBT10 10 17 -28 5 16 -53 GBT10 11 31 -4 30 19 -2

GBT100 -9 20 -3 34 4 -40 GBT100 20 41 -44 19 42 -83 GBT100 14 34 -47 16 33 -80 GBT100 21 40 -48 20 29 -43

GBT1000 -10 -3 -12 2 3 -42 GBT1000 18 46 -41 28 44 -82 GBT1000 15 35 -48 17 35 -83 GBT1000 5 17 -47 -2 6 -54

GBT10000 21 -28 28 -27 -30 29 GBT10000 15 44 -34 35 43 -74 GBT10000 14 30 -42 16 32 -80 GBT10000 -8 1 -37 -13 -8 -52

TC (sampled) TC (mean)
avgMI (sampled) avgMI (mean) Reconstruction KL TC (sampled) TC (mean)
avgMI (sampled) avgMI (mean) Reconstruction KL TC (sampled) TC (mean)
avgMI (sampled) avgMI (mean) Reconstruction KL TC (sampled) TC (mean)
avgMI (sampled) avgMI (mean) Reconstruction KL

Dataset = Scream-dSprites LR10 -22 -36 27 -30 -38 -23

Dataset = Shapes3D LR10 -2 -45 43 -12 -48 5

Dataset = SmallNORB LR10 11 31 -2 27 17 8

LR100 -19 -26 2 -33 -18 -42 LR100 10 -35 47 -3 -46 -1

LR100 3 -3 24 11 7 26

LR1000 -16 -29 -8 -44 -16 -43 LR1000 7 -66 73 3 -79 2 LR1000 11 -23 36 -12 -22 37

LR10000 -11 -28 -9 -43 -15 -45 LR10000 8 -66 71 -1 -79 3 LR10000 12 -55 51 -53 -60 46

GBT10 -18 -36 20 -31 -30 -27 GBT10 -11 3 18 42 4 -27 GBT10 4 60 -21 54 46 -4

GBT100 -22 -40 4 -27 -14 -41 GBT100 -13 16 -2 51 27 -40 GBT100 -15 -40 -1 -57 -66 -11

GBT1000 -26 -43 9 -24 -15 -40 GBT1000 -8 3 13 46 12 -34 GBT1000 -3 -51 9 -72 -78 1

GBT10000 -26 -45 10 -24 -15 -39 GBT10000 -7 -4 21 43 3 -32 GBT10000 1 -60 17 -79 -84 9

TC (sampled) TC (mean)
avgMI (sampled) avgMI (mean) Reconstruction KL TC (sampled) TC (mean)
avgMI (sampled) avgMI (mean) Reconstruction KL TC (sampled) TC (mean)
avgMI (sampled) avgMI (mean) Reconstruction KL

Figure 24. Rank correlation between unsupervised scores and downstream performance.

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations
J. Additional Figures

TC (sampled)

Model

VAE

β-VAE

FactorVAE

β-TCVAE

DIP-VAE-I

DIP-VAE-II

AnnealedVAE

0.05

Dataset = dSprites

0.12

Dataset = Color-dSprites

0.12

Dataset = Noisy-dSprites

0.06 Dataset = Scream-dSprites

0.04

0.10

0.10

0.05

0.08

0.08

0.04

0.03

0.06

0.06

0.03

0.02

0.04

0.04

0.02

0.01

0.02

0.02

0.01

0.00

0.00

0.00

0.00

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

2.5

Dataset = SmallNORB

0.30

Dataset = Cars3D

0.25

Dataset = Shapes3D

Regularization strength

2.0

0.25

0.20

0.20

1.5

0.15

0.15

1.0

0.10

0.10

0.5

0.05

0.05

0.0

0.00

0.00

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

Regularization strength

Regularization strength

Regularization strength

TC (sampled)

Figure 25. Total correlation of sampled representation plotted against regularization strength for different data sets and approaches (including AnnealedVAE).

TC (mean)

Model

VAE

β-VAE

FactorVAE

β-TCVAE

DIP-VAE-I

DIP-VAE-II

AnnealedVAE

3.0

Dataset = dSprites

3.0

Dataset = Color-dSprites

5

Dataset = Noisy-dSprites

7

Dataset = Scream-dSprites

2.5

2.5

4

6

2.0

2.0

5

3

4

1.5

1.5

2

3

1.0

1.0

2

0.5

0.5

1

1

0.0

0.0

0

0

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

20

Dataset = SmallNORB

6

Dataset = Cars3D

2.5

Dataset = Shapes3D

Regularization strength

15 5 2.0 4 1.5

10

3

1.0 2

5

1

0.5

0

0

0.0

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

Regularization strength

Regularization strength

Regularization strength

TC (mean)

Figure 26. Total correlation of mean representation plotted against regularization strength for different data sets and approaches (including AnnealedVAE).

Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations

avgMI (sampled)

Model

VAE

β-VAE

FactorVAE

β-TCVAE

DIP-VAE-I

DIP-VAE-II

0.040

Dataset = dSprites

0.040

Dataset = Color-dSprites

0.040

Dataset = Noisy-dSprites

0.032 Dataset = Scream-dSprites

0.030

0.035

0.035

0.035

0.028

0.030

0.030

0.030

0.026

0.024

0.025

0.025

0.025

0.022

0.020

0.020

0.020

0.020

0.018

0.015

0.015

0.015

0.016

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

0.035

Dataset = SmallNORB

0.050

Dataset = Cars3D

0.12

Dataset = Shapes3D

Regularization strength

0.045

0.030

0.040

0.10

0.035

0.08

0.025

0.030

0.06

0.020 0.025 0.04 0.020

0.015

0.015

0.02

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

Regularization strength

Regularization strength

Regularization strength

avgMI (sampled)

Figure 27. The average mutual information of the dimensions of the sampled representation generally decrease except for DIP-VAE-I.

avgMI (mean)

Model

VAE

β-VAE

FactorVAE

β-TCVAE

DIP-VAE-I

DIP-VAE-II

0.11

Dataset = dSprites

0.07

Dataset = Color-dSprites

0.11

Dataset = Noisy-dSprites

0.060 Dataset = Scream-dSprites

0.10

0.10

0.055

0.09

0.06

0.09

0.050

0.08

0.05

0.08

0.045

0.07 0.07 0.040

00..0056 0.04 0.06 0.035

0.04

0.03

0.05

0.030

0.03

0.04

0.025

0.02

0.02

0.03

0.020

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

0.35

Dataset = SmallNORB

0.08

Dataset = Cars3D

0.16

Dataset = Shapes3D

Regularization strength

0.30

0.07

0.14

0.25

0.06

0.12

0.20

0.05

0.10

0.15

0.10

0.04

0.08

0.05

0.03

0.06

0.00

0.02

0.04

0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0

Regularization strength

Regularization strength

Regularization strength

Figure 28. The average mutual information of the dimensions of the mean representation generally increase.

avgMI (mean)

