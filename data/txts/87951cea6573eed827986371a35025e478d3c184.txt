Stochastic Extragradient: General Analysis and Improved Rates

arXiv:2111.08611v3 [math.OC] 22 Feb 2022

Eduard Gorbunov
MIPT, Russia Mila & UdeM, Canada

Hugo Berard Mila & UdeM, Canada

Gauthier Gidel
Mila & UdeM, Canada Canada CIFAR AI Chair

Nicolas Loizou
Johns Hopkins University Baltimore, USA

Abstract
The Stochastic Extragradient (SEG) method is one of the most popular algorithms for solving min-max optimization and variational inequalities problems (VIP) appearing in various machine learning tasks. However, several important questions regarding the convergence properties of SEG are still open, including the sampling of stochastic gradients, mini-batching, convergence guarantees for the monotone ﬁnite-sum variational inequalities with possibly non-monotone terms, and others. To address these questions, in this paper, we develop a novel theoretical framework that allows us to analyze several variants of SEG in a uniﬁed manner. Besides standard setups, like Same-Sample SEG under Lipschitzness and monotonicity or Independent-Samples SEG under uniformly bounded variance, our approach allows us to analyze variants of SEG that were never explicitly considered in the literature before. Notably, we analyze SEG with arbitrary sampling which includes importance sampling and various mini-batching strategies as special cases. Our rates for the new variants of SEG outperform the current state-of-the-art convergence guarantees and rely on less restrictive assumptions.
1 INTRODUCTION
In the last few years, the machine learning community has been increasingly interested in diﬀerentiable game formulations where several parameterized models/players compete to minimize their respective objective functions. Notably, these formulations include
Proceedings of the 25th International Conference on Artiﬁcial Intelligence and Statistics (AISTATS) 2022, Valencia, Spain. PMLR: Volume 151. Copyright 2022 by the author(s).

generative adversarial networks (Goodfellow et al., 2014), proximal gradient TD learning (Liu and Wright, 2016), actor-critic (Pfau and Vinyals, 2016), hierarchical reinforcement learning (Wayne and Abbott, 2014; Vezhnevets et al., 2017), adversarial example games (Bose et al., 2020), and minimax estimation of conditional moment (Dikkala et al., 2020).
In that context, the optimization literature has considered a slightly more general setting, namely, variational inequality problems. Given a diﬀerentiable game, its corresponding VIP designates the necessary ﬁrst-order stationary optimality conditions. Under the assumption that the objectives functions of the diﬀerentiable game are convex (with respect to their respective players’ variables), the solutions of the VIP are also solutions of the original game formulation. In the unconstrained case, given an operator1F : Rd → Rd, the corresponding VIP is deﬁned as follows:
ﬁnd x∗ ∈ Rd such that F (x∗) = 0. (VIP)

When the operator F is monotone (a generalization of convexity), it is known that the standard gradient method does not converge without strong monotonicity (Noor, 2003; Gidel et al., 2019) or cocoercivity (Chen and Rockafellar, 1997; Loizou et al., 2021). Because of their convergence guarantees, even when the operator F is monotone, the extragradient method (Korpelevich, 1976) and its variants (Popov, 1980) have been the optimization techniques of choice to solve VIP. These techniques consist of two steps: a) an extrapolation step that computes a gradient update from the current iterate, and b) an update step that updates the current iterate using the value of the vector ﬁeld at the extrapolated point.

Motivated by recent applications in machine learning,

in this work we are interested in cases where the ob-

jective, operator F , is naturally expressed as a ﬁnite

sum, F (x) = n1

n i=1

Fi

(x)

or

more

generally

as

ex-

1In the context of a diﬀerentiable game, F corresponds to the concatenation of the gradients of the players’ losses, e.g., see the details in Gidel et al. (2019).

Stochastic Extragradient: General Analysis and Improved Rates

pectation F (x) = Eξ[Fξ(x)]. In that setting, we only assume to have access to a stochastic estimate of F .
Unfortunately, the additive value of extragradientbased techniques in the stochastic VIP setting is less apparent since the method is challenging to analyze in that setting due to the two stochastic gradient computations necessary for a single update. There are several ways to deal with the stochasticity in the SEG update. For example, one can use either independent samples (Nemirovski et al., 2009; Juditsky et al., 2011) or the same sample (Gidel et al., 2019) for the extrapolation and the update steps.
The selection of stepsizes in the update rule of SEG (for the extrapolation step and update step) is also a challenging task. In Chavdarova et al. (2019) it is shown that some same-stepsize variants of SEG diverge in the unconstrained monotone case. At the same time, in Hsieh et al. (2019) using a double stepsize rule, the authors provide convergence guarantees under an errorbound condition.
This discrepancy between the deterministic and the stochastic case has motivated a whole line of work (Gidel et al., 2019; Mishchenko et al., 2020; Beznosikov et al., 2020; Hsieh et al., 2019) to understand better the properties of SEG. However, several important questions remain open. To bridge this gap, in this work, we develop a novel theoretical framework that allows us to analyze several variants of SEG in a uniﬁed manner.

1.1 Preliminaries
Notation. We use standard notation for optimization literature. We also often use [n] to denote {1, . . . , n} and Eξ[·] for the expectation taken w.r.t. the randomness coming from ξ only.

Main assumptions. In this work, we assume that the operator F is L-Lipschitz and µ-quasi strongly monotone. Assumption 1.1. Operator F (x) is L-Lipschitz, i.e., for all x, y ∈ Rd

F (x) − F (y) ≤ L x − y .

(1)

Assumption 1.2. Operator F (x) is µ-quasi strongly monotone, i.e., for µ ≥ 0 and for all x ∈ Rd

F (x), x − x∗ ≥ µ x − x∗ 2.

(2)

We assume that x∗ is unique.

Assumption 1.1 is relatively standard and widely used in the literature on VIP. Assumption 1.2 is a relaxation of µ-strong monotonicity as it includes some non-monotone games as special cases. To the best

of our knowledge, the term quasi-strong monotonicity was introduced in Loizou et al. (2021) and has its roots in the quasi-strong convexity condition from the optimization literature (Necoara et al., 2019; Gower et al., 2019). In the literature of variational inequality problems, quasi strongly monotone problems are also known as strong coherent VIPs (Song et al., 2020) or VIPs satisfying the strong stability condition (Mertikopoulos and Zhou, 2019). If µ = 0, then Assumption 1.2 is also known as variational stability condition (Hsieh et al., 2020; Loizou et al., 2021).

Variants of SEG. In the literature of variational inequality problems there are two main stochastic extragradient variants.
The ﬁrst is Same-sample SEG:
xk+1 = xk − γ2,ξk Fξk xk − γ1,ξk Fξk (xk) , (S-SEG)
where in each iteration, the same sample ξk is used for the exploration (computation of xk −γ1,ξk Fξk (xk)) and update (computation of xk+1) steps. The selection of step-sizes γ2,ξk and γ1,ξk that guarantee convergence of the method in diﬀerent settings varies across previous papers (Mishchenko et al., 2020; Beznosikov et al., 2020; Hsieh et al., 2019). In this work, the proposed stepsizes for S-SEG satisfy 0 < γ2,ξk = αγ1,ξk , where 0 < α < 1, and are allowed to depend on the sample ξk. This speciﬁc stepsize selection is one of the main contributions of this work and we discuss its beneﬁts in more detail in the subsequent sections.
The second variant is Independent-samples SEG

xk+1 = xk − γ2Fξk xk − γ1Fξk (xk) ,

2

1

(I-SEG)

where ξ1k, ξ2k are independent samples. Similarly to SSEG, we assume that 0 < γ2 = αγ1, with 0 < α < 1, but unlike S-SEG, for I-SEG we consider stepsizes independent of samples ξ1k, ξ2k.2
Typically, S-SEG is analyzed under Lipschitzness and (strong) monotonicity of individual stochastic realizations Fξ (Mishchenko et al., 2020) that are stronger than Assumptions 1.1 and 1.2. In contrast, I-SEG is studied under Assumptions 1.1 and 1.2 but with additional assumptions like uniformly bounded variance or its relaxations (Beznosikov et al., 2020; Hsieh et al., 2020). See Appendix F.1 for further clariﬁcations.

1.2 Contributions
Our main contributions are summarized below.
2This is mainly motivated by the fact that the analysis of I-SEG does not rely on the Lipshitzness of particular stochastic realizations Fξ.

Eduard Gorbunov, Hugo Berard, Gauthier Gidel, Nicolas Loizou

Uniﬁed analysis of SEG. We develop a new theoretical framework for the analysis of SEG. In particular, we construct a uniﬁed assumption (Assumption 2.1) on the stochastic estimator, stepsizes, and the problem itself (VIP), and we prove a general convergence result under this assumption (Theorem 2.1). Next, we show that both S-SEG and I-SEG ﬁt our theoretical framework and can be analyzed in diﬀerent settings in a uniﬁed manner. In previous works, these variants of SEG have been only analyzed separately using diﬀerent proof techniques. Our proposed proof technique diﬀers signiﬁcantly from those existing in the literature and, therefore, is of independent interest.
Sharp rates for the known methods. Despite the generality of our framework, our convergence guarantees give tight rates for several well-known special cases. That is, the proposed analysis either recovers best-known (up to numerical factors) rates for some special cases like the deterministic EG and the I-SEG under uniformly bounded variance (UBV) assumption (Assumption 4.1 with δ = 0), or improves the previous SOTA results for other well known special cases, e.g., for S-SEG with uniform sampling and I-SEG under the generalized UBV assumption (Assumption 4.1 with δ > 0).
New methods with better rates. Through our framework, we propose a general yet simple theorem describing the convergence of S-SEG under the arbitrary sampling paradigm (Gower et al., 2019; Loizou et al., 2021). Using the theoretical analysis of S-SEG with arbitrary sampling, we can provide tight convergence guarantees for several well-known methods like the deterministic/full-batch EG and S-SEG with uniform sampling (S-SEG-US) as well as some variants of S-SEG that were never explicitly considered in the literature before. For example, we are ﬁrst to analyze S-SEG with mini-batch sampling without replacement (b-nice sampling; S-SEG-NICE) and show its theoretical superiority to vanilla S-SEG-US. Moreover, we propose a new method called S-SEG-IS that combines S-SEG with importance sampling – the sampling strategy, when the i-th operator from the sum is chosen with probability proportional to its Lipschitz constant. We prove the theoretical superiority of S-SEG-IS in comparison to S-SEG-US.
Novel stepsize selection. One of the key ingredients of our approach is the use of sample-dependent stepsizes. This choice of stepsizes is especially important for the S-SEG-IS, as it allows us to obtain better theoretical guarantees compared to the S-SEG-US. Moreover, as in Hsieh et al. (2020), for the update step we also use smaller stepsizes than for the exploration step: γ2,ξk ≤ γ1,ξk (γ2 ≤ γ1). However, unlike the results by Hsieh et al. (2020), our theory allows us-

ing γ2,ξk = αγ1,ξk with constant parameter α < 1 to achieve any predeﬁned accuracy of the solution.
Convergence guarantees under weak conditions. The ﬂexibility of our approach helps us to derive our main theoretical results under weak assumptions. In particular, in the analysis of S-SEG, we allow the stochastic realizations Fξ to be (µξ, x∗)-quasi strongly monotone with possibly negative µξ, meaning that Fξ can be non-monotone (see Assumption 3.2). In addition, in the analysis of S-SEG we do not require any bounded variance assumption. To the best of our knowledge, all previous works on the analysis of S-SEG require monotonicity of Fξ. Finally, in the analysis of I-SEG we obtain last-iterate convergence guarantees by only assuming µ-quasi strong monotonicity of F , which, as we explained before, is satisﬁed for some classes of non-monotone problems.
Numerical evaluation. In Section 5, we corroborate our theoretical results with experimental testing.
1.3 Related Work
Non-monotone VIP with special structure. Recent works of Daskalakis et al. (2021) and Diakonikolas et al. (2021) show that, for general nonmonotone VIP, the computation of approximate ﬁrstorder locally optimal solutions is intractable, motivating the identiﬁcation of structural assumptions on the objective function for which these intractability barriers can be bypassed.
In this work, we focus on such settings (structured nonmonotone operators) for which we are able to provide tight convergence guarantees and avoid the standard issues (like cycling and divergence of the methods) appearing in the more general non-monotone regime. In particular, we focus on quasi-strongly monotone VIPs (2). Recently, similar conditions have been used in several papers to provide convergence guarantees of algorithms for solving such structured classes of nonmonotone problems. For example,Yang et al. (2020) focuses on analyzing alternating gradient descent ascent under the Two-sided Polyak- Lojasiewicz inequality, while Hsieh et al. (2020) provides convergence guarantees of double stepsize stochastic extragradient for problems satisfying the error bound condition. Song et al. (2020) and Loizou et al. (2021) study the optimistic dual extrapolation and the stochastic gradient descent-ascent and stochastic consensus optimization method, respectively, for solving quasistrongly monotone problems. Kannan and Shanbhag (2019) provides an analysis for the stochastic extragradient for the class of strongly pseudo-monotone VIPs. The convergence of Hamiltonian methods for solving (stochastic) suﬃciently bilinear games (class of struc-

Stochastic Extragradient: General Analysis and Improved Rates

Table 1: Summary of the state-of-the-art convergence result for S-SEG and I-SEG. Our results are highlighted in green. Columns with
convergence rates provide the upper bounds for E[ xK − x∗ 2]. Numerical constants are omitted. Notation: µmin = mini∈[n] µi; µ = n1 i∈[n]:µi≥0 µi + n4 i∈[n]:µi<0 µi; Lmax = maxi∈[n] Li; L = n1 ni=1 Li (can be much smaller than Lmax); R02 = x0 − x∗ 2; σU2S∗ = n1 ni=1 Fi(x∗) 2; σI2S∗ = n1 ni=1 LLi Fi(x∗) 2 (can be much smaller than σU2S∗); δ and σ2 = parameters from As. 4.1; b = batchsize. Assumptions on constant stepsizes: Mishchenko et al. (2020) uses γ ≤ 1/2Lmax, Hsieh et al. (2019) uses γ2 ≤ γ1 ≤ c/L for some positive c > 0, Beznosikov et al. (2020) uses γ ≤ 1/4L, and we use γ1,ξ = γ ≤ 1/6Lmax for S-SEG-US, γ1,ξ = γL/Lξ, γ ≤ 1/6L for S-SEG-IS,
γ1,ξ = γ ≤ min 1µ8bδ , 4µ+√6(1L2+δ/b) for I-SEG, and in all cases γ2,ξ = αγ1 with α < 1. Numerical factors in our theoretical estimates can be tightened for S-SEG when µi ≥ 0 and for I-SEG when δ = 0.

Setup

Method

Citation

Convergence Rate for

Constant Stepsize

Diminishing Stepsize

n

F (x)

=

1 n

Fi (x)

i=1

+ As. 3.1, 3.2

F (x) = Eξ[Fξ(x)] + As. 1.1, 1.2, 4.1

S-SEG-US S-SEG-IS
I-SEG

(Mishchenko et al., 2020)(1) This paper This paper
(Hsieh et al., 2020)(3) (Beznosikov et al., 2020)(5)

(1 − γµmin)K R02 + γµσmU2iSn∗ (1 − γµ)K R02 + γσµU2S∗ (1 − γµ)K R02 + γσµI2S∗
(1 − γ1γ2µ2)K R02 + Cµσ2b2 C = γ1L(1 + γ1L) + γγ21
(1 − γµ)K R02 + γµσb2

This paper

(1 − γµ)K R02 + γµσb2

LmaxR02 exp
µmin

− µLmminaxK

+ µσ2U2S∗K (2)

min

LmaxR02 exp − µK + σU2S∗

µ

Lmax

µ2 K

LR02 exp − µK + σI2S∗

µ

L

µ2 K

L2σ2 (4) µ4 bK 1/3

R02 exp − µLK + µ2σb2K (6)

κR02 exp

−

K κ

+ √µ2σb2K

κ = max µδ2b , L+ µ δ/b

(1) Mishchenko et al. (2020) consider a regularized version of (VIP) with µmin-strongly convex regularization, F (x) = Eξ[Fξ(x)] and Fξ(x)

being monotone and Lξ-Lipschitz. In this case, one can construct an equivalent problem with convex regularizer, F (x) = Eξ[Fξ(x)] and

Fξ (x)

being

µmin -strongly

monotone

and

Lξ -Lipschitz.

If

regularization

is

zero

in

the

obtained

problem

and

Eξ [Fξ (x)]

=

1 n

n i=1

Fi (x),

the problem from (Mishchenko et al., 2020) ﬁts the considered setup with µi > 0 for all i ∈ [n].

(2) Mishchenko et al. (2020) do not consider diminishing stepsizes, but this rate can be derived from their Theorem 2 using similar steps

as we use for our results. (3) Hsieh et al. (2020) consider As. 4.1, but do not provide explicit rates when δ > 0. Moreover, instead of µ-quasi strong monotonicity they use slightly diﬀerent assumption: F (x) ≥ µ x − x∗ .

(4) This bound holds only for large enough K and σ > 0. Factor L2/µ4 is not explicitly given in (Hsieh et al., 2020). We derive this rate using γ1,k = γ1/(k+t)2/3, γ2,k = γ2/(k+t)1/3 with largest possible γ1 ∼ 1/µ, γ2 ∼ 1/µ and smallest possible t ∼ (L/µ)3 for given γ1 and γ2.

(5) Results are derived for the case δ = 0. Beznosikov et al. (2020) study a distributed version of I-SEG.

(6) This result is derived for the stepsize γ that explicitly depends on K and σ2, which makes it hard to use this stepsize in practice.

tured non-monotone games) was studied in Abernethy et al. (2021) and Loizou et al. (2020).
On the analysis of stochastic extragradient. In the context of VIP, SEG is also known as Stochastic Mirror Prox Juditsky et al. (2011). Several novel variants of SEG have been proposed and analyzed in recent papers, such as accelerated versions (Chen et al., 2017), single-call variants (a.k.a. optimistic methods) Hsieh et al. (2019), and a version with player sampling in the context of multi-player games (Jelassi et al., 2020). Comparing our results with these variants is outside of the scope of this paper. In this work, we focus on analyzing and better understanding the properties of the standard version of SEG with independent (I-SEG) or same sample (S-SEG).
Recent analysis of SEG by Mishchenko et al. (2020), Hsieh et al. (2020) and Beznosikov et al. (2020) have extended the seminal results of Juditsky et al. (2011) in the unconstrained case. We compare their results with our work in Table 1.
SEG has also been analyzed in settings that signiﬁcantly diﬀer from ours such as in the constrained pseudomonotone case (Kannan and Shanbhag, 2019) and the unconstrained bilinear case (Li et al., 2021).

Arbitrary sampling paradigm. The ﬁrst analysis of a stochastic optimization algorithm with an arbitrary sampling was performed by Richt´arik and Tak´aˇc (2016) in the context of randomized coordinate descent method for strongly convex functions. This arbitrary sampling paradigm was later extended in diﬀerent settings, including accelerated coordinate descent for (strongly) convex functions (Hanzely and Richt´arik, 2019; Qu and Richt´arik, 2016), randomized iterative methods for solving linear systems (Richt´arik and Tak´ac, 2020; Loizou and Richt´arik, 2020b,a), randomized gossip algorithms (Loizou and Richt´arik, 2021), variance-reduced methods with convex (Khaled et al., 2020), and nonconvex (Horv´ath and Richt´arik, 2019) objectives. The ﬁrst analysis of SGD under the arbitrary sampling was proposed in Gower et al. (2019) for (quasi)-strongly convex problems and later extended to the non-convex regime in Gower et al. (2021) and Khaled and Richt´arik (2020). In the area of smooth games and variational inequality problems the ﬁrst papers that provide an analysis of stochastic algorithms under the arbitrary sampling paradigm are (Loizou et al., 2020, 2021). In Loizou et al. (2020, 2021), the authors focus on algorithms like the stochastic Hamiltonian method, the stochastic gradient descent ascent, and the stochastic consensus optimization. To the

Eduard Gorbunov, Hugo Berard, Gauthier Gidel, Nicolas Loizou

best of our knowledge, our work is the ﬁrst that provides an analysis of SEG under the arbitrary sampling paradigm.

1.4 Paper Organization
Section 2 introduces our uniﬁed theoretical framework that is applied for the analysis of S-SEG and I-SEG in Sections 3 and 4 respectively. In section 5, we report the result of our numerical experiments, and we make the concluding remarks in Section 6. Proofs, technical details, and additional experiments are given in Appendix. We defer the discussion of our results for quasi monotone (µ = 0) problems to Appendix B.

2 GENERAL ANALYSIS OF SEG

To analyze the convergence of SEG, we consider a family of methods

xk+1 = xk − γξk gξk (xk),

(3)

where gξk (xk) is some stochastic operator evaluated at point xk and ξk encodes the randomness/stochasticity appearing at iteration k (e.g., it can be the sample used at step k). Parameter γξk is the stepsize that is allowed to depend on ξk. Inspired by Gorbunov et al. (2020), let us introduce the following general assumption on operator gξk (xk), stepsize γξk , and the problem (VIP).
Assumption 2.1. We assume that there exist non-
negative constants A, B, C, D1, D2 ≥ 0, ρ ∈ [0, 1], and (possibly random) non-negative sequence {Gk}k≥0 such that

Eξk γξ2k gξk (xk) 2 ≤ 2APk + C xk − x∗ 2 + D1, (4)

Pk ≥ ρ xk − x∗ 2 + BGk − D2,

(5)

where Pk = Eξk γξk gξk (xk), xk − x∗ .

Although inequalities (4) and (5) may seem unnatu-
ral, they are satisﬁed with certain parameters for sev-
eral variants of S-SEG and I-SEG under reasonable as-
sumptions on the problem and the stochastic noise.
Moreover, these inequalities have a simple intuition
behind them. That is, inequality (4) is a generaliza-
tion of the expected cocoercivity introduced in Loizou
et al. (2021), adjusted to the case of biased estimators gξk (xk) of F (xk), as it is the case for SEG. The biasedness of gξk (xk) and the (possible) dependence of γξk on ξk force us to introduce the expected inner product Pk = Eξk γξk gξk (xk), xk − x∗ instead of using Pk ∼ F (xk), xk −x∗ as in Loizou et al. (2021). Moreover, unlike the expected cocoercivity, our assumption
(4) does not imply (star-)cocoercivity of F . However,
when we derive (4) for S-SEG and I-SEG we rely in Lip-
schitzness of F or its stochastic realizations. The terms

C xk − x∗ 2 and D1 characterize the noise structure, and A is typically some constant smaller than 1/2.

Next, inequality (5) can be seen as a modiﬁcation of
µ-quasi strong monotonicity of F (2). Indeed, if we had γξk = γ and Eξk [gξk (xk)] = F (xk), then we would have Pk = γ F (xk), xk − x∗ and inequality (5) would
have been satisﬁed with ρ = γµ, B = 0, Gk = 0,
D2 = 0 for F being µ-quasi strongly monotone. However, because of the biasedness of gξk (xk) we have to account to the noise encoded by D2. In inequality (5), ρ also typically depends on some quantity related to
the quasi-strong monotonicity and the stepsize. Moreover, when gξk (xk) corresponds to SEG, we are able to show that B > 0 with Gk being an upper bound for F (xk) 2 up to the factors depending on the stepsize
selection (see Sections 3 and 4).

Under this assumption, we derive the following result.
Theorem 2.1. Let Assumption 2.1 hold with A ≤ 1/2 and ρ > C ≥ 0. Then, the iterates of SEG given by (3) satisfy

E xK − x∗ 2 ≤ (1 + C − ρ)K x0 − x∗ 2 + D1 + D2 . ρ−C

In the case that Assumption 2.1 holds with ρ = C = 0,

B > 0, then for all K ≥ 0, the iterates of SEG given

by (3) satisfy

1K

x0 − x∗ 2 D1 + D2

K +1

E[Gk] ≤ B(K + 1) +

. B

k=0

This theorem establishes linear convergence rate when ρ > C ≥ 0 and O(1/K) rate when ρ = C = 0, B > 0 to a neighborhood of the solution with the size proportional to the noise parameters D1, D2. In all special cases that we consider, the ﬁrst case corresponds to the quasi-strongly monotone problems and the second one – to quasi-monotone problems. All the rates from this paper are derived via Theorem 2.1.

3 SAME-SAMPLE SEG (S-SEG)
Consider the situation when we have access to Lipschitz-continuous stochastic realization Fξ(x) and can compute Fξ at diﬀerent points for the same ξ. For such problems, we consider S-SEG.

3.1 Arbitrary Sampling
Below we introduce reasonable assumptions on the stochastic trajectories that cover a wide range of sampling strategies. Therefore, following Gower et al. (2019); Loizou et al. (2021), we use the name arbitrary sampling to deﬁne this setup. First, we assume Lischitzness of Fξ.

Stochastic Extragradient: General Analysis and Improved Rates

Assumption 3.1. We assume that for all ξ there ex-
ists Lξ > 0 such that operator Fξ(x) is Lξ-Lipschitz, i.e., for all x ∈ Rd

Fξ(x) − Fξ(y) ≤ Lξ x − y .

(6)

The next assumption can be considered as a relaxation of standard strong monotonicity allowing Fξ(x) to be non-monotone with a certain structure.
Assumption 3.2. We assume that for all ξ operator Fξ(x) is (µξ, x∗)-strongly monotone, i.e., there exists (possibly negative) µξ ∈ R such that for all x ∈ Rd
Fξ(x) − Fξ(x∗), x − x∗ ≥ µξ x − x∗ 2. (7)

We emphasize that some µξ are allowed to be arbi-
trary heterogeneous and even negative, which allows
to have non-monotone Fξ. Moreover, if Fξ is Lξ-
Lipschitz, then in view of Cauchy-Schwarz inequality,
(7) holds with −Lξ ≤ µξ ≤ Lξ. Indeed, inequality (6) implies −Lξ x−x∗ 2 ≤ − Fξ(x)−Fξ(x∗) · x−x∗ ≤ Fξ(x)−Fξ(x∗), x−x∗ ≤ Fξ(x)−Fξ(x∗) · x−x∗ ≤ Lξ x − x∗ 2. However, µξ can be much larger than −Lξ. When Fξ(x∗) = 0 and µξ ≥ 0, inequality (7)
recovers quasi-strong monotonicity of Fξ, i.e., Fξ can
be non-monotone even when µξ ≥ 0.

Finally, we assume that the following two conditions are satisﬁed:

Eξk [γ1,ξk Fξk (x∗)] = 0, (8) Eξk [γ1,ξk µξk (1{µξk ≥0} + 4 · 1{µξk <0})] ≥ 0, (9)

where 1condition = 1 if condition holds, and 1condition = 0 otherwise. Here, (8) is a generalization of unbiasedness at x∗, since F (x∗) = 0, and the left-hand side of (9) is a generalization of the averaged quasi-strong monotonicity constant multiplied by the stepsize. Moreover, (9) holds when all µξ ≥ 0, which is typically assumed in the analysis of S-SEG. The numerical constant 4 in (9) appears mainly due to the technical reasons coming from our proof technique.

To better illustrate the generality of conditions (8)-

(9), let us provide three diﬀerent examples where

these conditions are satisﬁed. In all examples, we as-

sume that F (x) = n1

n i=1

Fi(x)

and

Fi(x)

is

(µi,

x∗)-

strongly monotone and Li-Lipschitz.

Let us start by considering the standard single-element uniform sampling strategy.
Example 3.1 (Uniform sampling). Let ξk be sampled from the uniform distribution on [n], i.e., for all i ∈ [n] we have P ξk = i = pi ≡ 1/n. If

µ= 1

µi + 4

µi ≥ 0

n i:µi≥0

n i:µi<0

(10)

and γ1,ξ ≡ γ > 0, then conditions (8)-(9) hold.

In the above example, the oracle is unbiased and, as the result, we use constant stepsize γ1,ξ = γ. Next, we note that µ satisﬁes: µ ≥ µ ≥ µmin, where µ is the parameter from (2), and µmin = mini∈[n] µi. Moreover, we emphasize that to fulﬁll conditions (8)-(9) in Example 3.1, and in the following examples we only need to assume that parameter γ is positive. However, to be able to derive convergence guarantees for S-SEG under diﬀerent sampling strategies we will later introduce an additional upper bound for γ (see Section 3.2).

Next, we consider a uniform sampling strategy of minibatching without replacement.

Example 3.2 (b-nice sampling). Let ξ be a random

subset of size b ∈ [n] chosen from the uniform distri-

bution on the family of all b-elements subsets of [n].

Next,

let

Fξ (x)

=

1 b

i∈ξ Fi(x). If





µb−NICE = 1n  
b

S⊆[n],

µS + 4

S⊆[n],

µS

 

≥

0,



|S|=b:µS ≥0

|S|=b:µS <0

where µS

≥

1 b

i∈S µi is such that the opera-

tor 1b i∈S Fi(x) is (µS, x∗)-strongly monotone, and

γ1,ξ ≡ γ > 0, then conditions (8)-(9) hold.

Finally, we provide an example of a non-uniform sampling.
Example 3.3 (Importance sampling). Let ξk be sampled from the following distribution: for i ∈ [n]

P ξk = i = pi = nLi . (11)
Lj
j=1

If (10) is satisﬁed and γ1,ξ = γL/Lξ, where L =

1 n

n i=1

Li,

γ

>

0,

then

conditions

(8)-(9)

hold.

We provide rigorous proofs that the above examples, as well as additional ones, ﬁt the conditions (8)-(9) in Appendix E.1.

3.2 Convergence of S-SEG

Having explained the main sampling strategies of SSEG that we are focusing on this work, let us now present our main convergence analysis results for this method.

Let assumptions 3.1 and 3.2 hold, and let us select the

stepsize γ1,ξk such that conditions (8)-(9) are satisﬁed,

and 1

γ1,ξk ≤ 4|µξk | + √2Lξk .

(12)

Then one is able to show that Assumption 2.1 is satisﬁed (see Appendix E.2 for this derivation) for

Eduard Gorbunov, Hugo Berard, Gauthier Gidel, Nicolas Loizou

gξk (xk) = Fξk xk − γ1,ξk Fξk (xk) and γξk = γ2,ξk . In particular, under these conditions, Assumption 2.1 holds with A = 2α, C = 0, B = 1/2, D1 = 6α2σA2S, D2 = 3ασA2S/2, and

σA2S = Eξ γ12,ξ Fξ(x∗) 2 , α ρ = 2 Eξk [γ1,ξk µξk (1{µξk ≥0} + 4 · 1{µξk <0})],

Gk = αEξk

γ

2 1,ξ

k

B

ξ

k

Fξk (xk) 2

,

(13) (14) (15)

where

Bξk

=

1 − 4|µξk |γ1,ξk

−

2

L2ξk

γ

2 1,ξ

k

.

Here (12)

implies that Bξk ≥ 0. Therefore, applying our general result (Theorem 2.1), we derive3 the following conver-

gence guarantees for S-SEG.

Theorem 3.1. Let Assumptions 3.2 and 3.1 hold. If
γ2,ξk = αγ1,ξk , 0 < α ≤ 1/4, and γ1,ξk satisﬁes (8)-(9) and (12) and ρ from (14) is positive, then the iterates
of S-SEG satisfy

E xK − x∗ 2 ≤ (1−ρ)K x0 − x∗ 2 + 3α (4α+1) σA2S , 2ρ

where σA2S is deﬁned in (14).

The next corollary establishes the convergence rate with diminishing stepsizes allowing to reduce the size of the neighborhood.
Corollary 3.1. Let Assumptions 3.2 and 3.1 hold, and let γ2,ξk = αγ1,ξk with α = 1/4, and γ1,ξk = βk · γξk , where γξk satisﬁes (8), (9), (12), and ρ = 18 Eξk [γξk µξk (1{µξk ≥0} + 4 · 1{µξk <0})]. Assume that ρ > 0. Then, for all K ≥ 0 and {βk}k≥0 such that

if K ≤ 1 , ρ
if K > 1 and k < k0, ρ
if K > 1 and k ≥ k0, ρ

βk = 1,

βk = 1,

(16)

2

βk

=

2

+

ρ(k

−

, k0)

where k0 = K/2 , we have that the iterates of S-SEG satisfy

E

xK − x∗

2

≤ 32

x0 −x∗

2
exp

ρK −

+ 27σA2S .

ρ

2

ρ2K

We notice that the stepsize schedule from the above corollary requires the knowledge of the total number of iterations K.
Next, we provide the results for the special cases described in Section 3.1. These results are direct corollaries of Theorem 3.1 and Corollary 3.1.
3For simplicity of exposition, in the main paper we focus on the case ρ > 0. For our results for ρ = 0, we refer the reader to Appendix B and E.2.

S-SEG-US: S-SEG with Uniform Sampling. Con-
sider the setup from Example 3.1. Then, Theorem 3.1
implies that for constant stepsizes γ1,ξk and γ2,ξk , the iterates of S-SEG-US satisfy

E xK − x∗ 2 ≤

1 − αγµ K x0 − x∗ 2 2
+ 3 (4α + 1) γσU2S∗ , µ

where γ ≤ 1/6Lmax, Lmax = maxi∈[n] Li, and σU2S∗ =

n

1 n

Fi(x∗) 2. For diminishing stepsizes following

i=1

(16), Corollary 3.1 implies that for the iterates of S-

SEG-US E xK − x∗ 2 is of the order

O

LmaxR02 exp

µK −

+ σU2S∗ ,

µ

Lmax

µ2K

where R0 = x0−x∗ 2. The previous SOTA rate for SSEG-US (Mishchenko et al., 2020) assumes that µi > 0 for all i ∈ [n] and depends on µmin = mini∈[n] µi which can be much smaller than µ. That is, our results for
S-SEG-US are derived under weaker assumptions and
are tighter than the previous ones for this method.

S-SEG-NICE: S-SEG with b-Nice Sampling. Con-
sider the setup from Example 3.2. Then, Theorem 3.1
implies that for constant stepsizes γ1,ξk and γ2,ξk , the iterates of S-SEG-NICE satisfy

E xK − x∗ 2 ≤

1 − αγµb−NICE K x0 − x∗ 2 2
+ 3 (4α + 1) γσb2−NICE∗ , µb−NICE

where γ ≤ / , 1 6Lb−NICE Lb−NICE = maxS⊆[n],|S|=b LS , and σb2−NICE∗ = b(nn−−b1) σUS∗. For diminishing stepsizes fol-
lowing (16), Corollary 3.1 implies that for the iterates of S-SEG-NICE E xK − x∗ 2 is of the order

O Lb−NICER02 exp − µb−NICEK + σb2−NICE∗ .

µb−NICE

Lb−NICE

µ2b−NICEK

These rates show the beneﬁts of mini-batching without replacement: the linearly decaying term decreases faster than the corresponding one for S-SEG-US since Lb−NICE ≤ Lmax and µb−NICE ≥ µ, and the variance σb2−NICE∗ is smaller than σU2S∗, i.e., O(1/K) term for S-SEG-NICE is more than b-times smaller than the corresponding term for S-SEG-US.
Moreover, we highlight that for n = b we recover the rate of deterministic EG up to numerical factors. That is, for the deterministic EG we obtain xK − x∗ 2 ≤ (1 − αγµ/2)K x0 − x∗ 2 with γ ≤ 1/6L,

Stochastic Extragradient: General Analysis and Improved Rates

since µb−NICE = µ and Lb−NICE = L in this case. This fact highlights the tightness of our analysis, since in
the known special cases our general theorem either re-
covers the best-known results (as for EG) or improves
them (as for S-SEG-US).

S-SEG-IS: S-SEG with Importance Sampling. Fi-

nally, let us consider the third special case described in

Example 3.3. In this case, if γ ≤ 1/6L, L = n1

n i=1

Li,

Theorem 3.1 implies that for constant stepsizes γ1,ξk

and γ2,ξk , the iterates of S-SEG-IS satisfy

E xK − x∗ 2 ≤

1 − αγµ K x0 − x∗ 2 2
+ 3 (4α + 1) γσI2S∗ , µ

n
where σI2S∗ = n1 i=1 LLi Fi(x∗) 2. For diminishing stepsizes following (16), Corollary 3.1 implies that for the iterates of S-SEG-IS E xK − x∗ 2 is of the order

O

LR02 exp

µK −

+ σI2S∗

.

µ

L

µ2K

Note that, in contrast to the rate of S-SEG-US, the

above rate depends on the averaged Lipschitz con-

stant L that can be much smaller than the worst con-

stant Lmax. In such cases, exponentially decaying term

for S-SEG-IS is much better than the one for S-SEG-

US. Moreover, theory for S-SEG-IS allows to use much

larger γ. Next, typically, larger norm of Fi(x∗) implies

larger Li, e.g., Fi(x∗) 2 ∼ L2i . In such situations,

σI2S∗

∼

(L)2

and

σU2 S∗

∼

L2

=

1 n

n i=1

L2i

≥

(L)2.

4 INDEPENDENT-SAMPLES SEG (I-SEG)

In this subsection, we consider I-SEG. We make the following assumption used in Hsieh et al. (2020).4 Assumption 4.1. For all x ∈ Rd the unbiased estimator Fξ(x) of F (x), i.e., Eξ[Fξ(x)] = F (x), satisﬁes
Eξ Fξ(x) − F (x) 2 ≤ δ x − x∗ 2 + σ2, (17)
where δ ≥ 0, σ ≥ 0, and x∗ is the solution of VIP.
Note that when δ = 0, (17) recovers the classical assumption of uniformly bounded variance (Juditsky et al., 2011).
4Although the analysis of Hsieh et al. (2019) can be conducted with δ > 0, the authors do not provide explicit rates in their paper for the case δ > 0.

In I-SEG, we use mini-batched estimators:

k

1b

k

Fξk (x ) 1

=

b

Fξ1k(i)(x ),

i=1

k

1b

k

k

Fξk (x ) 2

=

b

Fξ2k(i)(x − γ1Fξ1k (x )),

i=1

where

ξ

k 1

(1),

.

.

.

,

ξ

k 1

(b

),

ξ2k

(1),

.

.

.

,

ξ

k 2

(b

)

are

i.i.d.

sam-

ples satisfying Assumption 4.1.

In this setup (where Assumption 4.1 holds), if γ2 = αγ1 with 0 < α < 1, and

µb

1

γ1 = γ ≤ min 18δ , 4µ + 6(L2 + δ/b) , (18)

then Assumption 2.1 is satisﬁed5 for gξk (xk) =

Fξk xk − γ1Fξk (xk) and γξk = γ2. In particular,

2

1

in this setting, Assumption 2.1 holds with A = 2α,

C = 9δα2γ2/b, B = 1/2, D1 = D2 = 6α2σ2/b, ρ = αγµ/4,

Gk = Eξk Fξk (xk) 2 , B = αγ2/2. Therefore, apply-

1

1

ing our general result (Theorem 2.1), we obtain the

following convergence guarantees for I-SEG.

Theorem 4.1. Let Assumptions 1.1, 1.2 and 4.1 hold.
If µ > 0, γ2 = αγ1, 0 < α ≤ 1/4, and γ1 = γ satisﬁes (18), then the iterates of I-SEG satisfy

E xK − x∗ 2 ≤ 1 − αγµ K R2 + 48 (α + 1) γσ2 .

8

0

µb

Similarly to S-SEG, we also consider the diminishing stepsize policy (16) for the I-SEG.
Corollary 4.1. Let Assumptions 1.1, 1.2 and 4.1 hold. Assume that µ > 0, γ2,k = αγ1,k, 0 < α ≤ 1/4, γ1,k = βkγ, 0 < βk ≤ 1, where γ equals the righthand side of (18). Then, for all K ≥ 0 and {βk}k≥0 satisfying (16) with ρ = γµ/32, the iterates of I-SEG satisfy

E

xK − x∗ 2 = O

κR2 exp

K −

+

σ2

,

0

κ

µ2bK

√ where R0 = x0 − x∗ 2 and κ = max µδ2b , L+µ δ/b .

When δ = 0 our rate recovers the best-known one for I-SEG under uniformly bounded variance assumption (Beznosikov et al., 2020). Next, when δ > 0 the slowest term in our rate evolves as O(1/K), whereas the previous SOTA result for I-SEG under Assumption 4.1 depends on K as O(1/K1/3) (Hsieh et al., 2020), which is much slower than O(1/K). However, we emphasize that unlike our stepsize schedule the one from Hsieh et al. (2020) is independent of K.
5See Appendix F for the derivation.

Eduard Gorbunov, Hugo Berard, Gauthier Gidel, Nicolas Loizou

100

S-SEG-US

100

S-SEG-US

100

S-SEG-US

100

S-SEG-US

S-SEG-IS

S-SEG-IS

S-SEG-IS

S-SEG-IS

10−1

10−1

10−1

10−1

Distance to optimality Distance to optimality Distance to optimality

Distance to optimality

10−2

10−2

10−2

10−2

10−3

10−3

10−3

10−3

10−4 0

200

400

600

800

Number of Iterations

1000

10−4 0

200

400

600

800

Number of Iterations

1000

10−4 0

200

400

600

800

Number of Iterations

1000

10−4 0

200

400

600

800

1000

Number of Iterations

(a) Lmax = 2

(b) Lmax = 5

(c) Lmax = 10

(d) Lmax = 20

Figure 1: Comparison of S-SEG-US vs S-SEG-IS for diﬀerent values of Lmax. While the rate of convergence of

S-SEG-US becomes slower as Lmax increases, the rate of convergence of S-SEG-IS remains the same.

Distance to optimality Distance to optimality

Distance to optimality

100 10−1 10−2

S-SEG γ1 = 61L, γ2 = γ41 (ours) 100

S-SEG with decreasing step-size (ours Cor. 3.1)

S-SEG

γ1

=

γ2

=

1 2L

(Mishchenko

et

al.,

2020)

10−1

10−2

S-SEG

with

γ1

=

61L ,

γ2

=

γ1 4

S-SEG with decreasing step-size (Cor.3.2)

100 I-SEG γ1 = 4µ+√1 6L2 , γ2 = γ41 (ours)

I-SEG with decreasing step-size (ours Cor. 4.1)

10−1

I-SEG

γ1

=

γ2

=

1 4L

(Beznosikov

et

al.,

2020)

I-SEG with decreasing step-size (Hsieh et al, 2020) 10−2

10−3

10−3

10−3

10−4 0

200

400

600

800

Number of Iterations

1000

10−4 0

200

400

600

800

Number of Iterations

1000

10−4 0

200

400

600

800

1000

Number of Iterations

(a)

(b)

(c)

Figure 2: Experiments on quadratic games illustrating the theoretical results of the paper. (a) Comparison

of diﬀerent stepsize choices for S-SEG. (b) Convergence of S-SEG on quadratic games with negative µξ. (c)

Comparison of diﬀerent stepsize choices for I-SEG.

5 NUMERICAL EXPERIMENTS

To illustrate the theoretical results, we conduct experiments on quadratic games of the form:

1 n1

1

xm1∈iRnd xm2∈aRxp n i=1 2 x1 Aix1 + x1 Bix2 − 2 x2 Cix2

+ ai x1 − ci x2.

By choosing the matrices such that µiI Ai LiI and µiI Ci LiI we can ensure that the game satisﬁes the assumptions for our theory, i.e., the game is strongly monotone and smooth. In all the experiments, we report the average over 5 diﬀerent runs. Further details about the experiments can be found in Appendix A.

Experiment 1: S-SEG-US vs S-SEG-IS. To illustrate the advantages of importance sampling compared to uniform sampling, we construct quadratic games such that L1 = Lmax and Li = 1 ∀i > 1. We show in Fig. 1 that while the rate of convergence of S-SEG-US becomes slower as Lmax increases, the rate of convergence of S-SEG-IS remains almost the same, because L does not change signiﬁcantly.

Experiment 2: S-SEG with diﬀerent stepsizes.
We compare S-SEG with diﬀerent stepsize choices in Fig. 2a. We compare the decreasing stepsize proposed in Corollary 3.1 to the constant stepsize proposed in Mishchenko et al. (2020) where γ1 = γ2 ≤ 21L , and to the constant stepsize proposed in Theorem 3.1. S-SEG with the proposed decreasing stepsize strategy con-

verges faster to a smaller neighborhood of the solution compared to constant stepsize, see Fig. 2a.
Experiment 3: Convergence of S-SEG when some µξ are negative. To illustrate the generality of Assumption 3.2, we construct a quadratic game where one of the µξ is negative. We illustrate the generality of Theorem 3.1 in Fig. 2b by showing that S-SEG converges to the solution in such games.
Experiment 4: I-SEG with diﬀerent stepsizes. In Fig. 2c we compare I-SEG under diﬀerent stepsize choices. In particular, we show how the decreasing stepsize strategy proposed in Corollary 4.1 converges to a smaller neighborhood than existing stepsize choices and it has comparable performance to the stepsize rule proposed in Hsieh et al. (2020). However, let us note again that our theoretical rate is better than the one from Hsieh et al. (2020) (see Table 1).
6 CONCLUSION
In this paper, we develop a novel theoretical framework that allows us to analyze several variants of SEG in a uniﬁed manner. We provide new convergence analysis for well-known variants of SEG and derive new variants (e.g., S-SEG-IS) that outperform previous SOTA results. However, several important questions remain still open, such as the analysis of SEG for quasi-monotone problems (µ = 0) with unbounded domains without using large batchsizes, the analysis of S-SEG with arbitrary sampling, and the same stepsizes γ1,ξk = γ2,ξk , and the improvement of the dependence of µ on negative µi.

Stochastic Extragradient: General Analysis and Improved Rates

Acknowledgements
This work was partially supported by a grant for research centers in the ﬁeld of artiﬁcial intelligence, provided by the Analytical Center for the Government of the Russian Federation in accordance with the subsidy agreement (agreement identiﬁer 000000D730321P5Q0002) and the agreement with the Moscow Institute of Physics and Technology dated November 1, 2021 No. 70-2021-00138. Part of this work was done while Nicolas Loizou was a postdoctoral research fellow at Mila, Universit´e de Montr´eal, supported by the IVADO Postdoctoral Funding Program. Gauthier Gidel is supported by an IVADO grant. Part of this work was done while Eduard Gorbunov was an intern at Mila, Universit´e de Montr´eal under the supervision of Gauthier Gidel and Nicolas Loizou.
References
Abernethy, J., Lai, K. A., and Wibisono, A. (2021). Last-iterate convergence rates for min-max optimization: Convergence of hamiltonian gradient descent and consensus optimization. In Algorithmic Learning Theory, pages 3–47. PMLR.
Beznosikov, A., Samokhin, V., and Gasnikov, A. (2020). Distributed saddle-point problems: Lower bounds, optimal algorithms and federated gans. arXiv preprint arXiv:2010.13112.
Bose, J., Gidel, G., Berard, H., Cianﬂone, A., Vincent, P., Lacoste-Julien, S., and Hamilton, W. (2020). Adversarial example games. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M. F., and Lin, H., editors, Advances in Neural Information Processing Systems, volume 33, pages 8921–8934. Curran Associates, Inc.
Chavdarova, T., Gidel, G., Fleuret, F., and Lacoste-Julien, S. (2019). Reducing noise in GAN training with variance reduced extragradient. In Wallach, H., Larochelle, H., Beygelzimer, A., d'Alch´e-Buc, F., Fox, E., and Garnett, R., editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc.
Chen, G. H. and Rockafellar, R. T. (1997). Convergence rates in forward–backward splitting. SIAM Journal on Optimization, 7(2):421–444.
Chen, Y., Lan, G., and Ouyang, Y. (2017). Accelerated schemes for a class of variational inequalities. Mathematical Programming, 165(1):113–149.
Daskalakis, C., Skoulakis, S., and Zampetakis, M. (2021). The complexity of constrained min-max optimization. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing, pages 1466–1478.
Diakonikolas, J., Daskalakis, C., and Jordan, M. (2021). Eﬃcient methods for structured nonconvex-nonconcave min-max optimization. In International Conference on Artiﬁcial Intelligence and Statistics, pages 2746–2754. PMLR.
Dikkala, N., Lewis, G., Mackey, L., and Syrgkanis, V. (2020). Minimax estimation of conditional moment models. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan,

M. F., and Lin, H., editors, Advances in Neural Information Processing Systems, volume 33, pages 12248–12262. Curran Associates, Inc.
Gidel, G., Berard, H., Vignoud, G., Vincent, P., and Lacoste-Julien, S. (2019). A variational inequality perspective on generative adversarial networks. In International Conference on Learning Representations (ICLR).
Golowich, N., Pattathil, S., Daskalakis, C., and Ozdaglar, A. (2020). Last iterate is slower than averaged iterate in smooth convex-concave saddle point problems. In Conference on Learning Theory, pages 1758–1784. PMLR.
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y. (2014). Generative adversarial nets. In Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N., and Weinberger, K. Q., editors, Advances in Neural Information Processing Systems, volume 27. Curran Associates, Inc.
Gorbunov, E., Hanzely, F., and Richtarik, P. (2020). A Uniﬁed Theory of SGD: Variance Reduction, Sampling, Quantization and Coordinate Descent. In Chiappa, S. and Calandra, R., editors, Proceedings of the Twenty Third International Conference on Artiﬁcial Intelligence and Statistics, volume 108 of Proceedings of Machine Learning Research, pages 680–690. PMLR.
Gorbunov, E., Loizou, N., and Gidel, G. (2021). Extragradient method: O(1/K) last-iterate convergence for monotone variational inequalities and connections with cocoercivity. arXiv preprint arXiv:2110.04261.
Gower, R., Sebbouh, O., and Loizou, N. (2021). Sgd for structured nonconvex functions: Learning rates, minibatching and interpolation. In International Conference on Artiﬁcial Intelligence and Statistics, pages 1315– 1323. PMLR.
Gower, R. M., Loizou, N., Qian, X., Sailanbayev, A., Shulgin, E., and Richta´rik, P. (2019). SGD: General Analysis and Improved Rates. In Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pages 5200–5209.
Hanzely, F. and Richta´rik, P. (2019). Accelerated coordinate descent with arbitrary sampling and best rates for minibatches. In The 22nd International Conference on Artiﬁcial Intelligence and Statistics, pages 304–312. PMLR.
Horva´th, S. and Richt´arik, P. (2019). Nonconvex variance reduced optimization with arbitrary sampling. In International Conference on Machine Learning, pages 2781– 2789. PMLR.
Hsieh, Y.-G., Iutzeler, F., Malick, J., and Mertikopoulos, P. (2019). On the convergence of single-call stochastic extra-gradient methods. In Wallach, H., Larochelle, H., Beygelzimer, A., d'Alch´e-Buc, F., Fox, E., and Garnett, R., editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc.
Hsieh, Y.-G., Iutzeler, F., Malick, J., and Mertikopoulos, P. (2020). Explore aggressively, update conservatively: Stochastic extragradient methods with variable stepsize scaling. Advances in Neural Information Processing Systems, 33.
Jelassi, S., Domingo-Enrich, C., Scieur, D., Mensch, A., and Bruna, J. (2020). Extra-gradient with player sampling for faster convergence in n-player games. In III,

Eduard Gorbunov, Hugo Berard, Gauthier Gidel, Nicolas Loizou

H. D. and Singh, A., editors, Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pages 4736–4745. PMLR.

Juditsky, A., Nemirovski, A., and Tauvel, C. (2011). Solving variational inequalities with stochastic mirror-prox algorithm. Stochastic Systems, 1(1):17–58.

Kannan, A. and Shanbhag, U. V. (2019). Optimal stochastic extragradient schemes for pseudomonotone stochastic variational inequality problems and their variants. Computational Optimization and Applications, 74(3):779–820.

Khaled, A. and Richta´rik, P. (2020). for sgd in the nonconvex world. arXiv:2002.03329.

Better theory arXiv preprint

Khaled, A., Sebbouh, O., Loizou, N., Gower, R. M., and Richta´rik, P. (2020). Uniﬁed analysis of stochastic gradient methods for composite convex and smooth optimization. arXiv preprint arXiv:2006.11573.

Korpelevich, G. M. (1976). The extragradient method for ﬁnding saddle points and other problems. Matecon, 12:747–756.

Li, C. J., Yu, Y., Loizou, N., Gidel, G., Ma, Y., Roux, N. L., and Jordan, M. I. (2021). On the convergence of stochastic extragradient for bilinear games with restarted iteration averaging. arXiv preprint arXiv:2107.00464.

Liu, J. and Wright, S. (2016). An accelerated randomized Kaczmarz algorithm. Mathematics of Computation, 85(297):153–178.

Loizou, N., Berard, H., Gidel, G., Mitliagkas, I., and Lacoste-Julien, S. (2021). Stochastic gradient descentascent and consensus optimization for smooth games: Convergence analysis under expected co-coercivity. arXiv preprint arXiv:2107.00052.

Loizou, N., Berard, H., Jolicoeur-Martineau, A., Vincent, P., Lacoste-Julien, S., and Mitliagkas, I. (2020). Stochastic hamiltonian gradient methods for smooth games. In International Conference on Machine Learning, pages 6370–6381. PMLR.

Loizou, N. and Richta´rik, P. (2020a). Convergence analysis of inexact randomized iterative methods. SIAM Journal on Scientiﬁc Computing, 42(6):A3979–A4016.

Loizou, N. and Richta´rik, P. (2020b). Momentum and stochastic momentum for stochastic gradient, newton, proximal point and subspace descent methods. Computational Optimization and Applications, 77(3):653–710.

Loizou, N. and Richta´rik, P. (2021). Revisiting randomized gossip algorithms: General framework, convergence rates and novel block and accelerated protocols. IEEE Transactions on Information Theory.

Martinet, B. (1970). Regularisation d’inequations variationelles par approximations successives. Revue Francaise d’Informatique et de Recherche Operationelle, 4:154–159.

Mertikopoulos, P. and Zhou, Z. (2019). Learning in games with continuous action sets and unknown payoﬀ functions. Mathematical Programming, 173(1):465–507.

Mishchenko, K., Kovalev, D., Shulgin, E., Richtarik, P., and Malitsky, Y. (2020). Revisiting stochastic extragradient. In Chiappa, S. and Calandra, R., editors, Pro-
ceedings of the Twenty Third International Conference

on Artiﬁcial Intelligence and Statistics, volume 108 of Proceedings of Machine Learning Research, pages 4573– 4582. PMLR.
Necoara, I., Nesterov, Y., and Glineur, F. (2019). Linear convergence of ﬁrst order methods for nonstrongly convex optimization. Mathematical Programming, 175(1):69–107.
Nemirovski, A., Juditsky, A., Lan, G., and Shapiro, A. (2009). Robust stochastic approximation approach to stochastic programming. SIAM Journal on Optimization, 19(4):1574–1609.
Nesterov, Y. (2007). Dual extrapolation and its applications to solving variational inequalities and related problems. Mathematical Programming, 109(2):319–344.
Noor, M. A. (2003). New extragradient-type methods for general variational inequalities. Journal of Mathematical Analysis and Applications, 277(2):379–394.
Pfau, D. and Vinyals, O. (2016). Connecting generative adversarial networks and actor-critic methods. arXiv preprint arXiv:1610.01945.
Popov, L. D. (1980). A modiﬁcation of the arrow-hurwicz method for search of saddle points. Mathematical notes of the Academy of Sciences of the USSR, 28(5):845–848.
Qu, Z. and Richta´rik, P. (2016). Coordinate descent with arbitrary sampling i: Algorithms and complexity. Optimization Methods and Software, 31(5):829–857.
Richta´rik, P. and Taka´ˇc, M. (2016). On optimal probabilities in stochastic coordinate descent methods. Optimization Letters, 10(6):1233–1243.
Richta´rik, P. and Taka´c, M. (2020). Stochastic reformulations of linear systems: algorithms and convergence theory. SIAM Journal on Matrix Analysis and Applications, 41(2):487–524.
Rockafellar, R. T. (1976). Monotone operators and the proximal point algorithm. SIAM journal on control and optimization, 14(5):877–898.
Song, C., Zhou, Z., Zhou, Y., Jiang, Y., and Ma, Y. (2020). Optimistic dual extrapolation for coherent nonmonotone variational inequalities. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M. F., and Lin, H., editors, Advances in Neural Information Processing Systems, volume 33, pages 14303–14314. Curran Associates, Inc.
Stich, S. U. (2019). Uniﬁed optimal analysis of the (stochastic) gradient method. arXiv preprint arXiv:1907.04232.
Vezhnevets, A. S., Osindero, S., Schaul, T., Heess, N., Jaderberg, M., Silver, D., and Kavukcuoglu, K. (2017). Feudal networks for hierarchical reinforcement learning. In International Conference on Machine Learning, pages 3540–3549. PMLR.
Wayne, G. and Abbott, L. (2014). Hierarchical control using networks trained with higher-level forward models. Neural computation, 26(10):2163–2193.
Yang, J., Kiyavash, N., and He, N. (2020). Global convergence and variance reduction for a class of nonconvexnonconcave minimax problems. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M. F., and Lin, H., editors, Advances in Neural Information Processing Systems, volume 33, pages 1153–1165. Curran Associates, Inc.

Supplementary Material: Stochastic Extragradient: General Analysis and Improved Rates

Contents

1 INTRODUCTION

1

1.1 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2

1.2 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2

1.3 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3

1.4 Paper Organization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5

2 GENERAL ANALYSIS OF SEG

5

3 SAME-SAMPLE SEG (S-SEG)

5

3.1 Arbitrary Sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5

3.2 Convergence of S-SEG . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6

4 INDEPENDENT-SAMPLES SEG (I-SEG)

8

5 NUMERICAL EXPERIMENTS

9

6 CONCLUSION

9

A ON EXPERIMENTS

13

A.1 Experimental Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

A.2 Additional Experiment: S-SEG with b-Nice Sampling (S-SEG-NICE) . . . . . . . . . . . . . . . . . . . . . . 13

B DISCUSSION OF THE RESULTS UNDER QUASI MONOTONICITY

14

C BASIC INEQUALITIES AND AUXILIARY RESULTS

16

C.1 Basic Inequalities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

C.2 Auxiliary Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

D GENERAL ANALYSIS OF SEG: MISSING PROOFS

17

E SAME-SAMPLE SEG (S-SEG): MISSING PROOFS AND ADDITIONAL DETAILS

18

E.1 Details on the Examples of Arbitrary Sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18

E.2 Proof of the Main Result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20

E.3 S-SEG with Uniform Sampling (S-SEG-US) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26

E.4 S-SEG with b-Nice Sampling (S-SEG-NICE) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27

E.5 S-SEG with Importance Sampling (S-SEG-IS) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29

E.6 S-SEG with Independent Sampling Without Replacement (S-SEG-ISWOR) . . . . . . . . . . . . . . . . . . 31

Eduard Gorbunov, Hugo Berard, Gauthier Gidel, Nicolas Loizou

F INDEPENDENT-SAMPLES SEG (I-SEG): MISSING PROOFS AND ADDITIONAL DETAILS 33 F.1 On the Assumptions in the Analysis of S-SEG and I-SEG . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37

A ON EXPERIMENTS

A.1 Experimental Details

We describe here in more details the exact settings we use for evaluating the diﬀerent algorithms. As mentioned in Section 5, we evaluate the diﬀerent algorithms on the class of quadratic games:

11

1

xm1∈iRnd xm2∈aRxp n i 2 x1 Aix1 + x1 Bix2 − 2 x2 Cix2 + ai x1 − ci x2

In all our experiments, we choose d = p = 100 and n = 100. To sample the matrices Ai (resp. Ci) we ﬁrst generate a random orthogonal matrix Qi (resp. Qi), we then sample a random diagonal matrix Di (resp. Di) where the elements on the diagonal are sampled uniformly in [µA, LA] (resp. [µC , LC ]), such that at least one of the matrices has a minimum eigenvalue equal to µA (resp. µC) and one matrix has a maximum eigenvalue equal to LA (resp. LB). Finally we construct the matrices by computing Ai = QiDiQi (resp.
Ci = QiDiQ i ). This ensures that the matrices Ai and Ci for all i ∈ [n], are symmetric and positive deﬁnite. We sample the matrices Bi in a similar fashion with the diagonal matrix Di to lie between [µB, LB]6. The bias terms ai, ci are sampled from a normal distribution. In all our experiments we choose µA = µC = 0.1, LA = LC = 1, µB = 0 and LB = 1 unless stated otherwise. For further details please refer to the code: https://github.com/hugobb/Stochastic-Extragradient.

A.2 Additional Experiment: S-SEG with b-Nice Sampling (S-SEG-NICE)
To illustrate Remark E.1 about the advantages of S-SEG-NICE compared to S-SEG-US with i.i.d. batching, we construct a quadratic game such that L1 = Lmax and Li = 1, ∀i > 1. We use the constant stepsize speciﬁed in Section 3.2. We show in Fig. 3 that the rate of convergence of S-SEG-NICE is faster than S-SEG-US with i.i.d. batching when using the same batch size. However S-SEG-NICE converges to a slightly larger neighborhood of the solution.

Distance to optimality

100 10−1 10−2 10−3 10−4 10−5

S-SEG-NICE b=2 S-SEG-NICE b=10 S-SEG-US b=2 S-SEG-US b=10

0

2500

5000

7500 10000 12500 15000 17500 20000

Number of oracle calls

Figure 3: Convergence of S-SEG-NICE for diﬀerent batchsizes. In this experiment Lmax = 10.

6We highlight that matrices Bi are not necessarily symmetric.

Stochastic Extragradient: General Analysis and Improved Rates
B DISCUSSION OF THE RESULTS UNDER QUASI MONOTONICITY

Table 2: Summary of the state-of-the-art results for S-SEG and I-SEG for quasi monotone VIPs, i.e., for S-SEG it means that µ = n1 i∈[n]:µi≥0 µi + n4 i∈[n]:µi<0 µi = 0 and for I-SEG – µ = 0. Moreover, for I-SEG we assume that δ = 0 (see Assumption 4.1). Our results are highlighted in green. Columns: “Norm?” indicates whether the rate is given for
the expected squared norm of the operator, “Gap?” indicates whether the rate is given for the expected gap function E [GapC(z)] = E [maxu∈C F (u), z − u ] (here C is a compact set containing the solution set), “Unbounded Set?” indicates whether the analysis works for the case of unbounded sets, “b = O(1)?” indicates whether the analysis works with the
batchsize independent of the target accuracy of the solution.

Setup

Method

Citation

Norm? Gap? Unbounded Set? b = O(1)?

n
F (x) = 1 Fi(x)

S-SEG-US

(Mishchenko et al., 2020)(1) 

(2)



n i=1

This paper







+ As. 3.1, 3.2

S-SEG-IS

This paper







(3) (4) (4)

F (x) = Eξ[Fξ(x)]

I-SEG

(Beznosikov et al., 2020)(5) 







+ As. 1.1, 1.2, 4.1

This paper









(1) Mishchenko et al. (2020) consider a regularized version of (VIP) with convex regularization, F (x) = Eξ[Fξ(x)] and Fξ(x) being

monotone and Lξ-Lipschitz.

If regularization is zero in the obtained problem and Eξ[Fξ(x)]

=

1 n

n i=1

Fi (x),

the

problem

from

Mishchenko et al. (2020) ﬁts the considered setup with µi = 0 for all i ∈ [n].

(2) The rate is derived for maxu∈C E F (u), xˆK − u + R(xˆK ) − R(u) , where R(x) is the regularization term (in our settings, R(x) ≡ 0)

and xˆK is the average of the iterates produced by the method. This guarantee is weaker than the one for E GapC(xˆK ) .
(3) Mishchenko et al. (2020) use uniformly bounded variance assumption on a compact set that deﬁnes the gap function (Assumption 4.1 with δ = 0 on a compact). (4) In general, our results in this case require using batchsize dependent on the target accuracy. However, when Fi(x∗) = 0 for all i ∈ [n], i.e., when interpolation conditions are satisﬁed, batchsizes can be chosen arbitrarily, e.g., b = 1, to achieve the convergence to any predeﬁned accuracy.
(5) Beznosikov et al. (2020) study a distributed version of I-SEG.

Results under (quasi) monotonicity. The state-of-the-art results for the convergence of S-SEG and ISEG for (quasi) monotone VIP are summarized in Table 2. For S-SEG by quasi-monotonicity we mean that Assumption 3.2 holds and Eξk [γ1,ξk µξk (1{µξk ≥0} + 4 · 1{µξk <0})] = 0. In the context of ﬁnite-sum problems, it means that µ = n1 i∈[n]:µi≥0 µi + n4 i∈[n]:µi<0 µi = 0 both for S-SEG-US and S-SEG-IS. For I-SEG we use the term quasi-monotonicity to describe the problems satisfying Assumption 1.2 with µ = 0. The resulting inequality F (x), x − x∗ ≥ 0 is also known as variational stability condition (Hsieh et al., 2020; Loizou et al., 2021).
The best-known results (Mishchenko et al., 2020; Beznosikov et al., 2020) provide convergence guarantees in terms of the gap function (Nesterov, 2007): GapC(z) = maxu∈C F (u), z − u , where C is a compact set containing the solution set of (VIP). In particular, Beznosikov et al. (2020) derive a convergence guarantee for E[GapC(xˆk)], where xˆK is the average of the iterates produced by the method and the problem is assumed to be deﬁned on a compact set. The last requirement is quite restrictive, since many practically important problems are naturally unconstrained. Mishchenko et al. (2020) do not make such an assumption and consider VIPs with regularization, but derive convergence guarantees for maxu∈C E F (u), xˆK − u + R(xˆK ) − R(u) , where R(x) is the regularization term (in our settings, R(x) ≡ 0). That is, when R(x) ≡ 0 Mishchenko et al. (2020) obtain upper bounds for GapC(E[xˆk]) that is a weaker measure of convergence than E[GapC(xˆk)].
However, Mishchenko et al. (2020); Beznosikov et al. (2020) analyze SEG without using large batchsizes. In contrast, our convergence results for S-SEG and I-SEG are given for the expected squared norm of the operator and hold in the unconstrained case, but, in general, require using target accuracy dependent batchsizes. However, when Fξ(x∗) = 0 for all ξ, i.e., interpolation conditions are satisﬁed, our results for S-SEG provide convergence guarantees to any predeﬁned accuracy of the solution even with unit batchsizes (b = 1).
Last-iterate convergence rates without (quasi) strong monotonicity. All the results from Table 2 are derived either for the best-iterate or for the averaged-iterate. However, last-iterate convergence results are much more valuable, since the last-iterate is usually used as an output of a method in practical applications. Unfortunately, without additional assumptions a little is known about convergence of SEG in this settings. In fact, even for deterministic EG tight O(1/K) last-iterate convergence results were obtained (Golowich et al., 2020) under the additional assumption that the Jacobian of F is Lipschitz-continuous, and only recently Gorbunov et al. (2021) derive O(1/K) last-iterate convergence rate without using this additional assumption. There are also

Eduard Gorbunov, Hugo Berard, Gauthier Gidel, Nicolas Loizou
several linear last-iterate convergence results under the assumption that the operator F is aﬃne and satisﬁes F (x) ≥ µ x − x∗ (x∗ is the closest solution to x) (Hsieh et al., 2020) and under the assumption that F corresponds to the bilinear game (Mishchenko et al., 2020).

Stochastic Extragradient: General Analysis and Improved Rates

C BASIC INEQUALITIES AND AUXILIARY RESULTS

C.1 Basic Inequalities

For all a, b, a1, a2, . . . , an ∈ Rd, n ≥ 1 the following inequalities hold:

n

2

n

ai ≤ n

ai 2,

(19)

i=1

i=1

a + b 2 ≥ 1 a 2 − b 2,

(20)

2

2 a, b = a 2 + b 2 − a − b 2.

(21)

C.2 Auxiliary Results

We use the following lemma from Stich (2019) to derive the ﬁnal convergence rates from our results on linear convergence to the neighborhood.
Lemma C.1 (Simpliﬁed version of Lemma 3 from Stich (2019)). Let the non-negative sequence {rk}k≥0 satisfy the relation
rk+1 ≤ (1 − aγk)rk + cγk2
for all k ≥ 0, parameters a, c ≥ 0, and any non-negative sequence {γk}k≥0 such that γk ≤ 1/h for some h ≥ a, h > 0. Then, for any K ≥ 0 one can choose {γk}k≥0 as follows:

h if K ≤ ,
a h if K > a and k < k0, h if K > a and k ≥ k0,

γk = 1 , h

γk = 1 , h

2

γk

=

a(κ

+

k

−

, k0)

where κ = 2h/a and k0 = K/2 . For this choice of γk the following inequality holds:

rK ≤ 32hr0 exp

aK −

+ 36c .

a

2h

a2K

Eduard Gorbunov, Hugo Berard, Gauthier Gidel, Nicolas Loizou

D GENERAL ANALYSIS OF SEG: MISSING PROOFS

Theorem D.1 (Theorem 2.1). Consider the method (3). Let Assumption 2.1 hold and

K ≥0

E xK+1 − x∗ 2 ≤ (1 + C − ρ)E xK − x∗ 2 + D1 + D2,

E xK − x∗ 2 ≤ (1 + C − ρ)K x0 − x∗ 2 + D1 + D2 , ρ−C

when ρ > C ≥ 0, and

1K

x0 − x∗ 2 D1 + D2

K +1

E[Gk] ≤ B(K + 1) +

, B

k=0

when ρ = C = 0 and B > 0.

A ≤ 1/2.

Then

for all (22) (23)
(24)

Proof. Since xk+1 = xk − γξk gξk (xk), we have

xk+1 − x∗ 2 = =

xk − γξk gξk (xk) − x∗ 2 xk − x∗ 2 − 2γξk gξk (xk), xk − x∗ + γξ2k gξk (xk) 2.

Taking the expectation, conditioned on ξk, using our Assumption 2.1 and the deﬁnition of Pk = Eξk γξk gξk (xk), xk − x∗ , we continue our derivation:

Eξk xk+1 − x∗ 2

=
(4)
≤
A≤1/2
≤
(5)
≤

xk − x∗

2

−

2Pk

+

Eξ

k

[γ

2 ξk

gξk (xk)

2]

xk − x∗ 2 − 2Pk + 2APk + C xk − x∗ 2 + D1

(1 + C) xk − x∗ 2 − Pk + D1

(1 + C − ρ) xk − x∗ 2 − BGk + D1 + D2.

Next, we take the full expectation from the both sides

E xk+1 − x∗ 2 ≤ (1 + C − ρ)E xk − x∗ 2 − BE[Gk] + D1 + D2.

(25)

If ρ > C ≥ 0, then in the above inequality we can get rid of the non-positive term (−BE[Gk]) E xk+1 − x∗ 2 ≤ (1 + C − ρ)E xk − x∗ 2 + D1 + D2

and get (22). Unrolling the recurrence, we derive (23):

E xK − x∗ 2

K −1
≤ (1 + C − ρ)K x0 − x∗ 2 + (D1 + D2) (1 + C − ρ)k
k=0 ∞
≤ (1 + C − ρ)K x0 − x∗ 2 + (D1 + D2) (1 + C − ρ)k
k=0
= (1 + C − ρ)K x0 − x∗ 2 + D1 + D2 . ρ−C

If ρ = C = 0 and B > 0, then (25) is equivalent to BE[Gk] ≤ E xk − x∗ 2 − E

xk+1 − x∗ 2 + D1 + D2.

Summing up these inequalities for k = 0, 1, . . . , K and dividing the result by B(K + 1), we get (24):

K 1+ 1 K E[Gk] ≤ B(K1+ 1) K E xk − x∗ 2 − E xk+1 − x∗ 2 + BD(1K++D12)

k=0

k=0

=

1

x0 − x∗ 2 − E xK+1 − x∗ 2 + D1 + D2

B(K + 1)

B(K + 1)

≤ x0 − x∗ 2 + D1 + D2 . B(K + 1) B(K + 1)

Stochastic Extragradient: General Analysis and Improved Rates

E SAME-SAMPLE SEG (S-SEG): MISSING PROOFS AND ADDITIONAL DETAILS
In this section, we provide full proofs and missing details from Section 3 on S-SEG. Recall that our analysis of S-SEG based on the three following assumptions:

• Fξ(x) is Lξ-Lipschitz: Fξ(x) − Fξ(y) ≤ Lξ x − y for all x, y ∈ Rd (Assumption 3.1), • Fξ(x) is (µξ, x∗)-strongly monotone (with possibly negative µξ): Fξ(x) − Fξ(x∗), x − x∗ ≥ µξ x − x∗ 2 for
all x ∈ Rd (Assumption 3.2),
• the following conditions (inequalities (8)-(9)) hold:
Eξk [γ1,ξk Fξk (x∗)] = 0, Eξk [γ1,ξk µξk (1{µξk ≥0} + 4 · 1{µξk <0})] ≥ 0.

E.1 Details on the Examples of Arbitrary Sampling

In Section 3, we provide several examples when the assumptions above are satisﬁed. In all examples, we assume that F (x) has a ﬁnite-sum form
1n F (x) = n Fi(x) (26)
i=1

and Fi is Li-Lipschitz and (µi, x∗)-strongly monotone. First, we consider S-SEG with independent sampling with replacement, which covers uniform sampling (Example 3.1) and importance sampling (Example 3.3).

Example E.1 (Independent sampling with replacement). Let random indices j1, . . . , jb are sampled indepen-

dently from the the distribution D such that for j ∼ D we have P [j = i] = pi > 0 for i = 1, . . . , n,

n i=1

pi

=

1.

Let

ξ

=

(j1, . . . , jb)

and

Fξ (x)

=

1 b

b l=1

Fjl

(x).

Moreover,

assume

that

µ(j1,...,jb) + 4

µ(j1,...,jb) ≥ 0,

j1 ,...,jb :µ(j1 ,...,jb ) ≥0

j1 ,...,jb :µ(j1 ,...,jb ) <0

where

µ(j1 ,...,jb )

≥

1 b

b i=1

µjl

is

such

that

the

operator

1 b

b l=1

Fjl

(x)

is

(µ(j1,...,jb), x∗)-strongly

monotone.

For

example, the above inequality is satisﬁed when all µi ≥ 0. Then, Assumptions 3.1 and 3.2 hold with Lξ ≤

1 b

b l=1

Ljl

,

µξ

≥

1 b

b i=1

µjl ,

and

for

the

stepsize

γb γ1,ξ = nbpξ ,

γ > 0,

pξ = P [ξ = (j1, . . . , jb)] = pj1 . . . pjb

we have

Eξk [γ1,ξk Fξk (x∗)] = nγb n

b Fjl (x∗) = nγ n Fi(x∗) = γF (x∗) = 0

j1,...,jb=1 l=1

i=1

and

γb

Eξk [γ1,ξk µξk 1{µξk ≥0} + 4γ1,ξk µξk 1{µξk <0}] = nb

µ(j1 ,...,jb )

j1 ,...,jb :µ(j1 ,...,jb ) ≥0

4γb

+ nb

µ(j1 ,...,jb )

j1 ,...,jb :µ(j1 ,...,jb ) <0

≥ 0,

i.e., conditions from (8)-(9) are satisﬁed.

Eduard Gorbunov, Hugo Berard, Gauthier Gidel, Nicolas Loizou

Taking b = 1 and p1 = . . . = pn = 1/n in the previous example we recover single-batch uniform sampling

(Example 3.1) as as special case. If pi = Li/

n j=1

Lj ,

then

we

get

single-batch

importance

sampling

(Example

3.3)

as a special case of the previous example.

Finally, we consider two without-replacement sampling strategies. The ﬁrst one called b-nice sampling is described in Section 3 (Example 3.2). Below we prove that conditions (8)-(9) hold for this example. For the reader’s convenience, we also provide a complete description of this sampling.
Example E.2 (b-nice sampling). Let ξ be a random subset of size b ∈ [n] chosen from the uniform distribution on the family of all subsets of [n] of size b. Then, for each S ⊆ [n], |S| = b we have

Next,

let

Fξ (x)

=

1 b

pS = P [ξ = S] = 1n .
b
i∈ξ Fi(x) and γ1,ξ = γ. Moreover, assume that





µb−NICE = 1n 

µS + 4

µS ≥ 0,

b S⊆[n],|S|=b:µS ≥0

S⊆[n],|S|=b:µS <0

where

µS

≥

1 b

i∈S µi

is

such

that

the

operator

1 b

i∈S Fi(x) is (µS, x∗)-strongly monotone. For example,

the above inequality is satisﬁed when all µi ≥ 0.

Then, Assumptions 3.1 and 3.2 hold with Lξ ≤

1 b

i∈ξ Li,

µξ

≥

1 b

i∈ξ µi, and we have

Eξk [γ1,ξk Fξk (x∗)] = γn

∗

γ

n−1 b−1

Fi(x ) = n

n
Fi(x∗) = γF (x∗) = 0

b b S⊆[n],|S|=b i∈S

b b i=1

and

Eξk [γ1,ξk µξk 1{µξk ≥0} + 4γ1,ξk µξk 1{µξk <0}] =

γ

n

µS

b S⊆[n],|S|=b:µS ≥0

+ 4nγ µS
b S⊆[n],|S|=b:µS <0

= γµb−NICE ≥ 0,

i.e., conditions from (8)-(9) are satisﬁed.

The second without-sampling strategy, which we consider, is independent sampling without replacement.

Example E.3 (Independent sampling without replacement). Let ξ be a random subset of [n] such that each i

is picked with probability pi independently from other elements. It means that the size of ξ is a random variable

as well and E[|ξ|] =

n i=1

pi.

Next,

we

deﬁne

Fξ(x) = 1 Fi(x) |ξ| i∈ξ

and γ|ξ|
γ1,ξ = pξ2n−1n , for any S ⊆ [n]. Moreover, assume that

pξ = P [ξ = S] = pi · (1 − pi)

i∈S

i∈S

|S|µS + 4

|S|µS ≥ 0,

S⊆[n]:µS ≥0

S⊆[n]:µS <0

where

µS

≥

1 |S|

i∈S µi

is

such

that

the

operator

1 |S|

i∈S Fi(x) is (µS, x∗)-strongly monotone. For example,

the above inequality is satisﬁed when all µi ≥ 0.

Then, Assumptions 3.1 and 3.2 hold with Lξ

≤

1 |ξ|

i∈ξ Li,

Stochastic Extragradient: General Analysis and Improved Rates

µξ

≥

1 |ξ|

i∈ξ µi, and we have

Eξk [γ1,ξk Fξk (x∗)] = 2n−γ1n

Fi(x∗) = nγ n Fi(x∗) = γF (x∗) = 0

S⊆[n] i∈S

i=1

and

γ

Eξk [γ1,ξk µξk 1{µξk ≥0} + 4γ1,ξk µξk 1{µξk <0}] = 2n−1n

|S|µS

S⊆[n]:µS ≥0

4γ

+ 2n−1n

|S|µS

S⊆[n]:µS <0

≥ 0,

i.e., conditions from (8)-(9) are satisﬁed.

E.2 Proof of the Main Result The proof is based on two lemmas showing that Assumption 2.1 is satisﬁed. Lemma E.1. Let Assumptions 3.1 and 3.2 hold. If γ1,ξk satisﬁes (8)-(9) and

γ1,ξk ≤ 1 √ 4|µξk | + 2Lξk

(27)

then gk = Fξk xk − γ1,ξk Fξk (xk) satisﬁes the following inequality

Eξk γ12,ξk gk 2 ≤ 4Pk + 6Eξk γ12,ξk Fξk (x∗) 2 ,

(28)

where Pk = Eξk γ1,ξk gk, xk − x∗ .

Proof. Using the auxiliary iterate7 xk+1 = xk − γ1,ξk gk, we get

xk+1 − x∗ 2 = =
=

xk − x∗ 2 − 2γ1,ξk xk − x∗, gk + γ12,ξk gk 2 xk − x∗ 2 − 2γ1,ξk xk − γ1,ξk Fξk (xk) − x∗, gk −2γ12,ξk Fξk (xk), gk + γ12,ξk gk 2 xk − x∗ 2 − 2γ1,ξk xk − γ1,ξk Fξk (xk) − x∗, gk − Fξk (x∗) −2γ12,ξk Fξk (xk), gk − Fξk (x∗) − 2γ1,ξk xk − x∗, Fξk (x∗) + γ12,ξk gk 2.

(29)

Taking the expectation w.r.t. ξk from the above identity, using Eξk [γ1,ξk xk − x∗, Fξk (x∗) ] = xk −

7We use xk+1 as a tool in the proof. There is no need to compute xk+1 during the run of the method.

Eduard Gorbunov, Hugo Berard, Gauthier Gidel, Nicolas Loizou

x∗, Eξk [γ1,ξk Fξk (x∗)] (=8) 0, gk = Fξk xk − γ1,ξk Fξk (xk) and (µξ, x∗)-strong monotonicity of Fξ(x), we derive

Eξk xk+1 − x∗ 2 ≤ xk − x∗ 2 − 2Eξk γ1,ξk xk − γ1,ξk F (xk, ξk) − x∗, gk − F (x∗, ξk) −2Eξk γ12,ξk F (xk, ξk), gk − F (x∗, ξk) + Eξk γ12,ξk gk 2

(7)
≤ xk − x∗ 2 − 2Eξk γ1,ξk µξk xk − x∗ − γ1,ξk F (xk, ξk) 2 −2Eξk γ12,ξk Fξk (xk), gk − Fξk (x∗) + Eξk γ12,ξk gk 2

= xk − x∗ 2 − 2Eξk γ1,ξk µξk 1{µξk ≥0} xk − x∗ − γ1,ξk F (xk, ξk) 2

−2Eξk γ1,ξk µξk 1{µξk <0} xk − x∗ − γ1,ξk F (xk, ξk) 2

−2Eξk γ12,ξk Fξk (xk), gk − Fξk (x∗) + Eξk γ12,ξk gk 2

(20)
k − x∗ 2 − Eξk [γ1,ξk µξk 1{µ ≥0}] xk − x∗ 2 ≤ x ξk
+2Eξk [γ13,ξk µξk 1{µξk ≥0} Fξk (xk) 2] −2Eξk γ1,ξk µξk 1{µξk <0} xk − x∗ − γ1,ξk F (xk, ξk) 2

−2Eξk γ12,ξk Fξk (xk), gk − Fξk (x∗) + Eξk γ12,ξk gk 2

(19)
k − x∗ 2 − Eξk [γ1,ξk µξk 1{µ ≥0} + 4γ1,ξk µξk 1{µ <0}] xk − x∗ 2

≤x

ξk

ξk

+Eξk γ12,ξk gk 2

+2Eξk γ13,ξk (µξk 1{µξk ≥0} − 2µξk 1{µξk <0})) Fξk (xk) 2

−Eξk γ12,ξk gk − Fξk (x∗) 2

+Eξk γ12,ξk Fξk (xk) − gk + Fξk (x∗) 2

(21)
k − x∗ 2 − Eξk [γ1,ξk µξk 1{µ ≥0} + 4γ1,ξk µξk 1{µ <0}] xk − x∗ 2

≤x

ξk

ξk

+Eξk γ12,ξk gk 2

−Eξk γ12,ξk (1 − 2γ1,ξk (µξk 1{µξk ≥0} − 2µξk 1{µξk <0})) Fξk (xk) 2

−Eξk γ12,ξk gk − Fξk (x∗) 2

+Eξk γ12,ξk Fξk (xk) − gk + Fξk (x∗) 2

(9)
≤ xk − x∗ 2 + Eξk γ12,ξk gk 2

−Eξk γ12,ξk (1 − 4γ1,ξk |µξk |) Fξk (xk) 2

−Eξk γ12,ξk gk − Fξk (x∗) 2

+Eξk γ12,ξk Fξk (xk) − gk + Fξk (x∗) 2 ,

where in the last inequality we use8 µξk 1{µ k ≥0} − 2µξk 1{µ k <0} ≤ 2|µξk |. To upper bound the last two terms

ξ

ξ

8When all µξ ≥ 0, which is often assumed in the analysis of S-SEG, numerical constants in our proof can be tightened. Indeed, in the last step, we can get −Eξk γ12,ξk (1 − 2γ1,ξk µξk ) Fξk (xk) 2 instead of −Eξk γ12,ξk (1 − 4γ1,ξk |µξk |) Fξk (xk) 2 .

Stochastic Extragradient: General Analysis and Improved Rates

we use simple inequalities (20) and (19), and apply Lξk -Lipschitzness of Fξk (x):

E xk+1 − x∗ 2 | xk

(20),(19)
≤

xk − x∗ 2 + Eξk γ12,ξk gk 2

−Eξk γ12,ξk (1 − 4γ1,ξk |µξk |) Fξk (xk) 2 − 21 Eξk γ12,ξk gk 2 + Eξk γ12,ξk Fξk (x∗) 2 +2Eξk γ12,ξk Fξk (xk) − gk 2 + 2Eξk γ12,ξk Fξk (x∗) 2 = xk − x∗ 2 + 21 Eξk γ12,ξk gk 2 −Eξk γ12,ξk (1 − 4γ1,ξk |µξk |) Fξk (xk) 2

+3Eξk γ12,ξk Fξk (x∗) 2

+2Eξk γ12,ξk Fξk (xk) − Fξk (xk − γ1,ξk Fξk (xk)) 2 (≤6) xk − x∗ 2 + 21 Eξk γ12,ξk gk 2 + 3Eξk γ12,ξk Fξk (x∗) 2
−Eξk γ12,ξk 1 − 4γ1,ξk |µξk | − 2L2ξk γ12,ξk Fξk (xk) 2 (2≤7) xk − x∗ 2 + 21 Eξk γ12,ξk gk 2 + 3Eξk γ12,ξk F (x∗, ξk) 2 ,

Finally, we use the above inequality together with (29):

xk − x∗ 2 − 2Pk + Eξk γ12,ξk gk 2 ≤ xk − x∗ 2 + 21 Eξk γ12,ξk gk 2 + 3Eξk γ12,ξk Fξk (x∗) 2 ,

where Pk = Eξk γ1,ξk gk, xk − x∗ . Rearranging the terms, we obtain (28).

Lemma E.2. Let Assumptions 3.1 and 3.2 hold. Fξk xk − γ1,ξk Fξk (xk) satisﬁes the following inequality

If γ1,ξk satisﬁes (8),(9), and (27), then gk =

Pk ≥ ρ xk − x∗ 2 + 21 Gk − 23 Eξk γ12,ξk Fξk(x∗) 2

(30)

where Pk = Eξk γ1,ξk gk, xk − x∗ and

Gk = Eξk

1 ρ = 2 Eξk [γ1,ξk µξk (1{µξk ≥0} + 4 · 1{µξk <0})],

γ12,ξk

1

−

4|µξk |γ1,ξk

−

2L

2 ξk

γ

2 1,ξ

k

Fξk (xk) 2 .

Proof. We start with rewriting Pk:

−Pk = −Eξk γ1,ξk gk, xk − x∗ (=8) −Eξk γ1,ξk gk − Fξk (x∗), xk − x∗ = −Eξk γ1,ξk gk − Fξk (x∗), xk − γ1,ξk Fξk (xk) − x∗
−Eξk γ12,ξk gk − Fξk (x∗), Fξk (xk)

(2=1) −Eξk γ1,ξk Fξk (xk − γ1,ξk Fξk (xk)) − Fξk (x∗), xk − γ1,ξk Fξk (xk) − x∗

1 − 2 Eξk
1 − 2 Eξk

γ12,ξk γ12,ξk

gk − Fξk (x∗) 2 Fξk (xk) 2 .

T1
1 + 2 Eξk
T2

γ12,ξk

gk − Fξk (xk) − Fξk (x∗) 2

(31)

Eduard Gorbunov, Hugo Berard, Gauthier Gidel, Nicolas Loizou

Next, we upper bound terms T1 and T2. From (µξk , x∗)-strong monotonicity of Fξk we have9

T1

(7)
≤

−Eξk µξk γ1,ξk xk − x∗ − γ1,ξk Fξk (xK ) 2

= −Eξk 1{µξk ≥0}µξk γ1,ξk xk − x∗ − γ1,ξk Fξk (xK ) 2 −Eξk 1{µξk <0}µξk γ1,ξk xk − x∗ − γ1,ξk Fξk (xK ) 2

(20),(19)
≤
≤

1 − 2 Eξk

1{µξk ≥0}µξk γ1,ξk

xk − x∗ 2 + Eξk 1{µξk ≥0}µξk γ13,ξk Fξk (xk) 2

−2Eξk 1{µξk <0}µξk γ1,ξk xk − x∗ 2 − 2Eξk 1{µξk <0}µξk γ13,ξk Fξk (xk) 2

1 − 2 Eξk

1{µξk ≥0} + 4 · 1{µξk <0} µξk γ1,ξk

xk − x∗ 2 + 2Eξk

|

µξ

k

|

γ

3 1,ξ

k

Fξk (xk) 2

.

Using simple inequalities (20) and (19) and applying Lξk -Lipschitzness of Fξk (x), we upper bound T2:

T2 (20)≤,(19) − 41 Eξk γ12,ξk gk 2 + 12 E γ12,ξk Fξk (x∗) 2 +Eξk γ12,ξk gk − Fξk (xk) 2 + Eξk γ12,ξk Fξk (x∗) 2
≤ Eξk γ12,ξk gk − Fξk (xk) 2 + 23 Eξk γ12,ξk Fξk (x∗) 2 = Eξk γ12,ξk Fξk (xk − γ1,ξk Fξk (xk)) − Fξk (xk) 2 + 23 Eξk γ12,ξk Fξk (x∗) 2 (≤6) Eξk L2ξk γ14,ξk Fξk (xk) 2 + 23 Eξk γ12,ξk Fξk (x∗) 2 .

Putting all together in (31), we derive

1 −Pk ≤ − 2 Eξk

1{µξk ≥0} + 4 · 1{µξk <0} µξk γ1,ξk

xk − x∗ 2 + 32 Eξk γ12,ξk Fξk (x∗) 2

1 − 2 Eξk

γ12,ξk

1

−

4|µξk |γ1,ξk

−

2L2ξk

γ

2 1,ξ

k

Fξk (xk) 2 ,

where the last term is non-negative due to (27). This ﬁnishes the proof.

Combining two previous lemmas with Theorem 2.1, we derive the following result.
Theorem E.1 (Theorem 3.1). Let Assumptions 3.1 and 3.2 hold. If γ2,ξk = αγ1,ξk , α > 0, and γ1,ξk satisﬁes (8), (9), and (27), then gk = Fξk xk − γ1,ξk Fξk (xk) from (S-SEG) satisﬁes Assumption 2.1 with the following parameters:

Gk = αEξk

A = 2α, C = 0, D1 = 6α2σA2S = 6α2Eξ γ12,ξ Fξ(x∗) 2

α ρ = 2 Eξk [γ1,ξk µξk (1{µξk ≥0} + 4 · 1{µξk <0})],

γ12,ξk

1

−

4|µξk |γ1,ξk

−

2

L2ξk

γ

2 1,ξ

k

Fξk (xk) 2 ,

B = 1, 2

, D2 = 3α σ2 .
2 AS

If additionally α ≤ 1/4, then for all K ≥ 0 we have for the case ρ > 0

E xK+1 − x∗ 2 E xK − x∗ 2

≤ (1 − ρ) E ≤ (1 − ρ)K

xK − x∗ 2 + 3α (4α + 1) σ2 ,

2

AS

x0 − x∗ 2 + 3α (4α + 1) σA2S , 2ρ

9When all µξ ≥ 0, which be tightened. Indeed, in the

2Eξk

|

µ

ξ

k

|γ

3 1,ξ

k

Fξk (xk) 2 .

is often assumed in the analysis of S-SEG, numerical constants in our

last

step

of

the

derivation

below,

we

can

get

Eξk

µ

ξ

k

γ

3 1,ξ

k

Fξk (xk) 2

proof can instead of

Stochastic Extragradient: General Analysis and Improved Rates

and for the case ρ = 0

1K K+1 E
k=0

γ12,ξk

1

−

4|µξk |γ1,ξk

−

2

L2ξk

γ

2 1,ξ

k

F (xk) 2 ≤ 2 x0 − x∗ 2 + 3(4α + 1)σ2 .

ξk

α(K + 1)

AS

Proof. S-SEG ﬁts the uniﬁed update rule (3) with γξk = γ2,ξk and gk = Fξk xk − γ1,ξk Fξk (xk) . Moreover, Lemmas E.1 and E.2 imply

Eξk γ12,ξk gk 2 ≤ 4Pk + 6Eξk γ12,ξk Fξk (x∗) 2 , Pk ≥ ρ xk − x∗ 2 + 12 Gk − 23 Eξk γ12,ξk Fξk(x∗) 2 ,

where Pk = Eξk γ1,ξk gk, xk − x∗ and

Gk = Eξk

1 ρ = 2 Eξk [γ1,ξk µξk (1{µξk ≥0} + 4 · 1{µξk <0})],

γ12,ξk

1

−

4|µξk |γ1,ξk

−

2L

2 ξk

γ

2 1,ξ

k

Fξk (xk) 2 .

(32) (33)

Since γξk = γ2,ξk = αγ1,ξk , we multiply (32) by α2 and (33) by α and get that Assumption 2.1 holds with the parameters given in the statement of the theorem. Applying Theorem 2.1 we get the result.

The next corollary establishes the convergence rate with diminishing stepsizes allowing to reduce the size of the neighborhood, when ρ > 0.
Corollary E.1 (ρ > 0; Corollary 3.1). Let Assumptions 3.1 and 3.2 hold, γ2,ξk = αγ1,ξk , α = 1/4, γ1,ξk = βk ·γξk , and γξk satisﬁes (8), (9), and (27). Assume that

1 ρ = 8 Eξk [γξk µξk (1{µξk ≥0} + 4 · 1{µξk <0})] > 0.

Then, for all K ≥ 0 and {βk}k≥0 such that

if K ≤ 1 , ρ
if K > 1 and k < k0, ρ
if K > 1 and k ≥ k0, ρ

βk = 1,

βk = 1,

2

βk

=

2

+

ρ(k

−

, k0)

for k0 = K/2 we have

E

xK − x∗ 2

≤ 32 x0 − x∗ 2 exp

ρK −

+ 27σA2S ,

ρ

2

ρ2K

where σA2S = Eξ γξ2 Fξ(x∗) 2

Proof. In Theorem E.1, we establish the following recurrence:

E xk+1 − x∗ 2

≤ α==1/4

(1 − βkρ) E (1 − βkρ) E

xk − x∗ 2 + 3α (4α + 1) β2σ2

2

k AS

xk − x∗ 2 + βk2 3σ4A2S ,

where we redeﬁned ρ and σA2S to better handle decreasing stepsizes. Applying Lemma C.1 for rk = E γk = βk, a = ρ, c = 3σA2S/4, h = 1, we get the result.

xk − x∗ 2 ,

When ρ = 0, we use large batchiszes to reduce the size of the neighborhood.

Eduard Gorbunov, Hugo Berard, Gauthier Gidel, Nicolas Loizou

Corollary E.2 (ρ = 0). Let Assumptions 3.1 and 3.2 hold, γ2,ξk = αγ1,ξk , α = 1/4, and γ1,ξk satisﬁes (8)-(9),

and

0 < γ1,ξk ≤

1√ .

8|µξk | + 2 2Lξk

Assume that

1 ρ = 8 Eξk [γ1,ξk µξk (1{µξk ≥0} + 4 · 1{µξk <0})] = 0,

Eξk γ1,ξk Fξk (xk) = γF (xk)

for some γ > 0 and Fξk (xk) is computed via O(b) stochastic oracle calls and10

Eξk ∼D

γ12,ξk Fξk (x∗) 2

1 ≤ b Eξk∼D

γ12,ξk Fξk (x∗) 2

= σA2S , b

where D satisﬁes Assumptions 3.1 and 3.2. Then, for all K ≥ 0 we have

1K K+1 E
k=0

F (xk) 2 ≤ 16 x0 − x∗ 2 + 12σA2S ,

γ2(K + 1)

γ2b

and each iteration requires O(b) stochastic oracle calls.

Proof. Theorem E.1 implies that

Since we have

1K K+1 E
k=0

γ12,ξk

1

−

4|µξk |γ1,ξk

−

2L2ξk

γ

2 1,ξ

k

Fξk (xk) 2

≤

2 x0−x∗ 2 α(K+1)

+ 3(4α + 1)Eξk∼D

α=≤1/4 8 xK0−+x1∗ 2 + 6σbA2S .

γ12,ξk

Fξk (x∗) 2

0 < γ1,ξk ≤

1√ ,

8|µξk | + 2 2Lξk

2(K1+ 1) K E γ12,ξk Fξk (xk) 2
k=0

≤ 8 x0 − x∗ 2 + 6σA2S .

K +1

b

Finally, we use Jensen’s inequality and Eξk γ1,ξk Fξk (xk) = γF (xk):

γ2

K

2(K + 1) E
k=0

F (xk) 2

1

K

k2

= 2(K + 1) E Eξk γ1,ξk Fξk (x )

k=0

1

K

≤ 2(K + 1) E Eξk

k=0

γ1,ξk Fξk (xk) 2

= 2(K1+ 1) K E γ12,ξk Fξk (xk) 2
k=0

≤ 8 x0 − x∗ 2 + 6σA2S .

K +1

b

Multiplying the inequality by 2/γ2, we get the result.

10This can be achieved with i.i.d. batching from the distribution D, satisfying Assumptions 3.2 and 3.1.

Stochastic Extragradient: General Analysis and Improved Rates

E.3 S-SEG with Uniform Sampling (S-SEG-US)

Theorem E.2. Consider the setup from Example 3.1. If γ2,ξk = αγ1,ξk , α > 0, and γ1,ξk = γ ≤ 1/6Lmax, where Lmax = maxi∈[n] Li, then gk = Fξk xk − γ1,ξk Fξk (xk) from (S-SEG) satisﬁes Assumption 2.1 with the following parameters:

A = 2α,

C = 0,

D = 6α2γ2σ2

6α2γ2 n =

1

US∗

n

i=1

Fi(x∗) 2,

ρ = αγµ , 2

αγ2 n Gk = n

1 − 4|µi|γ − 2L2i γ2

i=1

Fi(xk) 2,

B = 1, 2

D2

=

3αγ2 σ2 .
US∗

2

If additionally α ≤ 1/4, then for all K ≥ 0 we have for the case µ > 0

E xK+1 − x∗ 2 ≤ 1 − αγµ E xK − x∗ 2 + 3α (4α + 1) γ2σ2 ,

2

2

US∗

E and for the case µ = 0

xK − x∗ 2 ≤

1 − αγµ K x0 − x∗ 2 + 3 (4α + 1) γσU2S∗ ,

2

µ

1K K+1 E
k=0

1n n i=1

1 − 4|µi|γ − 2L2i γ2

F (xk) 2 ≤ 2 x0 − x∗ 2 + 3(4α + 1)σ2 .

i

αγ2(K + 1)

US∗

Proof. Since γ ≤ /1 6Lmax and |µi| ≤ Li, condition (27) is satisﬁed. In Example E.1, we show that conditions (8) and (9) hold as well. Therefore, Theorem E.1 implies the desired result with

σ2

=

E

γ2

F (x∗) 2

γ2 =

n

F (x∗) 2 = γ2σ2 ,

AS

ξ 1,ξ ξ

n

i

US∗

i=1





α

αγ

αγµ

ρ = 2 Eξk [γ1,ξk µξk (1{µξk ≥0} + 4 · 1{µξk <0})] = 2n 

µi + 4

µi = 2 ,

i:µi ≥0

i:µi <0

Gk

=

αEξk

γ12,ξk

1

−

4|µξk |γ1,ξk

−

2L2ξk

γ

2 1,ξ

k

Fξk (xk) 2

= αnγ2 n 1 − 4|µi|γ − 2L2i γ2 Fi(xk) 2.
i=1

Corollary E.3 (µ > 0). Consider the setup from Example 3.1. Let µ > 0, γ2,ξk = αγ1,ξk , α = 1/4, and γ1,ξk = βkγ = βk/6Lmax, where Lmax = maxi∈[n] Li and 0 < βk ≤ 1. Then, for all K ≥ 0 and {βk}k≥0 such that

if K ≤ 48Lmax , µ
if K > 48Lmax and k < k0, µ
if K > 48Lmax and k ≥ k0, µ

βk = 1,

βk = 1,

βk =

96Lmax ,

96Lmax + µ(k − k0)

for k0 = K/2 we have

E xK − x∗ 2 ≤ 1536Lmax x0 − x∗ 2 exp − µK + 1728σU2S∗ .

µ

96Lmax

µ2K

Eduard Gorbunov, Hugo Berard, Gauthier Gidel, Nicolas Loizou

Proof. Corollary E.1 implies the needed result with





1

γ

µ

ρ = 8 Eξk [γξk µξk (1{µξk ≥0} + 4 · 1{µξk <0})] = 8n 

µi + 4

µi

=

, 48Lmax

i:µi ≥0

i:µi <0

σ2

=

E

γ2 F (x∗) 2

γ2 =

n

F (x∗) 2 = γ2σ2 .

AS

ξξ ξ

n

i

US∗

i=1

Corollary E.4 (µ = 0). Consider the setup from Example 3.1. Let µ = 0, γ2,ξk = αγ1,ξk , α = 1/4, and γ1,ξk = γ ≤ 1/6Lmax, where Lmax = maxi∈[n] Li. Assume that

k 1b

Fξk (x ) = b

Fξk (x), i

i=1

where

ξ

k 1

,

.

.

.

,

ξ

k b

are

i.i.d.

samples

from

the

uniform

distribution

on

[n].

Then,

for

all

K

≥

0

we

have

1K K+1 E
k=0

F (xk) 2 ≤ 16 x0 − x∗ 2 + 12σU2S∗ ,

γ2(K + 1)

b

and each iteration requires O(b) stochastic oracle calls.

Proof. Since

Eξk γ1,ξk Fξk (xk)

γn

=

Fi(xk) = γF (xk),

n i=1

Corollary E.2 implies the needed result with

σ2

=

E

γ2 F (x∗) 2

γ2 =

n

F (x∗) 2 = γ2σ2 .

AS

ξξ ξ

n

i

US∗

i=1

E.4 S-SEG with b-Nice Sampling (S-SEG-NICE)

Theorem E.3. Consider the setup from Example 3.2. If γ2,ξk = αγ1,ξk , α > 0, and γ1,ξk = γ ≤ / , 1 6Lb−NICE

where

Lb−NICE

=

maxS⊆[n],|S|=b LS

and

LS

is

the

Lipschitz

constant

of

FS (x)

=

1 |S|

n i=1

Fi

(x),

then

gk

=

Fξk xk − γ1,ξk Fξk (xk) from (S-SEG) satisﬁes Assumption 2.1 with the following parameters:

A = 2α,

C = 0,

D1 = 6α2γ2σb2−NICE∗ = 6αn2γ2
b S⊆[n],|S|=b

FS(x∗) 2,

ρ = αγµb−NICE , 2

αγ2 Gk = n

1 − 4|µS|γ − 2L2Sγ2

b S⊆[n],|S|=b

FS(xk) 2,

B = 1, 2

D2 = 3α2γ2 σb2−NICE∗.

If additionally α ≤ 1/4, then for all K ≥ 0 we have for the case µb−NICE > 0

E xK+1 − x∗ 2 ≤ 1 − αγµb−NICE E xK − x∗ 2 + 3α (4α + 1) γ2σ2

,

2

2

b−NICE∗

E xK − x∗ 2 ≤ and for the case µb−NICE = 0

1 − αγµb−NICE 2

K x0 − x∗ 2 + 3 (4α + 1) γσb2−NICE∗ , µ



1K

1

K +1 E n

1 − 4|µS|γ − 2L2Sγ2

k=0

b S⊆[n],|S|=b



F (xk) 2 ≤ 2 x0 − x∗ 2 + 3(4α + 1)σ2

.

S

 αγ2(K + 1)

b−NICE∗

Stochastic Extragradient: General Analysis and Improved Rates

Proof. Since γ ≤ /1 6Lb−NICE and |µS| ≤ LS for all S ⊆ [n], condition (27) is satisﬁed. In Example E.2, we show that conditions (8) and (9) hold as well. Therefore, Theorem E.1 implies the desired result with

σ2 = E γ2 F (x∗) 2 = γ2

AS

ξ 1,ξ ξ

n

FS (x∗) 2 = γ2σb2−NICE∗,

b S⊆[n]





ρ=

α

αγ 

2 Eξk [γ1,ξk µξk (1{µξk ≥0} + 4 · 1{µξk <0})] = 2 n

 

b

S⊆[n],

µS + 4

S⊆[n],

 µS 


|S|=b:µS ≥0

|S|=b:µS <0

= αγµb−NICE , 2

Gk

=

αEξk

γ12,ξk

1

−

4|µξk |γ1,ξk

−

2

L2ξk

γ

2 1,ξ

k

Fξk (xk) 2

αγ2 =n

1 − 4|µS|γ − 2L2Sγ2 FS(xk) 2.

b S⊆[n],|S|=b

Remark E.1. We notice that

Lb−NICE =

max LS ≤ max 1 Li ≤ max Li = Lmax,

S⊆[n],|S|=b

S⊆[n],|S|=b b i∈S

i∈[n]









µb−NICE =

1 n

b

S⊆[n],

µS + 4

S⊆[n],

µS ≥ 

1 n

b

S⊆[n],

1 µi + 4 b i∈S

S⊆[n],

1 µi

b



i∈S

|S|=b:µS ≥0

|S|=b:µS <0

|S|=b:µS ≥0

|S|=b:µS <0









=1 n

1b  µi +

µi + 4n

1b  µi +

µi

b

S⊆[n],

i∈S :µi ≥0

i∈S :µi <0

b

S⊆[n],

i∈S :µi ≥0

i∈S :µi <0

|S|=b:µS ≥0

|S|=b:µS <0





≥1 n

1b  µi +

4µi

b

S⊆[n],

i∈S :µi ≥0

i∈S :µi <0

|S|=b:µS ≥0





+1 n b

S⊆[n],

1b  µi +

4µi

i∈S :µi ≥0

i∈S :µi <0

|S|=b:µS <0









1

1

n−1 b−1

=n

b  µi +

4µi = b · n 

µi +

4µi

b S⊆[n],|S|=b

i∈S :µi ≥0

i∈S :µi <0

b

i:µi ≥0

i:µi <0

=1

µi + 4

µi = µ,

n i:µi≥0

n i:µi<0

σb2−NICE∗ =

2

1

FS (x∗) 2 = 1

1 Fi(x∗)

n b S⊆[n]

nb S⊆[n] b i∈S

=

1

Fi(x∗) 2 + 2

Fi(x∗), Fj (x∗)

b2 · nb S⊆[n] i∈S

i,j∈S,i<j





1

n−1 n

∗2

n−2

∗

∗

= b2 · n  b − 1

Fi(x ) + 2 b − 2

Fi(x ), Fj(x ) 

b

i=1

1≤i<j≤n

n−1 − n−2 n

n−2

=

b−1

b−2

b2 · n

Fi(x∗)

2+

b−2
b2 · n

b

i=1

b

= b(nn−−b1) σU2S∗.

n

2 ∗

n−b n

Fi(x ) = bn(n − 1)

i=1

i=1

Fi(x∗) 2

(34)

Eduard Gorbunov, Hugo Berard, Gauthier Gidel, Nicolas Loizou

Therefore, S-SEG-NICE converges faster to the smaller neighborhood than S-SEG-US. Moreover, the size of the neighborhood σb2−NICE∗ is smaller than σU2S∗/b, which corresponds to the variance in the case of i.i.d. sampling (Example E.1).

Corollary E.5 (µb−NICE > 0). Consider the setup from Example 3.2. If γ2,ξk = αγ1,ξk , α = 1/4, and γ1,ξk =

βk γ

=

/ , βk 6Lb−NICE

where

Lb−NICE

=

maxS⊆[n],|S|=b LS ,

LS

is

the

Lipschitz

constant

of

FS (x)

=

1 |S|

n i=1

Fi

(x),

and 0 < βk ≤ 1. Then, for all K ≥ 0 and {βk}k≥0 such that

if K ≤ 48Lb−NICE , µb−NICE
if K > 48Lb−NICE and k < k0, µb−NICE
if K > 48Lb−NICE and k ≥ k0, µb−NICE

βk = 1,

βk = 1,

βk =

96Lb−NICE ,

96Lb−NICE + µb−NICE(k − k0)

for k0 = K/2 we have

E xK − x∗ 2 ≤ 1536Lb−NICE x0 − x∗ 2 exp − µb−NICEK + 1728(n − b)σU2S∗ .

µb−NICE

96Lb−NICE

µ2b−NICEK

Proof. Corollary E.1 implies the needed result with





ρ=

1

γ

8 Eξk [γξk µξk (1{µξk ≥0} + 4 · 1{µξk <0})] = 8 n

 

b

S⊆[n],

µS + 4

S⊆[n],

 µS 


|S|=b:µS ≥0

|S|=b:µS <0

= µb−NICE , 48Lb−NICE

σ2 = E γ2 F (x∗) 2 = γ2

F (x∗) 2 = γ2σ2

(3=4) n − b σ2 .

AS

ξξ ξ

n

S

b S⊆[n]

b−NICE∗

b(n − 1) US∗

E.5 S-SEG with Importance Sampling (S-SEG-IS)

Theorem E.4. Consider the setup from Example 3.3. If γ2,ξk = αγ1,ξk , α > 0, and γ1,ξk = γL/Lξk , γ ≤

1/6L, where L = n1

n i=1

Li,

then

gk

=

Fξk

xk − γ1,ξk Fξk (xk)

from (S-SEG) satisﬁes Assumption 2.1 with the

following parameters:

A = 2α, C = 0, D1 = 6α2γ2σI2S∗ =

αγ2 n L Gk = n Li
i=1

1 − 4 |µi| Lγ − 2L2γ2 Li

6α2γ2 n L F (x∗)

n

Li i

i=1

Fi(xk) 2,

B = 1, 2

2, ρ = αγµ , 2

D2

=

3αγ2 σ2 .
IS∗

2

If additionally α ≤ 1/4, then for all K ≥ 0 we have for the case µ > 0

E xK+1 − x∗ 2 ≤ 1 − αγµ E xK − x∗ 2 + 3α (4α + 1) γ2σ2 ,

2

2

IS∗

E xK − x∗ 2 ≤ 1 − αγµ K x0 − x∗ 2 + 3 (4α + 1) γσI2S∗ ,

2

µ

and for the case µ = 0

1K K+1 E
k=0

1n L n i=1 Li

1 − 4 |µi| Lγ − 2L2γ2 Li

F (xk) 2

≤2

x0 − x∗

2
+ 3(4α + 1)σ2

.

i

αγ2(K + 1)

IS∗

Stochastic Extragradient: General Analysis and Improved Rates

Proof. Since γ ≤ 1/6L and |µi| ≤ Li, condition (27) is satisﬁed. In Example E.1, we show that conditions (8) and (9) hold as well. Therefore, Theorem E.1 implies the desired result with

σ2

=

E

γ2

F (x∗) 2

γ2 =

n

L

F (x∗) 2 = γ2σ2 ,

AS

ξ 1,ξ ξ

n

Li i

IS∗

i=1

α

α n γL

Li

ρ = 2 Eξk [γ1,ξk µξk (1{µξk ≥0} + 4 · 1{µξk <0})] = 2

Li µi(1{µi≥0} + 4 · 1{µi<0}) · nL

i=1





αγ

αγµ

= 2n 

µi + 4

µi = 2 ,

i:µi ≥0

i:µi <0

Gk

=

αEξk

γ12,ξk

1

−

4|µξk |γ1,ξk

−

2

L2ξk

γ

2 1,ξ

k

Fξk (xk) 2

= αγ2 n L 1 − 4 |µi| Lγ − 2L2γ2 n i=1 Li Li

Fi(xk) 2.

Corollary E.6 (µ > 0). Consider the setup from Example 3.3. Let µ > 0, γ2,ξk = αγ1,ξk , α = 1/4, and

γ1,ξk

=

/ βkγL Lξk

=

βk/6Lξk ,

where

L

=

1 n

n i=1

Li

and

0

<

βk

≤

1.

Then,

for

all

K

≥

0

and

{βk }k≥0

such

that

if K ≤ 48L , µ
if K > 48L and k < k0, µ
if K > 48L and k ≥ k0, µ

βk = 1,

βk = 1,

βk =

96L ,

96L + µ(k − k0)

for k0 = K/2 we have

E

xK − x∗ 2

≤ 1536L x0 − x∗ 2 exp

µK −

+ 1728σI2S∗ .

µ

96L

µ2K

Proof. Corollary E.1 implies the needed result with





1

γ

µ

ρ = 8 Eξk [γξk µξk (1{µξk ≥0} + 4 · 1{µξk <0})] = 8n 

µi + 4

µi = 48L ,

i:µi ≥0

i:µi <0

σ2

=

E

γ2 F (x∗) 2

γ2 =

n

L F (x∗) 2 = γ2σ2 .

AS

ξξ ξ

n

Li i

IS∗

i=1

Corollary E.7 (µ = 0). Consider the setup from Example 3.3. Let µ = 0, γ2,ξk = αγ1,ξk , α = 1/4, and

γ1,ξk

=

γL/Lξk ,

γ

≤

1/6L,

where

L

=

1 n

n i=1

Li.

Assume

that

k 1b

Fξk (x ) = b

Fξk (x), i

i=1

where

ξ

k 1

,

.

.

.

,

ξ

k b

are

i.i.d.

samples

from

the

distribution

on

[n]

from

Example

3.3.

Then,

for

all

K

≥

0

we

have

1K K+1 E
k=0

F (xk) 2 ≤ 16 x0 − x∗ 2 + 12σI2S∗ ,

γ2(K + 1)

b

and each iteration requires O(b) stochastic oracle calls.

Eduard Gorbunov, Hugo Berard, Gauthier Gidel, Nicolas Loizou

Proof. Since

Eξk γ1,ξk Fξk (xk)

γn

=

Fi(xk) = γF (xk),

n i=1

Corollary E.2 implies the needed result with

σ2

=

E

γ2 F (x∗) 2

γ2 =

n

L F (x∗) 2 = γ2σ2 .

AS

ξξ ξ

n

Li i

IS∗

i=1

E.6 S-SEG with Independent Sampling Without Replacement (S-SEG-ISWOR)
Theorem E.5. Consider the setup from Example E.3. If γ2,ξk = αγ1,ξk , α > 0, and γ1,ξk = γ|ξ|/pξ2n−1n, γ ≤ / , 1 6LISWOR where LISWOR = maxS⊆[n](|S|LS/pS2n−1n), then gk = Fξk xk − γ1,ξk Fξk (xk) from (S-SEG) satisﬁes Assumption 2.1 with the following parameters:

where

A = 2α,

C = 0,

D1 = 6α2γ2σI2SWOR∗ = 262nα−22γn22

|S|2 F (x∗) pS S

S⊆[n]

αγ2

|S|2

Gk = 22n−2n2

pS

S⊆[n]

1 − 4 |µS| · |S| γ − 2 L2S|S|2 γ2

pS 2n−1n

p2S 22n−2n2

B = 1, 2

D2

=

3αγ2 σ2

,

ISWOR∗

2

2, ρ = FS (xk )

αγµISWOR , 2
2,





1

µISWOR = 2n−1n 

|S|µS + 4

|S|µS .

S⊆[n]:µS ≥0

S⊆[n]:µS <0

If additionally α ≤ 1/4, then for all K ≥ 0 we have for the case µISWOR∗ > 0

E xK+1 − x∗ 2 ≤ 1 − αγµISWOR E xK − x∗ 2 + 3α (4α + 1) γ2σ2

,

2

2

ISWOR∗

E xK − x∗ 2 ≤ 1 − αγµISWOR K x0 − x∗ 2 + 3 (4α + 1) γσI2SWOR∗ ,

2

µ

and for the case µISWOR∗ = 0



1K

1

|S|2

K + 1 E  22n−2n2

pS

k=0

S⊆[n]

1 − 4 |µS| · |S| γ − 2 L2S|S|2 γ2

pS 2n−1n

p2S 22n−2n2



FS (xk )

2


≤

2 x0−x∗ 2 αγ 2 (K +1)

+ 3(4α + 1)σI2SWOR∗

Proof. Since γ ≤ /1 6LISWOR and |µS| ≤ LS for all S ⊆ [n], condition (27) is satisﬁed. In Example E.3, we show

Stochastic Extragradient: General Analysis and Improved Rates

that conditions (8) and (9) hold as well. Therefore, Theorem E.1 implies the desired result with

σ2 = E γ2 F (x∗) 2 = γ2

|S|2 F (x∗) 2 = γ2σ2

,

AS

ξ 1,ξ ξ

22n−2n2

pS S

ISWOR∗

S⊆[n]





α

αγ 



ρ=

2 Eξk [γ1,ξk µξk (1{µξk ≥0}

+ 4 · 1{µξk <0})]

=

2nn

 

|S|µS + 4

|S |µS  

S⊆[n]:

S⊆[n]:

µS ≥0

µS <0

= αγµISWOR , 2

Gk

=

αEξk

γ12,ξk

1

−

4|µξk |γ1,ξk

−

2L2ξk

γ

2 1,ξ

k

Fξk (xk) 2

αγ2 =

|S|2 1 − 4 |µS| · |S| γ − 2 L2S|S|2 γ2

22n−2n2

pS

S⊆[n]

pS 2n−1n

p2S 22n−2n2

FS(xk) 2.

Corollary E.8 (µISWOR∗ > 0). Consider the setup from Example E.3. Let µISWOR∗ > 0, γ2,ξk = αγ1,ξk , α = 1/4, and γ1,ξk = βkγ|ξ|/pξ2n−1n, γ = / , 1 6LISWOR where LISWOR = maxS⊆[n](|S|LS/pS2n−1n) and 0 < βk ≤ 1. Then, for all
K ≥ 0 and {βk}k≥0 such that

if K ≤ 48LISWOR , µISWOR
if K > 48LISWOR and k < k0, µISWOR
if K > 48LISWOR and k ≥ k0, µISWOR

βk = 1,

βk = 1,

βk =

96LISWOR ,

96LISWOR + µISWOR(k − k0)

for k0 = K/2 we have

E xK − x∗ 2 ≤ 1536LISWOR x0 − x∗ 2 exp − µISWORK + 1728σI2SWOR∗ .

µISWOR

96LISWOR

µ2ISWORK

Proof. Corollary E.1 implies the needed result with





1

αγ 



ρ

=

8 Eξk [γξk µξk (1{µξk ≥0}

+ 4 · 1{µξk <0})]

=

2n+2n

 

|S|µS + 4

|S |µS  

S⊆[n]:

S⊆[n]:

µS ≥0

µS <0

= µISWOR , 48LISWOR

σ2 = E γ2 F (x∗) 2 = γ2

|S|2 F (x∗) 2 = γ2σ2

.

AS

ξξ ξ

22n−2n2

pS S

ISWOR∗

S⊆[n]

Eduard Gorbunov, Hugo Berard, Gauthier Gidel, Nicolas Loizou

F INDEPENDENT-SAMPLES SEG (I-SEG): MISSING PROOFS AND ADDITIONAL DETAILS

In this section, we provide full proofs and missing details from Section 4 on I-SEG. Recall that our analysis of I-SEG based on the three following assumptions:

• F (x) is L-Lipschitz: F (x) − F (y) ≤ L x − y for all x, y ∈ Rd (Assumption 1.1), • F (x) is µ-quasi strongly monotone: F (x), x − x∗ ≥ µ x − x∗ 2 for all x ∈ Rd (Assumption 1.2), • Fξ(x) satisﬁes the following conditions (Assumption 4.1): Eξ[Fξ(x)] = F (x) and
Eξ Fξ(x) − F (x) 2 ≤ δ x − x∗ 2 + σ2.

Moreover, we assume that

k 1b

k

Fξk (x 1

)=

b

Fξ1k(i)(x ),

i=1

k 1b

k

k

Fξk (x 2

)=

b

Fξ2k(i)(x − γ1Fξ1k (x )),

i=1

where

ξ

k 1

(1),

.

.

.

,

ξ

k 1

(b

),

ξ2k

(1),

.

.

.

,

ξ

k 2

(b

)

are

i.i.d.

samples

satisfying

Assumption

4.1.

Due to independence of

ξ1k(1), . . . , ξ1k(b), ξ2k(1), . . . , ξ2k(b) we have

Eξk Fξk (xk) − F (xk) 2

1

1

Eξk Fξk (xk − γ1Fξk (xk)) − F (xk − γ1Fξk (xk)) 2

2

2

1

1

≤ δ xk − x∗ 2 + σ2 ,

b

b

≤ δb xk − γ1Fξ1k (xk) − x∗ 2 + σb2 .

(35) (36)

It turns out that under these assumptions gk satisﬁes Assumption 2.1. Lemma F.1. Let Assumptions 1.1, 1.2 and 4.1 hold. If
γ1 ≤ 1 (37) 3(L2 + 2δ/b)

then gk = Fξk xk − γ1Fξk (xk) satisﬁes the following inequality

2

1

γ2E gk 2 | xk ≤ 2P + 9δγ12 xk − x∗ 2 + 6γ12σ2 ,

(38)

1

k

b

b

where Pk = γ1Eξk,ξk gk, xk − x∗ . 12

Proof. Using the auxiliary iterate xk+1 = xk − γ1gk, we get

xk+1 − x∗ 2 = =

xk − x∗ 2 − 2γ1 xk − x∗, gk + γ12 gk 2 xk − x∗ 2 − 2γ1 xk − γFξk (xk) − x∗, gk
1

− 2γ12 Fξk (xk), gk + γ12 gk 2. 1

(39)

Taking the expectation Eξk,ξk [·] = E · | xk conditioned on xk from the above identity, using tower property 12

Eξk,ξk [·] = Eξk [Eξk [·]], and µ-quasi strong monotonicity of F (x), we derive

12

1

2

Eξ1k,ξ2k xk+1 − x∗ 2

= =
(2),(21)
≤

xk − x∗ 2 − 2γ1Eξk,ξk 12

xk − γ1Fξk (xk) − x∗, gk 1

−2γ12 Eξk ,ξk 12
xk − x∗ 2

Fξk (xk), gk 1

+ γ12Eξk,ξk 12

gk 2

−2γ1Eξk xk − γ1Fξk (xk) − x∗, F xk − γ1Fξk (xk)

1

1

1

−2γ12Eξk Fξk (xk), gk + γ12Eξk,ξk gk 2

1

1

12

xk − x∗ 2 − γ12Eξk,ξk 12

Fξk (xk) 2 + γ12Eξk,ξk

1

12

Fξk (xk) − gk 2 . 1

Stochastic Extragradient: General Analysis and Improved Rates To upper bound the last term we use simple inequality (19), and apply L-Lipschitzness of F (x):

Eξ1k,ξ2k xk+1 − x∗ 2

(19)
≤
(1),(35),(36)
≤
(19)
≤
(37)
≤

xk − x∗ 2 − γ12Eξk Fξk (xk) 2

1

1

+3γ12Eξk 1

2
F (xk) − F xk − γ1Fξk (xk) 1

+3γ12Eξk 1

2
Fξk (xk) − F (xk) 1

2

+3γ12Eξk,ξk Fξk xk −γ1Fξk (xk) − F xk −γ1Fξk (xk)

12

2

1

1

xk − x∗ 2 − γ12 1 − 3L2γ12 Eξk Fξk (xk) 2

1

1

+ 3γ12δ xk − x∗ 2 + 3γ12σ2

b

b

+ 3γb12δ Eξ1k

xk − x∗ − γ1Fξk (xk) 2 1

1 + 9γ12δ b

xk − x∗ 2

+ 3γ12σ2 b

−γ2 1 − 3γ2 L2 + 2δ

1

1

b

Eξk Fξk (xk) 2

1

1

+ 6γ12σ2 b
1 + 9γ12δ b

xk − x∗ 2 + 6γ12σ2 . b

Finally, we use the above inequality together with (39):

xk − x∗ 2 − 2Pk + γ12E gk 2 | xk ≤

1 + 9γ12δ b

xk − x∗ 2 + 6γ12σ2 , b

where Pk = γ1Eξk,ξk gk, xk − x∗ . Rearranging the terms, we obtain (38). 12

Lemma F.2. Let Assumptions 1.1, 1.2 and 4.1 hold. If

µb

1

γ1 ≤ min 18δ , 4µ + 6(L2 + 2δ/b) ,

(40)

then gk = Fξk xk − γ1Fξk (xk) satisﬁes the following inequality

2

1

Pk ≥ µ4γ1 xk − x∗ 2 + γ412 Eξ1k Fξ1k (xk) 2 − 6γ12bσ2 , where Pk = γ1Eξk,ξk gk, xk − x∗ .
12

(41)

Eduard Gorbunov, Hugo Berard, Gauthier Gidel, Nicolas Loizou

Proof. Since Eξk,ξk [·] = E[· | xk] and gk = Fξk xk − γ1Fξk (xk) , we have

12

2

1

−Pk

=

−γ1Eξk,ξk gk, xk − x∗

12

=

−γ1Eξk Eξk [gk], xk − γ1Fξk (xk) − x∗ − γ12E gk, Fξk (xk)

1

2

1

1

(2=1)
(2),(19)
≤
(20),(1),(17)
≤
(19)
≤
(40)
≤

−γ1Eξk F (xk − γ1Fξk (xk)), xk − γ1Fξk (xk) − x∗

1

1

1

γ12 − 2 Eξ1k,ξ2k

gk 2 − γ212 Eξ1k

Fξk (xk) 2 1

+ γ212 Eξ1k,ξ2k

gk − Fξk (xk) 2 1

−µγ1 Eξk ,ξk 12

xk − x∗ − γ1Fξ1k (xk) 2 − γ212 Eξ1k

Fξk (xk) 2 1

+ 3γ212 Eξ1k

2
F (xk) − F xk − γ1Fξk (xk) 1

+ 3γ212 Eξ1k

2
Fξk (xk) − F (xk) 1

+ 3γ212 Eξ1k,ξ2k

2

Fξk xk − γ1Fξk (xk) − F xk − γ1Fξk (xk)

2

1

1

− µγ1

xk − x∗

2

−

γ

2 1

(1

−

2γ1µ

−

3γ2L2)E

k

2

2

1

ξ1

Fξk (xk) 2 1

+ 3γ12δ xk − x∗ 2 + 3γ12σ2

2b

2b

+ 3γ21b2δ Eξ1k xk − x∗ − γ1Fξ1k (xk) 2 + 3γ212bσ2

− µγ1 1 − 9γ1δ

2

µb

xk − x∗ 2

− γ12 2

1 − 2γ1µ − 3γ12

L2 + 2δ b

Eξ1k Fξ1k (xk) 2 + 6γ212bσ2

− µ4γ1 xk − x∗ 2 − γ412 Eξ1k Fξ1k (xk) 2 + 6γ12bσ2

that concludes the proof11.

Combining Lemmas F.1 and F.2 and applying Theorem 2.1, we get the following result. Theorem F.1 (Theorem 4.1). Let Assumptions 1.1, 1.2, and 4.1 hold. If γ2 = αγ1, α > 0, and γ1 = γ, where12

γ ≤ min

µb 18δ , 4µ +

1 6(L2 + 2δ/b)

then gk = Fξk xk − γ1Fξk (xk) from (I-SEG) satisﬁes Assumption 2.1 with the following parameters:

2

1

A = 2α,

C = 9δα2γ2 , b

Gk = Eξk Fξk (xk) 2 ,

1

1

6α2γ2σ2

D1 =

,

b

ρ = αγµ , 4

αγ2 B= 4 ,

6αγ2σ2

D2 =

.

b

If additionally α ≤ 1/4, then for all K ≥ 0 we have for the case µ > 0

E xK+1 − x∗ 2 ≤ 1 − αγµ E xK − x∗ 2 + 6α (α + 1) γ2 σ2 ,

8

b

11When δ = 0, i.e., when we are in the classical setup of uniformly bounded variance, numerical constants in our proof can be tightened. Indeed, in the last step, we can get − µ2γ1 xk − x∗ 2 − γ412 Eξ1k Fξ1k (xk) 2 + 6γ12bσ2 . Moreover, if we
are interested in the case when µ > 0, then assuming that γ1 ≤ 2µ+1√3L , can get − µ2γ1 xk − x∗ 2 + 6γ12bσ2 . 12When µ = δ = 0, the ﬁrst term can be ignored.

Stochastic Extragradient: General Analysis and Improved Rates

E xK − x∗ 2 and for the case µ = 0 and δ = 0
1K K+1 E
k=0

≤ 1 − αγµ K x0 − x∗ 2 + 48 (α + 1) γσ2 ,

8

µb

Fξ1k (xk) 2 ≤ 4αγx20(K− x+∗1)2 + 24(α +b 1)σ2 .

Proof. I-SEG ﬁts the uniﬁed update rule (3) with γξk = γ2 and gk = Fξk xk − γ1Fξk (xk) . Moreover, Lem-

2

1

mas F.1 and F.2 imply

γ12E gk 2 | xk ≤ 2Pk + 9δbγ12 xk − x∗ 2 + 6γ12bσ2 , Pk ≥ µ4γ1 xk − x∗ 2 + γ412 Eξ1k Fξ1k (xk) 2 − 6γ12bσ2 ,

(42) (43)

where Pk = γ1Eξk,ξk gk, xk − x∗ . Since γξk = γ2 = αγ1, we multiply (42) by α2 and (43) by α and get that 12
Assumption 2.1 holds with the parameters given in the statement of the theorem. Applying Theorem 2.1 we get the result.

Corollary F.1 (µ > 0; Corollary 4.1). Let Assumptions 1.1, 1.2, and 4.1 hold. Let µ > 0, γ2,k = αγ1,k, α = 1/4, and γ1,k = βkγ, where

γ = min

µb 18δ , 4µ +

1 6(L2 + 2δ/b)

and 0 < βk ≤ 1. Then, for all K ≥ 0 and {βk}k≥0 such that

if K ≤ 32 , γµ
if K > 32 and k < k0, γµ
if K > 32 and k ≥ k0, γµ

βk = 1,

βk = 1,

64

βk

=

64

+

γµ(k

−

, k0)

for k0 = K/2 we have

E xK − x∗ 2

1024 x0 − x∗ 2

γµK 69120σ2

≤

γµ

exp − 64 + µ2bK











δ L + δ/b

= Omax µ2b , µ

x0 −x∗ 2 exp−  max

K √
µδ2b , L+µ δ/b

 σ2  + µ2bK .

Proof. In Theorem F.1, we establish the following recurrence:

E xk+1 − x∗ 2

≤ α==1/4

αγµ 1 − βk 8 E

xk − x∗ 2 + 6α (α + 1) βk2γ2 σb2

γµ 1 − βk 32 E

xk − x∗ 2 + βk2 158σb 2 .

Applying Lemma C.1 for rk = E xk − x∗ 2 , γk = βk, a = γµ/32, c = 15σ2/8b, h = 1, we get the result.

Corollary F.2 (µ = 0). Let Assumptions 1.1, 1.2, and 4.1 hold. Let µ = 0, δ = 0, γ2 = αγ1, α = 1/4, and γ1 = γ = 1/√6L. Then, for all K ≥ 0 we have

1K K+1 E
k=0

√

F (xk) 2 ≤ 16 6L x0 − x∗ 2 + 30σ2 ,

K +1

b

and each iteration requires O(b) stochastic oracle calls.

Proof. Given the result of Theorem F.1, it remains to plug in α = 1/4.

Eduard Gorbunov, Hugo Berard, Gauthier Gidel, Nicolas Loizou
F.1 On the Assumptions in the Analysis of S-SEG and I-SEG
In this subsection, we provide clariﬁcations on why we use diﬀerent assumptions to analyze S-SEG and I-SEG. In particular, our analysis of S-SEG requires Lipschitzness and quasi-strong monotonicity of F (x, ξ) for all ξ (Assumptions 3.1, 3.2) and no assumptions on the variance of F (x, ξ), while for I-SEG we use bounded variance assumption (Assumption 4.1).
First of all, it is known that deterministic EG can be viewed as an approximation of the Proximal Point method (Martinet, 1970; Rockafellar, 1976) when F is L-Lipschitz, e.g., see Theorem 1 from (Mishchenko et al., 2020). In some sense, Lipschitzness of F is a crucial property for the convergence of EG. One iteration of S-SEG can be seen as a step of deterministic EG for the stochastic operator F (x, ξ). Therefore, it is natural that Lipschitzness of F (x, ξ) is important for the analysis of S-SEG. On the other side, I-SEG uses diﬀerent samples for extrapolation and update steps. Therefore, Lipschitzness of individual F (x, ξ) does not help here and we need to use something like Assumption 4.1 to handle the stochasticity of the method.

