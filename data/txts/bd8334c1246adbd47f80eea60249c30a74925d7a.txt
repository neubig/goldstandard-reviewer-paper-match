arXiv:1709.01566v1 [cs.NI] 5 Sep 2017

1
Asynchronous Stochastic Approximation Based Learning Algorithms for As-You-Go Deployment
of Wireless Relay Networks along a Line
Arpan Chattopadhyay, Avishek Ghosh, and Anurag Kumar
Abstract—We are motivated by the need, in emergency situations, for impromptu (or “as-you-go”) deployment of multihop wireless networks, by human agents or robots (e.g., unmanned aerial vehicles (UAVs)); the agent moves along a line, makes wireless link quality measurements at regular intervals, and makes on-line placement decisions using these measurements. As a ﬁrst step we have formulated such deployment along a line as a sequential decision problem. In our earlier work, reported in [1], we proposed two possible deployment approaches: (i) the pure as-you-go approach where the deployment agent can only move forward, and (ii) the explore-forward approach where the deployment agent explores a few successive steps and then selects the best relay placement location among them. The latter was shown to provide better performance (in terms of network cost, network performance and power expenditure), but at the expense of more measurements and deployment time, which makes explore-forward impractical for quick deployment by an energy constrained agent such as a UAV. Further, since in emergency situations the terrain would be unknown, the deployment algorithm should not require a-priori knowledge of the parameters of the wireless propagation model. In [1] we, therefore, developed learning algorithms for the explore-forward approach.
The current paper ﬁlls in an important gap by providing deploy-and-learn algorithms for the pure as-you-go approach. We formulate the sequential relay deployment problem as an average cost Markov decision process (MDP), which trades off among power consumption, link outage probabilities, and the number of relay nodes in the deployed network. While the pure as-you-go deployment problem was previously formulated as a discounted cost MDP (see [1]), the discounted cost MDP formulation was not amenable for learning algorithms that are proposed in this paper. In this paper, ﬁrst we show structural results for the optimal policy corresponding to the average cost MDP, and provide new insights into the optimal policy. Next, by exploiting the special structure of the average cost optimality equation and by using the theory of asynchronous stochastic approximation (in single and two timescale), we develop two learning algorithms that asymptotically converge to the set of optimal policies as deployment progresses. Numerical results show reasonably fast speed of convergence, and hence the model-free algorithms can be useful for practical, fast deployment of emergency wireless networks.
Index Terms—Wireless networks, impromptu network deployment, as-you-go relay placement, relay placement by UAV, Markov decision process, stochastic approximation.
!

1 INTRODUCTION
In emergency situations, such as ﬁres in large buildings or forests, or houses in a ﬂooded neighbourhood (without electric power and telecom infrastructure), there is a need to quickly deploy wireless networks for situation monitoring. Such networks could be deployed by ﬁrst responders (e.g., ﬁre-ﬁghters moving through a burning building [2]), or by robots (e.g., unmanned aerial vehicles (UAVs) hopping over the rooftops of ﬂooded homes or ﬂying over a long road [3], [4], [5]), or by forest guards
The research reported in this paper was supported by a Department of Electronics and Information Technology (DeitY, India) and NSF (USA) funded project on Wireless Sensor Networks for Protecting Wildlife and Humans, by an Indo-French Centre for Promotion of Advance Research (IFCPAR) funded project, and by the Department of Science and Technology (DST, India), via a J.C. Bose Fellowship. Arpan Chattopadhyay is with the Electrical Engineering department, University of Southern California, Los Angeles. Avishek Ghosh is with the EECS department, UC Berkeley. Anurag Kumar is with the Department of ECE, Indian Institute of Science (IISc), Bangalore. This work was done when Arpan Chattopadhyay and Avishek Ghosh were with the Department of ECE, IISc. Email: arpanc.ju@gmail.com, avishek.ghosh38@gmail.com, anurag@ece.iisc.ernet.in All appendices are provided in the supplementary material.

along forest trails ([1]).1 Typically, such networks would have one or more base-stations, where the command and control would reside, and to which the measurements from the sensors in the ﬁeld would need to be routed. For example, in the case of the ﬁre-ﬁghting example, the base-station would be in a control truck parked outside the building. Evidently, in such emergency situations, there is a need for “as-you-go” deployment algorithms as there is no time for network planning. As they move through the affected area, the ﬁrst-responders would need to deploy wireless relays, in order to provide routes for the wireless sensors for situation monitoring.
With the above motivation for quick deployment of multihop wireless networks, in our work, in the present and earlier papers ([1], [9], [10]), we have considered the particular situation of as-you-deployment of relays along
1. See [6] and [7, Section 5] for application of multihop wireless sensor networks in wildlife monitoring and forest ﬁre detection. [8] illustrates a future possibility where drones deploy high speed, solarpowered access points on the roofs of city buildings in order to provide high speed internet connection. The drone can land on the ground or on a rooftop for link quality measurements, and can again take off.

2

a line, starting from a base-station, in order to connect a source of data (e.g., a sensor) whose location is revealed (or is itself placed) only during the deployment process. Figure 1 depicts our model for as-you-go deployment along a line, and also illustrates the difference between planned deployment and as-you-go deployment. Asyou-go deployment along a line is motivated by the need for quick deployment of relay networks along long forest trails by humans or mobile robots, and relay network deployment along a long straight road by human agents or UAVs. In practice, the location of the data source would be a-priori unknown, as the deployment agent would also need to select locations at which to place the sensors. Yet, as the deployment agent traverses the line, he or she (or it) has to judiciously deploy wireless relays so as to end up with a viable network connecting the data source (e.g., the sensor) to the sink. In a planned approach, all possible links could be evaluated; in an as-you-go approach, however, the agent needs to make decisions based on whatever links can be evaluated as deployment progresses.
Motivated by the need for as-you-go deployment of wireless sensor networks (WSNs) over large terrains, such as forest trails, in our earlier work [1] we had considered the problem of multihop wireless network deployment along a line, where a single deployment agent starts from a sink node (e.g., a base-station), places relays as the agent walks along the line, and ﬁnally places a source node (e.g., a sensor) where required. We formulated this problem as a measurement based sequential decision problem with an appropriate additive cost over hops. In order to explore the range of possibilities, we considered two alternatives for measurement and deployment: (i) the explore-forward approach: after placing a node, the deployment agent explores several potential placement locations along the next line segment, and then decides on where to place the next node, and (ii) the pure as-you-go approach: the deployment agent only moves forward, making measurements and committing to deploying nodes as he goes.
As expected, in [1] we found that the explore-forward approach yields better performance (in terms of the additive per hop cost (see [1, Section V]); but, of course, this approach takes more time for the completion of deployment. Hence, explore-forward is prohibitive when soldiers or robots need to quickly deploy a relay network along a forest trail or along a long road. In addition, a deployment agent such as a UAV would be limited by its fuel, and it would be desirable to complete the mission as quickly as possible, without many fuel consuming manoeuvres. Thus, pure as-you-go is the only option for network deployment by UAVs along long roads (see [3] for practical network deployment along a road by a UAV). Further, in an emergency situation, the algorithm cannot expect to be given the parameters of the propagation environment; this gives rise to the need for deploy-and-learn algorithms.
In [1], although we introduced explore-forward and

Figure 1: A line network connecting a source (e.g., a sensor) to a sink (e.g., a control centre) via relay nodes. The dots in between (ﬁlled and unﬁlled) denote potential relay locations, and are spaced δ meters apart. The deployed network consists of three relays (dots labeled Relay 1, 2, and 3) placed at three potential locations. The solid arrows show the multi-hop path from the source to the sink. The unﬁlled dots represent locations where no relay was placed. The dotted arrows represent some other possible links between pairs of potential locations. In case of planned deployment, link qualities between all potential location pairs need to be measured. But, in as-you-go deployment, the agent only measures the qualities of link from his (or its) current location to the previously placed nodes.
pure as-you-go approaches, we developed learning algorithms for explore-forward alone. However, with the above motivation, our current paper ﬁlls in an important gap by proposing online learning algorithms for pure asyou-go deployment. We mathematically formulate the problem of pure as-you-go deployment along a line as an optimal sequential decision problem so as to minimize the expected average cost per step, where the cost of a deployment is a linear combination of the sum transmit power, the sum outage probability and the number of relays deployed. We formulate the problem as a Markov decision process (MDP) and obtain the optimal policy structure. Next, we propose two learning algorithms (based on asynchronous stochastic approximation) and prove their asymptotic convergence to the optimal policy for the long-run average cost minimization problem. Finally, we demonstrate the convergence rate of the learning algorithms via numerical exploration.
The new contributions of this paper, in relation to [1], are discussed in Section 1.2.
1.1 Related Work
Prior work on the problem of impromptu deployment of WSN consists of mostly heuristic algorithms validated by experimentation. For example, the authors of [11] address this problem by studying experimentally the variation in indoor link quality. The authors of [12] also took a similar approach. The authors of [13] provide heuristics for deploying (incrementally) sensors so that a certain area is covered (e.g., self-deployment of autonomous robot teams). Bao and Lee, in [14], address the problem of a group of ﬁrst responders starting from a base station (e.g., a command center) and placing relay nodes while walking through a region devoid of communication infrastructure, in order to stay connected among themselves as well as with the base station. Liu et al., in [2], describe a breadcrumbs system meant for ﬁreﬁghters operating inside a building; this paper is in similar spirit with ours, but their goal is just to maintain connection with k previously placed nodes. This work was later extended by them in [15] which provides a reliable

3

multiuser breadcrumbs system. However, all the above works are based on heuristic algorithms, rather than on rigorous formulations; hence they do not provide any provable performance guarantee. A nice survey on rapid deployment of post-disaster networks is available in [16]. Sensor network deployment by UAVs have also been studied in literature (see [4], [5]).
In our current paper, we have formulated as-yougo deployment as an MDP, found structural results for the optimal policy, and proposed learning algorithms to solve the sequential decision problems without using any prior knowledge of the radio propagation parameters. The use of MDP to formulate as-you-go deployment was ﬁrst proposed by Mondal et al. in [17]. This work was later extended by Sinha et al. in [18], where the authors have provided an algorithm derived from an MDP formulation, so as to create a multi-hop wireless relay network between a sink and a source located at an unknown location, by placing relay nodes along a random lattice path. However, these papers do not consider spatial variability of wireless link qualities due to shadowing, which allows them to develop deployment algorithms that place the next relay based on the distance from the previously placed relay.
The spatial variation of link qualities due to shadowing requires measurement-based deployment; here the deployment agent makes placement decision at a given location based on the link quality to the previously placed node. Measurement-based as-you-go deployment was formulated ﬁrst in [9], and was later extended in [1]. The authors of [1] have proposed two possible approaches for deployment along a line: (i) the pure asyou-go approach and (ii) the explore-forward approach. [1] has provided MDP formulations and policy structures for both approaches; transition probabilities of the MDPs depend on the radio propagation parameters in the environment, and, in practice, these parameters are not known to the agent prior to deployment. Hence, [1] also provides learning algorithms for the explore-forward approach, that converge asymptotically to the set of optimal deployment policies as more and more measurements are made in course of deployment. One of these learning algorithms was used for actual network deployment (see [1] and [10]). Design of a two-connected network to guard against node and link failures was discussed in [19], but it did not provide any learning algorithm.
We also developed, in [20], as-you-go deployment algorithms for deploying a multi-relay line network, so that the end-to-end achievable rate is maximized; but it was done for an information-theoretic, full-duplex, multi-relay channel model where the nodes carry out decode-and-forward relaying. However, devices with such sophisticated relaying capability is not yet available for full commercial use. On the other hand, our current paper designs deployment algorithms for networks carrying packetized data, which is common in present day wireless standards.

1.2 Contributions of this paper, in relation to [1]:
(i) New deploy-and-learn algorithms: Our current paper provides learning algorithms for the pure as-you-go approach (Algorithm 2 and Algorithm 3), whereas [1] provides learning algorithms only for explore-forward. The learning algorithms are required to discover the optimal deployment policy as deployment progresses, for the situation where no prior accurate knowledge on the statistical nature of radio propagation environment is available. Learning algorithms for pure as-you-go deployment is an important requirement since the pure asyou-go deployment approach is more suitable for very fast deployment over a large region. In fact, the number of measurements in explore-forward deployment can be double or triple than that of pure as-you-go ([1, Section V]) for practical deployment; this makes pure as-you-go a better choice for emergency network deployment by soldiers or commandos or energy-constrained autonomous agents such as robots and UAVs.
Unlike [1], the learning algorithms presented in this paper make use of asynchronous stochastic approximation, where different iterates are updated at different time instants (in the learning algorithms proposed in [1], all iterates are updated when a new relay is placed). We provide formal proof for the convergence of our proposed learning algorithms to the optimal deployment policy for pure as-you-go deployment; these proofs require a signiﬁcant and non-trivial novel mathematical analysis (compared to [1]) in order to address many technical issues that arise in the proofs.
In other words, the most important contributions of the current paper w.r.t. [1], are the newly proposed learning algorithms for pure as-you-go deployment and their convergence proofs, which are new to the literature and addresses the problem of very fast deployment.
Interestingly, one of the learning algorithms proposed in this paper exhibits a nice separation property between estimation and control, which is not present in the learning algorithms presented in [1].
(ii) Average cost MDP formulation: [1] formulates the pure-as-you deployment problem for a line having a random length L ∼ Geometric(θ) (mean is θ1 ), i.e., P(L = l) = (1 − θ)l−1θ where l ∈ {1, 2, · · · , ∞}; the average cost optimal policy is obtained by taking θ → 0. Clearly, this requires value iteration to compute the optimal policy prior to deployment. This also requires the knowledge of radio propagation parameters, since they determine the transition probabilities of the MDP. On the other hand, our present paper establishes the structure of the optimal policy by using the average cost optimality equation (see (5)) with necessary modiﬁcation; it turns out that such a formulation along with the special structure of the problem enables us to propose very simple learning algorithms to ﬁnd the optimal policy, irrespective of whether the radio propagation parameters are known apriori or not. Thus, the average cost MDP formulation is a precursor to the learning algorithms (Algorithm 2

4

and Algorithm 3) presented later in this paper. Some new interesting properties of the value functions and the policy structure are also proved in the current paper, which were not present in [1] because the problem was formulated as discounted cost MDP in [1].
(iii) Additional measurements to facilitate learning: The pure-as-you go approach considered in our current paper is not exactly the same as that described in [1]. In [1], the agent makes a link quality measurement from the current location to the immediate previous node that he had placed. On the contrary, in the pure as-yougo approach described in our present paper, the agent measures link qualities from the current location to all previously placed nodes that are located within a certain distance. This is done to facilitate learning the optimal policy. The exact reason behind using this variation of pure as-you-go deployment will be explained in Section 4.1.
(iv) Bidirectional trafﬁc: In Section 2.5, we explain how the deployment algorithms presented in this paper can be adapted to the case where each link in the network has to carry data packets in both directions.
1.3 Organization
The rest of the paper is organized as follows. The system model has been described in Section 2. MDP formulation for pure-as-you deployment has been provided in Section 3. The learning algorithms have been proposed in Section 4 and Section 5. Convergence speed of the learning algorithms are demonstrated numerically in Section 6, after which the conclusion follows. The proofs of all theorems are provided in the appendices available as supplementary material.
2 SYSTEM MODEL
In this section, we describe the system model assumed in this paper. It has to be noted that the system model and notation used in this paper are similar in many aspects to those of [1]; a signiﬁcant difference in the system model will be found in the deployment procedure as described in Section 2.2 (deployment process), and in Section 2.5 (bi-directional trafﬁc). The channel model (Section 2.1), trafﬁc model (Section 2.4) and deployment objective (Section 2.3) subsections are almost similar to the respective sections in [1]; but we describe the system model here in detail to make this paper self-contained.
We assume that the line (i.e., the road or the forest trail along which the network is deployed) is discretized into steps (starting from the sink), each having length δ. The points located at distances {kδ}k∈{1,2,3,··· } are called potential locations; the agent is allowed to place nodes only at these potential locations. As the single deployment agent walks along the line, at each potential location, the agent measures the link quality from the current location to the previously placed nodes that are within a certain distance from the current location; placement decisions are made based on these measurements.

After deployment, as shown in Figure 1, the sink is called Node 0, and the relays are enumerated as nodes {1, 2, 3, · · · } as we move away from the sink. A link whose transmitter is Node i and receiver is Node j is called link (i, j).

2.1 Wireless Channel Model

We consider a wireless channel model where, for a link (i.e., a transmitter-receiver pair) with length r and transmit power γ, the received power of a packet (say the k-th packet) is given by:

r −η Prcv,k = γc r0 HkW (1)

Here c is the path-loss at a reference distance r0, and η

is the path-loss exponent. The fading random variable

seen by the k-th packet is Hk (e.g., Hk is exponentially

distributed for Rayleigh fading); it takes independent

values over different coherent times. W denotes the

shadowing random variable that captures the (random)

spatial variation in path-loss. In this paper, W is assumed

to take values from a set W, and we denote by g(w) the

probability mass function or probability density function

of W , depending on whether W is countable or uncount-

able. We assume that the transmit power of each node

comes from a discrete set, S := {P1, P2, · · · , PM }, where

the power levels are arranged in ascending order.

Shadowing becomes spatially uncorrelated if the trans-

mitter or receiver is moved by a certain distance that

depends on the sizes of the scatterers in the environment

(see [21]). It was shown experimentally that, in a forest-

like environment, shadowing has log-normal distribution (i.e., log10 W ∼ N (0, σ2) where σ is the standard

deviation of log-normal shadowing) and the shadowing

decorrelation distance can be as small as 6 meters (see

[10]). In this paper, we assume that the step size δ is

chosen to be more than the shadowing decorrelation

distance; this allows us to assume that the shadowing at

any two different links in the network are independent.

The k-th packet is said to see an outage in the link

if Prcv,k ≤ Prcv−min, where Prcv−min is a threshold

depending on the modulation scheme and the properties

of the receiving node. For example, Prcv−min can be

chosen to be −88 dBm for the TelosB “motes” (see

[22]), and −97 dBm for iWiSe motes (see [23]). For a

link with length r, transmit power γ and shadowing

realization W = w, the outage probability is denoted

by Qout(r, γ, w); it is increasing in r and decreasing in γ,

w. Qout(r, γ, w) = P(Prcv,k ≤ Prcv−min) depends on the

fading statistics; if H is exponentially distributed with

mean 1 (i.e., for Rayleigh fading), then Qout(r, γ, w) =

Prcv−min

(

r r

)η

r )−ηwH ≤ Prcv−min) = 1 − e−

0

γcw

. The

P(γc( r0

outage probability of a randomly chosen link (with given

r and γ) is a random variable, with the randomness

coming from shadowing W . Outage probability can be

measured by sending a large number of packets over a

5

link and calculating the fraction of packets with received power less than Prcv−min.

2.2 Pure As-You-Go Deployment Process

After placing a relay, the agent starts measuring the link qualities from the next B locations one by one (the value of B is ﬁxed prior to deployment). At any given location, the agent uses the measurements from the current location to make a placement decision; the agent does not make measurements from all of those B locations in order to place a new relay.
At any given location, the agent measures the link qualities from the given location to all previously placed nodes that are within Bδ distance from the current location; see Figure 2. Let us assume that the agent is standing at a distance kδ from the sink. Let Ik := {r ∈ {1, 2, · · · , B} : a relay was placed at a distance (k − r)δ from the sink}}. Then, the agent at this location will measure the outage probabilities {Qout(r, γ, wr)}γ∈S,r∈Ik (wr is the realization of shadowing in a link of length r steps).
However, at each location, only the link quality to the immediately previous node is used to decide whether to place a relay there or to move on to the next step. If the decision is to place a relay, then the agent also decides which transmit power γ ∈ S to use at that particular node. If the decision is not to place a relay, the agent moves to the next step. In this process, if he reaches B steps away from the previous relay, or if the source location is encountered, then he must place a node there.
It is important to note that, while the measurement to the immediately previous node is used to make a placement decision, other measurements made in this process provide useful information about the statistical characteristics of the radio propagation environment (more precisely, the probability distribution of Qout(r, γ, ·) for r ∈ {1, 2, · · · , B}, γ ∈ S), and those measurements are used to learn the optimal deployment policy as described in Section 4 and Section 5. But if the radio propagation parameters (such as η and σ) are exactly known, i.e., if the probability distribution of Qout(r, γ, ·) is known exactly, then these additional measurements will not be required (since shadowing is i.i.d. across links, these measurements will not provide any information about the link quality between the current location and the immediately previous node); this situation has been explored in Section 3, where measurement is made only to the previously placed relay node.
Choice of B: In general, the choice of B depends on the constraints and requirements for the deployment. Large B results in better performance at the expense of more measurements. One can simply choose B to be the largest integer such that, the probability that a randomly chosen wireless link with length Bδ respects a certain outage constraint, is larger than some prespeciﬁed target. This will make sure that the probability of obtaining a workable link is small in case the agent

Figure 2: Illustration of pure as-you-go deployment with learning for B = 4. Here the deployment agent has already placed Relay 1 and Relay 2, and the corresponding inter-relay distances are U1 and U2. The placed relays use transmit powers Γ1 and Γ2, thereby achieving outage probabilities Q(o1u,t0) and Q(o2u,t1) (in the links shown by solid arrows). After placing Relay 2, the agent measured the link qualities from the next location to the sink, Relay 1 and Relay 2 (since B = 4) and the algorithm advised him not to place a node there. Then the deployment agent moved to the next location (which is at a distance of 2δ from Relay 2) and measured the link qualities to Relay 1 and Relay 2 (but not to the sink since B = 4). In this snap-shot of the deployment process, the agent is evaluating the next location at r = 3δ distance from Relay 2 (see the dotted arrows). Since B = 4, the agent measures the link qualities from the current location to both Relay 1 and Relay 2; this corresponds to I6 = {3, 4} (see Section 2.2 for the deﬁnition of I6), since the distances to Relay 2 and Relay 1 from the current location are 3δ and 4δ respectively. Based on these measurements, the deployment agent will decide whether to place a relay at r = 3δ or not, and the transmit power of the node in case the decision is to place; if the decision is not to place a relay here, then a relay must be placed at the next location (since B = 4), and the agent would be at a distance of Bδ from the last placed relay (i.e., Relay 2).
reaches a location that is more than Bδ distance away from the previously placed node.
2.3 Network Cost Minimization Objective
We ﬁrst deﬁne the cost that we use to evaluate the performance of any deployment policy. A deployment policy π takes as input the distance of the current location of the agent from the previous relay and the link quality to the previously placed node, and provides the placement decision for that location and transmit power (if the decision is to place a relay) as output.
We denote the number of relays placed up to x steps from the sink by Nx, and let us deﬁne N0 = 0. Since deployment decisions are based on measurements of (random) outage probabilities, {Nx}x≥1 is a random process.
After the deployment is over, let us denote by Γi the transmit power used by node i, and by Q(oiu,it−1) the outage probability over the link (i, i − 1) (see Figure 2). Note that, Γi and Q(oiu,it−1) are random variables since shadowing between various potential location pairs are random variables, whose exact realization is known only after measurement. Given the measurement values (i.e., the information available to the deployment agent) and the deployment policy, one can ﬁnd the exact realizations of Γi and Qo(iu,it−1).
The expected cost of the deployed network up to xδ

6

distance is given by a sum of hop costs as follows:

Nx

Nx

Eπ( Γi + ξout Q(oiu,it−1) + ξrelayNx)

(2)

i=1

i=1

which is the expectation (under policy π) of a linear

combination of the sum power

Nx i=1

Γi,

the

sum

outage

Nx i=1

Q(oiu,it−1),

and

the

number

of

relays

Nx.

For

small

outage probabilities, the sum-outage

Nx i=1

Qo(iu,it−1)

is

approximately equal to the probability that a packet sent

from the point x to the sink encounters an outage along

the path (see also Section 2.4 for a better understanding

of the outage cost in light of the trafﬁc model). The sum

power

Nx i=1

Γi

is

proportional

to

the

battery

depletion

rate in the network, in case wake-on radios are used (see

[1, Section II] for a detailed discussion).

The multipliers ξout ≥ 0 and ξrelay ≥ 0 capture the

emphasis we place on

Nx i=1

Q(oiu,it−1)

or

Nx.

A

large

value

of ξout will aim for deployment with smaller end-to-

end expected outage. ξrelay can be viewed as the cost

of placing a relay.

Since the distance L to the source from the sink is

not known prior to deployment, we simply assume that

L = ∞. This assumption is practical when the distance

of the source from the sink is large (e.g., deployment

along a long forest trail). L = ∞ is also equivalent to

the scenario where deployment is done serially along

multiple trails in a forest, provided that the radio prop-

agation environment in various trails are statistically

identical; we deploy serially along multiple lines but use

this formulation to minimize the per-step cost averaged

over all the lines.

Next, we deﬁne the optimization problems that we

seek to address in this paper.

2.3.1 The Unconstrained Problem We seek to solve the following problem:

inf lim sup Eπ Ni=x1(Γi + ξoutQ(oiu,it−1) + ξrelay ) (3)

π∈Π x→∞

x

where Π is the set of all possible placement policies. We formulate (3) as an average cost MDP.

2.3.2 The Constrained Problem
(3) is the relaxed version of the following constrained problem:

inf lim sup Eπ
π∈Π x→∞

Nx i=1

Γi

x

s.t. lim sup Eπ Ni=x1 Q(oiu,it−1) ≤ q,

x→∞

x

and lim sup EπNx ≤ N (4) x→∞ x

Here we seek to minimize the mean power per step subject to constraints on the mean outage per step and the mean number of relays per step.
It turns out that (3) is the relaxed version of the constrained problem (4), with ξout and ξrelay as the Lagrange

multipliers. The constrained problem can be solved by solving the unconstrained problem, under proper choice of the Lagrange multipliers. The following theorem tells us how to choose the Lagrange multipliers ξout and ξrelay (see [24], Theorem 4.3):
Theorem 1: For the constrained problem (4), if there exists a pair ξo∗ut ≥ 0, ξr∗elay ≥ 0 and a policy π∗ such that π∗ is the optimal policy of the unconstrained problem (3) under (ξo∗ut, ξr∗elay), and if the constraints in (4) are met with equality under the policy π∗, then π∗ is an optimal policy for the constrained problem (4) as well.
2.4 Trafﬁc Model
Motivated by our prior work reported in [17], [18], [9], [1], we assume that the trafﬁc in the network is so light that there is only one packet in the network at a time; this model is called the “lone packet model” (or the zero trafﬁc model). This model results in collision-free transmissions, since there are no simultaneous transmissions in the network. As a result, we can easily write down the communication cost in the line network as a sum of hop costs (Section 2.3).
It has been formally shown that network design under the lone packet model may be necessary for designing a network with positive trafﬁc carrying capability (see [25, Section II]). We can easily adapt the result of [25, Section II] to show that, for a ﬁnite line network, if a target end-to-end packet delivery probability has to be achieved under positive trafﬁc, then it is necessary to achieve that target under lone packet trafﬁc. Now, the end-to-end packet error rate under lone packet trafﬁc is approximately equal to the sum outage; this justiﬁes the sum outage cost in (3) and the outage constraint in (4). Network design for a given positive trafﬁc rate is left for future research.
In a line network, if interference-free communication is achieved via multi-channel access and frequency reuse after several hops, then the trafﬁc model essentially becomes lone packet. There have been recent efforts to use multiple channels available in 802.15.4 radio in WSN; see [26], [27], [28], [29].
The lone packet trafﬁc model is realistic for WSNs carrying low duty cycle measurements, or just an occasional alarm packet. For example, recently developed passive infra-red (PIR) sensor platforms can detect and classify human or animal intrusion ([30]); such sensors deployed in a forest generate very low data. The paper [6, Section 3.2] uses 1.1% duty cycle for a multi-hop WSN for wildlife monitoring; the sensors gather data from RFID collars tied the animals, and generate light trafﬁc. Very light trafﬁc model is also realistic for condition monitoring/industrial telemetry applications ([31]), where infrequent measurements are taken. Very light trafﬁc model is also common in machine-to-machine communication ([32]). The paper [33, Table 1, Table 3] illustrate sensors with small sampling rate and sampled data size; it shows several bytes per second data rate requirement for habitat monitoring.

7

We assume that data packets traverse the network in a hop-by-hop fashion, without skipping any intermediate relay. Later we will explain in Section 3.4 why we do not consider the possibility of relay skipping in this paper; the reason is increased computational complexity without a very signiﬁcant gain in network performance.
2.5 Extension to Bi-Directional Trafﬁc Flow
Let us consider the situation where the trafﬁc is still lone packet, but a packet can ﬂow towards either direction along the line network with equal probabilities. In such cases, one can deﬁne the cost of link (i, i − 1) as Γi,forward + Γi−1,reverse + ξoutQ(oiu,it−1,forward) + ξoutQ(oiu−t1,i,reverse) + ξrelay, where Γi,forward is the transmit power used from node i to node (i − 1), and Γi−1,reverse is the transmit power used from node (i − 1) to node i. Similar meanings apply for the outage probabilities Q(oiu,it−1,forward) and Q(oiu−t1,i,reverse), under transmit power levels Γi,forward and Γi−1,reverse, respectively. It has to be noted that the shadowing between two potential locations in forward and reverse directions, Wforward and Wreverse, may not necessarily be independent. But the shadowing random variable pair (Wforward, Wreverse) ∈ R2+ between two potential locations have a joint distribution, and this pair assumes independent and identically distributed (i.i.d.) value in R2+ if either the transmitter or the receiver is moved beyond the shadowing decorrelation distance (which is smaller than the step size δ). Hence, with this new link cost, our formulation (3) can easily be adapted to deploy a network carrying bi-directional trafﬁc. In the process of deployment, the agent has to measure link qualities in both forward and reverse directions in such situation. The action at each step is to decide whether to place a relay; if the decision is to place a relay, then the agent also decides the transmit power levels used in that link along the forward and the reverse directions.
Since the design for bi-directional trafﬁc carrying network is mathematically equivalent to the design for unidirectional trafﬁc carrying network, we will consider only unidirectional trafﬁc for the rest of this paper.
3 FORMULATION FOR KNOWN PROPAGATION
PARAMETERS
Throughout this section, we will assume that we seek to solve the unconstrained problem given in (3), and that the radio propagation parameters (such as η and the standard deviation σ for log-normal shadowing) are known prior to deployment. We formulate the problem as an average cost MDP, and develop a threshold policy for deployment. In the process, we also discover some interesting properties of the value function, which do not follow from the discounted cost formulation.
Note that, we assume throughout this section that measurement only to the immediately previous node is used to make a placement decision at any given location. Measurement to more than one previous nodes will be used later in order to develop the learning algorithms.

3.1 Markov Decision Process (MDP) Formulation
When the deployment agent is r steps away from the previous node (r ∈ {1, 2, · · · , B}), the agent measures the outage probabilities {Qout(r, γ, w)}γ∈S on the link from the current location to the previous node,2 where w is the realization of shadowing in that link. Then the algorithm decides whether to place a relay there, and also the transmit power γ ∈ S in case it decides to place a relay. We formulate the problem as an average cost MDP with state space {1, 2, · · · , B} × W, where a typical state is of the form (r, w), 1 ≤ r ≤ B, w ∈ W. If r ≤ B −1, the action is either to place a relay and select a transmit power, or not to place. If r = B, the only feasible action is to place and select a transmit power γ ∈ S. If a relay is placed at state (r, w) and if a transmit power γ is chosen for it, then a hop-cost of γ + ξoutQout(r, γ, w) + ξrelay is incurred.3
A deterministic Markov policy π is a sequence of mappings {µk}k≥1 from the state space to the action space. The policy π is called a stationary policy if µk = µ for all k. Given the state (i.e., the measurements), the policy provides the placement decision.

3.2 Optimal Policy Based on Average Cost Optimality Equation
We will ﬁrst derive the structure of an optimal policy based on the average cost optimality equation (ACOE). Let λ∗ (or λ∗(ξout, ξrelay)) be the optimal average cost per step for the unconstrained problem (3) under the pure as-you-go deployment approach, and let v∗(r, w) be the differential cost for the state (r, w), where 1 ≤ r ≤ B and w ∈ W. The average cost optimality equation for our MDP is as follows (by the theory of [34, Chapter 4], for the case of ﬁnite W, and by the theory developed in [35, Chapter 5], when W is a Borel subset of the real line):

v∗(r, w) = min min(γ + ξoutQout(r, γ, w)) + ξrelay − λ∗
γ∈S

+ g(w )v∗(1, w ), −λ∗ + g(w )v∗(r + 1, w )

w

w

∀1 ≤ r ≤ B − 1

v∗(B, w) = min(γ + ξoutQout(B, γ, w)) + ξrelay − λ∗
γ∈S

+ g(w )v∗(1, w )

(5)

w

where g(w) was deﬁned (in Section 2.1) to be the probability mass function or probability density function of shadowing W .
The ACOE (5) can be explained as follows. When the state is (r, w), the deployment agent can either place or may not place a relay. If he places a relay, he will incur a stage cost of minγ∈S (γ + ξoutQout(r, γ, w)) + ξrelay and

2. Note that, for the time being, we will ignore the measurements made to other nodes from the set Ik.
3. We have taken (r, w) as a typical state for the sake of simplicity in representation; for the channel model given by (1), we can also take (r, {Qout(r, γ, w)}γ∈S ) as a typical state, since the cost of an action depends on the state (r, w) only via the outage probabilities.

8

the next (random) state is (1, W ), where W has p.m.f. or p.d.f. g(w ). If he does not place, then he incurs 0 cost at that step and the next state is (r + 1, W ). When at state (B, w), he can only place a relay and incur a cost of minγ∈S (γ+ξoutQout(B, γ, w))+ξrelay at that stage and the next (random) state is (1, W ). Note that, minγ∈S appears in the single-stage cost because choice of transmit power of the placed node is also a part of the action, and a transmit power is chosen so that the single-stage cost for a placed relay is minimized.
Note that, by multiplying both sides of (5) with g(w) and taking summation over w, we obtain the following:
V (r) = EW min min(γ + ξoutQout(r, γ, W )) + ξrelay − λ∗
γ∈S
+V (1), −λ∗ + V (r + 1) ∀1 ≤ r ≤ B − 1
V (B) = EW min(γ + ξoutQout(B, γ, W )) + ξrelay − λ∗ + V (1)
γ∈S
(6)
where V (r) = w g(w)v∗(r, w)∀1 ≤ r ≤ B. Now, it is easy to see that if any V (·) satisﬁes (6), then V (·) + c for any constant number c also satisﬁes (6). Hence, we can put V (1) = λ∗ in (6) and obtain:

V (r) = EW min min(γ + ξoutQout(r, γ, W )) + ξrelay,
γ∈S

V (r + 1) − V (1) ∀1 ≤ r ≤ B − 1

V (B) = EW min(γ + ξoutQout(B, γ, W )) + ξrelay

(7)

γ∈S

Remark: Let c(r, W ) := minγ∈S (γ + ξoutQout(r, γ, W )) + ξrelay be the (random) cost incurred if we place a relay at a distance r from the previous relay. (7) shows the criteria for optimality to be V (r) = EW min{c(r, W ), V (r + 1) − V (1)} for r ≤ B − 1 and V (B) = EW c(B, W ). We will see in Algorithm 1 that, by solving this system of (nonlinear) equations, one can ﬁnd the optimal policy; there is no need to compute the differential cost for each state explicitly. Also, (7) will be particularly useful when we develop online deploy-and-learn algorithms in later sections, using the theory of stochastic approximation.
Theorem 2: There exists a unique vector V ∗ = [V ∗(1), V ∗(2), · · · , V ∗(B)]T satisfying (7). Also, V ∗(r) ≥ rV ∗(1) for all r ∈ {1, 2, · · · , B−1} and V ∗(r) is increasing in r.
Proof: See Appendix A.

3.2.1 Policy Structure
Algorithm 1 speciﬁes the optimal decision when the agent is r steps away from the previously placed node and the shadowing realization from the current location to the previously placed node is w.
Theorem 3: The policy given by Algorithm 1 is optimal for the unconstrained problem in (3). The threshold cth(r) is increasing in r.
Proof: From (5), the optimal policy is to place a relay at state (r, w) if the cost of placing is less than the cost of not placing. Hence, the policy structure follows from

Input: ξout, ξrelay, V ∗. Output: Placement decision at each step. Pre-compute: The threshold values cth(r) := V ∗(r + 1) − V ∗(1) for all 1 ≤ r ≤ B − 1. Initialization: r = 1 (distance from the previous node) while 1 ≤ r ≤ B do
Measure Qout(r, γ, w)∀γ ∈ S; if r ≤ B − 1 and
minγ∈S (γ + ξoutQout(r, γ, w)) + ξrelay ≤ cth(r) then
Place a new relay and use transmit power arg minγ∈S (γ + ξoutQout(r, γ, w)); Move to next step and set r = 1; else if r ≤ B − 1 and
minγ∈S (γ + ξoutQout(r, γ, w)) + ξrelay > cth(r) then
Do not place a relay and move to next step; r = r + 1; else Place a new relay (since r = B); Use transmit power arg minγ∈S (γ + ξoutQout(B, γ, w)); Move to next step; Set r = 1. end
end Algorithm 1: OptAsYouGo Algorithm

equations (5), (6) and (7). cth(r) is increasing in r since V ∗(r + 1) is increasing in r.
We denote the optimal policy given by Algorithm 1 by π∗(ξout, ξrelay).

3.3 Some properties of the optimal cost

Let us consider a sub-class of stationary deployment

policies (parameterized by V , ξout ≥ 0 and ξrelay ≥ 0) where V ∗(·) in Algorithm 1 is replaced by any vector

V . Under this sub-class of policies, let us denote by (Uk, Γk, Q(oku,tk−1)), k ≥ 1, the sequence of inter-node

distances, transmit powers and link outage probabilities

(see Figure 2). Since shadowing is i.i.d. across links, the

deployment process probabilistically restarts after each relay placement. Hence, (Uk, Γk, Qo(ku,tk−1)), k ≥ 1, is an

i.i.d. sequence. Let Γ(V , ξout, ξrelay), Qout(V , ξout, ξrelay)

and U (V , ξout, ξrelay) denote the mean power per link,

mean outage per link and mean placement distance

(in steps) respectively, under this sub-class of poli-

∗

∗

cies. We denote by Γ (ξout, ξrelay), Qout(ξout, ξrelay) and

∗

U (ξout, ξrelay) the optimal mean power per link, the

optimal mean outage per link and the optimal mean

placement distance (in steps) respectively, under Algorithm 1, where V ∗ is used instead of any general V .

Now, the optimal mean power per step, the optimal

mean outage per step, and the optimal mean number of

relays per step are given by

Γ∗ (ξout ,ξrelay
∗

)

,

Q∗out(ξout,ξrelay )
∗

U (ξout,ξrelay ) U (ξout,ξrelay )

and U∗(ξout1,ξrelay) (by the Renewal-Reward theorem).

9

Theorem 4: The optimal average cost per step for problem (3), λ∗(ξout, ξrelay), is concave, increasing and Lips-

chitz continuous in ξout ≥ 0, ξrelay ≥ 0.

Proof: See Appendix A. Theorem 5: V ∗ = (V ∗(1), V ∗(2), · · · , V ∗(B)) is Lips-

chitz continuous in (ξout, ξrelay).

Proof: See Appendix A.

Theorem 6: For a given ξout, the mean number of relays

per step under Algorithm 1, U∗(ξout1,ξrelay) , decreases

with ξrelay. Similarly, for a given ξrelay, the optimal mean

outage

per

step,

Q∗out
∗

(ξout

,ξr

elay

)

,

decreases

with

ξout.

U (ξout,ξrelay )

Proof: The proof is exactly same as the proof of [1,

Theorem 5].

3.4 A note on the objective function in (3)

Even though the deployment policy developed in this

section uses only the measurements made to the im-

mediately previous placed node in order to make a

placement location, we will see in subsequent sections

that measurements to all placed relay nodes located

within B steps from the current location of the agent will

be used for on-line learning of the optimal deployment

policy. A question that naturally arises is whether we

can do better with the additional measurements (when

the propagation parameters are known and the optimal

policy can be computed prior to deployment); this might

require skipping some already placed relay nodes after

the deployment is over. The possibility of relay skipping

was considered in [9]; in the current paper, we brieﬂy

describe a similar formulation in our context and explain

why we rule out the possibility of relay skipping.

Let us consider deployment up to x steps. After the

deployment is over, we construct a directed acyclic graph

over the deployed nodes (including the sink) as follows.

Links are all directed edges from each node to every

node with smaller index and located within a distance

of B steps. Hence, if i and j are two nodes with i > j

and

i k=j+1

Uk

≤

B,

there

is

a

link

(i,

j)

between

them.

Consider all directed acyclic paths from node Nx to the

sink over this graph. Let us denote by p any arbitrary

directed acyclic path, and by E(p) the set of (directed)

links of the path p. We also deﬁne Px := {p : (i, j) ∈

E(p) =⇒ Nx ≥ i > j ≥ 0,

i k=j+1

Uk

≤

B}.

Let

us

denote a generic link (edge) on this graph by e, and the

transmit power and outage probability on edge e by Γ(e) and Q(oeu)t.

Let us consider the following problem:

p, and minp∈Px e∈E(p) Γ(e) + ξoutQ(oeu)t the length of
the shortest path. Formulation of problem (8) as an MDP will require
as the typical state the distance of all nodes located within B steps from the current location, the realization of shadowing to all these nodes (through the measured outage probabilities), and the lengths of the shortest paths from all these nodes to the sink. A similar situation was considered in [9]. It turns out that the state space becomes very large (the number of all possible lengths of shortest paths grows to ∞ as x → ∞, even when the set W of possible values of shadowing is ﬁnite), and the policy computation becomes numerically intensive; but the numerical results of [9] show that the margin of performance improvement achieved via this formulation (instead of the formulation used earlier in this section) is not signiﬁcant. Hence, in this paper, we only consider formulation (3) and proceed with it.
4 OPTASYOUGOLEARNING: LEARNING WITH DEPLOYMENT FOR GIVEN MULTIPLIERS
Note that, for any given values of ξout and ξrelay, the optimal policy given by Algorithm 1 can be completely speciﬁed by the vector V ∗. But, the computation of V ∗ requires the agent to solve a system of nonlinear equations (which is computationally intensive), and these nonlinear equations can be speciﬁed only when the channel model parameters (e.g., path-loss exponent η and standard deviation σ for log-normal shadowing) are known apriori. However, in practice, these parameters may not be available prior to deployment. Under this situation, the deployment agent has to learn the optimal policy as deployment progresses, and use the corresponding updated policy at each step to make a placement decision. In order to address this requirement, we propose an algorithm which will maintain a running estimate of V ∗, and update this estimate at each step (using new measurements made at each step). Using the theory of Asynchronous Stochastic Approximation (see [36]), we show that, as the number of deployed relays goes to inﬁnity, the running estimate converges to V ∗ almost surely. From (7) (and the notation deﬁned immediately after (7)), we see that the optimal V ∗ is the unique real zero of the system of equations: EW min{c(r, W ), V (r +1)−V (1)}−V (r) = 0 for r ≤ B −1 and EW c(B, W ) − V (B) = 0. We use asynchronous stochastic approximation so that the iterates {V (k)}k≥0 converge asymptotically to this unique zero.

min lim sup

π∈Π

x→∞

Eπ minp∈Px

e∈E (p)

Γ(e) + ξoutQo(eu)t x

+ ξrelay Nx (8)

We call e∈E(p) Γ(e) + ξoutQ(oeu)t the length of the path

4.1 OptAsYouGoLearning Algorithm
Suppose that the deployment agent is standing k steps away from the sink node. At the kth step, the agent makes a placement decision and then performs a learning operation. Let us recall the deployment process (see Section 2.2 and Figure 2) and notation: Ik := {r ∈ {1, 2, · · · , B} :

10

a relay was placed at a distance (k − r)δ from the sink}}.

For the learning operation, Ik ⊂ {1, · · · , B} denotes

the set of the values of r for which links from the

current location to the placed relay r steps backwards

are measured, and for which V (r) is updated, when

the agent is at a distance kδ from the sink. Clearly,

for each k ≥ 1, Ik is a random set. Let us denote by V (k) the estimate of V ∗ after an update (i.e., a learning

operation) is made at the k-th step from the sink. At

step k (after a placement decision is made), V (k−1)(r)

for r ∈ Ik is updated to V k(r), and it is not updated

for r ∈/ Ik (which means that V (k)(r) = V (k−1)(r) for

r ∈/ Ik). Let us deﬁne ν(r, k) :=

k i=1

I{r

∈

Ii}

the

number of times the estimate of V ∗(r) is updated up to

the k-th step.

Note that, Algorithm 1 requires the agent to measure

link quality only to the previous node, whereas the

learning algorithm presented in this section involves link

quality measurement to more than one previous nodes

(unlike our prior paper [1]). This is necessary because, if

we make measurement only to last relay, then, depending on the initial estimate V (0), there could arise a situation

that the inter-relay distance never equals to B steps in the entire deployment process, which implies that V (0)(B) will

never be updated, thereby converging to an unintended policy.

Making measurements to all previously placed nodes located

at distance less than Bδ from the current location ensures that

lim infk→∞

ν(r,k) k

>

0

almost

surely,

which

is

required

for

the

convergence proof.

The OptAsYouGoLearning algorithm is provided in

Algorithm 2.

Theorem 7: Under Algorithm 2, V (k)(r) → V ∗(r) al-

most surely for all 1 ≤ r ≤ B.

Proof: See Appendix B.

Discussion of Algorithm 2:

(i) The basic idea: From (7) (and the notation deﬁned immediately after (7)), we see that the optimal V ∗ is the unique real zero of the system of equations: EW min{c(r, W ), V (r + 1) − V (1)} − V (r) = 0 for r ≤ B − 1 and EW c(B, W ) − V (B) = 0. We use asynchronous stochastic approximation so that the iterates converge asymptotically to this unique zero.
(ii) Asynchronous stochastic approximation: In standard stochastic approximation techniques, all iterates are updated at the same time. However, the pure asyou-go deployment scheme does not allow the deployment agent to update all iterates at each step. Since only a subset Ik ⊂ {1, · · · , B} of iterates can be updated at step k, we have to use asynchronous stochastic approximation.
(iii) The proof of Theorem 7 exhibits a nice separation between the estimation and control. In other words, the iterates will asymptotically converge to V ∗ (and the policy will converge to the optimal policy) even when the placement decisions are not made according to the proposed threshold policy (but the measurement and update scheme should

Input: ξout, ξrelay, and a decreasing positive

sequence {a(n)}n≥1 such that

∞ n=1

a(n)

=

∞,

∞ n=1

a2(n)

<

∞.

Output: Placement decision at each step.

Initialization: r = 1 (distance from the previous

node), k = 1 (distance of the current location from the sink), initial estimate V (0).

while 1 ≤ r ≤ B do

Find Ik := {r ∈ {1, 2, · · · , B} :

relay placement at (k − r)δ distance from sink}};

Find ν(r, k) :=

k i=1

I{r

∈

Ii}∀r

∈

{1,

2,

·

·

·

,

B}

;

Measure Qout(r, γ, wr)∀γ ∈ S, r ∈ Ik;

if r ≤ B − 1 and

minγ∈S (γ + ξoutQout(r , γ, wr )) + ξrelay ≤

−V (k−1)(1) + V (k−1)(r + 1) then

Place a new relay and use transmit power

arg minγ∈S (γ + ξoutQout(r , γ, wr ));

Do the following updates:

V (k)(r)
= V (k−1)(r) + a(ν(r, k))I{r ∈ Ik} min min(γ + γ
ξoutQout(r, γ, wr)) + ξrelay, −V (k−1)(1)
+V (k−1)(r + 1) − V (k−1)(r) , ∀1 ≤ r ≤ B − 1
V (k)(B)
= V (k−1)(B) + a(ν(B, k))I{B ∈ Ik} min(γ + γ
ξoutQout(B, γ, wB )) + ξrelay − V (k−1)(B) (9)
Move to next step and set r = 1; else if r ≤ B − 1 and
minγ∈S (γ + ξoutQout(r , γ, wr )) + ξrelay > −V (k−1)(1) + V (k−1)(r + 1) then
Do not place, do the same updates as (9); Move to next step and do r = r + 1; else Place a new relay (since r = B); Use transmit power arg minγ∈S (γ + ξoutQout(B, γ, wB)); Do the same updates as (9); Move to next step and set r = 1. end k=k+1; end Algorithm 2: OptAsYouGoLearning Algorithm

be unchanged); but it may not yield the optimal cost for problem (3) since we do not use the optimal policy at each stage. However, this nice separation property will not hold in next section when we vary ξout and ξrelay in order to solve the constrained problem (4). (iv) Note that, since the state space of the MDP in Section 3 is large (potentially inﬁnite and even uncountable), it will not be easy to use traditional Q-learning

11

algorithms. In fact, all the state action-pairs in a Qlearning algorithm need to repeat comparably often over inﬁnite time horizon to guarantee the desired convergence, but this may not happen in case of inﬁnite state space (arising out of inﬁnite W). On the other hand, Algorithm 2 provides a learning algorithm with provable convergence guarantee while having only B number of iterates.

5 OPTASYOUGOADAPTIVELEARNING THE CONSTRAINED PROBLEM

FOR

In Section 4, we provided a deploy-and-learn algorithm
for given ξout and ξrelay. However, Theorem 1 tells us
how to choose the Lagrange multipliers ξout and ξrelay
(if they exist) in (3) in order to solve the constrained
problem (4). But we need to know the radio propagation
parameters (e.g., η and σ) in order to compute a pair (ξo∗ut, ξr∗elay) that satisﬁes the condition given in Theorem 1. In practice, these parameters may not be known.
Hence, we provide a sequential placement algorithm
such that, as deployment progresses, the placement
policy (updated at each step) converges to the set of
optimal policies for the constrained problem (4). We
modify the OptAsYouGoLearning algorithm so that a running estimate (V (k), ξo(ku)t, ξr(kel)ay) gets updated at each step, and asymptotically converges to the set of optimal (V ∗(ξout, ξrelay), ξout, ξrelay) tuples. This algorithm is
based on two time-scale stochastic approximation (see
[37, Chapter 6]).

5.1 Some Useful Notation and Assumptions
In this subsection, we will introduce some assumptions and notation (these were provided in [1, Section VII], but are repeated here for completeness).
Deﬁnition 1: We denote by γ∗ the optimal mean power per step for problem (4), for a given constraint pair (q, N ). The set K(q, N ) is deﬁned as follows:

K(q, N ) := (V ∗(ξout, ξrelay ), ξout, ξrelay ) :

Γ∗(ξout, ξrelay )

∗ Q∗out(ξout, ξrelay )

∗

=γ , ∗

≤q

U (ξout, ξrelay )

U (ξout, ξrelay )

1

∗

≤ N , ξout ≥ 0, ξrelay ≥ 0

U (ξout, ξrelay )

Note that, the pair (q, N ) can be infeasible. For exam-

ple,

if

N

=

1 B

(i.e.,

inter-node

distance

is

B)

and

q

<

EW Qout(B,PM ,W ) B

(PM

is

the

maximum

available

transmit

power), the outage constraint cannot be satisﬁed while

meeting the constraint on the mean number of relays per

step, even by using the maximum transmit power PM .

K(q, N ) is empty if (q, N ) is infeasible. In this paper, we

assume that K(q, N ) is non-empty (i.e., (q, N ) is a feasible

pair), which is true for feasible pairs of K(q, N ):

Assumption 1: q and N are such that there exists

at least one pair ξo∗ut ≥ 0, ξr∗elay ≥ (V ∗(ξo∗ut, ξr∗elay), ξo∗ut, ξr∗elay) ∈ K(q, N ).

0 such that

Assumption 2: The probability density function (p.d.f.)

of the shadowing random variable W is continuous over

(0, ∞); i.e., P(W = w) = 0 for any w ∈ (0, ∞) (e.g., log-

normal shadowing).

Theorem 8: Under Assumption 2 and Algorithm 1, the

optimal mean power per step

Γ∗ (ξout ,ξrelay
∗

)

,

the

opti-

U (ξout,ξrelay )

mal mean placement rate U∗(ξout1,ξrelay) and the optimal

mean

outage

per

step

Q∗out
∗

(ξout

,ξr

elay

)

,

are

continuous

in

U (ξout,ξrelay )

(ξout, ξrelay).

Proof: See Appendix C.

Remark: Theorem 8 implies that there is no need to do

any randomization among deterministic policies (unlike

[38]) in order to meet the constraints with equality.

5.2 OptAsYouGoAdaptiveLearning Algorithm
The basic idea behind this algorithm (Algorithm 3; see next page) is to vary ξo(ku)t and ξr(kel)ay at a much slower rate than V (k), as if ξo(ku)t and ξr(kel)ay are varied in an outer loop and V (k) is varied in an inner loop. If the outage in a newly created link is larger than the budgeted outage for a link with that length, then ξout is increased with the hope that subsequent links will have smaller outage; the opposite is done in case the outage in a newly created link is smaller. On the other hand, if a newly created link is shorter than N1 , then ξrelay is increased, otherwise it is decreased.
Notation in Algorithm 3: Λ[0,A1](x) denotes the projection of x on the interval [0, A1]. Let the power, outage and link length of the new relay (if placed) at the k-th step be ΓNk , Q(oNutk,Nk−1) and UNk (recall that Nk is the number of nodes placed up to the k-th step). Note that, I{Nk = Nk−1 + 1} is the indicator that a relay is placed at the k-th step.
Theorem 9: Under Assumption 1, Assumption 2 and under proper choice of A1 and A2, we have (V (k), ξo(ku)t, ξr(kel)ay) → K(q, N ) almost surely for Algorithm 3.
Proof: See Appendix C.
We complete the proof in four steps. First, we show that the difference between V (k) and V ∗(ξo(ku)t, ξr(kel)ay) converges to 0 almost surely. This proves the desired convergence in the faster timescale. Next, we pose the slower timescale iteration as a projected stochastic approximation iteration (see [39, Equation 5.3.1]). Next, we show that the slower timescale iteration satisﬁes some conditions given in [39] (see [39, Theorem 5.3.1]). Finally, we argue (using Theorem 5.3.1 of [39]) that the slower timescale iterates converge to the set of stationary points of a suitable ordinary differential equation.
It is to be noted that while the proof to some extent follows the outline of the proof of [1, Theorem 12], signiﬁcantly new nontrivialities arise in our work as compared to the proof of [1, Theorem 12]. For example, we had to prove the boundedness of the faster timescale iterates separately, since the asynchronous updates in the

12

Input: Two positive numbers A1 and A2

appropriately chosen, two decreasing positive

sequences {a(n)}n≥1 and {b(n)}n≥1 such that

∞ n=1

a(n)

=

∞,

∞ n=1

a2(n)

<

∞,

∞ n=1

b(n)

=

∞,

∞ n=1 b2(n) < ∞ and limn→∞ b(a(Bnn) ) = 0.

Output: Placement decision at each step.

faster timescale do not allow us to mimic the proof of [1, Theorem 12]. Similarly there are many other steps which require signiﬁcant novel additional mathematical analysis compared to [1, Theorem 12]. Hence, in this proof, we proved intermediate results wherever necessary, and skipped some steps if they follow from the proof of [1,

Initialization: r = 1 (distance from the previous

Theorem 12].

node), k = 1 (distance of the current location from the sink), initial estimates V (0), ξo(0u)t, ξr(0e)lay. while 1 ≤ r ≤ B do
Find Ik := {r ∈ {1, 2, · · · , B} :

Choice of A1 and A2: A1 and A2 need to be chosen carefully, otherwise the iterates (ξo(ku)t, ξr(kel)ay) may converge to undesired points on the boundary of [0, A1] ×
[0, A2]. In general, a stationary point on the boundary of

relay placed at (k − r)δ distance from sink}};

[0, A1]×[0, A2] may not correspond to a point in K(q, N ).

Find ν(r, k) :=

k i=1

I{r

∈

Ii}∀r

∈

{1,

2,

·

·

·

,

B};

Measure Qout(r, γ, wr)∀γ ∈ S, r ∈ Ik;

if r ≤ B − 1 and minγ∈S (γ + ξo(ku−t 1)Qout(r , γ, wr )) + ξr(kel−a1y) ≤

Hence, we borrow a scheme from [1] for choosing A1 and A2 which ensures that, if (ξout, ξrelay) is a stationary point of the o.d.e., then (V ∗(ξout, ξrelay), ξout, ξrelay) ∈ K(q, N ). The number A1 has to be chosen so large that,

−V (k−1)(1) + V (k−1)(r + 1) then

for all u ∈ {1, 2, · · · , B}, we will have P(arg minγ∈S (γ +

Place a new relay and use transmit power

A1Qout(u, γ, W )) = PM ) > 1 − κ for some small enough

arg minγ∈S (γ + ξo(ku−t 1)Qout(r , γ, wr ));

κ

>

0.

We

also

need

the

condition

that

Q∗out (A1 ,0)
∗

≤

q.

Do the following updates:

U (A1,0)
The number A2 has to be chosen so large that, for any

V (k)(r) = V (k−1)(r) + a(ν(r, k))I{r ∈ Ik, r < B} ξout ∈ [0, A1], we will have U ∗(ξout, A2) > N1 (when

(k−1)

(k−1) 1 < B). The numbers A1 and A2 have to be chosen

min

min(γ + ξout γ

Qout(r, γ, wr)) + ξrelay ,

N
so large that there exists at least one pair (ξout, ξrelay)

−V (k−1)(1) + V (k−1)(r + 1) − V (k−1)(r)

for which (V ∗(ξout, ξrelay), ξout, ξrelay) ∈ K(q, N ).

Discussion of Algorithm 3:

V (k)(B) = V (k−1)(B) + a(ν(B, k))I{B ∈ Ik}

(i) Two timescales: The update scheme (10) is based

min(γ + ξo(ku−t 1)Qout(B, γ, wB )) + ξr(kel−a1y) γ
−V (k−1)(B)

on two-timescale stochastic approximation (see [37, Chapter 6]). Since limn→∞ b(a(Bnn) ) = 0, we can say that ξout and ξrelay are adapted in a slower timescale,
and V is updated in a faster timescale, as if ξout and

ξo(ku)t = ξo(ku−t 1) + b(Nk)I{Nk = Nk−1 + 1}
A1
Qo(Nutk,Nk−1) − qUNk
0
ξr(kel)ay = ξr(kel−a1y) + b(Nk)I{Nk = Nk−1 + 1}

ξrelay are updated in a slow outer loop, and, V is updated in an inner loop. (ii) Structure of the iteration: The slower timescale iteration involves updating ξout and ξrelay based on whether the corresponding constraints are violated in a link (after placing a relay); if a constraint is

A2

1 − N UNk

(10)

0

Move to next step and set r = 1;

else if r ≤ B − 1 and

minγ∈S (γ + ξo(ku−t 1)Qout(r , γ, wr )) + ξr(kel−a1y) >

(iii)

−V (k−1)(1) + V (k−1)(r + 1) then

Do not place, and perform updates as in (10);

Move to next step and set r = r + 1;

else

Place a new relay (since r = B);

Use power arg minγ∈S (γ + ξo(ku−t 1)Qout(B, γ, wB));

Do the same updates as (10);

violated by a newly created link, then the corre-

sponding Lagrange multiplier is increased to coun-

terbalance it in subsequent node placements. The

goal is to meet both constraints with equality (if

possible) in the long run.

Asymptotic behaviour of the iterates: If q >

EW

Qout (B B

,P1

,W

)

;

we

will

have

ξo(ku)t

→

0;

here

the

policy places all the relays at the B-th step and

uses the smallest power P1 at each node. If the constraints are not feasible, then either ξo(ku)t → A1 or ξr(kel)ay → A2 or both happens.

Simulation results show that K(q, N ) has only one tuple

in case the pair (q, N ) is feasible.

Move to next step and set r = 1.

end
k=k+1;. end
Algorithm 3: OptAsYouGoAdaptiveLearning

5.3 Asymptotic Performance of Algorithm 3
Though Algorithm 3 induces a nonstationary policy, Theorem 9 states that the sequence of policies generated

by Algorithm 3 converges to the set of optimal stationary,

deterministic policies for the constrained problem (4).

13

Let πoaygal denote the (nonstationary) deployment policy induced by Algorithm 3.
Theorem 10: Under Assumption 1, Assumption 2 and proper choice of A1 and A2, we have:

lim sup Eπoaygal

x→∞

x

lim sup Eπoaygal
x→∞

Ni=x1 Γi = γ∗

Nx i=1

Q(oiu,it−1)

Eπoaygal Nx

≤ q, lim sup

≤N

x

x→∞

x

Proof: The proof is similar to [1, Theorem 13].

6 CONVERGENCE SPEED OF LEARNING ALGORITHMS: A SIMULATION STUDY
In this section, we provide a simulation study for the convergence rate of Algorithm 2 and Algorithm 3.

6.1 Parameter Values Used in the Simulation

For simulation, we consider a deployment environment

similar to that considered in [1, Section VIII]. The details

of the simulation environment are provided below.

We assume that deployment is done with iWiSe motes

([23]) equipped with 9 dBi antennas. S, the set of trans-

mit power levels, is taken to be {−18, −7, −4, 0, 5} dBm,

which is a subset of available transmit power levels

for iWiSe motes. Under the channel model as given by

(1), our measurements in a forest-like environment gave η = 4.7 and c = 100.17 (i.e., 1.7 dB); the experimental

details can be found in [10]. From the statistical analysis

of the measurement data, we also showed that shadow-

ing W follows log-normal distribution in such a forest-

like

environment;

W

=

10

Y 10

with

Y

∼ N (0, σ2),

where

σ = 7.7 dB was obtained from our data analysis. Shad-

owing decorrelation distance was calculated as 6 meters;

hence we consider deployment with δ = 20 meter. The

fading turned out to be Rayleigh fading.

Outage is deﬁned to be the event when a packet is received at a power level below Prcv−min = 10−9.7 mW

(i.e., −97 dBm); for a commercial implementation of

IEEE 802.15.4, received power −97 dBm results in a 2%

packet loss probability for 127 byte packets for iWiSe

motes (obtained from measurements).

We choose B in the following way. We deﬁne a link

to be workable if it has an outage probability less than

3%. B is chosen to be the largest integer such that the

probability of ﬁnding a workable link of length Bδ is

greater than 20%, under 5 dBm transmit power. For the

parameters η = 4.7 and σ = 7.7 dB, and 5 dBm transmit

power, B turned out to be 5.

It is important to note that, the radio propagation

parameters (e.g., η and σ) and modeling assumptions

(e.g., log-normal shadowing) are obtained and validated

using ﬁeld data collected via extensive measurements

in a forest-like environment; the details of these exper-

iments can be found in [10]. Hence, in this paper, we

evaluate our algorithms only via MATLAB simulation of

an environment that has radio propagation model and

parameters obtained from experiments in [10]. This is

done by generating random channel gains in MATLAB, for the wireless links that need to be measured in course of the deployment process.
The performance variation of OptAsYouGo algorithm with (ξout, ξrelay) has been demonstrated numerically in [1, Section V, Appendix C], which comply with Theorem 4 and Theorem 6.
6.2 OptAsYouGoLearning for Given Multipliers
Here we study the rate of convergence for OptAsYouGoLearning with ξout = 125, ξrelay = 2. Let us assume that the propagation environment, in which deployment is being carried out, is characterized by the parameters given in Section 6.1 (i.e., η = 4.7, σ = 7.7 dB etc.). The optimal average cost per step, under these parameter values, is λ∗ = V ∗(1) = 1.85 (computed numerically).4
We numerically study the performance of the following three types of algorithms: (i) η and σ are known prior to deployment (the agent uses the ﬁxed optimal policy with ξrelay = 2 and ξout = 125 in this case), (ii) the agent has imperfect estimates of η and σ deployment, and OptAsYouGoLearning is used to update the policy as deployment progresses, and (iii) the agent has imperfect estimates of η and σ deployment, but the corresponding suboptimal policy is used along the inﬁnite line without any update. We use the abbreviations OAYGL and OAYG for OptAsYouGoLearning and Optimal Algorithm for As-You-Go deployment (i.e., Algorithm 1), respectively. Also, following the terminology in [1], we use the abbreviation FPWU for “Fixed Policy without Update.”
Next, we formally explain the various cases considered in our simulations:
(i) OAYG: Here the agent knows η = 4.7, σ = 7.7 dB prior to deployment, and uses Algorithm 1 with ξout = 125, ξrelay = 2.
(ii) OAYGL Case 1: Here the true η = 4.7 and σ = 7.7 dB are unknown to the deployment agent. But the agent has an initial estimate η = 5, σ = 8 dB. Hence, he starts deploying using a V (0) which is optimal for these imperfect estimates of η and σ, and ξout = 125, ξrelay = 2. He updates the policy using the OptAsYouGoLearning algorithm as deployment progresses.
(iii) OAYGL Case 2: This is different from OAYGL Case 1 only in the aspect that here deployment starts with the optimal policy for η = 4, σ = 7 dB.
(iv) FPWU Case 1: Here the true η and σ are unknown prior to deployment, and the agent has an initial estimate η = 5, σ = 8 dB. The agent computes V ∗ for these imperfect initial estimates and ξout = 125, ξrelay = 2, and uses this policy throughout the deployment process without any update. This case will demonstrate the gain in performance by
4. These values of ξout and ξrelay are chosen because they can produce reasonable values of placement rate, mean power per step and mean outage per step, which can be used in practical networks. However, these values are chosen only for illustration purposes, and the choice will vary depending on the requirement for deployment.

14

Figure 3: Convergence speed of OptAsYouGoLearning (OAYGL) with the number of steps, k. In the legends, “OAYG” refers to the values that are obtained if Algorithm 1 is used; these are the target values for OptAsYouGoLearning.

updating the policy under OptAsYouGoLearning, w.r.t. the case where the suboptimal policy is used throughout the deployment process. (v) FPWU Case 2: It differs from FPWU Case 1 only in the aspect that here the agent has initial estimates η = 4, σ = 7 dB.

For simulation of OAYGL, we chose a(k) = 1k20 . We simulated 2000 independent network deployments (i.e.,

2000 sample paths of the deployment process) with Op-

tAsYouGoLearning, and estimated (by averaging over

2000 deployments) the expectation of V (k)(1), mean

Nk Γj

power per step (i.e.,

j=1
k

), mean outage per step (i.e.,

N j=k1 Q(oju,tj−1) ) and mean placement distance (i.e., k ),

k

Nk

in the part of the network between the sink node to

the k-th step. The results are summarized in Figure 3.

Asymptotically the estimates are supposed to converge

to the values provided by OAYG.

Observations: We observe that the estimate of E(V (k)(1)) approaches the optimal cost λ∗ = V ∗(1) = 1.85 (for the actual propagation parameters), as k increases, and gets to within 10% of the optimal cost by the time where k = 35 to 40 (within a distance of 800 meters), while starting with two widely different initial guesses of the propagation parameters. The es-

timates of mean power per step, mean outage per step and mean placement distance also converges very fast to the corresponding values achieved by OAYG. It also shows that, if the performance of the initial imperfect policy (FPWU) is signiﬁcantly different than that of OAYG, then OptAsYouGoLearning will provide closer performance to OAYG, as compared to FPWU (see the mean placement distance plot).
Note that, even though Theorem 7 guarantees almost sure convergence, the convergence speed will vary across sample paths. But here we demonstrate speed of convergence after averaging over 2000 sample paths.

6.3 OptAsYouGoAdaptiveLearning

Now we will demonstrate the performance of OptAsY-

ouGoAdaptiveLearning (Algorithm 3) for deployment

over a ﬁnite distance under an unknown propagation

environment. We again assume that the true propagation

parameters are given by η = 4.7, σ = 7.7 dB. For these

parameters, under the choice ξrelay = 2 and ξout = 125,

the optimal average cost per step will be λ∗ = 1.85,

which can be achieved by OAYG (Algorithm 1). OAYG

in this case will yield a mean placement distance of

2.285

steps,

a

mean

outage

per

step

of

0.0101 2.285

=

0.0044,

and a mean power per step of 0.423 mW.

15

Figure 4: Convergence speed of OptAsYouGoAdaptiveLearning (OAYGAL) with the number of steps, k. In the legends, “OAYG”
refers to the values that are obtained if Algorithm 1 is used; these are the target values for OptAsYouGoAdaptiveLearning. Evolution of ξo(ku)t and ξr(kel)ay are shown for a longer time, since they converge slowly to their respective target values.

Now, let us suppose that we need to solve the con-
strained problem in (4) with the targets q = 0.0044 and N = 2.2185 , but the true η and σ of the environment are unknown to us. Hence, we need to employ
OptAsYouGoAdaptiveLearning (we use the abbreviation
OAYGAL for it); as compared to OptAsYouGoLearning, we need to make an additional choice of ξo(0u)t and ξr(0e)lay.
We consider the following cases in our simulations:
(i) OAYG: This is same as in Section 6.2
(ii) OAYGAL Case 1: Here the true η = 4.7 and σ =

7.7 dB are unknown to the deployment agent. But
the agent has an initial estimate η = 5, σ = 8 dB. Hence, he starts deploying using a V (0) which is
optimal for these imperfect estimates of η and σ, and ξo(0u)t = 100, ξr(0e)lay = 3. He updates the policy using the OptAsYouGoAdaptiveLearning algorithm
as deployment progresses.
(iii) OAYGAL Case 2: This is same as OAYGAL Case 1,
except that the agent starts deploying using a policy

16

corresponding to the wrong initial estimate η = 4, σ = 7 dB (under ξo(0u)t = 100, ξr(0e)lay = 3). (iv) FPWU Case 3: Here the agent uses ξout = 100, ξrelay = 3, and uses the corresponding optimal policy for the imperfect estimates η = 5, σ = 8 dB, throughout the deployment process. (v) FPWU Case 4: This is similar to FPWU Case 3; the only difference is that the optimal policy for the imperfect estimates η = 4, σ = 7 dB is used throughout deployment.

For simulation of OAYGAL, we chose the step sizes

as follows. We took a(k)

=

1 k0.55

,

b(k)

=

100 k0.8

for

the

ξout

update

and

b(k)

=

1 k0.8

for

the

ξrelay

update

(however, both ξout and ξrelay are updated in the same

timescale). We simulated 2000 independent network de-

ployments (i.e., 2000 sample paths of the deployment

process) with OptAsYouGoLearning, and estimated (by

averaging over 2000 deployments) the expectations of

V (k)(1), mean power per step, mean outage per step mean placement distance, ξo(ku)t and ξr(kel)ay, in the part of

the network between the sink node to the k-th step. The

results are summarized in Figure 4 (see previous page).

Observations: Under OAYGAL Case 1 the estimates of the expectations of V (2000)(1), ξo(2u0t00), ξr(2e0la0y0), mean power per step up to the 2000th step, mean outage per

step up to the 2000th step, and mean placement distance

over 2000 steps are 1.8479, 124.89, 2.01, 0.4222, 0.04403

and 2.2852, whereas the corresponding target values are

1.85, 125, 2, 0.4223, 0.00441 and 2.2857, respectively. Sim-

ilarly, for OAYGAL Case 2 also, the quantities converge

close to the target values. In practice, the performance

metrics are reasonably close to their respective target

values within 100 steps (i.e., 2 kms).

FPWU Case 3 and FPWU Case 4 either violate some

constraint or uses signiﬁcantly higher per-step power

compared to OAYG. But, by using OptAsYouGoAdap-

tiveLearning, we can achieve mean power per step close

to the optimal while (possibly) violating the constraints

by small amount. However, performance of OAYGAL is

signiﬁcantly closer to the target compared to FPWU.

The speed of convergence will depend on the choice of a(k) and b(k), of ξo(0u)t, ξr(0e)lay and the initial estimates of

η and σ. However, optimizing convergence speed over

step size sequences is left for future research.

7 CONCLUSION
In this paper, we have formulated the problem of pureas-you-go deployment along a line, under a very light trafﬁc assumption. The problem was formulated as an average cost MDP, and its optimal policy structure was studied analytically. We also proposed two learning algorithms that asymptotically converge to the corresponding optimal policies. Numerical results have been provided to illustrate the speed of convergence of the learning algorithms.
While this paper provides an interesting set of results, it can be extended or modiﬁed in several ways: (i) One

can attempt to develop deployment algorithms for 2
dimensional regions, where multiple agents cooperate
to carry out the deployment. (ii) One can also attempt
to develop deployment algorithms that can provide
theoretical guarantees on the data rate supported by
the deployed networks (instead of assuming that the
trafﬁc is lone packet). (iii) The optimization of the rate of
convergence for the learning algorithms by proper choice
of the step sizes is also a challenging problem. We leave
these issues for future research endeavours.
REFERENCES
[1] A. Chattopadhyay, M. Coupechoux, and A. Kumar, “Sequential decision algorithms for measurement-based impromptu deployment of a wireless relay network along a line,” published in IEEE/ACM Transactions on Networking, available in http://www.arxiv. org/abs/1502.06878, vol. 24, no. 5, 2016.
[2] H. Liu, J. Li, Z. Xie, S. Lin, K. Whitehouse, J. A. Stankovic, and D. Siu, “Automatic and robust breadcrumb system deployment for indoor ﬁreﬁghter applications,” in MobiSys. ACM, 2010.
[3] http://robotics.eecs.berkeley.edu/~pister/29Palms0103/. [4] P. Corke, S. Hrabar, R. Peterson, D. Rus, S. Saripalli, and
G. Sukhatme, “Autonomous deployment and repair of a sensor network using an unmanned aerial vehicle,” in IEEE International Conference on Robotics and Automation. IEEE, 2004, pp. 3602–3608. [5] D. Anthony, J. Ore, C. Detweiler, and E. Basha, “Controlled sensor network installation with unmanned aerial vehicles,” in ACM Conference on Embedded Network Sensor Systems (SenSys). ACM, 2014, pp. 348–349. [6] V. Dyo, S. Ellwood, D. Macdonald, A. Markham, C. Mascolo, B. Pasztor, S. Scellato, N. Trigoni, R. Wohlers, and K. Yousef, “Evolution and sustainability of a wildlife monitoring sensor network,” in Proceedings of SenSys 2010. ACM, 2011, pp. 127— 140. [7] A. A. A. Alkhatib, “A review on forest ﬁre detection techniques,” International Journal of Distributed Sensor Networks (a journal published by Hindawi Publishing Corporation), vol. 2014. [8] www.cnet.com/news/inside-historic-nokia-bell-labs-tomorrows-5g-network-tech/. [9] A. Chattopadhyay, M. Coupechoux, and A. Kumar, “Measurement based impromptu deployment of a multi-hop wireless relay network,” in Proc. of the 11th Intl. Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks (WiOpt). IEEE, 2013. [10] A. Chattopadhyay, A. Ghosh, A. Rao, B. Dwivedi, S. Anand, M. Coupechoux, and A. Kumar, “Impromptu deployment of wireless relay networks: Experiences along a forest trail,” Proceedings of the IEEE International Conference on Mobile Ad hoc and Sensor Systems (MASS), 2014, a detailed version available in http://arxiv.org/abs/1409.3940. [11] M. Souryal, J. Geissbuehler, L. Miller, and N. Moayeri, “Real-time deployment of multihop relays for range extension,” in Proc. of the International Conference on Mobile Systems, Applications, and Services (MobiSys). ACM, 2007, pp. 85–98. [12] T. Aurisch and J. Tölle, “Relay Placement for Ad-hoc Networks in Crisis and Emergency Scenarios,” in Proc. of the Information Systems and Technology Panel (IST) Symposium. NATO Science and Technology Organization, 2009. [13] M. Howard, M. Mataric´, and G. Sukhatme, “An incremental self-deployment algorithm for mobile sensor networks,” Kluwer Autonomous Robots, vol. 13, no. 2, pp. 113–126, 2002. [14] J. Bao and C. Lee, “Rapid deployment of wireless ad hoc backbone networks for public safety incident management,” in Global Telecommunications Conference (GLOBECOM). IEEE, 2007, pp. 1217–1221. [15] H. Liu, Z. Xie, J. Li, K. Whitehouse, J. Stankovic, S. Lin, and D. Siu, “Efﬁcient and reliable breadcrumb systems via coordination among multiple ﬁrst responders,” in Proc. of PIMRC. IEEE, 2011, pp. 1005–1009. [16] K. Miranda, A. Molinaro, and T. Razaﬁndralambo, “A survey on rapidly deployable solutions for post-disaster networks,” IEEE Communications Magazine, vol. 54, no. 4, pp. 117–123, 2016.

17

[17] P. Mondal, K. Naveen, and A. Kumar, “Optimal Deployment of Impromptu Wireless Sensor Networks,” in Proc. of the IEEE National Conference on Communications (NCC),2012. IEEE, 2012.
[18] A. Sinha, A. Chattopadhyay, K. Naveen, M. Coupechoux, and A. Kumar, “Optimal sequential wireless relay placement on a random lattice path,” Ad Hoc Networks Journal (Elsevier)., vol. 21, pp. 1–17, 2014.
[19] A. Ghosh, A. Chattopadhyay, A. Arora, and A. Kumar, “Asyou-go deployment of a 2-connected wireless relay network for sensor-sink interconnection,” in International Conference on Signal Processing and Communications (SPCOM). IEEE, 2014.
[20] A. Chattopadhyay, A. Sinha, M. Coupechoux, and A. Kumar, “Deploy-as-you-go wireless relay placement: An optimal sequential decision approach using the multi-relay channel model,” Accepted in IEEE Transactions on Mobile Computing, available in http:// ieeexplore.ieee.org/ document/ 7463497/ .
[21] P. Agrawal and N. Patwari, “Correlated link shadow fading in multi-hop wireless networks,” http://arxiv.org/abs/0804.2708.
[22] A. Bhattacharya, A. Rao, D. G. R. Sahib, A. Mallya, S. Ladwa, R. Srivastava, S. Anand, and A. Kumar, “Smartconnect: A system for the design and deployment of wireless sensor networks,” in Proc. of the 5th International Conference on Communication Systems and Networks (COMSNETS). IEEE, 2013.
[23] http://www.astec.org.in/astec/content/wireless-sensor-network. [24] F. J. Beutler and K. W. Ross, “Optimal policies for controlled
markov chains with a constraint,” Journal of Mathematical Analysis and Applications, vol. 112, pp. 236–252, 1985. [25] A. Bhattacharya and A. Kumar, “QoS aware and survivable network design for planned wireless sensor networks,” http://arxiv.org/abs/1110.4746. [26] S. Lohier, A. Rachedi, I. Salhi, and E. Livolant, “Multichannel access for bandwidth improvement in IEEE 802.15.4 wireless sensor networks,” Available in https://hal-enpc.archives-ouvertes.fr/hal00680871/document. [27] N. Abdeddaim, F. Theoleyre, F. Rousseau, and A. Duda, “Multichannel cluster tree for 802.15.4 wireless sensor networks,” in Proc. of the 23th International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC). IEEE, 2012, pp. 590—595. [28] E. Toscano and L. Bello, “Multichannel superframe scheduling for IEEE 802.15.4 industrial wireless sensor networks,” IEEE Transactions on Industrial Informatics, vol. 8, no. 2, pp. 337 —350, 2012. [29] A. Bardella, N. Bui, A. Zanella, and M. Zorzi, “An experimental study on IEEE 802.15.4 multichannel transmission to improve RSSI-based service performance,” in Proc. of the 4th international conference on Real-world wireless sensor networks (REALWSN), 2010, pp. 154—161. [30] R. Upadrashta, T. Choubisa, V. S. Aswath, A. Praneeth, A. Prabhu, S. Raman, T. Gracious, and P. Kumar, “An animation-and-chirplet based approach to intruder classiﬁcation using PIR sensing,” in Proceedings of IEEE Tenth International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP), 2015, pp. 1–6. [31] B. Aghaei, “Using wireless sensor network in water, electricity and gas industry,” in Proceedings of the 3rd IEEE International Conference on Electronics Computer Technology, 2011, pp. 14—17. [32] T. Adame, A. Bel, B. Bellalta, J. Barcelo, and M. Oliver, “IEEE 802.11ah: the WiFi approach for M2M communications,” IEEE Wireless Communications, vol. 21, no. 6, pp. 144—152, 2014. [33] A. Mainwaring, J. Polastre, R. Szewczyk, D. Culler, and J. Anderson, “Wireless sensor networks for habitat monitoring,” in Proceedings of Wireless Sensor Network Applications (WSNA). ACM, 2002, pp. 88–97. [34] D. Bertsekas, Dynamic Programming and Optimal Control, Vol. II. Athena Scientiﬁc, 2007. [35] O. Hernandez-Lerma and J. B. Lasserre, Discrete-Time Markov Control Processes Basic Optimality Criteria. Springer, 1996. [36] S. Bhatnagar, “The borkar-meyn theorem for asynchronous stochastic approximations,” Systems and Control Letters, vol. 60, no. 7, pp. 472–478, 2011. [37] V. S. Borkar, Stochastic approximation: a dynamical systems viewpoint. Cambridge University Press, 2008. [38] D.-J. Ma and A. M. Makowski’, “A class of steering policies under a recurrence condition,” in Proc. of the 27th Conference on Decision and Control (CDC). IEEE, 1988. [39] H. Kushner and D. Clark, Stochastic Approximation Methods for Constrained and Unconstrained Systems. Springer-Verlag, 1978.

[40] N. Salodkar, A. Bhorkar, A. Karandikar, and V. Borkar, “An online learning algorithm for energy efﬁcient delay constrained scheduling over a fading channel,” IEEE Journal on Selected Areas in Communications, vol. 26, no. 4, pp. 732–742, 2008.
[41] J. Abounadi, D. Bertsekas, and V. S. Borkar, “Learning algorithms for markov decision processes with average cost,” SIAM Journal on Control and Optimization, vol. 40, pp. 681–698, 2001.
[42] V. S. Borkar and K. Soumyanath, “A new analog parallel scheme for ﬁxed point computation, part 1: Theory,” IEEE Transactions on Circuits and Systems I, vol. 44, pp. 351–355, 1997.
[43] W. Rudin, Principles of Mathematical Analysis, Third Edition. McGraw-Hill International Editions, 1976.
[44] C. Lakshminarayanan and S. Bhatnagar, “A stability criterion for two timescale stochastic approximation schemes,” Available in http://stochastic.csa.iisc.ernet.in/www/research/ﬁles/ttsastb.pdf , 2014.
Arpan Chattopadhyay obtained his B.E. in Electronics and Telecommunication Engineering from Jadavpur University, India in the year 2008, and M.E. and Ph.D in Telecommunication Engineering from Indian Institute of Science, Bangalore, India in the year 2010 and 2015, respectively. He is currently working in Electrical Engineering department, University of Southern California, as a postdoctoral researcher. His research interests include design, resource allocation, control and learning in wireless networks and cyber-physical systems.
Avishek Ghosh obtained his B.E. in Electronics and Telecommunication Engineering from Jadavpur University, India in 2012, and M.E. in Telecommunication from Indian Institute of Science, Bangalore, India in the year 2014. He is currently doing his Ph.D in the department of EECS of UC Berkeley. His research interests include networks and machine learning.
Anurag Kumar (B.Tech., Indian Institute of Technology (IIT) Kanpur; PhD, Cornell University, both in Electrical Engineering) was with Bell Labs, Holmdel, N.J., for over 6 years. Since then he has been on the faculty of the ECE Department at the Indian Institute of Science (IISc), Bangalore; he is at present the Director of the Institute. His area of research is communication networking, and he has recently focused primarily on wireless networking. He is a Fellow of the IEEE, the Indian National Science Academy (INSA), the Indian National Academy of Engineering (INAE), and the Indian Academy of Sciences (IASc). He was an associate editor of IEEE Transactions on Networking, and of IEEE Communications Surveys and Tutorials.

18

Supplementary Material Title: “Asynchronous Stochastic Approximation Based Learning Algorithms for As-You-Go Deployment of Wireless Relay Networks along a Line” Authors: Arpan Chattopadhyay, Avishek Ghosh, anurag Kumar
APPENDIX A FORMULATION FOR KNOWN PROPAGATION PA-
RAMETERS

APPENDIX B OPTASYOUGOLEARNING: LEARNING PURE AS-YOU-GO DEPLOYMENT, FOR LAGRANGE MULTIPLIERS

WITH
GIVEN

Proof of Theorem 7: We can rewrite (9) as follows:

V (k)(r) = V (k−1)(r) + a(ν(r, k))I{r ∈ Ik} fr(V (k−1)) + Mk(r) (11)
where, for all 1 ≤ r ≤ B − 1

fr(V (k−1)) = EW min min(γ + ξoutQout(r, γ, W )) + ξrelay,
γ
−V (k−1)(1) + V (k−1)(r + 1) − V (k−1)(r)

Proof of Theorem 2: From (7), V (B) is unique for ﬁxed ξout and ξrelay. Hence, we can say that V (B) is a continuous and decreasing function of V (1). Now, let us assume that V (r + 1) is continuous and decreasing in V (1) for some r, 1 ≤ r ≤ B − 1. Let us recall (7) for V (r). Since V (r + 1) is continuous and decreasing in V (1) by our induction hypothesis, it is evident from (7) that V (r) is also continuous and decreasing in V (1). Proceeding in this way, we can write V (1) = φ(V (1)) where φ(·) is continuous and decreasing in V (1). But V (1) is continuous and strictly increasing in V (1). Hence, V (1) = φ(V (1)) has a unique ﬁxed point V ∗(1). Now, from (7), V (B−1) is unique since V (1) = V ∗(1) is unique and V (B) is unique. Proceeding backwards in this way, we can show that we have a unique V ∗(r) for all r.
Now, from (7), we ﬁnd that V ∗(r) ≤ −V ∗(1)+V ∗(r+1), i.e., V ∗(r+1) ≥ V ∗(r)+V ∗(1) for all r ∈ {1, 2, · · · , B −1}. Also, V ∗(1) = λ∗ > 0 and it is unique. This proves the second part of the theorem.
Proof of Theorem 4: Let us denote the mean power per link, mean outage per link and mean placement distance (in steps) under a stationary policy π by Γπ, Qout,π and U π. Then, by Renewal-Reward Theorem, we have λ∗(ξout, ξrelay) = inf π Γπ+ξoutQout,π+ξrelay . The nu-
Uπ
merator is afﬁne and increasing in ξout and ξrelay, and the denominator is independent of ξout and ξrelay. Hence, λ∗(ξout, ξrelay) is concave, increasing in ξout and ξrelay, since the pointwise inﬁmum of increasing afﬁne functions of (ξout, ξrelay) is increasing and jointly concave in (ξout, ξrelay). Now, any increasing, concave function is continuous. Hence, λ∗(ξout, ξrelay) is continuous in (ξout, ξrelay). Also, it is easy to see that λ∗(ξout, ξrelay) is Lipschitz in each argument with Lipschitz constant 1.
Proof of Theorem 5: By Theorem 4, V ∗(1) := λ∗ is Lipschitz continuous in (ξout, ξrelay). By (7), V ∗(B) is Lipschitz continuous in (ξout, ξrelay). Hence, by (7), V ∗(B − 1) is also Lipschitz continuous in (ξout, ξrelay). Thus, by using backward induction, we can show that V ∗(r) is Lipschitz continuous in (ξout, ξrelay) for all 1 ≤ r ≤ B.

Mk(r) =

min min(γ + ξoutQout(r, γ, wr)) + ξrelay,
γ

−V (k−1)(1) + V (k−1)(r + 1) − V (k−1)(r) − fr(V (k−1))

and

fB (V (k−1)) = EW min(γ + ξoutQout(B, γ, W )) + ξrelay − V (k−1)(B)
γ

Mk(B) =

min(γ + ξoutQout(B, γ, wB )) + ξrelay − V (k−1)(B)
γ

−fB (V (k−1))

Let M k := (Mk(1), · · · , Mk(B)). Let us denote the σ-

ﬁeld Fk := σ(V i, Ii, M i, i ≤ k − 1); it is the information

available to the deployment agent before making any de-

cision at the k-th step. Clearly, the update equations fall

under the category of Asynchronous Stochastic Approx-

imation algorithms (see [36]). In order to see whether

V (k) → V ∗ almost surely, we will ﬁrst check whether

the ﬁve assumptions mentioned in [36] are satisﬁed.

Checking Assumption 1 of [36]: For each r, 1 ≤ r ≤ B,

V (r) gets updated at least once in every B steps. Hence,

lim infk→∞

ν(r,k) k

≥

1 B

>

0 almost surely. Hence, the

assumption is satisﬁed.

Checking Assumption 2 of [36]: If we choose

{a(k)}k≥1 to be a bounded, decreasing sequence with

k a(k) = ∞ and k a2(k) < ∞, this condition will be

satisﬁed.

Checking Assumption 3 of [36]: Not applicable to

our problem since before updating V (k) the deployment

agent knows V (k−1).

Before checking the other two conditions, we will

establish a lemma. Let us consider the following system

of o.d.e-s:

V˙t(r) = κt(r)fr(V t) ∀r ∈ {1, 2, · · · , B}

(12)

where κt(r) ∈ (0, 1] for all r and t. By Theorem 2,
this system of o.d.e-s has an unique stationary point V ∗(ξout, ξrelay).
Lemma 1: V ∗(ξout, ξrelay) is a globally asymptotically
stable equilibrium for the system of o.d.e-s (12). Also,

19

V = 0 is a globally asymptotically stable equilibrium for (12) when γ, ξout and ξrelay are replaced by 0 in the deﬁnition of fr(V ) for all r ∈ {1, 2, · · · , B}.
Proof: Note that, by Theorem 2, V ∗(ξout, ξrelay) is the unique stationary point for (12). Now, the proof for this lemma follows from similar line of arguments as in the appendix of [40] (which uses results from [41] and [42]).

Checking Assumption 4 of [36]: It is easy to see that

fr(V ) is Lipschitz in V for each r; this satisﬁes Assump-

tion 4(i). Let us consider the ODE (12) with 0 < κt(r) ≤ 1

corresponds to the relative rate at which V (r) is updated. By Lemma 1, V ∗(ξout, ξrelay) is a globally asymptotically

stable equilibrium for the system of o.d.e-s (12). Hence,

Assumption 4(ii) is satisﬁed.

Consider the functions fr(ccV ) , c ≥ 1 for all r. Clearly,

limc→∞

fr (cV ) c

=

min{0, −V (1) + V (r + 1)} − V (r)

for

r

=

B,

and

limc→∞

fB (cV ) c

=

−V (B).

Note

that

fr (cV ) c

for

all

r

and

limc→∞

fr (cV ) c

all

are

continuous

in

V,

and

fr (cV ) c

is

decreasing

in

c.

Hence,

by

Theorem

7.13

of

[43],

convergence

of

fr (cV ) c

over

compacts

is

uniform.

Hence,

Assumption 4(iii) is satisﬁed. Consider the ODE: V˙t(r) = κt(r)(min{0, −Vt(1)+Vt(r+
1)} − Vt(r)) for r = B and V˙t(B) = κB(t)(−Vt(B)).

Clearly, by the second part of Lemma 1, there is a unique

globally asymptotically stable equilibrium V = 0. Hence,

Assumption 4(iv) is satisﬁed.

Checking Assumption 5 of [36]: It is easy to see that,

{M k}k≥1 is a Martingale difference sequence adapted to

Fk. Hence, Assumption 5(i) is satisﬁed.

Now,

|Mk+1(r)| ≤ 2 min{PM + ξout + ξrelay, −V (k)(1)

+V (k)(r + 1)} − V (k)(r)

and |Mk+1(B)| ≤

PM + ξout + ξrelay − V (k)(B)

Now, by Renewal-Reward Theorem,

∗

Γ∗(ξout, ξrelay ) + ξoutQ∗out(ξout, ξrelay ) + ξrelay

λ (ξout, ξrelay ) =

∗

U (ξout, ξrelay )

Since λ∗(ξout, ξrelay) is continuous in (ξout, ξrelay)

∗

(by Theorem 4), we conclude that Qout(ξout, ξrelay) is

continuous in ξout

and ξrelay. Hence,

Γ∗ (ξout ,ξrelay
∗

)

,

U (ξout,ξrelay )

Q∗out(ξout,ξrelay )
∗

and

∗

1

are continuous in

U (ξout,ξrelay )

U (ξout,ξrelay )

(ξout, ξrelay).

Now, the proof of the theorem is completed by the

following lemma.

Lemma 2: Under Assumption 2, g(r, γ) is continuous

in (ξout, ξrelay).

Proof: We will ﬁrst prove the result for r ≤ B − 1.

Let us ﬁx an r ∈ {1, · · · , B − 1} and any γ ∈ S. We will

only show that g(r, γ) is continuous in ξout; the proof for

continuity of g(r, γ) w.r.t. ξrelay will be similar.

Let us consider a sequence {ξn}n≥1 such that ξn →

ξout. Let us denote the joint probability distribution

of (Uk, Γk) by gn(r, γ), if Algorithm 1 is used with

ξn as the cost for unit outage. We will show that

limn→∞ gn(r, γ) → g(r, γ).

Deﬁne the sets Er,γ = wr : γ + ξoutQout(r, γ, wr) <

γ + ξoutQout(r, γ , wr) and Eu = wu : minγ∈S (γ +

ξoutQout(u, γ, wu)) > −ξrelay − V ∗(1) + V ∗(u + 1) for
all 1 ≤ u ≤ r. Let us deﬁne E = ∩γ =γ Er,γ ∩u≤r−1 Eu ∩ Er, where Er
is the set complement of Er. Now, g(r, γ) = P(E) = E(IE ), where I denotes the
indicator function. The expectation is over the joint distribution of (W1, W2, · · · , Wr) (shadowing random variables from r locations).
Now, for any γ = γ, we have P γ +

ξoutQout(r, γ, Wr) = γ + ξoutQout(r, γ , Wr) = 0,

Hence, ||Mk+1|| ≤ C0(1 + ||V (k)||) for some C0 > 0.
Hence, Assumption 5(ii) is satisﬁed. Now, by [36, Theorem 3], V (k) → V ∗.

APPENDIX C OPTASYOUGOADAPTIVELEARNING WITH CONSTRAINTS ON OUTAGE PROBABILITY AND RELAY PLACEMENT RATE

C.1 Proof of Theorem 8

Let us denote by g(r, γ), r ∈ {1, 2, · · · , B}, γ ∈ S the

joint distribution of (Uk, Γk) under Algorithm 2. For

the time being, let us assume that g(r, γ) is continu-

ous in (ξout, ξrelay). Then, the mean placement distance

∗
U (ξout, ξrelay) =

B r=1

γ∈S rg(r, γ), and the mean

∗
power per link Γ (ξout, ξrelay) =

B r=1

γ∈S γg(r, γ) are

both continuous in (ξout, ξrelay).

and P minγ∈S (γ + ξoutQout(u, γ, Wu)) = −ξrelay −
V ∗(1) + V ∗(u + 1) = 0 for all u ≤ r; these two
assertions follow from Assumption 2 and from the continuity of Qout(r, γ, w) in w. Hence, we can safely assume the following:
• Er,γ has the same expression as Er,γ except that the < sign is replaced by > sign.
• Eu has the same expression as Eu except that the > sign is replaced by < sign.
Let Er(,nγ) , Eu(n) and E(n) be the sets obtained by replacing ξout by ξn in the expressions of the sets Er,γ , Eu and E respectively (also V ∗ has to be replaced by the corresponding optimal V (n,∗)). Clearly, we can make similar claims for Er(,nγ) , Eu(n).
Now, if we can show that E(IE(n) ) → E(IE ), the lemma will be proved, because g(r, γ) = P(E) = E(IE ).

20

Claim 1: limn→∞ IEu(n) → IEu , and limn→∞ IEr(,nγ) → IEr,γ almost surely, for γ = γ.
Proof: Suppose that, for some value of wu, IEu (wu) = 1, i.e., minγ∈S (γ + ξoutQout(u, γ, wu)) > −ξrelay − V ∗(1) + V ∗(u + 1). Now, V ∗(1) and V ∗(u + 1) are continuous in
(ξout, ξrelay) for all 1 ≤ u ≤ r (see Theorem 5). Hence,
there exists an integer n0 large enough, such that for all
n > n0, we have minγ∈S (γ+ξnQout(u, γ, wu)) > −ξrelay −

V (n,∗)(1) + V (n,∗)(u + 1)

, i.e., IEu(n) (wu) = 1 for
ξout =ξn

all n > n0. Hence, IEu(n) (wu) → IEu (wu) if IEu (wu) = 1. For the case IEu (wu) = 0, we can have similar arguments.

This proves the ﬁrst part of the claim, and second part

can be proved by similar arguments.

Now, IE(n) =

I γ =γ E(n) r,γ

u≤r−1 IEu(n) × IEr(n) . By

Claim 1, IE(n) → IE almost surely as n → ∞. Hence, by

Dominated Convergence Theorem, we have E(IE(n) ) →

E(IE ).

We can prove the same statement for r = B in a similar

method; but we need to deﬁne E = ∩γ =γ EB,γ ∩u≤B−1Eu.

Hence, the lemma is proved.

C.2 Proof of Theorem 9
We denote the shadowing in the link between the potential locations located at distances iδ and jδ from the sink node, by the random variable Wi,j. The sample space Ω is deﬁned to be the collection of all ω such that each ω corresponds to a ﬁxed realization {wi,j : i ≥ 0, j ≥ 0, i > j, 1 ≤ i−j ≤ B} of shadowing that could be encountered in the deployment process over inﬁnite horizon. Let F be the Borel σ-algebra on Ω. We also deﬁne a sequence
of sub-σ ﬁelds Fk := σ Wi,j : i ≥ 0, j ≥ 0, k ≥ i > j, 1 ≤
i−j ≤ B ; Fk is increasing in k, and captures the history
of the deployment process up to kδ distance. Let us recall the outline of the proof of Theorem 9 in
Section 5.2.
C.2.1 The Faster Time-Scale Iteration of V (k) Let us denote by V ∗(ξout, ξrelay) the value of V ∗, for given ξout and ξrelay. Let us also deﬁne a(k) := maxr∈Ik a(ν(r, k)).
Using the ﬁrst order Taylor series expansion of the function Λ[0,A1](·), and using the fact that Λ[0,A1](ξo(ku−t 1)) = ξo(ku−t 1) (since ξo(ku−t 1) ∈ [0, A1]), we rewrite the update equation (10) as (13). Now, for the update equation for ξrelay in (13), we can write:

Λ[0,A2 ] lim
β↓0

ξr(kel−a1y) + β(1 − N UNk ) β

− ξr(kel−a1y)

= (1 − N UNk )I{0 < ξr(kel−a1y) < A2}

+ (1 − N UNk )+I{ξr(kel−a1y) = 0}

− (1 − N UNk )−I{ξr(kel−a1y) = A2}

where y+ = max{y, 0} and y− = − min{y, 0}. We can write similar expression for the ξo(ku)t update. Since out-
age probabilities and placement distances are bounded quantities, and since Nk ≥ Bk and limk→0 b(a(Bkk) ) = 0,
we have:

lim b(Nk) lim k→∞ a(k) β↓0 −qUNk ) − ξo(ku−t 1)

Λ[0,A1] ξo(ku−t 1) + β(Qo(Nutk,Nk−1) /β + o(b(Nk)) = 0
b(Nk )

Similar claim can be made for ξrelay update.

Lemma 3: Under Algorithm 3, the faster timescale iterates {V (k)}k≥1 are almost surely bounded.

Proof: Note that, (13) combines the faster and slower

timescale iterations in a single timescale where the step

size is a(n). We will now use the theory from [44,

Section 3] to prove this lemma.

Note that, the R.H.S. of the faster timescale iteration

in (13) is Lipschitz continuous in both faster and slower

timescale iterates. Hence, the ﬁrst part of [44, Assump-

tion 2.1] is satisﬁed.

[44, Assumption 2.2] can be checked, using similar

arguments as in checking [36, Assumption 5(ii)] in the

proof of Theorem 7.

Also,

∞ n=1 a(n) ≥

∞ n=1

a(n)

=

∞

and

∞ n=1 a2(n) ≤

∞ n=1 a2(

n B

) < ∞, which satisﬁes [44, Assumption 2.3].

Checking [44, Assumption 2.4]: Let us consider

the following set of o.d.e. (similar to what

we considered in the proof of Theorem 7): V˙t(r) = κt(r)fr(V t, ξout(t), ξrelay(t)) for r ∈ {1, 2, · · · , B}, ξ˙out(t) = 0 and ξ˙relay(t) = 0 (recall the

interpretation of κt(r) from Appendix B). Note that,

limc→∞ fr(cV ,cξouct,cξrelay) = EW min{ξoutQout(r, γ, W ) +

ξrelay, −V (1) + V (r + 1)} − V (r) for r = B, and

limc→∞ fB(cV ,cξocut,cξrelay) = ξoutEW Qout(B, γ, W ) +

ξrelay − V (B).

Note

that

fr (cV ) c

for

all

r

and

limc→∞ fr(cV ,cξouct,cξrelay) all are continuous in

(V , ξout, ξrelay), and fr(cV ,cξouct,cξrelay) is decreasing

in c. Hence, by Theorem 7.13 of [43], convergence of

fr(cV ,cξouct,cξrelay) over compacts is uniform. Hence, one

part of [44, Assumption 2.4] is proved. Next, by similar

analysis done while checking [36, Assumption 4] in the

proof of Theorem 7 (using Lemma 1), we can verify the

second part of [44, Assumption 2.4].

Hence, using similar analysis as in [44, Section 3, The-

orem 11] (adapted to the case of asynchronous stochastic approximation), we can claim that ||V (k)|| ≤ C∗(1 + ξo(ku)t + ξr(kel)ay) for all k ≥ 1, for some C∗ > 0. Now,
since the slower timescale iterates are bounded in our

problem, the faster timescale iterates are also bounded.

This completes the proof of Lemma 3.

Lemma 4: For Algorithm 3, we have (V (k), ξo(ku)t, ξr(kel)ay) → {(V ∗(ξout, ξrelay), ξout, ξrelay) :
(ξout, ξrelay) ∈ [0, A1] × [0, A2]} almost surely, i.e., limk→∞ ||V (k) − V ∗(ξo(ku)t, ξr(kel)ay)|| = 0 almost surely.

Proof: Note that, the functions fr(V , ξout, ξrelay) =

21

V (k)(r) = V (k−1)(r) + a(k) a(ν(r, k)) I{r ∈ Ik} min min(γ + ξ(k−1)Qout(r, γ, wr)) + ξ(k−1), −V (k−1)(1) + V (k−1)(r + 1) − V (k−1)(r) ,

a(k)

γ

out

relay

∀1 ≤ r ≤ B − 1

V (k)(B)

=

V

(k−1) (B )

+

a(ν(r, a(k)

B)) I{B

∈

Ik }

min(γ + ξ(k−1)Qout(B, γ, wB )) + ξ(k−1) − V (k−1)(B)

a(k)

γ

out

relay

Λ[0,A1] ξo(ku−t 1) + β(Q(oNutk,Nk−1) − qUNk ) − ξo(ku−t 1)

ξo(ku)t = ξo(ku−t 1) + I{Nk = Nk−1 + 1} b(Nk) lim

+ o(b(Nk))

β↓0

β

(k−1)

b(Nk )

Λ[0,A1] ξo(ku−t 1) + β(Q(oNutk,Nk−1) − qUNk ) − ξo(ku−t 1) o(b(Nk))

= ξout + I{Nk = Nk−1 + 1}a(k) a(k) βli↓m0 β + b(Nk)

Λ[0,A2] ξr(kel−a1y) + β(1 − N UNk ) − ξr(kel−a1y)

ξr(kel)ay = ξr(kel−a1y) + I{Nk = Nk−1 + 1} b(Nk) lim

+ o(b(Nk))

β↓0

β

b(N )

Λ[0,A2] ξr(kel−a1y) + β(1 − N UNk ) − ξr(kel−a1y) o(b(N ))

= ξr(kel−a1y) + I{Nk = Nk−1 + 1}a(k) k lim

+

k

(13)

a(k) β↓0

β

b(Nk )

EW min minγ (γ + ξoutQout(r, γ, W )) + ξrelay, −V (1) +

V (r+1) −V (r) and fB(V , ξout, ξrelay) = EW minγ (γ +

ξoutQout(B, γ, W )) + ξrelay − V (B) are Lipschitz con-
tinuous in all arguments (by Theorem 5), and the collection of o.d.e. V˙ r(t) = κt(r)fr(V (t), ξout, ξrelay) for all r ∈ {1, 2, · · · , B} (see [37, Theorem 2, Chapter 7] and the proof of Theorem 7 for an interpretation of κt(r)) has a unique globally asymptotically stable equilibrium V ∗(ξout, ξrelay) for any ξout ≥ 0, ξrelay ≥ 0 (see Lemma 1 in the proof of Theorem 7). Also, by Theorem 5, V ∗(ξout, ξrelay) is Lipschitz continuous in ξout and ξrelay. On the other hand, by Lemma 3 and the projection in the slower timescale, the iterates are almost surely bounded.
Hence, by a similar argument as in the proof [37, Lemma 1, Chapter 6], and by Theorem 7, (V (k), ξo(ku)t, ξr(kel)ay) converges to the internally chain transitive invariant sets of the collection of o.d.e. given by V˙r(t) = κt(r)fr(V (t), ξout, ξrelay) for all r ∈ {1, 2, · · · , B}, ξ˙out(t) = 0, ξ˙relay(t) = 0 (where V (t) := {V1(t), V2(t), · · · , VB(t)}). Hence, (V (k), ξo(ku)t, ξr(kel)ay) → {(V ∗(ξout, ξrelay), ξout, ξrelay) : (ξout, ξrelay) ∈ [0, A1] × [0, A2]} and limk→∞ ||V (k) − V ∗(ξo(ku)t, ξr(kel)ay)|| = 0.
Remark: Lemma 4 does not guarantee the convergence of the slower timescale iterates.

C.2.2 The slower timescale iteration

We will pose the slower timescale update as a projected

stochastic approximation (see [39, Equation 5.3.1]). In

order to do that and to avoid complicated notation, for the rest of this appendix we will denote by V (k), ξo(ku)t and ξr(kel)ay the values of the corresponding variable after

placing the k-th relay and performing the update (ear-

lier they were deﬁned to be the iterates after a decision

is made at the k-th step). Let us also recall the deﬁnition

∗

∗

of the functions Qout(·, ·, ·), Qout(·, ·), U (·, ·, ·), U (·, ·).

Let us deﬁne the functions Qout(V (k−1), ξo(ku−t 1), ξr(kel−a1y))

and U (V (k−1), ξo(ku−t 1), ξr(kel−a1y)) to be the mean link outage and mean length of the k-th link that is created by Algorithm 3 (using the two-timescale update) starting with V (k−1), ξo(ku−t 1) and ξr(kel−a1y) (which are obtained by the algorithm after placing the (k − 1)-st relay and and doing the learning/update operation; note that, these quantities are obtained after placing (k − 1) nodes and not at the (k − 1)-th step).
The difference between U (V (k−1), ξo(ku−t 1), ξr(kel−a1y)) and U (V (k−1), ξo(ku−t 1), ξr(kel−a1y)) can be explained as follows. U (V (k−1), ξo(ku−t 1), ξr(kel−a1y)) is the mean length of the k-th link where no quantity is updated in the process of measurements made to create the k-th link; hence, U (V (k−1), ξo(ku−t 1), ξr(kel−a1y)) is the mean placement distance of a stationary policy which is similar to Algorithm 1 except that ξout, ξrelay and V ∗ are replaced by ξo(ku−t 1), ξr(kel−a1y) and V (k−1) respectively. On the other hand, U (V (k−1), ξo(ku−t 1), ξr(kel−a1y)) is the mean length of the k-th link created under Algorithm 3 (with (V (k−1), ξo(ku−t 1), ξr(kel−a1y)) as starting parameters), where the iterates are updated at each step between placement of the (k − 1)-th node and the k-th node.
Let us denote by G the set [0, A1] × [0, A2], deﬁned by the following constraints:
−ξout ≤ 0, ξout ≤ A1, −ξrelay ≤ 0, ξrelay ≤ A2 (15)
Clearly, projection onto the set G is nothing but coordinate wise projection.
We rewrite the slower timescale iteration in (10) as (14) (note the deﬁnitions of the functions f1(ξout, ξrelay), f2(ξout, ξrelay), g1(V , ξout, ξrelay), g2(V , ξout, ξrelay), l1(V , ξout, ξrelay) and l2(V , ξout, ξrelay) in (14)). The random variables M1(k) and M2(k) are two zero mean Martingale difference noise sequences w.r.t. Fk−1 (information available up to the (k − 1)-st placement instant); this happens due to i.i.d. shadowing across links.
(14) has the form of a projected stochastic approximation (see [39, Equation 5.3.1]). In order to show the desired conver-

22

ξo(ku)t = ΛG ξo(ku−t 1) + b(k) Qout(Uk, Γk, WUk ) − qUk

= ΛG ξo(ku−t 1) + b(k) Q∗out(ξo(ku−t 1), ξr(kel−a1y)) − qU ∗(ξo(ku−t 1), ξr(kel−a1y))

:=f1(ξo(ku−t 1),ξr(ke− la1y))
+ Qout(V (k−1), ξo(ku−t 1), ξr(kel−a1y)) − qU (V (k−1), ξo(ku−t 1), ξr(kel−a1y)) − f1(ξo(ku−t 1), ξr(kel−a1y))

:=g1(V (k−1),ξo(ku−t 1),ξr(ke− la1y))
+ Qout(V (k−1), ξo(ku−t 1), ξr(kel−a1y)) − qU (V (k−1), ξo(ku−t 1), ξr(kel−a1y)) −

Qout(V (k−1), ξo(ku−t 1), ξr(kel−a1y)) − qU (V (k−1), ξo(ku−t 1), ξr(kel−a1y))

+ Qout(Uk, Γk, WUk ) − qUk −

:=l1(V (k−1),ξo(ku−t 1),ξr(ke− la1y))
Qout(V (k−1), ξo(ku−t 1), ξr(kel−a1y)) − qU (V (k−1), ξo(ku−t 1), ξr(kel−a1y))

:=M1(k)
= ΛG ξo(ku−t 1) + b(k) f1(ξo(ku−t 1), ξr(kel−a1y)) + g1(V (k−1), ξo(ku−t 1), ξr(kel−a1y)) + l1(V (k−1), ξo(ku−t 1), ξr(kel−a1y)) + M1(k)
ξr(kel)ay = ΛG ξo(ku−t 1) + b(k) 1 − N Uk = ΛG ξr(kel−a1y) + b(k) 1 − N U ∗(ξo(ku−t 1), ξr(kel−a1y))
:=f2(ξo(ku−t 1),ξr(ke− la1y))
+ 1 − N U (V (k−1), ξo(ku−t 1), ξr(kel−a1y)) − f2(ξo(ku−t 1), ξr(kel−a1y))
:=g2(V (k−1),ξo(ku−t 1),ξr(ke− la1y))
+ 1 − N U (V (k−1), ξo(ku−t 1), ξr(kel−a1y)) − 1 − N U (V (k−1), ξo(ku−t 1), ξr(kel−a1y))

+ 1 − N Uk −

:=l2(V (k−1),ξo(ku−t 1),ξr(ke− la1y))
1 − N U (V (k−1), ξo(ku−t 1), ξr(kel−a1y))

:=M2(k)
= ΛG ξr(kel−a1y) + b(k) f2(ξr(kel−a1y), ξr(kel−a1y)) + g2(V (k−1), ξr(kel−a1y), ξr(kel−a1y)) + l2(V (k−1), ξo(ku−t 1), ξr(kel−a1y)) + M2(k)

(14)

gence of the iterates in (14), we will use [39, Theorem 5.3.1]; this requires us to check ﬁve conditions from [39], which is done in the next subsection.

C.2.3 Checking the ﬁve conditions from [39]

We will ﬁrst present a lemma that will be useful for

checking one condition.

Lemma 5: Under Assumption 2, the quan-

tities Γ(V , ξout, ξrelay), Qout(V , ξout, ξrelay) and

U (V , ξout, ξrelay) are continuous in V , ξout and ξrelay.

Proof: The proof is similar to that of Theorem 8.

Now, we will check conditions A5.1.3, A5.1.4, A5.1.5,

A5.3.1. and A5.3.2 from [39].

Checking Condition A5.1.3: We need f1(·, ·) and f2(·, ·)

to be continuous functions; this holds by Theorem 8.

Checking Condition A5.1.4: This condition is satisﬁed

by the choice of the sequence {b(k)}k≥1.

Checking Condition A5.1.5: This condition

requires that limk→∞ g1(V (k−1), ξo(ku−t 1), ξr(kel−a1y)) =

0, limk→∞ g2(V (k−1), ξo(ku−t 1), ξr(kel−a1y))

=

0,

limk→∞ l1(V (k−1), ξo(ku−t 1), ξr(kel−a1y))

=

0

limk→∞ l2(V (k−1), ξo(ku−t 1), ξr(kel−a1y)) = 0 almost surely.

and

We can ﬁnd a probability 1 subset of the sample

space Ω, such that for any sample path in this subset

the conclusions of Lemma 3 and Lemma 4 hold. Take

one such sample path ω. By Lemma 3, for this sam-

ple path ω, we can ﬁnd a compact subset C ⊂ RB such that (V (k), ξo(ku)t, ξr(kel)ay) lies inside the compact set

C × [0, A1] × [0, A2] for all k ≥ 1 along this sample path.

By Lemma 5 and the fact that continuous functions

are uniformly continuous over compact sets, we

can say that Qout(V , ξout, ξrelay), Γ(V , ξout, ξrelay)

and U (V , ξout, ξrelay) are uniformly continuous

over the compact set C × [0, A1] × [0, A2]. Now, the Euclidean distance between (V (k), ξo(ku)t, ξr(kel)ay) and (V ∗(ξo(ku)t, ξr(kel)ay), ξo(ku)t, ξr(kel)ay) converges to 0 along

the sample path ω. Hence, by uniform continuity,

we can say that limk→∞ |Qout(V (k), ξo(ku)t, ξr(kel)ay) −

Qout(V ∗(ξo(ku)t, ξr(kel)ay), ξo(ku)t, ξr(kel)ay)|

=

0

and

limk→∞ |U (V (k), ξo(ku)t, ξr(kel)ay)

−

23

U (V ∗(ξo(ku)t, ξr(kel)ay), ξo(ku)t, ξr(kel)ay)| = 0 along this sample path ω. Hence, limk→∞ g1(V (k−1), ξo(ku−t 1), ξr(kel−a1y)) = 0 and limk→∞ g2(V (k−1), ξo(ku−t 1), ξr(kel−a1y)) = 0 almost surely.

On the other hand, since C is bounded, we can say that {V (k)}k≥1 is bounded for the chosen ω. In a similar way

as in the proof of Theorem 8, in case of Lemma 5 we can

show that g(r, γ) is continuous in V , ξout and ξrelay. Now,

between the placement of the (k − 1)-st relay and k-th

relay, at each step, g(r, γ) for all r ∈ {1, 2, · · · , B}, γ ∈ S

can change at most by an amount K∗a(k − 1 − B)

(for a suitable constant K∗ > 0), and hence we can claim that limk→∞ |U (V (k−1), ξo(ku−t 1), ξr(kel−a1y)) −

U (V (k−1), ξo(ku−t 1), ξr(kel−a1y))|

=

0,

limk→∞ |Qout(V (k−1), ξo(ku−t 1), ξr(kel−a1y))

−

Qout(V (k−1), ξo(ku−t 1), ξr(kel−a1y))| = 0. Hence, we obtain

that limk→∞ l1(V (k−1), ξo(ku−t 1), ξr(kel−a1y)) = 0 and

limk→∞ l2(V (k−1), ξo(ku−t 1), ξr(kel−a1y)) = 0.

Also,

g1(V (k), ξo(ku)t, ξr(kel)ay),

g2(V (k), ξo(ku)t, ξr(kel)ay),

l1(V (k), ξo(ku)t, ξr(kel)ay) and l2(V (k), ξo(ku)t, ξr(kel)ay) are uniformly

bounded across k ≥ 1, since the outage probabilities

and placement distances are bounded quantities.

Hence, this condition is satisﬁed.

Checking Condition A5.3.1: This condition is easy to

check, and done in [1, Appendix E, Section C4].

Checking Condition A5.3.2: This condition is easy to

check, and done in [1, Appendix E, Section C4].

where kδ can be the distance from the sink or k can be the index of a placed relay node (the result holds for both interpretations of k). This completes the proof of Theorem 9.

C.2.4 Finishing the Proof of Theorem 9

Consider the function

, f1(ξout,ξrelay )
U ∗(ξout,ξrelay )

f2(ξout,ξrelay ) U ∗(ξout,ξrelay )

h(ξout, ξrelay)

:=

= − Q∗out(ξout,ξrelay )
U ∗(ξout,ξrelay )

q, ∗ 1

−N

U (ξout,ξrelay )

and the map:

ΛG (h(ξout, ξrelay ))

ΛG (ξout, ξrelay ) + βh(ξout, ξrelay )) − (ξout, ξrelay )

= lim

0<β→0

β

(16)

Lemma 6: If (ξout, ξrelay) ∈ [0, A1] × [0, A2] is
a zero of Λ , , then f1(ξout,ξrelay) f2(ξout,ξrelay)
G U ∗(ξout,ξrelay ) U ∗(ξout,ξrelay )
(V ∗(ξout, ξrelay), ξout, ξrelay) ∈ K(q, N ), provided that A1 and A2 are chosen using the procedure described in Section 5.
Proof: The proof is similar to the proof of [1, Lemma 9, Appendix E, Section C5].
Now, by using similar arguments as in [1, Appendix E, Section C5] and using [39, Theorem 5.3.1], We can show that the iterates (ξo(ku)t, ξr(kel)ay) will converge almost surely to the set of stationary points of the o.d.e. (ξ˙out(t), ξ˙relay(t)) =
Λ , . f1(ξout(t),ξrelay (t)) f2(ξout(t),ξrelay (t))
G U ∗(ξout(t),ξrelay (t)) U ∗(ξout(t),ξrelay (t))
Using this result and using Lemma 4 and Lemma 6, we obtain that (V (k), ξo(ku)t, ξr(kel)ay) → K(q, N ) almost surely,

