Function Design for Improved Competitive Ratio in Online Resource Allocation with Procurement Costs
Mitas Ray†‡ Omid Sadeghi† Lillian J. Ratliﬀ† Maryam Fazel†

arXiv:2012.12457v1 [math.OC] 23 Dec 2020

Abstract
We study the problem of online resource allocation, where multiple customers arrive sequentially and the seller must irrevocably allocate resources to each incoming customer while also facing a procurement cost for the total allocation. Assuming resource procurement follows an a priori known marginally increasing cost function, the objective is to maximize the reward obtained from fulﬁlling the customers’ requests sans the cumulative procurement cost. We analyze the competitive ratio of a primal-dual algorithm in this setting, and develop an optimization framework for synthesizing a surrogate function for the procurement cost function to be used by the algorithm, in order to improve the competitive ratio of the primal-dual algorithm.
Our ﬁrst design method focuses on polynomial procurement cost functions and uses the optimal surrogate function to provide a more reﬁned bound than the state of the art. Our second design method uses quasiconvex optimization to ﬁnd optimal design parameters for a general class of procurement cost functions. Numerical examples are used to illustrate the design techniques. We conclude by extending the analysis to devise a posted pricing mechanism in which the algorithm does not require the customers’ preferences to be revealed.

1 Introduction

In the problem of online resource allocation, a seller is allocating D types of resources to T incoming customers. The t-th customer has a payment function, denoted vt : RD+ → R+, which satisﬁes a natural set of assumptions listed in Assumption 3.1. The payment function reveals how much a customer will pay for any assigned bundle of resources. The seller has a procurement cost function, denoted by f : RD+ → R+, which represents the cost incurred by the seller in procuring the resources in the cumulative allocation, and is known to the seller a priori. The procurement cost function satisﬁes Assumption 3.2. We use xt ∈ [0, 1]D to denote the bundle allocated to customer t, where the d-th entry of xt represents the amount of the d-th type of resource in this bundle. The goal of the seller is to maximize the revenue collected from the assigned
bundles to the customers minus the procurement cost of the cumulative allocation. Had the seller known the
T customers’ payment functions beforehand, then the optimal allocation would be the result of the following
oﬄine optimization problem:

maximize

T t=1

vt(xt)

−

f

T t=1

xt

,

subject to 0 xt 1 ∀ t ∈ [T ]

(P-1)

where xt ∈ [0, 1]D for t = 1, . . . , T is the optimization variable. The challenge of online resource allocation comes from its online nature; the seller does not have any knowledge of the future customers and the seller must make an irrevocable allocation upon the arrival of each customer.
Online resource allocation has been studied extensively in the setting of ﬁxed resource capacities [BN07, BBM08, CHK13], where there is a hard budget on each type of resource, and the unlimited supply setting [BBHM05, BBM08], where the seller has unlimited access to each resource type. However, in many real-world situations, additional resources may be procured albeit at increasing marginal costs, such as energy costs for

†Department of Electrical & Computer Engineering, University of Washington ‡mitasray@uw.edu

1

running computer processors [MS14, AAZ16] and hiring costs for skilled labor [BMS12]. This motivates the problem of online resource allocation with procurement costs [BGMS11].
Past literature [BGMS11, HK18] considers the procurement cost function to be separable—i.e., the total cost incurred is the sum of the individual procurement costs for each resource. The work of [BGMS11], which was further tightened in [HK18], propose an online mechanism in which the seller determines the price of a particular item as a function of how much has already been sold, and the customer then chooses the bundle that maximizes their valuation function. In both works, it is assumed that the procurement cost function is separable, and so the cost of producing one item, has no eﬀect on the cost of producing another. However, in a real-world setting there may exist limited procurement infrastructure where procuring one resource would increase the cost of procuring another. It is important then, to generalize this setting and consider procurement cost functions that are non-separable.
While the work of [CHK15] studies the setting of non-separable procurement costs, the assumptions that the authors make essentially restricts the procurement cost function to polynomials. Therefore, the class of separable procurement cost functions has not been truly generalized, and there is no strategy on how to handle procurement cost functions which do not meet their stringent assumptions. We, on the other hand, in Theorem 3, drop the assumptions that restrict the function class to polynomials allowing us to consider general non-separable procurement cost functions.
Many algorithms in this setting are primal-dual algorithms, which comes from updating the dual variable at each time step and using it to assign the primal variable [BJN07, BN09, DJ12, AWY14, ABC+16, EF16]. One measure of algorithm performance in online optimization is the competitive ratio, which is deﬁned as the ratio of the objective value achieved by the algorithm to the oﬄine optimum (see Section 3.1). The competitive ratio we consider is under the adversarial arrival order, where the seller has no knowledge of the arriving customers or the order of their arrival. For more details on diﬀerent arrival models, we refer readers to Section 2.2 in [Meh13].
The problem of online resource allocation appears often in the operations research community for problems like airline revenue management [HJM18, JL12], hospital appointment scheduling [LJ13, EGD15], and bidding in auctions [BHP09], amongst others. Many of the underlying assumptions in these problems, are diﬀerent however, from the ones we make in our setting. For example, [HJM18] considers the arrival time of a fraction of agents to be chosen by an adversary, while the remaining agents come at random times. The optimization problems are also formulated diﬀerently for each setting; for example, [LJ13] considers a linear objective with budget constraints. Nonetheless, these setups encourage us to scrutinize our assumptions in order to capture many problem settings. Section 1.3 enumerates a few motivating applications of the framework proposed in this paper. For more details on related work, see Section 8.
1.1 Contributions
We analyze a greedy primal-dual algorithm, formalized in Algorithm 1 in which a surrogate function is used in place of the known procurement cost function in order to optimize the performance of the algorithm. We discuss a simple example in Section 6 to show that the competitive ratio of the greedy primal-dual algorithm without a surrogate function approaches zero asymptotically, illustrating the necessity of a surrogate function. Our main contributions come in the design of the surrogate function.
• For polynomial procurement cost functions, we design a surrogate function to be used in the algorithm that achieves a better competitive ratio than the state of the art result in [CHK15]. Furthermore, due to a lower bound result in [HK18] (Theorem 10), we know that our result is tight. Our result is stated formally in Theorem 2.
• For general procurement cost functions, we write the surrogate function design problem as a quasiconvex optimization problem in which the optimization variables deﬁne the function. This strategy comes from adopting an optimization perspective for maximizing the competitive ratio similar to [EF16]. This technique allows us to construct surrogate functions for a wide class of procurement cost functions beyond those that are separable [HK18] and polynomial [CHK15]. Our result is stated formally in Theorem 3.
• We propose Algorithm 2 which computes the primal and dual variables one after the other, as opposed
2

to solving a saddle-point problem, as does Algorithm 1. We extend the quasiconvex surrogate function design technique to this algorithm. Our results are stated formally in Theorems 5 and 7.
We complement our theoretical results with simulations in which we implement our design techniques on a numerical example and better performance over the current state of the art.
1.2 Organization
This paper is organized as follows. We close this section with a few motivating examples to show the generality of our framework. Then, we discuss preliminaries on convex optimization in Section 2. We introduce the formal problem statement and primal-dual algorithm in Section 3. We analyze the competitive ratio for our primal-dual algorithm in Section 4. We then propose our surrogate function design techniques in Section 5. In Section 6, we implement our design techniques on a numerical example. In Section 7, we extend the competitive analysis and design techniques to another primal-dual algorithm which computes the primal and dual variables sequentially.
1.3 Motivating Examples
To illustrate applicability, we provide a number of online resource allocation problems which can be cast in the proposed framework described in Problem (P-1). In each application, we describe the incoming valuation functions, vt, and the cost function, f . We also describe what our decision vector at time t—i.e., xt, represents.
Online auction. A seller has a set of D items and T customers arrive sequentially. Let xt ∈ [0, 1]D represent the decision vector at time t representing the bundle allocated to customer t. Each item can be included in a bundle a maximum of once. Hence, the decision vector is constrained to 0 xt 1. The payment function vt : RD+ → R+ is revealed by the t–th customer upon arrival. The procurement function is denoted f : RD+ → R+. The objective of the seller is to maximize their proﬁt—i.e., the sum of the payments of the customers minus the procurement cost of the total allocation. Variations of this framework are discussed in [BGN03, CHK15, HK18].
Data market. A manager supervises a set of D experts with diﬀering expertise. Data analysis tasks, such as classifying medical images, arrive online sequentially and each task can be assigned to any subset of the experts. Upon arrival, task t reveals a vector ct where [ct]d quantiﬁes the value that expert d would provide the manager if assigned to task t. The value function is linear—i.e., vt(xt) = ct xt. When a task is assigned to an expert, the amount of time they are being paid to spend on it is bounded. Therefore, the decision vector is constrained to 0 xt 1. The manager is responsible for paying for the experts’ time and the resources needed for the experts to do their work, which is captured in a cost function f : RD+ → R+. The cost of hiring skilled labor is marginally increasing and follows a convex cost function [BMS12]. The objective of the manager is to maximize the value of the completed work minus the cost of getting the work completed. Variations of this application are mentioned in [HV12].
Network routing with congestion. A network routing agent has a set of D pairs of terminals and T users arrive online with valuation functions over these routed connections. Since each pair of terminals can be assigned to a user at most once, the decision vector xt is constrained to 0 xt 1. Let vt : RD+ → R+ represent the payment function that each customer reveals upon arrival and let f : RD+ → R+ denote the congestion cost function which can represent the energy needed to maintain the routed connections. Since energy usage follows dis-economies of scale—i.e., energy usage is super-linear in terms of processor speed [MS14, AAZ16], f satisﬁes Assumption 3.2. The objective of the network routing agent is to maximize the valuations of the customers minus the energy costs of the cumulative assignment. Variations of this framework are discussed in [BGMS11].
3

2 Preliminaries

In this section, we review mathematical preliminaries as needed for the technical results. Throughout, we will use boldface symbols to denote vectors. For a D-dimensional vector u ∈ RD, let ui,
or equivalently [u]i, denote the i-th entry. The inner product of two vectors u, v ∈ RD is denoted u, v or, equivalently, u v. The generalized inequality with respect to the non-negative orthant is denoted u v,
and is equivalent to ui ≥ vi for all i. Deﬁne 1[u v] to be the vector where the i-th entry equals one if ui ≥ vi and zero otherwise.
Several function properties are need for the analysis in this paper. A function f : RD → R is separable if it can be written as
D
f (u) = fi(ui) .
i=1
A function f : RD → R is convex if dom(f ) is a convex set and for all u, v ∈ dom(f ),

f (θu + (1 − θ) v) ≤ θf (u) + (1 − θ) f (v)

for any θ ∈ [0, 1]. A function f : RD → R is quasiconvex if dom(f ) is a convex set and for each α ∈ R, the sub-level set, Sα = {u ∈ dom(f ) | f (u) ≤ α} is a convex set. A function f : RD → R is closed if for each
α ∈ R, the sub-level set, Sα, is a closed set. Given a function f : RD → R, its convex conjugate f ∗ : RD → R is deﬁned be

f ∗(v) = sup v u − f (u) .
u

For any function f and its convex conjugate f ∗, the Fenchel-Young inequality holds for every u, v ∈ RD:

f (u) + f ∗(v) ≥ u v.

(1)

For a diﬀerentiable, closed and convex function f , its gradient is given by ∇f (u) = arg minv v u − f ∗(v), and furthermore, f ∗∗ = f . Letting v = ∇f (u), the Fenchel-Young inequality holds with equality:

f (u) + f ∗(∇f (u)) = u ∇f (u) .

(2)

Similarly, given a function g : RD → R, the concave conjugate g∗ : RD → R is deﬁned by

g∗(v) = inf v u − g(u) .
u
An analogous inequality to (1) holds: g(u) + g∗(v) ≤ u v for all u, v ∈ RD. For a diﬀerentiable, closed and concave function g, its gradient is given by ∇g(u) = arg maxv v u − g∗(v) and, furthermore, g∗∗ = g. Again, with v = ∇g(u), Fenchel-Young inequality with equality:

g(u) + g∗(∇g(u)) = u ∇g(u) .

(3)

Finally, the index set {1, . . . , K} is denoted [K].

3 Problem Statement
To begin this section, we formalize the problem statement described in Section 1 by explicitly describing the online and oﬄine components as well as the assumptions made on the payment functions of the customers and the procurement cost function of the seller.
As described in Section 1, had the seller known all the customers that were to arrive, they would solve Problem (P-1) to obtain the optimal allocation to make to each customer. We denote the optimal value of Problem (P-1) as P . However, the challenge faced by the seller is that they have no knowledge of future customers, and so the seller must make decisions that trade oﬀ making a hefty proﬁt now with saving resources to potentially make a larger proﬁt later. The seller knows the procurement cost function, f , prior to any customers arriving. Upon arrival, the customer reveals their payment function, vt, and the seller must then make an irrevocable allocation before interacting with the next customer. In Section 7, we discuss an algorithm which does not require the customer to reveal their payment function. We have the following assumptions on the payment function of each customer.

4

Assumption 3.1. The function vt : RD+ → R+ satisﬁes the following:

1. vt is concave, diﬀerentiable, and closed. 2. vt is increasing; i.e., u v implies that vt(u) ≥ vt(v). 3. vt(0) = 0.

Concavity in Assumption 3.1(1) comes from the idea that a customer is willing to pay marginally less for a larger bundle, which comes from the natural desire for the customer to receive a bulk discount. Assumption 3.1(2) reﬂects the customer’s willingness to pay more for a larger bundle and Assumption 3.1(3) states that a customer would pay nothing for an empty bundle.
The procurement cost function satisﬁes the following assumptions.

Assumption 3.2. The function f : RD+ → R+ satisﬁes the following:

1. f is convex, diﬀerentiable, and closed. 2. f is increasing; i.e., u v implies that f (u) ≥ f (v). 3. f has an increasing gradient; i.e., u v implies that ∇f (u) 4. f (0) = 0.

∇f (v).

Convexity in Assumption 3.2(1) along with Assumption 3.2(3) captures the idea that procuring scarce resources comes at an increasing marginal cost. Assumption 3.2(2) comes from a larger cumulative allocation incurring a larger production cost and Assumption 3.2(4) states that the seller incurs no cost for allocating nothing.

3.1 Performance Metric

The performance of an algorithm making allocations in this setting is evaluated by its competitive ratio. The competitive ratio is the ratio of the objective value achieved by the algorithm to the oﬄine optimum for all possible instances. We provide the formal deﬁnition below.

Deﬁnition 3.1 (Competitive Ratio). Consider the set of decision vectors produced by an algorithm, ALG,
as {x¯t}Tt=1 and the oﬄine optimal decision vector that achieves P from Problem (P-1) as {xt }Tt=1. Then, ALG has a competitive ratio of α if

ALG

α≤

=

P

T t=1

vt

(x¯t

)

−

f

T t=1

vt(xt

)

−

f

T t=1

x¯t

T t=1

xt

for all {vt}Tt=1. Note that α ∈ [0, 1] and the closer to 1, the better the algorithm.

3.2 Primal-Dual Algorithm

We now present the primal-dual algorithm for the online optimization problem with procurement costs. We ﬁrst formulate the dual of (P-1) which is given by

TD

T

D := minimize

max{[zt]d − [λ]d , 0} − vt∗(zt) + f ∗(λ) .

λ 0,zt 0

t=1 d=1

t=1

(D-1)

From the computation of (D-1)—which is given in Appendix A—we develop an algorithm in which a greedy solution is obtained at time t given previous decisions. The greedy solution solves a marginal optimization problem for the t-th time step considering that decisions for time steps [t − 1] have already been made. Let x¯i denote the decision made by an algorithm at time i. The greedy solution at time t is the result of

t−1

t−1

maximize vt(xt) − f

x¯i + xt + f

x¯i .

0 xt 1

i=1

i=1

(M-1)

5

The objective of (M-1) represents the gain in the objective of (P-1) at time t if we make decision xt, since the decisions {x¯i}ti=−11 have already been made and cannot be changed. From Assumption 3.2(1), we know that f = f ∗∗, and from Assumption 3.1(1), we know that vt = vt∗∗, which allows us to re-write (M-1) as

maximize minimize zt xt − vt∗(zt) − λ
0 xt 1 λ 0,zt 0

t−1

t−1

x¯i + xt + f ∗(λ) + f

x¯i .

i=1

i=1

(M-2)

A greedy algorithm using this decision rule makes an allocation at time t based on the incoming vt, the previous decisions made, and f . In order to improve the performance of this algorithm with unknown future functions vt, we ask the following question: can we design a surrogate function such that decisions made with respect to this function give a better competitive ratio for our original problem? Consider the following optimization problem, with the surrogate function denoted by fs,

maximize

T t=1

vt(xt)

−

fs

T t=1

xt

,

subject to 0 xt 1 ∀ t ∈ [T ]

(P-2)

where xt ∈ [0, 1]D is the optimization variable and vt : RD+ → R+ satisﬁes Assumption 3.1. The only diﬀerence between Problem (P-1) and Problem (P-2) is that f has been replaced by fs, which satisﬁes the
following assumptions.

Assumption 3.3. The function fs : RD+ → R+ satisﬁes the following:

1. fs is convex, diﬀerentiable, and closed. 2. fs is increasing; i.e., u v implies fs(u) ≥ fs(v). 3. fs has an increasing gradient; i.e., u v implies ∇fs(u) 4. fs(0) = 0. 5. fs(u) ≥ f (u) for all 0 u T 1.

∇fs(v).

Assumptions 3.3(1)-(4) are identical to Assumptions 3.2(1)-(4). Assumption 3.3(5) is designed to make sure the resulting algorithm makes allocations more cautiously than the greedy algorithm without a surrogate function in order to best handle the uncertainty of the future customers. A simple example to illustrate this intuition is provided in Section 6. We discuss our choice of the surrogate function in more detail in Section 5.
Using the same strategy as above of writing the marginal optimization problem, now with respect to Problem (P-2), we can write the decision rule of Algorithm 1.

Algorithm 1: Simultaneous Update

Input: fs : RD → R 1 for t = 1, . . . , T do

2 receive vt;

3

λ¯t, z¯t, x¯t = arg min max zt xt − vt∗(xt) − λ

λ 0,zt 0 0 xt 1

t−1 i=1

x¯i

+

xt

+ fs∗(λ);

Line 3 in Algorithm 1, the main computational step of the algorithm, involves solving a (convex-concave) saddle-point problem. We point out that standard convex optimization methods (see, e.g., [Bub15]) can be used to solve this subproblem with desired accuracy, and the complexity analysis of these methods (number of iterations needed to reach -optimality) can be incorporated in the overall computational complexity analysis of our algorithm. In Section 7, we discuss an algorithm that computes the primal and dual variables sequentially.
In the remainder of this section, let x¯t denote the decision vector at time t given from Algorithm 1 called with fs. Algorithm 1 called with fs ensures that at every time step t,

x¯t = 1 z¯t − λ¯t 0 ,

(4)

6

where λ¯t = ∇fs

t i=1

x¯i

and z¯t = ∇vt(x¯t).

The superscript notation of s—taken from surrogate—denotes the objective of Problem (P-1) resulting

from the decision vectors coming from Algorithm 1 called with fs. The primal objective is given by

T

T

P s := vt(x¯t) − f

x¯t ,

(5)

t=1

t=1

and the dual objective is given by

TD

T

Ds :=

max [z¯t]d − λ¯t d , 0 − vt∗(z¯t) + f ∗ λ¯T .

(6)

t=1 d=1

t=1

These equations are used in the analysis of Algorithm 1 in Section 4.

4 Competitive Ratio Analysis for a Primal-Dual Algorithm

In this section, we bound the competitive ratio of Algorithm 1 called with fs in Theorem 1. In order to do this, we ﬁrst show that Algorithm 1 called with fs does not make a decision which causes the objective to become negative.

Lemma 1. If fs is convex and diﬀerentiable and fs(0) = 0, then

T
vt(x¯t) − fs
t=1

T
x¯t
t=1

≥ 0.

Proof. We upper bound this expression by incorporating the decision rule of Algorithm 1 called with fs as follows:

T
vt(x¯t) − fs
t=1

T
x¯t
t=1

(a) T
≥ ∇vt(x¯t) xt − fs

T
x¯t

t=1

t=1

T (b)
=

∇vt(x¯t) xt − fs

t
x¯i + fs

t=1

i=1

(c) T
≥

∇vt(x¯t) − ∇fs

t
x¯i , x¯t .

t=1

i=1

t−1
x¯i
i=1

Inequality (a) comes from concavity of vt. Equality (b) comes from writing fs(

T t=1

x¯t)

as

a

telescoping

sum with the assumption that fs(0) = 0. Inequality (c) follows from convexity of fs. Finally, the decision rule of Algorithm 1—i.e., x¯t = 1 z¯t − λ¯t 0 —called with fs ensures that the inner product is always

non-negative.

Now, we bound the competitive ratio of Algorithm 1 called with fs.

Theorem 1. Suppose that fs : RD → R satisﬁes Assumption 3.3. The competitive ratio of Algorithm 1 (called with fs) is bounded by 1/αf,fs where

f ∗(∇fs(u))

αf,fs

:=

0

sup
u T1

. fs(u) − f (u)

Proof. The general overview of the proof is as follows: writing Ds (6) in terms of P s (5), we bound the gap between Ds and P s. From here, we lower bound Ds by D (D-1), which in turn allows us to use weak
duality to relate D and P .

7

We start with writing Ds in terms of P s:

TD

Ds =

max

t=1 d=1

[z¯t]d −

λ¯t d , 0

T
− vt∗(z¯t) + f ∗ λ¯T
t=1

T (a)
=

z¯t − λ¯t

T
x¯t − vt∗(z¯t) + f ∗ λ¯T

t=1

t=1

T (b)
= ∇vt(x¯t)
t=1

T
x¯t − ∇fs
t=1

t
x¯i
i=1

T
x¯t − vt∗(z¯t) + f ∗ λ¯T .
t=1

Equality (a) comes from the decision rule of Algorithm 1 called with fs, which ensures that x¯t = 1 z¯t − λ¯t 0 .

Equality (b) comes from replacing λ¯t with ∇fs

t i=1

x¯i

and z¯t with ∇vt(x¯t). Now, we proceed to bound

the duality gap between Ds and P s by ﬁrst observing the following relationship:

(c) T
Ds ≤ ∇vt(x¯t) x¯t − fs

T

T

x¯t − vt∗(z¯t) + f ∗ λ¯T

t=1

t=1

t=1

T (d)
= ∇vt(x¯t) x¯t − fs

T

T

x¯t −

∇vt(x¯t) x¯t − vt(x¯t) + f ∗ λ¯T

t=1

t=1

t=1

T
= vt(x¯t) − fs

T
x¯t + f ∗ λ¯T + f

T
x¯t − f

T
x¯t

t=1

t=1

t=1

t=1

(e)
=

P

s

−

fs

T
x¯t + f ∗ λ¯T + f

T
x¯t .

t=1

t=1

Inequality (c) follows directly from convexity of fs. Equality (d) comes from the concave Fenchel-Young

inequality—i.e., equation (3) with g = vt and u = x¯t. Equality (e) follows by substituting the deﬁnition of

Ps =

T t=1

vt

(x¯t

)

−

f

(

T t=1

x¯t)

where

in

the

preceding

equality

we

add

and

subtract

f

(

T t=1

x¯t

).

We

bound

the gap between Ds and P s as a multiplicative factor of P s in order to relate these quantities as a ratio:

fs

T t=1

x¯t

− f ∗ λ¯T

−f

T t=1

x¯t

(f) fs

T t=1

x¯t

− f ∗ ∇fs

T t=1

x¯t

−f

T t=1

x¯t

=

Ps

T vt(x¯t) − f T x¯t

t=1

t=1

(g) fs ≥

T t=1

x¯t

− f ∗ ∇fs

T t=1

x¯t

−f

fs

T t=1

x¯t

−f

T t=1

x¯t

T t=1

x¯t

(h)

fs(u) − f ∗(∇fs(u)) − f (u)

≥ inf
0 u T1

fs(u) − f (u)

=: βf,fs .

In equality (f), we replace λ¯T with ∇fs(

follows from observing that 0

T t=1

x¯t

T i=1

x¯i

).

Inequality

(g)

follows

from

Lemma

1,

and

inequality

(h)

T 1. Hence,

βf,fs P s ≤ fs

T
x¯t
t=1

− f ∗ λ¯T − f

T
x¯t
t=1

≤ P s − Ds.

Deﬁne

f ∗(∇fs(u))

αf,fs

:=

1 − βf,fs

=

0

sup
u T1

. fs(u) − f (u)

(7)

Assumption 3.3(5) ensures that αf,fs ≥ 0 which, in turn, ensures that the competitive ratio is non-negative. We now lower bound Ds by D and subsequently use weak duality to get that Ds ≥ D ≥ P . From

8

Assumption 3.3(3), we know that ∇fs(

t i=1

x¯i)

∇fs(

T i=1

x¯i)

for

all

t

∈

[T ]

since

x¯i

This, in turn, implies that λ¯t λ¯T for all t ∈ [T ] so that

0 for all i ∈ [T ].

TD

Ds =

max

t=1 d=1

TD

≥

max

t=1 d=1

[z¯t]d − [z¯t]d −

λ¯t d , 0 λ¯T d , 0

T
− vt∗(z¯t) + f ∗ λ¯T
t=1
T
− vt∗(z¯t) + f ∗ λ¯T
t=1

≥D .

Hence, P s − D ≥ P sβf,fs , and applying weak duality, we get that P s − P

equation gives us the following:

Ps

1

1

≥

=

.

P

1 − βf,fs αf,fs

This concludes the proof.

≥ P sβf,fs . Rearranging this

This theorem allows us to write the competitive ratio as the result of an optimization problem for a large class of f and fs. Our objective then becomes to design fs such that αf,fs is as small as possible, since this would in turn yield a stronger competitive ratio bound. We can then verify the following intuition: with the goal of increasing the denominator of (7), we see that we must craft fs to be suﬃciently larger than f in order to make cautious allocations in the face of adversarial uncertainty. However, with the goal of decreasing the numerator of (7), we must not design fs to be too large, otherwise the algorithm will make little to no allocation. In the next section, we discuss how to choose fs to optimize this ratio.

5 Designing the Surrogate Function
As the analysis in the preceding section shows, the choice of the surrogate function plays a crucial role in obtaining an improved competitive ratio bound. In this section, we propose techniques to design fs for particular classes of functions. In particular, in Section 5.1, we propose a technique for designing the surrogate of polynomial functions and we obtain the competitive ratio bound in this setting. In Section 5.2, we exploit quasiconvex optimization to design the surrogate function for a general f .

5.1 Polynomial Function
We propose a design technique for a special class of f : polynomials that satisfy Assumption 3.2. We let fs(u) = ρ1 f (ρu) , ρ > 1. Note that ∇fs(u) = ∇f (ρu). Due to Assumption 3.2(3) (that the gradient of f is increasing) looking ahead when making a decision forces us to use a larger gradient and be more careful in our allocation. The intuition here is to stay cautious because we make no assumptions on the arriving input. Now, it suﬃces to determine ρ. This surrogate function was proposed in [CHK15], but their analysis yielded a suboptimal choice of ρ.
To determine our choice of ρ, we start with Lemmas 2 and 3. Using these, Theorem 2 shows that ﬁnding the optimal ρ for a general class of polynomial functions comes back to solving the optimization problem in Lemma 2.

Lemma 2. For τ ≥ 2, the solution to

ρτ argρmin (τ − 1) ρτ−1 − 1

is ρ = τ 1/(τ−1).

The proof is provided in Appendix B.1.

Lemma 3. Given ρ > 1, for any 0 ≤ a ≤ b,

bρb−a − a ρb − 1 ≥ 0. ρa − 1

9

The proof is provided in Appendix B.2.

Theorem 2. Suppose that u ∈ RD. For any K ∈ N, suppose fK (u) =

K k=1

ck gk (u)

is

a

convex

function

such that ck > 0 for each k ∈ [K] and gk(u) =

D i=1

uτi ki

where

D i=1

τki

=

τk ,

and

τki

∈

R+

for

all

pairs (k, i) ∈ [K] × [D]. Assume that τ := τi ≥ 2 where i = arg maxi τi. Then, choosing parameter ρ as ρ = τ 1/(τ−1) guarantees a competitive ratio of at least τ −τ/(τ−1) for Algorithm 1 called with ρ1 fK (ρu).

Proof. We ﬁrst use induction to show that

inf sup fK∗ (∇ρufK (ρu)) ≤ inf (τ − 1) ρτ ,

ρ>1 0

u

T1

1 ρ

fK

(ρu)

−

fK

(u)

ρ>1

ρτ−1 − 1

and then apply Lemma 2 to the optimization problem. First note that for any K ∈ N, the Fenchel-Young inequality holds with equality as described in Equation (2) in Section 2. That is,

fK∗ (∇ρufK (ρu)) = ∇ρufK (ρu) , ρu − fK (ρu) .

We now begin the inductive argument on K. For K = 1,

D
f1(u) = c1 uiτ1,i ,
i=1

where

D i=1

τ1,i

=

τ1

≥

2

and

τ1,i

is

non-negative

for

all

i.

Using the deﬁnition of f1, we have

inf
ρ>1 0

sup
u T1

f1∗(∇ρuf1(ρu))

1 ρ

f1

(ρu)

−

f1

(u)

(a)

∇ρuf1(ρu) , ρu − f1(ρu)

= inf sup
ρ>1 0 u T 1

1 f1(ρu) − f1(u)

ρ

(b)

ρτ1 (τ1 − 1) f1(u)

= inf sup

ρ>1 0 u T 1 (ρτ1−1 − 1) f1(u)

(c)

ρτ1

=

inf (τ1
ρ>1

−

1)

ρτ1−1

−

. 1

Equality (a) comes from the Fenchel-Young inequality holding with equality. Equality (b) comes from the following:

f1(ρu) = ρτ1 f1(u) , ∇ρuf1(ρu) , ρu = ρτ1 τ1f1(u) .

Equality (c) comes from removing f1(u) from the numerator and denominator, thus eliminating any dependence of u in the optimization problem. This concludes the proof for K = 1.
Suppose that the result holds for K − 1 ∈ N. We argue the result for K ∈ N. For notational convenience, we deﬁne

ak := ckρτk−τK (τk − 1) , ρτk−1 − 1
bk := ck (τK − 1) ρτK−1 − 1 , hk(u) := (gk(u))−1 .

Without loss of generality, let τ1 ≥ · · · ≥ τK where τ1 ≥ 2. Our strategy is to show that removing cK gK (u) upper bounds the optimization problem. We ﬁrst isolate the the cKgK(u) term. Then, we show that keeping this term reduces the objective. We then ﬁnish the claim with the inductive hypothesis.

10

We begin with the following:

∇ρufK (ρu) , ρu − fK (ρu) (d) ρ1 fK (ρu) − fK (u) = =

K k=1

ck ρτk

(τk

−

1)

gk (u)

K k=1

(ρτk −1

−

1)

gk (u)

K−1 k=1

ck ρτk

(τk

−

1)

gk (u)

+

cK ρτK

(τK

−

1)

gK (u)

K −1 k=1

ck

(ρτk −1

−

1)

gk (u)

+

cK

(ρτK −1

−

1)

gK (u)



(e) ρτK

hK (u)

=



ρτK−1 − 1 hK (u)

K−1 k=1

ak

gk

(u)

+ cK (τK − 1)



K −1 k=1

ck

ρτk −1 −1 ρτK −1−1

gk (u)

 + cK



(f) ρτK

hK (u)

K −1 k=1

(ak

−

bk )

gk (u)

= ρτK−1 − 1 (τK − 1) + hK (u)

K−1 k=1

ck

ρτk −1 −1 ρτK −1−1

gk (u)


. + cK

Equality (d) comes from the following:

K
fK (ρu) = ckρτk gk(u) ,
k=1 K
∇ρufK (ρu) , ρu = ρτk τkgk(u) .
k=1
Equality (e) comes from factoring out ρτK gK (u) from the numerator and ρτK−1 − 1 gK (u) from the denominator. Equality (f) comes from rearranging the fraction inside the parentheses by bringing (τK − 1) out front.
We have successfully isolated cK in the denominator of the fraction. Since cK > 0, adding it to the denominator shrinks the fraction inside the parentheses since the numerator is positive, which we know from Lemma 3. Indeed, Lemma 3 shows that for all k ∈ [K],

ak − bk = ck

ρτk−τK (τk − 1) − (τK − 1)

ρτk−1 − 1 ρτK −1 − 1

≥ 0.

Now, we have





∇ρufK (ρu) , ρu − fK (ρu) (g) ρτK

hK (u)

K −1 k=1

(ak

−

bk )

gk (u)

1 ρ

fK

(ρu)

−

fK

(u)

≤ ρτK−1 − 1 (τK − 1) + hK (u)

K −1 k=1

ck

ρτk −1 −1 ρτK −1−1

 gk (u)

 (h) ρτK = ρτK−1 − 1 (τK − 1) +



K −1 k=1

(ak

−

bk )

gk (u)

K −1 k=1

ck

ρτk −1 −1 ρτK −1−1

 gk (u)

(i)

K −1 k=1

ρτk

(τk

−

1)

gk (u)

= Kk=−11 (ρτk−1 − 1) gk(u)

∇ρufK−1(ρu) , ρu − fK−1(ρu)

=

1 f (ρu) − f (u) .

ρ K−1

K −1

Inequality (g) comes from removing cK from the denominator. Equality (h) comes from removing hK(u) from the numerator and denominator of the fraction inside the parentheses. Equality (i) comes from combining

11

the expression back into a single fraction. We now ﬁnish the claim with the following:

inf sup

fK∗ (∇ρufK (ρu))

(j)
= inf

sup

∇ρufK (ρu) , ρu − fK (ρu)

ρ>1 0

u

T1

1 ρ

fK

(ρu)

−

fK

(u)

ρ>1 0 u T 1

1 ρ

fK

(ρu)

−

fK

(u)

∇ρufK−1(ρu) , ρu − fK−1(ρu)

≤ inf sup
ρ>1 0 u T 1

1 fK−1(ρu) − fK−1(u)

ρ

(k)

fK∗ −1(∇ρufK−1(ρu))

=

inf
ρ>1 0

sup
u T1

1 fK−1(ρu) − fK−1(u)

ρ

(l)

ρτ1

≤

inf
ρ>1

(τ1

−

1)

ρτ1−1

−

. 1

Equality (j) and equality (k) come from the Fenchel-Young inequality, which holds at equality. Inequality (l) comes from the inductive hypothesis.
We now apply Lemma 2 to solve

ρτ1

1/(τ1 −1)

arg min (τ1
ρ>1

−

1)

ρτ1−1

−

1

=

τ1

.

Plugging this choice of ρ back into the objective gives us τ1τ1/(τ1−1) which concludes the proof.

Comparison to [CHK15]. Chan et al. [CHK15] approach a similar optimization problem, but exploit
their additional assumptions on the procurement cost function which essentially restricts their class to polynomials. They choose their design parameter to be ρ = λ1/(λ−1) where λ is deﬁned as the smallest
cumulative degree of a term in f ; i.e., λ := τj where j = arg minj τj. Chan et al. [CHK15] are interested in the asymptotic behavior of the competitive ratio in terms of τ , and both their choice of ρ and our choice of ρ give the same O(τ ) competitive ratio bound1. However, we achieve a more reﬁned competitive ratio bound with our choice of ρ = τ 1/(τ−1).

5.2 General Case

In this section, we propose a design approach for a general procurement cost function. We show that the
algorithm metric we aim to optimize is a quasiconvex function of fs, the surrogate function we are aiming to design. Therefore, the search over an appropriate family of fs can be carried out by quasiconvex optimization. Note that while the approach is general, solving the problem computationally requires discretizing the variable u ∈ RD+ , and thus this method is suitable for cases where D is small.

Theorem 3. Let f (u) =

N n=1

gn

(u)

where

gn

satisﬁes

Assumption

3.2

for

all

n

∈

[N ].

Let

a

∈

RN ,

where

a

1, and fs(u) =

N n=1

an

gn

(u).

Consider a discretization of the set {u | 0

u

T 1} and denote the

points in this discretized set as U. The following problem

minimize max f ∗(∇fs(u)) a 1 u∈U fs(u) − f (u)

(Q-1)

can be solved as a quasiconvex optimization problem.

Proof. In order to show that Problem (Q-1) is a quasiconvex optimization problem, we must verify that the constraints are convex and the objective is quasiconvex. It suﬃces to show that

max f ∗(∇fs(u)) u∈U fs(u) − f (u)
1In their work, [CHK15] deﬁne the competitive ratio to be the inverse of ours, and so to avoid confusion in case the reader refers to their work, we compare their result with ours according to their deﬁnition of competitive ratio.

12

is a quasiconvex function in a. Since a non-negative weighted maximum of quasiconvex functions is also quasiconvex, it suﬃces to show that f∗(∇fs(u)) is quasiconvex in a for a ﬁxed u. We can directly apply the
fs(u)−f(u)
deﬁnition of quasiconvexity. Let Sα(fs) be the sub-level sets of fs for a ∈ RN . We have the following:

Sα(fs) = a = {a

1 f ∗(∇fs(u)) ≤ α fs(u) − f (u)
1 | f ∗(∇fs(u)) ≤ α (fs(u) − f (u))} .

For a ﬁxed value of u, [∇fs(u)]d is linear in a for all d and since f ∗ is always convex, composing a convex function with a linear function of a is convex in a. Finally, since fs(u) is linear in a, the constraints of Sα(fs)
are convex, and thus Sα(fs) is a convex set.

Since Problem (Q-1) is a quasiconvex optimization problem from Theorem 3, we can solve it by a sequence of convex feasibility problems. For a ﬁxed α ∈ [1, ∞), we consider the following feasibility problem:

ﬁnd subject to

a f ∗(∇fs(u)) ≤ α (fs(u) − f (u)) a 1.

∀u ∈ U

(Q-2)

We now perform a binary search on α to ﬁnd the smallest α, up to precision, such that Problem (Q-2) is feasible. We write pseudocode for this procedure in Appendix C.

6 Numerical Examples

In this section, we illustrate the performance of our algorithm for speciﬁc procurement cost functions.

In our ﬁrst example, we use a simple procurement cost function in order to demonstrate the need for a

surrogate function when calling Algorithm 1. In our second example, we consider a non-separable polynomial

procurement cost function and compare the performance of Algorithm 1 for diﬀerent surrogate function design

techniques.

Consider the procurement cost function f (u) = u2, where u ∈ R+. This numerical example shows the

necessity of a surrogate function, and how running Algorithm 1 with the original procurement cost function

has a competitive ratio of 0 asymptotically. We show this by crafting a particular arrival instance in which

we highlight the weakness of not using a surrogate function. The intuition is that not using a surrogate

function allows the decision making to be excessively greedy, in that the algorithm does not caution itself

from accumulating a large procurement cost for minimal revenue. This instance, described below, forces the

algorithm to accumulate a large procurement cost before seeing higher valued arrivals which come soon after.

In this instance, the incoming valuations are linear, and so we have vt(xt) = ctxt. We have ct = 2t. Assume

that T is divisible by 2. From the decision rule of Algorithm 1 called with fs, i.e., x¯t = 1 ct − fs

t i=1

x¯i

,

calling Algorithm 1 with fs(u) = u2 leads to an allocation of xt = 1 for all t which gives a cumulative reward

of T .

The optimal allocation is one that sets xt

= 1 for all t >

T 2

and yields an objective of

1 2

T2 +T

. This

yields a ratio that tends to 0 as T becomes large. For each of our design techniques, the surrogate function

is the same and is fs(u) = 2u2. Calling Algorithm 1 with fs(u) = 2u2 leads to an allocation of xt = 0.5 for all t which gives an objective of T42 + T2 . This yields a ratio that tends to 21 as T becomes large. This example then shows that even for a simple procurement cost function, not using a surrogate function may

lead to a competitive ratio that tends to 0 as T becomes large. Now, consider the procurement cost function f (u) = u41 + (u1 + u2)2 where u ∈ R2+. Figure 1 shows the

shape of the surrogate function using the design techniques from Sections 5.1 and 5.2 respectively. For fs from Section 5.1, we use the surrogate function fs(u) = ρ1 f (ρu) and with Theorem 2, we choose ρ = 41/3.
This means that fs(u) = 4u41 + 41/3 (u1 + u2)2. This choice of ρ then gives a competitive ratio bound of 4−4/3 ≈ 0.1575. For fs from Section 5.2, we use surrogate function fs(u) = a1u41 + a2 (u1 + u2)2 from

Theorem 3. To solve Problem (Q-1), we set T = 10 and have 100 points per square unit in the discretization;

i.e.,

U = {u | ui ∈ {0, 0.1, 0.2, . . . , 9.9, 10} ∀i ∈ {1, 2}} .

13

This achieves the competitive ratio bound of approximately 0.1577 with a1 ≈ 3.791 and a2 ≈ 2.386. The surrogate function from Section 5.2 allows for an additional design parameter which allows us to achieve a slightly better competitive ratio bound than the surrogate function from Section 5.1. However, the technique from Section 5.2 has a much higher computational cost due to numerically solving the quasiconvex optimization problem in Problem (Q-1). Figure 2 compares the cumulative objective values up to time t,

u2
1e4
u2
1e4

f

fs (5.1)

4.0

3.5

3.0

2.5

2.0

1.5

1.0

0.5 0.0

108

64

2 00

2

4 u1 6

8 10

f
fs (5.2)

3.5

3.0

2.5

2.0

1.5

1.0

0.5

0.0

108

64

2 00

2

4 u1 6

8 10

Figure 1: Problem (Q-1) applied to f (u) = u41 + (u1 + u2)2. fs (5.1) represents the surrogate function from using the technique in Section 5.1. fs (5.2) represents the surrogate function from using the technique in
Section 5.2.

i.e.,

t i=1

vi(x¯i)

−

f

t i=1

x¯i

, of Algorithm 1 called with diﬀerent surrogate functions.

For the surrogate

functions, we have the label f representing the surrogate function equal to original production cost function, and so Algorithm 1 is called with u41 +(u1 + u2)2. We have the label fpoly representing the surrogate function from using the technique in Section 5.1, so Algorithm 1 is called with 4u41 +41/3 (u1 + u2)2. We have the label
fdesign representing the surrogate function from using the technique in Section 5.2, so Algorithm 1 is called with a1u41 + a2 (u1 + u2)2 where a1 ≈ 3.791 and a2 ≈ 2.386. Finally, we have the label fchk representing the surrogate function from using the technique in [CHK15], so Algorithm 1 is called with 8u31 + 2 (u1 + u2)2.
The online arrivals are generated by reasoning about instances that would be adversarial for Algorithm 1

called with the original procurement cost function. The weakness in calling Algorithm 1 called with f , i.e,

not using a surrogate function, is that the decisions are made too greedily, in that the algorithm does not

caution itself from accumulating a large procurement cost for minimal revenue. This instance is thus gener-

ated from having online arrivals which force the algorithm to amass a large procurement cost before seeing

higher valued arrivals which it can no longer take. In this instance, the incoming valuations are linear, i.e.,

vt(xt) = ct xt, where

∇f (t · 1) if t is odd

ct =

.

∇f (2t · 1) if t is even

7 Posted Pricing Mechanisms
In this section, we propose Algorithm 2 which is a primal-dual algorithm that computes the primal and dual variables sequentially, unlike Algorithm 1 which computes the primal and dual variables simultaneously as the solution to the saddle-point problem in equation (M-2). Algorithm 2 is much more computationally eﬃcient, and also possess an economic interpretation of incentive compatibility as deﬁned in Deﬁnition 7.1.
Deﬁnition 7.1 (Incentive compatibility). An online algorithm for problem (P-1) is called incentive compatible when each customer maximizes their utility by being truthful, i.e., each customer reports and acts according to their true beliefs.
Algorithm 2 is called a posted pricing mechanism, as deﬁned in Deﬁnition 7.2, and immediately satisﬁes incentive compatibility.

14

objective

1e6

3.0

f

2.5

fpoly fdesign

2.0

fchk

1.5

1.0

0.5

0.0 0 10 2t0ime step30 40 50

Figure 2: A plot comparing the the objectives up to time t of Algorithm 1 called with diﬀerent surrogate functions. For the surrogate functions, we have f representing the surrogate function equal to f , fpoly representing the surrogate function from using the technique in Section 5.1, fdesign representing the surrogate function from using the technique in Section 5.2, and fchk using the technique in [CHK15].

Deﬁnition 7.2 (Posted Pricing Mechanism). An online algorithm is a posted pricing mechanism when the seller posts item prices and allows the arriving customer to choose their desired bundle of items given the prices.
The interpretation here, is that upon arrival, the customer chooses the allocation which maximizes their utility, and this would be identical to the allocation that the seller would assign had the user reported their true valuation function. From the notation of Algorithm 2, the dual variable, λ¯t, represents a price that is revealed at each time step, before the customer arrives, and then the allocation for this arriving customer is then determined by this price. The posted price at time step t, therefore, does not depend on vt, and so the arriving agent does not need to reveal it. A posted pricing mechanism is therefore desirable in applications where the privacy of vt is important.

Algorithm 2: Sequential Update with Oﬀset

Input: f : RD → R, voﬀset ∈ RD+ 1 for t = 1 . . . T do

2

λ¯t = ∇f

t−1 i=1

x¯i

+

voﬀset

;

3 x¯t = arg max0 xt 1 vt(xt) − λ¯t xt

We propose the primal-dual algorithm in Algorithm 2. Here, in comparison to Algorithm 1, λ¯t is being used to set the threshold at time t, independent of the allocation made at time t. Thus, the value of λ¯t does not require solving a saddle-point problem. Furthermore, in comparison to Algorithm 1, in addition to passing in the function, f , as an argument, we pass in an oﬀset vector, voﬀset, to Algorithm 2 which allows us to additively control the threshold. The naming of both Algorithm 1 as Simultaneous Update and Algorithm 2 as Sequential Update to distinguish between how the primal and dual variables are computed, come from [EF16].

7.1 Analysis without Oﬀset

In this subsection, we analyze the competitive ratio of Algorithm 2 called with voﬀset = 0 and fs satisfying

Assumption 3.3. This ensures that at every time step t, x¯t = 1 z¯t − λ¯t 0 , where λ¯t = ∇fs

t−1 i=1

x¯i

15

and zt = ∇vt(x¯t) from Lemma 4. Now, we bound the competitive ratio of Algorithm 2.

Theorem 4. Let fs satisfy Assumption 3.3. The competitive ratio of Algorithm 2 called with fs and voﬀset = 0 is bounded by 1/αf,fs where

f ∗(∇fs(u))

αf,fs

:=

0

sup
u T1

fs(u) − f (u) − 1

. (∇fs(u) − ∇fs(0))

This proof is very similar to that of Theorem 1 and so the proof is provided in Appendix D.1.

Designing the general surrogate function In similar vein to Section 5.2, we now propose a design technique for the surrogate function, fs to be used in Algorithm 2 based on Theorem 4.

Theorem 5. Let f (u) =

N n=1

gn

(u)

where

gn

satisﬁes

Assumption

3.2

for

all

n

∈

[N ].

Let

a

∈

RN ,

where

a

1, and fs(u) =

N n=1

an

gn

(u).

Consider a discretization of the set {u | 0

u

T 1} and denote the

points in this discretized set as U. The following problem

minimize max

f ∗(∇fs(u))

a 1 u∈U fs(u) − f (u) − 1 (∇fs(u) − ∇fs(0))

(Q-2)

can be solved as a quasiconvex optimization problem.

This proof is very similar to that of Theorem 3 and so the proof is provided in Appendix D.2.

7.2 Analysis with Oﬀset

In this section, we show that posting a more cautious price, i.e., setting a larger threshold due to the

uncertainty from the allocation, allows for a clean analysis of the competitive ratio of Algorithm 2. We term

a larger price as more cautious, since an allocation is not made unless the larger threshold is reached, implying

a larger degree of caution for the current time step. This larger threshold comes from the assumption that

the gradient of fs is increasing, and so adding a non-negative oﬀset to the argument increases ∇fs.

In this subsection, we analyze Algorithm 2 called with fs satisfying Assumption 7.1 and voﬀset = 1. This

ensures that at every time step t, x¯t = 1 z¯t − λ¯t 0 , where λ¯t = ∇fs

t−1 i=1

x¯i

+

1

and z¯t = vt(x¯t) from

Lemma 4.

We now consider the following assumptions on fs.

Assumption 7.1. The function fs : RD+ → R+ satisﬁes the following:

1. fs is convex, diﬀerentiable, and closed.

2. fs is increasing; i.e., u v implies fs(u) ≥ fs(v).

3. fs has an increasing gradient; i.e., u v implies ∇fs(u) fs(v).

4. fs(0) = 0.

5. fs(u) ≥ f (u) for all 0 u (T − 1) 1.

6. fs(a) − f (a) ≤ fs(b) − f (b) if 0 a b.

Assumptions 7.1(1)-(4) are identical to Assumptions 3.3(1)-(4). We now bound the competitive ratio of Algorithm 2.

Theorem 6. Let fs satisfy Assumption 7.1. The competitive ratio of Algorithm 2 called with fs and voﬀset =

1 is bounded by 1/αf,fs where

f ∗(∇fs(u + 1))

αf,fs := sup
0 u (T −1)1

fs(u) − f (u)

.

This proof is very similar to that of Theorem 1 and so the proof is provided in Appendix D.3.

16

Designing the general surrogate function In similar vein to Section 5.2, we now propose a design technique for the surrogate function, fs to be used in Algorithm 2 based on Theorem 6.

Theorem 7. Let f (u) =

N n=1

gn

(u)

where

gn

satisﬁes

Assumption

3.2

for

all

n

∈

[N ].

Let

a

∈

RN ,

where

a

1, and fs(u) =

N n=1

an

gn

(u).

Consider

a

discretization

of

the

set

{u | 0

u

(T − 1) 1} and denote

the points in this discretized set as U. The following problem

minimize max f ∗(∇fs(u + 1)) a 1 u∈U fs(u) − f (u)

(Q-3)

can be solved as a quasiconvex optimization problem.

This proof is very similar to that of Theorem 3 and so the proof is provided in Appendix D.4.

8 Related Work
In this section, we review further related work at the intersection of online matching and combinatorial auctions.

Online Bipartite Matching. Online bipartite matching [KVV90, KP00, DJK13, KRTV13] is a classical problem that has been studied and reintroduced for many applications. Recently, the natural application of internet ad placement has caused a resurgence of online bipartite matching and its generalizations through the problem Adwords [MVV07, DH09]. In the Adwords problem, a search engine is trying to maximize revenue from a set of budget-constrained advertisers, who bid on queries arriving online. This problem was generalized to allow the revenue to be the sum of a concave function of the budget spent for each advertiser [DJ12]. All of the aforementioned problems have a separable cumulative budget constraint that must be satisﬁed, and so the algorithm techniques of choosing the allocation as a function of the budget is not applicable for our problem.

Primal-Dual Algorithms. State-of-the-art techniques for Adwords, its generalizations, and related problems have been primal-dual algorithms [BJN07, BN09]. A primal-dual algorithm uses the dual problem formulation, and updates the dual variables in order to determine the values of the primal variables. The advantages of primal-dual algorithms are two-fold. Firstly, the analysis for competitive ratio of a primaldual algorithm then decomposes into writing the dual objective of the algorithm in terms of the primal objective, since weak duality can then be used to connect the two (see the opening paragraph of our proof of Theorem 1). Secondly, the dual variable may have a meaningful interpretation in how to determine the primal variable. We adapt the intuition for primal and dual variables from problems of proﬁt maximization [BBM08, CHMS10]. Although these problems are diﬀerent from our framework, [BBM08] considers limited or unlimited supply of resources and [CHMS10] considers customers arriving from a known distribution, the interpretations of the primal and dual variables are key in developing our posted pricing mechanism in Section 7. In both Algorithm 1 and Algorithm 2, our allocation rules comes naturally from realizing that the payment obtained must be greater than the additional production cost. The dual variable can then be interpreted as the price oﬀered to the incoming buyer, as further discussed in Section 7.
This powerful tool of duality is best seen in online covering and packing problems [CHK15, ABC+16]. The oﬄine covering problem can be written as:

minimize f (x) subject to Ax 1,
x∈Rn+

where f is a non-negative increasing convex cost function and A is an m×n matrix with non-negative entries. In the online problem, rows of A come online and a feasible assignment x must be maintained at all times where x may only increase. The oﬄine covering problem can be written as:

maximize
y∈Rm +

yj − f ∗ A y ,
j

17

and in the online setting, columns of A arrive online upon which yt must be assigned. The packing problem is dual to the covering problem as the j-th entry of y corresponds to the j-th row of A. In the works of [CHK15] and [ABC+16], the authors use this duality to analyze similar algorithms proposed for each problem. In fact, the bulk of the results in [CHK15] are focused on the covering and packing problems, upon which the authors then adapt their results to the online resource allocation problem in Section 5 of their work. In this paper, we obtain stronger results for the online resource allocation problem by studying the problem directly rather than trying to adapt results from the related problem of online packing.
We share a similar perspective in this work with [EF16]. The authors there study a generalization of Adwords in which the objective is a concave function and constraint sets and linear maps arrive online. There, the authors propose a convex optimization problem to design a surrogate function in order to improve the competitive ratio; however, the problem studied in [EF16] is diﬀerent from ours in the following ways: (1) the data coming online in [EF16] is linear, whereas in our setting the payment functions arriving online are generally concave, and (2) the objective of the oﬄine optimization problem in [EF16] is a coupled term between allocations at diﬀerent rounds, but in our objective, in equation (P-1), we have a sum over decoupled terms representing the cumulative payment, as well as a coupled term in the procurement cost function. Since these key diﬀerences do not allow our problem to be mapped to that in [EF16], we must develop separate surrogate function design techniques based on the competitive ratio analysis for our problem.
Arrival Models. Most of the online optimization problems analyzed with respect to competitive ratio are studied under three arrival models: (1) the worst-case/adversarial model, with no assumptions on how the requests arrive, (2) the random order model, where the set of requests is arbitrary but the order of arrival is uniformly random, and (3) the independently and identically distributed (IID) model, where the requests are IID samples from an underlying distribution. For a more in depth survey, see Section 2.2 in [Meh13]. Our setting is that of the worst-case model. The key approach to problems in the worst-case model is for the decision maker to apply a greedy algorithm which maximizes a function of how much revenue can be immediately gained versus how much revenue may be achieved later. In doing so, the decision maker must be cautious in spending budget or accumulating a resource which may be better consumed in the future. This decision making strategy connects loosely to the ideas of regularization for online optimization problems in the regret metric as seen in classical algorithms such as follow the regularized leader [McM11] and multiplicative weights [LW94]. A key diﬀerence however from the regret setting to the competitive ratio setting, is that in the regret setting, regularization aims to keep the gap between the current and previous decision small, whereas in the competitive ratio setting, the regularization is used to make cautious decisions in order to protect resources which may obtain more value if used in future allocations.
In the random order model, the typical approach is to have an exploration period, where the decision maker learns about the distribution of the arriving requests, followed by an exploitation period in which the decision maker uses this knowledge to maximize their revenue. This is most clearly seen in the classical secretary problem described in [CMRS64] in which a set of candidates arrive one by one for an open job position, and the manager must hire or reject the candidate before interviewing future candidates. Adwords is studied in the random order model in [DH09] and the algorithm proposed uses the same technique of initial exploration, in which the bids on the ﬁrst few queries are used to learn weights on the bidders used to select the allocation, and an exploitation period, in which these weights are applied to future queries to make the assignment. Similar strategies are used for generalizations of Adwords such as online linear programming [AWY14, AD14] and proﬁt maximization subject to convex costs [GMM18]. The key diﬀerence between the random order model and our setting of the worst case model, is that previous customers tell us nothing about future customers, and so we forgo learning about our customers, and focus solely on cautiously allocating our resources.
Online Combinatorial Auctions. In many related works, our problem of online resource allocation has been titled online combinatorial auctions. Online combinatorial auctions have been studied in the setting with ﬁxed resource capacities, i.e., there is a hard budget constraint for each resource [BN07, BBM08, CHK13] and in the setting with unlimited resource supplies, in which additional resources can be acquired at no cost [BBHM05, BBM08]. Our setting falls in between these; resources can be acquired or developed following a procurement cost. This problem was proposed by [BGMS11] for separable procurement cost functions in the worst-case arrival model. [BGMS11] devised a posted pricing mechanism, in which customers wanting
18

to purchase the k-th copy of any item would be charged a price equal to the procurement cost of the 2k-th copy of that item. [HK18] build on this result by characterizing the competitive ratio of optimal algorithms in this setting for a wide range of separable procurement costs as the solution to a diﬀerential equation. Our framework looks to generalize this setting by considering non-separable production cost functions. Additionally, we bring an optimization viewpoint to this setting in which we use (quasi-)convex optimization to design the best surrogate function, rather than restricting ourselves to a small function class as do these papers.

9 Conclusion & Future Directions
In this paper, we studied the broad online optimization framework of online resource allocation with procurement costs. We analyzed the competitive ratio for a primal-dual algorithm and showed how we can design a surrogate function in order to improve the competitive ratio. We proposed two techniques to design or shape the surrogate function. The ﬁrst technique, discussed in Section 5.1, addressed the case of polynomial cost functions and determined a closed-form choice for the scalar design parameter, that guarantees a competitive ratio of at least τ −τ/(τ−1) where τ is the largest cumulative degree of a single term in the polynomial. This bound is optimal from a result in [HK18] (Theorem 10). The second technique, discussed in Section 5.2, considered a general class of procurement cost functions and relied on an optimization problem which is quasiconvex in the design parameters to determine a surrogate function. This allowed us to further improve the competitive ratio at a higher computational cost. In Section 6 we investigated the surrogate function arising from each design technique for numerical examples.
As a future direction, we aim to generalize Theorem 3 to allow a much larger class of functions for the design of the surrogate. We will also investigate which choice of gn would lead to optimal smoothing for a certain class of f . Future steps also include a modiﬁed analysis that would allow more ﬂexibility in f but make more assumptions on the arriving inputs. Additionally, practically motivated assumptions on the structure of the incoming payment functions might lead to competitive ratio results for Algorithm 1 that will not approach zero if fs is close to f . Furthermore, the diﬀerent assumptions on the input order such as the random order model may be more suitable for certain applications, and competitive analysis in this regime has yet to be studied for this problem. In addition, diﬀerent assumptions on the procurement cost function may be better suited for applications where the procurement cost functions satisfy gradient increasing, i.e., Assumption 3.2(3) (continuous supermodular functions), but are not necessarily convex [SF20, SEF19].

References

[AAZ16]

Matthew Andrews, Spyridon Antonakopoulos, and Lisa Zhang. Minimum-cost network design with (dis)economies of scale. SIAM Journal on Computing, 45(1):49–66, 2016.

[ABC+16]

Yossi Azar, Niv Buchbinder, T. H.Hubert Chan, Shahar Chen, Ilan Reuven Cohen, Anupam Gupta, Zhiyi Huang, Ning Kang, Viswanath Nagarajan, Joseph Naor, and Debmalya Panigrahi. Online Algorithms for Covering and Packing Problems with Convex Objectives. Proceedings Annual IEEE Symposium on Foundations of Computer Science, FOCS, 2016-Decem:148–157, 2016.

[AD14]

Shipra Agrawal and Nikhil R Devanur. Fast algorithms for online stochastic convex programming. In Proceedings of the twenty-sixth annual ACM-SIAM symposium on Discrete algorithms, pages 1405–1424. SIAM, 2014.

[AWY14] Shipra Agrawal, Zizhuo Wang, and Yinyu Ye. A dynamic near-optimal algorithm for online linear programming. Operations Research, 62(4):876–890, 2014.

[BBHM05] M-F Balcan, Avrim Blum, Jason D Hartline, and Yishay Mansour. Mechanism design via machine learning. In 46th Annual IEEE Symposium on Foundations of Computer Science (FOCS’05), pages 605–614. IEEE, 2005.

19

[BBM08] Maria-Florina Balcan, Avrim Blum, and Yishay Mansour. Item pricing for revenue maximization. In Proceedings of the 9th ACM conference on Electronic commerce, pages 50–59, 2008.

[BGMS11] Avrim Blum, Anupam Gupta, Yishay Mansour, and Ankit Sharma. Welfare and proﬁt maximization with production costs. Proceedings - Annual IEEE Symposium on Foundations of Computer Science, FOCS, pages 77–86, 2011.

[BGN03]

Yair Bartal, Rica Gonen, and Noam Nisan. Incentive compatible multi unit combinatorial auctions. In Proceedings of the 9th conference on Theoretical aspects of rationality and knowledge, pages 72–87, 2003.

[BHP09] Dimitris Bertsimas, Jeﬀrey Hawkins, and Georgia Perakis. Optimal bidding in online auctions. Journal of Revenue and Pricing Management, 8(1):21–41, 2009.

[BJN07]

Niv Buchbinder, Kamal Jain, and Joseph Seﬃ Naor. Online primal-dual algorithms for maximizing ad-auctions revenue. In European Symposium on Algorithms, pages 253–264. Springer, 2007.

[BMS12] Marc Blatter, Samuel Muehlemann, and Samuel Schenker. The costs of hiring skilled workers. European Economic Review, 56(1):20–35, 2012.

[BN07]

Liad Blumrosen and Noam Nisan. Combinatorial auctions. Algorithmic game theory, 267:300, 2007.

[BN09]

Niv Buchbinder and Joseph Naor. The Design of Competitive Online Algorithms via a Primal—Dual Approach, volume 3. 2009.

[Bub15]

S´ebastien Bubeck. Convex optimization: Algorithms and complexity. Foundations and Trends® in Machine Learning, 8(3–4):231–357, 2015.

[CHK13] Tanmoy Chakraborty, Zhiyi Huang, and Sanjeev Khanna. Dynamic and nonuniform pricing strategies for revenue maximization. SIAM Journal on Computing, 42(6):2424–2451, 2013.

[CHK15] T.H. Hubert Chan, Zhiyi Huang, and Ning Kang. Online Convex Covering and Packing Problems. 2015.

[CHMS10] Shuchi Chawla, Jason D Hartline, David L Malec, and Balasubramanian Sivan. Multi-parameter mechanism design and sequential posted pricing. In Proceedings of the forty-second ACM symposium on Theory of computing, pages 311–320, 2010.

[CMRS64] YS Chow, Sigaiti Moriguti, Herbert Robbins, and SM Samuels. Optimal selection based on relative rank (the “secretary problem”). Israel Journal of mathematics, 2(2):81–90, 1964.

[DH09]

Nikhil R Devanur and Thomas P Hayes. The adwords problem: online keyword matching with budgeted bidders under random permutations. In Proceedings of the 10th ACM conference on Electronic commerce, pages 71–78, 2009.

[DJ12]

Nikhil R Devanur and Kamal Jain. Online matching with concave returns. In Proceedings of the forty-fourth annual ACM symposium on Theory of computing, pages 137–144, 2012.

[DJK13]

Nikhil R Devanur, Kamal Jain, and Robert D Kleinberg. Randomized primal-dual analysis of ranking for online bipartite matching. In Proceedings of the twenty-fourth annual ACM-SIAM symposium on Discrete algorithms, pages 101–107. SIAM, 2013.

[EF16]

Reza Eghbali and Maryam Fazel. Worst case competitive analysis for online conic optimization. In Neural Information Processing Systems, 2016.

[EGD15] S Ayca Erdogan, Alexander Gose, and Brian T Denton. Online appointment sequencing and scheduling. IIE Transactions, 47(11):1267–1286, 2015.

20

[GMM18] Anupam Gupta, Ruta Mehta, and Marco Molinaro. Maximizing proﬁt with convex costs in the random-order model. arXiv preprint arXiv:1804.08172, 2018.

[HJM18] Dawsen Hwang, Patrick Jaillet, and Vahideh Manshadi. Online resource allocation under partially predictable demand. Available at SSRN 3252231, 2018.

[HK18]

Zhiyi Huang and Anthony Kim. Welfare maximization with production costs: A primal dual approach. Games and Economic Behavior, 1:1–20, 2018.

[HV12]

Chien-Ju Ho and Jennifer Wortman Vaughan. Online task assignment in crowdsourcing markets. In Twenty-sixth AAAI conference on artiﬁcial intelligence, 2012.

[JL12]

Patrick Jaillet and Xin Lu. Near-optimal online algorithms for dynamic resource allocation problems. arXiv preprint arXiv:1208.2596, 2012.

[KP00]

Bala Kalyanasundaram and Kirk R Pruhs. An optimal deterministic algorithm for online bmatching. Theoretical Computer Science, 233(1-2):319–325, 2000.

[KRTV13] Thomas Kesselheim, Klaus Radke, Andreas T¨onnis, and Berthold V¨ocking. An optimal online algorithm for weighted bipartite matching and extensions to combinatorial auctions. In European symposium on algorithms, pages 589–600. Springer, 2013.

[KVV90]

Richard M Karp, Umesh V Vazirani, and Vijay V Vazirani. An optimal algorithm for on-line bipartite matching. In Proceedings of the twenty-second annual ACM symposium on Theory of computing, pages 352–358, 1990.

[LJ13]

Antoine Legrain and Patrick Jaillet. Stochastic online bipartite resource allocation problems. CIRRELT, 2013.

[LW94]

Nick Littlestone and Manfred K Warmuth. The weighted majority algorithm. Information and computation, 108(2):212–261, 1994.

[McM11]

Brendan McMahan. Follow-the-regularized-leader and mirror descent: Equivalence theorems and l1 regularization. In Proceedings of the Fourteenth International Conference on Artiﬁcial Intelligence and Statistics, pages 525–533, 2011.

[Meh13]

Aranyak Mehta. Online matching and ad allocation. Foundations and Trends® in Theoretical Computer Science, 8(4):265–368, 2013.

[MS14]

Konstantin Makarychev and Maxim Sviridenko. Solving optimization problems with diseconomies of scale via decoupling. In 2014 IEEE 55th Annual Symposium on Foundations of Computer Science, pages 571–580. IEEE, 2014.

[MVV07] Aranyak Mehta, Umesh Vazirani, and Vijay Vazirani. AdWords and Generalized Online Matching. Journal of the ACM, 54(5):19, 2007.

[SEF19]

Omid Sadeghi, Reza Eghbali, and Maryam Fazel. Competitive Algorithms for Online BudgetConstrained Continuous DR-Submodular Problems. 2019.

[SF20]

Omid Sadeghi and Maryam Fazel. Online continuous dr-submodular maximization with longterm budget constraints. volume 108 of Proceedings of Machine Learning Research, pages 4410– 4419, Online, 26–28 Aug 2020. PMLR.

21

A Computation of Dual Problem

T

T

P = maximize vt(xt) − f

xt

0 xt 1 t=1 t=1

T

= maximize

vt(wt) − f (y)

0 xt 1,y,wt t=1

T

subject to y

xt

t=1

wt xt ∀ t ∈ [T ]

T

T

= maximize minimize

vt(wt) − f (y) + z (xt − wt) − f (y) + λ

0 xt 1,y,wt λ 0,zt 0 t=1

y − xt
t=1

T

T

≤ minimize
λ 0,zt 0

maximize (zt − λ) xt −

minimize zt wt − vt(wt) + maximize λ y − f (y)

0 xt 1 t=1 t=1 wt y

TD

T

= minimize

max{[zt]d − [λ]d , 0} − vt∗(zt) + f ∗(λ) = D

λ 0,zt 0

t=1 d=1

t=1

The inequality comes from weak duality. From the KKT (Karush-Kuhn-Tucker) conditions, we know

that solving for the optimal value of y following the inequality comes from taking the gradient with respect

to y, and setting this equal to 0. Solving this equation gives us λ = ∇f (y ). Since we know from our

construction of y that y =

T t=1

xt ,

we

can

conclude

that

λ

= ∇f

T t=1

xt

. Similarly, solving for wt

gives us zt = ∇vt(wt ) and from our construction of wt that wt = xt , we can conclude that zt = ∇vt(xt ). Our optimal values are then

xt = 1[zt − λ 0] ,

T

λ = ∇f

xt ,

t=1

zt = ∇vt(xt ) .

B Missing Proofs in Section 5

B.1 Proof of Lemma 2
Since (τ − 1) is a constant, we disregard it from the objective of the optimization problem, when we solve. We solve the optimization problem for ρ by computing the ﬁrst derivative,
d ρτ = τ ρτ−1 − 1 − (τ − 1) ρτ−1, dρ ρτ−1 − 1

and setting it equal to 0. Solving for ρ gives us ρ = τ 1/(τ−1). Now, it suﬃces to show that ρτ−ρ1τ−1 is convex for ρ > 1 and τ ≥ 2. We do this by computing the second

derivative,

d2

ρτ

(τ − 1) ρτ (−2ρτ + τ (ρ + ρτ ))

dρ2 ρτ−1 − 1 =

(ρτ − ρ)3

,

and verifying that it is greater than or equal to 0. Since ρ, τ > 1, we know that

(τ − 1) ρτ+1 (ρτ − ρ)3 ≥ 0,

22

and so we can remove it from the expression. Now, it suﬃces to show that −2ρτ−1 + τ 1 + ρτ−1 ≥ 0.
This inequality can be rewritten as τ ≥ (2 − τ ) ρτ−1 which is trivially true for τ ≥ 2.

B.2 Proof of Lemma 3

Rearranging the inequality gives us

ρb

ρa

b ρb − 1 ≥ a ρa − 1 .

To show that this holds for 0 ≤ a ≤ b, it suﬃces to show that for all ρ > 1,

ρx f (x) := x ρx − 1

is monotonically increasing for x > 0 for all ρ > 1. We show this by checking that f (x) ≥ 0. We ﬁrst rewrite

f (x) as follows:

eαx

x

f (x) = x eαx − 1 = 1 − e−αx ,

where α = log ρ > 0. Then, computing the derivative gives us

(1 − e−αx) − αxe−αx e−αx (eαx − 1 − αx)

f (x) =

(1 − e−αx)2

= (1 − e−αx)2 .

Since eαx ≥ 1 + αx for all α ≥ 0 and x ≥ 0, this implies that the numerator, and therefore f (x), is non-negative.

C Pseudocode for Quasiconvex Optimization
We use the notation aα to denote a choice of a such that Problem (Q-2) is feasible for this choice of α. We then perform binary search to ﬁnd the smallest value of α such that Problem (Q-2) is feasible. The algorithm is formalized in Algorithm 3.

Algorithm 3: Quasiconvex Optimization as Convex Feasibility Problems

Data: > 0, αupper > 1

1 αlower ← 1;

2 while αupper − αlower > do

3

α

←

1 2

(αupper

+ αlower);

4 solve Problem (Q-2) with α;

5 if Problem (Q-2) is feasible then

6

αupper ← α;

7 else

8

αlower ← α;

9 return aαupper

D Missing Proofs in Section 7
We ﬁrst introduce the following lemma, which is relevant for the proofs in this section.

23

Lemma 4. Let v : RD+ → R+ satisfy Assumption 3.1 and λ ∈ RD+ . The optimality conditions of

maximize v(x) − λ x
0x1

imply that x = 1[∇v(x ) − λ 0].

Proof. We ﬁrst re-write the optimization problem by introducing additional constraints, and then apply the KKT conditions.

maximize v(x) − λ x = maximize v(z) − λ x

0x1

0 x 1,z

subject to z x

= maximize minimize v(z) − λ x + w (x − z)

0 x 1,z

w0

= maximize minimize (w − λ) x + v(z) − w z.

0 x 1,z

w0

The ﬁrst equality comes from the assumption that v is increasing. Taking the gradient of the Lagrangian with respect to z gives the optimality condition: ∇v(z ) − w = 0. This immediately implies that w = ∇v(z ).
Now, solving the maximization over x, i.e., maximize0 x 1 (w − λ) x, leads to x = 1[∇v(z ) − λ 0]. From our constraint on z, i.e., z x, we know that z = x at optimality, and thus plugging this into the threshold rule for x gives x = 1[∇v(x ) − λ 0].

D.1 Proof of Theorem 4

In this subsection, we analyze Algorithm 2, called with fs satisfying Assumption 3.3, and voﬀset = 0. We

deﬁne the following quantities:

T

T

P s0 := vt(x¯t) − f

x¯t ,

t=1

t=1

TD

T

Ds0 :=

max [z¯t]d − λ¯t d , 0 − vt∗(z¯t) + f ∗ λ¯T .

t=1 d=1

t=1

Note that P s0 and Ds0 are identical to their counterparts, P s and Ds introduced in Section 3.2, with the only diﬀerence being that for P s0 and Ds0, x¯t, λ¯t, and z¯t come from Algorithm 2. For notational simplicity,
we deﬁne

T

t

t−1

L1

g

,

{x

t

}

T t=1

:=

∇g

xi − ∇g

xi

xt,

t=1

i=1

i=1

L2

g

,

{x

t

}

T t=1

:= 1

T

∇g

xt − ∇g(0) .

t=1

We see that L1 g, {xt}Tt=1 ≤ L2 g, {xt}Tt=1 for all g satisfying Assumption 3.3 and for 0 xt 1 for all t ∈ [T ], by upper bounding xt by 1 and performing the telescoping sum, since g is assumed to have an increasing gradient. We ﬁrst show the following lemmas which aid in our analysis of the competitive ratio of Algorithm 2.
Lemma 5. If fs is increasing and fs has an increasing gradient, then D ≤ Ds0.
Proof. From the assumption that fs has an increasing gradient, we know that

∇fs

t−1
x¯i
i=1

∇fs

T −1
x¯i
i=1

24

for all t ∈ [T ] since x¯i 0 for all i ∈ [T ]. This, in turn, implies that λ¯t λ¯T for all t ∈ [T ] so that

TD

Ds0 =

max

t=1 d=1

TD

≥

max

t=1 d=1

[z¯t]d − [z¯t]d −

λ¯t d , 0 λ¯T d , 0

T
− vt∗(z¯t) + f ∗ λ¯T
t=1
T
− vt∗(z¯t) + f ∗ λ¯T
t=1

≥D .

In order for the ﬁnal inequality to hold, λ¯T and {z¯t}Tt=1 must be feasible points for the optimization problem deﬁning D , i.e., λ¯T 0 and z¯t 0 for all t ∈ [T ]. Since fs is increasing by assumption, we know that fs has a non-negative gradient, and similarly since vt is increasing by assumption, we know that vt has a non-negative gradient.
Lemma 6. If fs is increasing and fs has an increasing gradient, then P s0 ≤ Ds0.
Proof. The proof comes from relating P s0 to P followed by relating Ds0 to D with Lemma 5 and combining the two inequalities using weak duality. Trivially, P s0 ≤ P since

T
P s0 = vt(x¯t) − f
t=1

T
x¯t
t=1

T
≤ maximize vt(xt) − f
0 xt 1 t=1

T
xt
t=1

=P .

From Lemma 5, we have shown that Ds0 ≥ D and with weak duality implying that P ≤ D , we can conclude that P s0 ≤ P ≤ D ≤ Ds0.

Lemma 7. Let vt satisfy Assumption 3.1. fs is convex and diﬀerentiable, and fs(0) = 0, then

T

T

vt(x¯t) − fs

x¯t + 1

t=1

t=1

T

∇fs

x¯t − ∇fs(0) ≥ 0.

t=1

Proof. We ﬁrst note that

L1

fs

,

{x¯

t

}

T t=1

≤ L2 fs, {x¯t}Tt=1

,

which allows us to write

T

T

T

vt(x¯t) − fs

x¯t + 1 ∇fs

x¯t − ∇fs(0)

t=1

t=1

t=1

T
= vt(x¯t) − fs
t=1

T
x¯t
t=1

+ L2 fs, {x¯t}Tt=1

T
≥ vt(x¯t) − fs
t=1

T
x¯t
t=1

+ L1 fs, {x¯t}Tt=1

T

T

t

t−1

(a)

= vt(x¯t) −

fs

x¯i − fs

x¯i

t=1

t=1

i=1

i=1

+ L1

fs

,

{

x¯t

}

T t=1

(b) T
≥ ∇vt(x¯t)
t=1

T
x¯t − ∇fs
t=1

t
x¯i
i=1

x¯t + L1 fs, {x¯t}Tt=1 .

Equality (a) comes from breaking the expression fs

T t=1

x¯t

into a telescoping sum with fs(0) = 0 by

assumption. Inequality (b) follows from convexity of fs and concavity of vt. Now, plugging in the expression

25

for L1

fs

,

{x¯

t

}

T t=1

, we get

T

T

vt(x¯t) − fs

x¯t + 1

t=1

t=1

T

∇fs

x¯t − ∇fs(0)

t=1

T
≥ ∇vt(x¯t)
t=1

T
x¯t − ∇fs
t=1

t
x¯i
i=1

x¯t + L1 fs, {x¯t}Tt=1

T

T

t−1

= ∇vt(x¯t) x¯t − ∇fs

x¯i x¯t

t=1

t=1

i=1

T

t−1

=

∇vt(x¯t) − ∇fs

x¯i , x¯t .

t=1

i=1

The decision rule of Algorithm 2—i.e., x¯t = 1 z¯t − λ¯t product is always non-negative.

0 (as seen in Lemma 4) ensures that the inner

Now, we bound the competitive ratio of Algorithm 2. The general overview of the proof of Theorem 4 is as follows: writing Ds0 in terms of P s0, we bound the gap between Ds0 and P s0. From here, we lower bound Ds0 by D , which in turn allows us to use weak duality to relate D and P .
We start with writing Ds0 in terms of P s0:

TD

Ds0 =

max

t=1 d=1

[z¯t]d −

λ¯t d , 0

T
− vt∗(z¯t) + f ∗ λ¯T
t=1

T (a)
=

z¯t − λ¯t

T
x¯t − vt∗(z¯t) + f ∗ λ¯T

t=1

t=1

T (b)
= ∇vt(x¯t)
t=1

T
x¯t − ∇fs
t=1

t−1
x¯i
i=1

T
x¯t − vt∗(∇vt(x¯t)) + f ∗ λ¯T
t=1

T (c)
= ∇vt(x¯t)
t=1

T
x¯t − ∇fs
t=1

t
x¯i
i=1

T

x¯t −

vt∗(∇vt(x¯t)) + f ∗ λ¯T

+ L1

fs

,

{x¯

t

}

T t=1

.

t=1

Equality (a) comes from the decision rule of Algorithm 2, which ensures that x¯t = 1 z¯t − λ¯t 0 . Equality

(b) comes from ﬁrst substituting the deﬁnition of λ¯t = ∇fs

t−1 i=1

x¯i

and z¯t = ∇vt(x¯t), and equality (c)

comes from adding and subtracting

T t=1

∇fs

t i=1

x¯i

x¯t. Now, we apply the concave Fenchel-Young

inequality at equality—i.e., Equation (3) with g = vt and u = x¯t, in order to decompose the vt∗(∇vt(x¯t))

term as follows:

T
Ds0 = ∇vt(x¯t)
t=1

T
x¯t − ∇fs
t=1

t
x¯i
i=1

T
x¯t −
t=1

∇vt(x¯t)

x¯t − vt(x¯t)

T

T

= vt(x¯t) − ∇fs

t=1

t=1

t
x¯i
i=1

x¯t + f ∗ λ¯T + L1 fs, {x¯t}Tt=1 .

+ f ∗ λ¯T

+ L1 fs, {x¯t}Tt=1

26

Now, we proceed to bound the duality gap between Ds0 and P s0 by ﬁrst observing the following relationship:

(d) T
Ds0 ≤ vt(x¯t) − fs

T
x¯t + f ∗ λ¯T

t=1

t=1

T
= vt(x¯t) − fs

T
x¯t + f ∗ λ¯T

t=1

t=1

(e)
=

P

s0

−

fs

T
x¯t + f ∗ λ¯T + f

t=1

(f )
≤ P s0 − fs

T
x¯t + f ∗ λ¯T + f

t=1

+ L1

fs

,

{x¯

t

}

T t=1

T

T

+f

x¯t − f

x¯t

t=1

t=1

T
x¯t
t=1

+ L1

fs

,

{

x¯

t

}

T t=1

T
x¯t
t=1

+ L2 fs, {x¯t}Tt=1

+ L1 .

fs

,

{x¯

t

}

T t=1

Inequality (d) follows directly from convexity of fs and concavity of vt. Equality (e) follows from substituting

the deﬁnition of P s0 =

T t=1

vt(x¯t)

−

f

T t=1

x¯t

, where in the preceding equality we add and subtract

f

T t=1

x¯t

. Inequality (f) follows from

L1 fs, {x¯t}Tt=1 ≤ L2 fs, {x¯t}Tt=1 .

We bound the gap between Ds0 and P s0 as a multiplicative factor of P s0 in order to relate these quantities as a ratio:

fs

T t=1

x¯t

− f ∗ λ¯T

−f

T t=1

x¯t

− L2 fs, {x¯t}Tt=1

P s0

(g) fs ≥

T t=1

x¯t

− f ∗ λ¯T +1 − f P s0

T t=1

x¯t

− L2 fs, {x¯t}Tt=1

(h) fs =

T t=1

x¯t

− f ∗ ∇fs

T t=1

x¯t

−f

T t=1

x¯t

T t=1

vt(x¯t

)

−

f

T t=1

x¯t

− L2

fs

,

{x¯

t

}

T t=1

(i) fs ≥

T t=1

x¯t

− f ∗ ∇fs

T t=1

x¯t

−f

T t=1

x¯t

− L2 fs, {x¯t}Tt=1

fs

T t=1

x¯t

−f

T t=1

x¯t

− L2 fs, {x¯t}Tt=1

(j)

fs(u) − f ∗(∇fs(u)) − f (u) − 1 (∇fs(u) − ∇fs(0))

≥ inf
0 u T1

fs(u) − f (u) − 1 (∇fs(u) − ∇fs(0))

=: βf,fs .

Inequality (g) follows from f ∗ being an increasing function and the assumption that fs has an increasing

gradient implying that λ¯T

λ¯T +1. In equality (h), we substitute the deﬁnition of λ¯T +1 = ∇fs

T i=1

x¯i

.

Inequality (i) follows from replacing

T t=1

vt(x¯t)

with

fs

T t=1

x¯t

− L2 fs, {x¯t}Tt=1

in the denominator.

This creates a lower bound because Lemma 6 shows that the numerator is non-positive and Lemma 7

shows that fs

T t=1

x¯t

− L2 fs, {x¯t}Tt=1

≤

T t=1

vt

(x¯t

).

Inequality (j) follows from observing that 0

T t=1

x¯t

T 1. Hence,

βf,fs P s0 ≤ fs

T
x¯t
t=1

− f ∗ λ¯T − f

T
x¯t
t=1

+ L2 fs, {x¯t}Tt=1 .

Deﬁne

f ∗(∇fs(u))

αf,fs

:=

1 − βf,fs

=

0

sup
u T1

fs(u) − f (u) − 1

. (∇fs(u) − ∇fs(0))

27

We lower bound Ds0 by D by Lemma 5 so P s0 − Ds0 ≥ P s0βf,fs . Applying weak duality, we get that P s0 − P ≥ P s0βf,fs . Rearranging this equation gives us the following:

P s0

1

1

≥

=

.

P

1 − βf,fs αf,fs

This concludes the proof of Theorem 4.

D.2 Proof of Theorem 5
In order to show that Problem (Q-2) is a quasiconvex optimization problem, we must verify that the constraints are convex and the objective is quasiconvex. It suﬃces to show that
max f ∗(∇fs(u)) u∈U fs(u) − f (u) − 1 (∇fs(u) − ∇fs(0))

is a quasiconvex function in a. Since a non-negative weighted maximum of quasiconvex functions is also

quasiconvex, it suﬃces to show that

f ∗(∇fs(u))

is quasiconvex in a for a ﬁxed u. We can

fs(u)−f(u)−1 (∇fs(u)−∇fs(0))

directly apply the deﬁnition of quasiconvexity. Let Sα(fs) be the sub-level sets of fs for a ∈ RN . We have

the following:

Sα(fs) = a

1 f ∗(∇fs(u)) ≤ α fs(u) − f (u) − 1 (∇fs(u) − ∇fs(0))

= a 1 f ∗(∇fs(u)) ≤ α fs(u) − f (u) − 1 (∇fs(u) − ∇fs(0)) .

For a ﬁxed value of u, [∇fs(u)]d is linear in a for all d. Since f ∗ is always convex, composing a convex function with a linear function of a is convex in a. Finally, since fs(u) is linear in a,

fs(u) − f (u) − 1 (∇fs(u) − ∇fs(0))

must be linear in a, and thus the constraints of Sα(fs) are convex, directly implying that Sα(fs) is a convex set.

D.3 Proof of Theorem 6

In this subsection, we analyze Algorithm 2 called with fs satisfying Assumption 7.1 and voﬀset = 1. We

deﬁne the following quantities:

T

T

P s1 := vt(x¯t) − f

x¯t ,

t=1

t=1

TD

T

Ds1 :=

max [z¯t]d − λ¯t d , 0 − vt∗(z¯t) + f ∗ λ¯T .

t=1 d=1

t=1

Note that P s1 and Ds1 are identical to their counterparts, P s and Ds introduced in Section 3.2, with the only diﬀerence being that for P s1 and Ds1, x¯t, λ¯t, and z¯t come from Algorithm 2.
We ﬁrst show the following lemmas which aid in our analysis of the competitive ratio of Algorithm 2.

Lemma 8. If fs is increasing and fs has an increasing gradient, then D ≤ Ds1.

Proof. From the assumption that fs has an increasing gradient, we know that

∇fs

t−1
x¯i + 1
i=1

∇fs

T −1
x¯i + 1
i=1

28

for all t ∈ [T ] since x¯i 0 for all i ∈ [T ]. This, in turn, implies that λ¯t λ¯T for all t ∈ [T ] so that

TD

Ds1 =

max

t=1 d=1

TD

≥

max

t=1 d=1

[z¯t]d − [z¯t]d −

λ¯t d , 0 λ¯T d , 0

T
− vt∗(z¯t) + f ∗ λ¯T
t=1
T
− vt∗(z¯t) + f ∗ λ¯T
t=1

≥D .

In order for the ﬁnal inequality to hold, λ¯T and {z¯t}Tt=1 must be feasible points for the optimization problem deﬁning D , i.e., λ¯T 0 and z¯t 0 for all t ∈ [T ]. Since fs is increasing by assumption, we know that fs has a non-negative gradient, and similarly since vt is increasing by assumption, we know that vt has a non-negative gradient.
Lemma 9. If fs is increasing and fs has an increasing gradient, then P s1 ≤ Ds1.
Proof. The proof comes from relating P s1 to P followed by relating Ds1 to D with Lemma 8 and combining the two inequalities using weak duality. Trivially, P s1 ≤ P since

T
P s1 = vt(x¯t) − f
t=1

T
x¯t
t=1

T
≤ maximize vt(xt) − f
0 xt 1 t=1

T
xt
t=1

=P .

From Lemma 8, we have shown that Ds1 ≥ D and with weak duality implying that P ≤ D , we can conclude that P s1 ≤ P ≤ D ≤ Ds1.

We now show that Algorithm 2 does not make a decision which causes the objective to become negative.

Lemma 10. Let vt satisfy Assumption 3.1. If fs is convex and diﬀerentiable, fs has an increasing gradient,

and fs(0) = 0, then

T

T

vt(x¯t) − fs

x¯t ≥ 0.

t=1

t=1

Proof. Since fs(0) = 0, we have that

T
vt(x¯t) − fs
t=1

T
x¯t
t=1

(a) T
≥ ∇vt(x¯t) x¯t − fs

T
x¯t

t=1

t=1

T

t

t−1

=

∇vt(x¯t) x¯t − fs

x¯i + fs

x¯i

t=1

i=1

i=1

(b) T
≥

∇vt(x¯t) − ∇fs

t
x¯i , x¯t

t=1

i=1

(c) T
≥

t−1

∇vt(x¯t) − ∇fs

x¯i + 1 , x¯t .

t=1

i=1

Inequality (a) comes from concavity of vt and inequality (b) follows from convexity of fs. Inequality (c) comes from fs having an increasing gradient. Finally, the decision rule of Algorithm 2—i.e., x¯t = 1 z¯t − λ¯t 0 (as seen in Lemma 4) ensures that the inner product is always non-negative.

Now, we bound the competitive ratio of Algorithm 2. The general overview of the proof of Theorem 6 is as follows: writing Ds1 in terms of P s1, we bound the gap between Ds1 and P s1. From here, we lower bound Ds1 by D , which in turn allows us to use weak duality to relate D and P .

29

We start with writing Ds1 in terms of P s1:

TD

Ds1 =

max

t=1 d=1

[z¯t]d −

λ¯t d , 0

T
− vt∗(z¯t) + f ∗ λ¯T
t=1

T (a)
=

z¯t − λ¯t

T
x¯t − vt∗(z¯t) + f ∗ λ¯T

t=1

t=1

T (b)
= ∇vt(x¯t)
t=1

T
x¯t − ∇fs
t=1

t−1
x¯i + 1
i=1

T
x¯t − vt∗(∇vt(x¯t)) + f ∗ λ¯T
t=1

(c) T
≤ ∇vt(x¯t)
t=1

T
x¯t − ∇fs
t=1

t
x¯i
i=1

T
x¯t − vt∗(∇vt(x¯t)) + f ∗ λ¯T .
t=1

Equality (a) comes from the decision rule of Algorithm 2, which ensures that x¯t = 1 z¯t − λ¯t 0 . Equality

(b) comes from substituting the deﬁnition of λ¯t = ∇fs

t−1 i=1

x¯i

+

1

.

Inequality (c) comes from the

increasing gradient property of fs. Now, we apply the concave Fenchel-Young inequality at equality—i.e.,

Equation (3) with g = vt and u = x¯t, in order to decompose the vt∗(∇vt(x¯t)) term as follows:

T
Ds1 ≤ ∇vt(x¯t)
t=1

T
x¯t − ∇fs
t=1

t
x¯i
i=1

T
x¯t − vt∗(∇vt(x¯t)) + f ∗ λ¯T
t=1

T
= ∇vt(x¯t)
t=1

T
x¯t − ∇fs
t=1

t
x¯i
i=1

T
x¯t −
t=1

∇vt(x¯t)

x¯t − vt(x¯t)

T

T

= vt(x¯t) − ∇fs

t=1

t=1

t
x¯i
i=1

x¯t + f ∗ λ¯T

+ f ∗ λ¯T

Now, we proceed to bound the duality gap between Ds1 and P s1 by ﬁrst observing the following relationship:

(d) T
Ds1 ≤ vt(x¯t) − fs

T
x¯t + f ∗ λ¯T

t=1

t=1

T
= vt(x¯t) − fs

T
x¯t + f ∗ λ¯T + f

T
x¯t − f

T
x¯t

t=1

t=1

t=1

t=1

(e)
=

P

s1

−

fs

T
x¯t + f ∗ λ¯T + f

T
x¯t .

t=1

t=1

Inequality (d) follows directly from convexity of fs and (e) follows by substituting the deﬁnition of P s1 =

T t=1

vt(x¯t)

−

f

T t=1

x¯t

where in the preceding equality we add and subtract f

T t=1

x¯t

.

We bound

30

the gap between Ds1 and P s1 as a multiplicative factor of P s1 in order to relate these quantities as a ratio:

fs

T t=1

x¯t

− f ∗ λ¯T

−f

T t=1

x¯t

P s1

(f) fs =

T t=1

x¯t

− f ∗ ∇fs

T −1 t=1

x¯t

+

1

−f

T t=1

vt

(x¯t)

−

f

T t=1

x¯t

T t=1

x¯t

(g) fs ≥

T t=1

x¯t

− f ∗ ∇fs

fs

T t=1

x¯t

T −1 t=1

x¯t

+

1

−f

−f

T t=1

x¯t

T t=1

x¯t

fs =

T −1 t=1

x¯t

+

x¯T

fs

− f ∗ ∇fs

T −1 t=1

x¯t

+

x¯T

T −1 t=1

x¯t

+

1

−f

−f

T −1 t=1

x¯t

+

x¯T

T −1 t=1

x¯t

+

x¯T

(≥h) inf fs(u + x¯T ) − f ∗(∇fs(u + 1)) − f (u + x¯T )

0 u (T −1)1

fs(u + x¯T ) − f (u + x¯T )

(i)

fs(u) − f ∗(∇fs(u + 1)) − f (u)

≥ inf
0 u (T −1)1

fs(u) − f (u)

=: βf,fs .

In equality (f), we replace λ¯T with ∇fs

T −1 i=1

x¯i

+

1

.

Inequality (g) follows from replacing

T t=1

vt

(x¯t

)

with fs

T t=1

x¯t

in the denominator. This creates a lower bound because Lemma 9 shows that the nu-

merator is non-positive and Lemma 10 shows that fs

T t=1

x¯t

≤

T t=1

vt

(x¯t

).

Inequality

(h)

follows

from

observing that 0

T −1 t=1

x¯t

(T − 1) 1. Inequality (i) comes from seeing that b−ba is increasing in b for

a, b > 0, where fs(u) − f (u) = b and f ∗(∇fs(u + 1)) = a, and fs(u) − f (u) is increasing in u by assumption.

Hence,

T

T

βf,fs P s1 ≤ fs

x¯t − f ∗ λ¯T − f

x¯t .

t=1

t=1

Deﬁne

f ∗(∇fs(u + 1))

αf,fs := 1 − βf,fs = sup
0 u (T −1)1

fs(u) − f (u)

.

Note that the assumption that fs(u) ≥ f (u) for all 0 u (T − 1) 1 ensures that αf,fs ≥ 0, which ensures

that the competitive ratio is non-negative. We lower bound Ds1 by D with Lemma 8 so P s1 − Ds1 ≥

P s1βf,fs . Applying weak duality, we get that P s1 − P ≥ P s1βf,fs . Rearranging this equation gives us the

following:

P s1

1

1

≥

=

.

P

1 − βf,fs αf,fs

This concludes the proof of Theorem 6.

D.4 Proof of Theorem 7
In order to show that Problem (Q-3) is a quasiconvex optimization problem, we must verify that the constraints are convex and the objective is quasiconvex. It suﬃces to show that
max f ∗(∇fs(u + 1)) u∈U fs(u) − f (u)
is a quasiconvex function in a. Since a non-negative weighted maximum of quasiconvex functions is also quasiconvex, it suﬃces to show that f∗(∇fs(u+1)) is quasiconvex in a for a ﬁxed u. We can directly apply the
fs(u)−f(u)

31

deﬁnition of quasiconvexity. Let Sα(fs) be the sub-level sets of fs for a ∈ RN . We have the following:

Sα(fs) = a = {a

1 f ∗(∇fs(u + 1)) ≤ α fs(u) − f (u)
1 | f ∗(∇fs(u + 1)) ≤ α (fs(u) − f (u))} .

For a ﬁxed value of u, [∇fs(u + 1)]d is linear in a for all d and since f ∗ is always convex, composing a convex function with a linear function of a is convex in a. Finally, since fs(u) is linear in a, the constraints
of Sα(fs) are convex, and thus Sα(fs) is a convex set.

32

