arXiv:1907.01060v6 [math.PR] 6 Jan 2021

Министерство науки и высшего образования Российской Федерации Федеральное государственное автономное
образовательное учреждение высшего образования «Московский физико-технический институт
(национальный исследовательский университет)»
ЛЕКЦИИ
ПО СЛУЧАЙНЫМ ПРОЦЕССАМ
Под редакцией А. В. Гасникова
МОСКВА МФТИ 2019

УДК 519.21(075) ББК 22.317я73
Л43
А в т о р ы: А. В. Гасников, Э. А. Горбунов, С. А. Гуз, Е. О. Черноусова,
М. Г. Широбоков, Е. В. Шульгин
Рецензенты: Институт проблем передачи информации
профессор В. Г. Спокойный НИУ Высшая школа экономики
доцент А. А. Наумов
Л43 Лекции по случайным процессам : учебное пособие / А. В. Гасников, Э. А. Горбунов, С. А. Гуз и др. ; под ред. А. В. Гасникова. – Москва : МФТИ, 2019. – 285 с. ISBN 978-5-7417-0710-4
Учебное пособие содержит конспект лекций и материалы семинарских занятий по курсу «Случайные процессы», десятилетиями формировавшемуся сотрудниками кафедры математических основ управления ФУПМ МФТИ А. А. Натаном, С. А. Гузом и О. Г. Горбачевым.
Написано на достаточно элементарном языке и рассчитано на широкую аудиторию (не только студентов МФТИ).
УДК 519.21(075) ББК 22.317я73

Печатается по решению Редакционно-издательского совета Московского физико-технического института (национального исследовательского университета)

ISBN 978-5-7417-0710-4

© Гасников А. В., Горбунов Э. А., Гуз С. А., Черноусова Е. О.,Широбоков М. Г., Шульгин Е В., 2019
© Федеральное государственное автономное образовательное учреждение высшего образования «Московский физико-технический институт (национальный исследовательский университет)», 2019

Оглавление
Список обозначений . . . . . . . . . . . . . . . . . . . . . . . . . 6
Обязательная часть программы учебного курса «Случайные процессы» . . . . . . . . . . . . . . . . . . . . . 7
Введение . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
1. Случайные процессы, примеры . . . . . . . . . . . . . . . 9 1.1. Базовые понятия и примеры . . . . . . . . . . . . . . . . . 9 1.2. Моментные характеристики процессов . . . . . . . . . . . 18 1.3. Винеровский процесс . . . . . . . . . . . . . . . . . . . . . 21 1.4. Пуассоновский процесс . . . . . . . . . . . . . . . . . . . . 28 1.5. Безгранично делимые случайные величины . . . . . . . . 41 1.6. Процессы Леви . . . . . . . . . . . . . . . . . . . . . . . . . 46
2. Введение в стохастический анализ . . . . . . . . . . . . . 52 2.1. Пространство L2 случайных величин . . . . . . . . . . . . 52 2.2. Непрерывность в среднем квадратичном . . . . . . . . . . 55 2.3. Дифференцируемость в среднем квадратичном . . . . . . 57 2.4. Интегрируемость в среднем квадратичном . . . . . . . . 59 2.5. Полезные формулы и примеры . . . . . . . . . . . . . . . 61 2.6. Интеграл Римана–Стилтьеса . . . . . . . . . . . . . . . . 63 2.7. Стохастический интеграл и формула Ито . . . . . . . . . 64 2.8. Стохастические дифференциальные уравнения* . . . . . 69
3. Гауссовские случайные процессы . . . . . . . . . . . . . . 70 3.1. Моментные характеристики . . . . . . . . . . . . . . . . . 70 3.2. Условные распределения сечений . . . . . . . . . . . . . . 74
4. Стационарные процессы . . . . . . . . . . . . . . . . . . . . 80 4.1. Комплекснозначные случайные процессы . . . . . . . . . 80 4.2. Стационарность в широком и узком смыслах . . . . . . . 81 4.3. Корреляционная функция . . . . . . . . . . . . . . . . . . 89 4.4. Спектральное представление процессов . . . . . . . . . . 93 4.5. Закон больших чисел для вещественнозначных стационарных в широком смысле процессов в дискретном и непрерывном времени. . . . . . . . . . . . . . . . . . . . . 102 4.6. Линейные преобразования процессов . . . . . . . . . . . . 103
5. Эргодические процессы . . . . . . . . . . . . . . . . . . . . 109 5.1. Эргодические случайные процессы . . . . . . . . . . . . . 109
3

5.2. Эргодические динамические системы . . . . . . . . . . . . 117
6. Дискретные цепи Маркова . . . . . . . . . . . . . . . . . . 128 6.1. Базовые определения и примеры . . . . . . . . . . . . . . 128 6.2. Классификация состояний . . . . . . . . . . . . . . . . . . 134 6.3. Эргодические дискретные цепи Маркова . . . . . . . . . . 148
7. Непрерывные цепи Маркова . . . . . . . . . . . . . . . . . 180 7.1. Базовые понятия и предположения . . . . . . . . . . . . . 180 7.2. Классификация состояний . . . . . . . . . . . . . . . . . . 195 7.3. Эргодические непрерывные цепи Маркова . . . . . . . . . 198 7.4. Поведение цепи и время возвращения . . . . . . . . . . . 202
8. Непрерывные процессы Маркова . . . . . . . . . . . . . . 204 8.1. Уравнения Колмогорова . . . . . . . . . . . . . . . . . . . 204 8.2. Процесс Ито и формула Дынкина . . . . . . . . . . . . . . 210
ПРИЛОЖЕНИЯ . . . . . . . . . . . . . . . . . . . . . . . . . . . 216
А. Модель Эренфестов . . . . . . . . . . . . . . . . . . . . . . . 216
Б. Вектор PageRank и Google Problem . . . . . . . . . . . . 224 Б.1. Google problem и эргодическая теорема . . . . . . . . . . 224 Б.2. Стандартные численные подходы к решению задачи . . . 227 Б.3. Markov Chain Monte Carlo и Google problem . . . . . . . . 231 Б.4. Параллелизуемый вариант MCMC . . . . . . . . . . . . . 234 Б.5. Модель Бакли—Остгуса и степенные законы . . . . . . . 240 Б.6. Элементы теории макросистем . . . . . . . . . . . . . . . 244
В. Задача о разборчивой невесте . . . . . . . . . . . . . . . . 247 В.1. Формулировка задачи . . . . . . . . . . . . . . . . . . . . . 247 В.2. Оптимальная стратегия . . . . . . . . . . . . . . . . . . . 247 В.3. Управляемые марковские процессы . . . . . . . . . . . . . 248 В.4. Принцип динамического программирования . . . . . . . . 248 В.5. Поиск оптимальной стратегии невесты . . . . . . . . . . . 249
Г. Задача о многоруких бандитах . . . . . . . . . . . . . . . . 253 Г.1. Формулировка задачи . . . . . . . . . . . . . . . . . . . . . 253 Г.2. Уравнение Вальда–Беллмана . . . . . . . . . . . . . . . . 253 Г.3. Индексы Гиттинса . . . . . . . . . . . . . . . . . . . . . . . 255 Г.4. Q-обучение . . . . . . . . . . . . . . . . . . . . . . . . . . . 256 Г.5. Асимптотически оптимальные оценки . . . . . . . . . . . 258
4

Заключение . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261 Литература . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
5

Список обозначений

(Ω, F, P) – вероятностное пространство (Ω – множество исходов, F – σ-алгебра, P – вероятностная мера). EX, E(X) – математическое ожидание случайной величины X. DX, D(X) – дисперсия случайной величины X. cov(X, Y ) – корреляционный момент случайных величин X и Y . Be(p) – распределение Бернулли. Po(λ) – распределение Пуассона. R(a, b) – непрерывное равномерное распределение на отрезке [a, b]. N(µ, σ2) – нормальное распределение. Exp(λ) – показательное распределение с параметром λ. B(α, β) – бета-распределение. Φ(x) – функция стандартного нормального распределения N(0, 1). −d→ – сходимость по распределению. −p→, −P→ – сходимость по вероятности. −п.→н. – сходимость с вероятностью 1 (почти наверное). =d – равенство по распределению. с.к. – в среднем квадратичном. ЗБЧ – закон больших чисел. х.ф. – характеристическая функция. ЦПТ – центральная предельная теорема. i.i.d. – independent identically distributed random variables. ⟨·, ·⟩ – скалярное произведение. Индикаторная функция:

I(true) = [true] = 1, I(false) = [false] = 0.

√︄

∥x∥22 =

n
∑︁ x2k, где x ∈ Rn.
k=1

Lp(X, µ) – пространство интегрируемых функций по мере µ (если µ не

указана, то рассматривается мера Лебега на множестве X). Норма в

Lp(X, µ) определяется следующим образом:

(︃ˆ

)︃1/p

∥f ∥Lp =

|f (x)|pdµ(x) .

X

R+ – неотрицательные вещественные числа. ∀ – квантор «для всех» ∃ – квантор «существует»

6

ОБЯЗАТЕЛЬНАЯ ЧАСТЬ ПРОГРАММЫ УЧЕБНОГО КУРСА
«Случайные процессы»
Определение понятия «случайный процесс». Система конечномерных распределений случайного процесса, ее свойства. Моментные функции случайного процесса. Корреляционная и взаимная корреляционная функции случайных процессов, их свойства. Преобразования случайных процессов. Непрерывность случайного процесса в среднем квадратическом, ее необходимое и достаточное условие. Непрерывность случайного процесса по вероятности и с вероятностью единица. Производная случайного процесса в среднем квадратическом, необходимое и достаточное условие ее существования. Интеграл от случайного процесса в среднем квадратическом, необходимое и достаточное условие его существования. Стационарный случайный процесс. Строгая и слабая стационарность случайного процесса. Взаимная стационарность случайных процессов. Эргодичность случайного процесса по математическому ожиданию в среднем квадратическом. Условия эргодичности по математическому ожиданию. Спектральное представление стационарного случайного процесса. Теорема Хинчина о спектральном представлении корреляционной функции случайного процесса. Спектральная функция и спектральная плотность случайного процесса, их свойства и приложение. Случайный процесс типа «белый шум». Пуассоновский случайный процесс. Сложный пуассоновский процесс. Гауссовский (нормальный) случайный процесс, его свойства. Винеровский случайный процесс. Процессы Леви. Марковский случайный процесс. Дискретная марковская цепь. Переходные вероятности. Уравнения Колмогорова–Чепмена. Однородные дискретные марковские цепи. Классификация состояний дискретной марковской цепи, теорема о «солидарности» их свойств. Управляемые марковские процессы. Уравнение Вальда–Беллмана. Задача о разборчивой невесте. Асимптотическое поведение дискретной марковской цепи. Предельное и стационарное распределения вероятностей состояний дискретной марковской цепи. Теоремы об эргодичности дискретных марковских цепей. Марковская цепь с непрерывным аргументом. Прямое и обратное уравнения Колмогорова–Феллера. Примеры приложения теории марковских цепей (модель Эренфестов, модель ранжирования web-страниц). Концепция равновесия макросистемы на примере задачи поиска вектора Page Rank. Непрерывный марковский процесс. Обобщенное уравнение Маркова. Уравнения Колмогорова и Колмогорова–Фоккера–Планка.
7

Введение
Курс теории случайных процессов читается студентам на факультете управления и прикладной математики МФТИ в весеннем семестре третьего курса. В осеннем семестре студенты изучают теорию вероятностей, в осеннем семестре четвертого курса – математическую статистику. Данный цикл вероятностных дисциплин входит в обязательную программу бакалавриата ФУПМ МФТИ на протяжении нескольких десятков лет [42, 43, 44]. Изначально в курсе случайных процессов большой акцент делался на задачах, связанных с исследованием операций [12, 13] (системы массового обслуживания [24], динамическое программирование [74], затем курс стал немного смещаться в сторону приложений к страхованию (актуарной математике [60, 61]) и финансовой математике [70]. Примеры, собранные в ряде основных учебников, определенно свидетельствуют об этом [10, 50, 62, 69].
Однако в последнее время, прежде всего в связи с бурным развитием, анализа данных в программу обучения магистров ФУПМ стали входить: дополнительные главы математической статистики, статистическая теория обучения и онлайн оптимизация, стохастическая оптимизация, обучение с подкреплением, моделирование интернета (случайные графы и модели их роста), стохастические дифференциальные уравнения. Все эти предметы оказались сильно завязаны на курс случайных процессов. Возникла необходимость в адаптации курса. К сожалению, большая нагрузка студентов третьего курса ФУПМ не позволила существенно изменить объем излагаемого материала. Тем не менее, некоторые акценты было решено немного изменить.
Предлагаемое пособие во многом написано на базе курса (пособия) [43], однако содержит больше примеров и материала, отражающего некоторые современные приложения теории случайных процессов. Такие, например, как Метод Монте-Карло для марковских цепей (Markov Chain Monte Carlo).
Материалы, собранные разделах Б и Г, разрабатывались в ходе кооперации с компаниями Яндекс и Хуавей.
Авторы хотели бы выразить благодарность своим коллегам по кафедре Математических основ управления за помощь в создании данного пособия: Олегу Геннадьевичу Горбачеву и Ольге Сергеевне Федько. Также хотели бы выразить признательность студентам МФТИ, помогавшим с набором данного курса лекций.
Замечания и пожелания просьба присылать на адрес электронной почты кафедры математических основ управления физтех-школы прикладной математики и информатики МФТИ mou@mail.mipt.ru.
8

1. Случайные процессы, примеры
1.1. Базовые понятия и примеры
Цель данного раздела – ввести новое для читателя понятие: случайный процесс. По своей сути, случайный процесс – это некоторое обобщение понятия случайной величины из курса Теории вероятностей. А именно, это параметризованное семейство случайных величин. Параметр может быть скалярным (случай, описываемый в этой книге), векторным (тогда говорят о случайных полях ) или даже функцией (обобщенные случайные процессы). Вводится понятие реализации случайного процесса, его многомерной функции распределения. Появляется и качественно новое для читателя понятие – сечение случайного процесса.
Кроме того, здесь же появляются определения самых важных с точки зрения последующего изложения процессов – винеровского процесса, пуассоновского процесса и процесса Леви.
Определение 1.1. Случайным процессом называется семейство случайных величин X(ω, t), ω ∈ Ω, заданных на одном вероятностном пространстве (Ω, F, P) и зависящих от параметра t, принимающего значения из некоторого множества T ⊆ R. Параметр t обычно называют временем.
Если множество T состоит из одного элемента, то случайный процесс состоит из одной случайной величины и, стало быть, является случайной величиной. Если T содержит n ≥ 1 элементов, то случайный процесс представляет собой случайный вектор с n компонентами. Если T = N, то случайный процесс представляет собой случайную последовательность (X1(ω), X2(ω), . . . , Xn(ω), . . . ). Если T = [a, b], −∞ ≤ a < b ≤ +∞, то такой процесс называют случайной функцией.
Определение 1.2. При фиксированном времени t = t0 случайная величина X(ω, t0) называется сечением процесса в точке t0. При фиксированном исходе ω = ω0 функция времени X(ω0, t) называется траекторией (реализацией, выборочной функцией) процесса.
К случайному процессу всегда следует относиться как к функции двух переменных: исхода ω и времени t. Это независимые переменные. Заметим, впрочем, что в записи случайного процесса X(ω, t) аргумент ω обычно опускают и пишут просто X(t). Точно так же поступают и со случайными величинами – вместо X(ω) пишут X. Надо помнить, однако, что во всех случаях зависимость от ω подразумевается. Записи X(ω, t) или X(ω) используются в тех случаях, когда необходимо явно подчеркнуть функциональную зависимость случайного процесса
9

или случайной величины от исхода ω. Иногда для случайного процесса используют обозначение {X(t), t ∈ T }, чтобы явно подчеркнуть множество времени T , на котором определен процесс.
Пример 1.1. Рассмотрим процесс ξ(ω, t) = t · η(ω), где η ∈ R(0, 1), t ∈ [0, 1] = T . В качестве вероятностного пространства здесь рассмотрим тройку (Ω, F, P), где пространство исходов Ω = [0, 1], σ-алгебра является борелевской F = B(R), а вероятностная мера совпадает с мерой Лебега на отрезке [0, 1]. В этом случае случайная величина η(ω) = ω, а случайный процесс ξ(ω, t) = t · ω. Тогда при фиксированном ω0 ∈ [0, 1] траектория представляет собой линейную функцию ξ(ω0, t) = ω0t, принимающую значение ноль в момент t = 0 и значение ω0 в момент t = 1. Если же зафиксировать t0 ∈ (0, 1], то получится случайная величина ξ(ω, t0) = t0ω, равномерно распределенная на отрезке [0, t0], т.е. ξ(ω, t0) ∈ R(0, t0). При t0 = 0 получается вырожденная случайная величина: ξ(ω, 0) = 0 при всех ω ∈ [0, 1]. △
Мы обращаем внимание читателя на то, что в данном примере траектория процесса однозначно восстанавливается по ее части: достаточно узнать наклон траектории на любом интервале времени. На практике же более типичная ситуация – это когда предыстория не позволяет однозначно восстановить траекторию процесса и узнать ее будущее. В таких случаях различным исходам ω1 и ω2 может соответствовать одна и та же наблюдаемая до текущего момента времени предыстория, но будущее этих траекторий может отличаться.
В приложениях случайные величины часто задаются не как явные функции исходов, а через вероятностное распределение. Вероятностное распределение случайных величин однозначно определяется функцией распределения. Случайные векторы также имеют функцию распределения:
FX (x1, . . . , xn) = P(X1 < x1, . . . , Xn < xn)
для случайного вектора X = (X1, . . . , Xn) с n компонентами. Определим теперь функцию распределения для случайного процесса.
Пусть даны n ≥ 1 сечений X(t1), . . . , X(tn) случайного процесса {X(t), t ∈ T }; t1, . . . , tn ∈ T . Так как по определению случайного процесса сечения заданы на одном вероятностном пространстве, то они образуют случайный вектор (X(t1), . . . , X(tn)). Функция распределения такого вектора
FX (x1, . . . , xn; t1, . . . , tn) = P(X(t1) < x1, . . . , X(tn) < xn) (1)
зависит от n и параметров t1, . . . , tn из множества T .
10

Определение 1.3. Функция распределения из (1) называется nмерной функцией распределения случайного процесса X(t). Совокупность функций распределения (1) для различных n ≥ 1 и всех возможных моментов времени t1, . . . , tn из множества T называется семейством конечномерных распределений случайного процесса X(t).
Пример 1.2. Рассмотрим случайный процесс ξ(t) = tη, t ∈ (0, 1), где η ∈ R[0, 1]. Для произвольных n ≥ 1 и t1, . . . , tn ∈ (0, 1) найдем его n-мерную функцию распределения:

Fξ(x1, . . . , xn; t1, . . . , tn) = P(ξ(t1) < x1, . . . , ξ(tn) < xn) =

(︃ x1

xn )︃

= P(t1η < x1, . . . , tnη < xn) = P η < , . . . , η <

=

t1

tn

(︃

xk )︃

(︃

xk )︃

= P η < min

= Fη min

,

1≤k≤n tk

1≤k≤n tk

где функция распределения случайной величины η равна

⎧ 0, y ≤ 0, ⎨ Fη(y) = y, y ∈ (0, 1], △ ⎩ 1, y > 1.

Семейство конечномерных распределений – это основная характеристика вероятностных свойств случайного процесса. Мы будем считать, что случайный процесс задан, если задано его семейство конечномерных распределений или если явно задано вероятностное пространство и соответствующая функция двух переменных – исхода и времени.
Пример 1.3. На вероятностном пространстве (︁[0, 1], B[0,1], λ[0,1])︁, состоящем из пространства элементарных исходов [0, 1], борелевской σ-алгебры B[0,1] подмножеств множества [0, 1] и меры Лебега λ[0,1], определен случайный процесс
ξ(ω, t) = {︃ 1, t ≤ ω, 0, t > ω.

Время определено на множестве T = [0, 1]. Найти траектории, сечения и двумерное распределение процесса. Исследовать сечения на попарную независимость.
Решение. Чтобы определить траектории процесса, зафиксируем произвольный исход ω0 ∈ [0, 1] и изобразим на графике зависимость ξ(ω0, t), см. рис. 1. По условию задачи ξ(ω0, t) = 1 при t ≤ ω0, а при t ∈ (ω0, 1] получаем ξ(ω0, t) = 0.

11

Рис. 1. Типичная траектория процесса ξ(ω, t) из примера 1.3

Чтобы определить сечения процесса, зафиксируем время t0 ∈ [0, 1]. Случайная величина ξ(ω, t0) может принимать только два значения: 0 и 1. Следовательно, она имеет распределение Бернулли Be(p) с некоторым параметром p. Напоминаем, что p есть вероятность принятия случайной величиной значения 1. Но случайная величина ξ(ω, t0) принимает значение 1 только при t0 ≤ ω ≤ 1. Вероятностная мера на отрезке [0, 1] по условию задачи является мерой Лебега, причем такой, что λ[0,1]([a, b]) = b − a для любого отрезка [a, b] ⊂ [0, 1]. Значит, искомая вероятность

p = P({ω : ξ(ω, t0) = 1}) = P({ω : t0 ≤ ω ≤ 1}) = 1 − t0,

поэтому произвольное сечение ξ(t) ∈ Be(1 − t), t ∈ [0, 1]. Запишем по определению формулу двумерной функции распреде-
ления: Fξ(x1, x2; t1, t2) = P(ξ(t1) < x1, ξ(t2) < x2).

Вычислим эту вероятность, рассмотрев все возможные значения x1 и x2, считая, что t1 и t2 принадлежат отрезку T = [0, 1]. Начнем с крайних случаев, когда хотя бы один из x1 или x2 превысит единицу или меньше нуля. Анализируя по отдельности случаи, можно прийти к выражению

⎧
⎪ ⎪ ⎪ ⎪ ⎨
Fξ(x1, x2; t1, t2) =
⎪ ⎪ ⎪ ⎪ ⎩

1, 0, t2, t1, min(t1, t2),

x1 > 1 и x2 > 1, x1 ≤ 0 или x2 ≤ 0, x1 > 1 и x2 ∈ (0, 1], x2 > 1 и x1 ∈ (0, 1], x1 ∈ (0, 1] и x2 ∈ (0, 1].

Здесь мы учли, что сечение ξ(t) принимает значение 1 с вероятностью 1 − t и значение 0 с вероятностью t. При подсчете первых четырех

12

выражений достаточно было информации о том, что сечения ξ(t) имеют распределение Бернулли. При вычислении последнего выражения этой информации недостаточно, требуется воспользоваться конкретным видом функции ξ(ω, t):
P(ξ(t1) < x1, ξ(t2) < x2) = P({ω : ξ(ω, t1) = 0, ξ(ω, t2) = 0}),
= P({ω : 0 ≤ ω < t1, 0 ≤ ω < t2}),
= P({ω : 0 ≤ ω < min(t1, t2)}),
= min(t1, t2).
Теперь исследуем произвольные два сечения ξ(t1) и ξ(t2) процесса на независимость. Для этого проверим наличие равенства в выражении
P(ξ(t1) < x1, ξ(t2) < x2) = P(ξ(t1) < x1) P(ξ(t2) < x2)
для всех x1 и x2 из R. Если x1 ∈/ (0, 1] или x2 ∈/ (0, 1], то это равенство очевидно выполнено, причем для любых t1 и t2. При x1 ∈ (0, 1] и x2 ∈ (0, 1] это равенство равносильно
min(t1, t2) = t1t2,
что верно лишь в случаях, когда хотя бы одно из значений t1 или t2 равно нулю или единице. В таких случаях ξ(t1) и ξ(t2) являются независимыми случайными величинами. В остальных случаях, т.е. когда t1 ̸= 0, 1 и t2 ̸= 0, 1, сечения ξ(t1) и ξ(t2) являются зависимыми случайными величинами. △
Пример 1.4. Пусть дан тот же самый процесс, что и в предыдущем примере, и мы можем его наблюдать. Пусть на отрезке времени [0, t0] значение процесса все еще равно единице. С какой вероятностью скачок до нуля произойдет на интервале времени [t0, t0 + ∆t], где ∆t < 1 − t0?
Решение. Нам доступна информация о том, что на отрезке [0, t0] траектория процесса ξ(ω, t0) = 1. Ясно, что скачок может произойти почти сразу после t0 или позже. Таким образом, данная нам предыстория процесса не позволяет однозначно определить поведение траектории в будущем. Однако вероятность скачка на наперед заданном интервале времени можно рассчитать точно. Воспользуемся для этого аппаратом условных вероятностей. Пусть событие A состоит в том, что скачок произойдет в интервале времени [t0, t0 + ∆t], а событие B состоит в том, что на интервале времени [0, t0] скачка нет. Тогда по условию задачи необходимо вычислить условную вероятность
P(A | B) = P(A ∩ B) . P(B)
13

Так как из события A следует событие B, то A ∩ B = A. Далее,

P(A) = P({ω : t0 ≤ ω ≤ t0 + ∆t}) = ∆t,

P(B) = P({ω : t0 ≤ ω ≤ 1}) = 1 − t0.

Отсюда ответ:

∆t P(A | B) = 1 − t0 .

Это и есть вероятность того, что скачок произойдет в ближайшее время ∆t при условии, что до момента t0 скачка не было. Отметим, что если скачок до момента t0 произошел, то будущее процесса определено однозначно – его значение так и останется равным нулю. △
Произвольная n-мерная функция распределения случайного процесса ξ(t) обладает следующими свойствами:

а) 0 ≤ Fξ(x1, . . . , xn; t1, . . . , tn) ≤ 1.

б) Функции Fξ(x1, . . . , xn; t1, . . . , tn) непрерывны слева по каждой переменной xi.

в) Если хотя бы одна из переменных xi → −∞, то

Fξ(x1, . . . , xn; t1, . . . , tn) → 0,

если же все переменные xi → +∞, то

Fξ(x1, . . . , xn; t1, . . . , tn) → 1.

г) Функции Fξ(x1, . . . , xn; t1, . . . , tn) монотонны в следующем смысле:
∆1 . . . ∆nFξ(x1, . . . , xn; t1, . . . , tn) ≥ 0, где ∆i – оператор конечной разности по переменной xi
∆iF = F (x1, . . . , xi−1, xi + hi, xi+1, . . . , xn; t1, . . . , tn)−
−F (x1, . . . , xi−1, xi, xi+1, . . . , xn; t1, . . . , tn) а h1 ≥ 0, . . . , hn ≥ 0 произвольны.
д) Для любой перестановки {k1, . . . , kn} индексов {1, . . . , n}
Fξ(x1, . . . , xn; t1, . . . , tn) = Fξ(xk1 , . . . , xkn ; tk1 , . . . , tkn ).

14

е) Для любых 1 ≤ k < n и x1, . . . , xk ∈ R
Fξ(x1, . . . , xk; t1, . . . , tk) = Fξ(x1, . . . , xk, +∞, . . . , +∞; t1, . . . , tn).
Пусть дано некоторое семейство функций F (x1, . . . , xn; t1, . . . , tn), обладающее свойствами а)–е). Всегда ли можно подобрать случайный процесс с соответствующими n-мерными функциями распределения? Положительный ответ на этот вопрос дает теорема Колмогорова.
Теорема 1.1 (Колмогоров). Пусть задано некоторое семейство функций
F = {F (x1, . . . , xn; t1, . . . , tn), xi ∈ R, ti ∈ T, i = 1, . . . , n, n ≥ 1},
удовлетворяющих условиям а)–е). Тогда существуют вероятностное пространство (Ω, F, P) и случайный процесс {ξ(t), t ∈ T }, определенный на этом вероятностном пространстве, такие, что семейство конечномерных распределений Fξ случайного процесса ξ(t) совпадает с F.
Напомним читателю, что функция распределения не задает случайную величину однозначно как функцию: может оказаться, что на одном и том же вероятностном пространстве существуют две случайные величины ξ(ω) и η(ω) с совпадающими функциями распределения. Точно так же семейство конечномерных распределений может неоднозначно определять случайный процесс. Это нас приводит к необходимости ввести понятие эквивалентности случайных процессов.
Определение 1.4. Пусть {ξ(t), t ∈ T } и {η(t), t ∈ T } – два случайных процесса, определенные на одном и том же вероятностном пространстве (Ω, F, P) и принимающие значения в одном и том же измеримом пространстве. Если для любого t ∈ T
P(ξ(t) = η(t)) = 1,
то эти процессы называются стохастически эквивалентными или просто эквивалентными. При этом ξ(t) называется модификацией процесса η(t), а η(t) – модификацией процесса ξ(t).
Легко показать, что конечномерные распределения эквивалентных процессов совпадают. В теории случайных процессов понятие эквивалентности процессов чрезвычайно важно, так как позволяет обосновать возможность расчета вероятности каких-нибудь событий, связанных с процессом, переходом к другому, эквивалентному, процессу. Например, пусть на вероятностном пространстве (Ω, F, P) дан какойнибудь процесс {ξ(t), t ≥ 0} с непрерывным временем и непрерывным
15

множеством значений на R и допустим, что нам требуется вычислить следующую вероятность:

(︄

)︄

P sup ξ(t) ≤ x .
t∈[0,1]

Вероятность определена лишь для элементов сигма-алгебры F, но принадлежит ли событие, записанное под вероятностью, этой сигма-алгебре? Супремум процесса не превосходит x на отрезке [0, 1] тогда и только тогда, когда в каждый момент времени t ∈ [0, 1] выполнено ξ(t) ≤ x. И хотя событие {ξ(t) ≤ x} является элементом сигма-алгебры F, несчетное пересечение таких событий для разных t ∈ [0, 1] может не быть элементом сигма-алгебры. Однако если все или почти все траектории процесса ξ(t) непрерывны на [0, 1], то супремум по [0, 1] можно заменить супремумом по рациональным точкам отрезка [0, 1], а это счетное пересечение событий сигма-алгебры. На самом деле траектории этого процесса не обязаны быть непрерывными, достаточно лишь, чтобы у процесса существовала его непрерывная модификация (модификация с почти всеми непрерывными траекториями). Установить существование непрерывной модификации процесса помогает следующая теорема.
Теорема 1.2 (Колмогоров [11]). Пусть {ξ(t), t ∈ T } – случай-
ный процесс и T = [a, b]. Если существуют α > 0, β > 0, c < ∞,
такие, что при всех t, t + h ∈ [a, b] выполнено неравенство
E |ξ(t + h) − ξ(t)|α ≤ c|h|1+β,

то ξ(t) имеет непрерывную модификацию.
Если непрерывная модификация процесса ξ(t) существует, то всегда можно так определить вероятностное пространство и сигму-алгебру F (с сохранением семейства конечномерных распределений), на которых задан этот процесс, что условия на процесс в несчетном числе точек можно заменить на условия в счетном числе точек, и множества типа {supt∈[0,1] ξ(t) ≤ x} становятся измеримыми, вероятность их определена.
Если непрерывной модификации процесса не существует или по каким-то причинам трудно установить ее существование, то на помощь может прийти следующее понятие.
Определение 1.5. Случайный процесс {ξ(t), t ∈ T } называется сепарабельным, если множество T содержит всюду плотное счетное подмножество S, такое, что для любого интервала I ⊂ T справедливо

(︃

)︃

P sup ξ(t) = sup ξ(t), inf ξ(t) = inf ξ(t) = 1.

t∈I ∩S

t∈I

t∈I ∩S

t∈I

16

Оказывается, что любой процесс с непрерывным временем имеет сепарабельную модификацию, и всегда можно построить вероятностное пространство и сигму-алгебру, на которых определен случайный процесс, таким образом, что множества, связанные со значениями процесса в несчетном числе точек, станут измеримыми. Впрочем, этот серьезный математический факт остается во многих случаях чисто теоретическим – для практических расчетов все равно потребуется знать множество сепарабельности S, которое следует дополнительно искать. Ситуация здесь упрощается в случае, когда исходный процесс ξ(t) является стохастически непрерывным.
Определение 1.6. Случайный процесс {ξ(t), t ∈ T } называется стохастически непрерывным, если в каждый момент времени t
∀ε > 0 lim P(|ξ(t + h) − ξ(t)| > ε) = 0.
h→0
Оказывается, что если случайный процесс является стохастически непрерывным, то в качестве множества сепарабельности S его сепарабельной модификации можно брать любое всюду плотное счетное подмножество S, например, множество рациональных чисел, поэтому поиском такого множества в этом случае заниматься не приходится.
Несколько слов добавим вообще про способы задания случайного процесса. С практической точки зрения удобно задавать и определять процессы через семейства конечномерных распределений. Именно такой подход и принят в настоящем пособии. Однако задание семейства конечномерных распределений неоднозначно определяет случайный процесс как функцию двух переменных; так же, как и функция распределения неоднозначно определяет случайную величину как функцию исхода. В литературе можно встретить случаи, когда вместе с процессом определяется вероятностное пространство, которому процесс принадлежит. Пространством исходов такого вероятностного пространства часто выступает какое-то множество функций, которому принадлежат траектории процесса. Например, это может быть множество всех функций, заданных на множестве времени T (для этого обычно используется обозначение RT ), или множество непрерывных функций на T (обозначение может быть, например, C(T )). Кроме того, много внимания уделяется сигма-алгебрам на таких пространствах исходов. Обычно сигма-алгебра определяется как минимальная сигмаалгебра, которая содержит какой-то набор более простых множеств. Например, в качестве такого набора может выступать набор цилиндрических множеств: множеств вида
{X(t1) ∈ B1, . . . , X(tn) ∈ Bn},
17

где B1, . . . , Bn – борелевские множества из R. Название оправдано следующей геометрической аналогией: если T = {1, 2, 3}, то для случайного вектора (X1, X2, X3) множество C = {X1 ∈ B1, X2 ∈ B2} представляет собой цилиндр с образующей, параллельной третьей оси. Вероятности на цилиндрических множествах определяют вероятность произвольных множеств из сигма-алгебры ими порожденной. Причем задание вероятности на цилиндрических множествах равносильно заданию семейства конечномерных распределений.

1.2. Моментные характеристики процессов

Теперь, когда все формальные сведения о распределении случайных процессов даны, перейдем к их моментным характеристикам. Мы дадим определение математическому ожиданию, а также корреляционной и ковариационной функции случайного процесса. Когда мы будем давать эти определения, мы будем предполагать, что дан случайный процесс {X(t), t ∈ T }, каждое сечение которого на T имеет конечный второй момент EX2(t) < ∞. Такие процессы называются случайными процессами второго порядка, а множество таких процессов обозначают L2.
Определение 1.7. Математическим ожиданием случайного про-
цесса X(t) называется функция mX : T → R, значение которой в каждый момент времени равно математическому ожиданию соответствующего сечения, т.е. ∀t ∈ T mX (t) = EX(t).
Определение 1.8. Корреляционной функцией случайного процес-
са X(t) называется функция двух переменных RX : T × T → R, которая каждой паре моментов времени сопоставляет корреляционный момент соответствующих сечений процесса, т.е.

◦

◦

RX (t1, t2) = EX(t1)X(t2) = EX(t1)X(t2) − EX(t1)EX(t2).

Замечание. Корреляционной эту функцию называют также в учебнике [43]. В некоторых других источниках, например – в книге [41], ее называют ковариационной. В учебнике [43] тоже есть понятие ковариационной функции: KX (t1, t2) = EX(t1)X(t2). В настоящем пособии мы будем придерживаться терминологии учебника [43].
Определение 1.9. Ковариационной функцией случайного процесса X(t) называется функция двух переменных KX : T × T → R, такая, что
KX (t1, t2) = EX(t1)X(t2).
Отметим, что корреляционная и ковариационная функции связаны соотношением KX (t1, t2) = RX (t1, t2) + mX (t1)mX (t2).

18

Определение 1.10. Дисперсией случайного процесса X(t) называется функция DX : T → R, в каждый момент времени равная дисперсии соответствующего сечения процесса, т.е.
◦
DX (t) = EX2(t) = EX2(t) − (EX(t))2.

Легко видеть, что дисперсия процесса связана с корреляционной функцией по формуле DX (t) = RX (t, t).
Введем также важное понятие взаимной корреляционной функции двух процессов.
Определение 1.11. Взаимной корреляционной функцией процессов X(t) и Y (t) из L2 называется функция двух переменных RX,Y : T × T → R такая, что

◦

◦

RX,Y (t1, t2) = EX(t1)Y (t2).

Определение 1.12. Характеристической функцией процесса X(t) называется функция

φX(t)(s) = E exp(isX(t)), s ∈ R.

Рассмотрим несколько задач на расчет введенных численных характеристик случайных процессов.
Пример 1.5. Вычислить математическое ожидание, корреляционную функцию и дисперсию случайного процесса ξ(t) = X cos (t + Y ), где t ∈ R, а случайные величины X ∈ N(0, 1) и Y ∈ R(−π, π) независимы.
Решение. Сначала найдем математическое ожидание ξ(t). Для этого зафиксируем момент времени t ∈ R и вычислим математическое ожидание сечения
Eξ(t) = E (X cos (t + Y )) .
По условию задачи случайные величины X и Y независимы, значит,

E (X cos (t + Y )) = EX · E cos (t + Y ).

Так как X ∈ N(0, 1), то EX = 0, откуда Eξ(t) = 0 для всех t ∈ R. Найдем теперь корреляционную функцию

Rξ(t1, t2) = Eξ(t1)ξ(t2) − Eξ(t1)Eξ(t2).

Из Eξ(t) = 0 для всех t ∈ R следует, что Rξ(t1, t2) = Eξ(t1)ξ(t2) = E (︁X2 cos (t1 + Y ) cos (t2 + Y ))︁ .

19

Снова воспользуемся независимостью X и Y , и получим Rξ(t1, t2) = EX2 · E (cos (t1 + Y ) cos (t2 + Y )) .

Второй момент посчитаем через дисперсию: EX2 = DX + (EX)2 = 1.

Второй множитель вычислим напрямую:
ˆ+∞ E cos (t1 + Y ) cos (t2 + Y ) = cos (t1 + y) cos (t2 + y)fY (y)dy,
−∞

где функция плотности равномерного распределения

{︃ 1/(2π), y ∈ (−π, π),

fY (y) = 0,

y ∈/ (−π, π).

Отсюда получаем

ˆπ

1

1

Rξ(t1, t2) = 2π cos (t1 + y) cos (t2 + y)dy = 2 cos (t1 − t2).

−π

Дисперсию можно вычислить по формуле Dξ(t) = Rξ(t, t) = 1/2. Итак,

в

результате

имеем

mξ (t)

≡

0,

Dξ (t)

≡

1/2,

Rξ(t1, t2)

=

1 2

cos (t1

−

t2).

△

Пример 1.6. Найти математическое ожидание, дисперсию и кор-

реляционную функцию случайного процесса из примера 1.3.

Решение. Мы выяснили, что любое сечение ξ(t) ∈ Be(1 − t). Зна-

чит, математическое ожидание и дисперсия равны

mξ(t) = 1 − t, Dξ(t) = t(1 − t).

Корреляционная функция равна

Rξ(t1, t2) = Eξ(t1)ξ(t2) − Eξ(t1)Eξ(t2).

Для вычисления первого слагаемого удобно воспользоваться общей формулой для математического ожидания через интеграл Лебега:
ˆ1 Eξ(t1)ξ(t2) = ξ(ω, t1)ξ(ω, t2) dω = 1 − max (t1, t2).
0

20

Другой подход состоит в том, чтобы заметить, что случайная величина ξ(t1)ξ(t2) имеет распределение Бернулли Be(1 − max (t1, t2)), стало быть, ее математическое ожидание равно 1 − max (t1, t2). В любом случае получаем
Rξ(t1, t2) = 1 − max (t1, t2) − (1 − t1)(1 − t2) = min (t1, t2) − t1t2. △
1.3. Винеровский процесс
Перейдём теперь к более содержательным примерам случайных процессов, повсеместно встречающихся в приложениях. Для этого дадим сначала определение одного важного класса случайных процессов.
Определение 1.13. Случайная функция {X(t), t ≥ 0} называется процессом с независимыми приращениями, если для любого n ≥ 1 и любых моментов времени 0 ≤ t1 ≤ t2 ≤ · · · ≤ tn случайные величины
X(0), X(t1) − X(0), X(t2) − X(t1), . . . , X(tn) − X(tn−1)
независимы в совокупности. Определение 1.14. Винеровским процессом с параметром σ > 0
называется случайная функция {W (t), t ≥ 0}, удовлетворяющая условиям:
а) W (0) = 0 почти всюду.
б) W (t) – процесс с независимыми приращениями.
в) Для любых t, s ≥ 0 выполнено W (t) − W (s) ∈ N(0, σ2|t − s|).
Для простоты винеровские процессы с параметром σ будем иногда называть просто винеровскими процессами там, где значение σ не играет принципиальную роль.
Найдем плотность n-мерного распределения винеровского процесса. Для этого составим вектор Y = (W (t1), . . . , W (tn)) из сечений процесса в точках t1 < · · · < tn. Сечения винеровского процесса являются зависимыми величинами, а приращения на непересекающихся интервалах – независимые. Найдем поэтому сначала распределение вектора
Z = (W (t1), W (t2) − W (t1), . . . , W (tn) − W (tn−1)).
Так как этот вектор состоит из независимых в совокупности нормальных случайных величин, определенных на одном вероятностном про-
21

странстве, то он является нормальным случайным вектором. Плотность его распределения выражается по формуле

n
∏︂

1

(︃

z2

)︃

fZ (z) =

exp −

k

, z = (z1, . . . , zn),

k=1 √︁2πσ2(tk − tk−1)

2σ2(tk − tk−1)

где t0 = 0. Остается заметить, что векторы Y и Z связаны линейным преобразованием Y = AZ, где

⎡ 1 0 0 0 ... 0 ⎤

⎢ 1 1 0 0 ... 0 ⎥

⎢ A=⎢

1

1

1

0

...

0

⎥ ⎥.

(2)

⎢⎢⎣ ... ... ... ... . . . ... ⎥⎥⎦

1 1 ... 1 1 1

Плотность распределения Y связана с плотностью распределения Z по формуле

fY (y) = 1 fZ (A−1y), y = (y1, . . . , yn). | det A|

После преобразований получаем окончательно

n
∏︂

1

(︃ (yk − yk−1)2 )︃

fY (y) = k=1 √︁2πσ2(tk − tk−1) exp − 2σ2(tk − tk−1) , t0 = 0, y0 = 0.

Напомним, что линейное преобразование переводит нормальные случайные векторы в нормальные случайные векторы (см. раздел 3). Принимая во внимание выкладки выше, мы можем заключить, что любой вектор, составленный из сечений винеровского процесса, является нормальным случайным вектором, причем

EY = E(AZ) = AEZ = 0,
RY = RAZ = ARZ AT = ∥min(ti, tj )∥ni,j=1 ,
где RY и RZ – ковариационные матрицы векторов Y и Z соответственно. Винеровский процесс таким образом относится к более широкому классу случайных процессов – гауссовским процессам.
Определение 1.15. Случайный процесс {X(t), t ≥ 0} называется гауссовским, если для любого n ≥ 1 и точек 0 ≤ t1 < · · · < tn вектор (X(t1), . . . , X(tn)) является нормальным случайным вектором.

22

Пример 1.7. Найти математическое ожидание, дисперсию, корреляционную и ковариационную функции винеровского процесса.
Решение. Воспользуемся тем, что W (t) = W (t) − W (0) ∈ N(0, σ2t):
mW (t) = EW (t) = 0 для любого t ≥ 0,
DW (t) = DW (t) = σ2t для любого t ≥ 0. Для расчета корреляционной функции
RW (t, s) = E (W (t)W (s)) − EW (t)EW (s) = E (W (t)W (s))
сначала рассмотрим случай t > s. В этом случае приращения W (t) − W (s) и W (s) − W (0) = W (s) являются независимыми. Значит,
RW (t, s) = E(W (t) − W (s))W (s) + EW 2(s) = E(W (t) − W (s))EW (s) + EW 2(s) = EW 2(s) = DW (s) + (EW (s))2 = σ2s.
Если же t < s, то аналогично получим RW (t, s) = σ2t. Случай t = s рассматривается отдельно, получается RW (t, t) = EW 2(t) = σ2t. Значит, в общем случае корреляционная функция винеровского процесса
RW (t, s) = σ2 min(t, s).
Так как математическое ожидание винеровского процесса равно нулю, то ковариационная функция равна
KW (t, s) = RW (t, s) + EW (t)EW (s) = RW (t, s) = σ2 min(t, s). △
В связи с определением гауссовкого процесса можно дать равносильное определение винеровского процесса.
Теорема 1.3. Процесс {W (t), t ≥ 0} является винеровским тогда и только тогда, когда
а) W (t) – гауссовский процесс; б) EW (t) = 0 для любого t ≥ 0; в) RW (t, s) = min(t, s) для любых t, s ≥ 0. Доказательство. Пусть процесс является винеровским. Ранее мы уже установили принадлежность винеровского процесса к гауссовским
23

процессам, а в предыдущем примере вычислили его математическое ожидание и корреляционную функцию.
Пусть теперь дан гауссовский процесс X(t) с численными характеристиками EX(t) = 0 и RX (t, s) = min(t, s). Из RX (0, 0) = DX(0) = 0 следует, что X(0) = const п.н., а из того, что EX(0) = 0 получаем X(0) = 0 п.н.
Далее, так как процесс X(t) гауссовский, то и произвольное приращение X(t) − X(s) является нормальной случайной величиной. Математическое ожидание E(X(t) − X(s)) = 0, а дисперсия
D(X(t) − X(s)) = DX(t) − 2cov(X(t), X(s)) + DX(s) =
= RX (t, t) − 2RX (t, s) + RX (s, s) = t + s − min(t, s) = |t − s|.
Так как процесс гауссовский, то любой вектор из его сечений является гауссовским, причем математическое ожидание этого вектора – нулевой вектор, а ковариационная матрица ∥Rij∥ состоит из элементов Rij = min(ti, tj). Если взять преобразование, обратное к A из формулы (2), то получится, что вектор (X(t1), X(t2) − X(t1), . . . , X(tn) − X(tn−1)) состоит из некоррелированных случайных величин, а раз вектор гауссовский, то – из независимых случайных величин. □
Согласно теореме 1.2 Колмогорова для винеровского процесса существует непрерывная модификация (для этого в теореме можно положить α = 4, β = 1, c = 3σ4). Поэтому всегда подразумевается, что траектории винеровского процесса непрерывны.
Мы дали аксиоматическое определение винеровского процесса, т.е. путем перечисления его свойств. Доказательство существования винеровского процесса можно выполнить различными способами [10], основанными на теоремах Колмогорова, разложениях в ряды, слабой сходимости мер в C(0, 1) и центральной предельной теореме. Здесь важно отметить, что винеровский процесс можно получать (и определять) как в некотором смысле предел случайных блужданий на вещественной оси. Поясним сказанное на модельном примере.
Допустим имеется некоторая акциия, цена которой формируется скачками в моменты времени 1/N , 2/N , 3/N и т.д., N ≥ 1. Пусть в момент времени t > 0 цена акции определяется формулой
[N t]
∑︂ XN (t) = ∆Xi,
i=1
где {︄ √ ∆Xi = −σ/σ/√NN, , сс ввеерроояяттннооссттььюю 11//22,,
24

причем {∆Xi} – независимые одинаково распределенные случайные величины. Заметим, что E∆Xi = 0, D∆Xi = σ2/N . Тогда из централь-
ной предельной теоремы следует, что для t > 0

XN (t) − 0

d

√

−−−−→ Z ∈ N(0, 1).

σ/ N · √︁[N t] N→∞

Но так как [N t]/N → t при N → ∞, то

XN (t) −−−d−→ X(t) ∈ N(0, σ2t), t > 0.
N →∞
Оказывается, что предел X(t) в этом выражении – это винеровский процесс W (t) с параметром σ, но чтобы это доказать, потребуется обратиться к понятию слабой сходимости случайных процессов, или слабой сходимости мер.
Подробное изложении теории слабой сходимости случайных процессов, включая доказательство сходимости процесса выше к винеровскому процессу, можно найти в монографии [4]. Мы же приведем лишь краткое пояснение.
Вообще в функциональном анализе под слабой сходимостью абстрактной последовательности xn к абстрактному элементу x в линейном топологическом пространстве E понимается сходимость числовой последовательности f (xn) к f (x) для любого непрерывного линейного функционала f из сопряженного пространства E∗. В теории вероятностей, когда говорят о слабой сходимости случайной последовательности ξn к величине ξ, обычно для простоты имеют в виду поточечную сходимость Fn(x) → F (x) функций распределения ξn к функции распределения ξ в точках непрерывности F (x). На самом деле же слабая сходимость ξn к ξ означает слабую сходимость последовательности мер Pn, порождаемой функциями распределения Fn(x), к мере P, порождаемой функцией распределения F (x), причем меры эти являются элементами некоторого линейного топологического пространства мер. Не важно, как строится такое топологическое пространство, отметим лишь, что слабую сходимость мер можно определить несколькими равносильными способами. Например, под слабой сходимостью мер Pn к мере P (определенных на некотором измеримом пространстве (S, F)) можно понимать сходимость числовой последовательности

Enf → Ef, n → ∞

для каждой непрерывной ограниченной функции f , определенной на элементах метрического пространства S; здесь En и E обозначают математические ожидания, подсчитанные относительно мер Pn и P, соответственно.

25

А теперь вернемся к случайным процессам. Траектории случайного процесса XN (t) и винеровского процесса W (t) непрерывны с вероятностью 1, поэтому можно считать, что они заданы на метрическом пространстве S = C[0, T ], оснащенном стандартной равномерной метрикой и некоторой сигма-алгеброй. Конечномерные распределения этих процессов порождают на S некоторые меры: PN и W (последняя еще называется мерой Винера). Оказывается, что PN слабо сходится к W. Доказывать это можно по-разному, одно из достаточных условий сходимости описывается в монографии [4]: 1) сначала надо доказать, что при каждом n ≥ 1 и каждом фиксированном наборе (t1, . . . , tn) конечномерные распределения процесса XN (t) сходятся к соответствующим конечномерным распределениям процесса W (t), а затем надо показать, что последовательность PN полна, т.е. «достаточно хорошая», чтобы вычислить пределы по N → ∞ для произвольных, нефиксированных наборов (t1, . . . , tn) (грубо говоря, чтобы имела место «равномерная сходимость по всем сечениям»). Мы же в примере выше показали только сходимость одномерных распределений XN (t) к W (t) для фиксированного t.
Отметим, наконец, что так как винеровский процесс является пределом некоторых других, более простых процессов, то его числовые характеристики можно аппроксимировать теми же числовыми характеристики простых процессов, и наоборот.
На рис. 2 показаны типичные траектории винеровского процесса. На рис. 3 показаны 1000 реализаций процесса. Хорошо видно, что они с большой в√ероятностью попадают в область между графиками функций y = ±3 t, которые отвечают правилу трех сигм нормального распределения: если ξ ∈ N(0, σ2), то P(−3σ ≤ ξ ≤ 3σ) ≈ 0.9973. В нашем случае ξ = W (t), σ2 = t.
Известны и более сильные результаты о поведении винеровского процесса (см., например, [10, гл. III]).
Теорема 1.4 (закон повторного логарифма, Хинчин). С ве-
роятностью единица

lim inf √ W (t) = −1, lim sup √ W (t) = 1.

t→∞ 2t ln ln t

t→∞ 2t ln ln t

С помощью преобразования W˜︂(t) = tW (1/t) получается снова винеровский процесс, поведение которого в окрестности нуля описывается поведением W (t) на бесконечности. Откуда вытекает следующая теорема.
Теорема 1.5 (локальный закон повторного логарифма). С ве-

26

3

2

1

0

-1

-2

-3

-4

0

2

4

6

8

10

1.6

1.4

1.2

1

0.8

0.6

0.4

0.2

3

3.2

3.4

3.6

3.8

4

(а)

(б)

Рис. 2. Пример траектории винеровского процесса на а) интервале t ∈ [0, 10] и б) интервале t ∈ [3, 4]

Рис. 3. Реализации винеровского процесса с вероятностью пр√иблизительно 99.7% попадают в область между графиками функций y = ±3 t
27

роятностью единица

W (t)

W (t)

lim inf √︁ = −1, lim sup √︁ = 1.

t→0+ 2t ln ln(1/t)

t→0+ 2t ln ln(1/t)

Теорема 1.6 (Башелье). При всех T , x ≥ 0

(︃

)︃

P max W (t) ≥ x = 2P (W (T ) ≥ x) = P (|W (T )| ≥ x) .
t∈[0,T ]

1.4. Пуассоновский процесс

Определение 1.16. Пуассоновским процессом с интенсивностью λ > 0 называется случайная функция {K(t), t ≥ 0}, удовлетворяющая свойствам:

а) K(0) = 0 почти всюду.

б) K(t) – процесс с независимыми приращениями.

в) ∀t > s ≥ 0 выполнено K(t) − K(s) ∈ Po(λ(t − s)).

Легко показать, что математическое ожидание, дисперсия и корреляционная функция пуассоновского процесса выражаются формулами EK(t) = λt, DK(t) = λt, RK(t, s) = λ min(t, s). Так как для любых t > s ≥ 0 приращение K(t) − K(s) ∈ Po(λ(t − s)) неотрицательно и может принимать лишь значения 0, 1, 2, . . . , то траектории пуассоновского процесса – неубывающие кусочно-постоянные функции. Эти функции начинаются в нуле, так как K(0) = 0 п.н., и испытывают прыжки (скачки) в случайные моменты времени.
Теорема 1.7. Пусть {ξn} – последовательность независимых случайных величин с распределением Exp(λ). Обозначим Sn = ξ1 +· · ·+ξn (S0 = 0). Введем процесс

X(t) = sup{n : Sn ≤ t}.

(3)

Тогда X(t) – пуассоновский процесс интенсивности λ.

Доказательство. Рассмотрим случайный вектор (S1, . . . , Sn). Этот

вектор связан со случайным вектором (ξ1, . . . , ξn) линейным преобра-

зованием:

⎡ S1 ⎤ ⎡ 1 0 0 . . . 0 ⎤ ⎡ ξ1 ⎤

⎢ S2 ⎥ ⎢ 1 1 0 . . . 0 ⎥ ⎢ ξ2 ⎥

⎢ ⎢

S3

⎥⎢ ⎥=⎢

1

1

1

...

0

⎥⎢ ⎥⎢

ξ3

⎥ ⎥

⎢⎢⎣ ... ⎥⎥⎦ ⎢⎢⎣ ... ... ... . . . ... ⎥⎥⎦ ⎢⎢⎣ ... ⎥⎥⎦

Sn

111 1 1

ξn

28

Это наблюдение позволяет вычислить плотность вектора (S1, . . . , Sn). Действительно определитель этой матрицы равен единице, поэтому плотность вектора (S1, . . . , Sn) равна

pS1,...,Sn (x1, . . . , xn) = pξ1,...,ξn (x1, x2 − x1, . . . , xn − xn−1).

Остается вспомнить, что случайные величины ξ1, . . . , ξn независимы, значит
n
pS1,...,Sn (x1, . . . , xn) = ∏︂ λe−λ(xj−xj−1)I(xj − xj−1 ≥ 0) =
j=1

= λne−λxn I(xn > xn−1 > · · · > x1).
Зафиксируем моменты времени 0 = t0 < t1 < · · · < tn и введем неотрицательные целые числа k1, . . . , kn ∈ Z+ и 0 = k0 ≤ k1 ≤ k2 ≤ · · · ≤ kn. Чтобы доказать, что процесс X(t) пуассоновский нужно доказать, что приращения его независимые и имеют пуассоновское распределение. Для этого мы вычислим вероятность

P(X(tn) − X(tn−1) = kn − kn−1, . . . , X(t2) − X(t1) = k2 − k1, X(t1) = k1),

покажем, что она распадается на произведение вероятностей и что эти вероятности равны тому, чему нужно, чтобы эти случайные величины имели пуассоновское распределение. Эта вероятность равна

P({S1, . . . , Sk1 } ∈ (0, t1), {Sk1+1, . . . , Sk2 } ∈ (t1, t2), . . . ,

. . . {Skn−1+1, . . . , Skn } ∈ (tn−1, tn), Skn+1 > tn) = ˆˆ = . . . λkn+1e−λxkn+1 I(0 < x1 < · · · < xkn+1) dx1 . . . dxn,

где интеграл берется по области A = {(x1, . . . , xkn+1) ∈ Rkn+1 : {x1, . . . , xk1 } ∈ (0, t1), . . . , xkn+1 > tn}.

Далее, интеграл выше равен

ˆ∞

nˆ

λe−λxkn+1 dxkn+1λkn ∏︂

tn

j=1

ˆ ...

I(xkj−1+1 < · · · < xkj ) dx1, . . . dxkn =

= e−λtn λkn ∏n︂ (tj − tj−1)kj −kj−1 = ∏n︂ (λ(tj − tj−1))kj −kj−1 e−λ(tj −tj−1).

j=1 (kj − kj−1)!

j=1 (kj − kj−1)!

29

Интеграл в выражении выше без индикатора равен объему многомерного прямоугольника, а с индикатором – объему симплекса, который равен объему прямоугольника поделить на факториал размерности пространства. Из полученного выражения следует, что все случайные величины X(tj) − X(tj−1) независимы, причем вероятность того, что

P(X(tj ) − X(tj−1)) = (λ(tj − tj−1))kj−kj−1 e−λ(tj−tj−1), (kj − kj−1)!

т.е. X(tj) − X(tj−1) ∈ Po(λ(tj − tj−1)). А это и есть то, что мы хотели доказать: приращения процесса независимы и распределены по Пуассону с нужными параметрами. □
Теперь разберемся с тем, какие следствия мы получаем из явной конструкции пуассоновского процесса.
1) Скачки происходят в моменты времени τ1 = S1, τ2 = S2 и так далее. Так как Sn представляет собой сумму n независимых случайных величин с распределением Exp(λ), то τn = Sn имеет распределение Эрла´нга Erl(n, λ).
2) Между скачками проходит случайное время

τn − τn−1 = Sn − Sn−1 = ξn ∈ Exp(λ).

Времена между соседними последовательными скачками – независимые случайные величины.
3) С вероятностью 1 все скачки пуассоновского процесса являются единичными. Действительно, скачки происходят только в моменты времени τ1 = S1, τ2 = S2 и так далее, поэтому

P(∃ скачок размера ≥ 2) = P(∃n : Sn = Sn+1) = P(∃n : ξn+1 = 0) = 0,

так как все ξj имеют непрерывное распределение. Доказывая вышеприведенную теорему, мы получили заодно и n-
мерную функцию вероятности пуассоновского процесса:

n
∏︂

(λ∆tj )∆kj

P(K(t1) = k1, . . . , K(tn) = kn) =

∆kj! exp (−λ∆tj),

j=1

где ∆tj = tj − tj−1, ∆kj = jj − kj−1, t0 = 0, k0 = 0. Процессы вида

{︄ n

}︄

∑︂

X(t) = sup n : ξk ≤ t ,

k=1

30

где ξk – независимые случайные величины (не обязательно одинаково

или показательно распределенные) называются еще процессами вос-

становления. Теорема, сформулированная и доказанная выше, гово-

рит о том, что пуассоновский процесс – это процесс восстановления,

построенный по случайным величинам с показательным распределе-

нием.

Последовательность

{Sn},

где

Sn

=

∑︁n
k=1

ξk ,

называется

случай-

ным блужданием.

На рисунке 4 изображена типичная траектория пуассоновского про-

цесса.

4

3.5

3

2.5

2

1.5

1

0.5

0

0

1

2

3

4

5

Рис. 4. Пример типичной траектории пуассоновского процесса
Также отметим, что формула (3) дает конструктивное определение пуассоновского процесса на вероятностном пространстве ([0, 1], B([0, 1]), L), L – мера Лебега. Для этого по ω ∈ [0, 1] нужно построить последовательность независимых равномерно на [0, 1] распределенных случайных величин ωk(ω), k ≥ 1, далее методом обратной функции построить показательные случайные величины ξk(ω) = − ln ωk(ω), k ≥ 1 и воспользоваться формулой (3). Для построения последовательности ωk, k ≥ 1, можно провести следующую процедуру: записать ω в двоичной системе исчисления, получив тем самым последовательность независимых случайных величин из распределения Be(1/2), разбить ее на счетное число непересекающихся подпоследовательностей (например, записав исходную последовательность «змейкой» в таблицу, выделить в ней строки) и снова свернуть каждую из них в десятичное представление.
Покажем теперь, как пуассоновский процесс может быть получен
31

из последовательности процессов путем предельного перехода. Пусть Xk ∈ R(0, N ), k = 1, . . . , N и нас интересует число точек, которые попадают на отрезок [0, λt] ⊆ [0, N ], где λ > 0, t ≥ 0. Для этого введем случайную величину νk = I(Xk ∈ [0, λt]) ∈ Be(λt/N ). Тогда из теоремы Пуассона следует, что
N
∑︂ νk −−−d−→ X(t) ∈ Po(λt).
N →∞ k=1
Можно показать, что определённый для t ≥ 0 предельный процесс X(t) является пуассоновским процессом K(t) с интенсивностью λ. Данный пример демонстрирует важное понятие, играющее ключевую роль в статистической механике – термодинамический предельный переход. Пусть есть сосуд длины N и N невзаимодействующих частиц, равномерно распределенных в нем. Тогда если выбрать в этом сосуде какуюнибудь произвольную область длины L, то при предельном переходе N → ∞ и сохранении равномерности распределения частиц (постоянстве концентрации) окажется, что вероятность нахождения k частиц в области L равна e−LLk/k!. Данный пример демонстрирует естественность возникновения распределения Пуассона при таком предельном переходе. Много интересных приложений пуассоновские процессы (поля) находят в [31, 32, 35, 39].
Приведем и другой важный пример естественного возникновения пуассоновского процесса. Предположим имеется остановка для автобусов, и время между прибытиями автобусов на остановку имеет показательное распределение ξi ∈ Exp(λ). Отметим, что в классе распределений, имеющих плотность, только показательное распределение удовлетворяет следующему условию (отсутствие последействия): для всех t, τ > 0:
P(ξ ≥ t + τ | ξ ≥ t) = P(ξ ≥ τ ).
Это значит, что если человек приходит на остановку в некоторый фиксированный момент времени t0, не связанный с пуассоновским процессом, то в силу отсутствия памяти у показательного распределения время ожидания автобуса будет по-прежнему иметь показательный закон с тем же параметром λ. Отметим еще, что в классе дискретных распределений таким свойством обладает только геометрическое распределение.
Пример 1.8 (нерадивый пешеход). Пешеход хочет перейти дорогу в неположенном месте. Для того, чтобы перебежать дорогу, ему требуется a секунд. Кроме того, ему приходится ждать некоторое случайное время, когда зазор между соседними машинами, образующими
32

пуассоновский процесс интенсивности λ, будет больше, чем a секунд. Вычислить математическое ожидание времени перехода дороги с учетом ожидания.
Решение. Сначала введем случайную величину, равную времени перехода дороги с учетом ожидания «зазора» между машинами:

Ta = min (t > 0 : K(t − a) = K(t)) .

Для вычисления ее математического ожидания воспользуемся формулой полной вероятности, «обуславливая» по моменту времени ξ1 проезда мимо пешехода первой машины:

ˆ∞

ˆ∞

ETa = E(Ta | ξ1 = x)fξ1 (x) dx = λe−λxE(Ta | ξ1 = x) dx,

0

0

где fξ1 (x) – плотность распределения ξ1. Заметим, что если ξ1 > a, то пешеходу не нужно ждать, т.е. Ta = a, а если ξ1 = x < a, то так как до следующей машины пройдет показательно распределенное время, мы
получаем ту же задачу, но со сдвигом на время x, т.е.

E(Ta | ξ = x) = x + ETa, x < a.

Поэтому, разбивая интеграл на две части, по отрезку [0, a] и [a, +∞), получаем
ˆa ETa = ae−λa + λe−λx(x + ETa) dx.
0
Разрешая это уравнение относительно ETa, получаем окончательно
eλa − 1 ETa = λ .
Отсюда следует, что при интенсивном потоке машин в среднем переход через дорогу придется ждать экспоненциально долго. △
Приведем еще одно определение пуассоновского процесса. Предположим, что во времени наблюдается некоторый поток случайных событий. Эти события происходят через случайные моменты времени, но не произвольным образом, а по следующим правилам:
1) Стационарность: распределение числа событий, происшедших на фиксированном (неслучайном) интервале времени [t, s] есть функция только длины интервала t − s.
2) Отсутствие последействия: числа событий, происшедших на непересекающихся временных интервалах независимы в совокупности.

33

3) Ординарность: вероятность того, что на интервале [t, t + ∆t] произойдет хотя бы одно событие, равна λ(t)∆t + o(1), ∆t → 0, где для стационарного процесса λ(t) = λ не зависит от t.
Поток событий с вышеперечисленными тремя свойствами называется простейшим потоком событий. Обозначим за ν(t, s) число событий такого потока, произошедшее на интервале времени [t, s]. Оказывается, что K(t) = ν(0, t). Другими словами, пуассоновский процесс можно определить как число событий простейшего потока событий на интервале времени [0, t].
Это определение удобно в том смысле, что допускает естественное обобщение понятия пуассоновского процесса до пуассоновского поля на Rd, d ≥ 1 и даже на произвольном измеримом пространстве S, не обладающем евклидовой структурой (см. [32]). При этом в евклидовом случае параметр времени теперь можно интерпретировать как пространственную переменную (см. пример 1.9 далее). Случайная конфигурация точек (иначе, событий) на S, обладающих свойствами:
1) распределение числа событий в произвольной измеримой области A зависит лишь от величины некоторой (неатомической) меры µ области A.
2) число событий, произошедших на непересекающихся измеримых областях независимы в совокупности.
3) число событий ν(A) в измеримой области A имеет распределение Пуассона с параметром µ(A).
Функцию, определенную на измеримых подмножествах A ⊂ S, ν(A), называют считающей функцией пуассоновского поля. Если S = R+, то принято называть пуассоновским процессом не случайную конфигурацию точек на действительной полуоси, а K(t) = ν ((0, t]) и интерпретировать параметр t ≥ 0 как время. В случае S = R мера µ может, в частности, иметь постоянную плотность относительно меры Лебега µ([0, t]) = λt, тогда мы получаем пуассоновский процесс с постоянной интенсивностью λ, а может быть представлена к
ˆt
µ([0, t]) = λ(u) du,
0
где λ(u) – неотрицательная функция (плотность интенсивности). В этом случае говорят о пуассоновском процессе с переменной интенсивностью.
Пример 1.9 (модель леса как пуассоновского поля, [32]). Рассматривается пуассоновское поле в Rd с постоянной плотностью интенсивности λ. Точки-события этого поля будем интерпретировать
34

как деревья в лесу. Выберем в качестве начала координат местоположение грибника. Нужно найти плотность распределения случайной величины ξ – расстояние до ближайшего дерева.
Важное свойство пуассоновских моделей состоит в том, что их можно отображать в другие пространства, при этом образы случайных точек вновь образуют пуассоновский процесс [32].
Рассмотрим в качестве первого отображения – переход от декартовых координат к полярным:

(︂√︁

)︂

f1(x, y) = x2 + y2, arctg(y/x) .

Мера интенсивности при этом преобразуется по формуле

µ1(B) =

λ dx dy = λr dr dθ,

f1−1(B) B

где B – борелевское множество в полосе {(r, θ) : r > 0, θ ∈ [0, 2π)}. В качестве второго отображения рассмотрим проекцию на ради-
альную компоненту: f2(r, θ) = r, тогда ˆ

µ2(C) =

λr dr dθ = 2πλr dr,

C ×[0,2π )

C

C – борелевское множество в R+.
Таким образом, композиция отображений f1 и f2 преобразует пуассоновское поле на Rd с постоянной интенсивностью λ в пуассоновский процесс на R+ с переменной интенсивностью 2πλr, r > 0. Значит,

⎛ ˆx

⎞

P(ξ > x) = exp ⎝− 2πλu du⎠ ,

0

а плотность распределения ξ есть 2πλx exp (−πλx2), x > 0. △ Определение 1.17. Случайный процесс

K (t)
∑︂ Q(t) = Vi,
i=1
где K(t) — пуассоновский процесс, {Vi}∞ i=1 – независимые одинаково распределенные случайные величины, не зависящие от K(t), называется сложным пуассоновским процессом. Предполагается, что если K(t) = 0, то и Q(t) = 0.

35

Найдем математическое ожидание, дисперсию, корреляционную и
характеристическую функцию сложного пуассоновского процесса в предположении EV12 < ∞. Для этого удобно воспользоваться формулами полной вероятности

EX = E(E(X | Y )), DX = D (E(X | Y )) + E(D(X | Y )).
При вычислении условного математического ожидания или условной дисперсии значение вспомогательной случайной величины Y фиксируется и воспринимается как неслучайная величина. Более подробно с понятием условными математическими ожиданиями и, в частности, с доказательством формул выше можно ознакомиться в книге [69]. Легко видеть, что

EQ(t) = E(E(Q(t) | K(t))) = E(K(t)EV1) = λtEV1.

Что касается дисперсии, то удобно сначала вычислить

E(Q(t) | K(t)) = K(t)EV1, D(Q(t) | K(t)) = K(t)DV1,

и затем подставить в формулу для дисперсии:
DQ(t) = D(K(t)EV1) + E(K(t)DV1) = λt(EV1)2 + λtDV1 = λtEV12.
Перейдем теперь к расчету корреляционной функции Q(t):
◦◦
RQ(t, s) = EQ(t)Q(s).

Для расчета этого выражения установим сначала вспомогательный факт: сложный пуассоновский процесс – это процесс с независимыми приращениями. Для доказательства независимости приращений воспользуемся аппаратом характеристических функций. Пусть ϕV (s) = EeisV – характеристическая функция случайной величины V . Вычислим сначала характеристическую функцию приращения Q(t2) − Q(t1), 0 ≤ t1 < t2, воспользовавшись формулой полной вероятности для математического ожидания.

⎧
⎨ ϕQ(t2)−Q(t1)(s) = Eeis(Q(t2)−Q(t1)) = E exp is

K (t2 )
∑︂

⎫
⎬ Vj =

⎩ j=K(t1)+1 ⎭

⎡⎧

⎫

⎤

∞

K (t2 )

∑︂ ⎨ ∑︂ ⎬ ⃓

=

E ⎣exp is

Vj ⃓⃓ K(t1) = m1, K(t2) = m1 + m2⎦ ×

m1 ,m2 =0

⎩ j=K(t1)+1 ⎭

36

×P (K(t1) = m1, K(t2) = m1 + m2) =

⎧

⎫

∞ ⎨ m1+m2 ⎬

∑︂

∑︂

=

E exp is

Vj P (K(t1) = m1, K(t2) = m1 + m2) =

m1 ,m2 =0

⎩ j=m1+1 ⎭

⎧

⎫

∞ ⎨ m1+m2 ⎬

∑︂

∑︂

=

E exp is

Vj P (K(t1) = m1) P (K(t2) − K(t1) = m2) =

m1 ,m2 =0

⎩ j=m1+1 ⎭

∞
= ∑︂ [ϕV (s)]m2 P (K(t1) = m1) P (K(t2) − K(t1) = m2) =
m1 ,m2 =0

∞
= ∑︂ [ϕV (s)]m2 P (K(t2) − K(t1) = m2) =

m2 =0

= ∑∞︂ [ϕV (s)]m2 (λ(t2 − t1))m2 e−λ(t2−t1) =

m2 =0

m2!

= exp {−λ(t2 − t1)(1 − ϕV (s))} .

Таким образом, характеристическая функция приращения сложного пуассоновского процесса на интервале [t1, t2] равна

ϕQ(t2)−Q(t1)(s) = exp {−λ(t2 − t1)(1 − ϕV (s)} .

(4)

В частности, если положить t1 = 0, t2 = t, получаем характеристическую функцию сечения

ϕQ(t)(s) = EeisQ(t) = exp {−λ(t)(1 − ϕV (s))} .

(5)

Из формул (4) и (5) можно сделать вывод, что сложный пуассоновский процесс является процессом со стационарными приращениями (иначе говоря, является однородным по времени):

Q(t2) − Q(t1)=d Q(t2 − t1)

для любых 0 ≤ t1 < t2. Вычислим теперь совместную характеристическую функцию век-
тора приращений (Q(t2) − Q(t1), Q(t3) − Q(t2), . . . , Q(tn) − Q(tn−1)), где t1 < t2 < · · · < tn, и увидим, что она распадается в произведение характеристических функций компонент вектора (что равносильно независимости компонент рассматриваемого вектора приращений).

ϕQ(t2)−Q(t1),Q(t3)−Q(t2),...,Q(tn)−Q(tn−1)(s1, . . . , sn) =

37

⎧

n

=

Eei

∑︁n
k=1

sk (Q(tk )−Q(tk−1 ))

=

⎨ ∑︂ E exp i sk

K (tk )
∑︂

⎫
⎬ Vj =

⎩ k=1 j=K(tk−1)+1 ⎭

⎡⎧

∞ ⎨n

∑︂

∑︂

=

E ⎣exp i sk

K (tk )
∑︂

⎫

⎧

⎫⎤

⎬⃓ n ⎨ ⋂︂

k⎬ ∑︂

Vj ⃓⃓

K(tk) = mj ⎦ ×

mi =0 i=1,...n

⎩ k=1 j=K(tk−1)+1 ⎭ k=1 ⎩

j=1 ⎭

⎛⎧

⎫⎞

n⎨ ⋂︂

k⎬ ∑︂

×P ⎝

K(tk) = mj ⎠ =

k=1 ⎩

j=1 ⎭

⎧

⎫

∞

n

mk

(︄ n

)︄

∑︂ ⎨ ∑︂ ∑︂ ⎬ ⋂︂

=

E exp i sk

Vj P

{K(tk) − K(tk−1) = mk} =

mi =0 i=1,...n

⎩ k=1 j=mk−1+1 ⎭ k=1

∞n

n

= ∑︂ ∏︂ [ϕV (sk)]mk ∏︂ P (K(tk) − K(tk−1) = mk) =

mi=0 k=1 i=1,...n

k=1

n∞

∏︂ =

∑︂

[ϕV (sk)]mk P (K(tk) − K(tk−1) = mk) =

k=1 mk=0

= ∏n︂ ∑∞︂ [ϕV (s)]mk (λ(tk − tk−1))mk e−λ(tk−tk−1) =

k=1 mk=0

mk !

n
∏︂ = exp {−λ(tk − tk−1)(1 − ϕV (sk))} .
k=1

С учётом формулы (4) получаем

n

Eei

∑︁n
k=1

sk

(Q(tk

)−Q(tk−1 ))

=

∏︂

Eeisk (Q(tk )−Q(tk−1 )) .

k=1

Независимость приращений сложного пуассоновского процесса установлена. Теперь легко вычислить

◦◦

◦

◦

◦

◦

EQ(t)Q(s) = EQ(min(t, s))(Q(max(t, s)) − Q(min(t, s)) + Q2(min(t, s))),

что с учетом независимости приращений дает

◦◦

◦

EQ(t)Q(s) = EQ2(min(t, s)) = DQ(min(t, s)),

(6)

38

откуда сразу получаем
RQ(t, s) = λ min(t, s)EV12.
Отметим, что формула (6) для корреляционной функции является общей для всех процессов с независимыми приращениями.
Характеристическая функция сечения сложного пуассоновского процесса была нами получена выше, как частный случай (см. формулу (5)). Выведем эту формулу еще раз независимо от предыдущих рассуждений. Для этого воспользуемся формулой полной вероятности для математического ожидания

EX = E(E(X | Y ))

и тем фактом, что характеристическая функция суммы независимых случайных величин равна произведению их характеристических функций:

φQ(t)(s) = EeisQ(t) = E(E(eisQ(t) | K(t))) = E(φV1 (s))K(t) =

+∞
∑︂

(λt)k

=

(φV (s))k

e−λt = exp (λt(φV (s) − 1)) .

1

k!

1

k=1

Теперь поговорим о распределениях сечений сложного пуассоновского процесса.
Определение 1.18. Распределение случайной величины Q(1), т.е. распределение случайной величины

ξ
∑︂ Q(1) = Vk,
k=1

где ξ ∈ Po(λ), а Vk – независимые одинаково распределенные случайные величины, называется сложным пуассоновским распределением.
Из формулы для характеристической функции φQ(t)(s) следует, что
φQ(1)(s) = exp (λ(φV1 (s) − 1)),

причем

φQ(t) = φtQ(1).

Сложное пуассоновское распределение зависит от двух вещей: параметра λ > 0 и распределения V1. В последующем нам пригодится следующее представление характеристической функции сложного

39

пуассоновской случайной величины:

ˆ+∞

ˆ+∞

φQ(1)(s) = exp λ(eixs − 1) dFV1 (x) = exp (eixs − 1) µ(dx),

−∞

−∞

где φV1 (s) = ´−+∞∞ eixs dFV1 (x) и µ(dx) = λdFV1 (x). Теперь можно сказать, что сложное пуассоновское распределение определяется лишь

только одной мерой µ(x). Обозначать принадлежность этому распре-

делению поэтому будем так: Q(1) ∈ CPo(µ), обозначение происходит

от слов Compound Poisson Process.

Обычное пуассоновское распределение является частным случаем

сложного пуассоновского распределения: Po(λ) = CPo(λδ(x − 1)), где

δ(x − 1) – дельта-функция. Если ξ ∈ Po(λ), то aξ ∈ CPo(λδ(x − a)) для

любой неслучайной величины a. Пусть даны неслучайные числа {ak}, k = 1, . . . , n и независимые случайные величины Xk ∈ CPo(µk). Тогда

n

⎛
n

ˆ+∞

⎞

∏︂

∑︂

φ∑︁ akXk (s) =

φakXk (s) = exp ⎝

λk(eixs −1) δ(x−ak) dx⎠ =

k=1

k=1−∞

⎛ ˆ+∞

n

⎞

= exp ⎝ (eixs − 1) ∑︂ λkδ(x − ak) dx⎠ ,

−∞

k=1

Рассмотрим теперь несколько частных случаев сложного пуассоновского процесса, они отличаются только выбором случайных величин Vi. Если Vi = 1 п.н., то Q(t) = K(t), т.е. обычный пуассоновский процесс. Если Vi ∈ Be(p), то из характеристической функции получаем, что Q(t) имеет распределение Пуассона с параметром λpt. На самом деле, этого достаточно, чтобы утверждать, что такой процесс является пуассоновским, поскольку, как будет написано ниже в разделе 1.6 процесс Пуассона является процессом Леви, для описания которого достаточно знать распределение только одного сечения (см. Теорему 1.12 и Замечание 1 в конце раздела 1.6. Однако, рассуждения ниже приводятся здесь для полноты картины.
С учетом независимости приращений процесса Q(t) получаем, что это снова пуассоновский процесс, но с интенсивностью λp. Действительно, из K(0) = 0 п.н. следует Q(0) = 0 п.н. Независимость приращений Q(t) была показана выше. Осталось показать, что Q(t+u)−Q(t)) ∈ Po(λpu), чтобы установить, что Q(t) является пуассоновским процессом с интенсивностью λp. Напомним, что характеристическая функция случайной величины ξ ∈ Po(λ) равняется φξ(s) = exp (︁λ(eis − 1))︁,

40

а для η ∈ Be(p) характеристическая функция имеет вид φη(s) = 1 + p(eis − 1). Поэтому

φQ(t)(s) = exp (︁λpt(eis − 1))︁ .

Рассмотрим произвольные t, u ≥ 0 и вычислим характеристическую функцию случайной величины Q(t + u) − Q(t). Из независимости приращений сложного пуассоновского процесса получаем

(︂

)︂

φQ(t+u)(s) = EeisQ(t+u) = E eisQ(t)eis(Q(t+u)−Q(t)) =

= EeisQ(t)Eeis(Q(t+u)−Q(t)) = φQ(t)(s)φQ(t+u)−Q(t)(s),

откуда следует, что

φQ(t+u)−Q(t)(s) = exp (︁λpu(eis − 1))︁ ,

что соответствует характеристической функции пуассоновской случайной величины с параметром λpu. Распределение случайной величины1 однозначно задается ее характеристической функцией (см., например, в [26]), а значит, Q(t + u) − Q(t) ∈ Po(λpu).
Итак, мы показали, что при Vi ∈ Be(p) процесс Q(t) является пуассоновским с интенсивностью λp. В этом случае говорят, что процесс Пуассона устойчив по отношению к случайному прореживанию. Можно дать следующую интерпретацию: каждое событие исходного процесса K(t) независимо от других с вероятностью p оставляем, а с вероятностью 1 − p удаляем. Такая процедура называется случайным прореживанием.
Если Vi равновероятно принимают значения +1 и −1, то процесс Q(t) называют рандомизированным случайным блужданием. Распределение координаты частицы при этом выражается через функции Бесселя (см. [62, Том 2, гл. II, §7]).

1.5. Безгранично делимые случайные величины
Теперь перейдем к более общему классу процессов, который включает в себя и винеровский, и пуассоновский процессы и сложный пуассоновский процесс – процессам Леви. Предварительно введем несколько вспомогательных определений.
Определение 1.19. Случайную величину X будем называть безгранично делимой, если для любого натурального n ≥ 1 существует
1Аналогичное утверждение выполнено и для случайных векторов.

41

набор {Xkn}nk=1 независимых одинаково распределенных случайных

величин, такой, что
n

X

=d

∑︂ Xkn.

k=1

Для безгранично делимых случайных величин справедливы следующие две теоремы, которые мы приводим без доказательства. С доказательствами можно познакомиться в [22, гл. I, § 3]. Эти теоремы дают эквивалентные представления характеристических функций безгранично делимых случайных величин. В зависимости от задачи удобно пользоваться разными представлениями, которые суть преобразование компонент триплета (см. далее). Также читателю могут быть полезны книги [23, 99].
Теорема 1.8 (Леви–Хинчина). Случайная величина Y являет-

ся безгранично делимой тогда и только тогда, когда логарифм ее ха-

рактеристической функции φY (s) имеет вид

σ2s2 ˆ+∞

g(s) = ln φY (s) = ibs −

+ (︁eisx − 1 − isxI(|x| < 1))︁ ν(dx), (7)

2

−∞

где b ∈ R и σ2 ≥ 0 – некоторые числа, а ν(x) –´некоторая мера на вещественной оси R со свойствами ν({0}) = 0 и min(1, x2)ν(dx) < ∞.
R
Тройка (b, σ2, ν) для каждой безгранично делимой случайной величины определяется единственным образом.
Теорема 1.9. Случайная величина Y является безгранично делимой тогда и только тогда, когда логарифм ее характеристической функции φY (s) имеет вид

σ2s2 ˆ+∞(︃

isx )︃ 1 + x2

g(s) = ln φY (s) = i¯bs− + eisx − 1 −

dν¯(x), (8)

2

x2 + 1 x2

−∞

где ¯b ∈ R, σ2 ≥ 0 – некоторые числа, а ν¯(x) – некоторая конечная (то есть ν¯(R) < ∞) мера на вещественной оси R, такая, что ν¯({0}) = 0. Тройка (¯b, σ2, ν¯) для каждой безгранично делимой случайной величины
определяется единственным образом.
Если случайная величина Y имеет конечный второй момент, то формула (8) может быть уточнена следующим образом:

σ˜2s2 ˆ+∞

1

g(s) = ln φY (s) = i˜bs −

+ (︁eisx − 1 − isx)︁ ν˜(dx), (9)

2

x2

−∞

42

где ν˜ – конечная (то есть ν˜(R) < ∞) мера и ν˜({0}) = 0. Тройка (˜b, σ˜2, ν˜) для каждой безгранично делимой случайной величины с ко-

нечным вторым моментом определяется единственным образом.

Теорема 1.10. Пусть для каждого n ≥ 1 набор {Xkn}nk=1 состоит из независимых одинаково распределенных случайных величин и,

кроме того,

n
∑︂ Xkn −−−d−→ X.
n→∞ k=1

Тогда X – безгранично делимая случайная величина.
Рассмотрим важнейшие примеры безгранично делимых случайных величин.
Пример 1.10. Пусть случайная величина X принимает одно и то же значение m при любом исходе, т.е. X ≡ m. По определению, это безгранично делимая случайная величина, т.к. для любого n ≥ 1 ее можно представить как сумму n чисел m/n, которые являются независимыми и одинаково распределенными случайными величинами.
Случайная величина X является безгранично делимой и согласно теореме Леви–Хинчина. Действительно, ее характеристическая функция
φX (s) = eims

имеет вид (7) при b = m, σ2 = 0 и ν(x) = 0. △ Пример 1.11. Пусть случайная величина X имеет распределение
Пуассона с параметром λ > 0, т.е. X ∈ Po(λ) и

P(X = k) = λk e−λ, k = 0, 1, 2, . . . k!
Покажем, что эта случайная величина является безгранично делимой по определению. Для каждого n ≥ 1 рассмотрим набор {Xkn}nk=1 независимых одинаково распределенных случайных величин, имеющих распределение Po(λ/n). Тогда, как известно,

n

(︄ n )︄

∑︂

∑︂

Xkn ∈ Po

λ/n = Po(λ),

k=1

k=1

значит,

X

=d

∑︁n
k=1

Xkn,

т.е.

X

∈

Po(λ)

–

безгранично

делимая

случай-

ная величина.

Легко видеть, что характеристическая функция случайной вели-

чины X имеет вид (7), где b = 0, σ2 = 0, ν(x) = λδ(x − 1), и δ(x) –

дельта-функция Дирака. △

43

Пример 1.12. Покажем теперь, что случайная величина, имеющая стандартное нормальное распределение X ∈ N(0, 1), т.е. непрерывная случайная величина с плотностью распределения

1 f (x) = √

e−x2/2, x ∈ R,

2π

тоже является безгранично делимой. Для этого рассмотрим набор неза-
висимых одинаково распределенных по закону N(0, 1/n) случайных величин {Xkn}nk=1. Как известно,

n

(︄ n )︄

∑︂

∑︂

Xkn ∈ N 0, 1/n = N(0, 1),

k=1

k=1

значит,

X

=d

∑︁n
k=1

Xkn,

т.е.

X

∈

N(0,

1)

–

безгранично

делимая

случай-

ная величина.

Свойство безграничной делимости можно было бы установить и

следуя теореме Леви–Хинчина, заметив, что характеристическая функ-

ция X имеет вид (7) при b = 0, σ2 = 1, ν(x) = 0. △

Безгранично делимыми случайными величинами являются также

случайные величины с гамма-распределением, отрицательным бино-

миальным распределением, геометрическим распределением и мно-

гие другие. Случайные величины с биномиальным Bi(n, p), равномер-

ным R(a, b) и всяким другим невырожденным распределением с огра-

ниченным носителем не являются безгранично делимыми.

Теперь дадим некоторые пояснения вышеприведенным теоремам.

Теорема 1.10 утверждает, что для сумм независимых одинаково рас-

пределенных случайных величин предельным может быть только без-

гранично делимое распределение. С другой стороны, теоремы 1.8 и 1.9

предоставляют явный вид характеристической функции произвольно-

го безгранично делимого распределения. Значит, предельное распре-

деление может иметь характеристическую функцию только вида (7)

и характеризуется тремя параметрами: b, σ2 и ν(x) либо эквивалент-

ного вида (8) с преобразованным триплетом: ¯b, σ2 и ν¯(x) (отметим

еще раз, что еще один вид характеристической функции, данный в

формуле (9), является уточнением (8) при условии конечности вто-

рого момента). Теперь рассмотрим, например, представление Леви–

Хинчина. Тогда при b ̸= 0, σ2 = 0, ν(x) = 0 предельное распределение

представляет собой распределение постоянной случайной величины,

константы. При b ∈ R, σ2 > 0 и ν(x) = 0 получается нормальное рас-

пределение с математическим ожиданием b и дисперсией σ2. Наконец,

44

пнраисbп=ар0а,мσе2тр=ом0 иλ,νа(xп)р=и λb δ=(x´−1 1x) νп(оdлxу)ч, аσе2тс=я 0раисппрреодиезлвеонлиьеноПйуамсесрое-
−1
ν(x) (равной какой-либо вероятностной мере с точностью до множителя), получается сложное пуассоновское распределение. В некотором смысле, любое другое предельное распределение, отвечающее какомуто набору (b, σ2, ν(x)), «складывается» из двух «базисных» распределений: нормального распределения N(b, σ2) и сложного распределения Пуассона CPo(ν) или предела этих распределений.
Чрезвычайно интересно отметить, что вообще класс безгранично
делимых распределений совпадает с классом пределов последователь-
ностей сложных пуассоновских распределений [62, Том 2, Глава IX, §5, Теорема 2]. Даже нормальное распределение является пределом последовательности сложных пуассоновских распределений. За подробной информацией о безгранично делимых случайных величинах и их свойствах мы также отправляем читателя к монографии [99].
Нам важно отметить, что при весьма общих предположениях о случайных последовательностях их суммы сходятся к одному из трех вышеописанных распределений. Для того, чтобы это показать, удобно использовать так называемую теорему непрерывности. Эта теорема связывает сходимость по распределению и поточечную сходимость характеристических функций. Так как эта теорема является мощным инструментом для исследования свойств сходимости случайных последовательностей, мы приводим ее формулировку здесь.
Теорема 1.11 (непрерывности [69]). Последовательность случайных величин {Xk}∞ k=1 сходится по распределению к случайной величине X тогда и только тогда, когда в каждой точке s ∈ R

φXk (s) → φX (s), k → ∞,

где φXk (s) – характеристическая функция Xk, а φX (s) – характери-

стическая функция X.

Рассмотрим произвольную последовательность независимых оди-

наково распределенных случайных величин {Xk}∞ k=1 с математическим ожиданием m. Характеристическую функцию случайной величи-

ны Xk обозначим за φXk (t) = E exp(itXk). Так как случайные величи-

ны

независимы,

то

характеристическая

функция

суммы

S

=

∑︁n
k=1

Xk

будет равна произведению характеристических функций слагаемых,

а так как распределения равные, то – φS(t) = (φX1 (t))n. Напомним,

что для произвольной случайной величины ξ есть равенство φaξ(t) =

= φξ(at), ∀a ∈ R. Далее получаем, что для каждого t ∈ R

φS/n(t) = φS(t/n) = (φX1 (t/n))n = (1 + itm/n + o(1/n))n , n → ∞,

45

откуда получаем

φS/n(t) → exp(itm), n → ∞.

Так как exp(itm) – это характеристическая функция случайной вели-

чины

X

≡

m,

то

по

теореме

непрерывности

получаем,

что

1/n

∑︁n
k=1

Xk

сходится по распределению к константе m. Этот факт известен в ли-

тературе как закон больших чисел по Хинчину.

Рассмотрим теперь последовательность {Xkn}nk=1 независимых и

одинаково распределенных случайных величин Xkn ∈ Be(pn), причем

pn → 0, npn → λ > 0.

φXkn (s) = 1 + pn (︁eis − 1)︁ .

Пусть

Sn

=

∑︁n
k=1

Xkn.

Тогда

φSn (s) = (φX1n (s))n = (︁1 + pn(eis − 1))︁n → eλ(eis−1), n → ∞.

Это значит, что Sn сходится по распределению к распределению Пуассона с параметром λ. Этот факт известен в литературе как теорема Пуассона.
Рассмотрим, наконец, последовательность независимых и одинаково распределенных случайных величин {Xk}nk=1 с конечным вторым моментом EXk2 < ∞. Обозначим математическое ожидание m = EX1, а дисперсию σ2 = DX1. Рассмотрим случайную последовательность

1

(︄ n ∑︂

)︄ n (︃ ∑︂

1

m )︃

ηn = √︁ σ2/n

Xk/n − m =

Xk · σ√n − σ√n .

k=1

k=1

Все коэффициенты здесь подобраны так, чтобы Eηn = 0, а Dηn = 1. Отсюда можно получить, что

(︃ t2 (︃ 1 )︃)︃n

φηn (t) =

1− +o 2n

n

, n → ∞,

т.е. φηn (t) → exp(−t2/2), n → ∞, что означает сходимость к стандартному нормальному распределению. Этот факт в литературе известен
как центральная предельная теорема.

1.6. Процессы Леви
Рассмотрим класс случайных процессов {X(t), t ≥ 0} с независимыми стационарными приращениями (у которых распределение приращения X(t + s) − X(t) не зависит от t) и выходящими из нуля, то

46

есть X(0) = 0 п.н. Пусть Ft – распределение X(t). Тогда для любых t, s > 0
Ft+s = Ft ⋆ Fs,
где ⋆ означает свертку распределений. В частности, для любого t > 0 и n получается Ft = (Ft/n)n⋆, т.е. Ft – распределение безгранично делимой случайной величины (безгранично делимое распределение). Таким образом, для описания случайного процесса, выходящего из нуля, с независимыми стационарными приращениями требуется безгранично делимое распределение Ft. Кстати говоря, если отказаться от условия X(0) = 0, то для задания процесса дополнительно потребуется распределение X(0).
Справедливо и обратное утверждение: всякое безгранично делимое распределение с характеристической функцией вида etψ, где ψ не зависит от t, определяет случайный процесс, выходящий из нуля, с независимыми стационарными приращениями. Этот результат можно обобщить на случай нестационарных приращений потребовав взамен стохастическую непрерывность: для всех t ≥ 0 X(t + h) − X(t) стремится по вероятности к нулю при h → 0 [62].
В связи с описанным выше введем важный класс процессов – процессов Леви.
Определение 1.20. Случайный процесс {X(t), t ≥ 0} будем называть процессом Леви, если
а) X(0) = 0 почти всюду,
б) X(t) – процесс с независимыми приращениями,
в) для любых t, s ≥ 0 случайная величина X(t + s) − X(t) имеет распределение, не зависящее от t (стационарность приращений),
г) X(t) – стохастически непрерывный процесс, т.е.
∀t ≥ 0 X(t + ε) −−P−→ X(t).
ε→0
Иногда в определении процесса Леви дополнительно требуют, чтобы с вероятностью единица траектории процесса Леви были непрерывны справа при t ≥ 0 и имели конечный предел слева при t > 0 (ca`dla`g функции от французского термина continue a` droite, limite a` gauche, или согласно английской терминологии rcll – right continuous, left-hand limits). На самом деле это дополнение несущественно, так как можно показать, что всегда существует модификация процесса Леви с данным условием.
47

Отметим, что винеровский, пуассоновский, сложный пуассоновский процессы являются процессами Леви. Можно даже ввести следующие эквивалентные определения.
Теорема 1.12. Случайный процесс {K(t), t ≥ 0} является пуассо-
новским процессом с параметром λ > 0, если

• K(t) – процесс Леви,

• для любого t > 0 сечение K(t) имеет распределение Po(λt).

Теорема 1.13. Случайный процесс {Q(t), t ≥ 0} является слож-

ным

пуассоновским

процессом

∑︁K(t)
i=1

Vi,

где

K (t)

–

пуассоновский

про-

цесс интенсивности λ > 0 и Vi определяются вероятностной мерой

PV1 , если

• Q(t) – процесс Леви,

• для любого t > 0 сечение Q(t) имеет распределение CPoiss(λtPV1 ).
Теорема 1.14. Случайный процесс {W (t), t ≥ 0} является винеровским процессом, если

• W (t) – процесс Леви,

• для любого t > 0 сечение W (t) имеет распределение N(0, t).

Несложно заметить, что для процессов Леви справедливо функциональное уравнение относительно математического ожидания:

EX(t + s) = EX(t) + EX(s)

для любых t, s > 0. Это – частный вид известного в литературе функционального уравнения Коши или уравнения Гамеля, в общем случае записывающегося как уравнение

f (x + y) = f (x) + f (y)

на функцию f . Читателю предлагается доказать, что без каких-либо дополнительных предположений на функцию f в рациональных точках x решения этого уравнения имеют вид f (x) = cx, где c ∈ Q – произвольная постоянная. Если же дополнительно предположить, что функция f непрерывная, то отсюда следует, что решения этого уравнения имеют вид f (x) = cx, где c ∈ R – произвольная постоянная. Поэтому если процесс Леви обладает непрерывным математическим ожиданием, то EX(t) = ct для некоторой постоянной c.
Если процесс Леви имеет конечные вторые моменты, то аналогичное уравнение можно записать для дисперсии, откуда DX(t) = σ2t. При этом корреляционная функция равна RX (t, s) = σ2 min(t, s).

48

Теорема 1.15. Справедливо следующее. 1) Если X(t), t ≥ 0 – процесс Леви, то для любого t > 0 сечение X(t) – безгранично делимая случайная величина. 2) Если F – безгранично делимое распределение, то существует процесс Леви X(t), t ≥ 0, такой, что X(1) имеет распределение F . 3) Если X(t), Y (t), t ≥ 0 – два процесса Леви таких, что распределения X(1) и Y (1) совпадают, то конечномерные распределения процессов X(t) и Y (t) совпадают. Доказательство. Для доказательства первого пункта заметим, что для произвольного натурального N выполнено

N (︃ ∑︂

(︃ jt )︃

(︃ (j − 1)t )︃)︃

X(t) − X(0) =

X

−X

.

j=1 N N

По определению процесса Леви все слагаемые в выписанной сумме независимы и одинаково распределены. Так как, кроме того, X(0) = 0 почти наверное, то по определению получаем, что X(t) — безгранично делимая случайная величина.
Далее мы приведём только схему доказательства пункта 2 (подробности см. в [99, Chapter 2, § 7, Theorem 7.10]), пункт 3 же следует из пункта 2. Во-первых, в качестве X(1) достаточно взять случайную величину, имеющую распределение F , а в качестве X(0) — константу 0. Оказывается, что таким образом мы задали распределения сечений во всех положительных рациональных точках (действительно, достаточно воспользоваться представлением из пункта 1, чтобы задать распределение сечений в рациональных точках из [0, 1], а затем воспользоваться тем, что распределение приращения X(t+s)−X(t) зависит только от s, чтобы задать распределение сечений в рациональных точках из [1, 2], затем из [2, 3] и так далее). Пользуясь стохастической непрерывностью, можно доопределить процесс и во всех иррациональных точках. □
Как мы убедились класс процессов Леви тесно связан с классом безгранично делимых случайных величин. Вид характеристических фунций сечений процесса Леви обобщает теоремы 1.8 и 1.9 и дается в следующей теореме (с доказательством можно познакомиться, например, в [22, гл. I, § 3, теорема 4]).
Теорема 1.16. Пусть X(t) – процесс Леви. Тогда характеристи-
ческая функция φX(t+τ)−X(t)(s) = exp (τ g(s)), где g(s) дается формулой (7) или (8). Если процесс X(t) является процессом второго порядка, то для g(s) имеет место представление (9).
Приведем несколько частных случаев процессов Леви.

49

а) Если σ = 0, ν ≡ 0, то φX(t)(s) = exp (itbs) – это характеристическая функция вырожденного распределения, то есть X(t) = bt.
б) Если ν ≡ 0, то φX(t)(s) = exp (︁itbs − tσ2s2/2)︁. В этом случае приращения X(t + τ ) − X(t) имеют нормальное распределение с математическим ожиданием bτ и дисперсией σ2τ . Таким образом, X(t), t ≥ 0
– гауссовский процесс и его можно представить как X(t) = bt + σW (t),
t ≥ 0, где W (t) – винеровский процесс.
в) Если b = 0, σ = 0, мера ν сосредоточена в точке x0 ∈ (−1, 1) и ν({x0}) = λ > 0, то φX(t)(s) = exp (︁tλ(eisx0 − 1 − isx0))︁. Процесс X(t) можно представить как X(t) = x0(K(t) − λt), t ≥ 0 где K(t) – пуассоновгс)киЕйслпироσц=есс0. и ´ 1 dν(x) < ∞, то
−1

⎛⎡

ˆ+∞

⎤⎞

φX(t)(s) = exp ⎝t · ⎣ib1s + λ (︁eisx − 1)︁ dν1(x)⎦⎠ ,

−∞
где b1 = b + ´−11 dν(x), λ = ´−∞∞ dν(x), ν1 = λ−1ν – вероятностная мера. Иначе говоря,

∞

(λt)n ⎡ ˆ∞

⎤n

φX(t)(s) = eitbs ∑︂ e−λt

⎣ eisx dν1(x)⎦ ,

n!

n=0

−∞

то

есть

X (t)

=

b1t

+

∑︁K(t)
n=1

ξn,

t

≥

0,

где

K (t)

–

пуассоновский

процесс

интенсивности λ, {ξn}∞ n=1 – последовательность независимых случай-

ных величин с одинаковым распределением ν1 (этот случай соответ-

ствует сложному пуассоновскому процессу).

Ранее мы выяснили, что безгранично делимая случайная величина

представляется в виде суммы константы, гауссовской случайной вели-

чины и сложной пуассоновской случайной величины (при ν(R) < ∞ в

(7)) или, в общем случае, предела сложных пуассоновских случайных

величин (при ν(R) ≤ ∞). Если воспользоваться аналогичными рас-

суждениями, то из примера выше мы получаем, что процесс Леви с

конечной мерой ν (см. теоремы 1.8, 1.16) можно представить в виде

суммы процесса вида X(t) = bt, промасштабированного винеровского

процесса и сложного пуассоновского процесса.

В качестве примера процесса Леви с ν(R) = ∞ рассмотрим суб-

ординатор Морана. По определению это процесс Леви, отвечающий

гамма-распределению: ν(dx) = x−1e−xdx (см. [8, гл. 5, задача 42]). При

помощи субординатора Морана можно генерировать последовательно-

сти случайных величин, имеющие распределение Пуассона–Дирихле.

50

Это распределение упорядоченных по убыванию нормированных скачков субординатора Морана (детали см. в [32]). Распределение Пуассона–Дирихле часто применяется в популяционной генетике и экономике (оно является равновесным распределением для ряда эволюционных моделей).
Замечание 1. Стоит еще раз подчеркнуть, что процессы Леви в некотором смысле просты в своем описании. А именно, для их задания не нужно знать семейства конечномерных распределений. Они полностью описываются распределением одного сечения, например, в момент времени t = 1. Действительно, если характеристическая функция сечения X(1) равна EeisX(1) = ϕ(s), то характеристическая функция
• произвольного сечения равна
EeisX(t) = (ϕ(s))t ,

• приращения на интервале [t1, t2] Eeis(X(t2)−X(t1)) = (ϕ(s))t2−t1 ,

• векторы из приращений X(t1) − X(t0), X(t2) − X(t1), X(t3) − X(t2),. . . , X(tn) − X(tn−1), где 0 = t0 = t1 < t2 < . . . < tn:

n

Eei

∑︁n
k=1

sk

(X (tk

)−X (tk−1 ))

=

∏︂

(ϕ(sk ))tk −tk−1

,

k=1

• векторы из сечений (X(t1), X(t2), . . . , X(tn)), где t1 < t2 < . . . <

tn:
n

Eei

∑︁n
k=1

sk

X

(tk

)

=

∏︂

(ϕ(s˜k ))tk −tk−1

,

k=1

где

s˜k

=

∑︁n
i=k

si.

Последняя формула следует из связи характеристических функций векторов, получающихся друг из друга с помощью линейного преобразования.

51

2. Введение в стохастический анализ
Данный раздел представляет собой введение в стохастический анализ случайных процессов. Здесь рассматриваются случайные процессы, любое сечение которых является случайной величиной второго порядка, т.е. ∀t ∈ T выполнено EX2(t) < ∞. Такие процессы мы называем случайными процессами второго порядка. Кроме того, будем считать для определенности, что T = [0, +∞). Здесь вводятся понятия непрерывности, дифференцируемости и интегрируемости случайных процессов.
2.1. Пространство L2 случайных величин
В данном разделе мы приведем несколько свойств случайных величин второго порядка, т.е. случайных величин с конечным вторым моментом: EX2 < ∞. Эти свойства понадобятся нам при построении корреляционной теории случайных процессов в следующем разделе.
Обозначим за L2 множество случайных величин второго порядка, заданных на одном вероятностном пространстве. Билинейная функция ⟨·, ·⟩ : L2 × L2 → R, такая, что ∀X, Y ∈ L2 ↪→ ⟨X, Y ⟩ = E(XY ) определяет скалярное произведение на L2. Чтобы это показать, проверим аксиомы скалярного произведения:
1. ∀X ∈ L2 ↪→ ⟨X, X⟩ = EX2 ≥ 0, т.к. X2 ≥ 0. Кроме того,
⟨X, X⟩ = 0 ⇔ EX2 = 0 ⇔ X п=.н. 0.
2. ∀X, Y ∈ L2 ↪→ ⟨X, Y ⟩ = E(XY ) = E(Y X) = ⟨Y, X⟩.
3. ∀X, Y, Z ∈ L2, α, β ∈ R ↪→ ⟨αX + βY, Z⟩ = α⟨X, Z⟩ + β⟨Y, Z⟩.
Аксиомы скалярного произведения проверены, линейное пространство L2 с введенным скалярным произведением является евклидовым. Отсюда вытекает несколько простых и полезных следствий, которые являются общими для всех евклидовых пространств.
Теорема 2.1 (неравенство Коши–Буняковского–Шварца).
∀X, Y ∈ L2 ↪→ ⟨X, Y ⟩2 ⩽ ⟨X, X⟩⟨Y, Y ⟩.
Доказательство. Выражение ⟨X + αY, X + αY ⟩ является квадратичной функцией α; при этом оно неотрицательно для каждого α ∈ R. Неравенство из утверждения теоремы – лишь условие неотрицательности дискриминанта этой квадратичной функции. □
52

Теперь перейдём к вопросу сходимости случайных величин из L2.
Введем евклидову норму, связанную со скалярным произведением: ∥X∥2 = √︁⟨X, X⟩. Договоримся далее о следующих обозначениях:

Xn −−L−2−→ X ⇔ ∥Xn − X∥2 −−−−→ 0 ⇔ X = l. i. m. Xn,

n→∞

n→∞

n→∞

означающих, что последовательность случайных величин {Xn}∞ n=1 сходится в среднем квадратичном к случайной величине X.

Теорема 2.2 (непрерывность скалярного произведения). Ес-

ли Xn −−L−2−→ X, Ym −−L−2−→ Y , то

n→∞

m→∞

⟨Xn, Ym⟩ −−−−−→ ⟨X, Y ⟩.
n,m→∞

Доказательство. Заметим, что согласно неравенству Коши–Буняковского–Шварца

|⟨Xn + X, Ym − Y ⟩|2 ≤ ⟨Xn + X, Xn + X⟩ · ⟨Ym − Y, Ym − Y ⟩ −−−−−→ 0,

⏞ ⏟⏟ ⏞ ⏞ ⏟⏟ ⏞ n,m→∞

ограничено

−−−−→0

m→∞

что означает

⟨Xn + X, Ym − Y ⟩ −−−−−→ 0.
n,m→∞

Аналогично доказывается, что

⟨Xn − X, Ym + Y ⟩ −−−−−→ 0.
n,m→∞

Пользуясь линейностью скалярного произведения, легко получаем

⟨Xn + X, Ym − Y ⟩ + ⟨Xn − X, Ym + Y ⟩ = 2 (⟨Xn, Ym⟩ − ⟨X, Y ⟩) ,

⏞

⏟⏟

⏞

−−−−−→0

n,m→∞

откуда следует ⟨Xn, Ym⟩ → ⟨X, Y ⟩ при n, m → ∞, что и требовалось доказать. □
Следующую теорему приводим без доказательства (доказательство можно найти, например, в [7]).
Теорема 2.3 (полнота L2). Любая фундаментальная по Коши последовательность из L2 сходится в среднем квадратичном к случайной величине из L2.
Мы же воспользуемся этой теоремой для доказательства следующей теоремы.

53

Теорема 2.4. Пусть для последовательности {Xn}∞ n=1 ⊂ L2 найдется такое c ∈ R, что для любых подпоследовательностей {Xnk }∞ k=1 и {Xnm }∞ m=1 выполнено ⟨Xnk , Xnm ⟩ −−−−−→ c. Тогда
k,m→∞

∃X ∈ L2 : X = l. i. m.Xn.
n→∞
Доказательство. Рассмотрим произвольные подпоследовательности {Xnk }∞ k=1, {Xnm }∞ m=1 ⊂ {Xn}∞ n=1 и квадрат их разности
(Xnk − Xnm )2 = Xn2k − 2Xnk Xnm + Xn2m .
Из условия теоремы следует, что существует c ∈ R, такое что

⟨Xnk , Xnm ⟩ −−−−−→ c, ⟨Xnk , Xnk ⟩ −−−−−→ c, ⟨Xnm , Xnm ⟩ −−−−−→ c.

k,m→∞

k,m→∞

k,m→∞

Отсюда получаем, что

lim ⟨Xnk − Xnm , Xnk − Xnm ⟩ = c − 2c + c = 0,
k,m→∞

т.е.

Xn − Xn −−−L−2−→ 0.

k

m k,m→∞

Если рассмотреть в качестве подпоследовательностей {Xnk } и {Xnm } исходную последовательность {Xn}∞ n=1, то получим, что

Xk − Xm −−−L−2−→ 0,
k,m→∞

т.е. что {Xn}∞ n=1 — фундаментальная по Коши последовательность. Но по теореме 2.3 это значит, что она сходится. □
Теперь, когда введено пространство случайных величин со скалярным произведением и пределом, мы приступаем к определению таких важнейших понятий любого анализа как непрерывность, дифференцируемость и интегрируемость.
Всюду далее мы будем называть процессами второго порядка те процессы, у которых каждое сечение имеет конечный второй момент, т.е. для любого t ≥ 0 второй момент EX2(t) < ∞. Принадлежность классу процессов второго порядка мы будем обозначать так: X(t) ∈ L2, аналогично тому, как мы поступали для случайных величин второго порядка.

54

2.2. Непрерывность в среднем квадратичном
Определение 2.1. Случайный процесс второго порядка X(t) называется непрерывным в среднем квадратичном (с.к.-непрерывным, непрерывным по математическому ожиданию), если

∀t ≥ 0 ↪→ X(t + ε) −−L−2→ X(t).
ε→0

Теорема 2.5 (критерий с.к.-непрерывности). Процесс X(t) ∈
∈ L2 является с.к.-непрерывным тогда и только тогда, когда его ковариационная функция KX (t1, t2) непрерывна на множестве [0, +∞)2.
Доказательство. Пусть процесс X(t) является с.к.-непрерывным. Тогда для любых t1, t2 ≥ 0 можно записать

X(t1 + ε1) −−L−2→ X(t1), X(t2 + ε2) −−L−2→ X(t2).

ε1 →0

ε2 →0

Из теоремы 2.2 получаем, что

⟨X(t1 + ε1), X(t2 + ε2)⟩ −−−−−→ ⟨X(t1), X(t2)⟩,
ε1 ,ε2 →0

что и означает KX (t1 + ε1, t2 + ε2) → KX (t1, t2) при ε1, ε2 → 0. Предположим теперь, что функция KX (t1, t2) непрерывна всюду
на [0, +∞)2. Тогда она непрерывна во всех точках вида (t, t), t ≥ 0. Остается заметить, что
E (X(t + ε) − X(t))2 = KX (t + ε, t + ε) − 2KX (t + ε, t) + KX (t, t)

и, взяв предел при ε → 0, получить

X(t + ε) −−L−2→ X(t). □
ε→0

Заметим, что при доказательстве с.к.-непрерывности процесса при непрерывной ковариационной функции используется ее непрерывность (как функции двух аргументов) лишь в точках вида (t, t). Получается, что непрерывность ковариационной функции в точках вида (t, t) влечет с.к.-непрерывность процесса, а с.к.-непрерывность процесса влечет непрерывность ковариационной функции всюду (не только в точках вида (t, t)). Это значит, что непрерывность ковариационной функции в точках вида (t, t) влечет ее непрерывность во всех точках множества [0, +∞)2.

55

Кроме того, легко показать, что непрерывность ковариационной функции равносильна непрерывности функции математического ожидания процесса и непрерывности корреляционной функции. Действительно, если математическое ожидание и корреляционная функция всюду непрерывны, то непрерывна и ковариационная функция, т.к. они связаны соотношением KX (t1, t2) = RX (t1, t2) + mX (t1)mX (t2). Наоборот, если ковариационная функция всюду непрерывна (и следовательно процесс – с.к.-непрерывный), то

(︃ ◦

◦

)︃2

E (X(t + ε) − X(t))2 = E X(t + ε) − X(t) + mX (t + ε) − mX (t) =

(︃ ◦

◦ )︃2

= E X(t + ε) − X(t) + (mX (t + ε) − mX (t))2 −−−→ 0.

ε→0

Так как оба слагаемых неотрицательные, то каждое из них стремится к нулю при ε → 0. Сходимость к нулю второго слагаемого означает непрерывность математического ожидания. Сходимость к нулю первого слагаемого означает с.к.-непрерывность центрированного процесса, а следовательно, – непрерывность его ковариационной функции. Но ковариационная функция центрированного процесса – это корреляционная функция исходного процесса.
Итак, теорему 2.5 можно сформулировать и следующим образом. Теорема 2.5′ (критерий с.к.-непрерывности). Процесс X(t) ∈
∈ L2 является с.к.-непрерывным тогда и только тогда, когда его математическое ожидание mX (t) непрерывно при t ≥ 0 и корреляционная функция RX (t1, t2) непрерывна на множестве [0, +∞)2.
Пример 2.1. Винеровский процесс является с.к.-непрерывным, так как его математическое ожидание всюду непрерывно (оно всюду равно нулю) и корреляционная функция RX (t1, t2) = min(t1, t2) непрерывна всюду. То же справедливо для пуассоновского процесса интенсивности λ > 0: его математическое ожидание mK(t) = λt и корреляционная функция RK (t1, t2) = λ min(t1, t2) непрерывны всюду на своих областях определения. Процесс из задачи 1.5 является с.к.-непрерывным, так как его математическое ожидание непрерывно (всюду равно нулю) и корреляционная функция Rξ(t1, t2) = 1/2 cos (t1 − t2) непрерывна всюду. Процесс из примера 1.6 является с.к.-непрерывным, так как его математическое ожидание mξ(t) = 1 − t и корреляционная функция Rξ(t1, t2) = min(t1, t2) − t1t2 непрерывны всюду на своих областях определения. △

56

2.3. Дифференцируемость в среднем квадратичном

Определение 2.2. Случайный процесс X(t) ∈ L2 называется дифференцируемым в среднем квадратичном (с.к.-дифференцируемым или дифференцируемым по математическому ожиданию), если существует процесс Y (t) ∈ L2, t ≥ 0, такой, что

X(t + ε) − X(t) L2

∀t ≥ 0 ↪→

−−−→ Y (t).

ε

ε→0

Случайный процесс Y (t) в этом случае называется с.к.-производной процесса X(t) и будет обозначаться штрихом, т.е. Y (t) = X′(t).
Теорема 2.6 (критерий с.к.-дифференцируемости). Случай-
ный процесс X(t) ∈ L2 является с.к.-дифференцируемым тогда и только тогда, когда для любой пары t1, t2 ≥ 0 существует конечный предел

1

lim

(KX (t1 + ε1, t2 + ε2) − KX (t1 + ε1, t2) −

ε1,ε2→0 ε1ε2

− KX (t1, t2 + ε2) + KX (t1, t2)) < ∞.

Доказательство. Пусть X(t) является с.к.-дифференцируемым. Введем обозначения

X(t1 + ε1) − X(t1)

Yε1 (t1) =

, ε1

X(t2 + ε2) − X(t2)

Yε2 (t2) =

. ε2

Тогда Yε (t1) −−L−2→ X′(t1) и Yε (t2) −−L−2→ X′(t2). Из теоремы 2.2 сле-

1

ε1 →0

2

ε2 →0

дует, что

E(Yε (t1)Yε (t2)) −−−−−→ E(X′(t1)X′(t2)) ≤ EX′(t1)2 · EX′(t2)2 < ∞.

1

2

ε1 ,ε2 →0

Остается заметить, что E(Yε1 (t1)Yε2 (t2)) равняется подпредельному выражению из утверждения теоремы и

1

∞

>

lim
ε1 ,ε2 →0

E(Yε1 (t1)Yε2 (t2))

=

lim
ε1 ,ε2 →0

ε1ε2

(KX (t1

+

ε1,

t2

+

ε2)−

− KX (t1 + ε1, t2) − KX (t1, t2 + ε2) + KX (t1, t2)).

Пусть теперь существует предел из утверждения теоремы для лю-
бой пары (t1, t2). Тогда этот предел существует для пары (t, t), т.е. при t1 = t2 = t. Из существования предела выражения E(Yε1 (t)Yε2 (t)) при ε1, ε2 → 0 и теоремы 2.4 следует существование процесса Y (t) ∈ L2

57

такого, что Y (t) = l. i. m.ε→0 Yε(t). По определению, это и означает существование с.к.-производной процесса X(t). □
Теперь, когда теорема доказана, необходимо сделать несколько важных замечаний.
Первое замечание состоит в том, что предел из утверждения теоремы не является смешанной производной второго порядка ковариационной функции KX (t1, t2). Дело в том, что по определению смешанная производная второго порядка функции двух переменных – это производная по одной переменной от производной по другой переменной, т.е. повторный предел по каждой переменной. Предел из теоремы – это предел по двум переменным, он отличается от второй смешанной производной так же, как предел по двум переменным отличается от повторного предела. Предел из теоремы обычно называется обобщенной смешанной производной (она не имеет никакого отношения к обобщенным функциям!). Из существования обобщенной смешанной производной вытекает существование обычной смешанной производной второго порядка; обратное, вообще говоря, не верно. Достаточным условием существования обобщенной смешанной производной функции KX (t1, t2) является непрерывность хотя бы одной из частных производных

∂ (︃ ∂KX (t1, t2) )︃ , ∂ (︃ ∂KX (t1, t2) )︃ .

∂t1

∂t2

∂t2

∂t1

Второе замечание состоит в том, что при доказательстве существования с.к.-производной мы воспользовались лишь конечностью обобщенной смешанной производной в точках вида (t, t). Получается, что конечность обобщенной смешанной производной в точках вида (t, t) влечет существование с.к.-производной исходного процесса, что влечет конечность обобщенной смешанной производной всюду. Поэтому, теорему можно сформулировать и следующим образом.
Теорема 2.6′ (критерий с.к.-дифференцируемости). Случай-
ный процесс X(t) ∈ L2 является с.к.-дифференцируемым тогда и только тогда, когда для любого t ≥ 0 существует конечный предел

1

lim

(KX (t + ε1, t + ε2) − KX (t + ε1, t) −

ε1,ε2→0 ε1ε2

− KX (t, t + ε2) + KX (t, t)) < ∞.

Наконец, третье замечание заключается в том, что существование обобщенной смешанной производной ковариационной функции равносильно существованию производной математического ожидания процесса и существованию обобщенной смешанной производной корреля-

58

ционной функции. Мы опускаем доказательство этого факта, но сформулируем еще один вариант теоремы 2.6.
Теорема 2.6′′ (критерий с.к.-дифференцируемости). Случай-
ный процесс X(t) ∈ L2 является с.к.-дифференцируемым тогда и только тогда, когда для любого t ≥ 0 существует производная математи-
ческого ожидания процесса mX (t) и существует конечный предел

1

lim

(RX (t + ε1, t + ε2) − RX (t + ε1, t) −

ε1,ε2→0 ε1ε2

− RX (t, t + ε2) + RX (t, t)) < ∞.

Пример 2.2. Винеровский процесс не является с.к.-дифференцируемым ни в какой точке, так как не существует обобщенной производной корреляционной функции в точках вида (t, t). Действительно, возьмем произвольную точку t и рассмотрим предел

1

lim

(RW (t + ε1, t + ε2) − RW (t + ε1, t) −

ε1,ε2→0 ε1ε2

− RW (t, t + ε2) + RW (t, t)).

Так как RW (t, s) = min(t, s) = (t + s − |t − s|)/2, то данный предел ра-

вен пределу

lim |ε1| + |ε2| − |ε1 − ε2| .

ε1 ,ε2 →0

2ε1ε2

Конечный предел не существует, так как при ε1 = ε2 он равен +∞. △

Пример 2.3. Процесс из задачи 1.5 является с.к.-дифференцируе-

мым. Действительно, его математическое ожидание тождественно рав-

но нулю, а значит, дифференцируемо всюду. Корреляционная функ-

ция Rξ(t1, t2) = 1/2 cos(t1 − t2) имеет непрерывную смешанную про-

изводную второго порядка в любой точке вида (t, t); следовательно,

обобщенная производная существует и конечна всюду.

2.4. Интегрируемость в среднем квадратичном
Определение 2.3. Пусть процесс X(t) ∈ L2 определен на отрезке [a, b] ⊂ [0, +∞). На отрезке [a, b] построим некоторое разбиение a = = t0 < t1 < · · · < tn−1 < tn = b, и на каждом из промежутков этого разбиения выберем произвольную точку τi ∈ [ti−1, ti), i = 1, . . . , n. Если при n → ∞ и max (ti − ti−1) → 0 существует предел в средне-
i=1,...,n
квадратическом
n
∑︂ X(τi)(ti − ti−1) −−L−2→ Y,
ε→0 i=1

59

не зависящий от способа разбиения {ti} и выбора точек {τi}, то процесс X(t) называется с.к.-интегрируемым на [a, b], а случайная величина Y называется ее с.к.-интегралом или стохастическим интегралом Римана на отрезке [a, b] и обозначается

ˆb Y = X(t) dt.

a

Определение с.к.-интеграла допускает полезное обобщение. Определение 2.4. Пусть процесс X(t) ∈ L2 определен на отрезке [a, b] ⊂ [0, +∞), а g(t) – неслучайная непрерывная функция на отрезке [a, b]. Тогда с.к.-интеграл случайного процесса g(t)X(t), если он существует, называется с.к.-интегралом процесса X(t) с непрерывной функцией g(t) или стохастическим интегралом Римана по математическому ожиданию процесса X(t) с непрерывной функцией g(t). Процесс X(t) в этом случае называется с.к.-интегрируемым с непрерывной функцией g(t). Следующие два критерия с.к.-интегрируемости мы приводим без доказательства. Теорема 2.7 (критерий с.к.-интегрируемости). Случайный
процесс X(t) ∈ L2 с.к.-интегрируем с непрерывной функцией g(t) на отрезке [a, b] ⊂ [0, +∞) тогда и только тогда, когда существует конечный интеграл Римана:

ˆb ˆb g(t1)g(t2)KX (t1, t2) dt1dt2 < ∞.

aa

Теорема 2.7′ (критерий с.к.-интегрируемости). Случайный процесс X(t) ∈ L2 с.к.-интегрируем с непрерывной функцией g(t) на отрезке [a, b] ⊂ [0, +∞) тогда и только тогда, когда существуют конечные интегралы Римана:

ˆb

ˆb ˆb

g(t)mX (t) dt < ∞,

g(t1)g(t2)RX (t1, t2) dt1dt2 < ∞.

a

aa

Отметим, что если процесс является с.к.-непрерывным, то он является с.к.-интегрируемым на любом отрезке и с любой непрерывной функцией. Если процесс является с.к.-дифференцируемым, то он является с.к.-непрерывным. Например, т.к. винеровский и пуассоновский процессы являются с.к.-непрерывными, то они являются с.к.интегрируемыми на любом отрезке с любой непрерывной функцией.

60

2.5. Полезные формулы и примеры

Итак, мы рассмотрели понятие с.к.-предела в пространстве L2 случайных величин второго порядка и ввели на его основе понятия с.к.- непрерывности, с.к.-производной и с.к.-интеграла случайных процессов. Совершенно аналогично можно было бы ввести понятия непрерывности, дифференцируемости и интегрируемости, рассматривая их в смысле сходимости почти наверное, по вероятности и по распределению. Для этого во всех определениях выше вместо с.к.-предела нужно поставить предел в соответствующем смысле. Отметим, что критерии непрерывности, дифференцируемости и интегрируемости в этом случае будут другие.
Пример 2.4. Выше мы видели, что пуассоновский процесс не является с.к.-дифференцируемым. Покажем, что он является дифференцируемым в смысле сходимости по вероятности, т.е. что существует такая случайная величина Y (t), что

K(t + ε) − K(t) P

∀t ≥ 0 ↪→

−−−→ Y (t),

ε

ε→0

или, по определению сходимости по вероятности,

(︃⃓ ⃓

K

(t

+

ε)

−

K

(t)

⃓ )︃ ⃓

∀t ≥ 0, ∀δ > 0 ↪→ P ⃓

− Y ⃓ > δ −−−→ 0.

⃓

ε

⃓

ε→0

Пусть λ – интенсивность пуассоновского процесса. Возьмем Y (t) = 0. Заметим, что K(t + ε) − K(t) ∈ Po(λε) и следовательно,
P(K(t + ε) − K(t) = k) = (λε)k e−λε, k = 0, 1, 2, . . . . k!
При ε < 1/δ число δε < 1, событие {K(t + ε) − K(t) > δε} совпадает с событием {K(t + ε) − K(t) > 0}, и значит,
P(K(t + ε) − K(t) > δε) = P(K(t + ε) − K(t) > 0) = 1 − e−λε → 0

при ε → 0. Итак, мы показали, что пуассоновский процесс в любой точке обладает производной в смысле сходимости по вероятности и эта производная всюду равна 0. Отсюда следует и то, что пуассоновский процесс в любой точке обладает производной в смысле сходимости по распределению, и эта производная тоже всюду равна 0. △
Пример 2.5. Покажем, что винеровский процесс не является дифференцируемым ни в какой точке даже по распределению. Предположим противное. Зафиксируем t ≥ 0. Пусть существует случайная величина Y такая, что

W (t + ε) − W (t) d

∀t ≥ 0 ↪→

−−−→ Y.

ε

ε→0

61

Введем обозначение

W (t + ε) − W (t)

Xε =

. ε

По теореме непрерывности, из сходимости по распределению следует сходимость характеристических функций, т.е.

∀s ∈ R ↪→ φXε (s) → φY (s), ε → 0.
Так как Xε ∈ N(0, 1/|ε|), то φXε (s) = e−s2/(2|ε|). Следовательно, при s = 0 имеем φXε (0) = 1, а при s ̸= 0 получаем φXε (s) → 0, ε → 0. Таким образом, предельная функция φY (s) не является непрерывной в точке s = 0, но так как характеристическая функция всякой случайной величины всюду непрерывна, получаем противоречие. △
Приведем также ряд соотношений, вывод которых предлагается выполнить читателю в качестве упражнения. Все процессы здесь предполагаются достаточно с.к.-гладкими.

EX′(t) =

d EX (t),

dt

cov(X′(t), X′(s)) = RX′ (t, s) = ∂2RX (t, s) , ∂t ∂s

cov(X′(t), X′(t)) = DX′(t) = ∂2RX (t, s) ⃓⃓⃓ , ∂t ∂s ⃓s=t
cov (X(t), X′(s)) = ∂RX (t, s) , ∂s

ˆb

ˆb

E X(t) dt = EX(t) dt,

a

a

⎛

ˆb

⎞ ˆb

cov ⎝X(t), X(t) dt⎠ = RX (t, s)ds,

a

a

⎛ˆb

ˆd

⎞ ˆb ˆd

cov ⎝ X(t) dt, X(t) dt⎠ =

RX (t, s) dtds,

a

c

ac

⎛ˆb

ˆb

⎞ ˆb

ˆb ˆb

cov ⎝ X(t) dt, X(t) dt⎠ = D X(t) dt =

RX (t, s) dtds.

a

a

a

aa

62

Пример 2.6. Пусть X(t) ∈ L2, X′(t) ∈ L2, J(t) = ´0t X(τ )dτ ∈ L2 и mX (t) ≡ 0. Вычислить взаимную корреляционную функцию случайных процессов X′(t) и J(t).
Решение. Из соотношений выше сразу следует, что mX′ (t) = 0 и mJ (t) = 0 для всех t. Следовательно,

RX′,J (t1, t2) = E(X′(t1)J (t2)) =

⎛

⎞

⎜

⎜

X(t1 + ε) − X(t1)

n

⎟

⎟

∑︂ ′

= E ⎜l. i. m.

⎜ ε→0

ε

·

l. i. m.

0=τ <τ <...<τ =t

X(τi )∆τi⎟⎟ =

⎜

0
max

1
∆τ

i

−−−−→n 0

2

i=1

⎟

⎝

i=1,n

n→∞

⎠

τi′ ∈[τi ,τi+1 )

Теорема 2.2

(︄ X(t1 + ε1) − X(t1)

n
∑︂

′

)︄

= lim E
ε→0

ε

· X(τi )∆τi =

n→∞

i=1

= lim E (︄∑n︂ X(t1 + ε)X(τi′) − X(t1)X(τi′) ∆τi)︄ =

ε→0

ε

n→∞ i=1

n R (t + ε, τ ′) − R (t , τ ′)

ˆt2 ∂R (t , τ )

∑︂ = lim

X1

i

X 1 i ∆τi =

X 1 dτ,

ε→0

ε

∂t1

n→∞ i=1

0

где ∆τi = τi − τi−1, i ≥ 1, и начиная с третьей строчки условия о стремлении мелкости разбиения отрезка [0, t2] к нулю, заменены для краткости одним условием n → ∞. △

2.6. Интеграл Римана–Стилтьеса
Теперь введем понятие интеграла Римана–Стилтьеса, аналогичное понятию интеграла Стилтьеса для неслучайных функций.
Определение 2.5. Пусть процесс X(t) ∈ L2 определен на отрезке [a, b] ⊂ [0, +∞) и g(t) – непрерывная на отрезке [a, b] функция. На отрезке [a, b] построим некоторое разбиение a = t0 < t1 < · · · < < tn−1 < tn = b, и на каждом из промежутков этого разбиения выберем произвольную точку τi ∈ [ti−1, ti), i = 1, . . . , n. Если при n → ∞ и ε = max (ti − ti−1) → 0 существует предел в среднеквадратическом
i=1,...,n
n
∑︂ g(τi)(X(τi) − X(τi−1)) −−L−2→ Y,
ε→0 i=1

63

не зависящий от способа разбиения {ti} и выбора точек {τi}, то случайная величина Y называется интегралом Римана–Стилтьеса с непрерывной функцией g(t) на отрезке [a, b] и обозначается символом

ˆb Y = g(t) dX(t).

a

Приведем без доказательства критерий существования такого интеграла.
Теорема 2.8. (см. [44]) Пусть X(t) ∈ L2. Интеграл Римана–Стилтьеса от случайного процесса X(t) с непрерывной функцией g(t) существует тогда и только тогда, когда

ˆb ˆb g(t1)g(t2) dKX (t1, t2) < ∞,
aa

где интеграл понимается в смысле интеграла Римана–Стилтьеса2. Интеграл Римана–Стилтьеса по конечным отрезкам естественным
образом обобщается на случай бесконечных интервалов. Например, по определению будем считать, что

ˆ+∞ g(t) dX(t) =
0
если этот предел существует.

ˆb
l. i. m. g(t) dX(t),
b→+∞ 0

2.7. Стохастический интеграл и формула Ито
Введем теперь понятие стохастического интеграла от случайного процесса по винеровскому процессу {W (t), t ≥ 0}. Это понятие пригождается для определения стохастических дифференциальных уравнений.
Далее нам пригодится обозначение σ{X(t), t ∈ T } сигма-алгебры, порожденной случайным процессом X(t) на множестве t ∈ T . Это минимальная сигма-алгебра, относительно которой измеримы все сечения X(t) на множестве t ∈ T .
2Здесь интеграл понимается в следующем смысле. Пусть мера клетки [a1, a2] × [b1, b2] равна K(a2, b2) − K(a1, b2) − K(a2, b1) + K(a1, b1). При помощи клеточных разбиений и сумм Римана вводится интеграл Римана–Стилтьеса от непрерывной функции подобно тому, как определялся интеграл Римана–Стилтьеса в одномерном случае (см. [7, гл. 3, §6]) и кратный интеграл Римана.

64

Определение 2.6. Случайная функция {X(t), t ∈ [a, b]} называется неупреждающей относительно процесса {W (t), t ∈ [a, b]}, если для любого t ∈ [a, b] и для любого борелевского множества B ∈ B выполнено {X(t) ∈ B} ∈ σ{W (s), s ≤ t}.
Если говорить очень грубо, то это значит, что события, связанные с процессом X(t) в момент t, связаны с событиями процесса W (t) на интервале времени до t включительно и не связаны с «будущим» процесса W (t), т.е. с событиями на интервалах времени после момента времени t.
Как обычно в теории меры, интеграл от случайной функции мы построим как предел интеграла от простых (ступенчатых, кусочнопостоянных) функций. Предел этот будем мы будем понимать в с.к.-смысле. Под интегралом же простой функции Xn(t), принимающей значения Xn(t) = Xn(tk) на интервалах tk ≤ t < tk+1 разбиения {tk}nk=1 интервала [a, b] будет понимать просто сумму
n
∑︂ I(Xn) = Xn(tk)(W (tk+1) − W (tk)).
k=1
Теорема 2.9. (см. [41, С. 214]) Пусть {X(t), t ∈ [a, b]} – с.к.-непрерывная на [a, b] неупреждающая функция. Тогда найдется последовательность Xn(t) простых неупреждающих функций {Xn(t)}, такая, что
ˆb E|Xn(t) − X(t)|2 dt → 0, n → ∞,
a
и для которой существует с.к.-предел I(Xn) −с−.к→. I, n → ∞. Определение 2.7. Предел I в теореме выше называется стоха-
стическим интегралом функции X(t) по винеровскому процессу W (t) на интервале [a, b] и обозначается
ˆb I(X) = X(t) dW (t).
a
Если сравнить это определение с интегралом от неслучайной функции по случайному процессу, то можно видеть, что все отличие состоит в паре формальностей: вместо непрерывной подынтегральной функции мы имеем дело с с.к.-непрерывной функцией и дополнительно требуем от нее свойство неупреждаемости. Можно доказать, что
65

значение I не зависит от выбора последовательности простых функций. Поэтому на практике интервал [a, b] можно разбивать равномерно по времени. Разберем хрестоматийный пример.
Пример 2.7. Вычислить стохастический интеграл

ˆT I = W (t) dW (t).

0

Решение. Подынтегральная функция W (t) является всюду

с.к.-непрерывной и, очевидно, неупреждающей функцией. Вычислять

интеграл будем по определению, для этого введем равномерное разби-

ение отрезка [0, T ], t1 < . . . tn, tk+1 − tk = h, запишем интегральную

сумму
n

∑︂

In = W (tk)(W (tk+1) − W (tk)).

(10)

k=1

Для краткости обозначений введем ∆tk = tk+1 − tk, ∆Wk = W (tk+1)− −W (tk) ∈ N(0, ∆tk). Теперь заметим, что

W (tk)∆Wk = 1 (︁W 2(tk+1) − W 2(tk))︁ − 1 (∆Wk)2.

2

2

Отсюда следует, что

1

1

n
∑︂

In = (︁W 2(T ) − W 2(0))︁ −

(∆Wk )2 .

2

2

k=1

Первое слагаемое этого выражения не зависит от n и с измельчением отрезка [0, T ] не меняется. Найдем с.к.-предел второго слагаемого.3
Попробуем сначала найти его математическое ожидание

и дисперсию

n

n

E ∑︂(∆Wk)2 = ∑︂ E(∆Wk)2 = nh = T

k=1

k=1

n
D ∑︂(∆Wk)2
k=1

n

n

= ∑︁ D(∆Wk)2 = ∑︁ E(∆Wk)4 − (E(∆Wk)2)2

k=1

k=1

n
= ∑︁ 3(D∆Wk)2 − nh2 = 3h2n − h2n = 2h2n,
k=1

3Ниже приводится только схема рассуждений. Более подробно соответствующие выкладки расписаны в примере 3.2.

66

где для расчета момента четвертого порядка можно воспользоваться теоремой Вика (теорема 3.1 настоящего пособия). Получается, что D ∑︁nk=1(∆Wk)2 = 2T 2/n → 0, n → ∞, но по определению с.к.-предела это значит, что ∑︁nk=1(∆Wk)2 −с−.к→. T . Итак, мы показали, что

In −с−.к→. 1 (︁W 2(T ) − T )︁ , n → ∞, 2
поэтому окончательно заключаем, что

ˆT W (t) dW (t) = 1 (︁W 2(T ) − T )︁ . △ 2
0

Обратим внимание на то, что если бы в формуле (10) значение подынтегральной функции вычислялось не в крайней левой точке отрезка [tk, tk+1], а в какой-либо другой, то значение интеграла изменилось бы. Если выбрать произвольное θ ∈ [0, 1] и в качестве промежуточной точки взять τkθ = (1 − θ)tk + θtk+1 и рассмотреть интегральную сумму
n
I(Xn) = ∑︂ X(τkθ)(W (tk+1) − W (tk)),
k=1
то при тех же условиях, что и ранее, справедливо утверждение:

I(Xn) −с−.к→. Iθ, n → ∞,

где предельная величина Iθ в общем случае зависит от параметра θ и называется стохастическим θ-интегралом. При θ = 0 мы получаем случай, рассмотренный выше. Такой интеграл называется еще стохастическим интегралом Ито. Если θ = 1/2, то интеграл называется стохастическим интегралом Стратоновича. Можно показать, что в случае Стратоновича интеграл из примера выше будет равен

I1/2(W ) = 1 W 2(T ). 2
Кстати говоря, в этом же случае справедлива привычная формула интегрирования по частям:

ˆT

⃓T

I1/2(W ) = W (t) dW (t) = 1 W 2(t)⃓⃓ = 1 W 2(T ).

2

⃓0 2

0

В общем случае вычислять стохастические интегралы помогает формула Ито.

67

Определение 2.8. Пусть даны два неупреждающих случайных процесса {f (t), t ∈ [a, b]} и {g(t), t ∈ [a, b]} такие, что

⎛ ˆb

⎞

⎛ ˆb

⎞

P ⎝ω : |f (ω, t)| dt < ∞⎠ = 1, P ⎝ω : |g(ω, t)|2 dt < ∞⎠ = 1.

a

a

Случайный процесс {X(t), t ∈ [a, b]} называется процессом Ито, если

ˆt

ˆt

X(t) = X(0) + f (ω, s) ds + g(ω, s) dW (s),

(11)

a

a

где первый интеграл понимается в «потраекторном» смысле, а второй – в смысле стохастического интеграла Ито.
Обычно вместо (11) используется запись в «дифференциалах»

dX(t) = f (ω, t)dt + g(ω, t)dW (t),

(12)

говоря при этом, что процесс X(t) имеет стохастический дифференциал. Запись (12) следует всегда понимать как сокращенную запись формулы (11).
Теперь приведем один из основных результатов стохастического анализа.
Теорема 2.10 (формула Ито [9]). Пусть неслучайная функция
F (t, x) непрерывно дифференцируема по t ≥ 0 и дважды непрерывно
дифференцируема по x ∈ R. Пусть процесс {X(t), t ≥ 0} имеет стохастический дифференциал (12). Тогда процесс {F (t, X(t)), t ≥ 0} также имеет стохастический дифференциал:

dF (t, X(t)) = [︃ ∂F + f (ω, t) ∂F + 1 g2(ω, t) ∂2F ]︃ dt + ∂F g(ω, t) dW (t).

∂t

∂x 2

∂x2

∂x

(13)

Эту формулу иногда записывают в более удобном для запоминания

виде:

dF = ∂F dt + ∂F dX(t) + 1 ∂2F (dX(t))2,

∂t

∂x

2 ∂x2

если всюду принять dt dt = 0, dW (t) dt = 0 и (dW (t))2 = dt. тегрЭатлаИтетоор´емT аWп(оtз)вdоWля(еtт).оПчоенсьутпир,омстыо ивщыечмисплриотцьесстсоXха(сt)т,идчиефскфиейриенн--
0
циал которого равен W (t) dW (t):

dX = W (t) dW (t).

68

Задача поиска X(t) сводится к задаче поиска подходящей функции F (t, x). Возьмем F (t, x) = x2 и вычислим
dF (t, W (t)) = 0 + 2W (t) dW (t) + (dW (t))2 = 2W (t) dW (t) + dt.

Как мы уже говорили выше, эта запись является сокращенной формой

записи

ˆt

ˆt

W 2(t) = W 2(0) + 2 W (s) dW (s) + ds,

0

0

откуда сразу получаем значение интересующего интеграла.

2.8. Стохастические дифференциальные уравнения*

Приведем, следуя [46], определение стохастического дифференциального уравнения и простой пример такого уравнения.
Определение 2.9. Стохастическое дифференциальное уравнение

Ито

dX(t) = f (t, X(t)) dt + g(t, X(t)) dW (t)

(14)

с коэффициентами f и g и начальным условием X0 – это задача поиска случайной функции X(t) с дифференциалом (14) и X(0) = X0. Решение с п.н.-непрерывными траекториями называется сильным решением такого уравнения.
Если функции f (t, x) и g(t, x) достаточно «хорошие», а именно если они по переменной x удовлетворяют локальному условию Липшица:

∀n ∈ N ∀x, y ∈ [−n, n] ∃C(n) |f (t, x) − f (t, y)| ≤ C(n)|x − y|,

∀n ∈ N ∀x, y ∈ [−n, n] ∃C(n) |g(t, x) − g(t, y)| ≤ C(n)|x − y|, а также условию линейного роста:

∃C > 0 ∀t ≥ 0 ∀x ∈ R |f (t, x)| ≤ C|x|, |g(t, x)| ≤ C|x|,

то сильное решение уравнения (14) существует и единственно для любой случайной величины X0, измеримой относительно W (0).
Приведем пример одного стохастического дифференциального уравнения:
dS(t) = aS(t)dt + σS(t) dW (t).
Решение S(t) этого уравнения называется процессом Башелье–Самуэльсона. Этот процесс является одной из первых моделей стоимости акций в финансовой математике. С помощью формулы Ито можно проверить, что
S(t) = S0eateσW (t)−σ2t/2.

69

3. Гауссовские случайные процессы

3.1. Моментные характеристики
В разделе 1 нами было введено важно понятие – гауссовский процесс. Гауссовский процесс – это процесс, все конечномерные распределения которого нормальные (гауссовские). Это значит, что любой случайный вектор, составленный из сечений такого процесса, имеет нормальное распределение. Такие случайные векторы обладают целом рядом полезных для практических расчетов свойств. Цель данного раздела – привести эти свойства и продемонстрировать их использование в задачах.
Напомним, что случайный вектор X ∈ Rn является гауссовским с математическим ожиданием m и корреляционной матрицей R ∈ Rn×n (обозначается X ∈ N(m, R)), если его характеристическая функция задается формулой

φX (s) d=ef Eei⟨s,X⟩

(︃ = exp i⟨s, m⟩ −

1

)︃

⟨s, Rs⟩ ,

s ∈ Rn.

2

Если det R ̸= 0, то X обладает плотностью распределения

pX (u) =

1

exp

(︃ −

1

⟨

u,

R

−

1

u

)︃ ⟩

,

u ∈ Rn.

√︁(2π)n det R

2

Если же det R = 0, то плотность распределения в Rn не существу-
ет. В этом случае найдется вектор c такой, что Rc = 0. Но так как R = E(XX⊤), то из цепочки равенств

0 = c⊤Rc = c⊤E(XX⊤)c = E(c⊤XX⊤c) = E(c⊤X)2 = E⟨c, X⟩2

вытекает равенство ⟨X, c⟩ = 0 почти всюду, то есть некоторые компоненты вектора X являются линейными комбинациями других. В этом случае вероятностная мера сосредоточена в пространстве меньшей размерности.
Класс нормальных случайных векторов X замкнут относительно линейных преобразований. А именно, если X ∈ N(m, R) – нормальный случайный вектор с n компонентами, то для любой (даже прямоугольной или невырожденной) матрицы A ∈ Rm×n и любого вектора b ∈ Rm случайный вектор (или случайная величина для m = 1) Y = AX + b ∈ N(Am + b, ARA⊤). Этот факт легко доказать с помощью

70

аппарата характеристических функций. Действительно,

φY (s) = Eei⟨s,Y ⟩ = Eei⟨s,AX+b⟩ = ei⟨s,b⟩Eei⟨A⊤s,X⟩ = ei⟨s,b⟩φX (A⊤s) =

=

exp

(︃ i⟨s,

b⟩

+

i⟨A⊤s,

m⟩

−

1 ⟨A⊤s,

)︃ RA⊤s⟩

=

2

=

(︃ exp i⟨s, (Am + b)⟩ −

1

⟨s,

AR

A

⊤

)︃ s⟩

,

s ∈ Rm.

2

Для нормальных случайных векторов известны явные выражения для моментов вида E(X1α1 . . . Xnαn ), где X = (X1, . . . , Xn)⊤. А именно, справедлива следующая теорема.
Теорема 3.1 (Вика). Пусть дан нормальный случайный вектор
X = (X1, . . . , Xn) ∈ N(0, R) с нулевыми средними и произвольной корреляционной матрицей R = ∥Rij∥ni,j=1. Тогда если n нечетно, то

E(X1 . . . Xn) = 0.

Если же n четно, то

∑︂ E(X1X2 . . . Xn) = Ri1j1 . . . R , in/2jn/2

⏞

⏟⏟

⏞

n/2 множителей

где сумма берется по всем неупорядоченным разбиениям множества
{1, . . . , n} на n/2 неупорядоченных пар.
Доказательство. Для доказательства случая с нечетным n заметим, что вектор Y = −X имеет то же распределение, что и вектор X, а значит и тот же момент E(Y1 . . . Yn) = E(X1 . . . Xn). Но с другой стороны E(Y1 . . . Yn) = (−1)nE(X1 . . . Xn). Для нечетного n отсюда следует, что E(X1 . . . Xn) = 0.
Для доказательства второго случая воспользуемся связью между смешанными моментами и производящей функцией моментов:

E(X1 . . . Xn) = ∂n Ee⟨s⊤X⟩⃓⃓⃓ = ∂n exp (︃ 1 s⊤Rs)︃⃓⃓⃓ ,

∂s1 . . . ∂sn

⃓s=0 ∂s1 . . . ∂sn

2

⃓s=0

где s = (s1, . . . , sn). Для расчета смешанной производной в правой части выражения выше выполним разложение функции exp (︁ 12 s⊤Rs)︁ по степеням компонент s и выделим только слагаемые со степенью
s1 . . . sn, так как остальные слагаемые после взятия производной в точке s = 0 обращаются в нуль. Для этого будем в разложении от-
брасывать члены, содержащие si, i = 1, . . . , n, во второй степени и

71

выше. Сначала заметим, что

⎛

⎞

exp (︃ 12 s⊤Rs)︃ = exp ⎝∑︂ Rijsisj + A(s)⎠ ,
i<j

где A(s) содержит не нужные нам слагаемые. Далее,

⎛

⎞

∑︂

∏︂

∏︂

exp ⎝ Rijsisj⎠ = exp(Rijsisj) = (1 + Rijsisj + Bij(s)),

i<j

i<j

i<j

где функции Bij(s) содержат не нужные нам слагаемые. В итоге получается, что

∂n exp (︃ 1 s⊤Rs)︃⃓⃓⃓ = ∂n ∏︂(1 + Rijsisj)⃓⃓⃓ .

∂s1 . . . ∂sn

2

⃓s=0 ∂s1 . . . ∂sn i<j

⃓s=0

Для расчета полученной смешанной производной нужно распределить n частных производных, по множителям, а точнее – распределить n/2 пар (si, sj), взятых из множества {s1, . . . , sn} по множителям. Получается, что

∂n ∏︂

⃓

⃓

∑︂

(1 + Rijsisj)⃓ =

∂s1 . . . ∂sn i<j

⃓s=0

Ri1j1 . . . Rin/2jn/2 ,

⏞

⏟⏟

⏞

n/2 множителей

где сумма берется по всем неупорядоченным разбиениям

{1, . . . , n} = {i1, j1} ∪ · · · ∪ {in/2, jn/2}
множества {1, . . . , n} на n/2 неупорядоченных пар. □ Замечание. Упомянутая теорема позволяет вычислять произволь-
ные моменты вида E(X1α1 . . . Xnαn ). Для этого можно просто рассмотреть нормальный вектор Y с N = α1 +. . .+αn компонентами, воспользоваться формулой для расчета момента E(Y1 . . . YN ) и затем заменить все Yi, i = 1, . . . , α1 на X1, все Yi, i = 1 + α1, . . . , α1 + α2 на X2 и т.д. Поясним сказанное на примерах.
Пример 3.1. Пусть имеется нормальный вектор (X1, X2, X3, X4) с нулевым средним и корреляционной матрицей R = ∥Rij∥4i,j=1. Тогда

E(X1X2X3X4) = R12R34 + R13R24 + R14R23.

Каждое слагаемое содержит n/2 = 4/2 = 2 сомножителя. Количество слагаемых определяется количеством разбиения множества {1, 2, 3, 4}

72

на n/2 = 2 пары. Множество {1, 2, 3, 4} на 2 пары можно разбить тремя способами: {1, 2} ∪ {3, 4}, {1, 3} ∪ {2, 4}, {1, 4} ∪ {2, 3}.
Так как любой подвектор нормального вектора является нормальным, то и (X1, X2, X3) является нормальным случайным вектором. Для него справедливо равенство

E(X1X2X3) = 0,

так как множителей – нечетное количество. △ А теперь рассмотрим задачу про предел в среднем квадратичном
сумм квадратов приращений винеровского процесса. Оказывается, что этот предел равен длине отрезка времени. Если бы мы вычисляли такой предел для гладкой функции, то он равнялся бы нулю. Отсюда на качественном уровне можно сделать вывод, что траектории ви-
неровского процесса почти нигде не дифференцируемы, хотя почти наверное всюду непрерывны. Подробнее см. [10, 11].
Пример 3.2. Пусть {W (t), t ≥ 0} – винеровский процесс, [a, b] ⊂ ⊂ T = [0, ∞) и a = t0 < t1 < . . . , < tN = b. Покажем теперь, что в смысле с.к.-сходимости существует предел

N
l.i.m. ∑︂ |W (ω, tk) − W (ω, tk−1)|2 = b − a.
max(tk−tk−1)→0 k=1
Согласно определению винеровского процесса, случайные величины W (ω, tk) − W (ω, tk−1), k = 1, N , являются независимыми, имеют нулевые математические ожидания и дисперсии
D(W (ω, tk) − W (ω, tk−1)) = E|W (ω, tk) − W (ω, tk−1)|2 = tk − tk−1.

А так как

N

N

E ∑︂ |W (ω, tk) − W (ω, tk−1)|2 = ∑︂ E|W (ω, tk) − W (ω, tk−1)|2 =

k=1

k=1

N
∑︂ = (tk − tk−1) = b − a,
k=1
73

то очевидно, что

(︄ N

)︄

lim

E ∑︂ |W (ω, tk) − W (ω, tk−1)|2 − (b − a)2 =

max(tk −tk−1 )→0

k=1

N

=

lim

D ∑︂ |W (ω, tk) − W (ω, tk−1)|2 =

max(tk−tk−1)→0 k=1

N

=

lim

∑︂ D|W (ω, tk) − W (ω, tk−1)|2.

max(tk−tk−1)→0 k=1

Кроме того, случайная величина

W (ω, tk) − W (ω, tk−1)

ηk(ω) =

√

tk − tk−1

распределена по нормальному закону с нулевым математическим ожиданием и единичной дисперсией, а случайная величина ηk2(ω) распределена по закону χ21. Поэтому Dηk2(ω) ≡ 2 и

D|W (ω, tk) − W (ω, tk−1)|2 ≡ 2(tk − tk−1)2.

Таким образом,

(︄ N

)︄

lim

E ∑︂ |W (ω, tk) − W (ω, tk−1)|2 − (b − a)2 =

max(tk −tk−1 )→0

k=1

N

=2

lim

∑︂ (tk

−

tk−1)2

≤

max(tk−tk−1)→0 k=1

N

∑︂

≤2

lim

max(tk − tk−1) (tk − tk−1) =

max(tk−tk−1)→0 k

k=1

= 2(b − a)

lim

max(tk − tk−1) = 0,

max(tk−tk−1)→0 k

что и требовалось доказать. △

3.2. Условные распределения сечений

Пусть дан нормальный случайный вектор X с n компонентами. Пусть X = (Y, Z), где Y и Z – два подвектора вектора X с n1 и n2 компонентами, соответственно; n = n1 + n2. Корреляционную матрицу вектора X можно представить в виде

R = [︃ R11 R21

R12 ]︃ , R22

74

где R12 – корреляционная матрица вектора Y , R22 – корреляционная матрица вектора Z, а матрицы R12 и R21 = R1⊤2 состоят из корреляций компонент вектора Y и Z (взаимные корреляционные матрицы). Вектор математического ожидания EX = m также разбивается на два подвектора EY = m1 и EZ = m2.
Найдем условное распределение подвектора Y при фиксированном подвекторе Z. Будем предполагать, что матрица R22 невырождена (если это не так, то некоторые компоненты Z являются линейными комбинациями других, а значит, их можно исключить, понизив размерность Z).
Введем случайную величину
Yˆ = m1 + R12R2−21(Z − m2).
Заметим, что для любых матриц A, B, C верны равенства

tr(AB) = tr(BA), tr(ABC) = tr(BCA) = tr(CAB).

Отсюда можно получить, что

E(Y − Yˆ )⊤ (Z − m2) = 0.

(15)

Действительно,

E(Y − Yˆ )⊤ (Z − m2) =

=

E (︁Y

− m1

− R12R2−21(Z

)︁⊤ − m2) (Z

− m2)

=

= tr (R12) − tr (︁R12R2−21R22)︁ = 0.
Условие (15) означает, что компоненты вектора Y − Yˆ и компоненты вектора Z некоррелированны, а значит, и независимы (в силу гауссовости эти понятия совпадают).
Таким образом, вектор Y раскладывается в сумму нормальных векторов Y = (Y − Yˆ ) + Yˆ = (Y − Yˆ ) + m1 + R12R2−21(Z − m2), где первое слагаемое Y − Yˆ не зависит от Z, а Yˆ при фиксированном Z является константой. Значит, условное распределение Y при фиксированном Z определяется нормальным законом с условным математическим ожиданием

(︂

)︂

E(Y | Z) = E Y − Yˆ + m1 + R12R2−21(Z − m2) =

= m1 + R12R2−21(Z − m2)

(16)

75

и условной корреляционной матрицей

(︂ E (Y

− E(Y

| Z)) (Y

− E(Y

| Z))⊤

)︂ ⃓ ⃓Z

=

E(Y

− Yˆ )(Y

− Yˆ )⊤

=

= E (Y − m1) (Y − m1)⊤ − R12R2−21E (Z − m2) (Y − E (Y − m1) (Z − m2)⊤ R2−21R21+ + R12R2−21E (Z − m2) (Z − m2)⊤ R2−21R21 = = R11 − R12R2−21R21.

− m1)⊤ −

(17)

Отметим, что условная корреляционная матрица не зависит от Z, а условное математическое ожидание является линейной функцией от Z.
Приведем и докажем теперь важную и полезную теорему о том, что условное математическое ожидание является на самом деле проекцией на подпространство функций от случайных величин, стоящих в условии условного математического ожидания. Эта теорема, с одной стороны, предоставляет геометрическую интуицию этого понятия, а с другой стороны, помогает решать задачи. Ради простоты мы докажем эту теорему для случая, когда условное математическое ожидание вычисляется от случайной величины, хотя аналогичные выкладки можно провести и для случайного вектора.
Теорема 3.2. Пусть случайная величина X имеет ограниченный
второй момент, т.е. X ∈ L2. Пусть также Y1, . . . , Yn ∈ L2. Доказать, что

∥X − E (X | Y1, . . . , Yn) ∥2 = min ∥X − φ(Y1, . . . , Yn)∥2,
φ∈H

где H — подпространство пространства L2 всевозможных борелевских функций φ(Y1, . . . , Yn) ∈ L2, E (X | Y1, . . . , Yn) — условное математическое ожидание случайной величины X относительно σ-алгебры, порожденной случайными величинами Y1, . . . , Yn. Напомним, что норма и скалярное произведение определяются следующим образом:
√︁ ∥X∥2 = ⟨X, X⟩, ⟨X, Y ⟩ = E (XY ) .

Доказательство. Заметим, что указанное равенство равносильно следующему утверждению:

∀φ ∈ H ⟨X − E (X | Y1, . . . , Yn) , φ(Y1, . . . , Yn)⟩ = 0,

т.е. разность X −E (X | Y1, . . . , Yn) ортогональна пространству H. Действительно, если это доказать, то мы докажем и исходное равенство, т.к.
E (X | Y1, . . . , Yn) ∈ H

76

по определению условного математического ожидания относительно набора случайных величин (см. в [69, гл. 2, § 7]). Во-первых, если случайная величина Z измерима относительно σ-алгебры, порожденной случайными величинами Y1, . . . , Yn, то
E (XZ | Y1, . . . , Yn) = ZE (X | Y1, . . . , Yn) .
Это свойство является одним из основных свойств условного математического ожидания и доказывается в два этапа: сначала для простых случайных величин, а затем при помощи предельного перехода под знаком условного математического ожидания доказывается для произвольных случайных величин из H (детали см. в [69, гл. 2, §7, свойство K*]). Кроме того, напомним еще одно важнейшее свойство условного математического ожидания (см. [69, гл. 2, § 7, свойства H* и I*]):
EX = E (E (X | Y1, . . . , Yn)) .
Используя эти факты, получаем для произвольной φ ∈ H
E ((X − E (X | Y1, . . . , Yn)) · φ(Y1, . . . , Yn)) = = E (E ((X − E (X | Y1, . . . , Yn)) · φ(Y1, . . . , Yn) | Y1, . . . , Yn)) = = E (φ(Y1, . . . , Yn)E (X − E (X | Y1, . . . , Yn) | Y1, . . . , Yn)) = = E (φ(Y1, . . . , Yn) (E (X | Y1, . . . , Yn) − E (X | Y1, . . . , Yn))) = 0,
а значит, ⟨X − E (X | Y1, . . . , Yn) , φ(Y1, . . . , Yn)⟩ = 0.
В случае, когда вектор (X, Y1, . . . , Yn) является нормальным случайным вектором, можно показать (см. [69, Глава 2, §13]), что условное математическое ожидание E (X | Y1, . . . , Yn) является линейной функцией от Y1, . . . , Yn:
n
∑︂ E (X | Y1, . . . , Yn) = ckYk+b,
k=1
а значит, можно искать проекцию именно в таком виде. Это следует из того, что для гауссовских случайных величин независимость равносильна некоррелированности. Отсюда, в частности следует, что часто прогнозы для гауссовских процессов, оптимальные в смысле квадрата невязки, получаются по явным и простым формулам. Подробности можно найти в заключении данной книги. □
77

Пример 3.3. Для винеровского процесса {W (t), t ≥ 0}, вычислить условные математическое ожидание и дисперсию

E (W (t) | W (s) = x) , D (W (t) | W (s) = x)

для произвольных t ≥ 0, s ≥ 0, x ∈ R. Решение. Так как все конечномерные распределения винеровско-
го процесса являются нормальными, то случайные векторы, составленные из его сечений, являются нормальными случайными векторами. В частности, вектор (W (t), W (s)) является нормальным с нулевым вектором математических ожиданий и корреляционной матрицей

R = [︃ t

min(t, s) ]︃ .

min(t, s)

s

По формуле (16) условное математическое ожидание равно E(ξ | Z = x) = Eξ + R12R2−21(x − Eη),
а условная дисперсия, по формуле (17), равна D(ξ | η = x) = Dξ − R12R2−21R21.
где Rij – это компонента матрицы R с индексами i, j. В нашем случае

1

min(t, s)

E (W (t) | W (s) = x) = EW (t) + min(t, s) · s · (x − EW (s)) =

x. s

В частности, при t > s имеем E (W (t) | W (s) = x) = x. Условная дисперсия равна

D (W (t) | W (s) = x) = t − min(t, s)2 · 1 = st − min(t, s)2 .

s

s

В частности, она равна t − s при t > s. △ Замечание. Совершенно аналогично решается задача о поиске
условной плотности распределения винеровского процесса W (t) при условии, что W (t1) = A и W (t2) = B, t1 < t < t2. В этом случае рассмотрим нормальный случайный вектор (W (t), W (t1), W (t2)). Тогда W (t) при условии W (t1) = A и W (t2) = B будет также иметь некоторое нормальное распределение N(µ, σ2), остается только найти среднее

µ = E (W (t) | W (t1) = A, W (t2) = B)

и дисперсию σ2 = D (W (t) | W (t1) = A, W (t2) = B) .

78

Корреляционная матрица R вектора (W (t), W (t1), W (t2)) имеет размеры 3 × 3. Из формул (16) и (17) следует

E (W (t) | W (t1) = A, W (t2) = B) =

= [︁ R12

[︃ ]︁

R22

R13

R32

R23 ]︃−1 [︃ A ]︃ ,

R33

B

D (W (t) | W (t1) = A, W (t2) = B) =

= R11 − [︁ R12

[︃ ]︁

R22

R13

R32

R23 ]︃−1 [︃ R21 ]︃ .

R33

R31

Остается лишь выразить R в терминах t, t1 и t2:

и получить ответ.

⎡ t t1 t ⎤ R = ⎣ t1 t1 t1 ⎦
t t1 t2

79

4. Стационарные процессы
В этом разделе мы приступаем к изучению одного из важнейших понятий теории случайных процессов – стационарности. Стационарные случайные процессы активным образом используются в инженерных приложениях и в особенности – в теории управления динамическими системами. В данном разделе дается определение стационарного процесса, разбираются базовые примеры стационарных процессов и базовый инструментарий для работы с такими процессами – разложение стационарного процесса и его корреляционной функции на гармоники.

4.1. Комплекснозначные случайные процессы

Теория стационарных случайных процессов помимо вещественнозначных процессов (принимающих реализации в R) опирается на понятие комплекснозначных процессов (принимающих значения в C). Введем аккуратные определения и распространим некоторые ранее введенные понятия на случай комплекснозначных процессов.
Определение 4.1. Комплекснозначным процессом {Z(t), t ∈ T }, определенном на вероятностном пространстве (Ω, F, P), называется функция Z(ω, t) = X(ω, t) + iY (ω, t), где i2 = −1, ω ∈ Ω, а X(t) и Y (t) – два вещественнозначных процесса, определенных при t ∈ T и принадлежащих тому же вероятностному пространству (Ω, F, P).
Определим математическое ожидание такого процесса Z(t) по формуле EZ(t) = EX(t) + iEY (t), где X(t) = Re Z(t) – вещественная часть процесса Z(t), а Y (t) = Im Z(t) – мнимая часть процесса Z(t). Дисперсией комплекснозначного процесса Z(t) будем называть

◦

◦

DZ(t) = EZ(t)Z(t),

а корреляционной функцией

◦

◦

RZ (t, s) = EZ(t)Z(s),

где черта означает комплексное сопряжение. Математическое ожидание и корреляционная функция комплекс-
нозначного процесса могут принимать комплексные значения. Дисперсия, как и прежде, может принимать только вещественные значения.
Определение 4.2. Комплекснозначным процессом {Z(t), t ∈ T } второго порядка будем называть комплекснозначный случайный процесс со всюду конечным вторым моментом E|Z(t)|2 < ∞, t ∈ T .

80

Множество комплекснозначных случайных процессов второго порядка будем обозначать символом CL2, т.е. будем писать X(t) ∈ CL2. Скалярное произведение на CL2 задается как ⟨X, Y ⟩ = EXY .
Кроме того, введем полезное для дальнейшего понятие комплекснозначного гауссовского процесса.
Определение 4.3. {Z(t), t ∈ T } – комплекснозначный гауссовский процесс, если для любого n ∈ N и любых t1, . . . , tn ∈ T вектор
(X(t1), Y (t1), . . . , X(tn), Y (tn)) ,
где X(t) = Re Z(t), Y (t) = Im Z(t), имеет нормальное распределение. Вещественнозначные процессы мы будем считать частным случаем
комплекснозначных процессов (с нулевой мнимой частью). При этом, если речь идет о комплекснозначном процессе, то его мнимая часть может быть как ненулевой, так и нулевой. Если же рассматривается вещественнозначный процесс, то считается, что мнимая часть нулевая.
4.2. Стационарность в широком и узком смыслах
Определение 4.4. Процесс X(t) ∈ CL2 называется стационарным в узком смысле (еще говорят, сильно стационарным), если ∀n ∈ N, для любых моментов времени t1, . . . , tn и любого h > 0 распределение вектора (X(t1), . . . , X(tn)) совпадает с распределением вектора (X(t1 + h), . . . , X(tn + h)).
Иными словами, процесс стационарен в узком смысле, если все его конечномерные распределения не зависят от сдвига моментов времени на одну и ту же величину. Отсюда следует, в частности для n = 1, что распределение X(t) совпадает с распределением X(t + h) для любого h, т.е. одномерное распределение не зависит от времени. Но это значит, что и никакие численные характеристики одномерного распределения такого процесса не зависят от времени. Например, математическое ожидание и дисперсия стационарного в узком смысле процесса не зависят от времени: mX (t) = const, DX (t) = const.
Что касается двумерного распределения стационарного в узком смысле процесса, то оно зависит лишь от разности t2 − t1. Следовательно, и все численные характеристики двумерного распределения (например, корреляционная и ковариационная функции) тоже зависят лишь от разности между t1 и t2. Это значит, что существует функция R(τ ) одного аргумента, такая, что корреляционная функция стационарного в узком смысле процесса X(t) равна RX (t1, t2) = R(t2 − t1).
Определение 4.5. Процесс X(t) ∈ CL2 называется стационарным в широком смысле (еще говорят, слабо стационарным), если его мате-
81

матическое ожидание не зависит от времени, а корреляционная функция зависит лишь от разности аргументов t1 и t2.
Из того, что у стационарных в широком смысле процессов корреляционная функция является функцией лишь разности аргументов, следует, что дисперсия не зависит от времени. Таким образом, дисперсия постоянна как для стационарного в узком смысле процесса (если это процесс второго порядка), так и для стационарного в широком смысле процесса.
Как видно из определений, для процессов второго порядка из стационарности в узком смысле следует стационарность в широком смысле. Вне класса процессов второго порядка это следствие уже не верно, так как определение стационарности в широком смысле предполагает существование вторых моментов сечений процесса. Например, можно рассмотреть процесс X(t), для любого t ≥ 0, равного
X(t) = ξ ∈ C(0, 1),
где C(0, 1) – стандартное распределение Коши с плотностью
1 f (x) = π(1 + x2) .
Такой процесс не зависит от времени, следовательно, является стационарным в узком смысле процессом. Однако, хорошо известно, что распределение Коши не имеет даже первый момент, поэтому X(t) пространству процессов второго порядка не принадлежит, и понятие стационарности в широком смысле к нему неприменимо.
Итак, простейшим примером стационарного в узком смысле процесса является не зависящий от времени процесс X(t) = ξ, где ξ – какая-нибудь случайная величина. Если ξ обладает конечным вторым моментом E|ξ|2 < ∞, то процесс X(t) будет стационарным и в широком смысле, потому что является стационарным в узком смысле. Математическое ожидание этого процесса EX(t) = Eξ не зависит от времени, а корреляционная функция RX (t, s) = Eξ2 − (Eξ)2 вообще не зависит ни от t, ни от s, поэтому и подавно RX (t, s) = RX (t + h, s + h) для любого h. В частности, если ξ = C = const, т.е. это вырожденная случайная величина, принимающая одно значение независимо от исхода, то EX(t) = C и RX (t, s) = 0.
А теперь возьмем какую-нибудь случайную величину ξ c конечным вторым моментом E|ξ|2 < ∞ и рассмотрим случайный процесс
X(t) = ξf (t)
82

с какой-нибудь (быть может комплекснозначной) неслучайной и непостоянной функцией f (t). Попробуем выяснить, в каких случаях этот процесс будет стационарным в широком смысле. Математическое ожидание EX(t) = f (t)Eξ не будет зависеть от времени тогда и только тогда, когда Eξ = 0, в этом случае EX(t) = 0. Корреляционная функция этого процесса равна
RX (t, s) = EX(t)X(s) − EX(t)EX(s) = f (t)f (s) · E|ξ|2.

Выясним, в каких случаях RX (t, s) = RX (t + h, s + h) для любых t, s и h. Пусть сначала t = s, тогда RX (t, t) = RX (t + h, t + h) приводит к |f (t)|2 = const, откуда сразу следует f (t) = r exp (iφ(t)) для произвольных ненулевых r, φ(t) ∈ R. Предположим дополнительно, что f (t) – всюду непрерывная функция. Функция RX (t + h, s + h) не будет зависеть от h тогда и только тогда, когда φ(t + h) − φ(s + h) не будет зависеть от h, т.е. тогда и только тогда, когда

φ(t + h) − φ(s + h) = φ(t) − φ(s).

Без потери общности будем считать, что s = 0, и перепишем это выражение в виде
φ(t + h) = φ(t) + φ(h) − φ(0).
Теперь если ввести обозначение g(t) = φ(t) − φ(0), то мы имеем непрерывную функцию g(t), во всех точках удовлетворяющую уравнению Гамеля [62]
g(t + h) = g(t) + g(h), ∀t, h ∈ R.
Можно доказать, что решением этого уравнения являются функции вида g(t) = ωt, где ω ∈ R – произвольная постоянная, не зависящая от t. Обозначив θ = −φ(0), мы приходим к выражению для φ(t):

φ(t) = ωt + θ, где ω, θ ∈ R.

Итак, мы выяснили, что процесс вида X(t) = ξf (t) будет стационарным в широком смысле тогда и только тогда, когда

X(t) = ξ · rei(ωt+θ).

(18)

Случайная величина ξ в (18) может быть и комплекснозначная. Теперь если объединить этот случай с независящими от времени процессами, а число r включить в состав случайной величины ξ, то мы получаем следующее утверждение.

83

Теорема 4.1. Случайный процесс вида X(t) = ξf (t) для E|ξ|2 < ∞
и непрерывной неслучайной функции f (t) будет стационарным в ши-
роком смысле тогда и только тогда, когда X(t) = ξ exp (i(ωt + θ)) для неслучайных ω, θ ∈ R.
Теперь рассмотрим процесс вида X(t) = ξ1eiω1t + ξ2eiω2t с Eξ1 = 0 и Eξ2 = 0 и ненулевыми частотами ω1 ̸= ω2 и выясним, при каких условиях этот процесс будет стационарным в широком смысле. Математическое ожидание EX(t) = 0 не зависит от времени. Корреляционная функция

RX (t, s) = E|ξ1|2eiω1τ + E(ξ1ξ2)ei(ω1−ω2)t+iω1τ + + E(ξ2ξ1)e−i(ω1−ω2)t+iω2τ + E|ξ2|2eiω2τ ,

где τ = t − s, является функцией лишь τ тогда и только тогда, когда E(ξ1ξ2) = E(ξ2ξ1) = 0, что следует из линейной независимости функцией перед этими коэффициентами. Получается, что процесс X(t) = = ξ1eiω1t + ξ2eiω2t является стационарным в широком смысле тогда и только тогда, когда случайные величины ξ1 и ξ2 некоррелированы. Корреляционная функция в этом случае равна

RX (t, s) = E|ξ1|2eiω1(t−s) + E|ξ2|2eiω2(t−s).

Рассуждая совершенно аналогичным образом, нетрудно доказать следующую теорему.
Теорема 4.2. Случайный процесс

n

X(t) = ∑︂ ξkeiωkt, ωk ̸= ωm, Eξk = 0,

(19)

k=1

является стационарным в широком смысле тогда и только тогда, когда случайные величины ξk попарно некоррелированы. В этом случае корреляционная функция равна

n
RX (t, s) = R(τ ) = ∑︂ E|ξk|2eiωkτ , τ = t − s.
k=1

Читателю следует здесь обратить внимание на то, что для стационарности в широком смысле необходима и достаточна некоррелированность комплексных гармоник (экспонент). Кроме того, в то время как процесс представляется в виде суммы некоррелированных гармоник с некоторыми случайными коэффициентами, корреляционная функция также представляет собой сумму гармоник с амплитудами, равными

84

вторым моментам этих коэффициентов. Например, случайный процесс X(t) = ξ cos t не является стационарным в широком смысле не просто потому, что его корреляционная функция
RX (t, s) = E|ξ|2 cos t cos s

не обладает свойством RX (t, s) = RX (t + h, s + h) для любого h, но и потому что расписав X(t) = 1/2ξeit + 1/2ξe−it, мы видим, что коэффициенты при экспонентах не являются некоррелированными (они равны). Эти замечания будут важны для нас потом, когда мы установим представление стационарных процессов в суммы из гармоник.
Ошибочно думать, впрочем, что некоррелированность гармоник достаточна для стационарности процесса в узком смысле. Действительно, пусть дан процесс Z(t) = X cos t + Y sin t, где случайные величины X и Y независимы и принимают значения ±1 с вероятностью 1/2. Легко получить, что EX(t) = 0 = const, а корреляционная функция

RZ (t, s) = EZ(t)Z(s) − EZ(t)EZ(s) =
⏞ ⏟⏟ ⏞
0

= E(X cos t + Y sin t)(X cos s + Y sin s)

= EX2 cos t cos s + EY 2 sin t sin s =

⏞ ⏟⏟ ⏞

⏞⏟⏟⏞

1

1

+ EXY (cos t sin s + sin t cos s) = ⏞ ⏟⏟ ⏞
EXEY =0
= cos t cos s + sin t sin s =

= cos (t − s)

зависит только от разницы t − s. Это говорит о стационарности про-

цесса в широком смысле. но если бы процесс был стационарен в узком

смысле, то его одномерное распределение не зависело бы от t. Одна-

ко для t = 0 сечение Z(0) = X принимает значения ±1, а при t = π/4

сечение

√ Z(π/4) = (X + Y )/ 2

√ принимает значения ± 2 и 0. Значит, уже одномерное распределение

меняется при сдвиге времени, поэтому процесс не является стационар-

ным в узком смысле.

Выше были рассмотрены процессы-гармоники с неслучайными ча-

стотами и фазами. Разберем пример со случайной частой и фазой.

Пример 4.1. Дан случайный процесс Z(t) = A cos (Bt + ϕ), t ≥ 0,

в котором A, B и ϕ являются случайными величинами, причем ϕ не

85

зависит от A и B и распределено равномерно на отрезке [0, 2π]. Про A и B известно, что они имеют совместную плотность распределения f (a, b) и A ≥ 0, B ≥ 0 п.н. Исследовать процесс Z(t) на стационарность в обоих смыслах.
Решение. Сначала исследуем процесс на стационарность в широком смысле. Для этого вычислим математическое ожидание

EZ(t) = EA cos (Bt + ϕ) = EA cos Bt cos ϕ − EA sin Bt sin ϕ.

Так как ϕ не зависит от A и B, то EA cos Bt cos ϕ = EA cos Bt·E cos ϕ = 0 (в предположении, что E|A| < ∞), что следует из того, что

ˆ2π 1
E cos ϕ = 2π cos x dx = 0.
0
Аналогично получаем, что EA sin Bt sin ϕ = EA sin Bt · E sin ϕ = 0. Следовательно, EZ(t) = 0 для любых t ≥ 0, т.е. от времени не зависит. Вычислим теперь корреляционную функцию (в предположении, что EA2 < ∞)

RZ (t, s) = EZ(t)Z(s) − EZ(t)EZ(s) =

⏞ ⏟⏟ ⏞
0

= EA2 cos (Bt + ϕ) cos (Bs + ϕ) =

=

EA2

·

1

(︃ cos

(︃ B(t

+

s)

+

)︃ ϕ

+

cos

B(t

−

s) )︃

=

2

2

2

=

EA2

·

1

cos

B(t

−

s)

+

EA2

·

1

cos

(︃ B(t

+

s)

+

)︃ ϕ

.

2

2

2

2

⏞

⏟⏟

⏞

⏞

⏟⏟

⏞

функция t−s

0

Получается, что корреляционная функция RZ(t, s) зависит от t и s только через их разность. Принимая во внимание постоянность математического ожидания, заключаем, что процесс Z(t) является стационарным в широком смысле (в предположении, что EA2 < ∞). При этом, как будет показано далее, без каких-либо дополнительных предположений процесс будет стационарен в узком смысле.
Теперь исследуем процесс на стационарность в узком смысле. Возьмем произвольные n ≥ 1 сечений процесса Z(t) в моменты времени t1, . . . , tn ≥ 0 и произвольный сдвиг по времени h > 0. Пусть

F (x1, . . . , xn; t1, . . . , tn)

86

есть функция распределения вектора (Z(t1), . . . , Z(tn)), тогда стационарность в узком смысле означает, что

F (x1, . . . , xn; t1, . . . , tn) = F (x1, . . . , xn; t1 + h, . . . , tn + h) или, в терминах вероятности,

P(Z(t1) < x1, . . . , Z(tn) < xn) = P(Z(t1 + h) < x1, . . . , Z(tn + h) < xn). Подставим выражение для Z(t) и получим

P(A cos (Bt1 + ϕ) < x1, . . . , A cos (Btn + ϕ) < xn) = (20) = P(A cos (Bt1 + Bh + ϕ) < x1, . . . , A cos (Btn + Bh + ϕ) < xn). Обусловим полученные выражения по A и B

P(a cos (bt1 + ϕ) < x1, . . . , a cos (btn + ϕ) < xn)f (a, b) da db =
R2

= P(a cos (bt1 + bh + ϕ) < x1, . . . , a cos (btn + bh + ϕ) < xn)f (a, b) da db,
R2
(21)

где интегралы берутся во всем a > 0 и b > 0. Чтобы интегралы были равны, достаточно, чтобы подынтегральные функции были равны при любых a > 0, b > 0:

P(a cos (bt1 + ϕ) < x1, . . . , a cos (btn + ϕ) < xn) = (22) = P(a cos (bt1 + bh + ϕ) < x1, . . . , a cos (btn + bh + ϕ) < xn).

В этом выражении a и b – неслучайные величины, случайной же ве-

личиной является лишь ϕ ∈ U (0, 2π). Теперь заметим, что левая часть

равна

ˆ λ(I) fϕ(y) dy = 2π ,

I

где fϕ(y) – плотность вероятности ϕ, множество

I = {y ∈ [0, 2π] : a cos (bt1 + y) < x1, . . . , a cos (btn + y) < xn},

а λ(·) – мера Лебега4. Аналогично, правую часть равенства (22) можно

выразить через интеграл

ˆ

λ(I ′ )

fϕ(z) dz = 2π ,

I′

4Про меру Лебега здесь достаточно знать, что λ([p, q]) = q − p для любого интервала [p, q] и что мера конечного или счетного объединения непересекающихся интервалов равна сумме мер этих интервалов.

87

где множество
I′ = {z ∈ [0, 2π] : a cos (bt1 + bh + z) < x1, . . . , a cos (btn + bh + z) < xn}.
Теперь заметим, что множества I и I′ представляют собой объединение конечного числа непересекающихся интервалов на [0, 2π]. Далее, если z ∈ I′, то
(z + bh mod 2π) ∈ I.
Это преобразование сдвига сохраняет длины интервалов. Следовательно, меры Лебега множеств I и I′ совпадают, т.е. λ(I) = λ(I′). Это равносильно выполнению равенства (22), откуда следует равенство интегральных выражений и равенство функций распределения, что означает стационарность процесса в узком смысле. △
Приведенные примеры показывают, что понятие стационарности в узком смысле сложнее понятия стационарности в широком смысле. В то время как понятие стационарности в широком смысле опирается лишь на две численные характеристики случайных процессов (математическое ожидание и корреляционная функция), которые в общем случае не определяют процесс однозначно, стационарность в узком смысле опирается на все конечномерное распределение процесса. Впрочем, в тех случаях, когда математическое ожидание и корреляционная функция однозначно определяют случайный процесс, может оказаться, что стационарность в широком смысле влечет стационарность в узком смысле. Таким свойством обладают, в частности, гауссовские процессы.
Теорема 4.3. Гауссовский процесс является стационарным в широком смысле тогда и только тогда, когда он является стационарным в узком смысле.
Доказательство. Рассмотрим произвольный стационарный в широком смысле гауссовский процесс {X(t), t ≥ 0}. Составим вектор из сечений процесса X = (X(t1), . . . , X(tn)). Тогда, по определению гауссовского процесса, характеристическая функция этого вектора имеет вид
φX (s) = exp (︃is⊤m − 21 s⊤Rs)︃ ,
где s = (s1, . . . , sn), m = (m1, . . . , mn), mi = EX(ti), R = ∥Rij∥ni,j=1, Rij = EX(ti)X(tj) − EX(ti)EX(tj). Так как процесс стационарный в широком смысле, то при эквидистантном изменении моментов времени вектор m и матрица R не изменятся. Значит, не изменится характеристическая функция φX (s), т.е. не изменится распределение
88

вектора X, который был выбран произвольно. По определению, X(t) – стационарный в узком смысле процесс. □
Пример 4.2. Исследовать на стационарность в широком и узком смыслах процесс X(t) = W (t + a) − W (t), где W (t) – винеровский процесс.
Решение. В первую очередь замечаем, что математическое ожидание процесса EX(t) = 0 для любого t и, следовательно, не зависит от времени. Корреляционная функция
RX (t, s) = E(W (t + a) − W (t))(W (s + a) − W (s)) =
= min(t + a, s + a) − min(t + a, s) − min(t, s + a) + min(t, s).
Хорошо видно, что если добавить к t и s любую величину h, то каждое слагаемое увеличится на h, а значение корреляционной функции не изменится. Поэтому процесс X(t) является стационарным в широком смысле.
Теперь остается заметить, что процесс X(t) является гауссовским. Действительно, составив из его произвольных сечений случайный вектор, мы получим с точностью до линейного преобразования вектор из сечений винеровского процесса, т.е. гауссовский вектор. А так как процесс X(t) гауссовский и стационарный в широком смысле, то он является стационарным и в узком смысле. △
Конечно, существуют процессы, которые не являются стационарными ни в каком смысле. Например, винеровский процесс не является стационарным в широком смысле (и, следовательно, стационарным в узком смысле), так как его дисперсия DW (t) = t зависит от времени. Пуассоновский процесс также не является стационарным ни в каком смысле, так как его математическое ожидание mK(t) = λt зависит от времени.
4.3. Корреляционная функция
В данном разделе мы приведем некоторые простейшие сведения о корреляционных функциях стационарных процессов. Они послужат вспомогательным материалом для понимания основных результатов теории стационарных процессов, изложенных в следующих двух разделах. Кроме того, в этом разделе мы отвечаем на вопрос, в каких случаях произвольная функция является корреляционной функцией некоторой стационарного процесса. Это первый шаг к пониманию природы стационарных процессов.
Для стационарного в широком смысле процесса X(t) удобно ввести
89

функцию RX (t) одной переменной:

◦

◦

RX (t) = RX (t, 0) = EX(t)X(0) − EX(t)EX(0) = EX(t)X(0).

Как и RX (t, 0), будем называть ее корреляционной функцией стационарного в широком смысле процесса. Данная функция обладает рядом легко проверяемых свойств.
а) Во-первых, заметим, что корреляционная функция связана с дисперсией процесса по формуле RX (0) = DX(0) = DX(t) для любого t, так как дисперсия стационарного процесса не зависит от времени. Отсюда следует, в частности, что в нуле значение этой функции вещественное и неотрицательное: RX (0) ≥ 0. Если RX (0) = 0, то тогда DX(t) = 0 для каждого t, что значит X(t) = f (t), где f (t) – произвольная неслучайная функция.
б) Далее, так как в силу стационарности RX (t, s) = RX (t + h, s + h) для любого h ∈ R, то RX (t, s) = RX (0, s − t). Отсюда следует, что

◦

◦

RX (−t) = RX (−t, 0) = RX (0, t) = EX(0)X(t) = RX (t, 0) = RX (t),

т.е. RX (−t) = RX (t) для любого t ∈ R. Функции с таким свойством называются эрмитовыми.
в) В силу неравенства Коши–Буняковского

◦

◦

√︁

|RX (t)| = |EX(t)X(0)| ≤ DX(t)DX(0) = DX(0) = RX (0),

т.е. абсолютное значение функции RX (t) ограничено сверху значением этой функции в нуле: |RX (t)| ≤ RX (0).
г) Пусть дан вектор (X(t1), . . . , X(tn)) из сечений некоторого стационарного процесса X(t). Ковариационная матрица этого вектора состоит из элементов

◦

◦

Rij = EX(ti)X(tj) = RX (ti, tj) = RX (tj − ti),

где i, j пробегают значения от 1 до n. Так как любая ковариационная матрица является неотрицательно определенной в том смысле, что
nn
∑︂ ∑︂ Rij zizj ≥ 0 ∀zi ∈ C,
i=1 j=1

то мы получаем, что и матрица ∥RX (tj − ti)∥ тоже является неотрицательно определенной, причем для любого набора t1, . . . , tn (необязательно упорядоченного и необязательно состоящего из различных элементов). В связи с этим удобно даже ввести определение неотрицательно определенной функции одной или двух переменных.

90

Определение 4.6. Функция f (t) ∈ C одной переменной называется неотрицательно определенной, если для любых комплексных чисел z1, . . . , zn ∈ C и моментов времени t1, . . . , tn, n ≥ 1:
nn
∑︂ ∑︂ ziz¯jf (ti − tj) ≥ 0.
i=1 j=1

Определение 4.7. Функция f (t1, t2) ∈ C двух переменных называется неотрицательно определенной, если для любых комплексных чисел z1, . . . , zn ∈ C и моментов времени t1, . . . , tn, n ≥ 1:
nn
∑︂ ∑︂ ziz¯jf (ti, tj) ≥ 0.
i=1 j=1

Получается, что корреляционная функция RX (t, s) любого процесса (необязательно стационарного) является неотрицательно определенной функцией двух переменных. А корреляционная функция RX (t) стационарного процесса является неотрицательно определенной функцией одной переменной. Кстати говоря, это можно показать и прямо:

nn
∑︂ ∑︂

⃓n

⃓2

⃓∑︂ ⃓

ziz¯jRX (ti − tj) = E ⃓⃓ (X(ti) − mX )zi⃓⃓ ≥ 0, ∀zi ∈ C.

i=1 j=1

⃓ i=1

⃓

Оказывается, верно и обратное (см., например, [10, гл. 2, § 6, теорема 4, с. 53]).
Теорема 4.4. Класс неотрицательно определенных комплексно-
значных функций {R(t, s), s, t ∈ T } совпадает с классом корреляци-
онных функций процессов второго порядка {X(t), t ∈ T } и, более то-
го, совпадает с классом корреляционных функций комплекснозначных гауссовских процессов {X(t), t ∈ T }.
Следствие. Отсюда следует, что класс неотрицательно определенных комплекснозначных функций {R(t), t ∈ T } совпадает с классом корреляционных функций стационарных в широком смысле процессов второго порядка {X(t), t ∈ T } и, более того, совпадает с классом корреляционных функций комплекснозначных стационарных в широком смысле гауссовских процессов {X(t), t ∈ T }.
Другими словами, функция является корреляционной для некоторого процесса тогда и только тогда, когда она является неотрицательно определенной. Неотрицательно определенная функция неоднозначно определяет процесс, для которого она является корреляционной функцией. Но, по крайней мере, всегда можно ей сопоставить подходящий гауссовский процесс.

91

д) Ранее в разделе 2 мы установили, что непрерывность ковариационной функции в точках вида (t, t) влечет ее непрерывность во всех точках множества [0, +∞)2 (или множества R2, если предполагать T = R). Стационарный в широком смысле процесс имеет постоянное (а значит, непрерывное) математическое ожидание. Следовательно, непрерывность корреляционной функции в точках вида (t, t) влечет ее непрерывность в любой точке вида (t1, t2). Это значит, что из непрерывности функции RX (t) в точке t = 0 следует ее непрерывность в любой другой точке t ∈ R.
Пример 4.3. Существует ли стационарный в широком смысле процесс X(t) с корреляционной функцией

RX (t) = {︃ σ2, |t| ≤ t0,

(23)

0, |t| > t0;

с такой корреляционной функцией:

RX (t) = {︃ σ2, |t| ≤ t0, t ̸= 0,

(24)

0, |t| > t0, t = 0;

с такой корреляционной функцией:

⎧ σ2 |t| ≤ t0, ⎨

RX (t) = f (t) t0 < |t| ≤ t0 + ∆,

(25)

⎩ 0 |t| > t0 + ∆,

где f (t) – функция с f (t0) = σ2 и f (t) = 0 для |t| ≥ t0 + ∆? Решение. Функция RX (t) из (23) непрерывна в точке t = 0, но
не является непрерывной в точках t = ±t0. Поэтому стационарного процесса с такой корреляционной функцией не существует.
Функция RX (t) из (24) имеет разрыв в нуле, поэтому, в принципе, может иметь разрывы и в других точках. Впрочем, эта функция все равно не является корреляционной ни для какого стационарного процесса, так как не выполнено неравенство |RX (t)| ≤ RX (0) для t ∈ (0, t0). Противоречие можно также обнаружить, показав, что предложенная функция RX (t) не является неотрицательно определенной. Действительно, пусть t1 = t0/2, t2 = −t0/2. Тогда определитель

det [︃ RX (t1 − t1) RX (t1 − t2) ]︃ = det [︃ 0 RX (t0) ]︃ = −σ2 < 0,

RX (t2 − t1) RX (t2 − t2)

RX (−t0) 0

и, следовательно, функция RX (t) не является неотрицательно определенной.

92

Перейдем теперь к функции RX (t) из (25). Предположим, что существует стационарный процесс X(t), для которого эта функция корреляционная. В этом случае функция RX (t) является неотрицательно определенной. Пусть t1 = 0, t2 = t0, t3 = 2t0. Тогда ковариационная матрица ∥RX (ti − tj)∥3i,j=1, равная

⎡ σ2

σ2 RX (2t0) ⎤

⎣ σ2

σ2

σ2 ⎦ ,

RX (2t0) σ2

σ2

будет неотрицательно определенной. Здесь мы учли, что R(t) является вещественной функцией, поэтому всюду RX (−t) = RX (t). Определитель этой матрицы равен

−σ2(σ4 − σ2RX (2t0)) + RX (2t0)(σ4 − σ2RX (2t0)) ≥ 0.

Разделим это выражение на −σ2, тогда

RX2 (2t0) − 2RX (2t0)σ2 + σ4 ≤ 0 ⇔ (RX (2t0) − σ2)2 ≤ 0,

что возможно, только лишь если RX (2t0) = σ2. Теперь пусть t1 = 0,

t2 = t0, t3 = 3t0. Тогда ковариационная матрица ∥RX (ti − tj)∥3i,j=1, равная

⎡ σ2

σ2 RX (3t0) ⎤

⎣ σ2

σ2

σ2 ⎦ ,

RX (3t0) σ2

σ2

является неотрицательно определенной. Отсюда следует, что RX (3t0)= = σ2. И вообще, необходимо, чтобы RX (nt0) = σ2 для любого n ∈ Z. Поэтому найдется такое n0, что n0t0 > t0 + ∆, но тогда RX (n0t0) = σ2, а нам дана функция с RX (n0t0) = 0. Мы получили противоречие. Это значит, что какую бы область сглаживания (−t0 − ∆, −t0) ∪ (t0, t0 + ∆) мы ни выбрали и какую бы функцию сглаживания f (t) на ней мы ни
выбрали, функция RX (t) не может быть корреляционной функцией ни для какого стационарного процесса X(t). △
Перейдем теперь к более содержательным результатам корреляци-
онной теории стационарных в широком смысле процессов.

4.4. Спектральное представление процессов
Теперь, когда даны начальные представления о стационарных процессах, самое время поговорить подробно о природе таких процессов.

93

Выше мы видели, что суммы гармоник (комплексных экспонент) образуют стационарный процесс тогда и только тогда, когда коэффициенты при этих гармониках являются попарно некоррелированными. В этом разделе мы увидим сильное обобщение этого наблюдения.
Начнем с содержательного примера. Рассмотрим случайный процесс
X(t) = ξeiΩt,
где ξ и Ω – независимые случайные величины, Eξ = 0, |ξ|2 < ∞, ξ – в общем случае комплекснозначная случайная величина, а Ω – вещественнозначная случайная величина. Математическое ожидание этого процесса
EX(t) = EξeiΩt = Eξ · EeiΩt = 0
в силу независимости случайных величин ξ и Ω (а стало быть, и произвольных функций от них) и условия Eξ = 0. Корреляционная функция

RX (t, s) = EX(t)EX(s) = E|ξ|2eiΩ(t−s)

зависит лишь от разности t − s. Отсюда следует, что процесс X(t) является стационарным в широком смысле.
Перепишем корреляционную функцию в другом виде. Введем функцию RX (τ ) = RX (t, s), τ = t − s, и запишем

ˆ+∞ R(τ ) = E|ξ|2 · EeiΩτ = E|ξ|2 eiντ dFΩ(ν), FΩ(ν) = P(Ω < ν),
−∞
что равносильно

ˆ+∞ RX (τ ) = eiντ d(E|ξ|2FΩ(ν)).
−∞

Если ввести еще обозначение S(ν) = E|ξ|2FΩ(ν), то мы приходим к вы-

ражению

ˆ+∞

RX (τ ) = eiντ dS(ν),

(26)

−∞

где S(ν) – это функция, которая с точностью до произвольного неотрицательного множителя совпадает с функцией распределения случайной величины Ω.

94

Кстати говоря, мы получили, что если функция одной переменной имеет вид (26) с функцией S(ν), которая с точностью до неотрицательного множителя совпадает с функцией распределения некоторой случайной величины, то эта функция является корреляционной функцией некоторого стационарного с.к.-непрерывного процесса X(t) = ξeiΩt, для которого S(ν) = E|ξ|2FΩ(ν).
Оказывается, справедливо и обратное (см. [10, гл. 7, теорема 8]). Теорема 4.5 (Бохнер–Хинчин). Для того чтобы функция R(τ ) являлась корреляционной функцией некоторого стационарного в широком смысле непрерывного в среднеквадратическом смысле случайного процесса, необходимо и достаточно, чтобы она была представима в следующем виде:

ˆ+∞

RX (τ ) = eiντ dS(ν),

(27)

−∞

где S(ν) = E|ξ|2 · P(Ω < ν) для некоторых случайных величин ξ и Ω. Функция S(ν) из теоремы Бохнера–Хинчина называется спектра-
льной функцией. Это название оправдано тем, что она представляет собой с точностью до множителя функцию распределения частоты гармоники eiΩt.
Обращаем внимание читателя на то, что в теореме Бохнера–Хинчина речь идет именно об с.к.-непрерывных процессах. Функция вида (27) нигде не может иметь разрывы. Естественно, существуют стационарные процессы с разрывной корреляционной функцией, например функция RX (t), для которой RX (0) = 1, RX (t) = 0 для остальных t. Эта функция является неотрицательно определенной, поэтому как минимум существует гауссовский стационарный процесс с такой корреляционной функцией.
Бывает, что случайная величина Ω из теоремы Бохнера–Хинчина имеет плотность вероятности распределения. В таких случаях S(ν) тоже имеет плотность.
Определение 4.8. Если функция S(ν) абсолютно непрерывна, т.е. если существует неотрицательная функция ρ(ν) такая, что для всех ν ∈ R:
ˆν
S(ν) = ρ(τ ) dτ,
−∞

то функция ρ(ν) называется спектральной плотностью. В этом случае корреляционная функция процесса представима фо-

95

рмулой

ˆ+∞

RX (t) = eiνtρ(ν) dν.

(28)

−∞

Отметим здесь же, что дисперсия процесса в этом случае

ˆ+∞ DX(t) = RX (0) = ρ(ν) dν.
−∞

Напомним также из теории интегралов Фурье достаточное условие существования спектральной плотности.
Теорема 4.6. Если корреляционная функция RX (t) с.к.-непрерывного процесса абсолютно интегрируема, т.е.

ˆ+∞ |RX (t)| dt < ∞,
−∞

то спектральная функция этого процесса обладает непрерывной и ограниченной спектральной плотностью ρ(ν), причем

ˆ+∞

1 ρ(ν) =

e−iνtRX (t) dt.

2π

−∞

Для вещественной функции RX (t) выражение выше упрощается:

ˆ+∞

1

ρ(ν) = π

cos νt RX (t) dt

0

и ρ(ν) является четной функцией ν. Пример 4.4. Дана спектральная плотность процесса X(t):

⎧ σ2

⎪ ⎨

,

ρ(ν) = 2π

⎪ ⎩ 0,

|ν| ≤ ν0, |ν| > ν0.

Найти корреляционную функцию RX (t) и дисперсию DX(t) процесса.

96

Решение. Из формулы (28) следует

ˆ+∞

ˆν0

σ2 ˆν0

RX (t) = eiνtρ(ν) dν = eiνt ρ(ν) dν =

cos νt dν.

2π

−∞

−ν0

−ν0

Отсюда получаем

σ2

σ2ν0

RX (t) = sin ν0t при t ̸= 0, RX (0) =

.

πt

π

Дисперсия DX(t) = RX (0) = σ2ν0/π. △ Пример 4.5. Корреляционная функция некоторого стационарного
процесса X(t) имеет вид

RX (t) = De−a|t|.

Найти спектральную плотность процесса. Решение. Существование спектральной функции следует из то-
го, что корреляционная функция этого процесса является абсолютно интегрируемой на R. Кроме того, спектральную плотность можно вычислить по формуле

ˆ+∞

ˆ+∞

1 ρ(ν) =

e−iνtRX (t) dt = 1

De−iνt−a|t| dt =

2π

2π

−∞

−∞

ˆ+∞

(︃

)︃

D =

(e−iνt−at + eiνt−at) dt = D

1

1

+

=

2π

2π iν + a −iν + a

0

Da 1 = π a2 + ν2 .△

Пример 4.6. Найти спектральную функцию случайного процесса с корреляционной функцией, заданной формально как

RX (t) = σ2δ(t),

где δ(t) – дельта-функция. Решение. Абстрагируясь от математической строгости, относя-
щейся к теории выше, мы можем записать:

ˆ+∞ 1

ˆ+∞ 1

σ2

ρX (ν) =

e−iνtRX (t) dt =

e−iνtσ2δ(t) dt = . △

2π

2π

2π

−∞

−∞

97

Хотя, строго говоря, процессов с такой корреляционной функцией

не существует, тем не менее эта абстракция оказывается чрезвычайно

полезна в приложениях. Процесс с такой формальной корреляцион-

ной функцией называется белым шумом. Его особенность в том, что

любые два сколь угодно близких сечения процесса являются некорре-

лированными. Конечно, существует математически строгое описание

процессов, у которых корреляционная функция представляет собой

какие-то комбинации обобщенных функций. Такие процессы называ-

ются обобщенными процессами, к ним принадлежит и белый шум. За

подробной справкой об определении и свойствах таких процессов мы

отправляем читателя к монографии [35, гл. 17].

Чтобы избежать описанных выше трудностей, можно рассматри-

вать корреляционную функцию из примера 4.6 в предположении, что

время дискретно. В этом случае не нужно требовать непрерывности

корреляционной функции, так как теперь RX (n), n ∈ Z – последо-

вательность. Аналогом теоремы Бохнера–Хинчина 4.5 для случайных

процессов в дискретном времени (т.е. случайных последовательностей)

является теорема Герглотца (см. гл. 7, теорема 4 [10]).

Теорема 4.7. Для того, чтобы функция RX (n), ∈ Z, являлась

корреляционной функции некоторой стационарной в широком смысле

последовательности, необходимо и достаточно, чтобы было справед-

ливо представление

ˆπ

RX (n) = einν dS(ν),

(29)

−π

где S – конечная мера на борелевской сигма-алебре отрезка [−π, π]. Теперь рассмотрим пример, аналогичный примеру 4.6, только в
дискретном времени. Пусть корреляционная функция имеет вид:

⎧ σ2, ⎨ RX (n) = ⎩ 0,

n = 0, n ̸= 0.

Как несложно проверить, последовательность некоррелированных случайных величин X1, X2, . . . с общей дисперсией DX = σ2 имеет такую корреляционную функцию. Это и есть модель белого шума в дискретном времени. Спектральная плотность для дискретного белого шума равна ρ(ν) = 1/(2π), ν ∈ [−π, π]. △
Мы видели выше, что комплексные гармоники с нулевым математическим ожиданием являются стационарными в широком смысле процессами. Линейные комбинации таких некоррелированных гармоник также являются стационарными процессами. Кроме того, мы

98

видели, что корреляционная функция стационарного процесса представляет собой интеграл («непрерывную сумму») гармоник. Возникает вопрос: можно ли и сам стационарный процесс представить в виде конечной или бесконечной суммы гармоник с некоррелированными коэффициентами? Оказывается, это всегда возможно.
Чтобы это продемонстрировать, вернемся к примеру со стационарным процессом X(t) = ξeiΩt, где ξ – комплекснозначная случайная величина второго порядка с нулевым математическим ожиданием и Ω – вещественнозначная случайная величина с произвольной функцией распределения FΩ(ν) и не зависящая от ξ. Представим этот процесс в виде интеграла от комплексной экспоненты.
Для простоты рассмотрим случай, когда ξ = 1 п.н. и Ω ∈ R(0, 1). Введем процесс V (ν) = I(Ω < ν), где ν выполняет роль времени для случайного процесса V (ν). В таком случае

ˆ+∞ X(t) = eiΩt = eiνt dV (ν),
−∞

где интеграл понимается в смысле определения 2.5. Чтобы это по-
казать, возьмем произвольное разбиение 0 = ν1 < · · · < νn = 1 произвольного отрезка [0, 1], выберем произвольные точки νk′ ∈ [νk, νk+1] и запишем интегральную сумму:

n−1

n−1

Sn = ∑︂ eiνk′ t(V (νk+1) − V (νk)) = ∑︂ eiνk′ t · I(Ω ∈ [νk, νk+1]).

k=1

k=1

Очевидно, что для каждого исхода ω в сумме выше будет только одно ненулевое слагаемое и оно будет зависеть от исхода: eiνk′ (ω)t. Кроме того, при измельчении разбиения, νk′ (ω) → Ω(ω). Получается, что имеется сходимость п.н. Sn → eiΩt, но так как последовательность eiνk′ (ω)t ограничена по модулю единицей, то это будет также сходимость и в
среднем квадратичном. С другой сторон´ы, по определению есть сходимость в среднем квадратичном Sn → 1 eiνt dV (ν). Значит, п.н.
0

ˆ1 eiνt dV (ν) = eiΩt.
0

Теперь в качестве отрезка интегрирования взять [a, b], a ≤ 0, b ≥ 1, и устремить a → −∞, b → +∞ в среднем квадратичном. Значение интеграла при этом меняться не будет, так как при таких ν не меняется

99

V (ν). Следовательно, мы доказали, что п.н.
ˆ+∞ eiνt dV (ν) = eiΩt.
−∞
Введем теперь одно вспомогательное понятие и сформулируем главную теорему о спектральном представлении стационарного процесса.
Определение 4.9. Центрированный случайный процесс V (t) ∈ CL2 будем называть процессом с ортогональными приращениями, если для любых t1 < t2 ≤ t3 < t4
E(V (t4) − V (t3))(V (t2) − V (t1)) = 0.
Теорема 4.8 (Крамер). Любому стационарному в широком смысле с.к.-непрерывному случайному процессу X(t) ∈ CL2 соответствует случайный процесс V (ν), заданный на том же вероятностном пространстве, что и процесс X(t), с ортогональными приращениями, такой, что с вероятностью единица
ˆ+∞ X(t) = mX + eiνt dV (ν), t ∈ R,
−∞
где интеграл понимается как несобственный интеграл в смысле Римана–Стилтьеса, а mX – математическое ожидание процесса X(t).
С доказательством этой теоремы можно познакомиться, например, в [10, гл. 7, теорема 9].
Отметим, что ортогональность приращений процесса V (ν) – это аналог ортогональности коэффициентов при комплексных экспонентах в теореме 4.2.
Аналогичная теорема имеет место и для стационарных последовательностей (см. [10, гл. 7, теорема 5]).
Теорема 4.9. Любой стационарной в широком смысле случайной последовательности Xn ∈ CL2 соответствует случайный процесс V (ν), ν ∈ [−π, π], заданный на том же вероятностном пространстве, что и последовательность Xn, с ортогональными приращениями, такой, что с вероятностью единица
ˆ+π Xn = mX + eiνn dV (ν), n ∈ Z.
−π
100

Ранее нами была выведена формула корреляционной функции
n
RX (t) = ∑︂ E|ξk|2eiωkt
k=1
стационарного случайного процесса
n
X(t) = ∑︂ ξkeiωkt.
k=1

Выведем теперь связь между корреляционной функцией RX (t) и процессом VX (ν) для произвольного стационарного процесса X(t). По определению

ˆ+∞

2N/h

◦
X(t) =

eiνtdV (ν) = l.i.m. ∑︂ eiνkt(V (νk) − V (νk−1)),

N →∞

−∞

h→+0 k=1

где рассматривается разбиение отрезка [−N, N ] на отрезки длины h (не умаляя общности, считаем, что 2N/h – целое число), νk – точка из k-го отрезка разбиения. Тогда корреляционную функцию случайного процесса X(t) можно записать в виде

◦

◦

RX (τ ) = EX(t + τ )X(t) =

⎛
2N/h

⎞
2N/h

= E ⎝l.i.m. ∑︂ eiνk(t+τ)(V (νk) − V (νk−1)) ∑︂ e−iνjt(V (νj ) − V (νj−1))⎠=

N →∞

h→+0 k=1

j=1

2N/h 2N/h

= lim ∑︂ ∑︂ ei(νk(t+τ)−νjt) E(V (νk) − V (νk−1))(V (νj ) − V (νj−1)) =

N →∞

h→+0 k=1 j=1

⏞

⏟⏟

⏞

=0, если k̸=j

2N/h
= lim ∑︂ eiνkτ E|V (νk) − V (νk−1)|2.
N →∞ h→+0 k=1

Полученное выражение представляет собой интеграл по мере

dS(ν) = E|dV (ν)|2

и может быть использовано в качестве определения такого интеграла.

101

4.5. Закон больших чисел для вещественнозначных стационарных в широком смысле процессов в дискретном и непрерывном времени.
Закон больших чисел для стационарных в широком смысле последовательностей имеет вид

1

N
∑︂

L

Xk −−−2−→ mX + V (0).

(30)

N

N →∞

k=1

Отметим, что в отличие от обычного закона больших чисел для независимых с.в. в общем случае может быть еще дополнительная случайная компонента V (0). Формула (30) следует из спектрального разложения:

1N

1 N ˆπ

ˆπ

∑︂

∑︂

Xk =

eiνkdV (ν) =

ΨN (ν)dV (ν),

N k=1 N k=1 −π −π

где функция ΨN (ν) = N1 eiν−1e−iνei(νN+1) такая что |ΨN (ν)| ≤ 1, ΨN (0) = 1, но если ν ̸= 0, то |ΨN (ν)| → 0 при N → ∞. Несложно показать, используя спектральное представление для корреляционной функции, что аналогично (30) имеет место

1

N
∑︂

RX (k) −−−−→ S({0}).

(31)

N

N →∞

k=1

Можно показать, что для стационарной в широком смысле последовательности X1, X2, . . . следующие условия эквивалентны:

• последовательность X1, X2, . . . является эргодичной по математическому ожиданию (см. далее определение 5.1), то есть

1

N
∑︂

L

Xk −−−2−→ mX ;

N

N →∞

k=1

• соответствующая спектральная мера непрерывна в нуле, то есть S({0}) = 0, а значит

1

N
∑︂

RX (k) −−−−→ 0

N

N →∞

k=1

(см. далее теорему Слуцкого 5.3);

102

• V (0) = 0 п.н.

Детали доказательства см. [10, гл. 7 ]. Аналогичные результаты можно выписать и для стационарных в широком смысле с.к.-непрерывных случайных процессов, если заменить суммы на интегралы. Отметим также, что понятие эргодичности по математическому ожиданию можно вводить и для нестационарных процессов, как будет показано в разделе 5. В этом разделе будет также приведен закон больших чисел для стационарных в узком смысле процессов.
Пример 4.7. Для процесса из примера 4.1 написать закон больших чисел.
Заметим, что представление

Z(t) = A cos (Bt + ϕ) = A eiϕeBt + A e−iϕe−Bt

2

2

даёт спектральное разложение процесса. А именно, если B ̸= 0, то

⎧
⎪ ⎪ ⎪ ⎪ ⎨
V (ν) =
⎪ ⎪ ⎪ ⎪ ⎩

A2 eiϕ, A2 e−iϕ,
0,

ν = B, ν = −B, иначе.

В этом случае Если B = 0, то В этом случае

1ˆT

L

Z(t) dt −−−2−→ 0.

T0

T →∞

⎧ A cos π, ⎨ V (ν) = ⎩ 0,

ν = 0, иначе.

1ˆT

L

Z(t) dt −−−2−→ A cos ϕ. △

T0

T →∞

4.6. Линейные преобразования процессов
Спектральное представление случайных процессов встречается в основном в инженерных приложениях, когда задана некоторая линейная система, на ее вход поступает стационарный случайный процесс, а на выходе получается преобразованный стационарный процесс. Эта
103

линейная система осуществляет линейное преобразование над входным процессом, обычно это какая-то комбинация производных и интегралов от входного процесса. Оказывается, свойства преобразованного процесса удается сравнительно легко описать в терминах спектральных функций входного процесса. Для того чтобы можно было корректно описывать преобразованный процесс в терминах входного процесса, кроме теоремы 4.8 нам потребуются следующие два факта (см., например, [41]).
Теорема 4.10. Пусть даны стационарный процесс X(t) ∈ CL2 с спектральной функцией SX (ν) и представлением
ˆ+∞ X(t) = eiνt dVX (ν)
−∞

и комплекснозначная функция Φ(ν), удовлетворяющая условию

ˆ+∞ |Φ(ν)|2 dSX (ν) < ∞.
−∞

Пусть некоторый центрированный стационарный случайный процесс Y (t) ∈ CL2 допускает представление
ˆ+∞ Y (t) = eiνtΦ(ν) dVX (ν).
−∞

Тогда спектральная функция SX (ν) процесса X(t) связана со спектральной функцией SY (t) процесса Y (t) соотношением
dSY (ν) = |Φ(ν)|2 dSX (ν).

Доказательство. Так как процесс Y (t) ∈ L2 является стационарным, то в силу теоремы 4.8 найдется процесс VY (ν) с ортогональными приращениями, такой, что почти всюду будет верно равенство

ˆ+∞

ˆ+∞

eiνtΦ(ν) dVX (ν) = eiνt dVY (ν).

−∞

−∞

Но так как процесс VY (ν) определен с точностью до аддитивной случайной величины (см. теорему 4.8), то

Φ(ν) dVX (ν) = dVY (ν).

104

Остается возмести обе части в квадрат и вычислить математическое ожидание:
|Φ(ν)|2 E|dVX (ν)|2 = E|dVY (ν)|2,
откуда сразу получаем требуемое утверждение. □ Теорема 4.11. Если для некоторого k ≥ 0 существует конечный
интеграл ˆ+∞ ν2k dSX (ν) < ∞,
−∞
а процесс X(t) является k раз с.к.-дифференцируемым, то с.к.-производная
ˆ+∞ X(k)(t) = eiνt(iν)k dVX (ν),
−∞
т.е. производную можно вносить под знак стохастического интеграла.
Пример 4.8. Дана линейная система

a1X˙ (t) + a0X(t) = Y (t)

с входным сигналом Y (t) и выходным сигналом X(t). Пусть EY (t) = 0 для любого t ∈ R. Считая известной спектральную плотность ρY (ν) процесса Y (t), вычислить спектральную плотность процесса X(t).
Решение. Будем искать стационарное с.к.-дифференцируемое решение X(t) указанного уравнения. Для этого представим процесс X(t) в виде
ˆ+∞ X(t) = eiνtdVX (ν)
−∞
и подставим это выражение в уравнение, воспользовавшись теоремой 4.11:

ˆ+∞ (a1iν + a0)eiνtdVX (ν) = Y (t),
−∞
предположив, что для искомого решения выполняются условия

ˆ+∞

|a1iν + a0|2 dSX (ν) < ∞,

(32)

−∞

105

ˆ+∞

ν2 dSX (ν) < ∞.

(33)

−∞

По теореме 4.10 получаем, что спектральные функции SY (ν) и SX (ν) связаны друг с другом соотношением

dSY (ν) = |a1iν + a0|2dSX (ν),

откуда следует

ρX (ν) = ρY (ν) = ρY (ν) .

(34)

|a1iν + a0|2 a21ν2 + a20

В результате мы получаем, что если условия (32) и (33) выполнены, то спектральная плотность процесса X(t) существует и удовлетворяет (34). Заметим, что для функции (34) оба условия оказываются выполнены. Действительно, условие (32) равносильно условию абсолютной интегрируемости спектральной плотности ρY (ν), а условие (33) выполнено, как следует из оценки

ν2ρY (ν) 1

a2ν2 + a2 ≤ a2 ρY (ν)

1

0

1

и, опять же, интегрируемости функции ρY (ν). Заметим, наконец, что в принципе могут существовать решения,
которые не удовлетворяют условию (33). Более того, спектральная плотность не однозначно определяет стационарный процесс. Другими словами, спектральной плотности, которую мы нашли, может соответствовать много разных процессов X(t). △
Закрепим предыдущий пример, рассмотрев содержательную задачу из курса физики.
Пример 4.9. Рассмотрим колебательный контур, состоящий из последовательно соединенных катушки индуктивности, конденсатора, сопротивления и источника сторонних эдс. Эдс E(t), заряд q(t) на обкладках конденсатора и производные q˙(t), q¨(t) считаются достаточно с.к.-гладкими стационарными в широком смысле случайными процессами с нулевым математическим ожиданием. Считая известной спектральную плотность ρE (ν) процесса E(t), вычислить спектральную плотность ρq(ν) процесса q(t).
Решение. Уравнение тока в цепи имеет вид (см. [33]):

q Lq¨ + Rq˙ + = E.
C

106

Так как E(t) и q(t) считаются стационарными процессами с нулевым математическим ожиданием, то они могут быть представлены в виде

ˆ+∞ E(t) = eiνtdVE (ν),
−∞

ˆ+∞ q(t) = eiνtdVq(ν).
−∞

Теперь вычислим поочередно первую и вторую производную q(t):

ˆ+∞ q˙(t) = (iν)eiνtdVq(ν),
−∞

ˆ+∞ q¨(t) = (iν)2eiνtdVq(ν)
−∞

в предположении условий

ˆ+∞

ˆ+∞

|iν|2dSq(ν) < ∞,

|iν|4dSq(ν) < ∞.

(35)

−∞

−∞

Подставляя выражения для q(t), q˙(t) и q¨(t) в исходное уравнение, мы получаем

ˆ+∞ [︁L(iν)2 + R(iν) + C−1]︁ eiνtdVq(ν) = E(t).
−∞

Теперь предположим, что

ˆ+∞

⃓⃓L(iν)2 + R(iν) + C−1⃓⃓2 dSq(ν) < ∞.

(36)

−∞

Тогда по теореме 4.10 получаем, что спектральные функции Sq(ν) и SE (ν) связаны соотношением

dSE (ν) = ⃓⃓L(iν)2 + R(iν) + C−1⃓⃓2 dSq(ν),

что означает существование спектральной плотности

ρE (ν) ρq(ν) = |L(iν)2 + R(iν) + C−1|2 .

Легко видеть, что условия (35) и (36) для этой функции выполнены.

107

Итак, среди всех достаточно с.к.-гладких стационарных в широком смысле процессов, удовлетворяющих условиям (35) и (36), решения исходного уравнения (если существуют) обладают спектральной плотностью, записанной выше. Вопрос о существовании таких решений здесь не рассматривается. △
За более полным изложением спектральной теории случайных процессов мы отправляем читателя к классическим источникам [36, 71]. В частности, из важного, но не вошедшего в данное пособие, отметим разложение Вольда [10, 70] и его использование при предсказании поведения случайного процесса по имеющейся истории.
108

5. Эргодические процессы

В этом разделе мы введем одно из важнейших понятий теории

случайных процессов – понятие эргодичности. Свойство эргодично-

сти процессов нам будет встречаться до конца этой книги. С резуль-

татами эргодического типа читатели уже знакомы из курса теории

вероятностей: (усиленный) закон больших чисел (ЗБЧ, УЗБЧ) для

последовательности независимых одинаково распределенных случай-

ных величин X1, X2, . . ., которые утверждают, что среднее по времени

1 N

∑︁N
n=1

Xn

в

соответствующем

смысле

(по

вероятности

или

п.н.)

близ-

ко к среднему по вероятностному пространству EX1. В курсе случай-

ных процессов результаты типа ЗБЧ тоже уже возникали для стаци-

онарных в широком смысле процессов, см. раздел 4.5. В этом разделе

5 будут получены результаты эргодического типа, но

• для более широкого класса процессов (см. раздел 5.1). При этом теоремы, касающиеся стационарных в широком смысле процессов будут получены здесь без использования спектрального представления (см. теорему Слуцкого 5.3).

• для стационарных в узком смысле последовательностей (теория которых тесно связана с понятием динамических систем, а именно с соответствующим преобразованием, сохраняющим вероятностную меру, и его свойствами (эргодичности, перемешивания и т.д.), см. раздел 5.2.

5.1. Эргодические случайные процессы
Рассмотрим следующую прикладную задачу курса случайных процессов. Пусть имеется единственная, но достаточно длинная реализация некоторого случайного процесса X(t), где t ∈ [0, T ], если время предполагается непрерывным, или t ∈ {1, 2, . . . , N }, если время дискретно. Требуется оценить какие-то характеристики этого процесса.
Определение 5.1. Вещественный случайный процесс X(t) ∈ L2 называется эргодическим по математическому ожиданию, если его математическое ожидание постоянно mX (t) ≡ mX ∈ R и

ˆT

def 1

L2

⟨X⟩T =

X(t) dt −−−−→ mX .

T

T →∞

0

109

В выражении выше подразумевается, что процесс X(t) с.к.-интег-

рируем на любом отрезке вида [0, T ], T > 0, а интеграл понимается в

смысле с.к.-интеграла.

Таким образом для эргодического по математическому ожиданию

процесса «хорошей» оценкой параметра mX служит среднее по време-

ни единственной наблюдаемой реализации ⟨X⟩T .

Теорема 5.1 (критерий эргодичности). Процесс X(t) ∈ L2 с по-

стоянным математическим ожиданием mX (t) ≡ mX является эр-

годическим по математическому ожиданию тогда и только тогда,

когда

ˆT ˆT

1

lim T →∞ T 2

RX (t1, t2) dt1dt2 = 0.

(37)

00

Доказательство. Покажем, что

ˆT ˆT 1

⃓

⃓2

T2

RX (t1, t2)dt1dt2 = E⃓⃓⟨X⟩T − mX ⃓⃓ .

00

Для этого разложим выражение E |⟨X⟩T − mX |2 на два множителя, представим в обоих множителях ⟨X⟩T в виде с.к.-предела, при этом разбиения отрезка [0, T ] выберем одинаковыми, а точки между ними различными, и воспользуемся теоремой 2.2:

⃓

⃓2 (︂

⃓⟨X⟩T − mX ⃓ = E

l.i.m.

1

m
∑︂

)︂

(X(t′i) − mX )∆ti ×

E⃓

⃓

0=t0<t1<...<tm=T T

max ∆ti−−−−→0 i=1

i=1,m

n→∞

t′i ∈[ti ,ti+1 )

(︂

1 ∑m︂ ′

)︂ Теорема 2.2

×

l.i.m.

0=t <t <...<t =T T

(X(tj) − mX )∆tj

=

0
max

∆1tj −−−−m→0

j=1

j=1,m

n→∞

t′j ∈[tj ,tj+1)

1

mm
∑︂ ∑︂

=

lim

0=t <t <...<t

=T E T 2

(X(t′i) − mX )(X(t′j) − mX )∆ti∆tj =

0
max

∆1ti−−−−m →0

i=1 j=1

i=1,m

n→∞

t′i ∈[ti ,ti+1 ) t′j ∈[tj ,tj+1)

1

mm
∑︂ ∑︂

=

lim

0=t <t <...<t =T T 2

RX

(t

′ i

,

t′j

)∆

ti

∆

t

j

=

0
max

∆1ti−−−−m →0

i=1 j=1

i=1,m

n→∞

t′i ∈[ti ,ti+1 ) t′j ∈[tj ,tj+1)

110

ˆT ˆT

1

= T2

RX (t1, t2) dt1dt2,

00

откуда и получаем требуемое, т.е.

ˆT ˆT

L2

1

⟨X⟩T −−−−→ mX
T →∞

⇔

lim T →∞ T 2

RX (t1, t2) dt1dt2 = 0. □

00

ствоОвбарнаитеисм.ке.-щиентвенгирмалаани´еTнXа (тt)оd, tчдтлояилзюубсолгоовиTя>(307.) следует суще-
0
Пример 5.1. Пусть {X(t) ∈ L2, t ≥ 0} – случайный процесс с нулевым математическим ожиданием и корреляционной функцией

RX (t1, t2) = e−|t1−t2|.

Исследовать процесс X(t) на эргодичность по математическому ожиданию.
Решение. Математическое ожидание данного процесса есть константа, а так как функция RX (t1, t2) интегрируема по Риману на любом квадрате [0, T ]2, T > 0, то X(t) является с.к.-интегрируемым на любом отрезке [0, T ], T > 0. Воспользуемся теперь критерием эргодичности по математическому ожиданию (теорема 5.1). Для этого рассмотрим интеграл

ˆT ˆT

ˆT ˆT

RX (t1, t2) dt1dt2 =

e−|t1−t2| dt1dt2 =

00

00

ˆT ⎛ˆt2

ˆT

⎞

=

⎝ et1−t2 dt1 + et2−t1 dt1⎠ dt2 =

00

t2

ˆT = (︁1 − e−t2 + 1 − et2−T )︁ dt2 =

0
= 2T + e−T − 1 + e−T − 1 = = 2T + 2e−T − 2.

Очевидно, T −2(2T + 2e−T − 2) → 0 при T → ∞, поэтому процесс X(t) является эргодическим по математическому ожиданию. △

111

Пример 5.2. Пусть {W (t), t ≥ 0} – винеровский процесс. Исследовать на эргодичность по математическому ожиданию процесс X(t) = W (t)/t, t ≥ 1.
Решение. Так как винеровский процесс в каждом сечении имеет конечные моменты произвольного порядка, то и процесс X(t) имеет моменты произвольного порядка. Следовательно, X(t) ∈ L2. Далее, очевидно, mX (t) = 0 всюду и

RX (t1, t2) = min(t1, t2) =

1 , t1 ≥ 1, t2 ≥ 1.

t1t2

max(t1, t2)

Теперь остается заметить, что max(t1, t2) ≥ t1 всюду, следовательно,

ˆT ˆT

ˆT ˆT

1

1

max(t1, t2) dt1dt2 ≤

t1 dt1dt2 = (T − 1) ln T.

11

11

Очевидно, что (T − 1)−2(T − 1) ln T → 0 при T → ∞, поэтому процесс X(t) = W (t)/t, t ≥ 1, является эргодическим по математическому ожиданию. △
Пример 5.3. На вход некоторой вычислительной машины поступают зашумленные значения функции вида eat с неизвестным значением параметра a; t интерпретируется как время. Модель фактически получаемого сигнала принята следующей:

S(t) = eat+W (t),

где W (t) – винеровский процесс. Ставится задача оценки параметра a. Решение. Для оценивания параметра a воспользуемся теорией эр-
годических процессов. Для этого найдем такой процесс X(t), являющийся преобразованием исходного процесса, чтобы EX(t) = a и X(t) был эргодичен по математическому ожиданию. Тогда хорошей оценкой параметра a будет служить его среднее по времени. В качестве такого процесса рассмотрим случайный процесс:

ln S(t)

W (t)

X(t) =

=a+

, t ≥ 1.

t

t

Каждое сечение этого процесса имеет моменты произвольного порядка, поэтому X(t) ∈ L2. Математическое ожидание этого процесса постоянно и равно неизвестному параметру a. Что касается корреляционной функцией, то она совпадает с корреляционной функции процесса из прошлого примера, т.е. RX (t1, t2) = 1/ max(t1, t2), т.к. аддитивные

112

постоянные (в нашем случае это a) не влияют на значения корреляционной функции или дисперсии. Из выкладок предыдущего примера следует, что X(t) является эргодическим по математическому ожиданию процессом. Следовательно, наблюдая процесс S(t) на достаточно продолжительном интервале времени [1, T ], мы можем оценить параметр a по формуле

ˆT

ˆT

1

1

ln S(t)

a≈

X(t) dt =

dt. △

T −1

T −1

t

1

1

Теорема 5.2 (достаточное условие эргодичности). Для того, чтобы процесс второго порядка X(t), с.к.-интегрируемый на любом отрезке и с постоянным математическим ожиданием, был эргодичен по математическому ожиданию, достаточно, чтобы

1

lim RX (t, s) = 0, lim max RX (t, t) = 0.

|t−s|→∞

T →∞ T t∈[0,T ]

Доказательство.. Пусть дан процесс с нужными свойствами. То-
гда для любого ε > 0 найдется T0 такой, что для любого T = |t2 − t1| > T0 выполнено |RX (t1, t2)| < ε. Зафиксируем ε > 0, возьмем подходящий T0 и разобьем квадрат [0, T ]2 на два множества:

G1 = {(t1, t2) ∈ T × T : |t2 − t1| > T0},

G2 = {(t1, t2) ∈ T × T : |t2 − t1| ≤ T0}.

Обозначим за S1 и S2 площади множеств G1 и G2 соответственно.

Тогда

⃓ ⃓

ˆT ˆT

⃓ ⃓

⃓1

⃓

⃓ ⃓T2

RX (t1, t2) dt1dt2⃓ = ⃓

⃓ 00

⃓

⃓

⃓

⃓ ⃓

1

1

⃓ ⃓

= ⃓⃓ T 2

RX (t1, t2) dt1dt2 + T 2

RX (t1, t2) dt1dt2⃓ ≤ ⃓

⃓ G1

G2

⃓

⎛

⎞

1

≤ T 2 ⎝ |RX (t1, t2)| dt1dt2 + |RX (t1, t2)| dt1dt2⎠ ≤

G1

G2

≤ εS1 + maxG2 |RX (t1, t2)|S2 ≤ ε + 2 max |RX (t1, t2)| T0 ,

T2

G2

T

113

так как S1 ≤ T 2 и S2 = T 2 − 2(1/2)(T − T0)2 = 2T T0 − T02 ≤ 2T0T . Из неравенства Коши–Буняковского следует, что
|RX (t1, t2)|2 ≤ RX (t1, t1)RX (t2, t2),

поэтому maxG2 |RX (t1, t2)| ≤ maxt∈[0,T ] |RX (t, t)|. Теперь достаточно взять T ≥ T0 и такое, чтобы maxt∈[0,T ] |RX (t, t)|/T ≤ ε. □
Из этой теоремы следует, что для того, чтобы стационарный в широком смысле процесс второго порядка X(t), с.к.-интегрируемый на любом отрезке и с постоянным математическим ожиданием, был эргодичен по математическому ожиданию достаточно, чтобы

lim RX (t) = 0.
t→∞

Заметим, что у стационарного в широком смысле процесса дисперсия постоянна и поэтому условие limT →∞ maxt∈[0,T ] RX (t, t)/T = 0 выполнено автоматически.
Эргодические процессы не обязательно являются стационарными в каком-либо смысле. Например, процесс из примера 5.2 не является стационарным в широком смысле, так как его корреляционная функция не является функцией разности t1 и t2. Однако в случаях, когда процесс является стационарным в широком смысле, достаточное условие становится использовать особенно легко. Например, в примере 5.1 дан процесс с корреляционной функцией RX (t1, t2) = exp(−|t1 − t2|). Очевидно, что RX (t1, t2) → 0 при |t1 − t2| → ∞, поэтому с учетом теоремы 5.2 легко заключаем, что этот процесс является эргодическим по математическому ожиданию.
Теорема 5.3 (Слуцкий, см. [71]). Пусть случайный процесс X(t)
стационарен в широком смысле и при этом RX (t1, t2) = RX (t2 − t1). Тогда

ˆT ˆT

ˆT

1

2 (︂ τ )︂

J = T2

RX (t1, t2) dt1dt2 = T 1 − T RX (τ ) dτ.

(38)

00

0

При этом процесс X(t) эргодичен по математическому ожиданию тогда и только тогда, когда

ˆT 1 RX (τ ) dτ → 0, T → ∞. (39) T
0
Иначе говоря, (39) равносильно тому, что J из формулы (38) стремится к нулю при T → ∞.

114

Доказательство. Выполним замену переменных: τ = t2 −t1, s = t2; модуль определителя матрицы Якоби такого преобразования равен единице. Область интегрирования в новых координатах (τ, s) — это два прямоугольных треугольника:
I1 с вершинами в точках (0, T ), (0, 0), (−T, 0),

I2 с вершинами в точках (0, 0), (0, T ), (T, T ).

s T

I2 I1
−T

τ T

Следовательно,

1

1

J = T 2 RX (τ ) dτ ds + T 2 RX (τ ) dτ ds =

I1

I2

ˆ0

τˆ+T

ˆT

ˆT

1

1

= T 2 RX (τ ) dτ ds + T 2 RX (τ ) dτ ds =

−T

0

0

τ

ˆ0

ˆT

1

1

= T 2 (T + τ )RX (τ ) dτ + T 2 (T − τ )RX (τ ) dτ =

−T

0

ˆT

ˆT

1

1

= T 2 (T − τ )RX (−τ ) dτ + T 2 (T − τ )RX (τ ) dτ =

0

0

ˆT

2 (︂ τ )︂

= T

1 − T RX (τ ) dτ,

0

где было учтено равенство RX (−τ ) = RX (τ ) для вещественных процессов.
Для доказательства второй части теоремы, заметим, что

ˆT 1 T RX (τ ) dτ = E [(X(0) − mX )(⟨X⟩T − mX )] .
0

115

Отсюда и из неравенств´а Коши–Буняковского следует, что если (⟨X⟩T − mX )2 → 0, то 1 T RX (τ ) dτ → 0. Это доказывает необходи-

E

T0

мость.

Для доказательства достаточности воспользуемся критерием 5.1 и

сделанной выше выкладкой. Удобнее поменять порядок интегрирова-

ния:

ˆT ˆs

2

2

J = T 2 RX (τ ) dτ ds = T 2

RX (τ ) dτ ds.

I2

00

Далее из условия 1 ´ T R (τ ) dτ → 0 следует, что для любого ε > 0

T0 X

´s

существует T◦(ε) такое, что для любого s > T◦ 0 RX (τ ) dτ < εs. При

s < T◦ воспользуем´сяs неравенством (которое на самом деле справед-

ливо для любых s) 0 RX (τ ) dτ ≤ RX (0)s.

ˆT ˆs

2

J = T2

RX (τ ) dτ ds =

00

ˆT◦ˆs

ˆT ˆs

2

2

= T2

RX (τ ) dτ ds + T 2

RX (τ ) dτ ds ≤

00

T◦ 0

ˆT◦

ˆT ˆ

2

2

≤ T 2 RX (0)s ds + T 2

εs ds =

0

T◦

T◦2

T 2 − T◦2

T◦2

= T 2 RX (0) + T 2 tε < T 2 RX (0) + ε.

Откуда следует, что J → 0 при T → ∞. Что и доказывает достаточность. □
Аналогично тому, как мы ввели ранее определение эргодичности по математическому ожиданию, можно ввести понятия эргодичности по дисперсии и эргодичности по корреляционной функции.
Определение 5.2. Случайный процесс X(t) ∈ L2 называют эргодическим по дисперсии, если случайный процесс

Y (t) = X◦ 2(t) = (X(t) − mX (t))2

эргодичен по математическому ожиданию. Таким образом, для процесса X(t) с постоянной дисперсией σX2 =

116

EX◦ 2(t) хорошей оценкой дисперсии будет

ˆT

def 1 ⟨Y ⟩T =

X◦ 2(t) dt −−L−2−→ σ2 .

T

T →∞ X

0

Определение 5.3. Случайный процесс X(t) ∈ L2 называют эрго-

дическим по корреляционной функции, если для каждого τ ≥ 0 слу-

◦

◦

чайный процесс Yτ (t) = X(t)X(t + τ ) эргодичен по математическому

ожиданию.

Таким образом, для процесса X(t) с корреляционной функцией,

◦

◦

зависящей от разности аргументов RX (τ ) = EX(t)X(t + τ ) хорошей

оценкой корреляционной функции в каждой фиксированной точке τ

будет

ˆT

def 1

◦

◦

L2

⟨Yτ ⟩T =

X(t)X(t + τ ) dt −−−−→ RX (τ ).

T

T →∞

0

5.2. Эргодические динамические системы и закон больших чисел для стационарных в узком смысле случайных последовательностей*
В данном разделе вводится новое понятие – динамическая система, а вместе с ней и понятие эргодической динамической системы. Здесь мы постараемся продемонстрировать, как теория эргодических процессов может помочь в понимании жемчужины теории динамических систем эргодической теоремы Биркгофа–Хинчина–Фон Неймана [35, 55, 70].
Определение 5.4. Совокупность M = (Ω, F, P = µ, T ), где (Ω, F, P = µ) — вероятностное пространство, и измеримое отображение T : Ω → Ω удовлетворяет свойству
∀B ∈ F ↪→ µ (︁T −1(B))︁ = µ(B)
(вероятностная мера µ инвариантна относительно преобразования T , либо иначе говоря, T – сохраняющее меру µ преобразование), будем называть динамической системой.
На самом деле для теории динамических систем мера µ не обязана быть вероятностной, однако для связи результатов со случайными процессами, мы будем все же предполагать,что µ вероятностная мера.
117

Пусть ξ некоторая случайная величина, заданная на вероятностном пространстве (Ω, F, µ). Рассмотрим случайный процесс, порожденный динамической системой (преобразованием T ) X0(ω) = ξ(ω), X1(ω) = ξ(T ω), X2(ω) = ξ(T 2ω), . . . Несложно убедиться, что такая последовательность является стационарной в узком смысле. На самом деле верен и обратный результат, что для каждой стационарной в узком смысле последовательности найдется динамическая система, порождающая её (см. [70, гл. V, §1]).
Определение 5.5. Динамическая система M = (Ω, F, µ, T ) называется эргодической, если из равенства T −1(B) = B (µ-п.н.) следует, что либо B = ∅ (µ-п.н.), либо B = Ω (µ-п.н.).
Здесь и далее равенство множеств A = B (µ-п.н.) означает равенство µ((A ∪ B) \ (A ∩ B)) = 0, т.е. что мера симметрической разности множеств равна нулю.
Пример 5.4. Пусть Ω = S1 — окружность единичной длины на плоскости (будем пользоваться ее гомеоморфностью отрезку [0, 1], концы которого отождествлены), F = B(S1) — борелевская σ-алгебра на S1, µ = λ — классическая мера Лебега на S1, T (ω) = {log10 2 + ω}, где {y} обозначает дробную часть числа y, ω ∈ Ω. Показать, что M= = (Ω, F, µ, T ) является динамической системой.
Решение. Из постановки задачи сразу следует, что тройка (Ω, F, µ) является вероятностным пространством. Остается доказать, что
∀B ∈ F ↪→ µ (︁T −1(B))︁ = µ(B).

Заметим, что преобразование T : Ω → Ω осуществляет сдвиг на величину log10 2 по часовой стрелке вдоль окружности. Обратное же преобразование осуществляет сдвиг на ту же величину, но в обратном направлении (против часовой стрелке). Так как мера Лебега не зависит от преобразования сдвига, то соотношение выше действительно имеет место. △
Теорема 5.4. Динамическая система M = (S1, B(S1), λ, T ) с преобразованием T (ω) = {α + ω}, ω ∈ S1, является эргодической тогда и
только тогда, когда число α иррационально.
Доказательство этой теоремы можно найти, например, в книгах [29, 55, 70]; мы же оставляем здесь только формулировку.
Определение 5.6. Динамическая система (Ω, F, µ, T ) обладает свойством перемешивания, если для любых A1, A2 ∈ F при n → ∞

µ

(︂ A1

⋂︂

T

)︂ −nA2

→

µ(A1)µ(A2).

Рассмотрим теперь порожденную динамической системой стационарную в узком смысле последовательность Xk(ω), k = 0, 1, 2, . . ..

118

Определение 5.7. Стационарная в узком смысле последовательность Xk(ω), k = 0, 1, 2, . . . обладает свойством слабой зависимости, если для любого k Xk и Xk+n асимптотически независимы при n → ∞, то есть для любых борелевских множеств B1, B2 при n → ∞:

µ (Xk ∈ B1, Xk+n ∈ B2) → µ(X0 ∈ B1)µ(X0 ∈ B2).

Стоит отметить, что в случае конечного второго момента Eξ2 < ∞ из свойства слабой зависимости следует свойство асимптотической некоррелированности: RX (n) → 0 при n → ∞. Для гауссовской меры эти понятия эквивалентны.
На самом деле, любая последовательность Xk(ω), k = 0, 1, 2, . . ., порожденная динамической системой обладает свойством слабой зависимости тогда и только тогда, когда динамическая система обладает свойством перемешивания.
Пример 5.5. Забегая немного вперед, заметим, что можно рассмотреть в качестве иллюстрации предыдущих определений конечную, неразложимую, апериодическую однородную марковскую цепь, на множестве состояний E. Это означает, что цепь «забывает» любое свое начальное распределение и сходится к стационарному распределению с положительными компонентами {πi}i∈E : при n → ∞

∑︂ P (Xn ∈ B|X0 = i) → π(B) = πj
j∈B

для любых i ∈ E и B ⊂ E. Положим начальное распределение равное инвариантному, тогда Xn, n = 0, 1, 2, . . . образует стационарный в узком смысле процесс. Несложно проверить, что Xn, n = 0, 1, 2, . . . обладает свойством слабой зависимости (а значит, порождающая цепь динамическая система – свойством перемешивания). Действительно, для любых подмножеств состояний B1, B2 ⊂ E выполнено при n → ∞

∑︂ P (X0 ∈ B1, Xn ∈ B2) = P (Xn ∈ B2|X0 = i) πi →
i∈B1
∑︂ → π(B2) πi = π(B1)π(B2). △
i∈B1

Определение 5.8. Динамическая система (Ω, F, µ, T ) обладает свой-

ством перемешивания в среднем, если для любых A1, A2 ∈ F при

n→∞

1

n
∑︂

(︂

⋂︂

)︂

µ A1 T −mA2 → µ(A1)µ(A2).

n

m=1

119

Определение 5.9. Стационарная в узком смысле последовательность Xk(ω), k = 0, 1, 2, . . . обладает свойством слабой зависимости в среднем, если для любых борелевских множеств B1, B2 при n → ∞:

1

n
∑︂

n µ (X0 ∈ B1, Xm ∈ B2) → µ(X0 ∈ B1)µ(X0 ∈ B2).

m=1

Аналогично предыдущему, любая последовательность Xk(ω), k =

0, 1, 2, . . ., порожденная динамической системой обладает свойством

слабой зависимости в среднем тогда и только тогда, когда динами-

ческая система обладает свойством слабой зависимости в среднем.

Пример 5.6. Пусть цепь из предыдущего примера 5.5 обладает

периодом d > 1. Тогда цепь уже не будет обладать свойством слабой

зависимости, но будет обладать свойством слабой зависимости в сред-

нем. △

Доказательство следующих теорем можно посмотреть в книге [7,

гл. 16, § 2].

Теорема 5.5. Динамическая система эргодична тогда и только то-

гда, когда она обладает свойством перемешивания в среднем.

Теорема 5.6. Динамическая система (Ω, F, µ, T ) эргодична тогда

и только тогда, когда для любого A ∈ F такого, что µ(A) > 0, выпол-

няется

(︄ ∞

)︄

µ ⋃︂ T −nA = 1,

n=0

что означает, что множества T −nA, n = 0, 1, 2, . . . «заметают» все пространство Ω.
Пусть Xk(ω) = ξ(T kω), k = 0, 1, 2, . . . – стационарная в узком смысле последовательность, порожденная динамической системой (Ω, F, µ, T ). Доказательство следующей теоремы можно посмотреть в [5, Теорема 1.3], или [7, гл. 16, § 3], [70, гл. V, § 3].
Теорема 5.7 (Биркгоф, Хинчин). Пусть E|ξ| < ∞, тогда µ−п.н. существует предел η, E|η| < ∞

1

n−1
∑︂

1

n−1
∑︂

lim

Xk(ω) = lim

ξ(T kω) = η(ω).

n→∞ n

n→∞ n

k=0

k=0

При этом Eη = Eξ и η – инвариантная случайная величина, то есть µ−п.н. выполнено
η(T ω) = η(ω).
Если к тому же динамическая система эргодична, то η = Eξ.

120

Другими словами, случайная величина η есть условное математическое ожидание случайной величины ξ относительно сигма-алгебры, порожденной инвариантными множествами. Если T эргодично, то такая сигма-алгебра тривиальна и тогда η равно константе, равной безусловному математическому ожиданию ξ.
Вместо доказательства теоремы 5.7 читатель может легко убедиться в более слабом утверждении.
Пример 5.7. Если динамическая система обладает свойством перемешивания, то для ξ(ω) = I{ω ∈ A}, где A ∈ F

1 n∑−︂1 I{T kω ∈ A} n
k=0

сходится по вероятности при n → ∞ к P(A). Схема доказательства: свойство перемешивания динамической системы эквивалентно свойству слабой зависимости для рассматриваемого процесса, откуда следует асимптотическая некоррелированность сечений этого процесса. Тогда дисперсия n1 ∑︁nk=−01 I{T kω ∈ A} стремится к нулю при n → ∞. Применяя неравенство Чебышева получаем нужное утверждение. △
Пример 5.8 Следствие теоремы 5.7. Если динамическая система эргодична, то для ξ(ω) = I{ω ∈ A}, где A ∈ F

1

n−1
∑︂

lim

I{T kω ∈ A} = P(A)µ-п.н. △

n→∞ n

k=0

Доказательство следующей теоремы можно посмотреть в [5, Теорема 2.1]
Теорема 5.8 (фон Нейман). Пусть ξ ∈ L2(Ω, F, µ), тогда существует η ∈ L2(Ω, F , µ),

1 n∑−︂1 k

L2

ξ(T ω) −−−−→ η(ω).

n k=0

N →∞

При этом Eη = Eξ и η – инвариантная случайная величина, то есть µ−п.н. выполнено
η(T ω) = η(ω).

Если к тому же динамическая система эргодична, то η = Eξ. Замечание 1. Интересно еще раз отметить, что в сравнении с
классическим усиленным законом больших чисел для независимых случайных величин, в случае стационарной последовательности предел в общем случае является случайной величиной (ср. с законом

121

больших чисел для стационарных в широком смысле последователь-

ностей). Случай, когда предел является константой является эргоди-

ческим.

Рассмотрим такой

Пример 5.9. Пусть Ω = {ω1, ω2, . . . , ωd}, d = 2l, мера µ – равномер-

ная, T ωi = ω(i+2) mod d. Несложно проверить, что такая динамическая

система не является эргодичной, так как множество A = {1, 3, 5, 2l −1}

будет инвариантным относительно T : A = T −1A, при этом µ(A) = 1/2.

Для любой ξ пределом суммы n1 ∑︁nk=−01 ξ(T kω) будет случайная вели-

чина

η

равновероятно

принимающая

два

значения:

1 l

∑︁l−1
j=0

ξ(2j

+

1),

если

ω

нечетное,

и

1 l

∑︁l
j

=1

ξ

(2j

),

если

ω

четное.

△

Еще раз резюмируем написанное выше. Следующие условия явля-

ются эквивалентными:

• Динамическая система является эргодической.

• Динамическая система обладает свойством перемешивания в среднем.

• Для любого A ∈ F такого, что µ(A) > 0, выполняется µ (⋃︁∞ n=0 T −nA) = 1.

• Любая последовательность, порожденная рассматриваемой динамической системой, обладает свойством слабой зависимости в среднем.

• Любая последовательность, порожденная рассматриваемой ди-

намической системой, с дополнительным условием Eξ2 < ∞ име-

ет непрерывную в нуле спектральную меру, а корреляционная

функция

имеет

нулевой

предел

(в

смысле

Чезаро):

1 n

∑︁n−1
k=0

RX (k)

→

0, n → ∞ (см. раздел 4.5).

Далее мы будем вместо ξ использовать f , как правило предполагая,

что функция f ∈ L2(Ω, F , µ).

Теперь рассмотрим один содержательный пример, который нам по-

требуется далее в этой главе. Пусть M = (Ω, F, µ, T ) — эргодическая

динамическая система. Рассмотрим функцию f ∈ L2(Ω, F, µ) и слу-

чайную последовательность {f (T kω)}∞ k=0. Заметим, что математическое ожидание величины f (T kω), ω ∈ Ω

не зависит от k и совпадает с математическим ожиданием величины

f (T 0ω) = f (ω), т.е.

ˆ

ˆ

f (T kω) dµ(ω) = f (ω) dµ(ω) = m.

Ω

Ω

122

Кроме того, по теореме фон Неймана

N

ˆ

1 ∑︂ f (T kω) −−L−2−→ m =

N

N →∞

k=1

Ω

f (ω′) dµ(ω′).

Итак, мы выяснили, что случайная последовательность {f (T kω)} име-

ет постоянное математическое ожидание, а ее среднее по времени схо-

дится к среднему по пространству (т.е. по мере). Напомним, что ана-

логичным образом было дано определение эргодичности по математи-

ческому ожиданию случайного процесса с непрерывным временем (см.

определение 5.1).

Приведем теперь ряд задач, которые могут быть решены с помо-

щью изложенных выше фактов теории эргодических динамических

систем.

Пример 5.10 (псевдослучайная последовательность). Вер-

немся к динамической системе из примера 5.4. Введем случайную по-

следовательность Xk(ω) = T kω, ω ∈ Ω = S1, k ≥ 1, µ – равномерная

мера (Лебега) на S1, что можно понимать, как ω ∈ R[0, 1]. Пока-

жем, что для каждого k случайная величина Xk имеет равномерное на

отрезке [0, 1] распределение. Рассмотрим множество B = {ω : ω < x},

x ∈ (0, 1). Тогда T −kB = {T −kω : ω < x} = {ω′ : T kω′ < x}. Но так как

µ(T −kB)

=

= µ(B), то µ({ω : Xk(ω) < x}) = µ({ω : ω < x}) = x, т.е. функция рас-

пределения случайной величины Xk равна FXk (x) = x на интервале

(0, 1). Очевидно, что FXk (x) = 0 при x ≤ 0 и FXk (x) = 1 при x ≥ 1. Сле-

довательно, Xk имеет равномерное распределение на отрезке [0, 1]. Бо-

лее того, аналогичным образом можно показать, что случайный про-

цесс {Xk}k≥1 – стационарный в узком смысле. При этом случайные

величины {Xk}k≥1 не будут независимыми! △

Пример 5.11 (метод Монте-Карло). Пусть дана интегрируе-

гмрааялн´а1оfт(рyе)зdкyе. Р[0а,с1с]мфотурникмципяоfсл=едfо(вxа)теильтнроесбтуьетнсеязаввыичсиисмлыихтьодииннтае--
0
ково распределенных случайных величин {Xk}k≥1 из распределения

R(0, 1). Тогда последовательность {f (Xk)} также будет состоять из

независимых одинаково распределенных случайных величин и, в силу

усиленного закона больших чисел,

N

ˆ1

1 ∑︂

п.н.

f (Xk) −−−−→ Ef (X1) = f (y) dy.

(40)

N

n→∞

k=1

0

Это значит, что среднее арифметическое чисел f (Xk) может служить

123

оценкой для искомого интеграла и чем выше N , тем ближе (на множестве исходов единичной меры) будет значение оценки к истинному значению интеграла.
Получить на практике по настоящему независимые одинаково распределенные на отрезке [0, 1] случайные величины, в свою очередь, представляет собой сложную задачу. Поэтому, как правило, используют «псевдослучайные последовательности». В качестве такой последовательности можно взять стационарную последовательность {Xk} из примера 5.10. Согласно эргодической теореме Биркгофа–Хинчина для почти всех точек старта ω ∈ [0, 1] будет иметь место формула (40), в которой сходимость почти наверное по равномерной мере µ как раз и понимается с точки зрения выбора ω ∈ [0, 1]. Впрочем, для сдвига окружности эти оговорки несущественны, см. следующий пример. △
Пример 5.12 (задача Вейля). Рассмотрим последовательность степеней двойки 2k, k ∈ N. Зададимся вопросом: как часто встречается цифра m ∈ {1, . . . , 9} в качестве первой цифры степени двойки?
Пусть ak – первая цифра числа 2k, тогда найдется целое r, такое, что 2k = ak · 10r + bk, где bk < 10r. Отсюда следует, что

log

2k = log

a + r + log

(︃ 1+

bk

)︃ ,

10

10 k

10

ak 10r

и, следовательно,

{log

{︃ 2k} = log

a + log

(︃ 1+

bk

)︃}︃ ,

10

10 k

10

ak 10r

где фигурные скобки обозначают дробную часть числа. Заметим, что выражение, которое стоит справа под фигурными скобками, не превышает единицы, поэтому фигурные скобки можно убрать:

{log

2k} = log

a + log

(︃ 1+

bk

)︃ .

10

10 k

10

ak 10r

Пусть ak = m, тогда log10 ak = log10 m, а

(︃

bk )︃ [︃

(︃ 1 )︃)︃

log10 1 + ak10r

∈

0, log10

1+ m

,

т.к. bk лежит в интервале [0, 10r). Это значит, что если ak = m, то {log10 2k} ∈ [log10 m, log10(m + 1)). Нетрудно установить и обратное: из {log10 2k} ∈ [log10 m, log10(m + 1)) следует ak = m.
Пусть Ω = S1 — окружность единичной длины на плоскости; как и
прежде, будем пользоваться ее гомеоморфностью отрезку [0, 1], концы

124

которого отождествлены. Пусть F = B — борелевская σ-алгебра на S1, µ — классическая мера Лебега на S1, T (x) = {log10 2 + x}. Как следует из теоремы 5.4, M = (Ω, F, µ, T ) является эргодической динамической
системой. Введем квадратично интегрируемую функцию

f (x) = {︃ 1, x ∈ [log10 m, log10(m + 1)), 0, x ∈/ [log10 m, log10(m + 1)).

Тогда согласно теореме Биркгофа–Хинчина:

N

ˆ

(︃

)︃

1 ∑︂ f (T kx) −µ−-−п−.н→. f (ω) dµ(ω) = log

1 1+ .

N

N →∞

10

m

k=1

Ω

Заметим, что теорема устанавливает лишь сходимость почти наверное. Из нее не следует сходимость, например, при x = 0. Однако для сдвигов по окружности верен и более сильный результат:

N

ˆ

(︃

)︃

1 ∑︂ f (T kx) −в−с−ю−д→у f (ω) dµ(ω) = log

1 1+ .

N

N →∞

10

m

k=1

Ω

Этот факт, как и его доказательство, можно найти в книге [55] (см. лек-

цию 3). Значит, сходимость имеет место в том числе и для x = 0.

Но

T k0

=

{log10

2k },

поэтому

сумма

∑︁N
k=1

f (T kx)

представляет

собой

не что иное, как количество степеней двойки, начинающихся с циф-

ры m. Получается, что в пределе доля единиц среди первых цифр

будет равна log10 2, доля двоек будет равна log10(3/2), доля троек –

log10(4/3), и т.д. △

Пример 5.13 (Гаусс–Гильден–Виман–Кузьмин). Рассмотрим

цепную дробь для числа ω ∈ [0, 1):

1

ω=

,

1

a1(ω) + 1

a2(ω) + a3(ω) + . . .

где (a1(ω), a2(ω), . . .) будем называть цепным разложением числа ω, а ak(ω) – k-м основанием числа ω. Известно, что если ω – рациональное число, то его цепное раз√ложение конечно. Если ω – квадратичная иррациональность, т.е. ω = α для рационального α, то цепное разложение числа ω периодично. Оказывается, что для любого заданного натурального числа m для почти всех (по мере Лебега на [0, 1]) чисел

125

на [0, 1) частота встречаемости m в цепном разложении будет одной и

той же.

Для того чтобы это показать, рассмотрим динамическую систему

M = (Ω, B, µ, T ), где Ω = [0, 1), B – борелевская σ-алгебра на [0, 1), мера

µ определяется как

1 dx

dµ(x) =

,

ln 2 1 + x

а преобразование T (ω) = {1/ω}, ω ∈ Ω. Мы опускаем доказательство того, что эта система является дина-
мической, как и то, что она является эргодической. Теперь заметим, что отображение T удаляет первый элемент цеп-
ного разложения, т.е. если

1

ω=

,

1

a1(ω) + 1

a2(ω) + a3(ω) + . . .

то

1

T (ω) =

.

1

a2(ω) + 1

a3(ω) + a4(ω) + . . .

Кроме того, легко видеть, что

(︃ 1 1 ]︃ a1(ω) = m ⇔ ω ∈ m + 1 , m .

Это значит, что

ak(ω) = m ⇔ T kω ∈ (︃ m 1+ 1 , m1 ]︃ .

Остается рассмотреть квадратично интегрируемую функцию:

f (x) = {︃ 1, x ∈ (1/(m + 1), 1/m], 0, x ∈/ (1/(m + 1), 1/m],

и тогда по теореме Биркгофа–Хинчина

N

ˆ1

1 ∑︂ f (T kω) −µ−−−п−.н→. f (x) dµ(x) =

N

n→∞

k=1

0

126

ˆ1 m
=
1 m+1

1 dx

(︃

1 )︃

ln 2 · 1 + x = log2

1+ m(m + 2)

.

Это и значит, что для почти всех ω ∈ [0, 1) частота встречаемости числа m ∈ N в цепном разложении ω не зависит от ω и равна

(︃

1 )︃

log2

1+ m(m + 2)

.△

127

6. Дискретные цепи Маркова

6.1. Базовые определения и примеры

Рассмотрим случайную последовательность {ξk} = {ξ0, ξ1, . . . }, компоненты которой могут принимать лишь конечное или счетное множество значений, например:

E = {0, 1, 2, . . . }, |E| ≤ ∞.

Такие случайные последовательности будем называть дискретными цепями (ДЦ ), множество E – множеством состояний, а его элементы – состояниями (дискретными, так как время дискретно; цепями, так как множество состояний тоже дискретно). Если множество состояний конечно, т.е. |E| < ∞, то цепь называют конечной. Термин цепь обосновывает дискретность множества состояний, а прилагательное дискретная цепь относится ко времени (время тоже принимает дискретные значения).
Определение 6.1. Дискретная цепь {ξk} называется дискретной цепью Маркова или дискретная марковская цепь (ДМЦ ), если равенство

P(ξn = xn | ξn−1 = xn−1, . . . , ξ0 = x0) = P(ξn = xn | ξn−1 = xn−1) (41)

выполнено для любых n ≥ 1 и всех состояний x0, . . . , xn ∈ E, для которых указанные условные вероятности существуют.
Свойство (41) также называют марковским свойством. Случайная величина ξn характеризует состояние цепи в момент времени n ≥ 0, поэтому событие {ξn = j} читается как «на шаге n цепь находится в состоянии j ∈ E».
Определение 6.2. Число pk,j(n) = P(ξn = j | ξn−1 = k) называется вероятностью перехода из состояния k ∈ E в состояние j ∈ E за один шаг в момент n ≥ 1. Числа pk,j(n) образуют переходную матрицу

⎡ p0,0(n) ⎢ p1,0(n) P (n) = ⎢⎢⎣ ...

p0,1(n) · · · ...

p0,N (n) ⎤
⎥ ⎥, ⎥ ⎦

pN,0(n)

pN,N (n)

где N = |E| − 1 ≤ ∞. Сумма компонент произвольной переходной матрицы в любой строке равна единице, т.е.

∀k ∈ E

N
∑︂ pk,j = 1.
j=0

128

Определение 6.3. Если P (n) не зависит от n, то соответствующую цепь называют однородной. Для краткости будем писать ОДМЦ.
Определение 6.4. Вероятность pk(n) = P(ξn = k), k ∈ E, называется вероятностью состояния k в момент n ≥ 0. Вектор
p(n) = [p0(n), p1(n), . . . ]⊤

называют распределением вероятностей состояний в момент n ≥ 0. Следующие две теоремы являются прямыми следствиями формулы
полной вероятности и марковского свойства цепи. Теорема 6.1. Распределение вероятностей состояний p(n) связа-
но с распределением вероятностей состояний p(n − 1) соотношением
p(n) = P ⊤(n)p(n − 1),

где P (n) – матрица перехода на шаге n ≥ 1. Если цепь однородная, то
p(n) = (︁P ⊤)︁n p(0).

Доказательство. Выразим вероятность pi(n) оказаться в состоянии i на n-м шаге через p(n − 1) и переходную матрицу в момент времени n. По формуле полной вероятности

∑︂

∑︂

pi(n) = P(ξn = i | ξn−1 = j)P(ξn−1 = j) = pj,i(n)pj(n − 1).

j∈E

j∈E

Если записать равенство выше в матричной форме, то получим p(n) = P ⊤(n)p(n − 1),

что и требовалось доказать. В случае, когда марковская цепь однородна, имеем P (n) = P и p(n) = P ⊤p(n − 1) = (︁P ⊤)︁2 p(n − 2) = . . . = = (︁P ⊤)︁n p(0). □
Введем следующее обозначение. Вероятность перехода за n шагов
из состояния k ∈ E в состояние j ∈ E для однородной марковской цепи
обозначим символом

pk,j(n) = P(ξn = j | ξ0 = k), n ≥ 1,

где E – множество состояний. Теорема 6.2(уравнение Колмогорова–Чэпмена). Для ОДМЦ
(однородной дискретной марковской цепи) для любых n, m ≥ 1 справедливо равенство

∑︂ pi,j (n + m) = pi,k(n)pk,j (m).
k∈E

129

Доказательство. Из теоремы 6.1 следует, что pk,j(n) — это элемент матрицы P n, стоящий в k-й строке и j-м столбце. Если записать равенство P n+m = P nP m покомпонентно, то получим

∑︂ pi,j (n) = pi,k(n)pk,j (m).
k∈E

Это же равенство можно доказать через формулу полной вероятности. Действительно, так как любая траектория из n + m шагов из i-го состояния в j-е через n шагов окажется в некотором состоянии k, а потом из этого состояния через m шагов попадет в j, то достаточно рассмотреть все возможные состояния k (воспользоваться формулой полной вероятности):

pi,j(n + m) = P(ξn+m = j | ξ0 = i) =

∑︂ = P(ξn+m = j | ξn = k, ξ0 = i)P(ξn = k | ξ0 = i) =

k∈E

∑︂ = P(ξn+m = j | ξn = k) P(ξn = k | ξ0 = i) .

k∈E ⏞

⏟⏟
pk,j (m)

⏞⏞

⏟⏟

⏞

pi,k (n)

Последнее равенство следует из марковского свойства цепи. □ Дискретные цепи удобно представлять в виде стохастического гра-
фа. Это ориентированный граф, в вершинах которого расположены состояния цепи, а веса ребер между состояниями равны вероятностям перехода за один шаг между этими состояниями. Рассмотрим, к примеру, стохастический граф

Ему соответствует матрица переходов P = [︃ 1/2 1/2 ]︃ . 10
Пусть начальное распределение p(0) = [0, 1]⊤. Это значит, что в момент времени n = 0 цепь находится в состоянии 0 с вероятностью 0 и
130

в состоянии 1 с вероятностью 1. Найдем распределение на следующем

шаге:

[︃ p(1) = P ⊤p(0) =

1/2

1 ]︃ [︃ 0 ]︃ = [︃ 1 ]︃ .

1/2 0 1

0

Еще через шаг распределение станет таким:

[︃ p(2) = P ⊤p(1) =

1/2

1 ]︃ [︃ 1 ]︃ = [︃ 1/2 ]︃ .

1/2 0 0

1/2

А еще через шаг таким:

[︃ p(3) = P ⊤p(2) =

1/2

1/2

1 ]︃ [︃ 1/2 ]︃ = [︃ 3/4 ]︃ .

0 1/2

1/4

Попробуем теперь вычислить распределение в произвольный момент времени, т.е. π(n), n ≥ 0. Для этого воспользуемся следующим соображением: если матрица A может быть представлена в виде A = SDS−1, где D – диагональная матрица, то An = SDnS−1. Иногда это удается сделать, решив задачу на собственные числа и векторы матрицы A. Так как в нашем случае
p(n) = (︁P ⊤)︁n p(0),

то попробуем найти собственные числа и собственные векторы матрицы P ⊤:

⃓ ⃓ 1/2 − λ

1

⃓ ⃓

=

λ2

−

1 λ

−

1

=

0

⇒

λ

= 1, λ

1 =− .

⃓

⃓

⃓ 1/2 −λ ⃓

22

1

2

2

Стоит отметить, что у стохастической матрицы единица всегда является собственным значением (см. далее). Еще одно собственное значение можно найти из следа матрицы.
При λ = 1 получаем

P ⊤ − λI

[︃ =

−1/2

1 ]︃ ,

1/2 −1

откуда собственный вектор v1 = [2, 1]⊤. При λ = −1/2 получаем

[︃ P ⊤ − λI =

1

1 ]︃ ,

1/2 1/2

откуда собственный вектор v2 = [1, −1]⊤. Значит, в нашем случае

P⊤

[︃ =

2

1 ]︃ [︃ 1

0 ]︃ [︃ 2

1 ]︃−1 .

1 −1 0 −1/2 1 −1

⏞ ⏟⏟ ⏞ ⏞ ⏟⏟ ⏞ ⏞ ⏟⏟ ⏞

S

D

S−1

131

Далее

(︁ ⊤)︁n [︃ 2 1 ]︃ [︃ 1

0 ]︃ [︃ 2 1 ]︃−1

P = 1 −1 0 (−1/2)n 1 −1 =

1 [︃ 2 + (−1/2)n 2 − 2(−1/2)n ]︃

= 3

1 − (−1/2)n 1 + 2(−1/2)n

.

Итак, мы получили, что для p(0) = [0, 1]⊤ распределение на шаге n ≥ 0

1 [︃ 2 − 2(−1/2)n ]︃

p(n) = 3

1 + 2(−1/2)n

.

Заметим, что при n → ∞

(︁P ⊤)︁n

[︃ →

2/3

1/3

2/3 ]︃ . 1/3

Поэтому, если взять произвольное начальное распределение p(0) = = [p0(0), p1(0)], то в пределе

p(n) → [︃ 2/3 2/3 ]︃ [︃ π0(0) ]︃ = [︃ 2/3 ]︃ ,

1/3 1/3 π1(0)

1/3

так как p0(0) + p1(0) = 1. Это значит, что в каком бы состоянии не находилась цепь изначально и каким бы ни было начальное распределение вероятностей состояний, в пределе вероятность оказаться в состоянии 0 равна 2/3, а в состоянии 1 она равна 1/3. Это проявление эргодичности цепи, строгое определение и свойства будут даны позднее.
Теперь несколько слов о матрице перехода P . Как уже было сказано, сумма компонент в каждой ее строке равна единице, и каждая ее компонента неотрицательна и не превышает единицу. Матрицы с такими свойствами называются стохастическими. Общих свойств таких матриц крайне мало, вот одно из них [30], [45].
Теорема 6.3. Матрицы P и P ⊤ всегда имеют собственное зна-
чение, равное 1. Остальные собственные значения по модулю не пре-
восходят 1. Доказательство. Так как сумма компонент матрицы P в каждой
ее строке равна 1, то достаточно взять вектор 1 = [1, . . . , 1]⊤ и увидеть, что
P 1 = 1.
Значит, матрица P имеет собственное значение λ = 1, а соответствующий собственный вектор равен 1. Отсюда следует, что и матрица P ⊤

132

имеет собственное значение λ = 1, так как детерминанты произвольной матрицы и ее транспонированной совпадают:

det(P − λI) = det(P − λI)⊤ = det(P ⊤ − λI) = 0.

То есть характеристические многочлены совпадают, а значит, и набор собственных значений матриц P и P ⊤ совпадает. Отметим, что вектор 1 не обязан быть собственным вектором матрицы P ⊤. Теперь предположим, что нашлось собственное значение λ матрицы P ⊤ с |λ| > 1, а v – соответствующий собственный вектор. Но тогда (︁P ⊤)︁n v = λnv и
правая часть растет экспоненциально с ростом n. Следовательно, найдется элемент матрицы (︁P ⊤)︁n, который превышает 1, но это невозможно, так как матрица (︁P ⊤)︁n = (P n)⊤ равна транспонированной стохастической матрице5, элементы которой не могут превышать 1.
Мы пришли к противоречию, значит, для всех собственных значений
λ выполнено |λ| ≤ 1. □ Попытки простым способом описать общие свойства матриц P ⊤
встречают серьезное сопротивление. Это подтверждают следующие
примеры. а) Матрица P ⊤ может быть вырожденной:

P⊤

[︃ =

0

0 ]︃ .

11

б) Матрица P ⊤ может иметь отрицательные собственные значения и отрицательный детерминант:

P⊤

[︃ =

0

1 ]︃ .

10

в) Матрица P ⊤ может иметь комплексные собственные значения и быть ортогональной (P ⊤ = P −1):
⎡0 1 0⎤ P⊤ = ⎣ 0 0 1 ⎦.
100

г) Кратность собственного значения λ = 1 может быть больше еди-

ницы:

P⊤

[︃ =

1

0 ]︃ .

01

5Если P – стохастическая матрица, то и P n – стохастическая матрица. Матрица P n есть матрица перехода за n шагов и состоит из соответствующих условных

вероятностей.

133

д) Не всякая матрица P ⊤ диагонализуема, например,
⎡ 5/12 1/4 1/3 ⎤ P ⊤ = ⎣ 5/12 1/4 1/3 ⎦ .
1/6 1/2 1/3

6.2. Классификация состояний
Перейдем теперь к классификации состояний однородной дискретной цепи Маркова. Напомним, что вероятность перехода за n шагов из состояния k ∈ E в состояние j ∈ E мы обозначили символом

pk,j(n) = P(ξn = j | ξ0 = k), n ≥ 0,

где E – множество состояний. Введем также обозначение для вероятности первого возвращения за n шагов в состояние k ∈ E:

fk(n) = P(ξn = k, ξn−1 ̸= k, . . . , ξ1 ̸= k | ξ0 = k), n ≥ 1,

и вероятность возвращения в k ∈ E за конечное число шагов:

∞

∑︂

Fk = fk(n).

(42)

n=1

Замечание. Вероятности pk,k(n) и fk(n) не обязаны совпадать. Вероятность fk(n) – это вероятность первого возвращения из k в k (при условии, что цепь вышла из состояния k). Вероятность же pk,k(n) подсчитывается с учетом того, что на промежуточных шагах цепь может находиться в состоянии k. В общем случае

n

n−1

∑︂

∑︂

pk,k(n) = fk(m)pk,k(n − m) = fk(n) + fk(m)pk,k(n − m) ≥ fk(n).

m=1

m=1

6.2.1. Классификация состояний на основе арифметических свойств pi,j(n)
Определение 6.5. Состояния k, j ∈ E называются сообщающимися, если
(∃m ≥ 1 : pk,j(m) > 0) ∧ (∃n ≥ 1 : pj,k(n) > 0) .
Иначе состояния k, j ∈ E называются несообщающимися:
(∀m ≥ 1 : pk,j(m) = 0) ∨ (∀n ≥ 1 : pj,k(n) = 0) .

134

Определение 6.6. Состояние k ∈ E называется несущественным, если
∃j ∈ E : (∃m ≥ 1 pk,j(m) > 0) ∧ (∀n ≥ 1 pj,k(n) = 0) .
Иначе состояние k ∈ E называется существенным:
∀j ∈ E ((∀m ≥ 1 pk,j(m) = 0) ∨ (∃n ≥ 1 pj,k(n) > 0)) .
Определение 6.7. Пусть ∃n0 ≥ 1 : pk,k(n0) > 0 и dk – наибольший общий делитель чисел
{n ≥ 1 : fk(n) > 0}.
Тогда если dk > 1, то состояние k называется периодическим с периодом dk. Если же dk = 1, то состояние k называется апериодическим.
Определение 6.8. Пусть ∃n0 ≥ 1 : pk,k(n0) > 0 и dk – наибольший общий делитель чисел
{n ≥ 1 : pk,k(n) > 0}.
Тогда если dk > 1, то состояние k называется периодическим с периодом dk. Если же dk = 1, то состояние k называется апериодическим.
Со схемой доказательства следующей теоремы можно познакомиться в абзаце после определения 1.6 на с. 361 в [7].
Теорема 6.4. Определения 6.7 и 6.8 эквивалентны. Замечание. Если состояние несущественное, то найдется состояние, с которым оно не сообщается. Если все состояния цепи сообщающиеся, то все они существенные. В конечной цепи всегда есть существенное состояние. Оно может быть одно. В бесконечной цепи может не быть существенных состояний (см. пример 6.1 ниже). Замечание. Понятие периодичности вводится только для состояний, для которых ∃n0 ≥ 1 : pk,k(n0) > 0. Введем следующие обозначения. Если для какого-то m ≥ 1 вероятность pi,j(m) > 0, то будем писать i → j (состояние j следует за i). Если для любого m ≥ 1 вероятность pi,j(m) = 0, то будем писать i ̸→ j. Кроме того, если i → j и j → i, то будем писать i ↔ j. По определению, состояния i и j называются сообщающимися, если i ↔ j. Состояние i несущественное, если ∃j ∈ E : (i → j) ∧ (j ̸→ i). Отношение i ↔ j является отношением эквивалентности (действительно, 1) i ↔ i, так как pi,i(0) = 1, 2) из i ↔ j следует j ↔ i, 3) если i ↔ j и j ↔ k, то i ↔ k). Таким образом, все множество состояний разбивается на классы эквивалентности. При этом может оказаться, что некоторые классы эквивалентности будут замкнутые (то есть из
135

них нельзя с положительной вероятностью выйти), а некоторые – открытые (см. рис. 5). Состояния, принадлежащие открытым классам эквивалентности, будем называть несущественными, а из замкнутых – существенными (см. другое определение 6.6). В конечной цепи всегда найдется хотя бы один замкнутый класс эквивалентности. В случае счетной цепи (то есть с бесконечным числом состояний) может не оказаться замкнутого класса эквивалентности. Так, в примере 6.1 каждое состояние образует открытый класс эквивалентности (из одного состояния) и число классов бесконечно. Если замкнутый класс состоит из одного состояния, то такое состояние называют поглощающим. Если есть только один класс эквивалентности (он автоматически замкнут), то цепь называют неразложимой (см. другое определение 6.12 ниже).
Рис. 5. Граф конечной марковской цепи с одним открытым классом эквивалентности и тремя замкнутыми.
Классификация состояний внутри класса эквивалентности одинакова для всех состояний из этого класса (см. далее теорему 6.8 о солидарности).
Разбиение множества состояний на классы эквивалентности приводит к блочной структуре матрицы переходных вероятностей, если правильно занумеровать состояния (см. рис. 6). На диагонали будут стоять квадратные блоки, отвечающие за вероятности перехода внутри замкнутых классов эквивалентности (если такие есть). Из замкнутости класса следует, что остальные вероятности перехода (вне диагонального блока) суть нули. Для состояний из открытых классов эквивалентности блочная структура немного сложнее: вне диагонали в общем случае стоят не нули, а вероятности перехода в состояния из других классов.
136

несущественные состояния

нули

P1

нули

нули

P2

нули

P=

нули

P3

Рис. 6. Блочная структура матрицы переходных вероятностей P c тремя замкнутыми классами эквивалентности. Здесь P1, P2, P3 — неразложимые квадратные матрицы, стоящие на диагонали общей матрицы P , соответствующие вероятностям перехода внутри трех замкнутых классов, блок «несущественные состояния» соответствует либо вероятностям перехода из несущественных состояний в состояния из замкнутых классов эквивалентности, либо вероятностям остаться в этом открытом классе, блоки «нули» — матрицы правильных размеров, состоящие из одних нулей
Пусть имеется замкнутый класс эквивалентности с периодом d > 1 и подмножеством состояний E∗. Тогда существует d групп состояний C0, C1, . . . , Cd−1 (так называемых циклических подклассов): E∗ = ∪dj=−01Cj , если Xn ∈ Cm, то для любого целого l Xn+l ∈ C(m+l) mod d, см. рис. 7.
Если перенумеровать состояния, перечислив последовательно состояния из C0, C1, . . . , Cd−1, то подматрица переходных вероятностей, соответствующая данному замкнутому классу состояний, будет иметь вид, как на рис. 8.
Замечание. Если такую матрицу возвести в степень d, то новая матрица P˜ = P d будет блочно-диагональной. Если рассмотреть ОДМЦ с матрицей переходных вероятностей P˜, то она является разложимой и имеет d замкнутых апериодических классов эквивалентности C0, C1, . . . , Cd−1. Таким образом, при исследовании асимптотического поведения pi,j(n) можно сразу предполагать, что цепь неразложима и апе-
137

риодична.

Рис. 7. Диаграмма движения по циклическим подклассам. На диаграмме i-я вершина соответствует подклассу Ci. Из вершин подкласса C0 можно попасть только в вершины подкласса C1, . . . , из вершин подкласса Cd−1 можно попасть только в вершины подкласса C0

нули

C0

нули

нули

C1

нули

нули C2

C3

нули

Рис. 8. Блочная структура подматрицы переходных вероятностей, соответствующей замкнутому классу эквивалентности с четырьмя циклическими подклассами. Здесь блок Ci содержит вероятности переходов из вершин подкласса Ci в вершины подкласса Ci+1 mod 4, блоки «нули» — матрицы правильных размеров, состоящие из одних нулей
138

6.2.2. Классификация состояний на основе асимптотических свойств pi,i(n)

Определение 6.9. Состояние k ∈ E называется нулевым, если существует
lim pk,k(n) = 0.
n→∞
Если указанный предел не существует или не равен нулю, то состояние k называется ненулевым.
Определение 6.10. Состояние k ∈ E называется возвратным, если вероятность возвращения за конечное число шагов Fk (см. (42)) равна единице. Иначе состояние k называется невозвратным.
Определение 6.11. Состояние k ∈ E называется возвратным, если ⎛ ⎞
∞⃓ ⋂︂ ⋃︂ P ⎝ {ξn = k} ⃓⃓ ξ0 = k⎠ = 1
m=1 n≥m

Если же эта вероятность равна нулю, то состояние k называется невоз-

вратным.

Заметим,

что

⋂︁∞
m=1

⋃︁n≥m{ξn

=

k}

означает,

что

цепь

бесконечно

часто возвращается в состояние k. Это событие из остаточной сигма-

алгебры, а значит, по теореме Колмогорова «закон нуля или единицы»

рассматриваемая вероятность не может принимать промежуточных

значений.

Доказательство следующей теоремы можно найти в [66] (следствие

теоремы 4.3, с. 39).

Теорема 6.5. Определения 6.10 и 6.11 эквивалентны.

Теорема 6.6 (критерий возвратности). Состояние j ∈ E явля-

ется возвратным тогда и только тогда, когда расходится ряд

∞
∑︂ Pj = pj,j(n) = ∞.
n=1

При этом для невозвратного состояния

Fj = Pj . 1 + Pj

Замечание. Данная теорема является обобщением леммы Бореля–

Кантелли. Напомним, что если события An, n ≥ 1 являются незави-

симыми,

то

расходимость

ряда

∑︁∞
n=1

P

(An

)

эквивалентна

тому,

что

события An происходят бесконечно часто с вероятностью 1. Рассмат-

риваемая теорема обобщает ситуацию, когда события An «слабо» зави-

симы: если j – фиксированное состояние, то пусть An означает, что на

139

n-м шаге цепь возвращается в j-е состояние. Тогда расходимость ряда

∑︁∞
n=1

P (An)

=

∑︁∞
n=1

pj,j (n)

эквивалентна

тому,

что

с

вероятностью

1

цепь бесконечно часто возвращается в состояние j, то есть состояние

j – возвратное.

Доказательство. Из формулы полной вероятности и марковского

свойства цепи получаем, что

n
∑︂ pj,j(n) = fj(n − k)pj,j(k).
k=0

Заметим, что данное выражение напоминает формулу для коэффициента многочлена, равного произведению двух многочленов. Развивая эту идею, рассмотрим два степенных ряда:

∞
V (z) = ∑︂ pj,j(k)zk,
k=0

∞
U (z) = ∑︂ fj(k)zk.
k=0

Тогда в силу того, что fj(0) = 0 и pj,j(0) = 1, получим, что

1

V (z) − 1 = U (z)V (z) =⇒ V (z) =

.

1 − U (z)

Заметим, что U (1) = Fj — вероятность возвращения за конечное число
шагов, а ряд V (z) сходится при всех |z| < 1 (при этом формально
∞
V (1) = ∑︁ pj,j(n) = 1 + Pj). Переходя к пределу при z → 1 − 0 в
полученнnо=м0 равенстве, приходим к следующему условию:

Fj = 1 (состояние возвратно) ⇐⇒ Pj = ∞.

Если Fj < 1 (состояние невозвратно), то мы дополнительно доказали соотношение: Fj = VV(1()1−) 1 = 1+PPj j . □
Из необходимого условия сходимости ряда получаем следующее следствие.
Следствие. Если состояние является невозвратным, то оно ну-
левое. Если состояние ненулевое, оно является возвратным.
Ниже мы вернемся к связям между нулевыми/ненулевыми и возвратными/невозвратными состояниями и увидим, что ситуации сильно отличаются в зависимости от конечности или счетности числа состояний.
Теорема 6.7. Несущественное состояние невозвратно.
С доказательством можно познакомиться в [66, теорема 4.4, с. 39].

140

Определение 6.12. Цепь Маркова называется неразложимой, если все ее состояния являются сообщающимися. В противном случае цепь называется разложимой.
Теорема 6.8 (свойство солидарности). Для неразложимой
ОДМЦ справедливо, что

а) если хотя бы одно состояние возвратное, то все состояния возвратные,

б) если хотя бы одно состояние нулевое, то все состояния нулевые,

в) если хотя бы одно состояние имеет период d > 1, то все остальные состояния периодичные с периодом d; если хотя бы одно состояние апериодично, то все состояния апериодичны.

Доказательство.

а) Пусть нашлось состояние i, являющееся возвратным. Из крите-

рия

возвратности

следует,

что

это

равносильно

тому,

что

∑︁∞
n=1

pi,i

(n)=

= ∞. Рассмотрим произвольное состояние j ̸= i и покажем, что оно то-

же является возвратным. Из неразложимости следует, что существуют

такие числа L и M , что pj,i(L) > 0 и pi,j(M ) > 0. Поэтому

∞

∞

∑︂

∑︂

pj,j(n) ≥ pj,j(L + n + M ) ≥

n=1

n=1

∞

∞

∑︂

∑︂

≥ pj,i(L)pi,i(n)pi,j (M ) = pj,i(L)pi,j (M ) pi,i(n) = ∞,

n=1

n=1

а значит, j тоже является возвратным.

б) Рассмотрим два произвольных состояния i, j ∈ S. Из неразложимости следует, что существуют такие числа L и M , что pj,i(L) > 0 и pi,j(M ) > 0. Если состояние j — нулевое, то из неравенства

pj,j (L + n + M ) ≥ pj,i(L)pi,i(n)pi,j (M )
следует, что pi,i(n) −n−→−−∞→ 0, т.е. i тоже является нулевым. Если же j не является нулевым, то из неравенства

pi,i(M + n + L) ≥ pi,j (M )pj,j (n)pj,i(L)

следует, что pi,i(M + n + L) не стремится к нулю при n → ∞, т.е. i тоже не является нулевым.

141

в) Рассмотрим два произвольных состояния i, j ∈ S. Из неразло-

жимости следует, что существуют такие числа L и M , что pj,i(L) > 0

и pi,j(M ) > 0. Пусть {n : pi,i(n) > 0} = {ni1, ni2, ni3, . . .} и {n : pj,j(n) >

>

0}

=

{

n

j 1

,

nj2

,

nj3

,

.

.

.},

причем

НОД

первого

множества

равен

di,

а НОД второго – dj. Заметим, что из неравенств pi,i(M + L) ≥

≥ pi,j(M )pj,i(L) > 0 и pj,j(M + L) ≥ pj,i(L)pi,j(M ) > 0 следует, что

M +L лежит в обоих множествах, а значит, M +L делится на di и на dj.

Кроме того, для любого числа nik выполняется pj,j(L + nik + M ) ≥ ≥ pj,i(L)pi,i(nik)pi,j(M ) > 0, а значит, nik + M + L делится на dj. Но, поскольку M + L тоже делится на dj, заключаем, что и nik делится на dj,

причем это верно для всех k. Отсюда следует, что для всех k числа

nik делятся на dj, а значит, dj ≤ di, ведь di — наибольший общий делитель чисел nik. Аналогичными рассуждениями можно показать, что для всех k числа njk делятся на di, а значит, di ≤ dj. В результате по-

лучили, что dj ≤ di и di ≤ dj, т.е. di = dj. Это означает, что периоды у

всех состояний цепи одинаковы (в силу произвольности выбора i и j).

□

Отметим, что предыдущая теорема доказана без использования предположения о конечности цепи.
Теорема 6.9. В неразложимой конечной ОДМЦ все состояния ненулевые (а значит, и возвратные).
Доказательство. Докажем теорему от противного. Пусть состояние i является нулевым: limn→∞ pi,i(n) = 0. Для произвольного состояния j ̸= i из условия неразложимости цепи найдется такое N = N (i, j), что pj,i(N ) > 0. Тогда в следующей сумме из неотрицательных слагаемых оставим только одно, получив оценку снизу:

∑︂ pi,i(n + N ) = pi,k(n)pk,i(N ) ≥ pi,j (n)pj,i(N ).
k∈E

С учетом нашего предположения limn→∞ pi,i(n) = 0 и pj,i(N ) > 0 по-

лучаем, что limn→∞ pi,j(n) = 0, или, иначе говоря, для любого ε > 0

найдется Mε = Mε(i, j), что для любого n > Mε pi,j(n) < ε. Но тогда

из условия конечности цепи существует M¯ε = maxj∈E Mε(i, j), что для

любого

n

>

M¯ ε

∑︁
j∈E

pi,j (n)

<

ε|E|.

Но

последнее

в

силу

произволь-

ности

выбора

ε

и

|E|

<

∞

противоречит

нормировке

∑︁
j∈E

pi,j (n)

=

1.

Значит, наше предположение о нулевости некоторого состояния i не

верно. □

Следствие. В замкнутом классе эквивалентности с конечным

числом состояний все состояния ненулевые и возвратные.

Таким образом, мы получаем, что классификация состояний из ко-

142

нечных классов ОДМЦ делится только на два типа, а именно справедлива
Теорема 6.10. Если S∗ – множество состояний ОДМЦ, образующий конечный класс эквивалентности, тогда все состояния из S∗
а) либо нулевые и невозвратные, при этом S∗ является открытым классом (состояния несущественные).
б) либо ненулевые и возвратные, при этом S∗ является замкнутым классом (состояния существенные).
Иначе говоря, для конечных неразложимых подцепей
нулевое состояние ⇐⇒ невозвратное ⇐⇒ несущественное
ненулевое состояние ⇐⇒ возвратное ⇐⇒ существенное Пример 6.1. Классифицировать состояния цепи, считая p ∈ (0, 1), q ∈ (0, 1).
Рис. 9. К примеру 6.1
Решение. Здесь E = {0, 1, 2, . . . } – счетное множество. Однако каждое состояние является открытым классом эквивалентности (при этом число классов счетно), а значит, является нулевым и невозвратным.
Данный пример демонстрирует, что в цепи может вовсе не быть существенных состояний (такая ситуация возможна, только если число состояний счетно). △
В общей ситуации, когда класс имеет счетное число состояний, ситуация усложняется. Рассмотрим следующий
Пример 6.2. Классифицировать состояния цепи, считая p ∈ (0, 1), q ∈ (0, 1).
Решение. Здесь E = {. . . , −1, 0, 1, . . . }. Все состояния цепи являются сообщающимися. Поэтому все они являются существенными. Возвращение в любое состояние возможно лишь за четное число шагов, следовательно ∀j ∈ E период dj = 2, поэтому все состояния являются периодическими с периодом 2.
143

Рис. 10. К примеру 6.2

Теперь выясним, являются ли состояния нулевыми. Для j ∈ E:
pj,j (2n) = C2nn pn qn = ((2nn!))2! pn qn. √
По формуле Стирлинга, n! ∼ nne−n 2πn, n → ∞. Отсюда

любого

√

√

pj,j(2n) ∼ (2n(︁n)2nnee−−n2√n 2π2nπ)︁·22n pnqn = 4n 22ππn· 2n pnqn = (4p(√1 π−np))n

при n → ∞. Но так как p(1 − p) ≤ 1/4 для всех p ∈ (0, 1), то pj,j(2n) → 0, n → ∞. Учитывая, что pj,j(2n + 1) = 0 для всех n, получаем, что все состояния являются нулевыми.
Теперь исследуем состояния на свойство возвратности. Для этого рассмотрим ряд

∞

∞

∑︂

∑︂

Pj = pj,j (n) = pj,j (2n).

n=1

n=1

Если p = q = 1/2, то 4pq = 1 и ряд расходится. В этом случае все состо-

яния являются возвратными. Если же p ̸= q, то ряд сходится и Pj < ∞.

В этом случае все состояния являются невозвратными. Вероятность

вернуться в состояние j при условии, что система вышла из него в

начальный момент времени, равна Fj = Pj/(1 + Pj) < 1. △

Замечание. Симметричное случайное блуждание по целочислен-

ной решетке возвратно в пространствах одного и двух измерений и

невозвратно в пространстве трех и более измерений. Это утверждение

есть теорема Пойа [56]. В одномерном случае утверждение можно обоб-

щить на случай произвольных симметричных случайных блужданий

на целочисленной прямой. Пусть теперь шаг блуждания ξ принима-

ет произвольные значения, не только +1 и −1. Если ξ – симметрич-

ная целочисленная случайная величина с конечным математическим

ожиданием

Eξ

=

0,

то

случайное

блуждание

X (n)

=

∑︁n
j=1

ξj

,

где

ξj

–

144

независимые одинаково распределенные случайные величины, образует возвратную ОДМЦ с нулевыми состояниями. Если при этом предположить, что наибольший общий делитель неотрицательных значений ξ равен 1, то ОДМЦ бесконечное число раз побывает в любом состоянии i. С доказательствами этих фактов можно познакомиться, например, в книге [7].
Из рассмотренного примера 6.2 видно, что в общем случае (счетного числа состояний) нулевое состояние может быть как возвратным (при этом существенным), так и невозвратным (при этом тоже существенным).
Определение 6.13. Возвратное ненулевое состояние называется положительно возвратным.
Возвратное нулевое состояние называется нуль возвратным. В случае счетного класса эквивалентности существенное состояние может принадлежать к одному из трех типов:

а) либо положительно возвратное состояние,

б) либо нуль возвратное,

в) либо невозвратное (как следствие, нулевое).

Таким образом, в общей ситуации справедливы только импликации

ненулевое состояние =⇒ возвратное =⇒ существенно

несущественно =⇒ невозвратное состояние =⇒ нулевое
как уже и утверждалось в следствии к теореме 6.6. Замечание 1. Отметим, что в случае возвратности состояния i, по-
следовательность fi(n), n ≥ 1, образует распределение вероятности. А значит, можно говорить, например, о математическом ожидании времени первого возвращения в i-е состояние:
∞
∑︂ µi := Eiτi = E[τi|X0 = i] = nfi(n),
n=1

где τi = min{n ≥ 1 : Xn = i}. Оказывается, что если состояние нульвозвратное, то Eiτi = ∞, а если состояние положительно возвратное, то Eiτi = π1i , где π – стационарное (инвариантное) распределение (про которое будет подробно рассказано в следующем подразделе), то есть распределение вероятностей, являющееся решением уравнения P T π =
π. Этот результат несложно показать из формулы полной вероятности.
Введём следующие обозначения

µij := Eiτj = E[τj|X0 = i],

(43)

145

в частности µi = µii. Тогда из формулы полной вероятности (усредняя по всем возможным состояниям на первом шаге X1 = k, k ∈ E) имеем систему линейных уравнений для любых состояний i и j

∑︂ µij = pi,kµkj + 1.
k̸=j

Умножим на πi и просуммируем по всем состояниям i ∈ E, воспользо-

вавшись

равенствами

∑︁
i∈E

πipi,j

=

πj

и

∑︁
i∈E

πi

=

1:

µjπj = 1.

Другое доказательство равенства µiπi = 1 на основе предельных законов см. в примере 6.10.

146

возвратное

i-е состояние

невозвратное

147

P(Xn = i бесконечно часто | X0 = i) = 1

P(Xn = i бесконечно часто | X0 = i) = 0

Вероятность возвращения за конечное
∞
число шагов: Fi = ∑︁ fi(n) = 1
n=1

Математическое ожидание числа

посещений i-го состояния:

∞

∞

E ∑︁ I(Xn = i) = ∑︁ pii(n) = ∞

n=1

n=1

нуль возвратное положительно возвратное

lim pii(n) = 0
n→∞

lim pii(n) ̸= 0
n→∞

∞
µi = ∑︁ nfi(n) = ∞
n=1

∞
µi = n∑=︁1 nfi(n) = π1i

Если i-е состояние апериодическое, то

lim pii(n) = πi > 0

n→∞ n

Иначе

lim

1 n

∑︁

pii(k) = πi

>0

n→∞ k=1

Вероятность возвращения за конечное
∞
число шагов: Fi = ∑︁ fi(n) < 1
n=1

Математическое ожидание числа

посещений i-го состояния:

∞

∞

E ∑︁ I(Xn = i) = ∑︁ pii(n) < ∞

n=1

n=1

(как следствие:

lim pii(n) = 0 – нулевое состояние)
n→∞

Рис. 11. Классификация состояний ОДМЦ по асимптотическим свойствам pi,i(n)

состояние возвратно

состояние нулевое

состояние невозвратно

состояние ненулевое

Рис. 12. Связь возвратности и нулевости состояния ОДМЦ. Стрелки означают логические импликации. Обратные стрелки в общем случае провести нельзя, если число состояний счетно. Если цепь конечна, то можно провести и обратные стрелки
Замечание 2.
а) Нуль-возвратные состояния могут быть только в случае счетных классов (классическим примером является симметричное случайное блуждание на одномерной решетке – пример 6.2).
б) В случае конечных замкнутых классов состояния положительно возвратные.
в) Примеры невозвратных состояний (а значит, нулевых) в случае
1) |E| < ∞: такими являются только открытые классы (то есть несущественные состояния).
2) |E| = ∞: такими могут быть, как несущественные состояния, так и существенные (несимметричное блуждание из примера 6.2).
6.3. Эргодические дискретные цепи Маркова
Перейдем теперь к важнейшим понятиям стационарности распределения и эргодичности цепи.
Определение 6.14. Распределение вероятностей π = (π0, π1, . . . ) называется стационарным, или инвариантным, если
P ⊤π = π,
148

где P – переходная матрица однородной дискретной марковской цепи (ОДМЦ).
Замечание. ОДМЦ является стационарным в узком смысле случайным процессом тогда и только тогда, когда распределение вероятностей на множестве состояний является стационарным.
Как мы увидим позже, стационарного распределения может и не быть. Такая ситуация возникает в случае счетных цепей.
Пример 6.3. Рассмотрим несколько примеров.

P = [︃ 0 1 ]︃ , π = [︃ 1/2 ]︃

10

1/2

P = [︃ 0 1 ]︃ , π = [︃ 0 ]︃

01

1

P = [︃ 1 0 ]︃ , π = [︃ p ]︃ ∀p ∈ [0, 1]

01

1−p

Теорема 6.11. В любой конечной цепи Маркова найдется хотя бы одно стационарное распределение.
Доказательство. Утверждение теоремы следует из одного варианта теоремы Брауэра о неподвижной точке, и для нашего случая доказательство проводится следующим образом. Рассмотрим множество всех стохастических векторов:
P = {p = (p1, . . . , pN ) : p1 ≥ 0, . . . , pN ≥ 0, p1 + · · · + pN = 1}.
Легко видеть, что это множество выпуклое, замкнутое и ограниченное. Возьмем произвольный вектор p ∈ P, введем обозначение A = P ⊤ и
149

рассмотрим последовательность

1

n
∑︂

wn =

Ak p.

n+1

k=0

Так как преобразование A переводит стохастические векторы в стоха-

стические, а множество P выпуклое, то {wn} ⊂ P. Далее, так как по-

следовательность {wn} ограничена (она лежит в ограниченном множе-

стве), то по теореме Больцано–Вейерштрасса из нее можно выделить

сходящуюся подпоследовательность {wnm }, причем предел w этой под-

последовательности лежит в P, так как множество P замкнутое. Из оце-

нок

1

⃓ nm ⃓∑︂

⃓ ⃓

|Awn − wn | =

⃓ (︁Ak+1p − Akp)︁⃓ =

m

m

nm

+

1

⃓ ⃓

⃓ ⃓

k=0

= 1 ⃓⃓Anm+1p − p⃓⃓ ≤ diam(P)

nm + 1

nm + 1

следует, что |Awnm − wnm | → 0, m → ∞; здесь diam(P) – диаметр множества P, он конечен в силу ограниченности P. Так как

A(wnm − w) − (wnm − w) → 0, Awnm − wnm → 0,

то необходимо Aw = w. Значит, мы нашли стационарное распределение p0 = w. □
Замечание. Теорема 6.11 является следствием теоремы 6.3, так как собственное пространство конечной матрицы P T , отвечающее собственному значению 1, порождается стационарным распределением. Более того, если цепь содержит единственный замкнутый конечный класс эквивалентности, то 1 является собственным значением матриц P и P T , причем алгебраическая и геометрическая кратность равны единице, и соответствующее собственное пространство матрицы P порождается вектором из одних единиц, а соответствующее собственное пространство матрицы P порождается стационарным распределением, см. теорему о спектре стохастической матрицы 1.12.3 [30]. Если матрица бесконечная, то собственный вектор матрицы P T с неотрицательными компонентами для собственного значения 1 тоже существует, но из-за бесконечности размера не всегда существует нормировочная константа, переводящая этот вектор в распределение вероятности.
Теорема 6.12. Пусть π – стационарное распределение конечной
цепи Маркова, а состояние i является несущественным. Тогда πi = 0. Доказательство. Все состояния цепи разобьем на два класса:
класс несущественных состояний S0 и класс всех остальных состояний

150

S1. Перенумеровав подходящим образом состояния цепи, мы можем записать переходную матрицу:

P = [︃ Q R ]︃ , OS

где матрица Q отвечает переходам между несущественными состояниями, матрица R отвечает переходам от несущественных состояний к существенным, матрица O нулевая, а матрица S отвечает переходам между существенными состояниями.

P = [︃ QO RS ]︃ , P 2 = [︃ QO2 QRS+2 RS ]︃ , . . . , P n = [︃ QOn SAn ]︃ ,

где A – некоторая матрица. Заметим, что в силу конечности цепи най-

дется n0 такое, что для всех несущественных состояний i ∈ 1, . . . , k

выполнено неравенство

k

∑︂ Qnij0 < 1,

(44)

j=1

где k < |E| – количество несущественных состояний. Теперь рассмотрим матричную норму для произвольных матриц M размера

n
∑︂ ∥M ∥∞ = max |Mij|.
1≤i≤n j=1

Тогда из (44) следует неравенство ∥Qn0 ∥∞ < 1. Докажем, что ∥Qn∥∞ → 0, n → ∞. Из неравенства ∥Q∥∞ ≤ 1 сле-

дует, что

∥Qn∥∞ ≤ ∥Q∥n∞ ≤ 1

для всех n ≤ n0. Далее, для всех n ∈ [n0, 2n0) имеем

∥Qn∥∞ ≤ ∥Qn0 ∥∞ ∥Q∥n∞−n0 ≤ ∥Qn0 ∥∞.

Для n ∈ [2n0, 3n0) получаем аналогично

∥Qn∥∞ ≤ ∥Qn0 ∥2∞ ∥Q∥n∞−2n0 ≤ ∥Qn0 ∥2∞.

В общем случае получаем, что

∥Qn∥∞ ≤ ∥Qn0 ∥[∞n/n0] → 0, n → ∞,

где квадратные скобки означают взятие целой части. Это означает, что с ростом n каждый элемент матрицы Q стремится к нулю.

151

Теперь транспонируем матрицу P : (︁ ⊤)︁n [︃ (︁Q⊤)︁n P = A⊤

O ]︃ (︁S⊤)︁n .

Произвольное стационарное распределение π удовлетворяет равенствам
π = P ⊤π = · = (P ⊤)nπ = · · · = lim (︁P ⊤)︁n π.
n→∞
Так как первые k компонент вектора limn→∞ (︁P ⊤)︁n π равны нулю, то нулю равны и первые k компонент вектора π, как следует из равенства выше. Значит, для всех несущественных состояний i = 1, . . . , k вероятности πi = 0. □
На самом деле справедливо более общее утверждение. Теорема 6.13. Пусть π – стационарное распределение ОДМЦ, а состояние i является нулевым. Тогда πi = 0. Доказательство. Стационарное распределение удовлетворяет системе уравнений для любого n ≥ 1
(︁P T )︁n π = π.

В частности,

∑︂

πi = πkpki(n) ≤ sup pki(n).

(45)

k∈E

k∈E

Заметим, что если i состояние нулевое, то для любого состояния k pki(n) → 0 при n → ∞. Это следует, если перейти к пределу n → ∞ в формуле полной вероятности

n
∑︂ pki(n) = fki(m)pii(n − m),
m=1

где fki(m) — вероятность первого попадания из k состояния в i на шаге m. Возвращаясь к доказательству теоремы, возьмем предел n → ∞ в формуле (45), получим требуемое утверждение. □
Замечание 1. В случае конечной ОДМЦ с единственным замкнутым классом эквивалентности существует единственное стационарное распределение, причем его значения на несущественных состояниях (т.е. тех состояниях, что принадлежат открытым классам эквивалентности) нулевые (см. пример 6.3, первую и вторую ситуации).
Замечание 2. Рассмотрим теперь ОДМЦ с m конечными замкнутыми классами эквивалентности: E1, E2, . . . , Em (число открытых классов и их размер не важны, так стационарное распределение на

152

несущественных состояниях все равно нулевое – обозначим класс несу-

щественных состояний через E0). Каждый замкнутый класс эквива-

лентности, если его рассматривать как самостоятельную цепь, имеет

единственное стационарное распределение: π(k) – вектор размерности

|Ek|, k = 1, . . . , m. Введем также вектор π(0) размерности |E0|, состоя-

щий из нулей: π(0) = (0, . . . , 0)T . Этот вектор отвечает несущественным

состояниям. Тогда стационарным распределением всей цепи π являет-

ся любая выпуклая комбинация стационарных распределение классов

(см. пример 6.3, третью ситуацию). Формально можно записать это

так:

(︂

)︂T

π = π(0), α1π(1), . . . , αmπ(m) ,

(46)

где

αk

≥

0,

∑︁m
k=1

αk

=

1.

Важно заметитьa, что формула (46) описывает всевозможные

(в зависимости от начального распределения p(0)) предельные

(финальные) распределения limt→∞ p(t) для однородных марков-

ских цепей в дискретном и непрерывном времени (в дискретном

времени, в случае периодической цепи, сходимость следует пони-

мать в смысле (48)). Набор чисел {αk} однозначно определяется

начальным распределением, см. пример 6.11. Причем все это вер-

но и для m = ∞ с счетными классами эквивалентности. Только

в случае счетного числа состояний в общем случае вместо αk ≥ 0,

∑︁m
k=1

αk

=

1

можно

лишь

утверждать,

что

αk

≥

0,

∑︁m
k=1

αk

≤

1.

Пример 6.11 при m = 1 как раз описывает такую ситуацию, в ко-

торой неравенство может быть строгим. Наиболее интересный

случай (эргодический), когда предельное распределение не зави-

сит от начального, т.е. когда m = 1, α1 = 1. Далее мы в основном

будем рассматривать только этот случай.

aСобственно, вся последующая часть данного раздела и весь следующий раздел можно понимать как обоснование и обсуждение того, что написано в этом абзаце. Этот абзац является, пожалуй, самым главным материалом, который рекоменудется вынести из теории марковских процессов.

Замечание 3. В случае ОДМЦ со счетным множеством состояний может оказаться, что вовсе нет стационарного распределения (см. пример 6.8 ниже). В этой ситуации необходимо дополнительное условие: существование положительно возвратного класса, где состояния ненулевые и возвратные. Если такой класс единственен, то и стационарное распределение единственно. Иначе возникает смесь стационарных распределений, как и в предыдущем замечании. Есть несколько

153

частных случаев, когда поиск стационарного распределения для замкнутого класса эквивалентности достаточно легок.
а) Пусть матрица переходов конечной ОДМЦ дважды стохастическая, то есть сумма ее элементов и по каждой строке, и по каждому столбцу равна единице. Тогда, как несложно проверить, равномерное распределение на множестве состояний является стационарным, то есть πi = 1/|E| для любого i ∈ E.
б) Пусть ОДМЦ описывает случайное блуждание на некотором неориентированном связном графе из n вершин и N ребер: находясь в произвольной вершине, на следующем шаге выбирается равновероятно одна из смежных вершин. Легко убедиться, что стационарное распределение на множестве вершин следующее:
πi = d2eNgi ,
где degi – степень вершины i, т.е. число смежных с ней вершин. в) Важным классом марковских цепей образуют цепи, обратимые
во времени, а именно введем следующее определение. Определение 6.15. ОДМЦ (возможно со счетным множеством со-
стояний) обладает свойством обратимости, если существует нетривиальное решение следующего уравнения детального баланса (см., например, главу 6, [8])6: для любых

i, j ∈ E πiPi,j = πj Pj,i,
где Pi,j – вероятность перейти из состояния i в j. Просуммируем уравнение детального баланса по j ∈ E, получим
уравнение на поиск стационарного распределения. Таким образом, распределение вероятностей, являющееся решением уравнения детального баланса, является стационарным распределением (обратной импликации нет).
Стоит также заметить (см.[30, § 1.10]), что свойство обратимости можно понимать следующим образом. Из уравнения детального баланса следует, что для любого n и для любых i0, i1, . . . , in ∈ E

πi0 Pi0,i1 Pi1,i2 · · · Pin−1,in = πin Pin,in−1 Pin−1,in−2 · · · Pi1,i0

Иначе говоря, для марковской цепи, обладающей свойством обрати-

мости и имеющей в качестве начального распределения стационарное

выполнено

(X0X1 . . . Xn) =d (XnXn−1 . . . X0) ,

6Как бы выполнен закон сохранения массы: сколько вышло из i-го состояний в j−е, столько и вошло из j-го в i-е состояние.

154

то есть у цепи с обратимым временем (Xn−k)nk=0 такое же распределение как и у исходной цепи (Xk)nk=0.
Пример 6.4. В качестве примера рассмотрим случайное блуждание на булевом кубе {0, 1}N : находясь в вершине v = (v1, . . . , vN ), где vm ∈ {0, 1} для всех m = 1, . . . , N , равновероятно выбирается одна их N компонент и меняется на противоположную. Ясно, что матрица переходных вероятностей будет дважды стохастической, а значит, и стационарное распределение равномерное: πv ≡ 2−N . Тот же ответ можно получить, воспользовавшись формулой выше из пункта б) для поиска стационарного распределения для симметричного случайного блуждания на неориентированном графе.
Пример 6.5. В качестве следующего примера рассмотрим дискретную модель диффузии Эренфестов, см. также раздел А. Пусть имеется сосуд с N молекулами, разделенный мембраной на две части. В каждый момент времени n выбирается равновероятно одна из молекул и переводится в противоположную часть сосуда. Пусть номер состояния i – число молекул в фиксированной части сосуда, i ∈ {0, 1, . . . , N }. Тогда

⎧ 1−

i,

⎪ ⎨

N

Pi,j = Ni ,

⎪⎩0,

если j = i + 1; если j = i − 1; иначе.

Несложно показать, что ОДМЦ является обратимой, и найти πi =

CNi 2−N . Заметим, что этот результат можно получить из следующих

рассуждений. Предположим, что молекулы пронумерованы. Тогда ди-

намика диффузии эквивалентна симметричному случайному блужда-

нию на булевом кубе {0, 1}N (см. пример 6.4) с равномерным стаци-

онарным распределением. Далее, осталось перейти от пронумерован-

ных молекул к неразличимым, объединив подмножества состояний в

одно (по числу ненулевых компонент). Иначе говоря, если Xn – мар-

ковская цепь, описывающая симметричное случайное блуждание на

булевом кубе {0, 1}N , то W (Xn) – марковская цепь, описывающая диф-

фузию

в

модели

Эренфестов,

где

W (V )

=

∑︁N
i=1

vi

,

vi

∈

{0, 1},

(ком-

поненты вектора V ) – хэммингов вес (число ненулевых компонент в

булевом слове).

Отметим также, что условие детального баланса активно исполь-

зуется в подходе Markov Chain Monte Carlo (см., например, [8, глава

7] и раздел Б ниже).

Наличие стационарного распределения указывает на то, каким мо-

жет быть предельное (финальное) распределение, если последнее су-

155

ществует. Определение 6.16. Конечная ОДМЦ называется эргодической,
если стационарное распределение единственно. Как мы увидим в дальнейшем, единственность стационарного рас-
пределения (и для конечной, и для счетной цепи) обеспечивается наличием ровно одного замкнутого класса сообщающихся состояний при возможном наличии несущественных состояний.
Оказывается единственность стационарного распределения π обеспечивает эргодичность конечной ОДМЦ {Xn} в смысле, который обсуждался ранее в пунктах 5.1, 5.2: для любой собственной (конечной) функции f (x), заданной на состояниях ОДМЦ, почти наверное (с вероятностью 1) имеет место

1

N
∑︂

∑︂

lim

f (Xn) = Eπf (X) = πkf (k),

(47)

N→∞ N

n=1

k

в частности, при f (x) = I(x = k), имеем

1

N
∑︂

lim

pk(n) = πk.

(48)

N→∞ N

n=1

Приведем, следуя [7, глава 13] и [14, глава 11], пример приложе-

ния небольшого обобщения формулы (47) (эргодической теоремы) для

конечных ОДМЦ в теории информации.

Пример 6.6. В теории информации одной из основных задач явля-

ется эффективное сжатие информации. В частности, если по каналу

передавать сигнал, в котором равновероятно (с одинаковыми часто-

тами) может встретиться одна из m букв, то для передачи n букв

потребуется n log2 m битов, т.е. log2 m битов на букву. Если же ве-

роятности появления букв в тексте (частоты) не равновероятны p =

= {pk}m k=1, то передачу букв можно организовать эффективнее: так,

чтобы

на

одну

букву

приходилось

лишь

H (p)

=

−

∑︁m
k=1

pk

log2

pk

≤

≤ log2 m битов. Покажите, что если буквы в тексте появляются соглас-

но конечной однородной эргодической марковской цепи с матрицей переходных вероятностей P = ∥pij∥m i,j,=m1 (альтернативная интерпретация

– известна матрица частот появления всевозможных пар букв (i, j)

друг за другом), то передачу букв можно организовать еще эффек-

тивнее: так, чтобы на одну букву приходилось лишь H({pij}m i,j,=m1) =

=

−

∑︁m
i=1

πi

∑︁m
j=1

pij

log2

pij

битов,

где

π

–

стационарное

распределе-

ние марковской цепи с матрицей переходных вероятностей P .

156

Решение. Рассмотрим вероятностных подход (частотный подход см. в [14, глава 11]). Рассмотрим n-буквенные случайные последовательности X = (X1, . . . , Xn), сгенерированные согласно введенной марковской цепи. Будем называть последовательность x = (x1, . . . , xn) δ-типичной, если вероятность ее появления лежит в специальном диапазоне:

P(X = x) ∈ [︂2−n(H({pij }m i,j,=m1)+δ), 2−n(H({pij }m i,j,=m1})−δ)]︂ .

(49)

Число таких последовательностей будет O (︂2n(H({pij}m i,j,=m1)+δ))︂, что мо-
жет быть много меньше общего числа возможных последовательностей 2n. Если будет показано, что для любых (сколь угодно малых) δ > 0 и σ > 0 можно подобрать такое (достаточно большое) n(δ, σ), начиная с которого событие (49) имеет место с вероятностью ≥ 1 − σ, то эффективное кодирование можно организовать, кодируя только δ-типичные последовательности.
Итак, рассмотрим на траектории марковского процесса функцию от двух соседних сечений f (xk, xk+1) = − log2 pxkxk+1 . Поскольку

n−1
∏︂ P(X= x) = px1 pxkxk+1 ,
k=1

то формула (49) будет выполняться для достаточно больших n, если почти наверное

1

n
∑︂

(︁

m,m )︁

n

f (Xk, Xk+1) −−−−→ H {pij }i,j=1 .
n→∞

k=1

Но поскольку рассматриваемый марковский процесс по предположению эргодический, то предел левой части существует и равняется математическому ожиданию f (Xk, Xk+1) в предположении, что Xk имеет стационарное (инвариантное) распределение π, а Xk+1 случайно порождается по Xk согласно матрице переходных вероятностей P , т.е.

EXk∼πf (Xk, Xk+1) = −EXk∼π log2 pXkXk+1 =

=

− ∑︁m i=1

πi

∑︁m
j=1

pij

log2

pij

=

H({pij }m i,j,=m1).

Приведенные здесь рассуждения можно провести более точно. В частности, можно оценить n(δ, σ) [79]. △
Для изучаемого класса случайных процессов (ОДМЦ) при некоторых дополнительных предположениях сходимость в чезаровском смысле (48) можно превратить в обычную сходимость. Оказывается, для

157

этого нужно дополнительно предположить, что ОДМЦ апериодическая.
В связи с некоторыми особенностями перенесения результатов об эргодичности конечных ОДМЦ на ОДМЦ со счетным числом состояний, оказывается, удобно также ограничиться классом ОДМЦ с отсутствием нулевых состояний. Далее об этом будет написано подробнее.
В связи с написанным выше также используют более сильное определение эргодичности ОДМЦ [43].
Определение 6.17. Конечная или счетная ОДМЦ называется сильно эргодической, если для любого j ∈ E существует не зависящий от i ∈ E положительный предел:
lim pi,j(n) = p∗j > 0.
n→∞
Несложно заметить, что если ОДМЦ сильно эргодическая, то стационарное распределение π единственное и p∗ = π.
Пример 6.7. Рассмотрим несколько примеров.
Здесь p0,0(2n) = 1, p0,0(2n + 1) = 0, n ≥ 1. Поэтому предел limn→∞ p0,0(n) не существует, цепь не будет сильно эргодической, но будет эргодической.
P = P 2 = P 3 = . . ., значит, для всех i, j предел limn→∞ pi,j(n) существует, но limn→∞ p0,0(n) = 0, поэтому цепь не будет сильно эргодической, но будет эргодической.
Рассмотрим теперь такую цепь:
158

Ранее мы получили, что P n → 1 [︃ 1 q ]︃ , n → ∞, 1+q 1 q

значит, существуют пределы lim pi,j(n) = p∗j > 0, причем
n→∞

1

q

p0 = 1 + q , p1 = 1 + q , p0 + p1 = 1.

По определению, данная цепь сильно эргодическая. △ Следующая теорема является ключевой для доказательства крите-
рия сильной эргодичности конечной ОДМЦ (однородной дискретной марковской цепи). Отметим, что доказательство теоремы ниже остается верным, если число состояний счетно, а время непрерывно. Марковские цепи с непрерывным временем подробнее изложены в разделе 7.
Теорема 6.14. Пусть для ОДМЦ с множеством состояний S и переходными вероятностями pi,j выполняется условие:

∃δ > 0 ∃j0 ∈ S ∃n0 : ∀i ∈ S pi,j0 (n0) ≥ δ. Тогда ∃ lim pi,j(n) = p∗j = πj для всех i, j ∈ S, причем pj0 ∗ > 0, и
n→∞

|pi,j (n) − p∗j | ≤ (1 − δ)[n/n0] ∀i, j ∈ S.

Доказательство. Пусть

Mj (n) = maxi∈S pi,j (n) и mj (n) = mini∈S pi,j (n).

Из определения чисел Mj(n) и mj(n) следует, что mj(n) ≤ pi,j(n) ≤ ≤ Mj(n) для всех i ∈ S. Кроме того, из уравнения Колмогорова– Чепмена имеем

∑︂

∑︂

pi,j (n + 1) = pi,k pk,j (n) ≤ Mj (n) pi,k = Mj (n)

k∈S ⏞ ⏟⏟ ⏞

k∈S

≤Mj (n)

∀i, j ∈ S,

∑︂

∑︂

pi,j (n + 1) = pi,k pk,j (n) ≥ mj (n) pi,k = mj (n)

k∈S ⏞ ⏟⏟ ⏞

k∈S

≥mj (n)

Отсюда следует, что

∀i, j ∈ S.

Mj(n + 1) = max pi,j(n + 1) ≤ Mj(n),
i∈S

159

mj(n + 1) = min pi,j(n + 1) ≥ mj(n).
i∈S
Таким образом, мы показали, что для каждого j ∈ S последовательность {Mj(n)}∞ n=1 возрастает, а последовательность {mj(n)}∞ n=1 убывает. Следовательно, обе последовательности имеют предел. Покажем, что эти пределы совпадают, т.е. покажем, что

Mj(n) − mj(n) −−−−→ 0.
n→∞

Отсюда будет следовать, что существуют числа

p∗j = lim pi,j(n) = lim Mj(n) = lim mj(n) ≥ 0,

n→∞

n→∞

n→∞

причем в силу того, что pi,j0 (n0) ≥ δ > 0 для всех i ∈ S, получаем

mj0 (n0) ≥ δ > 0 =⇒ ∀n ≥ n0 mj0 (n) ≥ δ =⇒ pj0 ∗ ≥ δ > 0.

Начнем с того, что оценим разность Mj(n) − mj(n):

Mj(n) − mj(n) = max pi,j(n) + max (−pk,j(n)) =

i∈S

k∈S

= max (pi,j(n) − pk,j(n)) .
i,k∈S

Далее будем считать, что n > n0. Тогда, продолжая предыдущую цепочку равенств и используя уравнение Колмогорова–Чепмена, получаем
∑︂ Mj(n) − mj(n) = max (pi,l(n0) − pk,l(n0)) pl,j(n − n0).
i,k∈S l∈S
Рассмотрим теперь два множества индексов:
Ii+,k = {l ∈ S : pi,l(n0) − pk,l(n0) ≥ 0},
Ii−,k = {l ∈ S : pi,l(n0) − pk,l(n0) < 0}.

160

Тогда

(︄

∑︂

Mj(n) − mj(n) = max

(pi,l(n0) − pk,l(n0)) pl,j (n − n0) +

i,k∈S

l∈Ii+,k

)︄

∑︂

+

(pi,l(n0) − pk,l(n0)) pl,j (n − n0) ≤

l∈Ii−,k

(︄

∑︂

Mj(n) − mj(n) ≤ max

(pi,l(n0) − pk,l(n0)) Mj (n − n0) +

i,k∈S

l∈Ii+,k

Mj(n) − mj(n)

)︄

∑︂

+

(pi,l(n0) − pk,l(n0)) mj (n − n0) .

l∈Ii−,k

Введем обозначения:

∑︂

∑︂

Ai,k =

(pi,l(n0) − pk,l(n0)) и Bi,k =

(pi,l(n0) − pk,l(n0)) .

l∈Ii+,k

l∈Ii−,k

Заметим, что

∑︂

Ai,k + Bi,k =

(pi,l(n0) − pk,l(n0)) =

l∈S

∑︂

∑︂

=

pi,l(n0) − pk,l(n0) =

l∈S

l∈S

= 1 − 1 = 0 =⇒ Ai,k = −Bi,k.

Поэтому

Mj(n) − mj(n) ≤ (Mj(n − n0) − mj(n − n0)) max Ai,k.
i,k∈S

Наконец, оценим сверху Ai,k. Рассмотрим два случая: когда j0 ∈ Ii+,k
и когда j0 ∈ Ii−,k. В первом случае Ai,k оценивается сверху следующим образом:

∑︂

∑︂

Ai,k =

pi,l(n0) −

pk,l(n0) ≤ 1 − pk,j0 (n0) ≤ 1 − δ.

l∈Ii+,k

l∈Ii+,k

⏞ ⏟⏟ ⏞ ⏞ ⏟⏟ ⏞

≤1

≥pk,j0 (n0)

161

Во втором случае немного другая выкладка приводит к той же самой оценке сверху:

∑︂

∑︂

Ai,k =

(pi,l(n0) − pk,l(n0)) ≤

pi,l(n0) ≤

l∈Ii+,k

l∈Ii+,k

∑︂

≤ 1−

pi,l(n0) ≤ 1 − pi,j0 (n0) ≤ 1 − δ.

l∈Ii−,k

⏞ ⏟⏟ ⏞
≥pi,j0 (n0)

Возвращаясь к полученной оценке на разность Mj(n) и mj(n), получаем

Mj(n) − mj(n) ≤ (Mj(n − n0) − mj(n − n0)) (1 − δ).

Отметим, что данное неравенство было доказано для произвольного n > n0. Следовательно, верно и следующее неравенство:

Mj(n) − mj(n) ≤ (Mj(n − n0) − mj(n − n0)) (1 − δ) ≤ ≤ (Mj(n − 2n0) − mj(n − 2n0)) (1 − δ)2 ≤

≤ ...

≤ (Mj(n mod n0) − mj(n mod n0))(1 − δ)[n/n0] ≤

⏞

⏟⏟

⏞

≤1−0=1

≤ (1 − δ)[n/n0].

Отметим, что полученное неравенство при n < n0 становится триви-

альным. Отсюда следует, что Mj(n) − mj(n) −−−−→ 0, т.е. существуют

числа

n→∞

p∗j = lim pi,j(n) = lim Mj(n) = lim mj(n) ≥ 0,

n→∞

n→∞

n→∞

причем, как было отмечено в начале доказательства, pj0 ∗ > 0. Оста-
лось теперь заметить, что для всех i, j ∈ S и всех n ≥ 1 числа pi,j(n) и p∗j лежат на отрезке [mj(n), Mj(n)]. Поэтому из полученной оценки на Mj(n) − mj(n) следует, что

|pi,j (n) − p∗j | ≤ (1 − δ)[n/n0],
что и требовалось доказать. □ Замечание 1. Согласно теореме 6.14 скорость сходимости к стаци-
онарному распределению экспоненциальная (иначе, геометрическая).

162

Для конечных цепей условия этой теоремы всегда выполнены, если цепь содержит ровно один замкнутый класс эквивалентности (в частности, неразложима) и апериодична (см. далее теорему 6.15). Однако, в этом случае оценка скорости сходимости, приведённая в теореме 6.14 как правило оказывается грубой. Более аккуратно: оценка скорости сходимости определяется вторым по модулю максимальным собственным значением стохастической матрицы переходных вероятностей P :

|pi,j(n) − p∗j | = O ((1 − δ)n) ,

(50)

где

δ = min {1 − |λ|, где λ – собственное значение P , отличное от 1}

– спектральная щель матрицы P (см. рис. 13). Действительно, предпо-

ложим, что матрица переходных вероятностей неразложимой аперио-

дической (то есть сильно эргодической) ОДМЦ P размера N + 1 явля-

ется диагонализуемой, то есть имеет N + 1 линейно независимых соб-

ственных векторов u0, u1, . . . uN соответствующих (необязательно по-

парно различным) собственным значениям λ0, λ1, . . . λN , (при чём в си-

лу неразложимости и апериодичности |λk| < 1 для всех k ≥ 1, посколь-

ку кратность собственного значения 1 равна числу замкнутых классов

эквивалентности, а при наличие периода d на единичной окружности

имеются

d

собственных

значений

ei

2π d

m,

m

=

0,

1,

.

.

.

,

d

−

1).

Аналогич-

но матрица P T имеет N + 1 линейно независимых собственных век-

торов v0, v1, . . . vN соответствующих тем же собственным значениям.

Поскольку собственные векторы определяются с точностью до мно-

жителя, выберем их так, чтобы при этом для любых i, j uTi vj = δij.

Выберем v0 = π (в действительности, как уже было сказано v0 = cπ

для любого c ̸= 0). Тогда u0 = 1 – вектор из одних единиц. Тогда

N

P

=

∑︂

λk

uk

v

T k

,

k=0

N

N

P n = ∑︂ λnk ukvkT = Π + ∑︂ λnk ukvkT ,

k=0

k=1

где Π = 1πT – матрица, у которой по строкам стоит стационарное

163

распределение вероятностей. Тогда
N
|pi,j(n) − πj| ≤ ∑︂ |λk|n|uk,i||vk,j| = O (N (1 − δ)n) .
k=1
В общем случае недиагонализуемых матриц тоже можно выписать формулы для степеней матрицы переходных вероятностей (см., например, формулу Перрона в [52, 5.I]). Но мы только отметим важный частный случай диагонализуемых матриц – матрицы переходных вероятностей для обратимых цепей (см. определение 6.15). В этом случае все собственные значения действительны и попарно различны (то есть спектр лежит на отрезке [−1, 1], а в предположении апериодичности – на полуоткрытом интервале (−1, 1]), а собственные векторы действительны и образуют ортонормированный базис. Это следует из теории симметричных матриц и того факта, что матрица A с элементами Ai,j = √︂ ππji Pi,j является симметричной (см. [30, Теорема 1.12.4]).
спектральный радиус

|λ| ≤ δ(P ) 0

κ δ(P ), спектральная щель
λ0 = 1

ρ(P ) = 1

Рис. 13. P неприводима и апериодична
Теорема 6.15 (критерий сильной эргодичности). Конечная ОДМЦ является сильно эргодической тогда и только тогда, когда она неразложима и апериодична.
Доказательство. Сначала покажем, что неразложимость и апери-
164

одичность являются необходимыми условиями сильной эргодичности конечной однородной цепи Маркова. Итак, рассмотрим произвольную конечную ОДМЦ с множеством состояний S и переходными вероятностями pi,j. По определению сильной эргодичности имеем
∀i, j lim pi,j(n) = p∗j > 0.
n→∞
В частности, отсюда следует, что

∀i, j ∀ε > 0 ∃n0 = n0(i, j, ε) : ∀n > n0pi,j(n) > p∗j − ε.

Пусть

ε

=

1 2

min pj

и

n0

=

max n0(i, j, ε).

j∈S

i,j∈S

Тогда для всех n > n0 и для всех i, j вероятность pi,j(n) > p∗j − ε > 0. Отсюда следует, что все состояния сообщаются, то есть цепь неразложима. Кроме того, цепь апериодична, т.к. для всех n > n0 и для всех i вероятности pi,i(n) > 0 и pi,i(n + 1) > 0.
Теперь с помощью теоремы 6.14 покажем, что неразложимость и апериодичность являются и достаточными условиями для сильной эргодичности конечной ОДМЦ. Идея состоит в том, чтобы показать, что условие теоремы 6.14 выполняется для всех вершин такой цепи. Если это показать, то получим, что для всех i, j ∈ S существуют пределы

lim pi,j(n) = p∗j > 0,
n→∞
не зависящие от i, что и означает сильную эргодичность цепи. Итак, рассмотрим, не умаляя общности, вершину s (считаем, что
S = {1, 2, . . . , s}). Из неразложимости следует, что существуют такие числа M1, M2, . . . , Ms−1, что

p1,s(M1) > 0, p2,s(M2) > 0, . . . , ps−1,s(Ms−1) > 0

(для удобства будем считать, что Ms = 0). Кроме того, из апериодичности следует, что найдутся два числа A и B, что A и B взаимно просты, и ps,s(A) > 0 и ps,s(B) > 0. Следовательно, чтобы выполнялось условие теоремы 6.14, достаточно доказать, что существуют такие неотрицательные целые числа n0, k1, m1, k2, m2, . . . , ks, ms, что n0 = M1 + Ak1 + Bm1 = M2 + Ak2 + Bm2 = . . . = Ms−1+ +Aks−1 + Bms−1 = Aks + Bms (ведь в таком случае pi,s(Mi + Aki+ +Bmi) ≥ pi,s(Mi)ps,s(Aki)ps,s(Bmi) ≥ pi,s(Mi) (ps,s(A))ki (ps,s(B))mi >

165

> 0 для всех i ∈ S, а в силу конечности множества S можно заключить, что найдется такое δ > 0, что pi,s(Mi + Aki + Bmi) ≥ δ для всех i ∈ S). Это эквивалентно системе линейных уравнений в целых числах:

A(k2 − k1) + B(m2 − m1) = M1 − M2, A(k3 − k2) + B(m3 − m2) = M2 − M3,
... A(ks − ks−1) + B(ms − ms−1) = Ms−1.

Так как A и B взаимно просты, то уравнение Ax + By = 1 разрешимо в целых числах. Пусть (x, y) — решение этого уравнения. Тогда

k2 − k1 = (M1 − M2)x, k3 − k2 = (M2 − M3)x,
... ks − ks−1 = Ms−1x,

m2 − m1 = (M1 − M2)y, m3 − m2 = (M2 − M3)y,
ms − ms−1 = Ms−1y.

Из полученных уравнений можно выразить все ki, mi для i ≥ 2 через k1, m1. Если выбрать k1 и m1 достаточно большими, то все ki, mi для i ≥ 2 получатся неотрицательными. Но это и означает, как было отмечено выше, что ∃δ > 0 ∃n0 : ∀i ∈ S pi,s(n0) ≥ δ. Поэтому из теоремы 6.14 получаем, что существует такое число p∗s > 0, что предел limn→∞ pi,s(n) = p∗s для всех i ∈ S. Аналогично можно доказать, что существуют числа p∗j > 0, что limn→∞ pi,j(n) = p∗j для всех i ∈ S. □
Приведем еще несколько очевидных фактов. а) В конечной сильно эргодической цепи существует такой шаг N , что ∀n ≥ N вероятности pi,j(n) > 0 для всех i, j. Другими словами, начиная с некоторого момента все элементы матрицы перехода станут строго положительными. б) Если цепь неразложимая и на диагонали переходной матрицы стоит хотя бы один положительный элемент, то цепь является апериодической. Действительно, в этом случае для соответствующего состояния fi(1) = pi,i > 0, поэтому наибольший общий делитель множества {n ≥ 1 : fi(n) > 0} равен 1 и состояние i будет апериодическим. По свойству солидарности все состояния цепи будут апериодическими. Для конечной цепи это будет означать сильную эргодичность. в) Если в какой-то момент все элементы переходной матрицы строго положительны, то все состояния являются сообщающимися и цепь является поэтому неразложимой. А так как на диагонали переходной

166

матрицы стоят положительные элементы, то цепь является апериодической. Для конечной цепи это будет означать сильную эргодичность.
Из этих фактов вытекает следующая теорема. Теорема 6.16. Конечная цепь Маркова является сильно эргодической тогда и только тогда, когда
∃n0 ≥ 1 ∀i, j ∈ E pi,j(n0) > 0.
В случае ОДМЦ со счетным множеством состояний ситуация немного усложняется. Мы уже видели, что в счетных цепях может вовсе не быть стационарного распределения (например, в простом блуждании на целочисленной решетке). Поэтому для эргодичности счетных ОДМЦ требуется дополнительное условие (которое автоматически выполняется в случае конечных ОДМЦ). А именно, справедлива следующая
Теорема 6.17 (см. [43, теорема 3.5]). В неразложимой ОДМЦ либо все состояния нулевые, либо все состояния ненулевые. ОДМЦ со счетным числом состояний является сильно эргодической тогда и только тогда, когда она неразложима, апериодична и положительно возвратна (то есть у нее все состояния ненулевые).
Замечание 2. В случае конечных неразложимых ОДМЦ все состояния всегда являются положительно возвратными. Проверять положительную возвратность счетных цепей можно с помощью существования стационарного распределения. Справедлива следующая
Теорема 6.18. ОДМЦ является сильно эргодической тогда и только тогда, когда цепь апериодична, существует единственное стационарное распределение, все компоненты этого стационарного рacпределения строго больше нуля.
Замечание. Единственность стационарного распределения с ненулевыми компонентами равносильна неразложимости цепи (то есть все состояния сообщаются, иначе говоря, образуют единственный класс эквивалентности).
Выше мы ввели определение эргодичности конечной ОДМЦ (см. определение 6.16), обеспечивающее выполнение условия (47). Определение по сути свелось к требованию единственности стационарного распределения. Для счетных ОДМЦ ситуация сложнее. Если под эргодичностью по-прежнему понимать выполнение условия (47) с ограниченной функцией f (k), то единственность стационарного распределения является только необходимым условием эргодичности. Более того, счетные ОДМЦ могут вообще не иметь стационарных распределений, в отличие от конечных ОДМЦ. Ранее мы уже это упоминали. Разберем
167

теперь эту ситуацию более подробно. В следующем примере рассматриваемая счетная ОДМЦ описывает
так называемый процесс рождения/гибели в дискретном времени. Пример 6.8. Рассмотрим простое случайное блуждание на неот-
рицательной части одномерной целочисленной решетки с частично отражающим экраном в состоянии 0: pi,i+1 = p, pi,i−1 = q = 1 − p, i ≥ 1, p ∈ (0, 1), p0,1 = p◦, p0,0 = q◦ = 1 − p◦, p◦ ∈ (0, 1).

Рис. 14. К примеру 6.8

Все состояния сообщаются, то есть все множество состояний образует единственный класс эквивалентности, значит цепь неразложима. Наличие «петельки» в состоянии 0 говорит об апериодичности цепи.
Попробуем найти стационарное распределение.

⎧ πk = pπk−1 + qπk+1,
⎪ ⎨
π1 = p◦π0 + qπ2,
⎪ ⎩π0 = q◦π0 + qπ1.

k ≥ 2,

Несложно увидеть, что оно существует только при условии p < 1/2:

(︂ )︂k p , k ≥ 1, π0 = A pp , где нормировочная константа A =
πk = A q ◦

= p(pp◦◦(+q−q−p)p) . То есть эта ситуация сильно эргодическая.

В случае p > 1/2 формальное решение уравнения инвариантно-

(︂ )︂k

p

,

k

≥

1,

π0

=

A pp ,

но

теперь

p q

>

1,

поэтому

сти то же: πk = A q ◦

такое решение не может давать распределение вероятностей. В слу-

чае p = 1/2 формальное решение уравнения стационарности πk = A,

k ≥ 1, π0 = A/(2p◦),что тоже не может давать вектор распределения

вероятностей никаким выбором нормировочной константы A. Значит,

при p ≥ 1/2 цепь неэргодична.

Убедимся, что при p > 1/2 цепь невозвратна. Интуитивно это по-

нятно: есть тенденция «ухода» вправо, на бесконечность. Вычислим

вероятность вернуться в состояние 0 за конечное число шагов f0. Со-

168

гласно формуле полной вероятности

f0 = p◦f1,0 + q◦,

где f1,0 – вероятность достигнуть состояния 0, стартуя из состояния 1. Но f1,0 есть не что иное, как вероятность разорения игрока в игре в «орлянку» с казино, если начальный капитал равен 1. Если обозначить ρk – вероятность разорения при начальном капитале k, то из формулы полной вероятности имеем

ρk = pρk+1 + qρk−1, k ≥ 1,

(︂ )︂k

с граничным условием ρ0 = 1. Если q < p, то ρk =

q p

, если q ≥ p, то

ρk = 1. Поэтому в нашей задаче при p > 1/2 цепь невозвратна, а при

p ≤ 1/2 цепь возвратна. Но, как мы уже убедились, цепь положительно

возвратна (состояния возвратные, ненулевые) только при p < 1/2, так

как в этой ситуации имеется стационарное решение. При p = 1/2 цепь

нуль-возвратна (состояния возвратные, нулевые). △

Как уже ранее отмечалось, к эргодическим теоремам также отно-

сят утверждения типа «усреднение по времени на большом временном

интервале совпадает с усреднением по пространству состояний относи-

тельно стационарного распределения». Приведем далее одну из таких

теорем, которую можно также понимать, как переформулировку фор-

мулы (48).

Введем случайные величины обозначающие число посещений ОД-

МЦ состояния i до момента времени n:

n
∑︂ Vi(n) = I(Xk = i).
k=0

Если существует предел

lim Vi(n) , n→∞ n
то его называют предельной пропорцией времени, проведенном в состоянии i.
Теорема 6.19. Рассматривается эргодическая ОДМЦ с конечным или счетным числом состояний, т.е. ОДМЦ с единственным стационарным распределением π. Для любого состояния i такой цепи

169

выполняется равенство

(︃ Vi(n) )︃

P lim

= ri = 1,

n→∞ n

где ri = πi, если состояние положительно возвратно, и ri = 0, если состояние невозвратно или имеет нулевую возвратность.
С доказательством можно ознакомиться в [30]. В качестве применения этой теоремы рассмотрим асимптотическое решение следующей задачи. Пример 6.9. Рассмотрим следующую «наивную» (но тем не менее осмысленную) стратегию задачи о двуруком бандите, см. также раздел Г. Имеется игральный автомат с двумя ручками. При нажатии первой приз появляется с вероятностью p1 (будем называть это событие успехом). Аналогично при нажатии второй успех будет с вероятностью p2. Стратегия заключается в повторении той же ручки, если на предыдущем шаге она давала успех, и смене ручки, если был неуспех. Ясно, что такая игра представима в виде ОДМЦ на множестве состояний {1, 2}, где номер состояния – номер ручки на данном шаге игры.

Рис. 15. К примеру 6.9
Вычислим приближенно (когда игра продолжается достаточно долго) среднее число успехов при данной стратегии. Обозначим a1 – число успехов при выборе первой ручки, аналогично a2 – число успехов при выборе второй ручки. Тогда
n
∑︂ a1 = I (Xk−1 = 1, Xk = 1) ,
k=1
170

n
∑︂ a2 = I (Xk−1 = 2, Xk = 2) .
k=1
После усреднения получаем

n

n

∑︂

∑︂

Ea1 = P(Xk−1 = 1, Xk = 1) = p1 P (Xk−1 = 1) .

k=1

k=1

Но

согласно

предыдущей

теореме

∑︁n
k=1

P (Xk−1

=

1)

=

EV1(n)

≈

nπ1.

Аналогично, для a2. В итоге среднее число успехов приближенно равно

n(p1π1 + p2π2) = p1 + p2 − 2p1p2 . 2 − p1 − p2

Рассмотренная стратегия тем больше отличается от стратегии с равновероятным выбором ручки на каждом шаге, чем больше |p1 − p2|. △
Сформулируем, наконец, аналоги закона больших чисел и центральной предельной теоремы для ОДМЦ. Введем случайную величину Vi(n), равную числу попаданий цепи ξn в фиксированное состояние i ∈ E за время n, т.е.

n
∑︂ Vi(n) = I(ξk = i),
k=1

где I(A) – индикаторная функция события A. Пусть τj есть время возвращения цепи в состояние i, т.е.

P(τi = k) = fi(k).

Следующая теорема справедлива как для конечных, так и для счетных цепей [7, с. 263].
Теорема 6.20. Пусть ОДМЦ эргодическая, т.е. существует единственное стационарное распределение π. Тогда независимо от того, где находилась ОДМЦ в начальный момент, при n → ∞

EVi(n)

Vi(n) п.н.

→ πi,

−→ πi.

n

n

Если дополнительно Dτi = σi2 < ∞, πi > 0, то

(︄

)︄

Vi(n) − nπi ⃓

P

√︁

< x ⃓ ξ0 = s → Φ(x)

σi nπi3

⃓

171

при n → ∞, где Φ(x) – функция распределения N(0, 1). Пример 6.10. Пусть ОДМЦ сильно эргодическая7, т.е. существует
единственное стационарное распределение π и все компоненты этого
распределения положительны. Доказать, что для всех j ∈ E выполнено µ−j 1 = πj > 0, где
∞
∑︂ µj = nfj(n)
n=1
– среднее время до первого возвращения в состояние j.
Решение. Рассмотрим случайное блуждание по ОДМЦ, которое начинается в вершине j. Пусть Tj1 — длина первой «прогулки», то есть число шагов, сделанных до первого возвращения в состояние j; Tj2 — длина второй «прогулки» и т.д. Получили последовательность {Tjk}∞ k=1 независимых одинаково распределенных случайных величин. Из усиленного закона больших чисел следует, что

n
∑︁ Tjk k=1 −−п−.н−→. ETj1 = µj .
n n→∞

Из свойств сходимости почти наверное следует, что

n

п.н. 1

n
∑︁

−−−−→ . k n→∞ µj

Tj

k=1

Заметим, кроме того, что

n

п.н. 1

−−−−→ .

n+1
∑︁ T k

n→∞

µj

j

k=1

Рассмотрим следующие случайные величины:

{︄ ξjk = 10,иенсалчие.на k-м шаге «прогулка» вернулась в состояние j,

Если

ввести

обозначение

N˜

=

∑︁n
k=1

Tjk

,

то

нетрудно

видеть,

что

n

=

=

∑︁N˜
k=1

ξjk

.

Рассмотрим

теперь

случайную

величину

n˜

=

∑︁N
k=1

ξjk

—

7В действительности, достаточно предположить единственность стационарного распределения. Результат µ−j 1 = πj ≥ 0 останется верным.

172

число возвращений за первые N шагов. Отсюда следует, что

n˜

n˜+1

∑︂ Tjk ≤ N ≤ ∑︂ Tjk,

k=1

k=1

а значит,

n˜

1

N
∑︂

n˜

≤

ξjk ≤

.

n˜+1

N

n˜

∑︁ Tjk

k=1

∑︁ Tjk

k=1

k=1

Теперь заметим, что с вероятностью 1 n˜ → ∞ при N → ∞. Следова-

тельно,

1 ∑N︂ k п.н. 1

N

ξj

−−−−→
N →∞

. µj

k=1

Так как µ1j — константа, то указанная последовательность сходится и

в среднем к µ1j :

(︄

1

N
∑︂

)︄

1

ξjk −−−−→ .

EN

N→∞ µj

k=1

Пользуясь линейностью математического ожидания, получим

(︄

1

N
∑︂

)︄

ξjk =

1

N
∑︂

Eξjk =

EN

N

k=1

k=1

1

N
∑︂

1

= N

pj,j(k) −−−−→ . N→∞ µj

k=1

В силу эргодичности цепи имеем

∀j ∈ S pj,j(k) −−−−→ πj,
k→∞

а значит,

1

N
∑︂

pj,j(k) −−−−→ πj,

N

N →∞

k=1

откуда следует, что µ1j = πj для всех j ∈ S. △ Другое решение см. в замечании 1 раздела 6.2.2.
Как уже отмечалось, в случае конечных ОДМЦ эргодичность эк-
вивалентна единственности стационарного распределения (которое и

173

будет предельным). Другими словами, в конечных цепях для эргодичности должен быть только один замкнутый класс эквивалентности, при этом несущественных состояний может быть любое конечное число. Это оправдывает термин несущественных состояний: они не влияют на предельное поведение ОДМЦ: limn→∞ pi(n) = 0, если i-е состояние несущественное.
В случае счетных ОДМЦ ситуация усложняется. Во-первых, напомним, что в случае счетных цепей может и не быть стационарного распределения: существование единственного стационарного распределение эквивалентно существованию и единственности положительно возвратного замкнутого класса эквивалентности. Однако это попрежнему недостаточно для того, чтобы предельное распределение не зависело от начального.
Пример 6.11 (см. [70, гл. VII, § 8, пример 4]). Рассмотрим следующую игру. Человек изначально имеет k рублей, а на каждом шаге игры подбрасывается несимметричная монетка (вероятность выпадения орла равна p, вероятность выпадения решки равна q = 1 − p). Если выпадает орёл, то человек получает рубль от казино, иначе — отдаёт свой рубль. Игра продолжается до тех пор, пока либо человек не разорится, либо не накопит M рублей (можно интерпретировать M как общую сумму денег человека и казино на момент начала игры, если считать, что общее количество денег у человека и казино не меняется во время игры). Пусть ξ(t) — количество рублей у человека в момент времени t. Последовательность {ξ(t)}∞ t=0 является марковской цепью, которая задаётся графом на рис. 16.
Рис. 16. Игра в «орлянку» с казино
Во-первых, заметим, что все состояния, кроме 0 и M , образуют несущественный класс с периодом 2, состояния 0 и M положительно возвратны и образуют 2 замкнутых класса. Поэтому в случае M < ∞ мы получаем, что цепь не может быть эргодической. Более интересен случай, когда M = ∞ (бесконечно богатое казино). Тем не менее случай конечного M будет полезен, чтобы перейти к случаю M = ∞.
Рассмотрим теперь M = ∞. В этом случае состояния 1, 2, . . . яв-
174

ляются несущественными, а состояние 0 является положительно воз-

вратным и образует единственный замкнутый класс эквивалентности.

Нетрудно заметить, что limn→∞ pi,j(n) = 0 для i, j = 1, 2, . . . . Пусть

πk — вероятность разорения игрока, если изначально у него было k

рублей. Так как состояние 0 является поглощающим, то pk,0(n) =

=

∑︁
m<n

fk,0(m),

где

fk,0(m)

—

вероятность,

что

через

m

шагов

цепь

окажется в состоянии 0 в первый раз, стартуя из состояния k. Но тогда

получаем, что
∞

∑︂

lim pk,0(n) = fk,0(m) = πk.
n→∞ m=0

Из уравнения Колмогорова–Чэпмена получаем

πk = pπk+1 + qπk−1, π0 = 1.

Записывая характеристический многочлен λ = λ2p + q

и

находя

его

корни

(при

p

=

q

=

1 2

корни

λ1

=

λ2

=

1,

при

p

̸=

q

корни

λ1 = pq ), получаем общий вид решения:

(︃ q )︃k πk = C1 p + C2 при p ̸= q,

πk = C1k + C2 при p = q = 1 . 2

Рассмотрим сначала случай p = q = 21 . В силу ограниченности πk для всех k получаем, что C1 = 0. Если учесть начальное условие π0 = 1, то

получим, что C2 = 1, т.е. πk = 1 для всех k, а значит, не зависит от k.

В этом случае цепь эргодична. Если q > p, то, как и в первом случае,

получаем, что из ограниченности πk необходимо, чтобы C1 = 0, а из

начального условия следует, что C2 = 1, т.е. в случае q > p цепь тоже

получается эргодической. Это интуитивно понятно, ведь в случае q > p

есть «тенденция» движения «влево» по графу и в пределе человек

разоряется, какова бы не была его стартовая сумма денег. В обоих

случаях, разобранных выше, предельное распределение есть вектор

π = [1, 0, 0, . . . ]⊤. Если же p > q, то есть тендеция движения вправо,

а значит, чем больше было изначально денег у человека, тем меньше

вероятность, что он разорится, т.е. πk → 0 при k → ∞, а значит,

(︂ )︂k

C2 = 0, и из начального условия получаем πk =

q p

. Это означает,

175

что предел limn→∞ pk,0(n) = πk зависит от k, т.е. цепь не является

эргодической.

(︂ )︂k

Докажем теперь формулу πk =

q p

для q < p формально. Вот

тут-то и оказывается полезна ситуация с M < ∞. Вернёмся теперь к

случаю конечного M . Пусть πk,M — это вероятность того, что стартуя

из состояния k, цепь раньше окажется в состоянии 0, чем в состоянии

M за конечное число шагов. Тогда

πk,M = pπk+1,M + qπk−1,M , π0,M = 1, πM,M = 0.

Решая аналогичным способом данное рекуррентное уравнение, полу-

чим

(︂ )︂k (︂ )︂M q −q

p

p

πk,M =

(︂ )︂M , 0 ≤ i ≤ M.

1 − pq

(︂ )︂k

Следовательно, limM→∞ πk,M =

q p

(устремляем бюджет казино на

бесконечность), т.е. нам достаточно показать, что πk = limM→∞ πk,M .

Как и раньше, интуитивно это понятно, но мы покажем это строго.

Пусть Ak — событие, состоящее в том, что найдётся такое M , что

человек, имея в начале k рублей, разорится раньше, чем накопит M

рублей. Понятно, что πk = P(Ak). Кроме того, рассмотрим событие

Ak,M — событие, состоящее в том, что человек, имея в начале k рублей,

разорится раньше, чем накопит M рублей (для конкретного M ). Тогда

∞

⋃︂

Ak =

Ak,M и Ak,M ⊆ Ak,M+1.

M =k+1

По теореме непрерывности вероятности получаем

(︄ ∞

)︄

⋃︂

πk = P(Ak) = P

Ak,M

M =k+1

= lim P(Ak,M ) = lim πk,M .

M →∞

M →∞

(︂ )︂k

Итак, если p > q, то предел limn→∞ pk,0(n) =

q p

зависит от k. △

В заключение зафиксируем основные моменты, связанные с поня-

тием эргодичности для конечных и счетных марковских цепей.

Начнем с конечных цепей Маркова. Общая картина отражена на

рис. 17. При этом, как уже было отмечено ранее,

1) в случае непрерывных марковских цепей и апериодичных дис-

176

Эргодичность конечной марковской цепи

Единственность стационарного распределения

Единственность замкнутого класса эквивалентности

Рис. 17. Эргодичность для конечных марковских цепей. Стрелки означают логические импликации

кретных марковских цепей limt→∞ p(t) = π, где t ∈ R+ или t ∈ N,

2) в случае же периодических ОДМЦ предел нужно понимать в

более

слабом

смысле8

(по

Чезаро):

limn→∞

1 n

∑︁n−1
k=0

p(k)

=

π.

Если состояние i не принадлежит единственному замкнутому классу эквивалентности S∗, то πi = 0. Если же i ∈ S∗, то πi > 0.
Алгоритм анализа конечных марковских цепей
на эргодичность

1. Выделить классы эквивалентности.

2. Проверить единственность замкнутого класса S∗.

3. Найти стационарное (инвариантное) распределение на подцепи S∗, т.е. найти вектор π˜︁ ∈ R|S∗|, что P˜︁⊤π˜︁ = π˜︁, ∑︁i∈S∗ π˜︁i = 1, πi > 0, i ∈ S∗ (не умаляя общности, здесь мы считаем, что состояния ˜︁ 1, 2, . . . , |S∗| образуют класс S∗), где P˜︁ ∈ R|S∗|×|S∗|, P˜︁ij = Pij ∀i, j ∈ S∗.
8Как известно из курса математического анализа, из обычной сходимости числовой последовательности следует и сходимость по Чезаро. Обратное в общем случае неверно.

177

Эргодичность счётной марковской цепи

1. Единственность стационарного распределения 2. Число невозвратных состояний не более, чем конечно
(если такие состояния есть, то они (из пункта 1) могут быть только несущественными)

1. Существование и единственность замкнутого класса эквивалентности. При этом все состояния из этого класса должны быть положительно возвратными. 2. Число невозвратных состояний не более, чем конечно
(если такие состояния есть, то они (из пункта 1) могут быть только несущественными)
Рис. 18. Эргодичность для счетных марковских цепей. Стрелки означают логические импликации

4. Предельное распределение (в смысле 1) или 2), указанных вы-

ше):

{︄

πi, если i ∈ S∗,

lim pi(t) = ˜︁

t→∞

0 иначе.

Теперь перейдем к вопросу о счетных марковских цепях. Общая картина отражена на рис. 18. Сходимость понимается в том же смысле, как для конечных марковских цепей.
Алгоритм анализа счетных марковских цепей на эргодичность полностью аналогичен соответствующему алгоритму для случая конечных марковских цепей, за исключением пункта 2, который в счетном случае будет следующим (курсивом выделены отличия от случая конечной марковской цепи).
2.1. Проверить существование и единственность замкнутого поло-

178

жительно возвратного класса S∗. 2.2. Проверить конечность числа невозвратных состояний. Сравнение случаев конечных и счетных марковских цепей 1) В конечных марковских цепях замкнутый класс эквивалентно-
сти всегда существует. Более того, любой конечный замкнутый класс является положительно возвратным. В счетных цепях может быть не так (см. пример 6.2).
2) Если существует счетное число несущественных невозвратных состояний, цепь может остаться «жить» в этом «плохом» подмножестве состояний, не попав в замкнутый класс. Примеры с нарушением требования конечности числа невозвратных состояний: пример 6.1, пример 6.11.
3) Как для конечных, так и для счетных марковских цепей в случае, когда цепь разложима, финальное распределение всегда есть, однако в таком случае оно зависит от начального, поэтому цепь не является эргодической.
179

7. Непрерывные цепи Маркова

7.1. Базовые понятия и предположения
Начнем с обобщения определения 6.1 на случай непрерывного времени.
Определение 7.1. Случайная функция {ξ(t), t ≥ 0}, принимающая при каждом t значения из множества E = {0, 1, . . . }, конечного или бесконечного, называется марковским процессом с непрерывным временем и дискретным множеством значений (или непрерывной цепью Маркова), если для любых n ≥ 2, любых моментов времени 0 ≤ t1 ≤ · · · ≤ tn−1 ≤ tn и значений x1, . . . , xn ∈ E выполняется равенство
P(ξ(tn) = xn | ξ(tn−1) = xn−1, . . . , ξ(t1) = x1) =
= P(ξ(tn) = xn | ξ(tn−1) = xn−1).
Как и прежде, предполагается, что это равенство выполнено лишь в тех случаях, когда указанные условные вероятности существуют. Это равенство также называют марковским свойством непрерывной цепи Маркова. Множество E называется множеством состояний, а его элементы – состояниями цепи.
Определение 7.2. Вероятностью перехода из состояния i ∈ E в состояние j ∈ E непрерывной цепи Маркова называется функция двух аргументов:

pi,j(s, t) = P(ξ(t) = j | ξ(s) = i), 0 ≤ s ≤ t.

Набор чисел P (s, t) = {pi,j(s, t)} (конечный или бесконечный) образует

матрицу перехода. Матрица перехода непрерывной цепи, как и мат-

рица перехода дискретной цепи, обладает следующими очевидными

свойствами:

а)

∑︁
j∈E

pi,j (s,

t)

=

1

для

всех

i∈E

и

0 ≤ s ≤ t,

б) pi,i(t, t) = 1 для всех i ∈ E и t ≥ 0,

в) pi,j(t, t) = 0 для всех i ̸= j и t ≥ 0,

г) справедливо уравнение Колмогорова–Чэпмена:

P (s, t) = P (s, u)P (u, t), 0 ≤ s ≤ u ≤ t.

Отметим, что уравнение Колмогорова–Чэпмена прямо вытекает из

180

формулы полной вероятности. Определение 7.3. Вероятностью i-го состояния цепи ξ(t) в мо-
мент t ≥ 0 называется величина

pi(t) = P(ξ(t) = i).

Очевидно, что

∑︂ pi(t) ≥ 0, pi(t) = 1
i∈E

для любого момента t ≥ 0. Набор вероятностей p(t) = {pi(t)} называется распределением вероятностей состояний. Распределение p(t) удовлетворяет уравнению

p(t) = P T (s, t)p(s), 0 ≤ s ≤ t,

что, как и в случае дискретных цепей Маркова, является прямым следствием применения формулы полной вероятности и марковского свойства.
Определение 7.4. Непрерывная цепь Маркова с переходной матрицей P называется однородной, если для любых s, t ≥ 0

P (s, s + t) = P (0, t).

Для однородных цепей мы введем также обозначение P (t) = P (0, t), а элементы этой матрицы будем обозначать просто pi,j(t). Всюду далее, если не оговорено противное, непрерывные цепи Маркова будут предполагаться однородными.
Стоит сразу отметить, что так же, как и в случае общих случайных процессов в непрерывном времени, может возникнуть проблема с неизмеримостью некоторых множеств, например, supt∈[0,1] ξ(t). В случае дискретного времени таких проблем, конечно, не было, так как соответствующие множества выражались через не более, чем счетное число объединений и пересечений измеримых множеств, а значит были тоже измеримы. Напомним также, что в случае непрерывного времени возникают сложности в «неоднозначности» задания случайных процессов по семейству конечномерных распределений, так как появляется возможность «испортить» процесс в конечном и даже в счётном множестве случайных моментов времени. Чтобы избежать трудностей такого типа, мы (как и всегда) предполагаем сепарабельность процессов. В частности, для непрерывных цепей Маркова, везде далее предполагается, что реализации суть кусочно-постоянные функции непре-

181

рывные справа. Формальное понимание непрерывных цепей связано полугруппо-
вым свойством семейства матриц P (t): P (t + s) = P (t)P (s) для любых t, s ≥ 0, и требует языка теории групп (инфинитезимального оператора, порождающего группу и т.д.) Мы будем придерживаться более прикладного способа понимания непрерывных марковских цепей. Заметим прежде всего, что время между скачками марковской цепи в непрерывном времени имеет показательный закон распределения. Действительно, пусть в некоторый момент времени t0 цепь находится в состоянии i и случайная величина τi(t0) есть время ожидания до выхода из этого состояния:
τi(t0) = inf{u > 0 : X(u + t0) ̸= i}
Пусть в течение интервала наблюдения [t0, t1], где t1 = t0 + s, цепь не покидала i-го состояния, то есть τi(t0) > s. Тогда в силу однородности и марковости рассматриваемого процесса заключаем, что случайная величина τi(t0) не зависит от t0 и обладает свойством отсутствия памяти, то есть остаточное время пребывания цепи в i-ом состоянии в момент времени t1 (то есть τi(t1)) имеет такой же закон распределения, как и в момент времени t0 (то есть τi(t1)), иначе говоря τi(t0) = τi(t1) = τi, где равенство понимается как равенство по распределению, и:
P (τi(t0) > s + t|τi(t0) > s) = P (τi(t1) > t) = P (τi(t0) > t) .
В классе невырожденных непрерывных законов распределения этим свойством обладает только показательное распределение (с некоторым параметром, зависящем только от номера состояния):
P (τi > t) = e−λit.
Если λi ∈ (0, ∞), то цепь за малый промежуток времени ∆t изменит свое i-е состояние с вероятностью
λi∆t + o(∆t), ∆t → 0 + .
Если λi = 0, то цепь остается в i-ом состоянии навсегда (этот вырожденный случай соответствует τi = ∞ с вероятностью единица, то есть несобственная случайная величина). В этом случае состояние i называют поглощающим. Формально, возможна также ситуация, когда λi = ∞ (этот вырожденный случай соответствует τi = 0 с вероятно-
182

стью единица). В этом случае состояние i называют мгновенным, но мы не будем рассматривать такие ситуации (см. ниже).
По прошествии случайного времени τi с λi-показательным законом (λi ∈ (0, ∞)) цепь совершает скачок в новое состояние j с вероятностью, зависящей только от i и j, обозначим эту вероятность (при условии, что цепь совершает прыжок в новое состояние) ρi,j:

ρi,j = lim P (X(t + ∆t) = j|X(t) = i, X(t + ∆t) ̸= i) .
∆t→0+

Безусловная вероятность того, что цепь за малый промежуток време-

ни ∆t окажется в состоянии j ̸= i равна (1 − e−λi∆t)ρi,j. В связи с

этим будем далее предполагать, что переходные вероятность однород-

ной марковской цепи в непрерывном времени удовлетворяют следую-

щим условиям:

lim 1 − pi,i(∆t) = λi

(51)

∆t→0

∆t

lim pi,j (∆t) = λiρi,j ,

∑︂ i ̸= j, при этом ρi,j = 1

(52)

∆t→0 ∆t j̸=i

Отметим, что вместо (51), (52) можно предполагать

lim pi,j(∆t) = δi,j равномерно по i, j.

(53)

∆t→0

Тогда (51), (52) будут выполнены автоматически (см. [1]). Другими словами, эволюция непрерывной марковской цепи при
сделанных предположениях задаётся локальными характеристиками 1) λi, которые суть интенсивности выхода из состояния i, и 2) ρi,j. i ̸= j, которые суть условные вероятности того, что если цепь меняет свое состояние i, то скачок переводит цепь в состояние j ̸= i, либо 2’) Λi,j = λiρi,j, которые суть интенсивности перехода из состояния i в состояние j ̸= i.
Определение 7.5. Матрица Λ = ∥Λi,j∥|iE,j|=1 с компонентами Λi,j ≥ 0 для i ̸= j, Λi,i = −λi ≤ 0 называется инфинитезимальной матрицей непрерывной марковской цепи или генератором.
Определение 7.6. Для марковской цепи в непрерывном времени определим вложенную цепь или цепь скачков, как ОДМЦ на том же множестве состояний E с вероятностями перехода за один шаг pi,j = Λi,j /λi, pi,i = 0, если λi > 0 и pi,j = 0, pi,i = 1, если λi = 0.
Вложенная цепь или цепь скачков попросту фиксирует последовательность состояний, через которые проходит ξ(t) безотносительно к

183

длительностям пребывания в различных состояниях. Таким образом, задание непрерывной марковской цепи сводится к
заданию двух независимых объектов: 1) дискретной цепи скачков Xk, k = 0, 1, . . .; 2) последовательности независимых стандартных показательных случайных величин τ0, τ1, τ2, . . . Тогда формально

{︄

n
∑︂

τk

}︄

ξ(t) = Xη(t), η(t) = max n :

≤t .

(54)

k=0 λXk

Ограничения на инфинитезимальную матрицу. Отметим ещё

раз, что в данном пособии рассматриваются консервативные цепи, то

есть все элементы инфинитезимальной матрицы конечны и сумма эле-

ментов

каждой

строки

равна

нулю:

λi

=

∑︁
j̸=i

Λi,j

<

∞

для

любого

i ∈ E. Теория марковских цепей, не удовлетворяющих условиям кон-

сервативности, гораздо сложнее. Например, если разрешить для неко-

торого состояния i λi = ∞, то такое состояние называют мгновенным,

так как, попав в такое состояние, цепь мгновенно его покидает: ве-

роятность того, что время нахождения в мгновенном состоянии поло-

жительно, равна нулю. Если разрешить инфенитезимальной матрице

сумму

по

строке

иметь

не

нулевую,

а

отрицательную:

∑︁
j∈E

Λi,j

≤

0,

то соответствующая матрица переходных вероятностей P (t) будет суб-

стохастической:

∑︁
j∈E

Pi,j

(t)

≤

1.

В

этом

случае

цепь

с

положительной

вероятностью «уходит» на бесконечность. Также в данном пособии не

будут рассматриваться так называемые взрывные цепи: когда на ко-

нечном интервале времени цепь может совершить бесконечно много

прыжков и «уйти» из любого конечного подмножества E (такая ситу-

ация невозможна, если цепь конечная, т.е. |E| < ∞). Другими слова-

ми, марковская цепь в непрырывном времени будет невзрывной, если

с вероятностью один выполнено

lim Tn = ∞,
n→∞
где Tn – момент времени n−го прыжка ξ(t). Для невзрывных цепей в формуле (54) для любого конечного t η(t) < ∞. Достаточным условием отсутствия взрыва является равномерная ограниченность параметров λi, то есть supi∈E λi ≤ c < ∞ (см. далее теорему 7.1). Действительно, если λ = supi∈E λi ≤ c < ∞, то
P (Tn+1 − Tn ≥ t) ≥ e−λt.

Тогда по лемме Бореля–Кантелли с единичной вероятностью произой-

184

дет бесконечно много событий {Tn+1 − Tn ≥ t}. Откуда будет следовать, что
lim Tn = ∞.
n→∞

Примером взрывной марковской цепи является процесс чистого раз-

множения, где интенсивности перехода зависят от номера состояния

так,

что

∑︁
i∈E

Λ−i,i1+1

<

∞

(см.

[30,

теорема

2.5.3]

или

[62,

Т.

1,

гл.

XVII,

§ 4]).

Отметим также, что вместо требуемых ограничений на инфините-

зимальную матрицу можно накладывать условия на переходные веро-

ятности(53).

Разобьём промежуток времени [0, t + ∆t) на два интервала [0, ∆t)

и [∆t, t + ∆t). В зависимости от того, был или не был скачок в малом

промежутке времени [0, ∆t) мы можем записать по формуле полной

вероятности:

∑︂ pi,j(t + ∆t) = pk,j(t)Λi,k∆t + pi,j(t)(1 − λi∆t) + o(∆t)
k̸=i
или pi,j(t + ∆t) − pi,j(t) ∑︂ = pk,j (t)Λi,k − pi,j (t)λi + o(1). ∆t
k̸=i
Переходя к пределу ∆t → 0, получаем матричное дифференциальное уравнение первого порядка

P˙ (t) = ΛP (t),

(55)

(где точка означает дифференцирование по времени t) c начальным условием P (0) = I. Полученное уравнение называют обратными уравнением Колмогорова–Феллера. Стоит отметить, что переход к пределу ∆t → 0 при выводе обратных уравнений законен в рамках принятых предположений (51) и (52).
Разобьём теперь промежуток времени [0, t + ∆t) на два интервала [0, t) и [t, t + ∆t). В зависимости от того, был или не был скачок в малом промежутке времени [t, t + ∆t) мы можем записать по формуле полной вероятности:

∑︂ pi,j(t + ∆t) = pi,k(t)Λk,j∆t + pi,j(t)(1 − λj∆t) + o(∆t)
k̸=j

185

или pi,j(t + ∆t) − pi,j(t) ∑︂ = pi,k(t)Λk,j − pi,j (t)λj + o(1). ∆t
k̸=j
Стоит отметить, что теперь для для существования предела при ∆t → 0 в правой части последнего выражения помимо принятых условий (51) и (52) требуется дополнительное предположение о том, что при фиксированном j переход к пределу в (52) равномерен по i. В итоге получаем матричное дифференциальное уравнение первого порядка

P˙ (t) = P (t)Λ, P (0) = I.

(56)

Полученное уравнение называют прямым уравнением Колмогорова– Феллера.
Ясно, что если |E| < ∞, то единственным решением этих уравнений является матричная экспонента

P (t) = exp(tΛ).

Этот факт будет верен и для случая бесконечных матриц с учётом принятых выше ограничений на инфинитезимальную матрицу, а именно, что supi∈E λi < ∞ (см. теорему Колмогорова 7.2). То есть на самом деле, в предположении, что цепь невзрывная (на конечном интервале времени происходит лишь конечное число скачков) обе системы прямых и обратных уравнений эквивалентны. При этом наше дополнительное предположение о равномерности предела в условии (52) при выводе прямых уравнений носит технический характер, его можно избежать, если уравнения записывать в терминах преобразования Лапласа (см. [62, Т. 2, гл. XIV, § 7]).
Под уравнениями Колмогорова–Феллера также понимают уравнения не на матрицу P (t) , а на вектор распределения вероятностей p(t):
p˙(t) = ΛT p(t).

Теорема 7.1. Пусть матрица Λ такова, что

Λi,i≤0, Λi,j ≥ 0, i ̸= j,

∑︂ Λi,j = 0,
j
Тогда для любого t ≥ 0

∑︂ sup |Λi,j| ≤ C < ∞.
i∈E j

186

а)

ряд

∑︁∞ tkΛk
k=0 k!

сходится ;

б) матричная экспонента P (t) = etΛ = ∑︁∞ k=0 tkkΛ!k является стохастической матрицей;

в) P (t) дифференцируемо по t, причем dPd(tt) = ΛP (t) = P (t)Λ, P (0) = I.

В пособии рассматриваются только инфинитезимальные матрицы Λ, удовлетворяющие этой теореме.
Доказательство. Пункт а) следует из верхней оценки для нормы (например, l∞−нормы)

⃦∞ ⃦∑︂

tk Λk

⃦ ⃦

∞
∑︂

tk ∥Λ∥k

∥etΛ∥∞ = ⃦

⃦≤

∞ = et∥Λ∥∞ ≤ etC .

⃦⃦k=0 k! ⃦⃦∞ k=0 k!

Для доказательства пункта б) заметим, что неотрицательность элементов матричной экспоненты следует из

P (t) = etΛ = e−tC et(Λ+CI),

где матрица Λ + CI состоит из неотрицательных элементов. Сумма в каждой строке матрицы P (t) равна единице, поскольку

∑︂ tkΛk

P (t) = I +

,

k≥1 k!

где сумма в каждой строке матрицы Λk, k ≥ 1, равна нулю. Пункт в) следует из дифференцирования представления матричной экспоненты в виде сходящегося ряда (пункт а) и коммутативности степеней матрицы Λ (в условиях теоремы). □
Сгруппируем все полученные результаты в рамках одной теоремы, доказательство которой можно посмотреть в [7, гл. 21, § 2, теорема 2.2], либо [62, Т. 2, гл. XIV, § 7, следствие 1]
Теорема 7.2. В однородных непрерывных цепях Маркова в предположениях теоремы 7.1 справедливы следующие уравнения:
P˙ (t) = P (t)Λ, P (0) = I,

P˙ (t) = ΛP (t), P (0) = I, p˙(t) = ΛT p(t),

187

где Λ – инфинитезимальная матрица, P (t) – матрица перехода, p(t) – распределение вероятностей состояний, I – единичная матрица. Единственным решением первых двух уравнений является матричная экспонента
P (t) = exp(tΛ).
Отметим, что при отсутствии ограничений на инфинитезимальную матрицу, либо при отсутствии условия (53) ситуация сильно усложняется, см., например, [1].
Рассмотрим теперь несколько конкретных примеров. Непрерывные цепи Маркова удобно обозначать в виде ориентированных графов, в вершинах которых расположены состояния цепи, а веса ребер между состояниями равны интенсивностям перехода между состояниями (в дискретных цепях там стоит вероятность перехода за один шаг).
Пример 7.1. Записать и решить уравнения Колмогорова–Феллера для процесса Пуассона с интенсивностью λ.
Решение. Инфинитезимальная матрица Λ = ∥Λi,j∥∞ i,j=1 имеет следующий вид:

⎡−λ λ 0 0 0 . . .⎤

⎢⎢ 0 −λ λ 0 0 . . .⎥⎥

Λ=⎢ ⎢ ⎢0

0 −λ λ 0 . . .⎥⎥⎥ ,

⎣ ... . . . . . . . . . . . . . . .⎦

т.е. для элементов матрицы Λ справедлива следующая формула:
⎧ ⎪−λ, если j = i, ⎨ Λi,j = λ, если j = i + 1, ⎪⎩0 иначе.
Обратные уравнения Колмогорова–Феллера записываются в виде

p˙i,j (t) = −λpi,j (t) + λpi+1,j (t),

с начальным условием pi,j(t) = δij. Ясно, что для всех j < i pi,j(t) = 0, а при i ≤ j pi,j(t) = p0,j−i(t). Таким образом, достаточно найти p0,i(t).

Сделаем замену, обозначив fi(t) = p0,i(t)eλt. Тогда

{︂ f˙0(t) = 0, fi(0) = 1,

188

а для i ≥ 1 Откуда

{︂ f˙i(t) = λfi−1(t), fi(0) = 0.

А значит

f0(t) = 1, f1(t) = λt,
(λt)2 f2(t) = 2! , ...
(λt)i fi(t) = i! .

{︄ (λt)j−i , pi,j (t) = (j−i)!
0,

если j ≥ i, иначе.

Прямые уравнения имеют вид

p˙i,j (t) = −λpi,j−1(t) + λpi+1,j (t),

с начальным условием pi,j(t) = δij. Решение будет таким же. △

В следующих примерах приведены методы получения распреде-

ления в момент времени t и переходной матрицы в момент времени

t. Важно заметить, что при решении задачи о предельном поведении

марковской цепи, не разумно честно вычислять p(t) и P (t). Правильно

воспользоваться результатами ниже из раздела 7.3.

Пример 7.2. Найти распределение вероятностей состояний p(t) и

переходную матрицу P (t) для следующей непрерывной цепи Маркова

(λ > 0, µ > 0).

Решение. В первую очередь выпишем матрицы Λ и Λ⊤ для данной

цепи. По условию задачи, Λ0,1 = λ, Λ1,0 = µ. Так как Λ0,0 + Λ0,1 = 0,

то Λ0,0 = −λ. Аналогично, так как Λ1,0 + Λ1,1 = 0, то Λ1,1 = −µ.

Поэтому

Λ = [︃ −λ

λ ]︃ ,

Λ⊤

[︃ =

−λ

µ ]︃ .

µ −µ

λ −µ

Теперь запишем дифференциальное уравнение Колмогорова:

p˙(t) = Λ⊤p(t),

где p(t) = [p0(t), p1(t)]⊤. Это однородная линейная система дифферен-

189

циальных уравнений, которую можно решить двумя способами. Способ 1 (общий). Как известно, решение линейных систем урав-
нений представляет собой линейную комбинацию линейно независимых решений. Линейно независимые решения можно искать через собственные (и, быть может, присоединенные) векторы и собственные числа матрицы системы. Найдем собственные числа матрицы Λ⊤:

⃓

⃓

⃓ −λ − r ⃓

µ ⃓⃓ = r2 + (λ + µ)r = 0,

⃓ λ −µ − r ⃓

откуда r1 = 0 и r2 = −(λ + µ) < 0. В действительности, для матрицы размера 2 даже не нужно решать квадратное уравнение для поиска собственных значений, так как одно собственное значение 0, а второе находится, зная след матрицы. Так как собственные числа различные, то собственных векторов будет достаточно, чтобы сформировать линейно независимые решения. При r = 0 получаем

Λ⊤ − rI

[︃ =

−λ

µ ]︃ ,

λ −µ

откуда собственный вектор v1 = [µ, λ]⊤. При r = −(λ + µ) получаем

Λ⊤ − rI

[︃ =

µ

µ ]︃ ,

λλ

откуда собственный вектор v2 = [1, −1]⊤. Отсюда получаем общий вид решения:

p(t) = C v

[︃ + C v e−t(λ+µ) =

C1µ + C2e−t(λ+µ)

]︃ .

11

22

C1λ − C2e−t(λ+µ)

Пусть в начальный момент времени известно распределение p(0) =

190

= [p0(0), p1(0)]⊤. Получаем систему линейных уравнений относительно C1 и C2:

{︄

C1µ + C2 = p0(0) ⇒ C1 = 1 , C2 = λp0(0) − µp1(0) .

C1λ − C2 = p1(0)

λ+µ

λ+µ

Значит, искомые вероятности

p0(t) = µ + λp0(0) − µp1(0) e−t(λ+µ),

λ+µ

λ+µ

p1(t) = λ − λp0(0) − µp1(0) e−t(λ+µ).

λ+µ

λ+µ

Способ 2 (простой). Запишем сначала уравнения по отдельности:

p˙0 = µp1 − λp0,

p˙1 = λp0 − µp1.
Затем воспользуемся равенством p0(t) + p1(t) = 1, которое выполнено в любой момент времени t, и сведем задачу к одному уравнению:

p˙0 = −(λ + µ)p0 + µ,

решение которого имеет вид

p0(t) = Ce−t(λ+µ) +

µ .

λ+µ

Константа C находится из начального условия p0(0). Далее определяется
p1(t) = 1 − p0(t).

Теперь перейдем к вычислению переходной матрицы P (t). Для этого
возьмем уравнения P˙ (t) = P (t)Q

и заметим, что каждая строка Pi(t) матрицы P (t) удовлетворяет урав-
нениям P˙i⊤(t) = Λ⊤Pi⊤(t).

Общий вид этих уравнений нам уже известен, и мы можем сразу на-

писать:

P0,0(t) = µ + λP0,0(0) − µP0,1(0) e−t(λ+µ),

λ+µ

λ+µ

191

P0,1(t) = λ − λP0,0(0) − µP0,1(0) e−t(λ+µ),

λ+µ

λ+µ

P1,0(t) = µ + λP1,0(0) − µP1,1(0) e−t(λ+µ),

λ+µ

λ+µ

P1,1(t) = λ − λP1,0(0) − µP1,1(0) e−t(λ+µ).

λ+µ

λ+µ

Теперь остается вспомнить, что P0,0(0) = P1,1(0) = 1, P0,1(0) = P1,0(0) =
= 0, тогда P0,0(t) = µ + λ e−t(λ+µ), λ+µ λ+µ

P0,01(t) = λ − λ e−t(λ+µ), λ+µ λ+µ
P1,0(t) = µ − µ e−t(λ+µ), λ+µ λ+µ

P1,1(t) = λ + µ e−t(λ+µ). △ λ+µ λ+µ

192

Пример 7.3. Найти распределения вероятностей состояний p(t) и переходную матрицу P (t) для следующей непрерывной цепи Маркова.

Решение. Выпишем матрицы Λ и Λ⊤ данной цепи:

⎡ −1 1 0 ⎤

⎡ −1 0 1 ⎤

Λ = ⎣ 0 −1 1 ⎦ , Λ⊤ = ⎣ 1 −1 0 ⎦ ,

1 0 −1

0 1 −1

составим характеристическое уравнение:

⎡ −1 − λ

⎣

1

0

0 −1 − λ
1

1⎤ 0 ⎦ = −(1 + λ)3 + 1 = 0
−1 − λ

и найдем собственные числа

√

3

3

λ1 = 0, λ2 = − 2 + i 2 ,

√

3

3

λ3 = − 2 − i 2 .

Так как все собственные числа различные, то общий вид уравнения

p˙(t) = Λ⊤p(t)

будет выглядеть следующим образом: p(t) = C1v1 + C2Re (︁v2etλ2 )︁ + C3Im (︁v2etλ2 )︁ ,

где v1 и v2 – собственные векторы, отвечающие собственным значениям λ1 и λ2 соответственно. Явное выражение для p(t) можно получить двумя способами.

193

Способ 1 (общий). Найдем все собственные векторы. При λ = 0

⎡ −1 0 1 ⎤ Λ⊤ − λI = ⎣ 1 −1 0 ⎦ ,
0 1 −1

√

откуда

собственный

вектор

v1

=

[1, 1, 1]⊤.

Для

λ

=

− 32

+i

3 2

введем

обозначение ρ = 1 + λ = e2πi/3, тогда

⎡ −ρ 0 1 ⎤ ⎡ 1 0 −ρ−1 ⎤ ⎡ 1 0 −ρ−1 ⎤

Λ⊤−λI = ⎣ 1 −ρ 0 ⎦ ∼ ⎣ 1 −ρ

0 ⎦ ∼ ⎣ 0 −ρ ρ−1 ⎦ ∼

0 1 −ρ

0 1 −ρ

0 1 −ρ

⎡ 1 0 −ρ−1 ⎤

⎡ 1 0 −ρ−1 ⎤

∼ ⎣ 0 1 −ρ−2 ⎦ ∼ [−ρ + ρ−2 = 0] ∼ ⎣ 0 1 −ρ−2 ⎦ ,

0 1 −ρ

00

0

откуда v2 = [ρ−1, ρ−2, 1]⊤, или можно взять v2 = [ρ, 1, ρ2]⊤. Далее,

⎡ v2etλ2 = ⎢
⎣

√
− 21 + i 23 1√
− 12 − i 23

⎤ (︄ √

√ )︄

⎥

e−

3 2

t

cos

3 t + i sin

3 t

,

⎦

2

2

откуда

⎛⎡

Re

(︁v2etλ2 )︁

=

e−

3 2

t

⎝⎣

−1/2 1
−1/2

⎤√ ⎡ 3
⎦ cos t + ⎣ 2

√ − 3/2 √0
3/2

⎤ √⎞ 3
⎦ sin t⎠ , 2

√ ⎛⎡ 3/2 ⎤

√

⎡ −1/2 ⎤ √ ⎞

Im

(︁v2etλ2 )︁

=

e−

3 2

t

⎝⎣

√0

3

3

⎦ cos t + ⎣ 1 ⎦ sin t⎠ .

2

2

− 3/2

−1/2

Отсюда можно получить выражение для распределения вероятностей

p(t). Остается лишь воспользоваться начальным условием p(0) для по-

иска C1, C2 и C3. Способ 2 (простой). Найдем собственный вектор v1 = [1, 1, 1]⊤,

это было сделано в предыдущем пункте. Далее, так как Re(λ2,3) < 0,

то в пределе

⎡1⎤

p(t) → C1 · ⎣ 1 ⎦ .

1

194

Но так как сумма компонент вектора p(t) равна 1 для любого t, то же самое справедливо и для предела. Значит, C1 = 1/3, причем независимо от начального распределения p(0). Далее заметим, что решение может быть представлено в виде

√

√

p(t)

=

C1

+

C2

·

e−

3 2

t

cos

3

t

+

C3

·

e−

3 2

t

sin

3 t

2

2

с некоторыми постоянными векторами C1, C2 и C3, причем мы уже нашли C1 = [1/3, 1/3, 1/3]⊤. Но тогда в начальный момент времени

⎡ p0(0) − 1/3 ⎤ p(0) = C1 + C2 ⇒ C2 = ⎣ p1(0) − 1/3 ⎦ .
p2(0) − 1/3

Константу C3 находим из соотношения

⎡ p2(0) − p0(0) ⎤ 3

√ 3

p˙(0) = Λ⊤p(0) = ⎣ p0(0) − p1(0) ⎦ = − C2 + C3,

p1(0) − p2(0)

2

2

откуда получаем

2

√

C3 = √ p˙(0) + 3 · C2.

3

Что касается компонент переходной матрицы, то, как мы уже поняли ранее, ее строки удовлетворяют тем же самым дифференциальным уравнениям, что и p(t), а значит, вид решения для них тот же самый. Отличие будет лишь в том, что надо воспользоваться начальным условием P (0) = I и соотношением P˙ (0) = P (0)Λ = Λ для определения констант интегрирования. △

7.2. Классификация состояний
Перейдем теперь к классификации состояний непрерывной цепи Маркова. Сделать это можно аналогично тому, как это делалось для дискретных цепей Маркова (см., например, [66]).
Определение 7.7. Состояния k, j ∈ E называются сообщающимися, если
(∃t > 0 : pk,j(t) > 0) ∧ (∃τ > 0 : pj,k(τ ) > 0) .

195

Иначе состояния k, j ∈ E называются несообщающимися:
(∀t > 0 pk,j(t) = 0) ∨ (∀τ > 0 pj,k(τ ) = 0) .
Определение 7.8. Состояние k ∈ E называется несущественным, если
∃j ∈ E : (∃t > 0 pk,j(t) > 0 ∧ ∀τ ≥ 1 pj,k(τ ) = 0) . Иначе состояние k ∈ E называется существенным:
∀j ∈ E (∀t > 0 pk,j(t) = 0) ∨ (∃τ > 0 pj,k(τ ) > 0) .
Определение 7.9. Состояние k ∈ E называется возвратным, если
P(ω : {t : ξ(ω, t) = k} не ограничено) = 1.
Состояние k ∈ E называется невозвратным, если
P(ω : {t : ξ(ω, t) = k} не ограничено) = 0.
Определение 7.10. Состояние k ∈ E называется нулевым, если
lim pk,k(t) = 0.
t→∞
Иначе состояние k называется ненулевым. Заметим, что для непрерывных цепей Маркова понятия периоди-
ческого состояния нет. Для непрерывных цепей Маркова известен критерий возвратности
состояния, аналогичный критерию для дискретных цепей Маркова. Теорема 7.3 (критерий возвратности). Состояние k ∈ E явля-
ется возвратным тогда и только тогда, когда
ˆ+∞ pk,k(t) dt = +∞.
0
С доказательством этой теоремы ознакомиться здесь [30, теорема 2.7.11, § 2.7, глава 2] или в [66].
Определение 7.11. Непрерывная цепь Маркова называется неразложимой, если все ее состояния сообщаются.
Определение 7.12. Распределение π(t) называется стационарным, если
∀t ≥ 0 π = P ⊤(t)π,
196

или π˙ (t) = 0 ⇔ Λ⊤π = 0. Уравнения Λ⊤π = 0 называются алгебраиче-

скими уравнениями Колмогорова.

Иными словами, стационарное распределение – собственный вектор

матрицы Λ⊤ для собственного значения 0, удовлетворяющий условиям

нормировки

∑︁
k≥1

πk

=

1

и

неотрицательности

компонент.

Как

и

было

уже сказано, 0 всегда является собственным значением для матриц Λ

и Λ⊤. Но так же, как и в случае дискретных марковских цепей, со-

ответствующий собственный вектор может не удовлетворять условию

нормировки (такая ситуация может возникнуть только для цепей со

счетным числом состояний).

Замечание 1. Стоит отметить, что классификация состояний непре-

рывных цепей эквивалентна классификации состояний соответствую-

щей дискретной цепи скачков (или вложенной цепи) (см. определе-

ние 7.6). Стоит отметить также, как связаны стационарные распре-

деления непрерывной марковской цепи и дискретной цепи её скачков

(в предположении, что стационарное распределение единственно). Ес-

ли π˜ – стационарное распределение цепи скачков, т.е. P˜T π˜ = π˜ или ∑︁j̸=i π˜j ΛΛjj,i = πi для всех i ∈ E, то стационарное распределение непре-

рывной

цепи

πi

=

π˜iΛ−i 1/

∑︁
j∈E

π˜j

Λ−j 1.

Например,

если

непрерывная

цепь задается стохастическим графом, как на рис. 19, то соответству-

ющая дискретная цепь – простое блуждание на полуоси с отражающим

0-состоянием и вероятностями шага вправо λ/(λ+µ) и влево µ/(λ+µ).

При λ/(λ + µ) > 1/2, т.е. λ > µ, цепь невозвратна, а значит, все со-

стояния нулевые, при λ/(λ + µ) = 1/2, т.е. λ = µ, цепь возвратна, но

все состояния нулевые (нуль-возвратность, то есть время возвращение

имеет бесконечное математическое ожидание), и при λ/(λ + µ) < 1/2,

т.е. λ < µ, существует стационарное распределение π˜k = µ22−λµλ2 (︂ µλ )︂k,

k

≥

1,

π˜0

=

µ−λ 2µ

и

цепь

возвратна

с

ненулевыми

состояниями

(поло-

жительная возвратность) (см. пример 6.8). В последнем случае стаци-

онарное распределение непрерывной цепи πk = µ2−µλ2 (︂ µλ )︂k, k ≥ 1 и

π0 = µ−µλ .

197

Рис. 19. Процесс рождения/гибели с параметрами λ/µ
7.3. Эргодические непрерывные цепи Маркова
Теорема 7.4. (см. [30, теорема 2.8.1]) В непрерывных цепях Маркова всегда существуют пределы
lim pi,j (t) = p∗i,j .
t→∞
Определение 7.13. Непрерывная однородная цепь Маркова называется сильно эргодической, если для любого состояния j ∈ E существует не зависящий от состояния i ∈ E положительный предел:
lim pi,j(t) = p∗j > 0.
t→∞
Несложно заметить, что если непрерывная однородная цепь Маркова сильно эргодическая, то стационарное распределение π единственное и p∗ = π.
Поскольку асимптотическое поведение непрерывных марковских цепей в случае отсутствия взрыва (то есть, удовлетворяющих условиям теоремы 7.1) равносильно асимптотическому поведению дискретной цепи скачков, то следствием эргодических теорем из предыдущего раздела является
Теорема 7.5 (эргодическая теорема). Для непрерывной однородной цепи Маркова с конечным или счётным числом состояний следующие утверждения эквивалентны:
а) цепь сильно эргодична, т.е. для любых состояний i, j lim pi,j(t) =
t→∞
πj > 0;
б) существует такое t0, что все элементы матрицы P (t0) положительны ;
в) существует единственное стационарное распределение, все компоненты которого положительны;
198

г) существует единственное стационарное распределение у цепи скачков, все компоненты которого положительны.

Кроме того, для сильно эргодической цепи выполнено следующее:

а) для любого начального распределения и для любого j ∈ E имеет место сходимость pj(t) → πj при t → ∞;

б) для любого начального распределения и для любого j ∈ E

ˆT

1

п.н.

I(ξ(s) = j) ds −→ πj, T → ∞.

T

0

Замечание. В случае конечных непрерывных цепей для сильной эргодичности необходимо и достаточно неразложимости, т.е. не нужна апериодичность (как было в дискретном случае), которую к тому же и непонятно как в непрерывном времени и определять. По этим же причинам наличие периода у цепи скачков не влияет на эргодичность непрерывной цепи. Подробности можно найти в конце раздела 6. В частности, отметим, что теорема 6.14 верна и в случае марковских цепей с непрерывным временем. Более того, все результаты раздела 6 переносятся на непрерывные однородные марковские цепи без изменения, за исключением отсутствия необходимости требовать аппериодичность. Сходимость в непрерывном времени всегда имеет место в обычном смысле (не только по Чезаро). Таким образом, более слабое условие эргодичности, не требующее положительности предела из определения 7.13, равносильно эргодичности (не в сильном смысле) дискретной цепи скачков, то есть что при любом начальном распределении цепь с единичной вероятностью попадает в единственный положительно-возвратный класс эквивалентности, так что предельное распределение совпадает со стационарным, которое равно нулю вне замкнутого положительно-возвратного класса эквивалентности.
В качестве примера использования марковских цепей в прикладных областях рассмотрим задачи из теории систем массового обслуживания (СМО).
Пример 7.4. Пусть имеется N серверов и входной поток заявок, который предполагается пуассоновским с параметром λ. Каждая заявка вне зависимости от остальных, поступив в систему, обслуживается любым из свободных серверов в течение случайного времени, распределенного по показательному закону с параметром µ, или безвозвратно покидает систему, если свободных серверов нет. Пусть X(t) – марков-

199

ская цепь на множестве состояний S, равных числу занятых серверов, или, иначе говоря, числу заявок в системе, т.е. S = {0, 1, . . . , N }. Требуется найти предельное распределение числа заявок в системе. Стохастический граф для этой задачи представлен на рис. 20.

Рис. 20. К примеру 7.4

Действительно, если в текущий момент времени в системе k ≤ N

заявок, каждая из них имеет остаточное время обслуживания – пока-

зательное с тем же параметром µ (в силу свойства отсутствия памяти

у показательного закона). Минимум из k независимых показательных

случайных величин имеет также показательный закон с суммарной

интенсивностью, то есть в нашем случае kµ.

Так как цепь конечна и неразложима, то согласно теореме 7.5 и за-

мечания к ней существует предельное распределение, которое совпада-

ет с единственным стационарным распределением, которое находится

из

решения

Λ⊤π

=

0,

∑︁N
j=0

πj

=

1,

πj

≥

0.

Легко

проверить,

что

реше-

нием является неполное пуассоновское распределение:

(︄∑N︂ (λ/µ)k )︄−1 (λ/µ)j

πj = k!
k=0

. j!

Можно этой задаче дать немного другую интерпретацию. Пусть серверы – это служащие некоторой компании, заявки – клиенты. Каждый обслуженный клиент (есть еще клиенты, которые если не могут сразу переговорить с представителем компании, то больше не приходят) приносит доход компании в A рублей. Заработная плата служащего составляет B рублей в час. Считается, что параметры λ−1 и µ−1 имеют единицы измерения часы. Требуется найти оптимальное число служащих.
Будем считать, что директор компании рассчитывает доход своей фирмы в предположении длительной ее работы. Тогда согласно эргодической теоремы предельное распределение занятых служащих совпадает со стационарным, и число клиентов, обслуженных в течение

200

часа,

можно

оценить,

как

∑︁N
j=1

j

πj

.

Доход

компании

в

течение

часа

составляет J(N ) = A ∑︁Nj=1 jπj − BN . Остается решить задачу опти-

мизации J(N ) → max, учитывая, что πj := πj(N ). △

Пример 7.5. Пусть на остановку приходят автобусы согласно пуас-

сновскому процессу с параметром µ. Поток пассажиров, приходящих

на остановку, тоже считается пуассоновским с параметром λ и незави-

сящим от прихода автобусов. Предполагается, что автобус, подошед-

ший к остановке, забирает всех пассажиров, ожидающих транспорт.

Требуется найти предельное распределение числа пассажиров, ожи-

дающих на остановке автобус. Для решения задачи рассмотрим мар-

ковскую цепь X(t), где X(t) ∈ {0, 1, 2, . . .} – число людей на остановке.

Стохастический граф, описывающий динамику цепи, представлен на

рис. 21.

Рис. 21. К примеру 7.5

Это пример счетной цепи. Легко проверить, что геометрическое

(︂ )︂j

распределение

πj

=

λ+µ µ

λ λ+µ

является стационарным распределе-

нием. С учетом неразложимости оно будет единственным, и согласно

теореме 7.5 это и будет предельным распределением. △

Очень важный класс цепей образуют процессы гибели и рождения.

По определению, это цепи со стохастическим графом, как на рис. 22.

Известны формулы для вычисления стационарного распределения

состояний таких процессов:

(︃ λ1 λ1λ2

λ1 . . . λN )︃−1

π0 = 1 + µ1 + µ1µ2 + . . . µ1 . . . µN ,

πk = µλkk πk−1, k = 1, . . . , N. △

201

Рис. 22. Стохастический граф процесса гибели и рождения
7.4. Поведение цепи и время возвращения
В заключение данного раздела приведем несколько более формальную сторону факта о том, как ведет себя непрерывная цепь Маркова при базовых предположениях.
Введем для состояния i ∈ E на множестве Ωi = {ω : ξ(ω, 0) = i} случайную величину:
τi(ω) = inf{t : t > 0, ξ(ω, t) ̸= i}.
Она называется моментом первого выхода из состояния i. Тогда если λi = −Λi,i < ∞ (в конечных цепях в базовых предположениях это выполнено), то
P(τi ≥ t | ξ(0) = i) = e−λit, t ≥ 0,
т.е. время, проведенное в каждом состоянии цепи, имеет показательное распределение с параметром λi. Поэтому среднее время пребывания в состоянии i есть λ−i 1.
Введем на Ωi = {ω : ξ(ω, 0) = i} случайную величину
ηi(ω) = ξ(ω, τi(ω)).
Это состояние, в котором окажется цепь после прыжка из состояния i. Тогда в наших обозначениях
P(ηi = j | ξ(0) = i) = (1 − δij)Λi,j = pi,j, Λi
где δij – символ Кронекера. Это вероятность того, что после состояния i цепь примет состояние j.
Введем теперь на множестве Ωi = {ω : ξ(ω, 0) = i} случайные вели-
202

чины:

αij(ω) = inf{t : t > τi(ω), ξ(ω, t) = j}, j ∈ E.

Оказывается, что если состояние i возвратное и для него 0 < λi < ∞

(все это выполнено для произвольного состояния в неразложимой ко-

нечной цепи), то

1

lim pi,i(t) =

.

t→∞

ΛiE(αii | Ωi)

Этой формулой можно пользоваться для того, чтобы в сильно эргодической цепи вычислить среднее время возвращения в состояние i, т.е.
1 E(αii | Ωi) = Λiπi .

203

8. Непрерывные процессы Маркова
8.1. Уравнения Колмогорова
Определение 8.1. Случайный процесс X(t), t ∈ R, называется марковским процессом, если ∀n ∈ N ∀t1 < t2 < . . . < tn < tn+1 ∀xn ∈ R и для любых борелевских множеств B1, B2, . . . , Bn−1, Bn+1 выполняется
P (X(tn+1) ∈ Bn+1 | X(tn) = xn, X(tn−1) ∈ Bn−1, . . . , X(t1) ∈ B1) =
= P (X(tn+1) ∈ Bn+1 | X(tn) = xn) .
Говоря неформальным языком, данное определение можно интерпретировать следующим образом: марковский процесс — это случайный процесс, у которого «будущее» определяется только «настоящим» и не зависит от «прошлого».
Пример 8.1. Любой процесс Леви является марковским процессом, что гарантирует свойство независимости приращений. В частности, винеровский и пуассоновский процессы являются марковскими.
Оставшуюся часть данного раздела мы посвятим изучению марковских процессов с непрерывным временем и континуальным числом состояний, а именно, мы приведем так называемые первое и второе уравнения Колмогорова, на которые можно смотреть, как на обобщения и следствия уравнений Колмогорова–Феллера и Колмогорова– Чэпмена.
Рассмотрим условную функцию распределения
FX (x, t | x0, t0) = P (X(t) < x | X(t0) = x0)
и условную плотность распределения (в предположении, что она существует)
d pX (x, t | x0, t0) = dx FX (x, t | x0, t0). При выводе уравнения Колмогорова–Феллера мы пользовались формулой полной вероятности
P (X(t) = j | X(0) = i) =
t1 <t
∑︂ = P (X(t1) = k | X(0) = i) P (X(t) = j | X(t1) = k) ,
k
которая в случае однородных марковских цепей эквивалентна очевид-
204

ному равенству

P t = P t1 P t−t1 ,

где P — матрица переходных вероятностей. Отметим, что момент времени t1 можно выбрать произвольным из интервала (0, t), а суммирование ведётся по всем возможным состояниям. Данный подход легко переносится и на случай континуального числа состояний: обуславливая функцию распределения по всем возможным состояниям v в промежуточный момент времени t1, получаем уравнение
ˆ
FX (x, t | x0, t0) = FX (x, t | v, t1)dvFX (v, t1 | x0, t0) =

ˆR = FX (x, t | v, t1)pX (v, t1 | x0, t0) dv.
R

Дифференцируя левую и правую части предыдущего равенства по

x, получаем непрерывный аналог уравнений Колмогорова–Феллера и

Колмогорова–Чэпмена

ˆ

pX (x, t | x0, t0) = pX (x, t | v, t1)pX (v, t1 | x0, t0) dv.

(57)

R

Эти уравнения на функции FX и fX называются в литературе обоб-

щенными уравнениями Маркова.

Теорема 8.1 (первое уравнение Колмогорова). Пусть выпол-

нены следующие условия:

1) марковский случайный процесс X(t) непрерывен в том смысле,

что каково бы ни было постоянное δ > 0, имеет место соотношение

1ˆ

lim

dxFX (x, t | x0, t0 − ∆t) = 0.

∆t→0 ∆t |x−x0|≥δ

(58)

2) частные производные

∂FX (x, t | x0, t0) ∂2FX (x, t | x0, t0)

, ∂x0

∂x2

0

существуют и непрерывны при любых значениях t0, x0 и t > t0.

3) каково бы ни было δ > 0, существуют пределы

1ˆ

lim

(x − x0) dxFX (x, t | x0, t0 − ∆t) = a(t, x), (59)

∆t→0 ∆t |x−x0|<δ

205

ˆ

1 lim

(x − x0)2 dxFX (x, t | x0, t0 − ∆t) = b(t, x), (60)

∆t→0 ∆t |x−x0|<δ

и эта сходимость равномерна относительно x0. Тогда функция FX (x, t | x0, t0) удовлетворяет уравнению

∂FX (x, t | x0, t0)

∂FX (x, t | x0, t0) b(t0, x0) ∂2FX (x, t | x0, t0)

∂t0 = −a(t0, x0) ∂x0 − 2

∂x2

.

0

(61)

Доказательство. Согласно обобщенному уравнению Маркова ˆ
FX (x, t | x0, t0 − ∆t) = FX (x, t | v, t0) dvFX (v, t0 | x0, t0 − ∆t).

С другой стороны, если ввести «умную единицу» ˆ
FX (x, t | x0, t0) = FX (x, t | x0, t0) dvFX (v, t0 | x0, t0 − ∆t).

Из этих равенств заключаем, что

FX (x, t | x0, t0 − ∆t) − FX (x, t | x0, t0) = ∆t
1ˆ = ∆t (FX (x, t | v, t0) − FX (x, t | x0, t0)) dvFX (v, t0 | x0, t0 − ∆t).
Воспользуемся формулой Тейлора:

FX (x, t | v, t0) = FX (x, t | x0, t0) + (v − x0) ∂FX (x, t | x0, t0) + ∂x0

1

2 ∂2FX (x, t | x0, t0)

2

+ 2 (v − x0)

∂x2

+ o((v − x0) ).

0

Далее все просто:

FX (x, t | x0, t0 − ∆t) − FX (x, t | x0, t0) = ∆t
1ˆ = ∆t |v−x0|≥δ(FX (x, t | v, t0) − FX (x, t | x0, t0)) dvFX (v, t0 | x0, t0 − ∆t)+
1ˆ + ∆t |v−x0|<δ(FX (x, t | v, t0) − FX (x, t | x0, t0)) dvFX (v, t0 | x0, t0 − ∆t) =

206

1ˆ = ∆t |v−x0|≥δ(FX (x, t | v, t0) − FX (x, t | x0, t0)) dvFX (v, t0 | x0, t0 − ∆t)+
∂FX (x, t | x0, t0) 1 ˆ + ∂x0 ∆t |v−x0|<δ(v − x0) dvFX (v, t0 | x0, t0 − ∆t)+

+ 1 ∂2FX (x, t | x0, t0) 1 ˆ

[(v−x0)2+o((v−x0)2)] dvFX (v, t0 | x0, t0−∆t).

2

∂x20

∆t |v−x0|<δ

Перейдем теперь к пределу при ∆t → 0. Первое слагаемое правой ча-
сти в силу (58) имеет своим пределом 0. Второе слагаемое, соглас-
но (59), в пределе равно a(t0, x0)∂FX /∂x0. Наконец, третье слагаемое может отличаться от 1/2b(t0, x0)∂2FX /∂x20 только на слагаемое, стремящееся к нулю при δ → 0. Но так как левая часть последнего равен-
ства от δ не зависит и указанные предельные значения от δ не зависят,
то предел правой части существует и равен

∂FX (x, t | x0, t0) 1

∂2FX (x, t | x0, t0)

a(t0, x0) ∂x0

+ 2 b(t0, x0)

∂x2

.

0

Отсюда мы заключаем о существовании предела:

lim FX (x, t | x0, t0 − ∆t) − FX (x, t | x0, t0) = − ∂FX (x, t | x0, t0) .

∆t→0

∆t

∂t0

Отсюда следует утверждение теоремы. □ Если существует плотность распределения pX (x, t | x0, t0), то диф-
ференцирование уравнения (61) показывает, что она удовлетворяет уравнению

∂pX (x, t | x0, t0)

∂pX (x, t | x0, t0) b(t0, x0) ∂2pX (x, t | x0, t0)

∂t0 = −a(t0, x0) ∂x0 − 2

∂x2

.

0

(62)

Уравнение (61) или (62) и называется в литературе первым уравнением

Колмогорова или обратным уравнением Колмогорова. Это дифферен-

циальные уравнения в частных производных, независимыми перемен-

ными здесь являются переменные x0 и t0, а переменные x, t играют

роль фиксированных параметров. Эти уравнения были впервые строго

доказаны А.Н. Колмогоровым.

Теорема 8.2 (второе уравнение Колмогорова). Добавим к усло-

виям 1)–3) предыдущей теоремы еще два условия:

207

4) существует плотность распределения вероятностей pX (x, t | x0, t0) = ∂FX (x, t | x0, t0) . ∂x

5) существуют непрерывные производные

∂pX (x, t | x0, t0) ∂

∂2

∂t

, ∂x [a(t, x)pX (x, t | x0, t0)], ∂x2 [b(t, x)pX (x, t | x0, t0)].

Тогда плотность pX (x, t | x0, t0) удовлетворяет уравнению

∂pX (x, t | x0, t0)

∂

1 ∂2

∂t

= − ∂x [a(t, x)pX (x, t | x0, t0)]+ 2 ∂x2 [b(t, x)pX (x, t | x0, t0)].

(63)

Доказательство этого утверждения можно найти в книге [26, С.

301]. Уравнение (63) называется вторым уравнением Колмогорова или

прямым уравнением Колмогорова. Это уравнение было также незави-

симо получено физиками Фоккером и Планком, поэтому часто их на-

зывают также уравнениями Фоккера–Планка или уравнениями Колмо-

горова–Фоккера–Планка. В этих уравнениях независимыми перемен-

ными являются x и t, а переменные x0 и t0 играют роль параметров.

Выясним теперь физический смысл коэффициентов a(t, x) и b(t, x).

Для этого мы предположим вместо (58), что при любом δ > 0 имеет

место соотношение

ˆ

1 lim

(x − x0)2 dxFX (x, t | x0, t0 − ∆t) = 0.

∆t→0 ∆t |x−x0|≥δ

Это более сильное предположение, из него следует (58). Ограниче-

ния (59) и (60) в силу этого требования упрощаются до

1ˆ

lim

(x − x0) dxFX (x, t | x0, t0 − ∆t) = a(t, x),

∆t→0 ∆t

ˆ

1 lim

(x − x0)2 dxFX (x, t | x0, t0 − ∆t) = b(t, x),

∆t→0 ∆t

т.е. теперь интегрирование осуществляется по всей числовой оси. Осталь-

208

ные ограничения не изменятся. Теперь видно, что ˆ (x − x0) dxFX (x, t | x0, t0 − ∆t) =

= E(X(t) − X(t − ∆t) | X(t0 − ∆t) = x0) = E(X(t) − X(t − ∆t))

является математическим ожиданием изменения процесса за время

∆t, а

ˆ

1 lim

(x − x0)2 dxFX (x, t | x0, t0 − ∆t) = E(X(t) − X(t − ∆t))

∆t→0 ∆t

есть математическое ожидание квадрата изменения X(t). Теперь предположим, что X(t) – это координата точки, движущейся под влиянием случайных воздействий. Тогда a(t, x) есть средняя скорость изменения этой координаты, а b(t, x) пропорциональна средней кинетической энергии.
Пример 8.2. Например, у винеровского процесса

a(t, x) = lim E(W (t) − W (t − ∆t)) = 0,

∆t→0

∆t

E(W (t) − W (t − ∆t))2

∆t

b(t, x) = lim

= lim = 1.

∆t→0

∆t

∆t→0 ∆t

Кроме того, у винеровского процесса существует условная плотность распределения pW (x, t | x0, t0) как плотность распределения невырожденного подвектора (из 1 компоненты) нормального вектора (из 2 компонент) и для этой функции, как можно проверить, все условия регулярности выполнены. Поэтому первым уравнением Колмогорова для винеровского процесса будет

∂pW (x, t | x0, t0)

1 ∂2pW (x, t | x0, t0)

∂t0

=− 2

∂x2

,

0

а вторым уравнением Колмогорова будет

∂pW (x, t | x0, t0) = 1 ∂2pW (x, t | x0, t0) .

∂t

2

∂x2

Легко убедиться, что функция

1 pW (x, t | x0, t0) = √︁

exp (︃− (x − x0)2 )︃

2π(t − t0)

2(t − t0)

209

удовлетворяет обоим уравнениям. Эту функцию условной плотности распределения можно было вывести и независимым образом как функцию плотности подвектора нормального вектора. △
Также заметим, что для выписанных уравнений в частных производных для возможности их решения необходимо еще задать начальные / граничные условия. Для прямого уравнения задают следующее начальное условие (Коши):
pX (x, t0 | x0, t0) = δ(x − x0),
где δ(x) – дельта функция Дирака. Такое начальное условие вызывает сразу много вопросов, главный из которых: как понимать решение, если начальное условие – обобщенная функция? Ключевую роль в ответе на этот вопрос играет линейность рассматриваемых уравнений и возможность их переписать в терминах FX (x, t0 | x0, t0) [26]. Другой важный вопрос: можно ли задавать, какие-то другие начальные условия, задаваемые произвольными функциями распределения? Ответ на этот вопрос для прямого уравнения положительный. Только тогда требуется изменить обозначения и вместо pX (x, t0 | x0, t0) или (в общем случае) FX (x, t0 | x0, t0) писать просто pX (x) или FX (x), не подчеркивая в виде функции начальное условие.

8.2. Процесс Ито и формула Дынкина*
В конце раздела 2 был введен стохастический диффузионный процесс Ито, который является важным представителем рассматриваемого в этой главе класса марковских процессов в непрерывном времени с несчетным (континуальным) множеством состояний. Далее конспективно (без доказательств) будет продемонстрирована связь этих процессов (Ито) с изложенными выше результатами.
Определение 8.2. Однородный по времени диффузионный процесс Ито — это случайный процесс Xt(ω) = X(ω, t) : Ω×[0, +∞) → Rn, удовлетворяющий стохастическому дифференциальному уравнению вида

dXt = a(Xt)dt + σ(Xt)dWt, t ≥ 0, X0 = x,

(64)

где Wt — n-мерный винеровский процесс (в каждой компоненте которого независимая реализация винеровского процесса), а векторная и матричная функции a : Rn → Rn и σ : Rn → Rn×n – равномерно липшицевы.
Определение 8.3. Производящий (инфинитезимальный) оператор A однородного по времени диффузионного процесса Ито Xt опре-

210

деляется, как

Af (x) = lim Exf (Xt) − f (x) , Exf (Xt) = E (f (Xt) | X0 = x) , x ∈ Rn,

t→0+

t

если этот предел существует.

Определение 8.4. Случайная величина τ называется моментом

остановки (относительно случайного процесса Xt = X(t)), если для

любого t ≥ 0 событие {τ ≤ t} измеримо относительно сигма-алгебры,

порожденной {Xs}0≤s≤t.

В простейшем случае τ = t – не случайная величина. Нетривиаль-

ным примером является первый момент выхода случайного процесса

из множества D:

τD = inf {t ≥ 0 : Xt ∈/ D} .

(65)

Следующая теорема является аналогом основной теоремы из математического анализа о связи интеграла и производной.
Теорема 8.3 (формула Дынкина). Пусть Xt – однородный по времени диффузионный процесс Ито, f – дважды непрерывно диффе-
ренцируемая функция с компактным носителем, τ – момент остановки, причём Exτ < ∞. Тогда справедлива формула

⎛ˆτ

⎞

Ex (f (Xτ )) = f (x) + Ex ⎝ Af (Xs)ds⎠ .

(66)

0

Пусть Xt удовлетворяет стохастическому дифференциальному уравнению Ито (64). Тогда по теореме 7.3.3 [46]

∑︂ ∂f 1 ∑︂ (︁ T )︁ ∂2f

Af = ai ∂xi + 2

σσ ij ∂xi∂xj .

i

i,j

Если f – дважды гладкая функция с компактным носителем (отлична от нуля на ограниченном множестве), то согласно формуле Дынкина можно ввести функцию

u(t, x) = Ex (f (Xt)) ,

(67)

u(0, x) = f (x), которая будет удовлетворять следующему уравнению:

∂u = Ex (Af (Xt)) , ∂t

211

что в свою очередь можно переписать следующим образом (аналог обратного уравнения Колмогорова(–Фоккера–Планка)):

∂u = Ex (Af (Xt)) = AEx (f (Xt)) = Au, ∂t
см. теорему 8.1.1 [46]. Заметим также, что в введенных ранее обозначениях

pX (x, t | x0, t0 = 0) = pX (x, t | x0)

имеем

ˆ Ex0 (f (Xt)) = f (x)pX (x, t | x0)dx.

Rn

Отсюда по формуле Дынкина получим

ˆ

ˆt ˆ

f (x)pX (x, t | x0)dx = f (x0) +

Af (x)pX (x, s | x0)dxds.

Rn

0 Rn

Если продифференцировать это тождество по t и воспользоваться ра-
венством (в L2) ⟨Aϕ, ψ⟩ = ⟨ϕ, A∗ψ⟩,

где функции ϕ, ψ дважды гладкие и имеют компактный носитель, а

A∗ϕ = − ∑︂ ∂(aiϕ) + 1 ∑︂ ∂2(σijϕ) ,

i ∂xi

2 i,j ∂xi∂xj

то получим прямое уравнение Колмогорова(–Фоккера–Планка)

∂pX (x, t | x0) = A∗pX (x, t | x0). ∂t
В заключении этого раздела, следуя [46, глава 9], покажем, как с помощью диффузионных процессов Ито решать краевые задачи для эллиптических уравнений:
Au = 0 в D, u = g на ∂D
с оператором A, определенным ранее. Рассмотрим соответствующий

212

A, диффузионный процесс Xt (64). Положим подобно (67) u(x) = Ex (g(XτD )) , (68)

где τD определяется согласно (65). Тогда по формуле Дынкина с f (x) = = u(x) при x ∈ D и 0 ≤ t ≤ τD:

⎛ˆt

⎞

Ex (u(Xt)) = u(x) + Ex ⎝ Au(Xs)ds⎠ .

0

Из определения (68) следует, что

Ex (u(Xt)) = u(x).

Таким образом, для 0 ≤ t ≤ τD Ex (Au(Xt)) = 0.

Отсюда при некоторых дополнительных предположениях (матрица σ – положительно определенная) уже можно получить, что

Au = 0.

Осталось только заметить, что u(x) = g(x) при x ∈ ∂D. Следовательно, на формулу (68) можно смотреть, как на способ
представления решения рассматриваемой краевой задачи для эллиптического уравнения. Представление (68) можно использовать для численного вычисления решения. Для этого траектории диффузионного процесса заменяются соответствующими случайными блужданиям (с соотношением размера скачков с шагом по времени соответствующим диффузионному скейлингу из раздела 1.3), выпущенными из точки, в которой хочется оценить решение. Траектории блужданий отслеживаются до первого момента попадания на границу ∂D. Если взять достаточно много таких траекторий и считать, что масштаб скачков в блужданиях достаточно мал, то среднее арифметическое полученных значений функции g в точках ∂D, в которые пришли траектории, дает хорошую оценку оцениваемого значения (метод Монте-Карло).
В заключение заметим, что здесь мы в основном исследовали марковские процессы в непрерывном времени с континуальным числом состояний на всем пространстве. Последний пример демонстрирует важность рассмотрения марковских процессов, «живущих» внутри множеств с поглощающей границей. В целом следует отметить, что в при-

213

ложениях большой интерес вызывают марковские процессы (в непрерывном и дискретном времени), которые живут на компактных множествах. В этом случае существование условной плотности вероятностей pX (x, t | x0, t0) обеспечивает эргодичность процесса. Это утверждение является аналогом эргодических теорем из предыдущих разделов – наличие плотности обеспечивает единственность стационарной меры, а компактность носителя – условие положительной возвратности, что достаточно для эргодичности в общем случае [39]. Приведем пару примеров.
В приложениях методов Монте-Карло важную роль играет возможность генерировать точки, равномерно распределенные в заданном конечномерном выпуклом (это условие можно ослабить) связном компакте в предположении, что задан граничный оракул для рассматриваемого компакта. Последнее означает, что для любой прямой такой оракул выдает отрезок из этой прямой, по которому прямая пересекается с компактом. С помощью такого оракула строится марковский процесс в дискретном времени с непрерывным множеством состояний (точки компакта): в текущем положении процесса равновероятно и независимо выбирается направление, это направление и текущее положение задают уравнение прямой; граничный оракул по этому уравнению выдает отрезок; на отрезке равновероятно и независимо выбирается новая точка, которая принимается за новое состояние процесса. Несложно понять, что инвариантной (стационарной) мерой здесь будет равномерная мера на компакте. Таким образом, после достаточно большого числа шагов (полиномиально зависящего от размерности пространства) можно гарантировать, что положение описываемого процесса будет с хорошей точностью равновероятно распределено на компакте, независимо от точки старта. В действительности, по ходу итераций гененируется много точек, с похожими свойствами. Проблема только в том, что они зависимы между собой. Однако корреляционная функция этого процесса (и любого другого марковского процесса в условиях эргодичности) экспоненциально убывает с увеличением числа шагов между сечениями9, поэтому при должном прореживании точек, генерируемых описанным процессом, можно получить не одну (конечную), а целый набор почти независимых точек, распределенных почти равномерно в заданном компакте. Описанный здесь алгоритм генерирования точек называется Hit and Run [92].
9Показатель убывания пропорционален spectral gap – расстоянию между максимальным собственным значением оператора, отвечающего за переходные вероятности (это число всегда равно 1), и следующим (по величине модуля) собственным значением.
214

Второй пример связан с популярной в последние десятилетия теорией случайных матриц, см., например, [104, 105]. Пусть матрицы

G1, . . . , Gn, . . .

независимы и одинаково распределены (с распределением, имеющим плотность πG с финитным носителем). Требуется доказать, что существует (максимальный показатель Ляпунова):

1 λmax = lim ln ∥Gn · . . . · G1∥2.
n→∞ n

Введем Yn = Gn · . . . · G1X0. Положим Xn = Yn/∥Yn∥2. Заметим, что {Xk} – дискретный марковский процесс, множества состояний которого – единичная сфера (компактное множество). Далее следует заметить (см. п. 3.2 [39]), что

1

n
∑︂

λmax = lim n→∞ n

ln ∥GkXk−1∥2.

k=1

При сделанных предположениях {Xk} – эргодический марковский процесс, поэтому
λmax = EπG,π (ln ∥GX∥2) ,
где случайная матрица G распределена согласно плотности πG, а независимый от нее случайный вектор X имеет плотность распределения π, где π – стационарное распределение для {Xk}.

215

ПРИЛОЖЕНИЯ А. Модель Эренфестов
В этом разделе на простейшем примере (модель Эренфестов) мы постараемся продемонстрировать основы теории макросистем. Более подробно о теории макросистем будет написано в следующем разделе.
Различают две модели Эренфестов: дискретную [30] и непрерывную [8, раздел 6, задача 1].
Определение А.1. Непрерывной цепью Эренфестов будем называть непрерывную цепь Маркова со следующим стохастическим графом, задающим инфинитезимальные вероятности переходов:
Определение А.2. Дискретной цепью Эренфестов будем называть дискретную цепь Маркова со следующим стохастическим графом, задающим вероятности переходов:
В этом разделе нашей целью будет анализ непрерывной модели Эренфестов, но поскольку (как несложно убедиться) дискретная цепь Эренфестов является цепью скачков (см. определение 54) для непрерывной цепи Эренфестов, то нам потребуется и дискретная модель.
Непрерывная цепь Эренфестов ξ(t), t ≥ 0, имеет конечное число состояний N + 1, причем интенсивности перехода между состояниями
216

определяются формулами:

λi,i+1 = λ(N − i), 0 ≤ i ≤ N − 1,

λi,i−1 = λi, 1 ≤ i ≤ N,
где λ > 0, и λi,j = 0 во всех остальных случаях. Дискретная цепь Эренфестов Xn, n = 0, 1, 2, . . ., также имеет ко-
нечное число состояний N + 1, причем вероятности перехода между состояниями определяются формулами:

N −i

i

pi,i+1 = N = 1 − N , 0 ≤ i ≤ N − 1,

i pi,i−1 = N , 1 ≤ i ≤ N,
и pi,j = 0 во всех остальных случаях. П. и Т. Эренфесты в 1907 году предложили данную модель для
описания диффузии через мембранную перегородку в сосуде или теплообмена между двумя изолированными телами. Мы будем придерживаться немного другой (шутливой) интерпретации данной цепи (см. [8, раздел 6, задача 1]). Две собаки сидят рядом друг с другом и страдают от N блох. Каждая блоха независимо от остальных в течение малого промежутка времени длины h перескакивает на соседнюю собаку с вероятностью λh + o(h). Тогда ξ(t) – число блох на первой собаке в момент времени t, N − ξ(t) – число блох на второй собаке в момент времени t.
Пример А.1. Найти для непрерывной цепи Эренфестов стационарное распределение, среднее время возвращения в состояние 0. Оценить предельную (по времени и количеству состояний N ) вероятность отклонения состояния цепи от N/2. Оцените время выхода на стационарный режим.
Решение. Данная цепь является процессом гибели и рождения, в которой интенсивности λk = λ(N − k + 1) и µk = λk, k = 1, . . . , N . Для вычисления стационарного распределения сначала заметим, что

λ1 . . . λk = N (N − 1) . . . (N − k + 1) = Ck .

µ1 . . . µk

k!

N

Отсюда получаем

π0 = (︁1 + CN1 + · · · + CNN )︁−1 = 2−N .

217

Далее получаем πk = 2−N CNk , k = 1, . . . , N . Итак, для произвольного состояния

−N k

k (︃ 1 )︃k (︃ 1 )︃N−k

πk = 2 CN = CN 2

2

, k = 0, . . . , N.

Отметим, что данный результат можно получить, рассмотрев дискретную модель Эренфестов, найти для неё стационарное распределение (см. пример 6.5) π˜k = 2−N CNk и воспользоваться замечанием 1 в конце раздела 7.2.
Заметим, что стационарное распределения является биномиальным распределением с параметрами N и p = 1/2, т.е. Bi(N, 1/2). Иначе говоря, стационарное распределение соответствует ситуации, когда все N блох независимо и равновероятно распределились по обеим собакам (классическая схема Бернулли). При больших значениях N согласно теореме Муавра–Лапласа это распределение приближенно совпадает с распределением N(N/2, N/4). Отсюда следует, что

(︃ |ξ(t) − N/2|

lim lim P 2 √

N →∞ t→∞

N

N 1+γ (0,1)

)︃

2ˆ

≤ N 1+γ (0, 1) =
2

−N 1+γ (0,1)
2

e

−

u2 2

√

2π

du =γ,

где N 1+γ (0, 1) – это (1 + γ)/2-квантиль распределения N(0, 1). Напри2
мер, если γ = 0.99, то N 1+γ (0, 1) = 2.5758. Итого, если время t и число 2
блох N достаточно велики, то блохи почти поровну распределятся на собаках (поскольку 2|ξ(t) − N/2| – модуль разности чи√сла блох на собаках), при этом флуктуации не велики, а именно O( N ). На самом деле, этот результат является только предельным и не даёт скорости сходимости.
Для получения более аккуратных оценок рассмотрим сначала дискретную цепь скачков Xn, n = 0, 1, 2, . . . Обозначим математическое ожидание разности числа блох на первой и второй собаке в момент времени n как
an = E(2Xn − N ).

218

Применив формулу полной вероятности, получаем, что

N
∑︂ EXn = E[Xn|Xn−1 = k]pk(n − 1) =

k=0

N (︃ ∑︂

k

k )︃

= (k − 1) N + (k + 1)(1 − N ) pk(n − 1) =

k=0

(︃

2

)︃

N
∑︂

(︃ 2 )︃

= 1− N

kpk(n − 1) + 1 = 1 − N EXn−1 + 1,

k=0

откуда

а значит

(︃ 2 )︃ an = 2EXn − N = 2 1 − N EXn−1 + 2 − N =

(︃ 2 )︃

(︃ 2 )︃

= 1 − N (2EXn−1 − N ) = 1 − N an−1,

(︃ 2 )︃n an = 1 − N a0.

Таким образом, первый момент для случайной величины, равной разности числа блох между собаками, с экспоненциальной скоростью стремится к нулю, однако, чем больше N , тем медленнее. Это утверждение имеет место для случая, когда a0 ̸= 0. Иначе, когда a0 = 0, то есть в начальный момент времени распределение блох между собаками симметрично, то очевидно, что в последующие моменты времени распределение блох между собаками будет также симметричным, что даст an = 0 для любого n.
Проведем аналогичные вычисления для второго момента. Обозначим математическое ожидание квадрата разности числа блох на первой и второй собаке в момент времени n как
bn = E(2Xn − N )2.

219

Применив формулу полной вероятности, получаем, что

откуда

N
EXn2 = ∑︂ E[Xn2|Xn−1 = k]pk(n − 1) =

k=0

N (︃ ∑︂

k

k )︃

=

(k − 1)2 + (k + 1)2(1 − ) pk(n − 1) =

N

N

k=0

= (︃1 − N4 )︃ EXn2−1 + 2EXn−1 + 1,

(︃
2

4 )︃

bn = E (2Xn − N ) = 1 − bn−1 + 4,

N

а значит

(︃ 4 )︃n

n (︃ ∑︂

4 )︃k (︃

4 )︃n

[︃ (︃ 4 )︃n]︃

bn = 1 − N b0+4

1 − N = 1 − N b0+N 1 − 1 − N .

k=0

Теперь найдем среднее время возвращения в состояние 0. Рассмотрим сначала дискретную модель. Согласно принятым в замечании 1 раздела 6.2.2 обозначениям средние времена первого достижения состояния j из состояния i µij удовлетворяют системе линейных уравнений (43). При чем µi = πi−1. В частности,
µ0 = 2N .

Для качественного понимания полученных результатов заметим, что

2N

√︃ 1 πN

µN/2 = C N2 ∼ λ 2 ,

N

N → ∞.

Таким образом, для больших значений N , если цепь находится в состоянии 0, то за разумное время наблюдения цепь не возвращается туда. И напротив, если цепь находится в состоянии макроравновесия N/2 = arg maxk πk, то циклы возвращения очень короткие.
Для перенесения результатов на непрерывную модель нужно заметить, что время между скачками в непрерывном случае имеет показательное распределение со средним 1/(λN ). Иначе говоря, ответы для непрерывной модели получаются из дискретной делением на λN (см.

220

также теорему 12.3 на с. 289 в [66] или раздел 7 данного пособия). Перейдем теперь к немного другому описанию модели Эренфе-
стов. Нас по-прежнему будет интересовать поведение макросистемы (N → ∞) на продолжительных временах (t → ∞) и ее равновесное состояние.
Пусть дана непрерывная цепь Эренфестов ξ(t) с N + 1 состоянием и начальным распределением P(ξ(0) = 0) (все блохи в начальный момент времени находятся на второй собаке). Рассмотрим N независимых непрерывных цепей Маркова ηi, i = 1, . . . , N (см. рис. 23) с одинаковым начальным распределением P(ηi(0) = 0). Иначе говоря, каждая цепь ηi соответствует поведению i−ой блохи, i = 1, . . . , N (поведения всех блох независимы друг от друга), так что ηi(t) = 1, если в момент времени t i−ая блоха находится на первой собаке, и ηi(t) = 0, если в момент времени t i−ая блоха находится на второй собаке. Тогда
N
ξ(t) =d ∑︂ ηi(t).
i=1
Отсюда следует, в частности, что
N
P(ξ(t) = 0) = ∏︂ P(ηi(t) = 0) = P(η1(t) = 0)N .
i=1
В примере А.1 мы выяснили, что при t → ∞ вероятность P(ξ(t) = 0) сходится к (1/2)N , следовательно, P(ηi(t) = 0) → 1/2 при t → ∞ для любого i = 1, . . . , N .
Рис. 23. Стохастический граф цепи Маркова ηi.
Теперь пусть ν0(t) = 1 − ξ(t)/N , ν1(t) = ξ(t)/N – доли цепей ηi, которые в момент t находятся в состоянии 0 и в состоянии 1 соответ-
221

ственно. Тогда

P(ν0(t) = c1, ν1(t) = c2) =

N!

P(η1(t) = 0)c1N P(η1(t) = 1)c2N .

(c1N )!(c2N )!

Перейдем к пределу при t → ∞ и получим

N!

1

lim P(ν0(t)
t→∞

=

c1, ν1(t)

=

c2)

=

(c1N )!(c2N )!

2N

.

Далее перейдем к пред√елу по N → ∞ и, воспользовавшись формулой Стирлинга n! = nne−n 2πn(1 + O(1/n)), получим

откуда

2−N

1

lim P(ν0(t) = c1, ν1(t) = c2) ≈ √

√ c N c N,

t→∞

2πc1c2 N c11 c22

2−N

lim P(ν0(t) = c1, ν1(t) = c2) ≈ √

√ exp (−N H(c1, c2)),

t→∞

2πc1c2 N

где H(c1, c2) = −c1 ln c1 − c2 ln c2. Зададимся теперь вопросом, при каких c1 и c2 система оказывается
равновесной. Под равновесием будем понимать такое состояние, т.е. такой вектор (c1, c2), в малой окрестности которого концентрируется стационарная мера, т.е. вероятность принятия частотами ν0(t) и ν1(t) значений c1 и c2 при t → ∞. Оценка этой вероятности при больших N выписана выше. Максимизация этого выражения при c1 ≥ 0, c2 ≥ 0, c1 + c2 = 1 равносильна минимизации функции H(c1, c2) при тех же c1, c2. Решением являются значения c1 = c2 = 1/2.
В более общих случаях макросистем оценку стационарной меры при большом числе степеней свободы N удается произвести с использованием теорем И. Н. Санова [53] о сходимости эмпирических мер на произвольных алфавитах (в нашем случае алфавитом являлось множество значений {0, 1} цепей ηi(t)).
Интересно отметить, что функция −H(c1, c2) (с минусом) оказывается функцией энтропии рассматриваемой системы, а равновесное состояние отвечает максимуму энтропии. Это проявление принципа максимума энтропии Больцмана–Джейнса охватывает и более общие случаи макросистем, см., например, [2] и следующий раздел.
Тот же результат можно получить, рассматривая пределы в обратном порядке: сначала по N → ∞, затем по t → ∞. А именно, предпо-

222

ложим, что при t = 0 существует предел

lim νi(t) п=.н. ci(t).

(69)

N →∞

Оказывается (теорема Т. Куртца [82]), что в этом случае предел (69) существует и при любом другом t > 0, причем c1(t) и c2(t) – неслучайные функции, удовлетворяющие системе обыкновенных дифференциальных уравнений
dc1 = λ(c2 − c1), dt
dc2 = λ(c1 − c2). dt
Положение равновесия этой системы существует, единственно и соответствует c1 = c2 = 1/2. Интересно отметить, что функция H(c1, c2) является функцией Ляпунова этой системы (убывает на траекториях этой системы и имеет минимум в точке c1 = c2 = 1/2).
Итак, мы продемонстрировали три точки зрения на изучение эволюции и равновесия макросистемы на больших временах: 1) стохастическую (концентрация меры), 2) механическую (функция Ляпунова) и 3) термодинамическую (максимум энтропии). Причем к 3) можно прийти как из 1), так и из 2).
В следующем разделе описанная выше схема для графа специального вида, изображенного на рисунке 23, будет перенесена на произвольные графы.
Оценки времени выхода марковских цепей на стационарное распределение [30] (mixing time) особенно важны в изучении эффективности алгоритмов, в основе которых лежит Markov Chain Monte Carlo, см. следующее приложение.

223

Б. Вектор PageRank и Google Problem
В данном разделе на примере ранжирования web-страниц приводится наглядный способ интерпретации основного уравнения (Колмогорова–Чэпмена) и основной теоремы (эргодической) теории однородных дискретных марковских цепей, изложенной в предыдущих разделах пособия. Также в данном разделе на примере задачи ранжирования web-страниц демонстрируется важный в различных современных приложениях алгоритм Markov Chain Monte Carlo [80] и закрепляется материал из предыдущего раздела про то, как можно понимать равновесия макросистем. Для более глубокого погружения в описываемые далее вопросы рекомендуем [19, 20] и литературу, на которую в этих статьях ссылаются. Для закрепления материала мы умышленно повторяем некоторые результаты, изложенные ранее.

Б.1. Google problem и эргодическая теорема

В 1998 г. Ларри Пейджем и Сергеем Брином был предложен спе-

циальный способ ранжирования web-страниц, который и лёг в основу

поисковой системы Google.

Рассмотрим ориентированный взвешенный граф (см. рис. 5). Граф

имеет n вершин. Каждой паре вершин соответствует некоторый вес

pi,j ≥ 0. Ребро, выходящее из вершины i в вершину j, имеет вес pi,j > 0.

Если из вершины i в вершину j ребра нет, то полагаем pi,j = 0. Число

pi,j интерпретируется как вероятность перейти из вершины i в верши-

ну j. Набор чисел {pi,j}ni,,jn=1,1 удобно будет записать в виде матрицы

P = ∥pi,j∥ni,,jn=1,1. Поскольку распределение вероятностей должно быть

нормировано на единицу, то для любой вершины i имеет место равен-

ство

∑︁n
j=1

pi,j

= 1,

и

матрица

P

является

стохастической

по

строкам.

На граф можно посмотреть как на город, вершинами которого яв-

ляются различные районы города, а ребрами – дороги (вообще гово-

ря, с односторонним движением). Предположим, что в городе имеется

«Красная площадь» – такой район, в который можно попасть по доро-

гам из любого другого. Оказывается, в этом предположении верен сле-

дующий результат (эргодическая теорема для марковских про-

цессов в варианте теоремы 6.14): если пустить блуждать челове-

ка по городу в течение длительного времени так, что человек будет

случайно перемещаться из района в район согласно весам ребер графа,

то доли {νk}nk=1 времени, которые человек провел в разных районах,

будут

удовлетворять

следующему

уравнению:

∑︁n
i=1

νipi,j

=

νj

или

в векторном виде ν⊤P = ν⊤, имеющему единственное решение, удо-

224

влетворяющее

∑︁n
i=1

νi

=

1.

В

связи

с

последним

представлением

гово-

рят, что ν = [ν1, . . . , νn]⊤ является левым собственным вектором мат-

рицы P . Вектор ν также называют инвариантным или стационарным

распределением вероятности в марковском процессе. В теории неот-

рицательных матриц [45], используемой в математической экономике,

вектор νT также называют вектором Фробениуса–Перрона. Предполо-

жение о «Красной площади» обеспечивает единственность ν. Если это

предположение не верно, то вектор ν существует, но он не единственен

и зависит от района, из которого стартовал человек. В общем случае

город распадается на отдельные несвязанные между собой существен-

ные кластеры10 из районов, связанных между собой внутри кластера,

и отдельного кластера несущественных районов. Последний опреде-

ляется тем, что из любого его района можно попасть в один из су-

щественных кластеров, но попасть обратно в несущественный кластер

из существенных кластеров невозможно. Из такого несущественного

кластера человек в конечном итоге попадет в один из существенных

кластеров, откуда уже не выйдет. Рисунок 5 из раздела 6 поясняет

общий случай.

Чтобы понять, откуда получается приведенная выше в вольной

трактовке эргодическая теорема, получим с помощью формулы пол-

ной вероятности уравнение Колмогорова–Чэмпена. Это уравнение яв-

ляется основным при описании дискретных однородных марковских

цепей. Обозначим через pi (t) вероятность того, что человек находится

в момент времени t в районе i. Тогда по формуле полной вероятности

для любого j = 1, ..., n

n (︃

)︃ (︃

)︃

∑︂ pj(t + 1) = P
i=1
⏞

человек в момент времени t находился в районе i
⏟⏟

P ⏞⏞

человек перешел в район j при

.

условии, что был в районе i

⏟⏟

⏞

pi (t)

pi,j

Или в матричном виде

p⊤(t + 1) = p⊤(t)P.

(70)

Последнее равенство и называют уравнением Колмогорова–Чэпмена. Предположим теперь, что существует предел limt→∞ p(t) = ν. Ка-
кому уравнению должен удовлетворять вектор ν? Переходя к пределу в обеих частях равенства (70) и учитывая, что limt→∞ (︁p⊤(t)P )︁ =
10То есть из каждого такого кластера в любой другой кластер дорог нет.

225

= limt→∞ (︁p⊤ (t))︁ P , получим уже известное нам соотношение

νT P = νT .

(71)

Именно из соотношения (71) и было предложено искать вектор ранжирования web-страниц, также назваемый вектор PageRank, в модели Брина–Пейджа. Отличие этой модели от описанной выше только в интерпретации. Теперь вершины графа – это web-страницы, ребра графа это гиперссылки. Под Google problem будем понимать задачу поиска вектора ν в этой модели.
Отметим, что приведенные выше рассуждения справедливы в предположении существования предела limt→∞ p (t) = ν. Казалось бы, что предположения о «Красной площади» будет достаточно и тут.11 Однако, как показывает простейший пример (рис. 24), в котором n = 2, p1,1 = p2,2 = 0, p1,2 = p2,1 = 1, хотя вектор ν = (1/2, 1/2)⊤ существует и единственен, предел limt→∞ p (t) не существует, поскольку с ростом t будет происходить периодическое чередование нулей и единиц в каждой компоненте вектора p (t).

Рис. 24. Периодическая марковская цепь c периодом 2
Оказывается, что если выполняется условие «непериодичности», то предел limt→∞ p (t) = ν действительно существует. Более того, эти два условия (существования «Красной площади» и «непериодичности») являются не только достаточными, но и необходимыми для существования предела. Опишем, в чем заключается условие «непериодичности». Из «Красной площади» выходит много различных маршрутов, которые в конце снова приводят на «Красную площадь». Условие «непериодичности» означает, что наибольший общий делитель последовательности длин всевозможных маршрутов (начинающихся и
11В непрерывном времени так оно и есть, см. раздел 9.
226

заканчивающихся на «Красной площади») равен 1. Уточним, что длина маршрута равна числу ребер, вошедших в маршрут. В типичных web-графах оба отмеченных условия выполняются, поэтому в дальнейшем мы считаем эти два условия выполненными.
Б.2. Стандартные численные подходы к решению задачи
С одной стороны, вектор ν является решением уравнения (71) ν⊤P= = ν⊤. С другой стороны, он является пределом ν = limt→∞ p(t), где p(t) рекуррентно рассчитывается согласно уравнению Колмогорова– Чепмена p(t + 1) = P ⊤p(t). Значит, это соотношение можно использовать для численного расчета p(t) как приближения к вектору PageRank (иными словами, можно применить метод простой итерации). Перейдем к анализу скорости сходимости такого метода.
Назовем спектральной щелью матрицы P наименьшее такое число α = 1 − |β| > 0, где (вообще говоря, комплексное) число β удовлетворяет условию: |β| < 1 и существует такой вектор η, что ηT P = βηT . Хотя бы одно такое β существует. Другими словами, α – расстояние между максимальным собственным значением матрицы P (для стохастических матриц оно всегда равно 1) и следующим по величине модуля. Отсюда и название – спектральная щель (спектральный зазор – от англ. spectral gap). Оказывается, что имеет место следующий результат:
n
∥p (t) − ν∥1 d=ef ∑︂ |pk (t) − νk| ≤ C exp (︂−αt/C˜)︂ . (72)
k=1
Здесь и далее константы C, C˜ будут обозначать некоторые (каждый раз свои) универсальные константы, которые зависят от некоторых дополнительных деталей постановки и которые, как правило, ограничены числом 10.
Заметим, что часто факт сходимости процесса p(t + 1) = P ⊤p(t) к решению ν⊤P = ν⊤ также называют эргодической теоремой. В предыдущем разделе мы видели, что для этого есть основания. Однако сходимость процесса p(t + 1) = P ⊤p(t) больше связана с принципом сжимающих отображений. Если под пространством понимать всевозможные лучи неотрицательного ортанта, а под метрикой на этом пространстве, в которой матрица P «сжимает», понимать метрику Биркгофа– Гильберта, то можно показать, что сходимость процесса p(t + 1) = P ⊤p(t) к решению ν⊤P = ν⊤ следует из принципа сжимающих отоб-
227

ражений. К сожалению, детали здесь не совсем элементарны, поэтому

мы ограничимся только следующей аналогией. Формула (72) отража-

ет геометрическую скорость сходимости, характерную для принципа

сжимающих отображений, а коэффициент α как раз и характеризует

степень сжатия, осуществляемого матрицей P . Геометрически себе это

можно представлять (правда, не очень строго) как сжатие с коэффици-

ентом, не меньшим 1 − α к инвариантному направлению, задаваемому

вектором ν.

С одной стороны, оценка (72) всего лишь сводит задачу оценки

скорости сходимости метода p(t + 1) = P ⊤p(t) к задаче оценки спек-

тральной щели α. С другой стороны, последняя задача в ряде случаев

может быть эффективно решена. В частности, к эффективным инстру-

ментам оценки α относятся изопериметрическое неравенство Чигера и

неравенство Пуанкаре, которое также можно понимать как неравен-

ство концентрации меры. Имеются и другие способы оценки α, однако

все эти способы далеко выходят за рамки нашего курса. Поэтому здесь

мы ограничимся простыми, но важными в контексте рассматриваемых

приложений случаями.

Предположим сначала, что для рассматриваемого web-графа су-

ществует такая web-страница, на которую есть ссылка из любой web-

страницы, в том числе из самой себя (усиленный аналог предположе-

ния о наличии «Красной площади» – поскольку теперь на «Красную

площадь» из любого района есть прямые дороги), более того, предпо-

ложим, что на каждой такой ссылке стоит вероятность, не меньшая,

чем γ. Для такого web-графа имеет место неравенство α ≥ γ.

Предположим далее, что в модели блуждания по web-графу име-

ется «телепортация»: с вероятностью 1 − δ человек действует как в

исходной модели, а с вероятностью δ «забывает про все правила» и

случайно равновероятно выбирает среди n вершин одну, в которую и

переходит. Тогда, если ввести квадратную матрицу E размера n на n,

состоящую из одинаковых элементов 1/n, уравнение p(t + 1) = P ⊤p(t)

примет вид

p(t + 1) = (︁(1 − δ) P ⊤ + δE)︁ p(t).

(73)

В таком случае вектор PageRank необходимо будет искать из уравне-

ния

ν = (︁(1 − δ) P ⊤ + δE)︁ ν.

(74)

При 0 < δ < 1 уравнение (74) гарантированно имеет единственное в классе распределений вероятностей решение. Более того, для спектральной щели матрицы (1 − δ) P + δE имеет место оценка α ≥ δ. На практике для вычисления вектора PageRank обычно используют

228

уравнение (74) c δ = 0.15. Поскольку матрица P для реальных web-графов обычно сильно
разреженная – большая часть элементов равна нулю, то использовать формулу (73) в таком виде не рационально: одна итерация будет стоить 3n2 арифметических операций типа сложения и умножения чисел. Однако формулу (73) можно переписать следующим образом:

p(t + 1) = (1 − δ) P ⊤p(t) + δ · (1/n, ..., 1/n)⊤ .

(75)

Расчет по этой формуле требует по порядку лишь 2sn арифметических операций, где s – среднее число ненулевых элементов в строке матрицы P . Для Интернета n ≈ 1010, а s ≪ 104.
Выше был описан исторически самый первый алгоритм, использовавшийся для расчета вектора PageRank. Он получил название метода простой итерации (МПИ). Как было отмечено, МПИ эффективен, если α не очень близко к нулю. В частности, как в модели с телепортацией. Действительно, современный ноутбук в состоянии выполнять до 1010 арифметических операций в секунду. С учетом программной реализации и ряда других ограничений этот порядок на практике обычно уменьшается до 108. Из оценки (72) видно, что сходимость, например, при α ≥ 0.15 очень быстрая. Хорошая точность получается уже после нескольких десятков итераций. С учетом того, что одна итерация требует по порядку 2sn ≤ 1013 арифметических операций, описанный метод позволяет за день найти вектор PageRank для всего Интернета. К сожалению, на самом деле все не так просто. Проблема в памяти, в которую необходимо загружать матрицу P . Разумеется, P необходимо загружать не как матрицу из n2 элементов, а в виде, так называемых, списков смежностей по строкам. Однако это все равно не решает проблемы. Быстрая память компьютера – кэш-память разных уровней. Кэш-память процессора совсем маленькая, ее совершенно недостаточно. Более медленная – оперативная память. Тем не менее если удалось бы выгрузить матрицу P в такую память, то производительность программы соответствовала бы оценке, приведенной выше. Обычно оперативной памяти в современном персональном компьютере не более нескольких десятков Гигабайт (∼ 1010 байт), чего, очевидно, недостаточно. Следующая память – жесткий диск. Обращение программы к этой памяти, по сути, останавливает нормальную работу программы. Как только кончаются ресурсы оперативной памяти, мы видим, что программа либо не работает совсем, либо начинает работать очень медленно. Отмеченную проблему можно решать, увеличивая оперативную память, либо используя распределенную память.

229

Но что делать, если α оказалось достаточно малым или мы не можем должным образом оценить снизу α, чтобы гарантировать быструю сходимость МПИ? В таком случае полезным оказывается следующий результат [48], не предполагающий, кстати, выполнения условия «непериодичности»,

⃦⊤

⃦C

def

1

T
∑︂

⃦P p¯T − p¯T ⃦1 ≤ T , p¯T = T p(t).

(76)

t=1

Эта оценка уже никак не зависит от α. Параллельное процедуре

p(t + 1) = P ⊤p(t)

суммирование получающихся векторов позволяет вычислять вектор

p¯T за время, по порядку величины равное времени расчета p(T ). К

сожалению, для ряда задач, например, исследования степенного зако-

на убывания компонент вектора PageRank, метод Поляка–Трембы [48]

не подходит. Причина связана с видом оценки (76). Имеется принци-

пиальная разница с оценкой (72) в том, что в оценке (72) мы можем

гарантировать близость найденного вектора p(T ) к вектору PageRank

ν, обеспечив малость ∥p(T ) − ν∥1. Что касается соотношения (76), то

в

типичных

случаях

из

⃦⃦P ⊤p¯T

−

⃦ p¯T ⃦

≈

ε

можно

при

больших

n

лишь

получить, что ∥p¯T − ν∥ ≈ ε/α, т.е. опять возникает «нехорошая» зави-

симость в оценке от α. Для симметричной матрицы P и 2-нормы этот

результат был получен Красносельским–Крейном [37] в 1952 г.

К сожалению, и другие способы поиска вектора PageRank, которые

на первый взгляд не используют в своих оценках α, на деле оказыва-

ются

методами,

выдающими

такой

вектор

p˜T ,

что

⃦⃦P ⊤p˜T

⃦ − p˜T ⃦

≈

ε

в некоторой норме (обычно это 1-норма, 2-норма и бесконечная нор-

ма – в следующем пункте мы поясним, что имеется в виду под этими

нормами), что приводит к той же сложности, что и в методе Поляка–

Трембы. Тем не менее хочется отметить большой прогресс, достигну-

тый за последнее время (во многом благодаря разработкам Б. Т. По-

ляка, А. С. Немировского, Ю. Е. Нестерова), в создании эффектив-

ных численных методов решения задач выпуклой оптимизации вида

(b = 1, 2; l = 1, 2, ∞)

⃦ ⃦P

⊤p

−

⃦b p⃦

→

min

.

l

n

p≥0: ∑︁ pk=1

k=1

Эти наработки оказываются полезными, поскольку вектор PageRank

230

можно также понимать, как решение такой задачи. Действительно,

всегда

имеет

место

неравенство

⃦⃦P ⊤p

−

⃦ p⃦

≥

0, и только на ν имеет

место

равенство

⃦ ⃦P

⊤ν

−

⃦ ν⃦

=

0.

Отметим, в частности, метод условного градиента, который позво-

ляет получить вектор p˜T , удовлетворяющий ⃦⃦P ⊤p˜T − p˜T ⃦⃦2 ≤ ε, за C ·(︁n + s2ε−2 ln n)︁ арифметических операций [18]. Удивительно, что

в эту оценку не входи√т sn – число ненулевых элементов матрицы P . В частности, при s ≈ n получается сложность пропорциональная n,

а не n3/2, как можно было ожидать (к сожалению, за это есть и плата в

виде множителя ε−2). Тем не менее еще раз повторим, что несмотря на

все возможные ускорения вычислений использование таких методов в

наших целях, к сожалению, не представляется возможным.

Отмеченные в этом разделе методы (МПИ и Поляка–Трембы) не

исчерпывают множество методов, гарантирующих малость ∥p˜T − ν∥,

в оценку скорости сходимости которых входит α. К таким методам

можно отнести, например, метод Д. Спилмана, являющийся вариацией

описанного выше метода Поляка–Трембы.

Б.3. Markov Chain Monte Carlo и Google problem
Далее мы сосредоточимся на так называемых методах Монте-Карло. Наряду с тем, что эти методы являются численными методами поиска вектора PageRank, они также позволяют по-новому проинтерпретировать вектор PageRank.
С одной стороны, в предположении достаточной величины спектральной щели МПИ обеспечивает очень быструю сходимость по норме приближенного решения к вектору PageRank. С другой стороны, одна итерация этого метода требует порядка sn арифметических операций, что может привести к невозможности его применения, если не выполнено неравенство s ≪ n. К тому же каждому поисковому запросу обычно соответствует свой web-граф релевантных страниц. Поэтому, как правило, для каждого запроса нужно вычислять свой вектор PageRank. Следовательно, для эффективной работы реальной поисковой системы скорость вычисления вектора PageRank оказывается важнее точности его вычисления. МПИ не позволяет в полной мере пожертвовать точностью в угоду скорости вычисления. В самом деле, согласно оценке (72), переход, скажем, от точности ε ≈ 10−6 к точности ε ≈ 10−3 уменьшит время счета всего лишь вдвое. Предложим другой алгоритм, который будет более чувствителен к точности по сравнению с МПИ, но при этом будет иметь меньшую стоимость итерации.

231

В основе этого алгоритма лежит метод Markov Chain Monte Carlo (MCMC). Основная идея заключается в практическом использовании эргодической теоремы. То есть, грубо говоря, нужно запустить человека и достаточно долго подождать, собирая статистику посещенных им вершин графа, т.е. web-страниц. При оценке эффективности работы такого метода важно ответить на два вопроса: насколько эффективным можно сделать шаг и сколько шагов надо сделать человеку.
Наиболее вычислительно затратная операция на каждом шаге метода – это случайный выбор ребра для перехода из текущей вершины. Случай, в котором из каждой вершины (web-страницы) выходит не более s ≪ n ребер, является простым. На каждом шаге за порядка s арифметических операций разыгрывается случайная величина в соответствии с вероятностями переходов. При этом память после каждой операции освобождается, т.е. не требуется хранить в памяти ничего, кроме матрицы P и текущего вектора частот. Отметим, тем не менее, как можно организовать вычисления в сложном случае, когда s является достаточно большим. Можно до старта итераций алгоритма подготовить специальным образом память за порядка sn арифметических операций, например, следующим образом. Каждой вершине ставится в соответствие свое разбиение отрезка [0, 1] так, чтобы число подотрезков равнялось числу выходящих ребер, а длины подотрезков были пропорциональны вероятностям перехода по этим ребрам. Тогда на каждом шаге достаточно один раз генерировать равномерно распределенную на отрезке [0, 1] случайную величину (стандартные генераторы, как правило, именно это в первую очередь и предлагают), и нанести ее на соответствующий текущей вершине подотрезок. В зависимости от того, в какой из подотрезков она попала, выбрать исходящее ребро и сдвинуть человека по нему. Недостаток этого подхода – использование дополнительно памяти для хранения порядка sn чисел и высокая стоимость подготовки этой памяти. К счастью, такая подготовка, требующая порядка sn арифметических операций, нужна только один раз, в отличие от МПИ, в котором таких затрат требует каждая итерация. При дополнительных предположениях о компактном описании формул расчета {pi,j}nj=1 существуют быстрые способы случайного выбора ребра для перехода из текущей вершины, которые приводят к тому, что шаг выполняется за ∼ log2 s ≤ log2 n арифметических операций. В частности, если имеет место равенство между собой отличных от нуля внедиагональных элементов матрицы P в каждой строке, то сложность шага ∼ log2 s достигается, например, методом Кнута–Яо.
Перейдем теперь к обсуждению оценки числа шагов, которое нуж-
232

но сделать человеку для достижения заданной точности приближения вектора PageRank. Постараемся грубо сформулировать основной результат. Пусть ν (T ) – вектор частот (случайный вектор) пребывания в различных вершинах блуждающего человечка после T шагов и T ≫ T0 d=ef Cα−1 ln (n/ε). Тогда с вероятностью не меньше 1 − σ (здесь и везде в дальнейшем σ ∈ (0, 1) – произвольный доверительный
уровень) имеет место неравенство

√︃

ln n + ln (σ−1)

∥ν (T ) − ν∥2 ≤ C

. αT

(77)

Приведем сравнительные характеристики упомянутых к настоящему моменту методов. Под сложностью понимается количество арифметических операций типа умножения двух чисел, которые достаточно осуществить, чтобы (в случае MCMC: с вероятностью не меньше 1−σ) достичь точности решения ε по целевой функции12, которая в табл. 1 обозначается целью.

Таблица 1

Сравнение методов решения задачи поиска вектора PageRank*

Метод 1 2 3
4
5

Сложность

sαn ln (︁ 2ε )︁
2sn

ε

C

·

(︂ n

+

s2

)︂ ln (︁ 1 )︁

αε

ε

C · (︂n + log2 nα·lεn2(n/σ) )︂

C · (︂n + s2εl2n n )︂

Цель ∥p˜T − ν∥1 ⃦⃦P T p˜T − p˜T ⃦⃦1 ∥p˜T − ν∥∞
∥p˜T − ν∥2 ⃦⃦P T p˜T − p˜T ⃦⃦2

*Методы: 1 – МПИ, 2 – метод Поляка–Трембы, 3 – метод Д. Спилмана, 4 – MCMC, 5 – вариация метода условного градиента.

Напомним, что вектор p˜T – это результат работы метода, а ν – вектор PageRank. Стоит также пояснить обозначение ∥x∥∞ = = maxk=1,...,n |xk|. Сравнение затрудняется тем, что у всех методов разные целевые функции, а значит и разные критерии точности. Кро-
ме того, разные методы могут по-разному быть ускорены с исполь-
зованием параллельных вычислений. Для задач огромных размеров,

12Заметим, что для метода MCMC имеет смысл рассматривать только ε ≪ n−1/2,

поскольку

⃦

(︁ ⃦

n−1

,

...,

n−1)︁⊤⃦⃦

= n−1/2.

⃦

⃦2

233

к которым, безусловно, относится и Google problem, этот вопрос выходит на передний план. Если умножение матрицы на вектор в МПИ хорошо параллелится, то, например, возможность применения параллельных вычислений к MCMC в описанном здесь варианте не ясна.
Б.4. Параллелизуемый вариант MCMC
Идею распараллеливания, собственно так же, как и идеи остальных описанных методов (МПИ, MCMC), подсказывает «жизнь». А именно, в реальном Интернете «блуждает» не один человек (пользователь), а много пользователей. Обозначим число независимо блуждающих пользователей через N . Рассмотрим сначала для простоты ситуацию, когда в графе всего две вершины, т.е. n = 2. Поскольку пользователи блуждают независимо, то для каждого из них можно ожидать, что на шаге T0 = Cα−1 ln (2/ε) вероятность обнаружить пользователя в вершине 1 с хорошей точностью (∼ ε) равна ν1. Соответственно, вероятность обнаружить его в вершине 2 равна ν2 = 1−ν1. Таким образом, посмотрев на то, в какой вершине находился каждый человек на шаге T0, мы с хорошим приближением получим так называемую простую выборку X (независимые одинаково распределенные случайные величины) из распределения Бернулли с вероятностью успеха (выпадения орла), равной ν1. Последнее означает, что каждый человек (подобно монетке) на шаге T0 независимо от всех остальных с вероятностью ν1 будет обнаружен в состоянии 1 («выпал орлом»), а с вероятностью 1 − ν1 будет обнаружен в состоянии 2 («выпал решкой»). Чтобы оценить вектор PageRank в данном простом случае, достаточно оценить по этой выборке ν1 – частоту выпадения орла. Интуиция подсказывает, что в качестве оценки неизвестного параметра ν1 следует использовать r/N – долю людей, которые оказались в состоянии 1. Интуиция подсказывает правильно! Далее будет показано, что такой способ действительно оптимальный.
Вероятность, что число людей r, которые наблюдались в состоянии 1, равно k, может быть посчитана по формуле (биномиальное распределение )
P (r = k) = CNk ν1k (1 − ν1)N−k .
Используя грубый вариант формулы Стирлинга k! ≃ (k/e)k, получаем оценку типа Санова:
CNk ν1k (1 − ν1)N−k ≃ exp (−N · KL (k/N, ν1)) ,
234

где

(︃ p )︃

(︃ 1 − p )︃

KL (p, q) = −p ln

− (1 − p) ln

.

q

1−q

Отсюда, по неравенству Пинскера:

KL (p, q) ≥ 2 (p − q)2 ,

следует, что с вероятностью не меньше 1 − σ имеет место неравен-

ство

√︃

⃓r

⃓

ln (σ−1)

⃓ − ν1⃓ ≤ C

,

(78)

⃓N ⃓

N

которое иллюстрируется на рисунке 25.

площадь под графиком ≥ 1 − σ

r/N

√︂

√︂

ν1 + C ln(σN−1) ν1 ν1 − C ln(σN−1)

Рис. 25. График зависимости P (r) = CNr ν1r (1 − ν1)N−r при большом значении N

По сути, этот рисунок отражает тот факт, что биномиальное распределение (биномиальная мера) с ростом числа исходов (людей) N концентрируется вокруг ν1.
Вектор ν = [ν1, ν2]⊤, в малой окрестности которого с большой вероятностью на больших временах находится реальный вектор распределения людей по web-страницам (в данном случае двум), естественно называть равновесием макросистемы, описываемой блуждающими по web-графу людьми. Таким образом, мы пришли к еще одному пониманию вектора PageRank ν, как равновесию описанной выше макросистемы.
235

На соотношение (78) можно посмотреть и с другой стороны – с точки зрения математической статистики. А именно, вспомним, что ν1 нам не известно. В то время как реализацию случайной величины (статистики) r/N мы можем измерить. Соотношение (78) от такого взгляда на себя не перестанет быть верным.
В общем случае для n вершин можно провести аналогичные рассуждения: с заменой биномиального распределения мультиномиальным. Чтобы получить аналог оценки (78), для концентрации мультиномиальной меры, можно использовать векторное неравенство Хефдинга. Оказывается, с вероятностью не меньше 1 − σ имеет место следующее неравенство:

√︃

⃦⃦ r − ν⃦⃦ ≤ C ln (σ−1) , (79)

⃦N

⃦
2

N

где вектор r = (r1, ..., rn)⊤ описывает распределение людей по webстраницам в момент наблюдения T0. Заметим, что константу C здесь можно оценить сверху числом 4. Неравенства (78), (79) являются пред-
ставителям класса неравенств концентрации меры, играющего важ-
ную роль в современной теории вероятностей и ее приложениях. Если запустить N ∼ ε−2 ln (︁σ−1)︁ человек, дав каждому сделать
T0 ∼ α−1 ln (n/ε) шагов (стоимость шага ∼ log2 n), то (вообще говоря, случайный) вектор r/N , характеризующий распределение людей по
web-страницам на шаге T0, с вероятностью не меньше 1 − σ обладает таким свойством: ∥r/N − ν∥2 ≤ ε. Это следует из оценки (79). Таким образом, мы приходим к оценке сложности (параллельного варианта)
метода MCMC:

(︄ log2 n · ln (n/ε) ln (︁σ−1)︁ )︄ C · n + αε2 ,

которая с точностью до логарифмического множителя совпадает с оценкой, приведенной в табл. 1. Однако отличие данного подхода в том, что можно пустить блуждать людей параллельно. То есть можно распараллелить работу программы на N процессорах. Разумеется, можно распараллелить и на любом меньшем числе процессоров, давая процессору следить сразу за несколькими людьми. Можно еще немного «выиграть», если сначала запустить меньшее число людей, но допускать, что со временем люди случайно производят клонов, которые с момента рождения начинают жить независимой жизнью так, чтобы к моменту T0 наблюдалось, как и раньше, N человек.

236

Пока мы не пояснили, в каком смысле и почему выбранный способ рассуждения оптимален. Для большей наглядности снова вернемся к случаю n = 2 и заметим, что оценка r/N неизвестного параметра ν1 может быть получена следующим образом:

r/N = arg max νr · (1 − ν)N−r .

(80)

ν∈[0,1]

Действительно, максимум у функций f1 (ν) = νr · (1 − ν)N−r1 и

f2

(ν)

=

ln

(︂ νr

·

(1

−

ν )N −r )︂

=

r

ln

ν

+

(N

−

r)

ln

(1

−

ν)

достигается в одной и той же точке, поэтому рассмотрим задачу

f2 (ν) → max .
ν∈[0,1]

Из принципа Ферма (максимум лежит либо на границе, либо среди точек, в которых производная обращается в ноль) получаем условие df2 (ν)/dν = 0, которое в данном случае примет вид

r N −r

−

= 0,

ν 1−ν

т.е.

r/N 1 − r/N

=

.

ν

1−ν

Отсюда и следует формула (80). Функция правдоподобия, стоящая в правой части (80), отражает
вероятность конкретного13 распределения людей по вершинам (webстраницам), для которого число людей в первой вершине равно ν. То есть оценка r/N может быть проинтерпретирована как оценка максимального правдоподобия. Указанный выше способ построения оценок является общим способом получения хороших оценок неизвестных параметров. А именно, пусть есть схема эксперимента (параметрическая модель), согласно которой можно посчитать вероятность того, что мы будем наблюдать то, что наблюдаем. Эта вероятность (плотность вероятности) зависит от неизвестного вектора параметров θ. Будем максимизировать эту вероятность по параметрам этого вектора при заданных значениях наблюдений, т.е. при заданной выборке. Тогда получим зависимость неизвестных параметров от выборки X. Именно эту зависимость θˆN (X) в общем случае и называют оценкой макси-

13Поскольку «конкретного», то не нужно писать биномиальный коэффициент.

237

мального правдоподобия вектора неизвестных параметров. Оказывается (теорема Фишера), что в случае выполнения довольно общих условий регулярности используемой параметрической модели такая оценка является асимптотически оптимальной (теория ле Кама). Последнее можно понимать так, что для каждой отдельной компоненты k вектора θ можно написать неравенство, аналогичное (78), справедливое с вероятностью не меньшей 1 − σ:

√︃

⃓

⃓

⃓θˆN (X) − θ ⃓ ≤ C

ln (σ−1) (θ)

⃓k

k⃓

k,N

N

c Ck,N (θ) → Ck (θ) при N → ∞, где N – объем выборки, т.е. число наблюдений. При этом Ck (θ) > 0 являются равномерно по θ и k наименее возможными. Имеется в виду, что если как-то по-другому оценивать θ (обозначим другой способ оценивания θ˜N (X)), то для любого θ и k
с вероятностью не меньшей 1 − σ

√︃

⃓

⃓

⃓θ˜N (X) − θ ⃓ > C˜

ln (σ−1)

(θ)

,

⃓k

k⃓

k,N

N

где lim infN→∞ C˜k,N (θ) ≥ Ck (θ). Строго говоря, именно такая зависимость правой части от σ имеет
место не всегда. В общем случае при зафиксированном N с уменьшением σ правая часть может вести себя хуже, однако при не очень маленьких значениях14 σ написанное верно всегда.
К сожалению, приведенная выше весьма вольная формулировка не отражает в полной мере всю мощь теоремы Фишера. Ведь в таком виде открытым остается вопрос об оценках совместного распределения отклонений сразу нескольких компонент оценки максимального правдоподобия от истинных значений. На самом деле можно сформулировать результат (делается это чуть более громоздко) об асимптотической оптимальности оценки максимального правдоподобия и в таких общих категориях. Мы не будем здесь этого делать.
Основным недостатком теоремы Фишера в приведенном нами варианте ле Кама заключается в том, что оценка оптимальна только в пределе N → ∞. В реальности же нам дана только конечная выборка, пусть и большого объема. Сформулированный выше результат ничего не говорит, насколько хорошей будет такая оценка при конечном N . Также теорема не говорит о том, как получать точные оценки на Ck,N (θ). Теорема лишь предлагает эффективный способ расчета
14Пороговое значение σ0 удовлетворяет следующей оценке: ln N ≪ ln σ0−1 ≪ N .

238

Ck (θ).15 Скажем, приведенная нами ранее оценка (78), хотя по фор-

ме и выглядит так, как нужно, но все же она далеко не оптимальна.

В частности, в оптимальный вариант оценки (78) нужно прописывать

под корнем в числителе еще множитель ν1 · (1 − ν1), оцененный нами

сверху в (78) константой 1/4. Мы сделали такую замену в (78), что-

бы в правую часть неравенства не входил неизвестный параметр ν1.

При значениях ν1 близких к нулю или единице, такая «замена» ока-

зывается слишком грубой. Мы привели простой пример, в котором

мы смогли проконтролировать грубость своих рассуждений. В общем

случае, к сожалению, это не так просто сделать (если говорить о по-

терях в мультипликативных константах типа C). Поэтому если мы

хотим использовать оценки типа (78), (79), то борьба за «оптималь-

ные константы» сводится не только к выбору оптимального способа

оценивания неизвестных параметров, но и к способу оценивания кон-

центрации вероятностного распределения выбранной оценки вокруг

истинного значения. За последние несколько лет теория ле Кама бы-

ла существенно пересмотрена как раз в контексте отмеченных выше

проблем.

Другая проблема – это зависимость Ck от неизвестного парамет-

ра θ. Грубо, но практически эффективно, проблема решается подста-

(︂

)︂

новкой Ck θˆN (X) . Более точно надо писать неравенство концентра-

(︂

)︂

ции для Ck θˆN (X) , исходя из неравенства на θˆN (X). Казалось бы,

что возникает «порочный круг», и это приводит к иерархии «зацепля-

ющихся неравенств». Однако если выполнить описанное выше огруб-

ление16 для того, чтобы обрезать эту цепочку не сразу, а на каком-то

далеком вложенном неравенстве, то чем оно дальше, тем к меньшей

грубости это в итоге приведет. Детали мы также вынуждены здесь

опустить.

Пример Б.1. Оценить, сколько надо опросить человек на выхо-

де с избирательных участков большого города, чтобы с точностью 5%

(0.05) и с вероятностью 0.99 оценить победителя во втором туре выбо-

ров (два кандидата, графы против всех нет). Для решения этой задачи

рекомендуется воспользоваться неравенством (78) с явно выписанны-

ми константами: √︃

⃓r

⃓ 1 ln (2/σ)

⃓⃓ N − ν1⃓⃓ ≤ 2

.△ N

15Ck (θ) – не универсальны и зависят от использующейся параметрической модели.
16Речь идет об оценке ν1 · (1 − ν1) ≤ 1/4.
239

Б.5. Модель Бакли—Остгуса и степенные законы
С точки зрения практических нужд (например, для разработки алгоритмов борьбы со спамом), модели web-графа оказываются зачастую более востребованными, чем сами вебграфы ввиду того, что вебграфы имеют слишком большие для анализа размеры. Кроме того, с помощью моделей можно исследовать различные закономерности, присущие web-графу. Так, Интернету и многим социальным сетям присущи определенные хорошо изученные закономерности: наличие гигантской компоненты, правило пяти рукопожатий, степенной закон для распределения степеней вершин, специальные свойства кластерных коэффициентов и т.д. Хотелось бы предложить такую модель формирования этих сетей, которая бы объясняла все эти закономерности. Построив такую модель, с помощью фундаментальной науки мы можем открывать новые свойства, присущие изучаемой сети, исследуя лишь свойства выбранной модели. Такие исследования позволяют в дальнейшем использовать полученные результаты при разработке алгоритмов для реальных сетей, в том числе Интернета.
Одной из лучших на текущий момент моделей web-графа считается модель Бакли–Остгуса [49]. Именно ее мы и будем рассматривать. Новым свойством, которое мы хотим проверить, будет степенной закон распределения компонент вектора PageRank, посчитанного для графа, сгенерированного по этой модели. Далее мы описываем модель Бакли– Остгуса и выводим17 степенной закон распределения степеней вершин графа, построенного по этой модели. Именно этот закон приводит к степенному закону распределения компонент вектора PageRank.
Итак, рассмотрим следующую модель роста сети. База индукции. Сначала имеется всего одна вершина, которая ссылается сама на себя (вершина с петлей). Шаг индукции. Предположим, что уже имеется некоторый ориентированный граф. Добавим в граф новую вершину. С вероятностью β > 0 из этой вершины проведем ребро равновероятно в одну из существующих вершин, а с вероятностью 1−β из этой вершины проводится ребро в одну из существующих вершин не равновероятно, а с вероятностями, пропорциональными входящим степеням вершин18 – правило предпочтительного присоединения (от англ. preferential attachment). Другими словами, если уже построен граф из n−1 вершины, то но-
17Не строго, а в так называемом термодинамическом пределе. 18Выходящая степень всех вершин одинакова и равна 1.
240

вая n-я вершина сошлется на вершину i = 1, ..., n − 1 с вероятностью

Indegn−1 (i) + a , (n − 1) (a + 1)

где Indegn−1 (i) – входящая степень вершины i в графе, построенном на шаге n − 1. Параметры β и a связаны следующим образом:

β

a=

.

1−β

При a = 1 получается известная модель Боллобаша–Риордана. Интернету наилучшим образом соответствует значение a = 0.277 [49].
Далее вводится число m – среднее число web-страниц на одном сайте, и каждая группа web-страниц с номерами km + 1, ..., (k + 1) m объединяется в один сайт. При этом все ссылки, имеющиеся между web-страницами, наследуются содержащими их сайтами – получается, что с одного сайта на другой19 может быть несколько ссылок. Пусть, скажем, получилось, что для заданной пары сайтов таких (одинаковых) ссылок оказалось l ≤ m, тогда мы превращаем их в одну ссылку, но с весом (вероятностью перехода) l/m. Именно для так построенного взвешенного ориентированного графа можно изучать закон распределения компонент вектора PageRank.
К сожалению, строго доказать, что имеет место степенной закон распределения компонент вектора PageRank в этой модели, насколько нам известно, пока никому не удалось. Имеется только один специальный результат на эту тему, касающийся модели, близкой к модели Боллобаша–Риордана. Однако, чтобы у читателей появилась некоторая интуиция, почему такой закон может иметь место в данном случае, мы приведем далее некоторые аргументы.
Сначала установим степенной закон распределения входящих вершин в модели Бакли–Остгуса. При этом ограничимся случаем m = 1. Обозначим через Xk (t) число вершин с входящей степенью k в момент времени t, т.е. когда в графе имеется всего t вершин. Заметим, что по определению

∑︂

∑︂

∑︂

t = Xk (t) = kXk (t) = kXk (t).

k≥0

k≥1

k≥0

Поэтому для k ≥ 1 вероятность того, что Xk (t) увеличится на еди-
19Впрочем, сайты могут совпадать – внутри одного сайта web-страницы также могут друг на друга сослаться.

241

ницу при переходе на следующий шаг t → t + 1 по формуле полной вероятности равна

β Xk−1 (t) + (1 − β) (k − 1) Xk−1 (t) .

t

t

Аналогично, для k ≥ 1 вероятность того, что Xk (t) уменьшится на единицу при переходе на следующий шаг t → t + 1

β Xk (t) + (1 − β) kXk (t) .

t

t

Таким образом, «ожидаемое» приращение ∆Xk(t) = Xk (t + 1) − Xk (t) за ∆t = (t + 1) − t = 1 будет20

∆Xk (t) = β Xk−1(t) − Xk(t) + (1 − β) (k − 1) Xk−1 (t) − kXk (t) . (81)

∆t

t

t

Для X0 (t) уравнение, аналогичное (81), будет иметь вид

∆X0 (t) = 1 − β X0 (t) .

(82)

∆t

t

К сожалению, соотношения (81), (82) – не есть точные уравнения, описывающие то, как меняется Xk (t), хотя бы потому, что изменение Xk (t) происходит случайно. Динамика же (81), (82) полностью детерминированная. Однако для больших значений t, когда наблюдается концентрация случайных величин Xk (t) вокруг своих математических ожиданий, реальная динамика поведения Xk (t) и динамика поведения средних значений Xk (t) становятся близкими21 – вариация на тему теоремы Куртца. Таким образом, на систему (81), (82) можно смотреть, как на динамику средних значений, вокруг которых плотно сконцентрированы реальные значения. Под плотной концентрацией

20Корректная запись:

(︃

∆Xk

(t)

⃓ ⃓

)︃

EXk+1 (t)

∆t ⃓⃓ X0 (t) , ..., Xk (t) =

β Xk−1 (t) − Xk (t) + (1 − β) (k − 1) Xk−1 (t) − kXk (t) .

t

t

Беря от обеих частей математическое ожидание EX0(t),...,Xk(t) (·), получим

E (︃ ∆Xk(t) )︃ = β E (Xk−1 (t)) − E (Xk (t)) + (1 − β) (k − 1) E (Xk−1 (t)) − kE (Xk(t)) .

∆t

t

t

21Последняя динамика уже является детерминированной динамикой.

242

имеется в виду, что разброс значений величины контролируется квадратным корнем из ее среднего значения.
Будем искать решение системы (81), (82) на больших временах (t → ∞) в виде Xk (t) ∼ ck · t (иногда такого вида режимы называют промежуточными асимптотиками). Подставляя это выражение в формулы (81), (82), получим

1 c0 = 1 + β ,

ck = 1 −

2−β

(︃ 2 − β )︃ 1

≃1−

.

ck−1

1 + β + k · (1 − β)

1−β k

Откуда получаем следующий степенной закон:

ck

∼

k

−

2−β 1−β

= k−2−a.

(83)

Заметим, что если построить на основе (83) ранговый закон распределения вершин по их входящим степеням, т.е. отранжировать вершины по входящей степени, начиная с вершины с самой высокой входящей степенью, то также получим степенной закон

in deg(r) ∼ r−1−β.

(84)

Действительно, обозначив для краткости in deg(r) через x, получим,

что нам нужно найти зависимость x (r), если из формулы (83) извест-

но, что

dr (x)

∼

−x

−

2−β 1−β

=

−x

−

1−

1 1−

β

,

dx

где зависимость r (x) получается из зависимости x (r) как решение уравнения x (r) = x. Остается только подставить сюда и проверить приведенное соотношение (84).
Перейдем теперь к пояснению того, почему может иметь место степенной закон распределения компонент вектора PageRank. Для этого предположим, что матрица P имеет вид

⎡ 1−λ 2−λ 3−λ 4−λ 5−λ ... ⎤ ⎢ 1−λ 2−λ 3−λ 4−λ 5−λ ... ⎥ P ∼ ⎢⎣ 1−λ 2−λ 3−λ 4−λ 5−λ ... ⎥⎦ .
......................................

Такой вид матрицы означает, что для каждого сайта имеет место точный (т.е. не в вероятностном смысле) степенной закон распределения выходящих степеней вершин, имеющий одинаковый вид для всех сайтов. Конечно, это намного более сильное предположение, чем то, что

243

мы выше получили для модели Бакли–Остгуса. Тогда для выписанной матрицы P выполняются условия единственности вектора PageRank ν, определяющегося формулой (2). Более того, этот вектор, неизбежно должен совпадать со строчкой (не важно какой именно – они одинаковые) матрицы P , т.е.
νk ∼ k−λ.
Но это и означает, что имеет место степенной закон распределения компонент вектора PageRank. Разумеется, проведенные рассуждения ни в какой степени нельзя считать доказательством. Тем не менее мы надеемся, что некоторую интуицию эти рассуждения читателям всетаки смогли дать.
В заключении этого раздела заметим, что можно получить закон (83) в более точных вероятностных категориях. Хотя это можно сделать вполне элементарными комбинаторными средствами, тем не менее соответствующие выкладки оказываются достаточно громоздкие, поэтому мы не приводим их здесь.

Б.6. Элементы теории макросистем

В контексте написанного выше хотелось бы отметить, что подобно системе (81), (82) можно записать динамику средних (говорят также квазисредних ) и для макросистемы блуждающих по web-графу людей. А именно, предположим, что людей достаточно много и что каждый человек в любом промежутке времени [t, t + ∆t) независимо от остальных с вероятностью, равной ∆t + o(∆t), совершает переход по одной из случайно выбранных согласно матрице P ссылок. Обозначив через ck (t) долю людей, находящихся в момент времени t на web-странице с номером k, получим следующую систему:

∆cT (t) = cT (t) P − cT (t) .

(85)

∆t

Формула (85) подтверждает вывод о том, что вектор PageRank ν, удовлетворяющий системе (71), действительно можно понимать как равновесие макросистемы. В самом деле, если существует предел ν = = limt→∞ c (t), то из (85) следует, что этот предел должен удовлетворять (71). Здесь предел всегда существует, но может зависеть от начального условия. Для того чтобы предел не зависел от начального условия и был единственным, нужно сделать предположение о наличии в графе «Красной площади».
Имеется глубокая связь между приведенной выше схемой рассуж-

244

дений и общими моделями макросистем, которые, с точки зрения математики, можно понимать как разнообразные модели стохастической химической кинетики. В частности, система (85) соответствует закону действующих масс Гульдберга–Вааге. При этом важно подчеркнуть, что возможность осуществлять описанный выше канонический скейлинг, по сути заключающийся в замене концентраций их средними значениями, обоснована теоремой Куртца (в том числе и для нелинейных систем, появляющихся, когда имеются не только унарные реакции, как в примере с PageRank’ом) только на конечных отрезках времени. Для бесконечного отрезка22 требуются дополнительные оговорки, например, выполнение условия детального баланса и его обобщений. В общем случае использованные нами предельные переходы (по времени и числу агентов) не перестановочны, см., например, [8, глава 6]!
Рассуждения предыдущих пунктов соответствуют следующему порядку предельных переходов: сначала t → ∞ (выходим на инвариантную меру/стационарное распределение), потом N → ∞ (концентрируемся вокруг наиболее вероятного макросостояния инвариантной меры), а рассуждения этого пункта: сначала N → ∞ (переходим на описание макросистемы на языке концентраций, устраняя случайность с помощью законов больших чисел), потом t → ∞ (исследуем аттрактор полученной при скейлинге детерминированной, т.е. не стохастической, системы). Для примеров макросистем, рассмотренных в этом и предыдущем приложениях, получается один и тот же результат. Более того, если посмотреть на то, как именно концентрируется инвариантная мера для, то получим, что концентрация экспоненциальная

P (r = k) = N ! νk1 · ... · νkn ≃ exp (−N · KL (k/N, ν)) ,

k1! · ... · kn! 1

n

n
где функция действия (функция Санова) KL(x, y) = −∑︁ xk ln (xk/yk).
k=1
В других контекстах функцию KL чаще называют дивергенцией Кульбака–Лейблера или просто энтропией23. При этом функция KL(c(t),ν), как функция t, монотонно убывает с ростом t на траекториях системы (85), т.е. является функцией Ляпунова. Оказывается, этот факт24 имеет место и при намного более общих условиях [8]. Точнее говоря, сам
22А именно эта ситуация нам наиболее интересна, поскольку, чтобы выйти на
равновесие, как правило, необходимо перейти к пределу t → ∞. 23Отсюда, по-видимому, и пошло, что «равновесие следует искать из принципа
максимума энтропии» [2]. 24Известный из курса термодинамики/статистической физики, как H-теорема
Больцмана.

245

факт о том, что функция, характеризующая экспоненциальную концентрацию инвариантной меры, будет функцией Ляпунова динамической системы, полученной в результате скейлинга из марковского процесса, породившего исследуемую инвариантную меру, имеет место всегда, а вот то, что именно такая KL-функция будет возникать, соответствует макросистемам, удовлетворяющим обобщенному условию детального баланса (условию Штюкельберга–Батищевой–Пирогова), и только таким макросистемам [8].
246

В. Задача о разборчивой невесте
Рассматриваемая далее задача о разборчивой невесте также изложена с точки зрения оптимальной остановки марковских процессов в [70], где можно посмотреть детали. Популярное изложение имеется в брошюре [27].
На примере решения этой задачи хотелось бы продемонстрировать элементы теории управляемых марковских процессов и основное уравнение данной теории – уравнение Вальда–Беллмана.
В.1. Формулировка задачи
Примерно 55 лет тому назад Мартин Гарднер придумал такую задачу: «В некотором царстве, в некотором государстве пришло время принцессе выбирать себе жениха. В назначенный день явились 1000 царевичей. Их построили в очередь в случайном порядке и стали по одному приглашать к принцессе. Про любых двух претендентов принцесса, познакомившись с ними, может сказать, какой из них лучше. Познакомившись с претендентом, принцесса может либо принять предложение (и тогда выбор сделан навсегда), либо отвергнуть его (и тогда претендент потерян: царевичи гордые и не возвращаются). Какой стратегии должна придерживаться принцесса, чтобы с наибольшей вероятностью выбрать лучшего?»
В.2. Оптимальная стратегия
Везде в дальнейшем будем считать, что все 1000! способов расстановки претендентов равновероятны (это означает отсутствие изначально у невесты какой-либо информации о том, где может быть наилучший жених). Под оптимальной стратегией невесты понимается такая стратегия, которая максимизирует вероятность выбора наилучшего жениха. Другими словами, максимизирует число расстановок претендентов, на которых невеста выбирает наилучшего жениха.
Оптимальная стратегия невесты: пропустить первых 1/e претендентов (приблизительно треть) и затем выбрать первого наилучшего претендента (если такой появится: среди пропущенных претендентов мог быть самый лучший – в таком случае, никого лучше невеста уже не встретит, т.е. такая стратегия не позволит ей сделать выбор). Такая стратегия позволяет невесте выбрать наилучшего жениха с вероятностью 1/e.
247

В.3. Управляемые марковские процессы
Рассмотрим некоторую управляемую марковскую систему, которая со временем (t = 0, 1, 2, . . . ) претерпевает случайные изменения. Будем считать, что все время система может находиться лишь в конечном числе возможных состояний S. На каждом шаге система находится в одном из этих состояний, и на каждом шаге мы должны управлять системой, выбирая свою стратегию из конечного множества стратегий A. Исходя из того, в каком состоянии s ∈ S находится система в текущий момент t и какое действие было выбрано a ∈ A, можно определить, с какой вероятностью система окажется в следующий момент t + 1 в состоянии s′ ∈ S. Обозначим эту вероятность p(s, a; s′). По определению
∑︂ p(s, a; s′) = 1.
s′ ∈S
В каждый момент времени мы получаем вознаграждение r(s, a) (r – reward), зависящее от состояния системы s и выбранного действия a (E r(s, a) = R(s, a)).
Цель (управления) – получить максимальное итоговое вознаграждение:
∞
V ∗(s) = max E ∑︂ γtr(st, a(st)), s0 = s.
a(·) t=0
В данной записи E(·) обозначает математическое ожидание (среднее значение), максимум по a(·) означает, что мы должны оптимизировать по конечному множеству (мощности |A||S| ) всевозможных функций a : S → A, параметр γ ∈ (0, 1] обычно называют коэффициентом дисконтирования (этот параметр отвечает, грубо говоря, за то, как обесцениваются деньги – считаем, что вознаграждение денежное), st – состояние системы в момент времени t. Функция V ∗(s) – функция цены (ожидаемый выигрыш при использовании оптимальной стратегии, если система в начальный момент находилась в состоянии s).

В.4. Принцип динамического программирования
Функция V ∗(s) удовлетворяет уравнению Вальда—Беллмана:

(︄

)︄

V ∗(s) = max R(s, a) + γ ∑︂ p(s, a; s′)V ∗(s′) ,
a∈A s′ ∈S

248

а оптимальная стратегия может быть найдена из условия

(︄

)︄

a(s) = arg max R(s, a) + γ ∑︂ p(s, a; s′)V ∗(s′) .

(86)

a∈A

s′ ∈S

Идея доказательства (здесь s = s0, s1 = s′):

∞
V ∗(s) = max E ∑︂ γtr(st, a(st)) =
a(·) t=0

(︄

∞

)︄

= max E r(s0, a(s0)) + γ ∑︂ γtr(st+1, a(st+1)) =
a(·) t=0

= max (R(s0, a) + γEs V ∗(s1)) =

a∈A

1

(︄

)︄

= max R(s, a) + γ ∑︂ p(s, a; s1)V ∗(s1) .
a∈A s1

В общем случае искать решение (86) сложно! Но для задачи о разборчивой невесте, все можно сделать явно!

В.5. Поиск оптимальной стратегии невесты
Введем управляемую марковскую систему, соответствующую задаче. Положим γ = 1, S = {1, 2, . . . , N, End}, N = 1000. Если система оказалась в состоянии s, то это соответствует тому, что претендент, вошедший s-м по порядку, оказался лучше всех предыдущих. Определим множество стратегий (действий невесты). Довольно очевидно, что возможны всего два действия A = {не выбрать, выбрать}. «Фиктивное» состояние End наступает либо на следующем шаге, после того как невеста пропустила (не выбрав) лучшего жениха, либо на следующем шаге, после шага, когда невеста сделала свой выбор. Исходя из такого описания, можно посчитать соответствующие функции вознаграждения и вероятности переходов:
R(s = End, a = выбрать) = 0, R(s, a = не выбрать) = 0;
R(s, a = выбрать) = s/N, s = 1, . . . , N,

249

поскольку
{︄ r(s, a = выбрать) = 1, с вероятностью s/N,
0, с вероятностью 1 − s/N.

С переходными вероятностями немного сложнее:

p(s, a = выбрать; s′) = 0, s′ ̸= End,

p(s, a = выбрать; s′ = End) = 1;

p(s = End, a, s′ = End) = 1;

p(s, a = не выбрать; s′ = End) =

(︄

)︄

s-й претендент лучше всех, если

s

= P известно только, что он лучше предыдущих = N ;

p(s, a = не выбрать; s′) =

(︄

s′-й

претендент

–

первый

кто,

лучше

)︄ s-го,

= P если известно, что s-й лучше предыдущих =

(︄

)︄

s-й претендент лучше предыдущих и

P s′-й претендент – первый кто, лучше s-го = P(s-й претендент лучше предыдущих)

s = s′(s′ − 1) ,

поскольку

P(s-й претендент лучше предыдущих) = (s − 1)! = 1 ,

s!

s

(︄

)︄

s-й претендент лучше предыдущих и (s′ − 2)!

1

P

s′-й – первый кто, лучше s-го

= s′! = s′(s′ − 1) .

250

Граф, отвечающий марковской цепи в задаче о разборчивой невесте.

p

=

S S ′ (S ′ −1)

1 1

2

...

S

...

S′

...

N

p = NS

End

1 a = не выбрать
2 ... S ... S′ ... N 1
1 1 11
End

1 a = выбрать

251

Теперь можно выписать уравнение Вальда–Беллмана

(︄

)︄

V ∗(s) = max R(s, a) + γ ∑︂ p(s, a; s′)V ∗(s′) ,
a∈A s′ ∈S

V ∗(s) = max (︄ s , ∑N︂

)︄ s V ∗(s′) , s = 1, . . . , N −1; V ∗(N ) = 1.

N

s′(s′ − 1)

s′ =s+1

Если максимум достигается на первом аргументе, то a(s) = выбрать, если на втором, то a(s) = не выбрать. Оказывается, что данное уравнение можно явно разрешить.
Для этого определим s∗(N ) из уравнения

1

1

1

1

1

1

s∗ + s∗ + 1 + · · · + N − 1 ≤ 1 ≤ s∗ − 1 + s∗ + · · · + N − 1 .

Можно показать, что

s∗(N ) ≃ [︃ N ]︃ . e

Введем

V ∗ = s∗(N ) − 1 (︃ 1

1

1 )︃ 1

+

+···+

≃.

N

s∗(N ) − 1 s∗(N )

N −1 e

Тогда

{︄ V ∗(s) = V ∗, 1 ≤ s ≤ s∗(N ),
s/N, s ≥ s∗(N ).

252

Г. Задача о многоруких бандитах
В данном разделе будет рассмотрена другая популярная задача на управляемые марковские процессы – задача о многоруких бандитах [77, 78, 103, 108]. В отличие от задачи о разборчивой невесте, явно решить здесь уравнение Вальда–Беллмана не получается. Тем не менее существуют различные достаточно эффективные способы приближенного решения данной задачи, которые хотелось бы продемонстрировать.

Г.1. Формулировка задачи
Имеется n ручек (игровых автоматов). Дергая ручку i = 1, . . . , n, мы каждый раз (независимо ни от чего) с вероятностью pi получаем один рубль, а с вероятностью 1 − pi ничего не получаем. Разрешается сделать N ≫ 1 шагов, на каждом шаге можно дергать только одну ручку. Величины pi априорно не известны. Однако известно, что pi «были приготовлены» следующим образом: pi ∈ R(0, 1), i = 1, . . . , n. Требуется найти оптимальную (максимизирующую ожидаемый доход) стратегию выбора ручек на шагах.

Г.2. Уравнение Вальда–Беллмана
Основной задачей данного раздела является сопоставление описанному процессу выбора ручек управляемого марковского процесса и получение соответствующего уравнения Вальда–Беллмана.
Прежде всего, определим пространство состояний (w – win, l – lose): s = (w1, l1; . . . ; wn, ln), где ∑︁ni=1(wi + li) = k ≤ N , k – номер шага, wi – сколько выигрышей было связано с ручкой i к шагу k (т.е. сколько рублей нам принесла i-я ручка к шагу k), li – сколько неудач было связано с ручкой i к шагу k. Стратегией является выбор на каждом шаге одной из ручек a(s) ∈ {1, . . . , n}, исходя из истории выигрышей, имеющейся к данному шагу.
В постановке задачи ничего явно не говорится относительно вероятностей переходов из одного состояния в другое:

(w1, l1; . . . ; wi, li; . . . ; wn, ln) → (w1, l1; . . . ; wi + 1, li; . . . ; wn, ln) ,

(w1, l1; . . . ; wi, li; . . . ; wn, ln) → (w1, l1; . . . ; wi, li + 1; . . . ; wn, ln) .

Для того чтобы определить вероятности таких переходов (обозначим

их

соответственно

ρwi (wi, li)

и

ρ

l i

(w

i

,

li

)

=

1

−

ρ

w i

(

wi

,

li

)),

заметим,

что

253

если априорно pi ∈ B(w, l), т.е. плотность распределения pi имеет вид

(w + l + 1)! xw(1 − x)l, x ∈ [0, 1], w!l!
то (по формуле Байеса) апостериорное распределение

pi | (wi, li) ∈ B(w + wi, l + li).

Заметим, что B(0, 0) = R(0, 1), поэтому

ρwi (wi, li) | (wi, li) ∈ B(wi, li).

В этой связи говорят, что бета-распределение является сопряженным

к схеме испытаний Бернулли.

Функция вознаграждения также определяется по введенным веро-

ятностям: если была выбрана ручка i (с историей (wi, li)), то возна-

граждение равно 1 рубль с вероятностью ρwi (wi, li) и 0 рублей с вероятностью ρli(wi, li).

Подчеркнем, что появление в постановке задачи априорного рас-

пределения

на

pi

привело

к

тому,

что

вероятности

ρ

w i

(w

i

,

li

),

ρ

l i

(wi

,

li

),

в свою очередь, являются случайными величинами, и при выводе урав-

нения Вальда–Беллмана следует это учитывать, беря дополнительное

(условное/апостериорное) усреднение.

Итак, уравнение Вальда–Беллмана в данном случае будет иметь

следующий вид (по постановке задачи γ = 1):

V ∗ (w1, l1; . . . ; wn, ln) =

(︃ = max Eρw,ρl ρwi (wi, li) · (1 + γV ∗(w1, l1; . . . ; wi + 1, li; . . . ; wn, ln)) +
i=1,...,n i i

)︃

+ρli(wi,

li)γV

∗(w1,

l1;

.

.

.

;

wi,

li

+

1;

.

.

.

;

wn,

ln)

⃓ ⃓

(wi,

li)

=

(︃ = max

wi + 1

(1 + γV ∗(w , l ; . . . ; w + 1, l ; . . . ; w , l )) +

i=1,...,n wi + li + 2

11

i

i

nn

+

li + 1

)︃ γV ∗(w , l ; . . . ; w , l + 1; . . . ; w , l ) .

wi + li + 2

11

ii

nn

Полагая V ∗ (w1, l1; . . . ; wn, ln) = 0 при ∑︁ni=1(wi + li) > N,

можно попробовать получить решение этого уравнения. Однако для

254

этого придется проделать экспоненциально много (по N ) вычислений и использовать экспоненциально большие ресурсы памяти, что типично для динамического программирования [74].

Г.3. Индексы Гиттинса
Возможным способом решения отмеченной выше проблемы является использование специфики задачи, связанное с допустимостью представления решения в виде индексной стратегии.
Для простоты будем считать в этом и следующем разделах, что γ < 1 и N → ∞. Рассмотрим сначала случай, когда всего две ручки, вероятность на одной из которых известна и равна p. Обозначим функцию выигрыша в этом случае V ∗(w, l; p). Уравнение Вальда–Беллмана для такой функции будет иметь вид

V ∗(w, l; p)

=

(︃ max

p

,

w+1

[1 + γV ∗(w + 1, l; p)] +

1−γ w+l+2

+

l+1

)︃ γV ∗(w, l + 1; p) .

w+l+2

Заметим, что при w + l ≫ 1 значение этой функции с хорошей точностью можно определять, как V ∗(w, l; p) = (1 − γ)−1 max (p, w/(w + l)). Заметим также, что неточность, допущенная в этой формуле, при каждом последующем уменьшении номера шага k = w + l на 1 согласно уравнению Вальда–Беллмана будет уменьшаться в γ раз, т.е. нет необходимости следовать условию N → ∞, достаточно задать V ∗(w, l; p) лишь при больших значениях N = w + l, как указано выше. Таким образом, можно определить при каждом p функцию V ∗(w, l; p) и сделать это намного эффективнее (с полиномиальной сложностью), чем в предыдущем пункте.
Далее определим индекс Гиттинса ручки с историей (w, l), как pγ(w, l) из решения уравнения (относительно p):

V ∗(w, l; p) =

p .

1−γ

При w + l → ∞ имеем pγ(w, l) → (1 − γ)−1 w/(w + l). Заметим, что индекс pγ(w, l) можно считать в целом известной функцией, значения которой хорошо протабулированы. Используя эту функцию (индекс) и принцип Вальда–Беллмана, несложно заметить, что максимум в правой части уравнения Вальда–Беллмана из предыдущего пункта будет достигаться на той ручке, у которой наибольший индекс pγ(wi, li) [83].

255

Таким образом, решение задачи о многоруких бандитах можно получить в предположении наличия таблицы значений pγ(w, l).
Г.4. Q-обучение
В предыдущих разделах проблема отсутствия информации об управляемом марковском процессе, отвечающем задаче о многоруких бандитах, была решена в итоге с помощью индексов Гиттинса за счет байесовского подхода – задания априорного распределения. В общем случае возможность использовать байесовский подход в исследовании управляемых марковских процессов предполагает наличие вероятностной модели для переходных вероятностей и вознаграждений, зависящей от неизвестных параметров. Сам факт наличия такой параметрической модели далеко не всегда имеет место. Но еще более специальное предположение, которое мы существенным образом использовали, – это некоторая симметричность постановки задачи, позволившая искать решение в виде индексной стратегии. Естественно, возникает вопрос: что же делать в общем случае, когда ничего не известно и все, что можно делать, это только наблюдать за процессом и обучаться?
Для ответа на поставленный вопрос вернемся к достаточно общей модели управляемого марковского процесса с конечным числом состояний и стратегий (действий). Будем использовать общие обозначения, введенные в разделе В.3. Только сделаем для удобства обозначений, одно небольшое уточнение: будем считать, что функция вознаграждения всецело определяется текущим состоянием, выбранной стратегией и состоянием, в которое перейдет процесс на следующем шаге. Таким образом, предполагается, что случайность в функции вознаграждения всецело определяется состоянием, в которое переходит процесс. Заметим, что и примеры с разборчивой невестой и с многорукими бандитами подходят под это предположение. В сделанных предположениях уравнение Вальда–Беллмана будет иметь вид
V ∗(s) = max ∑︂ p(s, a; s′) (r(s, a; s′) + γV ∗(s′)) .
a∈A s′ ∈S
Введем Q-функцию
Q(s, a) = ∑︂ p(s, a; s′) (r(s, a; s′) + γV ∗(s′)) .
s′ ∈S
256

Несложно заметить, что

V ∗(s) = max Q(s, a).
a∈A

Следовательно, Q-функция должна удовлетворять Q-уравнению:

(︃

)︃

Q(s, a) = ∑︂ p(s, a; s′) r(s, a; s′) + γ max Q(s′, a′) .
a′ ∈A s′ ∈S

Данное уравнение может быть решено методом последовательных (простых) итераций. Действительно, если смотреть на Q = {Q(s, a)}s∈S,a∈A, как на вектор, то Q-уравнение можно записать в операторном виде Q = H(Q) (метод простых итераций будет иметь вид Qt+1 = H(Qt)), где по определению можно показать, что оператор в правой части H является сжимающим с коэффициентом γ в бесконечной норме:

⃓

⃓

⃓

⃓

max ⃓H(Q˜(s, a)) − H(Q(s, a))⃓ ≤ γ max ⃓Q˜(s, a) − Q(s, a)⃓ .

s∈S,a∈A ⃓

⃓

s∈S,a∈A ⃓

⃓

Однако это не решает отмеченные проблемы с отсутствием какой-либо информации о функциях r(s, a; s′) и p(s, a; s′). Основная идея Q-обучения заключается в замене невычислимой правой части в уравнении Qt+1 = H(Qt) на ее вычислимую несмещенную оценку:

Qt+1(s, a) = Qt(s, a)+

(︃

)︃

+ αt(s, a) r(s, a; s′(s, a)) + γ max Qt(s′(s, a), a′) − Qt(s, a) , (87)
a′ ∈A

где s′(s, a) – положение процесса на шаге t + 1, если на шаге t процесс был в состоянии s и было выбрано действие a. Если на шаге t процесс находился в состоянии s и было выбрано действие a, то 0 < < αt(s, a) ≤ 1, иначе αt(s, a) = 0. При сделанных предположениях правая часть (87) может быть вычислена просто путем наблюдения того, куда перешел процесс s′(s, a). Действительно, набор {Qt(s, a)}s∈S,a∈A уже известен с прошлой итерации (следовательно, можно посчитать и maxa′∈A Qt(s′(s, a), a′)), а вознаграждение r(s, a; s′(s, a)) мы также можем всегда наблюдать по условию, если из состояния s при действии a перешли в состоянии s′(s, a). Определять r(s, a; s′(s, a)) в ненаблюдаемых состояниях и/или при неиспользуемых действиях нет необходимости ввиду условия αt(s, a) = 0 в этих случаях. Оказывается, что если используемая стратегия a(s) приводит к тому, что с вероятностью 1 каждая пара (s, a) будет бесконечное число раз встречаться

257

на бесконечном горизонте наблюдения, то из отмеченного выше условия сжимаемости при

∞

∞

∑︁

αt(s, a)

=

∞,

∑︁

α

2 t

(s,

a)

<

∞

t=0

t=0

будет следовать сходимость (с вероятностью 1) также и процесса (87) [84]: limt→∞ Q(s, a) = Q(s, a), V ∗(s) = maxa∈A Q(s, a). Таким образом, после достаточно большого числа шагов, даже в отсутствие какой-либо информации об управляемом марковском процессе, можно определить оптимальную стратегию a(s) = arg maxa∈A Q(s, a).
Однако приведенный результат ничего не говорит о скорости обучения и о том, когда можно заканчивать обучение, т.е. о том, в какой момент можно уже переходить на стратегию

at(s) = arg max Qt(s, a)
a∈A

со стратегии, которой придерживались сначала и которая обеспечивала максимально быструю сходимость процесса (87). Собственно, наиболее ярко это все можно продемонстрировать как раз на примере задачи о многоруких бандитах, в которой до какого-то момента идет обучение и исследуются все ручки, и только после того, как все ручки были проверены достаточное число раз, выбирается наилучшая из них (exploration vs exploitation). На самом деле асимптотически оптимальные стратегии выглядят немного по-другому, см. следующий пункт. В заключение упомянем, что полученные недавно оценки скорости сходимости процедур, построенных на базе (87) для широкого класса задач, во многом отвечают разобранному здесь примеру задачи о многоруких бандитах [85]. О каких именно оценках идет речь, мы постараемся пояснить далее.

Г.5. Асимптотически оптимальные оценки
Снова вернемся к задаче о многоруких бандитах. Будем считать γ = 1. Если число шагов N , то, зная оптимальную ручку (с наибольшей вероятностью успеха pmax), можно получить ожидаемое вознаграждение pmaxN . Оказывается, что, не имея никакой информации об n ручках, в общем случае невозможно получить ожидаемое вознаграждение больше, чем [77, 78]:
√ pmaxN − 0.05 N n.

258

Этот результат можно объяснить, опираясь на следующее наблюдение,

см. раздел Б.4. Пусть имеются всего две ручки. Одной соответствует

вероятность p = 1/2, второй p = 1/2 + ε. Но неизвестно, какой ручке,

какая вероятность соответствует. Тогда, для того чтобы определить

(скажем, с вероятностью 0.95), какой ручке соответствует большая ве-

роятность успеха, необходимо дернуть каждую ручку не менее ∼ 1/ε2

раз. Возвращаясь к исходной постановке, припишем n − 1 ручке оди-

наковую вероятность p = 1/2, а одной оставшейся ручке вероятность

p = 1/2 + ε, где ε = √︁n/N . Поскольку всего шагов N , то хотя бы одна

ручка выбиралась не более чем на N/n = 1/ε2 шагах. Таким образом,

нельзя гарантировать, что на сделанных N шагах можно достоверно

определить лучшую ручку. Использование не оптимальной ручки при-

водит на каждом ш√аге к средним потерям ε. Суммарные потери за N шагов будут εN = N n, что и требовалось объяснить.

Можно ли предложить такой алгоритм выбора ручек, который бы

позволял приблизиться к приведенной оценке? Оказывается это мож-

но сделать, не используя описанную в предыдущих пунктах техни-

ку,25 а рассматривая задачу как задачу стохастической онлайн опти-

мизации [21, 77]. Мы не будем приводить здесь наилучший известный

сейчас алгоритм (детали см. в [77, 108]). Тем не менее описываемый

далее алгоритм Exp3 гарантирует ожидаемое вознаграждение не мень-

ше, чем

√

pmaxN − 2 N n ln n,

что достаточно близко к нижней оценке, приведенной выше. Алгоритм Exp3 (Exponential weights for Exploration and Exploitation)
предписывает выбирать на шаге k ручку i с вероятностью

k

exp

(︁

η

N

R

k i

)︁

pi = ∑︁nj=1 exp (︁ηN Rjk)︁ ,

где

√︃

2 ln n

ηN =

. Nn

25Собственно говоря, не очень и понятно, что можно было бы использовать из описанного в предыдущих пунктах, кроме Q-обучения. Впрочем, для Q-обучения желательно (но не обязательно, см., например, [85]), чтобы γ < 1. В остальных подходах требуется делать априорные предположения о распределении pi. От чего в данном пункте мы отказались.

259

Если на шаге t была выбрана ручка номер i, то

Rt+1 = Rt +

1 ,

i

i pti

если был успех (с вероятностью pi):

Rit+1 = Rit,

если была неудача (с вероятностью 1 − pi) и

Rjt+1 = Rjt ,

для j ̸= i. Причем Ri1 = 0, i = 1, . . . , n. В некотором смысле аналогичные результаты недавно были полу-
чены и для достаточно большого и важного подкласса управляемых марковских процессов (MDP): episodic MDP [85]. А именно, было показано, что нижние оценки тут можно получать на базе задачи о многоруких бандитах, а верхние оценки, которые в данном случае все же получаются немного похуже нижних, обеспечивает Q-обучение, в варианте очень близком к приведенному выше (87), с естественной стратегией поведения at(s) = arg maxa∈A Qt(s, a).
Отметим также работы [86, 106], в которых показано, что если для MDP разрешается произвольно выбирать следующее состояние s′ (и действие), при которых можно наблюдать вознаграждение r или его реализацию (т.е. не обязательно следовать матрице переходных вероятностей p MDP при выборе нового состояния s′, в котором следует наблюдать r), то для равномерной аппроксимации функции Q (вектора Q в бесконечной норме) с точностью ε достаточно (с точностью до логарифмических множителей) ∼ |S||A|ε−2 переходов управляемого марковского процесса и вычислений вознаграждений при этих переходах. Данная оценка оптимальная. Примечательно, что работа [106] также базируется на процедуре типа Q-обучения.
В целом затронутые в данном разделе вопросы оказываются сильно завязаны на стохастическую оптимизацию, онлайн оптимизацию, взвешивание экспертных решений, предсказание последовательностей, теорию игр и, конечно, машинное обучение. Заинтересовавшемуся читателю можно порекомендовать следующую литературу [18, 21, 77, 78, 97, 100, 107, 108]. В частности, около трети студентов ФУПМ МФТИ продолжат изучение данной темы в рамках курса [16].

260

Заключение

Далее приводится краткое содержание пособия с выделением ос-

новных идей и объяснением связей с другими областями.

В курсе теории вероятностей [26, 42, 69] было показано, что ос-

новной объект изучения – случайные события и подсчет их вероятно-

стей сводится к изучению случайных величин X и случайных векторов [X1, ..., Xn]⊤ и свойств их функций распределения, которые пол-

ностью их определяют26: FX (x) = P(X < x) и FX1,...,Xn (x1, ..., xn) =

= P(X1 < x1, ..., Xn < xn). Были установлены естественные (необхо-

димые и достаточные) условия27 (теорема Колмогорова [34]), при ко-

торых FX1,...,Xn (x1, ..., xn) будет функцией распределения некоторого

случайного вектора. Также в курсе теории вероятностей было введе-

но важное понятие слабой сходимости случайных векторов, которое

можно

понимать

следующим

образом:

[︁X1N

,

...,

X

N n

]︁⊤

слабо

сходится

к [X1, ..., Xn]⊤ при N → ∞ если

FXN ,...,XN (x1, ..., xn) → FX1,...,Xn (x1, ..., xn)

1

n

в точках непрерывности (x1, ..., xn) последней функции. Если в определении случайного вектора считать n счетной беско-
нечностью, то получим случайный процесс в дискретном времени. Все основные свойства без изменения наследуются из курса теории вероятностей с небольшими техническими оговорками, которые мы изложим далее в более общем случае (для непрерывного времени). Сложнее обстоит дело для случайного процесса в непрерывном времени. В этом случае (как и в случае счетного времени) случайный процесс задается семейством своих всевозможных конечномерных распределений FX(t1),...,X(tn)(x1, ..., xn), где n пробегает всевозможные натуральные числа, а набор t1, ..., tn пробегает всевозможные значения с условием:
26Для доказательства предельных теорем удобным средством является аппарат характеристических функций (х.ф.). Грубо говоря, вместо изучения функций распределения предлагается изучать преобразования Фурье их производных (производная функции распределения есть плотность распределения). Связано это с тем, что х.ф. суммы независимых с.в. равна произведению соответствующих х.ф.
27Из наиболее нетривиальных отметим непрерывность слева по каждому аргументу и условие вида (n = 2): для любых a1 < a2, b1 < b2 выполняется
FX1,X2 (a2, b2) − FX1,X2 (a1, b2) − FX1,X2 (a2, b1) + FX1,X2 (a1, b1) ≥ 0.

261

0 ≤ t1 < ... < tn. Причем

FX(t1),...,X(tn)(x1, ...xn−1, ∞) = FX(t1),...,X(tn−1)(x1, ...xn−1).

Слабая сходимость случайных процессов понимается как слабая сходи-
мость всевозможных конечномерных распределений. Проблема однако возникает при подсчете вероятностей событий вида28 {supt∈[0,T ] X(t) < < x}. Событие, вероятность которого необходимо посчитать, в общем
случае не принадлежит σ-алгебре событий, порожденной семейством
конечномерных распределений. Причина связана с несчетностью мно-
жества [0, T ]. Однако X(t) имеет сепарабельную стохастическую модификацию X˜ (t) [10, 11]. Последнее означает, что для каждого t ≥ 0 выполняется P(X(t) = X˜ (t)) = 1 и существует такое счетное множество29 S в R+, что для любого Q (в том числе и для Q = [0, T ]) события supt∈Q X˜ (t) < x и supt∈S∩Q X˜ (t) < x совпадают с вероятностью 1, т.е. для стохастической модификации отмеченной проблемы
нет. Отмеченные выше тонкости необходимо знать для понимания объ-
екта изучения (случайного процесса), однако последующее изложение
практически не требует понимания написанного выше.
Намного более важным разделом курса случайных процессов яв-
ляется специальный класс (стохастически непрерывных) процессов,
у которых приращения независимы. Особенно важным представите-
лем этого класса процессов являются однородные процессы (процессы
Леви [72]). Однородность процесса X(t) означает, что распределение
X(t + s) − X(t) не зависит от t, а независимость приращений, что
для любого натурального n и 0 ≤ t1 < ... < tn случайные величины X(tn)−X(tn−1), ..., X(t1)−X(0) – независимы в совокупности. Из этих двух свойств30 следует, что для любого n справедливо представление

n−1 (︃ ∑︂

(︃ (k + 1)t )︃

(︃ kt )︃)︃

X(t) =

X

−X

,

k=0 n n

28Тут может возникнуть естественное желание не считать вероятности таких событий и ограничиться рассмотрением только дискретного времени. Однако ситуация здесь приблизительно такая же, как и с дифференциальными уравнениями – переход от изучения динамики в дискретном времени к непрерывному обогащает и упрощает в ряде случаев изучение интересующих процессов. Далее в курсе это можно пронаблюдать на примере случайного блуждания в дискретном времени и броуновского движения.
29Eсли процесс X(t) стохастически непрерывен limε→0 P(|X(t+ε)−X(t)| > δ) = 0 для любого δ > 0, то в качестве множества S можно брать любое счетное всюду плотное множество [10, 11] .
30Далее еще используется свойство X(0) = 0 почти наверное.

262

т.е. X(t) для любого n может быть представлена (имеет такое же рас-

пределение) как сумма независимых одинаково распределенных слу-

чайных величин. Последнее означает, что X(t) – безгранично-делимая

случайная величина31. Несложно понять, что нормальная случайная

величина и пуассоновская случайная величина являются безгранич-

но делимыми.32 Более того, они сами себя «безгранично делят». На-

пример, сумма n независимых одинаково распределенных по закону

N(m/n, σ2/n2) случайных величин имеет закон распределения N(m, σ2).

Аналогично и сумма n независимых случайных величин с распре-

делением Po(λ/n) имеет распределение Po(λ). Есть ли еще какие-то

безгранично-делимые случайные величины? Ответ: да – сложная пуас-

соновская

случайная

величина:

∑︁K
k=0

Vk ,

где

все

случайные

величины

K ∈ Po(λ), {Vk}Kk=0 независимы в совокупности, при этом все случай-

ные величины {Vk}Kk=0 одинаково распределены (не важно, как имен-

но). Отметим, что нормальным распределением и сложным пуассо-

новским распределением33 исчерпывается класс безгранично-делимых

с.в. Из вышенаписанного «в первом приближении» можно заключить,

что для процесса Леви X(t+s)−X(t) имеет либо нормальное распреде-

ление N(ms, σ2s) – в этом случае процесс Леви называют броуновским

движением (если m = 0, σ2 = 1 – винеровским процессом), либо слож-

ное распределение Пуассона (с K ∈ Po(λ) → K(s) ∈ Po(λs)).

31Другой способ определения безгранично-делимой случайной величины – это такая случайная величина, которая может возникать в качестве предела сумм независимых одинаково распределенных случайных величин [25]
32Собственно, именно этот факт и определяет привилегированность данных распределений, отражающуюся, например, в том, что часто именно эти два закона возникали в качестве предельных распределений сумм случайная величина в курсе теории вероятностей (теорема Муавра–Лапласа, ц.п.т., теорема Пуассона). Другой факт, свидетельствующий о привилегированности нормального распределения – теорема Максвелла–Клартага [28, 89] – о т√ом, что проекция вектора, равномерно распределенного на шаре (сфере) радиуса N , на фиксированную гиперплоскость малой размерности стремится при N → ∞ к нормальному вектору, причем все это переносится и на равномерные √распределения на изотропных выпуклых телах с диаметром, пропорциональным N [93].
33C точностью до небольших оговорок относительно возможности того, что случайные величины {Vk}K k=0 несобственные. Отметим также, что при наиболее естественных условиях в качестве предельных распределений возникает распределение Пуассона (теорема Пуассона), нормальное распределение (ц.п.т.) и вырожденный случай нормального распределения (σ = 0) – не случайная величина (з.б.ч.). В последнем случае из слабой сходимости (сходимости по распределению) вытекает сходимость по вероятности. Однако вполне можно себе представить «жизненные» ситуации, когда предельное распределение может быть и не из отмеченного набора, например, гравитационное поле, создаваемое равномерно распределенными во Вселенной звездами, на Земле описывается безгранично-делимым распределением Хольцмарка [31, 65].

263

Броуновское движение, так же, как и нормальный закон в ц.п.т., естественным образом возникает в задачах, в которых изучают предельное поведение других случайных процессов вида суммы. Рассмотрим один естественный пример (случайное блуждание на прямой). Пусть время течет дискретно (один шаг по време√ни 1/N ) и точка может двигаться впер√ед с вероятностью 1/2 на σ¯/ N и назад с вероятностью 1/2 на σ¯/ N . Если рассматривать предел34 (диффузионный скейлинг) при N → ∞, то описанное выше случайное блуждание слабо сходится к броуновскому движению с m = 0 и σ = σ¯ [10]. 35 Другой важный для курса статистики [6, 10] и статистической теории обучения [90] (теории эмпирических процессов) пример36 – это эмпирическая функция распределения и слабая сходимость функционалов (статистик) от этой функции к функционалам от винеровского процесса. Заметим, что, как правило, такие функционалы включают в себя супремум по несчетному множеству, поэтому отмеченные выше тонкости (о существовании сепарабельной стохастической модификации у стохастически непрерывного случайного процесса) все же необходимо принимать в расчет.
Хорошим примером возникновения пуассоновского процесса является модель случайного бросания (независимого и равновероятного) N точек на отрезок [0, N ] и изучение числа точек KN (t), попавших в отрезок [0, λt]. Если t считать параметром и при зафиксированных λ и t устремить N → ∞ (термодинамический предельный переход), то KN (t) сходится по распределению к Po(λt) (этот простой факт следует из теоремы Пуассона) и, более того, KN (t) слабо сходится к пуассоновскому процессу K(t) с параметром λ. Такое понимание пуассоновского процесса часто используется в статистической физике и различных геометрических задачах с вероятностью [31, 32, 35, 39]. Другой способ определения пуассоновского процесса K(t) – число звонков «пуассоновского будильника» к моменту времени t. Пуассоновский будильник определяется следующим образом. Вероятность того, что он зазвонит в промежутке времени [t, t + δt], не зависит от t и от того, сколько раз он уже звонил и равна λδt + o(δt). Другой способ определения пуассо-
34Отметим, что скейлинг с другими степенями N не приводит к интересным результатам – полученный в результате скейлинга случайный процесс либо будет не отделим от нуля с вероятностью 1, либо сразу же «взорвется» и уйдет на бесконечность с вероятностью 1.
35Заметим, что из ц.п.т. следует слабая сходимость в каждом сечении. 36В данный курс было решено не включать изложение данного примера, однако мы рекомендуем заинтересованным читателям посмотреть указанную литературу ввиду важности примера для последующего более глубокого понимания курса математической статистики.
264

новского будильника

(︄

k

)︄

∑︂

K(t) = max k ≥ 0 : ξi < t ,

i=1

где ξi ∈ Exp(λ) – независимые случайные величины, базируется на свойстве отсутвия последействия P(ξ > t + τ | ξ > t) = P(ξ > τ ) у показательной случайной величины: ξ ∈ Exp(λ) если P(ξ > t) = exp(−λt). Отмеченное свойство в классе случайных величин, имеющих плотность, имеет место только у показательных случайных величин.
Понимание пуассоновского процесса посредством пуассоновского будильника позволяет достаточно легко построить и теорию марковских процессов в непрерывном времени с конечным или счетным числом состояний как обобщение пуассоновского процесса. А именно, в момент звонка будильника частица (независимо от предыстории37) перемещается по (ориентированному) графу марковской цепи38 согласно вероятностям, написанным на выходящих из данной вершины (в другие вершины/состояния) ребрах. Отметим, что ввиду независимости приращений, винеровский процесс (броуновское движение) также будет марковским процессом, т.е. процессом, вероятностное описание будущего которого всецело определяется точно заданным настоящим (текущим) положением, но не тем, как в это положение процесс пришел. Марковское свойство является ключевым для возможности построения аналогии между динамическими системами (дифференциальными и разностными уравнениями) и стохастическими процессами. Так же, как и для динамических систем, для марковских процессов можно задать (инфинитезимальный) оператор перехода (с полугрупповым свойством), который определяет эволюцию процесса. Другими словами, для определения вероятностного закона распределения сечений процесса, достаточно решить некоторую систему дифференциальных уравнений Колмогорова–Феллера (для непрерывного времени и конечного/счетного числа состояний) или уравнение в частных производных Колмогорова–Фоккера–Планка (для непрерывного времени и несчетного числа состояний).39 Огромная популярность марковских
37В этом и в отсутствии последействия и заключается марковское свойство. 38Каждая вершина графа отвечает состоянию, а наличие ребра – возможности перехода; над каждым ребром написана вероятность, сумма вероятностей на ребрах, выходящих из каждой вершины, равна 1. 39Полезно заметить, что вывод таких уравнений базируется на формуле полной вероятности и различных предельных переходах. Причем пуассоновский будильник хорошо поясняет, как именно осуществлять такие переходы в части рассмотрения непрерывного времени на базе дискретного времени. В частности, именно

265

процессов в приложениях как раз и обусловлена тем, что это в некотором смысле наиболее хорошо математически изученный инструмент, с помощью которого можно аппроксимировать и изучать сложные процессы с непонятной структурой. Различные попытки существенно выйти за пределы этого класса случайных процессов хотя и привели к определенным успехам (стационарные процессы, гауссовские процессы, мартингалы и др.), о чем будет сказано далее, тем не менее основным (наиболее важным) классом процессов, безусловно, являются именно марковские процессы, ввиду богатой теории и возможности их глубокого изучения, а также ввиду вполне естественных предположений (будущее определяется настоящим и только настоящим), которые в хорошем приближении выполняются во многих интересных на практике задачах.
Наиболее важным классом задач, возникающим при изучении случайных процессов, в том числе марковских, является описание поведения процесса при больших значениях времени. Общая идея поиска асимптотики следующая: если, на√пример, изучаем предел числовой последовательности [63] xk+1 = xk + 2 и считаем, что предел существует, то, чтобы найти такой предел a = limk→∞ xk, нужно найти непо√движную (стационарную, инвариантную) точку данной динамики a = a + 2, то есть a = 2. Аналогичным образом необходимо действовать и в случае марковских процессов.
Как уже отмечалось, для марковских процессов так же, как и для однородных (время не входит в уравнения) динамических систем, можно говорить об эволюции меры. Только для марковских процессов эту меру можно не вводить, она естественным образом присутствует в самой задаче. Раскроем написанное выше подробнее. Пусть в начальный момент динамическая система с разной вероятностью могла находиться в разных состояний, тогда под эволюцией меры, описывающей заданную систему, понимается просто описание того, с какой вероятностью в каждый момент времени система будет находиться в том или ином состоянии. В пространстве мер однородная динамическая система порождает унитарный (ортогональный) оператор (грубо говоря, поворот пространства). Стационарная (инвариантная) мера, которую данный оператор оставляет неподвижной, в случае единственности (нет других стационарных мер – это условие называется условием эргодичности системы) и определяет предельное распределение динамической системы (не зависящее от начального!). Скажем, если ди-
таким образом наиболее просто объяснить вывод системы уравнений Колмогорова– Феллера из формулы полной вероятности (уравнения Колмогорова–Чэпмена), описывающей эволюцию конечной однородной дискретной марковской цепи.
266

намическая система – это поворот окружности единичного периметра на иррациональный угол, то единственной инвариантной (стационарной) мерой такой эволюции будет равномерная мера (так же говорят «лебегова мера») на данной окружности. Таким образом, с какими бы вероятностями система не была «разбросана» в начальный момент по этой окружности, со временем вероятность найти систему на некотором измеримом подмножестве этой окружности будет равна лебеговой мере этого подмножества. Можно сказать дополнительно, что доля времени, которую система (откуда бы она не стартовала) провела на выделенном множестве на бесконечном промежутке наблюдения за ней, также равна площади этого множества (среднее по времени равно среднему по пространству, если среднее по пространству понимать согласно инвариантной мере).40 Все эти результаты естественным образом переносятся на марковские случайные процессы (а также класс стационарных процессов; и даже, с некоторыми оговорками, на очень общий класс – процессы второго порядка с постоянным средним), для которых мы изначально имеем только одно пространство – вероятностное и сразу изучаем эволюцию мер, заданную линейным оператором марковской полугруппы (унитарность оператора проявляется в том, что при эволюции меры свойство нормировки на единицу и неотрицательности не изменяется).
Ключевым вопросом в описанной выше схеме является выявление необходимых и достаточных условий, которые гарантируют единственность стационарной (инвариантной) меры41, а также вопрос о том, что будет, если такая мера не единственная?
Для марковских процессов с конечным или счетным числом состояний в пособии приводится подробный ответ на поставленный вопрос. А именно, если изоморфным образом понимать марковский процесс как случайное блуждание на графе согласно вероятностям, написан-
40Отметим, что описанный пример демонстрирует порождение последовательности со случайными свойствами чисто детерминированными методами. Такого типа последовательности активно используются в методах Монте-Карло [57]. Например, при вычислении многомерных интегралов. Пример вычисления одномерного интеграла с помощью такой последовательности разобран в пособии.
41Существование инвариантной (стационарной) меры для динамических систем, действующих на компакте, следует из теоремы Боголюбова–Крылова [55], а для марковских процессов с конечным числом состояний – из принципа неподвижной точки Брауэра: непрерывное отображение (в нашем случае линейное) выпуклого компакта (в нашем случае симплекса) в себя имеет неподвижную точку. Пример случайного блуждания на прямой показывает, что уже в случае счетного числа состояний стационарной меры может не существовать. Точнее говоря, существует только тривиальная (нулевая) стационарная мера, что не интересно, ввиду необходимости нормировать стационарную (инвариантную) меру на 1.
267

ным на ребрах, то стационарное распределение единственное, если существует такое состояние (вершина), в которую можно попасть, двигаясь по этому графу из любой другой вершины [10]. Если это условие не выполняется, то стационарное распределение не единственно, и предельное (финальное) распределение уже зависит от стартового (начального)42. В этом случае также можно определять асимптотику. Важным примером, демонстрирующим, как это следует делать, является задача об игре в орлянку, разобранная в пособии. В этой игре двое игроков кидают монетку и делают ставки по одному рублю. Игра идет до разорения одного из игроков. Понятно, что в данной игре существует две стационарные меры. Одна сосредоточена в состоянии, когда все деньги у первого игрока, вторая сосредоточена в состоянии, когда все деньги у другого игрока. Поиск вероятностей, с которыми система «свалится» из заданного начального положения (состояния) в одно из этих предельных состояний, сводится к выписыванию рекуррентных соотношений, связывающих (с помощью формулы полной вероятности) вероятности разорения в текущем стартовом состоянии с вероятностями разорения для соседних (на графе) стартовых состояний.
Вопрос о сходимости к стационарному распределению в случае непрерывного времени и компактного пространства состояний не стоит (достаточно единственности стационарного распределения). В случае дискретного времени необходимы оговорки о непериодичности марковской цепи, однако эти технические моменты вполне можно опустить в сухом остатке от курса, поскольку в чезаровском смысле (наиболее важном с точки зрения основных приложений) сходимость будет в любом случае (и для периодических дискретных марковских цепей)43.
42Тут следует сделать оговорку. Для марковских цепей с не конечным числом состояний, например, со счетным числом состояний, в ряде случаев существует возможность с ненулевой вероятностью «уйти на бесконечность». Например, в игре в орлянку, когда игрок играет с казино, имеющим неограниченный бюджет, и выигрывает у казино с большей вероятностью, чем проигрывает, существует единственное стационарное распределение, сосредоточенное в состоянии, когда игрок разорится. Тем не менее в финальном состоянии вероятность игрока оказаться в этом состоянии будет зависеть от его стартового капитала и будет меньше 1. С оставшей вероятностью игра будет продолжаться бесконечно. Таким образом, для счетных цепей даже в случае единственности стационарного распределения, но наличия бесконечного числа несущественных состояний, финальное распределение может зависеть от начального.
43В дискретном времени марковская динамика задается следующим уравнением Колмогорова–Чэпмена эволюции меры (вектора распределения вероятностей по состояниям p): pk+1 = P ⊤pk, где P – матрица переходных вероятностей (Pij – вероятность перейти из состояния i в состояние j). Принцип сжимающих отображений в классическом варианте здесь не сработает, поскольку λmax(P ⊤) = 1, и,
268

Стоит отметить, что изложенная выше схема, связывающая эргодичность случайных процессов и эргодичность динамических систем [29], не является оригинальной и уже неоднократно использовалась в различных местах при разработке курса теории вероятностей и случайных процессов [9, 35, 39, 70]. Однако в данном пособии было решено пойти дальше. А именно, на примере изучения эволюции ансамбля конечных однородной дискретных марковских цепей продемонстрировать концепцию равновесия макросистемы. Более точно, вместо того, чтобы изучать вероятность нахождения блуждающей частицы на графе в разные моменты времени, находящейся в начальный момент с разными вероятностями в разных состояниях, предлагается поместить в эти состояния в начальный момент частицы в пропорции, определяемой начальными вероятностями, а далее следить за эволюцией всех частиц одновременно. Для эргодической марковской цепи каждая частица (независимо от стартового состояния) распределится на графе согласно стационарному распределению. Если частиц достаточно много, то со временем по распределению частиц на графе можно будет восстанавливать стационарное распределение. Таким образом, в пособии интерпретируется вектор PageRank (см. также [75]) как вектор, который. с одной стороны, является стационарным распределением марковской цепи с графом переходных вероятностей, отвечающих интернету (вершины это web-страницы, а ребра – гиперссылки), а с другой стороны, как вектор, отражающий популярность web-страниц (компо-

таким образом, P ⊤ не может быть сжимающим отображением. С другой стороны,

у P ⊤ есть сжимаемость к собственному вектору π, отвечающего максимально-

му собственному значению (стационарному распределению, вектору Фробениуса–

Перрона в экономической литературе [45]). То есть можно надеяться, что, напри-

мер,

⃦⃦(︁P ⊤)︁n

(p

−

⃦ π)⃦

≤ α(P )n, где α(P ) < 1. Как искать это α(P ) и при каких

1

условиях можно обеспечить условие α(P ) < 1? Ответ на этот вопрос можно попро-

бовать получить, рассмотрев модельный случай, когда у марковской цепи всего

два состояния [39]. Оказывается, что достаточным (и необходимым в случае отсут-

ствия несущественных состояний) условием, которое назовем условием (Э), для

α(P ) < 1 является существование такой натуральной степени r, что у матрицы P r

все элементы положительны. Это условие равносильно тому, что граф марковской

цепи неразложим (из любого состояния можно добраться в любое другое по этому

графу) и цепь непериодическая. Замечательно, что все эти результаты переносятся

и на более общие линейные динамики с матрицами, элементы которых неотрица-

тельны. Такие динамики возникают в динамических моделях межотраслевого ба-

ланса [45]. Заметим также, что можно ввести специальную метрику (Биркгофа) на

пространстве лучей неотрицательного ортанта так, что в этой метрике линейный

оператор P ⊤ будет сжимающим при том же самом условии (Э) [38]. Отметим, что

оценка α(P ) является важной задачей (о некоторых подходах к ее решению см.,

например, [30]). Чем меньше значение α(P ), тем быстрее цепь выходит на стацио-

нарное распределение, что может быть важно, например, в методах Монте-Карло,

базирующихся на марковских цепях, см. далее.

269

ненты вектора пропорциональны числу посетителей web-страницы в единицу времени при установившемся режиме). Важно также отметить, что описанный способ восстановления стационарного распределения марковской цепи (Markov Chain Monte Carlo [80]) является хорошим практическим/численным способом (ввиду возможности параллелизации блужданий частиц) поиска (генерирования) стационарного распределения.
Однако в пособии для закрепления материала и дополнительной демонстрации концепции равновесия макросистемы44 разбирается парадокс Эренфестов в варианте [30]. Пример замечателен во многих аспектах, в частности, своей связью с простейшими системами массового обслуживания (процессы гибели и размножения), в связи с обыгрыванием теоремы Пуанкаре о возвращении, понятием обратимой динамики, демонстрацией того, что математическое ожидание времени первого возвращения марковской цепи в заданное состояние есть величина, обратная к соответствующей (данному состоянию) компоненте стационарной меры. Наконец, пример наглядно демонстрирует другую важную связь случайных процессов (процессов стохастической химической кинетики [17, 40, 82])45 и систем (не обязательно линейных!) дифференциальных уравнений. А именно, в результате специального (канонического) скейлинга из первого объекта можно получать второй. Аттрактор полученной системы дифференциальных уравнений будет соответствовать равновесию макросистемы, заданной шкалируемым процессом (детали см., например, в [8]). Другой достаточно поучительный пример скейлинга (так же, как и ранее на базе теоремы Куртца [82]) стохастической динамики в детерминированную содержится в пособии при описании роста интернета [94, 96].
Продолжая тему марковских процессов, отметим, что в пособие было решено включить, пожалуй, наиболее яркий (из известных нам) пример на управляемые марковские процессы – «задачу о разборчивой невесте» [27], как демонстрацию основного принципа стохастического динамического программирования – принципа Вальда–Беллмана. Здесь мы также не были оригинальными, см. [50, 70]. Ранее такого типа примеры включали в связи с большой популярностью этого принципа в исследовании операций, в том числе в военном деле [12]. Однако в нашем случае мотивация была несколько другой – а имен-
44Равновесие макросистемы – это такое ее макросостояние, около которого концентрируется стационарная мера при стремлении числа агентов к бесконечности. В случае задачи поиска вектора Page Rank агентами были блуждающие по webграфу пользователи.
45Эволюция распределений которых всегда задана линейными уравнениями!
270

но, в связи с огромной популярностью обучения с подкреплением [103] (Reinforcement Learning), также базирующегося на упомянутом ранее принципе Вальда–Беллмана.
Завершая тему марковских процессов, снова вернемся к винеровскому процессу W (t) и, следуя П. Самуэльсону, рассмотрим геометрическое броуновское движение S(t) = exp (︂(a − σ22 )t + σW (t))︂. Таким процессом на заре эры финансовой математики описывали поведение цены акции, причины см., например, [8, 68, 98]. Можно показать, что следующее стохастическое дифференциальное уравнение46:

dS(t) = aS(t)dt + σS(t)dW (t)

определяет выписанное ранее S(t). Более корректно это уравнение записывается в интегральном виде:

ˆt

ˆt

S(t) = a S(τ )dτ + σ S(τ )dW (τ ).

0

0

Последний объект уже вполне можно определить стандартным образом. Собственно, марковские процессы (обычно их называют диффузионные процессы или процессы Ито), полученные в результате решения стохастических дифференциальных уравнений, представляют естественное обобщение винеровского процесса, и возникают в различных приложениях, из которых наиболее часто встречается физика (уравнение Ланжевена) и финансовая математика [9, 46]. Использование в качестве шума именно винеровского процесса представляется настолько же естественным, насколько естественным представляется использование нормального распределения для описания шума в теории вероятностей. Напомним, что нормальное распределение часто наблюдается на практике благодаря ц.п.т. и ее робастности (центральная предельная теорема часто выполняется при намного более общих условиях, чем условия, при которых она изучалась в курсах теории вероятности). Другими словами, наличие большого количества независимых (или даже слабо зависимых) малых шумов одного масштаба (не обязательно одинаково распределенных) в сумме в хорошем приближении приводит к нормальному шуму. Таким образом, с помощью стохастических дифференциальных уравнений вносится (винеровский) шум в обычные детерминированные динамические системы.
46Структура которого хорошо проясняет, почему S(t) может описывать поведение цены акции в случае сложной процентной ставки.

271

В качестве одного из интересных следствий данного раздела отметим, что с помощью диффузионных процессов (в частности, случайных блужданий) можно численно решать краевые задачи для полуэллиптических уравнений в частных производных, в частности задачу Дирихле для уравнения Лапласа [10, 46]. Один простой пример для случайного блуждания будет рассмотрен в пособии, следуя [58]. Общая идея – выпускать из данной точки рассматриваемой области независимые траектории случайного блуждания и ждать момента их первого попадания на границу той области, где решается краевая задача. Усредняя значение граничного условия в точках выхода различных траекторий по этим траекториям, можно восстанавливать решение соответствующей задачи Дирихле для уравнения Лапласа. Идея обоснования этого наблюдения близка к тому, как исследуется задача об игре в орлянку. Отметим также глубокие связи данного результата с ТФКП [46, 67].
Выше мы уже отмечали другие классы процессов (мартингалы, гауссовские процессы), для которых удаётся построить достаточно интересную теорию, приносящую много полезного на практике.
К сожалению, объем курса и соответствующего ему пособия не позволяет никак коснуться такого важного класса процессов, как мартингалы и мартингал-разности. Изложение таких процессов вошло в ряд современных учебников [10, 35, 70]. В основном данные процессы описываются в связи с приложениями к финансовой математике (основная теорема финансовой математики об отсутствии арбитража и мартингальная мера [8, 68, 70]) и страхованию (теорема Лундберга– Крамера), однако хотелось бы отметить, что во многих современных приложениях в Машинном обучении [100], Стохастической оптимизации [18, 81, 101], Онлайн оптимизации [78, 87], Многоруких бандитах [77, 108] мартингалы (а точнее мартингал-разности) возникают в связи с изучением скорости сходимости итерационных процедур вида стохастического градиентного спуска
xk+1 = xk − h∇xf (xk, ξk),
где Eξk ∇xf (xk, ξk) = ∇f (xk).47 Про гауссовские процессы [47] было решено добавить в пособие
47Используется неравенство концентрации меры [76] Азумы–Хеффдинга для оценки сумм мартингал-разностей [91]:
N
∑︂⟨∇xf (xk, ξk) − ∇f (xk), xk − x∗⟩.
k=0
272

только самые необходимые сведения. Прежде всего, полезно заметить, что гауссовским процессом, т.е. процессом, любое конечномерное семейство распределений которого – нормальный случайный вектор, является броуновское движение. Важной особенностью гауссовских процессов (унаследованной от гауссовских/нормальных векторов) является то, что вероятностные свойства такого процесса X(t) полностью определяются его математическим ожиданием m(t) = EX(t) и корреляционной функцией48 R(t1, t2) = E ((X(t1) − m(t1))(X(t2 − m(t2))). В частности, независимость сечений гауссовского процесса эквивалентна некоррелированности, стационарность в широком и узком смыслах совпадают. Но, пожалуй, главным свойством, являющимся следствием эквивалентности независимости и некоррелированности сечений, является то, что условное математическое ожидание одних сечений гауссовского процесса при фиксированных других всегда есть линейная вектор-функция от этих фиксированных сечений. Данный факт заслуживает особого внимания, поскольку играет очень важную роль при прогнозировании и восстановлении значений гауссовских процессов. Для его понимания полезно в целом напомнить, что такое условное математическое ожидание. Далее ограничимся для простоты пространством случайных величин с конечным математическим ожиданием их квадрата [51]. Введем в этом пространстве скалярное произведение по формуле ⟨X, Y ⟩ = E(XY ). Несложно проверить, что все свойства скалярного произведения выполняются, если под элементом этого пространства понимать не просто случайную величину, а целый класс эквивалентных ей случайных величин (с точностью до почти наверное). В таком (гильбертовом) пространстве условное математическое ожидание можно определять как решение задачи
E (Y | X) = arg min E|Y − ϕ(X)|2,
ϕ(·)∈B(R)
является просто проекцией элемента (случайной величины) Y на подпространство всевозможных борелевских функций, зависящих только от X. В частности, из такого понимания условного математического ожидания сразу же следует формула полного математического ожидания:49
E (E(Y | X)) = ⟨1, E(Y |X)⟩ = ⟨1, Y ⟩ = EY.
48Корреляционная функция любого процесса Леви (в том числе и броуновского движения) может быть представлена в виде R(t1, t2) = D (min(t1, t2)), где D(t) = = E (︁X(t)2)︁ − (EX(t))2 – дисперсия X(t).
49Эта формула используется в курсе, например, при выводе характеристической функции сложного пуассоновского процесса.
273

Формула справедлива, поскольку тождественная единица 1 принадлежит подпространству всевозможных борелевских функций, зависящих только от X, следствием чего является ⟨Y − E(Y |X), 1⟩ = 0. Так вот в случае, когда Y и X – это сечения гауссовского процесса, то вместо класса всевозможных борелевских функций достаточно использовать класс линейных функций50 E(Y | X) = aX + b (решение всегда удается подобрать в этом, более узком, классе). Аналогично и в векторном случае.
Введенная выше корреляционная функция гауссовского процесса и математическое ожидание, очевидным образом, могут быть введены и для любого другого процесса второго порядка, т.е. процесса, у которого существует математическое ожидание от квадратов сечений. Свойства этих функций (непрерывность, дифференцируемость, интегрируемость) определяют аналогичные свойства (в смысле среднего квадратичного) соответствующего случайного процесса. Заметная часть пособия (по сложившейся при изложении данного курса на ФУПМ МФТИ традиции) посвящена изучению данных свойств. Хотя важность для практики этой части курса в настоящий момент, пожалуй, наименьшая (по сравнению с другими частями курса), все же было решено оставить эту часть (особо не сокращая) ввиду хорошей возможности продемонстрировать с её помощью элементы «классического» стохастического анализа случайных процессов, а также связи с курсом функционального анализа [64]. В частности, доказательства почти всех фактов данного раздела базируются на одном простом наблюдении из функционального анализа: скалярное произведение как функция своих аргументов непрерывна относительно нормы (топологии), порожденной этим же самым скалярным произведением.
Важным свойством корреляционной функции R(t1, t2) является ее неотрицательная определенность. Последнее означает, что для любого набора 0 ≤ t1 < . . . < tn матрица ∥R(ti, tj)∥ni,j=1 – неотрицатель-
50Коэффициенты a и b подбираются из условия ортогональности и несмещенности
⟨Y − (aX + b), X⟩ = 0, EY = aEX + b.
Отсюда (поскольку процесс гауссовский) будет следовать независимость Y − (aX+ +b) и X, следовательно, и независимость любых функций от этих с.в., в частности, независимость с.в. Y − (aX + b) и ϕ(X), где ϕ(x) – любая борелевская функция. Из последнего следует ортогональность: Y − (aX + b) и ϕ(X), где ϕ(x) – любая борелевская функция. Но это и означает, по определению, что aX + b – проекция Y на подпространство, порожденное борелевскими функциями от X, т.е. условное математическое ожидание: E(Y | X) = aX + b.
274

но определена51. Это следует из того, что52 R(t1, t2) = ⟨X(t1), X(t2)⟩. Верно и обратное утверждение: любая неотрицательно определенная функция есть корреляционная функция некоторого случайного процесса второго порядка53. В действительности, это общий факт54 [10, 64], что для любого неотрицательно определенного ядра (функции двух аргументов) существует такое преобразование пространства аргументов этого ядра в некоторое гильбертово пространство55, что в этом новом пространстве значение ядра при любых двух заданных аргументах представляется скалярным произведением их образов. В простейшем случае, когда в некотором конечномерном векторном пространстве выбран новый базис, то матрица Грама (матрица скалярных произведений новых базисных векторов) будет положительно определенной и представлять собой простейший пример возможного ядра с конечным набором значений аргументов (каждый аргумент может принимать число значений, равное размерности пространства). В данном случае по построению понятно, что матрица Грама имеет необходимое представление. В обратную сторону – если задана положительно определенная матрица (ядро), то существует такой базис, что эта матрица будет матрицей Грама данного базиса (легко и конструктивно выводится из SVD разложения). Для бесконечномерных пространств последнее утверждение называется теоремой Мерсера.
Несколько примеров в данное пособие были вставлены из замеча-

51Если случайный процесс (слабо) стационарен, его корреляционная функция будет иметь вид R(ti, tj ) = R˜(ti − tj ). Определение неотрицательной определенности

естественным образом переносится и на такую корреляционную функцию (одного аргумента) R˜(τ ). Оказывается (далее намеренно немного огрубляем формулировку

теоремы Бохнера–Хинчина [10, 11, 35], чтобы результат был понятнее), для того, чтобы R˜(τ ) была неотрицательной определенной, необходимо и достаточно, чтобы

она была преобразованием Фурье неотрицательной функции, которую называют

спектральной плотностью. Эта функция (спектральная плотность) играет важную

роль в анализе стационарных случайных процессов. 52Для простоты считаем процесс X(t) центрированным. 53Можно даже сузить класс процессов до гауссовских. 54Теорема о воспроизводящем ядре гильбертова пространства

(Reproducing

Kernel Hilbert Space Theorem). 55Это пространство (спрямляющее) играет важную роль в задачах обучения ма-

шины опорных векторов [100] (Support Vector Machine (SVM)). Простейший ли-

нейный классификатор (в виде разделяющий гиперплоскости) можно использо-

вать для более сложной классификации. Для этого нужно исходную постановку

задачи перевести в должным образом выбранное спрямляющее пространство (как

правило, существенно большой размерности) и заметить, что для построения раз-

деляющей гиперплоскости в этом пространстве достаточно уметь считать значе-

ния ядра на элементах исходного пространства (что предполагается постановкой

задачи). Подчеркнем, что сложность такой задачи (квадратичной оптимизации)

определяется объемом выборки, но не размерностью спрямляющего пространства.

275

тельной книги [54] (например, парадокс времени ожидания автобуса), которая уже на протяжении нескольких десятилетий является, пожалуй, основным источником парадоксальных задач к курсам стохастических дисциплин. Также много тонких контпримеров по теории вероятностей и теории случайных процессов можно найти в книге [59].
Цель данного заключения – правильным образом структурировать пройденный материал, выделяя главные идеи и ранжируя результаты по важности. Авторы надеются, что это может помочь в освоении курса, дополнительно мотивировав изучение ряда разделов.
276

Литература
1. Афанасьева Л.Г., Булинская Е.В. случайные процессы в теории массового обслуживания и управления запасами. Москва : Изд-во МГУ, 1960. 110 с.
2. Баймурзина Д.Р., Гасников А.В., Гасникова Е.В. Теория макросистем с точки зрения стохастической химической кинетики // Труды МФТИ. 2015. Т. 7, № 4. С. 95–103.
3. Бенджио И., Гудфеллоу Я., Курвилль А. Глубокое обучение. Москва : ДМК-Пресс. 2018.
4. Биллингсли П. Сходимость вероятностных мер. Москва : Наука, 1977. 352 с.
5. Биллингсли П. Эргодическая теория и информация. Москва : Мир, 1969. 238 с.
6. Боровков А.А. Математическая статистика: учебник. Москва : Лань, 2010. 704 с.
7. Боровков А.А. Теория вероятностей. Москва : Эдиториал УРСС, 1999. 472 с.
8. Бузун Н.О., Гасников А.В., Гончаров Ф.О., Горбачев О.Г., Гуз С.А., Крымова Е.А., Натан А.А., Черноусова Е.О. Стохастический анализ в задачах. Ч. 1 / под ред. А.В. Гасникова. Москва : МФТИ, 2016. 212 с. URL: https://arxiv.org/pdf/1508.03461.pdf
9. Булинский А.В. Случайные процессы. Примеры, задачи и упражнения: учебное пособие. Москва : МФТИ, 2010. 216 с.
10. Булинский А.В., Ширяев А.Н. Теория случайных процессов. Москва : Физматлит, 2005. 408 с.
11. Вентцель А.Д. Курс теории случайных процессов. Москва : Наука, 1996. 400 с.
12. Вентцель Е.С. Исследование операций. Москва : Советское радио, 1972. 552 с.
13. Вентцель Е.С. Исследование операций: задачи, принципы, методология. 2-е изд. Москва : Наука, 1988. 208 с.
14. Верещагин Н.К., Щепин Е.В. Информация, кодирование и предсказание. Москва : МЦНМО, 2012. 236 с.
15. Волков И.К., Зуев С.М., Цветкова Г.М. Случайные процессы: учеб. для вузов / под ред. B.C. Зарубина, А.П. Крищенко. Москва : Изд-во МГТУ им. Н.Э. Баумана, 1999. 448 с.
16. Вьюгин В.В. Математические основы теории машинного обучения и прогнозирования. Москва : МЦНМО, 2013. 390 с. URL: http://www.iitp. ru/upload/publications/6256/vyugin1.pdf
277

17. Гардинер К.В. Стохастические модели в естественных науках. Москва : Мир, 1986. 591 c.
18. Гасников А.В. Современные численные методы оптимизации. Метод универсального градиентного спуска. 2-е изд. М: МФТИ, 2019. 270 с. URL: https://arxiv.org/pdf/1711.00394.pdf
19. Гасников А.В., Гасникова Е.В., Двуреченский П.Е., Мохаммед А.А.М., Черноусова Е.О. Вокруг степенного закона распределения компонент вектора PageRank. Ч. 1. Численные методы поиска вектора PageRank // Сибирский журнал вычислительной математики. 2017. Т. 20, № 4. С. 359–378.
20. Гасников А.В., Двуреченский П.Е., Жуковский М.Е., Ким С.В., Плаунов С.С., Смирнов Д.А., Носков Ф.А. Вокруг степенного закона распределения компонент вектора PageRank. Ч. 2. Модель Бакли–Остгуса, проверка закона для этой модели и устройство реальных поисковых систем // Сибирский журнал вычислительной математики. 2018. Т. 21, № 1. С. 23–45.
21. Гасников А.В., Нестеров Ю.Е., Спокойный В.Г. Об эффективности одного метода рандомизации зеркального спуска в задачах онлайн оптимизации // Журнал вычислительной математики и математической физики. 2015. Т. 55, № 4. С. 582–598.
22. Гихман И.И., Скороход А.В. Введение в теорию случайных процессов. Москва : Наука, 1977. 568 с.
23. Гихман И.И., Скороход А.В. Теория случайных процессов. В 3-х томах. Москва : Наука, 1971.
24. Гнеденко Б.В., Коваленко И.Н. Введение в теории массового обслуживания, Москва : УРСС, 2005. 397 с.
25. Гнеденко Б.В., Колмогоров А.Н. Предельные распределения для сумм независимых случайных величин. Москва–Ленинград : Государственное издательство технико-теоретической литературы, 1949. 264 с.
26. Гнеденко Б.В. Курс теории вероятностей. Москва : Наука, 1988. 451 с.
27. Гусейн-Заде С.М. Разборчивая невеста. Серия: Библиотека «Математическое просвещение». Вып. 25. Москва : МЦНМО, 2003. 24 с.
28. Зорич В.А. Математический анализ задач естествознания. Москва : МЦНМО, 2017. 160 с.
29. Каток А.Б., Хассельблат Б. Введение в современную теорию динамических систем. Москва : Факториал, 1999. 767 с.
30. Кельберт М.Я., Сухов Ю.М. Вероятность и статистика в примерах и задачах. Т. 2. Марковские цепи как отправная точка теории случайных процессов. Москва : МЦНМО, 2010. 550 c.
31. Кендалл М., Моран П. Геометрические вероятности. Москва : Наука, 1972. 192 с.
278

32. Кингман Дж. Пуассоновские процессы. Москва : МЦНМО, 2007. 136 c.
33. Кингсеп А.С., Локшин Г.Р., Ольхов О.А. Основы физики. Курс общей физики: учебник. В 2-х томах. Т. 1. Механика, электричество и магнетизм, колебания и волны, волновая оптика / под ред. А.С. Кингсепа. Москва : Физматлит, 2001. 225 с.
34. Колмогоров А.Н. Основные понятия теории вероятностей. Москва : Наука, 1974.
35. Коралов Л.Б., Синай Я.Г. Теория вероятностей и случайные процессы / пер. с англ. Москва : МЦНМО, 2014. 408 с.
36. Крамер Г., Лидбеттер М. Стационарные случайные процессы. Москва : Мир, 1969.
37. Красносельский М.А., Крейн С.Г. Итерационный процесс с минимальными невязками // Матем. сб. 1952. 31(73):2. 315–334.
38. Красносельский М.А., Лифшиц Е.А., Соболев А.В. Позитивные линейные системы. Метод положительных операторов. Москва : Наука, 1985.
39. Малышев В.А. Кратчайшее введение в современные вероятностные модели. Москва : Изд-во мехмата МГУ, 2009.
40. Малышев В.А., Пирогов С.А. Обратимость и необратимость в стохастической химической кинетике // УМН. 2008. Т. 63:1(379). С. 3–36.
41. Миллер Б.М., Панков А.Р. Теория случайных процессов в примерах и задачах. Москва : Физматлит, 2002. 320 с.
42. Натан А.А., Горбачев О.Г., Гуз С.А. Теория вероятностей: учеб. пособие. Москва : МЗ Пресс; МФТИ, 2007.
43. Натан А.А., Горбачев О.Г., Гуз С.А. Основы теории случайных процессов: учеб. пособие. Москва : МЗ Пресс; МФТИ, 2003.
44. Натан А.А., Горбачев О.Г., Гуз С.А. Математическая статистика: учеб. пособие. Москва : МЗ Пресс; МФТИ, 2005.
45. Никайдо Х. Выпуклые структуры и математическая экономика. Москва : Мир, 1972. 520 с.
46. Оксендаль Б. Стохастические дифференциальные уравнения. Москва : Мир, 2003. 408 с.
47. Питербарг В.И. Двадцать лекций о гауссовских случайных процессах. Москва : МЦНМО, 2015. 192 с.
48. Поляк Б.Т., Тремба А. А. Решение задачи PageRank для больших матриц с помощью регуляризации // Автомат. и телемех. 2012. № 11. 144–166; Autom. Remote Control. 2012. 73:11. 1877–1894.
49. Райгородский А.М. Модели интернета. Долгопрудный : Издательский дом «Интеллект». 2013.
279

50. Розанов Ю.А. Лекции по теории вероятностей. Долгопрудный : Издательский дом «Интеллект», 2008. 136 с.
51. Розанов Ю.А. Теория вероятностей, случайные процессы и математическая статистика. Москва : Наука, 1985. 320 с.
52. Романовский В.И. Дискретные цепи Маркова. Москва : ГОСТЕХИЗДАТ, 1949. 436 с.
53. Санов И.Н. О вероятности больших отклонений случайных величин // Математический сборник. 1957. Т. 42(84):1. С. 11–44.
54. Секей Г. Парадоксы в теории вероятностей и математической статистике. Москва : РХД, 2003. 272 с.
55. Синай Я.Г. Введение в эргодическую теорию. Москва : Фазис, 1996. 128 с.
56. Скопенков М., Смыкалов В., Устинов А. Случайные блуждания и электрические цепи // Матем. просв., сер. 3. 2012. Т. 16. С. 25—47.
57. Соболь И.М. Численные методы Монте-Карло. Москва : Физматлит, 1973. 312 с.
58. Сосинский А.Б. Мыльные пленки и случайные блуждания. Серия: Библиотека «Математическое просвещение». Вып. 6. Москва : МЦНМО, 2000. 24 с.
59. Стоянов Й. Контрпримеры в теории вероятностей. М.: МЦНМО, 2012. 296 с.
60. Фалин Г.И., Фалин А.И. Актуарная математика в задачах. Москва : Физматлит, 2003. 192 c.
61. Фалин А.Г., Фалин Г.И. Введение в актуарную математику. Математические модели в страховании: учебн. пособие. Москва : Изд-во Московского университета, 1994. 110 с.
62. Феллер В. Введение в теорию вероятностей и ее приложения. Т. 1, 2. Москва : Мир, 1984. 528 с.
63. Фихтенгольц Г.М. Основы математического анализа. В 2-х томах. Москва : Наука, 1968.
64. Халмош П. Гильбертово пространство в задачах. Москва : Мир, 1970. 351 с.
65. Чеботарев А.М. Введение в теорию вероятностей и математическую статистику для физиков. Москва : МФТИ, 2009. 250 с.
66. Чжун К.Л. Однородные цепи Маркова. Москва : Мир, 1964. 426 с.
67. Шабат Б.В. Введение в комплексный анализ. В 2-х частях. Москва : Лань, 2004.
68. Ширяев А.Н. Основы финансовой стохастической математики. Т. 1. Москва : МЦНМО, 2016. 440 с.
280

69. Ширяев А.Н. Вероятность-1. Москва : МЦНМО, 2017. 552 c.
70. Ширяев А.Н. Вероятность-2. Москва : МЦНМО, 2017. 416 c.
71. Яглом А.М. Корреляционная теория стационарных случайных функций. Ленинград : Гидрометеоиздат, 1987.
72. Applebaum D. Le’vy processes and stochastic calculus. 2nd ed. Cambridge University Press, 2009.
73. Amir, G. Continuous time Markov Chains. URL: http://u.math.biu.ac. il/~amirgi/CTMCnotes.pdf
74. Bertsekas, Dimitri P., et al. Dynamic programming and optimal control. V. 1, N 2. Belmont, MA: Athena scientific, 1995.
75. Blum A., Hopcroft J., Kannan R. Foundations of data science. 2019. URL: https://www.cs.cornell.edu/jeh/
76. Boucheron S., Lugosi G., Massart P. Concentration Inequalities: A Nonasymptotic Theory of Independence. Oxford : Oxford University Press, 2013. 480 p.
77. Bubeck S., Cesa-Bianchi N. Regret analysis of stochastic and nonstochastic multi-armed bandit problems // Foundations and Trends® in Machine Learning. 2012 Dec 12. V. 5(1). P. 1–122.
78. Cesa-Bianchi N., Lugosi G. Prediction, learning, and games. Cambridge university press, 2006.
79. Cover T.M., Thomas J.A. Elements of information theory. John Wiley & Sons, 2012.
80. Diaconis P. The Markov chain Monte Carlo revolution // Bulletin (New Series) of the AMS. 2009. V. 49:2. P. 179–205.
81. Duchi J.C. Introductory lectures on stochastic optimization // IAS/Park City Mathematics Series. 2016. URL: http://stanford.edu/~jduchi/ PCMIConvex/Duchi16.pdf
82. Ethier N.S., Kurtz T.G. Markov processes. Wiley Series in Probability and Mathematical Statistics. New York : John Wiley & Sons, Inc., 2005.
83. Gittins J.C., Glazebrook K.D., Weber R. Multi-armed bandit allocation indices. New York : John Wiley & Sons, Inc., 2011.
84. Jaakkola T., Jordan M.I., Singh S.P. Convergence of stochastic iterative dynamic programming algorithms // In Advances in neural information processing systems, 1994. P. 703–710.
85. Jin C., Allen-Zhu Z., Bubeck S., Jordan M.I. Is Q-learning provably efficient? // In Advances in Neural Information Processing Systems. 2018. P. 4863– 4873.
86. Jin Y., Sidford A. Efficiently Solving MDPs with Stochastic Mirror Descent. URL: https://proceedings.icml.cc/static/paper_files/icml/2020/ 6568-Supplemental.pdf
281

87. Hazan E. Introduction to online convex optimization // Foundations and Trends® in Optimization. 2016. V. 2, N 3–4. P. 157–325.
88. Kac M. Random Walk and the Theory of Brownian Motion // The American Mathematical Monthly. 1947. V. 54, N. 7 (Part I). P. 369-391.
89. Klartag B. A central limit theorem for convex sets // Inventiones mathematicae. April 2007. V. 168, I. 1. P. 91–131.
90. Koltchinskii V. Oracle inequalities in empirical risk minimization and sparse recovery problems, volume 2033 of Lecture Notes in Mathematics, 2011. URL: https://www.stat.washington.edu/jaw/COURSES/EPWG/PAPERS-11/ sflour_book.pdf
91. Lan G., Nemirovski A., Shapiro A. Validation analysis of mirror descent stochastic approximation method // Mathematical programming. 2012. V. 134(2). P. 425–58.
92. Lova´sz, L., Vempala S. (2003). Hit-and-run is fast and fun. Microsoft Research preprint, 2003.
93. Milman V.D. Geometrization of Probability // Progress in Mathematics. 2008. V. 265.
94. Mitzenmacher M. A brief history of generative models for power law and lognormal distributions // Internet mathematics. 2004. V. 1, N 2. P. 226–251.
95. Narita K. Asymptotic behavior of continuous-time Markov chains of the Ehrenfest type with applications // Mathematical Models and Stochastic Processes Arising in Natural Phenomena and Their Applications. V. 1193. P. 79–103.
96. Newman M.E.J. Power laws, Pareto distributions and Zipf’s law // Contemporary physics. 2005. V. 46, N 5. P. 323–351.
97. Rakhlin A, Sridharan K. Statistical learning theory and sequential prediction. Lecture Notes in University of Pennsyvania, 2014. URL: http: //www.mit.edu/~rakhlin/courses/stat928/stat928_notes.pdf
98. Ross S.M. An elementary introduction to mathematical finance. Cambridge University Press, 2011.
99. Sato Ken-iti. L´evy Processes and Infinitely Divisible Distributions. Cambridge University Press, 1999.
100. Shalev-Shwartz S., Ben-David S. Understanding Machine Learning: From theory to algorithms. Cambridge University Press, 2014.
101. Shapiro A., Dentcheva D., Ruszczynski A. Lecture on stochastic programming: Modeling and theory. Series on Optimization. Philadelphia : MOS SIAM, 2014.
102. Sigman K. Lecture Notes on Stochastic Modeling I. URL: http://www. columbia.edu/~ks20/stochastic-I/stochastic-I.html
282

103. Sutton R.S., Barto A.G. Reinforcement learning: An introduction. MIT press, 2018. URL: http://incompleteideas.net/bookdraft2017nov5.pdf
104. Vershynin R. Introduction to the non-asymptotic analysis of random matrices : preprint // arXiv.org. 2010. URL: https://arxiv.org/abs/1011. 3027
105. Vershynin R. Four lectures on probabilistic methods for data science : preprint // arXiv.org. 2016. URL: https://arxiv.org/abs/1612.06661
106. Wainwright M. J. Variance-reduced Q-learning is minimax optimal // arXiv.org. 2019. URL: https://arxiv.org/pdf/1906.04697.pdf
107. URL: https://arxiv.org/pdf/1904.07272.pdf 108. URL: http://banditalgs.com
283

Учебное издание
Гасников Александр Владимирович Горбунов Эдуард Александрович Гуз Сергей Анатольевич Черноусова Елена Олеговна Широбоков Максим Геннадьевич Шульгин Егор Владимирович
ЛЕКЦИИ ПО СЛУЧАЙНЫМ
ПРОЦЕССАМ
Под редакцией А. В. Гасникова
Редакторы: В. А. Дружинина, И. А. Волкова, О. П. Котова Корректор Н. Е. Кобзева Компьютерная верстка Н. Е. Кобзева Дизайн обложки Е. А. Казённова Подписано в печать 00.07.2019. Формат 60×841/16. Усл. печ. л. 15,9. Уч.-изд. л. 13,7. Тираж 000 экз. Заказ № 000. Федеральное государственное автономное образовательное учреждение высшего образования «Московский физико-технический институт (национальный исследовательский университет)» 141700, Московская обл., г. Долгопрудный, Институтский пер., 9 Тел. (495) 408-58-22, e-mail: rio@mipt.ru
Отпечатано в полном соответствии с предоставленным оригиналом-макетом ООО «Печатный салон ШАНС» 127412, г. Москва, ул. Ижорская, д. 13, стр. 2 Тел. (495) 484-26-55

Для заметок

