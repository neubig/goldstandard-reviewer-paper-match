Interpretable Multi-dataset Evaluation for Named Entity Recognition
Jinlan Fu† ∗, Pengfei Liu ∗, Graham Neubig † Fudan University, Carnegie Mellon University fujl16@fudan.edu.cn, {pliu3,gneubig}@cs.cmu.edu

arXiv:2011.06854v2 [cs.CL] 9 Dec 2020

Abstract
With the proliferation of models for natural language processing tasks, it is even harder to understand the differences between models and their relative merits. Simply looking at differences between holistic metrics such as accuracy, BLEU, or F1 does not tell us why or how particular methods perform differently and how diverse datasets inﬂuence the model design choices. In this paper, we present a general methodology for interpretable evaluation for the named entity recognition (NER) task. The proposed evaluation method enables us to interpret the differences in models and datasets, as well as the interplay between them, identifying the strengths and weaknesses of current systems. By making our analysis tool available, we make it easy for future researchers to run similar analyses and drive progress in this area: https: //github.com/neulab/InterpretEval.
1 Introduction
With improvements in model architectures (Hochreiter and Schmidhuber, 1997; Kalchbrenner et al., 2014; Lample et al., 2016; Collobert et al., 2011) and learning of pre-trained embeddings (Peters et al., 2018; Akbik et al., 2018, 2019; Devlin et al., 2018; Pennington et al., 2014), Named Entity Recognition (NER) systems are evolving rapidly but also quickly reaching a performance plateau (Akbik et al., 2018, 2019). This proliferation of methods poses a great challenge for the current evaluation methodology, which usually is based on comparing systems on a single holistic score assessing accuracy (usually entity F 1-score). There are several issues with this practice. First, a single evaluation number does not allow us to distinguish on a ﬁne-grained level the strengths and weaknesses
∗These two authors contributed equally.

Life in New York is fun .< l a t e x i t s h a 1 _ b a s e 6 4 = " h J 9 f T Y + N 5 y s r Q M e z 0 S I H t Y d G c 3 U = " > A A A C 6 X i c j V H N L s V A G D 3 q v / 4 u l j a N S 2 J 1 0 9 q w l N h Y i J C 4 f o J I W 3 O Z 3 N 6 2 m U 6 J i B e w s x N b L 2 D L i 4 g 3 4 C 2 c G Z X 4 i T B N v 5 4 5 3 3 d O 5 5 s v y h N Z a N 9 / 7 n K 6 e 3 r 7 + g c G 3 a H h k d G x 2 v j E V p G V K h b N O E s y t R O F h U h k K p p a 6 k T s 5 E q E n S g R 2 1 F 7 2 e S 3 T 4 U q Z J Z u 6 v N c H H T C 4 1 S 2 Z B x q U o e 1 m V X Z E p 7 r y p R h T Z w x 7 m a q b Z i C o V W m r t s 4 r N X 9 h m + X 9 x M E F a i j W u t Z 7 Q n 7 O E K G G C U 6 E E i h i R O E K P j s I Y C P n N w B L s g p I m n z A p d w q S 1 Z J V g R k m 0 z H n O 3 V 7 E p 9 8 a z s O q Y f 0 n 4 K i o 9 z F K T s U 4 R m 7 9 5 N l 9 a Z 8 P + 5 n 1 h P c 3 Z z v m N K q 8 O W Y 0 T s n / p P i r / q z O 9 a L S w a H u Q 7 C m 3 j O k u r l x K e y v m 5 N 6 n r j Q d c n I G H z G v i G O r / L h n z 2 o K 2 7 u 5 2 9 D m X 2 y l Y c 0 + r m p L v J p T c s D B 9 3 H + B F v z j c B v B B v z 9 a W 5 a t Q D m M I 0 5 j j P B S x h B e t o 0 v s K 9 3 j A o 9 N 2 r p 0 b 5 / a 9 1 O m q N J P 4 s p y 7 N / 8 C m Q k = < / l a t e x i t >

. . .< l a t e x i t s h a 1 _ b a s e 6 4 = " f w A 7 Q 9 1 L 9 W e 2 S d 7 + Q C x G 6 2 8 M 1 / k = " > A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k X o K i Q i 6 L L g p s u K t h V q k W Q 6 r U P z Y j J R S h H 8 A b f 6 a e I f 6 F 9 4 Z 0 x B L a I T k p w 5 9 5 4 z c + 8 N 0 l B k y n V f S 9 b C 4 t L y S n m 1 s r a + s b l V 3 d 7 p Z E k u G W + z J E z k Z e B n P B Q x b y u h Q n 6 Z S u 5 H Q c i 7 w f h U x 7 u 3 X G Y i i S / U J O X 9 y B / F Y i i Y r 4 g 6 d x z n u l p z H d c s e x 5 4 B a i h W K 2 k + o I r D J C A I U c E j h i K c A g f G T 0 9 e H C R E t f H l D h J S J g 4 x z 0 q p M 0 p i 1 O G T + y Y v i P a 9 Q o 2 p r 3 2 z I y a 0 S k h v Z K U N g 5 I k 1 C e J K x P s 0 0 8 N 8 6 a / c 1 7 a j z 1 3 S b 0 D w q v i F i F G 2 L / 0 s 0 y / 6 v T t S g M c W J q E F R T a h h d H S t c c t M V f X P 7 S 1 W K H F L i N B 5 Q X B J m R j n r s 2 0 0 m a l d 9 9 Y 3 8 T e T q V m 9 Z 0 V u j n d 9 S x q w 9 3 O c 8 6 B z 6 H i u 4 5 0 d 1 R r 1 Y t R l 7 G E f d Z r n M R p o o o U 2 e Y / w i C c 8 W 0 0 r t n L r 7 j P V K h W a X X x b 1 s M H 2 h a P i Q = = < / l a t e x i t >

. . .< l a t e x i t s h a 1 _ b a s e 6 4 = " f w A 7 Q 9 1 L 9 W e 2 S d 7 + Q C x G 6 2 8 M 1 / k = " > A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k X o K i Q i 6 L L g p s u K t h V q k W Q 6 r U P z Y j J R S h H 8 A b f 6 a e I f 6 F 9 4 Z 0 x B L a I T k p w 5 9 5 4 z c + 8 N 0 l B k y n V f S 9 b C 4 t L y S n m 1 s r a + s b l V 3 d 7 p Z E k u G W + z J E z k Z e B n P B Q x b y u h Q n 6 Z S u 5 H Q c i 7 w f h U x 7 u 3 X G Y i i S / U J O X 9 y B / F Y i i Y r 4 g 6 d x z n u l p z H d c s e x 5 4 B a i h W K 2 k + o I r D J C A I U c E j h i K c A g f G T 0 9 e H C R E t f H l D h J S J g 4 x z 0 q p M 0 p i 1 O G T + y Y v i P a 9 Q o 2 p r 3 2 z I y a 0 S k h v Z K U N g 5 I k 1 C e J K x P s 0 0 8 N 8 6 a / c 1 7 a j z 1 3 S b 0 D w q v i F i F G 2 L / 0 s 0 y / 6 v T t S g M c W J q E F R T a h h d H S t c c t M V f X P 7 S 1 W K H F L i N B 5 Q X B J m R j n r s 2 0 0 m a l d 9 9 Y 3 8 T e T q V m 9 Z 0 V u j n d 9 S x q w 9 3 O c 8 6 B z 6 H i u 4 5 0 d 1 R r 1 Y t R l 7 G E f d Z r n M R p o o o U 2 e Y / w i C c 8 W 0 0 r t n L r 7 j P V K h W a X X x b 1 s M H 2 h a P i Q = = < / l a t e x i t >

. . .< l a t e x i t s h a 1 _ b a s e 6 4 = " f w A 7 Q 9 1 L 9 W e 2 S d 7 + Q C x G 6 2 8 M 1 / k = " > A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k X o K i Q i 6 L L g p s u K t h V q k W Q 6 r U P z Y j J R S h H 8 A b f 6 a e I f 6 F 9 4 Z 0 x B L a I T k p w 5 9 5 4 z c + 8 N 0 l B k y n V f S 9 b C 4 t L y S n m 1 s r a + s b l V 3 d 7 p Z E k u G W + z J E z k Z e B n P B Q x b y u h Q n 6 Z S u 5 H Q c i 7 w f h U x 7 u 3 X G Y i i S / U J O X 9 y B / F Y i i Y r 4 g 6 d x z n u l p z H d c s e x 5 4 B a i h W K 2 k + o I r D J C A I U c E j h i K c A g f G T 0 9 e H C R E t f H l D h J S J g 4 x z 0 q p M 0 p i 1 O G T + y Y v i P a 9 Q o 2 p r 3 2 z I y a 0 S k h v Z K U N g 5 I k 1 C e J K x P s 0 0 8 N 8 6 a / c 1 7 a j z 1 3 S b 0 D w q v i F i F G 2 L / 0 s 0 y / 6 v T t S g M c W J q E F R T a h h d H S t c c t M V f X P 7 S 1 W K H F L i N B 5 Q X B J m R j n r s 2 0 0 m a l d 9 9 Y 3 8 T e T q V m 9 Z 0 V u j n d 9 S x q w 9 3 O c 8 6 B z 6 H i u 4 5 0 d 1 R r 1 Y t R l 7 G E f d Z r n M R p o o o U 2 e Y / w i C c 8 W 0 0 r t n L r 7 j P V K h W a X X x b 1 s M H 2 h a P i Q = = < / l a t e x i t >

. . .< l a t e x i t s h a 1 _ b a s e 6 4 = " f w A 7 Q 9 1 L 9 W e 2 S d 7 + Q C x G 6 2 8 M 1 / k = " > A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k X o K i Q i 6 L L g p s u K t h V q k W Q 6 r U P z Y j J R S h H 8 A b f 6 a e I f 6 F 9 4 Z 0 x B L a I T k p w 5 9 5 4 z c + 8 N 0 l B k y n V f S 9 b C 4 t L y S n m 1 s r a + s b l V 3 d 7 p Z E k u G W + z J E z k Z e B n P B Q x b y u h Q n 6 Z S u 5 H Q c i 7 w f h U x 7 u 3 X G Y i i S / U J O X 9 y B / F Y i i Y r 4 g 6 d x z n u l p z H d c s e x 5 4 B a i h W K 2 k + o I r D J C A I U c E j h i K c A g f G T 0 9 e H C R E t f H l D h J S J g 4 x z 0 q p M 0 p i 1 O G T + y Y v i P a 9 Q o 2 p r 3 2 z I y a 0 S k h v Z K U N g 5 I k 1 C e J K x P s 0 0 8 N 8 6 a / c 1 7 a j z 1 3 S b 0 D w q v i F i F G 2 L / 0 s 0 y / 6 v T t S g M c W J q E F R T a h h d H S t c c t M V f X P 7 S 1 W K H F L i N B 5 Q X B J m R j n r s 2 0 0 m a l d 9 9 Y 3 8 T e T q V m 9 Z 0 V u j n d 9 S x q w 9 3 O c 8 6 B z 6 H i u 4 5 0 d 1 R r 1 Y t R l 7 G E f d Z r n M R p o o o U 2 e Y / w i C c 8 W 0 0 r t n L r 7 j P V K h W a X X x b 1 s M H 2 h a P i Q = = < / l a t e x i t > . . .< l a t e x i t s h a 1 _ b a s e 6 4 = " f w A 7 Q 9 1 L 9 W e 2 S d 7 + Q C x G 6 2 8 M 1 / k = " > A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k X o K i Q i 6 L L g p s u K t h V q k W Q 6 r U P z Y j J R S h H 8 A b f 6 a e I f 6 F 9 4 Z 0 x B L a I T k p w 5 9 5 4 z c + 8 N 0 l B k y n V f S 9 b C 4 t L y S n m 1 s r a + s b l V 3 d 7 p Z E k u G W + z J E z k Z e B n P B Q x b y u h Q n 6 Z S u 5 H Q c i 7 w f h U x 7 u 3 X G Y i i S / U J O X 9 y B / F Y i i Y r 4 g 6 d x z n u l p z H d c s e x 5 4 B a i h W K 2 k + o I r D J C A I U c E j h i K c A g f G T 0 9 e H C R E t f H l D h J S J g 4 x z 0 q p M 0 p i 1 O G T + y Y v i P a 9 Q o 2 p r 3 2 z I y a 0 S k h v Z K U N g 5 I k 1 C e J K x P s 0 0 8 N 8 6 a / c 1 7 a j z 1 3 S b 0 D w q v i F i F G 2 L / 0 s 0 y / 6 v T t S g M c W J q E F R T a h h d H S t c c t M V f X P 7 S 1 W K H F L i N B 5 Q X B J m R j n r s 2 0 0 m a l d 9 9 Y 3 8 T e T q V m 9 Z 0 V u j n d 9 S x q w 9 3 O c 8 6 B z 6 H i u 4 5 0 d 1 R r 1 Y t R l 7 G E f d Z r n M R p o o o U 2 e Y / w i C c 8 W 0 0 r t n L r 7 j P V K h W a X X x b 1 s M H 2 h a P i Q = = < / l a t e x i t >

New Yor k < l a t e x i t s h a 1 _ b a s e 6 4 = " r f y y Z / w 9 J w 0 W y o G 2 e l R 2 Y A 6 e A o 0 = " > A A A C z 3 i c j V H L S s N A F D 2 N r x p f V Z d u g k X o q i T d 6 L L g x p W 0 Y B / S F k n S a Q 1 N M 2 E y s Z S i u P U H 3 O p f i X + g f + G d M Q W 1 i E 5 I c u b c e 8 7 M v d e L w y C R t v 2 a M 5 a W V 1 b X 8 u v m x u b W 9 k 5 h d 6 + Z 8 F T 4 r O H z k I u 2 5 y Y s D C L W k I E M W T s W z B 1 7 I W t 5 o 1 M V b 9 0 w k Q Q 8 u p D T m P X G 7 j A K B o H v S q K 6 5 2 x i m e Y l F y P L v C o U 7 b K t l 7 U I n A w U k a 0 a L 7 y g i z 4 4 f K Q Y g y G C J B z C R U J P B w 5 s x M T 1 M C N O E A p 0 n O E W J m l T y m K U 4 R I 7 o u + Q d p 2 M j W i v P B O t 9 u m U k F 5 B S g t H p O G U J w i r 0 y w d T 7 W z Y n / z n m l P d b c p / b 3 M a 0 y s x D W x f + n m m f / V q V o k B j j R N Q R U U 6 w Z V Z 2 f u a S 6 K + r m 1 p e q J D n E x C n c p 7 g g 7 G v l v M + W 1 i S 6 d t V b V 8 f f d K Z i 1 d 7 P c l O 8 q 1 v S g J 2 f 4 1 w E z U r Z s c t O v V K s l r J R 5 3 G A Q 5 R o n s e o 4 g w 1 N M g 7 x i O e 8 G z U j Y l x Z 9 x / p h q 5 T L O P b 8 t 4 + A C D c p K E < / l a t e x i t >
. . .< l a t e x i t s h a 1 _ b a s e 6 4 = " f w A 7 Q 9 1 L 9 W e 2 S d 7 + Q C x G 6 2 8 M 1 / k = " > A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k X o K i Q i 6 L L g p s u K t h V q k W Q 6 r U P z Y j J R S h H 8 A b f 6 a e I f 6 F 9 4 Z 0 x B L a I T k p w 5 9 5 4 z c + 8 N 0 l B k y n V f S 9 b C 4 t L y S n m 1 s r a + s b l V 3 d 7 p Z E k u G W + z J E z k Z e B n P B Q x b y u h Q n 6 Z S u 5 H Q c i 7 w f h U x 7 u 3 X G Y i i S / U J O X 9 y B / F Y i i Y r 4 g 6 d x z n u l p z H d c s e x 5 4 B a i h W K 2 k + o I r D J C A I U c E j h i K c A g f G T 0 9 e H C R E t f H l D h J S J g 4 x z 0 q p M 0 p i 1 O G T + y Y v i P a 9 Q o 2 p r 3 2 z I y a 0 S k h v Z K U N g 5 I k 1 C e J K x P s 0 0 8 N 8 6 a / c 1 7 a j z 1 3 S b 0 D w q v i F i F G 2 L / 0 s 0 y / 6 v T t S g M c W J q E F R T a h h d H S t c c t M V f X P 7 S 1 W K H F L i N B 5 Q X B J m R j n r s 2 0 0 m a l d 9 9 Y 3 8 T e T q V m 9 Z 0 V u j n d 9 S x q w 9 3 O c 8 6 B z 6 H i u 4 5 0 d 1 R r 1 Y t R l 7 G E f d Z r n M R p o o o U 2 e Y / w i C c 8 W 0 0 r t n L r 7 j P V K h W a X X x b 1 s M H 2 h a P i Q = = < / l a t e x i t >

e L e n < l a t e x i t s h a 1 _ b a s e 6 4 = " 3 l j 7 k H X H P l E W S n C w 4 1 u M M o 7 p 0 v P U G 0 b l J t G v E 0 I j J Q I + v N V o T 2 S 4 Q = " > A A A C x 3 i c j V H L S s N A F D 2 N r 1 p f V Z d u g k X W p q m i 5 R K u 4 d 0 G Z f 0 B F j N Y w K o L u C K v t Y g B H t U E i W S T 6 t b u Q h N a 5 R k I U m y k K 2 Z I b p i L w v h w / B Q t p / X o 6 R E f X o + R F / P I i f H 6 + B g f H o + B D 7 e 7 O 0 9 x M T U U 1 I C v I o 6 h I C c R m n Z z c j 8 3 8 n 5 z M N 3 w f Z G N D / l J 0 5 n L F C o 3 b r x N m W t P F M m z Z S u 8 f s m L F m 7 W K X L c u y a u X r l a l + d s W b 1 + / c P 2 p t G W L h Q w 6 m S w i m P N E V q L C / 9 R w D g 0 a X t C h d W m z P F k 3 8 H Y 5 F 1 X J h p C c J 8 c a 3 k w W o D h O b w n P u V 3 Z y 3 u e n 2 1 f 1 q L H O p v 9 1 y A E Y T 9 M i w J + / B A S v j x i D L D W k G b j c j / d q g + H U e 7 4 X 5 Y 0 Z h a F Q s F X D M / W j X / O m c W L + V Y s J n Q S M w N 5 f w R F p d Y g K o a K g x c 0 P / R F U j / 2 H c i A + l b T + D 1 / V g i v u w 0 L E W c u J g D g g A g E E M Y C A D k x j w C + P B h G z E E X 9 F D m R J h 6 w m 0 j J B E h X I A C t S j u 4 j g R Q F h x r E u S s F M H t 1 8 T i l R u N k y C E N V v I Q 4 i V p D O b C J o + v + Y X K Z / o r 1 2 U a z N a Z g M u W c Z q / M m t M d j u N j W V b X k x a 6 r B u T P l R N G 7 5 J N E S n x J Q J 5 0 6 g A r d F B Y F z h d u T Z 3 q R u y 6 Y o r l 9 K L l X u u x s v M 2 9 S X O e V R K v f R c 3 2 0 p 6 L w + B d s Z R n I n 9 E Y C v / S y J T / Z c X s / 3 9 U a f l 7 e X J D 3 o s 4 R 0 6 j O 1 J w Q 6 9 i e n B S Q j T O 6 r F O i S Z 1 H M c S s f T S U p n q U 5 q + c a i X d r 6 i 1 Q + l 6 R E M p Q p Q 3 E K i a d 6 x I h O + x o p R 5 Y / a S a c T k e 3 2 P J W d l e S / d q W b v B c 1 u d z f t 9 V N T K 9 x T a S q k 5 l l K 2 + o c T s v 1 K S t Z d 4 0 l g 7 X u b k P C 6 z 9 Z z / F X t u Q c O 0 S q r O Z 2 V X s T i K + N s k Q n n h k u f F k 8 5 i H 7 F G D I n 4 Z s R t p b P K s N 8 I R 9 B 3 m n A q M K k B 5 K Q 2 Q T Z 3 W c y 4 + w 7 G j P D x A p x k 6 R 1 G U k y P 3 j Q Z B i t I r 1 M W q K l p n l G U 9 s + 8 G m c v f g c 3 J t d 9 s h 6 P T Z T o w p = R = l < / l a t e x i t > . . .< l a t e x i t s h a 1 _ b a s e 6 4 = " f w A 7 Q 9 1 L 9 W e 2 S d 7 + Q C x G 6 2 8 M 1 / k = " > A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k X o K i Q i 6 L L g p s u K t h V q k W Q 6 r U P z Y j J R S h H 8 A b f 6 a e I f 6 F 9 4 Z 0 x B L a I T k p w 5 9 5 4 z c + 8 N 0 l B k y n V f S 9 b C 4 t L y S n m 1 s r a + s b l V 3 d 7 p Z E k u G W + z J E z k Z e B n P B Q x b y u h Q n 6 Z S u 5 H Q c i 7 w f h U x 7 u 3 X G Y i i S / U J O X 9 y B / F Y i i Y r 4 g 6 d x z n u l p z H d c s e x 5 4 B a i h W K 2 k + o I r D J C A I U c E j h i K c A g f G T 0 9 e H C R E t f H l D h J S J g 4 x z 0 q p M 0 p i 1 O G T + y Y v i P a 9 Q o 2 p r 3 2 z I y a 0 S k h v Z K U N g 5 I k 1 C e J K x P s 0 0 8 N 8 6 a / c 1 7 a j z 1 3 S b 0 D w q v i F i F G 2 L / 0 s 0 y / 6 v T t S g M c W J q E F R T a h h d H S t c c t M V f X P 7 S 1 W K H F L i N B 5 Q X B J m R j n r s 2 0 0 m a l d 9 9 Y 3 8 T e T q V m 9 Z 0 V u j n d 9 S x q w 9 3 O c 8 6 B z 6 H i u 4 5 0 d 1 R r 1 Y t R l 7 G E f d Z r n M R p o o o U 2 e Y / w i C c 8 W 0 0 r t n L r 7 j P V K h W a X X x b 1 s M H 2 h a P i Q = = < / l a t e x i t >

eLen = 2 < l a t e x i t s h a 1 _ b a s e 6 4 = " T H V o U 7 r e k 1 K k c l Q W 1 A k j i L S Q Z X M = " > A A A C 1 H i c j V H L S s N A F D 2 N r 1 o f j b p 0 E 2 w F V y X p R j d C w Y 0 L F x X s A 2 w p S T p t h + Z F M h F K 7 U r c + g N u 9 Z v E P 9 C / 8 M 6 Y g l p E J y Q 5 c + 4 5 d + b e 6 0 Q e T 4 R p v u a 0 p e W V 1 b X 8 e m F j c 2 u 7 q O / s N p M w j V 3 W c E M v j N u O n T C P B 6 w h u P B Y O 4 q Z 7 T s e a z n j M x l v 3 b A 4 4 W F w J S Y R 6 / r 2 M O A D 7 t q C q J 5 e L H e i E e 9 N 2 Q U L Z q f V c k 8 v m R V T L W M R W B k o I V v 1 U H 9 B B 3 2 E c J H C B 0 M A Q d i D j Y S e a 1 g w E R H X x Z S 4 m B B X c Y Y Z C u R N S c V I Y R M 7 p u + Q d t c Z G 9 B e 5 k y U 2 6 V T P H p j c h o 4 J E 9 I u p i w P M 1 Q 8 V R l l u x v u a c q p 7 z b h P 5 O l s s n V m B E 7 F + + u f K / P l m L w A A n q g Z O N U W K k d W 5 W Z Z U d U X e 3 P h S l a A M E X E S 9 y k e E 3 a V c 9 5 n Q 3 k S V b v s r a 3 i b 0 o p W b l 3 M 2 2 K d 3 l L G r D 1 c 5 y L o F m t W G b F u q y W a u V s 1 H n s 4 w B H N M 9 j 1 H C O O h p q 5 o 9 4 w r P W 1 G 6 1 O + 3 + U 6 r l M s 8 e v i 3 t 4 Q N e e 5 T R < / l a t e x i t >

1< l a t e x i t s h a 1 _ b a s e 6 4 = " S o o 8 B I r f S 2 r 7 a h G Q e X v b R P Z D Z d k = " > A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g q 3 Q V U m 6 0 W X B T Z c V 7 Q O 0 S J J O 6 9 C 8 m E y U U g R / w K 1 + m v g H + h f e G a e g F t E J S c 6 c e 8 + Z u f f 6 a c g z 6 T i v B W t p e W V 1 r b h e 2 t j c 2 t 4 p 7 + 5 1 s y Q X A e s E S Z i I v u 9 l L O Q x 6 0 g u Q 9 Z P B f M i P 2 Q 9 f 3 K q 4 r 1 b J j K e x B d y m r J B 5 I 1 j P u K B J 4 k 6 r 7 r V 6 3 L F q T t 6 2 Y v A N a A C s 9 p J + Q V X G C J B g B w R G G J I w i E 8 Z P R c w o W D l L g B Z s Q J Q l z H G e 5 R I m 1 O W Y w y P G I n 9 B 3 T 7 t K w M e 2 V Z 6 b V A Z 0 S 0 i t I a e O I N A n l C c L q N F v H c + 2 s 2 N + 8 Z 9 p T 3 W 1 K f 9 9 4 R c R K 3 B D 7 l 2 6 e + V + d q k V i h B N d A 6 e a U s 2 o 6 g L j k u u u q J v b X 6 q S 5 J A S p / C Q 4 o J w o J X z P t t a k + n a V W 8 9 H X / T m Y p V + 8 D k 5 n h X t 6 Q B u z / H u Q i 6 j b r r 1 N 2 z R q V Z M 6 M u 4 g C H q N E 8 j 9 F E C 2 1 0 y H u M R z z h 2 W p Z s Z V b d 5 + p V s F o 9 v F t W Q 8 f s Q W P d g = = < / l a t e x i t >

2< l a t e x i t s h a 1 _ b a s e 6 4 = " F Y S t H Y k S U n S d 6 f K Q B l b x V A C v g 6 U = " > A A A C x n i c j V H L S s N A F D 2 N r 1 p f V Z d u g q 3 Q V U m 6 0 W X B T Z c V 7 Q O 0 S J J O 6 9 C 8 m E y U U g R / w K 1 + m v g H + h f e G a e g F t E J S c 6 c e 8 + Z u f f 6 a c g z 6 T i v B W t p e W V 1 r b h e 2 t j c 2 t 4 p 7 + 5 1 s y Q X A e s E S Z i I v u 9 l L O Q x 6 0 g u Q 9 Z P B f M i P 2 Q 9 f 3 K q 4 r 1 b J j K e x B d y m r J B 5 I 1 j P u K B J 4 k 6 r z a q 1 + W K U 3 f 0 s h e B a 0 A F Z r W T 8 g u u M E S C A D k i M M S Q h E N 4 y O i 5 h A s H K X E D z I g T h L i O M 9 y j R N q c s h h l e M R O 6 D u m 3 a V h Y 9 o r z 0 y r A z o l p F e Q 0 s Y R a R L K E 4 T V a b a O 5 9 p Z s b 9 5 z 7 S n u t u U / r 7 x i o i V u C H 2 L 9 0 8 8 7 8 6 V Y v E C C e 6 B k 4 1 p Z p R 1 Q X G J d d d U T e 3 v 1 Q l y S E l T u E h x Q X h Q C v n f b a 1 J t O 1 q 9 5 6 O v 6 m M x W r 9 o H J z f G u b k k D d n + O c x F 0 G 3 X X q b t n j U q z Z k Z d x A E O U a N 5 H q O J F t r o k P c Y j 3 j C s 9 W y Y i u 3 7 j 5 T r Y L R 7 O P b s h 4 + A L N m j 3 c = < / l a t e x i t >

3< l a t e x i t s h a 1 _ b a s e 6 4 = " h y P d u 2 i t i k J L I i i g c 7 G m e W S y b 1 I = " > A A A C x n i c j V H L T s J A F D 3 U F + I L d e m m E U x Y k R Y X u i R x w x K j P B I k p h 0 G n F D a Z j r V E G L i D 7 j V T z P + g f 6 F d 8 a S q M T o N G 3 P n H v P m b n 3 + n E g E u U 4 r z l r a X l l d S 2 / X t j Y 3 N r e K e 7 u t Z M o l Y y 3 W B R E s u t 7 C Q 9 E y F t K q I B 3 Y 8 m 9 i R / w j j 8 + 0 / H O L Z e J i M J L N Y 1 5 f + K N Q j E U z F N E X Z S P y 9 f F k l N 1 z L I X g Z u B E r L V j I o v u M I A E R h S T M A R Q h E O 4 C G h p w c X D m L i + p g R J w k J E + e 4 R 4 G 0 K W V x y v C I H d N 3 R L t e x o a 0 1 5 6 J U T M 6 J a B X k t L G E W k i y p O E 9 W m 2 i a f G W b O / e c + M p 7 7 b l P 5 + 5 j U h V u G G 2 L 9 0 8 8 z / 6 n Q t C k O c m h o E 1 R Q b R l f H M p f U d E X f 3 P 5 S l S K H m D i N B x S X h J l R z v t s G 0 1 i a t e 9 9 U z 8 z W R q V u 9 Z l p v i X d + S B u z + H O c i a N e q r l N 1 z 2 u l e i U b d R 4 H O E S F 5 n m C O h p o o k X e I z z i C c 9 W w w q t 1 L r 7 T L V y m W Y f 3 5 b 1 8 A G 1 x 4 9 4 < / l a t e x i t >

4 < l a t e x i t s h a 1 _ b a s e 6 4 = " + a S h o h R M i B L + k E J M g G 3 x T 5 o h F 1 8 = " > A A A C y n i c j V H L S s N A F D 2 N r 1 p f V Z d u g q 3 Q V U m K o M u C G x c u K t g H t E W S d F q H p k m c T I R S 3 P k D b v X D x D / Q v / D O O A W 1 i E 5 I c u b c c + 7 M v d d P Q p 5 K x 3 n N W U v L K 6 t r + f X C x u b W 9 k 5 x d 6 + V x p k I W D O I w 1 h 0 f C 9 l I Y 9 Y U 3 I Z s k 4 i m D f x Q 9 b 2 x 2 c q 3 r 5 j I u V x d C W n C e t P v F H E h z z w J F H t c m / E b o / L 1 8 W S U 3 X 0 s h e B a 0 A J Z j X i 4 g t 6 G C B G g A w T M E S Q h E N 4 S O n p w o W D h L g + Z s Q J Q l z H G e 5 R I G 9 G K k Y K j 9 g x f U e 0 6 x o 2 o r 3 K m W p 3 Q K e E 9 A p y 2 j g i T 0 w 6 Q V i d Z u t 4 p j M r 9 r f c M 5 1 T 3 W 1 K f 9 / k m h A r c U P s X 7 6 5 8 r 8 + V Y v E E K e 6 B k 4 1 J Z p R 1 Q U m S 6 a 7 o m 5 u f 6 l K U o a E O I U H F B e E A + 2 c 9 9 n W n l T X r n r r 6 f i b V i p W 7 Q O j z f C u b k k D d n + O c x G 0 a l X X q b q X t V K 9 Y k a d x w E O U a F 5 n q C O c z T Q 1 F U + 4 g n P 1 o U l r K k 1 + 5 R a O e P Z x 7 d l P X w A I P i R O g = = < / l a t e x i t >

F 1 < l a t e x i t s h a 1 _ b a s e 6 4 = " A y 5 w a S m 5 t M P z b 0 t R 7 G a b u A 1 h m O U = " > A A A C x X i c j V H L S s N A F D 2 N r 1 p f V Z d u g l V w V Z J u d F k Q 1 G U V + 4 B a J E m n d W h e T C a F U s Q f c K u / J v 6 B / o V 3 x i m o R X R C k j P n 3 n N m 7 r 1 + G v J M O s 5 r w V p Y X F p e K a 6 W 1 t Y 3 N r f K 2 z u t L M l F w J p B E i a i 4 3 s Z C 3 n M m p L L k H V S w b z I D 1 n b H 5 2 q e H v M R M a T + F p O U t a L v G H M B z z w J F F X Z + 5 t u e J U H b 3 s e e A a U I F Z j a T 8 g h v 0 k S B A j g g M M S T h E B 4 y e r p w 4 S A l r o c p c Y I Q 1 3 G G e 5 R I m 1 M W o w y P 2 B F 9 h 7 T r G j a m v f L M t D q g U 0 J 6 B S l t H J I m o T x B W J 1 m 6 3 i u n R X 7 m / d U e 6 q 7 T e j v G 6 + I W I k 7 Y v / S z T L / q 1 O 1 S A x w o m v g V F O q G V V d Y F x y 3 R V 1 c / t L V Z I c U u I U 7 l N c E A 6 0 c t Z n W 2 s y X b v q r a f j b z p T s W o f m N w c 7 + q W N G D 3 5 z j n Q a t W d Z 2 q e 1 m r 1 A / M q I v Y w z 6 O a J 7 H q O M C D T T J e 4 B H P O H Z O r c i S 1 r j z 1 S r Y D S 7 + L a s h w + F H I 9 m < / l a t e x i t >

1< l a t e x i t s h a 1 _ b a s e 6 4 = " H / p n W R R 6 s C i f S S M G u 5 4 G g 3 U a C h E = " > A A A C x n i c j V H L S s N A F D 3 G V 6 2 v q k s 3 w V Z x V Z J u d F l w 0 2 V F + 4 B a J J l O 6 9 C 8 m E y U U g R / w K 1 + m v g H + h f e G V N Q i + i E J G f O v e f M 3 H v 9 J B C p c p z X B W t x a X l l t b B W X N / Y 3 N o u 7 e y 2 0 z i T j L d Y H M S y 6 3 s p D 0 T E W 0 q o g H c T y b 3 Q D 3 j H H 5 / p e O e W y 1 T E 0 a W a J L w f e q N I D A X z F F E X F b d y X S o 7 V c c s e x 6 4 O S g j X 8 2 4 9 I I r D B C D I U M I j g i K c A A P K T 0 9 u H C Q E N f H l D h J S J g 4 x z 2 K p M 0 o i 1 O G R + y Y v i P a 9 X I 2 o r 3 2 T I 2 a 0 S k B v Z K U N g 5 J E 1 O e J K x P s 0 0 8 M 8 6 a / c 1 7 a j z 1 3 S b 0 9 3 O v k F i F G 2 L / 0 s 0 y / 6 v T t S g M c W p q E F R T Y h h d H c t d M t M V f X P 7 S 1 W K H B L i N B 5 Q X B J m R j n r s 2 0 0 q a l d 9 9 Y z 8 T e T q V m 9 Z 3 l u h n d 9 S x q w + 3 O c 8 6 B d q 7 p O 1 T 2 v l e t H + a g L 2 M c B j m m e J 6 i j g S Z a 5 D 3 C I 5 7 w b D W s y M q s u 8 9 U a y H X 7 O H b s h 4 + A L B r j 3 Q = < / l a t e x i t >

2< l a t e x i t s h a 1 _ b a s e 6 4 = " L Q r c w P m S b u 6 4 6 Y 4 R u M V q V z I 3 V 4 Q = " > A A A C x n i c j V H L S s N A F D 3 G V 6 2 v q k s 3 w V Z x V Z J u d F l w 0 2 V F + 4 B a J J l O a 2 h e T C Z K K Y I / 4 F Y / T f w D / Q v v j F N Q i + i E J G f O v e f M 3 H v 9 N A w y 6 T i v C 9 b i 0 v L K a m G t u L 6 x u b V d 2 t l t Z 0 k u G G + x J E x E 1 / c y H g Y x b 8 l A h r y b C u 5 F f s g 7 / v h M x T u 3 X G R B E l / K S c r 7 k T e K g 2 H A P E n U R a V W u S 6 V n a q j l z 0 P X A P K M K u Z l F 5 w h Q E S M O S I w B F D E g 7 h I a O n B x c O U u L 6 m B I n C A U 6 z n G P I m l z y u K U 4 R E 7 p u + I d j 3 D x r R X n p l W M z o l p F e Q 0 s Y h a R L K E 4 T V a b a O 5 9 p Z s b 9 5 T 7 W n u t u E / r 7 x i o i V u C H 2 L 9 0 s 8 7 8 6 V Y v E E K e 6 h o B q S j W j q m P G J d d d U T e 3 v 1 Q l y S E l T u E B x Q V h p p W z P t t a k + n a V W 8 9 H X / T m Y p V e 2 Z y c 7 y r W 9 K A 3 Z / j n A f t W t V 1 q u 5 5 r V w / M q M u Y B 8 H O K Z 5 n q C O B p p o k f c I j 3 j C s 9 W w Y i u 3 7 j 5 T r Q W j 2 c O 3 Z T 1 8 A L L M j 3 U = < / l a t e x i t >

3< l a t e x i t s h a 1 _ b a s e 6 4 = " 9 G J B K I M K D b N / w G y h h A E N s 4 8 J 8 N 0 = " > A A A C x n i c j V H L T s J A F D 3 U F + I L d e m m E T S u S I s L X Z K 4 Y Y l R H g k S 0 w 4 D T i h t M 5 1 q C D H x B 9 z q p x n / Q P / C O 2 N J V G J 0 m r Z n z r 3 n z N x 7 / T g Q i X K c 1 5 y 1 s L i 0 v J J f L a y t b 2 x u F b d 3 W k m U S s a b L A o i 2 f G 9 h A c i 5 E 0 l V M A 7 s e T e 2 A 9 4 2 x + d 6 X j 7 l s t E R O G l m s S 8 N / a G o R g I 5 i m i L s r H 5 e t i y a k 4 Z t n z w M 1 A C d l q R M U X X K G P C A w p x u A I o Q g H 8 J D Q 0 4 U L B z F x P U y J k 4 S E i X P c o 0 D a l L I 4 Z X j E j u g 7 p F 0 3 Y 0 P a a 8 / E q B m d E t A r S W n j g D Q R 5 U n C + j T b x F P j r N n f v K f G U 9 9 t Q n 8 / 8 x o T q 3 B D 7 F + 6 W e Z / d b o W h Q F O T Q 2 C a o o N o 6 t j m U t q u q J v b n + p S p F D T J z G f Y p L w s w o Z 3 2 2 j S Y x t e v e e i b + Z j I 1 q / c s y 0 3 x r m 9 J A 3 Z / j n M e t K o V 1 6 m 4 5 9 V S 7 T A b d R 5 7 2 M c R z f M E N d T R Q J O 8 h 3 j E E 5 6 t u h V a q X X 3 m W r l M s 0 u v i 3 r 4 Q O 1 L Y 9 2 < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = " 7 v 4 d R 4 K 9 4 Y + / + e Z 5 Z m 5 U b 0 m q d a o = " > A A A C y n i c j V H L S s N A F D 2 N r 1 p f V Z d u g q 3 i q i R F 0 G X B j Q s X F e w D 2 i L J d F q H p k m c T I R S 3 P k D b v X D x D / Q v / D O m I J a R C c k O X P u O X f m 3 u v H g U i U 4 7 z m r I X F p e W V / G p h b X 1 j c 6 u 4 v d N M o l Q y 3 m B R E M m 2 7 y U 8 E C F v K K E C 3 o 4 l 9 8 Z + w F v + 6 E z H W 3 d c J i I K r 9 Q k 5 r 2 x N w z F Q D B P E d U q d 4 f 8 9 r h 8 X S w 5 F c c s e x 6 4 G S g h W / W o + I I u + o j A k G I M j h C K c A A P C T 0 d u H A Q E 9 f D l D h J S J g 4 x z 0 K 5 E 1 J x U n h E T u i 7 5 B 2 n Y w N a a 9 z J s b N 6 J S A X k l O G w f k i U g n C e v T b B N P T W b N / p Z 7 a n L q u 0 3 o 7 2 e 5 x s Q q 3 B D 7 l 2 + m / K 9 P 1 6 I w w K m p Q V B N s W F 0 d S z L k p q u 6 J v b X 6 p S l C E m T u M + x S V h Z p y z P t v G k 5 j a d W 8 9 E 3 8 z S s 3 q P c u 0 K d 7 1 L W n A 7 s 9 x z o N m t e I 6 F f e y W q o d Z q P O Y w / 7 O K J 5 n q C G c 9 T R M F U + 4 g n P 1 o U l r Y k 1 / Z R a u c y z i 2 / L e v g A I F 6 R O A = = < / l a t e x i t >

e L e n < l a t e x i t s h a 1 _ b a s e 6 4 = " i u E u f D E I + z g h c Q 8 V L I 5 C J X y n n C j 3 Q B q U D x 7 P t G U G K o l w l Z h 0 y a I j M Q = " > A A A C x 3 i c j V H L S s N A F D 2 N r 1 x p f V Z d u Q o v g q i R u d C M W 3 C i 4 q G A f U I s k 6 b Q d N T z D Y I v h J m p R F R i L K E C f 3 Q / H A 3 r O e o 5 f d + E n i F H P + 9 h C f / e 8 G M e 4 a 0 g B l b p W E I J T y k Q h 5 y c 5 + t 4 x 5 z Z z + s b y O d u c J W H L P f E S 2 4 l R Z p b v z u l W j 0 b h n c 5 W h l c 5 S Z m X / 8 X q F r h 6 Z 2 X v V r v G f 5 K V G d 5 j u e N q R S K d R x y h l 6 1 r W e c 8 y I M X / c 4 c k t 3 1 H E T u p b j z v k h N a U w l m l P z O 5 G r z R Z T s F y z Z A H t T d g n + T a f z f i m D R M N 1 W l b v Q D x B Y l n P X v I C S i X 8 c F h q S O x Y T t u Q D O 0 7 Q F 9 3 7 p j d n z i 7 M W V F x p c N 5 g Z l e C F 2 0 8 s L W J x b V N L s D q 3 m M H W M 2 A B y k s o D H p 7 d 8 N U X j / u S 4 R B + 1 m E e T j x V F q V D f D o B Q D s T B q D I i 4 g C A J M F I A S I R Y h Q H g w r 4 A S P e G t w q k w 9 Y L S V E g i w r E o R M P x X c x T p E g h 4 r T u s s h M T d y Y i Z Q 7 N 6 y O U R V N I S 4 c V D I 7 Y A R 1 M 9 7 + o z G R + r P Z 2 q x 2 I M c D 5 W W k Z u a M L x d P H l q d / m j k 0 V x n u 1 Q 5 0 O s T U g s P e 7 Q 5 b I q l Y I s x F w r n N L 1 P Q V x U V J T y 1 v W 2 y t Z + H y / x L z H l q R t 7 M G u 9 b H c f R z / b Z I 0 C s Y K i y U B G W x o P E 7 / l s m X y 7 r 6 / Z 6 8 1 r O 8 9 + S 2 P Y R t w A q F H 8 v e g q 1 B F 4 O 9 k 6 G i d h W U d j l u 6 3 W O k z + l l F T S U d z i s t 0 y v 5 X 8 U a l U K r i Q I Q h k T x u c E R v J 1 3 m q L M C 4 n J n u d 8 N o z 5 N O r 2 U d n D 0 e b R 2 L r V s u 3 z V x 0 b / W V 9 0 X r f F l a V v K m y X c q u Z 5 N m 8 2 a h F Q 2 f S c R p d s 0 / w 7 d z b O P W 6 d 5 D w Y H r 9 9 c h O W y x Z b Z 6 a w t y K t 7 U N S U J K i W O I P 6 H 8 Z t S h w D R E / Q d 5 0 g n C 0 p e O o U 4 U B O x d V s 1 g C d i 4 7 x j B 0 O c e 8 j 4 T V N m D 7 G 0 E C P J j t d q i N I 1 1 N c p p V l o n u G 8 9 + + z G i 8 2 f 9 A J e B P P g 2 E S 2 M S A 5 = O = k < / l a t e x i t > 4

Entity

Attributes

Bucketing

Breakdown

Figure 1: An example of our evaluation methodology. eLen (entity length) represents one of the attributes (detailed in Sec. 3.1) of the entity “New York”. After bucketing, performance can be broken down over different attribute values.

among diverse systems. Second, it is hard to improve what we do not understand; if an engineer or researcher looking to make model improvements cannot tell where the model is failing, it is also hard to decide which methodological improvements to try next.
To alleviate this problem, a few works (Ichihara et al., 2015; Derczynski et al., 2015) have attempted to perform ﬁne-grained error analysis of NER systems. While a step in the right direction, these analyses frequently rely upon labor-intensive manual examination and also customarily depend on pre-existing error typologies encoding assumptions about the errors a system is likely to make.
Orthogonally, some other works (Qian et al., 2018; Hu et al., 2020; Luo et al., 2020; Li et al., 2020; Lin et al., 2020) evaluate holistic metrics such as F1 across multiple datasets that differ in domain, language, or other characteristics (Sang and De Meulder, 2003; Collobert et al., 2011; Weischedel et al., 2013). Although this enables us to more comprehensively assess the models, the reliance on holistic metrics precludes a ﬁner-grained view of how various aspects of the model performance vary across the different settings.
In this paper, we argue that an ideal evaluation methodology should be (1) fully or partially automatic, (2) allow evaluation and comparison across multiple datasets, and (3) allow users to dig deeper into ﬁne-grained strengths and weaknesses of each model. To this end, we devise a generalized, ﬁne-

Attributes < l a t e x i t s h a 1 _ b a s e 6 4 = " e x m 3 h q 6 e w d Q K V K 0 K A W c d R p 8 x 4 + A = " > A A A C z X i c j V H L T s M w E J y G V 3 k X O H K J q J A 4 V U k v 9 F j E h R t F o g 9 R K p S k b r G a l 2 w H q S p w 5 Q e 4 w m 8 h / g D + g r V J J a B C 4 C j J e H Z n 7 N 3 1 0 5 B L 5 T i v B W t u f m F x q b i 8 s r q 2 v r F Z 2 t p u y S Q T A W s G S Z i I j u 9 J F v K Y N R V X I e u k g n m R H 7 K 2 P z r W 8 f Y N E 5 I n 8 b k a p 6 w X e c O Y D 3 j g K a I u j p Q S 3 M 8 U k 1 e l s l N x z L J n g Z u D M v L V S E o v u E Q f C Q J k i M A Q Q x E O 4 U H S 0 4 U L B y l x P U y I E 4 S 4 i T P c Y Y W 0 G W U x y v C I H d F 3 S L t u z s a 0 1 5 7 S q A M 6 J a R X k N L G P m k S y h O E 9 W m 2 i W f G W b O / e U + M p 7 7 b m P 5 + 7 h U R q 3 B N 7 F + 6 a e Z / d b o W h Q F q p g Z O N a W G 0 d U F u U t m u q J v b n + p S p F D S p z G f Y o L w o F R T v t s G 4 0 0 t e v e e i b + Z j I 1 q / d B n p v h X d + S B u z + H O c s a F U r r l N x z 6 r l e i 0 f d R G 7 2 M M B z f M Q d Z y g g S Z 5 x 3 j E E 5 6 t U y u z b q 3 7 z 1 S r k G t 2 8 G 1 Z D x + N u p N 6 < / l a t e x i t >

< l a t e x i t s h a 1 _ b a s e 6 4 = " O y E F O 8 8 P R z Y u S 5 u j 6 q w w l W 4 v U l k = " > A A A C z X i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 l E 0 G X B j R u x g n 1 g L Z J M p 3 V o m g n J R C l V t / 6 A W / 0 t 8 Q / 0 L 7 w z p q A W 0 Q l J z p x 7 z 5 m 5 9 / p R I B L l O K 8 5 a 2 p 6 Z n Y u P 1 9 Y W F x a X i m u r t U T m c a M 1 5 g M Z N z 0 v Y Q H I u Q 1 J V T A m 1 H M v Y E f 8 I b f P 9 T x x j W P E y H D M z W M e H v g 9 U L R F c x T R J 0 f y w 4 P d m 5 E w i + L J a f s m G V P A j c D J W S r K o s v u E A H E g w p B u A I o Q g H 8 J D Q 0 4 I L B x F x b Y y I i w k J E + e 4 Q 4 G 0 K W V x y v C I 7 d O 3 R 7 t W x o a 0 1 5 6 J U T M 6 J a A 3 J q W N L d J I y o s J 6 9 N s E 0 + N s 2 Z / 8 x 4 Z T 3 2 3 I f 3 9 z G t A r M I V s X / p x p n / 1 e l a F L o 4 M D U I q i k y j K 6 O Z S 6 p 6 Y q + u f 2 l K k U O E X E a d y g e E 2 Z G O e 6 z b T S J q V 3 3 1 j P x N 5 O p W b 1 n W W 6 K d 3 1 L G r D 7 c 5 y T o L 5 b d p 2 y e 7 p b q u x l o 8 5 j A 5 v Y p n n u o 4 I j V F E j 7 x C P e M K z d W K l 1 q 1 1 / 5 l q 5 T L N O r 4 t 6 + E D y t a T J Q = = < / l a t e x i t >Mo < l a t e x i t s h a 1 _ b a s e 6 4 = " U J M d V N k i 5 / o z 4 6 W k r s b 3 7 H W v a p w = " > A A A C y X i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z K 2 m n Z X c C O 4 q d A X a J E k n d b Y v E w m Y i 2 u / A G 3 + m P i H + h f e G d M Q R d F J y Q 5 c + 4 9 Z + b e a 0 e e m 3 B d f 8 8 p C 4 t L y y v 5 1 c L a + s b m V n F 7 p 5 O E a e y w t h N 6 Y d y z r Y R 5 b s D a 3 O U e 6 0 U x s 3 z b Y 1 1 7 f C L i 3 T s W J 2 4 Y t P g k Y n 3 f G g X u 0 H U s T l S n Z d m a W r 4 q l n R N l 0 s l c F y p V U w C 1 b p 5 Z N Z V I w u V k K 1 m W H z D J Q Y I 4 S C F D 4 Y A n L A H C w k 9 F z C g I y K u j y l x M S F X x h k e U S B t S l m M M i x i x / Q d 0 e 4 i Y w P a C 8 9 E q h 0 6 x a M 3 J q W K A 9 K E l B c T F q e p M p 5 K Z 8 H O 8 5 5 K T 3 G 3 C f 3 t z M s n l u O a 2 L 9 0 s 8 z / 6 k Q t H E P U Z A 0 u 1 R R J R l T n Z C 6 p 7 I q 4 u f q j K k 4 O E X E C D y g e E 3 a k c t Z n V W o S W b v o r S X j H z J T s G L v Z L k p P s U t a c C z K a r z Q a e s G b p m n J d L j W o 2 6 j z 2 s I 9 D m q e J B k 7 R R J u 8 b / C M F 7 w q Z 8 q t c q 8 8 f K c q u U y z i 1 9 L e f o C b R G R A g = = < / l a t e x i t >dTela-b.wis2e

< l a t e x i t s h a 1 _ b a s e 6 4 = " K m M 6 Z h N N R t O c e i P a o o v X M L z e q S 4 = " > A A A C y X i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z J a j M u C I I K b C v Y B t U i S T u v Y v E w m Y i 2 u / A G 3 + m P i H + h f e G d M Q R d F J y Q 5 c + 4 9 Z + b e 6 8 Y + T 4 V p v h e 0 u f m F x a X i c m l l d W 1 9 o 7 y 5 1 U q j L P F Y 0 4 v 8 K O m 4 T s p 8 H r K m 4 M J n n T h h T u D 6 r O 2 O j m W 8 f c e S l E f h h R j H r B c 4 w 5 A P u O c I o l o n f G j o t a t y x T R M t X Q C h 9 a B X S V Q s 2 3 T t n Q r D 1 W Q r 0 Z U f s M l + o j g I U M A h h C C s A 8 H K T 1 d W D A R E 9 f D h L i E E F d x h k e U S J t R F q M M h 9 g R f Y e 0 6 + Z s S H v p m S q 1 R 6 f 4 9 C a k 1 L F H m o j y E s L y N F 3 F M + U s 2 V n e E + U p 7 z a m v 5 t 7 B c Q K X B P 7 l 2 6 a + V + d r E V g g C N V A 6 e a Y s X I 6 r z c J V N d k T f X f 1 Q l y C E m T u I + x R P C n l J O + 6 w r T a p q l 7 1 1 V P x D Z U p W 7 r 0 8 N 8 O n v C U N e D p F f T Z o V Q 3 L N K z z a q V e y 0 d d x A 5 2 s U / z t F H H K R p o k v c N n v G C V + 1 M u 9 X u t Y f v V K 2 Q a 7 b x a 2 l P X z r v k O w = < / l a t e x i t >
AtFtriigb. u4te-wise < l a t e x i t s h a 1 _ b a s e 6 4 = " T 0 8 N T b z v V z q T X r g 6 V t F D q D W f e P I = " > A A A C 0 X i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 m K o M u K G 5 c V 7 Q N q l W Q 6 r U P T J E w m S i m C u P U H 3 O p P i X + g f + G d M Y J a R C c k O X P u P W f m 3 u v H g U i U 4 7 z k r K n p m d m 5 / H x h Y X F p e a W 4 u t Z I o l Q y X m d R E M m W 7 y U 8 E C G v K 6 E C 3 o o l 9 4 Z + w J v + 4 F D H m 1 d c J i I K T 9 U o 5 p 2 h 1 w 9 F T z B P E X V + o J Q U f q r 4 z r V I + E W x 5 J Q d s + x J 4 G a g h G z V o u I z z t B F B I Y U Q 3 C E U I Q D e E j o a c O F g 5 i 4 D s b E S U L C x D l u U C B t S l m c M j x i B / T t 0 6 6 d s S H t t W d i 1 I x O C e i V p L S x R Z q I 8 i R h f Z p t 4 q l x 1 u x v 3 m P j q e 8 2 o r + f e Q 2 J V b g k 9 i / d Z + Z / d b o W h R 7 2 T Q 2 C a o o N o 6 t j m U t q u q J v b n + p S p F D T J z G X Y p L w s w o P / t s G 0 1 i a t e 9 9 U z 8 1 W R q V u 9 Z l p v i T d + S B u z + H O c k a F T K r l N 2 j y u l 6 m 4 2 6 j w 2 s I l t m u c e q j h C D X X y l n j A I 5 6 s E 2 t k 3 V p 3 H 6 l W L t O s 4 9 u y 7 t 8 B p Q S V E A = = < / l a t e x i t >

Tab . < l a t e x i t s h a 1 _ b a s e 6 4 = " F b h u B G h U N / d 5 l e P X A K 7 v q s G o L T c = " > A A A C y X i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z K 2 m n Z X c C O 4 q d A X a J E k n d b Y v E w m Y i 2 u / A G 3 + m P i H + h f e G d M Q R d F J y Q 5 c + 4 9 Z + b e a 0 e e m 3 B d f 8 8 p C 4 t L y y v 5 1 c L a + s b m V n F 7 p 5 O E a e y w t h N 6 Y d y z r Y R 5 b s D a 3 O U e 6 0 U x s 3 z b Y 1 1 7 f C L i 3 T s W J 2 4 Y t P g k Y n 3 f G g X u 0 H U s T l S n Z d m a W r k q l n R N l 0 s l c F y p V U w C 1 b p 5 Z N Z V I w u V k K 1 m W H z D J Q Y I 4 S C F D 4 Y A n L A H C w k 9 F z C g I y K u j y l x M S F X x h k e U S B t S l m M M i x i x / Q d 0 e 4 i Y w P a C 8 9 E q h 0 6 x a M 3 J q W K A 9 K E l B c T F q e p M p 5 K Z 8 H O 8 5 5 K T 3 G 3 C f 3 t z M s n l u O a 2 L 9 0 s 8 z / 6 k Q t H E P U Z A 0 u 1 R R J R l T n Z C 6 p 7 I q 4 u f q j K k 4 O E X E C D y g e E 3 a k c t Z n V W o S W b v o r S X j H z J T s G L v Z L k p P s U t a c C z K a r z Q a e s G b p m n J d L j W o 2 6 j z 2 s I 9 D m q e J B k 7 R R J u 8 b / C M F 7 w q Z 8 q t c q 8 8 f K c q u U y z i 1 9 L e f o C b 3 G R A w = = < / l a t e x i t >

3

Bucket-wise < l a t e x i t s h a 1 _ b a s e 6 4 = " 3 h x K m p c y E A U r D 7 i U + X V U 6 o + C e / U = " > A A A C z n i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w Y 0 m K o M u i G 5 c V 7 A N q k W Q 6 r U P T J E w m l V K K W 3 / A r X 6 W + A f 6 F 9 4 Z U 1 C L 6 I Q k Z 8 4 9 5 8 7 c e / 0 4 E I l y n N e c t b C 4 t L y S X y 2 s r W 9 s b h W 3 d x p J l E r G 6 y w K I t n y v Y Q H I u R 1 J V T A W 7 H k 3 t A P e N M f n O t 4 c 8 R l I q L w S o 1 j 3 h l 6 / V D 0 B P M U U e 2 z l A 2 4 O r o T C b 8 p l p y y Y 5 Y 9 D 9 w M l J C t W l R 8 w T W 6 i M C Q Y g i O E I p w A A 8 J P W 2 4 c B A T 1 8 G E O E l I m D j H F A X y p q T i p P C I H d C 3 T 7 t 2 x o a 0 1 z k T 4 2 Z 0 S k C v J K e N A / J E p J O E 9 W m 2 i a c m s 2 Z / y z 0 x O f X d x v T 3 s 1 x D Y h V u i f 3 L N 1 P + 1 6 d r U e j h 1 N Q g q K b Y M L o 6 l m V J T V f 0 z e 0 v V S n K E B O n c Z f i k j A z z l m f b e N J T O 2 6 t 5 6 J v x m l Z v W e Z d o U 7 / q W N G D 3 5 z j n Q a N S d p 2 y e 1 k p V Y + z U e e x h 3 0 c 0 j x P U M U F a q i b j j / i C c 9 W z R p Z U + v + U 2 r l M s 8 u v i 3 r 4 Q P 3 j J O c < / l a t e x i t >

M< l a t e x i t s h a 1 _ b a s e 6 4 = " m Z r Q r u e d Z n l g Z Y H L / 8 i p T B y L C t A = " > A A A C y X i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V Z J u F F c F N 4 I I F e w D a p F k O q 2 x a S Z O J m I t r v w B t / p j 4 h / o X 3 h n T E E t o h O S n D n 3 n j N z 7 / X j M E i U 4 7 z m r J n Z u f m F / G J h a X l l d a 2 4 v t F I R C o Z r z M R C t n y v Y S H Q c T r K l A h b 8 W S e 0 M / 5 E 1 / c K j j z R s u k 0 B E Z 2 o U 8 8 7 Q 6 0 d B L 2 C e I q p x I r o 8 T C 6 K J a f s m G V P A z c D J W S r J o o v O E c X A g w p h u C I o A i H 8 J D Q 0 4 Y L B z F x H Y y J k 4 Q C E + e 4 R 4 G 0 K W V x y v C I H d C 3 T 7 t 2 x k a 0 1 5 6 J U T M 6 J a R X k t L G D m k E 5 U n C + j T b x F P j r N n f v M f G U 9 9 t R H 8 / 8 x o S q 3 B J 7 F + 6 S e Z / d b o W h R 7 2 T Q 0 B 1 R Q b R l f H M p f U d E X f 3 P 5 S l S K H m D i N u x S X h J l R T v p s G 0 1 i a t e 9 9 U z 8 z W R q V u 9 Z l p v i X d + S B u z + H O c 0 a F T K r l N 2 T y u l 6 k E 2 6 j y 2 s I 1 d m u c e q j h C D X X y v s I j n v B s H V v X 1 q 1 1 9 5 l q 5 T L N J r 4 t 6 + E D u 1 K R k Q = = < / l a t e x i t > o

dels

Holistic-metric < l a t e x i t s h a 1 _ b a s e 6 4 = " / h 5 s m Q S W T Q F c l A c N 3 G H o q q Z O R a 0 = " > A A A C 1 H i c j V H L S s N A F D 3 G V 6 2 P R l 2 6 C R b B j S U R Q Z e C m y 4 r 2 A d o k W Q 6 6 m C S C Z O J U N S V u P U H 3 O o 3 i X + g f + G d M Q W 1 i E 5 I c u b c c + 7 M v T f K Y p F r 3 3 + d c C a n p m d m K 3 P V + Y X F p Z q 7 v N L J Z a E Y b z M Z S 9 W L w p z H I u V t L X T M e 5 n i Y R L F v B t d H p h 4 9 4 q r X M j 0 S A 8 z 3 k / C 8 1 S c C R Z q o k 7 d W l O a U w T b S r h W g p 2 6 d b / h 2 + W N g 6 A E d Z S r J d 0 X n G A A C Y Y C C T h S a M I x Q u T 0 H C O A j 4 y 4 P q 6 J U 4 S E j X P c o k r e g l S c F C G x l / Q 9 p 9 1 x y a a 0 N z l z 6 2 Z 0 S k y v I q e H D f J I 0 i n C 5 j T P x g u b 2 b C / 5 b 6 2 O c 3 d h v S P y l w J s R o X x P 7 l G y n / 6 z O 1 a J x h z 9 Y g q K b M M q Y 6 V m Y p b F f M z b 0 v V W n K k B F n 8 I D i i j C z z l G f P e v J b e 2 m t 6 G N v 1 m l Y c 2 e l d o C 7 + a W N O D g 5 z j H Q W e 7 E f i N 4 H C 7 v r 9 T j r q C N a x j k + a 5 i 3 0 0 0 U L b z v w R T 3 h 2 O s 6 N c + f c f 0 q d i d K z i m / L e f g A M O a V o g = = < / l a t e x i t >

Tab . < l a t e x i t s h a 1 _ b a s e 6 4 = " Q I 8 4 i 3 4 M c c F v S T g T I l z 1 n g C B k 5 E = " > A A A C y X i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w F Z K 2 m n Z X c C O 4 q d A X a J E k n d b Y v E w m Y i 2 u / A G 3 + m P i H + h f e G d M Q R d F J y Q 5 c + 4 9 Z + b e a 0 e e m 3 B d f 8 8 p C 4 t L y y v 5 1 c L a + s b m V n F 7 p 5 O E a e y w t h N 6 Y d y z r Y R 5 b s D a 3 O U e 6 0 U x s 3 z b Y 1 1 7 f C L i 3 T s W J 2 4 Y t P g k Y n 3 f G g X u 0 H U s T l S n Z d m a a l w V S 7 q m y 6 U S O K 7 U K i a B a t 0 8 M u u q k Y V K y F Y z L L 7 h E g O E c J D C B 0 M A T t i D h Y S e C x j Q E R H X x 5 S 4 m J A r 4 w y P K J A 2 p S x G G R a x Y / q O a H e R s Q H t h W c i 1 Q 6 d 4 t E b k 1 L F A W l C y o s J i 9 N U G U + l s 2 D n e U + l p 7 j b h P 5 2 5 u U T y 3 F N 7 F + 6 W e Z / d a I W j i F q s g a X a o o k I 6 p z M p d U d k X c X P 1 R F S e H i D i B B x S P C T t S O e u z K j W J r F 3 0 1 p L x D 5 k p W L F 3 s t w U n + K W N O D Z F N X 5 o F P W D F 0 z z s u l R j U b d R 5 7 2 M c h z d N E A 6 d o o k 3 e N 3 j G C 1 6 V M + V W u V c e v l O V X K b Z x a + l P H 0 B a r G R A Q = = < / l a t e x i t >

1

Datasets < l a t e x i t s h a 1 _ b a s e 6 4 = " 7 i b i t Q e y O t 1 2 / 2 5 o 2 O 8 D k O 9 O M X 4 = " > A A A C y 3 i c j V H L S s N A F D 2 N r 1 p f V Z d u g k V w V Z J u F F c F X b g R K t g H 1 C J J O q 1 D 8 2 J m I t T q 0 h 9 w q / 8 l / o H + h X f G F N Q i O i H J m X P P u T P 3 X j 8 N u V S O 8 1 q w 5 u Y X F p e K y 6 W V 1 b X 1 j f L m V k s m m Q h Y M 0 j C R H R 8 T 7 K Q x 6 y p u A p Z J x X M i / y Q t f 3 R s Y 6 3 b 5 i Q P I k v 1 D h l v c g b x n z A A 0 8 R 1 T n x F J m V v C p X n K p j l j 0 L 3 B x U k K 9 G U n 7 B J f p I E C B D B I Y Y i n A I D 5 K e L l w 4 S I n r Y U K c I M R N n O E e J f J m p G K k 8 I g d 0 X d I u 2 7 O x r T X O a V x B 3 R K S K 8 g p 4 0 9 8 i S k E 4 T 1 a b a J Z y a z Z n / L P T E 5 9 d 3 G 9 P f z X B G x C t f E / u W b K v / r 0 7 U o D H B o a u B U U 2 o Y X V 2 Q Z 8 l M V / T N 7 S 9 V K c q Q E q d x n + K C c G C c 0 z 7 b x i N N 7 b q 3 n o m / G a V m 9 T 7 I t R n e 9 S 1 p w O 7 P c c 6 C V q 3 q O l X 3 v F a p H + W j L m I H u 9 i n e R 6 g j l M 0 0 D R z f M Q T n q 0 z S 1 q 3 1 t 2 n 1 C r k n m 1 8 W 9 b D B w X X k n o = < / l a t e x i t >

Figure 2: Relations among attributes, models, and datasets.

grained, and multi-dataset evaluation methodology for the task of NER, as demonstrated in Fig. 1. Speciﬁcally, it leverages the notion of “attributes”, values which characterize the properties of an entity that may be correlated with the NER performance (e.g. entity length in words). Afterward, we partition test entities into a set of buckets based on the entity’s attributes, where entities in different buckets may have different performance scores on average (e.g. entities with more words may be predicted less accurately).
Methodologically, our evaluation framework allows for three analytical views as elucidated in Fig. 2. Model-wise (Sec. 5.1) analysis investigates how the performances of different models vary according to attribute value (e.g. “Is a model with a CRF layer better at dealing with long entities?”). Attribute-wise (Sec. 5.2) analysis compares how different attributes affect performance on different datasets (e.g. “Does entity length correlate with model performance on all datasets or just some?”). Bucket-wise (Sec. 5.3) compares among all possible analysis dimensions, and can diagnose the strengths and weaknesses of existing models (e.g. “What entity attributes indicate that a BERTbased model will likely fail?”), or help us understand how different choices of datasets inﬂuence model performance (e.g. “On which datasets is using a CRF layer more appropriate?”).
Experimentally, we conduct a comprehensive analysis over twelve models, eight attributes, and six datasets. Proposed quantiﬁable measures allow us to draw several qualitative conclusions as highlighted below: 1) label consistency (the degree of label agreement of an entity on the training set) and entity length have a consistent inﬂuence on NER task’s performance (Sec. 5.2.2); 2) CRF-based systems are more likely to make a mistake compared with MLP-based systems when dealing with long entities (Sec. 5.1.2); 3) Higher-frequency tokens of a test entity cannot guarantee better performance since other crucial factors such as label consistency

also matter (Sec. 5.2.2); 4) Even more advanced models (e.g., BERT, Flair) fail to predict entities with low label consistency (Sec. 5.3.2).
Finally, motivated by observation 4), we present an effective solution to improve current NER systems. Quantitative and qualitative experiments demonstrate that introducing larger context is an effective method, obtaining improvements of up to 10 points in F1 score on some datasets.
2 Background
Task Description NER is frequently formulated as a sequence labeling problem (Chiu and Nichols, 2015; Huang et al., 2015; Ma and Hovy, 2016; Lample et al., 2016), where X = {x1, x2, . . . , xT } is an input sequence and Y = {y1, y2, . . . , yT } are the output labels (e.g., “B-PER”, “I-LOC”, “O”). The goal of this task is to accurately predict entities by assigning output label yt for each token xt: P (Y |X) = P (yt|X, y1, · · · , yt−1)
Standard Evaluation Strategy for NER The common evaluation metric for NER systems (Sang and De Meulder, 2003) is to compute a corpuslevel metric using micro-averaged F 1 score: F 1 = 2×PP+×RR : where P is the percentage of named entities output by learning system that are correct. R is the percentage of gold entities identiﬁed by the system. Here a named entity is correct only if it is an exact match of an annotated entity.
3 Attribute-aided Evaluation
Our proposed attribute-aided evaluation methodology involves two key elements: attribute deﬁnition and bucketing. We ﬁrst deﬁne diverse attributes for each entity, by which test entities are partitioned into different buckets. We then calculate the performance for each bucket of test entities.
3.1 Attribute Deﬁnition
Attributes are deﬁned either over a span or a token and characterize the diverse properties thereof. In practice, the span will be instantiated as a genuine or a mis-predicted entity (calculating precision) in the test set, while tokens can be any token in the test corpus. We classify attributes into two categories: local attributes and aggregate attributes.
Local attributes are calculated with respect to a span or token regarding attributes of the span/token itself, its label, or the sentence in which the span appeared. We deﬁne a token x or span x, to have a

Life in New York is fun .
New York

eLen 2
Entity Length

sLen 7
Sentence Length

oDen .0
OOV Density

eDen .29
Entity Density

tCon tFre eCon eFre .3, .6 (2.6,.7)E-3 .53 1.4E-4
Label Con. Token Label Con. Entity of Token Frequency of Entity Frequency

Local Attributes

Aggregation Attributes

Figure 3: The eight attributes deﬁned in this paper and corresponding values with respect to the entity “New York” in the sentence “Life in New York is fun .”. The text in orange is the full name of the attribute, in which Con. denotes Consistency.

gold-standard or predicted label y = lab(·),1 which occurs in sentence X = sent(x). We also deﬁne two functions that count the number of words outside the training set2 oov(·) and the number of entities ent(·) in a sequence of words. Based on this, we deﬁne several feature functions φ(x) that can compute different attributes of each span:
• φstr(x) = x: span surface string • φlabel(x) = lab(x): entity span label • φeLen(x) = |x|: entity span length
We additionally deﬁne feature functions over tokens φ(x):
• φstr(x) = x: token surface string • φlabel(x) = lab(x): token label
We also deﬁne several features of the underlying sentence, which can be applied to either spans x or tokens x; we show the example of applying to token x below:
• φsLen(x) = |sent(x)|: sentence length • φeDen(x) = |ent(sent(x))|/φsLen(x):
entity density • φoDen(x) = |oov(sent(x))|/φsLen(x):
OOV density
Aggregate attributes are properties of spans or tokens based on aggregate statistics that require calculation over the whole training corpus. To calculate these attributes, we ﬁrst deﬁne Etr as all spans/tokens in the training set. We then deﬁne an aggregation function that takes a particular span/token (example of tokens below), feature function φ(·), and span set E ⊆ Etr as arguments:
F(x, φ(·), E) = |{ε|φ(ε) = φ(x), ∀ε ∈ E}| , (1) |E |

1y is a simple entity label for tokens, and does not distin-
guish between “B” and “I” in the BIO tagging scheme. 2Not considering the vocabulary of pre-trained models.

calculating the ratio of spans/tokens in E that have the same feature value φ(·) as x. We can deﬁne E := Etr, calculating statistics over the entire train-
ing set. We can also choose it to be only the
spans/tokens with a particular surface form:

Ex := {ε|φstr(ε) = φstr(x), ε ∈ Etr}. (2)

Based on the above general formulation, we de-

ﬁned a few speciﬁc instantiations that we use in the

following experiments. First, entity frequency and

token frequency:

φeFre(x) := F (x, φstr(·), Etr)

(3)

φtFre(x) := F (x, φstr(·), Etr)

(4)

Besides, we use two consistency-based attributes,

which attempt to measure how consistently a par-

ticular span/token is labeled with a particular label: φeCon(x) := F (x, φlabel(·), Etr) (5)

φtCon(x) := F (x, φlabel(·), Etr) (6)

We give an example to illustrate above by setting

x = “New York” with gold label “LOC”. There-

fore, the numerator of φeCon tallies entities “New

York” with label “LOC” in training set, while

the denominator counts spans “New York”. The

overall ratio quantiﬁes the degree of label consis-

tency in train set for a given span “New York”.

3.2 Bucketing
Bucketing is an operation that breaks down the holistic performance into different categories (Neubig et al., 2019; Fu et al., 2020b). This can be achieved by dividing the set of test entities into different subsets of test entities (regarding spanand sentence-level attributes) or test tokens (regarding token-level attributes). Here we describe the entity-based bucketing strategies, which can also be similarly applied to token-based strategies. The bucketing process can be expressed in the following general form:
E1te, · · · , Emte = Bucket(Ete, φ(·)) (7) where Ete represents a set of test entities or tokens, and m is the number of buckets. φ(·) denotes one type of feature functions (as deﬁned in Sec. 3.1) to calculate attribute value for a given entity (e.g., φeLen(x) to compute span length). Speciﬁcally, we divide the range of attribute values into m discrete parts, whose intervals can be obtained mainly based on two ways: 1) dividing value range evenly 2) dividing test entities or tokens equally. In practice, the way to obtain intervals may be diverse for different attributes.3 We
3We have implemented ﬂexible functions to do this as users need in our released code.

detail our settings in the appendix. Finally, once we have generated buckets, we calculate the F1 score with respect to entities (or tokens) of each bucket. We can easily extend the attribute-aided evaluation to other tasks, such as Chinese Word Segmentation (Fu et al., 2020a).
4 Experimental Settings
In this section we describe our experimental settings, each of which is followed by an experiment and analysis results.
4.1 NER Datasets for Evaluation
We conduct experiments on: CoNLL-2003 (CoNLL), 4 WNUT-2016 (WNUT),5 and OntoNotes 5.0 dataset. 6 The CoNLL dataset (Sang and De Meulder, 2003) is based on Reuters data (Collobert et al., 2011). The WNUT dataset (Strauss et al., 2016) is provided by the second shared task at WNUT-2016 and consists of social media data from Twitter. The OntoNotes 5.0 dataset (Weischedel et al., 2013) is collected from broadcast news (BN), broadcast conversation (BC), weblogs (WB), and magazine genre (MZ).
4.2 Models
We varied the evaluated models mainly in terms of four aspects: 1) character/subword-sensitive encoder: ELMo (Peters et al., 2018), Flair (Akbik et al., 2018, 2019), BERT 7 (Devlin et al., 2018)
2) additional word embeddings: GloVe (Pennington et al., 2014); 3) sentence-level encoders: LSTM (Hochreiter and Schmidhuber, 1997), CNN (Kalchbrenner et al., 2014; Chen et al., 2019); 4) decoders: MLP or CRF (Lample et al., 2016; Collobert et al., 2011). In total, we study 12 NER models and we give more detailed description of models in the appendix. Detailed model settings are illustrated in Tab.1. We use the result from the model with the best development set performance, terminating training when the performance on development is not improved in 20 epochs.
4.3 Holistic Analysis
Before giving a ﬁne-grained analysis, we present the results of different models on different datasets
4https://www.clips.uantwerpen.be/conll2003/ner/ 5https://noisy-text.github.io/2016/ner-shared-task.html 6https://catalog.ldc.upenn.edu/LDC2013T19 7The reason why we group BERT into a subword-sensitive encoder is that we use it to obtain the representation of each subword.

as traditional multi-dataset evaluation does. As Tab. 1 demonstrates, there is no one-size-ﬁts-all model; different models get the best results on different datasets. Naturally, this raises the following questions: 1) what factors of the datasets significantly inﬂuence NER performance? 2) how do these factors inﬂuence the choices of models? 3) does a worse-ranked model outperform the bestranked model in some aspects and how do datasets inﬂuence the choices of models? The following analyses will investigate these questions.

5 Fine-grained Analysis

To better characterize the relationship among mod-
els, attributes, and datasets, we propose three analy-
sis approaches: model-, attribute-, and bucket-wise. Formally, we refer to M = {m1, · · · , m|M|}
as a set of models and Φ = {φ1, · · · , φ|Φ|} as a set of attributes. As described in Sec. 3.2, the test set E could be split into different buckets of E = {E1j, · · · , E|jE|} based on an attribute φj. We introduce the concept of a performance table T ∈ R|M|×|Φ|×|E|, whose element Tijk represents the performance (F 1 score) of i-th model on the kth sub-test set (bucket) generated by j-th attribute.
Next, we will explain how above-mentioned analysis approaches are deﬁned based on T .

5.1 Exp-I: Model-wise Analysis
Model-wise analysis investigates how different attributes inﬂuence performance of models with different architectures and initializations, e.g. “does eLen inﬂuence performance of a CNN-LSTM-CRF-based NER system?”

5.1.1 Approach

Here we adopt two types of statistical variables Sρi,j and Sσi,j to characterize how the j-th attribute inﬂuences the of performance i-th model.

Sρi,j = Spearman(T [i, j :], Rj)

(8)

Sσi,j = Std(T [i, j :])

(9)

where Spearman is a function to calculate the
Spearman’s rank correlation coefﬁcient (Mukaka,
2012) and Rj is the rank values of buckets based on the j-th attribute. Std(·) is the function to compute
the standard deviation. Intuitively, Sρi,j characterizes how well the per-
formance of the i-th model correlates with the values of the j-th attribute while Sσi,j measures the degree to which this attribute inﬂuences the model’s

Models

Char/Subword Word Sentence Decoder

Overall F1

none cnn elmo ﬂair bert none rand glove lstm cnn crf mlp

CoNLL WNUT BN BC MZ WB

CRF++ CnonWrandLstmCrf CcnnWnoneLstmCrf CcnnWrandLstmCrf

√ √ √

√√

√

√

√

√

√√

√

√

CcnnWgloveLstmCrf √

CcnnWgloveCnnCrf

√

CcnnWgloveLstmMlp

√√

√

√

√√

√√

√

CelmWnoneLstmCrf CelmWgloveLstmCrf CbertWnoneLstmMlp CﬂairWnoneLstmCrf CﬂairWgloveLstmCrf

√

√

√

√√

√√

√

√ √√
√ √ √√

√ √
√ √ √

80.74 78.13 77.01 83.80
90.48 90.14 88.05
91.64 92.22 91.11 89.98 93.03

21.53 17.24 22.73 22.57

82.02 67.71 77.80 47.90 80.36 66.17 73.89 49.80 77.96 65.01 79.05 47.31 83.59 71.57 78.85 52.14

40.61 36.21 32.84

86.78 76.04 85.39 60.17 86.42 76.74 88.10 49.10 84.07 70.00 81.09 56.61

44.56 45.33 47.77 41.49 45.96

89.75 89.35 89.64 87.98 87.92

77.10 78.71 81.03 77.46 77.23

86.32 85.70 86.90 84.11 85.56

60.51 63.26 66.35 56.71 63.38

Table 1: Neural NER systems with different architectures. CRF++ is a Conditional Random Fields (Lafferty et al., 2001) method based on feature engineering. Bold is the best performance of a given dataset according to F1. For the model name, “C” refers to “Char/Subword” and “W” refers to “Word”. For example, ”CnonWrandLstmCrf ” is a model with no character features, with randomly initialized embeddings, and the sentence encoder is LSTM and decoder is CRF.

Spearman (Sρi,j )

Standard Deviation (Sσi,j )

eDen oDen sLen eCon tCon eFre tFre eLen eDen oDen sLen eCon tCon eFre tFre eLen

Model

F1

CRF++

55.00 -4 9 -10 87 79 96 56 -92 5.5 7.5 5.2 16.2 12.7 14.8 6.6 5.8

CnonWrandLstmCrf 60.93 -37 -2 -7 90 79 94 57 -92 5.9 8.2 4.4 21.2 16.3 21.3 9.9 7.8

CcnnWnoneLstmCrf 61.51 -11 -6 -7 77 85 95 49 -75 6.1 6.7 5.6 15.2 11.9 14.3 5.9 7.2

CcnnWrandLstmCrf 65.42 -19 5 -7 87 82 95 44 -92 5.5 7.3 4.0 16.0 12.5 15.5 6.6 8.8

CcnnWgloveLstmCrf 73.25 -23 2 -15 90 64 93 12 -92 5.7 6.6 4.0 12.0 9.2 14.9 5.2 9.0

CcnnWgloveCnnCrf 75.52 -16 -11 -25 90 65 88 0 -83 5.6 6.8 3.8 12.4 9.6 14.7 6.1 9.0

CcnnWgloveLstmMlp 68.78 -34 5 -17 93 63 97 3 -67 5.9 6.8 3.9 14.9 11.6 16.5 6.8 7.1

CelmWnoneLstmCrf 74.99 7 3 5 87 56 98 16 -83 5.8 6.6 4.1 11.5 8.5 13.6 4.9 6.5

CelmWgloveLstmCrf 75.76 -3 -8 -9 87 60 93 -2 -92 5.5 6.8 4.0 11.4 8.2 13.4 5.1 6.4

CbertWnoneLstmMlp 76.26 0 -12 0 83 56 87 17 -58 5.4 5.6 3.7 11.8 8.3 12.5 5.8 4.8

CﬂairWnoneLstmCrf 72.96 -25 7 -23 80 72 97 21 -83 5.6 6.4 4.1 12.2 9.1 13.6 5.3 6.6

CﬂairWgloveLstmCrf 75.51 -16 -11 8 87 67 91 24 -92 5.2 5.8 4.0 11.6 8.7 13.1 5.3 6.5

Table 2: Model-wise measures (Percentage) Sρi,j and Sσi,j which are the average over all the datasets. The F1 score for a model is also an average case on all the datasets. The value in grey denotes the attribute does not pass a signiﬁcance test (p ≥ 0.05). The values in green and in pink support observation 1 and observation 2, respectively. The bold is the maximum value in the attribute column.

performance. For example, SρCNN,eCon = 0.9 reveals that the performance of the CNN model positively and highly correlates with the attribute value eCon (label consistency). And a larger SσCNN,eCon implies that CNN model’s performance is heavily inﬂuenced by the factor eCon. Signiﬁcance Tests: We perform Friedman’s test (Zimmerman and Zumbo, 1993) with p = 0.05. We examine whether the performance of different buckets partitioned by an attribute have the same expected performance, and the signiﬁcance testing results are shown in appendix. We omit the attributes whose Sρi,j and Sσi,j are not statistically signiﬁcant (the values in grey in Tab. 2).
5.1.2 Observations Tab. 2 illustrates the average case of Sρi,j and Sσi,j on all datasets.8 We highlight some major observa-
8Correlations on individual datasets is in the Appendix.

tions and more are in the appendix. 1) The performance of character-unaware
models is more sensitive to the label consistency. We observe that the performances of CRF++ and CnonWrandLstmCrf are highly correlated with eCon, and tCon with high values of Sρ and Sσ. Speciﬁcally, CcnnWrandLstmCrf achieve higher performance and lower Sσ than CnonWrandLstmCrf. This suggests that the character-level encoder plays a major role in generalization to entities with low label consistency.
2) The inﬂuence of entity length varies greatly between different decoders. Entity length is strongly negatively correlated with the performance of models, which means the performance of the model will drop with the entity length increasing. We observe that the variance scores Sσ of CcnnWgloveLstmMlp and CbertWnoneLstmMlp are the smallest, compared with the variances of the models using non-contextualized and contextualized pre-trained embeddings, respectively. We attribute this to the structural biases of different decoders: MLP-based models have better robustness when dealing with long entities, while CRF-based models may lead to error propagation. We will present a detailed explanation of this in Sec. 5.3.2.
5.2 Exp-II: Attribute-wise Analysis
Attribute-wise analysis aims to quantify the degree to which an attribute inﬂuences NER performance overall, across all systems.
5.2.1 Approach
To achieve this, we introduce two dataset bias measures: task-independent variable ζj and taskdependent variable ρj based on Eq. 8:

eCon sLen oDen

eCon sLen oDen

WB MZ BC BN WNUT CoNLL

tCon eDen tCon eDen

eFre

eLen

eFre

eLen

tFre

tFre

(a) ζ

(b) ρ

Figure 4: DatMaWEset biases characterized by measures ζ and ρ. MWE
We normalize ζ on each attribute by dividing the maximum ζ on six datasets, and ρ ∈ [0, 1].

1N ζj(E, φ(·)) = N φj(x), (10)
i
|M |
ρj = |M1 | |Sρi,j |, (11) i
where E denotes a dataset, φj(x) is the feature function to calculate an attribute value for a given entity x, j denotes the j-th attribute function, and N and |M | are the numbers of test entities and models respectively.
For example, when j denotes the attribute of sentence length, ζj is the average sentence length of the whole dataset. Intuitively, a higher absolute value of ρj suggests that attribute j is a crucial factor, whose values heavily correlate with the performances of NER systems.
5.2.2 Observations
Similar to the above section, we conduct Friedman’s test at p = 0.05. For all attributes, we ﬁnd different-valued buckets are signiﬁcantly different in their expected performance (p < 0.05). We include a full version of p values in the appendix. Detailed observations are listed as follows:
1) Label consistency and entity length have a more consistent inﬂuence on NER performance. The common parts of the radar chart in Fig. 4(b) illustrate that for all datasets, the performance of the NER task is highly correlated with these attributes: tCon (label consisency of tokens), eCon (label consistency of entities), eLen (entity length). This reveals that the prediction difﬁculty of a named entity is commonly inﬂuenced by label consistency (tCon, eCon) and entity length (eLen).
2) Frequency and sentence length matter but are minor factors. The outliers in the radar chart highlight the peculiarities of different datasets. Intuitively, in Fig. 4(b), on these attributes: sLen, tFre, oDen, the extent to which different datasets

are affected varies greatly, and thus these attributes are not, in general, decisive factors for the NER task. Typically, as observed from Fig. 4(b), Spearman correlations of ρ on the attribute tFre vary greatly, i.e., a smaller ρ on BC and WB. This implies that tFre is not a decisive factor and higherfrequency tokens cannot guarantee better performance since other crucial factors such as label consistency also matter. We print the performance of the buckets with respect to token frequency, and ﬁnd that the bucket with higher token frequency does not achieve a better performance.
Understanding these intrinsic differences in datasets provides us with evidence to explain how different datasets may inﬂuence different choices of models, which will be elaborated later (Sec. 5.3).
5.3 Exp-III: Bucket-wise Analysis
Bucket-wise analysis aims to identify the buckets that satisfy some speciﬁc constraints. In this paper, we present two ﬂavors of diagnostic: self-diagnosis and comparative diagnosis.
5.3.1 Approach
Self-diagnosis Given a model M1 and a speciﬁc evaluation attribute (e.g., eLen), self-diagnosis selects the buckets in which test samples have achieved the highest and lowest performance (F1 score). Intuitively, this operation can help us diagnose under which conditions a particular model performs well or poorly: SelfDiag(M1) = argFunckT [M1, j, k] where argFunc can be instantiated as argMax and argMin.
Comparative diagnosis Given two models M1, M2 and an attribute, comparative diagnosis aims to select buckets in which the performance gap between the two systems achieve the highest and lowest values. This method can indicate under which conditions a particular system may have a relative advantage over another system: CoDiag(M1, M2) = argFunck(T [M1, j, k] − T [M2, j, k])
Signiﬁcance Tests We test for statistical significance at p = 0.05 with Wilcoxon’s signed-rank test (Wilcoxon et al., 1970). The null hypothesis is that, given a speciﬁc attribute value (e.g. long entities eLen:XL), two different models have the same expected performance.9
9We opt for Wilcoxon’s signed-rank test instead of Friedman’s test because the diagnosis (self- or comparative diagnosis) only has two group samples while the Friedman’s

CoNLL03

WNUT16

OntoNotes-MZ

OntoNotes-BC

OntoNotes-BN

OntoNotes-WB

eDen oDen sLen eCon eFre tCon tFre eLen eDen oDen sLen eCon eFre tCon tFre eLen eDen oDen sLen eCon eFre tCon tFre eLen eDen oDen sLen eCon eFre tCon tFre eLen eDen oDen sLen eCon eFre tCon tFre eLen eDen oDen sLen eCon eFre tCon tFre eLen

XS-XL L-XL S-XS S-XL
XS-XL XS-XL
XS-L L-S
XL-S XL-XS
S-L XS-XL
XS-S S-XL XL-S XL-S XS-L L-XS L-XL S-XL XS-XL XS-L XS-L L-XL
L-S XS-XL XL-XS
S-XL XS-L XS-XL XL-L
L-S XS-XL
S-XS XL-S XS-XL XS-L XS-XL XS-L XL-XS XS-S L-XS S-XL XS-L XS-L XS-L XS-L XL-S

Overall F1

M1: 91.11

100
95
M1: CbertWnoneLstmMlp 90 Self-diagnosis 85

M1: 47.77
80 60 40 20

M1: 86.90
100 90 80 70

M1: 81.03
100 90 80 70 60

M1: 89.64
100 90 80

M1: 66.35
100 80 60 40

Overall F1

M1: 90.48; M2: 88.05

5
M1: CcnnWgloveLstmCrf 0
M2: CcnnWgloveLstmMlp Comparative diagnosis −5

M1: 40.61; M2: 32.84
10 5 0 −5

M1: 85.39; M2: 81.09
20 10 0

M1: 76.04; M2: 70.00
15 10 5 0

M1: 86.78; M2: 84.07
5 0

M1: 60.17; M2: 56.61
10 0

-S XL-L
-L -S -XS -S -XL XL-XS -XL -XS -L L-XS XL-XS -L -XS -XS -XL -L -L XL-S L-XS S-XS XL-XS XL-XS -L -XS -S -S -XS XL-XS -XL -XS -XL XL-S -XL -S -XS -S -XL XL-XS -XL L-XL -XS XL-XS XL-XS L-S XS-XL -XL

Table 3: Self-diagnosis, and Comparative diagnosis (Sec. 5.3.1) of different NER systems. M1 and M2 denote two models. We classify the attribute values into four categories: extra-small (XS), small (S), large (L) and extra-large (XL). In the self-diagnosis histogram, green (red) x ticklabels represents the bucket value of a speciﬁc attribute on which system achieved best (worst) performance. Gray bins represent worst performance while blue bins denote the gap between best and worst performance. In the comparative diagnosis histogram, green (red) x ticklabels represents the bucket value of a speciﬁc attribute on which system M1 surpasses (under-performs) M2 by the largest margin that is illustrated by a green (red) bin.

5.3.2 Self-Diagnosis
BERT The ﬁrst row in Tab. 3 illustrates the selfdiagnosis of the model CbertWnonelstmMlp. The green (red) x ticklabels represent the bucket value of a speciﬁc attribute on which system has achieved best (worst) performance. Gray bins represent worst performance while blue bins denote the gap between best and worst performance.
We observe that large performance gaps (tall blue bins) commonly occur for the attributes label consistency and entity frequency, and the worst performance on these attributes was obtained on buckets with low consistency (eCon, tCon:XS/S) and low entity frequency (eFre:S).
We conduct signiﬁcance testing on the worst and best performances10 of eCon (1.7 × 10−8), tCon (2.3 × 10−7) and eFre (1.2 × 10−5) respectively, and they all passed with p < 0.05. This reveals that it is still challenging for contextualized pre-trained NER systems to handle entities with lower label consistency and lower entity frequency.
5.3.3 Comparative Diagnosis
We highlight major observations and include more analysis in the appendix.
CRF v.s. MLP The beneﬁts of using CRF on the sentence with high entity density (eDen:XL) are
test requires more than two groups (Zimmerman and Zumbo, 1993).
10We restarted the BERT-based system twice on six datasets, and we got 12 best and 12 worst F1 scores for a given attribute.

remarkably stable, and improvement can be seen in all datasets (p = 1.8 × 10−5 < 0.05). Similarly, based on attribute-wise metric ζ in Fig. 4(a), we ﬁnd label consistency (eCon, tCon) is a major factor for the choices of CRF and MLP layers:
1) Introducing a CRF achieves larger improvements on long entities once the dataset has a lower label consistency (e.g. ζeCon,tCon(WNUT), ζeCon,tCon(WB), and ζeCon,tCon(BC) are lowest). We conduct the signiﬁcance testing on CRF and MLP systems with respect to the long entities on these three datasets11 (WNUT, WB, and BC), and the result indicates that the performance of the CRF and MLP systems are signiﬁcantly different on long entity bucket (p = 6.5 × 10−4 < 0.05). 2) by contrast, if a dataset has a higher label consistency (ζeCon,tCon(CoNLL),ζeCon,tCon(BN), ζeCon,tCon(MZ) are highest), using the CRF layer does not exhibit signiﬁcant gains (even worse than models without CRF) on longer entities (eLen:XL). We do signiﬁcance testing like 1), and p = 5.1 × 10−3 < 0.05.
6 Application: Well-grounded Model Improvement
The purpose of interpretable evaluation and analysis is to provide more evidence for us to rethink current learning models and move forward. In what
11We restarted the CRF and MLP systems on WNUT, WB, and BC for 5 times, and we got 3 × 5 = 15 F1 scores on CRF and MLP systems respectively.

follows, we choose a piece of evidence observed from the above analysis and attempt to present one simple solution to improve the model. From Sec. 5.2 and Sec. 5.3.2, we know that label consistency is a decisive factor, and even more advanced models (e.g., BERT, Flair) fail to consistently predict entities with low label consistency. An intuitive idea to disambiguate these entities is using more contextual information. To this end, we shift the setting of traditional sentence-level training and testing to use larger context, and investigate this change’s effectiveness.
6.1 Experimental Setting
We choose CbertWnoneLstmMlp as a base model, which will be trained under different numbers (K = 1, 2, 3, 4, 5, 6, 10) of contextual sentences on all six datasets respectively. For example, K = 2 represents that each training sample is constructed by concatenating two consecutive sentences from the original dataset (K = 1).

0.3 0.2 0.1
0 −0.1 −0.2 2 3 4 5 6 10
(a) CoNLL
2
1.5
1
0.5
0 2 3 4 5 6 10
(d) BC

0.2
0
−0.2
−0.4 2 3 4 5 6 10
(b) BN
10 8 6 4 2 0
2 3 4 5 6 10
(e) WB

0
−0.5
−1 2 3 4 5 6 10
(c) MZ
0 −2 −4 −6 −8
2 3 4 5 6 10
(f) WNUT

Figure 5: Illustration of the improvement achieved by the larger context method with different sizes (K) on different datasets. The part above the red suggests the improvement brought by the corresponding value of K.

6.2 Results and Analysis
Results As presented in Fig. 5, the green line describes the relative improvement of the larger context method compared with the vanilla model (K = 1) with different numbers of context sentences K = 2, · · · , 10. In detail, we observed:
1) For most of the datasets (except “WNUT”), the performance increases as more context sentences are introduced. 2) Surprisingly, we achieved a 10.07 improvement (66.35 vs. 76.42, signiﬁcance testing result13: p = 5.1 × 10−3 < 0.05) F1
12We leave WNUT out due to its worse performance. 13We restart the system on WB with K = 1 and K = 6 setting for 10 times respectively.

(a) eCon (b) tCon (c) eFre

(d) tFre

(e) eDen (f) eLen (g) sLen (h) oDen Figure 6: The relative increase of the larger-context method on ﬁve datasets12 based on eight evaluation attributes. “Co” represents the dataset CoNLL-2003 while “wb”, “bc”, “mz”, “bn” denote different domains from the OntoNotes.
score on dataset “WB”, with such a simple largercontext training method. 3) There is no gain on “WNUT”, and the reason can be attributed to lack of dependency between samples, which are collected from Twitter14 where each sentence is relatively independent with the another.
Analysis using Multi-dimensional Evaluation To probe into where the gain afforded by larger context comes from, we use our proposed evaluation attributes to conduct a ﬁne-grained investigation, aiming to answer the question: how does this method inﬂuence different datasets’ performance seen from different attributes? (e.g., label consistency of entity, eCon). As expressed in Fig. 6, the value of each unit in the heat maps denotes the relative increase achieved by the larger-context method. Intuitively, a darker green area implies more significant improvement while a darker red unit suggests larger-context leads to worse performance.
Different evaluation attributes allow us to understand the source of improvement from diverse perspectives: 1) in terms of label consistency (eCon, tCon), test entities with lower label consistency will achieve larger improvements with the help of more contextual sentences. Importantly, from Fig. 6 we can see this observation holds true for all datasets. 2) in terms of entity length (eLen), largercontext information has no advantage in dealing with longer entities (L, XL). For example, in the three of ﬁve datasets, more contextual sentences lead to worse performance on longer test entities.
14https://twitter.com/

7 Discussion
This paper has provided a framework where we can covert our understanding of the NER task (i.e., which attributes matter for the current task?) into interpretable evaluation aspects, and deﬁne axes through which we can apply them to acquire insights and make model improvements. This is just a ﬁrst step towards the goal of fully-automated interpretable evaluation, and applications to new attributes and tasks beyond NER are promising future directions.
Acknowledgments
We would like to thank the anonymous reviewers for their valuable comments. This material is based on research sponsored by the Air Force Research Laboratory under agreement number FA8750-192-0200. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the ofﬁcial policies or endorsements, either expressed or implied, of the Air Force Research Laboratory or the U.S. Government.
References
Alan Akbik, Tanja Bergmann, and Roland Vollgraf. 2019. Pooled contextualized embeddings for named entity recognition. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 724–728.
Alan Akbik, Duncan Blythe, and Roland Vollgraf. 2018. Contextual string embeddings for sequence labeling. In Proceedings of the 27th International Conference on Computational Linguistics, pages 1638–1649.
Hui Chen, Zijia Lin, Guiguang Ding, Jianguang Lou, Yusen Zhang, and Borje Karlsson. 2019. Grn: Gated relation network to enhance convolutional neural network for named entity recognition. ThirtyThird AAAI Conference on Artiﬁcial Intelligence, 33(01):6236–6243.
Jason PC Chiu and Eric Nichols. 2015. Named entity recognition with bidirectional lstm-cnns. arXiv preprint arXiv:1511.08308.
Ronan Collobert, Jason Weston, Le´on Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011. Natural language processing (almost) from

scratch. Journal of Machine Learning Research, 12(Aug):2493–2537.
Leon Derczynski, Diana Maynard, Giuseppe Rizzo, Marieke Van Erp, Genevieve Gorrell, Raphae¨l Troncy, Johann Petrak, and Kalina Bontcheva. 2015. Analysis of named entity recognition and linking for tweets. Information Processing & Management, 51(2):32–49.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.
Jinlan Fu, Pengfei Liu, Qi Zhang, and Xuanjing Huang. 2020a. Rethinkcws: Is chinese word segmentation a solved task? arXiv preprint arXiv:2011.06858.
Jinlan Fu, Pengfei Liu, Qi Zhang, and Xuanjing Huang. 2020b. Rethinking generalization of neural models: A named entity recognition case study. In AAAI, pages 7732–7739.
Sepp Hochreiter and Ju¨rgen Schmidhuber. 1997. Long short-term memory. Neural computation, 9(8):1735–1780.
Anwen Hu, Zhicheng Dou, Jirong Wen, and Jianyun Nie. 2020. Leveraging multi-token entities in document-level named entity recognition. ThirtyForth AAAI Conference on Artiﬁcial Intelligence.
Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional lstm-crf models for sequence tagging. arXiv preprint arXiv:1508.01991.
Masaaki Ichihara, Kanako Komiya, Tomoya Iwakura, and Maiko Yamazaki. 2015. Error analysis of named entity recognition in bccwj. Recall, 61:2641.
Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom. 2014. A convolutional neural network for modelling sentences. In Proceedings of ACL.
John Lafferty, Andrew Mccallum, and Fernando Pereira. 2001. Conditional random ﬁelds: Probabilistic models for segmenting and labeling sequence data. pages 282–289.
Guillaume Lample, Miguel Ballesteros, Sandeep Subramanian, Kazuya Kawakami, and Chris Dyer. 2016. Neural architectures for named entity recognition. In Proceedings of NAACL-HLT, pages 260–270.
Xiaoya Li, Jingrong Feng, Yuxian Meng, Qinghong Han, Fei Wu, and Jiwei Li. 2020. A uniﬁed mrc framework for named entity recognition. Proceedings of the 58rd Annual Meeting of the Association for Computational Linguistics.
Bill Yuchen Lin, Dong-Ho Lee, Ming Shen, Ryan Moreno, Xiao Huang, Prashant Shiralkar, and Xiang Ren. 2020. Triggerner: Learning with entity triggers as explanations for named entity recognition. In Proceedings of ACL.

Ying Luo, Fengshun Xiao, and Hai Zhao. 2020. Hierarchical contextualized representation for named entity recognition.
Xuezhe Ma and Eduard Hovy. 2016. End-to-end sequence labeling via bi-directional lstm-cnns-crf. In Proceedings of the 54th Annual Meeting of ACL, volume 1, pages 1064–1074.
Mavuto M Mukaka. 2012. A guide to appropriate use of correlation coefﬁcient in medical research. Malawi Medical Journal, 24(3):69–71.
Graham Neubig, Zi-Yi Dou, Junjie Hu, Paul Michel, Danish Pruthi, and Xinyi Wang. 2019. compare-mt: A tool for holistic comparison of language generation systems. arXiv preprint arXiv:1903.07926.
Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. Glove: Global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pages 1532–1543.
Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep contextualized word representations. In Proceedings of the 2018 Conference of NAACL, volume 1, pages 2227–2237.
Yujie Qian, Enrico Santus, Zhijing Jin, Jiang Guo, and Regina Barzilay. 2018. Graphie: A graph-based framework for information extraction. arXiv: Computation and Language.
Erik F Sang and Fien De Meulder. 2003. Introduction to the conll-2003 shared task: Languageindependent named entity recognition. arXiv preprint cs/0306050.
Benjamin Strauss, Bethany Toma, Alan Ritter, Mariecatherine De Marneffe, and Wei Xu. 2016. Results of the wnut16 named entity recognition shared task. pages 138–144.
Ralph Weischedel, Martha Palmer, Mitchell Marcus, Eduard Hovy, Sameer Pradhan, Lance Ramshaw, Nianwen Xue, Ann Taylor, Jeff Kaufman, Michelle Franchini, et al. 2013. Ontonotes release 5.0 ldc2013t19. Linguistic Data Consortium, Philadelphia, PA.
Frank Wilcoxon, SK Katti, and Roberta A Wilcox. 1970. Critical values and probability levels for the wilcoxon rank sum test and the wilcoxon signed rank test. Selected tables in mathematical statistics, 1:171–259.
Donald W Zimmerman and Bruno D Zumbo. 1993. Relative power of the wilcoxon test, the friedman test, and repeated-measures anova on ranks. The Journal of Experimental Education, 62(1):75–86.

A Models Description
Tab. 1 shows the evaluated models in this paper, mainly in terms of four aspects: 1) character/subword-sensitive encoder: ELMo, Flair, BERT 2) additional word embeddings: GloVe; 3) sentence-level encoders: LSTM, CNN; 4) decoders: MLP or CRF.
For example, 1) ”CnonWrandlstmCrf ” is a model with no character features, with randomly initialized embeddings, and the sentence encoder is LSTM and the decoder is CRF. 2) ”CbertWnoneLstmMlp” is a model that concatenates the representations from BERT and GloVe as a subword-sensitive encoder. Then the concatenation will be fed into an MLP layer, predicting a label over all classes. 3) ”CelmWgloveLstmCrf ” is a model that concatenates the representations from ELMo and GloVe as a subword-sensitive encoder. Then the concatenation will be fed into an LSTM layer, followed by the CRF layer.
B Bucketing Interval Strategy
In this section, we will illustrate the bucketing interval with respect to attribute. We divide the range of attribute values into m discrete parts. For a given attribute, the number of entities covered by an attribute value is various. For example, oDen=0 covered nearly half of the entity in the test set for OOV density; for label consistency, eCon=0 and eCon=1 each occupy a large part of the test entities. We customize the interval method for each attribute in accordance with its own characteristics.
1) Label consistency (eCon, tCon): ﬁrst, we divide the entities in the test set with attribute values φeCon(x) = 0 and φeCon(x) = 1 into the ﬁrst bucket (E1te) and last bucket Emte, respectively; then, divide the remaining entities equally into m − 2 buckets. The bucketing interval strategy of eCon is suitable for tCon.
2) Frequency (eFre, tFre) and OOV density (oDen): ﬁrst, we divide the entities in test set with attribute value φeF re(x) = 0 into the ﬁrst bucket (E1te); then, divide the remaining entities equally into m − 1 buckets. The bucketing interval strategy of eFre is suitable for tFre and oDen.
3) Sentence length (sLen) and entity density (eDen): we divide the test entities equally into m buckets.
4) Entity length (eLen): a small m is suitable for entity length, because of a few attribute values (generally, the entity length is rarely greater than

6). In this paper, we put the entities in the test set with lengths of 1, 2, 3, and ≥ 4 into four buckets, respectively.
C Model-wise Analysis and Observation
Tab. 2 gives the model-wise measures Sρi,j and Sσi,j which are the average case on all the datasets. We ﬁnd that: pre-trained knowledge enhanced models are tardier to the token-level attribute. We observe that the values of Sρ dropped sharply on tCon and tFre, when the pre-trained embedding is introduced, therefore, comparing with the models without pre-trained knowledge, the performance of the models with pre-trained knowledge is slower improved as the increasing of token consistency and token frequency. Speciﬁcally, the models with pre-trained knowledge have higher performance and lower Sσ, compared with the models without pre-trained knowledge. This reveals that the introduction of external knowledge will handle the lower label consistency of token and low token frequency.
D Bucket-wise Analysis and Observation
Tab. 4 illustrates the comparative diagnosis of different NER systems. Here, we will give the observations.
LSTM v.s. CNN The sentence encoder of CNN is better at dealing with long entities (eLen:XL) on the datasets with a high value of ζeCon. As shown in Tab.4, the performance of LSTM and CNN systems are signiﬁcantly different on the “eLen:XL” bucket (p = 1.2 × 10−2 < 0.05) without regard to WNUT16 and WB two datasets which have the lowest values of ζeCon.
The encoder of LSTM does better in dealing with highly-ambiguous entities (eCon:S). For example, the LSTM system has surpassed CNN on the datasets WNUT and WB, whose average label ambiguities of entities are the two largest ones.
Flair v.s. ELMo While the current state-of-theart NER model (Flair) has achieved the best performance in terms of dataset-level F1 score, a worse-ranked model (ELMo) can outperform it in some attributes. Typically, Flair performs worse when dealing with long sentences, which holds for all the datasets (p = 1.4 × 10−3 < 0.05). The reason can be attributed to its structural bias, which adopts an LSTM-based encoder for character language modeling, suffering from long-term

dependency problems. One potential promising improvement is resorting to the Transformer-based architecture for the character language model pretraining.
E Signiﬁcance Testing
We break down the holistic performance into different categories for conducting the ﬁne-grained evaluation. Speciﬁcally, we divide the set of test entities (or tokens) into different subsets (we named buckets) of test entities. To test whether the performance of buckets with respect to an attribute is signiﬁcantly different, we perform Friedman significance testing at p = 0.05 in dataset-dimension and model-dimension. To ensure a sufﬁcient sample size to conduct signiﬁcance testing, we restarted a model on the same dataset for twice.
Dataset-dimension signiﬁcance testing It is the premise of attribute-wise analysis. The null hypothesis is that the performance of different buckets with respect to an attribute has the same means for a given dataset. The signiﬁcance testing results are shown in Tab. 5. The p-values of these eight attributes on the six datasets are smaller than 0.05, indicating that the performance of buckets with respect to one of the eight attributes is signiﬁcantly different for a given dataset.
Model-dimension signiﬁcance testing It is the premise of model-wise analysis. The null hypothesis is that the performance of different buckets with respect to an attribute has the same means for a given model. The signiﬁcance testing results are shown in Tab. 6. We observe that the p-values of eDen, oDen, and sLen are larger than 0.05, therefore, eDen, oDen, and sLen does not pass the signiﬁcance testing for a given model. The performance of the buckets with respect to eDen (oDen, sLen) are not signiﬁcantly different.

CoNLL03

WNUT16

OntoNotes-MZ

OntoNotes-BC

OntoNotes-BN

OntoNotes-WB

eDen oDen sLen eCon eFre tCon tFre eLen eDen oDen sLen eCon eFre tCon tFre eLen eDen oDen sLen eCon eFre tCon tFre eLen eDen oDen sLen eCon eFre tCon tFre eLen eDen oDen sLen eCon eFre tCon tFre eLen eDen oDen sLen eCon eFre tCon tFre eLen

-XS XL-XS
XL-L -S -L
S-L -L
XL-L -L -S
-XL -S -S -S
-XS L-XS
LLXLXSLSXLLXL-S S-XS XL-L S-XL XL-S S-XS XL-XS
LXL-L L-XL XS-L L-XL XS-S XS-S XL-L XL-L
-XS -S
-XS -S -S
-XL -XL -XL

Overall F1

M1: 90.48; M2: 90.14 M1: 40.61; M2: 36.21

4

2

15

M1: CcnnWgloveLstmCrf 0

10

M2: CcnnWgloveCnnCrf −2

5

Comparative diagnosis −4 0

M1: 85.39; M2: 88.10
0 −5 −10

M1: 76.04; M2: 76.74 M1: 86.78; M2: 86.42

5

6

4

0

2

0

−5

−2

M1: 60.17; M2: 49.10
20 10 0

Overall F1

M1: 93.03; M2: 92.22

4 M1: CﬂairWgloveLstmCrf 2 M2: CelmWgloveLstmCrf 0
Comparative diagnosis −2

M1: 45.96; M2: 45.33
10 5 0 −5

M1: 85.56; M2: 85.70
0 −10

M1: 77.23; M2: 78.71 M1: 87.92; M2: 89.35

5 0
0

−5

−5

M1: 63.38; M2: 63.26
10 0 −10

-L -L XL-S -XS -XS -S -XL -L XS-L XS-L XL-XS XL-S S-L S-XS XL-XS XL-L XS-S XL-L XL-S S-XS S-XS XL-XS XS-XL L-XL L-XS XS-S XSXS-S XS-XL XS-L XS-L XLXLXL-S SXS-L XSSXLLXS-XL XL-L S-XS XL-L XL-S XL-S S-L L-XS

Table 4: Comparative diagnosis of different NER systems. M1 and M2 denote two models. We classify the attribute values into four categories: extra-small (XS), small (S), large (L), and extra-large (XL). In the comparative diagnosis histogram, green (red) x ticklabels represents the bucket value of a speciﬁc attribute on which system M1 surpasses (under-performs) M2 by the largest margin that is illustrated by a green (red) bin.

dataset
conll03 wnut16 notewb notemz notebc notebn

eDen
2.2 × 10−12 2.6 × 10−15 3.9 × 10−16 3.6 × 10−11 1.7 × 10−05 2.9 × 10−07

oDen
2.0 × 10−17 7.3 × 10−17 9.0 × 10−13 5.1 × 10−11 3.8 × 10−11 1.6 × 10−11

sLen
1.1 × 10−10 1.1 × 10−13 5.5 × 10−09 2.2 × 10−11 8.8 × 10−13 5.7 × 10−14

eCon
1.0 × 10−6 1.4 × 10−6 7.5 × 10−8 1.3 × 10−6 1.3 × 10−6 1.3 × 10−7

eFre
1.2 × 10−14 4.8 × 10−10 2.1 × 10−16 5.3 × 10−12 6.3 × 10−15 2.9 × 10−15

tCon
8.8 × 10−18 3.7 × 10−15 2.1 × 10−18 2.9 × 10−18 4.1 × 10−18 2.9 × 10−18

tFre
8.2 × 10−11 1.4 × 10−14 8.0 × 10−17 6.1 × 10−16 5.2 × 10−15 2.4 × 10−15

eLen
4.8 × 10−7 4.8 × 10−7 3.6 × 10−7 5.5 × 10−7 5.5 × 10−7 7.5 × 10−8

Table 5: p-values from the Friedman test. The null hypothesis is that the performance of different buckets with respect to an attribute has the same means for a given dataset.

Model
CRF++ CnoneWrandLstmCrf CcnnWnoneLstmCrf CcnnWrandLstmCrf CcnnWgloveLstmCrf CcnnWgloveCnnCrf CcnnWgloveLstmMlp CelmoWnoneLstmCrf CelmoWgloveLstmCrf CbertWnonLstmMlp CﬂairWnoneLstmCrf CﬂairWgloveLstmCrf

eDen
0.39 0.09 0.10 0.46 0.61 0.61 0.39 0.26 0.85 0.06 0.13 0.39

oDen
0.31 0.17 0.80 0.56 0.28 0.39 0.46 0.57 0.10 0.12 0.22 0.33

sLen
0.28 0.10 0.80 0.85 0.49 0.80 0.33 0.33 0.22 0.61 0.39 0.20

eCon
9.4 × 10−4 1.0 × 10−3 3.2 × 10−3 2.2 × 10−3 1.5 × 10−3 1.5 × 10−3 1.1 × 10−3 2.0 × 10−3 2.0 × 10−3 3.8 × 10−3 2.2 × 10−3 4.6 × 10−3

eFre
1.8 × 10−3 1.0 × 10−3 9.4 × 10−4 7.1 × 10−4 5.6 × 10−3 6.3 × 10−3 2.9 × 10−3 4.2 × 10−3 3.8 × 10−3 4.2 × 10−3 3.8 × 10−3 2.2 × 10−3

tCon
9.4 × 10−4 9.4 × 10−4 1.5 × 10−3 9.4 × 10−4 1.1 × 10−3 1.7 × 10−3 1.1 × 10−3 1.1 × 10−3 1.1 × 10−3 2.0 × 10−3 1.1 × 10−3 1.1 × 10−3

tFre
9.7 × 10−3 1.8 × 10−3 2.9 × 10−2 1.8 × 10−3 9.7 × 10−3 1.5 × 10−3 5.6 × 10−3 5.6 × 10−3 8.1 × 10−3 2.0 × 10−2 3.8 × 10−3 6.0 × 10−2

eLen
3.8 × 10−3 3.8 × 10−3 5.6 × 10−3 3.8 × 10−3 1.5 × 10−3 2.0 × 10−3 6.7 × 10−3 5.6 × 10−3 1.5 × 10−3 3.5 × 10−2 5.6 × 10−3 3.8 × 10−3

Table 6: p-values from the Friedman test. The null hypothesis is that the performance of different buckets with respect to an attribute has the same means for a given model. The Pink region denote the attribute on the given model does not pass (p ≥ 0.05) a signiﬁcance test at p = 0.05.

