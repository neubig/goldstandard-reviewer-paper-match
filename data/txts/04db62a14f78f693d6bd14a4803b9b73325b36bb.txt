Knowledge Enhanced Multi-modal Fake News Detection

arXiv:2108.04418v1 [cs.SI] 10 Aug 2021

Yi Han, Amila Silva, Ling Luo, Shanika Karunasekera, Christopher Leckie
{yi.han@,amila.silva@student.,ling.luo@,karus@,caleckie@}unimelb.edu.au School of Computing and Information Systems The University of Melbourne

ABSTRACT
Recent years have witnessed the significant damage caused by various types of fake news. Although considerable effort has been applied to address this issue and much progress has been made on detecting fake news, most existing approaches mainly rely on the textual content and/or social context, while knowledge-level information—entities extracted from the news content and the relations between them—is much less explored. Within the limited work on knowledge-based fake news detection, an external knowledge graph is often required, which may introduce additional problems: it is quite common for entities and relations, especially with respect to new concepts, to be missing in existing knowledge graphs, and both entity prediction and link prediction are open research questions themselves. Therefore, in this work, we investigate knowledge-based fake news detection that does not require any external knowledge graph. Specifically, our contributions include: (1) transforming the problem of detecting fake news into a subgraph classification task—entities and relations are extracted from each news item to form a single knowledge graph, where a news item is represented by a subgraph. Then a graph neural network (GNN) model is trained to classify each subgraph/news item. (2) Further improving the performance of this model through a simple but effective multi-modal technique that combines extracted knowledge, textual content and social context. Experiments on multiple datasets with thousands of labelled news items demonstrate that our knowledge-based algorithm outperforms existing counterpart methods, and its performance can be further boosted by the multi-modal approach.
CCS CONCEPTS
• Computing methodologies → Supervised learning by classification; Neural networks.
KEYWORDS
fake news detection, knowledge graph, graph neural networks, social media
ACM Reference Format: Yi Han, Amila Silva, Ling Luo, Shanika Karunasekera, Christopher Leckie. . Knowledge Enhanced Multi-modal Fake News Detection. In . ACM, New York, NY, USA, 10 pages.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. ,, © Copyright held by the owner/author(s). Publication rights licensed to ACM.

1 INTRODUCTION
The prevalence of fake news1 on social media has serious repercussions on our society. Especially when equipped with big data analysis, it can accurately reach specific target audiences to spread fear, aggravate hatred, and cause riots and violence.
While significant efforts have been made on fake news detection, most existing work focuses on the textual content and social context, where textual content includes the news headline and body, and social context means user interactions over social media. For example, once a news item is published online, it may be tweeted by multiple users. Each of these tweets and its retweets form a separate cascade [42], and all the cascades form the propagation pattern/network (we use these two terms interchangeably in this work) of a news item.
Knowledge-level information, on the other hand, has been much less explored. Here knowledge refers to the entities in the news content and the relations between them. Typically, it can be represented in the format of a triple: (Subject, Predicate, Object), i.e., SPO triple [1]. Within the limited work on knowledge-based fake news detection, an external knowledge graph is often required. For example, Cui et al. [8] incorporate an article-entity bipartite graph and a medical knowledge graph to better capture the important entities and guide the embedding of news articles to detect healthcare misinformation. However, it is unlikely for any knowledge graph to contain all possible entities and relations, and it is not a trivial task to accurately predict missing ones. To overcome this issue, in this work, we investigate knowledge-based fake news detection that does not require any external knowledge graph.
Pan et al. [24] approach this problem by constructing two knowledge graphs, with one on real news (𝐾𝐺𝑇 ) and one on fake news (𝐾𝐺𝐹 ). Each of these two knowledge graphs is then used to train a TransE [6] model, and a news item is verified by comparing the average or maximum bias of the two models over the extracted relations, where the bias of a triple (𝑠, 𝑝, 𝑜) is defined as ||𝑠 +𝑝 −𝑜 ||22. A news item is classified as “Real" if the bias of the model trained on 𝐾𝐺𝑇 is smaller, and “Fake" otherwise.
In our work, by contrast, we look at the problem from a different perspective: given the recent development on graph neural networks (GNNs) and their superior performance on non-Euclidean data, we investigate whether it is possible to transform fake news detection into a knowledge graph classification problem.
Initially, we test a method that constructs a separate knowledge graph for each news item, and then applies GNNs for graph-level classification. However, our preliminary experiments suggest that this method does not achieve satisfactory results, with an average accuracy only around 73%. A key reason is that normally a very
1Here we use the definition in [59]: fake news is intentionally and verifiably false news published by a news outlet.

,,

Yi Han, Amila Silva, Ling Luo, Shanika Karunasekera, Christopher Leckie

News 1 text
News 2 text . .
News n . text

Extracted relation set 1 Extracted relation set 2 Extracted relation set n

News 2 News 1

.

.

.

SubGNN

Trained model

(a) Knowledge-based fake news detection. Information is extracted from all news items to form a single knowledge graph, where each news item can be represented by a subgraph, so that the fake news detection problem becomes a subgraph classification task. A SubGNN model is then trained to classify each subgraph/news item.

Propagation network

tweets/ retweets

News 1

text

.. ... . ...
Embedding

Pretrained propagation-based model Pretrained text-based model

. text . . . . .

Extracted relation set Pretrained knowledge-based model

News n

h1P

Concatenation

h1T

h1

h1K ... ...

MLP

hn

...

...

...

... ... ...

(b) Multi-modal fake news detection that combines extracted knowledge, text content and propagation network. The propagation-, text- and knowledge-based models are pre-trained separately, and their generated embeddings are concatenated to train a MLP.
Figure 1: Overview of the proposed knowledge-based and multi-modal fake news detection algorithms.

limited number of relations/triples can be extracted from each news item, which means that the constructed knowledge graph is too small to accurately verify the veracity of a news item.
Therefore, we propose a new approach and transform the problem of fake news detection into a subgraph classification task. Specifically, our contributions include:
• Inspired by the work of [2], which designs a GNN model called SubGNN for subgraph classification, we propose to extract entities and relations from each news item, all of which form a single knowledge graph where a news item is represented by a subgraph (Fig. 1a), and then all subgraphs with their corresponding news labels (fake/real) are used to train a SubGNN model, so that the obtained model can classify each subgraph/news item. As demonstrated by the experimental results in Section 6, this method can achieve much better performance.
• To further improve the performance of the above model, we develop a simple but effective multi-modal fake news detection algorithm. In addition to extracted knowledge, other forms of information, such as the textual content and propagation network, can also contribute to detecting fake news. Specifically, as can be seen from Fig. 1b, in our proposed method three models are first trained separately: (1) a propagation-based model [12] that verifies a news

item purely on its propagation pattern; (2) a document classification model using hierarchical attention networks [50] that operates directly on the news content; and (3) a knowledge-based model proposed in this work. We demonstrate that by concatenating the generated embeddings of these three models to train a multilayer perceptron (MLP), this seemingly simple approach can outperform each individual model by a clear margin.
The remainder of this paper is organised as follows: Section 2 defines the research problem; Sections 3 and 4 present our knowledgebased fake news detection algorithm which does not require any external knowledge graph; Section 5 introduces an architecture that combines knowledge-, text- and propagation-based models to facilitate multi-modal fake news detection; Section 6 provides experimental results to demonstrate the effectiveness of our proposed methods; Section 7 reviews previous work related to fake news detection on social media; and finally Section 8 concludes the paper and offers directions for future work.
2 PROBLEM DEFINITION
Originally, the fake news detection problem can be defined as: given a set of labelled news items D = {(𝑊𝑖, 𝑦𝑖 ) | 𝑖 = 1, 2, ...}, where 𝑊𝑖 ∈ W is the textual content for news item 𝑖 (i.e., a sequence of

Knowledge Enhanced Multi-modal Fake News Detection
words), and 𝑦𝑖 ∈ Y = {0 (Real), 1 (Fake)} is the label of 𝑊𝑖 , the goal is to learn a mapping 𝑔 : W → Y that classifies each news item.
In this work, we take a knowledge-based approach and break down the above formulation into the following two sub-problems:
Knowledge graph construction. The aim of the first step is to extract information from each news item to construct a knowledge graph. Conventionally, this involves named entity recognition and relation extraction, which have been extensively studied. However, we have tested several existing named entity-based relation extraction techniques, and our results suggest that when applied to news items, these methods normally generate a relatively small number of relations, which may lead to substantial information loss. Therefore, in the first sub-problem we design a new relation extraction algorithm that extracts a set of relations/triples 𝑅𝑖 = {(𝑒𝑖 𝑗 , 𝑟𝑖 𝑗 , 𝑒 ′ )| 𝑗 = 1, 2, ...} from news content
𝑖𝑗
𝑊𝑖 , where 𝑒𝑖 𝑗 , 𝑟𝑖 𝑗 , 𝑒 ′ contain one or multiple words in 𝑊𝑖 . Each
𝑖𝑗
of these triples means that 𝑒𝑖 𝑗 and 𝑒 ′ has the relation of 𝑟𝑖 𝑗 . For
𝑖𝑗
example, a triple (David Warner, troll, Virat Kohli) can be extracted from the sentence “David Warner trolls Virat Kohli on Instagram over his grey beard" (Fig. 2). Note that here we do not pre-define any relation type or named entity.
Subgraph classification. Once all the relations are extracted from news items, and a single knowledge graph is constructed (in the case where a part of the graph is isolated from the rest, we only keep the largest connected component), each news item is assigned to a subgraph based on its extracted relations. Therefore, the original fake news detection problem is transformed into a subgraph classification task formulated as follows: given a set of labelled sub-knowledge graphs {(𝑆𝐺𝑖, 𝑦𝑖 ) | 𝑖 = 1, 2, ...}, where 𝑆𝐺𝑖 ∈ SG represents the sub-knowledge graph that corresponds to news item 𝑖, and 𝑦𝑖 ∈ Y = {0 (Real), 1 (Fake)} is the label of 𝑆𝐺𝑖 , then the goal is to learn a classifier 𝑓 : SG → Y that labels each subgraph. Note that here different subgraphs are not necessarily mutually exclusive and may contain common nodes.
In the following two sections, we explain in detail our solution to the above two problems.
3 KNOWLEDGE GRAPH CONSTRUCTION
In order to extract relations from news items to build a knowledge graph, we have first tested the following options: (1) an OpenNRE [11] model trained on the Wiki80 dataset2 with a BERT encoder, (2) an OpenNRE model trained on the Wiki80 dataset with a CNN encoder, (3) an OpenNRE model trained on the TACRED dataset3 [54] with a BERT encoder, (4) an ATLOP [55] model trained on the DocRED dataset [51]. The first three models are for sentencelevel relation extraction, while the last one is for document-level relation extraction—hence it can extract more accurate relations than the other three models in our case.
Our experimental results suggest that all these models extract a relatively small number of relations from each news item, which may lead to substantial information loss. In addition, it is also unlikely for all the extracted relations to form a single graph. A main reason is that the relation types are pre-defined in these three
2 https://github.com/thunlp/OpenNRE/blob/master/benchmark/download_wiki80.sh 3 https://nlp.stanford.edu/projects/tacred/

,,

Algorithm 1: Relation Extraction

Input: The textual content 𝑊 = {𝑤0, 𝑤1, ...} of a news

record

Output: The list of relations 𝐿

1 𝐿 ← ∅;

2 𝑊 ← 𝑐𝑜𝑟𝑒 𝑓 𝑒𝑟𝑒𝑛𝑐𝑒_𝑟𝑒𝑠𝑜𝑙𝑢𝑡𝑖𝑜𝑛(𝑊 );

3 {𝐷0, 𝐷1, ...} ← 𝑑𝑒𝑝𝑒𝑛𝑑𝑒𝑛𝑐𝑦_𝑝𝑎𝑟𝑠𝑖𝑛𝑔(𝑊 );

4 {𝑝0, 𝑝1, ...} ← 𝑝𝑜𝑠_𝑡𝑎𝑔𝑔𝑖𝑛𝑔(𝑊 );

5 {𝑙0, 𝑙1, ...} ← 𝑙𝑒𝑚𝑚𝑎𝑡𝑖𝑧𝑎𝑡𝑖𝑜𝑛(𝑊 );

6 for 𝑖 in {0, 1, 2, ...., |𝑊 | − 1} do

7 if 𝑝𝑖 is a verb then

8

{𝑙𝑒 𝑓 𝑡_𝑛𝑜𝑑𝑒𝑠, 𝑟𝑖𝑔ℎ𝑡_𝑛𝑜𝑑𝑒𝑠} ← {∅, ∅};

9

𝑒𝑑𝑔𝑒_𝑡𝑦𝑝𝑒 ← 𝑙𝑖 ;

10

for (𝑤𝑘, 𝑟, 𝑤𝑖 ) in 𝐷𝑖 do

11

if 𝑙𝑘 is “not" then

12

𝑒𝑑𝑔𝑒_𝑡𝑦𝑝𝑒 ← “𝑛𝑜𝑡_” + 𝑒𝑑𝑔𝑒_𝑡𝑦𝑝𝑒;

13

else if 𝑟 in {𝑛𝑠𝑢𝑏 𝑗 } then

14

𝑙𝑒 𝑓 𝑡_𝑛𝑜𝑑𝑒𝑠 ← 𝑙𝑒 𝑓 𝑡_𝑛𝑜𝑑𝑒𝑠 ∪ {𝑙𝑘 };

15

else if 𝑟 in {𝑑𝑜𝑏 𝑗, 𝑖𝑜𝑏 𝑗, 𝑎𝑡𝑡𝑟, 𝑥𝑐𝑜𝑚𝑝} then

16

𝑟𝑖𝑔ℎ𝑡_𝑛𝑜𝑑𝑒𝑠 ← 𝑟𝑖𝑔ℎ𝑡_𝑛𝑜𝑑𝑒𝑠 ∪ {𝑙𝑘 };

17

for 𝑙𝑒 𝑓 𝑡_𝑛𝑜𝑑𝑒 in 𝑙𝑒 𝑓 𝑡_𝑛𝑜𝑑𝑒𝑠 do

18

for 𝑟𝑖𝑔ℎ𝑡_𝑛𝑜𝑑𝑒 in 𝑟𝑖𝑔ℎ𝑡_𝑛𝑜𝑑𝑒𝑠 do

19

𝐿 ← 𝐿 ∪ (𝑙𝑒 𝑓 𝑡_𝑛𝑜𝑑𝑒, 𝑒𝑑𝑔𝑒_𝑡𝑦𝑝𝑒, 𝑟𝑖𝑔ℎ𝑡_𝑛𝑜𝑑𝑒);

20 𝑟𝑒𝑡𝑢𝑟𝑛 𝐿

datasets: Wiki80/TACRED/DocRED contains 80/41/96 relations, which cannot cover all the scenarios. As a result, in many cases even though a certain type of relation does exist, “no_relation" is returned instead.
One option is to create our own dataset from the collected news items with a larger number of pre-defined relations, and then retrain an OpenNRE or ATLOP model. However, in order to significantly increase the number of pre-defined relations, we also need a considerably larger number of relation instances for training. Considering that DocRED already has a total number of 1, 508, 320 instances, it is unlikely to obtain a much larger quantity from the thousands of collected news items.
Therefore, we design a new technique that can expand the number of extracted relations. Specifically, we do not pre-define any relation type, and instead focus on the verbs in each sentence, since verbs often play an important role in deciding the veracity of a statement. Algorithm 1 summarises our relation extraction method. As illustrated in Fig. 2, for a news record,
• The title and the body text are concatenated to extract its textual content 𝑊 = {𝑤0, 𝑤1, ...}.
• Co-reference resolution4 is performed to replace all the mentions in 𝑊 that refer to the same real-world entity with a single token (Line 2). In the given example, “Kohli" is replaced by “Virat Kohli".
4 https://spacy.io/universe/project/neuralcoref

,,

Yi Han, Amila Silva, Ling Luo, Shanika Karunasekera, Christopher Leckie

“David Warner trolls Virat Kohli on Instagram over his grey beard. Kohli did not care to respond.” By Coreference Resolution (Line 2)
“David Warner trolls Virat Kohli on Instagram over his grey beard. Virat Kohli did not care to respond.” By Dependency Parsing and POS tagging (Lines 3-4)

Instagram pobj on David Warner nsubj

over
prep prep
trolls dobj
VERB

pobj his grey beard
aux
Virat Kohli nsubj care neg
VERB

did
not
xcomp

aux to
respond
VERB

By retaining {nsubj, dobj, iobj, attr, xcomp, neg} relations (Lines 13-16)

David Warner

nsubj trolls dobj

Virat Kohli nsubj care

neg not
xcomp

By updating verbs to capture negation (Lines 11-12)

respond

David Warner nsubj trolls dobj Virat Kohli nsubj

not_care

xcomp respond

By combining subjects and objects using verbs (Lines 17-19)

Subject: David Warner Object: Virat Kohli Predicate: troll

Subject: Virat Kohli Object: respond Predicate: not_care

Figure 2: An illustration of Algorithm 1.

• The grammatical structure of each sentence in𝑊 is extracted using the dependency parser available in Spacy5 (Line 3). This step returns a set of tuples 𝐷𝑖 for each word 𝑤𝑖 . Each entry in 𝐷𝑖 is a tuple (𝑤𝑘, 𝑟, 𝑤𝑖 ), where 𝑤𝑘 is another word in the same sentence of 𝑤𝑖 that is related to word 𝑤𝑖 from the relation type 𝑟 , e.g., nominal subject (𝑛𝑠𝑢𝑏 𝑗), direct object (𝑑𝑜𝑏 𝑗), open clausal complement (𝑥𝑐𝑜𝑚𝑝), as shown in the third box in Fig. 2. Note that the relation here has different meaning from the relation between entities mentioned above in the problem definition.
• The Part-of-Speech (POS) tags {𝑝0, 𝑝1, ...} and the base-forms {𝑙0, 𝑙1, ...} of the words in 𝑊 are recovered using the POS tagger6 and the lemmatizer7 in Spacy (Line 4-5).
• The verbs in 𝑊 are identified by looping through POS tags of the words in 𝑊 (Line 6-7).
• For each identified verb 𝑤𝑖 , the connected words in the dependency parse tree 𝐷𝑖 are analysed. If a negation, i.e., words that reverse the meaning of a word, is found to be attached to 𝑤𝑖 , 𝑤𝑖 is updated as “not_" + 𝑤𝑖 , e.g., “care" becomes “not_care" in the given example (Line 11-12).
• Then, the connected nodes are categorised as either 𝑙𝑒 𝑓 𝑡_ 𝑛𝑜𝑑𝑒𝑠 or 𝑟𝑖𝑔ℎ𝑡_𝑛𝑜𝑑𝑒𝑠 based on their relation to 𝑤𝑖 . If the relation type of a connected word is nominal subject (𝑛𝑠𝑢𝑏 𝑗), it is added to 𝑙𝑒 𝑓 𝑡_𝑛𝑜𝑑𝑒𝑠 (Line 13-14).
• Otherwise, if the relation to 𝑤𝑖 belongs to one of the following types: direct object (𝑑𝑜𝑏 𝑗), indirect object (𝑖𝑜𝑏 𝑗), attribute (𝑎𝑡𝑡𝑟 ), and open clausal complement (𝑥𝑐𝑜𝑚𝑝), it is added to 𝑟𝑖𝑔ℎ𝑡_𝑛𝑜𝑑𝑒𝑠 (Line 15-16). In the example of Fig. 2,
5 https://spacy.io/usage/linguistic-features#dependency-parse 6 https://spacy.io/usage/linguistic-features#pos-tagging 7 https://spacy.io/usage/linguistic-features#lemmatization

for the verb “troll", “David Warner"/“Virat Kohli" is categorised as 𝑙𝑒 𝑓 𝑡_𝑛𝑜𝑑𝑒𝑠/𝑟𝑖𝑔ℎ𝑡_𝑛𝑜𝑑𝑒𝑠, respectively. In addition, even though “respond" is a verb in the second sentence, it will be extracted as a possible object of “not_care" by our algorithm due to the xcomp connection between them. • In the end, the relation set is constructed by connecting each item in 𝑙𝑒 𝑓 𝑡_𝑛𝑜𝑑𝑒𝑠 with each item in 𝑟𝑖𝑔ℎ𝑡_𝑛𝑜𝑑𝑒𝑠 using the corresponding verb, i.e., 𝑤𝑖 in the above example (Line 1719).
Our experimental results show that by applying the above approach, substantially more (over 10 times) number of relations can be extracted from the news items in total. For example, as shown in Fig. 3, in the left text box is the snippet of a news item8, and the relations extracted by our method are listed in the middle text box. As a comparison, the relations extracted by the ATLOP model are given on the right.
We have compared the cases where the knowledge graph is built using the relations extracted by (1) Algorithm 1, (2) an ATLOP model trained on the DocRED dataset (since DocRED is especially collected for document-level relation extraction), (3) both (1) and (2). Our experiment suggests that the best result is achieved when only the relations extracted by Algorithm 1 are used.
Note that we are not proposing a general method for relation extraction, since it is unlikely for the defined rules to work for all cases, and Algorithm 1 is only for our knowledge-based fake news detection technique.
After all the relations are extracted from news items, we add them one by one to form a single knowledge graph. Then each news item can be represented by a subgraph, based on the relations extracted from it. Therefore, the original problem of detecting fake
8 https://www.politifact.com/factchecks/2010/feb/04/paul-krugman/krugman-callssenate-health-care-bill-similar-law-/

Knowledge Enhanced Multi-modal Fake News Detection

,,

Krugman calls Senate health care bill similar to law in Massachusetts
The recent Massachusetts Senate election captivated Americans far beyond the Bay State. In that contest, Republican Scott Brown picked up a seat formerly held by the late Democratic giant Edward Kennedy. Brown’s upset victory was aided by a wave of frustration over how Congress and President Barack Obama have been handling health care reform legislation.
During the campaign, Brown said that if he was elected, he would become the 41st Republican senator, enabling the GOP to block the Democratic majority from reaching the 60-vote threshold required to pass key legislation, including a health care bill. The Senate has already passed a version of health care, but it needs to be reconciled with a different bill passed by the House and then signed by the president before it becomes law.

Subject: election Object: Americans Predicate: captivate
Subject: Brown Object: seat Predicate: pick
Subject: Congress Object: legislation Predicate: handle
Subject: Brown Object: senator Predicate: become
Subject: Senate Object: version Predicate: pass

Subject: Massachusetts Senate Object: Massachusetts Predicate: located in the administrative territorial entity
Subject: Massachusetts Senate Object: Massachusetts Predicate: applies to jurisdiction

Figure 3: An example that compares the extracted relations using Algorithm 1 and by an ATLOP model. Left text box: the snippet of a news item. Middle text box: relations extracted by Algorithm 1. Right text box: relations extracted by an ATLOP model trained on the dataset of DocRED.

news now transforms into classifying each of the subgraphs, as explained in the next section.
4 SUBGRAPH CLASSIFICATION
In this section, we first give a brief introduction to graph neural networks and SubGNN, and then explain how a sub-knowledge graph is classified in our case.
4.1 Background on Graph Neural Networks
Given a graph G = (V, E), with vertex/node set V, edge set E, and node feature set X ∈ R|V |×𝑑 (i.e., each node has 𝑑 features), many GNN models can be formulated as a message passing framework [3, 47] in which information is propagated from one node to another along edges.
During each message-passing iteration 𝑘, the embedding for node 𝑣 ∈ V is updated according to the information aggregated from 𝑣’s neighbourhood N (𝑣), which can be expressed as follows:
ℎ𝑣(𝑘+1) = 𝑈 𝑃𝐷𝐴𝑇 𝐸 ℎ𝑣(𝑘), 𝐴𝐺𝐺𝑅𝐸𝐺𝐴𝑇 𝐸 ℎ𝑢(𝑘) | 𝑢 ∈ N (𝑣) , where ℎ0𝑣 = 𝑥𝑣 ∈ X. The update step is often omitted by adding self-loops to the input graph, and the node embedding becomes:
ℎ𝑣(𝑘+1) = 𝐴𝐺𝐺𝑅𝐸𝐺𝐴𝑇 𝐸 ℎ𝑢(𝑘) | 𝑢 ∈ N (𝑣) ∪ {𝑣 } . Take a basic GNN for example [10], the model can be defined as: 𝐻 (𝑘+1) = 𝜎 (𝐴 + 𝐼 ) 𝐻 (𝑘) 𝑀 (𝑘+1) , where (1) 𝐻 is the matrix of node embeddings/representations; (2) 𝜎 is a non-linear activation function, e.g., the rectified linear unit (ReLU) function; (3) 𝐴 ∈ {0, 1} |V |×|V | is the adjacency matrix: 𝐴𝑖,𝑗 = 1 if there is an edge from node 𝑖 to node 𝑗, and 𝐴𝑖,𝑗 = 0 otherwise; and (4) 𝑀 is the weight matrix to be learned.

4.2 Background on SubGNN
Most existing work on GNN focuses on node- and graph-level prediction tasks, while subgraphs are much less studied. To bridge this research gap, Alsentzer et al. [2] propose SubGNN that learns an embedding function F : SG → R𝑑𝑆 to map each subgraph into a lower-dimensional representation.
Specifically, the embedding function F captures features from three channels—position, neighbourhood and structure, each of which has two subchannels—internal and border:
• Position. The internal position of subgraph 𝑆𝐺𝑖 is defined as the distance between 𝑆𝐺𝑖 ’s components—𝑆𝐺𝑖 may contain a single connected component or multiple isolated components. The border position is defined as the distance between 𝑆𝐺𝑖 and rest of G.
• Neighborhood. The internal neighborhood and border neighborhood are defined as the identity of 𝑆𝐺𝑖 ’s internal nodes and border nodes, respectively, where border nodes refer to nodes within the 𝑘-hop neighborhood of internal nodes.
• Structure. The internal structure is defined as the internal connectivity of 𝑆𝐺𝑖 , while the border structure is defined by edges connecting 𝑆𝐺𝑖 ’s internal nodes to the border neighborhood.
4.3 Classify Sub-Knowledge Graphs
Each of the above channels can be used separately or together. We have tested multiple SubGNN models with different combinations of the three channels, and find that models that rely only on the structure channel gives the best result. This is because in our case, the internal and border structures, i.e., how nodes are connected with each other within a subgraph and with the rest of the graph, are more informative for determining whether a news item is fake or not. Interestingly, the neighborhood channel does not perform

,,
as well as the other two, but this is consistent with the ablation study in the original work [2].
In order to facilitate subgraph-level message passing for the structure channel, a number of connected components (each subgraph may contain single or multiple components) are randomly sampled via triangular random walks [5]—they are called anchor patches A = {𝐴𝑖 |𝑖 = 1, 2, ..., 𝑛𝐴}. The embedding of a subgraph component (𝑆𝐶) is then represented in the following form: ℎ𝑆(𝑘𝐶+1) = 𝜎 𝑀 (𝑘+1) · ℎ𝑆(𝑘𝐶) ; 𝐴𝐺𝐺 ({𝛾 (𝑆𝐶, 𝐴𝑖 ) · 𝑎𝑖 |𝑖 = 1, ..., 𝑛𝐴}) , where 𝛾 is a pre-defined similarity function, 𝑎𝑖 is the learned representation of 𝐴𝑖 , 𝐴𝐺𝐺 is an aggregation function, e.g., the sum operator, and 𝑀 is a layer-wise trainable weight matrix.
If a subgraph contains multiple isolated connected components, its embedding is generated by concatenating the embeddings of all components.
5 KNOWLEDGE ENHANCED MULTI-MODAL FAKE NEWS DETECTION
In addition to the extracted knowledge, the textual content itself and how the news item propagates through the social network also provide valuable information for detecting fake news. Therefore, in this section we study how to combine our knowledge-based approach with existing content- and propagation-based methods for more accurate detection.
Formally, given a set of labelled news items {(𝑆𝐺𝑖,𝑊𝑖, 𝑃𝑖, 𝑦𝑖 ) | 𝑖 = 1, 2, ...}, where 𝑆𝐺𝑖 ∈ SG is the sub-knowledge graph, 𝑊𝑖 ∈ W is the textual content, 𝑃𝑖 ∈ P is the propagation network, and 𝑦𝑖 ∈ Y = {0 (Real), 1 (Fake)} is the label of the corresponding news, the goal is to learn a classifier 𝑓 : SG × W × P → Y that can label each news item.
As shown in Fig. 1b, we first train three knowledge-, text- and propagation-based models separately on the same training dataset. Then for each training instance, we feed its 𝑆𝐺𝑖,𝑊𝑖, and 𝑃𝑖 into the obtained models to generate three separate embeddings ℎ𝑖𝐾 , ℎ𝑖𝑇 , ℎ𝑖𝑃 , all of which are concatenated to form the final embedding ℎ𝑖 = ℎ𝑖𝐾 ⊕ ℎ𝑖𝑇 ⊕ ℎ𝑖𝑃 . In the end, an MLP is trained on the set of embeddings {ℎ𝑖 |𝑖 = 1, 2, ...}.
Our experimental results in Section 6 demonstrate that this seemingly simple method outperforms each individual model by a clear margin. Specifically, in this work we choose the following two as the text- and propagation-based models:
• A document classification model using hierarchical attention networks [50]. The overall architecture of this model consists of four components: (1) a word encoder where words are embedded with a GRU-based sequence encoder; (2) a word-level attention layer where the importance of a word is measured by its similarity with a word-level context vector, which is jointly learned during the training process; (3) a sentence encoder that is also based on bidirectional GRU; and (4) a sentence-level attention layer that calculate the weight of a sentence in a similar way to (2). The reason why we choose this model is that previous work has shown that it performs better than other text-based models for fake news detection [33], such as LIWC [25], text-CNN [17].
• A propagation-based algorithm [12] that applies the GNN model of DiffPool [52] (built on top of GraphSage [9]) to verify a news item purely on its propagation pattern (as explained in the

Yi Han, Amila Silva, Ling Luo, Shanika Karunasekera, Christopher Leckie

Table 1: Sstatistics of the PolitiFact and GossipCop datasets.

Dataset PolitiFact GossipCop

No. of Fake News 185 4942

No. of Real News 225 2520

introduction) and the features of the corresponding Twitter users, including (1) whether the user is verified, (2) the timestamp when the user was created, (3) the number of followers, (4) the number of friends, (5) the number of lists, (6) the number of favourites; (7) the number of statuses, (8) the timestamp of the tweet. The adjacency matrix corresponding to the propagation pattern of a news item and the node feature matrix are fed as input for graphlevel classification. We choose this model due to its simplicity and efficiency.
Note that (1) although the experimental results in the next section suggest that our knowledge-based model works well together with the above two models, especially the propagation-based model, they can be replaced by other options too; (2) in addition to text content and propagation network, there are other useful forms of information as well, including user replies, images and external knowledge graphs, especially domain-specific knowledge graphs. We leave more sophisticated fusion techniques for future work.
6 EXPERIMENTAL VERIFICATION
In this section, we empirically verify the effectiveness of our proposed knowledge-based and multi-modal fake news detection algorithms over two datasets with thousands of labelled news items.
6.1 Datasets
While there are a number of public datasets on fake news detection covering different domains, we choose the dataset of FakeNewsNet [34] in our work. FakeNewsNet contains labelled news from two websites: politifact.com9 and gossipcop.com10—we call them PolitiFact and GossipCop hereafter. For each news item, the dataset provides both linguistic and visual information, all the tweets and retweets, as well as the information of the corresponding Twitter users. For more details please refer to [34].
The reasons why we choose PolitiFact and GossipCop over other options include: (1) they align with the our definition of fake news— fake news is intentionally and verifiably false news published by a news outlet. Some public datasets on fake news detection, e.g., Twitter16 [22], Weibo [21], Pheme [18] are intended for detecting rumours, satires, misinformation, etc. (2) They provide accurate ground truth labels, which are collected using fact-checking websites. As a result, they are more accurate than those datasets where news items are weakly labelled by applying distant supervision techniques. For example, the datasets of ReCOVery [57] and CoAID [7] label news records based on the reliability of the source. (3) They provide social context data, which is missing in datasets such as BuzzFeedNews [32], Ma-Twitter [21] and LIAR [43]. This type of information is required by the chosen propagation-based approach to construct the propagation network for each news item.
9 https://www.politifact.com/ 10 https://www.gossipcop.com/

Knowledge Enhanced Multi-modal Fake News Detection

Table 2: Performance comparison of fake news detection on the dataset of PolitiFact

K1 T1 P1 Accuracy Precision Recall F1

✓

0.837

0.844 0.801 0.836

✓

0.829

0.838 0.824 0.826

✓ 0.854

0.855 0.852 0.852

✓✓

0.858

0.853 0.842 0.857

✓ ✓ 0.884

0.922 0.825 0.883

✓

✓ 0.876

0.862 0.877 0.876

✓ ✓ ✓ 0.919

0.913 0.913 0.919

Avg bias [24] Max bias [24]

0.752 0.662

0.725 0.617

0.776 0.638

0.729 0.618

1 K: knowledge-based, T: text-based [50], P: propagationbased [12]

Table 3: Performance comparison of fake news detection on the dataset of GossipCop

K1 T1 P1 Accuracy Precision Recall F1

✓

0.783

0.813 0.870 0.750

✓

0.788

0.767 0.747 0.754

✓ 0.872

0.855 0.860 0.858

✓✓

0.800

0.823 0.888 0.768

✓ ✓ 0.861

0.882 0.910 0.843

✓

✓ 0.879

0.916 0.899 0.866

✓ ✓ ✓ 0.871

0.903 0.900 0.856

Avg bias [24] Max bias [24]

0.749 0.723

0.646 0.625

0.621 0.627

0.629 0.626

1 K: knowledge-based, T: text-based [50], P: propagationbased [12]

The statistics of the dataset are listed in Table 1. Note that the values are smaller than those reported in [34] because (1) many news items, especially fake news, have already been removed, (2) some tweets and retweets of a news items are no longer retrievable, and we cannot build the corresponding propagation pattern. Therefore, those news items are also excluded from our experiments.
6.2 Baselines
Three baselines are considered: in addition to the two models chosen in Section 5, i.e., test-based [50] and propagation-based [12], we also implement the knowledge-based method [24] described in the introduction.
In order to compare these models, the datasets are split as follows: 70% of the data are used for training, 15% are for validation, and the remaining 15% are for test. In addition, all models are evaluated with the following commonly used metrics: accuracy, precision, recall and F1 score.
Model hyper-parameters. (1) For the text-based model, both the word embedding dimension and the GRU dimension are set to 100, the learning rate is 0.003, and the batch size is 32 for PolitiFact and 128 for GossipCop. (2) For the propagation-based model, the hyper-parameters for the DiffPool algorithm are: 2 pooling layers,

,,
64 hidden dimensions and 64 embedding dimensions. In addition, the learning rate is 0.001, and the batch size is 128. (3) For our knowledge-based model, the hyper-parameters for SubGNN are selected from the following ranges: batch size ∈ [64, 128], learning rate ∈ [3𝑒-5, 1𝑒-3], number of layers ∈ [1, 4], number of structure anchor patches |𝐴𝑆 | ∈ [15, 45], and feed forward hidden dimension sizes ∈ [32, 64] with dropout ∈ [0.0, 0.4]. (4) For our multi-modal approach, number of feed forward layers ∈ [2, 4] with hidden dimension sizes ∈ [8, 64] and dropout ∈ [0.0, 0.2]. (5) For the baseline of [24], the embedding dimensions of 𝐾𝐺𝐹 and 𝐾𝐺𝑇 are in the range of [30, 50] for PolitiFact, and [50, 100] for GossipCop.
6.3 Performance Comparison of Fake News Detection
Tables 2 and 3 show the performance comparison on the two datasets of PolitiFact and GossipCop (results in bold correspond to the best values or values less than 0.01 below the best values). The results suggest that:
• Our knowledge-based model outperforms the baseline of [24] on both datasets.
• In terms of each single model of 𝐾, 𝑇 and 𝑃, the difference among their performances on the dataset of PolitiFact is not significant, but the propagation-based model achieves the best performance on the dataset of GossipCop, while the other two perform similarly again.
• In terms of the multi-modal approach, the performance of any combination of two models is almost always better than each individual model.
• If we compare the different combinations, 𝐾 + 𝑇 < 𝑇 + 𝑃 ≈ 𝐾 + 𝑃 ≤ 𝐾 + 𝑇 + 𝑃: (1) since the knowledge- and text-based models rely on the same source of information—the news content, the combination of these two performs the worst. (2) When the knowledge- or text-based model is combined with the propagation-based model, they perform similarly and both better than (1). (3) The combination of all three models performs the best overall.
The above results suggest that while our knowledge-based approach that does not require any external knowledge graph is effective, combining it with other sources of information can further boost its performance.
6.4 Time sensitivity analysis
In addition to the metrics of accuracy, precision, recall and F1 score, it is important to understand how the performance of a model changes over time, since in real cases a deployed fake news detection system is likely to face highly dynamic and volatile data.
We run time sensitivity analysis over a period of 26 weeks (half a year) on the dataset of GossipCop (the dataset of PolitiFact contains only around 400 news items spread over a number of months, which are insufficient to run the analysis): all news items are sorted by their timestamp, and the first 70% are used for training while the last 30% are for testing. During test time the data are divided into separate groups based on the number of weeks from the test news item to the last training item, then the four metrics are calculated over each group, i.e., the model performance is measured weekly. Fig. 4 shows how different models perform over time.

,,

Yi Han, Amila Silva, Ling Luo, Shanika Karunasekera, Christopher Leckie

Accuracy

1

0.8

0.6

0.4 Propagation-based (P)

Text-based (T)

0.2

Knowledge-based (K)

P+T+K

0 5

10

15

20

25

No. of weeks

(a) Accuracy

1

0.8

0.6

0.4 Propagation-based (P)

Text-based (T)

0.2

Knowledge-based (K)

P+T+K

0 5

10

15

20

25

No. of weeks

(c) Recall

F1

Precision

1

0.8

0.6

0.4 Propagation-based (P)

Text-based (T)

0.2

Knowledge-based (K)

P+T+K

0 5

10

15

20

25

No. of weeks

(b) Precision

1

0.8

0.6

0.4 Propagation-based (P)

Text-based (T)

0.2

Knowledge-based (K)

P+T+K

0 5

10

15

20

25

No. of weeks

(d) F1

Recall

Figure 4: Time sensitivity analysis for the dataset of GossipCop. The x-axis is the number of weeks from the test item to the last training item.

We can see that (1) the multi-modal approach performs the best in most cases. (2) In the first few weeks, the performance drop of the text-based and the knowledge-based approaches is more obvious than that of the multi-modal and the propagation-based approaches. (3) All four models are relatively stable between Week 5 and Week 25. The results further confirm the effectiveness of the multi-modal approach that combines extracted knowledge, text content and propagation network.
7 RELATED WORK
In this section, we provide a brief review of the related work on fake news detection, which has become a popular research problem over recent years. Specifically, following a similar taxonomy in [26, 36], we classify existing work into three categories: content-based approaches, context-based approaches and mixed approaches, which mainly rely on news content, social context, and a mix of both for detection, respectively. In addition, we also summarise prior work on fake news early detection and explainability.
7.1 Content-based Approaches
The most straightforward content-based approach is to consider fake news detection as a text classification problem, and apply techniques such as RST [30], LIWC [25] and text-CNN [17] to identify fake news. These algorithms often serve as baselines.
In addition to the knowledge-based detection methods discussed in this paper, another line of research studies fake news from a style-based perspective.

7.1.1 Style-based Detection. Since the purpose of fake news is to mislead the public, they should exhibit unique writing styles that are rarely seen in real news. This is supported by forensic psychological studies [40], which have shown that statements based on factual experiences differ from those derived from fabrication or fiction in both content and quality.
Therefore, style-based methods aim to identify the different content style, which can be represented by quantifiable features, including attribute-based language features or structure-based language features. For example, Perez-Rosas et al. [29] train linear SVMs on the following linguistic features to detect fake news: unigrams, bigrams, punctuation, psycholinguistic, readability and syntax features. Other methods that fall into this category include [13, 28, 41, 43].
In addition to textual information, images posted in social media have also been investigated to facilitate the detection of fake news [15, 44, 49, 58].
7.2 Context-based Approaches
Social context here refers to the interactions between users, including tweet, retweet, reply, mention and follow. As mentioned in the introduction, these engagements can form the propagation pattern for a news item, and a number of studies have used various types of models to identify the difference in the propagation pattern between real and fake news: Wu et al. [45] use a hybrid SVM; Ma et al. [22] use Propagation Tree Kernel; Wu et al. [46] incorporate LSTM cells into the RNN model; Liu et al. [19] use both RNNs and CNNs; Shu et al. [35] and Zhou et al. [60] propose different types of

Knowledge Enhanced Multi-modal Fake News Detection
features and compare multiple commonly used machine learning models; Monti et al. [23], Lu et al. [20] and Bian et al. [4] apply GNNs to study propagation patterns.
In addition to the propagation network, other types of graphs can also be built from social context. For example, Jin et al. [14] build a stance network where the weight of an edge represents how much each pair of posts support or deny each other. Then the credibility of all the posts related to a news item is estimated to decide whether the news is fake or real, which can be formalised as a graph optimisation problem.
In another example, Tacchini et al. [39] propose to detect fake news based on users who liked them on Facebook. They tested logistic regression-based and harmonic Boolean label crowdsourcingbased methods, and their results suggest that both methods can achieve high accuracy.
While all the above methods are supervised, an unsupervised approach is proposed by Yang et al. [48], which builds a Bayesian probability graphical model to capture the generative process among the validity of news, user opinions and user credibility.
7.3 Mixed Approaches
Since both news content and social context can provide valuable evidence, mixed approaches use these two sources of information to differentiate between fake news and real news.
Ruchansky et al. [31] design a three-module architecture that combines the text of a news article, the received user response and the source of the news: (1) in order to capture temporal representations of articles, the first module trains a RNN that takes the user response, news content and user features as input; (2) the second module generates for each user a score and a low-dimensional representation based on user features; (3) the third module takes the output of the first two modules and trains a neural network to label the news item.
A pre-extracted word set is used in [53] to construct explicit features from the news content, user profile and news subject description. Meanwhile, RNNs are applied to learn latent features, such as news article content information inconsistency and profile latent patterns. Once the features are obtained, a deep diffusive network is built to learn the representations of news articles, creators and subjects.
Shu et al. [37] propose to use the tri-relationship among publishers, news articles and users to detect fake news. Specifically, the latent representations for news content and users are learned with non-negative matrix factorization, and the problem is formalised as an optimisation over the linear combination of each relation. They compare a number of machine learning algorithms to solve the optimisation problem in their experiments.
7.4 Explainability
In addition to the above work, a few recent papers have started to work on explainability, which provides evidence to support why their model labels certain news items as fake/real [20, 27, 33].
For example, Lu et al. [20] propose a novel attention mechanism for fake news detection which jointly considers news textual content, retweet sequences in propagation networks, and user cooccurrence networks.

,,
7.5 Fake News Early Detection
Considering that it is difficult to correct people’s perception towards an issue, even if the previous impression is inaccurate [16], it is more crucial to detect fake news at an early stage before it becomes widespread. Therefore, another line of research works on early detection of fake news [19, 38, 56]. Shu et al. [38] study multiple weak signals of user sentiment, bias and credibility, and then combine weakly labelled data with a small amount of manually labelled data to train a fake news detection model.
8 CONCLUSIONS AND FUTURE WORK
A series of incidents over recent years have demonstrated the significant damage that fake news can cause to society. In this work, we investigate knowledge-enhanced multi-modal techniques for fake news detection. Specifically, we transform the problem of detecting fake news into a subgraph classification task, and design a knowledge-based algorithm that does not require any external knowledge graph. In addition, we propose a multi-modal detection algorithm that combines extracted knowledge, textual content and social context. Experimental results on two datasets with thousands of labelled news items demonstrate the effectiveness of our approaches.
For future work, we will further explore more sophisticated methods rather than simple concatenation to combine different sources of information. Moreover, in addition to news content and propagation networks, we intend to exploit other modalities as well, including images and external knowledge graphs.
REFERENCES
[1] 1999. Resource Description Framework (RDF) Model and Syntax Specification. https://www.w3.org/TR/PR- rdf- syntax/
[2] Emily Alsentzer, Samuel G Finlayson, Michelle M Li, and Marinka Zitnik. 2020. Subgraph Neural Networks. Proceedings of NeurIPS (2020).
[3] Peter W. Battaglia, Jessica B. Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, Caglar Gulcehre, Francis Song, Andrew Ballard, Justin Gilmer, George Dahl, Ashish Vaswani, Kelsey Allen, Charles Nash, Victoria Langston, Chris Dyer, Nicolas Heess, Daan Wierstra, Pushmeet Kohli, Matt Botvinick, Oriol Vinyals, Yujia Li, and Razvan Pascanu. 2018. Relational inductive biases, deep learning, and graph networks. eprint arXiv (2018), arXiv:1806.01261.
[4] Tian Bian, Xi Xiao, Tingyang Xu, Peilin Zhao, Wenbing Huang, Yu Rong, and Junzhou Huang. 2020. Rumor Detection on Social Media with Bi-Directional Graph Convolutional Networks. (2020), arXiv:2001.06362.
[5] Paolo Boldi and Marco Rosa. 2012. Arc-Community Detection via Triangular Random Walks. In 2012 Eighth Latin American Web Congress. 48–56.
[6] Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko. 2013. Translating Embeddings for Modeling Multi-relational Data. In Proc. of NeurIPS.
[7] Limeng Cui and Dongwon Lee. 2020. Coaid: Covid-19 healthcare misinformation dataset. arXiv preprint arXiv:2006.00885 (2020).
[8] Limeng Cui, Haeseung Seo, Maryam Tabar, Fenglong Ma, Suhang Wang, and Dongwon Lee. 2020. DETERRENT: Knowledge Guided Graph Attention Network for Detecting Healthcare Misinformation. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD ’20). Association for Computing Machinery, 492–502.
[9] Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive Representation Learning on Large Graphs. In NeurIPS-2017. Curran Associates, Inc., 1024–1034.
[10] William L. Hamilton. 2020. Graph Representation Learning. Synthesis Lectures on Artificial Intelligence and Machine Learning 14, 3 (2020), 1–159.
[11] Xu Han, Tianyu Gao, Yuan Yao, Deming Ye, Zhiyuan Liu, and Maosong Sun. 2019. OpenNRE: An Open and Extensible Toolkit for Neural Relation Extraction. In Proceedings of EMNLP-IJCNLP: System Demonstrations. 169–174.
[12] Yi Han, Shanika Karunasekera, and Christopher Leckie. 2020. Graph Neural Networks with Continual Learning for Fake News Detection from Social Media. arXiv e-prints (2020), arXiv:2007.03316.

,,
[13] Benjamin D. Horne and Sibel Adali. 2017. This Just In: Fake News Packs a Lot in Title, Uses Simpler, Repetitive Content in Text Body, More Similar to Satire than Real News. arXiv e-prints (2017), arXiv:1703.09398.
[14] Zhiwei Jin, Juan Cao, Yongdong Zhang, and Jiebo Luo. 2016. News Verification by Exploiting Conflicting Social Viewpoints in Microblogs. In Proceedings of the 30th AAAI (AAAI’16). Phoenix, Arizona, 2972–2978.
[15] Z. Jin, J. Cao, Y. Zhang, J. Zhou, and Q. Tian. 2017. Novel Visual and Statistical Image Features for Microblogs News Verification. IEEE Transactions on Multimedia 19, 3 (2017), 598–608.
[16] Jonas De keersmaecker and Arne Roets. 2017. ‘Fake news’: Incorrect, but hard to correct. The role of cognitive ability on the impact of false information on social impressions. Intelligence 65 (2017), 107 – 110.
[17] Yoon Kim. 2014. Convolutional Neural Networks for Sentence Classification. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) (Doha, Qatar). 1746–1751.
[18] Elena Kochkina, Maria Liakata, and Isabelle Augenstein. 2017. Turing at SemEval2017 Task 8: Sequential Approach to Rumour Stance Classification with BranchLSTM. In Proc. of SemEval.
[19] Yang Liu and Yi-fang Brook Wu. 2018. Early Detection of Fake News on Social Media Through Propagation Path Classification with Recurrent and Convolutional Networks. In Proceedings of the 32nd AAAI. 354–361.
[20] Yi-Ju Lu and Cheng-Te Li. 2020. GCAN: Graph-aware Co-Attention Networks for Explainable Fake News Detection on Social Media. (2020), arXiv:2004.11648.
[21] Jing Ma, Wei Gao, Prasenjit Mitra, Sejeong Kwon, Bernard J Jansen, Kam-Fai Wong, and Meeyoung Cha. 2016. Detecting rumors from microblogs with recurrent neural networks. In Proc. of IJCAI.
[22] Jing Ma, Wei Gao, and Kam-Fai Wong. 2017. Detect Rumors in Microblog Posts Using Propagation Structure via Kernel Learning. In Proceedings of the 55th ACL (Vancouver, Canada). 708–717.
[23] Federico Monti, Fabrizio Frasca, Davide Eynard, Damon Mannion, and Michael M. Bronstein. 2019. Fake News Detection on Social Media using Geometric Deep Learning. arXiv e-prints (2019), arXiv:1902.06673.
[24] Jeff Z. Pan, Siyana Pavlova, Chenxi Li, Ningxi Li, Yangmei Li, and Jinshuo Liu. 2018. Content Based Fake News Detection Using Knowledge Graphs. In The Semantic Web – ISWC 2018 (Cham). Springer International Publishing, 669–683.
[25] James W. Pennebaker, Ryan L. Boyd, Kayla Jordan, and Kate Blackburn. 2015. The Development and Psychometric Properties of LIWC 2015. Technical Report. https://repositories.lib.utexas.edu/handle/2152/31333
[26] Francesco Pierri and Stefano Ceri. 2019. False News On Social Media: A DataDriven Survey. SIGMOD Record 48, 2 (2019), 18–27.
[27] Kashyap Popat, Subhabrata Mukherjee, Andrew Yates, and Gerhard Weikum. 2018. DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep Learning. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (Brussels, Belgium). 22–32.
[28] Martin Potthast, Johannes Kiesel, Kevin Reinartz, Janek Bevendorff, and Benno Stein. 2018. A Stylometric Inquiry into Hyperpartisan and Fake News. In Proceedings of the 56th ACL (Melbourne, Australia). 231–240.
[29] Verónica Pérez-Rosas, Bennett Kleinberg, Alexandra Lefevre, and Rada Mihalcea. 2018. Automatic Detection of Fake News. In Proceedings of the 27th International Conference on Computational Linguistics. 3391–3401.
[30] Victoria Rubin, Nadia Conroy, and Yimin Chen. 2015. Towards News Verification: Deception Detection Methods for News Discourse. In Proceedings of the 48th Hawaii International Conference on System Sciences (HICSS48).
[31] Natali Ruchansky, Sungyong Seo, and Yan Liu. 2017. CSI: A Hybrid Deep Model for Fake News Detection. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management (CIKM ’17). 797–806.
[32] Giovanni Santia and Jake Williams. 2018. Buzzface: A news veracity dataset with facebook user commentary and egos. In Proc. of ICWSM.
[33] Kai Shu, Limeng Cui, Suhang Wang, Dongwon Lee, and Huan Liu. 2019. DEFEND: Explainable Fake News Detection. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (New York, NY, USA) (KDD ’19). Anchorage, AK, USA, 395–405.
[34] Kai Shu, Deepak Mahudeswaran, Suhang Wang, Dongwon Lee, and Huan Liu. 2018. FakeNewsNet: A Data Repository with News Content, Social Context and Spatialtemporal Information for Studying Fake News on Social Media. arXiv e-prints (2018), arXiv:1809.01286.
[35] Kai Shu, Deepak Mahudeswaran, Suhang Wang, and Huan Liu. 2019. Hierarchical Propagation Networks for Fake News Detection: Investigation and Exploitation. arXiv e-prints (2019), arXiv:1903.09196.
[36] Kai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, and Huan Liu. 2017. Fake News Detection on Social Media: A Data Mining Perspective. SIGKDD Explorations Newsletter 19, 1 (2017), 22–36.
[37] Kai Shu, Suhang Wang, and Huan Liu. 2019. Beyond News Contents: The Role of Social Context for Fake News Detection. In Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining (New York, NY, USA) (WSDM ’19). Melbourne, VIC, Australia, 312–320.
[38] Kai Shu, Guoqing Zheng, Yichuan Li, Subhabrata Mukherjee, Ahmed Hassan Awadallah, Scott Ruston, and Huan Liu. 2020. Leveraging Multi-Source

Yi Han, Amila Silva, Ling Luo, Shanika Karunasekera, Christopher Leckie
Weak Social Supervision for Early Detection of Fake News. arXiv:2004.01732 (2020). [39] Eugenio Tacchini, Gabriele Ballarin, Marco L. Della Vedova, Stefano Moret, and Luca de Alfaro. 2017. Some Like it Hoax: Automated Fake News Detection in Social Networks. arXiv e-prints (2017), arXiv:1704.07506. [40] Udo Undeutsch. 1967. Beurteilung der Glaubhaftigkeit von Aussagen. Handbuch der Psychologie, Band 11: Forensische Psychologie (1967), 26–181. [41] Svitlana Volkova, Kyle Shaffer, Jin Yea Jang, and Nathan Hodas. 2017. Separating Facts from Fiction: Linguistic Models to Classify Suspicious and Trusted News Posts on Twitter. In Proceedings of the 55th ACL (Vancouver, Canada). 647–653. [42] Soroush Vosoughi, Deb Roy, and Sinan Aral. 2018. The spread of true and false news online. Science 359, 6380 (2018), 1146–1151. [43] William Yang Wang. 2017. “Liar, Liar Pants on Fire”: A New Benchmark Dataset for Fake News Detection. In Proceedings of the 55th ACL. 422–426. [44] Yaqing Wang, Fenglong Ma, Zhiwei Jin, Ye Yuan, Guangxu Xun, Kishlay Jha, Lu Su, and Jing Gao. 2018. EANN: Event Adversarial Neural Networks for MultiModal Fake News Detection. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (New York, NY, USA) (KDD ’18). London, United Kingdom, 849–857. [45] K. Wu, S. Yang, and K. Q. Zhu. 2015. False rumors detection on Sina Weibo by propagation structures. In 2015 IEEE 31st International Conference on Data Engineering. 651–662. https://doi.org/10.1109/ICDE.2015.7113322 [46] Liang Wu and Huan Liu. 2018. Tracing Fake-News Footprints: Characterizing Social Media Messages by How They Propagate. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining (New York, NY, USA) (WSDM ’18). Marina Del Rey, CA, USA, 637–645. [47] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S. Yu. 2019. A Comprehensive Survey on Graph Neural Networks. arXiv e-prints (2019), arXiv:1901.00596. [48] Shuo Yang, Kai Shu, Suhang Wang, Renjie Gu, Fan Wu, and Huan Liu. 2019. Unsupervised Fake News Detection on Social Media: A Generative Approach. Proceedings of the 33rd AAAI 33 (2019), 5644–5651. [49] Yang Yang, Lei Zheng, Jiawei Zhang, Qingcai Cui, Zhoujun Li, and Philip S. Yu. 2018. TI-CNN: Convolutional Neural Networks for Fake News Detection. arXiv e-prints (2018), arXiv:1806.00749. [50] Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He, Alex Smola, and Eduard Hovy. 2016. Hierarchical Attention Networks for Document Classification. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 1480–1489. [51] Yuan Yao, Deming Ye, Peng Li, Xu Han, Yankai Lin, Zhenghao Liu, Zhiyuan Liu, Lixin Huang, Jie Zhou, and Maosong Sun. 2019. DocRED: A Large-Scale Document-Level Relation Extraction Dataset. In Proceedings of ACL 2019. [52] Rex Ying, Jiaxuan You, Christopher Morris, Xiang Ren, William L. Hamilton, and Jure Leskovec. 2018. Hierarchical Graph Representation Learning with Differentiable Pooling. In Proceedings of the 32nd NeurIPS. 4805–4815. [53] Jiawei Zhang, Bowen Dong, and Philip S. Yu. 2018. FAKEDETECTOR: Effective Fake News Detection with Deep Diffusive Neural Network. arXiv e-prints (2018), arXiv:1805.08751. [54] Yuhao Zhang, Victor Zhong, Danqi Chen, Gabor Angeli, and Christopher D. Manning. 2017. Position-aware Attention and Supervised Data Improve Slot Filling. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 35–45. [55] Wenxuan Zhou, Kevin Huang, Tengyu Ma, and Jing Huang. 2021. DocumentLevel Relation Extraction with Adaptive Thresholding and Localized Context Pooling. In Proceedings of the AAAI Conference on Artificial Intelligence. [56] Xinyi Zhou, Atishay Jain, Vir V. Phoha, and Reza Zafarani. 2020. Fake News Early Detection: A Theory-Driven Model. Digital Threats: Research and Practice 1, 2 (2020), 1–25. [57] Xinyi Zhou, Apurva Mulay, Emilio Ferrara, and Reza Zafarani. 2020. Recovery: A multimodal repository for covid-19 news credibility research. In Proc. of CIKM. [58] Xinyi Zhou, Jindi Wu, and Reza Zafarani. 2020. SAFE: Similarity-Aware Multimodal Fake News Detection. In Advances in Knowledge Discovery and Data Mining. Springer International Publishing, 354–367. [59] Xinyi Zhou and Reza Zafarani. 2018. Fake News: A Survey of Research, Detection Methods, and Opportunities. arXiv:1812.00315 [cs] (2018). arXiv:1812.00315 [60] Xinyi Zhou and Reza Zafarani. 2019. Network-based Fake News Detection: A Pattern-driven Approach. arXiv e-prints (2019), arXiv:1906.04210.

