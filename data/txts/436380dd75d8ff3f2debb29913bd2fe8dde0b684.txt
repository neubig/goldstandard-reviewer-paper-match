A COMPLEX MATRIX FACTORIZATION APPROACH TO JOINT MODELING OF MAGNITUDE AND PHASE FOR SOURCE SEPARATION
Chaitanya Ahuja, Karan Nathwani and Rajesh M. Hegde
Indian Institute of Technology, Kanpur Email: {chahuja, nathwani, rhegde}@iitk.ac.in

arXiv:1411.6741v1 [cs.SD] 25 Nov 2014

ABSTRACT
Conventional NMF methods for source separation factorize the matrix of spectral magnitudes. Spectral Phase is not included in the decomposition process of these methods. However, phase of the speech mixture is generally used in reconstructing the target speech signal. This results in undesired traces of interfering sources in the target signal. In this paper the spectral phase is incorporated in the decomposition process itself. Additionally, the complex matrix factorization problem is reduced to an NMF problem using simple transformations. This results in effective separation of speech mixtures since both magnitude and phase are utilized jointly in the separation process. Improvement in source separation results are demonstrated using objective quality evaluations on the GRID corpus.
Index Terms— Non Negative Matrix Factorization, Complex Matrix Factorization, Source Separation, Phase Reconstruction
1. INTRODUCTION
Monaural speaker separation is challenging in the presence of a competing speaker, due to all the information mixed up in a single channel. This results in degradation of intelligibility of the target speaker speech in the presence of an interfering speaker. There have been signiﬁcant breakthroughs to tackle this problem in the yesteryear. Though, when compared to humans’ innate ability to separate mixed speech intuitively, the separation algorithms have a long way to go. This serves as a motivation to develop such source separation systems, which can achieve performance comparable to humans.
In literature, many source separation algorithms have been developed. Computational auditory scene analysis (CASA) [1], hidden Markov models (HMM) [2], sinusoidal modeling [3] and nonnegative matrix factorization (NMF) [3]. NMF [4,5] has been widely used for source separation. In NMF, power spectrograms have been analyzed to reveal underlying latent components of audio signals. Other methods include modifying conventional NMF by applying sparseness constraints and achieving temporal continuity of sources [6].
A novel method to factorize complex matrices is proposed in this paper. This method converts the complex matrix factorization problem to a non-negative matrix factorization (NMF) problem by using simple transformations. Conventional NMF factorizes the magnitude of the input complex matrix, hence disregarding phase. Additionally, phase of the mixed signal is generally used for individual signal reconstruction which brings undesired traces of interfering sources in the target signal. In the proposed method, phase is taken into account while decomposition itself and thus is called complex matrix factorization (CMF). CMF has been attempted before in [7–10]. Some of these methods assume a probabilistic approach

Fig. 1. Illustrating CMF for joint modeling of phase and magnitude
while estimating the error where as our method involves a deterministic approach to solve the problem at hand.
NMF has been used for various applications other than source separation. A denoising method using NMF has been explained in [11]. In [12] NMF has been applied to polyphonic music transcription. Speech Enhancement has also been performed using an NMF framework in [13]. Multi-channel source separation using factorization of complex data has been discussed in [14]. We will, instead, look into application of the proposed CMF in supervised single-channel separation domain. Our proposed method converts the complex matrix to a non-negative matrix while maintaining the integrity of the problem. Hence, for all methods based on an NMF framework, CMF could be a desired alternative.
Objective evaluations on separated individual speech signals are used for illustrating the signiﬁcance of the proposed method when compared to other single channel source separation methods in literature. GRID corpus database has been used in the performance evaluation.
Terminologies used throughout the paper are as follows. |A| and φA gives the magnitude and phase respectively of a complex matrix A, . represents the Frobenius norm in all cases.
The remainder of this paper is organized as follows. Section 2 describes problem formulation for source separation in anechoic environment. In Section 3, Matrix Factorization is explained along with the Complex Matrix Factorization (CMF) formulation. An algorithm is also proposed to incorporate the new theory into application. Section 4 deals with Performance Evaluation of phase reconstruction and speech separation. Finally, in Section 5 the discussion is concluded with future prospects of the proposed theory.

2. PROBLEM FORMULATION
Let us consider a mixed speech signal z(n) consisting of two speakers z1(n) and z2(n). The objective of speaker separation is to obtain the estimates of z1(n) and z2(n) where n are the time samples. Speech signals have huge amount of variation in time-domain, hence signals are transformed to frequency-domain for further analysis. Let Z(k, m), Z1(k, m) and Z1(k, m) represent the STFT of z(n), z1(n) and z2(n) respectively. Here, k represents frequency bin index and m corresponds to the frame index in STFT. Since STFT is linear, we can write

Z(k, ω) = Z1(k, ω) + Z2(k, ω)

(1)

|Z(k, ω)|ejφZ(k,ω) = |Z1(k, ω)|ejφZ1(k,ω) + |Z2(k, ω)|ejφZ2(k,ω) (2)
Standard separation methods involve constructing trained bases [15] for both the speakers in question. With the constructed bases, corresponding weights are calculated for a mixture giving way to estimation of separated speech signals.
We use speech zi(n) of the ith speaker from the training set of clean speech to generate a bases vector set Xtrain. This bases vector set can be used to estimate weights Hi corresponding to each speaker. Both, generating a bases vector set and estimation of weights require CMF. Hence the problem reduces to ﬁnding an accurate technique to estimate complex bases Xtrain and corresponding weights Hi such that Zi ≈ XtrainHi.

3. COMPLEX MATRIX FACTORIZATION APPROACH TO JOINT MODELING OF MAGNITUDE AND PHASE

Non negative matrix factorization is a widely accepted method for single-channel source separation. Decomposition of the speech into basis vectors and corresponding weights has been shown to work well for signal-channel mixtures. In general, Non-Negative Matrix Factorization (NMF) has been used to factorize the magnitudes in the given matrix. Phase, is either taken to be equal to the input signal or is reconstructed via various methods.
Given a Non-Negative Matrix Z, we factorize it to non-negative factors X and H such that

Z ≈ XH

(3)

This problem does not have a closed-form solution. Classically, numerical solutions have been computed by constructing an appropriate optimization problem. We have fast converging iterative algorithms which ensure reduction in distance between Z and XH after successive updates. The proposed Complex Matrix Factorization has been formulated for Euclidean Distance metric, hence Euclidean Distance is minimized in the classic NMF domain
min Z − XH 2 with respect to X and H (4)
Z, X and H are Non-Negative Matrices
Iterative Updates in [5], that ensure convergence of X and H, are given as follows

(ZHT )

(XT Z)np

Xmn

←

Xmn

(XHHT

mn
)

Hnp ← Hnp (XT XH)

(5)

mn

np

It has been proved in literature that every update will decrease the distance between Z and XH. Stability of the updates have also been discussed in [16].

In Section 3.1, we start with a new method of Complex Matrix Factorization (CMF) which is used to reconstruct phase and magnitude jointly, within the NMF framework. Discussion related to the need of phase reconstruction is covered in Section 3.1.1. Reconstruction of individual speech signals is talked about in 3.2. In Section 3.3, an algorithm has been proposed which incorporates all the modiﬁcations.

3.1. The proposed complex matrix factorization approach
Consider Z to be a complex matrix. Let the bases vectors be denoted by a matrix X and the corresponding weights by H. Here X is complex and H real. Also, let Zˆ = XH. To reduce CMF to NMF, we perform separation in Z, Zˆ, X and H (also shown in Figure 1) via a simple transformation given as follows

Zˆ = Zˆ+r − Zˆ−r + j Zˆ+i − Zˆ−i

(6)

where,

Zˆ+r = max 0, real Zˆ

Zˆ−r = − min 0, real Zˆ

Zˆ+i = max 0, imag Zˆ Zˆ−i = − min 0, imag Zˆ

(7) where max, min, real and imag are element-wise functions, taking maxima, taking minima, real part and imaginary part of each element.
Z is also separated as described in Equation 7, whereas X and H are to be separated as follows

X = X+r − X−r + j (X+i − X−i)

(8)

H = H+ − H−

(9)

where X+r, X−r, X+i, X−i, H+ and H− are non-negative matrices Simplifying and comparing LHS and RHS of Zˆ = XH we get

Zˆ1 = Zˆ+r = X+rH+ + X−rH−

Zˆ2 = Zˆ−r = X+rH− + X−rH+

Zˆ3 = Zˆ+i = X+iH+ + X−iH−

(10)

Zˆ4 = Zˆ−i = X+iH− + X−iH+

Lastly, for convenience sake let

Z1 = Z+r Z2 = Z−r Z3 = Z+i Z4 = Z−i (11)

With all the equations in place, let us move to the transformation of CMF to NMF. Apply triangle inequality to Equation 4 to get

4

min Z − XH 2 ≤ min

Zk − Zˆk 2

(12)

X,H

X,H

k=1

As Zk’s and Zˆk’s are independent of each other we get

4

min Z − XH 2 ≤ min Zk − Zˆk 2

(13)

X,H

X,H

k=1

The problem now reduces to minX,H Zk − Zˆk 2 for all k ∈ {1, 2, 3, 4}. RHS value of Equation 13 gives an upper bound to the

Fig. 2. Spectrogram of (a) Mixed speech signal (b) Individual speech signal used as a ground truth, (c) Reconstructed speech signal via CMFbrian, (d) Reconstructed speech signal via proposed CMF

solution of the optimization problem in Equation 4. Hence convergence of RHS of Equation 13 guarantees convergence of the cost function in Equation 4.
Now, we have 4 optimization problems to be solved simultaneously with same variables having dependencies on different cost functions. Solving them sequentially would lead to a bias towards the ﬁrst optimization problem. To avoid divergent solutions, we combine the sub-matrices to get a single matrix. This is shown as follows

Zˆ+r Zˆ−r

X+r X−r

Zˆ+i Zˆ−i = X+i X−i

or,

H+ H−

H− H+

(14)

Zˆ1 Zˆ2

X1 X2

H1 H2

Zˆ3 Zˆ4 = X3 X4

H3 H4

(15)

Zˆc = XcHc

(16)

As H1 = H4 and H2 = H3, we perform an update after every NMF iteration which takes care of the aforementioned constraints.

H1, H4 ← H1+2 H4 H2, H3 ← H2+2 H3

(17)

The CMF problem is now reduced to an NMF problem of the form

min Zc − XcHc 2 with respect to Xc and Hc

Zc =

Z+r Z+i

Z−r Z−i

, Xc and Hc are Non-Negative Matrices

(18)

This can be solved by various methods in literature, of which

one of them is referred to in Equation 5.

3.1.1. Signiﬁcance of phase spectrum in reconstruction of individual signals
In general, phase of the individual source signals is not used in estimating the separated signals. The original phase of the mixture is taken as it is for the reconstructed separated signal in the conventional methods [17]. However, phase plays an important role in the reconstruction of individual source signals. This can be noted in [18], where the estimated signal’s SNR increases by up to 1.8 dB.

In this work, phase is taken into account in the decomposition process itself. This leads to a robust speech reconstruction method with improved perceptual quality.

3.2. Reconstruction of individual speech signals
For the ith speaker, trained bases Xtrain(i) are obtained by applying CMF on

Zi ≈ Xtrain(i)Hˆ i

(19)

Given a mixed speech signal Z of speaker i and j in STFT domain,
and Xtrain(i)’s as known and ﬁxed quantities, we solve for Hi and Hj by applying CMF on

Z ≈ Xtrain(i) Xtrain(j)

H(i) H

(20)

(j)

Separated speech signals Zei stm and Zej stm are estimated by

Zei stm ← Xtrain(i)H(i) Zej stm ← Xtrain(j)H(j)

(21)

3.3. Algorithm to compute bases and weights using the proposed CMF method
The algorithmic steps to compute the bases X and corresponding weights H are listed in Algorithm 1.

Algorithm 1 : Algorithm to compute H, X using proposed CMF

Method

1: Initialization: Random non-negative values are assigned to

X+r, X−r, X+i, X−i, H+ and H−.

2: Rearrange these sub-matrices to form Xc and Hc as shown in

Equation 15 and 16.

(ZcHTC )

3:

Xc(ij)

←

Xc(ij)

(Xc

Hc

HT

(ij)
)

c (ij)

(XTc Zc)

4:

Hc(jk)

←

Hc(jk)

(XT

Xc

(jk)
Hc )

c

(jk)

5: H1, H4 ← H1+2 H4 and H3, H2 ← H2+2 H3 . 6: Repeat: Step 2 through 5 for a number of iterations to minimize

the distance between Z and Zc.

7: Termination: X ← X1 −X2 +j (X3 − X4) and H ← H+ −H−

to reconstruct the actual factors along with the correct phases.

Table 1. Objective Evaluation results of individual speech reconstructed by various methods

Methods PESQ TIRloss
TIRLESC

NTF µσ 0.81 0.56 0.96 0.02 0.74 0.14

NMF µσ 2.03 0.50 0.96 0.01 0.50 0.1

CMFbrian µσ
2.31 0.55 0.89 0.05 0.12 0.05

CMF µσ 2.26 0.35 0.89 0.01 0.40 0.08

4. PERFORMANCE EVALUATION
Section 4.1 describes the database used for performance evaluation of the algorithm. Spectrographic Analysis and Phase reconstruction are discussed in Section 4.2 and 4.3 respectively.
4.1. Database
Grid-Corpus Database [19] is used for testing purposes in this work. This database consists of 1000 clean speech signals for each of the 34 speakers listed. Audio-Intelligibility tests indicated that speech material is understandable without the video, hence the database is used to test and compare various algorithms.
Mixtures of speech signals are generated with target to interference ratio equal to 1. The experiments are performed in a supervised manner. We use 200 speech signals of ﬁrst 10 speakers for training and use 100 speech signals of the same speakers for testing. The proposed algorithm is compared with other methods in literature using the testing set.
4.2. Spectrographic Analysis
Training data from Grid-Corpus [19] was used to estimate bases vectors for each speaker. The proposed algorithm in Section 3.3 was applied to estimate the separated signals from a given mixture of speech signals which are a part of the Testing data. A sample of reconstructed Spectrograms by the proposed CMF and CMF in [9] are depicted in Figure 2. Demo of source separation can be seen at1.
4.3. Phase Reconstruction Accuracy
Simulations were performed by factorizing STFT of some speech signals. This was done to test the convergence of Algorithm-1 for complex signals. Figure 3 gives a pictorial representation of phase of a column vector of STFT of input (Z) versus estimated phase of the respective column vector of STFT of output (Zˆ).
4.4. Objective evaluation of reconstructed speech signals
Reconstruction was performed for 500 mixtures generated from Grid-Cropus. Non-negative matrix factorization (NMF), Nonnegative tensor factorization (NTF) [20], Complex-matrix factorization in [9] (CMFbrian) and the proposed Complex-matrix factorization have been used on the same testing data to extract individual speech signals from a given mixture. Objective evaluation values PESQ, target to interference ratio loss (TIRLoss) and excitation spectra correlation (TIRESC) have been calculated for all factorization methods and are listed in Table 1. TIRLoss and TIRLESC are values similar to SNRLoss and SNRLESC deﬁned in [21] with the signal being replaced by the target-speaker and noise by interference.
PESQ [22] gives a overall speech quality evaluation on a scale of 1 (bad) to 5 (good). TIRLoss gives a quantitative value to
1http://home.iitk.ac.in/˜rhegde/chdemo.html

Fig. 3. Comparison of original versus estimated phase of one timeframe of STFT. The phase was estimated by the proposed CMF method
loss due to interference on a scale of 0 (good) to (bad). TIRESC = [TIRloss] 1 − r2 is also a value between 0 (good) to 1 (bad), where r is the correlation coefﬁcient between the clean speech and reconstructed speech of the target speaker.
The mean scores (µ) obtained, imply that CMF performs much better than NTF and NMF. It performs equally well when compared to CMFbrian. The standard deviation (σ) of PESQ and TIRloss values of reconstructed speech by CMF is lower than CMFbrian which indicates that the performance of CMF remains more consistent than CMFbrian. Although, the reconstructions by CMF and CMFbrian are competitive, the proposed CMF is computationally more efﬁcient as it uses the standard NMF framework.
5. CONCLUSION
A new method of complex matrix factorization, which jointly utilizes both the spectral magnitude and phase is proposed in this work for single channel source separation. In this work the phase spectrum is incorporated into the decomposition stage, along with magnitude, making it a complex factorization method. Additional contributions of this work include converting the complex matrix factorization method into a standard NMF method using simple transformations.
Its superiority is demonstrated with respect to other methods, using magnitude only reconstruction, motivating the need for incorporating phase into the decomposition process. Although this method has been applied to single-channel source separation, the proposed algorithm and can be applied to any generalized NMF method with applications in speech enhancement, music transcription and multi channel source separation. Currently we are investigating different distance measures to obtain better performance at lower SNR.

6. REFERENCES
[1] Albert S Bregman, Auditory scene analysis: The perceptual organization of sound, MIT press, 1994.
[2] Sam T Roweis, “One microphone source separation,” in NIPS, 2000, vol. 13, pp. 793–799.
[3] Pejman Mowlaee, Mads Græsbøll Christensen, and Søren Holdt Jensen, “Improved single-channel speech separation using sinusoidal modeling,” in Acoustics Speech and Signal Processing (ICASSP), 2010 IEEE International Conference on. IEEE, 2010, pp. 21–24.
[4] Daniel D Lee and H Sebastian Seung, “Learning the parts of objects by non-negative matrix factorization,” Nature, vol. 401, no. 6755, pp. 788–791, 1999.
[5] Daniel D Lee and H Sebastian Seung, “Algorithms for nonnegative matrix factorization,” in Advances in neural information processing systems, 2001, pp. 556–562.
[6] Tuomas Virtanen, “Monaural sound source separation by nonnegative matrix factorization with temporal continuity and sparseness criteria,” Audio, Speech, and Language Processing, IEEE Transactions on, vol. 15, no. 3, pp. 1066–1074, 2007.
[7] R Mitchell Parry and Irfan Essa, “Incorporating phase information for source separation via spectrogram factorization,” in Acoustics, Speech and Signal Processing, 2007. ICASSP 2007. IEEE International Conference on. IEEE, 2007, vol. 2, pp. II– 661.
[8] Hirokazu Kameoka, Nobutaka Ono, Kunio Kashino, and Shigeki Sagayama, “Complex nmf: A new sparse representation for acoustic signals,” in Acoustics, Speech and Signal Processing, 2009. ICASSP 2009. IEEE International Conference on. IEEE, 2009, pp. 3437–3440.
[9] Brian King and Les Atlas, “Single-channel source separation using simpliﬁed-training complex matrix factorization,” in Acoustics Speech and Signal Processing (ICASSP), 2010 IEEE International Conference on. IEEE, 2010, pp. 4206–4209.
[10] Holger Kirchhoff, Roland Badeau, Simon Dixon, et al., “Towards complex matrix decomposition of spectrograms based on the relative phase offsets of harmonic sounds,” in Proc. of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2014.
[11] Kevin W Wilson, Bhiksha Raj, and Paris Smaragdis, “Regularized non-negative matrix factorization with temporal dependencies for speech denoising.,” in INTERSPEECH, 2008, pp. 411–414.
[12] Nancy Bertin, Roland Badeau, and Emmanuel Vincent, “Enforcing harmonicity and smoothness in bayesian non-negative matrix factorization applied to polyphonic music transcription,” Audio, Speech, and Language Processing, IEEE Transactions on, vol. 18, no. 3, pp. 538–549, 2010.

[13] Nasser Mohammadiha, Paris Smaragdis, and Arne Leijon, “Supervised and unsupervised speech enhancement using nonnegative matrix factorization,” Audio, Speech, and Language Processing, IEEE Transactions on, vol. 21, no. 10, pp. 2140– 2151, 2013.
[14] Hiroshi Sawada, Hirokazu Kameoka, Shoko Araki, and Naonori Ueda, “Multichannel extensions of non-negative matrix factorization with complex-valued data,” IEEE Transactions on Audio, Speech and Language Processing, vol. 21, no. 5, pp. 971–982, 2013.
[15] Y. Wang, A Narayanan, and D. Wang, “On training targets for supervised speech separation,” Audio, Speech, and Language Processing, IEEE/ACM Transactions on, vol. 22, no. 12, pp. 1849–1858, Dec 2014.
[16] Roland Badeau, Nancy Bertin, and Emmanuel Vincent, “Stability analysis of multiplicative update algorithms for nonnegative matrix factorization,” in Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on. IEEE, 2011, pp. 2148–2151.
[17] Paris Smaragdis, “Convolutive speech bases and their application to supervised speech separation,” Audio, Speech, and Language Processing, IEEE Transactions on, vol. 15, no. 1, pp. 1–12, 2007.
[18] Timo Gerkmann, Martin Krawczyk, and Robert Rehr, “Phase estimation in speech enhancementunimportant, important, or impossible?,” in Electrical & Electronics Engineers in Israel (IEEEI), 2012 IEEE 27th Convention of. IEEE, 2012, pp. 1–5.
[19] Martin Cooke, Jon Barker, Stuart Cunningham, and Xu Shao, “An audio-visual corpus for speech perception and automatic speech recognition,” The Journal of the Acoustical Society of America, vol. 120, no. 5, pp. 2421–2424, 2006.
[20] Tom Barker and Tuomas Virtanen, “Non-negative tensor factorisation of modulation spectrograms for monaural sound source separation.,” in INTERSPEECH, 2013, pp. 827–831.
[21] Jianfen Ma and Philipos C. Loizou, “Snr loss: A new objective measure for predicting the intelligibility of noise-suppressed speech,” Speech Commun., vol. 53, no. 3, pp. 340–354, Mar. 2011.
[22] Antony W Rix, John G Beerends, Michael P Hollier, and Andries P Hekstra, “Perceptual evaluation of speech quality (pesq)-a new method for speech quality assessment of telephone networks and codecs,” in Acoustics, Speech, and Signal Processing, 2001. Proceedings.(ICASSP’01). 2001 IEEE International Conference on. IEEE, 2001, vol. 2, pp. 749–752.

