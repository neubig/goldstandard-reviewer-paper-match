Show, Don’t Tell: Demonstrations Outperform Descriptions for Schema-Guided Task-Oriented Dialogue
Raghav Gupta∗, Harrison Lee∗, Jeffrey Zhao, Abhinav Rastogi, Yuan Cao, Yonghui Wu Google Research
{raghavgupta, harrisonlee}@google.com

arXiv:2204.04327v1 [cs.CL] 8 Apr 2022

Abstract
Building universal dialogue systems that can seamlessly operate across multiple domains/APIs and generalize to new ones with minimal supervision and maintenance is a critical challenge. Recent works have leveraged natural language descriptions for schema elements to enable such systems; however, descriptions can only indirectly convey schema semantics. In this work, we propose Show, Don’t Tell, a prompt format for seq2seq modeling which uses a short labeled example dialogue to show the semantics of schema elements rather than tell the model via descriptions. While requiring similar effort from service developers, we show that using short examples as schema representations with large language models results in stronger performance and better generalization on two popular dialogue state tracking benchmarks: the Schema-Guided Dialogue dataset and the MultiWoZ leave-one-out benchmark.
1 Introduction
Task-oriented dialogue (TOD) systems need to support an ever-increasing variety of services. Since many service developers lack the resources to collect labeled data and/or the requisite ML expertise, zero and few-shot transfer to unseen services is critical to the democratization of dialogue agents.
New approaches to TOD that can generalize to new services primarily rely on combining two techniques: large language models like BERT (Devlin et al., 2019) and T5 (Raffel et al., 2020), and schema-guided modeling i.e. using natural language descriptions of schema elements (intents and slots) as model inputs to enable inference on unseen services (Rastogi et al., 2020a,b). Models combining the two currently show state-of-the-art results on dialogue state tracking (DST) (Heck et al., 2020; Lee et al., 2021a; Zhao et al., 2022).
∗*Equal contribution

However, description-based schema representations have drawbacks. Writing precise natural language descriptions requires manual effort and can be tricky, and descriptions only provide indirect supervision about how to interact with a service compared to an example. Furthermore, Lee et al. (2021b) showed that state-of-the-art schemaguided DST models may not be robust to variation in schema descriptions, causing signiﬁcant accuracy drops.
We propose using a single dialogue example with state annotations as an alternative to the description-based schema representation, similar to one-shot priming (Brown et al., 2020). Rather than tell the model about schema element semantics in natural language, we show the schema through a demonstration, as in Figure 1. Applying our approach, Show, Don’t Tell (SDT), to two SotA DST models consistently results in superior accuracy and generalization to new APIs across both the Schema-Guided Dataset (SGD) (Rastogi et al., 2020b) and MultiWoZ Leave-OneOut (Budzianowski et al., 2018; Lin et al., 2021b) benchmarks, while being more data-efﬁcient and robust to schema variations.
2 Show, Don’t Tell
Following SoTA models, we pose DST as a seq2seq task (Wu et al., 2019; Zhao et al., 2021a), where the seq2seq language model (in our case, T5) is ﬁnetuned on a DST dataset. During ﬁnetuning and evaluation, the model input consists of a prompt and context, and the target contains ground truth belief states. We compare against two baselines:
• T5-ind (Lee et al., 2021a): Model input comprises the dialogue history as context concatenated with one slot description as the prompt. The target is the value of that slot in the dialogue state. Inference is done per slot - i.e. values for different slots are independently decoded.

T5-ind P1 = amount: The amount of money to send or request P2 = receiver: Name of the contact or account to make the transaction with ...
T5-seq P = 0: The amount of money to send or request 1: Name of the contact or account to make the transaction with 2: Whether the transaction is private or not a) True b) False 3: The source of money used for making the payment a) credit card b) debit card c) app balance

SDT-ind Pi1nd = [ex] [user] I need to transfer 125 dollars [slot] amount=125 dollars Pi2nd = [ex] [user] Make the transfer to Victoria. [slot] receiver=Victoria ...
SDT-seq Pseq = [ex] [user] I want to make a payment to Jerry for $82 from my mastercard [system] Conﬁrming you want to pay Jerry $82 with your credit card yes? [user] Yes that’s right, make the transaction private too [slot] amount=$82 receiver=Jerry private_visibility=a of a) True b) False payment_method=a of a) credit card b) debit card c) app balance

Figure 1: Illustration of all prompt formats for a payment service for both description-based and Show, Don’t Tell models with independent (top) and sequential (bottom) decoding of dialogue state.

• T5-seq (Zhao et al., 2022): Model input comprises the descriptions of all slots as the prompt, followed by the dialogue history as the context. The target is the sequence of slot-value pairs in the dialogue state - i.e. the dialogue state is decoded sequentially in a single pass.
We modify the prompt formats above to utilize demonstrations instead of descriptions as described below and illustrated in Figure 1.
• SDT-ind: A prompt Piind comprises a single utterance labeled with a slot value pair formatted as Piind = [ex]; uiind; [slot]; svi where uiind is a user utterance where slot i is active and svi is the slot value pair. [ex], [slot] are special delimiter tokens, and ; denotes concatenation.
• SDT-seq: A prompt Pseq comprises a single labeled dialogue formatted as:
Pseq = [ex]; u1; ...; un; [slot]; sv1; ...; svm
where uj is an utterance, and other symbols are shared with SDT-ind. In simple terms, the prompt is constructed by concatenating all utterances in the example dialogue followed by all slot-value pairs in the ﬁnal dialogue state.
The context in both formats is a concatenation of the dialogue history for the current training example. The ﬁnal model input is formed by concatenating the prompt and the context strings. The target string is the same as T5-*, containing only

a single slot value for *-ind models and the entire turn’s belief state for *-seq models.
For both T5-* (baseline) and SDT-*, we enumerate the categorical slot values in multiple-choice format in the prompt and task models with decoding the correct multiple choice letter.
More details on the prompt design and its impact on performance are provided in Appendix C. Formulating prompt examples: It is imperative that SDT prompts contain sufﬁcient information to infer the semantics for all slots in the schema. This is easy for SDT-ind, which uses a separate prompt for each slot. However, for SDT-seq, we only choose example dialogues where all slots in the schema are used.
3 Experimental Setup
Datasets: We conduct experiments on two DST benchmarks: Schema-guided Dialogue (SGD) (Rastogi et al., 2020b) and MultiWOZ 2.1 (Budzianowski et al., 2018; Eric et al., 2020). For MultiWOZ, we evaluate on the leave-one-out setup (Wu et al., 2019; Lin et al., 2021a), where models are trained on all domains but one and evaluated on the holdout domain. Additionally, we apply the recommended TRADE pre-processing script1 for fair comparison with other work. For both datasets, we created concise prompt dialogues modeled after dialogues observed in the datasets. Implementation: We train SDT models by ﬁnetuning pretrained T5 1.1 checkpoints. For both datasets, we select one example prompt per service schema (for SDT-seq) or slot (for SDT-ind),
1https://github.com/budzianowski/ multiwoz#dialog-state-tracking

Model MRC+WD-DST* T5-seq T5-ind SDT-ind SDT-seq

All 86.5 86.4 87.7 87.5±0.9 88.8±0.5

Seen 92.4 95.8 95.3 95.2±0.7 95.8±0.2

Unseen 84.6 83.3 85.2
85.0±1.4 86.4±0.7

Table 1: SGD test set JGA for SDT versus other approaches. *Data augmentation/special rules applied.

and use the same prompt for all examples for that service/slot across training and evaluation. Unless otherwise noted, all T5-based models (T5/SDTseq/ind) are ﬁnetuned on T5-XXL (11B parameters). See appendices A and B for more details on training and baselines respectively.
4 Results
4.1 Results on SGD
Table 1 contains results on the SGD test set. Since SDT results may depend on the choice of example turn/dialogue provided in the prompt, 5 different versions of prompts are created for each service using different examples. We report the average JGA across these versions and the 95% conﬁdence intervals. SDT-seq achieves the highest JGA, showing major gains, particularly on unseen services, over its description-based counterpart T5-seq and the next-best model T5-ind. SDT-ind is comparable to its counterpart T5-ind, and better than T5-seq. Based on these results, conveying service semantics via a single dialogue example appears more effective than using natural language descriptions.
We hypothesize that SDT-seq outperforms SDTind because the full dialogue prompts used in SDTseq demonstrate more complex linguistic patterns (e.g. coreference resolution, long term dependencies) than the single utterance prompts of SDT-ind. On the other hand, T5-seq does not outperform T5ind because no additional information is conveyed to the model through stacking descriptions. Also all-else-equal, decoding all slots in one pass is more challenging than decoding each slot independently.
We also experimented with using more than one dialogue to prompt SDT-seq, but we did not see an increase in performance.
4.2 MultiWOZ Results
Table 2 summarizes results for the MultiWOZ 2.1 leave-one-out setup. Comparing T5-seq and SDTseq, both ﬁnetuned on T5-XXL, SDT achieves

Model Attraction Hotel Restaurant Taxi Train Avg

TRADE

20.1 14.2 12.6 59.2 22.4 25.7

SUMBT

22.6 19.8 16.5 59.5 22.5 28.2

TransferQA 31.3 22.7 26.3 61.9 36.7 35.8

T5-seq

76.1 28.6 69.8 87.0 60.4 64.4

SDT-seq

73.2 34.2 71.9 83.7 68.4 66.3

Table 2: Cross-domain (leave-one-out) JGA on MultiWOZ 2.1. Results for TRADE, SUMBT, and TransferQA from (Kumar et al., 2020), (Campagna et al., 2020), and (Lin et al., 2021a), respectively.

state-of-the-art results on the overall task by +2% and in 3 of the 5 domains.

4.3 Impact of Model Size
T5’s XXL size may be unsuitable in a number of settings; consequently, we measure SDT’s performance on SGD across other model sizes in Table 3. For the base and large model sizes, both SDT variations offer higher JGA than their description-based counterparts, possibly due to smaller T5 models being less capable of inferring unseen slots with just a description. Additionally, SDT-ind outperforms SDT-seq for these sizes.

Model T5-seq T5-ind SDT-ind SDT-seq

Base (250M) 72.9 72.6
78.2±0.6 76.3±1.6

Large (800M) 80.0 82.2
83.7±0.8 83.2±0.6

XXL (11B) 86.4 87.7
87.5±0.9 88.8±0.5

Table 3: SGD test set JGA across T5 model sizes.

4.4 Data Efﬁciency
To examine the data efﬁciency of SDT models, we train SDT-seq in a low-resource setting with 0.16% (10-shot), 1%, and 10% of the SGD training data and evaluate on the entire test set. For 10-shot, we randomly sample 10 training dialogues from every service; for 1% and 10%, we sample uniformly across the entire dataset. SDT-seq demonstrates far higher data efﬁciency than T5-seq (Table 4).

Model T5-seq SDT-seq

10-shot 1% 10% 51.0 79.4 83.0 70.7 84.5 87.4

Table 4: Data efﬁciency experiments on SGD test set.

4.5 Robustness
Large LMs are often sensitive to the choice of prompt (Zhao et al., 2021b; Reynolds and Mc-

Example Dialogue
1. T5-seq confused by similar-sounding slots I need to ﬁnd tickets to Anaheim, CA. When would you like to travel, and where are you going to? Traveling to Sacramento on the 4th.
2. T5-seq misses active slots Can you please add an alarm called Grocery run.
3. SDT-seq misses categorical values not seen in prompt I like Broadway shows and want to see one on Tuesday next week.

Error T5-seq: to=Sacramento, from=Anaheim
T5-seq: new_alarm_name=None SDT-seq: event_type=music (ground truth=theater)

Figure 2: Examples of common error patterns made by T5-seq but not SDT-seq, and vice versa.

Donell, 2021). To this end, we evaluate SDT-seq on the SGD-X (Lee et al., 2021b) benchmark, which comprises 5 variants with paraphrased slot names and descriptions per schema (see Appendix Figure 4). Table 5 shows SDT-seq achieves the highest average JGA (J GAv1−5) and lowest schema sensitivity (SSJGA), indicating it is the most robust of the compared models. Even so, the JGA decline indicates SDT-seq is sensitive to how slot names are written.

Model SGP-DST* T5-indbase* T5-seq (name)# T5-seq SDT-seq

J GAOrig 60.5 72.6 79.7 86.4 88.8

J GAv1−5 49.9 64.0 73.0 77.8 81.2

Dif frel -17.5 -11.9 -8.4 -10.0 -8.6

S SJ GA 51.9 40.4 35.0 27.0 24.1

Table 5: Robustness evaluation on the SGD-X test sets. *Results from Lee et al. (2021b). #Result of using T5-seq with only slot names and not descriptions, from Zhao et al. (2022).

5 Discussion
5.1 Writing descriptions vs. demonstrations
We note that the information provided to SDT is not identical to what is provided to typical schemaguided models, as SDT exchanges natural language descriptions for a demonstration of identifying slots in a dialogue. However, we argue that from the developer standpoint, creating a single example is similar in effort to writing descriptions, so we consider the methods comparable. Creating the SDT-seq prompts for all 45 services in SGD took an experienced annotator ∼2 hours, compared to ∼1.5 hours for generating slot descriptions. SDTind prompts are even simpler to write because they relax the requirement for creating a coherent dialogue where all slots are used.
One advantage of descriptions is that they can be

easier to generate than a succinct dialogue that covers all slots. However, given the performance gain, example-based prompts may be a better choice for many settings, especially for smaller model sizes where the gain is more pronounced.
5.2 Descriptions plus demonstrations
Training with descriptions has proven effective for improving DST performance (Zhao et al., 2022; Lee et al., 2021a), and our experiments show that demonstrations are even more effective. We combined both together to see if the two are complementary or overlapping, and we ﬁnd that performance does not improve above using demonstrations alone (Appendix Table A1. We hypothesize that demonstrations already convey slot semantics sufﬁciently and descriptions become extraneous.
5.3 Prompting vs. traditional ﬁnetuning
To understand the impact of using a single demonstration as a prompt vs. traditional ﬁnetuning, we ﬁnetune T5-seq a second time on the same set of dialogues used in SDT-seq prompts; it therefore has access to both slot descriptions as well as a single demonstration for each service. In this case, T5-seq is provided strictly more information than SDT-seq. T5-seq with ﬁnetuning obtains a JGA of 87.7% on SGD, on par with T5-ind but still lower than SDT-seq, suggesting that dialogue examples are better used as prompts (Le Scao and Rush, 2021). Interestingly, ﬁnetuning on more than one dialogue example per service did not improve performance (Appendix Figure 3).
5.4 Error analysis
Figure 2 compares some common errors made by T5-seq and SDT-seq. The patterns suggest that SDT’s demonstrations are helpful when multiple slots are similar to each other (#1) and when prompt dialogues closely match target dialogues

(#2). However, SDT can be limited by its prompt. For instance, in #3 it has only seen the "music" value for the event_type slot in the prompt, potentially resulting in under-predicting the other categorical value ("theater").
6 Related Work
Prior approaches focused on framing DST as question answering (Ruan et al., 2020; Ma et al., 2019; Zhang et al., 2021). Many MultiWoZ cross-domain models leverage slot names/descriptions (Wu et al., 2019; Lee et al., 2019; Lin et al., 2021a).
Pretrained generative LLMs (Raffel et al., 2020; Brown et al., 2020) have enabled framing NLP tasks as seq2seq problems. Some DST papers (Zhao et al., 2021a; Feng et al., 2021) look at settings with no train-test discrepancy. Many studies explore the efﬁcacy of task-speciﬁc prompts (Jiang et al., 2020; Liu et al., 2021). Madotto et al. (2020) and prime LMs with examples for dialogue tasks, but without ﬁnetuning. Wei et al. (2021) ﬁnetunes language models to understand prompts for a different task.
7 Conclusion
We study the use of demonstrations as LM prompts to convey the semantics of APIs in lieu of natural language descriptions for TOD. While taking similar effort to construct, demonstrations outperform description-based prompts in our experiments across DST datasets (SGD and MultiWOZ), model sizes, and training data sizes, while being more robust to changes in schemata. This work provides developers of TOD systems with more options for API representations to enable transfer to unseen services. In future work, we would like to explore this representation for other TOD tasks (e.g. dialogue management and response generation).
8 Ethical Considerations
We proposed a more efﬁcient way of building TOD systems by leveraging demonstrations in place of descriptions, leading to increased accuracy with minimal/no data preparation overhead. We conduct our experiments on publicly-available TOD datasets in English, covering domains which are popular for building conversational agents. We hope our work leads to building more accurate TOD systems with similar or less overhead, and encourages further research in the area.

References
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel HerbertVoss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Advances in Neural Information Processing Systems, volume 33, pages 1877–1901. Curran Associates, Inc.
Paweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang Tseng, Iñigo Casanueva, Stefan Ultes, Osman Ramadan, and Milica Gašic´. 2018. MultiWOZ - a large-scale multi-domain Wizard-of-Oz dataset for task-oriented dialogue modelling. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 5016–5026, Brussels, Belgium. Association for Computational Linguistics.
Giovanni Campagna, Agata Foryciarz, Mehrad Moradshahi, and Monica Lam. 2020. Zero-shot transfer learning with synthesized data for multi-domain dialogue state tracking. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 122–132, Online. Association for Computational Linguistics.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.
Mihail Eric, Rahul Goel, Shachi Paul, Abhishek Sethi, Sanchit Agarwal, Shuyang Gao, Adarsh Kumar, Anuj Goyal, Peter Ku, and Dilek Hakkani-Tur. 2020. MultiWOZ 2.1: A consolidated multi-domain dialogue dataset with state corrections and state tracking baselines. In Proceedings of the 12th Language Resources and Evaluation Conference, pages 422–428, Marseille, France. European Language Resources Association.
Yue Feng, Yang Wang, and Hang Li. 2021. A sequenceto-sequence approach to dialogue state tracking. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1714–1725, Online. Association for Computational Linguistics.
Michael Heck, Carel van Niekerk, Nurul Lubis, Christian Geishauser, Hsien-Chin Lin, Marco Moresi, and

Milica Gasic. 2020. TripPy: A triple copy strategy for value independent neural dialog state tracking. In Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 35–44, 1st virtual meeting. Association for Computational Linguistics.
Zhengbao Jiang, Frank F. Xu, Jun Araki, and Graham Neubig. 2020. How can we know what language models know?
Norman P. Jouppi, Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal, Raminder Bajwa, Sarah Bates, Suresh Bhatia, Nan Boden, Al Borchers, Rick Boyle, and Pierre-luc et al. Cantin. 2017. Indatacenter performance analysis of a tensor processing unit. SIGARCH Comput. Archit. News, 45(2):1–12.
Adarsh Kumar, Peter Ku, Anuj Goyal, Angeliki Metallinou, and Dilek Hakkani-Tur. 2020. Ma-dst: Multi-attention-based scalable dialog state tracking. Proceedings of the AAAI Conference on Artiﬁcial Intelligence, 34(05):8107–8114.
Teven Le Scao and Alexander Rush. 2021. How many data points is a prompt worth? In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2627–2636, Online. Association for Computational Linguistics.
Chia-Hsuan Lee, Hao Cheng, and Mari Ostendorf. 2021a. Dialogue state tracking with a language model using schema-driven prompting. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 4937–4949, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.
Harrison Lee, Raghav Gupta, Abhinav Rastogi, Yuan Cao, Bin Zhang, and Yonghui Wu. 2021b. Sgd-x: A benchmark for robust generalization in schemaguided dialogue systems.
Hwaran Lee, Jinsik Lee, and Tae-Yoon Kim. 2019. SUMBT: Slot-utterance matching for universal and scalable belief tracking. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5478–5483, Florence, Italy. Association for Computational Linguistics.
Zhaojiang Lin, Bing Liu, Andrea Madotto, Seungwhan Moon, Paul Crook, Zhenpeng Zhou, Zhiguang Wang, Zhou Yu, Eunjoon Cho, Rajen Subba, and Pascale Fung. 2021a. Zero-shot dialogue state tracking via cross-task transfer.
Zhaojiang Lin, Bing Liu, Seungwhan Moon, Paul Crook, Zhenpeng Zhou, Zhiguang Wang, Zhou Yu, Andrea Madotto, Eunjoon Cho, and Rajen Subba. 2021b. Leveraging slot descriptions for zero-shot cross-domain dialogue StateTracking. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational

Linguistics: Human Language Technologies, pages 5640–5648, Online. Association for Computational Linguistics.
Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. 2021. Gpt understands, too.
Yue Ma, Zengfeng Zeng, Dawei Zhu, Xuan Li, Yiying Yang, Xiaoyuan Yao, Kaijie Zhou, and Jianping Shen. 2019. An end-to-end dialogue state tracking system with machine reading comprehension and wide & deep classiﬁcation.
Andrea Madotto, Zihan Liu, Zhaojiang Lin, and Pascale Fung. 2020. Language models as few-shot learner for task-oriented dialogue systems. CoRR, abs/2008.06239.
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a uniﬁed text-to-text transformer.
Abhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara, Raghav Gupta, and Pranav Khaitan. 2020a. Schemaguided dialogue state tracking task at dstc8.
Abhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara, Raghav Gupta, and Pranav Khaitan. 2020b. Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset. Proceedings of the AAAI Conference on Artiﬁcial Intelligence, 34(05):8689–8696.
Laria Reynolds and Kyle McDonell. 2021. Prompt programming for large language models: Beyond the few-shot paradigm.
Yu-Ping Ruan, Zhen-Hua Ling, Jia-Chen Gu, and Quan Liu. 2020. Fine-tuning bert for schema-guided zeroshot dialogue state tracking.
Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V. Le. 2021. Finetuned language models are zero-shot learners.
Chien-Sheng Wu, Andrea Madotto, Ehsan HosseiniAsl, Caiming Xiong, Richard Socher, and Pascale Fung. 2019. Transferable multi-domain state generator for task-oriented dialogue systems.
Yang Zhang, Vahid Noroozi, Evelina Bakhturina, and Boris Ginsburg. 2021. Sgd-qa: Fast schema-guided dialogue state tracking for unseen services.
Jeffrey Zhao, Raghav Gupta, Yuan Cao, Dian Yu, Mingqiu Wang, Harrison Lee, Abhinav Rastogi, Izhak Shafran, and Yonghui Wu. 2022. Descriptiondriven task-oriented dialog modeling.
Jeffrey Zhao, Mahdis Mahdieh, Ye Zhang, Yuan Cao, and Yonghui Wu. 2021a. Effective sequence-tosequence dialogue state tracking. In Proceedings of

the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7486–7493, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.
Tony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021b. Calibrate before use: Improving few-shot performance of language models.
A SDT Model Details
All T5 checkpoints used are available publicly2. For all experiments, we use a sequence length of 2048, dropout of 10% and a batch size of 16. We used a constant learning rate of 1e − 3 or 1e − 4. All models were trained for 50k steps or until convergence, and each experiment was conducted on either 64 or 128 TPU v3 chips (Jouppi et al., 2017).
B Baseline Models
For SGD, we compare against SGP-DST (Ruan et al., 2020), MRC+WD-DST (Ma et al., 2019), T5-seq (Zhao et al., 2022) and T5-ind (Lee et al., 2021a).
For MultiWOZ, we compare against TRADE (Wu et al., 2019), SUMBT (Lee et al., 2019), TransferQA (Lin et al., 2021a), and T5-seq.
Transfer QA is based on T5-large, and T5-ind and T5-seq are based on T5-XXL in this paper unless otherwise noted.
C Prompt Design
We experimented with various formats for the SDT prompt before arriving at the ﬁnal format. Below, we list alternative designs that we tried and their impact on JGA, as evaluated on the SGD test set.
C.1 Categorical value strings vs. multiple choice answers
We found that JGA dropped -2% when we tasked the model with decoding categorical values instead of multiple choice answers - e.g. payment_method=debit card instead of payment_method=b (where b is linked to the value debit card in the prompt as described in Section 2). We found that when tasking the model to decode categorical values, it would often decode related yet invalid values, which we counted as false in our evaluation. For example, instead
2https://github.com/google-research/ text-to-text-transfer-transformer/blob/ main/released_checkpoints.md

of debit card, the model might decode bank balance.
C.2 Slot IDs vs. slot names
When we delexicalized slot names with slot IDs, JGA dropped -5%. One downside of this approach is that the model lost access to valuable semantic information conveyed by the slot name. Another downside is that the model could not distinguish two slots that had the same value in the prompt. For example, if the prompt was "I would like a petfriendly hotel room with wiﬁ" and the corresponding slots were 1=True (has_wiﬁ) and 2=True (pets_allowed), it is ambiguous which ID refers to which slot.
The potential upside of using slot IDs was to remove dependence on the choice of slot name, but this did not succeed for the reasons above.
C.3 Decoding active slots vs. all slots
We experimented with training the model to only decode active slots rather than all slots with none values when they were inactive. JGA dropped 0.4%, which we hypothesized could be a result of greater dissimilarity between the slot-value string in the prompt (which contained all slots by construction) and the target, which only contained a subset of slots.
C.4 In-line annotations vs. dialogue+slots concatenated
We hypothesized that bringing the slot annotation in the prompt closer to where it was mentioned in the dialogue might help the model better understand the slot’s semantic meaning. We changed the format as follows:

• Original:

[example] [user] I

would like a pet-friendly

hotel room with wifi

[system] I found ... [slot]

has_wifi=True

• In-line: [example] [user] I would like a pet-friendly hotel room with wifi [has_wifi=True] [system] I found ...

However, this decreased JGA by more than 20%. We hypothesized that this was likely due to a mismatch between the prompt’s annotations and the target string format, which remained the same.

Model SDT-seq + desc SDT-seq

All

Seen Unseen

88.6±0.9 95.7±0.5 86.2±1.0

88.8±0.5 95.8±0.2 86.4±0.7

Table A1: We experiment with prompting using both descriptions and demonstrations (SDT-seq + desc) vs. demonstrations-only (SDT-seq) and ﬁnd that descriptions do not improve performance.

Figure 3: Results of secondarily ﬁnetuning T5-seq with dialogues, to help understand whether prompting or ﬁnetuning is more effective. The examples used for ﬁnetuning are derived from the set of dialogues used as prompts across the 5 trials of SDT-seq. From this, we observe that prompting outperforms ﬁnetuning.

Figure 4: The original schema for a Payment service its closest (v1) and farthest (v5) SGD-X variants, as measured by linguistic distance functions. For the SGD-X benchmark, models are trained on the original SGD dataset and evaluated on the test set, where the original test set schemas are replaced by SGD-X variant schemas.

