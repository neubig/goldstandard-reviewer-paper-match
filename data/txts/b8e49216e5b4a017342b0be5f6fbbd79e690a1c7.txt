arXiv:1706.03459v5 [cs.GT] 21 Aug 2020

Optimal Auctions through Deep Learning∗
Paul Du¨ttinga, Zhe Fengb, Harikrishna Narasimhanc, David C. Parkesb, and Sai Srivatsa Ravindranathb
aDepartment of Mathematics, London School of Economics p.d.duetting@lse.ac.uk
bJohn A. Paulson School of Engineering and Applied Sciences, Harvard University zhe feng,parkes,saisr@g.harvard.edu cGoogle Research, Mountain View hnarasimham@google.com
August 21, 2020
Abstract
Designing an incentive compatible auction that maximizes expected revenue is an intricate task. The single-item case was resolved in a seminal piece of work by Myerson in 1981. Even after 30-40 years of intense research the problem remains unsolved for settings with two or more items. In this work, we initiate the exploration of the use of tools from deep learning for the automated design of optimal auctions. We model an auction as a multi-layer neural network, frame optimal auction design as a constrained learning problem, and show how it can be solved using standard machine learning pipelines. We prove generalization bounds and present extensive experiments, recovering essentially all known analytical solutions for multiitem settings, and obtaining novel mechanisms for settings in which the optimal mechanism is unknown.
1 Introduction
Optimal auction design is one of the cornerstones of economic theory. It is of great practical importance, as auctions are used across industries and by the public sector to organize the sale of their products and services. Concrete examples are the US FCC Incentive Auction, the sponsored search auctions conducted by web search engines such as Google, and the auctions run on platforms such as eBay. In the standard independent private valuations model, each bidder has a valuation
∗Part of the work of the ﬁrst author was completed while visiting Google Research. This work is supported in part through NSF award CCF-1841550, as well as a Google Fellowship for Zhe Feng. We would like to thank Dirk Bergemann, Yang Cai, Vincent Conitzer, Yannai Gonczarowski, Constantinos Daskalakis, Glenn Ellison, Sergiu Hart, Ron Lavi, Kevin Leyton-Brown, Shengwu Li, Noam Nisan, Parag Pathak, Alexander Rush, Karl Schlag, Zihe Wang, Alex Wolitzky, participants in the Economics and Computation Reunion Workshop at the Simons Institute, the NIPS’17 Workshop on Learning in the Presence of Strategic Behavior, a Dagstuhl Workshop on Computational Learning Theory meets Game Theory, the EC’18 Workshop on Algorithmic Game Theory and Data Science, the Annual Congress of the German Economic Association, participants in seminars at LSE, Technion, Hebrew, Google, HBS, MIT, and the anonymous reviewers on earlier versions of this paper for their helpful feedback. The ﬁrst version of this paper was posted on arXiv on June 12, 2017. An extended abstract appeared in the Proceedings of the 36th International Conference on Machine Learning. The source code for all experiments is available from Github at https://github.com/saisrivatsan/deep-opt-auctions.
1

function over subsets of items, drawn independently from not necessarily identical distributions. It is assumed that the auctioneer knows the distributions and can (and will) use this information in designing the auction. A major diﬃculty in designing auctions is that valuations are private and bidders need to be incentivized to report their valuations truthfully. The goal is to learn an incentive compatible auction that maximizes revenue.
In a seminal piece of work, Myerson resolved the optimal auction design problem when there is a single item for sale [Myerson, 1981]. Quite astonishingly, even after 30-40 years of intense research, the problem is not completely resolved even for a simple setting with two bidders and two items. While there have been some elegant partial characterization results [Manelli and Vincent, 2006, Pavlov, 2011, Haghpanah and Hartline, 2019, Giannakopoulos and Koutsoupias, 2018, Daskalakis et al., 2017, Yao, 2017], and an impressive sequence of recent algorithmic results [Cai et al., 2012b,a, 2013, Hart and Nisan, 2017, Babaioﬀ et al., 2014, Yao, 2015, Cai and Zhao, 2017, Chawla et al., 2010], most of them apply to the weaker notion of Bayesian incentive compatibility (BIC). Our focus is on designing auctions that satisfy dominant-strategy incentive compatibility (DSIC), the more robust and desirable notion of incentive compatibility.
A recent, concurrent line of work started to bring in tools from machine learning and computational learning theory to design auctions from samples of bidder valuations. Much of the eﬀort here has focused on analyzing the sample complexity of designing revenue-maximizing auctions [Cole and Roughgarden, 2014, Mohri and Medina, 2016, Huang et al., 2018, Morgenstern and Roughgarden, 2015, Gonczarowski and Nisan, 2017, Morgenstern and Roughgarden, 2016, Syrgkanis, 2017, Gonczarowski and Weinberg, 2018, Balcan et al., 2016]. A handful of works has leveraged machine learning to optimize diﬀerent aspects of mechanisms [Lahaie, 2011, Du¨tting et al., 2014, Narasimhan et al., 2016], but none of these oﬀers the generality and ﬂexibility of our approach. There have also been computational approaches to auction design, under the agenda of automated mechanism design [Conitzer and Sandholm, 2002, 2004, Sandholm and Likhodedov, 2015], but where scalable, they are limited to specialized classes of auctions known to be incentive compatible.
1.1 Our Contribution
In this work we provide the ﬁrst, general purpose, end-to-end approach for solving the multi-item auction design problem. We use multi-layer neural networks to encode auction mechanisms, with bidder valuations being the input and allocation and payment decisions being the output. We then train the networks using samples from the value distributions, so as to maximize expected revenue subject to constraints for incentive compatibility.
We propose two diﬀerent approaches to handling IC constraints. In the ﬁrst, we leverage characterization results for IC mechanisms, and constrain the network architecture appropriately. We speciﬁcally show how to exploit Rochet’s characterization result for single-bidder multi-item settings [Rochet, 1987], which states that DSIC mechanisms induce Lipschitz, non-decreasing, and convex utility functions.
Our second approach, replaces the IC constraints with the goal of minimizing expected ex post regret, and then lifts the constraints into the objective via the augmented Langrangian method. We minimize a combination of negated revenue, and a penalty term for IC violations. This approach is also applicable in multi-bidder multi-item settings for which we don’t have tractable characterizations of IC mechanisms, but will generally only ﬁnd mechanisms that are approximately incentive compatible.
We show through extensive experiments that our two approaches are capable of recovering essentially all analytical results that have been obtained over the past 30-40 years, and that deep learning is also a powerful tool for conﬁrming or refuting hypotheses concerning the form of optimal
2

auctions and can be used to ﬁnd new designs. We also present generalization bounds in the style of machine learning that provide conﬁdence
intervals on the expected revenue and expected ex post regret based on the empirical revenue and empirical regret during training, the complexity of the neural network used to encode the allocation and payment rules, and the number of samples used to train the network.
1.2 Discussion
In general, the optimization problems we face may be non-convex, and so gradient-based approaches may get stuck in local optima. Empirically, however, this has not been an obstacle to deep nets in other problem domains, and there is growing theoretical evidence in support of this “no local optima” phenomenon (see, e.g., [Choromanska et al., 2015, Kawaguchi, 2016, Patel et al., 2016]).
By focusing on expected ex post regret we adopt a quantiﬁable relaxation of dominant-strategy incentive compatibility, ﬁrst introduced in [Du¨tting et al., 2014]. Our experiments suggest that this relaxation is an eﬀective tool for approximating optimal DSIC auctions.
While not strictly limited to neural networks, our approach beneﬁts from the expressive power of neural networks and the ability to enforce complex constraints using the standard pipeline. A key advantage of our method over other approaches to automated mechanism design such as [Sandholm and Likhodedov, 2015] is that we optimize over a broad class of mechanisms, constrained only by the expressivity of the neural network architecture.
While the original work on automated auction design framed the problem as a linear program (LP) [Conitzer and Sandholm, 2002, 2004], follow-up work acknowledged that this has severe scalablility issues as it requires a number of constraints and variables that is exponential in the number of agents and items [Guo and Conitzer, 2010]. We ﬁnd that even for small setting with 2 bidders and 3 items (and a discretization of the value into 5 bins per item) the corresponding LP takes 69 hours to complete since the LP needs to handle ≈ 105 decision variables and ≈ 4 × 106 constraints. For the same setting, our approach found an auction with low regret in just over 9 hours (see Table 10).
1.3 Further Related Work
Several other research groups have recently picked up deep nets and inference tools and applied them to economic problems, diﬀerent from the one we consider here. These include the use of neural networks to predict behavior of human participants in strategic scenarios [Hartford et al., 2016, Fudenberg and Liang, 2019], an automated equilibrium analysis of mechanisms [Thompson et al., 2017], deep nets for causal inference [Hartford et al., 2017, Louizos et al., 2017], and deep reinforcement learning for solving combinatorial games [Raghu et al., 2018].1
1.4 Organization
Section 2 formulates the auction design problem as a learning problem, describes our two basic approaches, and states the generalization bound. Section 3 presents the network architectures, and instantiates the generalization bound for these networks. Section 4 describes the training and optimization procedures, and Section 5 the experiments. Section 6 concludes.
1There has also been follow-up work to the present paper that extends our approach to budget constrained bidders [Feng et al., 2018] and to the facility location problem [Golowich et al., 2018], and that develops specialized architectures for single bidder settings that satisfy IC [Shen et al., 2019] and for the purpose of minimizing agent payments [Tacchetti et al., 2019]. A short survey also appears as a chapter in [Du¨tting et al., 2019].
3

2 Auction Design as a Learning Problem

2.1 Auction Design Basics

We consider a setting with a set of n bidders N = {1, . . . , n} and m items M = {1, . . . , m}. Each

bidder i has a valuation function vi : 2M → R≥0, where vi(S) denotes how much the bidder values

the subset of items S ⊆ M . In the simplest case, a bidder may have additive valuations. In this case

she has a value vi({j}) for each individual item j ∈ M , and her value for a subset of items S ⊆ M is

vi(S) = j∈S vi({j}). If a bidder’s value for a subset of items S ⊆ M is vi(S) = maxj∈S vi({j}), we say this bidder has a unit-demand valuation. We also consider bidders with general combinatorial

valuations, but defer the details to Appendix A.2.

Bidder i’s valuation function is drawn independently from a distribution Fi over possible valu-

ation functions Vi. We write v = (v1, . . . , vn) for a proﬁle of valuations, and denote V =

n i=1

Vi.

The auctioneer knows the distributions F = (F1, . . . , Fn), but does not know the bidders’ realized

valuation v. The bidders report their valuations (perhaps untruthfully), and an auction decides

on an allocation of items to the bidders and charges a payment to them. We denote an auction

(g, p) as a pair of allocation rules gi : V → 2M and payment rules pi : V → R≥0 (these rules can

be randomized). Given bids b = (b1, . . . , bn) ∈ V , the auction computes an allocation g(b) and

payments p(b).

A bidder with valuation vi receives a utility ui(vi; b) = vi(gi(b)) − pi(b) for a report of bid

proﬁle b. Let v−i denote the valuation proﬁle v = (v1, . . . , vn) without element vi, similarly for b−i,

and let V−i = j=i Vj denote the possible valuation proﬁles of bidders other than bidder i. An auction is dominant strategy incentive compatible (DSIC) if each bidder’s utility is maximized by

reporting truthfully no matter what the other bidders report. In other words, ui(vi; (vi, b−i)) ≥

ui(vi; (bi, b−i)) for every bidder i, every valuation vi ∈ Vi, every bid bi ∈ Vi, and all bids b−i ∈ V−i

from others. An auction is ex post individually rational (IR) if each bidder receives a non-zero

utility, i.e. ui(vi; (vi, b−i)) ≥ 0 ∀i ∈ N , vi ∈ Vi, and b−i ∈ V−i .

In a DSIC auction, it is in the best interest of each bidder to report truthfully, and so the

revenue on valuation proﬁle v is i pi(v). Optimal auction design seeks to identify a DSIC auction that maximizes expected revenue.

2.2 Formulation as a Learning Problem
We pose the problem of optimal auction design as a learning problem, where in the place of a loss function that measures error against a target label, we adopt the negated, expected revenue on valuations drawn from F . We are given a parametric class of auctions, (gw, pw) ∈ M, for parameters w ∈ Rd for some d ∈ N, and a sample of bidder valuation proﬁles S = {v(1), . . . , v(L)} drawn i.i.d. from F .2 The goal is to ﬁnd an auction that minimizes the negated, expected revenue −E[ i∈N pwi (v)], among all auctions in M that satisfy incentive compatibility.
We present two approaches for achieving IC. In the ﬁrst, we leverage characterization results to constrain the search space so that all mechanisms within this class are IC. In the second, we replace the IC constraints with a diﬀerentiable approximation, and lift the constraints into the objective via the augmented Lagrangian method. The ﬁrst approach aﬀords a smaller search space and is exactly DSIC, but requires an IC characterization that can be encoded within a neural network architecture and applies to single-bidder multi-item settings. The second approach applies to multibidder multi-item settings and does not rely on the availability of suitable characterization results, but entails search through a larger parametric space and only achieves approximate IC.
2There is no need to compute equilibrium inputs—we sample true proﬁles, and seek to learn rules that are IC.

4

2.2.1 Characterization-Based Approach

We begin by describing our ﬁrst approach, in which we exploit characterizations of IC mechanisms

to constrain the search space. We provide a construction for single-bidder multi-item settings based

on Rochet [1987]’s characterization of IC mechanisms via induced utilities, which we refer to as

RochetNet. We present this construction for additive preferences, but the construction can easily

be extended to unit demand valuations. See Section 3.1. In Appendix A.1 we describe a second

construction based on Myerson [1981]’s characterization result for single-bidder multi-item settings,

which we refer to as MyersonNet.

To formally state Rochet’s result we need the following notion of an induced utility function.
The utility function u : Rm≥0 → R induced by a mechanism (g, p) for a single bidder with additive preferences is3:
m

u(v) = gj(v) vj − p(v).

(1)

j=1

Rochet’s result establishes the following connection between DSIC mechanisms and induced utility functions:

Theorem 2.1 (Rochet [1987]). A utility function u : Rm≥0 → R is induced by a DSIC mechanism iﬀ u is 1-Lipschitz w.r.t. the 1-norm, non-decreasing, and convex. Moreover, for such a utility function u, ∇u(v) exists almost everywhere in Rm≥0, and wherever it exists, ∇u(v) gives the allocation probabilities for valuation v and ∇u(v) · v − u(v) is the corresponding payment.

Further, for a mechanism to be IR, its induced utility function must be non-negative, i.e. u(v) ≥ 0, ∀v ∈ Rm≥0.
To ﬁnd the optimal mechanism, it thus suﬃces to search over all non-negative utility functions that satisfy the conditions in Theorem 2.1, and pick the one that maximizes expected revenue.
This can be done by modeling the utility function as a neural network, and formulating the above optimization as a learning problem. The associated mechanism can then be recovered from the gradient of the learned neural network. We describe the neural network architectures for this approach in Section 3.1, and we present extensive experiments with this approach in Section 5 and Appendix B.

2.2.2 Characterization-Free Approach

Our second approach—which we refer to as RegretNet—does not rely on characterizations of IC mechanisms. Instead, it replaces the IC constraints with a diﬀerentiable approximation and lifts the IC constraints into the objective by augmenting the objective with a term that accounts for the extent to which the IC constraints are violated.
We propose to measure the extent to which an auction violates incentive compatibility through the following notion of ex post regret. Fixing the bids of others, the ex post regret for a bidder is the maximum increase in her utility, considering all possible non-truthful bids. For mechanisms (gw, pw), we will be interested in the expected ex post regret for bidder i:

rgt i(w) = E max uwi (vi; (vi, v−i)) − uwi (vi; (vi, v−i)) ,
vi∈Vi

where

the

expectation

is

over

v

∼

F

and

uwi (vi; b)

=

v

i

(g

w i

(

b))

−

p

w i

(

b)

for

model

parameters

w.

We

assume that F has full support on the space of valuation proﬁles V , and recognizing that the regret

3For a unit-demand bidder, the utility can also be represented via (1) with the additional constraint that j gj(v) ≤ 1, ∀v. We discuss this more in Section 3.1.

5

is non-negative, an auction satisﬁes DSIC if and only if rgti(w) = 0, ∀i ∈ N , except for measure zero events.
Given this, we re-formulate the learning problem as minimizing expected negated revenue subject to the expected ex post regret being zero for each bidder:

min
w∈Rd
s.t.

Ev∼F − i∈N pwi (v) rgti(w) = 0, ∀i ∈ N.

Given a sample S of L valuation proﬁles from F , we estimate the empirical ex post regret for bidder i as:
rgt i(w) = L1 L=1 maxvi∈Vi uwi vi( ); vi, v−( i) − uwi (vi( ); v( )) , (2)

and seek to minimize the empirical loss (negated revenue) subject to the empirical regret being zero for all bidders:

min

− L1

L =1

n i=1

pwi (v(

))

w∈Rd

s.t. rgti(w) = 0, ∀i ∈ N.

(3)

We additionally require the designed auction to satisfy IR, which can be ensured by restricting the search space to a class of parametrized auctions that charge no bidder more than her valuation for an allocation.
In Section 3 we will model the allocation and payment rules as neural networks and incorporate the IR requirement within the architecture. In Section 4 we describe how the IC constraints can be incorporated into the objective using Lagrange multipliers, so that the resulting neural nets can be trained with standard pipelines. Section 5 and Appendix B present extensive experiments.

2.3 Quantile-Based Regret
Our characterization-free approach will lead to mechanisms with low (typically vanishing) expected ex post regret. The bounds on the expected ex post regret also yield guarantees of the form “the probability that the ex post regret is larger than x is at most q.”
Deﬁnition 2.1 (Quantile-based ex post regret). For each bidder i, and q with 0 < q < 1, the qquantile-based ex post regret, rgtqi (w), induced by the probability distribution F on valuation proﬁles, is deﬁned as the smallest x such that
P max uwi (vi; (vi, v−i)) − uwi (vi; (vi, v−i)) ≥ x ≤ q.
vi∈Vi
We can bound the q-quantile based regret rgtqi (w) by the expected ex post regret rgti(w) as in the following lemma. The proof appears in Appendix D.1.
Lemma 2.1. For any ﬁxed q, 0 < q < 1, and bidder i, we can bound the q-quantile-based ex post regret by
rgtqi (w) ≤ rgtiq(w) .
Using this lemma we can show, for example, that when the expected ex post regret is 0.001, then the probability that the ex post regret exceeds 0.01 is at most 10%.

6

2.4 Generalization Bound
We conclude this section with two generalization bounds. We provide a lower bound on the expected revenue and an upper bound on the expected ex post regret in terms of the empirical revenue and empirical regret during training, the complexity (or capacity) of the auction class that we optimize over, and the number of sampled valuation proﬁles.
We measure the capacity of an auction class M using a deﬁnition of covering numbers used in the ranking literature [Rudin and Schapire, 2009]. Deﬁne the ∞,1 distance between auctions (g, p), (g , p ) ∈ M as

max

|gij(v) − gij(v)| + |pi(v) − pi(v)|.

v∈V

i∈N,j∈M

i∈N

For any > 0, let N∞(M, ) be the minimum number of balls of radius under the ∞,1 distance.

required to cover M

Theorem 2.2. For each bidder i, assume w.l.o.g. that the valuation function vi satisﬁes vi(S) ≤ 1, ∀S ⊆ M . Let M be a class of auctions that satisfy individual rationality. Fix δ ∈ (0, 1). With probability at least 1 − δ over draw of sample S of L proﬁles from F , for any (gw, pw) ∈ M,

Ev∼F

i∈N pwi (v)

≥

1 L

L =1

n i=1

pwi (v(

))

−

2n∆L

−

Cn

log(L1/δ) ,

and

1n

1n

n rgti(w) ≤ n rgti(w) + 2∆L + C

i=1

i=1

log(1/δ) ,
L

where ∆L = inf >0

n+2

2 log(N∞(M, /2)) L

and C, C are distribution-independent constants.

See Appendix D.2 for the proof. If the term ∆L in the above bound goes to zero as the sample size L increases then the above bounds go to zero as L → ∞. In Theorem 3.2 in Section 3, we bound ∆L for the neural network architectures we present in this paper.

3 Neural Network Architecture
We describe the RochetNet architecture for single-bidder multi-item settings in Section 3.1, and the RegretNet architecture for multi-bidder multi-item settings in Section 3.2. We focus on additive and unit-demand preferences. We discuss how to extend the constructions to capture combinatorial valuations for multi-bidder, multi-item settings in Appendix A.2.

3.1 The RochetNet Architecture

Recall that in the single-bidder, multi-item setting we seek to encode utility functions that satisfy

the requirements of Theorem 2.1. The associated auction mechanism can be deduced from the

gradient of the utility function.

We ﬁrst describe the construction for additive valuations. To model a non-negative, monotone,

convex, Lipschitz utility function, we use the maximum of J linear functions with non-negative

coeﬃcients and zero:

uα,β(v) = max max {αj · v + βj}, 0 ,

(4)

j ∈[J ]

7

b1 b2
... bm

h1 0
h2 max u(b)
...
hJ (a)

u(b) h1

h4

h2
b (b)

h3 u(b) = 0

Figure 1: RochetNet: (a) Neural network representation of a non-negative, monotone, convex induced utility function; here hj(b) = αj · b + βj for b ∈ Rm and αj ∈ [0, 1]m. (b) An example of a utility function represented by RochetNet for one item.

where parameters w = (α, β), with αj ∈ [0, 1]m and βj ∈ R for j ∈ [J]. By bounding the hyperplane coeﬃcients to [0, 1], we guarantee that the function is 1-Lipschitz. The following theorem veriﬁes that the utility modeled by RochetNet satisﬁes Rochet’s characterization (Theorem 2.1). The proof is given in Appendix D.3.

Theorem 3.1. For any α ∈ [0, 1]mJ and β ∈ RJ , the function uα,β is non-negative, monotonically non-decreasing, convex and 1-Lipschitz w.r.t. the 1-norm.

The utility function, represented as a single layer neural network, is illustrated in Figure 1(a), where each hj(b) = αj · b + βj for bid b ∈ Rm. Figure 1(b) shows an example of a utility function represented by RochetNet for m = 1. By using a large number of hyperplanes one can use this
neural network architecture to search over a suﬃciently rich class of monotone, convex 1-Lipschitz utility functions. Once trained, the mechanism (gw, pw), with w = (α, β), can be derived from the
gradient of the utility function, with the allocation rule given by:

gw(b) = ∇uα,β(b),

(5)

and the payment rule is given by the diﬀerence between the expected value to the bidder from the allocation and the bidder’s utility:

pw(b) = ∇uα,β(b) · b − uα,β(b).

(6)

Here the utility gradient can be computed as: ∇juα,β(b) = αj∗(b), for j∗(b) ∈ argmaxj∈[J]{αj · b + βj}. We seek to minimize the negated, expected revenue:

−Ev∼F ∇uα,β(v) · v − uα,β(v) = Ev∼F βj∗(v) .

(7)

To ensure that the objective is a continuous function of the parameters α and β (so that the parameters can be optimized eﬃciently), the gradient term is computed approximately by using a softmax operation in place of the argmax. The loss function that we use is given by the negated revenue with approximate gradients:

L(α, β) = −Ev∼F

βj∇j(v) ,

(8)

j ∈[J ]

where

∇j(v) = softmaxj κ · (α1 · v + β1), . . . , κ · (αJ · v + βJ )

(9)

8

Allocation Network g

softmax

b11 ...
b1m
...
bn1 ...
bnm

h(11)

h(1R)

h(21) . . . h(2R)

...

...

h(J11)

h(JRR)

z11 ...
zn1
...
z1m ...
znm

softmax

Payment Network p z11, . . . , z1m

b11 ...

c(11)

c(1T )

σ

b1m ...

c(21) . . . c(2T )

σ

bn1 ... ... ...

... bnm

c(1)

c(T )

σ

J1

JT

zn1, . . . , znm

b

p˜1

×

b

p˜2

×

...

...

b

p˜n

×

m
p1 = p˜1 z1j b1j
j=1 m
p2 = p˜2 z2j b2j
j=1
m
pn = p˜n znj bnj
j=1

wg

Metrics: rev, rgt1, . . . , rgtn

wp

Figure 2: RegretNet: The allocation and payment networks for a setting with n additive bidders and m items. The inputs are bids from each bidder for each item. The revenue rev and expected ex post rgti are deﬁned as a function of the parameters of the allocation and payment networks w = (wg, wp).

and κ > 0 is a constant that controls the quality of the approximation.4 We seek to optimize

the parameters of the neural network α ∈ [0, 1]mJ , β ∈ RJ to minimize loss. Given a sample S = {v(1), . . . , v(L)} drawn from F , we optimize an empirical version of the loss.

This approach easily extends to a single bidder with a unit-demand valuation. In this case, the

sum of the allocation probabilities cannot exceed one. This is enforced by restricting the coeﬃcients

for each hyperplane to sum up to at most one, i.e.

m k=1

αjk

≤

1,

∀j

∈

[J ],

and

αjk

≥

0,

∀j

∈

J,

k

∈

[m].5 It can be veriﬁed that even with this restriction, the induced utility function continuous to

be monotone, convex and Lipschitz, ensuring that the resulting mechanism is DSIC.6

An interpretation of the RochetNet architecture is that the network maintains a menu of ran-

domized allocations and prices, and chooses the option from the menu that maximizes the bidder’s

utility based on the bid. Each linear function hj(b) = αj · b + βj in RochetNet corresponds to

an option on the menu, with the allocation probabilities and payments encoded through the pa-

rameters αj and βj respectively. Recently, Shen et al. [2019] extended RochetNet to more general

settings, including non-linear utility function settings.

3.2 The RegretNet Architecture
We next describe the basic architecture for the characterization-free, RegretNet approach. Recall that in this case the goal is to train neural networks that explicitly encode the allocation and payment rule of the mechanism. The architectures generally consist of two logically distinct components: the allocation and payment networks. These components are trained together and the outputs of these networks are used to compute the regret and revenue of the auction.

3.2.1 Additive Valuations
An overview of the RegretNet architecture for additive valuations is given in Figure 2. The allocation network encodes a randomized allocation rule gw : Rnm → [0, 1]nm and the payment network encodes a payment rule pw : Rnm → Rn≥0, both of which are modeled as feed-forward,
4The softmax function, softmaxj(κx1, . . . , κxJ ) = eκxj / j eκxj , takes as input J real numbers and returns a probability distribution consisting of J probabilities, proportional to the exponential of the inputs.
5To achieve this contraint, we can re-parameterize αjk as softmaxk γj1, · · · , γjm , where γjk ∈ R, ∀j ∈ J, k ∈ m. 6The original characterization of Rochet [1987] applies to general, convex outcome spaces, as is the case here.

9

b11 ...
b1m
...
bn1 ...
bnm

sof tmax sof tmax

h(11)

h(1R)

h(21) . . . h(2R)

...

...

h(J11)

h(JRR)

s11

s1m

... . . . ...

...

s¯

sn1

snm

...

s11 . . . s1m

...

s¯ sof tmax

...

sn1 . . . snm

sof tmax

z11 = min{s¯11, s¯11} zn1 = min{s¯n1, s¯n1}
z1m = min{s¯1m, s¯1m} znm = min{s¯nm, s¯nm}

Figure 3: RegretNet: The allocation network for settings with n unit-demand bidders and m items.

fully-connected networks with a tanh activation function in each of the hidden nodes. The input

layer of the networks consists of bids bij ≥ 0 representing the valuation of bidder i for item j.

The allocation network outputs a vector of allocation probabilities z1j = g1j(b), . . . , znj = gnj(b),

for each item j ∈ [m]. To ensure feasibility, i.e., that the probability of an item being allocated

is at most one, the allocations are computed using a softmax activation function, so that for all

items j, we have

n i=1

zij

≤

1.

To

accommodate

the

possibility

of

an

item

not

being

assigned,

we

include a dummy node in the softmax computation to hold the residual allocation probability. The

payment network outputs a payment for each bidder that denotes the amount the bidder should

pay in expectation for a particular bid proﬁle.

To ensure that the auction satisﬁes IR, i.e., does not charge a bidder more than her expected

value for the allocation, the network ﬁrst computes a normalized payment p˜i ∈ [0, 1] for each bidder

i using a sigmoidal unit, and then outputs a payment pi = p˜i(

m j=1

zij

bij ),

where

the

zij ’s

are

the

outputs from the allocation network.

3.2.2 Unit-Demand Valuations

The allocation network for unit-demand bidders is the feed-forward network shown in Figure 3.
For revenue maximization in this setting, it is suﬃcient to consider allocation rules that assign at most one item to each bidder.7 In the case of randomized allocation rules, this requires that the
total allocation probability to each bidder is at most one, i.e., j zij ≤ 1, ∀i ∈ [n]. We would also require that no item is over-allocated, i.e., i zij ≤ 1, ∀j ∈ [m]. Hence, we design allocation networks for which the matrix of output probabilities [zij]ni,j=1 is doubly stochastic.8
In particular, we have the allocation network compute two sets of scores sij’s and sij’s. Let s, s ∈ Rnm denote the corresponding matrices. The ﬁrst set of scores are normalized along the rows and the second set of scores normalized along the columns. Both normalizations can be performed
by passing these scores through softmax functions. The allocation for bidder i and item j is then
computed as the minimum of the corresponding normalized scores:

zij = ϕDijS(s, s ) = min

esij n+1 eskj ,
k=1

esij m+1 esik ,
k=1

7 This holds by a simple reduction argument: for any IC auction that allocates multiple items, one can construct an IC auction with the same revenue by retaining only the most-preferred item among those allocated to a bidder.
8This is a more general deﬁnition for doubly stochastic than is typical. Doubly stochastic is usually deﬁned on a square matrix with the sum of rows and the sum of columns equal to 1.

10

where indices n + 1 and m + 1 denote dummy inputs that correspond to an item not being allocated to any bidder and a bidder not being allocated any item, respectively.
We ﬁrst show that ϕDS(s, s ) as constructed is doubly stochastic, and that we do not lose in generality by the constructive approach that we take. See Appendix D.4 for a proof.
Lemma 3.1. The matrix ϕDS(s, s ) is doubly stochastic ∀ s, s ∈ Rnm. For any doubly stochastic matrix z ∈ [0, 1]nm, ∃ s, s ∈ Rnm, for which z = ϕDS(s, s ).
It remains to show that doubly-stochastic matrices correspond to lotteries over one-to-one assignments. This is a special case of the bihierarchy structure proposed in [Budish et al., 2013] (Theorem 1), which we state in the following lemma for completeness.9
Lemma 3.2 (Budish et al. [2013]). Any doubly stochastic matrix A ∈ Rn×m can be represented as a convex combination of matrices B1, . . . , Bk where each B ∈ {0, 1}n×m and j∈[m] Bij ≤ 1, ∀i ∈ [n] and i∈[n] Bij ≤ 1, ∀j ∈ [m].
The payment network for unit-demand valuations is the same as for the case of additive valuations (see Figure 2).
3.3 Covering Number Bounds
We conclude this section by instantiating our generalization bound from Section 2.4 for the RegretNet architectures, where we have both a regret and revenue term. Analogous results can be derived for RochetNet, where we only have a revenue term.
Theorem 3.2. For RegretNet with R hidden layers, K nodes per hidden layer, dg parameters in the allocation network, dp parameters in the payment network, m items, n bidders, a sample size of L, and the vector of all model parameters w satisfying w 1 ≤ W 10 the following are valid bounds for the ∆L term deﬁned in Theorem 2.2, for diﬀerent bidder valuation types:
(a) additive valuations: ∆L ≤ O R(dg + dp) log(LW max{K, mn})/L , (b) unit-demand valuations: ∆L ≤ O R(dg + dp) log(LW max{K, mn})/L ,
The proof is given in Appendix D.6. As the sample size L → ∞, the term ∆L → 0. The dependence of the above result on the number of layers, nodes, and parameters in the network is similar to standard covering number bounds for neural networks [Anthony and Bartlett, 2009].
4 Optimization and Training
We next describe how we train the neural network architectures presented in the previous section. We focus on the RegretNet architectures where we have to take care of the incentives directly. The approach that we take for RochetNet is the standard (projected) stochastic gradient descent11 (SGD) for loss function L(α, β) in Equation 8.
For RegretNet we use the augmented Lagrangian method to solve the constrained training problem in (3) over the space of neural network parameters w. We ﬁrst deﬁne the Lagrangian
9Budish et al. [2013] also propose a polynomial algorithm to decompose the doubly stochastic matrix. 10Recall that · 1 is the induced matrix norm, i.e. w 1 = maxj i |wij|. 11During training for additive valuations setting in RochetNet, we project each weight αjk into [0, 1] to guarantee feasibility.
11

Algorithm 1 RegretNet Training

1: Input: Minibatches S1, . . . , ST of size B

2: Parameters: ∀t, ρt > 0, γ > 0, η > 0, Γ ∈ N, K ∈ N 3: Initialize: w0 ∈ Rd, λ0 ∈ Rn

4: for t = 0 to T do

5: Receive minibatch St = {v(1), . . . , v(B)}

6:

Initialize

misreports

v

( i

)

∈

Vi,

∀

∈ [B], i ∈ N

7: for r = 0 to Γ do

8:

∀ ∈ [B], i ∈ N :

9:

v

( i

)

←

v

( i

)

+

γ∇v

uwi

vi( );

v (i ), v−( i)

i

10: end for

11: Compute regret gradient: ∀ ∈ [B], i ∈ N :

12:

gt,i =

13:

∇w uwi vi( ); v (i ), v−( i) − uwi (vi( ); v( ))

w=wt

14: Compute Lagrangian gradient using (10) and update wt:

15:

wt+1 ← wt − η∇w Cρt (wt, λt)

16: Update Lagrange multipliers once in Q iterations:

17:

if t is a multiple of Q

18:

λti+1 ← λti + ρt rgt i(wt+1), ∀i ∈ N

19:

else

20:

λt+1 ← λt

21: end for

function for the optimization problem, augmented with a quadratic penalty term for violating the constraints:

Cρ(w; λ) =

1L

w ()

ρ

− L

pi (v ) + λi rgti(w) + 2

=1 i∈N

i∈N

i∈N

2
rgt i(w)

where λ ∈ Rn is a vector of Lagrange multipliers, and ρ > 0 is a ﬁxed parameter that controls
the weight on the quadratic penalty. The solver alternates between the following updates on the model parameters and the Lagrange multipliers: (a) wnew ∈ argminw Cρ(wold; λold) and (b) λni ew = λoi ld + ρ rgt i(wnew), ∀i ∈ N.
The solver is described in Algorithm 1. We divide the training sample S into minibatches of size
B, and perform several passes over the training samples (with random shuﬄing of the data after each pass). We denote the minibatch received at iteration t by St = {v(1), . . . , v(B)}. The update (a) on model parameters involves an unconstrained optimization of Cρ over w and is performed using a gradient-based optimizer. Let rgti(w) denote the empirical regret in (2) computed on minibatch St. The gradient of Cρ w.r.t. w for ﬁxed λt is given by:

∇w Cρ(w; λt) =

1 −
B

B

∇w pwi (v( )) +

=1 i∈N

i∈N

B

λti g ,i + ρ

=1

i∈N

B
rgt i(w) g ,i
=1

(10)

where

g ,i = ∇w max uwi vi( ); vi, v−( i)
vi∈Vi

− uwi (vi( ); v( )) .

12

The terms rgti and g ,i in turn involve a “max” over misreports for each bidder i and valuation

proﬁle . We solve this inner maximization over misreports using another gradient based optimizer.

In particular, we maintain misreports v (i ) for each i and valuation proﬁle . For every update on the model parameters wt, we perform Γ gradient updates to compute the optimal misreports:

v

( i

)

=

v

( i

)

+

γ∇v

uwi

vi( );

v (i ), v−( i)

, for some γ > 0. We show a visualization of these iterations

i

in Appendix C. In our experiments, we use the Adam optimizer [Kingma and Ba, 2014] for updates

on model parameters w and misreports v (i ).12 Since the optimization problem is non-convex, the solver is not guaranteed to reach a globally

optimal solution. However, our method proves very eﬀective in our experiments. The learned

auctions incur very low regret and closely match the structure of optimal auctions in settings

where this is known.

5 Experiments
We demonstrate that our approach can recover near-optimal auctions for essentially all settings for which the optimal solution is known, that it is an eﬀective tool for conﬁrming or refuting hypotheses about optimal designs, and that it can ﬁnd new auctions for settings where there is no known analytical solution. We present a representative subset of the results here, and provide additional experimental results in Appendix B.
5.1 Setup
We implemented our framework using the TensorFlow deep learning library.13 For RochetNet we initialized parameters α and β in Equation (4) using a random uniform initializer over the interval [0,1] and a zero initializer, respectively. For RegretNet we used the tanh activation function at the hidden nodes, and Glorot uniform initialization [Glorot and Bengio, 2010]. We performed cross validation to decide on the number of hidden layers and the number of nodes in each hidden layer. We include exemplary numbers that illustrate the tradeoﬀs in Section 5.6.
We trained RochetNet on 215 valuation proﬁles sampled every iteration in an online manner. We used the Adam optimizer with a learning rate of 0.1 for 20,000 iterations for making the updates. The parameter κ in Equation (9) was set to 1,000. Unless speciﬁed otherwise we used a max network over 1,000 linear functions to model the induced utility functions, and report our results on a sample of 10,000 proﬁles.
For RegretNet we used a sample of 640,000 valuation proﬁles for training and a sample of 10,000 proﬁles for testing. The augmented Lagrangian solver was run for a maximum of 80 epochs (full passes over the training set) with a minibatch size of 128. The value of ρ in the augmented Lagrangian was set to 1.0 and incremented every two epochs. An update on wt was performed for every minibatch using the Adam optimizer with learning rate 0.001. For each update on wt, we ran Γ = 25 misreport updates steps with learning rate 0.1. At the end of 25 updates, the optimized misreports for the current minibatch were cached and used to initialize the misreports for the same minibatch in the next epoch. An update on λt was performed once every 100 minibatches (i.e., Q = 100).
We ran all our experiments on a compute cluster with NVDIA Graphics Processing Unit (GPU) cores.
12Adam is a variant of SGD, which involves a momentum term to update weights. Lines 9 and 15 in the pseudo-code of Algorithm 1 are for a standard SGD algorithm.
13All code is available through the GitHub repository at https://github.com/saisrivatsan/deep-opt-auctions.

13

v2

1.0 Prob. of allocating item 1 1.0

0.8

0.8

0.6

1

0.6

0.4

0.4

0.2

0

0.2

0.00.0 0.2 0.4 0.6 0.8 1.0 0.0

v1

(a)

(c)

v2

v2

1.0 Prob. of allocating item 2 1.0

0.8

0.8

0.6

1

0.6

0.4

0.4

0.2

0

0.2

0.00.0 0.2 0.4 0.6 0.8 1.0 0.0
v1

3.0 Prob. of allocating item 2 1.0

2.8 1

0.8

2.6

0.5

0.6

2.4

0.4

2.2

0

0.2

2.0 0

0.0

2.0 2.2 2.4v12.6 2.8 3.0

v2

v2

1.0 Prob. of allocating item 1 1.0

0.8

0.8

0.6

1

0.6

0.4

0.4

0.2

0

0.2

0.00.0 0.2 0.4 0.6 0.8 1.0 0.0

v1

(b)

3.0 Prob. of allocating item 1 1.0

2.8 0

0.8

2.6

0.5

0.6

2.4

0.4

2.2

1

0.2

2.0 0

0.0

2.0 2.2 2.4v12.6 2.8 3.0 (d)

v2

v2

1.0 Prob. of allocating item 2 1.0

0.8

0.8

0.6

1

0.6

0.4

0.4

0.2

0

0.2

0.00.0 0.2 0.4v10.6 0.8 1.0 0.0

3.0 Prob. of allocating item 2 1.0

2.8 1

0.8

2.6

0.5

0.6

2.4

0.4

2.2

0

0.2

2.0 0

0.0

2.0 2.2 2.4v12.6 2.8 3.0

Figure 4: Side-by-side comparison of allocation rules learned by RochetNet and RegretNet for single bidder, two items settings. Panels (a) and (b) are for Setting A and Panels (c) and (d) are for Setting B. The panels describe the probability that the bidder is allocated item 1 (left) and item 2 (right) for diﬀerent valuation inputs. The optimal auctions are described by the regions separated by the dashed black lines, with the numbers in black the optimal probability of allocation in the region.

5.2 Evaluation

In addition to the revenue of the learned auction on a test set, we also evaluate the regret achieved by

RegretNet, averaged across all bidders and test valuation proﬁles, i.e., rgt = n1

n i=1

rgt

i

(gw

,

pw

).

Each rgti has an inner “max” of the utility function over bidder valuations vi ∈ Vi (see (2)). We evaluate these terms by running gradient ascent on vi with a step-size of 0.1 for 2,000 iterations (we test 1,000 diﬀerent random initial vi and report the one that achieves the largest regret).
For some of the experiments we also report the total time it took to train the network. This

time is incurred during oﬄine training, while the allocation and payments can be computed in a

few milliseconds once the network is trained.

5.3 The Manelli-Vincent and Pavlov Auctions
As a representative example of the exhaustive set of analytical results that we can recover with our approach we discuss the Manelli-Vincent and Pavlov auctions [Manelli and Vincent, 2006, Pavlov, 2011]. We speciﬁcally consider the following single-bidder, two-item settings:
A. Single bidder with additive valuations over two items, where the item values are independent draws from U [0, 1].
B. Single bidder with unit-demand valuations over two items, where the item values are independent draws from U [2, 3].
The optimal design for the ﬁrst setting is given by Manelli and Vincent [2006], who show that the optim√al mechanism is deterministic and oﬀers the bidder three options: receive both items and pay (4 − 2)/3, receive item 1 and pay 2/3, or receive item 2 and pay 2/3. For the second setting Pavlov [2011] shows that it is optimal to oﬀer a fair lottery ( 21 , 12 ) over the items (at a discount), or to p√urchase any item at a ﬁxed price. For the parameters here√the price for the lottery is 16 (8 + 22) ≈ 2.115 and the price for an individual item is 16 + 16 (8 + 22) ≈ 2.282.
We used two hidden layers with 100 hidden nodes in RegretNet for these settings. A visualization of the optimal allocation rule and those learned by RochetNet and RegretNet is given in Figure 4. Figure 5(a) gives the optimal revenue, the revenue and regret obtained by RegretNet, and the

14

Distribution
Setting A Setting B

Opt rev 0.550 2.137

RegretNet

rev

rgt

0.554 < 0.001

2.137 < 0.001

RochetNet rev 0.550 2.136

Test Revenue Test Regret

(a)

0.60

0.010

0.55

0.008

0.50 0.45 0.40 0

RegretNet OMpetcihmaanlism 20 Epo40chs 60 80

0.006

0.004

0.002

0.000 0

20

40

60

80

Epochs

(b)

Figure 5: (a): Test revenue and regret for RegretNet and revenue for RochetNet for Settings A and B. (b): Plot of test revenue and regret as a function of training epochs for Setting A with RegretNet.

revenue obtained by RochetNet. Figure 5(b) shows how these terms evolve over time during training in RegretNet.
We ﬁnd that both approaches essentially recover the optimal design, not only in terms of revenue, but also in terms of the allocation rule and transfers. The auctions learned by RochetNet are exactly DSIC and match the optimal revenue precisely, with sharp decision boundaries in the allocation and payment rule. The decision boundaries for RegretNet are smoother, but still remarkably accurate. The revenue achieved by RegretNet matches the optimal revenue up to a < 1% error term and the regret it incurs is < 0.001. The plots of the test revenue and regret show that the augmented Lagrangian method is eﬀective in driving the test revenue and the test regret towards optimal levels.
The additional domain knowledge incorporated into the RochetNet architecture leads to exactly DSIC mechanisms that match the optimal design more accurately, and speeds up computation (the training took about 10 minutes compared to 11 hours). On the other hand, we ﬁnd it surprising how well RegretNet performs given that it starts with no domain knowledge at all.
We present and discuss a host of additional experiments with single-bidder, two-item settings in Appendix B.

5.4 The Straight-Jacket Auction
Extending the analytical result of Manelli and Vincent [2006] to a single bidder, and an arbitrary number of items (even with additive preferences, all uniform on [0, 1]) has proven elusive. It is not even clear whether the optimal mechanism is deterministic or requires randomization.
A recent breakthrough came with Giannakopoulos and Koutsoupias [2018], who were able to ﬁnd a pattern in the results for two items and three items. The proposed mechanism—the StraightJacket Auction (SJA)—oﬀers bundles of items at ﬁxed prices. The key to ﬁnding these prices is to view the best-response regions as a subdivision of the m-dimensional cube, and observe that there is an intrinsic relationship between the price of a bundle of items and the volume of the respective best-response region.

15

Items 2 3 4 5 6 7 8 9 10

SJA (rev ) 0.549187 0.875466 1.219507 1.576457 1.943239 2.318032 2.699307 3.086125 3.477781

RochetNet (rev ) 0.549175 0.875464 1.219505 1.576455 1.943216 2.318032 2.699305 3.086125 3.477722

Figure 6: Revenue of the Straight-Jacket Auction (SJA) computed via the recursive formula in [Giannakopoulos and Koutsoupias, 2018], and that of the auction learned by RochetNet, for various numbers of items m. The SJA is known to be optimal for up to six items, and conjectured to be optimal for any number of items.

Giannakopoulos and Koutsoupias gave a recursive algorithm for ﬁnding the subdivision and the prices, and used LP duality to prove that the SJA is optimal for m ≤ 6 items.14 They also conjecture that the SJA remains optimal for general m, but were unable to prove it.
Figure 6 gives the revenue of the SJA, and that found by RochetNet for m ≤ 10 items. We used a test sample of 230 valuation proﬁles (instead of 10,000) to compute these numbers for higher precision. It shows that RochetNet ﬁnds the optimal revenue for m ≤ 6 items, and that it ﬁnds DSIC auctions whose revenue matches that of the SJA for m = 7, 8, 9, and 10 items. Closer inspection reveals that the allocation and payment rules learned by RochetNet essentially match those predicted by Giannakopoulos and Koutsoupias for all m ≤ 10.
We take this as strong additional evidence that the conjecture of Giannakopoulos and Koutsoupias is correct.
For the experiments in this subsection, we used a max network over 10,000 linear functions (instead of 1,000). We followed up on the usual training phase with an additional 20 iterations of training using Adam optimizer with learning rate 0.001 and a minibatch size of 230. We also found it useful to impose item-symmetry on the learned auction, especially for m = 9 and 10 items, as this helped with accuracy and reduced training time. Imposing symmetry comes without loss of generality for auctions with an item-symmetric distribution [Daskalakis and Weinberg, 2012]. With these modiﬁcations it took about 13 hours to train the networks.

5.5 Discovering New Optimal Designs

We next demonstrate the potential of RochetNet to discover new optimal designs. For this, we

consider a single bidder with additive but correlated valuations for two items as follows:

C. One additive bidder and two items, where the bidder’s valuation is drawn uniformly from the

triangle

T

=

{(

v

1

,

v2

)|

v1 c

+ v2

≤

2, v1

≥

0, v2

≥

1}

where

c

>

0

is

a

free

parameter.

There is no analytical result for the optimal auction design for this setting. We ran RochetNet

for diﬀerent values of c to discover the optimal auction. The mechanisms learned by RochetNet

for c = 0.5, 1, 3, and 5 are shown in Figure 8. Based on this, we conjectured√that the optimal mechanism contains two menu items for c ≤ 1, namely {(0, 0), 0} and {(1, 1), 2+ 31+3c }, and three menu items for c > 1, namely {(0, 0), 0}, {(1/c, 1), 4/3}, and {(1, 1), 1 + c/3}, giving the optimal

14 The duality argument developed by Giannakopoulos and Koutsoupias is similar but incomparable to the duality approach of Daskalakis et al. [2013]. We will return to the latter in Section 5.5.

16

c 0.500 1.000 3.000 5.000

Opt (rev ) 1.104783 1.185768 1.482129 1.778425

RochetNet (rev ) 1.104777 1.185769 1.482147 1.778525

Figure 7: Revenue of the newly discovered optimal mechanism and that of RochetNet, for Setting C with

varying parameter c.

2.0 Prob. of allocating item 1 1.0 2.0 Prob. of allocating item 2 1.0

2.0 Prob. of allocating item 1 1.0 2.0 Prob. of allocating item 2 1.0

1.8

0.8 1.8

0.8

1.8

0.8 1.8

0.8

1.6

0.6 1.6

0.6

1.6

0.6 1.6

0.6

v2

v2

v2

v2

1.4

0.4

1.2 1

0.2

1.0 0

0.0

0.0 0.1 0.2 0.3 0.4 0.5

v1

(a)

2.0 Prob. of allocating item 1 1.0

1.4

0.4

1.2 1

0.2

1.0 0

0.0

0.0 0.1 0.2 0.3 0.4 0.5

v1

2.0 Prob. of allocating item 2 1.0

1.4

1

0.4 1.4

1

0.4

1.2

0.2 1.2

0.2

1.0 0

0.0 1.0 0

0.0

0.0 0.2 0.4 0.6 0.8 1.0

0.0 0.2 0.4 0.6 0.8 1.0

v1

(b)

v1

2.0 Prob. of allocating item 1 1.0

2.0 Prob. of allocating item 2 1.0

1.8

0.8 1.8

0.8

1.8

0.8

1.8

0.8

1.6

0.6 1.6

0.6

1.6

0.6

1.6

0.6

v2

v2

v2

v2

1.4 0.33

1.2

1

1.0 0 0 1 v1 2

0.4 1.4
0.2 1.2 3 0.0 1.0 0 0
(c)

1 1 v1 2

0.4 0.2 3 0.0

1.4 0.2

0.4

1.2

1

0.2

1.0 0 0 1 2 3 4 5 0.0

v1

(d)

1.4

1

0.4

1.2

0.2

1.0 0 0 1 2 3 4 5 0.0 v1

Figure 8: Allocation rules learned by RochetNet for Setting C. The panels describe the probability that the bidder is allocated item 1 (left) and item 2 (right) for c = 0.5, 1, 3, and 5. The auctions proposed in Theorem 5.1 are described by the regions separated by the dashed black lines, with the numbers in black the optimal probability of allocation in the region.

allocation and payment in each region. In particular, as c transitions from values less than or equal to 1 to values larger than 1, the optimal mechanism transitions from being deterministic to being randomized. Figure 7 gives the revenue achieved by RochetNet and the conjectured optimal format for a range of parameters c computed on 106 valuation proﬁles.
We validate the optimality of this auction through duality theory [Daskalakis et al., 2013] in Theorem 5.1. The proof is given in Appendix D.7.

Theorem 5.1. For any c > 0, suppose the bidder’s valuation is uniformly distributed over set

T

=

{

(v

1

,

v2

)|

v1 c

+ v2

≤ 2, v1
√

≥

0, v2

≥

1}.

Then the optimal auction contains two menu items

{(0, 0), 0} and {(1, 1), 2+ 31+3c } when c ≤ 1, and three menu items {(0, 0), 0}, {(1/c, 1), 4/3}, and

{(1, 1), 1 + c/3} otherwise.

5.6 Scaling Up
We next consider settings with up to ﬁve bidders and up to ten items. This is several orders of magnitude more complex than existing analytical or computational results. It is also a natural playground for RegretNet as no tractable characterizations of IC mechanisms are known for these settings.
We speciﬁcally consider the following two settings, which generalize the basic setting considered in [Manelli and Vincent, 2006] and [Giannakopoulos and Koutsoupias, 2018] to more than one bidder:
D. Three additive bidders and ten items, where bidders draw their value for each item independently from U [0, 1].

17

Setting
D: 3 × 10 E: 5 × 10

RegretNet rev 5.541 6.778

(a)
RegretNet rgt
< 0.002 < 0.005
(b)

Item-wise Myerson
5.310 6.716

Bundled Myerson
5.009 5.453

Figure 9: (a) Revenue and regret of RegretNet on the validation set for auctions learned for Setting D using diﬀerent architectures, where (R, K) denotes R hidden layers and K nodes per layer. (b) Test revenue and regret for Settings D and E, for the (5, 100) architecture.

Setting 2×3

Method RegretNet LP (5 bins/value)

rev 1.291 1.53

rgt < 0.001
0.019

IR viol. 0
0.027

Run-time ∼9 hrs 69 hrs

Figure 10: Test revenue, regret, IR violation, and running-time for RegretNet and an LP-based approach for a two bidder, three items setting with additive uniform valuations.

E. Five additive bidders and ten items, where bidders draw their value for each item independently from U [0, 1].
The optimal auction for these settings is not known. However, running a separate Myerson auction for each item is optimal in the limit of the number of bidders [Palfrey, 1983]. For a regime with a small number of bidders, this provides a strong benchmark. We also compare to selling the grand bundle via a Myerson auction.
For Setting D, we show in Figure 9(a) the revenue and regret of the learned auction on a validation sample of 10,000 proﬁles, obtained with diﬀerent architectures. Here (R, K) denotes an architecture with R hidden layers and K nodes per layer. The (5, 100) architecture has the lowest regret among all the 100-node networks for both Setting D and Setting E. Figure 9(b) shows that the learned auctions yield higher revenue compared to the baselines, and do so with tiny regret.

5.7 Comparison to LP

Finally, we compare the running time of RegretNet with the LP approach proposed in [Conitzer and

Sandholm, 2002, 2004]. To be able to run the LP, we consider a smaller setting with two additive

bidders and three items, with item values drawn independently from U [0, 1]. For RegretNet we

used two hidden layers, and 100 nodes per hidden layer. The LP was solved with the commercial

solver Gurobi. We handled continuous valuations by discretizing the value into ﬁve bins per item

(resulting in ≈ 105 decision variables and ≈ 4 × 106 constraints) and rounding a continuous input

valuation proﬁle to the nearest discrete proﬁle for evaluation.

The results are shown in Figure 10. We also report the violations in IR constraints incurred by

the LP on the test set; for L valuation proﬁles, this is measured by L1n

L =1

i∈N max{ui(v( )), 0}.

Due to the coarse discretization, the LP approach suﬀers signiﬁcant IR violations (and as a result

yields higher revenue). We were not able to run an LP for this setting for ﬁner discretizations in

18

more than one week of compute time. In contrast, RegretNet yields much lower regret and no IR violations (as the neural network satisﬁes IR by design), and does so in just around nine hours. In fact, even for the larger Settings D–E, the running time of RegretNet was less than 13 hours.
6 Conclusion
Neural networks have been deployed successfully for exploration in other contexts, e.g., for the discovery of new drugs [G´omez-Bombarelli et al., 2018]. We believe that there is ample opportunity for applying deep learning in the context of economic design. We have demonstrated how standard pipelines can re-discover and surpass the analytical and computational progress in optimal auction design that has been made over the past 30-40 years. While our approach can easily solve problems that are orders of magnitude more complex than could previously be solved with the standard LP-based approach, a natural next step would be to scale this approach further to industry scale (e.g., through standardized benchmarking suites and innovations in network architecture). We also see promise for the framework in the present paper in advancing economic theory, for example in supporting or refuting conjectures and as an assistant in guiding new economic discovery.
References
M. Anthony and P. L. Bartlett. Neural Network Learning: Theoretical Foundations. Cambridge University Press, 1st edition, 2009.
M. Babaioﬀ, N. Immorlica, B. Lucier, and S. M. Weinberg. A simple and approximately optimal mechanism for an additive buyer. In Proceedings of the 55th IEEE Symposium on Foundations of Computer Science, pages 21–30, 2014.
M-F. Balcan, T. Sandholm, and E. Vitercik. Sample complexity of automated mechanism design. In Proceedings of the 29th Conference on Neural Information Processing Systems, pages 2083–2091, 2016.
C. Boutilier and H. H. Hoos. Bidding languages for combinatorial auctions. In Proceedings of the 17th International Joint Conference on Artiﬁcial Intelligence, pages 1211–1217, 2001.
E. Budish, Y.-K. Che, F. Kojima, and P. Milgrom. Designing random allocation mechanisms: Theory and applications. American Economic Review, 103(2):585–623, April 2013.
Y. Cai and M. Zhao. Simple mechanisms for subadditive buyers via duality. In Proceedings of the 49th ACM Symposium on Theory of Computing, pages 170–183, 2017.
Y. Cai, C. Daskalakis, and M. S. Weinberg. Optimal multi-dimensional mechanism design: Reducing revenue to welfare maximization. In Proceedings of the 53rd IEEE Symposium on Foundations of Computer Science, pages 130–139, 2012a.
Y. Cai, C. Daskalakis, and S. M. Weinberg. An algorithmic characterization of multi-dimensional mechanisms. In Proceedings of the 44th ACM Symposium on Theory of Computing, pages 459– 478, 2012b.
Y. Cai, C. Daskalakis, and S. M. Weinberg. Understanding incentives: Mechanism design becomes algorithm design. In Proceedings of the 54th IEEE Symposium on Foundations of Computer Science, pages 618–627, 2013.
19

S. Chawla, J. D. Hartline, D. L. Malec, and B. Sivan. Multi-parameter mechanism design and sequential posted pricing. In Proceedings of the 42th ACM Symposium on Theory of Computing, pages 311–320, 2010.
A. Choromanska, Y. LeCun, and G. Ben Arous. The landscape of the loss surfaces of multilayer networks. In Proceedings of The 28th Conference on Learning Theory, Paris, France, July 3-6, 2015, pages 1756–1760, 2015.
R. Cole and T. Roughgarden. The sample complexity of revenue maximization. In Proceedings of the 46th ACM Symposium on Theory of Computing, pages 243–252, 2014.
V. Conitzer and T. Sandholm. Complexity of mechanism design. In Proceedings of the 18th Conference on Uncertainty in Artiﬁcial Intelligence, pages 103–110, 2002.
V. Conitzer and T. Sandholm. Self-interested automated mechanism design and implications for optimal combinatorial auctions. In Proceedings of the 5th ACM Conference on Electronic Commerce, pages 132–141, 2004.
C. Daskalakis and S. M. Weinberg. Symmetries and optimal multi-dimensional mechanism design. In Proceedings of the 13th ACM Conference on Electronic Commerce, Proceedings of the 13th ACM Conference on Economics and Computation, pages 370–387, 2012.
C. Daskalakis, A. Deckelbaum, and C. Tzamos. Mechanism design via optimal transport. In Proceedings of the 14th ACM Conference on Electronic Commerce, pages 269–286, 2013.
C. Daskalakis, A. Deckelbaum, and C. Tzamos. Strong duality for a multiple-good monopolist. Econometrica, 85:735–767, 2017.
P. Du¨tting, F. Fischer, P. Jirapinyo, J. Lai, B. Lubin, and D. C. Parkes. Payment rules through discriminant-based classiﬁers. ACM Transactions on Economics and Computation, 3(1):5, 2014.
P. Du¨tting, Z. Feng, N. Golowich, H. Narasimhan, D. C. Parkes, and S. Ravindranath. Machine learning for optimal economic design. In J.-F. Laslier, H. Moulin, M. R. Sanver, and W. S. Zwicker, editors, The Future of Economic Design, volume 70, pages 495–515. Springer, 2019.
Z. Feng, H. Narasimhan, and D. C. Parkes. Deep learning for revenue-optimal auctions with budgets. In Proceedings of the 17th International Conference on Autonomous Agents and Multiagent Systems, pages 354–362, 2018.
D. Fudenberg and A. Liang. Predicting and understanding initial play. American Economic Review, 2019. Forthcoming.
Y. Giannakopoulos and E. Koutsoupias. Duality and optimality of auctions for uniform distributions. In SIAM Journal on Computing, volume 47, pages 121–165, 2018.
X. Glorot and Y. Bengio. Understanding the diﬃculty of training deep feedforward neural networks. In Proceedings of the 13th International Conference on Artiﬁcial Intelligence and Statistics, 2010.
N. Golowich, H. Narasimhan, and D. C. Parkes. Deep learning for multi-facility location mechanism design. In Proceedings of the 27th International Joint Conference on Artiﬁcial Intelligence, pages 261–267, 2018.
20

R. G´omez-Bombarelli, J. N. Wei, D. Duvenaud, J. M. Hern´andez-Lobato, B. S´anchez-Lengeling, D. Sheberla, J. Aguilera-Iparraguirre, T. D. Hirzel, R. P. Adams, and A. Aspuru-Guzik. Automatic chemical design using a data-driven continuous representation of molecules. ACS Central Science, 4(2):268–276, 2018.
Y. A. Gonczarowski and N. Nisan. Eﬃcient empirical revenue maximization in single-parameter auction environments. In Proceedings of the 49th Annual ACM Symposium on Theory of Computing, pages 856–868, 2017.
Y. A. Gonczarowski and S. M. Weinberg. The sample complexity of up-to- multi-dimensional revenue maximization. In 59th IEEE Annual Symposium on Foundations of Computer Science, pages 416–426, 2018.
M. Guo and V. Conitzer. Computationally feasible automated mechanism design: General approach and case studies. In Proceedings of the 24th AAAI Conference on Artiﬁcial Intelligence, 2010.
N. Haghpanah and J. Hartline. When is pure bundling optimal? Review of Economic Studies, 2019. Revise and resubmit.
S. Hart and N. Nisan. Approximate revenue maximization with multiple items. Journal of Economic Theory, 172:313–347, 2017.
J. S. Hartford, J. R. Wright, and K. Leyton-Brown. Deep learning for predicting human strategic behavior. In Proceedings of the 29th Conference on Neural Information Processing Systems, pages 2424–2432, 2016.
J. S. Hartford, G. Lewis, K. Leyton-Brown, and M. Taddy. Deep IV: A ﬂexible approach for counterfactual prediction. In Proceedings of the 34th International Conference on Machine Learning, pages 1414–1423, 2017.
Z. Huang, Y. Mansour, and T. Roughgarden. Making the most of your samples. SIAM Journal on Computing, 47(3):651–674, 2018.
P. Jehiel, M. Meyer-ter-Vehn, and B. Moldovanu. Mixed bundling auctions. Journal of Economic Theory, 134(1):494–512, 2007.
K. Kawaguchi. Deep learning without poor local minima. In Proceedings of the 30th Conference on Neural Information Processing Systems, pages 586–594, 2016.
D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. CoRR, abs/1412.6980, 2014.
S. Lahaie. A kernel-based iterative combinatorial auction. In Proceedings of the 25th AAAI Conference on Artiﬁcial Intelligence, pages 695–700, 2011.
C. Louizos, U. Shalit, J. M. Mooij, D. Sontag, R. S. Zemel, and M. Welling. Causal eﬀect inference with deep latent-variable models. In Proceedings of the 30th Conference on Neural Information Processing Systems, pages 6449–6459, 2017.
A. Manelli and D. Vincent. Bundling as an optimal selling mechanism for a multiple-good monopolist. Journal of Economic Theory, 127(1):1–35, 2006.
M. Mohri and A. M. Medina. Learning algorithms for second-price auctions with reserve. Journal of Machine Learning Research, 17:74:1–74:25, 2016.
21

J. Morgenstern and T. Roughgarden. On the pseudo-dimension of nearly optimal auctions. In Proceedings of the 28th Conference on Neural Information Processing Systems, pages 136–144, 2015.
J. Morgenstern and T. Roughgarden. Learning simple auctions. In Proceedings of the 29th Conference on Learning Theory, pages 1298–1318, 2016.
R. Myerson. Optimal auction design. Mathematics of Operations Research, 6:58–73, 1981.
H. Narasimhan, S. Agarwal, and D. C. Parkes. Automated mechanism design without money via machine learning. In Proceedings of the 25th International Joint Conference on Artiﬁcial Intelligence, pages 433–439, 2016.
T. Palfrey. Bundling decisions by a multiproduct monopolist with incomplete information. Econometrica, 51(2):463–83, 1983.
A. Patel, T. Nguyen, and R. Baraniuk. A probabilistic framework for deep learning. In Proceedings of the 30th Conference on Neural Information Processing Systems, pages 2550–2558, 2016.
G. Pavlov. Optimal mechanism for selling two goods. B.E. Journal of Theoretical Economics, 11: 1–35, 2011.
M. Raghu, A. Irpan, J. Andreas, R. Kleinberg, Q. V. Le, and J. M. Kleinberg. Can deep reinforcement learning solve Erdos-Selfridge-Spencer games? In Proceedings of the 35th International Conference on Machine Learning, pages 4235–4243, 2018.
J.-C. Rochet. A necessary and suﬃcient condition for rationalizability in a quasilinear context. Journal of Mathematical Economics, 16:191–200, 1987.
C. Rudin and R. E. Schapire. Margin-based ranking and an equivalence between adaboost and rankboost. Journal of Machine Learning Research, 10:2193–2232, 2009.
T. Sandholm and A. Likhodedov. Automated design of revenue-maximizing combinatorial auctions. Operations Research, 63(5):1000–1025, 2015.
S. Shalev-Shwartz and S. Ben-David. Understanding Machine Learning: From Theory to Algorithms. Cambridge University Press, New York, NY, USA, 2014.
W. Shen, P. Tang, and S. Zuo. Automated mechanism design via neural networks. In Proceedings of the 18th International Conference on Autonomous Agents and Multiagent Systems, 2019. Forthcoming.
J. Sill. Monotonic networks. In Proceedings of the 12th Conference on Neural Information Processing Systems, pages 661–667, 1998.
V. Syrgkanis. A sample complexity measure with applications to learning optimal auctions. In Proceedings of the 20th Conference on Neural Information Processing Systems, pages 5358–5365, 2017.
A. Tacchetti, D.J. Strouse, M. Garnelo, T. Graepel, and Y. Bachrach. A neural architecture for designing truthful and eﬃcient auctions. CoRR, abs/1907.05181, 2019.
22

D. Thompson, N. Newman, and K. Leyton-Brown. The positronic economist: A computational system for analyzing economic mechanisms. In Proceedings of the 31st AAAI Conference on Artiﬁcial Intelligence, pages 720–727, 2017.
A. C.-C. Yao. An n-to-1 bidder reduction for multi-item auctions and its applications. In Proceedings of the 26th ACM-SIAM Symposium on Discrete Algorithms, pages 92–109, 2015.
A. C.-C. Yao. Dominant-strategy versus bayesian multi-item auctions: Maximum revenue determination and comparison. In Proceedings of the 18th ACM Conference on Economics and Computation, pages 3–20, 2017.

A Additional Architectures
In this appendix we present our network architectures for multi-bidder single-item settings and for a general multi-bidder multi-item setting with combinatorial valuations.

A.1 The MyersonNet Approach

We start by describing an architecture that yields optimal DSIC auction for selling a single item

to multiple buyers.

In the single-item setting, each bidder holds a private value vi ∈ R≥0 for the item. We consider

a randomized auction (g, p) that maps a reported bid proﬁle b ∈ Rn≥0 to a vector of allocation

probabilities g(b) ∈ Rn≥0, where gi(b) ∈ R≥0 denotes the probability that bidder i is allocated the

item and

n i=1

gi(b)

≤

1.

We shall represent the payment rule pi

via a price conditioned on the

item being allocated to bidder i, i.e. pi(b) = gi(b) ti(b) for some conditional payment function

ti : Rn≥0 → R≥0. The expected revenue of the auction, when bidders are truthful, is given by:

n

rev(g, p) = Ev∼F

gi(v) ti(v) .

(11)

i=1

The structure of the revenue-optimal auction is well understood for this setting.

Theorem A.1 (Myerson [1981]). There exist a collection of monotonically non-decreasing func-

tions, φ¯i : R≥0 → R called the ironed virtual valuation functions such that the optimal BIC auction

for selling a single item is the DSIC auction that assigns the item to the buyer with the highest

ironed virtual value φ¯i(vi) provided that this value is non-negative, with ties broken in an arbitrary

value-independent manner, and charges the bidders according to pi(vi) = vigi(vi) −

vi 0

gi(t)

dt.

For distribution Fi with density fi the virtual valuation function is ψi(vi) = vi−(1−F (vi))/f (vi).
A distribution Fi with density fi is regular if ψi is monotonically non-decreasing. For regular distributions F1, . . . , Fn no ironing is required and φ¯i = ψi for all i.
If the virtual valuation functions ψ1, . . . , ψn are furthermore monotonically increasing and not
only monotonically non-decreasing, the optimal auction can be viewed as applying the monotone transformations to the input bids ¯bi = φ¯i(bi), feeding the computed virtual values to a second price auction (SPA) with zero reserve price, denoted (g0, p0), making an allocation according to g0(¯b), and charging a payment φ¯−i 1(p0i (¯b)) for winning bidder i. In fact, this auction is DSIC for any choice of strictly monotone transformations of the values:

23

b1

φ¯1

...

bn φ¯n

SPA-0 g0
p0

(z1, . . . , zn)
φ¯−1 1 t1 ...
φ¯−n 1 tn

h1,1 ... max
h1,J

bi

...

... min ¯bi

hK,1 ...
hK,J

max

(a)

(b)

Figure 11: (a) MyersonNet: The network applies monotone transformations φ¯1, . . . , φ¯n to the input
bids, passes the virtual values to the SPA-0 network in Figure 12, and applies the inverse transformations φ¯−1 1, . . . , φ¯−n 1 to the payment outputs. (b) Monotone virtual value function φ¯i, where hkj(bi) = eαikj bi + βki j.

Theorem A.2. For any set of strictly monotonically increasing functions φ¯1, . . . , φ¯n, an auction deﬁned by outcome rule gi = gi0 ◦ φ¯ and payment rule pi = φ¯−i 1 ◦ p0i ◦ φ¯ is DSIC and IR, where (g0, p0) is the allocation and payment rule of a second price auction with zero reserve.
For regular distributions with monotonically increasing virtual value functions designing an optimal DSIC auction thus reduces to ﬁnding the right strictly monotone transformations and corresponding inverses, and modeling a second price auction with zero reserve.
We present a high-level overview of a neural network architecture that achieves this in Figure 11(a), and describe the components of this network in more detail in Section A.1.1 and Section A.1.2 below.
Our MyersonNet is tailored to monotonically increasing virtual value functions. For regular distributions with virtual value functions that are not strictly increasing and for irregular distributions this approach only yields approximately optimal auctions.

A.1.1 Modeling Monotone Transforms
We model each virtual value function φ¯i as a two-layer feed-forward network with min and max operations over linear functions. For K groups of J linear functions, with strictly positive slopes wki j ∈ R>0, k = 1, . . . , K, j = 1, . . . , J and intercepts βki j ∈ R, k = 1, . . . , K, j = 1, . . . , J, we deﬁne:
φ¯i(bi) = min max wki j bi + βki j.
k∈[K] j∈[J]
Since each of the above linear function is strictly non-decreasing, so is φ¯i. In practice, we can set each wki j = eαikj for parameters αki j ∈ [−B, B] in a bounded range. A graphical representation of the neural network used for this transform is shown in Figure 11(b). For suﬃciently large K and J, this neural network can be used to approximate any continuous, bounded monotone function (that satisﬁes a mild regularity condition) to an arbitrary degree of accuracy [Sill, 1998]. A particular advantage of this representation is that the inverse transform φ¯−1 can be directly obtained from the parameters for the forward transform:
φ¯−i 1(y) = max min e−αikj (y − βki j).
k∈[K] j∈[J]
A.1.2 Modeling SPA with Zero Reserve
We also need to model a SPA with zero reserve (SPA-0) within the neural network structure. For the purpose of training, we employ a smooth approximation to the allocation rule using a

24

sof tmax

¯b1

z1

¯b1

max t01

¯b2 ...
¯bn

z2 ...
zn−1

¯b2 ...
¯bn

max ...
max

t02 t0n−1

0

zn

0

max t0n

(a) Allocation rule g0

(b) Payment rule t0

Figure 12: MyersonNet: SPA-0 network for (approximately) modeling a second price auction with zero

reserve price. The inputs are (virtual) bids ¯b1, . . . , ¯bn and the output is a vector of assignment probabilities

z1, . . . , zn

and

prices

(conditioned

on

allocation)

t01

,

.

.

.

,

t

0 n

.

neural network. Once we learn value functions using this approximate allocation rule, we use them
together with an exact SPA with zero reserve to construct the ﬁnal auction. The SPA-0 allocation rule g0 can be approximated using a ‘softmax’ function on the virtual
values ¯b1, . . . , ¯bn and an additional dummy input ¯bn+1 = 0:

gi0(¯b) =

eκ¯bi n+1 eκ¯bj , i ∈ N,
j=1

(12)

where κ > 0 is a constant ﬁxed a priori, and determines the quality of the approximation. The higher the value of κ, the better the approximation but the less smooth the resulting allocation function.
The SPA-0 payment to bidder i, conditioned on being allocated, is the maximum of the virtual values from the other bidders and zero:

t0i (¯b) = max max ¯bj, 0 , i ∈ N.

(13)

j=i

Let gα,β and tα,β denote the allocation and conditional payment rules for the overall auction in Figure 11(a), where (α, β) are the parameters of the forward monotone transform. Given a sample of valuation proﬁles S = {v(1), . . . , v(L)} drawn i.i.d. from F , we optimize the parameters using the negated revenue on S as the error function, where the revenue is approximated as:

1 L n α,β ( ) α,β ( )

rev(g, t) = L

gi (v ) ti (v ).

=1 i=1

(14)

We solve this training problem using a minibatch stochastic gradient descent solver.

A.2 RegretNet for Combinatorial Valuations
We next show how to adjust the RegretNet architecture so that it can handle bidders with general, combinatorial valuations. In the present work, we develop this architecture only for small number of items.15 In this case, each bidder i reports a bid bi,S for every bundle of items S ⊆ M (except the empty bundle, for which her valuation is taken as zero). The allocation network has an output
15With more items, combinatorial valuations can be succinctly represented using appropriate bidding languages; see, e.g. [Boutilier and Hoos, 2001].

25

zi,S ∈ [0, 1] for each bidder i and bundle S, denoting the probability that the bidder is allocated the bundle. To prevent the items from being over-allocated, we require that the probability that an item appears in a bundle allocated to some bidder is at most one. We also require that the total allocation to a bidder is at most one:

zi,S ≤ 1, ∀j ∈ M ;
i∈N S⊆M :j∈S

(15)

zi,S ≤ 1, ∀i ∈ N.

(16)

S⊆M

We refer to an allocation that satisﬁes constraints (15)–(16) as being combinatorial feasible. To

enforce these constraints, the allocation network computes a set of scores for each bidder and a

set of scores for each item. Speciﬁcally, there is a group of bidder-wise scores si,S, ∀S ⊆ M for each bidder i ∈ N , and a group of item-wise scores s(i,jS), ∀i ∈ N, S ⊆ M for each item j ∈ M . Let s, s(1), . . . , s(m) ∈ Rn×2m denote these bidder scores and item scores. Each group of scores is normal-

ized using a softmax function: s¯i,S = exp(si,S)/

S

exp(si,S

) and s¯(j)
i,S

= exp(s(i,jS))/

i ,S exp(s(ij,)S ).

The allocation for bidder i and bundle S ⊆ M is deﬁned as the minimum of the normalized bidder-

wise

score

s¯i,S

and

the

normalized

item-wise

scores

s¯(j)
i,S

for

each

j

∈

S:

zi,S

=

ϕ

CF i,S

(s,

s(1)

,

.

.

.

,

s

(m)

)

=

min

s¯i,S ,

s¯(j)
i,S

:

j

∈

S

.

Similar to the unit-demand setting, we ﬁrst show that ϕCF (s, s(1), . . . , s(m)) is combinatorial feasible and that our constructive approach is without loss of generality. See Appendix D.5 for a proof.
Lemma A.1. The matrix ϕCF (s, s(1), . . . , s(m)) is combinatorial feasible ∀ s, s(1), . . . , s(m) ∈ Rn×2m. For any combinatorial feasible matrix z ∈ [0, 1]n×2m, ∃ s, s(1), . . . , s(m) ∈ Rn×2m, for which z = ϕCF (s, s(1), . . . , s(m)).

In addition, we want to understand whether a combinatorial feasible allocation z can be implementable, deﬁned in the following way.

Deﬁnition A.1. A fractional combinatorial allocation z is implementable if and only if z can be represented as a convex combination of combinatorial feasible, deterministic allocations.

Unfortunately, Example A.1 shows that a combinatorial feasible allocation may not have an integer decomposition, even for the case of two bidders and two items.

Example A.1. Consider a setting with two bidders and two items, and the following fractional, combinatorial feasible allocation:

z = z1,{1} z1,{2} z1,{1,2} = 3/8 3/8 1/4

z2,{1} z2,{2} z2,{1,2}

1/8 1/8 1/4

Any integer decomposition of this allocation z would need to have the following structure:

z = a 0 0 1 +b 0 0 0 +c 1 0 0 +d 1 0 0 +e 0 0 0

000

001

010

000

010

+f 0 1 0 + g 0 1 0 + h 0 0 0

100

000

100

where the coeﬃcients sum to at most 1. Firstly, it is straightforward to see that a = b = 1/4. Given the construction, we must have c + d = 3/8, e ≥ 0 and f + g = 3/8, h ≥ 0. Thus, a + b + c + d + e + f + g + h ≥ 1/2 + 3/4 = 5/4 for any decomposition. Hence, z is not implementable.

26

To ensure that a combinatorial feasible allocation has an integer decomposition we need to introduce additional constraints. For the two items case, we introduce the following constraint:

n
∀i, zi,{1} + zi,{2} ≤ 1 − zi ,{1,2}.
i =1

(17)

Theorem A.3. For m = 2, any combinatorial feasible allocation z with additional constraints (17) can be represented as a convex combination of matrices B1, . . . , Bk where each B is a combinatorial
feasible, 0-1 allocation.

Proof. Firstly, we observe in any deterministic allocation B , if there exists an i, s.t. Bi,{1,2} = 1, then ∀j = i, S : Bj,S = 0. Therefore, we ﬁrst decompose z into the following components,

n
z = zi,{1,2} · Bi + C,
i=1

and

Bji,S =

1 if j = i, S = {1, 2}, and 0 otherwise.

Then we want to argue that C can be represented as

k =i+1

p

· B , where

k =i+1

p

≤ 1−

n i=1

zi,{1,2}

and

each

B

is a feasible 0-1 allocation.

Matrix C has all zeros in the last (items

{1, 2}) column,

i Ci,{1} ≤ 1 −

n i=1

zi,{1,2},

and

i Ci,{2} ≤ 1 −

n i=1

zi,{1,2}.

In addition, based on constraint (17), for each bidder i,

n
Ci,{1} + Ci,{2} = zi,{1} + zi,{2} ≤ 1 − zi ,{1,2}.
i =1

Thus C is a doubly stochastic matrix with scaling factor 1 −

n i =1

zi

,{1,2}.

Therefore,

we

can

always decompose C into a linear combination

k =i+1

p

·B

, where

k =i+1

p

≤ 1−

n i =1

zi

,{1,2}

and each B is a feasible 0-1 allocation.

We leave to future work to characterize the additional constraints needed for the multi-item (m > 2) case.

A.2.1 RegretNet for Two-item Auctions with Implementable Allocations

To accommodate the additional constraint (17) for the two items case we add an additional softmax

layer for each bidder. In addition to the original (unnormalized) bidder-wise scores si,S, ∀i ∈

N, S ⊆ M and item-wise scores s(i,jS), ∀i ∈ N, S ⊆ M, j ∈ M and their normalized counterparts

s¯i,S, ∀i

∈

N, S

⊆

M

and

s¯(j), ∀i
i,S

∈

N, S

⊆

M, j

∈

M,

the

allocation

network

computes

an

additional

set of scores for each bidder i, s (i,i{)1}, s (i,i{)2}, s 1(i,){1,2}, · · · , s (ni,){1,2}. These additional scores are then

normalized using a softmax function as follows,

∀i, k ∈ N, S ⊆ M,

s¯ = (i)

exp s (ki,)S

k,S exp s (i) +exp s (i) +

i,{1}

i,{2}

. k exp s (ki,){1,2}

27

Distribution n Opt SPA MyersonNet

rev rev

rev

Setting F 3 0.531 0.500

0.531

Setting G 5 2.314 2.025

2.305

Setting H 3 2.749 2.500

2.747

Setting I

3 2.368 2.210

2.355

Figure 13: The revenue of the single-item auctions obtained with MyersonNet.

To satisfy constraint (17) for each bidder i, we compute the normalized score s¯ i,S for each i, S

as,



 s¯ (i)

s¯ i,S =

i,S

 min

s¯ (i,kS) : k ∈ N

if S = {1} or {2}, and if S = {1, 2}.

Then the ﬁnal allocation for each bidder i is:

zi,S = min

s¯i,S

,

s¯

i,S

,

s¯(j)
i,S

:

j

∈

S

.

The payment network for combinatorial bidders has the same structure as the one in Figure 2, computing a fractional payment p˜i ∈ [0, 1] for each bidder i using a sigmoidal unit, and outputting a payment pi = p˜i S⊆M zi,S bi,S.

B Additional Experiments
We present a broad range of additional experiments for the two main architectures used in the body of the paper, and additional ones for the architectures presented in Appendix A

B.1 Experiments with MyersonNet
We ﬁrst evaluate the MyersonNet architecture introduced in Appendix A.1 for designing single-item auctions. We focus on settings with a small number of bidders because this is where revenue-optimal auctions are meaningfully diﬀerent from eﬃcient auctions. We present experimental results for the following four settings:
F. Three bidders with independent, regular, and symmetrically distributed valuations vi ∼ U [0, 1].
G. Five bidders with independent, regular, and asymmetrically distributed valuations vi ∼ U [0, i].
H. Three bidders with independent, regular, and symmetrically distributed valuations vi ∼ Exp(3).
I. Three bidders with independent irregular distributions Firregular, where each vi is drawn from U [0, 3] with probability 3/4 and from U [3, 8] with probability 1/4.
We note that the optimal auctions for the ﬁrst three distributions involve virtual value functions φ¯i that are strictly monotone. For the fourth and ﬁnal distribution the optimal auction uses ironed virtual value functions that are not strictly monotone.
For the training set and test set we used 1,000 valuation proﬁles sampled i.i.d. from the respective valuation distribution. We modeled each transform φ¯i in the MyersonNet architecture using 5 sets of 10 linear functions, and we used κ = 103.

28

The results are summarized in Figure 13. For comparison, we also report the revenue obtained by the optimal Myerson auction and the second price auction (SPA) without reserve. The auctions learned by the neural network yield revenue close to the optimal.
B.2 Additional Experiments with RochetNet and RegretNet
In addition to the experiments with RochetNet and RegretNet on the single bidder, multi-item settings in Section 5.3 we also considered the following settings:
J. Single additive bidder with independent preferences over two non-identically distributed items, where v1 ∼ U [4, 16] and v2 ∼ U [4, 7]. The optimal mechanism is given by Daskalakis et al. [2017].
K. Single additive bidder with preferences over two items, where (v1, v2) are drawn jointly and uniformly from a unit triangle with vertices (0, 0), (0, 1) and (1, 0). The optimal mechanism is due to Haghpanah and Hartline [2019].
L. Single unit-demand bidder with independent preferences over two items, where the item values v1, v2 ∼ U [0, 1]. See [Pavlov, 2011] for the optimal mechanism.
We used RegretNet architectures with two hidden layers with 100 nodes each. The optimal allocation rules as well as a side-by-side comparison of those found by RochetNet and RegretNet are given in Figure 14. Figure 15 gives the revenue and regret achieved by RegretNet and the revenue achieved by RochetNet.
We ﬁnd that in all three settings RochetNet recovers the optimal mechanism basically exactly, while RegretNet ﬁnds an auction that matches the optimal design to surprising accuracy.
B.3 Experiments with RegretNet with Combinatorial Valuations
We next compare our RegretNet architecture for combinatorial valuations described in Section A.2 to the computational results of Sandholm and Likhodedov [2015] for the following settings for which the optimal auction is not known:
M. Two additive bidders and two items, where bidders draw their value for each item independently from U [0, 1].16
N. Two bidders and two items, with item valuations v1,1, v1,2, v2,1, v2,2 drawn independently from U [1, 2] and set valuations v1,{1,2} = v1,1 + v1,2 + C1 and v2,{1,2} = v2,1 + v2,2 + C2, where C1, C2 are drawn independently from U [−1, 1].
O. Two bidders and two items, with item valuations v1,1, v1,2 drawn independently from U [1, 2], item valuations v2,1, v2,2 drawn independently from U [1, 5], and set valuations v1,{1,2} = v1,1 + v1,2 + C1 and v2,{1,2} = v2,1 + v2,2 + C2, where C1, C2 are drawn independently from U [−1, 1].
These settings correspond to Settings I.-III. described in Section 3.4 of Sandholm and Likhodedov [2015]. These authors conducted extensive experiments with several diﬀerent classes of incentive compatible mechanisms, and diﬀerent heuristics for setting the parameters of these auctions. They observed the highest revenue for two classes of mechanisms that generalize mixed bundling auctions and λ-auctions [Jehiel et al., 2007].
These two classes of mechanisms are the Virtual Value Combinatorial Auctions (VVCA) and Aﬃne Maximizer Auctions (AMA). They also considered a restriction of AMA to bidder-symmetric auction (AMAbsym). We use VVCA∗, AMA∗, and AMA∗bsym to denote the best mechanism in the
16This setting can be handled by the non-combinatorial RegretNet architecture and is included here for comparison to Sandholm and Likhodedov [2015].
29

v2

v2

7.0 Prob. of allocating item 1 1.0

6.5

0.8

6.0 0.5

0.6

5.5

1

5.0

0.4

4.5 0

0.2

4.0 5.0 7.5 10.0 12.5 15.0 0.0

v1

(a)

1.0 Prob. of allocating item 1 1.0

0.8

0.8

0.6

0.6

0.4

1

0.4

0.2 0

0.2

0.00.0 0.2 0.4 0.6 0.8 1.0 0.0

v1

(c)

1.0 Prob. of allocating item 1 1.0

0.8

0.8

0.6 0.4 0

0.6

1

0.4

0.2

0.2

0.00.0 0.2 0.4 0.6 0.8 1.0 0.0

v1

(e)

v2

v2

v2

7.0 Prob. of allocating item 2 1.0

6.5

0.8

56..50 1 0.6

5.0

0.4

4.5 0

0.2

4.0 5.0 7.5 10.0 12.5 15.0 0.0
v1
1.0 Prob. of allocating item 2 1.0

0.8

0.8

0.6

0.6

0.4

1

0.4

0.2 0

0.2

0.00.0 0.2 0.4v10.6 0.8 1.0 0.0
1.0 Prob. of allocating item 2 1.0

0.8

1

0.8

0.6

0.6

0.4

0

0.4

0.2

0.2

0.00.0 0.2 0.4v10.6 0.8 1.0 0.0

v2

v2

v2

7.0 Prob. of allocating item 1

6.5

6.0 0.5

5.5

1

5.0 4.5 0

4.0 5.0 7.5 10.0 12.5 15.0
v1
1.0 Prob. of allocating item 1

0.8

0.6

0.4

1

0.2 0
0.00.0 0.2 0.4v10.6 0.8 1.0
1.0 Prob. of allocating item 1

0.8

0.6

0.4 0

1

0.2

0.00.0 0.2 0.4v10.6 0.8 1.0

1.0 0.8 0.6 0.4 0.2 0.0
(b)
1.0 0.8 0.6 0.4 0.2 0.0
(d)
1.0 0.8 0.6 0.4 0.2 0.0
(f )

v2

v2

v2

7.0 Prob. of allocating item 2 1.0

6.5

0.8

56..50 1 0.6

5.0

0.4

4.5 0

0.2

4.0 5.0 7.5 10.0 12.5 15.0 0.0
v1
1.0 Prob. of allocating item 2 1.0

0.8

0.8

0.6

0.6

0.4

1

0.4

0.2 0

0.2

0.00.0 0.2 0.4v10.6 0.8 1.0 0.0
1.0 Prob. of allocating item 2 1.0

0.8

1

0.8

0.6

0.6

0.4

0

0.4

0.2

0.2

0.00.0 0.2 0.4v10.6 0.8 1.0 0.0

v2

Figure 14: Side-by-side comparison of the allocation rules learned by RochetNet and RegretNet for single bidder, two items settings. Panels (a) and (b) are for Setting J, Panels (c) and (d) are for Setting K, and Panels (e) and (f) for Setting L. Panels describe the learned allocations for the two items (item 1 on the left, item 2 on the right). Optimal mechanisms are indicated via dashed lines and allocation probabilities in each region.
respective class, as reported by Sandholm and Likhodedov and found using a heuristic grid search technique.
For Setting M and N, Sandholm and Likhodedov observed the highest revenue for AMA∗bsym, and for Setting O the best performing mechanism was VVCA∗. Figure 16 compares the performance of RegretNet to that of these best performing, benchmark mechanisms. To compute the revenue of the benchmark mechanisms we used the parameters reported in [Sandholm and Likhodedov, 2015] (Table 2, p. 1011), and evaluated the respective mechanisms on the same test set used for RegretNet. Note that RegretNet is able to learn new auctions with improved revenue and tiny regret.

C Gradient-Based Regret Approximation
In Section 4, we describe a gradient-based approach to estimating a bidder’s regret. We present a visualization of this approach in Figure 17 for a well-trained mechanism that has (almost) zero regret for Setting A. We consider a bidder with true valuation (v1, v2) = (0.1, 0.8), represented as a green dot. The heat map represents the utility diﬀerence u((v1, v2); (b1, b2)) − u((v1, v2); (v1, v2)) for misreports (b1, b2) ∈ [0, 1]2, with shades of yellow corresponding to low utility diﬀerences and shades of blue corresponding to high utility diﬀerences. To estimate the regret of the bidder which is essentially zero in this case, we draw 10 random initial misreports from the underlying valuation distribution, represented as red dots, and then perform a sequence of gradient-descent steps on these random misreports. The ﬁgure shows the random initial misreports and then the 20 gradient-descent steps, plotting one in every four steps.

30

Distribution
Setting J Setting K Setting L

Opt rev 9.781 0.388 0.384

RegretNet

rev

rgt

9.734 < 0.001

0.392 < 0.001

0.384 < 0.001

RochetNet rev 9.779 0.388 0.384

Figure 15: Test revenue and regret achieved by RegretNet and revenue achieved by RochetNet for Settings J–L.

Distribution
Setting M Setting N Setting O

RegretNet

rev

rgt

0.878 < 0.001

2.860 < 0.001

4.269 < 0.001

VVCA∗ rev — — 4.209

AMA∗bsym rev 0.862 2.765 —

Figure 16: Test revenue and regret for RegretNet for Settings M–O, and comparison with the best performing VVCA and AMAbsym auctions as reported by Sandholm and Likhodedov [2015].

D Omitted Proofs

In this appendix we present formal proofs for all theorems and lemmas that were stated in the

body of the paper or the other appendices. We ﬁrst introduce some notation. We denote the inner

product between vectors a, b ∈ Rd as a, b =

d i=1

aibi.

We

denote

the

1 norm for a vector x by

x 1 and the induced 1 norm for a matrix A ∈ Rk×t by A 1 = max1≤j≤t

k i=1

Aij

.

D.1 Proof of Lemma 2.1

Let fi(v; w) := maxvi∈Vi uwi (vi; (vi, v−i)) − uwi (vi; (vi, v−i)). Then we have rgt i(w) = Ev∼F [fi(v; w)]. Rewriting the expected value, we have

∞

rgt q (w)

rgti(w) = P(fi(v; w) ≥ x)dx ≥ i P(fi(v; w) ≥ x)dx ≥ q · rgtqi (w),

0

0

where the last inequality holds because for any 0 < x < rgtqi (w), P(fi(v; w) ≥ x) ≥ P(fi(v; w) ≥ rgtqi (w)) = q.

D.2 Proof of Theorem 2.2
We present the proof for auctions with general, randomized allocation rules. A randomized allocation rule gi : V → [0, 1]2M maps valuation proﬁles to a vector of allocation probabilities for bidder i, where gi,S(v) ∈ [0, 1] denotes the probability that the allocation rule assigns subset of items S ⊆ M to bidder i, and S⊆M gi,S(v) ≤ 1. This encompasses both the allocation rules for the combinatorial setting, and the allocation rules for the additive and unit-demand settings, which only output allocation probabilities for individual items. The payment function p : V → Rn maps valuation proﬁles to a payment for each bidder pi(v) ∈ R. For ease of exposition, we omit the superscripts “w”. Recall that M is a class of auctions consisting of allocation and payment rules (g, p). As noted in the theorem statement, we will assume w.l.o.g. that for each bidder i, vi(S) ≤ 1, ∀S ⊆ M .

31

Figure 17: Visualization of the gradient-based approach to regret approximation for a well-trained auction for Setting A. The top left ﬁgure shows the true valuation (green dot) and ten random initial misreports (red dots). The remaining ﬁgures display 20 steps of gradient descent, showing one in every four steps.
D.2.1 Deﬁnitions
Let Ui be the class of utility functions for bidder i deﬁned on auctions in M, i.e.,
Ui = ui : Vi × V → R ui(vi, b) = vi(g(b)) − pi(b) for some (g, p) ∈ M .
and let U be the class of proﬁle of utility functions deﬁned on M, i.e., the class of tuples (u1, . . . , un) where each ui : Vi × V → R and ui(vi, b) = vi(g(b)) − pi(b), ∀i ∈ N for some (g, p) ∈ M.
We will sometimes ﬁnd it useful to represent the utility function as an inner product, i.e., treating vi as a real-valued vector of length 2M , we may write ui(vi, b) = vi, gi(b) − pi(b).
Let rgt ◦ Ui be the class of all regret functions for bidder i deﬁned on utility functions in Ui, i.e.,
rgt ◦ Ui = fi : V → R fi(v) = max ui(vi, (vi, v−i)) − ui(vi, v) for some ui ∈ Ui ,
vi
and as before, let rgt ◦ U be deﬁned as the class of proﬁles of regret functions. Deﬁne the ∞,1 distance between two utility functions u and u as
max |ui(vi, (vi, v−i)) − ui(vi, (vi, v−i))|
v,v i
and let N∞(U, ) denote the minimum number of balls of radius to cover U under this distance. Similarly, deﬁne the distance between ui and ui as maxv,vi |ui(vi, (vi, v−i)) − ui(vi, (vi, v−i))|, and let N∞(Ui, ) denote the minimum number of balls of radius to cover Ui under this distance. Similarly, we deﬁne covering numbers N∞(rgt ◦ Ui, ) and N∞(rgt ◦ U , ) for the function classes rgt ◦ Ui and rgt ◦ U respectively.
Moreover, we denote the class of allocation functions as G and for each bidder i, Gi = {gi : V → 2M | g ∈ G}. Similarly, we denote the class of payment functions by P and Pi = {pi : V → R | p ∈
32

P}. We denote the covering number of P as N∞(P, ) under the ∞,1 distance and the covering number for Pi using N∞(Pi, ) under the ∞,1 distance.

D.2.2 Auxiliary Lemma

We will use a lemma from [Shalev-Shwartz and Ben-David, 2014]. Let F denote a class of bounded functions f : Z → [−c, c] deﬁned on an input space Z, for some c > 0. Let D be a distribution over Z and S = {z1, . . . , zL} be a sample drawn i.i.d. from D. We are interested in the gap between the expected value of a function f and the average value of the function on sample S, and would like to bound this gap uniformly for all functions in F. For this, we measure the capacity of the function class F using the empirical Rademacher complexity on sample S, deﬁned below:





RˆL(F ) := 1 Eσ sup σif (zi) , L f ∈F zi∈S

where σ ∈ {−1, 1}L and each σi is drawn i.i.d from a uniform distribution on {−1, 1}. We then have:

Lemma D.1 (Shalev-Shwartz and Ben-David [2014]). Let S = {z1, . . . , zL} be a sample drawn i.i.d. from some distribution D over Z. Then with probability of at least 1 − δ over draw of S from D, for all f ∈ F,

Ez∼D[f (z)] ≤ L1 L f (zi) + 2RˆL(F ) + 4C
i=1

2 log(4/δ) ,
L

D.2.3 Generalization Bound for Revenue

We ﬁrst prove the generalization bound for revenue. For this, we deﬁne the following auxiliary function class, where each f : V → R≥0measures the total payments from some mechanism in M:

rev ◦ M = f : V → R≥0 f (v) =

n i=1

pi

(v),

for some (g, p) ∈ M

.

Note each function f in this class corresponds to a mechanism (g, p) in M, and the expected value Ev∼D[f (v)] gives the expected revenue from that mechanism. The proof then follows by an application of the uniform convergence bound in Lemma D.1 to the above function class, and by further bounding the Rademacher complexity term in this bound by the covering number of the auction class M.
Applying Lemma D.1 to the auxiliary function class rev ◦ M, we get with probability of at least 1 − δ over draw of L valuation proﬁles S from D, for any f ∈ rev ◦ M,

Ev∼F

− pi(v)
i∈N

≤ − 1 L n pi(v( )) L
=1 i=1

+ 2RˆL(rev ◦ M) + Cn

log(1/δ) ,

(18)

L

All that remains is to bound the above empirical Rademacher complexity RˆL(rev ◦ M) in terms of the covering number of the payment class P and in turn in terms of the covering number of the auction class M. Since we assume that the auctions in M satisfy individual rationality and v(S) ≤ 1, ∀S ⊆ M , we have for any v, pi(v) ≤ 1.

33

By the deﬁnition of the covering number for the payment class, there exists a cover Pˆ for P of size |Pˆ| ≤ N∞(P, ) such that for any p ∈ P, there is a fp ∈ Pˆ with maxv i |pi(v) − fpi(v)| ≤ . We thus have:

Rˆ

(rev ◦ M) =

1 E

L
sup σ ·

L

Lσ p

pi(v( ))

=1

i

1

L

()

1

L

()

()

= L Eσ supp

σ·

fpi(v

) + L Eσ

sup
p

σ·

pi(v ) − fpi(v )

=1

i

=1

i

1

L

≤ Eσ sup σ ·

pˆi(v( ))

1 + Eσ σ 1

L

pˆ∈Pˆ =1

i

L

≤

( pˆi(v ))2 2 log(N∞(P, )) +

iL

≤ 2n 2 log(N∞(P, )) + , (19) L

where the second-last inequality follows from Massart’s lemma, and the last inequality holds because

2
pˆi(v ) ≤
i

pi(v ) + n
i

2

√

≤ 2n L.

We further observe that N∞(P, ) ≤ N∞(M, ). By the deﬁnition of the covering number for the auction class M, there exists a cover Mˆ for M of size |Mˆ | ≤ N∞(M, ) such that for any (g, p) ∈ M, there is a (gˆ, pˆ) ∈ Mˆ such that for all v,

|gij(v) − gˆij(v)| + |pi(v) − pˆi(v)| ≤ .

i,j

i

This also implies that most N∞(M, ).

i |pi(v) − pˆi(v)| ≤ , and shows the existence of a cover for P of size at

Substituting the bound on the Radamacher complexity term in (19) in (18) and using the fact

that N∞(P, ) ≤ N∞(M, ), we get:

Ev∼F

− pi(v)
i∈N

≤ − 1 L n pi(v( )) + 2 · inf

L

>0

=1 i=1

+ 2n 2 log(N∞(M, )) + Cn log(1/δ) ,

L

L

which completes the proof.

D.2.4 Generalization Bound for Regret
We move to the second part, namely a generalization bound for regret, which is the more challenging part of the proof. We ﬁrst deﬁne the class of sum regret functions:
n
rgt ◦ U = f : V → R f (v) = ri(v) for some (r1, . . . , rn) ∈ rgt ◦ U .
i=1
The proof then proceeds in three steps:

34

(1) bounding the covering number for each regret class rgt ◦ Ui in terms of the covering number for individual utility classes Ui
(2) bounding the covering number for the combined utility class U in terms of the covering number for M
(3) bounding the covering number for the sum regret class rgt ◦ U in terms of the covering number for the (combined) utility class M.
An application of Lemma D.1 then completes the proof. We prove each of the above steps below.
Step 1. N∞(rgt ◦ Ui, ) ≤ N∞(Ui, /2).
Proof. By the deﬁnition of covering number N∞(Ui, ), there exists a cover Uˆi with size at most N∞(Ui, /2) such that for any ui ∈ Ui, there is a uˆi ∈ Uˆi with
sup |ui(vi, (vi, v−i)) − uˆi(vi, (vi, v−i))| ≤ /2.
v,vi
For any ui ∈ Ui, taking uˆi ∈ Uˆi satisfying the above condition, then for any v,

max ui(vi, (vi, v−i)) − ui(vi, (vi, v−i)) − max uˆi(vi, (v¯i, v−i)) − uˆi(vi, (vi, v−i))

vi∈V

v¯i∈V

≤ max ui(vi, (vi, v−i)) − max uˆi(vi, (v¯i, v−i)) + uˆi(vi, (vi, v−i)) − ui(vi, (vi, v−i))

vi

v¯i

≤ max ui(vi, (vi, v−i)) − max uˆi(vi, (v¯i, v−i)) + uˆi(vi, (vi, v−i)) − ui(vi, (vi, v−i))

vi

v¯i

≤ max ui(vi, (vi, v−i)) − max uˆi(vi, (v¯i, v−i)) + /2

vi

v¯i

Let vi∗ ∈ arg maxvi ui(vi, (vi, v−i)) and vˆi∗ ∈ arg maxv¯i uˆi(vi, (v¯i, v−i)), then

max ui(vi, (vi, v−i)) = ui(vi∗, v−i) ≤ uˆi(vi∗, v−i) + /2 ≤ uˆi(vˆi∗, v−i) + /2 = max uˆi(vi, (v¯i, v−i)) + ,

vi

v¯i

max uˆi(vi, (v¯i, v−i)) = uˆi(vˆi∗, v−i) ≤ ui(vˆi∗, v−i) + /2 ≤ ui(vi∗, v−i) + /2 = max ui(vi, (vi, v−i)) + /2 .

v¯i

vi

Thus, for all ui ∈ Ui, there exists uˆi ∈ Uˆi such that for any valuation proﬁle v,

max ui(vi, (vi, v−i)) − ui(vi, (vi, v−i)) − max uˆi(vi, (v¯i, v−i)) − uˆi(vi, (vi, v−i)) ≤ ,

vi

v¯i

which implies N∞(rgt ◦ Ui, ) ≤ N∞(Ui, /2). This completes the proof of Step 1.

Step 2. For all i ∈ N , N∞(U , ) ≤ N∞(M, ).

Proof. Recall that the utility function of bidder i is ui(vi, (vi, v−i)) = vi, gi(vi, v−i) − pi(vi, v−i). There exists a set Mˆ with |Mˆ | ≤ N∞(M, ) such that, there exists (gˆ, pˆ) ∈ Mˆ such that

sup |gij(v) − gˆij(v)| + p(v) − pˆ(v) 1 ≤ .
v∈V i,j

35

We denote uˆi(vi, (vi, v−i)) = vi, gˆi(vi, v−i) − pˆi(vi, v−i), where we treat vi as a real-valued vector of length 2M .
For all v ∈ V, vi ∈ Vi,

ui(vi, (vi, v−i)) − uˆi(vi, (vi, v−i)) ≤ vi, gi(vi, v−i) − vi, gˆi(vi, v−i) + pi(vi, v−i) − pˆi(vi, v−i) ≤ vi ∞ · gi(vi, v−i) − gˆi(vi, v−i) 1 + pi(vi, v−i) − pˆi(vi, v−i)

≤

|gij(vi, v−i) − gˆij(vi, v−i)| + pi(vi, v−i) − pˆi(vi, v−i)

j

Therefore, for any u ∈ U, take uˆ = (gˆ, pˆ) ∈ Mˆ , for all v, v ,

|ui(vi, (vi, v−i)) − uˆi(vi, (vi, v−i))|
i

≤ |gij(vi, v−i) − gˆij(vi, v−i)| +

ij

i

≤

pi(vi, v−i) − pˆi(vi, v−i)

This completes the proof of Step 2.
Step 3. N∞(rgt ◦ U , ) ≤ N∞(M, /2). Proof. By deﬁnition of N∞(U , ), there exists Uˆ with size at most N∞(U , ), such that, for any u ∈ U, there exists uˆ such that for all v, v ∈ V ,

|ui(vi, (vi, v−i)) − uˆi(vi, (vi, v−i))| ≤ .
i
Therefore for all v ∈ V , | i ui(vi, (vi, v−i)) − i uˆi(vi, (vi, v−i))| ≤ , from which it follows that N∞(rgt ◦ U , ) ≤ N∞(rgt ◦ U , ). Following Step 1, it is easy to show N∞(rgt ◦ U , ) ≤ N∞(U , /2).
Together with Step 2 this completes the proof of Step 3.
Based on the same arguments as in Section D.2.3, we can thus bound the empirical Rademacher complexity as:

RˆL(rgt ◦ U ) ≤ inf
>0
≤ inf
>0

+ 2n 2 log N∞(rgt ◦ U , ) L
+ 2n 2 log N∞(M, /2) . L

Applying Lemma D.1, completes the proof of the generalization bound for regret.

D.3 Proof of Theorem 3.1

The convexity of uα,β follows from the fact it is a “max” of linear functions. We now show that uα,β is monotonically non-decreasing. Let hj(v) = wj · v + βj. Since wj is non-negative in all entries, for any vi ≤ vi, ∀i ∈ M , we have hj(v) ≤ hj(v ). Then

uα,β(v) = max hj(v) = hj∗(v) ≤ hj∗(v ) ≤ max hj(v ) = uα,β(v ),

j ∈[J ]

j ∈[J ]

36

where j∗ ∈ argminj∈[J] hj(v). It remains to be shown that uα,β is 1-Lipschitz. For any v, v ∈ Rm≥0,

|uα,β(v) − uα,β(v )| = | max hj(v) − max hj(v )|

j ∈[J ]

j ∈[J ]

≤ max |hj(v ) − hj(v)|
j ∈[J ]

= max |wj · (v − v)|
j ∈[J ]

≤ max wj ∞ |v − v|1
j ∈[J ]

≤ |vk − vk|1,

where the last inequality holds because each component αjk = σ(αjk) ≤ 1.

D.4 Proof of Lemma 3.1
First, given the property of the softmax function and the min operation, ϕDS(s, s ) ensures that the row sums and column sums for the resulting allocation matrix do not exceed 1. In fact, for any doubly stochastic allocation z, there exists scores s and s , for which the min of normalized scores recovers z (e.g. sij = sij = log(zij) + c for any c ∈ R).

D.5 Proof of Lemma A.1
Similar to Lemma 3.1, ϕCF (s, s(1), . . . , s(m)) trivially satisﬁes the combinatorial feasibility (constraints (15)–(16)). For any allocation z that satisﬁes the combinatorial feasibility, the following scores
∀j = 1, · · · , m, si,S = s(i,jS) = log(zi,S) + c,
makes ϕCF (s, s(1), . . . , s(m)) recover z.

D.6 Proof of Theorem 3.2

In Theorem 3.2, we only show the bounds on ∆L for RegretNet with additive and unit-demand

bidders. We restate this theorem so that it also bounds ∆L for the general combinatorial valuations

setting (with combinatorial feasible allocation). Recall that the 1 norm for a vector x is denoted

by x 1 and the induced 1 norm for a matrix A ∈ Rk×t is denoted by A 1 = max1≤j≤t

k i=1

Aij

.

Theorem D.1. For RegretNet with R hidden layers, K nodes per hidden layer, dg parameters in the allocation network, dp parameters in the payment network, and the vector of all model parameters
w 1 ≤ W , the following are the bounds on the term ∆L for diﬀerent bidder valuation types: (a) additive valuations: ∆L ≤ O R(dg + dp) log(LW max{K, mn})/L , (b) unit-demand valuations:
∆L ≤ O R(dg + dp) log(LW max{K, mn})/L , (c) combinatorial valuations (with combinatorial feasible allocation):
∆L ≤ O R(dg + dp) log(LW max{K, n 2m})/L .

We ﬁrst bound the covering number for a general feed-forward neural network and specialize it to the three architectures we present in Section 3 and Appendix A.2.

37

Lemma D.2. Let Fk be a class of feed-forward neural networks that maps an input vector x ∈ Rd0 to an output vector y ∈ Rdk , with each layer containing T nodes and computing z → φ (w z),
where each w ∈ RT ×T −1 and φ : RT → [−B, +B]T . Further let, for each network in Fk, let the parameter matrices w 1 ≤ W and φ (s) − φ (s ) 1 ≤ Φ s − s 1 for any s, s ∈ RT −1.

2Bd2W (2ΦW )k d

N∞(Fk, ) ≤

,

where T = max ∈[k] T and d is the total number of parameters in a network.

Proof. We shall construct an 1,∞ cover for Fk by discretizing each of the d parameters along [−W, +W ] at scale 0/d, where we will choose 0 > 0 at the end of the proof. We will use Fˆk
to denote the subset of neural networks in Fk whose parameters are in the range {−( W d/ 0 − 1) 0/d, . . . , − 0/d, 0, 0/d, . . . , W d/ 0 0/d}. The size of Fˆk is at most 2dW/ 0 d. We shall now show that Fˆk is an -cover for Fk.
We use mathematical induction on the number of layers k. We wish to show that for any f ∈ Fk there exists a fˆ ∈ Fˆk such that:
f (x) − fˆ(x) 1 ≤ Bd 0(2ΦW )k.

For k = 0, the statement holds trivially. Assume that the statement is true for Fk. We now show that the statement holds for Fk+1.
A function f ∈ Fk+1 can be written as f (z) = φk+1(wk+1H(z)) for some H ∈ Fk. Similarly, a function fˆ ∈ Fˆk+1 can be written as fˆ(z) = φk+1(wˆk+1Hˆ (z)) for some Hˆ ∈ Fˆk and wˆk+1 is a matrix of entries in {−( W d/ 0 − 1) 0/d, . . . , − 0/d, 0, 0/d, . . . , W d/ 0 0/d}. Also, for any parameter matrix w ∈ RT ×T −1, there is a matrix wˆ with discrete entries s.t.

w − wˆ

T

1 = max

|w ,i,j − wˆ ,i,j | ≤ T

1≤j≤T −1 i=1

0/d ≤ 0.

(20)

We then have:

f (x) − fˆ(x) 1 = φk+1(wk+1H(x)) − φk+1(wˆk+1Hˆ (x)) 1 ≤ Φ wk+1H(x) − wˆk+1Hˆ (x) 1 ≤ Φ wk+1H(x) − wk+1Hˆ (x) 1 + Φ wk+1Hˆ (x) − wˆk+1Hˆ (x) 1 ≤ Φ wk+1 1 · H(x) − Hˆ (x) 1 + Φ wk+1 − wˆk+1 1 · Hˆ (x) 1 ≤ ΦW H(x) − Hˆ (x) 1 + ΦTkB wk+1 − wˆk+1 1 ≤ Bd 0ΦW (2ΦW )k + ΦBd 0 ≤ Bd 0(2ΦW )k+1,

where the second line follows from our assumption on φk+1, and the sixth line follows from our inductive hypothesis and from (20). By choosing 0 = B(2ΦW )k , we complete the proof.

We next bound the covering number of the auction class in terms of the covering number for the
class of allocation networks and for the class of payment networks. Recall that the payment networks computes a fraction α : Rm(n+1) → [0, 1]n and computes a payment pi(b) = αi(b) · vi, gi(b) for each bidder i. Let G be the class of allocation networks and A be the class of fractional payment
functions used to construct auctions in M. Let N∞(G, ) and N∞(A, ) be the corresponding covering numbers w.r.t. the ∞ norm. Then:

38

Lemma D.3. N∞(M, ) ≤ N∞(G, /3) · N∞(A, /3)
Proof. Let Gˆ ⊆ G, Aˆ ⊆ A be ∞ covers for G and A, i.e. for any g ∈ G and α ∈ A, there exists gˆ ∈ Gˆ and αˆ ∈ Aˆ with

sup |gij(b) − gˆij(b)| ≤ /3

(21)

b i,j

sup |αi(b) − αˆi(b)| ≤ /3.

(22)

bi

We now show that the class of mechanism Mˆ = {(gˆ, αˆ) | gˆ ∈ Gˆ, and pˆ(b) = αˆi(b) · vi, gˆi(b) } is an -cover for M under the 1,∞ distance. For any mechanism in (g, p) ∈ M, let (gˆ, pˆ) ∈ Mˆ be a mechanism in Mˆ that satisﬁes (22). We have:

|gij(b) − gˆij(b)| + |pi(b) − pˆi(b)|

i,j

i

≤ /3 + |αi(b) · bi, gi,·(b) − αˆi(b) · bi, gˆi(b) |
i

≤ /3 +
i

|(αi(b) − αˆi(b)) · bi, gi(b) |

+ |αˆi(b) · ( bi, gi(b) − bi, gˆi,·(b)) |

≤ /3 + |αi(b) − αˆi(b)| + bi ∞ · gi(b) − gˆi(b) 1

i

i

≤ 2 /3 + |gij(b) − gˆij(b)| ≤ ,
i,j

where in the third inequality we use bi, gi(b) ≤ 1. The size of the cover Mˆ is |Gˆ||Aˆ|, which completes the proof.

We are now ready to prove covering number bounds for the three architectures in Section 3 and Appendix A.2.

Proof of Theorem D.1. All three architectures use the same feed-forward architecture for computing fractional payments, consisting of K hidden layers with tanh activation functions. We also have by our assumption that the 1 norm of the vector of all model parameters is at most W , for each
= 1, . . . , R + 1, w 1 ≤ W . Using that fact that the tanh activation functions are 1-Lipschitz and bounded in [−1, 1], and there are at most max{K, n} number of nodes in any layer of the payment network, we have by an application of Lemma D.2 the following bound on the covering number of the fractional payment networks A used in each case:

max(K, n)2(2W )R+1 dp N∞(A, ) ≤

where dp is the number of parameters in payment networks. For the covering number of allocation networks G, we consider each architecture separately. In
each case, we bound the Lipschitz constant for the activation functions used in the layers of the allocation network and followed by an application of Lemma D.2. For ease of exposition, we omit the dummy scores used in the ﬁnal layer of neural network architectures.

39

Additive bidders. The output layer computes n allocation probabilities for each item j

using a softmax function. The activation function φR+1 : Rn → Rn for the ﬁnal layer for input

s ∈ Rn×m can be described as: φR+1(s) = [softmax(s1,1, . . . , sn,1), . . . , softmax(s1,m, . . . , sn,m)],

where softmax : Rn → [0, 1]n is deﬁned for any u ∈ Rn as softmaxi(u) = eui/

n k=1

euk

.

We then have for any s, s ∈ Rn×m,

φR+1(s) − φR+1(s ) 1

≤

softmax(s1,j, . . . , sn,j) − softmax(s1,j, . . . , sn,j) 1

j

√ ≤n

softmax(s1,j, . . . , sn,j) − softmax(s1,j, . . . , sn,j) 2

j
√ √ n−1 ≤n
nj

sij − sij 2
i

≤

|sij − sij|

(23)

ji

where the third step follows by bounding the Frobenius norm of the Jacobian of the softmax function.
The hidden layers = 1, . . . , R are standard feed-forward layers with tanh activations. Since the tanh activation function is 1-Lipschitz, φ (s)−φ (s ) 1 ≤ s−s 1. We also have by our assumption that the 1 norm of the vector of all model parameters is at most W , for each = 1, . . . , R + 1,
w 1 ≤ W . Moreover, the output of each hidden layer node is in [−1, 1], the output layer nodes is in [0, 1], and the maximum number of nodes in any layer (including the output layer) is at most max{K, mn}.
By an application of Lemma D.2 with Φ = 1, B = 1, and d = max{K, mn} we have

max{K, mn}2(2W )R+1 dg

N∞(G, ) ≤

,

where dg is the number of parameters in allocation networks.
Unit-demand bidders. The output layer n allocation probabilities for each item j as an element-wise minimum of two softmax functions. The activation function φR+1 : R2n → Rn for the ﬁnal layer for two sets of scores s, s¯ ∈ Rn×m can be described as:

φR+1,i,j(s, s ) = min{softmaxj(si,1, . . . , si,m), softmaxi(s1,j, . . . , sn,j)}. We then have for any s, s˜, s , s˜ ∈ Rn×m,

φR+1(s, s˜) − φR+1(s , s˜ ) 1

≤
i,j

min{softmaxj(si,1, . . . , si,m), softmaxi(s˜1,j, . . . , s˜n,j)} − min{softmaxj(si,1, . . . , si,m), softmaxi(s˜1,j, . . . , s˜n,j)}

≤
i,j

max{softmaxj(si,1, . . . , si,m) − softmaxj(si,1, . . . , si,m), softmaxi(s˜1,j, . . . , s˜n,j) − softmaxi(s˜1,j, . . . , s˜n,j)}

≤
i

softmax(si,1, . . . , si,m) − softmax(si,1, . . . , si,m) 1

40

+
j

softmax(s˜1,j, . . . , s˜n,j) − softmax(s˜1,j, . . . , s˜n,j)} 1

≤ |sij − sij| + |s˜ij − s˜ij|,

i,j

i,j

where the last step can be derived in the same way as (23). As with additive bidders, using additionally hidden layers = 1, . . . , R are standard feed-forward
layers with tanh activations, we have from Lemma D.2 with Φ = 1, B = 1 and d = max{K, mn},

max{K, mn}2(2W )R+1 dg

N∞(G, ) ≤

.

Combinatorial bidders. The output layer outputs an allocation probability for each bidder i and bundle of items S ⊆ M . The activation function φR+1 : R(m+1)n2m → Rn2m for this layer for m + 1 sets of scores s, s(1), . . . , s(m) ∈ Rn×2m is given by:

φR+1,i,S(s, s(1), . . . , s(m)) = min

softmaxS(si,S : S ⊆ M ), softmaxS(s(i,1S) : S ⊆ M ), . . . , softmaxS(s(i,mS) : S ⊆ M ) ,

where softmaxS(aS : S ⊆ M ) = eaS / S ⊆M eaS . We then have for any s, s(1), . . . , s(m), s , s (1), . . . , s (m) ∈ Rn×2m, φR+1(s, s(1), . . . , s(m)) − φR+1(s , s (1), . . . , s (m)) 1

≤
i,S

min softmaxS(si,S : S ⊆ M ), softmaxS(s(i,1S) : S ⊆ M ), . . . , softmaxS(s(i,mS) : S ⊆ M )

− min softmaxS(si,S : S ⊆ M ), softmaxS(si(,S1) : S ⊆ M ), . . . , softmaxS(si(,Sm) : S ⊆ M )

≤ max softmaxS(si,S : S ⊆ M ) − softmaxS(si,S : S ⊆ M ) , i,S softmaxS(s(i,1S) : S ⊆ M ) − softmaxS(si(,S1) : S ⊆ M ) , . . . softmaxS(s(i,mS) : S ⊆ M ) − softmaxS(si(,Sm) : S ⊆ M )

≤

softmax(si,S : S ⊆ M ) − softmax(si,S : S ⊆ M ) 1

i
+

softmax(s(i,jS) : S ⊆ M ) − softmax(si(,Sj) : S ⊆ M ) 1

i,j

≤ |si,S − si,S | + |s(i,jS) − si(,Sj)|,

i,S

i,j,S

where the last step can be derived in the same way as (23).
As with additive bidders, using additionally hidden layers = 1, . . . , R are standard feed-forward layers with tanh activations, we have from Lemma D.2 with Φ = 1, B = 1 and d = max{K, n · 2m}

max{K, n · 2m}2(2W )R+1 dg N∞(G, ) ≤

where dg is the number of parameters in allocation networks.

41

C
(0,2)

E
(0, 43 )
A
(0, 1)

R2 R1

FG H I
R3
D JK
c , 1) (3

B
(c, 1)

Figure 18: The transport of transformed measure of each region in Setting C. .

We now bound ∆L for the three architectures using the covering number bounds we derived
above. In particular, we upper bound the the ‘inf’ over > 0 by substituting a speciﬁc value of : (a) For additive bidders, choosing = √1 , we get
L

∆L ≤ O

log(W max{K, mn}L) R(dp + dg) L

(b) For unit-demand bidders, choosing = √1 , we get
L

∆L ≤ O

log((W max{K, mn}L) R(dp + dg) L

(c) For combinatorial bidders, choosing = √1 , we get
L

∆L ≤ O

log(W max{K, n · 2m}L) R(dp + dg) L .

D.7 Proof of Theorem 5.1
We apply the duality theory of [Daskalakis et al., 2013] to verify the optimality of our proposed mechanism (motivated by empirical results of RochetNet). For the completeness of presentation, we provide a brief introduction of their approach here.
Let f (v) be the joint valuation distribution of v = (v1, v2, · · · , vm), V be the support of f (v) and deﬁne the measure µ with the following density,

Iv=v¯ + Iv∈∂V · f (v)(v · nˆ(v)) − (∇f (v) · v + (m + 1)f (v))

(24)

where v¯ is the “base valuation”, i.e. u(v¯) = 0, ∂V denotes the boundary of V , nˆ(v) is the outer unit normal vector at point v ∈ ∂V , and m is the number of items. Let Γ+(X) be the unsigned (Radon) measures on X. Consider an unsinged measure γ ∈ Γ+(X × X), let γ1 and γ2 be the two marginal measures of γ, i.e. γ1(A) = γ(A × X) and γ2(A) = γ(X × A) for all measurable sets

42

A ⊆ X. We say measure α dominates β if and only if for all (non-decreasing, convex) functions u, u dα ≥ u dβ. Then by strong duality theory we have

sup u dµ =

inf

v − v 1 dγ,

uV

γ∈Γ+(V,V ),γ1−γ2 µ V ×V

(25)

and both the supremum and inﬁmum are achieved. Based on ”complementary slackness” of linear programming, the optimal solution of Equation 25 needs to satisfy the following conditions.

Corollary D.1 (Daskalakis et al. [2017]). Let u∗ and γ∗ be feasible for their respective problems in Equation 25, then u∗ dµ = v − v 1 dγ∗ if and only if the following two conditions hold:

u∗ d(γ1∗ − γ2∗) = u∗ dµ

u∗(v) − u∗(v ) = v − v 1, γ∗-almost surely.

Then we prove the utility function u∗ induced by the mechanism for setting C is optimal. Here we only focus on Settiong C with c > 1, for c ≤ 1 the proof is analogous and we omit here17. The
transformed measure µ of the valuation distribution is composed of:
1. A point mass of +1 at (0, 1). 2. Mass −3 uniformly distributed throughout the triangle area (density − 6c ). 3. Mass −2 uniformly distributed on lower edge of triangle (density − 2c ). 4. Mass +4 uniformly distributed on right-upper edge of triangle (density + √14+c2 ). It is straightforward to verify that µ(R1) = µ(R2) = µ(R3) = 0. We will show there exists an optimal measure γ∗ for the dual program of Theorem 2 (Equation 5) in [Daskalakis et al., 2013]. γ∗ can be decomposed into γ∗ = γR1 + γR2 + γR3 with γR1 ∈ Γ+(R1 × R1), γR2 ∈ Γ+(R2 × R2), γR3 ∈ Γ+(R3 × R3). We will show the feasibility of γ∗, such that

γ1R1 − γ2R1 µ|R1 ; γ1R2 − γ2R2 µ|R2 ; γ1R3 − γ2R3 µ|R3 .

(26)

Then we show the conditions of Corollary 1 in [Daskalakis et al., 2013] hold for each of the measures

γR1, γR2, γR3 separately, such that u∗d(γ1A − γ2A) = A u∗dµ and u∗(v) − u∗(v ) = v − v 1 hold γA-almost surely for any A = R1, R2, and R3. We visualize the transport of measure γ∗ in Figure 18.

Construction of γR1. µ+|R1 is concentrated on a single point (0, 1) and µ−|R1 is distributed

throughout a region which is coordinate-wise greater than (0, 1), then it is obviously to show

0 µ|R1. We set γR1 to be zero measure, and we get γ1R1 − γ2R1 = 0 µ|R1. In addition, u∗(v) = 0, ∀v ∈ R1, then the conditions in Corollary 1 in [Daskalakis et al., 2013] hold trivially.

Construction of γR2. µ+|R2 is uniformly distributed on upper edge CF of the triangle and

µ−|R2 is uniformly distributed in R2. Since we have µ(R2) = 0, we construct γR2 by “transporting” µ+|R2 into µ−|R2 downwards, that is γ1R2 = µ+|R2 , γ2R2 = µ−|R2 . Therefore, u∗d(γ1R2 − γ2R2 ) =
u∗dµ holds trivially. The measure γR2 is only concentrated on the pairs (v, v ) such that v1 =

v1, v2

≥

v2.

Thus

for

such

pairs

(v

v

),

we

have

u∗(v)−u∗(v

)

=

(

v1 c

+

v2

−

4 3

)

−

(

v1 c

+

v2

−

4 3

)

=

||v−v

||1.

Construction of γR3. It is intricate to directly construct γR3 analytically, however, we

will show there the optimal measure γR3 only transports mass from µ+|R3 to µ−|R3 leftwards and

17It is fairly similar to the proof for setting c > 1. If c ≤ 1, there are only two regions to discuss, in which R1 and R2 are the regions correspond to allocation (0, 0) and (1, 1), respectively. Then we show the optimal γ∗ = γ¯R1 + γ¯R2 where γ¯R1 = 0 for region R1 and show γR2 only ”transports” mass of measure downwards and leftwards in region R2, which is analgous to the analysis for γR3 for setting c > 1.

43

downwards.

Let’s consider a point H

on edge BF

with

coordinates

(

v

H 1

,

v2H

).

Deﬁne the regions

RLH = {v ∈ R3|v1 ≤ v1H } and RUH = {v ∈ R3|v2 ≥ v2H }. Let (·) represent the length of segment,

then we have (F H) < 3√c22+1 . Thus,

µ(RUH ) = √4 c(2F+H1) − 6c · 22(c(F2 +H1)c) = √(cF2 H+)1 · 4 − √3 c(2F+H1) > 0

µ(RLH ) = √4 c(2F+H1) − 2c · √(cF2H+)1c − 6c · 32√(cF2H+)1c − 22(c(F2 +H1)c)

(F H) 3 (F H)

=√

·√

−2 <0

c2 + 1

c2 + 1

Thus, there exists a unique line lH with positive slope that intersects H and separate R3 into two parts, RUH (above lH ) and RBH (below lH ), such that µ+(RUH ) = µ−(RUH ). We will then show for any two points on edge BF , H and I, lines lH and lI will not intersect inside R3. In Figure 18, on
the contrary, we assume lH = HK and lI = IJ intersects inside R3. Given the deﬁnition of lH and
lI , we have

µ+(F HKD) = µ−(F HKD); µ+(F IJ D) = µ−(F IJD)

Since µ+ is only distributed along the edge BF , we have

µ+(F IKD) = µ+(F IJ D) = µ−(F IJ D)

Notice µ− is only distributed inside R3 and edge DB, thus µ−(F IKD) > µ−(F IJD). Given the above discussion, we have

µ+(HIK) = µ+(F IJ D) − µ+(F HKD) = µ−(F IJD) − µ−(F HKD) (27)
< µ−(F IKD) − µ−(F HKD) = µ−(HIK)

On the other hand, let S(HIK) be the area of triangle HIK, DG be the altitude of triangle DBF w.r.t BF , and h be the altitude of triangle HJK w.r.t the base HI.

6

61

3

µ−(HJK) = c · S(HIK) = c · 2 (HI)h ≤ c ·

= 3 · √ 2c · (HI) = √ 2 ·

c 3 c2 + 1

c2 + 1

< √ 2 · (HI) = µ+(HIK), c2 + 1

(HI) · (H I )

(DG)

which is a contradiction of Equation 27. Thus, we show lH and lI doesn’t intersect inside R3. Let

γR3 be the measure that transport mass from µ+|R3 to µ−|R3 through lines {lH |H ∈ BF }. Then we have γ1R3 = µ+|R3 , γ2R3 = µ−|R3 , which leads to u∗d(γ1R3 − γ2R3 ) = u∗dµ. The measure γR3

is only concentrated on the pairs (v, v ), s.t. v1 ≥ v1 and v2 ≥ v2. Therefore, for such pairs (v, v ),

we

have

u∗(v)

−

u∗(v

)

=

(v1

+

v2

−

c 3

−

1)

−

(v1

+

v2

−

c 3

−

1)

=

(v1

−

v1)

+

(v2

−

v2)

=

||v

−

v

||1.

Finally, we show there must exist an optimal measure γ for the dual program of Theorem 2 in

[Daskalakis et al., 2013].

44

