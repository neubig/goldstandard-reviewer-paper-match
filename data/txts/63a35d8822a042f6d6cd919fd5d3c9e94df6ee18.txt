arXiv:2202.04000v3 [cs.LG] 10 Feb 2022

Learning Sinkhorn divergences for supervised change point detection
Nauman Ahad, Eva L. Dyer, Keith B. Hengen, Yao Xie, Mark A. Davenport
February 11, 2022
Abstract Many modern applications require detecting change points in complex sequential data. Most existing methods for change point detection are unsupervised and, as a consequence, lack any information regarding what kind of changes we want to detect or if some kinds of changes are safe to ignore. This often results in poor change detection performance. We present a novel change point detection framework that uses true change point instances as supervision for learning a ground metric such that Sinkhorn divergences can be then used in two-sample tests on sliding windows to detect change points in an online manner. Our method can be used to learn a sparse metric which can be useful for both feature selection and interpretation in high-dimensional change point detection settings. Experiments on simulated as well as real world sequences show that our proposed method can substantially improve change point detection performance over existing unsupervised change point detection methods using only few labeled change point instances.
1 Introduction
Sequential data permeates our daily lives. Many applications, ranging from health care to climate monitoring, require detecting change points in sequential data [4, 18]. Such applications often involve increasingly complex and high-dimensional data, leading to challenging change point detection problems.
More precisely, let X denote a sequence x1, x2, . . . , xt P Rd. We say that X has a change point at index nc if xnc , xnc`1, . . . are generated according to a diﬀerent distribution from xnc´1, xnc´2, . . .. The problem of change point detection is to identify the indices corresponding to such change points. There is a rich literature studying this problem, with approaches that can be broadly classiﬁed as either oﬄine methods that focus on partitioning a complete sequence [26] or online methods that that can operate in a streaming setting. Online methods can vary in whether their focus is to rapidly detect a single change point (e.g., [29]) or to detect a sequence of multiple change points (e.g., [19, 17, 5, 6]). What nearly all of these approaches have in common is that they are fundamentally unsupervised. This makes it particularly challenging to identify subtle changes, especially in the high-dimensional setting. In such problems we are hoping to ﬁnd a needle in a haystack, but without knowing what a needle looks like!
Fortunately, in many settings we actually have access to a limited number of expert-labeled change points. This oﬀers a potentially powerful way to provide information about what kind of changes we wish to detect, what kind of changes we may wish to ignore, and what features are most relevant to our task. In this paper we propose a framework for using labeled change points to learn a ground metric for improved online change point detection. We show that by learning a metric that highlights changes of interest, we can both improve change point detection (over unsupervised and non-metric based approaches) and also reveal interpretable maps of which features are most important.
N.Ahad, E.L.Dyer and M.A.Davenport are with the School of Electrical and Computer Engineering, Georgia Tech, Atlanta, GA, USA. K.B.Hengen is with the Department of Biology, Washington University in St. Louis, St. Louis, USA. Y.Xie is with the School of Industrial and Systems Engineering, Georgia Tech, Atlanta, GA, USA. This work was supported, in part, by NSF awards DMS-2134037, IIS-2039741, NIH award 1R01EB029852-01, and a generous gift from the McKnight Foundation. Correspondence to nahad3@gatech.edu, mdav@gatech.edu
1

The main contributions of our work are:
• We propose SinkDivLM, a novel approach for change point detection that uses available change points labels to obtain similarity triplets for learning a ground metric for Sinhkorn divergences. These learned Sinkhorn divergences are then used in two-sample tests over sliding windows for change point detection in the online setting.
• The ground metric learned through our approach provides ﬂexibility and can be suitable for diﬀerent change point detection settings. For example, by incorporating an 1-norm penalty, we show how a sparse ground metric can be learned for simultaneous feature selection and change point detection in high-dimensional settings.
• We experiment on simulated as well as real world sequences to show that our proposed method can improve change point detection performance and reveal important features and interactions needed to reliably detect change points in both low- and high-dimensional settings.

2 Background and related work
2.1 Change point detection
The most widely used algorithms for change point detection are parametric approaches such as Cumulative SUM (CUSUM) and Generalized Likelihood Ratio (GLR). Both of these methods model changes as parametric shifts in the underlying distributions and operate on statistics formed from the log-likelihood ratio between the pre-change and post-change distributions [3, 29]. These methods are best suited to detecting a single change in the quickest time (given some false alarm constraint) in settings where simple parametric models are realistic.
Over the past decade, there has been an increasing focus on non-parametric change point detection methods that operate over sliding windows. Integral probability metrics such as the kernel ratio, the maximum mean discrepancy (MMD), and Wasserstein distances are then used in a two-sample test detect change points [19, 17, 6]. Other kernel methods such as the Hilbert Schmidt Independence Criterion with 1 regularization (HSIC Lasso) have used sliding windows for feature selection in high dimensional change point settings [31]. One potential problem for kernel based non-parametric change point detection methods is that it is diﬃcult to tune the bandwidth parameter for the commonly-used radial basis function (RBF) kernel that is used in MMD. This can lead to undesirable performance in some regimes. Wasserstein distances provide an alternate way to conduct two-sample tests without needing to tune a bandwidth parameter. Some recent works have also used neural network autoencoders and GANs to learn (unsupervised) representations that can then be used in sliding windows to detect change points [5, 9].
All of these methods detect change points in an unsupervised way. There is, however, limited work that incorporates supervision in the form of labeled change points. Most of this work (see [16, 15, 1]) is restricted to the oﬄine change point setting, as opposed to the online setting that we consider in this paper.

2.2 Wasserstein distances and Sinkhorn divergences

Wasserstein distances compute the minimal cost of transporting mass from one distribution to another.

Concretely, consider two discrete multivariate distributions α and β on Rd. We can express these distributions

as n m

ÿ

ÿ

α “ aiδxi and β “ bj δyj ,

i“1

j“1

where δx is the Dirac function at position x P Rd, so that the xi and yj denote the mass locations for the
distributions and ai, bi P R` are the weights at these mass locations for α and β respectively. The ground cost metric C P Rnˆm represents the transportation cost between each pair of distribution mass locations. In this work, we consider Wasserstein 2 (W2) distances that use a squared distance ground cost metric, where
the pi, jqth entry of C is given by Ci,j “ }xi ´ yj }22.

2

As the goal is to minimize the cost of moving mass between two distributions, Wasserstein distances require computing a transport plan P that dictates how mass is transported between the distributions. This is done by solving the following optimization problem:

Wpα, βq “ minxC, P y,
P

subject

to

P

P

R

nˆ `

m

,

P

T

1

n

“

b, P 1m

“

a,

where xC, P y is the Frobenius inner product between the cost matrix C and the transport plan P , a and b
contain the mass weights for the distributions α and β, and 1n P Rn is the vector of all ones.
Wasserstein distances can be unstable and computationally expensive to compute, requiring Opn3 log nq computations to evaluate in the case where n and m are of the same order. This makes it diﬃcult to use
Wasserstein distances repeatedly in two-sample tests. Additionally, the minimization problem can also be
sensitive to slight changes in the input. One solution to these problems is to add a regularization term HpP q to form the entropic regularized Wasserstein distance Wγ [7, 22]. This is also known as the Sinkhorn distance and is deﬁned as

Wγpα, βq “ minxC, P y ´ γHpP q,

(1)

P

subject

to

P

P

R

nˆ `

m

,

P

T

1

n

“

b, P 1m

“

a,

where HpP q is the entropy of the transport plan matrix P and is given by

nm

ÿÿ

HpP q “

P i.j plog P i,j ´ 1q,

i“1 j“1

while γ is a regularization parameter. This regularization terms makes the minimization problem convex, which makes it less sensitive to changes in input, and can be solved with Opn2q computations using the Sinkhorn algorithm [7]. Note that the regularized Wasserstein distance is biased as Wγ2pα, αq ‰ 0. An unbiased divergence can be constructed from these regularized Wasserstein distances and is called the Sinkhorn

divergence:

1

1

Sγpα, βq “ Wγpα, βq ´ 2 Wγpα, αq ´ 2 Wγpβ, βq. (2)

The regularization parameter γ allows Sinkhorn divergences to interpolate between Wasserstein distances

and energy distances [10, 23].

2.3 Learning a ground metric for optimal transport
While the squared distance is a natural choice for the ground cost metric, when it is available, side information can also be used to learn an improved ground metric. This idea was ﬁrst explored to directly estimate the ground cost given similarity/dissimilarity information for nearest neighbour classiﬁcation tasks [8]. Similarity/dissimilarity information was also used to learn a Mahalanobis ground metric to compare word embeddings through Wasserstein distances in [13]. Unsupervised ground metric learning has been also leveraged to devise subspace robust Wasserstein distances [21] that lead to better Wasserstein distance performance in high dimensional settings. This is done by ﬁndind an orthogonal projection of a given rank on the input data such that the Wasserstein distance between samples is maximized. Ground metric learning has also been used to compare entire time series/sequences using order preserving Wasserstein distances [25]. In such settings, time series labels are used to learn a ground metric. Other applications involving ground metric learning include domain adaptation and label distribution learning [33, 14].

2.4 Sinkhorn divergence with learned ground metric
A learned ground metric can be readily incorporated into the calculation of the Sinkhorn divergence. Suppose that we have learned a Mahalanobis metric parameterized by an inverse covariance matrix M with rank r, and consider the factorization M “ LT L, where L is an r ˆ d matrix. For mass weight locations xi, yj P Rd,

3

we can express the ground cost matrix in terms of this Mahalanobis distance as the matrix CL with pi, jqth element given by
CLi,j “ }Lpxi ´ yj q}22.
CL can then be used to compute the Sinhkorn distance:

WL,γpα, βq “ minxCL, P y ´ γHpP q,

(3)

P

subject

to

P

P

R

nˆ `

m

,

P

T

1

n

“

b, P 1m

“

a.

As before, these paramaterized Sinkhorn distances can be used to obtain the parameterized Sinkhorn

divergence:

1

1

SL,γ pα, βq “ WL,γ pα, βq ´ 2 WL,γ pα, αq ´ 2 WL,γ pβ, βq.

3 Proposed method

3.1 Sinkhorn divergence on sequences
Before considering how supervised change detection can be performed by combining Sinkhorn divergence with a learned ground metric, we ﬁrst clarify how Sinkhorn divergences can be applied to compare two sequences. Consider two sequences X P Rtˆd and Y P Rtˆd, where t is the length of the two sequences (which for simplicity we assume to be equal) and d is the dimension of each sample in the two sequences. We can construct the empirical distribution of X and Y via

t
ÿ

1

t
ÿ

1

t δxi and

t δyi

i“1

i“1

These empirical distributions take uniform weights of 1t at the mass locations. While there are many other ways to represent the sequences as discrete distributions, this scheme is often used because of it simplicity.
The parameterized Wasserstein distance between the two sequences can be computed as:

t

WL,γ pX, Y q “ min ÿ P i,j}Lpxi ´ yjq}22 ´ γHpP q

(4)

P

i,j“1

subject

to

P

P

R

tˆt `

,

P

T

1

t

“

1t, P 1t

“

1t.

3.2 Generating similarity triplets from change points
As shown in Figure 1, a true change point can be used to generate similar and dissimilar pairs of sub-sequences. In 1(B), we obtain two sub-sequences represented by the grey and blue squares. Mathematically, we refer to these as Xp1 and Xp2 respectively. Similarly we can obtain two sub-sequences after the change point that are shown in blue and grey circles. We refer to these as Xf1 and Xf2 . Sub-sequences on the same side of the change should be similar, whereas the sub-sequences on the opposite side of the change points should be dissimilar. This can be captured mathematically via the Sinkhorn divergence via a constraint that, for example, SL,γpXp1, Xp2q should be smaller than SL,γpXp1, Xf2 q. Such constraints can be represented as triplets pXi, Xsi , Xdi q, where Xsi represents a sequence that that is nearer to Xi than Xdi . From each labelled change point we can construct such triplets.
Note that we will slightly abuse notation in writing WL,γ pX, Y q by letting X and Y denote both the empirical distribution of the sequences as well as the sequences themselves.

4

A C

Dim 3

B

Dim 2

Dim 1 time

Across

Within

..

Learned Sinkhorn Div.

Change Point Statistic

Figure 1: In (A-B), we show how labeled change point instances (red vertical lines) are used to obtain similarity triplets from pre-change (square sub-sequences) and post-change windows (circled sub-sequences) as shown in B. These triplets are then used to learn a linear transformation L that ensures samples across the change points are far apart. (C) After learning L, we use a two-sample test in a sliding window to perform online change point detection.

3.3 Learning a ground metric for change detection

Our goal is to leverage the triplets generated from the labelled change points to learn a ground metric such that the Sinkhorn divergence SL,γ does a better job of highlighting change points. The metric learning community has been considering similar problems in a range of works works [28, 30]. When comparing distributions, the Wasserstein distance, or its variants such as the Sinkhorn divergence, can capture diﬀerences in geometry of samples in a distribution, helping detect samples with dissimilar distributions. Equipping Sinkhorn divergences with a learned ground metric can further improve improve this ability by transforming the data in a way that highlights dissimilarities (and de-emphasizes similarities). This can be done by using the triplet loss

lpLq “ ÿ ”c ´ pSL,γ pXi, Xdi q ´ SL,γ pXi, Xsi qqı` , (5)
iPTriplets

where c is the triplet margin, r¨s` is the hinge loss, and SL,γ is the parameterized Sinkhorn divergence from (2). The gradient of the parameterized Sinkhorn divergence between two sequences X and Y with respect to L can be computed as

BSLpX, Y q

t
ÿ˚

T

BL “ 2L P i,jpxi ´ yjqpxi ´ yjq ,

i,j“1

where P ˚ is the optimal transport plan computed by solving (4). The gradient of the triplet loss function in (5) is

BlpLq ÿ

t
ÿ˚

t

s

sT

ÿ˚

d

dT

BL “

2L P vi,vjs pxvi ´ xvj qpxvi ´ xvj q ´ 2L P vi,vjd pxvi ´ xvj qpxvi ´ xvj q , (6)

vPViol i,j“1

i,j“1

5

Algorithm 1 Learn transform L for ground metric using similarity triplets from true change points

Inputs:

Set

of

triplets

pX

i

,

X

s i

,

X

d i

q

from

true

change

points,

Sinkhorn

regularization

parameter

γ

,

Gradient

descent rate µ, Triplet loss constant c

Output: Trained L

Initialize: L0

for t “ 1 to number of iterations do

Identify triplet indices v that violate the hinge constraint

Compute

transport

plan

between

similar

pairs

P

˚ v,v

s

by

solving

SLt´1

pX

v

,

X

s v

q

@

v

Compute

transport

plan

between

dissimilar

pairs

P

˚ v,v

d

by

solving

SLt´1

pX

v

,

X

d v

q

@

v

Use

computed

transport

plans

P

˚ v,v

d

and

P

˚ v,v

s

to

form

gradient

BlpLq BL

Lt “ Lt´1 ´ µ BlBpLLq

where

v

is

the

index

for

similarity

triplets

that

violate

the

hinge

loss

constraint

in

(5),

P

˚ v,v

s

is

the

transport

plan

between

Xv

and

its

similar

pair

X sv ,

and

P

˚ v,v

d

is

the

transport

plan

between

Xv

and

its

dissimilar

pair

Xdv. Algorithm 1 shows how this gradient can be used to learn the transformation L. Algorithm 2 shows how

this learned transformation can be used for change detection.

Algorithm 2 Using Sinkhorn divergence with learned metric for change detection

Inputs: Sequence X, Window length w, Change threshold τ , Learned L

Output: Detected changes

for n “ 1 to length of sequence X do

Form

consecutive

windows

X

n p

,

X

n f

at

index

n

mn

“

SL,γ

p

X

n p

,

X

n f

q

using

(2)

if mn ą τ then

Add n to change points

3.4 Learning a sparse ground metric
Additional regularization terms can be used in conjunction with the triplet loss to learn a ground metric that is suitable for diﬀerent change detection settings. For example, adding a regularizing with an 1 or a mixed norm loss has been used for learning a sparse metric [32]. We can use the same idea for learning a sparse ground metric by considering, for example,
min lpLq ` λ}L}1.
L
Such an approach aims to learn a metric that depends on only a sparse subset of the original features in Rd.
3.5 Learned metrics can improve two-sample tests using Sinhkorn divergences
Sample complexity results for Sinkhorn distances, Wγ, were given in [11]. A straightforward extension of these results can be obtained for Sinkhorn divergences.

6

Proposition 3.1. If n samples are used to estimate the empirical distributions αp n „ α and βpn „ β on Rd, then the deviation of the Sinkhorn divergence between these empirical distributions from the true distributions
is bounded with probability 1 ´ δ:

d

λK

8

log

p

2 δ

q

|Sγpα, βq

´

Sγ

p

α p

n

,

βp

n

q|

ď

6B

? n

`

C

, n

(7)

where

λ

“

Opmaxp1,

γ

1
d{2

q,

B

and

C

are

constants,

and

K

is

the

kernel

associated

with

the

dual

Sinkhorn

potentials.

These sample complexity results can be used to obtain deviation bounds for the Sinkhorn divergence under the null distribution.

Corollary 3.1. The Sinkhorn divergence between two n samples α1n, α2n „ α, is bounded by

d

12

λK

8

log

p

2 δ

q

|Sγ

p

α p

n

,

α p

n

q|

ď

6B

? n

`

C

. n

(8)

As the metric learning loss in (5) contains similar pairs from the same distribution, an ideally learned metric would ensure that SL,γpα, αq “ 0, while SL,γpα, βq ě c for dissimilar pairs, where c is the triplet loss margin. In other words, the Sinkhorn divergence between similar pairs from the same distribution would be 0 and the Sinkhorn divergence between dissimilar pairs would be greater than the margin c. If this margin c is set such that c ą Sγpα, βq, i.e., greater than the Sinkhorn divergence without a learned metric, then it is
likely that SL,γpα, βq ą Sγpα, βq. From (7), this will likely ensure that SL,γpαp n, βpnq ą Sγpαp n, βpnq, resulting in a Sinkhorn divergence with increased testing power.
Under the case where case, where both samples come from the same distribution, the results in (8) show that when the regularization parameter γ is small, a large dimension of the input distributions can lead to a large Sinkhorn divergence, which would result in false change points. Learning a ground metric learning allows us to enforce a structure on the distribution that improves sample complexity results. This can be done by projecting the distribution into low-dimensional subspace, as explored in [21, 27]. Learning either a low-dimensional projection L or a sparse projection L reduces the eﬀective dimension of the data distribution, leading to improved change by detecting fewer false change points.

4 Experiments
4.1 Evaluation metrics
We use area under the curve (AUC) to report the performance of our change point detection method as it is used by other work papers to evaluate performance [5, 6]. Similar to the evaluation methods used in [5], a change point is detected correctly if it is detected at the true change point location. The AUC metric covers the true positive and false positive rates at diﬀerent detection thresholds and is thus a suitable metric to evaluate change point detection performance.
4.2 Synthetic datasets
Switching variance. We simulate the AR process
x1ptq “ 0.6x1pt ´ 1q ´ 0.5x1pt ´ 2q ` t,
where t „ N p0, σ2q and σ switches between σ “ 1 and σ “ 5 every 100 time steps. We also generate a noise vector rx2ptq, . . . , x50ptqs „ N p049, I49qq. We concatenate x1ptq with rx2ptq, . . . , x50ptqs to obtain a 50 dimensional vector rx1ptq, . . . , x50ptqs where changes are only happening in the ﬁrst dimension.

7

Switching Gaussian mixtures. Two 100 dimensional Gaussian mixture distributions α “ N p0, Iq ` N p1, Σ0q and β “ N p0, Iq ` N p1.5, Σ1q were used to simulate a sequence where α and β switched every 100 samples. Σ0 and Σ1 are diagonal covariance matrices where the ﬁrst 3 entries on the diagonal are 3 and 5 respectively, while the rest of the diagonal entries are 1. A training sequence consisting of 25 changes, of which 80 percent used for training and 20 percent were used for validation, was used to train the ground metric. A separate testing sequence consisting of 25 changes was used to evaluate performance.
Switching frequency mixture. A two dimensional sequence where the ﬁrst dimension switches between sinp2πp0.1qtq ` sinp2πp0.5qtq ` sinp2πp0.3qtq and sinp2πp0.1qtq ` sinp2πp0.5qtq ` sinp2πp0.35qtq every t “ 100. The second dimension switches between sinp2πtq ` sinp2πp1.5qtq ` sinp2πp1.70qtq and sinp2πtq ` sinp2πp1.5qtq ` sinp2πp0.35qtq every t “ 100. These sequences are generated such that there are 10 samples per second. Both these dimension have N p0, 0.1q noise added. 15 changes points are used to train the ground metric, 4 are used for validation. A diﬀerent sequence consisting of 19 changes points is used as the test set.
Switching frequency mixture with slopes. This includes the frequency switching dataset concatenated with 48 additional dimensions whose slopes change every 1000 samples, resulting in a 50 dimensional dataset. True change point are only labeled at instances where the frequencies in the ﬁrst two dimensions change. For 24 of the additional dimensions the slope changes from a gradient of -0.06 to 0.06, and for the other 24 dimensions the slopes change from 0.06 to -0.06. All of the slope dimensions have N p0, 0.0001q noise added.
4.3 Real world datasets
Bee Dance. Bees are tracked using videos to obtain three dimensional sequences, where the ﬁrst two dimensions represent the x,y coordinates for bee location, while the third dimension shows the bee heading angle. Instances where the bee waggle dance changes from one stage to the other are labelled as change points. The dataset consists of 6 sequences. We used two sequences for training and validation, while the rest of the sequences are used as test datasets. In total there are 15 change points that are used for training, of which 12 are used for training and 3 for validation.
HASC (Activity Detection). HASC-2011 and HASC-2016 datasets consists of people performing performing diﬀerent activities such as walking, running, skipping, staying. An accelerometer provides a three dimensional sequence where changes are labeled when there is a change in activity. A single sequence from HASC-2016 was used for true labels and training the ground metric. This sequence provided 15 true change points of which 80 percent are used for training and 20 percent for validation. The rest of the 89 sequence datasets in the HASC-2016 are used as test datasets. A single sequence dataset, the same used by [5], from HASC-2011 is also used as a test dataset.
Yahoo. 15 sequences containing change points that indicate a change in diﬀerent metrics, such as CPU usage, memory usage, etc. All sequences are one dimensional. We use 3 change points from one of the 15 sequences to train our metric and use the rest of the sequences for evaluation.
ECG. A single dimensional sequence containing change point labels at Ischemia, or abnormal heartbeat, instances. We split the dataset for training and testing, and use 21 change points for training and validation, in an 80-20 split.
Mouse Sleep Stage. This dataset consists of the spiking activity of 42 neurons detected from multielectrode arrays implanted in the hippocampus of a mouse as it moves through diﬀerent arousal and sleep stages [2, 12, 20] (REm, nREM, and wake) over 12 hours. A sub-sequence that contained 14 change points (between REM and nREM) were used to train and validate the learned ground metric. A diﬀerent sub-sequence consisting of 28 change points was used as a test dataset.
4.4 Baselines
We compare the performance of our method (SinkDivML) with diﬀerent methods that we classify into two categories: those that require access to true change points for learning a model and those that do not.
8

Table 1: AUC for diﬀerent change point methods

Model
HSIC M-stats TIRET TIREF KLCPD SinkDiv SinkDivLM

Swch GMM
0.493 0.947 0.501 0.677 0.802 0.778 0.974

Swch Freq
0.426 0.437 0.551 0.647 0.709 0.481 0.843

Bee Dance
0.543 0.494 0.539 0.556 0.632 0.556 0.682

HASC (2011)
0.603 0.605 0.659 0.725 0.663 0.757 0.803

HASC (2016)
0.591 0.751 0.643 0.712 0.742 0.717 0.759

Yahoo
0.737 0.865 0.871 0.932 0.942 0.946

ECG
0.844 0.747 0.900 0.810 0.900 0.899

Baselines not requiring access to true change points. These baselines include Sinkhorn divergence without learning a metric (SinkDiv), M-stats [17], and HSIC [31]. SinkDiv and M-stats do not involve any model learning whereas HSIC learns a model using pseudo labels only.
Baselines requiring access to true change points. These include generative neural network based kernel change point (KLCPD), autoencoder based methods in time domain TIRET, and frequency domain TIREF[9]. Though these models are trained in an unsupervised manner, they need access to true change labels to tune and validate the learned model. We use the same sequence datasets to train and validate these models that we use to train and validate our method. We also use a supervised version of HSIC (sHSIC) for experiments that involve feature selection in high dimensional change settings. Rather than using pseudo labels, which HSIC uses, we use true change point labels for feature selection.
4.5 Window size and projection dimension settings
As suggested by the results in the previous section, the empirical Sinkhorn divergence will be closer to the true Sinkhorn divergence as the number of samples increase. Thus a larger sliding window size would generally be better, but would result in increased computation time. The window size is also dataset dependent, with the major constraint being that the windows should not be so large as to cover segments spanning multiple change points. However, it should also be large enough to capture all the aspects of the sequence. For example in the frequency mixture dataset, the window should be long enough to capture at least one complete period of the sinusoids. The learned projection L should ideally project data to a lower dimension to reduce error between true and empirical divergences. However, a larger projection dimension might be needed to actually learn the model. Validation loss can be used to tune both the projection dimension r and regularization parameter γ.
5 Results
Table 1 compares the performance for diﬀerent change point detection methods on datasets that are either low dimensional, i.e. datasets which have a maximum dimension of 3, or datasets that involve changes in all dimensions, such as the switching GMM dataset. As these datasets are either low dimensional or involve changes in all dimensions, the ground metric is learned without 1 regularization. Barring the the ECG dataset, SinkDivLM performs the best on all datasets. The Bee Dance dataset and HASC 2011 datasets are particularly challenging for other change point detection methods as seen in [5]. For the Bee Dance dataset, SinkDivLM improves performance by 8% over KLCPD, which is the next best method. On HASC 2011, SinkDivLM leads to a 21% improvement over KLCPD and a 6 % improvement over SinkDiv which provided the second best results. This shows that kernel methods that require tuning the bandwidth parameter, such as KLCPD and M-stats, do much worse on HASC 2011 than methods, such as SinkDiv and SinkDivLM, that are based on Optimal Transport. For HASC 2016 it is easier to detect change points in most of the 90 sequences in the dataset. This leads to larger scores for most of the baselines, leading to a relatively smaller improvement for SinkDivLM. The Yahoo and ECG datasets involve abrupt instantaneous changes (and thus involve a
9

1000 500
0 420 360 300 0

SinkDivLM change statistic True CP
SinkDiv change statistic
25 50 75Tim1e00 125 150 175
(a) Detected changes

Type 2 error Type 2 error

1.0

SinkDivLM

SinkDiv

0.8

w = 4

w = 4

0.6

w = 8

w = 8

0.4

w = 16

w = 16

0.2

0.0

0.0

0.2 T0y.4pe 1 er0r.o6r 0.8

1.0

(b) Errors across window sizes

1.0

SinkDivLM

SinkDiv

0.8

2 = 0.5

2 = 0.5

0.6

2 = 1

2 = 1

0.4

2 = 2

2 = 2

0.2

0.0

0.0

0.2 T0y.4pe 1 er0r.o6r 0.8

1.0

(c) Errors across noise levels

Figure 2: Results for the switching GMM dataset. On the left, we show the change point statistic for the Sinkhorn divergence with (SinkDivLM) and without (SinkDiv) a learned metric. To the right, we show Type 1 vs Type 2 errors for both approaches as we vary the (B) window sizes and (C) amount of added noise.

Table 2: AUC on high-dimensional datasets. SinkDivLM is used with 1-regularization to learn a sparse metric.

Dataset
Sleep Stage Swch Var Swch Frq/Slp

HSIC
0.668 0.868 0.592

sHSIC
0.941 0.934 0.521

SinkDiv
0.925 0.567 0.331

SinkDivLM
0.946 0.931 0.672

very small window size of size 2 and 3 respectively). Our method assumes that changes persist for some time to learn a metric, and these datasets involve transient changes leaving very small sub-sequence windows to learn a metric. For this reason, the performance gain is not prominent on these datasets. Additionally the performance is already relatively strong for other methods on these datasets, leaving relatively till room for improvement. Results for HSIC were not available for one dimensional datasets such as Yahoo and ECG.
When a ground metric is correctly learned, the Sinkhorn divergence between dissimilar samples is larger than the provided margin constant c in (5). This results in the change point statistics between dissimilar sub-sequences being larger than the change point statistics between similar sub-sequences, which makes it easier to set a threshold that correctly detects true change points with out detecting many false change points. Figure 2(a) shows how a learned metric leads to a larger change statistic between dissimilar sequences on the switching GMM dataset. This leads to improved change point detection performance in Table 1.
Figures 2(b) and 2(c) show the relationship between type 1 and type 2 errors between samples from the two 100 dimensional Gaussian Mixture Models, that are used in the GMM switching dataset, at diﬀerent noise and window sizes. Solid lines represent the Sinkhorn divergence with a metric that is learned without added noise using 10 samples from each distribution, while dashed lines represent Sinkhorn divergence without a learned ground metric. Samples for the null hypothesis were generated using α “ N p0, Iq ` N p1, Σ0q, while samples for the alternate hypothesis were generated using β “ N p0, Iq ` N p1.5, Σ1q. For 2(b), a noise of N p0, 2Iq was added. In Figure 2(c) 10 samples from each distribution were used.
5.1 Learning a sparse metric for feature selection
When 1 regularization is used, the learned ground metric can be used for selecting features that correspond to changes of interest. For the switching variance dataset, the learned metric L is large in magnitude for indices corresponding to the dimension in which the variance is changing. The true changes between REM and non-REM sleep in the mouse sleep stage dataset also correspond to changes in only some of the 48 dimensions (diﬀerent neurons), which the 1 regularized ground metric is able to select. Table 2 shows results on switching variance and sleep stage datasets. As these datasets are high-dimensional, 1 regularization is used to learn a sparse ground metric.
Though HSIC is presented in [31] as an unsupervised method that ﬁnds features that maximize separation by using pseudolabels at every time instance, we can also use HSIC for feature selection in a supervised manner by focusing on true change points. Both HSIC and our method aim to focus on ﬁnding a small number

10

Dim1 1.414 -0.396 0.109
Dim2 -0.396 0.918 -0.496
Dim3 0.109 -0.496 8.805 Dim1 Dim2 Dim3
(a) Learned metric for Bee Dance

1.0

Dim1

Dim2

0.5

Dim3

Truth

0.0

SinkDivLM change statistic

0.4

0.2

0.0
SinkDiv change statistic
0.10

0.05

0.00 0

100 200 300 400 500 600 700

(b) Sample sequence from the Bee Dance dataset

Figure 3: The ﬁrst subplot in 3(b) shows a sample sequence from the Bee dance dataset. It can be seen that true changes, shown by red vertical lines, are often associated by changes in the variance of the third (green) dimension of this sequence. The learned metric in 3(a) captures this information as the 3 dimension is associated with a much larger value as compared to other dimensions. The 2nd subplot in 3(b) shows that our method allows Sinkhorn divergences to use this learned metric to do a much better job at identifying change points than Sinkhorn divergences without a learned metric.

Dim1 26.995 30.607 -30.47
Dim2 30.607 35.08 -34.986
Dim3 -30.47 -34.986 34.92 Dim1 Dim2 Dim3
(a) Learned metric for HASC

1.0

Dim1

Dim2

0.5

Dim3

Truth

0.0

2

SinkDivLM change statistic

1

0
SinkhDiv change statistic

0.050

0.025

0.000 0

2000 4000 6000 8000 10000

(b) Sample sequence from the HASC dataset

Figure 4: 4(a) shows the learned metric for the HASC dataset, while 4(b) shows an example sequence with true change points shown by vertical lines. The learned metric. As compared to Sinkhorn divergence without a learned metric (SinkDiv), learned metric results (SinkDivLM) in higher change statistic between sub-sequences across true changes points (higher testing power), and lower test statistic in regions with no changes that leading to a lesser number of false change points.

of features that can predict changes of interest. However, our method can also identify multivariate patterns (or correlations in diﬀerent variables) that must be present for a CP to be detected. For this reason, when we tested both methods on the switching frequency with slopes dataset. HSIC fails to identify the correct feature in switching frequency dataset and mistakenly identiﬁes other dimensions with constant slope as features causing the change. Moreover, through using a triplet loss in our approach, we can identify features whose Sinkhorn divergence is smaller for sub-sequences before the change than sub-sequences across a change. This allows it to correctly identify the feature of interest causing the change.
5.2 Interpretability
A learned linear metric also allows us to interpret how diﬀerent input features contribute to detecting changes. For example, Figure 3 shows that third dimension of the input sequence is mostly responsible for detecting changes. This helps us get a better understanding of what kinds of changes in sequences are of interest. For the Human activity dataset, the learned metric in Figure 4 shows what input features are positively correlated
11

(a) Sparse metric learned by SinkDivLM ofor Sleep Stage dataset

400 200
0
400 200
0
400 200
0
400 200
0 1
400 200
0 1

Neuron 6 recording Neuron 15 recording

REM Non REM

Neuron 13 recording

Neuron 14 recording

100

200

300

400

500

Neuron 16 recording

100

200

300

400

500

Sequence Instance

(b) Top 5 Neurons identiﬁed by SinkDivLM

400 200
0
400 200
0
400 200
0
400 200
0 1
400 200
0 1

Neuron 15 recording Neuron 28 recording

REM Non REM

Neuron 3 recording

Neuron 13 recording

100

200

300

400

500

Neuron 6 recording

100

200

300

400

500

Sequence Instance

(c) Top 5 Neurons identiﬁed by sHSIC

Figure 5: 5(a) shows the learned sparse metric for the Sleep Stage dataset. The top 5 features, or neurons, from this metric are are visualized in 5(b), while 5(c) visualizes top 5 features identiﬁed by sHSIC.

and what features are negatively correlated. This learned metric increases the change statistic at true change points, leading to better change detection performance. Figure 5 shows the sparse learned metric for the Sleep Stage dataset. This helps us identify what features, or neurons in the hippocampus, are responsible for causing changes between REM and non-REM sleep stages. Tables 3 and 4 show the top 5 neurons identiﬁed by SinkDivLM and HSIC respectively for causing changes between REM and Non-REM sleep stages. These neurons are visualized in Figures 5(b) and 5(c).

12

Type 1 error
Rank

1.0

d =5

d =50

0.8

d =100

d =200

0.6

d =500 d =1000

0.4 Unprojected

0.2

0.0 0

20 T40hreshol6d0

80

100

(a) Errors across diﬀerent projection dimensions of L

100 90 80 70 60 50 40 30 20 10
0 0 20D0 imen4s00ion pr6o00jection800 1000
(b) Projection dimension vs rank of LT L

Figure 6: 6(a) shows the Type 1 errors for diﬀerent dimension projections for the transformation L. 6(b) shows the rank for the Mahalanobis metric (LT L) that is induced by L. For dimension projections greater than 50, the eﬀective rank was lower than the ambient dimension, leading to better Type1 error rates than the unprotected case. This held true even when the projection dimension was 1000.
Table 3: Top 5 Neurons identiﬁed by SinkDivLM on Sleep Stage dataset

Normalized Feature value

Neuron 6 1.00

Neuron 15 0.8058

Neuron 13 0.5405

Neuron 14 0.4225

Neuron 16 0.226

Table 4: Top 5 Neurons identiﬁed by sHSIC on Sleep Stage dataset

Normalized Feature value

Neuron 15 1.00

Neuron 28 0.464

Neuron 3 0.452

Neuron 13 0.436

Neuron 6 0.384

5.3 Type1 error versus projection dimension
We further study the results in 8 that relate how projection dimension of L aﬀects type 1 error. For this, we conducted two samples tests between samples from two 100 dimensional Gaussian mixture models; α “ N p0, Iq ` N p1, Σ0q and samples from β “ N p0, Iq ` N p1.5, Σ1q. Σ0 and Σ1 are diagonal covariance matrices where the ﬁrst 3 entries on the diagonal are 3 and 5 respectively, while the rest of the diagonal entries are 1. α is chosen to be the null distribution and β is used as the alternate distribution for these experiments. An additional noise of N p0, 2q was added to these samples. Samples from these two distributions were used to minimize (5) with diﬀerent choices of projection dimension L. Figure 6 shows the results for type 1 error across L learned with diﬀerent projection dimensions.
For dimension projections greater than 50, the eﬀective rank was lower than the ambient dimension of the input data, leading to better Type1 error rates than the unprotected case. This held true even when the projection dimension was 1000. This is an interesting observation we would like to further analyze in the future. Though our loss function doesn’t explicitly require the learned metric to be low rank, the learned metric through the triplet loss resulted in a metric that was lower rank (than the ambient dimension), leading to smaller Type 1 errors.

13

6 Conclusion and future directions
There are numerous ways in which we can further improve our method. For training sequences, we only obtain similar dissimilar pairs from true change point labels. We can increase the number of training pairs by using the learned metric to detect change points on the training sequences. Falsely detected change points can be used to obtain similar pairs which could in turn be used to increase the number of similarity triplets for retraining the metric.
Sinkhorn divergences provide a powerful tool for distinguishing between samples. However, they do not naturally incorporate temporal structure into the cost. This means that Sinkhorn divergences can not, for example, distinguish a sequence from its temporally inverted counterpart. One potential way to address this weakness is to leverage tools from order preserving Wasserstein distances in [24, 25] that regularize the transport plan so that the temporal nature of the data is respected. This makes sense for comparing sequences which have similar starting time, an assumption that is violated by consecutive sequences obtained through sliding windows. This causes many false change points at the boundary of these sliding windows. A possible future step would be to look for Sinkhorn divergences that incorporate temporal nature of the data but can be used on consecutive sliding windows.
It would also be interesting to see how supervised change point detection could be used in conjunction with unsupervised change point detection to further improve performance. One straight forward method is to use our method in a transductive manner by ﬁrst using available labels to learn a supervised ground metric for detecting change points. This metric can be used to be detect unlabeled change points for retraining the ground metric.
References
[1] Samaneh Aminikhanghahi and Diane Cook. A survey of methods for time series change point detection. Knowl. Inf. Syst., 51(2):339–367, 2017.
[2] Mehdi Azabou, Mohammad Gheshlaghi Azar, Ran Liu, Chi-Heng Lin, Erik C. Johnson, Kiran BhaskaranNair, Max Dabagia, Bernardo Avila-Pires, Lindsey Kitchell, Keith B. Hengen, William Gray-Roncal, Michal Valko, and Eva L. Dyer. Mine your own view: Self-supervised learning through across-sample prediction, 2021. arxiv:2102.10106 [cs.LG].
[3] Michele Basseville, Igor Nikiforov, et al. Detection of abrupt changes: Theory and Application, volume 104. Prentice Hall, 1993.
[4] Claudie Beaulieu, Jie Chen, and Jorge L Sarmiento. Change-point analysis as a tool to detect abrupt climate variations. Philos. Trans. R. Soc. A, 370(1962):1228–1249, 2012.
[5] Wei-Cheng Chang, Chun-Liang Li, Yiming Yang, and Barnaba´s Po´czos. Kernel change-point detection with auxiliary deep generative models. In Proc. Int. Conf. Learn. Representations (ICLR), Vancouver, Canada, 2018.
[6] Kevin C Cheng, Shuchin Aeron, Michael C Hughes, Erika Hussey, and Eric L Miller. Optimal transport based change point detection and time series segment clustering. In Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP), Virtual Conference, 2020.
[7] Marco Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. In Proc. Int. Conf. Neural Inf. Process. Syst. (NeurIPS), Lake Thaoe, Nevada, 2013.
[8] Marco Cuturi and David Avis. Ground metric learning. J. Mach. Learn. Res. (JMLR), 15(1):533–564, 2014.
[9] Tim Deryck, Maarten De Vos, and Alexander Bertrand. Change point detection in time series data using autoencoders with a time-invariant representation. IEEE Trans. Signal Process., 69(1):3513 – 3524, 2021.
[10] Jean Feydy, Thibault S´ejourn´e, Fran¸cois-Xavier Vialard, Shun-ichi Amari, Alain Trouv´e, and Gabriel Peyr´e. Interpolating between optimal transport and mmd using sinkhorn divergences. In Proc. Int. Conf. Art. Intell. Stat. (AISTATS), Naha, Japan, 2019.
14

[11] Aude Genevay, L´enaic Chizat, Francis Bach, Marco Cuturi, and Gabriel Peyr´e. Sample complexity of sinkhorn divergences. In Proc. Int. Conf. Art. Intell. Stat. (AISTATS), Naha, Japan, 2019.
[12] Keith B Hengen, Alejandro Torrado Pacheco, James N McGregor, Stephen D Van Hooser, and Gina G Turrigiano. Neuronal ﬁring rate homeostasis is inhibited by sleep and promoted by wake. Cell, 165(1):180– 191, 2016.
[13] Gao Huang, Chuan Quo, Matt J Kusner, Yu Sun, Kilian Q Weinberger, and Fei Sha. Supervised word mover’s distance. In Proc. Int. Conf. Neural Inf. Process. Syst. (NeurIPS), Barcelona, Spain, 2016.
[14] Tanguy Kerdoncuﬀ, R´emi Emonet, and Marc Sebban. Metric learning in optimal transport for domain adaptation. In Proc. Int. Joint Conf. on Artiﬁcial Intelligence (IJCAI), Virtual Conference, 2021.
[15] R´emi Lajugie, Francis Bach, and Sylvain Arlot. Large-margin metric learning for constrained partitioning problems. In Proc. Int. Conf. Mach. Learn. (ICML), Beijing, China, 2014.
[16] Fang Li, George C Runger, and Eugene Tuv. Supervised learning for change-point detection. Int. Journ. of Product. Res., 44(14):2853–2868, 2006.
[17] Shuang Li, Yao Xie, Hanjun Dai, and Le Song. Scan b-statistic for kernel change-point detection, 2015. arxiv:1507.01279 [CS.LG].
[18] Siqi Liu, Adam Wright, and Milos Hauskrecht. Change-point detection method for clinical decision support system rule monitoring. Artif. Intell. in Medicine, 91:49–56, 2018.
[19] Song Liu, Makoto Yamada, Nigel Collier, and Masashi Sugiyama. Change-point detection in time-series data by relative density-ratio estimation. Neural Netw., 43:72–83, 2013.
[20] Zhengyu Ma, Gina G Turrigiano, Ralf Wessel, and Keith B Hengen. Cortical circuit dynamics are homeostatically tuned to criticality in vivo. Neuron, 104(4):655–664, 2019.
[21] Fran¸cois-Pierre Paty and Marco Cuturi. Subspace robust wasserstein distances. In Proc. Int. Conf. Mach. Learn. (ICML), Long Beach, California, 2019.
[22] Gabriel Peyr´e, Marco Cuturi, et al. Computational optimal transport: With applications to data science. Found. Trends Mach. Learn., 11(5-6):355–607, 2019.
[23] Aaditya Ramdas, Nicol´as Garc´ıa Trillos, and Marco Cuturi. On wasserstein two-sample testing and related families of non-parametric tests. Entropy, 19(2):47, 2017.
[24] Bing Su and Gang Hua. Order-preserving wasserstein distance for sequence matching. In Proc. IEEE Conf. on Comp. Vision and Patter. Recog (CVPR), Honolulu, Hawaii, 2017.
[25] Bing Su and Ying Wu. Learning distance for sequences by learning a ground metric. In Proc. Int. Conf. Mach. Learn. (ICML), Long Beach, California, 2019.
[26] Charles Truong, Laurent Oudre, and Nicolas Vayatis. Selective review of oﬄine change point detection methods. Signal Process., 167:107299, 2020.
[27] Jie Wang, Rui Gao, and Yao Xie. Two-sample test using projected wasserstein distance. In Proc. Int. Symp. Info. Theory (ISIT), Virtual Conference, 2021.
[28] Kilian Q Weinberger and Lawrence K Saul. Distance metric learning for large margin nearest neighbor classiﬁcation. J. Mach. Learn. Res. (JMLR), 10(2), 2009.
[29] Liyan Xie, Shaofeng Zou, Yao Xie, and Venugopal V Veeravalli. Sequential (quickest) change detection: Classical results and new directions. IEEE Journ. on Select. Areas in Info. Theory, 2(2):494–514, 2021.
[30] Eric Xing, Michael Jordan, Stuart J Russell, and Andrew Ng. Distance metric learning with application to clustering with side-information. In Proc. Int. Conf. Neural Inf. Process. Syst. (NeurIPS), Vancouver, Canada, 2002.
15

[31] Makoto Yamada, Akisato Kimura, Futoshi Naya, and Hiroshi Sawada. Change-point detection with feature selection in high-dimensional time-series data. In Proc. Int. Joint Conf. on Artiﬁcial Intelligence (IJCAI), Beijing, China, 2013.
[32] Yiming Ying, Kaizhu Huang, and Colin Campbell. Sparse metric learning via smooth optimization. In Proc. Int. Conf. Neural Inf. Process. Syst. (NeurIPS), Vancouver, Canada, 2009.
[33] Peng Zhao and Zhi-Hua Zhou. Label distribution learning by optimal transport. In AAAI Conf. Artif. Intell (AAAI), New Orleans, Louisiana, 2018.
16

A Data sources
Beedance: https://sites.cc.gatech.edu/~borg/ijcv_psslds/ More details on the bee waggle dance can be seen at https://www.youtube.com/watch?v=1MX2WN-7Xzc HASC: http://hub.hasc.jp ECG: https://timeseriesclassification.com/description.php?Dataset=ECG200 These sources can also be downloaded from datapages in: https://github.com/OctoberChang/klcpd_code https://github.com/kevin-c-cheng/OtChangePointDetection Sleep Stage: Extracellular single unit spiking was collected from chronically implanted, freely behaving animals [24, 12]. Tetrode arrays were implanted without drives into mouse CA1 (C57BL/6) and rat V1 (Long Evans). Following recovery, neural data were recorded at 25 kHz continuously during free behavior. Raw data were processed and clustered using standard pipelines. Data was bandpassed (500-10,000 Hz) and clustered using MountainSort. Single units were identiﬁed in the clustering output via XGBoost. Trained human scorers evaluated the LFP power spectral density and integral of animal movement to evaluate waking, NREM and REM sleep.
B Baseline sources
HSIC: https://github.com/riken-aip/pyHSICLasso KLCPD: https://github.com/OctoberChang/klcpd_code TIRE: https://github.com/deryckt/TIRE
C Experiment details

Table 5: Parameter settings for experiments

Dataset

GMM switch Freq switch Freq switch w Beedance HASC Yahoo ECG Sleep stage

slope

Project dim (d)
5 50 50 3 3 5 2 42

Win size w
10 100 100 15 200 2 3 15

Entrp Reg (γ)
0.1 1 1 0.1 0.1 0.1 0.001 1

Learn rate (µ)
0.01 0.01 0.01 0.01 0.01 0.001 0.001 0.01

1 Regul (λ) 5e-5 0.01

For all experiments, a total of 2000 iterations were used and the model with best validation loss was saved. For baselines that involved two-sample tests (such as M-Stats, KLCPD, SinkDiv), the same window sizes were used. For TIRE diﬀerent window sizes were used till the best performance was attained. We do not use a window margin (where a change is correctly detected if it is within a certain margin of the true change point)
For time eﬃciency, sliding windows were used to obtain batched batched two-sample tests. two-sample tests using Sinkhorn divergence libraries for Pytorch were conducted on these batches.
Sinkhorn library:https://github.com/gpeyre/SinkhornAutoDiff
For the Sleep stage dataset, the true change points between REM and non-REM sleep stages are often not labelled perfectly (There might not be any prominent change at a true labelled change point for very short window sizes). For these reasons, when learning features through both sHSIC and SinkDivLM, we select windows on the opposite side of change points with a buﬀer of size 10. This buﬀer is not needed when detecting change points over sliding windows.

17

D Alternate formulation

Unfortunately, the loss function in (5) is not convex in L as its Hessian, with respect to L, is not guaranteed to be positive semi-deﬁnite. Sinkhorn divergence with parameterized ground metric in (4) can be equivalently expressed as
nm
WM,γ pX, Y q “ min ÿ ÿ P i,jpxi ´ yjqT M pxi ´ yjq ´ γHpP q
P i“1 j“1
subject to P P Rn`ˆm
P T 1n “ 1, P 1m “ 1,

where M “ LT L. Consequently, M can be learned by

min

ÿ

”

ı`

c ´ pSM,γ pXi, Xdq ´ SM,γ pXi, Xsqq

M

i

i

iPTriplets

subject to M 0

The positive semi-deﬁnite condition on M arises from the requirement on Wasserstein distance WM,γ, and subsequently SM,γ, to be positive. Additionally, SM,γ is linear in M .

E Obtaining the transport plan for Sinkhorn distances
The transport plan P for the regularized Wasserstein distances (or Sinkhorn distances), can be obtained using the Sinkhorn algorithm. We ﬁrst set up the dual formulation of (1)

E.1 Dual formulation

We can incorporate the constraints into a Lagrangian dual function

max min LpP, f , gq “ max minxC, Py ´ γEpPq ` xf , a ´ P1my ` xg, b ´ PT 1ny

f ,g P

f ,g P

“ maxxf , ay ` xg, by ` minxC ´ f 1m ´ g1m, Py ´ γEpPq

f ,g

P

“ maxxf , ay ` xg, by ` minxC ´ f 1m ´ g1m, Py ´ γxP, log P ´ 1nˆmy

(9)

f ,g

P

By solving BLpBPP,f,gq “ 0, we can obtain P such that: Pi,j “ efi{γ e´Ci,j {γ egj {γ looomooon
Kernel
Substituting P in (9), we can obtain after simpliﬁcation the equivalent dual problem

maxxf , ay ` xg, ny ´ γxef{γ , e´C{γ eg{γ .y
f ,g
For non-discrete distributions, a more generalized dual formulation can be seen below

ż

ż

ż

f pxq`gpyq´cpx,yqp

Wγppa, bq “

sup

f pxqdαpxq ` gpyqdβpyq ´ γ e

γ

dαpxqdβpyq

pf pxqPCpX q,gpyqPCpYqq X

Y

X ,Y

“

sup

EαβrzX,Y pf, gqs

pf pxqPCpX q,gpyqPCpYqq

f pxq`gpyq´cpx,yqp

where zx,ypf, gq “ f pxq ` gpyq ´ γe

γ

.

(10)
(11) (12)

18

E.2 Sinkhorn Algorithm
We can rewrite (9) in terms of vectors u, u and K “ e´Ci,j{γ as:

P “ diagpuqKdiagpvq

(13)

Also from constraints:

diagpuqKdiagpvq1m “ a and pdiaguqKdiagpvqqT 1n “ b,

u d Kv “ a and v d KT u “ b. An alternating update scheme can be used to update the dual potentials until convergence

ul`1 “ a and vl`1 “

b .

Kvl

KT ul

19

