Automatic Rule Generation for Time Expression Normalization
Wentao Ding, Jianhao Chen, Jinmao Li, Yuzhong Qu National Key Laboratory for Novel Software Technology, Nanjing University {wtding, jh_chen, jmli}@smail.nju.edu.cn, yzqu@nju.edu.cn

arXiv:2108.13658v2 [cs.CL] 30 Sep 2021

Abstract
The understanding of time expressions includes two sub-tasks: recognition and normalization. In recent years, signiﬁcant progress has been made in the recognition of time expressions while research on normalization has lagged behind. Existing SOTA normalization methods highly rely on rules or grammars designed by experts, which limits their performance on emerging corpora, such as social media texts. In this paper, we model time expression normalization as a sequence of operations to construct the normalized temporal value, and we present a novel method called ARTime, which can automatically generate normalization rules from training data without expert interventions. Speciﬁcally, ARTime automatically captures possible operation sequences from annotated data and generates normalization rules on time expressions with common surface forms. The experimental results show that ARTime can signiﬁcantly surpass SOTA methods on the Tweets benchmark, and achieves competitive results with existing expert-engineered rule methods on the TempEval-3 benchmark.
1 Introduction
Temporal information plays an important role in natural language. The research community divides the understanding of time expressions into two subtasks: recognition and normalization (UzZaman et al., 2013). The ﬁrst task is to annotate time expressions from free text, and the second one is to annotate the temporal values and types of the recognized time expressions. Some recent research work (Zhong et al., 2017; Zhong and Cambria, 2018; Ding et al., 2019) achieved signiﬁcant improvements on the recognition task comparing with classic rule-based or semantic parsing systems, while the researches on normalization have lagged behind. Normalization methods often rely on expert-designed rules or grammars to model the

compositional structure of time expression, which are domain-sensitive and not sufﬁcient enough on covering emerging corpora.
To avoid the performance limitation and the labor cost of manually designing rules for different corpora, we study the problem of automatically generating normalization rules from annotated data. There are some challenges to achieve this goal. Firstly, the surface text forms of natural language expressions are diverse, and the normalized value of time expressions may not directly correspond to their surface text form. (e.g., both the expression “May” and “this month” could be normalized to “2021-05”.) Secondly, time expressions have rich semantic structures which are not explicitly reﬂected in their annotations. The implicitness of semantic structure makes supervised approaches hard to apply to the task of generating normalization rules. Besides, the annotations in practical datasets are noisy, which challenges the robustness of data-driven methods.
To achieve the goal, we regard time expression normalization as a sequence of operations to construct the normalized temporal value of speciﬁc types. We assume that the surface form of time expressions activates the corresponding normalization sequence. The normalization rules are deﬁned as the alignment between surface form pattern and activated operation sequences, as demonstrated in Example 1. Section 3 will describe operations and normalization rules in details.
Example 1. The time expression “last October” can be normalized by the rule (Pattern=“last MONTH:$1”, Type=Instant, Operations=(ToLast[Year], ModifyEnum[$1])), where the type “Instant” indicates that the normalized value should be a date or time instant, the ﬁrst operation decreases the current value on year ﬁeld by 1, and the second operation modiﬁes the value on month ﬁeld by the “MONTH” variable obtained from the expression (i.e., October).

We name the method for automatically generating normalization rules as ARTime 1. ARTime computes the difference between the base value and the annotated value of input time expression to capture possible operation sequences, aligning the captured sequence with the surface form of the time expression to construct candidate rules. It ranks the noisy candidates by their frequency to distinguish the good rules. When applying the rules for normalization, ARTime attempts to dynamically search a rule composition for unmatched expressions to improve the coverage of generated rules. The whole normalization process only relies on a small set of pre-deﬁned lexicon of temporal values (e.g, numeric values and time units), and does not need the intervention of human experts.
The rest sections are organized as follows: The second section summarizes related research work. The third section introduces the representation of temporal values and time expressions in detail. The fourth section describes the framework and main components of ARTime. The ﬁfth section reports the evaluation results of ARTime on two benchmarks. The last section concludes this paper.
2 Related Work
Understanding time expressions in natural language has long attracted the attention of researchers. The TIDES research program proposed TIMEX (Setzer and Gaizauskas, 2000) and TIMEX2 (Ferro et al., 2005), which are standalone annotation schemes of time expression with detailed descriptions of temporal values. The TERQAS workshops conceptualized TimeML (Pustejovsky et al., 2010) based on TIMEX and TIMEX2. TimeML became an ISO standard in 2009. Bethard and Parker (2016) pointed out that the classic annotation schemes failed to show the semantic composition structure of of time expressions and proposed the Semantically Compositional Annotation of Time Expressions (SCATE). However, applying SCATE to existing corpus requires to manually re-annotate the expressions in a more complex way, and many of the existing SOTA methods can not handle annotation in SCATE format directly (Laparra et al., 2018).
On the recognition of time expression, an early study shows that the complexity of time expressions is limited, and ﬁnite state automata or regex
1Our codes are available at https://github.com/ nju-websoft/ARTime

expression can be effective for recognizing those expressions (Hobbs et al., 1997). Mainstream recognition methods can be roughly divided to surface-structure-based methods (Verhagen et al., 2005; Strötgen and Gertz, 2010; Strötgen et al., 2013; Chang and Manning, 2012; Lee et al., 2014; Zhong et al., 2017; Ding et al., 2019) and sequential-tagging-model-based methods (Bethard, 2013; Ning et al., 2018; Zhong and Cambria, 2018). Research work in recent years achieves signiﬁcant improvements on the recognition. SynTime (Zhong et al., 2017) deﬁnes generic but heuristic rules on a group of time-related triggering token types. TOMN (Zhong and Cambria, 2018) uses the SynTime deﬁned token types instead of the classic BIO-tagging scheme for the CRF model. PTime (Ding et al., 2019) generalizes time expressions in training data to sequential patterns and selects a subset of the patterns for recognition. However, these studies only focus on the recognition.
The normalization of time expression is dominated by methods with expert designed rules or grammars. HeidelTime (Strötgen and Gertz, 2010; Strötgen et al., 2013, 2014) uses regex rules on time tokens and modiﬁers to combine recognized tokens and ﬁlter ambiguous expressions. SUTime (Chang and Manning, 2012) proposes a 3-layered temporal pattern language. It ﬁrstly extends recognized tokens to string, then composes and ﬁlters the strings to get temporal values. Angeli and Uszkoreit (2013) use an EM-style bootstrapping approach to learn a PCFG parser on pre-deﬁned preternminals. UWTime (Lee et al., 2014) uses a combinatory categorical grammar to parse possible meanings of time expressions. It selects meanings for recognized expressions via a linear classiﬁer with context-dependent features. CogCompTime (Ning et al., 2018) provides a rule-based standalone normalizer conceptually built on Zhao et al. (2012), which achieves the SOTA normalization results on the (UzZaman et al., 2013) dataset. There are also some efforts on understanding event-related expressions. Tissot et al. (2015) analyzes time expressions in clinical notes. TweetTime (Tabassum et al., 2016) improves existing methods by establishing an external event knowledge base. According to existing studies (UzZaman et al., 2013; Tabassum et al., 2016), rule-engineering can achieve good results on covered expressions but are hard to extend to emerging corpora.
In this paper, we focus on automatically recover-

ing the semantic structure of expressions without any compositional annotations. The latest work on recognition inspired our idea of using surface form patterns to activate normalization rules, and we replace the labor cost of designing rules by the automatic rule generation.
3 Time Expression Normalization as a Sequence of Operations
We model the normalization of a time expression as a sequence of operations deﬁned on time ﬁelds, which can construct a temporal value of speciﬁc type. The normalization rule is deﬁned as a triplet consists of a surface form pattern, a type of temporal value, and an operation sequence. The following subsections introduce the above concepts.
3.1 Time Fields
The time ﬁelds can be simply treated as time units with lower and upper bound constraints on values. Each temporal value can be denoted by a series of non-overlapping ﬁelds. For example, ISO:8601 represents a date value in the format “yyyy-MMDD”, where “MM” represents the “month” ﬁeld with lower bound 1 and upper bound 12.2
3.2 Type of Temporal Values
According to TimeML, we classify the temporal value into 3 types according to their formats. 1) Instant for representing date and time (e.g., “2021-0517T12:00”), 2) Duration for denoting the amount of intervening time in a time interval (e.g, “P2M” represents 2 months.), and 3) Approximate reference for representing approximate referring value (e.g, “PAST_REF”).
3.3 Operations
ARTime takes the function of time expression as changing a base temporal value to a target value. The semantic of a time expression is represented by a sequence of operations deﬁned the temporal ﬁelds. We design ten types of operations for ARTime (as listed in Table 1. The operations take 5 kinds of parameters: 1) integer values v, 2) time units u, 3) temporal ﬁelds f , 4) enumerable temporal constant e, and 5) approximate reference r (i.e., Past, Present and Future). Most of the operations are designed for temporal values of instant
2In real applications, the upper bound of a time ﬁeld can denoted by a larger explicit or default time unit. For example, the ﬁeld with the name “month” can be represented as “monthOfYear” or (month, year).

type, while ApproxRef and Add are designed for approximate reference values and duration values respectively. Speciﬁcally, we use a MakeSet operation to represent the TIMEX3 type “SET”.
In the execution of operations, we require the operations be arranged in order. Operations on larger ﬁelds should be executed ﬁrst. Operations on the same ﬁelds will be arranged according to their type. The operations independent to the base (e.g, ModifyVal) should be executed ﬁrst. The reason to use descending order of granularity is that the order corresponds to the way humans understand time ﬁelds. For example, the token “day” denotes “dayOfYear” in “the ﬁrst day in 2021” and “dayOfWeek” in “the ﬁrst day in this week”. Its meaning depends on the larger ﬁelds mentioned in the context. Arrange operations according to their type is to prevent redundant sequences. Example 2 explained why executing some operations later may overriding the execution results of previous operations.
Example 2. Considering the base value “202101”, we have
ToNext[Month] (“2021-01”)
=“2021-02”,
ModifyEnum[May] (“2021-02”)
=ModifyEnum[May] (“2021-01”)
=“2021-05”
, which indicates that executing the subsequent ModifyEnum[May] might make ToNext[Month] a redundant operation.
3.4 The Surface Form Pattern of Rule
In our design, each rule has a surface form pattern to determine whether it can be applied to an input expression. The pattern in our approach is similar to the sequential pattern in PTime (Ding et al., 2019), which is deﬁned as a sequence consisting of token types and untyped tokens. A token type consists of multiple values, and each value has a corresponding regex to capture its various surface forms. We only use 6 token types listed in Table 2 for obtaining variable values. The 6 types including 4 kinds of enumerable temporal constants (i.e, the ﬁrst 4 rows in the table), time units, and inequality modiﬁers (denoted as “IN_EQ”) collected from HeidelTime.
In our method, only the tokens referring to temporal values that appear in the operation sequences

Table 1: The temporal operations used in ARTime.

Action ModifyVal[v, f ] ModifyEnum[e] CountEnum[v, e, f ] Equal[f ] ToBegin/End[f ] For/Backward[v, u] ToNext/Last[u] MakeSet[f ] Add[v, u] ApproxRef[r]

Description
Modify the value in f to v. (e.g, ModifyVal[5,Day,Week](“2021-05-17”)=“2021-05-21”) Use the enumerable constant e to modify the corresponding ﬁeld. (e.g, ModifyVal[Summer](“2021-05-17”)=“2021-SU”) Find the v-th e in ﬁeld f . (e.g, CountEnum[1,Friday,Month](“2021-05-17”)=“2021-05-07”) Let the target value equals to the base on ﬁeld f . (e.g, Equal[1,Friday,Month](“2021-05-17”)=“2021-05”) Modify the value in f to its begin/end point. (e.g, ToBegin[Month,Quarter](“2021-05”)=“2021-04”) Increase/decrease current value by v u. (e.g, Backward[2, Month](“2021-05”)=“2021-03”) Increase/decrease current value by one u. (e.g, ToNext[Month](“2021-05”)=“2021-06”) Denote that the current value are sets of f . (e.g, MakeSet[Week](“2021”)=“2021-WXX”) Add v u to the current value, only works for duration values. (e.g, Add[2, Month](“P1Y”)=“P1Y2M”) Mean the value is the approximate reference r. (e.g, ApproxRef[Past](“2021-05”)=“PAST_REF”)

Table 2: The token types.

Type
MONTH WEEK SEASON DAY_TIME TIME_UNIT IN_EQ

Contents
January, Jan., Feb., etc. Sunday, Sun., etc, Spring, Summer, etc. moring, afternoon, etc. year, month, etc. a mere, no more than, etc.

will be generalized to the corresponding type. For example, the token “day” in rule (Pattern=“several day later”, Type=ApproximateReference, Operations=(ApproxRef[FUTURE_REF]) is not generalized to corresponding type “TIME_UNIT” since the operations do not require a unit variable.
4 Framework of ARTime
Figure 1 illustrates the normalization process of ARTime. The pre-processing step is adopted from the corresponding components in PTime. The rest normalization procedures can be divided into two parts, 1) generating rules (i.e., the left part of Figure 1) and 2) applying the generated rules (i.e. the right part of Figure 1). Since the TimeML standard does

Training Docs

Test Docs

Pre-Processing

Capture Possible Operations

Find a Rule
Unmatched

Matched

Construct Candidate Rules

Search a Rule Composition

Generated Rules

Rank & Filter Candidate Rules

Annotations

Figure 1: The framework of ARTime.

not annotate the base value of each time expression, we simply use the document creation time as a substitute in capturing the possible operation sequences. The following sub-sections describe the key techniques in ARTime. Section 4.1 details how to capture possible operation sequences. Section 4.2 describes how to generate rules from the noisy results. Section 4.3 describes how to use the generated rules to normalize input time expressions.

4.1 Capturing Possible Operations
By regarding temporal values as vertices and operations as directed edges connecting the base values to the normalized values, the task of reasoning possible operation sequence can be formalized as searching paths on the graph of temporal values, where each path corresponds to a sequence of operations (as demonstrated in Figure 2). The main challenge is that there could be a great quantity of paths between two values, and not all of them correspond to meaningful expression in daily communications (e.g., the sequence (ToEnd[Quarter,Year],ToBegin[Month,Quarter]) is legal in semantic but unnatural).

2021-05-17

ModifyVal[2020, Year]

ToLast[Year]

2020(-05-17) ToEnd[Quarter, Year]
2020-Q4 ToBegin[Month, Quarter]

Algorithm 1 The DFS algorithm for changing Vc to Vt, where pool is the pool of usable numeric values for acceleration.
1: function DFS(Vc, Vt, f , pool) 2: if f = 1/∞ then 1/∞ is a virtual ﬁeld for

the termination condition

3:

return Vc = Vt

4: S ← ∅

5: for f ∈ {f |1/∞ ≤ f < f } do

6:

∆ = Vt[f:f ] − Vc[f:f ]

7:

if ∆ = 0 then

8:

S+ = DFS(Vc, Vt, f , pool)

9:

for a ⊂ {operations on f } do

10:

if Vc.exec(a) − Vc = ∆ then

11:

continue

12:

if ¬(numVals(a) ⊆ vP ool) then

13:

continue

14:

pool ← pool − numVals(a)

15:

V ← Vc.exec(a)

16:

sol ← DFS(V , Vt, f , pool )

17:

if haveSolution then

18:

S = S ∪ (a + sol)

19: return S

ModifyEnum[October] Forward[5, Month]

2020-10
Figure 2: Some operation paths from “2021-05-17” to “2020-10”
Our method is based on the assumption that practical time expressions are low-redundancy sequences. i.e., we prefer direct sequences like (Equal[Day])(“today”) rather than the complex ones of the same meaning such as (ToLast[Week],Forward[37,Day])(“7 days after a week ago”).
We implement the process by a heuristic depthﬁrst search (DFS) algorithm described in Algorithm 1. The main idea is to guide the search process by the difference between the base value and the annotated value. In each iteration, we ensure that the current value Vc and the target value Vt are the same on ﬁelds of granularity not less than the iterated ﬁeld f . (line 1). We enumerate a smaller ﬁeld f (line 8) and check if there are some operations a on ﬁeld f corresponds the difference between Vc and Vt from f to f (line 13-14). In the enumeration of a (line 12), we only consider no-redundancy sequences of th e partial order introduced in section 3.3. Speciﬁcally, we accelerate the process by requiring all numeric values that appear in the search results must also appear in the input

time expression (line 15-16). Given the time expression T with anno-
tated value Va and the base time Vb, we obtain possible operation sequences by calling DFS(Vb, Va, ∞, numVals(T )), where ∞ is a virtual time unit as the initialization condition and numVals is the function for collecting appeared numeric values.
4.2 Constructing and Filtering Rules
All the captured operation sequences will be used for constructing candidate rules. We ﬁrstly ﬁnd the values appear in both the surface form and the operation sequence, then replace its appearance with corresponding token types and variable symbols to construct candidate rules. For example, given the expression “this month” and operation sequence Equal[Month], the replacement result will be “this TIME_UNIT:$1” and Equal[$1].
The generation produces many noises since there are more than one sequence from one time value to another. We distinguish good rules by a quite simple intuition that more general patterns and more correct rules should appears on more expressions. We rank the candidate rules by their frequency and the frequency of their patterns on training corpus,

then select the most frequent rules for normalization. We suppose that there is no need to drop the low frequency rules. The reason is that a low frequency rule either be replaced by more generalized rules (e.g., the second rule in Example 3), or do capture some meaningful token patterns that are difﬁcult to generalize (e.g., “as soon as possible”).
Example 3. Consider the expression “last month” and normalized value “2021-04” and suppose that there are two candidate rules, · (“last TIME_UNIT:$1” ⇒ ToLast[$1]), · (“last month”, ⇒ ModifyEnum[April]). The ﬁrst one is correct and can handle similar expressions (e.g., “last year”), while the second one only holds on the coincidence appearance of the base value “2021-05” .
4.3 Applying Rules For Normalization
Given an input expression, ARTime will try to ﬁnd a matchable rule to normalize it. If it can not match any generated rules, ARTime will attempt to search a consecutive composition of rules and stop words to cover it. The stop words include connecting symbols (e.g., “-”), determiners (e.g., “this”), prepositions (e.g., “to”) and so on.
The search process is performed by a segmentation algorithm (i.e., the dynamic programming algorithm described in Algorithm 2.) The algorithm tries to cover the input expression except for stop words in it (line 6-7) with minimum rules (line 11-13). For the case that there are multiple compositions of the same size, we simply choose the one that contains the most frequent rules. After that, we assume that all the operations in chosen rules are useful and merge them into a new sequence according to the order described in section 3.3.
5 Evaluation
5.1 Datasets
We use the TempEval-3 (UzZaman et al., 2013) benchmark and the Tweets benchmark proposed by Zhong et al. (2017).3 The statistics of the two benchmarks are illustrated in Table 3.
TempEval-3 (UzZaman et al., 2013) is a sub-task in SemEval 2013 consisting of English news articles. We follow the previous study (Lee et al.,
3Benchmarks with lots of event-related time expressions like Wikiwars (Mazur and Dale, 2010) and Tabassum et al. (2016)’s tweets dataset are not used in our evaluations. The reason is that understanding those expressions requires the external knowledge of the events, which is not our focus.

Algorithm 2 The segmentation algorithm for unmatched expressions.

1: function SEGMENT(T : expression, R: rules)

2: Initalize F ← to an array of empty sets.

3: F[0] ← {∅}

4: for i ← 1 to |T | do

5:

C ←∅

6:

if isStopword(T[i]) ∧ F[i−1] = ∅ then

7:

C ← C ∪ {F[i−1]}

8:

for j ← 0 to i − 1 do

9:

if F[j] = ∅ then

10:

continue

11:

if ∃r ∈ R. match(r, T[j+1:i]) then

12:

C ← C ∪ {F[j] ∪ {r}}

13:

if C = ∅ then

14:

F[i] = argminc∈C |c|

15: return F|T |

Table 3: The statistics of the datasets. The Doc., Token, and Exp. columns report the number of documents, tokens, and time expressions in the datasets respectively.

Dataset
TimeBank AQUAINT TempEval-3 Eval Tweets train Tweets test

Doc.
183 73 20 742 200

Token
61,418 33,973
6,375 15,571
4,198

Exp.
1,243 579 138 892 237

2014) to use corrected TimeBank (Pustejovsky et al., 2003) and AQUAINT as its training datasets.
Tweets (Zhong et al., 2017) is a new benchmark consisting of English tweets. The annotators tend to annotate years in a ﬁner granularity (e.g. the annotation “... in T value=2014-XX-XX 2014 /T ” means “a day in 2014”.) These annotations are legal according to TimeML, but do not conform to the intuition of expert designed rules in existing methods. Thus we provide the alter-version Tweets-M by annotating the year expressions as is.
5.2 Compared Methods
We compare ARTime with 4 normalization systems, HeidelTime (Strötgen et al., 2013), UWTime (Lee et al., 2014), SUTime (Chang and Manning, 2012) and CogCompN (Ning et al., 2018). HedidelTime is the SOTA purely-rule-based system. UWTime achieves the SOTA performances on TempEval-3.

Table 4: The accuracy(%) of normalization results on gold recognition annotations. The best results are in bold, and the second-best results are underlined.

Method
HeidelTime SUTime UWTime
CogCompN ARTime
ARTime+H

TempEval-3

Type Value

81.2

76.1

83.3

70.3

88.4

82.6

91.3

83.4

84.8

75.4

90.6

81.9

Tweets

Type Value

76.4

66.2

89.5

83.5

76.4

71.3

86.5

70.9

93.2

87.3

94.5

84.4

Tweets-M

Type Value

76.4

71.3

89.5

88.6

76.4

76.4

86.5

75.9

93.2

89.0

94.5

89.5

SUTime outperforms the other ones on social media texts according to Tabassum et al. (2016). CogCompN is the standalone normalizer of CogCompTime (Ning et al., 2018) which achieves SOTA results on TempEval-3.
We also evaluate the performance of compared normalization methods in real applications. We implement end-to-end systems with 3 SOTA recognition methods, SynTime (Zhong et al., 2017), TOMN (Zhong and Cambria, 2018), and PTime (Ding et al., 2019). We directly use the output of HeidelTime, SUTime, and UWTime for end-to-end comparison because that they use the same rules (or grammar) for recognition and normalization.
5.3 Evaluation Metrics
We use the scripts4 provided by TempEval-3 for evaluation. For the normalization results, we report the accuracy of normalized temporal results with gold mentions. For the end-to-end results, we report the F1 score of normalized types, and the precision (Pr), recall (Re), and F1 score of normalized temporal values.
5.4 Experimental Results
5.4.1 Normalization Results
Table 4 reports the normalization results on gold recognition annotations. ARTime surpasses other methods and shows better adaptability and robustness on Tweets (i.e., +3.8 points on the original Tweets). The performances of the compared methods dramatically vary on the different corpus. All compared methods except SUTime achieve very poor results on Tweets, while SUTime achieves the worst results on TempEval-3. ARTime’s performances are not very well on TempEval-3. The
4https://bitbucket.org/kentonl/uwtime/ src/master/evaluation_tools/

main reason is that the training data and the test data of TempEval-3 are annotated separately, and the insufﬁciency of training data severely hurts the performance of purely data-driven methods like ARTime according to previous study (Ding et al., 2019). For example, the test data of TempEval-3 includes 2 expressions about “ﬂu season” (It should be normalized as winter), our method cannot handle them since none of the training expressions contains the word “season”. Besides, the normalized values of some expressions rely on the tenses of corresponding utterances and need to be re-computed by post-modiﬁcation (Strötgen and Gertz, 2010; Lee et al., 2014). (e.g, “ﬁnished in June” denotes “June in last year” for base temporal values like “2021-05”). The above problems can be alleviated by introducing prior knowledge. We transform the expert rules in HeidelTime into ARTime’s formats as pre-deﬁned rules, name the combined approach as ARTime+H. ARTime+H achieves a good balance on different domains with the best results on Tweets-M and competitive results on TempEval3. (i.e, 1.5 points lower than the SOTA results on values.)
5.4.2 End-to-end Results
Table 5 reports the end-to-end results on TempEval3 and Tweets-M. ARTime with the SOTA recognition method (PTime) outperforms the existing methods with an improvement of +2.2 points on the F1 scores of normalized values on Tweets-M. The results of ARTime on TempEval-3 are not good enough, but can be easily improved by introducing the same prior knowledge used in HeidelTime. ARTime+H with SynTime achieve the second-best results on the F1 score on values without losing the advantages on Tweets (1.4 points higher than the best results achieved by compared methods).

Table 5: The end-to-end results(%) on TempEval-3 and Tweets. The best results are in bold, and the second-best results are underlined.

Method

TempEval-3

Type

Value

Tweets-M

Type

Value

Reco. Norm.

F1

Pr

Re

F1

F1

Pr

Re

F1

HeidelTime SUTime UWTime

83.3 80.2 76.1 78.1 84.4 88.0 71.3 78.8 81.9 67.8 70.3 69.0 87.8 85.4 88.6 87.0 85.7 85.9 79.7 82.7 83.6 93.7 74.7 83.1

CogCompN 88.5 80.0 81.2 80.6 86.5 77.0 74.7 75.8 SynTime ARTime 86.3 78.6 74.6 76.6 93.9 91.9 86.5 89.1
ARTime+H 90.1 82.2 80.4 81.3 94.4 90.3 86.5 88.4

CogCompN 89.3 82.0 79.0 80.4 86.1 75.7 73.4 74.5 TOMN ARTime 86.2 80.3 71.0 75.4 89.3 91.1 86.1 88.5
ARTime+H 88.7 82.8 76.8 79.7 93.3 89.5 86.1 87.7

CogCompN 85.5 82.4 78.3 80.3 88.0 76.7 76.4 76.5 PTime ARTime 83.0 75.8 72.5 74.1 94.7 89.7 88.6 89.2
ARTime+H 86.0 79.9 77.5 78.7 95.2 89.1 89.5 89.3

Table 6: The statistics(%) of negative samples in the normalization results

Table 7: The statistics of rules in the normalization results of ARTime+H.

Errors
Unseen Pattern Tense Error Bad Rule Annotation Error Others

TempEval-3
41.2 17.6 8.8 8.8 23.5

Tweets-M
50.0 11.5 19.2 3.8 15.4

5.4.3 Analysis
We categorize the negative samples in the normalization results of ARTime by their causes in Table 6. About half of the negative samples are due to unseen patterns that can not be captured by our rules. Another problem is the errors caused by tense in the context. Some existing systems apply post-modiﬁcation tricks by comparing the tense to the positivity of the difference between the output value and the base value. If our method can correctly utilize the oracle tense information, the accuracy on TempEval-3 can increase to 79.7% (+4.3 points). There are also some cases that the rules generated in our method do not ﬁt the input expressions (The 3rd row in Table 6).
We also manually analyzed the rules used in the test process to show what extent the introduction of expert rules replaces the automatic generation

Dataset
TempEval-3 Tweets-M

Auto
34 40

Full
36 42

Ratio(%)
91.9% 95.2%

in ARTime+H, the results are illustrated in Table 7. The “Full” column reports the number of rules used in normalizing the expressions, and the “Auto” and “Ratio” columns report how many of those rules can be covered by automatically generation. From the results we can know that the automatic generation can cover over 90 percent of the manual rules and adding about 2 rules are enough for ARTime.
5.4.4 Running Efﬁciency
All the results of ARTime are obtained by a singlethreaded Scala implementation on a personal workstation with an Intel Xeon CPU E5-1607 v4 @ 3.10GHz CPU and 128GB RAM. In average, ARTime generates ∼4.8 candidate rules for each expression. The ofﬂine training process took ∼16.3 minutes on TempEval-3 and ∼13.5 minutes on Tweets. The test process took ∼47 seconds on TempEval-3 and ∼46 seconds on Tweets.

6 Conclusion
In this paper, we mainly focus on automatically generating rules for time expression normalization. The main contributions of this paper are summarized as follows:
· We model time expression normalization as an operation sequence to construct the normalized temporal value, and ten basic operations are deﬁned for time expression normalization.
· We present a novel method, called ARTime, for generating normalization rules from training data without expert interventions. Speciﬁcally, ARTime captures possible operation sequences from annotated data and generates candidate rules on time expressions with common surface forms, and ﬁnally obtains normalization rules by ranking the candidate rules.
· Our experimental results show that ARTime outperforms SOTA methods on the Tweets benchmark, and achieves competitive results with existing expert-engineered rule methods on the Tempeval-3 benchmark. The end-to-end results when combining ARTime with time expression recognition systems are also very competitive.
There are still some rooms to improve ARTime. One of the future work is to generate more highquality rules. The other is to enable ARTime to use the tense and event information in context.
Acknowledgements
This work is supported by the National Science Foundation of China under grant No.61772264. We would like to thank our team members Guanji Gao and Yanjia Wang for their help in the early exploration stage of this work.
References
Gabor Angeli and Jakob Uszkoreit. 2013. Languageindependent discriminative parsing of temporal expressions. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 83–92, Soﬁa, Bulgaria. Association for Computational Linguistics.
Steven Bethard. 2013. ClearTK-TimeML: A minimalist approach to TempEval 2013. In Proceedings of the Seventh International Workshop on Semantic Evaluation, pages 10–14, Atlanta, Georgia, USA. Association for Computational Linguistics.
Steven Bethard and Jonathan Parker. 2016. A semantically compositional annotation scheme for time normalization. In Proceedings of the Tenth Interna-

tional Conference on Language Resources and Evaluation, pages 3779–3786.
Angel X. Chang and Christopher Manning. 2012. Sutime: A library for recognizing and normalizing time expressions. In Proceedings of the Eight International Conference on Language Resources and Evaluation, pages 3735–3740, Istanbul, Turkey. European Language Resources Association.
Wentao Ding, Guanji Gao, Linfeng Shi, and Yuzhong Qu. 2019. A pattern-based approach to recognizing time expressions. In The Thirty-Third AAAI Conference on Artiﬁcial Intelligence, pages 6335–6342, Honolulu, Hawaii, USA. AAAI Press.
Lisa Ferro, Laurie Gerber, Inderjeet Mani, Beth Sundheim, and George Wilson. 2005. Standard for the annotation of temporal expressions-tides. The MITRE Corporation, McLean-VG-USA.
Jerry R Hobbs, Douglas Appelt, John Bear, David Israel, Megumi Kameyama, Mark Stickel, and Mabry Tyson. 1997. Fastus: A cascaded ﬁnite-state transducer for extracting information from naturallanguage text. arXiv preprint cmp-lg/9705013.
Egoitz Laparra, Dongfang Xu, Ahmed Elsayed, Steven Bethard, and Martha Palmer. 2018. SemEval 2018 task 6: Parsing time normalizations. In Proceedings of The Twelfth International Workshop on Semantic Evaluation, pages 88–96, New Orleans, Louisiana. Association for Computational Linguistics.
Kenton Lee, Yoav Artzi, Jesse Dodge, and Luke Zettlemoyer. 2014. Context-dependent semantic parsing for time expressions. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1437– 1447, Baltimore, Maryland. Association for Computational Linguistics.
Pawel Mazur and Robert Dale. 2010. WikiWars: A new corpus for research on temporal expressions. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 913–922, Cambridge, MA. Association for Computational Linguistics.
Qiang Ning, Ben Zhou, Zhili Feng, Haoruo Peng, and Dan Roth. 2018. CogCompTime: A tool for understanding time in natural language. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 72–77, Brussels, Belgium. Association for Computational Linguistics.
James Pustejovsky, Patrick Hanks, Roser Sauri, Andrew See, Robert Gaizauskas, Andrea Setzer, Dragomir Radev, Beth Sundheim, David Day, Lisa Ferro, et al. 2003. The timebank corpus. In Corpus linguistics, volume 2003, page 40. Lancaster, UK.
James Pustejovsky, Kiyong Lee, Harry Bunt, and Laurent Romary. 2010. ISO-TimeML: An international standard for semantic annotation. In Proceedings of

the Seventh International Conference on Language Resources and Evaluation, pages 394–397, Valletta, Malta. European Language Resources Association.
Andrea Setzer and Robert Gaizauskas. 2000. Annotating events and temporal information in newswire texts. In Proceedings of the Second International Conference on Language Resources and Evaluation, Athens, Greece. European Language Resources Association.
Jannik Strötgen, Thomas Bögel, Julian Zell, Ayser Armiti, Tran Van Canh, and Michael Gertz. 2014. Extending HeidelTime for temporal expressions referring to historic dates. In Proceedings of the Ninth International Conference on Language Resources and Evaluation, pages 2390–2397, Reykjavik, Iceland. European Language Resources Association.
Jannik Strötgen and Michael Gertz. 2010. HeidelTime: High quality rule-based extraction and normalization of temporal expressions. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 321–324, Uppsala, Sweden. Association for Computational Linguistics.
Jannik Strötgen, Julian Zell, and Michael Gertz. 2013. HeidelTime: Tuning English and developing Spanish resources for TempEval-3. In Proceedings of the Seventh International Workshop on Semantic Evaluation, pages 15–19, Atlanta, Georgia, USA. Association for Computational Linguistics.
Jeniya Tabassum, Alan Ritter, and Wei Xu. 2016. TweeTime : A minimally supervised method for recognizing and normalizing time expressions in Twitter. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 307–318, Austin, Texas. Association for Computational Linguistics.
Hegler Tissot, Angus Roberts, Leon Derczynski, Genevieve Gorrell, and Marcus Didonet Del Fabro. 2015. Analysis of temporal expressions annotated in clinical notes. In Proceedings of the 11th Joint ACLISO Workshop on Interoperable Semantic Annotation, London, UK. Association for Computational Linguistics.
Naushad UzZaman, Hector Llorens, Leon Derczynski, James Allen, Marc Verhagen, and James Pustejovsky. 2013. SemEval-2013 task 1: TempEval-3: Evaluating time expressions, events, and temporal relations. In Proceedings of the Seventh International Workshop on Semantic Evaluation, pages 1– 9, Atlanta, Georgia, USA. Association for Computational Linguistics.
Marc Verhagen, Inderjeet Mani, Roser Sauri, Jessica Littman, Robert Knippen, Seok B. Jang, Anna Rumshisky, John Phillips, and James Pustejovsky. 2005. Automating temporal annotation with TARSQI. In Proceedings of the ACL Interactive Poster and Demonstration Sessions, pages 81–84, Ann Arbor, Michigan. Association for Computational Linguistics.

Ran Zhao, Quang Do, and Dan Roth. 2012. A robust shallow temporal reasoning system. In Proceedings of the Demonstration Session at the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 29–32, Montréal, Canada. Association for Computational Linguistics.
Xiaoshi Zhong and Erik Cambria. 2018. Time expression recognition using a constituent-based tagging scheme. In Proceedings of the 2018 World Wide Web Conference, page 983–992, Republic and Canton of Geneva, CHE. International World Wide Web Conferences Steering Committee.
Xiaoshi Zhong, Aixin Sun, and Erik Cambria. 2017. Time expression analysis and recognition using syntactic token types and general heuristic rules. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 420–429, Vancouver, Canada. Association for Computational Linguistics.

