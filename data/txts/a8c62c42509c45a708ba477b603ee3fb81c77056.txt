False News Detection on Social Media

arXiv:1908.10818v1 [cs.MM] 28 Aug 2019

Juan Cao1,2, Qiang Sheng1,2, Peng Qi1,2, Lei Zhong1,2, Yanyan Wang1,2 and Xueyao Zhang1,2
1Key Laboratory of Intelligent Information Processing & Center for Advanced Computing Research,
Institute of Computing Technology, CAS, Beijing, China 2University of Chinese Academy of Sciences, Beijing, China
{caojuan,shengqiang,qipeng,zhonglei,wangyanyan,zhangxueyao}@ict.ac.cn

ABSTRACT
Social media has become an important information platform where people consume and share news. However, it has also enabled the wide dissemination of false news, i.e., news posts published on social media that are veriﬁably false, causing signiﬁcant negative eﬀects on society. To help prevent further propagation of false news on social media, we set up this competition to motivate the development of automated real-time false news detection approaches. Speciﬁcally, this competition includes three subtasks: false-news text detection, false-news image detection, and falsenews multi-modal detection, which aims to motivate participants to further explore the eﬃciency of multiple modalities in detecting false news and eﬀective fusion approaches of multi-modal contents. To be er support this competition, we also construct and release a multi-modal data repository about False News on Weibo Social platform(MCG-FNeWS) to help evaluate the performance of diﬀerent approaches from participants.
1 INTRODUCTION
Social media, such as Twi er1 or Chinese Sina Weibo2, has become an important information platform where people acquire the latest news and express their opinions freely [1], [2]. However, the convenience and openness of social media have also promoted the proliferation of false news, i.e., news posts published on social media that are veriﬁably false, which not only disturbed the cyberspace order but also caused many detrimental eﬀects on realworld events. For example, in India, dozens of innocent people were beaten to death by locals because of the false news about child traﬃcking that was widely spread on social media [3]. us, false news detection is a critical issue that needs to be addressed.
Some existing researches utilize the information generated in the news proliferation process, such as reviews, retweets and other relevant posts, to help detect false news [4], [5], [6], [7], but these contents can become available only a er the news has been propagated on social networks for a while. However, according to statistics, false news spreads very quickly on social media, even six times faster than real news [8]. is further indicates that false news may have already been widely spread and caused many negative eﬀects when enough relevant posts are generated. erefore, to help prevent further propagation of false news on social media, we set up this competition to motivate the development of automated real-time false news detection approaches.
To eﬀectively detect the false news from the news feed on social media in real time, the information we are looking at will mostly be the raw news content, which mainly includes text, images or
1h ps://twi er.com/ 2h ps://weibo.com/

videos, and publisher proﬁle. Traditional false news detection researches based on news content usually focus on the textual content [9], [4], [10], from where they exploit some linguistic features to capture the diﬀerences of writing styles between false and real news. With the evolution of self-media news from text-based posts to multimedia posts with images or videos, false news usually utilize misrepresented or even tampered images to a ract and mislead readers for rapid dissemination, which leads researchers to pay more a ention to the visual content of false news [11], [12]. Considering that multiple modalities could provide cues for distinguishing false news, some works propose novel models to fuse features from diﬀerent modalities to solve the challenging false news detection problem [13], [14], [15]. For this reason, we set up this competition to encourage participants to fully utilize the raw news content for false news detection, which consists of three subtasks: (a) false-news text detection, (b) false-news image detection, and (c) false-news multi-modal detection. Existing datasets about false news detection usually lack corresponding visual content [16], [4], [17], and the scale of multi-modal datasets in this ﬁeld are limited [18], [19], [13]. erefore, to be er support this competition, we construct and publicize a multi-modal data repository about False News on Weibo Social platform(MCG-FNeWS), which is the largest multi-modal false news detection dataset, to help evaluate the performance of diﬀerent approaches from participants. Besides, external knowledge is also helpful for determining the truthfulness of a particular claim in a real-time [20]. us, we also provide some resources which contain a large number of refutations about existing false news. We encourage participants to utilize the given external knowledge to help detect false news.
2 TASK OVERVIEW
e problem addressed in this competition is how to utilize the raw news content, mainly including the textual and visual content and publisher proﬁle, to verify whether the given post is false or real in real-time. It has been proved that textual and visual content play important roles in detecting false news, thus we establish subtask A and subtask B to explore the eﬃciency of textual and visual modalities in detecting false news, respectively. Diﬀerent modalities can not only mutually support but also be supplementary [21], but how to eﬀectively process and relate information from diﬀerent modalities is still a challenging problem. Subtask C aims to eﬀectively fuse the information of diﬀerent modalities to detect false news. In all the above subtasks, we encourage participants to fully utilize the external knowledge that we have given to help detect false news.

2.1 Subtask A - False-news text detection
Text is a major component of a news event, which is widely utilized by existing researches to verify the given news post is real or false. Many linguistic-based features have been widely studied to help to detect false news, but the underlying characteristics of false news have not been fully understood. erefore, the aim of subtask A is to further explore the eﬃciency of text content in detecting false news. Success on this subtask will support the success of subtask C by providing eﬀective features. e deﬁnition of subtask A is the following: ”Given a set of news posts X = {x1, x2, . . . , xm } and labels Y = { 1, 2, . . . , m }, the subtask requires participants to learn a classiﬁer f that can utilize the corresponding text to classify whether a given post is false news ( t = 1) or real news ( t = 0) , i.e., ˆt = f (xt ). ” Accordingly, we deﬁne false-news text as text in false news, and real-news text as text in real news. In practice, participants receive a list of text and are required to automatically predict, for each text, whether it is a false-news text or a real-news text.
2.2 Subtask B - False-news image detection
Visual cues have been shown to be an important manipulator for false news detection[22], [23]. However, very limited research has been done to exploit eﬀective visual features, including traditional local and global features [24] and newly emerging deep network-based features [12], for the false news detection problem. Subtask B encourages the participants to put more a ention on the visual content (images) to detect false news. Similarly, success of this subtask also promotes the success of subtask C. e definition of subtask B is the following: Given a set of news posts X = {x1, x2, . . . , xm }, corresponding images I = {i1, i2, . . . , im }, and labels Y = { 1, 2, . . . , m }, learn a classiﬁer f that can utilize the corresponding image to classify whether a given post is false news ( t = 1) or real news ( t = 0) , i.e., ˆt = f (it ). Accordingly, we deﬁne false-news image as a ached image in false news, and real-news image as a ached image in real news. In practice, participants receive a list of images and are required to automatically predict, for each image, whether it is a false-news image or a real-news image. Note that this subtask is diﬀerent from tampered image detection because the tampered image is only a typical category of false-news image [12].
2.3 Subtask C - False-news multi-modal detection
is subtask aims at utilizing information from diﬀerent modalities to eﬀectively detect false news. Although there are already some studies focusing on fusing multi-modal information for false news detection, it is still a challenging problem which needs further investigation. For example, we can use the semantic alignment between image and text to explore the role of diﬀerent modalities in false news detection, or utilize the technique of co-learning to tackle the problem of missing data. e deﬁnition of subtask C is the following: Given a set of news posts X = {x1, x2, . . . , xm }, corresponding images I = {i1, i2, . . . , im }, publisher proﬁle U = {u1, u2, . . . , um }, and labels Y = { 1, 2, . . . , m }, learn a classiﬁer f that can utilize the corresponding text, image and publisher proﬁle to classify whether a given post is false news ( t = 1) or

real news ( t = 0) , i.e., ˆt = f (xt , it , ut ). Moreover, we refer to existing category lists from well-known debunking websites and ﬁnally summarize the following nine overarching topics: Society & Life, Disasters & Accidents, Health & Medicine, Education & Examinations, Science & Technology, Finance & Business, Culture & Sports & Entertainment, Politics and Military. For each post in the dataset, we also provide a topic tag which is manually labeled by its key objects of interest. In practice, participants receive a list of posts which include a text component, an associated images list, a user proﬁle, and a topic tag, and are required to automatically predict, for each post, whether it is a false-news post or a real-news post.
In all cases, the competition asks participants to optionally return an explanation (which can be a text string, or indexes pointing to the given knowledge) that supports the veriﬁcation decision.
e explanation is not used for quantitative evaluation, but rather for gaining qualitative insights into the results.
3 DATA & RESOURCES
Training dataset: is is provided with ground truth and is used by participants to develop their approaches. It contains 38,471 news posts with 34,096 corresponding images, comprising 19,285 false-news posts with corresponding 13,635 false-news images, and 19,186 real-news posts with corresponding 20,461 real-news images. Validation dataset: is is provided with ground truth and is used by participants to evaluate their approaches. It contains 4,000 news posts with 3,837 corresponding images, comprising 2,000 falsenews posts with corresponding 1,760 false-news images, and 2,000 real-news posts with corresponding 2,077 real-news images. Testing dataset: is is provided without ground truth and is used by organizers to compare the performance of participants’ approaches. It contains 3,902 news posts with 3,957 corresponding images.
In all datasets, the text of false news and real news are used to develop subtask A, images are used to develop subtask B, and all given data are for subtask C.
e data for all datasets are publicly available3. e false-news posts are crawled from May 2012 to November 2018 and veriﬁed by the oﬃcial Weibo Community Management Center4, which usually serves as a reputable source to collect false-news posts on Weibo platform in literature [4], [13], [25], [26]. e real-news posts are collected during the same period as false news from Weibo. To explore the underlying characteristics of false-news posts in addition to superﬁcial linguistics features, we crawl some real-news posts which have the similar linguistic style with false-news posts as negative samples. Speciﬁcally, following the method in [27], we discover false-news linguistics pa erns like ”is it real/false?” in false-news posts via text mining, and then crawl a large set of matched posts from the live stream of Weibo. For each post, we extract the keywords as the seed to crawl corresponding posts. A er removing the duplicated posts, we obtain a candidate set of realnews posts, which are further manually veriﬁed by cross-checking
3h ps://www.biendata.com/competition/falsenews/data/ 4h ps://service.account.weibo.com/

online sources(articles and blogs), producing a real-news set. Finally, we sample the real-news posts to keep the balance of falsenews and real-news posts. To alleviate the impact of events [14], we select real-news posts that belong to the same or similar events with false-news posts. In the preprocessing stage, we manually remove some meaningless statistical clues from the text.
We also provide a debunking repository which contains 37,877 refutations about existing false news. We crawl these refutations from multiple reputable debunking Weibo accounts and web articles. ese refutations are crawled from September 2012 to August 2019. We encourage participants to utilize these refutations to help the detection of false news, but we do not promise that all false news in the competition dataset has corresponding refutations in this debunking repository.

Table 1: Baselines for ree Subtasks

Method
LSTM GRU TextCNN Bert
Pre-trained VGG19 Fine-tuned VGG19 MVNN
Early Fusion Late Fusion a RNN

Accuracy
0.864 0.857 0.851 0.867
0.728 0.759 0.805
0.876 0.846 0.852

Precision
0.891 0.911 0.953 0.916
0.729 0.791 0.804
0.916 0.935 0.871

Recall
0.829 0.784 0.732 0.799
0.622 0.607 0.743
0.837 0.757 0.820

F1
0.859 0.843 0.828 0.854
0.671 0.687 0.772
0.875 0.836 0.845

4 EVALUATION
Overall, all the above subtasks are interested in the accuracy with which an automatic method can distinguish between false news and real news. Hence, given the testing set of labeled instances and a set of predicted labels (included in the submi ed runs) for these instances, the classic measures (i.e., Precision P, Recall R, and F1score) are used to quantify the classiﬁcation performance, where the target class is the class of false news. Since the two classes (false news/real news) are represented in a relatively balanced way in the testing set, these measures are good proxies of the classiﬁer accuracy.
5 BASELINES
In this section, we provide some baselines of the three subtasks for reference, which are shown in Table 1. For each subtask, we deploy some basic and state-of-the-art baselines on given datasets. Note that we doesn’t focus on searching the best hyper-parameters of these model, thus the given baselines are not the best results of corresponding models.
• Subtask A: For subtask A, we introduce four basic models including LSTM [28], GRU [29], TextCNN [30] and Bert [31], which are widely used in many NLP applications. In detail, we adopt the implementation of Bert in [32]. According to Table 1, Bert is slightly be er than other models in accuracy.
• Subtask B: VGG[33] is widely used as a feature extractor in existing studies about multi-modal fake news detection[13], [14], [15], thus we implement pre-trained and ﬁne-tuned VGG19 as baselines of subtask B. Also, we implement the state-of-the-art method utilizing visual content to detect false news MVNN [12], which is much be er than other baselines in subtask B.
• Subtask C: For subtask C, we introduce three baselines including early and late fusion and a RNN[13] to fuse the information of text, image and user modality. Speciﬁcally, we use TextCNN and pre-trained VGG19 to extract the abstract representations of text and image respectively. Early fusion integrates features from diﬀerent modalities by simply concatenating their representations, while late fusion performs integration a er each of the modalities

has made a classiﬁcation decision. More intuitively, attRNN proposes a neuron-level a ention mechanism to fuse multi-modal content. According to Table 1, early fusion outperforms other baselines for Subtask C.

6 CONCLUSION
With the popularity of multi-modal content in social media, incorporating the information of diﬀerent modalities to detect false news is a critical task in the current media landscape. is competition about false news detection set up three subtasks to encourage participants to fully explore the eﬃciency of diﬀerent modalities and eﬀective fusion methods. is competition also leaves behind a benchmark dataset of ten thousands of false news and real news, which will help beginners of this research domain to quickly get started and evaluate their systems.

7 ACKNOWLEDGMENTS
is work was supported by the National Natural Science Foundation of China(U1703261).

REFERENCES

[1] Timothy I Murphy. News use across social media platforms 2018.

https://www.journalism.org/2018/09/10/news- use- across- social- media- platf orms- 2018/.

Accessed September 10, 2018.

[2] A research report about china internet news market 2016.

http://www.cnnic.cn/hlwfzyj/hlwxzbg/mtbg/201701/t20170111 66401.htm.

Accessed January 11, 2017.

[3] Annie Gowen.

As mob lynchings fueled by whatsapp mes-

sages sweep india, authorities struggle to combat fake news.

https://www.washingtonpost.com/world/asia pacific/as-mob-lynchings-fueled-by-whatsapp-swe

Accessed July 2, 2018.

[4] Jing Ma, Wei Gao, Prasenjit Mitra, Sejeong Kwon, Bernard J Jansen, Kam-Fai

Wong, and Meeyoung Cha. Detecting rumors from microblogs with recurrent

neural networks. In IJCAI, pages 3818–3824, 2016.

[5] Han Guo, Juan Cao, Yazi Zhang, Junbo Guo, and Jintao Li. Rumor detection

with hierarchical social a ention network. In Proceedings of the 27th ACM Inter-

national Conference on Information and Knowledge Management, pages 943–951.

ACM, 2018.

[6] Kai Shu, Limeng Cui, Suhang Wang, Dongwon Lee, and Huan Liu. defend: Ex-

plainable fake news detection. 2019.

[7] Chuan Guo, Juan Cao, Xueyao Zhang, Kai Shu, and Miao Yu. Exploiting emo-

tions for fake news detection on social media, 2019.

[8] Soroush Vosoughi, Deb Roy, and Sinan Aral. e spread of true and false news

online. Science, 359(6380):1146–1151, 2018.

[9] Carlos Castillo, Marcelo Mendoza, and Barbara Poblete. Information credibility

on twi er. In Proceedings of the 20th international conference on World wide web,

pages 675–684. ACM, 2011.

[10] Jing Ma, Wei Gao, and Kam-Fai Wong. Detect rumors on twi er by promoting information campaigns with generative adversarial learning. 2019.
[11] Zhiwei Jin, Juan Cao, Yongdong Zhang, Jianshe Zhou, and Qi Tian. Novel visual and statistical image features for microblogs news veriﬁcation. IEEE transactions on multimedia, 19(3):598–608, 2017.
[12] Peng Qi, Juan Cao, Tianyun Yang, Junbo Guo, and Jintao Li. Exploiting multidomain visual information for fake news detection. In 19th IEEE International Conference on Data Mining. IEEE, 2019.
[13] Zhiwei Jin, Juan Cao, Han Guo, Yongdong Zhang, and Jiebo Luo. Multimodal fusion with recurrent neural networks for rumor detection on microblogs. In Proceedings of the 2017 ACM on Multimedia Conference, pages 795–816. ACM, 2017.
[14] Yaqing Wang, Fenglong Ma, Zhiwei Jin, Ye Yuan, Guangxu Xun, Kishlay Jha, Lu Su, and Jing Gao. Eann: Event adversarial neural networks for multi-modal fake news detection. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 849–857. ACM, 2018.
[15] Kha ar Dhruv, Goud Jaipal Singh, Gupta Manish, and Varma Vasudeva. Mvae: Multimodal variational autoencoder for fake news detection. In Proceedings of the 2019 World Wide Web Conference. ACM, 2019.
[16] Xiaomo Liu, Armineh Nourbakhsh, anzhi Li, Rui Fang, and Sameena Shah. Real-time rumor debunking on twi er. In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, pages 1867– 1870. ACM, 2015.
[17] Kai Shu, Deepak Mahudeswaran, Suhang Wang, Dongwon Lee, and Huan Liu. Fakenewsnet: A data repository with news content, social context and dynamic information for studying fake news on social media. arXiv preprint arXiv:1809.01286, 2018.
[18] Christina Boididou, Katerina Andreadou, Symeon Papadopoulos, Duc-Tien Dang-Nguyen, Giulia Boato, Michael Riegler, Yiannis Kompatsiaris, et al. Verifying multimedia use at mediaeval 2015. In MediaEval, 2015.
[19] Christina Boididou, Symeon Papadopoulos, Duc-Tien Dang-Nguyen, Giulia Boato, Michael Riegler, Stuart E. Middleton, Andreas Petlund, Yiannis Kompatsiaris, et al. Verifying multimedia use at mediaeval 2016. In MediaEval, 2016.
[20] Shu Kai, Suhang Wang, Amy Sliva, Jiliang Tang, and Huan Liu. Fake news detection on social media: A data mining perspective. Acm Sigkdd Explorations Newsle er, 19(1), 2017.
[21] Tadas Baltrusˇaitis, Chaitanya Ahuja, and Louis-Philippe Morency. Multimodal machine learning: A survey and taxonomy. IEEE Transactions on Pa ern Analysis and Machine Intelligence, 41(2):423–443, 2018.
[22] Aditi Gupta, Hemank Lamba, Ponnurangam Kumaraguru, and Anupam Joshi. Faking sandy: characterizing and identifying fake images on twi er during hurricane sandy. In Proceedings of the 22nd international conference on World Wide Web, pages 729–736. ACM, 2013.
[23] Pe er Bae Brandtzaeg, Marika Lu¨ders, Jochen Spangenberg, Linda RathWiggins, and Asbjørn Følstad. Emerging journalistic veriﬁcation practices concerning social media. Journalism Practice, 10(3):323–342, 2016.
[24] Dong ping Tian et al. A review on image feature extraction and representation techniques. International Journal of Multimedia and Ubiquitous Engineering, 8(4):385–396, 2013.
[25] Yahui Liu, Xiaolong Jin, Huawei Shen, and Xueqi Cheng. Do rumors diﬀuse diﬀerently from non-rumors? a systematically empirical analysis in sina weibo for rumor identiﬁcation. In Paciﬁc-Asia Conference on Knowledge Discovery and Data Mining, pages 407–420. Springer, 2017.
[26] Zilong Zhao, Jichang Zhao, Yukie Sano, Orr Levy, Hideki Takayasu, Misako Takayasu, Daqing Li, and Shlomo Havlin. Fake news propagate diﬀerently from real news even at early stages of spreading. arXiv preprint arXiv:1803.03443, 2018.
[27] Zhiwei Jin, Juan Cao, Jiebo Luo, and Yongdong Zhang. Image credibility analysis with eﬀective domain transferred deep networks. arXiv preprint arXiv:1611.05328, 2016.
[28] Sepp Hochreiter and Ju¨rgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735–1780, 1997.
[29] Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555, 2014.
[30] Yoon Kim. Convolutional neural networks for sentence classiﬁcation. arXiv preprint arXiv:1408.5882, 2014.
[31] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pretraining of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.
[32] Implementation of bert that could load oﬃcial pre-trained models for feature extraction and prediction. https://github.com/CyberZHG/keras-bert.
[33] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.

