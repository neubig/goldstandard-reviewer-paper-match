Fast and Efﬁcient MMD-based Fair PCA via Optimization over Stiefel Manifold
Junghyun Lee,1 Gwangsu Kim*,2 Matt Olfat,3,4 Mark Hasegawa-Johnson,5 Chang D. Yoo*2
1 Kim Jaechul Graduate School of AI, KAIST, Seoul, Republic of Korea 2 School of Electrical Engineering, KAIST, Daejeon, Republic of Korea
3 UC Berkeley IEOR, Berkely, CA, USA 4 Citadel, Chicago, IL, USA
5 Department of Electrical and Computer Engineering, University of Illinois Urbana-Champaign, IL, USA {jh lee00, s88012, cd yoo}@kaist.ac.kr, molfat@berkeley.edu, jhasegaw@illinois.edu

Abstract
This paper deﬁnes fair principal component analysis (PCA) as minimizing the maximum mean discrepancy (MMD) between dimensionality-reduced conditional distributions of different protected classes. The incorporation of MMD naturally leads to an exact and tractable mathematical formulation of fairness with good statistical properties. We formulate the problem of fair PCA subject to MMD constraints as a non-convex optimization over the Stiefel manifold and solve it using the Riemannian Exact Penalty Method with Smoothing (REPMS; Liu and Boumal, 2019). Importantly, we provide local optimality guarantees and explicitly show the theoretical effect of each hyperparameter in practical settings, extending previous results. Experimental comparisons based on synthetic and UCI datasets show that our approach outperforms prior work in explained variance, fairness, and runtime.
1 Introduction
It has become increasingly evident that many widelydeployed machine learning algorithms are biased, yielding outcomes that can be discriminatory across key groupings such as race, gender and ethnicity (Mehrabi et al. 2019). As the applications of these algorithms proliferate in protected areas like healthcare (Karan et al. 2012), hiring (Chien and Chen 2008) and criminal justice (Kirchner et al. 2016), this creates the potential for further exacerbating social biases. To address this, there has recently been a surge of interest in ensuring fairness in resulting machine learning algorithms.
Working in high-dimensional spaces can be undesirable as the curse of dimensionality manifests in the form of data sparsity and computational intractability. Various dimensionality reduction algorithms are deployed to resolve these issues, and Principal Component Analysis (PCA) (Pearson 1901; Hotelling 1933), is one of the most popular methods (Jolliffe and Cadima 2016). One particular advantage of PCA is that there’s no need to train a complex neural network.
In this work, fair PCA is deﬁned as performing dimensionality reduction while minimizing the difference in the conditional distributions of projections of different protected groups. Here, the projected data can be considered as a dimension-reduced fair representation of the input data
Copyright © 2022, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved. *Corresponding authors

(Zemel et al. 2013). We answer the questions of 1) how fairness should be deﬁned for PCA and 2) how to (algorithmically) incorporate fairness into PCA in a fast and efﬁcient manner. This work takes a different approach from prior studies on PCA fairness (Samadi et al. 2018; Olfat and Aswani 2019), which is discussed in Section 3 and 7.
Our main contributions are as follows:
• We motivate a new mathematical deﬁnition of fairness for PCA using the maximum-mean discrepancy (MMD), which can be evaluated in a computationally efﬁcient manner from the samples while guaranteeing asymptotic consistency. Such properties were not available in the previous deﬁnition of fair PCA (Olfat and Aswani 2019). This is discussed in detail in Section 3 and 4.
• We formulate the task of performing MMD-based fair PCA as a constrained optimization over the Stiefel manifold and propose using REPMS (Liu and Boumal 2019). For the ﬁrst time, we prove two general theoretical guarantees of REPMS regarding the local minimality and feasibility. This is discussed in detail in Section 5 and 6.
• Using synthetic and UCI datasets, we verify the efﬁcacy of our approach in terms of explained variance, fairness, and runtime. Furthermore, we verify that using fair PCA does indeed result in a fair representation, as in (Zemel et al. 2013). This is discussed in detail in Section 8.
2 Preliminaries
2.1 Notations
For b ≥ 1, let Pb be the set of all Borel probability measures deﬁned on Rb. For some measurable function Π : Rp → Rd and a measure P ∈ Pp, the push-forward measure of P via Π is the probability measure Π#P ∈ Pd, deﬁned as (Π#P )(S) = P (Π−1(S)) for any Borel set S. Let 0 and 1 denote matrices (or vectors) of zeros and ones of appropriate size, respectively. In this work, we focus on binary cases, i.e., we assume that the protected attribute A and outcome Y are binary (A, Y ∈ {0, 1}). We abbreviate demographic parity, equalized opportunity, and equalized odds as DP, EOP, and EOD, respectively.
2.2 Maximum Mean Discrepancy (MMD) Let k : Rd × Rd → R be a positive-deﬁnite kernel function, and Hk be a unit-ball in the RKHS generated by k. We

(a) Original data

(b) PCA

(c) FPCA (Olfat and Aswani 2019)

(d) MBF-PCA (ours)

Figure 1: Synthetic data #1: Comparison of PCA, FPCA, and MBF-PCA on data composed of two groups with same mean and covariance, but different distributions. Blue and orange represent different protected groups.

impose some regularity assumptions on k:
Assumption 1. k is measurable, and bounded i.e. K := supx,y k(x, y) < ∞.
Then one can pseudo-metrize Pd by the following distance:

Deﬁnition 1 (Gretton et al., 2007). Given µ, ν ∈ Pd, their maximum mean discrepancy (MMD), denoted as
MMDk(µ, ν), is a pseudo-metric on Pd, deﬁned as follows:

MMDk(µ, ν) := sup

f d(µ − ν)

(1)

f ∈Hk Rd

As our fairness constraint involves exactly matching the
considered distributions using MMD, we require the property of MMDk(µ, ν) = 0 implying µ = ν. Any kernel k that satisﬁes such property is said to be characteristic (Fukumizu et al. 2008) to Pd. Furthermore, Sriperumbudur et al. (2008) deﬁned and characterized stationary characteristic kernels
and identiﬁed that well-known kernels such as RBF and Laplace are characteristic. Based on this fact, we set k to be the RBF kernel krbf (x, y) := exp − x − y 2/2σ2 .
For the choice of bandwidth σ, the median of the set of pairwise distances of the samples after vanilla PCA is considered following the median heuristic of (Scho¨lkopf, Smola, and Mu¨ller 1998; Ramdas et al. 2015). For simplicity, we refer to MMDkrbf as MMD.

Beneﬁts of MMD There are several reasons for using MMD as the distance on a space of probability measures. First, it can act as a distance between distributions with different, or even disjoint, supports. This is especially crucial as the empirical distributions are often discrete and completely disjoint. Such a property is not generally true, one prominent example being the KL-divergence. Second, since many problems in fairness involve comparing two distributions, MMD has already been used in much of the fairness literature as a metric (Madras et al. 2018; Adel et al. 2019) and as an explicit constraint/penalty (Quadrianto and Sharmanska 2017; Louizos et al. 2016; Prost et al. 2019; Oneto et al. 2020; Jung et al. 2021), among other usages.

2.3 Fairness for supervised learning
The fair PCA discussed above should ultimately lead to fairness in supervised learning tasks based on the dimension-

reduced data with minimal loss in performance. Let us now review three of the most widely-used deﬁnitions of fairness in supervised learning, as formulated in (Madras et al. 2018). Let (Z, Y, A) ∈ Rd × {0, 1} × {0, 1} be the joint distribution of the dimensionality-reduced data, (downstream task) label, and protected attribute. Furthermore, let g : Rd → {0, 1} be a classiﬁer that outputs prediction Yˆ for Y from Z. We want to determine the fairness of a well-performing classiﬁer g w.r.t. protected attribute A.
First, let Ds be the probability measure of Zs Z|A = s for s ∈ {0, 1}:
Deﬁnition 2 (Feldman et al., 2015). g is said to satisfy demographic parity (DP) up to ∆DP w.r.t. A with ∆DP |Ex∼D0 [g(x)] − Ex∼D1 [g(x)]|.
Now, let Ds,y be the probability measure of Zs Z|A = s, Y = y for s, y ∈ {0, 1}.
Deﬁnition 3 (Hardt, Price, and Srebro, 2016). g is said to satisfy equalized opportunity (EOP) up to ∆EOP w.r.t. A and Y with ∆EOP Ex∼D0,1 [g(x)] − Ex∼D1,1 [g(x)] .
Deﬁnition 4 (Hardt, Price, and Srebro, 2016). g is said to satisfy equalized odds (EOD) up to ∆EOD w.r.t. A and Y with ∆EOD maxy∈{0,1} Ex∼D0,y [g(x)] − Ex∼D1,y [g(x)] .
From hereon, we refer to such ∆f (g) as the fairness metric of f ∈ {DP, EOP, EOD} w.r.t. g, respectively.
3 New deﬁnition of fairness for PCA
For p > d, let Rd be the space onto which data will be projected. A dimensionality reduction is a map Π : Rp → Rd, and PCA is deﬁned as Π(x) = V x for some V ∈ Rp×d satisfying1 V V = Id i.e. PCA is a linear, orthogonal dimensionality-reduction. From hereon, we denote a linear PCA as the mapping Π.
Here, we consider a rather canonical notion of fairness; a projection (which includes PCA) is considered to be fair when the projected data distributions of two protected classes are the same, or at least similar. This concept was ﬁrst considered by (Olfat and Aswani 2019). As we discuss later
1The beneﬁts of pursuing orthogonality in the loading matrix, and thus the resulting PCs, are already well-studied; for example, see (Qi, Luo, and Zhao 2013; Benidis et al. 2016).

(Section 3.1 and 5), their deﬁnition does not directly translate into a tractable optimization formulation. In fact, their proposed algorithm, FPCA, necessarily relies on the Gaussian assumption of the underlying data distributions i.e. FPCA only matches the means and covariances of the projected data distributions, which is problematic. To illustrate this, consider a 3-dimensional synthetic dataset with two protected classes colored as blue and orange, shown in Figure 1a. We’ve designed the data distributions such that their means and covariances are almost the same. We assume that we’re reducing the dimensionality of the dataset to 2. Vanilla PCA results in Figure 1b, where the distribution dissimilarity persists. Due to the Gaussian assumption, FPCA results in Figure 1c where the dissimilarity also persists.
This calls for a new deﬁnition of fairness in PCA that can lead to a tractable form of optimization formulation that ensures fairness exactly in the sense that the equality of the two projected data distributions is guaranteed, resulting in Figure 1d. Recall how the necessity for such assumption was derived from the inherent complexity of their deﬁnition. Inspired from our previous discussions on MMD, we propose the following new deﬁnition of fairness for PCA:
Deﬁnition 5 (∆-fairness). Let Ps be the probability measure of Xs X|A = s for s ∈ {0, 1}, and let Qs := Π#Ps ∈ Pd. Then Π is said to be ∆-fair with ∆ := MMD(Q0, Q1), and we refer to ∆ as the fairness metric.
In other words, low ∆ means that the discrepancy between the projected conditional distributions of different protected classes, measured in a non-parametric manner using MMD, while retaining as much variance as possible, is low.
Furthermore, Deﬁnition 5 ensures that a downstream classiﬁcation task using ∆-fair dimensionality-reduced data will be fair, as formalized below2:
Proposition 1 (Oneto et al., 2020). Up to a constant factor, MMD(Q0, Q1) bounds the MMD of the push-forward measures of Q0, Q1 via the weight vector of any given downstream task classiﬁer g.
Remark 1. The above discussions easily generalize to equal opportunity and equalized odds.

3.1 Relation with other deﬁnitions of fair PCA
The notion of fairness proposed by Olfat and Aswani (2019) is similar to ours in that it measures the predictability of protected group membership in dimensonality-reduced data. However, unlike ours, their deﬁnition is explicitly adversarial, which can be a problem.
Deﬁnition 6 (∆A-fairness; Olfat and Aswani, 2019). Consider a ﬁxed classiﬁer h(u, t) : Rd × R → {0, 1} that inputs features u ∈ Rd and a threshold t, and predicts the protected class s ∈ {0, 1}. Then, Π is ∆A(h)-fair if

sup P h(Π(x), t) = 1|s = 1

t∈R

(2)

− P h(Π(x), t) = 1|s = 0 ≤ ∆A(h)

2See Lemma 3 of (Oneto et al. 2020) for the precise statement.

Moreover, for a family of classiﬁers Fc, if Π is ∆A(h)-fair for ∀h ∈ Fc, we say that Π is ∆A(Fc)-fair.
As ∆A can’t be computed exactly, an estimator of the following form was used:

1

1

∆A(Fc) := hs∈uFpc sutp |P | Ii(Π, ht) − |N | Ii(Π, ht)

i∈P

i∈N

(3)

where {xi}ni=1 are the data points, (P, N ) is a partition

of the index set {1, 2, . . . , n} into two protected groups,

Ii(Π, ht) = 1(h(Π(xi), t) = +1), and 1(·) is the indica-

tor function.

Remark 2. It can be argued that, for some choice of Fc, Deﬁnition 5 and 6 are equivalent: in effect, that these are dual notions. Recognizing this, we proceed with Deﬁnition 5, as it has two main advantages in the context of our work:

• It ties more directly and intuitively into our optimization formulation; see Section 5.
• It can be represented non-variationally which allows for tighter statistical guarantees.

4 Statistical properties of ∆
4.1 Consistent and efﬁcient estimation of ∆
As deﬁned in Deﬁnition 5, let Q0, Q1 ∈ Pd be the probability measures with respect to the samples of which we want to estimate MMD(·, ·). Let {Xi}m i=1 and {Yj}nj=1 be these samples, respectively. Accordingly, we consider the following estimator:

∆ := MMD(Qˆ0, Qˆ1)

(4)

where Qˆs is the usual empirical distribution, deﬁned as the mixture of Dirac measures on the samples.
Unlike other statistical distances (e.g. total variation dis-
tance), ∆k has several desirable theoretical properties that have important practical implications, some of which we recall here. (See Sriperumbudur et al. (2010) for more comprehensive discussions.)
First, ∆k can be computed exactly and efﬁciently:

Lemma 1 (Gretton et al., 2007). ∆ is computed as follows:

∆=

1m

1n

m2

k(Xi, Xj) + n2

k(Yi, Yj)

i,j=1

i,j=1

2 m,n

− mn

k(Xi, Yj)

i,j=1

1/2
.
(5)

Moreover, it is asymptotically consistent with a convergence rate, depending only on m and n:

Proposition 2 (Gretton et al., 2007). For any δ > 0, with

probability at least 1 − 2 exp − 2(δm2m+nn) the following

holds:

1

1

∆−∆ ≤2 √ + √ +δ

(6)

mn

4.2 Advantages over ∆A
∆A is known to satisfy the following high probability bound:
Proposition 3 (Olfat and Aswani, 2019). Consider a ﬁxed family of classiﬁers Fc. Then for any δ > 0, with probability at least 1 − exp − (n+m)δ2 the following holds:
2
∆A(Fc) − ∆A(Fc) ≤ 8 V C(Fc) + δ (7) m+n
where V C(·) is the VC dimension.
If Fc is too expressive in terms of VC-dimension, then the above bound may become void. This is the case, for instance, when Fc is the set of RBF-kernel SVMs.
In addition, computing ∆A requires considering all possible classiﬁers in the designated family Fc. This is computationally infeasible, and it forces one to use another approximation (e.g. discretization of Fc), which incurs additional error that may further inhibit asymptotic consistency.
As exhibited in the previous subsection, our MMD-based approach suffers from none of these issues.
5 Manifold optimization for MBF-PCA
5.1 Improvements over FPCA
Olfat and Aswani (2019) proposed FPCA, an SDP formulation of fair PCA3, in which matching the ﬁrst and second moments of the protected groups after dimensionality-reduction are approximated as convex constraints. However, this has several shortcomings, which we discuss here and empirically exhibit in a later section.
First, there are cases in which matching the mean and covariance alone is not enough; this was explicitly shown and discussed in Section 3 where we’ve presented a simple “counterexample” in which two protected groups have different distributions with same mean and covariance. (Figure 1) While this previous point may be countered by the application of the kernel trick to FPCA, this raises a second issue: their formulation requires solving 4 a p × p-dimensional SDP, motivated by the reparameterization P = V V (Arora, Cotter, and Srebro 2013). Since SDP is known to become inefﬁcient (or even computationally infeasible) in high dimensions, this quickly becomes intractable for high-dimensional data (for linear or polynomial kernels) or for any moderate to large size datasets (for the RBF kernel). Finally, their approach involves a relaxation of a rank constraint (rank(P ) ≤ d) to a trace constraint (tr(P ) ≤ d), yielding sub-optimal outputs in presence of (fairness) constraints, even to substantial order in some cases. In Section C of the SP, we discuss in detail why FPCA may lead to such degraded explained variance.
3See Section B of the supplementary material (SP) for its precise description.
4In their approach, the ﬁnal solution V is obtained by taking the ﬁrst d eigenvectors of P .

5.2 Formulating MBF-PCA

Observing that the shortcomings of FPCA stem from the reparametrization of P = V V , we propose a new formulation of fair PCA that solves directly for V . This allows for an effective and efﬁcient approach.
We start by noting that the set of all V with orthonormal columns has the intrinsic geometric structure of a manifold:

Deﬁnition 7. For p > d, the Stiefel manifold, denoted as St(p, d), is an embedded Riemannian sub-manifold of Rp×d such that each element of St(p, d) has orthonormal columns
i.e. V V = Id for all V ∈ St(p, d).

St(p, d) has several desirable properties such as compactness, completeness and smoothness, which we present in Section D of the SP. As St(p, d) is prevalent in various ﬁelds of machine learning (most notably PCA), much work has been done that focuses on exploiting this geometric structure for efﬁcient optimization (Hu et al. 2020).
Based on our MMD-based formulation and letting Σ be the sample covariance matrix of the full dataset, we formulate our fair PCA as follows, which we refer to as MBF-PCA:

minimize f (V ) := − Σ, V V

V ∈St(p,d)

(8)

subject to h(V ) := MMD2(Q0, Q1) = 0.

Here, Q0 and Q1 are deﬁned as in deﬁnition 5. Observe how our deﬁnition of fairness directly incorporates itself into the optimization problem as a constraint.

Remark 3. Under Gaussian assumption, our MMD-based formulation indeed amounts to the same constraints as FPCA since MMD2(·, ·) is a metric and Gaussian distribution is completely characterized by its ﬁrst and second moments.

6 REPMS for MBF-PCA, with new theoretical guarantees
6.1 Description of Algorithm 1
One crucial observation is that the constraint function h is always non-negative5 and smooth. This motivates the use of the exact penalty method (Han and Mangasarian 1979), recently extended to manifold optimization as the Riemannian Exact Penalty Method via Smoothing (REPMS; Liu and Boumal, 2019). Note that smoothing tricks (Liu and Boumal 2019), which were required to smooth out possible non-differentiable functions emerging from the 1-penalty, are not necessary. Moreover, by leveraging the kernel trick, there is a closed form for ∇V h(V ), thus alleviating the need for computationally expensive numerical approximations; see Section G of the SP for the derivation. The pseudo-code for the algorithm is shown in Algorithm 1.
For practical concerns that will be addressed in the following subsection, we’ve set the fairness tolerance level, τ , to be a ﬁxed and sufﬁciently small, non-negative value. Formally, we consider the following deﬁnition:
Deﬁnition 8. For ﬁxed τ ≥ 0, V ∈ St(p, d) is τ approximate fair if it satisﬁes h(V ) ≤ τ . If τ = 0, we simply say that V is fair.
5This follows from closed form of ∆k (Lemma 1). See Section 2 of Gretton et al. (2012) for more details.

Algorithm 1: REPMS for MbF-PCA
Input: X, K, min, 0 > 0, θ ∈ (0, 1), ρ0 > 0, θρ > 1, ρmax ∈ (0, ∞), τ > 0, dmin > 0.
1 Initialize V0; 2 for k = 0, 1, . . . , K do 3 Compute an approximate solution Vk+1 for the
following sub-problem, with a warm-start at Vk, until grad Q ≤ k:

min Q(V, ρk)

(9)

V ∈St(p,d)

where

Q(V, ρk) = f (V ) + ρkh(V )

4 if Vk+1 − Vk F ≤ dmin and k ≤ min then

5

if h(Vk+1) ≤ τ then

6

return Vk+1;

7

end

8 end

9

k+1 = max{ min, θ k};

10 if h(Vk+1) > τ then

11

ρk+1 = min(θρρk, ρmax);

12 else

13

ρk+1 = ρk;

14 end

15 end

6.2 New theoretical guarantees for Algorithm 1

We start by observing that Eq. (9) in Algorithm 1 is smooth, unconstrained manifold optimization problem, which can be solved using conventional algorithms; these include ﬁrstorder methods like line-search methods (Absil, Mahony, and Sepulchre 2007), or second-order methods like the Riemannian Trust Region (RTR; Absil, Baker, and Gallivan, 2007) method. It is known that, pathological examples excluded, most conventional unconstrained manifold optimization solvers produce iterates whose limit points are local minima, and not other stationary points such as saddle point or local maxima: see (Absil, Baker, and Gallivan 2007; Absil, Mahony, and Sepulchre 2007) for more detailed discussions.
Motivated by this, we consider the following assumption:

Assumption 2 (informal; locality assumption). Each Vk+1 is sufﬁciently close to a local minimum of Eq. (9).

Lastly, we consider the following auxiliary optimization

problem:

min h(V )

(10)

V ∈St(p,d)

The following theorem, whose proof is deferred to Section F of the SP, provides an exact theoretical convergence guarantee of MBF-PCA under the ideal hyperparameter setting:

Theorem 1. Let K = ∞, ρmax = ∞, min = τ = 0, {Vk} be the sequence generated by Alg. 1 under Assumption 2, and
V be any limit point of {Vk}, whose existence is guaranteed. Then the following holds:

(A) V is a local minimizer of Eq. (10), which is a necessary condition for V to be fair.
(B) If V is fair, then V is a local minimizer of Eq. (8)

The assumption of V being fair, which is used in (B), is at least partially justiﬁed in (A) in the following sense: the ideal hyperparameter setting of ρmax = ∞, τ = 0, min = 0 implies the exact local minimality of V for Eq. (10), which is in turn a necessary condition for V to be fair.
The next theorem, whose is also deferred to Section F of the SP, asserts that with small τ, min and large ρmax, the above guarantee can be approximated in rigorous sense:

Theorem 2. Let K = ∞, ρmax < ∞, min, τ > 0, {Vk} be the sequences generated by Alg. 1 under Assumption 2 and
V be any limit point of {Vk}, whose existence is guaranteed. Then for any sufﬁciently small min and r˜ = r˜( min) > 0, the following hold:

(A) V is an approximate local minimizer of Eq. (10) in the sense that

h(V ) ≤ h(V ) + β V − V + (β + Lh)g( min) (11)

for all V ∈ Br˜(V ) ∩ St(p, d), where β = β(ρmax, τ ) is a function that satisﬁes the following:

• 0 < β ≤ 2 ρΣ0 • β(ρmax, τ ) is increasing in ρmax and decreasing in τ .

(B) If V is fair, then it is an approximate local minimizer of Eq. (8) in the sense that it satisﬁes

f (V ) ≤ f (V ) + 2 Σ g( min)

(12)

for all fair V ∈ Br˜(V ) ∩ St(p, d).

In both (A) and (B), g is some continuous, decreasing
function that satisﬁes g(0) = 0, and r˜( min) = r − g( min) for some ﬁxed constant r > 0.

Existing optimality guarantee of REPMS (Proposition 4.2; Liu and Boumal, 2019) states that when min = 0, ρ is not updated (i.e. line 10-14 is ignored), and the resulting limit point is feasible, then that limit point satisﬁes the KKT condition (Yang, Zhang, and Song 2014). Comparing Theorem 1 and 2 to the previous result, we see that ours extend the previous result in several ways:

• Our theoretical analyses are much closer to the actual implementation, by incorporating the ρ-update step (line 11) and the practical hyperparameter setting.

• Our theoretical analyses are much more stronger in the sense that 1) by introducing a reasonable, yet novel locality assumption, we go beyond the existing KKT conditions and prove the local minimality of the limit point, and 2) we provide a partial justiﬁcation of the feasibility assumption in (A) by proving a necessary condition for it.

6.3 Practical implementation
In line 4 in Algorithm 1, we implemented the termination criteria: sufﬁciently small distance between iterates and sufﬁciently small tolerance for solving Eq. (9). However, such a heuristic may return some point V that is not τ -approximate fair for user-deﬁned level τ in practical hyperparameter setting. To overcome this issue, we’ve additionally implemented line 5 that forces the algorithm to continue on with the loop until the desired level of fairness is achieved.

7 Related Work
7.1 Fairness in ML
A large body of work regarding fairness in the context of supervised learning (Feldman et al. 2015; Calders, Kamiran, and Pechenizkiy 2009; Dwork et al. 2012; Hardt, Price, and Srebro 2016; Zafar et al. 2017) has been published. This includes key innovations in quantifying algorithmic bias, notably the concepts of demographic parity and equalized odds (opportunity) that have become ubiquitous in fairness research (Barocas and Selbst 2016; Hardt, Price, and Srebro 2016). More recently, fair machine learning literatures have branched out into a variety of ﬁelds, including deep learning (Beutel et al. 2017), regression (Calders et al. 2013), and even hypothesis testing (Olfat et al. 2020).
Among these, one line of research has focused on learning fair representations (Kamiran and Calders 2011; Zemel et al. 2013; Feldman et al. 2015; Calmon et al. 2017), which aims to learn a representation of the given data on which various fairness deﬁnitions are ensured for downstream modeling. A growing number of inquiries have been made into highly specialized algorithms for speciﬁc unsupervised learning problems like clustering (Chierichetti et al. 2017; Kleindessner, Awasthi, and Morgenstern 2019; Bera et al. 2019), but these lack the general applicability of key dimensionality reduction algorithms such as PCA (Pearson 1901; Hotelling 1933).
To the best of our knowledge, Olfat & Aswani (2019) is the only work on incorporating fair representation to PCA, making it the sole comparable approach to ours. Another line of work (Bian and Tao 2011; Samadi et al. 2018; Tantipongpipat et al. 2019; Zalcberg and Wiesel 2021) considers a completely orthogonal deﬁnition of fairness for PCA: minimizing the discrepancy between reconstruction errors over protected attributes. This doesn’t ensure the fairness of downstream tasks, rendering it incomparable to our deﬁnition of fairness; see Section A of the SP for more details.
7.2 Manifold Optimization
A constrained problem over Euclidean space can be transformed to an unconstrained problem over a manifold (or at least manifold optimization with less constraints). Many algorithms for solving Euclidean optimization problems have direct counterparts in manifold optimization problems that includes Riemannian gradient descent and Riemannian BFGS. By making use of the geometry of lower dimensional manifold structure, often embedded in potentially very high dimensional ambient space, such Riemannian counterparts are much more computationally efﬁcient than algorithms that do not make use of manifold structure. This is shown in numerous literatures (Liu and Boumal 2019; Alsharif et al. 2021; Meng, Chakraborty, and Singh 2021), including this work. We refer interested readers to the standard textbooks Absil, Mahony, and Sepulchre (2007) and Boumal (2020) on this ﬁeld, along with a survey by Hu et al. (2020).
8 Experiments
MBF-PCA was implemented using ROPTLIB (Huang et al. 2018), a state-of-the-art manifold optimization framework on

60 0.6

Var.exp Squared_MMD

40

Label 0.4

Label

PCA

PCA

FPCA

FPCA

MbF−PCA

MbF−PCA

0.2 20

20 30 40 50 60 70 80 90 100 dimension
(a) Variance explained (%)

0.0
20 30 40 50 60 70 80 90 100 dimension
(b) MMD2

Figure 2: Synthetic data #2: Comparison of PCA, FPCA, and MBF-PCA on the synthetic datasets of increasing dimensions.

FPCA MbF−PCA

1500

1000

runtime

500

0

20

40

60

80

100

dimension

Figure 3: Synthetic data #2: Comparison of runtimes of FPCA, and MbF-PCA.

MATLAB. For solving Eq. (9), we use the cautious Riemannian BFGS method (RBFGS; Huang, Absil, and Gallivan, 2018), a memory-efﬁcient quasi-Newton method. As for the hyperparameters, we’ve set K = 100, min = 10−6, 0 = 10−1, θ = ( min/ 0)1/5, ρmax = 1010, θρ = 2, dmin = 10−6. For FPCA, we use the same Python MOSEK(ApS 2021) implementation as provided by (Olfat and Aswani 2019). (µ, δ) are the hyperparameters of FPCA; see Section B of the SP. Codes are available in our Github repository6.
All data is pre-processed to be standardized such that each covariate has zero mean and unit variance. For all experiments, we considered 10 different 70 − 30 train-test splits.
8.1 Synthetic data #1
We consider synthetic data composed of two groups, each of size n = 150; one is sampled from N3(0, 0.1I3 + 1) and one is sampled from a (balanced) mixture of N3(1, 0.1I3) and N3(−1, 0.1I3). Note how the two groups follow different distributions, yet have the same mean and covariance.
6https://github.com/nick-jhlee/fair-manifold-pca

Table 1: Comparison of PCA, FPCA, MBF-PCA for UCI datasets. Number in parenthesis for each dataset is its dimension. Also, the parenthesis for each fair algorithm is its hyperparameter setting; (µ, δ) for FPCA and τ for MBF-PCA. Among the fair algorithms considered, results with the best mean values are bolded. Results in which our approach terminates improperly in the
sense that the maximum iteration is reached before passing the termination criteria are highlighted .

COMPAS (11)

GERMAN CREDIT (57)

ADULT INCOME (97)

d

ALG. %VAR

%ACC

MMD2

∆DP

%VAR

%ACC

MMD2

∆DP

%VAR

%ACC

MMD2

∆DP

PCA 39.285.17 64.531.45 0.0920.010 0.290.09 11.420.47 76.871.39 0.1470.049 0.120.06

7.780.82

82.031.15 0.3490.027

0.200.05

FPCA (0.1, 0.01) 35.065.16 61.651.17 0.0120.007 0.100.07 7.430.59 72.171.09 0.0170.010 0.030.02 4.050.98 77.442.96 0.0160.011 0.040.04

2

FPCA (0, 0.01) 34.435.02 60.861.09 0.0110.006 0.100.06 7.330.57 71.771.60 0.0150.010 0.030.03 3.650.97 77.053.18 0.0050.004 0.010.01

MBF-PCA (10−3) 33.955.01 65.371.11 0.0050.002 0.120.07 10.170.57 74.531.92 0.0180.014 0.050.04 6.030.61 79.501.22 0.0050.004 0.030.02

MBF-PCA (10−6) 11.833.59 57.731.50 0.0020.002 0.060.08 9.360.33 74.101.56 0.0160.010 0.020.02 5.830.57 79.121.14 0.0050.004 0.010.01

PCA 100.000.00 73.141.22 0.2410.005 0.210.07 38.250.98 99.930.14 0.1300.019 0.120.08 21.772.06 93.640.92 0.1950.007 0.160.01

FPCA (0.1, 0.01) 87.791.27 72.250.93 0.0150.003 0.160.06 29.850.87 99.930.14 0.0200.005 0.120.08 15.751.20 91.940.88 0.0060.003 0.130.02

10

FPCA (0, 0.1) 87.441.35 72.320.93 0.0150.002 0.160.07 29.790.89 99.930.14 0.0200.006 0.120.08 15.521.18 91.660.97 0.0040.002 0.130.02

MBF-PCA (10−3) 87.751.36 72.160.90 0.0140.002 0.160.07 34.101.00 99.930.14 0.0200.008 0.120.08 18.711.47 92.810.84 0.0050.002 0.140.01

MBF-PCA (10−6) 87.751.36 72.160.90 0.0140.002 0.160.07 16.951.52 92.703.00 0.0130.007 0.060.05 15.496.44 86.363.77 0.0030.002 0.070.03

Thus, we expect FPCA to project in a similar way as vanilla PCA, while MBF-PCA should ﬁnd a fairer subspace such that the projected distributions are exactly the same. Hyperparameters are set as follows: δ = 0, µ = 0.01 for FPCA and τ = 10−5 for MBF-PCA. We’ve set d = 2 and Figure 1 displays the results of each algorithm using the top two principal components. Indeed, only MBF-PCA successfully obfuscates the protected group information by merging the two orange clusters with the blue cluster.
8.2 Synthetic data #2
We consider a series of synthetic datasets of dimension p. For each p, the dataset is composed of two groups, each of size n = 240 and sampled from two different p-variate normal distributions. We vary p ∈ {20, 30, . . . , 100}; see Section H of the SP for a full description of the setting. For the hyperparameters, we’ve set δ = 0, µ = 0.01 for FPCA and τ = 10−5 for MBF-PCA.
Figure 2 plots the explained variance and fairness metric values. Observe how MBF-PCA achieves better explained variance, while achieving similar level of fairness. In addition, Figure 3 shows a clear gap in runtime between FPCA and MBF-PCA; the runtime of FPCA explodes for even moderate problem sizes, while MBF-PCA scales well. For higher dimensions, conventional computing machine will not be able to handle such computational burden.
8.3 UCI datasets
For target dimensions d ∈ {2, 10}, we compare the performance of FPCA and MBF-PCA on 3 datasets from the UCI Machine Learning Repository (Dua and Graff 2017); COMPAS dataset (Kirchner et al. 2016), Adult income dataset, and German credit dataset. See Section I of the SP for complete description of the pre-processing steps. For both algorithms, we consider two different hyperparameter settings, such that one simulates the relaxed fairness while the other simulates a stricter fairness constraints. For computing ∆DP (g), we trained a RBF SVM g to be the downstream task classiﬁer that best classiﬁes the target attribute in the dimensionalityreduced data. Table 1 displays the results, from which several observations can be made:

Figure 4: Comparison of communality of “age” of German credit dataset for PCA, FPCA, and MBF-PCA.
• Across all considered datasets, MBF-PCA is shown to outperform FPCA in terms of fairness (both MMD2 and ∆DP ) with low enough τ .
• For GERMAN CREDIT and ADULT INCOME, MBF-PCA shows a clear trade-off between explained variance and fairness; by relaxing τ , we see that MBF-PCA outperforms FPCA in terms of explained variance and downstream task accuracy.
In addition, to see how correlated are the PCs with the protected attribute, we examine the communalities. For clarity of exposition, we consider the German credit dataset, whose protected attribute is age, and d = 10. Here, we again consider PCA, FPCA (0, 0.01), and MBF-PCA (10−3). For PCA, communality of a feature is its variance contributed by the PCs (Johnson and Wichern 2008), computed as the sum of squares of the loadings of the considered feature. High communality implies that the correlations between the feature and PCs are strong. Figure 4 displays the boxplot of communality, plotted over the 10 splits. Indeed the amount of variance in age that is accounted for from the loadings of MBF-PCA is much smaller than that of PCA or FPCA. In other words, the PCs resulting from MBF-PCA have the least correlations with age, the protected attribute.

9 Conclusion and Future Works
We present a MMD-based deﬁnition of fair PCA, and formulate it as a constrained optimization over the Stiefel manifold. Through both theoretical and empirical discussions, we show that our approach outperforms the previous approach (Olfat and Aswani 2019) in terms of explained variance, fairness, and runtime. Many avenues remain for future research. Statistical characterizations of our fair PCA in asymptotic regime, as well as incorporation of sparsity (Johnstone et al. 2009) are important open questions. Incorporating stochastic optimization-type modiﬁcations (Shamir 2015; Roh et al. 2021) is also an important direction, as such modiﬁcations are expected to result in better scalability and performance.
Acknowledgements
JH, GS, and CD were partly supported by Institute for Information & communications Technology Planning & Evaluation(IITP) grant funded by the Korea government(MSIT) (No. 2019-0-01396, Development of framework for analyzing, detecting, mitigating of bias in AI model and training data), and partly supported by Institute for Information & communications Technology Planning & Evaluation(IITP) grant funded by the Korea government(MSIT) (No. 2021-0-01381, Development of Causal AI through Video Understanding). JH was also supported by Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government(MSIT) (No. 2019-0-00075, Artiﬁcial Intelligence Graduate School Program(KAIST)) JH would like to thank Jaeho Lee and Se-Young Yun for providing helpful comments on the writing and organization of the paper.
References
Absil, P.-A.; Baker, C. G.; and Gallivan, K. A. 2007. TrustRegion Methods on Riemannian Manifolds. Foundations of Computational Mathematics, 7(3): 303–330.
Absil, P.-A.; Mahony, R.; and Sepulchre, R. 2007. Optimization Algorithms on Matrix Manifolds. USA: Princeton University Press.
Adel, T.; Valera, I.; Ghahramani, Z.; and Weller, A. 2019. One-Network Adversarial Fairness. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 33, 2412– 2420.
Alsharif, M. H.; Douik, A.; Ahmed, M.; Alnaffouri, T.; and Hassibi, B. 2021. Manifold Optimization for High Accuracy Spacial Location Estimation Using Ultrasound Waves. IEEE Transactions on Signal Processing, 1–1.
ApS, M. 2021. MOSEK Optimizer API for Python. Version 9.2.36.
Arora, R.; Cotter, A.; and Srebro, N. 2013. Stochastic Optimization of PCA with Capped MSG. In Burges, C. J. C.; Bottou, L.; Welling, M.; Ghahramani, Z.; and Weinberger, K. Q., eds., Advances in Neural Information Processing Systems, volume 26. Curran Associates, Inc.
Barocas, S.; and Selbst, A. D. 2016. Big Data’s Disparate Impact. 104 California Law Review 671.

Bellamy, R. K. E.; Dey, K.; Hind, M.; Hoffman, S. C.; Houde, S.; Kannan, K.; Lohia, P.; Martino, J.; Mehta, S.; Mojsilovic, A.; Nagar, S.; Ramamurthy, K. N.; Richards, J.; Saha, D.; Sattigeri, P.; Singh, M.; Varshney, K. R.; and Zhang, Y. 2018. AI Fairness 360: An Extensible Toolkit for Detecting, Understanding, and Mitigating Unwanted Algorithmic Bias.
Benidis, K.; Sun, Y.; Babu, P.; and Palomar, D. P. 2016. Orthogonal Sparse PCA and Covariance Estimation via Procrustes Reformulation. IEEE Transactions on Signal Processing, 64(23): 6211–6226.
Bera, S. K.; Chakrabarty, D.; Flores, N.; and Negahbani, M. 2019. Fair Algorithms for Clustering. In Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, 4955–4966. Vancouver, BC, Canada.
Beutel, A.; Chen, J.; Zhao, Z.; and Chi, E. H. 2017. Data decisions and theoretical implications when adversarially learning fair representations. arXiv preprint arXiv:1707.00075.
Bian, W.; and Tao, D. 2011. Max-Min Distance Analysis by Using Sequential SDP Relaxation for Dimension Reduction. IEEE Transactions on Pattern Analysis and Machine Intelligence, 33(5): 1037–1050.
Boumal, N. 2020. An introduction to optimization on smooth manifolds. Available online.
Boyd, S.; El Ghaoui, L.; Feron, E.; and Balakrishnan, V. 1994. Linear Matrix Inequalities in System and Control Theory. Society for Industrial and Applied Mathematics.
Calders, T.; Kamiran, F.; and Pechenizkiy, M. 2009. Building Classiﬁers with Independency Constraints. In ICDM Workshops 2009, IEEE International Conference on Data Mining Workshops, 13–18. Miami, Florida, USA.
Calders, T.; Karim, A.; Kamiran, F.; Ali, W.; and Zhang, X. 2013. Controlling attribute effect in linear regression. In Data Mining (ICDM), 2013 IEEE 13th International Conference on, 71–80. IEEE.
Calmon, F. P.; Wei, D.; Vinzamuri, B.; Ramamurthy, K. N.; and Varshney, K. R. 2017. Optimized Pre-Processing for Discrimination Prevention. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, 3992–4001. Long Beach, CA, USA.
Chien, C.-F.; and Chen, L.-F. 2008. Data mining to improve personnel selection and enhance human capital: A case study in high-technology industry. Expert Systems with applications, 34(1): 280–290.
Chierichetti, F.; Kumar, R.; Lattanzi, S.; and Vassilvitskii, S. 2017. Fair Clustering Through Fairlets. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, 5029–5037. Long Beach, CA, USA.
Dua, D.; and Graff, C. 2017. UCI Machine Learning Repository.
Dwork, C.; Hardt, M.; Pitassi, T.; Reingold, O.; and Zemel, R. S. 2012. Fairness through awareness. In Innovations in Theoretical Computer Science 2012, 214–226. Cambridge, MA, USA.

Eckart, C.; and Young, G. 1936. The approximation of one matrix by another of lower rank. Psychometrika, 1: 211— 218.
Feldman, M.; Friedler, S. A.; Moeller, J.; Scheidegger, C.; and Venkatasubramanian, S. 2015. Certifying and Removing Disparate Impact. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 259–268. Sydney, NSW, Australia.
Fukumizu, K.; Gretton, A.; Sun, X.; and Scho¨lkopf, B. 2008. Kernel Measures of Conditional Dependence. In Platt, J.; Koller, D.; Singer, Y.; and Roweis, S., eds., Advances in Neural Information Processing Systems, volume 20. Curran Associates, Inc.
Gretton, A.; Borgwardt, K.; Rasch, M.; Scho¨lkopf, B.; and Smola, A. 2007. A Kernel Method for the Two-SampleProblem. In Scho¨lkopf, B.; Platt, J.; and Hoffman, T., eds., Advances in Neural Information Processing Systems, volume 19. MIT Press.
Gretton, A.; Borgwardt, K. M.; Rasch, M. J.; Scho¨lkopf, B.; and Smola, A. 2012. A Kernel Two-Sample Test. Journal of Machine Learning Research, 13(25): 723–773.
Han, S. P.; and Mangasarian, O. L. 1979. Exact penalty functions in nonlinear programming. Mathematical Programming, 17(1): 251–269.
Hardt, M.; Price, E.; and Srebro, N. 2016. Equality of Opportunity in Supervised Learning. In Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, 3315–3323. Barcelona, Spain.
Hotelling, H. 1933. Analysis of a complex of statistical variables into principal components. Journal of Educational Psychology, 24(6): 417–441.
Hu, J.; Liu, X.; Wen, Z.-W.; and Yuan, Y.-X. 2020. A Brief Introduction to Manifold Optimization. Journal of Operations Research Society of China, 8: 199–248.
Huang, W.; Absil, P.-A.; and Gallivan, K. A. 2018. A Riemannian BFGS Method Without Differentiated Retraction for Nonconvex Optimization Problems. SIAM Journal on Optimization, 28(1): 470–495.
Huang, W.; Absil, P.-A.; Gallivan, K. A.; and Hand, P. 2018. ROPTLIB: An Object-Oriented C++ Library for Optimization on Riemannian Manifolds. ACM Transactions on Mathematical Softwares, 44(4).
Johnson, R. A.; and Wichern, D. W. 2008. Applied Multivariate Statistical Analysis. Pearson, 6 edition.
Johnstone, I. M.; Lu, A. Y.; Nadler, B.; Witten, D. M.; Hastie, T.; Tibshirani, R.; and Ramsay, J. O. 2009. On Consistency and Sparsity for Principal Components Analysis in High Dimensions [with Comments]. Journal of the American Statistical Association, 104(486): 682–703.
Jolliffe, I. T.; and Cadima, J. 2016. Principal component analysis: a review and recent developments. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 374(2065).
Jung, S.; Lee, D.; Park, T.; and Moon, T. 2021. Fair Feature Distillation for Visual Recognition. In Proceedings of

the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 12115–12124.
Kamiran, F.; and Calders, T. 2011. Data preprocessing techniques for classiﬁcation without discrimination. Knowledge and Information Systems, 33(1): 1–33.
Kamishima, T.; Akaho, S.; and Sakuma, J. 2011. Fairnessaware Learning through Regularization Approach. In 2011 IEEE 11th International Conference on Data Mining Workshops, 643–650.
Karan, O.; Bayraktar, C.; Gu¨mu¨s¸kaya, H.; and Karlık, B. 2012. Diagnosing diabetes using neural networks on small mobile devices. Expert Systems with Applications, 39(1): 54–60.
Kirchner, L.; Larson, J.; Mattu, S.; and Angwin, J. 2016. Machine Bias. ProPublica.
Kleindessner, M.; Awasthi, P.; and Morgenstern, J. 2019. Fair k-Center Clustering for Data Summarization. In Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 3448–3457. Long Beach, CA, USA.
Liu, C.; and Boumal, N. 2019. Simple Algorithms for Optimization on Riemannian Manifolds with Constraints. Applied Mathematics and Optimization, 82: 949–981.
Louizos, C.; Swersky, K.; Li, Y.; Welling, M.; and Zemel, R. S. 2016. The Variational Fair Autoencoder. In Bengio, Y.; and LeCun, Y., eds., 4th International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings.
Madras, D.; Creager, E.; Pitassi, T.; and Zemel, R. 2018. Learning Adversarially Fair and Transferable Representations. In Dy, J.; and Krause, A., eds., Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, 3384–3393. PMLR.
Mahdi Kamani, M.; Haddadpour, F.; Forsati, R.; and Mahdavi, M. 2019. Efﬁcient Fair Principal Component Analysis. arXiv e-prints, arXiv:1911.04931.
Massart, P. 2007. Concentration Inequalities and Model Selection. E´ cole d’E´ te´ de Probabilite´s de Saint-Flour. SpringerVerlag Berlin Heidelberg, 1 edition.
Mehrabi, N.; Morstatter, F.; Saxena, N.; Lerman, K.; and Galstyan, A. 2019. A Survey on Bias and Fairness in Machine Learning. arXiv e-prints, arXiv:1908.09635.
Meng, Z.; Chakraborty, R.; and Singh, V. 2021. An Online Riemannian PCA for Stochastic Canonical Correlation Analysis. arXiv:2106.07479.
Nocedal, J.; and Wright, S. J. 2006. Numerical optimization. Springer Series in Operations Research and Financial Engineering. Springer-Verlag New York, 2 edition.
Olfat, M.; and Aswani, A. 2019. Convex Formulations for Fair Principal Component Analysis. In The Thirty-Third AAAI Conference on Artiﬁcial Intelligence, AAAI 2019, Honolulu, Hawaii, USA, January 27 - February 1, 2019, 663–670.
Olfat, M.; Sloan, S.; Hespanhol, P.; Porter, M.; Vasudevan, R.; and Aswani, A. 2020. Covariance-robust dynamic watermarking. In 2020 59th IEEE Conference on Decision and Control (CDC), 3793–3799. IEEE.

Oneto, L.; Donini, M.; Luise, G.; Ciliberto, C.; Maurer, A.; and Pontil, M. 2020. Exploiting MMD and Sinkhorn Divergences for Fair and Transferable Representation Learning. In Larochelle, H.; Ranzato, M.; Hadsell, R.; Balcan, M. F.; and Lin, H., eds., Advances in Neural Information Processing Systems, volume 33, 15360–15370. Curran Associates, Inc.
Pearson, K. 1901. LIII. On lines and planes of closest ﬁt to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11): 559–572.
Pelegrina, G. D.; Brotto, R. D. B.; Duarte, L. T.; Romano, J. M. T.; and Attux, R. 2020. A multi-objective-based approach for Fair Principal Component Analysis. arXiv:2006.06137.
Prost, F.; Qian, H.; Chen, Q.; Chi, E. H.; Chen, J.; and Beutel, A. 2019. Toward a better trade-off between performance and fairness with kernel-based distribution matching. In NeurIPS 2019 Workshop on Machine Learning with Guarantees. Vancouver, BC, Canada.
Qi, X.; Luo, R.; and Zhao, H. 2013. Sparse principal component analysis by choice of norm. Journal of Multivariate Analysis, 114: 127 – 160.
Quadrianto, N.; and Sharmanska, V. 2017. Recycling Privileged Learning and Distribution Matching for Fairness. In Guyon, I.; Luxburg, U. V.; Bengio, S.; Wallach, H.; Fergus, R.; Vishwanathan, S.; and Garnett, R., eds., Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc.
Ramdas, A.; Reddi, S. J.; Po´czos, B.; Singh, A.; and Wasserman, L. 2015. On the Decreasing Power of Kernel and Distance Based Nonparametric Hypothesis Tests in High Dimensions. In Proceedings of the Twenty-Ninth AAAI Conference on Artiﬁcial Intelligence, AAAI’15, 3571–3577. AAAI Press.
Rockafellar, R. T.; and Wets, R. J.-B. 1998. Variational Analysis. Grundlehren der mathematischen Wissenschaften. Springer-Verlag Berlin Heidelberg, 1 edition.
Roh, Y.; Lee, K.; Whang, S. E.; and Suh, C. 2021. FairBatch: Batch Selection for Model Fairness. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net.
Samadi, S.; Tantipongpipat, U. T.; Morgenstern, J. H.; Singh, M.; and Vempala, S. S. 2018. The Price of Fair PCA: One Extra dimension. In Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, 10999–11010. Montre´al, Canada.
Scho¨lkopf, B.; Smola, A.; and Mu¨ller, K. 1998. Nonlinear Component Analysis as a Kernel Eigenvalue Problem. Neural Computation, 10(5): 1299–1319.
Shamir, O. 2015. A Stochastic PCA and SVD Algorithm with an Exponential Convergence Rate. In Bach, F.; and Blei, D., eds., Proceedings of the 32nd International Conference on Machine Learning, volume 37 of Proceedings of Machine Learning Research, 144–152. Lille, France: PMLR.
Shumway, R. H.; and Stoffer, D. S. 2017. Time Series Analysis and Its Applications: With R Examples. Springer Texts in Statistics. Springer International Publishing, 4 edition.

Sriperumbudur, B. K.; Gretton, A.; Fukumizu, K.; Lanckriet, G. R.; and Scho¨lkopf, B. 2008. Injective Hilbert Space Embeddings of Probability Measures. In Servedio, R.; and Zhang, T., eds., Proceedings of the 21st Annual Conference on Learning Theory (COLT), 111–222.
Sriperumbudur, B. K.; Gretton, A.; Fukumizu, K.; Scho¨lkopf, B.; and Lanckriet, G. R. 2010. Hilbert Space Embeddings and Metrics on Probability Measures. Journal of Machine Learning Research, 11(50): 1517–1561.
Tantipongpipat, U.; Samadi, S.; Singh, M.; Morgenstern, J. H.; and Vempala, S. S. 2019. Multi-Criteria Dimensionality Reduction with Applications to Fairness. In Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, 15135–15145. Vancouver, BC, Canada.
Yang, W. H.; Zhang, L.-H.; and Song, R. 2014. Optimality conditions for the nonlinear programming problems on Riemannian manifolds. Paciﬁc Journal of Optimization, 10: 415–434.
Zafar, M. B.; Valera, I.; Gomez-Rodriguez, M.; and Gummadi, K. P. 2017. Fairness Beyond Disparate Treatment & Disparate Impact: Learning Classiﬁcation without Disparate Mistreatment. In Proceedings of the 26th International Conference on World Wide Web, WWW 2017, 1171–1180. Perth, Austrailia.
Zalcberg, G.; and Wiesel, A. 2021. Fair Principal Component Analysis and Filter Design. IEEE Transactions on Signal Processing, 69: 4835–4842.
Zemel, R. S.; Wu, Y.; Swersky, K.; Pitassi, T.; and Dwork, C. 2013. Learning Fair Representations. In Proceedings of the 30th International Conference on Machine Learning, ICML 2013, 325–333. Atlanta, GA, USA.

Figure 5: Comparison of fair PCA’s as considered in (Samadi et al. 2018), and our work and (Olfat and Aswani 2019).

A Relation to (Samadi et al. 2018)
There is another branch work (Samadi et al. 2018; Tantipongpipat et al. 2019; Mahdi Kamani et al. 2019; Pelegrina et al. 2020) in which the task of solving fair PCA is deﬁned as ﬁnding a (linear) subspace in which the reconstruction errors for each protected class are approximately equal. Here, we emphasize again that their fair PCA is incomparable with our considered fair PCA.
Consider the task of performing PCA on a twodimensional data as shown in Figure 5, where A ∈ {0, 1} denotes a protected attribute and the target dimension is set to d = 1. We assume that the data distributions for both A = 0 and A = 1 take an elliptical density, the only difference being their orientation and position.
Fairness in reconstruction error can be achieved by projecting the data onto blue or red subspace. However, fair PCA deﬁned by Samadi et al. (2018) aims to minimize the reconstruction error with the fairness constraint, and thus the blue subspace is chosen. Under our MMD-based deﬁnition of fair PCA, projecting onto the blue subspace is considered unfair because the distributions conditioned on each protected attribute A are not the same; our fair PCA would choose the red subspace.
One important observation is that while our deﬁnition of fairness ensures that the downstream tasks are fair w.r.t many of existing fairness deﬁnitions (see Proposition 1), the reconstruction error-based deﬁnition has no such guarantees.

B Brief Description of FPCA
This section follows the discussion in Olfat and Aswani (2019), and by “they”, we refer to its authors. First recall their proposed adversarial deﬁnition of fairness for PCA:
Deﬁnition 6 (∆A-fairness; Olfat and Aswani, 2019). Consider a ﬁxed classiﬁer h(u, t) : Rd × R → {0, 1} that inputs features u ∈ Rd and a threshold t, and predicts the protected class s ∈ {0, 1}. Then, Π is ∆A(h)-fair if

sup P h(Π(x), t) = 1|s = 1

t∈R

(2)

− P h(Π(x), t) = 1|s = 0 ≤ ∆A(h)

Moreover, for a family of classiﬁers Fc, if Π is ∆A(h)-fair for ∀h ∈ Fc, we say that Π is ∆A(Fc)-fair.

B.1 Fairness Constraints
By choosing Fc to be Flin = {h(u, t) = 1(w u − t ≤ 0) : w ∈ Rd}, ∆A(Flin) becomes the Kolmogorov distance between Xs w V X|A = s, which is upper bounded by their total variation distance. Applying Pinsker’s inequality (Massart 2007), we have that

∆A(Flin) ≤

1 2 KL (X0||X1)

In order to obtain a tractable form of fairness constraints, they make normality assumptions on the data as follows: Xs = X|A = s ∼ Np(µs, Σs). Then an upper bound of closed form can be obtained as follows:

∆A(Flin)

≤ 1 |Σ1| + tr Σ−1Σ0 − d + (µ1 − µ0) Σ−1(µ1 − µ0),

2 |Σ0|

1

1

and thus, the sufﬁcient condition for the RHS to be 0 is that µ0 = µ1 and Σ0 = Σ1.
Denoting f = µ1 − µ0 and Q = Σ1 − Σ0, they introduced two constraints:
• Mean constraint: hm(V ) := V f = 0
• Covariance constraint: hc(V ) = V QV 2 = 0
Based on these, the optimization considered in their work is as follows:
minimize f (V ) = − Σ, V V subject to V V = Id,
(13) hm(V ) = 0, hc(V ) = 0.

B.2 SDP Formulation

Standard convex relaxation techniques (Boyd et al. 1994)
were then used to derive an SDP w.r.t. a new variable P = V V ∈ Rp×p:

max XTX, P − µt s.t. tr(P ) ≤ d Ip P 0 P, ffT ≤ δ2 tIp P M+T 0 P M+ Ip tIp M−T P 0 P M− Ip

(14a) (14b) (14c) (14d)
(14e)
(14f)

where MsMs is the Cholesky decomposition of (−1)sQ + ϕIp, ϕ ≥ Q 2, and δ, µ ≥ 0 are the fairness tolerance levels7 for mean and covariance constraints, respectively.
The ﬁnal loading matrix V is obtained by extracting the top d eigenvectors from the resulting P ∗.

4

Cutoff for final loading matrix

3.5

Cutoff for final loading matrix 5

Explained variance(%) Explained variance(%)

3

4

2.5 3
2

1.5

2

1 1
0.5

0

0

1 5 10 15 20 25 30 35 40 45 50

57

Each dimension of P

(a) FPCA (Olfat and Aswani 2019)

1 5 10 15 20 25 30 35 40 45 50

57

Each dimension of P

(b) MBF-PCA (ours)

Figure 6: Explained variance of each eigenvector of P ∗ for GERMAN CREDIT DATASET, over the considered 10 train-test splits. Note how in FPCA’s case, the there’s signiﬁcant “leakage” of explained variance in the latter part (i.e. starting from 11-th eigenvector of P )

C Low Explained Variance of FPCA
C.1 Empirical Exploration
As seen in the Experiments, FPCA generally results in low explained variance than MBF-PCA, when same(similar) level of fairness is achieved. For clarity of exposition, we consider GERMAN CREDIT DATASET with d = 10 and the following hyperparameter settings: τ = 10−3 for MBF-PCA and (δ, µ) = (0, 0.1) for FPCA. The reason for choosing a rather relaxed hyperparameter setting for MBF-PCA is to ensure a fair comparison i.e. to compare the two algorithms under the setting in which they achieve the same level of fairness.
To analyze this phenomenon in a detailed manner, we consider the variance explained of each eigenvector of P ∗, in order of the eigenvalues. Here, P ∗ is the outputted p × p matrix from solving the SDP of FPCA. Figure 6 shows the plots of the explained variance of each eigenvector of P ∗ for FPCA and MBF-PCA, over the considered 10 traintest splits. (Since our algorithm directly outputs the loading matrix V , we simply set P to be V V ) Observe how the order of the eigenvalues do not match the order of explained variance, and the discrepancy is very high.
C.2 Theoretical Exploration
We now give a sketch of theoretical argument of why such phenomenon of misalignment in ordering of eigenvalues of P ∗ and explained variance of each eigenvector of P ∗ may occur. Again, we consider the Gaussian assumption of the data.
7analogous to τ in our approach.

Let Σˆ be positive deﬁnite, and let Σˆ =

p k=1

λk

wk

wk

be its spectral decomposition with λ1 ≥ λ2 ≥ · · · ≥ λp >

0 being the eigenvalues and wk’s being the corresponding

orthonormal eigenvectors.

Also,

d

p

tr V Σˆ V = vl

λkwkwk vl (15)

l=1

k=1

pd

=

λk < vl, wk >2

(16)

k=1 l=1

pd
= λk cos2 θvl,wk (17)

k=1 l=1

where V V = Id, vl is the l-th column of V , and cos θu,v :=< u, v > . Eq. (15) shows that the maximization of tr V Σˆ V can be thought of as a optimization problem
w.r.t. orthonormal v1, . . . , vd, given λk’s and wk’s. For example, with no constraint, the {vl∗}dl=1 such that cos θvl∗,wl = 1 achieve the maximization of tr V Σˆ V and the variances
explained are ordered by the {λl}dl=1, which is precisely Eckart-Young theorem (Eckart and Young 1936).
When the covariance constraint V QV 2 = 0 is imposed on the Eq. (15), we will show the effect of this quadratic constraint to the optimal V ∗. The feasible space on the con-
straint V QV 2 = 0 can be rewritten (Olfat and Aswani 2019): for some ﬁxed ϕ ≥ Q 2, the covariance condition V QV 2 = 0, is equivalent to

max { V QV + ϕId 2, V QV − ϕId 2} − ϕ = 0. (18)

We can write Q =

p k=1

qk sk sk ,

where

qk ’s

and

sk ’s

are

real eigenvalues and real eigenvectors from the spectral decomposition of Q; note that all of them are real due to the symmetry of Q, but since Q is not necessarily positive deﬁnite, qk’s can be negative. On the other hand, by construction, we have that qk + ϕ, −qk + ϕ ≥ 0 for all k’s. Here, recall that for symmetric matrices, spectral norm is equivalent to the largest absolute value of eigenvalues.
Rewriting the LHS of Eq. (18), we have that for either choice of + and −,

p

V (Q ± ϕId)V 2 = (qk ± ϕ)V skskV

k=1

2

p

= max (qk ± ϕ)x V skskV x
x =1 k=1

p
= max (ϕ ± qk) (x V sk)2
x =1 k=1

p
= max (ϕ ± qk) (x V sk)2
x =1 k=1

p
≤ (ϕ ± qk) max (x V sk)2
x =1 k=1

p
= (ϕ ± qk) V sk 2

k=1

p

d

= (ϕ ± qk) cos2 θvl,sk

k=1

l=1

pd

≤ max (ϕ ± qk)

cos2 θv ,s .

k

lk

k=1 l=1

Above and Eq. (18) imply that

ϕ = max { V QV + ϕId 2, V QV − ϕId 2}

≤ max

max (ϕ + qk)
k

pd
cos2 θvl,sk ,
k=1 l=1

max (ϕ − qk)
k

pd
cos2 θvl,sk
k=1 l=1

p
= max {ϕ + q1, ϕ − qp}

d
cos2 θvl,sk

k=1 l=1

p
= (ϕ + max {q1, −qp})

d
cos2 θvl,sk

k=1 l=1

If ϕ+max{ϕq1,−qp} is sufﬁciently large enough, then we would be constraining the sum of square of cosines to be somewhat close to 1 i.e. forcing some of the to-be-found eigenvectors vl’s into directions such that they are somewhat orthogonal to sk’s, the eigenvectors of Q. Such restriction becomes more prominent as d increases. All in all, the presence of the covariance (quadratic) constraint may cause a
misalignment in the ordering of the explained variance of

each loading vector, potentially causing the ordering of the explained variance to be substantially different from the ordering of the eigenvalues.

D Theoretical Minimum
In this section, we provide (minimum) required background for understanding the proofs of propositions/theorems presented in the main paper. All proofs of the results here are deferred to the respective references and therein.

D.1 A Primer on (Matrix) Manifolds, and Stiefel Manifold
Preliminaries (Here, we mainly follow the exposition from the textbook by (Absil, Mahony, and Sepulchre 2007))
Let M be a smooth, ﬁnite-dimensional Riemannian manifold, endowed with a Riemannian metric ·, · x on each tangent space TxM and x ∈ M. Let · x be the associated norm. We omit x when it is clear from context. Let expx be the exponential map at x, and let dist be the Riemannian distance.
Let f : M → R be a smooth function. We ﬁrst consider the gradient of f , deﬁned on manifolds::
Deﬁnition 9. The Riemannian gradient at x ∈ M of f , denoted as grad f (x), is the unique element of TxM such that

∀ξ ∈ TxM grad f (x), ξ x = Df (x)[ξ]

where Df (x)[v] is the directional derivative of f at x along v.
Finding a closed-form of grad may be difﬁcult in some cases. However, if f can be extended to the ambient Euclidean space Rp×d, then grad can be computed as follows:

grad f (x) = PTxM(∇f (x))

(19)

where ∇ is the usual Euclidean gradient, and PTxM is the projection operator onto TxM.

Matrix Manifolds Matrix is a mathematical object of fundamental importance. Often in applications in machine learning and optimization, we are given the task of ﬁnding some matrix satisfying certain conditions, such as orthonnormality, while optimizing some real-valued function of the matrices (Hu et al. 2020). In the perspective of optimization, it is natural to see whether an intrinsic geometric structure can be found in a set of matrices with certain common properties. It turns out that such structures can be characterized by manifold, hence the term matrix manifold.
To start, let us consider Rp×d, a set of all possible realvalued p×d matrices. Along with the Frobenius inner product, deﬁned as X, Y := tr(X Y ), Rn×p can be regarded as a Euclidean space, and thus a Riemannian manifold.
Many of the well-known matrix manifolds are actually embedded Riemannian submanifold of Rp×d i.e. its subspace topology is exactly the given topology on Rp×d . We shall discuss about one speciﬁc matrix manifold that is crucial to our MBF-PCA in the next subsection.

Stiefel Manifold We are mainly concerned with the Stiefel manifold, deﬁned as follows8:

St(p, d) = {V ∈ St(p, d) | V V = Id} (20)
By considering the mapping F (V ) = V V − Id, we can prove the following result:
Theorem 3. St(p, d), deﬁned as above, is an embedded (Riemannian) submanifold of Rp×d .
Now let us look at several properties of St(p, d), many of which prove itself to be effective in both theoretical and practical perspective.
Theorem 4. St(p, d) is (p − d − 1)-connected.
Corollary 4.1. When p > d, St(p, d) is always at least pathconnected, which implies connectedness.
Theorem 5. St(p, d) is compact. Lemma 2. Projection of any X ∈ Rp×d onto TV St(p, d) is given as

PTV St(p,d)(X) = X − V sym(V X)

(21)

where sym(X) = 21 (X + X ).

E Feasibility of Fair PCA
Here, we brieﬂy discuss the feasibility problem of fair PCA. Let us consider Eq. (13), which is a special case of our
formulation of fair PCA under Gaussian assumption. For our analysis, we consider Eq. (13) as a constrained manifold optimization over St(p, d); geometric properties of manifolds turn out to be crucial in obtaining to-be-presented results.
When only the mean constraint is in place i.e. assume that Q = O, then the feasibility of Eq. (13) is always guaranteed:

Proposition 4. If Q = O, then Eq. (13) is always feasible.
Proof. We start by observing that the mean constraint, V f = 0, is a linear hyperplane passing through the origin 0, and the manifold constraint9, V V = Id, is a manifold that is at least path-connected. Now suppose that there exists some f such that the linear hyperplane does not intersect St(p, d). Let V ∈ St(p, d) be on the “left” side of the hyperplane. Since St(p, d) is symmetric about the origin (V V = Id ⇒ (−V ) (−V ) = Id), −V is on the “right” side of the hyperplane. Then there must exist some path on St(p, d) connected V and −V , which should intersect the hyperplane, a contradiction.
When covariance constraint is also in-place, the problem becomes more complex. However, especially in high dimensions, it is expected that the feasibility assumption is not so far-off. As such discussion is not limited to Gaussian case of Eq. (13), from hereon and forth we consider the following assumption:
Assumption 3. Eq. (8) is feasible.
8Another characterization of St(p, d) is as a quotient space of set of d linearly independent p-dimensional vectors.
9In manifold optimization framework, this shouldn’t be considered as an explicit constraint; we use such words here for clarity.

F Proof of Theoretical Guarantee of Algorithm 1

F.1 Assumptions

Let us start by formally stating Assumption 2: for each outputted solution of each Eq. (9), Vk+1, consider the following induced sequence Wk+1 deﬁned as:

Wk+1 := argmin V − Vk+1 .
V ∈St(p,d) gradQ(V,ρk) =0

(22)

Assumption 4 (formal; locality assumption). For each k, Wk+1 is a local minimum of Eq. (9) i.e. for some ﬁxed r > 0, any W ∈ St(p, d) ∩ Br(Wk+1) satisﬁes Q(Wk+1, ρk+1) ≤ Q(W, ρk+1).
For simplicity, we omit the dependency of Wk+1 on Vk+1 and we write k instead of k + 1. Also, let us deﬁne

r˜ = r˜( min) := r − g( min).

(23)

F.2 Lemmas Let us ﬁrst establish the existence of limit point of {Vk}: Lemma 3. {Vk} has at least one limit point.
Proof. Noting that for all k’s Vk ∈ St(p, d), and that St(p, d) is compact i.e. closed and bounded, by Bolzano-Weierstrass theorem, {Vk} must have some limit point, which we denote as V ∈ St(p, d).

Next lemma establishes an important connection between the two mentioned sequences, namely that there exists a limit point of {Wk} that is very close (possibly equal) to V :

Lemma 4. Let V be any limit point of {Vk}. Then there

exists some limit point W of {Wk} and some decreasing,

continuous function g : R≥0 → R≥0 satisfying g(0) = 0,

such that

V − W ≤ g( min).

(24)

Proof. Since Wk ∈ St(p, d) for all k, there exists some
subsequence {ik} ⊂ {k} such that Wik → W for some W ∈ St(p, d), by Bolzano-Weierstrass theorem. Obviously,
Vik → V . For simplicity, let us denote Vik and Wik as Vk and Wk, respectively.
Then we denote

1

V ∈ St(p, d) : gradf (V ) + gradh(V ) ≤

ρk

ρk

(25)

by Gk( ). As ρk < ∞, above is related to Algorithm 1 as

Gk( ) = {V ∈ St(p, d) : gradQ(V, ρk) ≤ } , (26)

where

Q(V, ρk) = f (V ) + ρkh(V ).

(27)

One crucial observation is that Gk( ) ⊆ Gk( ) for ≤ . Let ε > 0 be arbitrary. By given, there exists some K > 0

such that for any k > K, Vk −V < ε/2 and Wk −W < ε/2. By triangle inequality,

V − W ≤ Vk − V + Wk − W + Vk − Wk < ε + Vk − Wk .

We can further bound the second term as follows:

Vk − Wk

= min Vk − W
W ∈Gk(0)
≤ max min V − W
V ∈Gk( k) W ∈Gk(0)

where the ﬁrst equality follows from the deﬁnition of {Wk}, and the last inequality follows from the fact that our algorithm satisﬁes Vk ∈ Gk( k).
Note that since Gk(0) ⊆ Gk( k), above is the variational form of the Hausdorff distance (Rockafellar and Wets 1998) between Gk(0) and Gk( k), which we denote as dH (·, ·). Additionally, we denote

1

V ∈ St(p, d) : gradf (V ) + gradh(V ) ≤ (28)

ρ

ρ

by G∞( ), where ρ := limk→∞ ρk ≤ ρmax ≤ ∞ and ∞1 = 0.
Then it is easy to see that as k → ∞, Gk(0) → G∞(0),

Gk( k) → G∞( min), and G∞(0) ⊂ G∞( min). Now de-

ﬁne

g( ) := dH (G∞(0), G∞( )).

(29)

Then g is continuous and decreasing with respect to since G∞( ) ⊆ G∞( ) for ≤ , and it satisﬁes g(0) = 0.
Since ε > 0 was arbitrary, the statement follows.

Now let us prove the Lipschitzness of the functions considered in our fair PCA:
Lemma 5. f is 2 Σ -Lipschitz.

Proof. For all V, W ∈ St(p, d),

V ΣV − W ΣW ≤ V Σ(V − W ) + (V − W ) ΣW ≤ V Σ V −W + V −W Σ W ≤ 2 Σ V −W .

Lemma 6. There exists some Lh > 0 such that h : St(p, d) → R is Lh-Lipschitz.

Proof. Suppose not. Then for any Lh > 0, there exists some V, W ∈ St(p, d) such that |h(V ) − h(W )| > Lh V − W . Especially for W = V , we have that Lh < |h(VV)−−Wh(w)| . Let-
ting W → V , we have that Lh < |∇V h(V )|. This implies that ∇xh is unbounded on St(p, d), a contradiction since the continuity of ∇V h and compactness of St(p, d) implies that ∇V h is bounded by the Extreme Value theorem.

As done in proof of Lemma 4, let us deﬁne ρ limk→∞ ρk. We now show how ρmax, τ affect ρ:
Lemma 7. ρ = ρ(ρmax, τ ) is characterized as follows: there exists some function K := K(τ ) ∈ N, satisfying K < ∞ for τ > h(V ) and K ≤ ∞ otherwise, such that

ρ = min(θρK ρ0, ρmax).

(30)

Moreover, K is decreasing in τ and increasing in ρmax.

Proof. Deﬁne K(τ ) := |{k ∈ N : h(Vk) > τ }|, which is the number of ρ-updates in the algorithm. From the algorithm, Eq. (30) is directly implied. Now it remains to characterize the function K(τ ).
Let us ﬁrst consider the case of τ > h(V ). Since h(Vk) → h(V ) and h is continuous, it must be that K(τ ) < ∞ by the algorithm, regardless of the other hyperparameters. Now suppose that τ ≤ h(V ). Then there are two cases to consider:

1. If h(VM ) ≤ τ for some M < ∞, then from the algorithm it is clear that K(τ ) ≤ M .
2. If h(Vk) > τ for all k, then again, from the algorithm it is clear that K(τ ) = ∞.

By construction, K(τ ) is decreasing in τ , and thus, ρ is decreasing in τ and increasing in ρmax.

Corollary 5.1. If no k satisﬁes h(Vk) ≤ τ , then ρ = ∞ if and only if ρmax = ∞, τ = 0.
Denote C St(p, d) ∩ h−1(0) as the set of feasible points. By compactness of St(p, d) and continuity of h, we have that C is also compact. By Assumption 3, C is non-empty. Lastly, recall from Eq. (23) r˜ = r − g( min). The last lemma asserts that after sufﬁciently many iterations have passed, the sequences {Vk} and {Wk} are always close to C.
Lemma 8. If V is fair and min is sufﬁciently small in the sense that g( min) < r, then there exists some K > 0 such that for all k > K, Br˜(Vk) ∩ C = ∅ and Br(Wk) ∩ C = ∅.

Proof. First, suppose that for all k, Br˜(Vk) ∩ C = ∅. Taking
the limit of k → ∞ on both sides, we have that V ∈ Br˜(V )∩ C = ∅ by the given assumption, a contradiction. Thus there exists some K1 such that for all k > K1, Br˜(Vk) ∩ C = ∅.
Now suppose that for all k, Br(Wk) ∩ C = ∅. Recall from Lemma 4 that

W − V ≤ g( min) < r

Again taking the limit of k → ∞, we have that V ∈ C ∩ Br(W ) = ∅, a contradiction. Thus there exists some K2 such that for all k > K2, Br(Wk) ∩ C = ∅.
Set K = max(K1, K2), and we are done.

F.3 Proof of Theorem 2

(The proof is inspired from the optimality guarantee for the

Euclidean quadratic penalty method; see Theorem 17.1 of

Nocedal and Wright, 2006) The proof is divided into 3 parts.

Existence of limit point of {Wk}

By Lemma 4, there exists some limit point W of {Wk}

such that V − W ≤ g( min). By considering appropriate

subsequence, let Wk → W .

V is approximate local minimizer of (10)

By Assumption 4, we have that for all W ∈ Br(Wk) ∩

St(p, d),

Q(Wk, ρk) ≤ Q(W, ρk)

(31)

i.e.

f (Wk) + ρkh(Wk) ≤ f (W ) + ρkh(W ). (32)

Rearranging gives

1 h(Wk) ≤ h(W ) + ρk (f (W ) − f (Wk)) (33)

Taking the limit k → ∞ gives

1 h(W ) ≤ h(W ) + f (W ) − f (W )
ρ

2Σ

≤ h(W ) +

W −W ,

ρ

for all W ∈ Br(W ) ∩ St(p, d). By Lemma 4, Br˜(V ) ∩ St(p, d) ⊂ Br(W ) ∩ St(p, d). Thus we have that for all V ∈ Br˜(V ) ∩ St(p, d),

h(V ) ≤ h(W ) + |h(V ) − h(W )|

= h(V ) + h(W ) − h(V ) + Lh V − W

2Σ ≤ h(V ) + ρ V − W + Lh V − W

2Σ ≤ h(V ) +
ρ

V − V + V − W + Lh V − W

2Σ

2Σ

= h(V ) + ρ V − V + Lh + ρ

g( min).

Deﬁne β(ρmax, τ ) := ρ(ρ2mΣax,τ) . By Lemma 7, β indeed satisﬁes limρmax→∞ ρ(ρmax, 0) ≥ 0 and limρmax→∞ ρ(ρmax, τ ) > 0 for τ > 0. Also, by the same lemma, β is indeed decreasing in τ and increasing in ρmax. (Note how this particular part of the proof does not rely on
the assumption that V is feasible!)
If V is fair, then V is an approximate local minimizer
of Eq. (8)
By Lemma 8, we may only consider k’s such that Br˜(Vk) ∩ C = ∅ and Br(Wk) ∩ C = ∅. By Assumption 4, we have that for all W ∈ Br(Wk) ∩ C,

Q(Wk, ρk) ≤ Q(W, ρk)

(34)

i.e.
f (Wk) ≤ f (Wk)+ρkh(Wk) ≤ f (W )+ρkh(W ) = f (W ), (35)
where the last equality follows from W ∈ C. Thus we have that
f (V ) ≤ f (W ) + |f (V ) − f (W )|
≤ lim f (Wk) + 2 Σ V − W
k→∞
≤ f (W ) + 2 Σ g( min),

for all W ∈ Br(Wk) ∩ C. Speciﬁcally, since Br˜(V ) ∩ St(p, d) ⊂ Br(W ) ∩ St(p, d) by Lemma 4, we have that

f (V ) ≤ f (V ) + 2 Σ g( min), for all V ∈ Br˜(V ) ∩ C.

F.4 Proof of Theorem 1
Set min = 0, τ = 0, and ρmax = ∞ in the above proof. (Note that g(0) = 0 implies that V = W ) Just as in proof of Lemma 7, if there exists some M < ∞ such that h(VM ) = 0, then from the algorithm it is clear that V is fair and we are done. If not, then we must have that ρ(∞, 0) = ∞ i.e. β(∞, 0) = 0 i.e. V is a local minimizer of Eq. 10.

G Closed form of ∇V h(V )
In this section, we derive the closed form of the constraint gradient.
First, we recall the lemma that provides a closed form of h(V ) = MMD2(·, ·):

Lemma 1 (Gretton et al., 2007). ∆ is computed as follows:

∆=

1m

1n

m2

k(Xi, Xj) + n2

k(Yi, Yj)

i,j=1

i,j=1

2 m,n

− mn

k(Xi, Yj)

i,j=1

1/2
.
(5)

For simplicity, we use the followin abbreviations: m i,j=1 := m i=1 m j=1 and m i,j,=n1 := m i=1 nj=1.

After squaring both sides, let us refer to the three terms as

h1, h2, and h3 i.e. h(V ) = ∆2 = h1(V ) + h2(V ) − 2h3(V )

where

1m

h1(V ) = m2

k(V Xi, V Xj),

i,j=1

1n

h2(V ) = n2

k(V Yi, V Yj),

i,j=1

1 m,n h3(V ) = mn k(V Xi, V Yj).
i,j=1

G.1 Closed form of ∇V h1(V ) Denote

gij(V ) = tr((Xi − Xj) V V (Xi − Xj)) Kij(V ) = exp −gij(V )/(2σ2) KX (V ) = {Kij(V )} ∈ Rm×m,

and X be the data matrix whose i-th row is Xi . By chain rule, we have that

1m

∇V h1(V ) = − 2m2σ2

Kij (V )∇V gij (V )

i,j=1

1m

= − m2σ2

Kij(V )(Xi − Xj)(Xi − Xj) V

i,j=1

Now denote Hi(V ) =

m j=1

Kij

(V

)

and

HX (V )

=

diag(H1(V ), H2(V ), · · · , Hm(V )), where ‘diag’ is the

block-diagonal operator. We have that





m

m

m

Kij (V )XiXi =  Kij (V ) XiXi

i,j=1

i=1 j=1

= X HX (V )X,

and m

Kij(V )XiXj = X KX (V )X.
i,j=1

Since KX (V ) is symmetric i.e. Kij(V ) = Kji(V ),

m

m

Kij (V )Xj Xj =

Kji(V )XjXj = X HX (V )X,

i,j=1

i,j=1

and
m
Kij (V )Xj Xi
i,j=1

m

=

Kji(V )Xj Xi

i,j=1

=X

KX (V )X.

Thus we have that 2
∇V h1(V ) = − m2σ2 X (HX (V ) − KX (V ))XV.

G.2 Closed form of ∇V h2(V ) The computation is almost exactly the same as above, and thus we only show the ﬁnal result:
2 ∇V h2(V ) = − n2σ2 Y (HY (V ) − KY (V ))Y V, where Y , HY (V ), and KY (V ) are deﬁned analogously.

G.3 Closed form of ∇V h3(V ) Let us overload the notation a bit and now denote

gij(V ) = tr((Xi − Yj) V V (Xi − Yj)), Kij(V ) = exp −gij(V )/(2σ2) , KXY (V ) = {Kij (V )} ∈ Rm×n.

Again by chain rule, we have that

1 m,n

∇V h3(V ) = − 2mnσ2

Kij (V )∇V gij (V )

i,j=1

1 m,n

= − mmσ2

Kij(V )(Xi − Yj)(Xi − Yj) V.

i,j=1

Now, again with a slight notation overload, denote

n

Hi(V ) =

Kij(V ),

j=1

HXY (V ) = diag(H1(V ), H2(V ), · · · , Hm(V )),

m

H˜j(V ) =

Kij(V ),

i=1
H˜XY (V ) = diag(H˜1(V ), H˜2(V ), · · · , H˜n(V )).

We have that
m,n
Kij (V )XiXi
i,j=1





m

n

=  Kij(V ) XiXi

i=1 j=1

= X HXY (V )X,

and
m,n
Kij (V )Yj Yj
i,j=1

n

m

=

Kij (V )

j=1 i=1

= Y H˜XY (V )Y.

Yj Yj

Next, we have that
m,n
Kij (V )XiYj
i,j=1

=X

KXY (V )Y,

and
m,n
Kij(V )YjXi = Y KXY (V ) X.
i,j=1

Thus we have that

1 ∇V h3(V ) = −

X HXY (V )X + Y H˜XY (V )Y

mnσ2

− X KXY (V )Y − Y KXY (V ) X V.

H Description of 2nd Part of Experiment 1
With p0 = 1000 and n = 250, we ﬁrst constructed two different p0-variate Gaussian distributions Np0 (µ(ps0), Σ(ps0)) and sampled n points for each s ∈ {0, 1}. Then for each considered p, we projected the samples by multiplying the constructed data matrices with a Gaussian random matrix of size p0 × p. This creates 18 pairs of p-dimensional distributions. This allowed for us model the situation in which two protected groups have different non-Gaussian distributions.
We now describe how we’ve set µ(ps0) and Σ(ps0) for each s. The mean difference is set as fp0 = µ(p10) − µ(p00) where 2 ∗ fpr0aw/ fpr0aw and fpr0aw = 1. Then µ(p00) is set as 0 and µ(p10) is set as µ(p00) + fp0 .
The covariance difference is set as Qrpaw/ Qrpaw 2 where
Qrpaw = A(p1) − A(p0),

Σ(p0) = diag ARp/5(0.99), ARp/5(0.98), ARp/5(0.97), ARp/5(0.98), ARp/5(0.95) ,
and Σ(p1) = diag ARp/5(0.99), ARp/5(0.98), ARp/5(0.97), ARp/5(0.98), ARp/5(0.99) .
Here, ‘diag’ is the block-diagonal operator, and r|i−j|
ARp/5(r) ij = 1 − r2 , i, j ∈ {1, . . . , p/5} (36)

is the covariance matrix of a p/5-variate Gaussian AR(1) process (Shumway and Stoffer 2017). The r ∈ (0, 1) is a parameter that controls the strength of correlation. Finally, Σ(p0) is set as A(ps)/ Qp .
Due to the scaling, fp = 2 and Qp = 1 for all p. This is to ensure that fp and Qp do not explode as p increases, allowing for us to see the effect of high dimensions more clearly under the “same” fairness setting.
I Description of Experiment 2
Here, we describe the full pre-processing steps for the three UCI datasets considered in this paper. All pre-processing steps were done using AI Fairness 360 (AIF360; Bellamy et al., 2018) built-in functionalities. In our Github repository10. , we include the links for downloading the raw datasets, along with the pre-processing codes.
I.1 COMPAS dataset The raw data was randomly reduced to 40%, resulting in 2468 samples. This was to avoid computational burden in computing the MMD2 metric, as it scales quadratically in number of samples. ’Race’ was set as the protected attribute, and the task is to classify the bank account holders into credit class Good or Bad. The features ‘sex’ and ‘c charge desc’ were dropped, resulting in total of 11 features.
I.2 German credit dataset The total number of samples was 1000. ‘Age’ was set as the protected attribute as done in (Kamiran and Calders 2011), and the task is to classify whether the individual bank account holder has good or bad credit class. The features ‘sex‘ and ‘personal status‘ were dropped, resulting in total of 57 features.
I.3 Adult income dataset The raw data was randomly reduced to 5%, resulting in 2261 samples; this was due to the same reason as the COMPAS dataset. ‘Sex’ was set as the protected attribute as done in (Kamishima, Akaho, and Sakuma 2011), and the task is to indicate whether the individual’s income is larger than 50K dollars. The features ‘fnlwgt‘ and ‘race‘ were dropped, resulting in total of 99 features.
10https://github.com/nick-jhlee/fair-manifold-pca

J Full results for EDA of considered UCI datasets
We show two things:
• Boxplots of communality of the protected attribute of each considered UCI dataset, for both d = 2 and d = 10. (Figures 7, 11, 15)
• PC (d = 2) biplot of each considered UCI dataset, for all considered algorithms. (Figures 8, 9, 10, 12, 13, 14, 16, 17, 18)
Particularly for biplots, one train-test split was chosen, and based on that, only the top 10 features with the highest communalities (+ the sensitive attribute, if it is not included) were chosen for plots.

(a) d = 2

(b) d = 10

Figure 7: Boxplots of communalities of race for COMPAS dataset

Figure 8: PC biplot of PCA for COMPAS dataset

Figure 9: PC biplot of FPCA for COMPAS dataset Figure 10: PC biplot of MBF-PCA for COMPAS dataset

(a) d = 2

(b) d = 10

Figure 11: Boxplots of communalities of age for German credit dataset

Figure 12: PC biplot of PCA for German credit dataset

Figure 13: PC biplot of FPCA for German credit dataset Figure 14: PC biplot of MBF-PCA for German credit dataset

(a) d = 2

(b) d = 10

Figure 15: Boxplots of communalities of gender(sex) for Adult income dataset

Figure 16: PC biplot of PCA for Adult income dataset

Figure 17: PC biplot of FPCA for Adult income dataset Figure 18: PC biplot of MBF-PCA for Adult income dataset

