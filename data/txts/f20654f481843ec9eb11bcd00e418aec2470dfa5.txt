A Piggybacking Design Framework for Read-and Download-efﬁcient Distributed Storage Codes
K. V. Rashmi, Nihar B. Shah, Kannan Ramchandran, Fellow, IEEE Department of Electrical Engineering and Computer Sciences University of California, Berkeley. {rashmikv, nihar, kannanr}@eecs.berkeley.edu

arXiv:1302.5872v1 [cs.IT] 24 Feb 2013

Abstract
We present a new piggybacking framework for designing distributed storage codes that are efﬁcient in dataread and download required during node-repair. We illustrate the power of this framework by constructing classes of explicit codes that entail the smallest data-read and download for repair among all existing solutions for three important settings: (a) codes meeting the constraints of being Maximum-Distance-Separable (MDS), high-rate and having a small number of substripes, arising out of practical considerations for implementation in data centers, (b) binary MDS codes for all parameters where binary MDS codes exist, (c) MDS codes with the smallest repairlocality. In addition, we employ this framework to enable efﬁcient repair of parity nodes in existing codes that were originally constructed to address the repair of only the systematic nodes. The basic idea behind our framework is to take multiple instances of existing codes and add carefully designed functions of the data of one instance to the other. Typical savings in data-read during repair is 25% to 50% depending on the choice of the code parameters.
I. INTRODUCTION
Distributed storage systems today are increasingly employing erasure codes for data storage, since erasure codes provide much better storage efﬁciency and reliability as compared to replication-based schemes [1]–[3]. Frequent failures of individual storage nodes in these systems mandate schemes for efﬁcient repair of failed nodes. In particular, upon failure of a node, it is replaced by a new node, which must obtain the data that was previously stored in the failed node by reading and downloading data from the remaining nodes. Two primary metrics that determine the efﬁciency of repair are the amount of data read at the remaining nodes (termed data-read) and the amount of data downloaded from them (termed data-download or simply the download).

An MDS Code

Intermediate Step

Piggybacked Code

Node 1

a1

b1

a1

b1

a1

b1

Node 2

a2

b2

a2

b2

a2

b2

Node 3

a3

b3

a3

b3

a3

b3

Node 4 Node 5 Node 6

a4 4i=1 ai 4i=1 iai
(a)

b4 4i=1 bi 4i=1 ibi

a4 4i=1 ai 4i=1 iai

b4

4i=1 bi

4 i=1

ibi

+

2i=1 iai

(b)

a4

4i=1 ai

4 i=3

ia

i

−

4i=1 ibi

(c)

b4

4i=1 bi

4 i=1

ibi

+

2i=1 iai

Fig. 1: An example illustrating efﬁcient repair of systematic nodes using the piggybacking framework. Two instances of a (6,4) MDS code are piggybacked to obtain a new (6,4) MDS code that achieves 25% savings in data-read and download in the repair of any systematic node. A highlighted cell indicates a modiﬁed symbol.

2

Node 1

a1

b1

c1

d1

Node 2

a2

b2

c2

d2

Node 3

a3

b3

c3

d3

Node 4 Node 5 Node 6

a4

4i=1 ai

4 i=3

ia

i

−

4i=1 ibi

b4

4i=1 bi

4 i=1

ibi

+

2i=1 iai

c4

4i=1 ci +

4 i=1

ibi

+

2i=1 iai

4 i=3

ici

−

4i=1 idi

d4

4i=1 di

4 i=1

idi

+

2i=1 ici

Fig. 2: An example illustrating of the mechanism of repair of parity nodes under the piggybacking framework, using two instances of the code of Fig. 1c. A shaded cell indicates a modiﬁed symbol.

In this paper, we present a new framework, which we call the piggybacking framework, for design of repairefﬁcient storage codes. In a nutshell, this framework considers multiple instances of an existing code, and the piggybacking operation adds (carefully designed) functions of the data of one instance to the other. We design these functions with the goal of reducing the data-read and download requirements during repair. Piggybacking preserves many of the properties of the underlying code such as the minimum distance and the ﬁeld of operation.

We need to introduce some notation and terminology at this point. Let n denote the number of (storage) nodes

and assume that the nodes have equal storage capacities. The data to be stored across these nodes is termed the

message. A Maximum-Distance-Separable (MDS) code is associated to another parameter k: an [n, k] MDS code

guarantees

that

the

message

can

be

recovered

from

any

k

of

the

n

nodes,

and

requires

a

storage

capacity

of

1 k

of

the size of the message at every node. It follows that an MDS code can tolerate the failure of any (n − k) of the

nodes without suffering any permanent data-loss. A systematic code is one in which k of the nodes store parts of

the message without any coding. These k nodes are termed the systematic nodes and the remaining (n − k) nodes

are termed the parity nodes. We denote the number of parity nodes by r = (n − k). We shall assume without loss

of generality that in a systematic code, the ﬁrst k nodes are systematic. The number of substripesof a (vector) code

is deﬁned as the length of the vector of symbols that a node stores in a single instance of the code.

The piggybacking framework offers a rich design space for constructing codes for various different settings. We illustrate the power of this framework by providing the following four classes of explicit code constructions in this paper.

(Class 1) A class of codes meeting the constraints of being MDS, high-rate, and having a small number of substripes, with the smallest known average data-read for repair: A major component of the cost of current day data-centers which store enormous amounts of data is the storage hardware. This makes it critical for any storage code to minimize the storage space utilization. In light of this, it is important for the erasure code employed to be MDS and have a high-rate (i.e., a small storage overhead). In addition, practical implementations also mandate a small number of substripes. There has recently been considerable work on the design of distributed storage codes with efﬁcient data-read during repair [4]–[26]. However, to the best of our knowledge, the only explicit codes that meet the aforementioned requirements are the Rotated-RS [8] codes and the (repair-optimized) EVENODD [25], [27] and RDP [26], [28] codes. Moreover, Rotated-RS codes exist only for r ∈ {2, 3} and k ≤ 36; the (repairoptimized) EVENODD and RDP codes exist only for r = 2. Through our piggybacking framework, we construct a class of codes that are MDS, high-rate, have a small number of substripes, and require the least amount of data-read and download for repair among all other known codes in this class. An appealing feature of our codes is that they support all values of the system parameters n and k.

(Class 2) Binary MDS codes with the lowest known average data-read for repair, for all parameters where binary MDS codes exist: Binary MDS codes are extensively used in disk arrays [27], [28]. Through our piggybacking framework, we construct binary MDS codes that require the lowest known average data-read for repair among all

3

existing binary MDS codes [8], [25]–[29]. Furthermore, unlike the other codes and repair algorithms [8], [25]–[29] in this class, the codes constructed here also optimize the repair of parity nodes (along with that of systematic nodes). Our codes support all the parameters for which binary MDS codes are known to exist.

(Class 3) Efﬁcient repair MDS codes with smallest possible repair-locality: Repair-locality is the number of nodes that need to be read during repair of a node. While several recent works [20]–[23] present codes optimizing on locality, these codes are not MDS and hence require additional storage overhead for the same reliability levels as MDS codes. In this paper, we present MDS codes with efﬁcient repair properties that have the smallest possible repair-locality for an MDS code.

(Class 4) A method of reducing data-read and download for repair of parity nodes in existing codes that address only the repair of systematic nodes: The problem of efﬁcient node-repair in distributed storage systems has attracted considerable attention in the recent past. However, many of the codes proposed [7]–[9], [19], [30] have algorithms for efﬁcient repair of only the systematic nodes, and require the download of the entire message for repair of any parity node. In this paper, we employ our piggybacking framework to enable efﬁcient repair of parity nodes in these codes, while also retaining the efﬁciency of repair of systematic nodes. The corresponding piggybacked codes enable an average saving of 25% to 50% in the amount of download and read required for repair of parity nodes.

The following examples highlight the key ideas behind the piggybacking framework.

Example 1: This example illustrates one method of piggybacking for reducing data-read during systematic node

repair. Consider two instances of a (6, 4) MDS code as shown in Fig. 1a, with the 8 message symbols {ai}4i=1

and {bi}4i=1 (each column of Fig. 1a depicts a single instance of the code). One can verify that the message can

be recovered from the data of any 4 nodes. The ﬁrst step of piggybacking involves adding

2 i=1

iai

to

the

second

symbol of node 6 as shown in Fig. 1b. The second step in this construction involves subtracting the second symbol

of node 6 in the code of Fig. 1b from its ﬁrst symbol. The resulting code is shown in Fig. 1c. This code has 2

substripes (the number of columns in Fig. 1c).

We now present the repair algorithm for the piggybacked code of Fig. 1c. Consider the repair of node 1. Under

our repair algorithm, the symbols b2, b3, b4 and

4 i=1

bi

are

download

from

the

other

nodes,

and

b1

is

decoded.

In addition, the second symbol (

4 i=1

ibi

+

2 i=1

iai)

of

node

6

is

downloaded.

Subtracting

out

the

components

of

{bi}4i=1 gives the piggyback

2 i=1

iai.

Finally,

the

symbol

a2

is

downloaded

from

node

2

and

subtracted

to

obtain

a1. Thus, node 1 is repaired by reading only 6 symbols which is 75% of the total size of the message. Node 2 can

be repaired in a similar manner. Repair of nodes 3 and 4 follows on similar lines except that the ﬁrst symbol of

node 6 is read instead of the second.

The piggybacked code is MDS, and the entire message can be recovered from any 4 nodes as follows. If node 6

is one of these four nodes, then add its second symbol to its ﬁrst, to recover the code of Fig. 1b. Now, the decoding

algorithm of the original code of Fig, 1a is employed to ﬁrst recover {ai}4i=1, which then allows for removal of

the piggyback (

2 i=1

iai)

from

the

second

substripe,

making

the

remainder

identical

to

the

code

of

Fig.

1c.

Example 2: This example illustrates the use of piggybacking to reduce data-read during the repair of parity

nodes. The code depicted in Fig. 2 takes two instances of the code of Fig. 1c, and adds the second symbol of node

6, (

4 i=1

ibi

+

2 i=1

iai)

(which

belongs

to

the

ﬁrst

instance),

to

the

third

symbol

of

node

5

(which

belongs

to

the

second instance). This code has 4 substripes (the number of columns in Fig. 2). In this code, repair of the second

parity

node

involves

downloading

{a

i

,

ci

,

di

}

4 i=1

and

the

modiﬁed

symbol

(

4 i=1

ci

+

4 i=1

ibi

+

2 i=1

iai),

using

which the data of node 6 can be recovered. The repair of the second parity node thus requires read and download

of only 13 symbols instead of the entire message of size 16. The ﬁrst parity is repaired by downloading all 16

message symbols. Observe that in the code of Fig. 1c, the ﬁrst symbol of node 5 is not used for repair of any of

the systematic nodes. Thus the modiﬁcation in Fig. 2 does not change the algorithm or the efﬁciency of the repair

of systematic nodes. The code retains its MDS property: the entire message can be recovered from any 4 nodes by

4

ﬁrst decoding {ai, bi}4i=1 using the decoding algorithm of the code of Fig. 1a, which then allows for removal of the

piggyback (

4 i=1

ibi

+

2 i=1

iai)

from

the

second

instance,

making

the

remainder

identical

to

the

code

of

Fig.

1a.

Our piggybacking framework, enhances existing codes by adding piggybacks from one instance onto the other. The design of these piggybacks determine the properties of the resulting code. In this paper, we provide a few designs of piggybacking and specialize it to existing codes to obtain the four speciﬁc classes mentioned above. This framework, while being powerful, is also simple, and easily amenable for code constructions in other settings and scenarios.

The rest of the paper is organized as follows. Section II introduces the general piggybacking framework. Sections III and IV then present code designs and repair-algorithms based on this framework, special cases of which result in classes 1 and 2 discussed above. Section V provides piggyback design which result in low-repair locality along with low data-read and download. Section VI provides a comparison of these codes and various other codes in the literature. Section VII demonstrates the use of piggybacking to enable efﬁcient parity repair in existing codes that were originally constructed for repair of only the systematic nodes. Section VIII draws conclusions.

Readers interested only in repair locality may skip Sections III and IV, and readers interested only in the mechanism of imbibing efﬁcient parity-repair in existing codes optimized for systematic-repair may skip Sections III, IV, and V without any loss in continuity.

II. THE PIGGYBACKING FRAMEWORK
The piggybacking framework operates on an existing code, which we term the base code. The choice of the base code is arbitrary. The base code is associated to n encoding functions {fi}ni=1: it takes the message u as input and encodes it to n coded symbols {f1(u), . . . , fn(u)}. Node i (1 ≤ i ≤ n) stores the data fi(u).
The piggybacking framework operates on multiple instances of the base code, and embeds information about one instance into other instances in a speciﬁc fashion. Consider α instances of the base code. The encoded symbols in α instances of the base code are

Node 1
...

f1(a) f1(b) ··· f1(z)

...

...

...

...

Node n fn(a) fn(b) ··· fn(z) where a, . . . , z are the (independent) messages encoded under these α instances.
We shall now describe the piggybacking of this code. For every i, 2 ≤ i ≤ α, one can add an arbitrary function of the message symbols of all previous instances {1, . . . , (i−1)} to the data stored under instance i. These functions are termed piggyback functions, and the values so added are termed piggybacks. Denoting the piggyback functions by gi,j (i ∈ {2, . . . , α}, j ∈ {1, . . . , n}), the piggybacked code is thus:

Node 1
...

f1(a) f1(b) + g2,1(a) f1(c) + g3,1(a,b) ··· f1(z) + gα,1(a,...,y)

...

...

...

...

...

Node n fn(a) fn(b) + g2,n(a) f1(c) + g3,n(a,b) ··· fn(z) + gα,n(a,...,y)
The decoding properties (such as the minimum-distance or the MDS nature) of the base code are retained upon piggybacking. In particular, the piggybacked code allows for decoding of the entire message from any set of nodes from which the base code allowed decoding. To see this, consider any set of nodes from which the message can be recovered in the base code. Observe that the ﬁrst column of the piggybacked code is identical to a single instance of the base code. Thus a can be recovered directly using the decoding procedure of the base code. The piggyback functions {g2,i(a)}ni=1 can now be subtracted from the second column. The remainder of this column

5

is precisely another instance of the base code, allowing recovery of b. Continuing in the same fashion, for any instance i (2 ≤ i ≤ n), the piggybacks (which are always a function of previously decoded instances {1, . . . , i − 1}) can be subtracted out to obtain the base code of that instance which can be decoded.

The decoding properties of the code are thus not hampered by the choice of the piggyback functions gi,j’s. This allows for ﬂexibility in the choice of the piggyback functions, and these need to be picked cleverly to achieve the desired goals (such as efﬁcient repair, which is the focus of this paper).

The piggybacking procedure described above was followed in Example 1 to obtain the code of Fig. 1b from Fig. 1a. Subsequently, in Example 2, this procedure was followed again to obtain the code of Fig. 2 from Fig. 1c.

The piggybacking framework also allows any invertible linear transformation of the data stored in any individual node. In other words, each node of the piggybacked code (e.g., each row in Fig. 1b) can separately undergo a invertible transformation. Clearly, any invertible transformation of data within the nodes does not alter the decoding capabilities of the code, i.e., the message can still be recovered from any set of nodes from which it could be recovered in the base code. In Example 1, the code of Fig. 1c is obtained from Fig. 1b via an invertible transformation of the data of node 6.

The following theorem formally proves that piggybacking does not reduce the amount of information stored in any subset of nodes.

Theorem 1: Let U1, . . . , Uα be random variables corresponding to the messages associated to the α instances

of the base code. For i ∈ {1, . . . , n}, let Xi denote the data stored in node i under the base code. Let Yi denote

the encoded symbols stored in node i under the piggybacked version of that code. Then for any subset of nodes

S ⊆ {1, . . . , n},

I {Yi}i∈S ; U1, . . . , Uα ≥ I {Xi}i∈S ; U1, . . . , Uα .

(1)

The proof of this theorem is provided in the appendix.

Corollary 2: Piggybacking a code does not decrease its minimum distance; piggybacking an MDS code preserves the MDS property.

Notational Conventions: For simplicity of exposition, we shall assume throughout this section that the base

codes are linear, scalar, MDS and systematic. Using vector codes (such as EVENODD or RDP) as base codes is a

straightforward extension. The base code operates on a k-length message vector, with each symbol of this vector

drawn from some ﬁnite ﬁeld. The number of instances of the base code during piggybacking is denoted by α, and

{a, b, . . .} shall denote the k-length message vectors corresponding to the α instances. Since the code is systematic,

the ﬁrst k nodes store the elements of the message vector. We use p1, . . . , pr to denote the r encoding vectors

corresponding to the r parity symbols, i.e., if a denotes the k-length message vector then the r parity nodes under

the

base

code

store

p

T 1

a

,

.

.

.

,

p

T r

a

.

The transpose of a vector or a matrix will be indicated by a superscript T . Vectors are assumed to be column vectors. For any vector v of length κ, we denote its κ elements as v = [v1 · · · vκ]T , and if the vector itself has an associated subscript then we its elements as vi = [vi,1 · · · vi,κ]T .

Each of the explicit codes constructed in this paper possess the property that the repair of any node entails reading of only as much data as what has to be downloaded. 1 This property is called repair-by-transfer [24]. Thus the amounts of data-read and download are equal under our codes, and hence we shall use the same notation γ to denote both these quantities.

1In general, the amount of download lower bounds the amount of read, and the download could be strictly smaller if a node passes a (non-injective) function of the data that it stores.

6
III. PIGGYBACKING DESIGN 1
In this section, we present our ﬁrst design of piggyback functions and associated repair algorithms. This design allows one to reduce data-read and download during repair while having a small number of substripes. For instance, when the number of substripes is is small as 2, we can achieve a 25 to 35% savings during repair of systematic nodes. We shall ﬁrst present the piggyback design for optimizing the repair of systematic nodes, and then move on to the repair of parity nodes.

A. Efﬁcient repair of systematic nodes

This design operates on α = 2 instances of the base code. We ﬁrst partition the k systematic nodes into r

sets, S1, . . . , Sr. of equal size (or nearly equal size if k is not a multiple of r). For ease of understanding, let

us

assume

that

k

is

a

multiple

of

r,

which

ﬁxes

the

size

of

each

of

these

sets

as

kr .

Then,

let

S1

=

{1,

.

.

.

,

k r

},

S2 = { kr + 1, . . . , 2rk } and so on, with Si = { (i−r1)k + 1, . . . , irk } for i = 1, . . . , r.

Deﬁne the following k−length vectors:

q2 = [ pr,1 · · · pr, k

0 ···

···

···

r

q3 = [ 0 · · · 0 pr, k +1 · · · pr, 2k

0 ···

···

r

r

...

··· 0

]T

··· 0

]T

qr = [ 0 · · ·

···

qr+1 = [ 0 · · ·

···

Also, let

··· 0 ···

pr, k (r−2)+1 · · · pr, k (r−1)

0 ··· 0

]T

r

r

··· 0

pr, k (r−1)+1 · · · pr,k ]T . r

vr = pr − qr

= [ pr,1 · · ·

···

· · · pr, k (r−2)

r

0 ··· 0

pr, k (r−1)+1 · · · pr,k ]T . r

Note that each element pi,j is non-zero since the base code is MDS. We shall use this property during repair

operations.

The base code is piggybacked in the following manner:

Node 1
...
Node k Node k+1 Node k+2
...
Node k+r

a1

b1

...

...

ak

bk

p

T 1

a

p

T 2

a

...

p

T 1

b

pT2 b + qT2 a
...

p

T r

a

pTr b + qTr a

Fig. 1b depicts an example of such a piggybacking.
We shall now perform an invertible transformation of the data stored in node (k + r). In particular, the ﬁrst symbol of node (k + r) in the code above is replaced with the difference of this symbol from its second symbol, i.e., node (k + r) now stores

7

Node k+r vrT a − pTr b pTr b + qTr a

The other symbols in the code remain intact. This completes the description of the encoding process.

Next, we present the algorithm for repair of any systematic node (∈ {1, . . . , k}). This entails recovery of the two symbols a and b from the remaining nodes.

Case 1 ( ∈/ Sr): Without loss of generality let ∈ S1. The k symbols {b1, . . . , b −1, b +1, . . . , bk, pT1 b} are downloaded from the remaining nodes, and the entire vector b is decoded (using the MDS property of the base

code). It now remains to recover a . Observe that the

th

element

of

q2

is

non-zero.

The

symbol

(

p

T 2

b

+

q

T 2

a)

is

downloaded from node (k + 2), and since b is completely known, pT2 b is subtracted from the downloaded symbol

to

obtain

the

piggyback

q

T 2

a

.

The

symbols

{ai}i∈S1\{

}

are

also

downloaded

from

the

other

systematic

nodes

in

set S1. The speciﬁc (sparse) structure of q2 allows for recovering a from these downloaded symbols. Thus the

total data-read and download during the repair of node

is

(k

+

k r

)

(in

comparison,

the

size

of

the

message

is

2k).

Case

2

(S

=

Sr ):

As

in

the

previous

case,

b

is

completely

decoded

by

downloading

{b1, . . . , b

−1, b

+1, . . . , bk,

p

T 1

b

}

.

The

ﬁrst

symbol

(v

T r

a

−

p

T r

b

)

of

node

(k

+

r)

is

downloaded.

The

second

symbols

{

p

T i

b

+

q

T i

a}

i

stored

in

the

parities i ∈ {(k + 2), . . . , (k + r − 1)} are also downloaded, and are then subtracted from the ﬁrst symbol of node

(k + r). This gives (qTr+1a + wT b) for some vector w. Using the previously decoded value of b, vT b is removed

to obtain qTr+1a. Observe that the th element of qr+1 is non-zero. The desired symbol a can thus be recovered by

downloading {a k (r−1)+1, . . . , a −1, a +1, . . . , ak} from the other systematic nodes in Sr. The total data-read and

r

download required in recovering node

is

(k

+

k r

+

r

−

2).

Observe that the repair of systematic nodes in the last set Sr requires more read and download as compared to

repair of systematic nodes in the other sets. Given this observation, we do not choose the sizes of the sets to be

equal (as described previously), and instead optimize the sizes to minimize the average read and download required.

For i = 1, . . . , r, denoting the size of the set Si by ti, the optimal sizes of the sets turn out to be

k r−2 t1 = · · · = tr−1 = r + 2r := t, (2)

tr = k − (r − 1)t .

(3)

The amount of data read and downloaded for repair of any systematic node in the ﬁrst (r − 1) sets is (k + t), and the last set is (k + tr + r − 2). Thus, the average data-read and download γ1sys for repair of systematic nodes, as a fraction of the total number 2k of message symbols, is
γ1sys = 21k2 [(k − tr) (k + t) + tr (k + tr + r − 2)] . (4) This quantity is plotted in Fig. 5a for various values of the system parameters n and k.

B. Reducing data-read during repair of parity nodes
We shall now piggyback the code constructed in Section III-A to introduce efﬁciency in the repair of parity nodes, while also retaining the efﬁciency in the repair of systematic nodes. Observe that in the code of Section III-A, the ﬁrst symbol of node (k + 1) is never read for repair of any systematic node. We shall add piggybacks to this unused parity symbol to aid in the repair of other parity nodes.
This design employs m instances of the piggybacked code of Section III-A. The number of substripes in the resultant code is thus 2m. The choice of m can be arbitrary, and higher values of m result in greater repair-efﬁciency. For every instance i ∈ {2, 4, . . . , 2m − 2}, the (r − 1) parity symbols in nodes (k + 2) to (k + r) are summed up. The result is added as a piggyback to the (i + 1)th symbol of node (k + 1). The resulting code, when m = 2, is shown below.

8

Node 1

a1

b1

c1

d1

...

...

...

...

...

Node k

ak

Node k+1

pT1 a

Node k+2
...

pT2 a
...

bk

p

T 1

b

pT2 b + qT2 a
...

pT1 c +

ck

ri=2(pTi b + qTi a)

p

T 2

c

...

dk

p

T 1

d

pT2 d + qT2 c
...

Node k+r-1 Node k+r

pTr−1a vrT a − pTr b

pTr−1b + qTr−1a pTr b + qTr a

pTr−1c vrT c − pTr d

pTr−1d + qTr−1c pTr d + qTr c

This completes the encoding procedure. The code of Fig. 2 is an example of this design.
As shown in Section II, the piggybacked code retains the MDS property of the base code. In addition, the repair of systematic nodes is identical to the that in the code of Section III-A, since the symbol modiﬁed in this piggybacking was never read for the repair of any systematic node in the code of Section III-A.
We now present an algorithm for efﬁcient repair of parity nodes under this piggyback design. The ﬁrst parity node is repaired by downloading all 2mk message symbols from the systematic nodes. Consider repair of some other parity node, say node ∈ {k + 2, . . . , k + r}. All message symbols a, c, . . . in the odd substripes are downloaded from the systematic nodes. All message symbols of the last substripe (e.g., message d in the m = 2 code shown above) are also downloaded from the systematic nodes. Further, the {3rd, 5th, . . . , (2m − 1)th} symbols of node (k + 1) (i.e., the symbols that we modiﬁed in the piggybacking operation above) are also downloaded, and the components corresponding to the already downloaded message symbols are subtracted out. By construction, what remains in the symbol from substripe i (∈ {3, 5, . . . , 2m − 1}) is the piggyback. This piggyback is a sum of the parity symbols of the substripe (i − 1) from the last (r − 1) nodes (including the failed node). The remaining (r − 2) parity symbols belonging to each of the substripes {2, 4, . . . , 2m − 2} are downloaded and subtracted out, to recover the data of the failed node. The procedure described above is illustrated via the repair of node 6 in Example 2.
The average data-read and download γ1par for repair of parity nodes, as a fraction of the total message symbols, is
γ1par = 2k1r 2k + (r − 1) 1 + m1 k + 1 − m1 (r − 1) .
This quantity is plotted in Fig. 5b for various values of the system parameters n and k.

IV. PIGGYBACKING DESIGN 2
The design presented in this section provides a higher efﬁciency of repair as compared to the previous design. On the downside, it requires a larger number of substripes: the minimum number of substripes required under the design of Section III-A is 2 and under that of Section III-B is 4, while that required in the design of this section is (2r − 3). The following example illustrates this piggybacking design.
Example 3: Consider some (n = 13, k = 10) MDS code as the base code, and consider α = (2r − 3) = 3 instances of this code. Divide the systematic nodes into two sets of sizes 5 each as S1 = {1, . . . , 5} and S2 =

9

{6, . . . , 10}. Deﬁne 10-length vectors q2, v2, q3 and v3 as q2 = [p2,1 · · · p2,5 v2 = [0 · · · 0 q3 = [0 · · · 0 v3 = [p3,1 · · · p3,5

0 · · · 0] p2,6 · · · p2,10] p3,6 · · · p3,10] 0 · · · 0]

Now piggyback the base code in the following manner

Node 1 a1

b1

c1

...

...

...

...

Node 10 Node 11 Node 12 Node 13

a10

p

T 1

a

p

T 2

a

p

T 3

a

b10

p

T 1

b

pT2 b + qT2 a

pT3 b + qT3 a

c10

p

T 1

c

pT2 c + qT2 b + qT2 a

pT3 c + qT3 b + qT3 a

Next, we take invertible transformations of the (respective) data of nodes 12 and 13. The second symbol of node i ∈ {12, 13} in the new code is the difference between the second and the third symbols of node i in the code above. The fact that (p2 − q2) = v2 and (p3 − q3) = v3 results in the following code

Node 1 a1

b1

c1

...

...

...

...

Node 10 Node 11 Node 12 Node 13

a10 pT1 a pT2 a pT3 a

b10

p

T 1

b

v2T b − pT2 c

v3T b − pT3 c

c10

p

T 1

c

pT2 c + qT2 b + qT2 a

pT3 c + qT3 b + qT3 a

This completes the encoding procedure.

We

now

present

an

algorithm

for

(efﬁcient)

repair

of

any

systematic

node,

say

node

1.

The

10

symbols

{c2, . . . , c10,

p

T 1

c

}

are

downloaded,

and

c

is

decoded.

It

now

remains

to

recover

a1

and

b1.

The

third

symbol

(p

T 2

c

+

q

T 2

b

+

q

T 2

a)

of node 12 is downloaded and pT2 c subtracted out to obtain (qT2 b + qT2 a). The second symbol (v3T b − pT3 c) from

node 13 is downloaded and (−pT3 c) is subtracted out from it to obtain v3T b. The speciﬁc (sparse) structure of q2

and

v3

allows

for

decoding

a1

and

b1

from

(q

T 2

b

+

q

T 2

a

)

and

v

T 3

b

,

by

downloading

and

subtracting

out

{ai}5i=2

and {bi}5i=2. Thus, the repair of node 1 involved reading and downloading 20 symbols (in comparison, the size of

the message is kα = 30). The repair of any other systematic node follows a similar algorithm, and results in the

same amount of data-read.

The general design is as follows. Consider (2r − 3) instances of the base code, and let a1, . . . a2r−3 be the

messages associated to the respective instances. First divide the k systematic nodes into (r − 1) equal sets (or

nearly equal sets if k is not a multiple of (r − 1)). Assume for simplicity of exposition that k is a multiple of

(r − 1).

The

ﬁrst

of

the

k r−1

sets

consist

of

the

ﬁrst

k r−1

nodes,

the

next

set

consists

of

the

next

k r−1

nodes

and

so

on. Deﬁne k-length vectors {vi, vˆi}ri=2 as

vi = ar−1 + iar−2 + i2ar−3 + · · · + ir−2a1

vˆi = vi − ar−1 = iar−2 + i2ar−3 + · · · + ir−2a1 .

10

Further, deﬁne k-length vectors {qi,j}ri=,r2−,j1=1 as

0



 ... 

0





1



 qi,j = 

...

  pi







1





0



... 

0

where the positions of the ones on the diagonal of the (k × k) diagonal matrix depicted correspond to the nodes

in the jth group. It follows that
r−1

qi,j = pi ∀ i ∈ {2, . . . r} .

j=1

Parity node (k + i), i ∈ {2, . . . , r}, is then piggybacked to store

pTi a1 ··· pTi ar−2 pTi ar−1 + rj=−11,j=i−1qTi,j vˆi pTi ar +qTi,1vi ··· pTi ar+i−3 +qTi,i−2vi pTi ar +qTi,ivi ··· pTi a2r−3 +qTi,r−1vi

Following this, an invertible linear combination is performed at each of the nodes {k + 2, . . . , k + r}. The transform subtracts the last (r−2) substripes from the (r−1)th substripe, following which the node (k+i), i ∈ {2, . . . , r}, stores

pTi a1 ··· pTi ar−2 qTi,i−1ar−1 −

2r− j=r

3

p

T i

a

j

p

T i

a

r

+

q

T i,

1

v

i

···

p

T i

a

r

+

i

−

3

+

q

T i,i

−2

v

i

pTi

ar

+

q

T i,i

v

i

···

p

T i

a2r

−3

+

q

T i,r

−

1

v

i

Let us now see how repair of a systematic node is performed. Consider repair of node . First, from nodes {1, . . . , k + 1}\{ }, all the data in the last (r − 2) substripes is downloaded and the data ar, . . . , a2r−3 is recovered. This also provides us with the desired data {ar, , . . . , a2r−3, }. Next, observe that in each parity node {k+2, . . . , k+ r}, there is precisely one ‘q’ vector that has a non-zero ﬁrst component. From each of these nodes, the symbol having this vector is downloaded, and the components along {ar, . . . , a2r−3} are subtracted out. Further, we download all symbols from all other systematic nodes in the same set as node , and subtract this out from the previously downloaded symbols. This leaves us with (r − 1) independent linear combinations of {a1, , . . . , ar−1, } from which the desired data is decoded.

When k is not a multiple of (r − 1), the k systematic nodes are divided into (r − 1) sets as follows. Let

k

k

t = r − 1 , th = r − 1 , t = (k − (r − 1)t ) . (5)

The ﬁrst t sets are chosen of size th each and the remaining (r − 1 − t) sets have size t each. The systematic symbols in the ﬁrst (r − 1) substripes are piggybacked onto the parity symbols (except the ﬁrst parity) of the last

(r − 1) stripes. For repair of any failed systematic node ∈ {1, . . . , k}, the last (r − 2) substripes are decoded

completely by reading the remaining systematic and the ﬁrst parity symbols from each. To obtain the remaining

(r − 1) symbols of the failed node, the (r − 1) parity symbols that have piggyback vectors (i.e., q’s and v’s) with a non-zero value of the th element are downloaded. By design, these piggyback vectors have non-zero components

only along the systematic nodes in the same set as node . Downloading and subtracting these other systematic

symbols gives the desired data.

The average data-read and download γ2sys for repair of systematic nodes, as a fraction of the total message symbols 2k, is
γ2sys = 21k2 [t((r − 2)k + (r − 1)th) + (k − t)((r − 2)k + (r − 1)t )] . (6) This quantity is plotted in Fig. 5a for various values of the system parameters n and k.

11
While we only discussed the repair of systematic nodes for this code, the repair of parity nodes can be made efﬁcient by considering m instances of this code. A procedure analogous to that described in Section III-B is followed, where the odd instances are piggybacked on to the succeeding even instances. As in Section III-B, higher a value of m results in a lesser amount of data-read and download for repair. In such a design, the average data-read and download γ2par for repair of parity nodes, as a fraction of the total message symbols, is
γ2par = 1r + 2rr−−13 (m + 1)(r − 2)k + (m − 1)(r − 2)(r − 1) + m2 k + m2 (r − 1) . (7) This quantity is also plotted in Fig. 5b for various values of the system parameters n and k.
V. PIGGYBACKING DESIGN 3
In this section, we present a piggybacking design to construct MDS codes with a primary focus on the locality of repair. The locality of a repair operation is deﬁned as the number of nodes that are contacted during the repair operation. The codes presented here perform the efﬁcient repair of any systematic node with the smallest possible locality for any MDS code, which is equal to (k + 1). 2 The amount of read and download is the smallest among all known MDS codes with this locality, when (n − k) > 2.
This design involves two levels of piggybacking, and these are illustrated in the following two example constructions. The ﬁrst example considers α = 2m instances of the base code and shows the ﬁrst level of piggybacking, for any arbitrary choice of m > 1. Higher values of m result in repair with a smaller read and download. The second example uses two instances of this code and adds the second level of piggybacking. We note that this design deals with the repair of only the systematic nodes.
Example 4: Consider any (n = 11, k = 8) MDS code as the base code, and take 4 instances of this code. Divide the systematic nodes into two sets as follows, S1 = {1, 2, 3, 4}, S2 = {5, 6, 7, 8}. We then add the piggybacks as shown in Fig. 3. Observe that in this design, the piggybacks added to an even substripe is a function of symbols in its immediately previous (odd) substripe from only the systematic nodes in the ﬁrst set S1, while the piggybacks added to an odd substripe are functions of symbols in its immediately previous (even) substripe from only the systematic nodes in the second set S2.
2A locality of k is also possible, but this necessarily mandates the download of the entire data, and hence we do not consider this option.

Node 1 a1

b1

c1

d1

...

...

...

...

...

Node 4 a4

b4

c4

d4

Node 5 a5

b5

c5

d5

...

...

...

...

...

Node 8 Node 9 Node 10 Node 11

a8

p

T 1

a

p

T 2

a

p

T 3

a

b8

p

T 1

b

pT2 b+a1 + a2

pT3 b+a3 + a4

c8

p

T 1

c

pT2 c+b5 + b6

pT3 c+b7 + b8

d8

p

T 1

d

pT2 d+c1 + c2

pT3 d+c3 + c4

Fig. 3: Example illustrating ﬁrst level of piggybacking in design 3. The piggybacks in the even substripes (in blue) are a function of only the systematic nodes {1, . . . , 4} (also in blue), and the piggybacks in odd substripes (in green) are a function of only the systematic nodes {5, . . . , 8} (also in green). This code requires an average data-read and download of only 71% of the message size for repair of systematic nodes.

12

We now present the algorithm for repair of any systematic node. First consider the repair of any systematic

node

∈ {1, . . . , 4} in the ﬁrst set. For instance, say

=

1,

then

{b2, . . . , b8,

pT1 b}

and

{d2, . . . , d8,

p

T 1

d}

are downloaded, and {b, d} (i.e., the messages in the even substripes) are decoded. It now remains to recover

the symbols a1 and c1 (belonging to the odd substripes). The second symbol (pT2 b + a1 + a2) from node 10 is downloaded and pT2 b subtracted out to obtain the piggyback (a1 + a2). Now a1 can be recovered by downloading and subtracting out a2. The fourth symbol from node 10, (pT2 d + c1 + c2), is also downloaded and pT2 d subtracted
out to obtain the piggyback (c1 + c2). Finally, c1 is recovered by downloading and subtracting out c2. Thus, node

1 is repaired by by reading a total of 20 symbols (in comparison, the total total message size is 32). The repair

of node 2 can be carried out in an identical manner. The two other nodes in the ﬁrst set, nodes 3 and 4, can be

repaired in a similar manner by reading the second and fourth symbols of node 11 which have their piggybacks.

Thus, repair of any node in the ﬁrst group requires reading and downloading a total of 20 symbols.

Now we consider the repair of any node ∈ {5, . . . , 8} in the second set S2. For instance, consider = 5.

The symbols

a1, . . . , a8, pT1 a

\{a5},

c1, . . . , c8, pT1 c

\{c5} and

d1, . . . , d8,

p

T 1

d

\{d5} are downloaded in

order

to

decode

a5, c5,

and

d5.

From

node

10,

the

symbol

(pT2 c

+

b5

+

b6)

is

downloaded

and

p

T 2

c

is

subtracted

out. Then, b5 is recovered by downloading and subtracting out b6. Thus, node 5 is recovered by reading a total of

26 symbols. Recovery of other nodes in S2 follows on similar lines.

The average amount of data read and downloaded during the recovery of systematic nodes is 23, which is 71% of the message size. A higher value of m (i.e., a higher number of substripes) would lead to a further reduction in the read and download (the last substripe cannot be piggybacked and hence mandates a greater read and download; this is a boundary case, and its contribution to the overall read reduces with an increase in m).

Example 5: In this example, we illustrate the second level of piggybacking which further reduces the amount of data-read during repair of systematic nodes as compared to Example 4. Consider α = 8 instances of an (n = 13, k = 10) MDS code. Partition the systematic nodes into three sets S1 = {1, . . . , 4}, S2 = {5, . . . , 8}, S3 = {9, 10} (for readers having access to Fig. 4 in color, these nodes are coloured blue, green, and red respectively). We ﬁrst add piggybacks of the data of the ﬁrst 8 nodes onto the parity nodes 12 and 13 exactly as

Node 1 a1

b1

c1

d1

e1

f1

g1

h1

...

...

...

...

...

...

...

...

...

Node 4 a4

b4

c4

d4

e4

f4

g4

h4

Node 5 a5

b5

c5

d5

e5

f5

g5

h5

...

...

...

...

...

...

...

...

...

Node 8 Node 9 Node 10 Node 11 Node 12 Node 13

a8

a9

a10

p

T 1

a

p

T 2

a

p

T 3

a

b8

b9

b10

p

T 1

b

p

T 2

b+a

1

+

a

2

p

T 3

b+a

3

+

a

4

c8
c9
c10 pT1 c pT2 c+b5 +b6 pT3 c+b7 +b8

d8
d9
d10 pT1 d pT2 d+c1 +c2 pT3 d+c3 +c4

e8

e9

e10

p

T 1

e+a9

+

a

10

pT2 e

pT3 e

f8

f9

f10

pT1 f +b9 +b10

p

T 2

f

+e1

+

e

2

p

T 3

f

+e3

+

e

4

g8

g9

g10

pT1 g+c9 +c10

p

T 2

g

+f5

+

f6

p

T 3

g

+f7

+

f8

h8

h9

h10

pT1 h+c9 +c10

p

T 2

h

+g1

+

g2

p

T 3

h

+g3

+

g4

Fig. 4: An example illustrating piggyback design 3, with k = 10, n = 13, α = 8. The piggybacks in the ﬁrst parity node (in red) are functions of the data of nodes {8, 9} alone. In the remaining parity nodes, the piggybacks in the even substripes (in blue) are functions of the data of nodes {1, . . . , 4} (also in blue), and the piggybacks in the odd substripes (in green) are functions of the data of nodes {5, . . . , 8} (also in green), and the piggybacks in red (also in red). The piggybacks in nodes 12 and 13 are identical to that in Example 4 (Fig 3). The piggybacks in node 11 piggyback the ﬁrst set of 4 substripes (white background) onto the second set of number of substripes (gray background)
.

13

done in Example 4 (see Fig. 4). We now add piggybacks for the symbols stored in systematic nodes in the third set, i.e., nodes 9 and 10. To this end, we parititon the 8 substripes into two groups of size four each (indicated by white and gray shades respectively in Fig. 4). The symbols of nodes 9 and 10 in the ﬁrst four substripes are piggybacked onto the last four substripes of the ﬁrst parity node, as shown in Fig. 4 (in red color).

We now present the algorithm for repair of systematic nodes under this piggyback code. The repair algo-

rithm for the systematic nodes {1, . . . , 8} in the ﬁrst two sets closely follows the repair algorithm illustrated

in Example 4. Suppose ∈ S1, say = 1. By construction, the piggybacks corresponding to the nodes in

S1 are present in the parities of even substripes. From the even substripes, the remaining systematic symbols,

{bi, di, fi, hi}i={2,...,10},

and

the

symbols

in

the

ﬁrst

parity,

{p

T 1

b

,

p

T 1

d

,

p

T 1

f

+

b9

+

b10,

pT1 h + d9 + d10},

are

downloaded. Observe that, the ﬁrst two parity symbols downloaded do not have any piggybacks. Thus, using the

MDS property of the base code, b and d can be decoded. This also allows us to recover pT1 f , pT1 h from the symbols already downloaded. Again, using the MDS property of the base code, one recovers f and h. It now

remains to recover {a1, c1, e1, g1}. To this end, we download the symbols in the even substripes of node 12, {pT2 b+a1 + a2, pT2 d+c1 + c2, pT2 f +e1 + e2, pT2 h+g1 + g2}, which have piggybacks with the desired symbols. By subtracting out previously downloaded data, we obtain the piggybacks {a1 +a2, c1 +c2, e1 +e2, g1 +g2}. Finally,

by downloading and subtracting a2, c2, e2, g2, we recover a1, c1, e1, g1. Thus, node 1 is recovered by reading 48

symbols, which is 60% of the total message size. Observe that the repair of node 1 was accomplished by downloading

data from only (k + 1) = 11 other nodes. Every node in the ﬁrst set can be repaired in a similar manner. Repair of

the systematic nodes in the second set is performed in a similar fashion by utilizing the corresponding piggybacks,

however, the total number of symbols read is 64 (since the last substripe cannot be piggybacked; such was the case

in Example 4 as well).

We now present the repair algorithm for systematic nodes {9, 10} in the third set S3. Let us suppose = 9.

Observe that the piggybacks corresponding to node 9 fall in the second group (i.e., the last four) of substripes.

From the last four substripes, the remaining systematic symbols {ei, fi, gi, hi}i={1,...,8,10}, and the symbols in the

second

parity

{p

T 1

e,

pT1 f + e1 + e2,

pT1 g + f1 + f2,

pT1 h + g1 + g2, }

are

downloaded.

Using

the

MDS

property

of

the base code, one recovers e, f , g and h. It now remains to recover a9, b9, c9 and d9. To this end, we download

{pT1 e + a9 + a10, pT1 f + b9 + b10, pT1 g + c9 + c10, pT1 h + d9 + d10} from node 11. Subtracting out the previously

downloaded data, we obtain the piggybacks {a9 + a10, b9 + b10, c9 + c10, d9 + d10}. Finally, by downloading

and subtracting out {a10, b10, c10, d10}, we recover the desired data {a9, b9, c9, d9}. Thus, node 9 is recovered by

reading and downloading 48 symbols. Observe that the repair process involved reading data from only (k +1) = 11

other nodes. Node 10 is repaired in a similar manner.

For general values of the parameters, n, k, and α = 4m for some integer m > 1, we choose the size of the three

sets S1, S2, and S3, so as to make the number of systematic nodes involved in each piggyback equal or nearly

equal. Denoting the sizes of S1, S2 and S3, by t1, t2, and t3 respectively, this gives

1

r−1

r−1

t1 = 2r − 1 , t2 = 2r − 1 , t3 = 2r − 1 . (8)

Then the average data-read and download γ3sys for repair of systematic nodes, as a fraction of the total message symbols 4mk, is

γ3sys = 4m1k2 t1 k2 + t21 + t2 k2 + 2(rt−2 1) + t3

1 + 1 k + 1 − 1 t3

2m

2 m (r − 1)

. (9)

This quantity is plotted in Fig. 5a for various values of the system parameters n and k.

VI. COMPARISON OF DIFFERENT CODES
We now compare the average data-read and download entailed during repair under the piggyback constructions with various other storage codes in the literature. As discussed in Section I, practical considerations in data centers

14

require the storage codes to be MDS, high-rate, and have a small number of substripes. The table below compares different explicit codes designed for efﬁcient repair, with respect to whether they are MDS or not, the parameters they support and the number of substripes. Shaded cells indicate a violation of the aforementioned requirements. The parameter m associated to the piggyback codes can be chosen to have any value m ≥ 1. The base code for each of the piggyback constructions is a Reed-Solomon code [31].

Code High-rate Regenerating [7], [9]
Product-Matrix MSR [5] Local Repair [20]–[23]
Rotated RS [8] EVENODD, RDP [25]–[28]
Piggyback 1 Piggyback 2 Piggyback 3

MDS Y Y N Y Y Y Y Y

k, r supported r ∈ {2, 3} r ≥ k−1 all
r ∈ {2, 3}, k ≤ 36 r=2 all r≥3 all

Number of substripes rk
r
r 1 2 k 2m (2r − 3)m 4m

The piggyback, rotated-RS, (repair-optimized) EVENODD and RDP codes satisfy the desired conditions. Fig. 5 shows a plot comparing the repair properties of these codes. The plot corresponds to the number of substripes being 8 in Piggyback 1 and Rotated-RS, 4(2r − 3) in Piggyback 2, and 16 in the Piggyback 3 codes. We observe from the plot that piggyback codes require a lesser (average) data-read and download as compared to Rotated-RS, (repair-optimized) EVENODD and RDP.
VII. REPAIRING PARITIES IN EXISTING CODES THAT ADDRESS ONLY SYSTEMATIC REPAIR
Several codes proposed in the literature [7], [8], [19], [30] can efﬁciently repair only the systematic nodes, and require the download of the entire message for repair of any parity node. In this section, we piggyback these codes to reduce the read and download during repair of parity nodes, while also retaining the efﬁciency of repair of systematic nodes. This piggybacking design is ﬁrst illustrated with the help of an example.
Example 6: Consider the code depicted in Fig. 6a, originally proposed in [19]. This is an MDS code with parameters (n = 4, k = 2), and the message comprises four symbols a1, a2, b1 and b2 over ﬁnite ﬁeld F5. The code can repair any systematic node with an optimal data-read and download. Node 1 is repaired by reading and downloading the symbols a2, (3a1 + 2b1 + a2) and (3a1 + 4b1 + 2a2) from nodes 2, 3 and 4 respectively; node 2 is repaired by reading and downloading the symbols b1, (b1 + 2a2 + 3b2) and (b1 + 2a2 + b2) from nodes 1, 3 and 4 respectively. The amount of data-read and downloaded in these two cases are the minimum possible. However, under this code, the repair of parity nodes with reduced data-read has not been addressed.
In this example, we piggyback the code of Fig. 6a to enable efﬁcient repair of the second parity node. In particular, we take two instances of this code and piggyback it in a manner shown in Fig. 6b. This code is obtained by piggybacking on the ﬁrst parity symbol of the last two instance, as shown in Fig. 6b. In this piggybacked code, repair of systematic nodes follow the same algorithm as in the base code, i.e., repair of node 1 is accomplished by downloading the ﬁrst and third symbols of the remaining three nodes, while the repair of node 2 is performed by downloading the second and fourth symbols of the remaining nodes. One can easily verify that the data obtained in each of these two cases is identical to what would have been obtained in the code of Fig. 6a in the absence of piggybacking. Thus the repair of the systematic nodes remains optimal. Now consider repair of the second parity node, i.e., node 4. The code (Fig. 6a), as proposed in [19], would require reading 8 symbols (which is the size of the

15

Average data−read & download as % of message size Average data−read & download as % of message size
Average data−read & download as % of message size

75

100

RRS, EVENODD, RDP

Piggyback1

Piggyback2

Piggyback3

70

95

RRS, EVENODD, RDP Piggyback1 Piggyback2 Piggyback3

65

90

60

85

55

80

50 (12, 10)

(14, 12)

(15, 12)

(12, 9)

(16, 12)

Code Parameters: (n, k)

(a) Systematic

80

(20, 15)

(24, 18)

75

75 (12, 10)

(14, 12)

(15, 12)

(12, 9)

(16, 12)

Code Parameters: (n, k)

(b) Parity

(20, 15)

(24, 18)

RRS, EVENODD, RDP Piggyback1 Piggyback2 Piggyback3

70

65

60

55 (12, 10)

(14, 12)

(15, 12)

(12, 9)

(16, 12)

Code Parameters: (n, k)

(c) Overall

(20, 15)

(24, 18)

Fig. 5: Average data-read and download for repair of systematic, parity, and all nodes in the three piggybacking designs, Rotated-RS codes [8], and (repair-optimized) EVENODD and RDP codes [25], [26]. The (repair-optimized) EVENODD and RDP codes exist only for (n − k) = 2, and the data-read and download required for repair are identical to that of a rotated-RS codes with the same parameters. While the savings plotted correspond to a relatively small number of substripes, an increase in this number improves the performance of the piggybacked codes.

Node 1 Node 2 Node 3

a1 a2 3a1 +2b1 +a2

b1 b2 b1 +2a2 +3b2

Node 4 3a1 +4b1 +2a2 b1 +2a2 +b2
(a) An existing code [19] originally designed to address repair of only systematic nodes

a1

b1

c1

d1

a2 3a1 +2b1 +a2

b2 b1 +2a2 +3b2

c2
3c1 +2d1 +c2 +(3a1 +4b1 +2a2)

d2
d1 +2c2 +3d2 +(b1 +2a2 +b2)

3a1 +4b1 +2a2 b1 +2a2 +b2 3c1 +4d1 +2c2

d1 +2c2 +d2

(b) Piggybacking to also optimize repair of parity nodes

Fig. 6: An example illustrating piggybacking to perform efﬁcient repair of the parities in an existing code that originally addressed the repair of only the systematic nodes. See Example 6 for more details.

16

entire message) for this repair. However, the piggybacked version of Fig. 6b can accomplish this task by reading and downloading only 6 symbols: c1, c2, d1, d2, (3c1+2d1+c2+3a1+4b1+2a2) and (d1+2c2+3d2+b1+2a2+b2). Here, the ﬁrst four symbols help in the recovery of the last two symbols of node 4, (3c1 + 4d1 + 2c2) and (d1 + 2c2 + d2). Further, from the last two downloaded symbols, (3c1 + 2d1 + c2) and (d1 + 2c2 + 3d2) can be subtracted out (using the known values of c1, c2, d1 and d2) to obtain the remaining two symbols (3a1 + 4b1 + 2a2) and (b1 + 2a2 + b2). Finally, one can easily verify that the MDS property of the code in Fig. 6a carries over to Fig. 6b as discussed in Section II.

We now present a general description of this piggybacking design. We ﬁrst set up some notation. Let us assume
that the base code is a vector code, under which each node stores a vector of length µ (a scalar code is, of course, a special case with µ = 1). Let a = [aT1 aT2 · · · aTk ]T be the message, with systematic node i (∈ {1, . . . , k}) storing the µ symbols aTi . Parity node (k + j), j ∈ {1, . . . , r}, stores the vector aT Pj of µ symbols for some (kµ × µ) matrix Pj. Fig. 7a illustrates this notation using two instances of such a (vector) code.

We assume that in the base code, the repair of any failed node requires only linear operations at the other nodes. More concretely, for repair of a failed systematic node i, parity node (k + j) passes aT PjQ(ji) for some matrix Q(ji).
The following lemma serves as a building block for this design.

Lemma 1: Consider two instances of any base code, operating on messages a and b respectively. Suppose there exist two parity nodes (k + x) and (k + y), a (µ × µ) matrix R, and another matrix S such that

RQ(xi) = Q(yi)S ∀ i ∈ {1, . . . , k} .

(10)

Then, adding aT PyR as a piggyback to the parity symbol bT Px of node (k + x) (i.e., changing it from bT Px to (bT Px + aT PyR)) does not alter the amount of read or download required during repair of any systematic node.

Proof: Consider repair of any systematic node i ∈ {1, . . . , k}. In the piggybacked code, we let each node pass

the same linear combinations of its data as it did under the base code. This keeps the amount of read and download

identical

to

the

base

code.

Thus,

parity

node

(k

+ x)

passes

aT

Px

Q

(i x

)

and

(bT Px

+ aT PyR)Qx(i),

while

parity

node

(k

+

y)

passes

aT

P

y

Q

(i y

)

and

bT PyQ(yi).

From

(10)

we

see

that

the

data

obtained

from

parity

node

(k

+

y)

gives access to aT PyQ(yi)S = aT PyRQ(xi). This is now subtracted from the data downloaded from node (k + x) to

obtain bT PxQx(i). At this point, the data obtained is identical to what would have been obtained under the repair

algorithm of the base code, which allows the repair to be completed successfully.

An example of such a piggybacking is depicted in Fig. 7b.

Under a piggybacking as described in the lemma, the repair of parity node (k + y) can be made more efﬁcient by exploiting the fact that the parity node (k + x) now stores the piggybacked symbol (bT Px + aT PyR). We now

demonstrate the use of this design by making the repair of parity nodes efﬁcient in the explicit MDS ‘regenerating

code’ constructions of [7], [9], [19], [30] which address the repair of only the systematic nodes. These codes have

the property that

Q(xi) = Qi ∀ i ∈ {1, . . . , k}, ∀ x ∈ {1, . . . , r}

i.e., the repair of any systematic node involves every parity node passing the same linear combination of its data (and this linear combination depends on the identity of the systematic node being repaired). It follows that in these codes, the condition (10) is satisﬁed for every pair of parity nodes with R and S being identity matrices.

Example 7: The piggybacking of (two instances) of any such code [7], [9], [19], [30] is shown in Fig. 7c (for the case r = 3). As discussed previously, the MDS property and the property of efﬁcient repair of systematic nodes is retained upon piggybacking. The repair of parity node (k + 1) in this example is carried out by downloading all the 2kµ symbols. On the other hand, repair of node (k + 2) is accomplished by reading and downloading b from the systematic nodes, (bT P1 + aT P2 + aT P3) from the ﬁrst parity node, and (aT P3) from the third parity

17

Node 1 ...

aT1

bT1

...

...

Node k Node k+1

aTk aT P1

bTk bT P1

Node k+2 ...

aT P2 ...

bT P2 ...

Node k+r aT Pr bT Pr

(a) Two instances of the vector base code.

aT1

bT1

...

...

aTk aT P1

bTk bT P1 + aT P2R

aT P2 ...

bT P2 ...

aT Pr

bT Pr

(b) Illustrating the piggybacking stated in Lemma 1. The parities (k + 1) and (k + 2) respectively correspond to (k +x) and (k +y) of the Lemma.

Node 1

aT1

bT1

...

...

...

Node k Node k+1

aTk aT P1

bTk bT P1 + aT P2 + aT P3

Node k+2 aT P2

bT P2

Node k+3 aT P3

bT P3

(c) Piggybacking the ‘regenerating code’ constructions of [7], [9], [19], [30] for efﬁcient parity repair

Fig. 7: Piggybacking for efﬁcient parity-repair in existing codes originally constructed for repair of only systematic nodes.

node. This gives the two desired symbols aT P2 and bT P2. Repair of the third parity is performed in an identical manner, except that aT P2 is downloaded from the second parity node. The average amount of download and read for the repair of parity nodes, as a fraction of the size kµ of the message, is thus
2k + 2
3k which translates to a saving of around 33%.

In general, the set of r parity nodes is partitioned into

g= √ r k+1

sets of equal sizes (or nearly equal sizes if r is not a multiple of g). Within each set, the encoding procedure of

Fig. 7c is performed separately. The ﬁrst parity in each group is repaired by downloading all the data from the

systematic nodes. On the other hand, as in Example 7, the repair of any other parity node is performed by reading

b from the systematic nodes, the second (which is piggybacked) symbol of the ﬁrst parity node of the set, and the

ﬁrst symbols of all other parity nodes in the set. Assuming the g sets have equal number of nodes (i.e., ignoring

rounding effects), the average amount of read and download for the repair of parity nodes, as a fraction of the size

kµ of the message, is

1 k + ( gr − 1)2

+

.

2 2k gr

VIII. CONCLUSIONS AND OPEN PROBLEMS
We present a new piggybacking framework for designing storage codes that require low data-read and download during repair of failed nodes. This framework operates on multiple instances of existing codes and cleverly adds functions of the data from one instance onto the other, in a manner that preserves properties such as minimum distance and the ﬁnite ﬁeld of operation, while enhancing the repair-efﬁciency. We illustrate the power of this framework by using it to design the most efﬁcient codes (to date) for three important settings. In the paper, we also show how this framework can enhance the efﬁciency of existing codes that focus on the repair of only systematic nodes, by piggybacking them to also enable efﬁcient repair of parity nodes.
This simple-yet-powerful framework provides a rich design space for construction of storage codes. In this paper, we provide a few designs of piggybacking and specialize it to existing codes to obtain the four speciﬁc classes of

18
code constructions. We believe that this framework has a greater potential, and clever designs of other piggybacking functions and application to other base codes could potentially lead to efﬁcient codes for various other settings as well. Further exploration of this rich design space is left as future work. Finally, while this paper presented only achievable schemes for data-read efﬁciency during repair, determining the optimal repair-efﬁciency under these settings remains open.
REFERENCES
[1] D. Borthakur, “HDFS and Erasure Codes (HDFS-RAID),” 2009. [Online]. Available: http://hadoopblog.blogspot.com/2009/08/ hdfs-and-erasure-codes-hdfs-raid.html
[2] D. Ford, F. Labelle, F. Popovici, M. Stokely, V. Truong, L. Barroso, C. Grimes, and S. Quinlan, “Availability in globally distributed storage systems,” in Proceedings of the 9th USENIX Symposium on Operating Systems Design and Implementation, 2010.
[3] “Erasure codes: the foundation of cloud storage,” Sep. 2010. [Online]. Available: http://blog.cleversafe.com/?p=508 [4] K. V. Rashmi, N. B. Shah, P. V. Kumar, and K. Ramchandran, “Explicit construction of optimal exact regenerating codes for distributed
storage,” in Proc. 47th Annual Allerton Conference on Communication, Control, and Computing, Urbana-Champaign, Sep. 2009, pp. 1243–1249. [5] K. V. Rashmi, N. B. Shah, and P. V. Kumar, “Optimal exact-regenerating codes for the MSR and MBR points via a product-matrix construction,” IEEE Transactions on Information Theory, vol. 57, no. 8, pp. 5227–5239, Aug. 2011. [6] I. Tamo, Z. Wang, and J. Bruck, “MDS array codes with optimal rebuilding,” in Proc. IEEE International Symposium on Information Theory (ISIT), St. Petersburg, Jul. 2011. [7] V. Cadambe, C. Huang, and J. Li, “Permutation code: optimal exact-repair of a single failed node in MDS code based distributed storage systems,” in IEEE International Symposium on Information Theory (ISIT), 2011, pp. 1225–1229. [8] O. Khan, R. Burns, J. Plank, W. Pierce, and C. Huang, “Rethinking erasure codes for cloud ﬁle systems: minimizing I/O for recovery and degraded reads,” in Proc. Usenix Conference on File and Storage Technologies (FAST), 2012. [9] Z. Wang, I. Tamo, and J. Bruck, “On codes for optimal rebuilding access,” in Communication, Control, and Computing (Allerton), 2011 49th Annual Allerton Conference on, 2011, pp. 1374–1381. [10] S. Jiekak, A. Kermarrec, N. Scouarnec, G. Straub, and A. Van Kempen, “Regenerating codes: A system perspective,” arXiv:1204.5028, 2012. [11] A. S. Rawat, O. O. Koyluoglu, N. Silberstein, and S. Vishwanath, “Optimal locally repairable and secure codes for distributed storage systems,” arXiv:1210.6954, 2012. [12] K. Shum and Y. Hu, “Functional-repair-by-transfer regenerating codes,” in IEEE International Symposium on Information Theory (ISIT), Cambridge, Jul. 2012, pp. 1192–1196. [13] S. El Rouayheb and K. Ramchandran, “Fractional repetition codes for repair in distributed storage systems,” in Allerton Conference on Control, Computing, and Communication, Urbana-Champaign, Sep. 2010. [14] O. Olmez and A. Ramamoorthy, “Repairable replication-based storage systems using resolvable designs,” arXiv:1210.2110, 2012. [15] Y. S. Han, H.-T. Pai, R. Zheng, and P. K. Varshney, “Update-efﬁcient regenerating codes with minimum per-node storage,” arXiv:1301.2497, 2013. [16] B. Gasto´n, J. Pujol, and M. Villanueva, “Quasi-cyclic regenerating codes,” arXiv:1209.3977, 2012. [17] B. Sasidharan and P. V. Kumar, “High-rate regenerating codes through layering,” arXiv:1301.6157, 2013. [18] A. G. Dimakis, P. B. Godfrey, Y. Wu, M. Wainwright, and K. Ramchandran, “Network coding for distributed storage systems,” IEEE Transactions on Information Theory, vol. 56, no. 9, pp. 4539–4551, 2010. [19] N. B. Shah, K. V. Rashmi, P. V. Kumar, and K. Ramchandran, “Explicit codes minimizing repair bandwidth for distributed storage,” in Proc. IEEE Information Theory Workshop (ITW), Cairo, Jan. 2010. [20] F. Oggier and A. Datta, “Self-repairing homomorphic codes for distributed storage systems,” in INFOCOM, 2011 Proceedings IEEE, 2011, pp. 1215–1223. [21] P. Gopalan, C. Huang, H. Simitci, and S. Yekhanin, “On the locality of codeword symbols,” IEEE Transactions on Information Theory, Nov. 2012. [22] D. Papailiopoulos and A. Dimakis, “Locally repairable codes,” in Information Theory Proceedings (ISIT), 2012 IEEE International Symposium on. IEEE, 2012, pp. 2771–2775. [23] G. M. Kamath, N. Prakash, V. Lalitha, and P. V. Kumar, “Codes with local regeneration,” arXiv:1211.1932, 2012. [24] N. B. Shah, K. V. Rashmi, P. V. Kumar, and K. Ramchandran, “Distributed storage codes with repair-by-transfer and non-achievability of interior points on the storage-bandwidth tradeoff,” IEEE Transactions on Information Theory, vol. 58, no. 3, pp. 1837–1852, Mar. 2012. [25] Z. Wang, A. G. Dimakis, and J. Bruck, “Rebuilding for array codes in distributed storage systems,” in Workshop on the Application of Communication Theory to Emerging Memory Technologies (ACTEMT), Dec. 2010. [26] L. Xiang, Y. Xu, J. Lui, and Q. Chang, “Optimal recovery of single disk failure in RDP code storage systems,” in ACM SIGMETRICS, vol. 38, no. 1, 2010, pp. 119–130. [27] M. Blaum, J. Brady, J. Bruck, and J. Menon, “EVENODD: An efﬁcient scheme for tolerating double disk failures in RAID architectures,” IEEE Transactions on Computers, vol. 44, no. 2, pp. 192–202, 1995.

19

[28] P. Corbett, B. English, A. Goel, T. Grcanac, S. Kleiman, J. Leong, and S. Sankar, “Row-diagonal parity for double disk failure correction,” in Proc. 3rd USENIX Conference on File and Storage Technologies (FAST), 2004, pp. 1–14.
[29] M. Blaum, J. Bruck, and A. Vardy, “MDS array codes with independent parity symbols,” Information Theory, IEEE Transactions on, vol. 42, no. 2, pp. 529–542, 1996.
[30] D. Papailiopoulos, A. Dimakis, and V. Cadambe, “Repair optimal erasure codes through hadamard designs,” in Proc. 47th Annual Allerton Conference on Communication, Control, and Computing, Sep. 2011, pp. 1382–1389.
[31] I. Reed and G. Solomon, “Polynomial codes over certain ﬁnite ﬁelds,” Journal of the Society for Industrial & Applied Mathematics, vol. 8, no. 2, pp. 300–304, 1960.

APPENDIX

Proof of Theorem 1: Let us restrict our attention to only the nodes in set S, and let |S| denote the size of this set. From the description of the piggybacking framework above, the data stored in instance j (1 ≤ j ≤ α) under the base code is a function of Uj. This data can be written as a |S|-length vector f (Uj) with the elements of this vector corresponding to the data stored in the |S| nodes in set S. On the other hand, the data stored in instance j of the piggybacked code is of the form (f (Uj) + gj(U1, . . . , Uj−1)) for some arbitrary (vector-valued) functions ‘g’. Now,

I {Yi}i∈S ; U1, . . . , Uα = I {f (Uj) + gj(U1, . . . , Uj−1)}αj=1 ; U1, . . . , Uα

(11)

α

=

I {f (Uj) + gj(U1, . . . , Uj−1)}αj=1 ; U U1, . . . , U −1

(12)

=1

α

=

I f (U ) , {f (Uj) + gj(U1, . . . , Uj−1)}αj= +1 ; U

U1, . . . , U −1 (13)

=1 α

≥

I ( f (U ) ; U | U1, . . . , U −1)

(14)

=1 α

=

I (f (U ) ; U )

(15)

=1

= I {Xi}i∈S ; U1, . . . , Uα .

(16)

where the last two equations follow from the fact that the messages U of different instances are independent.

