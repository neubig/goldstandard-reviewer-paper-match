arXiv:2006.03045v1 [cs.IT] 4 Jun 2020

This is an extended version of the IEEE ISIT 2020 paper with the same title.
Online Versus Ofﬂine Rate in Streaming Codes for Variable-Size Messages
Michael Rudow and K.V. Rashmi
Abstract
Providing high quality-of-service for live communication is a pervasive challenge which is plagued by packet losses during transmission. Streaming codes are a class of erasure codes speciﬁcally designed for such low-latency streaming communication settings. We consider the recently proposed setting of streaming codes under variable-size messages which reﬂects the requirements of applications such as live video streaming. In practice, streaming codes often need to operate in an “online” setting where the sizes of the future messages are unknown. Yet, previously studied upper bounds on the rate apply to “ofﬂine” coding schemes with access to all (including future) message sizes.
In this paper, we evaluate whether the optimal ofﬂine rate is a feasible goal for online streaming codes when communicating over a burst-only packet loss channel. We identify two broad parameter regimes where, perhaps surprisingly, online streaming codes can, in fact, match the optimal ofﬂine rate. For both of these settings, we present rate-optimal online code constructions. For all remaining parameter settings, we establish that it is impossible for online coding schemes to attain the optimal ofﬂine rate.
I. INTRODUCTION Real-time communication with high quality-of-service is critical to many pervasive streaming applications, including VoIP and video conferencing. These live streaming applications rely on transmitting packets of information and must contend with packet losses during transmission. A standard solution to recover from packet loss is to retransmit lost packets. However, it is infeasible to use the retransmission-based approach in the live communication setting, as the three-way delay of transmission, feedback, and retransmission exceeds the real-time latency constraint [1]. One viable technique to provide robustness to packet loss is forward error correction. Yet using conventional coding schemes while complying with the real-time delay constraint induces a signiﬁcant bandwidth overhead. Coding schemes which are designed speciﬁcally for live streaming communication can attain signiﬁcantly higher rate than traditional coding schemes (including the class of maximal distance separable codes). This improved performance was demonstrated in [2] in which the authors proposed a new “streaming model” for real-time communication. The authors also presented a coding scheme and an upper bound on rate for the model. Under the streaming model, at each time slot, a “message packet” arrives at a sender who then sends a “channel packet” to a receiver. The channel packets are transmitted over a burst-only packet loss channel. Due to the real-time latency constraints, each message packet must be decoded by the receiver within the delay of a strict ﬁxed number of time slots. The streaming model is depicted in Figure 1. Code constructions designed speciﬁcally for the streaming model can have signiﬁcantly higher rate than traditional code constructions. This has motivated numerous subsequent works on the streaming model (discussed brieﬂy in Section II). The streaming model proposed in [2] and studied further in several subsequent works considers a setting where at each time slot a sender receives a message packet comprising some ﬁxed constant number of symbols to be transmitted to a receiver. However, many applications intrinsically require transmitting a stream of variable-size message packets. For example, in video conferencing a sender transmits a sequence of compressed video frames of ﬂuctuating sizes. Consequently, a new streaming model incorporating variable-size message packets was introduced in [3]. In this work, we focus on the setting of communicating variable-size message packets over a burst-only packet loss channel.
This work was funded in part by an NSF grant (CCF-1910813). The authors thank Francisco Maturana for his feedback in editing this work. M. Rudow and K.V. Rashmi are with the Computer Science Department at Carnegie Mellon University, Pittsburgh, PA, USA. (emails: mrudow@cs.cmu.eduand rvinayak@cs.cmu.edu)

Delay constraint %

Delay constraint %

![#]

Sender

&[#]

Packet loss

&#

or ∗ Receiver

![# − %]

channel

Message packets

Channel packets

![#] to be decoded by time slot # + %

Fig. 1. Overview of the streaming model. At each time slot i, a sender receives a message packet S[i] and transmits a channel packet X[i] over a packet loss channel to a receiver. The message packet S[i] is to be decoded within delay τ , i.e. by time slot (i + τ ).
Under the setting of variable-size message packets, the upper bound on rate of the ﬁxed-size regime still applies. However, the variability in the message packet sizes can induce more stringent rate constraints. Moreover, at each time slot, the optimal number of symbols to transmit can depend on the sizes of future message packets, which are inherently variable and unknown. This leads to the distinction between “ofﬂine” coding schemes, which have access to the sizes of message packets of future time slots, and “online” schemes, which do not have access to such information. Online constructions are of practical interest, as future message packet sizes are often unknown in live streaming applications. This leads to the natural question of “whether online coding schemes can match the rate of ofﬂine coding schemes?”
In this work, we identify two broad parameter regimes where, perhaps surprisingly, online coding schemes can match the rate of optimal ofﬂine coding schemes. For both these settings, we present rate-optimal online code constructions. For all remaining parameter regimes, we demonstrate that online coding schemes necessarily have strictly lower rate than optimal ofﬂine coding schemes.

II. BACKGROUND, SYSTEM MODEL AND NOTATION

As discussed in Section I, the streaming model was proposed in [2]. It captures the setting of real-time com-

munication of a sequence of message packets of a ﬁxed constant size over a burst-only packet loss channel. The

authors also introduced a class of code constructions applicable to the streaming model, called “streaming codes.”

Furthermore, they presented an upper bound on rate (which will be discussed shortly). Later, this bound was met

by a construction proposed in [4]. Streaming codes have signiﬁcantly higher rate than traditional code constructions

under the streaming model. This improvement in rate has prompted several works on bounds on rate and code

constructions for the streaming model under a variety of settings [5]–[18].

In applications such as video communication, the sizes of the messages to be transmitted ﬂuctuate considerably.

To incorporate this, a streaming model for variable-size messages was introduced in [3]. The authors designed

streaming codes for this new setting with higher rate than constructions designed for the setting of ﬁxed-size

messages. We later present rate-optimal streaming codes for two parameter regimes which outperform the code

construction from [3].

This work considers the streaming model from [3] (with a few minor changes in how time slots are indexed).

There is a ﬁnite stream of (t + 1) messages for an arbitrary natural number t. At each time slot i ∈ {0, . . . , t}, a

sender receives a message packet S[i] comprised of ki symbols drawn uniformly at random from a ﬁnite ﬁeld Fq.

The number of symbols is between 0 and m for a natural number m representing the maximum message packet

size. The sender then transmits a channel packet, X[i], consisting of ni symbols from Fq to a receiver. Each channel

packet X[i] either arrives at the receiver or is lost. We denote a lost channel packet by ∗. Each channel packet X[i]

depends only on the symbols of previous message packets (i.e. S[0], . . . , S[i]). Due to real-time latency constraints,

each message packet S[i] must be decoded by the receiver within a delay of τ time slots (i.e. S[i] is recovered

using the channel packets received by time slot (i + τ )). This requirement is called the worst-case-delay constraint.

In this setting, the rate Rt is deﬁned as the number of symbols of all message packets divided by the number of

transmitted symbols: Rt =

. t
i=0

ki

t

i=0 ni

The channel packets are transmitted over a burst-only packet loss channel equivalent to the one considered in

[2]. This channel is denoted C(b, w) and may introduce a single burst loss of length at most b packets within

every sliding window of length w channel packets. We restrict our attention to (w > τ ) in this work. Under a

2

C(b, w > τ ) channel for any sequence of (t + 1) message packets, the rate Rt is upper bounded by τ+τ b . This upper bound was initially shown for the setting of ﬁxed-size message packets in [4] and was shown to hold for the setting of variable-size message packets in [3]. Depending on the sizes of the message packets, the upper bound may be loose, as will be seen later in this work.
We refer to constructions which at time slot i ∈ {0, . . . , t} can access all future message packet sizes (ki+1, . . . , kt) as “ofﬂine.” Ofﬂine schemes have access to the sizes but not the symbols of the future message packets. In contrast, when a code construction cannot access future message packet sizes, we denote it as “online.” Thus, at time slot i, for an online construction, the future message packet sizes (ki+1, . . . , kt) are unknown. We distinguish between the feasible rates for ofﬂine and online coding schemes. We denote the best possible rate for ofﬂine coding schemes as the “ofﬂine-optimal-rate” and for online coding schemes as the “online-optimal-rate.”
Under the setting of variable-size message packets, it was shown in [3] that there is an inherent tradeoff between rate of a code and the decoding delay under lossless transmission (i.e. the number of time slots needed to decode a message packet when all channel packets are received). This tradeoff is captured in [3] via a new delay constraint called the lossless-delay constraint: When there are no losses, the receiver must decode each message packet S[i] within a delay of τL (< τ ) time slots.1 The lossless-delay constraint is relevant to applications which can infrequently tolerate a worst-case-delay of τ but require faster decoding for most message packets.
The valid value ranges for parameters b, τ, and τL are: 1 ≤ b ≤ τ and 0 ≤ τL ≤ τ − b. A maximum burst length of 0 is not considered, as coding is unnecessary in lossless transmission. Moreover, reliable transmission is impossible when b exceeds τ , as S[i] cannot be decoded by its deadline when X[i], . . . , X[i + τ ] are all lost in a burst. The restrictions on τL hold without loss of generality. τL cannot be negative and S[i] is decoded by time slot (i + τ − b) if there are no losses since a burst can drop X[i + τ − b + 1], . . . , X[i + τ ].
This paper uses the following notation. The term [n] denotes {0, . . . , n}. All vectors are row vectors. The length of a vector V is denoted |V |. A vector V is indexed using the notation V = (V0, . . . , V|V |−1) and VI = (Vi1, . . . , Vi|I|) for I = {i1, . . . , i|I| ⊆ [|V |]. Let A be an n × n matrix and I, J ⊆ {0, . . . , n − 1}. The quantity AI,J refers to restriction of A to the rows in I and columns in J. For message packets S[0], . . . , S[t], we call k0, . . . , kt the “message size sequence.”
The following conventions are used throughout this work. We restrict the parameter t to be at least τ and the ﬁnal τ message packets to have size 0. This ensures that coding schemes can encode the ﬁnal message packet of nonzero size using τ extra channel packets. Furthermore, these restrictions can be satisﬁed by appending τ message packets of size 0 to the stream of messages. This appending does not impact the rate of the code. For convenience of notation of edge cases, k1−b, . . . , k−1, kt+1, . . . , kt+b−1 are each deﬁned to be 0. A burst loss of X[i], . . . , X[i + b − 1] for i ∈ {1 − b, . . . , −1} denotes a burst loss of X[0], . . . , X[i + b − 1]. Similarly, a burst loss of X[i], . . . , X[i + b − 1] for i ∈ {t − b + 2, . . . , t} denotes a burst loss of X[i], . . . , X[t].

III. ONLINE CODE CONSTRUCTIONS WITH OPTIMAL RATE

In this section, we identify two broad parameter regimes where it is possible for online coding schemes to

match the ofﬂine-optimal-rate. We then present online constructions which do so. Both the settings have unique

characteristics that enable the online-optimal-rate to equal the ofﬂine-optimal-rate. In the ﬁrst regime, a simple

scheme which encodes each message packet separately has optimal rate. Hence, the knowledge of future messages

sizes does not provide any leverage. In the second regime, the lossless-delay constraint forces the encoder to send

each message packet immediately rather than distributing its symbols over multiple channel packets. This serves to

mitigate the potential advantage of ofﬂine schemes, enabling online coding schemes to attain the ofﬂine-optimal-rate.

Later, in Section IV, we show that for all other parameter settings it is impossible for an online code construction

to meet the ofﬂine-optimal-rate.

The two domains where the online-optimal-rate equals the ofﬂine-optimal-rate are: Regime 1: (τL = τ − b and

b|τ ) and Regime 2: (τL = 0).

Under Regime 1, for any parameters (τ, b), a simple online coding scheme applied to each message packet

separately

meets

the

upper

bound

on

the

rate

of

τ +τ b .

Each

message

packet

S[i]

is

partitioned

evenly

into

τ b

components which are transmitted in channel packets X[i], X[i + b], . . . , X[i + τ − b] respectively. This satisﬁes

the lossless-delay constraint. The summation of these components is sent in channel packet X[i + τ ]. At most one

1The notation of lossless-delay constraint has been changed from [3].

3

!&[0] !([0] !"[0]

!([1] !"[1]

!"[2]

!([3] !"[3]

,&[4] ,([4] ,"[4] !"[4]

,([5] ,"[5]

,"[8]

0

1

2

3

4

5

6

7

8

Fig. 2. A toy example of the (4, 2)-Variable-sized Generalized MS Code. Each message packet S[i] = (U [i], V [i]) is transmitted in the corresponding channel packet X[i] along with parity symbols P [i] (when applicable). White boxes with purple dots represent symbols of U [i], white boxes with an orange grid represent symbols of V [i], and solid red boxes represent symbols of P [i]. The numbers under the lines at the bottom indicate the time slots.

of X[i], X[i + b], . . . , X[i + τ − b], X[i + τ ] is lost in a burst of length b. Thus, the worst-case-delay constraint is satisﬁed.2
The remainder of this section focuses on Regime 2. Intuitively, in this regime, it is possible for an online coding scheme to match the ofﬂine-optimal-rate for the following reason: at each time slot i, for any code construction, at least ki symbols are sent in channel packet X[i] to meet the lossless-delay constraint for message packet S[i]. This eliminates the choice of distributing symbols corresponding to S[i] over multiple channel packets.
We next present an online coding scheme for any (τ, b) which meets the ofﬂine-optimal-rate. We include a high level description, then present a toy example, and ﬁnally provide its details. The scheme can be viewed as extending the Generalized Maximally Short Codes presented in [13] to incorporate variability in the message size sequence. We call the proposed scheme the (τ, b)-Variable-sized Generalized MS Code.
Code construction (high level description). During time slot i, each message packet S[i] is partitioned into two pieces S[i] = (U [i], V [i]). Redundant parity symbols P [i] = (U [i − τ ] + P [i]) are created where P [i] consists of linear combinations (taken from a Cauchy matrix) of the symbols of (V [i − τ ], . . . , V [i − 1]). Channel packet X[i] = (S[i], P [i]) is then sent. This satisﬁes the lossless-delay constraint (τL = 0). V [i] is deﬁned to contain as many symbols of S[i] possible while meeting the following requirement. For any burst loss of X[j], . . . , X[j + b − 1] which includes X[i], the sum of the sizes of V [j], . . . , V [i] is at most the number of parity symbols in X[j + b], . . . , X[j + τ − 1] (i.e. the sum of the sizes of P [j + b], . . . , P [j + τ − 1]). The remaining symbols of S[i] are allocated to U [i]. The size of P [i] is deﬁned to be |U [i − τ ]|.
Loss recovery. A burst loss of X[i], . . . , X[i+b−1] is recovered in two steps. First, for j ∈ {i+b, . . . , i+τ −1}, U [j − τ ] is canceled from P [j] to obtain P [j]. P [i + b], . . . , P [i + τ − 1] are used to recover V [i], . . . , V [i + b − 1] at time slot (i + τ − 1). Second, at time slot j ∈ {i + τ, . . . , i + τ + b − 1}, V [j − τ ], . . . , V [j − 1] are used to compute P [j]. Subtracting P [j] from P [j] decodes U [j].
Code construction (toy example). We present a toy example of the (4, 2)−Variable-sized Generalized MS Code for message size sequence k0 = 3, k1 = 2, k2 = 1, k3 = 2, k4 = 1, and kj = 0 for j ∈ {5, . . . , 8} in Figure 2. Each message packet S[i] is sent in the corresponding channel packet X[i] for i ∈ [4]. This satisﬁes the lossless-delay constraint. For i ∈ {0, 1, 4}, U [i] is deﬁned to equal S[i]. For i ∈ {2, 3} V [i] is set to be S[i]. P [4] = (S[0] + P [4]) is transmitted in X[4] where P [4] = (S0[2], S0[3], S1[3]). P [5] = (S[1] + P [5]) is sent in X[5] for P [5] = (S0[3], S1[3]). P0[8] = S0[4] is transmitted in X[8]. If a burst loss occurs, within delay 3 of its start all lost symbols of V [2] and or V [3] are decoded. Any lost symbols of U [0], U [1], and U [4] are each decoded with delay exactly 4 using P [4], P [5], and P [8] respectively (and cancelling decoded symbols of V [2] and V [3]). Therefore, the worst-case-delay constraint is satisﬁed.
Code construction (detailed description). At each time slot i, channel packet X[i] = (S[i], P [i]) is sent. The scheme is formally described in three parts: initialization, partitioning S[i] into (U [i], V [i]), and deﬁning P [i].
Initialization: The size |P [i]| is set to 0 for i ∈ [τ − 1] and ki−τ for i ∈ {τ, . . . , τ + b − 1}. The quantities U [i] = S[i] and |V [i]| = 0 are deﬁned for i ∈ [b − 1]. A is deﬁned to be a τ m × τ m Cauchy matrix, where m is the maximum message packet size.

2In a recent work [18], an interleaving approach similar to the coding scheme where each packet is encoded separately was found to be useful in designing a low complexity streaming code with linear ﬁeld size in the setting of ﬁxed-size message packets.

4

Partitioning S[i]: For any i ≥ b, S[i] is partitioned into S[i] = (U [i], V [i]) as follows. The auxiliary variable zi is

computed to encapsulate the minimum number of parity symbols available for use in recovering S[i] when X[i] is

dropped in a burst (i.e. zi = minj∈{i−b+1,...,i}

i+τ −1 l=j+b

|P

[l]|

−

i−1 l=j

kl.).

V

[i]

is

deﬁned

to

be

the

ﬁrst

min(ki,

zi)

symbols of S[i]. U [i] is set to be the remaining symbols of S[i]. |P [i + τ ]| = |U [i]| parity symbols are allocated to

be sent in channel packet X[i + τ ], although the actual symbols of P [i + τ ] are not yet identiﬁed. This ensures for

each burst in X[j], . . . , X[j + b − 1] for j ∈ {i − b + 1, . . . , i}, the number of parity symbols sent after the burst

by time slot (i + τ ) (i.e.

i+τ l=j+b

|P [l]|)

is

enough

to

recover

S[j],

.

.

.

,

S[i].

Deﬁning P [i]: P [i] is constructed during time slot (i ≥ τ ) as follows. P [i] = (U [i−τ ]+P [i]) where the symbols

of P [i] are linear combinations of the symbols of V [i − τ ], . . . , V [i − 1]. The linear combinations are deﬁned to

ensure for any j ∈ {i − τ + 1, . . . , i − b}, V [j], . . . , V [j + b − 1] can be decoded using V [j + b − τ ], . . . , V [j −

1], V [j + b], . . . , V [j + τ − 2], P [j + b], . . . , P [j + τ − 1]. To meet this objective, the linear combinations are chosen from a Cauchy matrix, as described below. Let V ∗[j] be the length m vector obtained by appending (m − |V [j]|) 0’s to V [j] for j ∈ {i − τ, . . . , i − 1}. The length τ m vector E[i] is deﬁned by placing each V ∗[j]

into m consecutive positions of E[i] starting with position (j mod τ )m. The Cauchy matrix A is used to deﬁne

P [i] = E[i]A[τ m−1],{(i mod τ )m,...,(i mod τ )m+|P [i]|−1}.

We observe that the ﬁeld size requirement is dictated by the Cauchy matrix and is at most 2τ m.

In Theorem 1, we verify that the Variable-sized Generalized MS Code meets the requirements of the model.

Theorem 1: For any parameters (τ, b) and message size sequence k0, . . . , kt, the (τ, b)-Variable-sized Generalized

MS Code satisﬁes the lossless-delay and worst-case-delay constraints over any C(b, w > τ ) channel.

Proof sketch: The full proof is provided in Appendix A.

The lossless-delay constraint is satisﬁed since the scheme transmits X[i] = (S[i], P [i]) for i ∈ [t].

We prove that the worst-case-delay constraint is satisﬁed by showing for any burst X[i], . . . , X[i + b − 1] that

each of S[i], . . . , S[i + b − 1] are recovered within delay τ . First, we show that V [i], . . . , V [i + b − 1] are recovered

by time slot (i + τ − 1). Second, we prove that U [i], . . . , U [i + b − 1] are each recovered with delay exactly τ .

First, the construction identiﬁes P [j] by time slot j by canceling U [j −τ ] from P [j] for j ∈ {i+b, . . . , i+τ −1}.

The total number of parity symbols in P [i + b], . . . , P [i + τ − 1] is at least as many as V [i], . . . , V [i + b − 1] by

deﬁnition. P [i + b], . . . , P [i + τ − 1] can be used to decode V [i], . . . , V [i + b − 1] by properties of the Cauchy

matrix A.

Second, the scheme uses V [j], . . . , V [j + τ − 1] to compute P [j + τ ] for j ∈ {i, . . . , i + b − 1}. It then cancels

P [j + τ ] from P [j + τ ] to decode U [j] with delay exactly τ .

In Theorem 2, we show that the Variable-sized Generalized MS Code meets the ofﬂine-optimal-rate under Regime 2. The proof involves an inductive argument on the time slot. It will show that the cumulative number of symbols sent by each time slot under any code construction must be at least as many as under the (τ, b)-Variable-sized Generalized MS Code. This will follow from the requirement of satisfying the lossless-delay and worst-case-delay constraints.
Theorem 2: For any parameters (τ, b, τL = 0), the (τ, b)-Variable-sized Generalized MS Code attains the ofﬂineoptimal-rate over a C(b, w > τ ) channel.
Proof sketch: The full proof is provided in Appendix B. For an arbitrary message size sequence k0, k1, . . . , kt, consider any optimal ofﬂine construction O. We use a proof by induction on time slot i = 0, 1, 2, . . . , t to show that the cumulative number of symbols sent by O by time slot i is at least as many as that of the (τ, b)-Variable-sized Generalized MS Code. Thus, the rate, Rt, of the (τ, b)-Variable-sized Generalized MS Code is at least as high as that of O. In the base case, for each i ∈ [τ − 1], channel packet X[i] under O must contain at least ki symbols to satisfy the lossless-delay constraint for message packet S[i]. Under the (τ, b)-Variable-sized Generalized MS Code, |X[i]| = ki. The inductive step for i ∈ {τ, . . . , t} has two cases. First, when X[i] = S[i] is sent under the (τ, b)-Variable-sized Generalized MS Code, at least |S[i]| = ki symbols are sent in X[i] under O to meet the lossless-delay constraint. Second, suppose X[i] = (S[i], P [i]) is sent under the (τ, b)-Variable-sized Generalized MS Code where |P [i]| > 0. Applying Lemma 5 shows that there is a burst loss starting at time slot j ∈ {i − τ − b + 1, . . . , i − τ } for which the number of parity symbols received under the (τ, b)-Variable-sized Generalized MS Code in X[j + b], . . . , X[i] is exactly enough to decode message packet S[j], . . . , S[i − τ ]. Combining this fact with satisfying the lossless-delay

5

constraint for S[j + b], . . . , S[i] necessitates that at least as many symbols are sent under O between time slots (j + b) and i as are respectively sent under the (τ, b)-Variable-sized Generalized MS Code. Applying the inductive hypothesis for time slot (j + b − 1) concludes the proof.

IV. INFEASIBLITY OF OFFLINE-OPTIMAL-RATE FOR ONLINE SCHEMES
In Section III, we presented online code constructions which match the ofﬂine-optimal-rate under the two broad settings of Regime 1 and Regime 2. This motivates us to ask the question of whether there are any other parameter settings where an online coding scheme can attain the ofﬂine-optimal-rate. In this section, we show that the onlineoptimal-rate is strictly less than the ofﬂine-optimal-rate for all other parameter settings.
At a high level, the reason for online coding schemes being unable to match the ofﬂine-optimal-rate stems from the need to distribute symbols over multiple channel packets. For all parameter settings besides Regime 1 and Regime 2, the optimal approach to spreading symbols from a message packet S[i] over channel packets X[i], . . . , X[i + τL] can depend on the sizes of future message packets (i.e. ki+1, . . . , kt). This dependency enables ofﬂine coding schemes to have higher rate than online coding schemes. This result is formally established in Theorem 3.
Theorem 3: For any parameters (τ, b, τL) outside of Regime 1 and Regime 2, the online-optimal-rate is strictly less than ofﬂine-optimal-rate.
Proof: The proof is provided in Section IV-A.

A. Proof of Theorem 3

The proof is divided into three mutually exclusive cases shown in Lemmas 1, 2, and 3. Each Lemma uses the

following argument. Two distinct message size sequences of length (t+1) are introduced which are identical for the

ﬁrst several time slots. We show a lower bound on the ofﬂine-optimal-rate for the two message size sequences by presenting an ofﬂine coding scheme which has rates Rt(1) and Rt(2) on the ﬁrst and second message size sequences respectively. The manner in which symbols are transmitted to attain rate at least Rt(1) on the ﬁrst message size sequence prohibits the code construction from having rate at least Rt(2) on the second.
We provide the full proof for Lemma 1 below. Proofs for Lemmas 2 and 3 are provided in the Appendix C

and D.

Lemma 1: For parameters (τ, b, τL = τ − b) where (τL ≥ b), the online-optimal-rate is strictly less than ofﬂine-

optimal-rate.

Proof: Let (a =

τL b

) and (e ≡ τL

mod b). We note (e > 0) since (b

| τ ). Let d be an arbitrary multiple

of (a + 1).

Consider the following two message size sequences:

1) kj(1) = d for j ∈ [e − 1] and kj(1) = 0 for j ∈ {e, . . . , t}. 2) kj(2) = d for j ∈ [b − 2], kb(−2)1 = d(τL + 1), and kj(2) = 0 for j ∈ {b, . . . , t}.

We

present

an

ofﬂine

coding

scheme

for

message

size

sequences

1

and

2

which

has

rates

Rt(1)

=

a+1 a+2

and

Rt(2)

=

τ τ +b

on

the

two

message

size

sequences

respectively.

We

describe

and

then

validate

the

scheme

for

each

message size sequence.

Ofﬂine scheme for message size sequence 1: Each message packet is encoded separately with parameters (τ =

τ b

b, b

= b, τL = τ

− b) as described in Section III and detailed below.

• S[i] is evenly split into S(0)[i], . . . , S(a)[i] for i ∈ [e − 1].

• X[i + zb] = S(z)[i] is sent for z ∈ [a] and i ∈ [e − 1].

• X[i + (a + 1)b] =

a z=0

X [i

+

zb]

is

sent

for

i

∈

[e

−

1].

Verifying constraints: The lossless-delay and worst-case-delay constraints are met since S[i] is sent by time slot ab

and at most one of X[i], X[i + b], . . . , X[i + ab], X[i + (a + 1)b] is lost for i ∈ [e − 1].

Before

the

scheme

for

message

size

sequence

2

is

described,

we

present

a

rate

τ τ +b

block

code

from

[8]

(or

alternatively a block code from [5]–[7], [9]) which the scheme will build on. The block code systematically maps

τ input symbols (s0, . . . , sτ−1) to (τ + b) codeword symbols (s0, . . . , sτ−1, p0, . . . , pb−1). For each j ∈ [τ − 1]

and any burst erasing up to b codeword symbols, the non-erased symbols of (s0, . . . , sτ−1, p0, . . . , pmin(b−1,j)) are

sufﬁcient to decode sj. Hence, each symbol is recovered within τ symbols.

6

Ofﬂine scheme for message size sequence 2: The ﬁrst (b − 1) message packets are sent with no delay and the symbols of the next message packet are transmitted evenly over X[b − 1], . . . , X[τ − 1]. d symbols are sent in each of X[τ ], . . . , X[τ + b − 1] to creates d blocks of the code from [8]. The scheme is described in detail below.
• X[j] = S[j] is sent for j ∈ [b − 2]. • S[b − 1] is divided evenly into S(0)[b − 1], . . . , S(τL)[b − 1]. • X[b − 1 + j] = S(j)[b − 1] is sent for j ∈ [τL]. • For each z ∈ [d − 1], an instance of the block code from [8] is created which maps (Xz[0], . . . , Xz[τ − 1]) to
(Xz[0], . . . , Xz[τ − 1], p(0z), . . . , p(bz−)1). • X[τ + j] = (p(j0), . . . , p(jd−1)) is sent for j ∈ [b − 1]. Verifying constraints: The lossless-delay constraint is satisﬁed, as each message packet is transmitted within delay τL. Each symbol Xz[i] for z ∈ [d − 1] and i ∈ [τ − 1] is decoded within delay τ or by time slot (τ + b − 1) by properties of the block code (Xz[0], . . . , Xz[τ − 1], p(0z), . . . , pb(z−)1). Thus, the worst-case-delay constraint is met. High level converse: Due to the ofﬂine scheme, the ofﬂine-optimal-rate is at least Rt(1) and Rt(2) for message size sequences 1 and 2 respectively. Next, we show mutually exclusive conditions for sum of the sizes of X[0], . . . , X[e− 1] to have rates at least Rt(1) and Rt(2) on message size sequences 1 and 2 respectively. All online coding schemes, thus, fail the condition for at least one message size sequence, since they are identical until time slot e. Condition for rate Rt(1) on message size sequence 1: Consider any coding scheme for message size sequence 1. At least de symbols are sent over X[b], . . . , X[t] since X[0], . . . , X[b − 1] could be lost. At most d a+e 1 symbols can be sent over X[0], . . . , X[b − 1] if the rate is at least Rt(1). Condition for rate Rt(2) on message size sequence 2: Consider an arbitrary coding scheme for message size sequence 2. At least dτ symbols are sent in X[0], . . . , X[τ − 1] to meet the lossless-delay constraint. Let X(+) ∈ {(X[e + ib], . . . , X[e + (i + 1)b − 1]) | 0 ≤ i ≤ a}. At least dτ symbols are sent outside of X(+) in case X(+) is lost. Each |X(+)| ≤ db and at least (dτ − d(a + 1)b = de) symbols are sent in X[0], . . . , X[e − 1] if the rate is at least Rt(2). Conclude converse: Thus, for any online scheme with rate at least Rt(1) on message size sequence 1, at most d a+e 1 symbols are sent in X[0], . . . , X[b − 1]. Such a scheme necessarily has rate less than Rt(2) on message size sequence 2 since fewer than de symbols are sent in X[0], . . . , X[e − 1].
Lemma 2: For parameters (τ, b, τL = τ − b) where (τL < b), the online-optimal-rate is strictly less than ofﬂineoptimal-rate.
Proof: Provided in Appendix C. Lemma 3: For parameters (τ, b, τL) where (τL < τ − b), the online-optimal-rate is strictly less than ofﬂineoptimal-rate.
Proof: Provided in Appendix D. We combine Lemmas 1, 2, and 3 to prove Theorem 3 below.
Proof of Theorem 3: Case 1 (τL = τ − b and τL ≥ b): Follows from Lemma 1. Case 2 (τL = τ − b and τL < b): Follows from Lemma 2. Case 3 (τL < τ − b): Follows from Lemma 3.
APPENDIX
A. Proof of Theorem 1
The lossless-delay constraint is satisﬁed since X[i] = (S[i], P [i]) is transmitted for i ∈ [t]. We prove that the worst-case-delay constraint is satisﬁed by showing for any burst loss of X[i], . . . , X[i + b − 1] that each of S[i], . . . , S[i + b − 1] are recovered within delay τ for i ∈ [t − τ ].3 This involves showing ﬁrst that V [i], . . . , V [i + b − 1] are recovered by time slot (i + τ − 1) and second that U [i], . . . , U [i + b − 1] are each recovered with delay exactly τ .
3Each message packet S[i] for i > (t − τ ) is of size 0 and is known by the receiver due to the termination of the message size sequence.
7

First, the construction identiﬁes P [j] by time slot j by subtracting U [j −τ ] from P [j] for j ∈ {i+b, . . . , i+τ −1}.

The total number of symbols in P [i + b], . . . , P [i + τ − 1] is at least as many as V [i], . . . , V [i + b − 1], as will

be veriﬁed shortly. We then use properties of the Cauchy matrix A to show that P [i + b], . . . , P [i + τ − 1] can be

used to decode V [i], . . . , V [i + b − 1].

The manner in which V [i], . . . , V [i + b − 1] are deﬁned ensures that

i+τ +b−1 j=i+b

|P

[j]|

≥

i+b−1 j=i

kj .

Recall

that

|P [j]| = |U [j − τ ]| for j ∈ {i + τ, . . . , i + τ + b − 1}. Combining these expressions yields

i+τ −1 j=i+b

|P

[j]|

≥

i+b−1 j=i

|V

[j

]|.

Recall from the deﬁnition of P [i + b], . . . , P [i + τ − 1] that E[i + b], . . . , E[i + τ − 1] are vectors which includes

V [j] in positions Ij = {(j mod τ )m, . . . , (j mod τ )m + |V [j]|} for j ∈ {i, . . . , i + b − 1}. In other words,

E[l]Ij = V [j] for l ∈ {i + b, . . . , i + τ − 1} and j ∈ {i, . . . , i + b − 1}. Therefore, restricting each of the E[l] to the

indexes of I =

i+τ −1 j=i+b

Ij

results

in

a

permutation

of

V [i + b], . . . , V [i + τ

− 1]

(i.e.

for

some

permutation

matrix

σ and all j ∈ {i + b, . . . , i + τ − 1}, σEI [j] = (V [i + b], . . . , V [i + τ − 1])).

For j ∈ {i + b, . . . , i + τ − 1}, let P ∗[j] be the result of canceling V [i − τ ], . . . , V [i − 1], V [i + b], . . . , V [j − 1]

from P [j]. In other words, for I∗ = l∈{j−τ,...,i−1,i+b,...,j−1}{(l mod τ )m, . . . , (l mod τ )m + |V [l]|}, P ∗[j] =

(P [j] − EI∗ [j]AI∗,{(j mod τ )m,...,(j mod τ )m+|P [j]|−1}). Consider any size

j=i+b−1 j=i

|V

[j

]|

set

J

⊆

ij+=τi+−b1{(j

mod τ )m, . . . , (j mod τ )m + |P [j]| − 1}.

There are at least

j=i+b−1 j=i

|V

[j]|

symbols

of

P ∗[i

+

b],

.

.

.

,

P ∗[i

+

τ

−

1]

corresponding

to

EI [i

+

τ

−

1]AI,J

available at time slot (i + τ − 1). As AI,J is a square Cauchy matrix, it can be inverted to solve for V [i], . . . , V [i +

b − 1].

Second, for j ∈ {i, . . . , i + b − 1} the scheme uses V [j], . . . , V [j + τ − 1] to compute P [j + τ ] = E[j +

τ ]A[τm−1],{(j mod τ)m,...,(j mod τ)m+|P [j+τ]|−1}. It then decodes U [j] = (P [j + τ ] − P [j + τ ]) with delay exactly τ .4

B. Proof of Theorem 2

In this Section, we will prove Theorem 2. At a high level, the proof is inductive and shows that the cumulative

number of symbols sent by each time slot under the (τ, b)-Variable-sized Generalized MS Code is minimal.

Whenever a channel packet consists solely of a message packet it follows immediately by the lossless-delay

constraint. Otherwise, there is some burst for which every redundant parity symbol in the channel packet is needed

to both recover the burst within the worst-case-delay and satisfy the lossless-delay constraint for the message packets

immediately after the burst.

We begin by introducing preliminary notation for the proof. We then include a few auxiliary Lemmas which will

be used throughout the proof. Finally, we present the full proof itself.

Let t be an arbitrary natural number. Let O be an arbitrary ofﬂine code construction which satisﬁes the lossless-

delay and worst-case-delay constraints over a C(b, w > τ ) channel. For any length (t + 1) message size sequence,

let the channel packet transmitted during time slot j ∈ [t] under each of construction O and the (τ, b)-Variable-

sized Generalized MS Code be labeled XO[j] and XV [j] respectively. Let the cumulative number of symbols

transmitted through time slot j under each of construction O and the (τ, b)-Variable-sized Generalized MS Code

be denoted n+O,j =

j i=0

|XO

[i]|

and

n+V,j

=

j i=0

|XV

[i]|

respectively.

Consider

any

i

∈

{τ, . . . , t}

and

any

j ∈ {max(0, i − τ − b), . . . , i − τ }. Let L(i,j) = (S[j], . . . , S[i − τ ]), Q(Oi,j) = (XO[j + b], . . . , XO[i]), Q(Vi,j) = (XV [j + b], . . . , XV [i]), and G(i,j) = (S[j + b], . . . , S[i]). For any j ∈ [t] let S(−,j) = (S[0], . . . , S[j]). Finally, let

S be a random variable representing an arbitrary symbol of an arbitrary message packet.

We show the intuitive property that for each time slot any scheme transmits at least as many symbols as the size

of the corresponding message packet.

Lemma 4: Consider any parameters (τ, b), an arbitrary message size sequence k0, k1, . . . , kt, and any code

construction which satisﬁes the lossless-delay and worst-case-delay constraints over a C(b, w > τ ) channel. For

any j ∈ [t], nj ≥ kj.

Proof: The proof follows from independence of the message packets and satisfying the lossless-delay constraint.

A full proof is included for completeness.

4In the edge case where i > (t − τ ), S[i] is known by the decoder to have size 0 and this step is not needed.

8

Consider any j ∈ [t]. In order to meet the lossless-delay requirement, H(S[j]|X[0], . . . , X[j]) = 0. The X[0], . . . , X[j − 1] are functions of S(−,j−1). Therefore, H(S[j]|X[0], . . . , X[j]) ≤ H(S[j]|S(−,j−1), X[j]). Furthermore, the message packets are independent, hence H(S[j]|S(−,j−1), X[j]) = H(S[j]|X[j]) = 0. The entropy of a channel packet is at most H(S) times its size. Furthermore, H(S[j]) = H(S)kj by deﬁnition. Combining these statements leads to the following inequality:
∀j ∈ [t], H(S)nj ≥ H(X[j]) ≥ H(S[j]) = H(S)kj.

The below Lemma 5 essentially shows that all parity symbols sent in any channel packet under the (τ, b)−Variable-

sized Generalized MS Code are needed to satisfy the worst-case-delay constraint.

Lemma 5: Consider any parameters (τ, b), message size sequence k0, . . . , kt, and the (τ, b)-Variable-sized Gener-

alized MS Code. For all i ≥ τ where |P [i]| > 0, ∃j ∈ {i − τ − b + 1, . . . , i − τ } such that

i−τ l=j

kl

=

i l=j

+b

|P

[l]|.

Proof: This holds for i ∈ {τ, . . . , τ + b − 1} due to the initialization and a burst in X[0], . . . , X[b − 1].

For (i ≥ τ + b), if (|P [i]| = |U [i − τ ]| > 0) then (|V [i − τ ]| < ki−τ ). By deﬁnition of V [i − τ ] there is some

j ∈ {i−τ −b+1, . . . , i−τ } for which |V [i−τ ]| = (

i−1 l=j+b

|P

[l]|

−

i−τ −1 l=j

kl).

Thus,

(

i−τ l=j

kl

=

i l=j

+b

|P

[l]|).

Next, we establish that whenever a burst of length b occurs, all message packets from time slots before the burst

must be decoded prior to the burst in order to satisfy both the lossless-delay and worst-case-delay constraints.

Lemma 6: Consider any parameters (τ, b), an arbitrary message size sequence k0, k1, . . . , kt, j ∈ [t], and any

code construction which satisﬁes the lossless-delay and worst-case-delay constraints over a C(b, w > τ ) channel. When X[j], . . . , X[j + b − 1] are lost in a burst, S(−,j−1) are decoded by time slot (j − 1).

Proof: S[0], . . . , S[j − τ − 1] are all decoded by time slot (j − 1) in order to satisfy the worst-case-delay

constraint. Furthermore, when a burst occurs starting in time slot j, all of X[j − τ ], . . . , X[j − 1] must be received

by deﬁnition of the C(b, w > τ ) channel. Consequently, up to time slot (j − 1), the transmission is without loss of

generality lossless. Each of S[j − τ ], . . . , S[j − 1] are decoded with delay τL = 0, since the lossless-delay constraint is satisﬁed. Therefore, S(−,j−1) are decoded by time slot (j − 1).
Lemma 6 shows when X[j], . . . , X[j + b − 1] are lost for j ∈ [t], the receiver has access to S(−,j−1) by time

slot (j − 1). This fact will be assumed as part of the proof of Theorem 2, which is presented below.

Proof of Theorem 2: Let k0, k1, . . . , kt be an arbitrary message size sequence. The proof will show that the

total number of symbols transmitted under an arbitrary ofﬂine construction O is at least as many that of the (τ, b)-

Variable-sized Generalized MS Code. Speciﬁcally, the proof will show by induction that the cumulative number of

symbols sent through time slot i ∈ [t] under construction O is at least as many as that of the (τ, b)−Variable-sized Generalized MS Code (i.e. n+O,i ≥ n+V,j). Consequently, the (τ, b)-Variable-sized Generalized MS Code matches the ofﬂine-optimal-rate.

In the base case, we consider j ∈ [τ −1]. Applying Lemma 4 determines that |XO[j]| ≥ kj = |XV [j]|∀j ∈ [τ −1]. For the inductive hypothesis, we assume for some (i∗ ≥ τ − 1) for all l ∈ [i∗] that n+O,l ≥ n+V,l. For the inductive step, consider time slot (i = i∗ + 1 ≥ τ ). By the inductive hypothesis, n+O,i−1 ≥ n+V,i−1. We will show that n+O,i ≥ n+V,i using two cases.
Case |XV [i]| = ki: Applying Lemma 4 determines that |XO[i]| ≥ ki. Therefore, (n+O,i = n+O,i−1 + ki ≥ n+V,i−1 + ki = n+V,i).
Case |XV [i]| = |(S[i], P [i])| > ki:

At a high level, this case is shown as follows: Applying Lemma 5 shows that there is a burst starting in time slot

j ∈ {i − τ − b + 1, . . . , i − τ } for which the (τ, b)-Variable-sized Generalized MS Code receives exactly enough redundant parity symbols to decode message packet L(i,j) by time slot i. Combining this fact with meeting the lossless-delay constraint for G(i,j) shows that the number of symbols sent under O between time slots (j + b) and

i is at least as many as that of the (τ, b)-Variable-sized Generalized MS Code. Applying the inductive hypothesis

for time slot (j + b − 1) and combining with above concludes the proof.

There is some j ∈ {i − τ − b + 1, . . . , i − τ } such that

i l=j+b

|P

[l]|

=

i−τ l=j

kl

by

Lemma

5.

Hence,

i

i−τ

i

|XV [l]| = kl +

kl.

(1)

l=j+b

l=j

l=j+b

9

Next, it is shown that at least as many symbols are sent over Q(Oi,j) as are sent over Q(Vi,j). Consider a burst loss of X[j], . . . , X[j + b − 1]. Applying Lemma 6 shows that S(−,j−1) are known by the receiver by time slot (j − 1). Let Q(i,j) ∈ {(Q(Oi,j)), (Q(Vi,j))}. In order to meet the worst-case-delay constraint,
H(L(i,j)|Q(i,j), S(−,j−1)) = 0.
By applying the chain rule twice H(Q(i,j), S(−,j−1), L(i,j)) = H(S(−,j−1)) + H(Q(i,j)|S(−,j−1)) + H(L(i,j)|Q(i,j), S(−,j−1)) = H(Q(i,j)|S(−,j−1)) = H(S(−,j−1)) + H(L(i,j)|S(−,j−1)) + H(Q(i,j)|S(−,j−1), L(i,j)).
The message packets are independent, hence H(L(i,j)|S(−,j−1)) = H(L(i,j)). This yields the following equation,

H(Q(i,j)|S(−,j−1)) = H(L(i,j)) + H(Q(i,j)|S(−,j−1), L(i,j)).

(2)

The following derives a lower bound for H(Q(i,j)|S(−,j−1), L(i,j)) which will later be combined with the above equation. The quantity is bounded by conditioning as

H(Q(i,j)|S(−,j−1), L(i,j)) ≥ H(Q(i,j)|S(−,j+b−1)).

The chain rule is then applied to determine H(G(i,j), Q(i,j)|S(−,j+b−1)) = H(G(i,j)|S(−,j+b−1)) + H(Q(i,j)|S(−,j+b−1), G(i,j)). = H(G(i,j)|S(−,j+b−1)).

The second step above follows from the fact that Q(i,j) is a function of (S[0], . . . , S[i]) = (S(−,j+b−1), G(i,j)). Applying the independence of the message packets determines
H(G(i,j), Q(i,j)|S(−,j+b−1)) = H(G(i,j)).

Applying the chain rule yields H(G(i,j), Q(i,j)|S(−,j+b−1)) = H(Q(i,j)|S(−,j+b−1)) + H(G(i,j)|Q(i,j), S(−,j+b−1)) = H(Q(i,j)|S(−,j+b−1)).

The second step above follows from the fact that H(G(i,j)|Q(i,j), S(−,j+b−1)) = 0 in order to meet the lossless
delay constraint. Combining these equations shows that H(G(i,j)) = H(Q(i,j)|S(−,j+b−1)). Therefore, H(Q(i,j)|S(−,j−1), L(i,j)) ≥
H(G(i,j)). Applying this inequality to Equation 2 results in,

H(Q(i,j)|S(−,j−1)) ≥ H(L(i,j)) + H(G(i,j)).

(3)

Next, it is shown that Q(Vi,j) contains the minimum necessary number of symbols possible. By deﬁnition

i−τ

i

H(L(i,j)) + H(G(i,j)) = H(S)( kl +

kl)

l=j

l=j+b

and
i

H (S )

|XV [l]| ≥ H(Q(Vi,j)) ≥ H(Q(Vi,j)|S(−,j−1)).

l=j+b

Combining these facts with Equations 1 and 3 derives

i

H (S )

|XV [l]| = H(L(i,j)) + H(G(i,j)).

(4)

l=j+b

10

It is now shown that at least as many symbols are sent over Q(Oi,j) as are transmitted in Q(Vi,j). The sizes of

channel packets ensure

i

H (S )

|XO[l]| ≥ H(Q(Oi,j))

l=j+b

By conditioning, H(Q(Oi,j)) ≥ H(Q(Oi,j)|S(−,j−1)). Combining this with Equations 3 and 4 determines that

i

i

H (S )

|XO[l]| ≥ H(S)

|XV [l]|.

(5)

l=j+b

l=j+b

By deﬁnition, (n+O,i = n+O,j+b−1 +

i l=j

+b

|XO

[l]|)

and

(n+V,i

=

n+V,j+b−1 +

i l=j+b

|XV

[l]|).

Applying

the

inductive hypothesis to (j + b − 1 < i) shows that (n+V,j+b−1 ≤ n+O,j+b−1). Combining the above equations with

Equation 5 determines that n+V,i ≤ n+O,i.

C. Proof of Lemma 2

Proof: Let d be an arbitrary positive even integer. Consider the following two message size sequences:

1) kj(1) = d for j ∈ [b − τL] and kj(1) = 0 for j ∈ {b − τL + 1, . . . , t}.

2) ki(2) = d for i ∈ [b − τL] ∪ {b} and kj(2) = 0 for j ∈ {b − τL + 1, . . . , b − 1} ∪ {b + 1, . . . , t}.

We

will

introduce

an

ofﬂine

coding

scheme

for

the

two

message

size

sequences

with

rates

Rt(1)

=

b−τL+1 2b−2τ +1.5

L

and

Rt(2)

=

b−τL+2 2b−2τ +3

on

message

size

sequence

1

and

2

respectively.

After

presenting

the

scheme

for

each

message

L

size sequence, we verify that it satisﬁes the lossless-delay and worst-case-delay constraints.

Ofﬂine scheme for message size sequence 1: The ﬁrst (b − τL) message packets are sent in the corresponding

channel packets. The message packet S[b − τL] is divided in half to be transmitted evenly over X[b − τL] and X[b].

d symbols are sent in each of the next (b − τL) channel packets to decode (a) the ﬁrst (b − τL) message packets

if the corresponding channel packets are lost and (b) X[b] if X[b − τL] and X[b] are both lost. A parity check of

X[b − τL] and X[b] is later sent in X[2b] to ensure S[b − τL] is decoded within delay τ . The scheme is detailed

below:

• Divide message packets S[0] and S[b − τL] in half into S[0] = (S(0)[0], S(1)[0]) and S[b − τL] = (S(0)[b − τL], S(1)[b − τL]) respectively.

• X[i] = S[i] is transmitted for i ∈ [b − τL − 1]. • X[b − τL] = S(0)[b − τL] is transmitted. • X[b] = S(1)[b − τL] is transmitted. • X[b + 1] = (S(0)[0], S(1)[0] + S(1)[b − τL]) is transmitted.

• X[i + b + 1] = (X[i + b] + S[i]) is transmitted for i ∈ {1, . . . , b − τL − 1}. • X[b − τL + τ ] = X[2b] = (S(0)[b − τL] + S(1)[b − τL]) is transmitted.

Verifying constraints: The lossless-delay constraint is satisﬁed, since each message packet is transmitted within delay

τL. We now verify that the worst-case-delay constraint is satisﬁed for each message packet. Either X[0] = S[0] is received or X[0] is lost and both X[b] = S(1)[b − 1] and X[b + 1] = (S(0)[0], S(1)[0] + S(1)[b − 1]) are received.

Therefore, S[0] is decoded within delay τ . Next, for i ∈ {1, . . . , b − τL − 1}, either X[i] = S[i] is received or both

X[i + b] and X[i + b + 1] = (X[i + b] + S[i]) are received. Thus, S[i] is recovered within delay (b + 1 ≤ τ ). Either

X[b − τL] = S(0)[b − τL] is received or X[2b − τL] = (S(0)[0], S(1)[0] + S(1)[b − τL]) +

2b−τL−1 i=b+1

S[i

−

b]

is

received. In the latter case, S[0], . . . , S[b − τL − 1] are decoded by time slot (2b − 1) and combined with X[2b − τL] to decode S(1)[b − τL]. S(1)[b − τL] is then combined with X[2b] = (S(0)[b − τL] + S(1)[b − τL]) to recover S(0)[b − τL] within delay τ . Hence, S(0)[b − τL] is decoded within delay τ . Either X[b] = S(1)[b − τL] is received or X[2b] = (S(0)[b − τL] + S(1)[b − τL]) is received and S(0)[b − τL] is decoded by time slot 2b. Thus, S(1)[b − τL]

is recovered within delay τ .

Ofﬂine scheme for message size sequence 2: Each message packet S[i] is transmitted in the corresponding channel

packet X[i]. d redundant symbols are sent in the next τL channel packets. These dτL symbols are used to decode

11

(a) the ﬁrst (b − τL) message packets when the corresponding channel packets are lost and (b) S[b] when both

X[b − τL] = S[b − τL] and X[b] = S[b] are dropped. A parity check of S[b − τL] and S[b] is sent in X[2b] to

ensure that S[b − τL] is recovered if X[b − τL] is dropped. The scheme is described in full detail below:

• S[i] = X[i] is transmitted for i ∈ [b − τL] ∪ {b}.

• X[b + 1] = (S[0] + S[b]) is transmitted.

• X[i + b + 1] = (X[b + i] + S[i]) is transmitted for i ∈ {1, . . . , b − τL − 1}.

• X[2b] = (S[b] + S[b − τL]) is transmitted.

Verifying constraints: Satisfaction of the lossless-delay constraint is immediate, since each message packet is

transmitted within delay (0 ≤ τL). We verify that the worst-case-delay is met by showing each message packet is

decoded within delay τ . Either X[0] = S[0] is received or both X[b] = S[b] and X[b + 1] = (S[0] + X[b]) are

received. Consequently, S[0] is decoded within delay (b + 1 ≤ τ ). For i ∈ {1, . . . , b − τL − 1}, either X[i] = S[i] is

received or both X[i + b] and X[i + b + 1] = (X[i + b] + S[i]) is received. Therefore, each S[i] is recovered within

delay (b + 1 ≤ τ ). Either X[b − τL] = S[b − τL] is received or X[2b − τL] = (S[b] +

b−τL−1 i=0

S[i])

is

received.

In

the latter case, S[0], . . . , S[b − τL] are decoded by time slot (b − τL + τ ) and combined with X[2b − τL] to decode

S[b]. Then, S[b] and X[2b] = (S[b] + S[b − τL]) used to recover S[b − τL]. Therefore, S[b − τL] is decoded within

delay τ . Either X[b] = S[b] is received or X[2b] = (S[b] + S[b − τL]) is received and S[b − τL] is decoded by time

slot 2b. Hence, S[b] is recovered within delay τ . High level converse: The construction presented above shows that the ofﬂine-optimal-rate is at least Rt(1) and
Rt(2) on message size sequences 1 and 2 respectively. Next, we present necessary and mutually exclusive conditions on the total number of symbols sent in X[0], . . . , X[b − 1] for a code construction to attain rates at least Rt(1) and Rt(2) on the two respective message size sequences. The two message size sequences are the same until time slot
b. Therefore, any online coding scheme violates the condition on one or both message size sequence(s). Condition for rate Rt(1) on message size sequence 1: Consider an arbitrary coding scheme for message size
sequence 1. At least d(b − τL + 1) symbols are transmitted in X[b], . . . , X[t] since X[0], . . . , X[b − 1] could be

dropped in a burst. At most an additional d(b − τL + .5) symbols can be sent over X[0], . . . , X[b − 1] if the rate is at least Rt(1).
Condition for rate Rt(2) on message size sequence 2: Consider any coding scheme for message size sequence 2.
It will be shown that if no more than d(b − τL + .5) symbols are sent over X[0], . . . , X[b − 1], then the rate must be strictly less than Rt(2). First, at least d(b − τL + 2) symbols are sent in X[0], . . . , X[b − 1], X[2b], . . . , X[t] to satisfy
the worst-case-delay constraint when X[b], . . . , X[2b − 1] are lost. Second, at least d(b − τL + 1.5) symbols must

be sent in X[b], . . . , X[2b − 1] for the lossless-delay and worst-case-delay constraints to be satisﬁed; this will be

described in detail below. In total, this is d(2b − 2τL + 3.5) symbols. In contrast, at most d(2b − 2τL + 3) symbols are transmitted as part of a scheme with rate at least Rt(2).
The following notation is used. Let S(−) = (S[0], . . . , S[b − τL − 1]), S(+) = (S[b − τL], S[b]), X(−) =
(X[0], . . . , X[b − 1]), X(∗) = (X[b], . . . , X[2b − 1]), and X(+) = (X[2b], . . . , X[b + τ ]). S is a random variable

representing an arbitrary symbol of an arbitrary message packet. By assumption, d ≤ d(b − τL + .5) symbols are transmitted in X(−).
Consider a burst loss of X(∗). It will be demonstrated that at least d(b − τL + 2) symbols are sent in X(−), X(+). Equations which will be used later will also be derived. All message packets of S(−) must be decoded by time slot

(2b − 1) to meet the worst-case-delay constraint. Therefore,

H(S(−)|X(−)) = 0.

(6)

As a consequence, d ≥ (b − τL)d. In order to meet the worst-case-delay constraints with X(∗) lost,
H(S(−), S(+)|X(−), X(+)) = 0.

Due to the sizes of the message packets and the chain rule

d(b − τL + 2)H(S) = H(S(−), S(+))

≤ H(S(−), S(+), X(−), X(+))

(7)

= H(X(−), X(+)) + H(S(−), S(+)|X(−), X(+))

12

It therefore remains to prove that H(X(∗)) ≥ d(b − τL + 1.5)H(S). Doing so will involve ﬁrst deriving a few

equations.

In order to satisfy the lossless-delay constraint, all message packets are decoded by time slot (b + τL) in lossless

transmission. Due to the assumptions of Lemma 2, (τL < b), so (τ = b + τL < 2b). This leads to the following

equation:

H(S(−), S(+)|X(−), X(∗)) = 0.

(8)

Consider a burst loss of X(−). All of S(−) must be decoded by time slot (b − τL − 1 + τ = 2b − 1) in order to satisfy the worst-case-delay constraint. This derives the next equation:

H(S(−)|X(∗)) = 0.

(9)

Applying the chain rule and Equation 6 determines H(X(−), S(−)) = H(X(−)) + H(S(−)|X(−)) = H(X(−)) ≤ d H(S).

Applying the chain rule in the reverse order and substituting the value of H(S(−)) derives H(X(−), S(−)) = H(S(−)) + H(X(−)|S(−)) = d(b − τL)H(S) + H(X(−)|S(−)).

Combining the above expressions leads to the following equation:

H(X(−)|S(−)) ≤ d − d(b − τL) H(S)

(10)

Considering the sizes of the message packets, applying the chain rule, and then substituting Equations 8 and 9 yields
d(b − τL + 2)H(S) ≤ H(S(−), S(+)) ≤ H(S(−), S(+), X(−), X(∗)) ≤ H(X(∗)) + H(S(−)|X(∗)) + H(X(−)|S(−)) + H(S(+)|X(−), X(∗)) ≤ H(X(∗)) + H(X(−)|S(−))

Applying Equation 10 to the above expression and rearranging terms yields

d(2b − 2τL + 2) − d H(S) ≤ H(X(∗)).

(11)

The total number of symbols sent in X(−) and X(+) is at least d(b − τL + 2) by Equation 7. At least (d(2b − 2τL + 2) − d ) symbols are sent in X(∗) by Equation 11. In total, the number of symbols sent is at least

d(3b − 3τL + 4) − d ≥ (d(3b − 3τL + 4) − d(b − τL + .5)) = (d(2b − 2τL + 3.5)) .
In order to have rate at least Rt(2), at most d(2b − 2τL + 3) symbols are sent in total. Thus, the rate is strictly lower than Rt(2).
Conclude converse: Hence, for any online scheme with rate at least Rt(1) on message size sequence 1, at most d(b − τL + .5) symbols are sent over X[0], . . . , X[b − 1]. Consequently, the rate is strictly less than Rt(2) on message size sequence 2.

13

D. Proof of Lemma 3

Proof: Let d be an arbitrary integer. Consider the following two message size sequences:

1) kj(1) = d for j ∈ [b − 1] and kj(1) = 0 for j ∈ {b, . . . , t}. 2) kj(2) = d for j ∈ [τ − τL − 2], kτ(2−)τL−1 = d(τL + 1), and kj(2) = 0 for j ∈ {τ − τL, . . . , t}.

We

will

describe

an

ofﬂine

coding

scheme

applicable

to

message

size

sequence

1

or

2

which

has

rates

Rt(1)

=

b 2b−.5

and

Rt(2)

=

τ τ +b

on

the

two

respective

message

size

sequences.

For

each

message

size

sequence

we

also

verify

that

the lossless-delay and worst-case-delay constraints are satisﬁed.

Ofﬂine scheme for message size sequence 1: Each of S[0], . . . , S[b − 2] is transmitted immediately as part of the

corresponding channel packet. The message packet S[b − 1] is divided in half to be sent over X[b − 1] and X[b]. d

parity symbols are sent in each of the following (b − 1) channel packets. These d(b − 1) parity symbols are used

to decode (a) message packets S[0], . . . , S[b − 2] when the corresponding channel packets are lost and (b) X[b]

when both X[b − 1] and X[b] are lost. A parity check of X[b − 1] and X[b] is sent in X[2b] to ensure S[b − 1] is

decoded within delay τ . The scheme is described in detail below:

• The message packets S[0] and S[b − 1] are divided in half into S[0] = (S(0)[0], S(1)[0]) and S[b − 1] =

(S(0)[b − 1], S(1)[b − 1]) .

• X[j] = S[j] is transmitted for 0 ≤ j < b − 1.

• X[b − 1] = S(0)[b − 1] is transmitted.

• X[b] = S(1)[b − 1] is transmitted.

• X[b + 1] = (S(0)[0], S(1)[0] + S(1)[b − 1]) is transmitted.

• X[i + b + 1] = (X[i + b] + S[i]) is transmitted for i ∈ {1, . . . , b − 2}.

• X[2b] = (S(0)[b − 1] + S(1)[b − 1]) is transmitted.

Verifying constraints: The lossless-delay constraint is satisﬁed, since each message packet is sent within delay

(1 ≤ τL). We now validate that the worst-case-delay constraint is met for each message packet. Either X[0] = S[0] is received or X[b] = S1[b−1] and X[b+1] = (S(0)[0], S(1)[0]+S(1)[b−1]) are received. Thus, S[0] is decoded within

delay (b+1 ≤ τ ). For (1 ≤ j < b−1) either X[j] = S[j] is received or X[j +b] and X[j +b+1] = (X[j +b]+S[j]) are both received. Hence, S[j] is decoded within delay (b + 1 ≤ τ ). Either X[b − 1] = S(0)[b − 1] is received or it

is dropped and X[2b − 1] is received. In the latter case, S[0], . . . , S[b − 2] are decoded by time slot (2b − 1) and

are combined with X[2b − 1] = (S(0)[0], S(1)[0] + S(1)[b − 1]) +

b−2 i=1

S

[i]

to recover S(1)[b − 1]. The receiver

then decodes S(0)[b − 1] = (X[2b] − S(1)[b − 1]) within delay (b + 1 ≤ τ ). Either X[b] = S(1)[b − 1] is received or X[2b] = (S(0)[b − 1] + S(1)[b − 1]) is received. In the second case, S(0)[b − 1] is decoded by time slot 2b and is combined with X[2b] to recover S(1)[b − 1] within delay τ .

Ofﬂine scheme for message size sequence 2: Each of S[0], . . . , S[τ −τL−2] is transmitted within the corresponding

channel packet. The symbols of S[τ − τL − 1] are evenly divided into (τL + 1) components sent over X[τ − τL −

1], . . . , X[τ − 1] respectively. d blocks of [τ + b, τ ] systematic block codes (described in the proof of Lemma 1)

are created by sending d redundant symbols in each of X[τ ], . . . , X[τ + b − 1]. The scheme is presented in detail

below:

• X[j] = S[j] is transmitted for 0 ≤ j < τ − τL. • The message packet S[τ − τL − 1] is divided evenly into (τL + 1) components: (S(0)[τ − τL − 1], . . . , S(τL)[τ −
τL − 1]). • X[j] = S(j−τ+τL+1)[τ − τL − 1] is transmitted for j ∈ {τ − τL − 1, . . . , τ − 1}.
• For each z ∈ [d − 1], an instance of the block code from [8] is created which maps (Xz[0], . . . , Xz[τ − 1]) to (Xz[0], . . . , Xz[τ − 1], p(0z), . . . , p(bz−)1).
• X[τ + j] = (p(j0), . . . , p(jd−1)) is transmitted for j ∈ [b − 1].
Verifying constraints: The lossless-delay constraint is satisﬁed, since each message packet is sent within delay (0 ≤ τL). Properties of the block code (Xz[0], . . . , Xz[τ − 1], p(0z), . . . , p(bz−)1) ensure for z ∈ [d − 1] that: (a) Each symbol Xz[i] for i ∈ [b − 1] is decoded within delay τ . (b) Each symbol Xz[i] for i ∈ [τ − 1] \ [b − 1] is decoded
by time slot (τ + b − 1). Thus, the worst-case-delay constraint is satisﬁed. High level converse: The rates Rt(1) and Rt(2) of the above construction for message size sequences 1 and 2
respectively serve as a lower bound on the ofﬂine-optimal-rate for the two message size sequences. Next, we

14

present mutually exclusive conditions on the number of symbols transmitted in the ﬁrst b channel packets to have rates at least Rt(1) or Rt(2) on message size sequences 1 or 2 respectively. All online coding schemes cannot

differentiate between the two message size sequences prior to time slot b. Hence, the number of symbols sent in

X[0], . . . , X[b − 1] under any online scheme violates the condition for at least one message size sequence. Condition for rate Rt(1) on message size sequence 1: Consider any coding scheme for message size sequence 1.

At least db symbols are transmitted in X[b], . . . , X[t] in case there is a burst loss of X[0], . . . , X[b − 1]. At most d(b − .5) additional symbols are sent in X[0], . . . , X[b − 1] if the rate is at least Rt(1).
Condition for rate Rt(2) on message size sequence 2: Consider any coding scheme for message size sequence 2.

We will demonstrate that if at most d(b − .5) symbols are sent X[0], . . . , X[b − 1] then the rate is strictly less than Rt(2) = τ+τ b . At a high level, the argument uses the following steps. (a) All symbols are shown to be transmitted by X[τ + b − 1] without loss of generality. (b) A loss pattern under the C(b, w > τ ) channel which drops strictly

more than db symbols is identiﬁed. When such a loss occurs, at least dτ additional symbols are sent to meet the worst-case-delay constraint. This leads to a rate strictly less than Rt(2).

First, each of S[0], . . . , S[τ − τL − 1] are recovered by X[τ − 1] under lossless transmission. If any of the channel

packets X[0], . . . , X[b−1] are lost, S[0], . . . , S[b−1] (and X[0], . . . , X[b−1]) are recovered by time slot (τ +b−1).

Moreover, X[τ + b − 1] can only be dropped if X[b], . . . , X[τ − 1] are received. Thus, whenever X[τ + b − 1]

is lost, S[0], . . . , S[τ − τL − 1] are recovered by time slot (τ + b − 1). Hence, any symbols sent after time slot

(τ + b − 1) can be sent instead in X[τ + b − 1].

Second, consider the following erasure channels Ci for i ∈ [τ + b − 1]. Each Ci introduces bursts of packet

losses in {X[j], . . . , X[j + b − 1] | j ≡ i mod τ + b} and results in li lost (dropped) symbols. At least d(τ + b)

symbols are sent in total due to the upper bound on the rate of τ+τ b . Each packet is dropped by exactly b channels.

Therefore,

τ +b−1 i=0

li

=

db(τ

+

b).5

Consequently,

the

Ci

on

average

drop

db

symbols

1 τ +b−1 τ + b li = db. (12)
i=0

Under the assumption that the number of symbols in X[0], . . . , X[b−1] is at most d(b−.5), l0 ≤ d(b−.5). Applying

this

to

Equation

12

shows

that

1 τ +b−1

τ +b−1 i=1

li

≥

(db

+

τ +.5bd−1 ).

Hence,

there

is

some

i

∈

{1,

.

.

.

,

τ

+

b

−

1}

for

which li ≥ (db + τ+.5bd−1 ). In order to satisfy the worst-case-delay constraint over channel Ci, at least dτ symbols

are received outside of the channel packets dropped by Ci. Thus, the total number of symbols sent is at least d(τ + b + τ+.b5−1 ). In contrast, at most d(τ + b) symbols are sent if the rate is at least Rt(2).
Conclude converse: Hence, for any online coding scheme with rate at least Rt(1) on message size sequence 1, at most d(b − .5) symbols are transmitted in X[0], . . . , X[b − 1]. This ensures that the rate is strictly lower than Rt(2)

on message size sequence 2.

REFERENCES
[1] A. Badr, A. Khisti, W. Tan, and J. Apostolopoulos, “Perfecting protection for interactive multimedia: A survey of forward error correction for low-delay interactive applications,” IEEE Signal Processing Magazine, vol. 34, no. 2, pp. 95–113, March 2017.
[2] E. Martinian and C. . W. Sundberg, “Burst erasure correction codes with low decoding delay,” IEEE Transactions on Information Theory, vol. 50, no. 10, pp. 2494–2502, Oct 2004.
[3] M. Rudow and K. V. Rashmi, “Streaming codes for variable-size arrivals,” in 2018 56th Annual Allerton Conference on Communication, Control, and Computing (Allerton), Oct 2018, pp. 733–740.
[4] E. Martinian and M. Trott, “Delay-optimal burst erasure code construction,” in 2007 IEEE International Symposium on Information Theory, June 2007, pp. 1006–1010.
[5] S. L. Fong, A. Khisti, B. Li, W. Tan, X. Zhu, and J. Apostolopoulos, “Optimal streaming codes for channels with burst and arbitrary erasures,” IEEE Transactions on Information Theory, vol. 65, no. 7, pp. 4274–4292, July 2019.
[6] M. N. Krishnan and P. V. Kumar, “Rate-optimal streaming codes for channels with burst and isolated erasures,” in 2018 IEEE International Symposium on Information Theory (ISIT), June 2018, pp. 1809–1813.
[7] D. Dudzicz, S. L. Fong, and A. Khisti, “An explicit construction of optimal streaming codes for channels with burst and arbitrary erasures,” IEEE Transactions on Communications, vol. 68, no. 1, pp. 12–25, 2020.
5A similar argument was used to show the upper bound on rate of τ+τ b in [4].

15

[8] M. N. Krishnan, D. Shukla, and P. V. Kumar, “A quadratic ﬁeld-size rate-optimal streaming code for channels with burst and random erasures,” in 2019 IEEE International Symposium on Information Theory (ISIT), 2019, pp. 852–856.
[9] E. Domanovitz, S. L. Fong, and A. Khisti, “An explicit rate-optimal streaming code for channels with burst and arbitrary erasures,” in 2019 IEEE Information Theory Workshop (ITW), 2019, pp. 1–5.
[10] N. Adler and Y. Cassuto, “Burst-erasure correcting codes with optimal average delay,” IEEE Transactions on Information Theory, vol. 63, no. 5, pp. 2848–2865, May 2017.
[11] Z. Li, A. Khisti, and B. Girod, “Correcting erasure bursts with minimum decoding delay,” in 2011 Conference Record of the Forty Fifth Asilomar Conference on Signals, Systems and Computers (ASILOMAR), Nov 2011, pp. 33–39.
[12] A. Badr, A. Khisti, W. Tan, and J. Apostolopoulos, “Streaming codes with partial recovery over channels with burst and isolated erasures,” IEEE Journal of Selected Topics in Signal Processing, vol. 9, no. 3, pp. 501–516, April 2015.
[13] A. Badr, P. Patil, A. Khisti, W. Tan, and J. Apostolopoulos, “Layered constructions for low-delay streaming codes,” IEEE Transactions on Information Theory, vol. 63, no. 1, pp. 111–141, Jan 2017.
[14] Y. Wei and T. Ho, “On prioritized coding for real-time streaming under packet erasures,” in Communication, Control, and Computing (Allerton), 2013 51st Annual Allerton Conference on. IEEE, 2013, pp. 327–334.
[15] D. Leong and T. Ho, “Erasure coding for real-time streaming,” in 2012 IEEE International Symposium on Information Theory Proceedings, July 2012, pp. 289–293.
[16] D. Leong, A. Qureshi, and T. Ho, “On coding for real-time streaming under packet erasures,” in 2013 IEEE International Symposium on Information Theory, July 2013, pp. 1012–1016.
[17] M. Haghifam, A. Badr, A. Khisti, X. Zhu, W. Dan, and J. Apostolopoulos, “Streaming codes with unequal error protection against burst losses,” in 2018 29th Biennial Symposium on Communications (BSC), June 2018, pp. 1–5.
[18] M. N. Krishnan, V. Ramkumar, M. Vajha, and P. V. Kumar, “Simple streaming codes for reliable, low-latency communication,” IEEE Communications Letters, pp. 1–1, 2019.
16

