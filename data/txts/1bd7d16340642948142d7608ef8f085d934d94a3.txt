Published as a conference paper at ICLR 2020

arXiv:1905.13278v2 [math.OC] 16 Feb 2020

A STOCHASTIC DERIVATIVE FREE OPTIMIZATION METHOD WITH MOMENTUM

Eduard Gorbunov∗ MIPT, Russia and IITP RAS, Russia and RANEPA, Russia eduard.gorbunov@phystech.edu

Adel Bibi KAUST, Saudi Arabia adel.bibi@kaust.edu.sa

Ozan Sener Intel Labs ozan.sener@intel.com

El Houcine Bergou KAUST, Saudi Arabia and MaIAGE, INRA, France elhoucine.bergou@inra.fr

Peter Richtárik KAUST, Saudi Arabia and MIPT, Russia peter.richtarik@kaust.edu.sa

ABSTRACT
We consider the problem of unconstrained minimization of a smooth objective function in Rd in setting where only function evaluations are possible. We propose and analyze stochastic zeroth-order method with heavy ball momentum. In particular, we propose, SMTP, a momentum version of the stochastic three-point method (STP) Bergou et al. (2019). We show new complexity results for non-convex, convex and strongly convex functions. We test our method on a collection of learning to continuous control tasks on several MuJoCo Todorov et al. (2012) environments with varying difﬁculty and compare against STP, other state-of-the-art derivative-free optimization algorithms and against policy gradient methods. SMTP signiﬁcantly outperforms STP and all other methods that we considered in our numerical experiments. Our second contribution is SMTP with importance sampling which we call SMTP_IS. We provide convergence analysis of this method for non-convex, convex and strongly convex objectives.

1 INTRODUCTION

In this paper, we consider the following minimization problem

min f (x),

(1)

x∈Rd

where f : Rd → R is "smooth" but not necessarily a convex function in a Derivative-Free Optimization (DFO) setting where only function evaluations are possible. The function f is bounded from below by f (x∗) where x∗ is a minimizer. Lastly and throughout the paper, we assume that f is
L-smooth.

DFO. In DFO setting Conn et al. (2009); Kolda et al. (2003), the derivatives of the objective function f are not accessible. That is they are either impractical to evaluate, noisy (function f is noisy) (Chen, 2015) or they are simply not available at all. In standard applications of DFO, evaluations of f are only accessible through simulations of black-box engine or software as in reinforcement learning and continuous control environments Todorov et al. (2012). This setting of optimization problems appears also in applications from computational medicine Marsden et al. (2008) and ﬂuid dynamics Allaire (2001); Haslinger & Mäckinen (2003); Mohammadi & Pironneau (2001) to localization Marsden et al. (2004; 2007) and continuous control Mania et al. (2018); Salimans et al. (2017) to name a few.

The literature on DFO for solving (1) is long and rich. The ﬁrst approaches were based on deterministic direct search (DDS) and they span half a century of work Hooke & Jeeves (1961); Su (1979); Torczon

∗The research of Eduard Gorbunov was supported by RFBR, project number 18-31-20005 mol_a_ved

1

Published as a conference paper at ICLR 2020
(1997). However, for DDS methods complexity bounds have only been established recently by the work of Vicente and coauthors Vicente (2013); Dodangeh & Vicente (2016). In particular, the work of Vicente Vicente (2013) showed the ﬁrst complexity results on non-convex f and the results were extended to better complexities when f is convex Dodangeh & Vicente (2016). However, there have been several variants of DDS, including randomized approaches Matyas (1965); Karmanov (1974a;b); Baba (1981); Dorea (1983); Sarma (1990). Only very recently, complexity bounds have also been derived for randomized methods Diniz-Ehrhardt et al. (2008); Stich et al. (2011); Ghadimi & Lan (2013); Ghadimi et al. (2016); Gratton et al. (2015). For instance, the work of Diniz-Ehrhardt et al. (2008); Gratton et al. (2015) imposes a decrease condition on whether to accept or reject a step of a set of random directions. Moreover, Nesterov & Spokoiny (2017) derived new complexity bounds when the random directions are normally distributed vectors for both smooth and non-smooth f . They proposed both accelerated and non-accelerated zero-order (ZO) methods. Accelerated derivative-free methods in the case of inexact oracle information was proposed in Dvurechensky et al. (2017). An extension of Nesterov & Spokoiny (2017) for non-Euclidean proximal setup was proposed by Gorbunov et al. (2018) for the smooth stochastic convex optimization with inexact oracle. In Stich (2014a;b) authors also consider acceleration of ZO methods and, in particular, develop the method called SARP, proved that its convergence rate is not worse than for non-accelerated ZO methods and showed that in some cases it works even better.
More recently and closely related to our work, Bergou et al. (2019) proposed a new randomized direct search method called Stochastic Three Points (STP). At each iteration k STP generates a random search direction sk according to a certain probability law and compares the objective function at three points: current iterate xk, a point in the direction of sk and a point in the direction of −sk with a certain step size αk. The method then chooses the best of these three points as the new iterate:
xk+1 = arg min{f (xk), f (xk + αksk), f (xk − αksk)}.
The key properties of STP are its simplicity, generality and practicality. Indeed, the update rule for STP makes it extremely simple to implement, the proofs of convergence results for STP are short and clear and assumptions on random search directions cover a lot of strategies of choosing decent direction and even some of ﬁrst-order methods ﬁt the STP scheme which makes it a very ﬂexible in comparison with other zeroth-order methods (e.g. two-point evaluations methods like in Nesterov & Spokoiny (2017), Ghadimi & Lan (2013), Ghadimi et al. (2016), Gorbunov et al. (2018) that try to approximate directional derivatives along random direction at each iteration). Motivated by these properties of STP we focus on further developing of this method.
Momentum. Heavy ball momentum1 is a special technique introduced by Polyak in 1964 Polyak (1964) to get faster convergence to the optimum for the ﬁrst-order methods. In the original paper,
Polyak proved that his method converges locally with O L/µ log 1/ε rate for twice continuously differentiable µ-strongly convex and L-smooth functions. Despite the long history of this approach, there is still an open question whether heavy ball method converges to the optimum globally with accelerated rate when the objective function is twice continuous differentiable, L-smooth and µstrongly convex. For this class of functions, only non-accelerated global convergence was proved Ghadimi et al. (2015) and for the special case of quadratic strongly convex and L-smooth functions Lessard et. al. Lessard et al. (2016) recently proved asymptotic accelerated global convergence. However, heavy ball method performs well in practice and, therefore, is widely used. One can ﬁnd more detailed survey of the literature about heavy ball momentum in Loizou & Richtárik (2017).
Importance Sampling. Importance sampling has been celebrated and extensively studied in stochastic gradient based methods Zhao & Zhang (2015) or in coordinate based methods Richtárik & Takácˇ (2016). Only very recently, Bibi et al. (2019) proposed, STP_IS, the ﬁrst DFO algorithm with importance sampling. In particular, under coordinate-wise smooth function, they show that sampling coordinate directions, can be generalized to arbitrary directions, with probabilities proportional to the function coordinate smoothness constants, improves the leading constant by the same factor typically gained in gradient based methods.
Contributions. Our contributions can be summarized into three folds.
• First ZO method with heavy ball momentum. Motivated by practical effectiveness of ﬁrst-order momentum heavy ball method, we introduce momentum into STP method and
1We will refer to this as momentum.
2

Published as a conference paper at ICLR 2020

Algorithm 1 SMTP: Stochastic Momentum Three Points

Require: learning rates {γk}k≥0, starting point x0 ∈ Rd, D — distribution on Rd, 0 ≤ β < 1 —

momentum parameter

1: Set v−1 = 0 and z0 = x0

2: for k = 0, 1, . . . do

3: Sample sk ∼ D

4: Let v+k = βvk−1 + sk and v−k = βvk−1 − sk

5: Let xk++1 = xk − γkv+k and xk−+1 = xk − γkv−k

6:

Let

z+k+1

=

xk++1

−

γkβ 1−β

v+k

and

z−k+1

=

xk−+1

−

γkβ 1−β

v−k

7:

Set zk+1 = arg min

f

(z

k

),

f

(z

k+1 +

),

f

(z−k+1

)

xk++1, if zk+1 = z+k+1 

v+k+1, if zk+1 = z+k+1 

8: Set xk+1 = xk−+1, if zk+1 = z−k+1 and vk+1 = v−k+1, if zk+1 = z−k+1

xk, if zk+1 = zk

vk, if zk+1 = zk

9: end for

propose new DFO algorithm with heavy ball momentum (SMTP). We summarized the method in Algorithm 1, with theoretical guarantees for non-convex, convex and strongly convex functions under generic sampling directions D. We emphasize that the SMTP with momentum is not a straightforward generalization of STP and Polyak’s method and requires insights from virtual iterates analysis from Yang et al. (2016).
To the best of our knowledge it is the ﬁrst analysis of derivative-free method with heavy ball momentum, i.e. we show that the same momentum trick that works for the ﬁrst order method could be applied for zeroth-order methods as well.
• First ZO method with both heavy ball momentum and importance sampling. In order to get more gain from momentum in the case when the sampling directions are coordinate directions and the objective function is coordinate-wise L-smooth (see Assumption 4.1), we consider importance sampling to the above method. In fact, we propose the ﬁrst zeroth-order momentum method with importance sampling (SMTP_IS) summarized in Algorithm 2 with theoretical guarantees for non-convex, convex and strongly convex functions. The details and proofs are left for Section 4 and Appendix E.
• Practicality. We conduct extensive experiments on continuous control tasks from the MuJoCo suite Todorov et al. (2012) following recent success of DFO compared to modelfree reinforcement learning Mania et al. (2018); Salimans et al. (2017). We achieve with SMTP_IS the state-of-the-art results on across all tested environments on the continuous control outperforming DFO Mania et al. (2018) and policy gradient methods Schulman et al. (2015); Rajeswaran et al. (2017).
We provide more detailed comparison of SMTP and SMTP_IS in Section E.4 of the Appendix.

2 NOTATION AND DEFINITIONS

We use · p to deﬁne p-norm of the vector x ∈ Rd: x p d=ef di=1 |xi|p 1/p for p ≥ 1 and

x ∞ d=ef maxi∈[d] |xi| where xi is the i-th component of vector x, [d] = {1, 2, . . . , d}. Operator E[·]

denotes mathematical expectation with respect to all randomness and Es∼D[·] denotes conditional

expectation w.r.t. randomness coming from random vector s which is sampled from probability

distribution D on Rd. To denote standard inner product of two vectors x, y ∈ Rd we use x, y d=ef

d i=1

xiyi,

ei

denotes

i-th

coordinate

vector

from

standard

basis

in

Rd,

i.e.

x

=

d i=1

xiei.

We

use

· ∗ to deﬁne the conjugate norm for the norm · : x ∗ d=ef max a, x | a ∈ Rd, a ≤ 1 .

As we mention in the introduction we assume throughout the paper2 that the objective function f is L-smooth.

2We will use thinner assumption in Section 4.

3

Published as a conference paper at ICLR 2020

Assumptions on f
None Convex, R0 < ∞ µ-strongly convex

SMTP Complexity

ln 2r0 LγD

µ2D ε2

1 LγD R02

2r0

ε µ2D ε

µµL2 ln

2r0 ε

D

Theorem
3.1 3.2 3.5

Importance Sampling

pi = pi = pi =

Li

d i=1

Li

Li

d i=1

Li

Li

d i=1

Li

SMTP_IS Complexity

2r0 d

d i=1

Li

ε2

ln R02 d

d i=1

Li

2r0

ε

ε

ln d
i=1

Li

2r0

µ

ε

Theorem
E.1 E.2 E.5

Table 1: Summary of the new derived complexity results of SMTP and SMTP_IS. The complexities

for SMTP are under a generic sampling distribution D satisfying Assumption 3.1 while for SMTP_IS

are under an arbitrary discrete sampling from a set of coordinate directions following Bibi et al.

(2019) where we propose an importance sampling that improves the leading constant marked in red.

Note that r0 = f (x0) − f (x∗) and that all assumptions listed are in addition to Assumption 2.1.

Complexity means number of iterations in order to guarantee E ∇f (zK) D ≤ ε for the non-convex

case, E f (zK ) − f (x∗) ≤ ε for convex and strongly convex cases. R0 < ∞ is the radius in

· ∗D-norm of a bounded level set where the exact deﬁnition is given in Assumption 3.2. We

notice that for SMTP_IS

· D=

· 1 and

·

∗ D

=

· ∞ in non-convex and convex cases and

· D = · 2 in the strongly convex case.

Assumption 2.1. (L-smoothness) We say that f is L-smooth if

∇f (x) − ∇f (y) 2 ≤ L x − y 2 ∀x, y ∈ Rd.

(2)

From this deﬁnition one can obtain |f (y) − f (x) − ∇f (x), y − x | ≤ L2 y − x 22, ∀x, y ∈ Rd, (3)

and if additionally f is convex, i.e. f (y) ≥ f (x) + ∇f (x), y − x , we have

∇f (x)

2 2

≤ 2L(f (x) − f (x∗)),

∀x ∈ Rd.

(4)

3 STOCHASTIC MOMENTUM THREE POINTS (SMTP)

Our analysis of SMTP is based on the following key assumption. Assumption 3.1. The probability distribution D on Rd satisﬁes the following properties:

1.

The

quantity

γD

def
=

Es∼D

s

2 2

is

ﬁnite.

2. There is a constant µD > 0 for a norm · D in Rd such that for all g ∈ Rd

Es∼D| g, s | ≥ µD g D.

(5)

Some examples of distributions that meet above assumption are described in Lemma 3.4 from Bergou et al. (2019). For convenience we provide the statement of the lemma in the Appendix (see Lemma F.1).

Recall that one possible view on STP Bergou et al. (2019) is as following. If we substitute gradient ∇f (xk) in the update rule for the gradient descent xk+1 = xk − γk∇f (xk) by ±sk where sk is sampled from distribution D satisﬁed Assumption 3.1 and then select xk+1 as the best point in terms of functional value among xk, xk − γksk, xk + γksk we will get exactly STP method. However,
gradient descent is not the best algorithm to solve unconstrained smooth minimization problems and
the natural idea is to try to perform the same substitution-trick with more efﬁcient ﬁrst-order methods
than gradient descent.

We put our attention on Polyak’s heavy ball method where the update rule could be written in the

following form:

vk = βvk−1 + ∇f (xk), xk+1 = xk − γkvk.

(6)

As in STP, we substitute ∇f (xk) by ±sk and consider new sequences {v+k }k≥0 and {v−k }k≥0 deﬁned in the Algorithm 1. However, it is not straightforward how to choose next xk+1 and vk and

4

Published as a conference paper at ICLR 2020

the virtual iterates analysis Yang et al. (2016) hints the update rule. We consider new iterates z+k+1 =

xk++1

−

γkβ 1−β

v+k

and

z−k+1

=

xk−+1

−

γkβ 1−β

v−k

and

deﬁne

zk+1

as

arg

min

f (zk), f (z+k+1), f (z−k+1)

.

Next we update xk+1 and vk in order to have the same relationship between zk+1, xk+1 and vk as

between z+k+1, xk++1 and v+k and z−k+1, xk−+1 and v−k . Such scheme allows easily apply virtual iterates

analysis and and generalize Key Lemma from Bergou et al. (2019) which is the main tool in the

analysis of STP.

By deﬁnition of zk+1, we get that the sequence {f (zk)}k≥0 is monotone:

f (zk+1) ≤ f (zk) ∀k ≥ 0.

(7)

Now, we establish the key result which will be used to prove the main complexity results and remaining theorems in this section.
Lemma 3.1. Assume that f is L-smooth and D satisﬁes Assumption 3.1. Then for the iterates of SMTP the following inequalities hold:

k+1

k

γk

kk

L(γk)2 k 2

f (z

) ≤ f (z ) −

| ∇f (z ), s

1−β

| + 2(1 − β)2 s

2

(8)

and

k+1

k γkµD

k

L(γ k )2 γD

Esk∼D f (z

)

≤ f (z

)− 1−β

∇f (z

)

D + 2(1 − β)2 .

(9)

3.1 NON-CONVEX CASE

In this section, we show our complexity results for Algorithm 1 in the case when f is allowed to be non-convex. In particular, we show that S√MTP in Algorithm 1 guarantees complexity bounds with the same order as classical bounds, i.e. 1/ K where K is the number of iterations, in the literature. We notice that query complexity (i.e. number of oracle calls) of SMTP coincides with its iteration complexity up to numerical constant factor. For clarity and completeness, proofs are left for the appendix.
Theorem 3.1. Let Assumptions 2.1 and 3.1 be satisﬁed. Let SMTP with γk ≡ γ > 0 produce points {z0, z1, . . . , zK−1} and zK is chosen uniformly at random among them. Then

E ∇f (zK ) D ≤ (1 − β)(f (x0) − f (x∗)) + LγγD . (10)

K γ µD

2µD(1 − β)

Moreover, if we choose γ = √γ0 the complexity (10) reduces to
K

E ∇f (zK )

1 ≤√

(1 − β)(f (z0) − f (x∗)) + Lγ0γD

.

(11)

D
K

γ0µD

2µD(1 − β)

Then γ0 = 2(1−β)2(fL(γxD0)−f(x∗)) minimizes the right-hand side of (11) and for this choice we have

E ∇f (zK ) D ≤ 2 (f (x0) −√f (x∗)) LγD . (12) µD K

In other words, the above theorem states that SMTP converges no worse than STP for non-convex problems to the stationary point. In the next sections we also show that theoretical convergence guarantees for SMTP are not worse than for STP for convex and strongly convex problems. However, in practice SMTP signiﬁcantly outperforms STP. So, the relationship between SMTP and STP correlates with the known in the literature relationship between Polyak’s heavy ball method and gradient descent.

3.2 CONVEX CASE
In this section, we present our complexity results for Algorithm 1 when f is convex. In particular, we show that this method guarantees complexity bounds with the same order as classical bounds, i.e. 1/K, in the literature. We will need the following additional assumption in the sequel.

5

Published as a conference paper at ICLR 2020

Assumption 3.2. We assume that f is convex, has a minimizer x∗ and has bounded level set at x0:

def
R0 = max

x − x∗

∗ D

|

f (x)

≤

f (x0)

< +∞,

(13)

where ξ ∗D d=ef max { ξ, x | x D ≤ 1} deﬁnes the dual norm to · D.

From the above assumption and Cauchy-Schwartz inequality we get the following implication:

f (x) ≤ f (x0) =⇒ f (x) − f (x∗) ≤

∇f (x), x − x∗

≤

∇f (x)

D

x − x∗

∗ D

≤

R0

∇f (x)

D,

which implies f (x) − f (x∗)
∇f (x) D ≥ R0 ∀x : f (x) ≤ f (x0). (14)
Theorem 3.2 (Constant stepsize). Let Assumptions 2.1, 3.1 and 3.2 be satisﬁed. If we set γk ≡ γ < (1−µβD)R0 , then for the iterates of SMTP method the following inequality holds:

E f (zk) − f (x∗) ≤ 1 − γµD k f (x0) − f (x∗) + LγγDR0 . (15)

(1 − β)R0

2(1 − β)µD

If we choose γ = ε(1−β)µD for some 0 < ε ≤ LγDR02 and run SMTP for k = K iterations where

LγD R0

µ2D

1 LγDR02 2(f (x0) − f (x∗))

K= ε

µ2

ln

ε

,

(16)

D

then we will get E f (zK ) − f (x∗) ≤ ε.

In order to get rid of factor ln 2(f(x0)ε−f(x∗)) in the complexity we consider decreasing stepsizes.
Theorem 3.3 (Decreasing stepsizes). Let Assumptions 2.1, 3.1 and 3.2 be satisﬁed. If we set γk = αk2+θ , where α = (1−µβD)R0 and θ ≥ α2 , then for the iterates of SMTP method the following inequality holds:

E f (zk) − f (x∗) ≤ 1 max f (x0) − f (x∗), 2LγD ,

(17)

ηk + 1

αθ(1 − β)2

where η d=ef αθ . Then, if we choose γk = α22kα+2 where α = (1−µβD)R0 and run SMTP for k = K iterations where

1 2R02

2

0

∗

2(1 − β)2R02

K=

· ε

µ2

max

(1 − β) (f (x ) − f (x )), LγD

−

µ2

, ε > 0,

(18)

D

D

we get E f (zK ) − f (x∗) ≤ ε.

We notice that if we choose β sufﬁciently close to 1, we will obtain from the formula (18) that K ≈ 2R02LγD .
εµ2D

3.3 STRONGLY CONVEX CASE

In this section we present our complexity results for Algorithm 1 when f is µ-strongly convex. Assumption 3.3. We assume that f is µ-strongly convex with respect to the norm · ∗D:
f (y) ≥ f (x) + ∇f (x), y − x + µ2 ( y − x ∗D)2, ∀x, y ∈ Rd. (19)

It is well known that strong convexity implies

∇f (x)

2 D

≥ 2µ (f (x) − f (x∗)) .

(20)

6

Published as a conference paper at ICLR 2020

Theorem 3.4 (Solution-dependent stepsizes). Let Assumptions 2.1, 3.1 and 3.3 be satisﬁed. If we set γk = (1−βL)θkµD 2µ(f (zk) − f (x∗)) for some θk ∈ (0, 2) such that θ = inf {2θk − γDθk2} ∈
k≥0
(0, L/(µ2Dµ)), then for the iterates of SMTP, the following inequality holds:
E f (zk) − f (x∗) ≤ 1 − θµ2Dµ k f (x0) − f (x∗) . (21) L

Then, If we run SMTP for k = K iterations where

κ

f (x0) − f (x∗)

K = θµ2 ln

ε

, ε > 0,

(22)

D

where κ d=ef Lµ is the condition number of the objective, we will get E f (zK ) − f (x∗) ≤ ε.

Note that the previous result uses stepsizes that depends on the optimal solution f (x∗) which is often not known in practice. The next theorem removes this drawback without spoiling the convergence rate. However, we need an additional assumption on the distribution D and one extra function evaluation.

Assumption 3.4. We assume that for all s ∼ D we have s 2 = 1.

Theorem 3.5 (Solution-free stepsizes). Let Assumptions 2.1, 3.1, 3.3 and 3.4 be satisﬁed. If additionally we compute f (zk + tsk), set γk = (1−β)|f(zk+tsk)−f(zk)|/(Lt) for t > 0 and assume that D
is such that µ2D ≤ L/µ, then for the iterates of SMTP the following inequality holds:

E f (zk) − f (x∗) ≤ 1 − µ2Dµ k f (x0) − f (x∗) + L2t2 . (23)

L

8µ2D µ

Moreover, for any ε > 0 if we set t such that

0 < t ≤ 4εµ2Dµ ,

(24)

L2

and run SMTP for k = K iterations where

κ

2(f (x0) − f (x∗))

K = µ2 ln

ε

,

(25)

D

where κ d=ef Lµ is the condition number of f , we will have E f (zK ) − f (x∗) ≤ ε.

4 STOCHASTIC MOMENTUM THREE POINTS WITH IMPORTANCE SAMPLING (SMTP_IS)

In this section we consider another assumption, in a similar spirit to Bibi et al. (2019), on the objective.

Assumption 4.1 (Coordinate-wise L-smoothness). We assume that the objective f has coordinatewise Lipschitz gradient, with Lipschitz constants L1, . . . , Ld > 0, i.e.

f (x + hei) ≤ f (x) + ∇if (x)h + Li h2, ∀x ∈ Rd, h ∈ R,

(26)

2

where ∇if (x) is i-th partial derivative of f at the point x.

For this kind of problems we modify SMTP and present STMP_IS method in Algorithm 2. In general, the idea behind methods with importance sampling and, in particular, behind SMTP_IS is to adjust probabilities of sampling in such a way that gives better convergence guarantees. In the case when f satisﬁes coordinate-wise L-smoothness and Lipschitz constants Li are known it is natural to sample direction sk = ei with probability depending on Li (e.g. proportional to Li). One can ﬁnd more detailed discussion of the importance sampling in Zhao & Zhang (2015) and Richtárik & Takácˇ (2016).
Now, we establish the key result which will be used to prove the main complexity results of STMP_IS.

7

Published as a conference paper at ICLR 2020

Algorithm 2 SMTP_IS: Stochastic Momentum Three Points with Importance Sampling

Require: stepsize parameters w1, . . . , wn > 0, probabilities p1, . . . , pn > 0 summing to 1, point x0 ∈ Rd, 0 ≤ β < 1 — momentum parameter
1: Set v−1 = 0 and z0 = x0

2: for k = 0, 1, . . . do

3: Select ik = i with probability pi > 0 4: Choose stepsize γik proportional to w1ik 5: Let v+k = βvk−1 + eik and v−k = βvk−1 − eik

6: Let xk++1 = xk − γikv+k and xk−+1 = xk − γikv−k

7: Let zk+1 = xk+1 − γikβ vk and zk+1 = xk+1 − γikβ vk

+

+

1−β +

−

−

1−β −

8:

Set zk+1 = arg min

f

(z

k

),

f

(z

k+1 +

),

f

(z−k+1

)

xk++1, if zk+1 = z+k+1 

v+k+1, if zk+1 = z+k+1 

9: Set xk+1 = xk−+1, if zk+1 = z−k+1 and vk+1 = v−k+1, if zk+1 = z−k+1

xk, if zk+1 = zk

vk, if zk+1 = zk

starting

10: end for

Lemma 4.1. Assume that f satisﬁes Assumption 4.1. Then for the iterates of SMTP_IS the following

inequalities hold:

k+1

k

γik

k

Li

k

(

γ

k i

)2

f (z ) ≤ f (z ) − 1 − β |∇ik f (z )| + 2(1 − β)2

(27)

and

Esk∼D f (zk+1) ≤ f (zk) − 1 −1 β E γik|∇ik f (zk)| | zk + 2(1 −1 β)2 E Lik (γik)2 | zk . (28)

Due to the page limitation, we provide the complexity results of SMTP_IS in the Appendix.

5 EXPERIMENTS
Experimental Setup. We conduct extensive experiments3 on challenging non-convex problems on the continuous control task from the MuJoCO suit Todorov et al. (2012). In particular, we address the problem of model-free control of a dynamical system. Policy gradient methods for model-free reinforcement learning algorithms provide an off-the-shelf model-free approach to learn how to control a dynamical system and are often benchmarked in a simulator. We compare our proposed momentum stochastic three points method SMTP and the momentum with importance sampling version SMTP_IS against state-of-art DFO based methods as STP_IS Bibi et al. (2019) and ARS Mania et al. (2018). Moreover, we also compare against classical policy gradient methods as TRPO Schulman et al. (2015) and NG Rajeswaran et al. (2017). We conduct experiments on several environments with varying difﬁculty Swimmer-v1, Hopper-v1, HalfCheetah-v1, Ant-v1, and Humanoid-v1.
Note that due to the stochastic nature of problem where f is stochastic, we use the mean of the function values of f (xk), f (xk+) and f (xk−), see Algorithm 1, over K observations. Similar to the work in Bibi et al. (2019), we use K = 2 for Swimmer-v1, K = 4 for both Hopper-v1 and HalfCheetah-v1, K = 40 for Ant-v1 and Humanoid-v1. Similar to Bibi et al. (2019), these values were chosen based on the validation performance over the grid that is K ∈ {1, 2, 4, 8, 16} for the smaller dimensional problems Swimmer-v1, Hopper-v1, HalfCheetah-v1 and K ∈ {20, 40, 80, 120} for larger dimensional problems Ant-v1, and Humanoid-v1. As for the momentum term, for SMTP we set β = 0.5. For SMTP_IS, as the smoothness constants are not available for continuous control, we use the coordinate smoothness constants of a θ parameterized smooth function fˆθ (multi-layer perceptron) that estimates f . In particular, consider running any DFO for n steps; with the queried sampled {xi, f (xi)}ni=1, we estimate f by solving θn+1 = argminθ i(f (xi) − fˆ(xi; θ))2. See Bibi et al. (2019) for further implementation details
3The code will be made available online upon acceptance of this work.

8

Published as a conference paper at ICLR 2020

Average Reward

Swimmer-v1

300

200

100

0

0

50 100 150 200 250 300 350 400

Number of Episodes

Average Reward

3000
2000
1000
0 0

Hopper-v1

1000

2000

3000

4000

Number of Episodes

Average Reward

HalfCheetah-v1

5000 4000 3000 2000 1000
0 0

2000 4000 6000 8000 10000 12000 14000
Number of Episodes

Average Reward

Ant-v1

4000

3000

2000

1000 0

20000 40000 60000 80000 100000 120000 140000
Number of Episodes

Average Reward

Humanoid-v1

6000 4000 2000
00

100000 200000 300000 400000
Number of Episodes

Figure 1: SMTP is far superior to STP on all 5 different MuJoCo tasks particularly on the high dimensional Humanoid-v1 problem. The horizontal dashed lines are the thresholds used in Table 2 to demonstrate complexity of each method.

Table 2: For each MuJoCo task, we report the average number of episodes required to achieve a predeﬁned reward threshold. Results for our method is averaged over ﬁve random seeds, the rest is copied from (Mania et al., 2018) (N/A means the method failed to reach the threshold. UNK means the results is unknown since they are not reported in the literature.)

Threshold STP STPIS SMTP SMTPIS ARS(V1-t) ARS(V2-t) NG-lin TRPO-nn

Swimmer-v1 Hopper-v1
HalfCheetah-v1 Ant-v1
Humanoid-v1

325 3120 3430 3580 6000

320 3970 13760 107220 N/A

110 2400 4420 43860 530200

80 1264 1872 19890 161230

100 1408 1624 14420 207160

100 51840 8106 58133 N/A

427 1973 1707 20800 142600

1450 13920 11250 39240 130000

N/A 10000 4250 73500 UNK

as we follow the same experimental procedure. In contrast to STP_IS, our method (SMTP) does not required sampling from directions in the canonical basis; hence, we use directions from standard Normal distribution in each iteration. For SMTP_IS, we follow a similar procedure as Bibi et al. (2019) and sample from columns of a random matrix B.
Similar to the standard practice, we perform all experiments with 5 different initialization and measure the average reward, in continuous control we are maximizing the reward function f , and best and worst run per iteration. We compare algorithms in terms of reward vs. sample complexity.
Comparison Against STP. Our method improves sample complexity of STP and STP_IS signiﬁcantly. Especially for high dimensional problems like Ant-v1 and Humanoid-v1, sample efﬁciency of SMTP is at least as twice as the STP. Moreover, SMTP_IS helps in some experiments by improving over SMTP. However, this is not consistent in all environments. We believe this is largely due to the fact that SMTP_IS can only handle sampling from canonical basis similar to STP_IS.
Comparison Against State-of-The-Art. We compare our method with state-of-the-art DFO and policy gradient algorithms. For the environments, Swimmer-v1, Hopper-v1, HalfCheetah-v1 and Ant-v1, our method outperforms the state-of-the-art results. Whereas for Humanoid-v1, our methods results in a comparable sample complexity.

6 CONCLUSION
We have proposed, SMTP, the ﬁrst heavy ball momentum DFO based algorithm with convergence rates for non-convex, convex and strongly convex functions under generic sampling direction. We specialize the sampling to the set of coordinate bases and further improve rates by proposing a momentum and importance sampling version SMPT_IS with new convergence rates for non-convex, convex and strongly convex functions too. We conduct large number of experiments on the task of

9

Published as a conference paper at ICLR 2020
controlling dynamical systems. We outperform two different policy gradient methods and achieve comparable or better performance to the best DFO algorithm (ARS) on the respective environments.
REFERENCES
G. Allaire. Shape Optimization by the Homogenization Method. Springer, New York, USA, 2001.
N. Baba. Convergence of a random optimization method for constrained optimization problems. Journal of Optimization Theory and Applications, 33:1–11, 1981.
El Houcine Bergou, Eduard Gorbunov, and Peter Richtárik. Stochastic three points method for unconstrained smooth minimization. arXiv preprint arXiv:1902.03591, 2019.
Adel Bibi, El Houcine Bergou, Ozan Sener, Bernard Ghanem, and Peter Richtárik. Stochastic derivative-free optimization method with importance sampling. arXiv preprint arXiv:1902.01272, 2019.
Ruobing Chen. Stochastic derivative-free optimization of noisy functions. PhD thesis at Lehigh University., 2015.
A. R. Conn, K. Scheinberg, and L. N. Vicente. Introduction to Derivative-Free Optimization. SIAM, Philadelphia, PA, USA, 2009.
M. A. Diniz-Ehrhardt, J. M. Martinez, and M. Raydan. A derivative-free nonmonotone line-search technique for unconstrained optimization. Journal of Optimization Theory and Applications, 219:383–397, 2008.
Mahdi Dodangeh and Luís N Vicente. Worst case complexity of direct search under convexity. Mathematical Programming, 155(1-2):307–332, 2016.
C. Dorea. Expected number of steps of a random optimization method. Journal of Optimization Theory and Applications, 39:165–171, 1983.
Pavel Dvurechensky, Alexander Gasnikov, and Alexander Tiurin. Randomized similar triangles method: A unifying framework for accelerated randomized optimization methods (coordinate descent, directional search, derivative-free method). arXiv preprint arXiv:1707.08486, 2017.
Euhanna Ghadimi, Hamid Reza Feyzmahdavian, and Mikael Johansson. Global convergence of the heavy-ball method for convex optimization. In 2015 European Control Conference (ECC), pp. 310–315. IEEE, 2015.
Saeed Ghadimi and Guanghui Lan. Stochastic ﬁrst-and zeroth-order methods for nonconvex stochastic programming. SIAM Journal on Optimization, 23(4):2341–2368, 2013.
Saeed Ghadimi, Guanghui Lan, and Hongchao Zhang. Mini-batch stochastic approximation methods for nonconvex stochastic composite optimization. Mathematical Programming, 155(1-2):267–305, 2016.
E. Gorbunov, P. Dvurechensky, and A. Gasnikov. An accelerated method for derivative-free smooth stochastic convex optimization. arXiv preprint arXiv:1802.09022, 2018.
S. Gratton, C. W. Royer, L. N. Vicente, and Z. Zhang. Direct search based on probabilistic descent. SIAM Journal on Optimization, 25(3):1515–1541, 2015.
J. Haslinger and R.A.E. Mäckinen. Introduction to Shape Optimization: Theory, Approximation, and Computation. SIAM, Philadelphia, PA, USA, 2003.
R. Hooke and T.A. Jeeves. Direct search solution of numerical and statistical problems. J. Assoc. Comput. Mach, 8:212–229, 1961.
V. G. Karmanov. Convergence estimates for iterative minimization methods. USSR Computational Mathematics and Mathematical Physics, 14:1–13, 1974a.
V. G. Karmanov. On convergence of a random search method in convex minimization problems. Theory of Probability and its applications, 19:788–794, 1974b.
T. G. Kolda, R. M. Lewis, and V. J. Torczon. Optimization by direct search: New perspectives on some classical and modern methods. SIAM Review, 45:385–482, 2003.
Laurent Lessard, Benjamin Recht, and Andrew Packard. Analysis and design of optimization algorithms via integral quadratic constraints. SIAM Journal on Optimization, 26(1):57–95, 2016.
10

Published as a conference paper at ICLR 2020
Nicolas Loizou and Peter Richtárik. Momentum and stochastic momentum for stochastic gradient, newton, proximal point and subspace descent methods. arXiv preprint arXiv:1712.09677, 2017.
Horia Mania, Aurelia Guy, and Benjamin Recht. Simple random search provides a competitive approach to reinforcement learning. arXiv preprint arXiv:1803.07055, 2018.
A. L. Marsden, M. Wang, J. E. Dennis, and P. Moin. Optimal aeroacustic shape design using the surrogate management framework. Optimization and Engineering, 5:235–262, 2004.
A. L. Marsden, M. Wang, J. E. Dennis, and P. Moin. Trailing-edge noise reduction using derivative-free optimization and large-eddy simulation. Journal of Fluid Mechanics, 5:235–262, 2007.
A. L. Marsden, J. A. Feinstein, and C. A. Taylor. A computational framework for derivative-free optimization of cardiovascular geometries. Computer Methods in Applied Mechanics and Engineering, 197:1890–1905, 2008.
J. Matyas. Random optimization. Automation and Remote Control, 26:246–253, 1965.
Konstantin Mishchenko, Eduard Gorbunov, Martin Takácˇ, and Peter Richtárik. Distributed learning with compressed gradient differences. arXiv preprint arXiv:1901.09269, 2019.
B. Mohammadi and O. Pironneau. Applied Shape Optimization for Fluids. Clarendon Press, Oxford, 2001.
Y. Nesterov and V. Spokoiny. Random gradient-free minimization of convex functions. Foundations of Computational Mathematics, 17:527–566, 2017.
Boris T Polyak. Some methods of speeding up the convergence of iteration methods. USSR Computational Mathematics and Mathematical Physics, 4(5):1–17, 1964.
Aravind Rajeswaran, Kendall Lowrey, Emanuel V Todorov, and Sham M Kakade. Towards generalization and simplicity in continuous control. In Advances in Neural Information Processing Systems, pp. 6550–6561, 2017.
Peter Richtárik and Martin Takácˇ. On optimal probabilities in stochastic coordinate descent methods. Optimization Letters, 10(6):1233–1243, 2016.
Tim Salimans, Jonathan Ho, Xi Chen, Szymon Sidor, and Ilya Sutskever. Evolution strategies as a scalable alternative to reinforcement learning. arXiv preprint arXiv:1703.03864, 2017.
M. Sarma. On the convergence of the Baba and Dorea random optimization methods. Journal of Optimization Theory and Applications, 66:337–343, 1990.
John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp Moritz. Trust region policy optimization. In International Conference on Machine Learning, pp. 1889–1897, 2015.
S. U. Stich, C. L. Muller, and B. Gartner. Optimization of convex functions with random pursuit. arXiv preprint arXiv:1111.0194, 2011.
Sebastian U Stich. Convex optimization with random pursuit. PhD thesis, ETH Zurich, 2014a.
Sebastian Urban Stich. On low complexity acceleration techniques for randomized optimization. In International Conference on Parallel Problem Solving from Nature, pp. 130–140. Springer, 2014b.
Yu Wen Su. Positive basis and a class of direct search techniques. Scientia Sinica (in Chinese), 9(S1):53–67, 1979.
Emanuel Todorov, Tom Erez, and Yuval Tassa. Mujoco: A physics engine for model-based control. In Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International Conference on, pp. 5026–5033. IEEE, 2012.
Virginia Torczon. On the convergence of pattern search algorithms. SIAM Journal on optimization, 7(1):1–25, 1997.
Luís Nunes Vicente. Worst case complexity of direct search. EURO Journal on Computational Optimization, 1 (1-2):143–153, 2013.
Tianbao Yang, Qihang Lin, and Zhe Li. Uniﬁed convergence analysis of stochastic momentum methods for convex and non-convex optimization. arXiv preprint arXiv:1604.03257, 2016.
Peilin Zhao and Tong Zhang. Stochastic optimization with importance sampling for regularized loss minimization. In international conference on machine learning, pp. 1–9, 2015.
11

Published as a conference paper at ICLR 2020

A Stochastic Derivative Free Optimization Method with Momentum
(Supplementary Material)

A PRELIMINARIES

We ﬁrst list the main assumptions. Assumption A.1. (L-smoothness) We say that f is L-smooth if:

∇f (x) − ∇f (y) 2 ≤ L x − y 2 ∀x, y ∈ Rd.

(29)

Assumption A.2. The probability distribution D on Rd satisﬁes the following properties:

1.

The

quantity

γD

def
=

Es∼D

s

2 2

is

positive

and

ﬁnite.

2. There is a constant µD > 0 and norm · D on Rd such that for all g ∈ Rd

Es∼D| g, s | ≥ µD g D.

(30)

We establish the key lemma which will be used to prove the theorems stated in the paper.
Lemma A.1. Assume that f is L-smooth and D satisﬁes Assumption A.2. Then for the iterates of SMTP the following inequalities hold:

k+1

k

γk

kk

L(γk)2 k 2

f (z

) ≤ f (z ) −

| ∇f (z ), s

1−β

| + 2(1 − β)2 s

2

(31)

and

k+1

k γkµD

k

L(γ k )2 γD

Esk∼D f (z

)

≤ f (z

)− 1−β

∇f (z

)

D + 2(1 − β)2 .

(32)

Proof. By induction one can show that

zk = xk − γkβ vk−1. (33) 1−β

That is, for k = 0 this recurrence holds and update rules for zk, xk and vk−1 do not brake it. From this we get

k+1

k+1 γkβ k

k k k γkβ k

z+ = x+ − 1 − β v+ = x − γ v+ − 1 − β v+

k

γk k

k γkβ k−1

γk k

=

x

− 1 − β v+ = x

−

v

1−β

−

s

1−β

(33) k

γk k

= z−

s.

1−β

Similarly,

k+1

k+1 γkβ k

k k k γkβ k

z− = x− − 1 − β v− = x − γ v− − 1 − β v−

k

γk k

k γkβ k−1

γk k

=

x

− 1 − β v− = x

−

v

1−β

+

s

1−β

(33) k

γk k

= z+

s.

1−β

12

Published as a conference paper at ICLR 2020

It implies that

f (z+k+1) (≤3) f (zk) + ∇f (zk), z+k+1 − zk + L2 z+k+1 − zk 22

k

γk

kk

L(γk)2 k 2

=

f (z ) −

∇f (z ), s

1−β

+ 2(1 − β)2 s

2

and

k+1

k

γk

kk

L(γk)2 k 2

f (z−

)

≤

f (z ) +

∇f (z ), s

1−β

+ 2(1 − β)2 s

2.

Unifying these two inequalities we get

k+1

k+1

k+1

k

γk

kk

L(γk)2 k 2

f (z

)

≤

min{f (z+

), f (z−

)} = f (z ) −

| ∇f (z ), s

1−β

| + 2(1 − β)2 s

2,

which proves (31). Finally, taking the expectation Esk∼D of both sides of the previous inequality and invoking Assumption A.2, we obtain

k+1

k γkµD

k

L(γ k )2 γD

Esk∼D f (z

)

≤ f (z

)− 1−β

∇f (z

)

D + 2(1 − β)2 .

B NON-CONVEX CASE

Theorem B.1. Let Assumptions A.1 and A.2 be satisﬁed. Let SMTP with γk ≡ γ > 0 produce points {z0, z1, . . . , zK−1} and zK is chosen uniformly at random among them. Then

E ∇f (zK ) D ≤ (1 − β)(f (x0) − f (x∗)) + LγγD . (34)

K γ µD

2µD(1 − β)

Moreover, if we choose γ = √γ0 the complexity (34) reduces to
K

E ∇f (zK )

1 ≤√

(1 − β)(f (z0) − f (x∗)) + Lγ0γD

.

(35)

D
K

γ0µD

2µD(1 − β)

Then γ0 = 2(1−β)2(fL(γxD0)−f(x∗)) minimizes the right-hand side of (35) and for this choice we have

E ∇f (zK ) D ≤ 2 (f (x0) −√f (x∗)) LγD . (36) µD K

Proof. Taking full expectation from both sides of inequality (32) we get

E ∇f (zk) D ≤ (1 − β)E f (zk) − f (zk+1) + LγγD .

γµD

2µD(1 − β)

Further, summing up the results for k = 0, 1, . . . , K −1, dividing both sides of the obtained inequality by K and using tower property of the mathematical expectation we get

E ∇f (zK ) D = 1 K−1 E ∇f (zk) D ≤ (1 − β)(f (z0) − f (x∗)) + LγγD .

K k=0

K γ µD

2µD(1 − β)

The last part where γ = √γ0 is straightforward.
K

13

Published as a conference paper at ICLR 2020

C CONVEX CASE

Assumption C.1. We assume that f is convex, has a minimizer x∗ and has bounded level set at x0:

def
R0 = max

x − x∗

∗ D

|

f (x)

≤

f (x0)

< +∞,

(37)

where ξ ∗D d=ef max { ξ, x | x D ≤ 1} deﬁnes the dual norm to · D.
Theorem C.1 (Constant stepsize). Let Assumptions A.1, A.2 and C.1 be satisﬁed. If we set γk ≡ γ < (1−µβD)R0 , then for the iterates of SMTP method the following inequality holds:

E f (zk) − f (x∗) ≤ 1 − γµD k f (x0) − f (x∗) + LγγDR0 . (38)

(1 − β)R0

2(1 − β)µD

If we choose γ = ε(1−β)µD for some 0 < ε ≤ LγDR02 and run SMTP for k = K iterations where

LγD R0

µ2D

1 LγDR02 2(f (x0) − f (x∗))

K= ε

µ2

ln

ε

,

(39)

D

then we will get E f (zK ) − f (x∗) ≤ ε.

Proof. From the (32) and monotonicity of {f (zk)}k≥0 we have

Es∼D f (zk+1)

k γµD

k

Lγ2γD

≤

f (z

)− 1−β

∇f (z

)

D + 2(1 − β)2

(≤14) f (zk) − γµD (f (zk) − f (x∗)) + Lγ2γD .

(1 − β)R0

2(1 − β)2

Taking full expectation, subtracting f (x∗) from the both sides of the previous inequality and using the tower property of mathematical expectation we get

E f (zk+1) − f (x∗) ≤ 1 − γµD E f (zk) − f (x∗) + Lγ2γD . (40)

(1 − β)R0

2(1 − β)2

Since γ < (1−µβD)R0 the term 1 − (1−γµβD)R0 is positive and we can unroll the recurrence (40):

E f (zk) − f (x∗) ≤ ≤ ≤ =

1 − γµD k f (z0) − f (x∗) + Lγ2γD k−1 1 − γµD l

(1 − β)R0

2(1 − β)2

(1 − β)R0

l=0

1 − γµD k f (x0) − f (x∗) + Lγ2γD ∞ 1 − γµD l

(1 − β)R0

2(1 − β)2

(1 − β)R0

l=0

1 − γµD k f (x0) − f (x∗) + Lγ2γD · (1 − β)R0

(1 − β)R0

2(1 − β)2 γµD

1 − γµD k f (x0) − f (x∗) + LγγDR0 .

(1 − β)R0

2(1 − β)µD

Lastly, putting γ = ε(L1γ−DβR)µ0D and k = K from (39) in (38) we have

E[f (zK )] − f (x∗) =

1 − εµ2D K f (x0) − f (x∗) + ε

LγD R02

2

≤ exp −K · εµ2D LγD R02

f (x0) − f (x∗)

ε +

2

(39) ε ε = + = ε.
22

14

Published as a conference paper at ICLR 2020

Next we use technical lemma from Mishchenko et al. (2019). We provide the original proof for completeness. Lemma C.1 (Lemma 6 from Mishchenko et al. (2019)). Let a sequence {ak}k≥0 satisfy inequality ak+1 ≤ (1 − γkα)ak + (γk)2N for any positive γk ≤ γ0 with some constants α > 0, N > 0, γ0 > 0. Further, let θ ≥ γ20 and take C such that N ≤ α4θ C and a0 ≤ C. Then, it holds
ak ≤ C αθ k + 1
if we set γk = αk2+θ .

Proof. We will show the inequality for ak by induction. Since inequality a0 ≤ C is one of our assumptions, we have the initial step of the induction. To prove the inductive step, consider

ak+1 ≤ (1 − γkα)ak + (γk)2N ≤ 1 − 2α

θC

C

+ θα

.

αk + θ αk + θ

(αk + θ)2

To show that the right-hand side is upper bounded by α(k+θC1)+θ , one needs to have, after multiplying both sides by (αk + θ)(αk + α + θ)(θC)−1,

2α

αk + α + θ

1−

(αk + α + θ) + α

≤ αk + θ,

αk + θ

αk + θ

which is equivalent to

αk + α + θ

α−α

≤ 0.

αk + θ

The last inequality is trivially satisﬁed for all k ≥ 0.

Theorem C.2 (Decreasing stepsizes). Let Assumptions A.1, A.2 and C.1 be satisﬁed. If we set γk = αk2+θ , where α = (1−µβD)R0 and θ ≥ α2 , then for the iterates of SMTP method the following inequality holds:

E f (zk) − f (x∗) ≤ 1 max f (x0) − f (x∗), 2LγD ,

(41)

ηk + 1

αθ(1 − β)2

where η d=ef αθ . Then, if we choose γk = α22kα+2 where α = (1−µβD)R0 and run SMTP for k = K iterations where

1 2R02

2

0

∗

2(1 − β)2R02

K=

· ε

µ2

max

(1 − β) (f (x ) − f (x )), LγD

−

µ2

, ε > 0,

(42)

D

D

we get E f (zK ) − f (x∗) ≤ ε.

Proof. In (40) we proved that

E f (zk+1) − f (x∗) ≤

1 − γµD (1 − β)R0

E f (zk) − f (x∗) + Lγ2γD . 2(1 − β)2

Having that, we can apply Lemma C.1 to the sequence E f (zk) − f (x∗) . The constants for

the lemma are: N = 2(L1−γDβ)2 , α = (1−µβD)R0 and C = max f (x0) − f (x∗), αθ2(L1−γDβ)2 . Lastly,

choosing γk

=

2α α2 k+2

is equivalent to the choice θ

=

α2 .

In this case, we have αθ

=

2, C

=

max f (x0) − f (x∗), LγD and η = α = α2 = µ2D . Putting these parameters and K

(1−β)2

θ

2

2(1−β )2 R02

from (42) in the (41) we get the result.

15

Published as a conference paper at ICLR 2020

D STRONGLY CONVEX CASE

Assumption D.1. We assume that f is µ-strongly convex with respect to the norm · ∗D: f (y) ≥ f (x) + ∇f (x), y − x + µ2 ( y − x ∗D)2, ∀x, y ∈ Rd. (43)

It is well known that strong convexity implies

∇f (x)

2 D

≥ 2µ (f (x) − f (x∗)) .

(44)

Theorem D.1 (Solution-dependent stepsizes). Let Assumptions A.1, A.2 and D.1 be satisﬁed. If we set γk = (1−βL)θkµD 2µ(f (zk) − f (x∗)) for some θk ∈ (0, 2) such that θ = inf {2θk − γDθk2} ∈
k≥0

0,

L
2

, then for the iterates of SMTP the following inequality holds:

µD µ

E f (zk) − f (x∗) ≤ 1 − θµ2Dµ k f (x0) − f (x∗) . (45) L

If we run SMTP for k = K iterations where

κ

f (x0) − f (x∗)

K = θµ2 ln

ε

, ε > 0,

(46)

D

where κ d=ef Lµ is the condition number of the objective, we will get E f (zK ) − f (x∗) ≤ ε.

Proof. From (32) and γk = θkLµD Esk∼D f (zk+1) − f (x∗)

2µ(f (xk) − f (x∗)) we have

k

∗ γkµD

k

L(γ k )2 γD

≤

f (z

) − f (x ) − 1−β

∇f (z

)

D + 2(1 − β)2

(≤44) f (zk) − f (x∗) − γkµD 2µ(f (zk) − f (x∗)) 1−β

+ γDθk2µ2Dµ (f (zk) − f (x∗)) L
≤ f (zk) − f (x∗) − 2θkµ2Dµ (f (zk) − f (x∗)) L
+ γDθk2µ2Dµ (f (zk) − f (x∗)) L
≤ 1 − (2θk − γDθk2) µ2DLµ (f (zk) − f (x∗)).

Using θ = inf {2θk −γDθk2} ∈ 0, µ2Lµ and taking the full expectation from the previous inequality

k≥0

D

we get

E f (zk+1) − f (x∗) ≤ ≤

1 − θµ2Dµ L
1 − θµ2Dµ L

E f (zk) − f (x∗)
k+1
f (x0) − f (x∗) .

Lastly, from (45) we have

E f (zK ) − f (x∗) ≤

1 − θµ2Dµ K f (x0) − f (x∗) L

≤ exp −K θµ2Dµ L

f (x0) − f (x∗)

(46)
≤ ε.

16

Published as a conference paper at ICLR 2020

Assumption D.2. We assume that for all s ∼ D we have s 2 = 1.

Theorem D.2 (Solution-free stepsizes). Let Assumptions A.1, A.2, D.1 and D.2 be satisﬁed. If additionally we compute f (zk + tsk), set γk = (1−β)|f(zk+tsk)−f(zk)| for t > 0 and assume that D
Lt
is such that µ2D ≤ Lµ , then for the iterates of SMTP the following inequality holds:

E f (zk) − f (x∗) ≤ 1 − µ2Dµ k f (x0) − f (x∗) + L2t2 . (47)

L

8µ2D µ

Moreover, for any ε > 0 if we set t such that

0 < t ≤ 4εµ2Dµ ,

(48)

L2

and run SMTP for k = K iterations where

κ

2(f (x0) − f (x∗))

K = µ2 ln

ε

,

(49)

D

where κ d=ef Lµ is the condition number of f , we will have E f (zK ) − f (x∗) ≤ ε.

Proof. Recall that from (31) we have

f (zk+1) ≤ f (zk) − γk | ∇f (zk), sk | + L(γk)2 .

1−β

2(1 − β)2

If we minimize the right hand side of the previous inequality as a function of γk, we will get that the optimal choice in this sense is γokpt = (1−β)| ∇Lf(zk),sk | . However, this stepsize is impractical for derivative-free optimization, since it requires to know ∇f (zk). The natural way to handle this is to
approximate directional derivative ∇f (zk), sk by ﬁnite difference f(zk+tskt)−f(zk) and that is what we do. We choose γk = (1−β)|f (zkL+ttsk)−f (zk)| = (1−β)| ∇Lf (zk),sk | + (1−β)|f (zkL+ttsk)−f (zk)| − (1−β)| ∇Lf(zk),sk | d=ef γokpt + δk. From this we get

f (zk+1) ≤ f (zk) − | ∇f (zk), sk |2 + L (δk)2.

2L

2(1 − β)2

Next we estimate |δk|:

It implies that

|δk| = (1 − β) |f (zk + tsk) − f (zk)| − | ∇f (zk), tsk | Lt
≤ (1 − β) f (zk + tsk) − f (zk) − ∇f (zk), tsk Lt
(≤3) (1 L−tβ) · L2 tsk 22 = (1 −2 β)t .

f (zk+1) ≤ f (zk) − | ∇f (zk), sk |2 + L · (1 − β)2t2

2L

2(1 − β)2

4

= f (zk) − | ∇f (zk), sk |2 + Lt2

2L

8

and after taking full expectation from the both sides of the obtained inequality we get

E f (zk+1) − f (x∗) ≤ E f (zk) − f (x∗) − 1 E | ∇f (zk), sk |2 + Lt2 .

2L

8

Note that from the tower property of mathematical expectation and Jensen’s inequality we have

E | ∇f (zk), sk |2

= E Esk∼D | ∇f (zk), sk |2 | zk ≥ E Esk∼D | ∇f (zk), sk | | zk 2

(30)

(44)

≥

E

µ2D

∇f (zk)

2 D

≥ 2µ2DµE f (zk) − f (x∗) .

17

Published as a conference paper at ICLR 2020

Putting all together we get

E f (zk+1) − f (x∗) ≤ 1 − µ2Dµ E f (zk) − f (x∗) + Lt2 .

L

8

Due

to

µ2D

≤

L µ

we

have

E f (zk) − f (x∗) ≤ ≤ =
Lastly, from (47) we have

1 − µ2Dµ k f (x0) − f (x∗) + Lt2 k−1 1 − µ2Dµ l

L

8

L

l=0

1 − µ2Dµ k f (x0) − f (x∗) + Lt2 ∞ 1 − µ2Dµ l

L

8

L

l=0

1 − µ2Dµ k f (x0) − f (x∗) + L2t2 .

L

8µ2D µ

E f (zK ) − f (x∗) ≤

1 − µ2Dµ K f (x0) − f (x∗) + L2t2

L

8µ2D µ

(48)
≤

exp

−K µ2Dµ

L

f (x0) − f (x∗)

ε +

2

(49) ε ε ≤ + = ε.
22

18

Published as a conference paper at ICLR 2020

E SMTP_IS: STOCHASTIC MOMENTUM THREE POINTS WITH IMPORTANCE SAMPLING

Again by deﬁnition of zk+1 we get that the sequence {f (zk)}k≥0 is monotone:

f (zk+1) ≤ f (zk) ∀k ≥ 0.

(50)

Lemma E.1. Assume that f satisﬁes Assumption 4.1. Then for the iterates of SMTP_IS the following

inequalities hold:

k+1

k

γik

k

Li

k

(

γ

k i

)2

f (z ) ≤ f (z ) − 1 − β |∇ik f (z )| + 2(1 − β)2

(51)

and

Esk∼D f (zk+1) ≤ f (zk) − 1 −1 β E γik|∇ik f (zk)| | zk + 2(1 −1 β)2 E Lik (γik)2 | zk . (52)

Proof. In the similar way as in Lemma A.1 one can show that

zk = xk − γikβ vk−1 (53) 1−β

and

k+1

k

γik

z+ = z − 1 − β eik ,

k+1

k

γik

z− = z + 1 − β eik .

It implies that

k+1 (26)

k

γik

k

Li

k

(

γ

k i

)2

f (z+ ) ≤ f (z ) − 1 − β ∇if (z ) + 2(1 − β)2

and

k+1

k

γik

k

Li

k

(γ

k i

)2

f (z− ) ≤ f (z ) + 1 − β ∇if (z ) + 2(1 − β)2 .

Unifying these two inequalities we get

k+1

k+1

k+1

k

γik

k

Li

k

(

γ

k i

)2

f (z ) ≤ min{f (z+ ), f (z− )} = f (z ) − 1 − β |∇if (z )| + 2(1 − β)2 ,

which proves (51). Finally, taking the expectation E[· | zk] conditioned on zk from the both sides of the previous inequality we obtain

E f (zk+1) | zk ≤ f (zk) − 1 −1 β E γik|∇ik f (zk)| | zk + 2(1 −1 β)2 E Lik (γik)2 | zk .

E.1 NON-CONVEX CASE

Theorem E.1. Assume that f satisﬁes Assumption 4.1. Let SMTP_IS with γik = wγik for some γ > 0 produce points {z0, z1, . . . , zK−1} and zK is chosen uniformly at random among them. Then

K

(1 − β)(f (x0) − f (x∗))

γ

d Lipi

E ∇f (z ) 1 ≤

Kγ min pi

+ 2(1 − β) min

pi

w2 . (54)

i=1,...,d wi

i=1,...,d wi i=1 i

19

Published as a conference paper at ICLR 2020

Moreover, if we choose γ = √γ0 , then
K

K

1

(1 − β)(f (x0) − f (x∗))

γ0

d Lipi

E ∇f (z ) 1 ≤ √K min pi

γ0

+ 2(1 − β)

w2 . (55)

i=1,...,d wi

i=1 i

Note that if we choose γ0 = will get

2(1−β)2(f(x0)−f(x∗)) in order to minimize right-hand side of (55), we d Lipi w2 i=1 i

E ∇f (zK ) 1 ≤

d

2 (f (x0) − f (x∗))

Li pi
2

i=1 wi

√K min wpi .

i=1,...,d i

(56)

Note that for pi = Li/

d i

Li

with

wi

=

Li

we

have

that

the

rates

improves

to

2(f (x0) − f (x∗))d

d i=1

Li

E ∇f (zK ) 1 ≤

√

.

(57)

K

Proof. Recall that from (52) we have

E f (zk+1) | zk ≤ f (zk) − 1 −1 β E γik|∇ik f (zk)| | zk + 2(1 −1 β)2 E Lik (γik)2 | zk . (58)

Using our choice γik = wγik we derive

E γik|∇ik f (zk)| | zk

= γ d pi |∇if (zk)| ≥ γ ∇f (zk) 1 min pi

i=1 wi

i=1,...,d wi

and

E

Li

k

(γ

k i

)2

|

zk

2 d Lipi = γ i=1 wi2 .

Putting it in (58) and taking full expectation from the both sides of obtained inequality we get

γ min pi
i=1,...,d wi

γ2

E f (zk+1) ≤ E f (zk) −

E ∇f (zk) 1 +

d Lipi ,

1−β

2(1 − β)2 i=1 wi2

whence

k

(1 − β) E f (zk) − E f (zk+1)

∇f (z ) 1 ≤

γ min pi

i=1,...,d wi

γ

d Lipi

+ 2(1 − β) min

pi

w2 .

i=1,...,d wi i=1 i

Summing up previous inequality for k = 0, 1, . . . , K − 1 and dividing both sides of the result by K, we get

1 K−1 E
K k=0

∇f (zk) 1

(1 − β)(f (z0) − f (x∗))

γ

d Lipi

≤

Kγ min pi

+ 2(1 − β) min

pi

w2 .

i=1,...,d wi

i=1,...,d wi i=1 i

K −1
It remains to notice that K1 E
k=0
straightforward.

∇f (zk) 1 = E

∇f (zK ) 1 . The last part where γ = √γ0 is
K

20

Published as a conference paper at ICLR 2020

E.2 CONVEX CASE

As for SMTP to tackle convex problems by SMTP_IS we use Assumption 3.2 with · D = · 1. Note that in this case R0 = max x − x∗ ∞ | f (x) ≤ f (x0) .

Theorem E.2 (Constant stepsize). Let Assumptions 3.2 and 4.1 be satisﬁed. If we set γik = wγik such

that 0 < γ ≤

(1−β)R0
p

, then for the iterates of SMTP_IS method the following inequality holds:

min

i w

i=1,...,d i

 γ min pi k

d

E f (zk) − f (x∗) ≤ 1 − i=1,...,d wi  (1 − β)R0

f (z0) − f (x∗) + 2(1 − βγ)Rm0 in pi
w

Lipi wi2 .

i=1,...,d i i=1

(59)

Moreover, if we choose γ =

ε(1−β) min pi
i=1,...,d wi
R0 d Lwip2i
i=1 i

for some 0 < ε ≤

R2 d Lipi

0

w2

i=1 i

p2

min

i 2

i=1,...,d wi

and run SMTP_IS for

k = K iterations where

d

K = 1 R02 i=1 Lwipi2i ln 2(f (x0) − f (x∗)) ,

ε min p2i

ε

i=1,...,d wi2

(60)

we will get E f (zK )

− f (x∗) ≤ ε. Moreover, for pi = Li/

d i

Li

with

wi

=

Li,

the

rate

improves

to

1

d

2(f (x0) − f (x∗))

K = R02d Li ln

.

(61)

ε

ε

i=1

Proof. Recall that from (52) we have

E f (zk+1) | zk ≤ f (zk) − 1 −1 β E γik|∇ik f (zk)| | zk + 2(1 −1 β)2 E Lik (γik)2 | zk . (62)

Using our choice γik = wγik we derive

E γik∇ik f (zk) | zk

= γ d pi |∇if (zk)| ≥ γ ∇f (zk) 1 min pi

i=1 wi

i=1,...,d wi

(14)
≥

γ

min pi f (zk) − f (x∗)

R0 i=1,...,d wi

and

E

Li

k

(γ

k i

)2

|

zk

2 d Lipi = γ i=1 wi2 .

Putting it in (62) and taking full expectation from the both sides of obtained inequality we get

 γ min pi 
i=1,...,d wi

γ2

E f (zk+1) − f (x∗) ≤ 1 −

 E f (zk) − f (x∗) +

d Lipi . (63)

(1 − β)R0

2(1 − β)2 i=1 wi2

21

Published as a conference paper at ICLR 2020

Due to our choice of γ ≤

(1−β)R0
p

we have that the factor

min

i w

i=1,...,d i

negative and, therefore,

1− γ

min pi

(1−β)R0 i=1,...,d wi

is non-

E f (zk) − f (x∗) ≤

γ 1−

min pi

(1 − β)R0 i=1,...,d wi

k
f (z0) − f (x∗)

γ2

d Lipi k−1

γ

pi l

+ 2(1 − β)2 i=1 wi2

1−

min

l=0 (1 − β)R0 i=1,...,d wi

γ ≤ 1−

min pi k f (z0) − f (x∗)

(1 − β)R0 i=1,...,d wi

γ2

d Lipi ∞

γ

pi l

+ 2(1 − β)2 i=1 wi2

1−

min

l=0 (1 − β)R0 i=1,...,d wi

 γ min pi k

d

i=1,...,d wi
≤ 1−

f (z0) − f (x∗) +

γR0





(1 − β)R0

2(1 − β) min wpi

Lipi wi2 .

i=1,...,d i i=1

ε(1−β) min pi

Then, putting γ =

i=1,...,d wi and k = K from (60) in (59) we have

R0 d Lwip2i

i=1 i



K

ε min p2i

E[f (zK )] − f (x∗)

=



i=1,...,d wi2 

1 −





d





R02

Lipi 
w2

i=1 i

f (z0) − f (x∗)

ε +

2





 

ε min p2i 

≤

 
exp −K ·

i=1,...,d

wi2

 

f (z0) − f (x∗)

ε +

d

 

R2

Li pi

 

2

 

0

wi2

 

i=1

(60) ε ε = + = ε.
22

Theorem E.3 (Decreasing stepsizes).

Let Assumptions 3.2 and 4.1 be satisﬁed.

If we set γik

=

γk w

ik

min pi

and γk = αk2+θ , where α = i=(11−,..β.,)dRw0i and θ ≥ α2 , then for the iterates of SMTP_IS method the

following inequality holds:

k

∗

1

0

∗

2

d Lipi

E f (z ) − f (x ) ≤ ηk + 1 max f (x ) − f (x ), αθ(1 − β)2 i=1 wi2 , (64)

min pi
where η d=ef αθ . Moreover, if we choose γk = α22kα+2 where α = i=(11−,..β.,)dRw0i and run SMTP_IS for k = K iterations where

1

2R02

K= · ε

min

p2 max i

i=1,...,d wi2

2

0

∗ d Lipi

(1 − β) (f (x ) − f (x )), i=1 wi2

we will get E f (zK ) − f (x∗) ≤ ε.

2(1 − β)2R02

−

p2 ,

min

i
w2

i=1,...,d i

ε > 0, (65)

Proof. E

In (63) we proved that  γ min pi 
f (zk+1) − f (x∗) ≤ 1 − i=1,...,d wi  E (1 − β)R0

f (zk) − f (x∗)

γ2

d Lipi

+ 2(1 − β)2 l=1 wi2 .

22

Published as a conference paper at ICLR 2020

Having that, we can apply Lemma C.1 to the sequence E f (zk) − f (x∗) . The con-

d

min pi

stants for the lemma are:

N

=

1 2(1−β)2

Lipi , α = i=1,...,d wi and C =

wi2

(1−β)R0

l=1

d

max f (x0) − f (x∗),

2
2

Li pi
2

. Lastly, note that choosing γk =

2α
2

is equivalent

αθ(1−β) i=1 wi

α k+2

d

to choice θ = 2 . In this case we have αθ = 2 and C = max f (x0) − f (x∗),

1
2

Li pi
2

α

(1−β) i=1 wi

p2

and η

=

α

=

α2

=

. min

i 2

i=1,...,d wi

Putting these parameters and K

from (65) in the (64) we get the

θ

2

2(1−β )2 R02

result.

E.3 STRONGLY CONVEX CASE

Theorem E.4 (Solution-dependent stepsizes). Let Assumptions 3.3 (with · D = · 1) and 4.1

(1−β)θk min pi

be satisﬁed. If we set γik =

i=1,...,d wi d Lipi

2µ(f (zk) − f (x∗)) for some θk ∈ (0, 2) such that

wik

w2

i=1 i



d Lipi 

θ = inf {2θk − θ2} ∈ 0,

w2
i=1 i 2 , then for the iterates of SMTP_IS method the following

k≥0

k

µ min pi

i=1,...,d

w2 i

inequality holds:



k

θµ min p2i

 E f (zk) − f (x∗) ≤ 1 −

i=1,...,d wi2  

f (x0) − f (x∗) .

(66)



d





Lipi 

i=1 wi2

If we run SMTP_IS for k = K iterations where

d Li pi

i=1 wi2

f (x0) − f (x∗)

K=

p2 ln

θµ min i

ε

,

i=1,...,d wi2

ε > 0,

(67)

we will get E f (zK ) − f (x∗) ≤ ε.

Proof. Recall that from (52) we have

E f (zk+1) | zk ≤ f (zk) − 1 −1 β E γik|∇ik f (zk)| | zk + 2(1 −1 β)2 E Lik (γik)2 | zk . (68)

(1−β)θk min pi

Using our choice γik =

i=1,...,d wi d Lipi

wik

w2

i=1 i

2µ(f (zk) − f (x∗)) we derive

E γik∇ik f (zk) | zk

(1 − β)θk

min

pi w

i=1,...,d i

dp

=

2µ(f (zk) − f (x∗))

i |∇if (zk)|

d Li pi

i=1 wi

i=1 wi2

2

(1 − β)θk min wpi
i=1,...,d i
≥d
Li pi

2µ(f (zk) − f (x∗)) ∇f (zk) 1

i=1 wi2

2(1 − β)θk

min

p2i
2

(20)
≥

i=1,...,d wi µ(f (zk) − f (x∗))

d

Li pi

i=1 wi2

23

Published as a conference paper at ICLR 2020

and

E

Li

k

(γ

k i

)

2

|

zk

2(1 − β)2θ2 min p2i

d

=

k i=1,...,d wi2 µ(f (zk) − f (x∗)) Lipi

d

2

Li pi

i=1 wi2

i=1 wi2

2(1 − β)2θ2 min p2i

=

k i=1,...,d wi2 µ(f (zk) − f (x∗)).

d

Li pi

i=1 wi2

Putting it in (68) and taking full expectation from the both sides of obtained inequality we get





µ min p2i

 E f (zk+1) − f (x∗) ≤ 1 − (2θ − θ2)

i=1,...,d wi2  E

f (zk) − f (x∗)

.



d





Lipi 

i=1 wi2



d Lipi 

Using θ = inf {2θk − θ2} ∈ 0,

w2
i=1 i 2  we obtain

k≥0

k

µ min pi

i=1,...,d

w2 i

E f (zk+1) − f (x∗)





θµ min p2i

 ≤ 1 −

i=1,...,d wi2  E

f (zk) − f (x∗)



d





Lipi 

i=1 wi2



k+1

θµ min p2i



i=1,...,d wi2 

≤ 1 −





d





Lipi 

f (x0) − f (x∗) .

i=1 wi2

Lasrtly, from (66) we have



K

θµ min p2i

 E f (zK ) − f (x∗) ≤ 1 −

i=1,...,d wi2  



d





Lipi 

f (x0) − f (x∗)

i=1 wi2





 

θµ min p2i 

 
≤ exp −K

i=1,...,d

wi2

 

f (x0) − f (x∗)

d

 

Li pi

 

 i=1 wi2 

(67)
≤ ε.

The previous result based on the choice of γk which depends on the f (zk) − f (x∗) which is often unknown in practice. The next theorem does not have this drawback and makes it possible to obtain the same rate of convergence as in the previous theorem using one extra function evaluation.

Theorem E.5 (Solution-free stepsizes). Let Assumptions 3.3 (with · D = · 2) and 4.1 be satisﬁed.
If additionally we compute f (zk + teik ), set γik = (1−β)|f(zkL+iktetik )−f(zk)| for t > 0, then for the iterates of SMTP_IS method the following inequality holds:

k

∗

pi k

0

∗

t2

d

E f (z ) − f (x ) ≤ 1 − µ min i=1,...,d Li

f (x ) − f (x ) + 8µ

min

pi

piLi. (69)

i=1,...,d Li i=1

24

Published as a conference paper at ICLR 2020

Moreover, for any ε > 0 if we set t such that

0<t≤

4εµ min pi
l=1,...,d Li
d, piLi
i=1

(70)

and run SMTP_IS for k = K iterations where

1

2(f (x0) − f (x∗))

K= µ min

pi ln

ε

,

(71)

i=1,...,d Li

we will get E f (zK ) improves to

− f (x∗) ≤ ε. Moreover, note that for pi = Li/

K=

di=1 Li ln 2(f (x0) − f (x∗)) .

µ

ε

d i

Li

with

wi

=

Li,

the

rate

(72)

Proof. Recall that from (51) we have

k+1

k

γik

k

L

ik

(γ

k i

)

2

f (z ) ≤ f (z ) − 1 − β |∇ik f (z )| + 2(1 − β)2 .

If we minimize the right hand side of the previous inequality as a function of γik, we will get that

the optimal choice in this sense is γk = (1−β)|∇ik f(zk)| . However, this stepsize is impractical for

opt

Lik

derivative-free optimization, since it requires to know ∇ik f (zk). The natural way to handle this is to

approximate directional derivative ∇ik f (zk) by ﬁnite difference f(zk+teitk )−f(zk) and that is what

we do. We choose γk = (1−β)|f (zk+teik )−f (zk)| = (1−β)|∇ik f (zk)| + (1−β)|f (zk+teik )−f (zk)| −

i

Lik t

Lik

Lik t

(1−β)|∇ik f(zk)| d=ef γk + δk. From this we get

Lik

opt i

k+1

k |∇ik f (zk)|2

Lik

k2

f (z ) ≤ f (z ) − 2Li

+ 2(1 − β)2 (δi ) .

k

Next we estimate |δik|:

|δk| = (1 − β) |f (zk + tei ) − f (zk)| − |∇i f (zk)|t

i

Li t

k

k

k

≤ (1 − β) f (zk + tei ) − f (zk) − ∇i f (zk)t

Lik t

k

k

(≤26) (1 − β) · Lik t2 = (1 − β)t .

Lik t

2

2

It implies that

f (zk+1) ≤ f (zk) − |∇ik f (zk)|2 + Lik · (1 − β)2t2

2Lik

2(1 − β)2

4

= f (zk) − |∇ik f (zk)|2 + Lik t2

2Lik

8

and after taking expectation E · | zk conditioned on zk from the both sides of the obtained inequality

we get Note that

k+1

k

k 1 |∇ik f (zk)|2 k t2

k

E f (z ) | z ≤ f (z ) − E 2

Li

|z

+

E 8

Lik | z

.

k

E |∇ik f (zk)|2 | zk Lik

= d pi |∇if (zk)|2 i=1 Li
≥ ∇f (zk) 2 min pi 2 i=1,...,d Li

(44)
≥ 2µ f (zk) − f (x∗)

min pi ,

i=1,...,d Li

25

Published as a conference paper at ICLR 2020

since · D = · 2, and

E Lik | zk

d
= piLi.
i=1

Putting all together we get

E f (zk+1) | zk

≤ f (zk) − µ min pi i=1,...,d Li

f (zk) − f (x∗)

t2 d + 8 piLi.
i=1

Taking full expectation from the previous inequality we get

E f (zk+1) − f (x∗) ≤

1 − µ min pi i=1,...,d Li

t2 d

E f (zk) − f (x∗) +

piLi.

8

i=1

Since µ ≤ Li for all i = 1, . . . , d we have

E f (zk) − f (x∗) ≤ ≤

1 − µ min pi i=1,...,d Li t2 d
+ 8 piLi
i=1
1 − µ min pi i=1,...,d Li t2 d
+ 8 piLi
i=1

= 1 − µ min pi i=1,...,d Li

k
f (x0) − f (x∗)

k−1

pi l

1 − µ min

l=0 i=1,...,d Li

k
f (x0) − f (x∗)

∞

pi l

1 − µ min

l=0 i=1,...,d Li

k

0

∗

t2

f (x ) − f (x ) + 8µ

min

pi

i=1,...,d Li

d
piLi.
i=1

Lastly, from (69) we have

E f (zK ) − f (x∗) ≤

1 − µ min pi i=1,...,d Li

K
f (x0) − f (x∗) +

t2

d

p

piLi

8µ

min

i
L

i=1,...,d i

i=1

(≤70) exp −Kµ min pi i=1,...,d Li

f (x0) − f (x∗)

ε +

2

(71) ε ε ≤ + = ε.
22

E.4 COMPARISON OF SMTP AND SMTP_IS

Here we compare SMTP when D is normal distribution with zero mean and dI covariance matrix

with SMTP_IS with probabilities pi = Li/

d i=1

Li.

We

choose

such

a

distribution

for

SMTP

since

it shows the best dimension dependence among other distributions considered in Lemma F.1. Note

that if f satisﬁes Assumption 4.1, it is L-smooth with L = max Li. So, we always have that
i=1,...,d

d i=1

Li

≤

dL.

Table

3

summarizes

complexities

in

this

case.

We notice that for SMTP we have · D = · 2. That is why one needs to compare SMTP with SMTP_IS accurately. At the ﬁrst glance, Table 3 says that for non-convex and convex cases we
get an extra d factor in the complexity of SMTP_IS when L1 = . . . = Ld = L. However, it is natural since we use different norms for SMTP and SMTP_IS. In the non-convex case for SMTP we give number of iterations in order to guarantee E ∇f (zK) 2 ≤ ε while for SMTP_IS we provide number of iterations in order to guarantee E ∇f (zK) 1 ≤ ε. From Holder’s inequality

26

Published as a conference paper at ICLR 2020

Assumptions on f
None Convex, R0 < ∞ µ-strongly convex

SMTP Compleixty

πr0 dL ε2

πR02, 2 dL ln 2r0

2ε

ε

π2dµL ln 2rε0

Theorem
3.1 3.2 3.5

Importance Sampling

pi = pi = pi =

Li

d i=1

Li

Li

d i=1

Li

Li

d i=1

Li

SMTP_IS Complexity

2r0 d

d i=1

Li

ε2

ln R02, ∞ d

d i=1

Li

2r0

ε

ε

ln d
i=1

Li

2r0

µ

ε

Theorem
E.1 E.2 E.5

Table 3: Comparison of SMTP with D = N 0, dI

and SMTP_IS with pi = Li/

d i=1

Li.

Here

r0 = f (x0) − f (x∗), R0, 2 corresponds to the R0 from Assumption C.1 with · D = · 2 and

R0, ∞ corresponds to the R0 from Assumption C.1 with · D = · 1.

√ · 1 ≤ d · 2 and, therefore, in order to have E ∇f (zK ) 1 ≤ ε for SMTP we need to ensure

that E ∇f (zK ) 2 ≤ √ε . That is, to guarantee E ∇f (zK ) 1 ≤ ε SMTP for aforementioned
d

distribution needs to perform πr0εd22L iterations. √
Analogou√sly, in the convex case using Cauchy-Schwartz inequality · 2 ≤ d · ∞ we have that R0, 2 ≤ dR0, ∞ . Typically this inequality is tight and if we assume that R0, ∞ ≥ C R√0,d2 , we will

get that SMTP_IS complexity is R02, 2

d i=1

Li

ln

2r0

up to constant factor.

ε

ε

That is, in all cases SMTP_IS shows better complexity than SMTP up to some constant factor.

F AUXILIARY RESULTS

Lemma F.1 (Lemma 3.4 from Bergou et al. (2019)). Let g ∈ Rd.

1. If D is the uniform distribution on the unit sphere in Rd, then

1

γD = 1 and Es∼D | g, s | ∼ √ g 2.

(73)

2πd

Hence, D satisﬁes Assumption 3.1 with γD = 1, · D = · 2 and µD ∼ √ 1 .
2πd

2. If D is the normal distribution with zero mean and identity over d as covariance matrix (i.e.

s ∼ N (0, I )) then

d

√

2

γD = 1 and Es∼D | g, s | = √ g 2.

(74)

dπ

√

Hence, D satisﬁes Assumption 3.1 with γD = 1, · D = · 2 and µD = √ 2 .

dπ

3. If D is the uniform distribution on {e1, . . . , ed}, then 1
γD = 1 and Es∼D | g, s | = d g 1. (75) Hence, D satisﬁes Assumption 3.1 with γD = 1, · D = · 1 and µD = d1 .

4. If D is an arbitrary distribution on {e1, . . . , ed} given by P {s = ei} = pi > 0, then

d

γD = 1

and

Es∼D | g, s | =

def
g D=

pi|gi|.

(76)

i=1

Hence, D satisﬁes Assumption 3.1 with γD = 1 and µD = 1.

5. If D is a distribution on D = {u1, . . . , ud} where u1, . . . , ud form an orthonormal basis of Rd and P {s = di} = pi, then

d

γD = 1

and

Es∼D | g, s | =

def
g D=

pi|gi|.

(77)

i=1

27

Published as a conference paper at ICLR 2020 Hence, D satisﬁes Assumption 3.1 with γD = 1 and µD = 1.
28

