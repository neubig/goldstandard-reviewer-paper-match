CPMETRIC: Deep Siamese Networks for Metric Learning on Structured Preferences

arXiv:1809.08350v2 [cs.LG] 20 Jun 2019

Andrea Loreggia University of Padova
Padova, Italy
Francesca Rossi IBM Research
Yorktown Heights, NY, USA

Nicholas Mattei Tulane University New Orleans, LA, USA
K. Brent Venable Tulane University and IHMC
New Orleans, LA, USA

Abstract
Preference are central to decision making by both machines and humans. Representing, learning, and reasoning with preferences is an important area of study both within computer science and across the social sciences. When working with preferences it is necessary to understand and compute a metric (distance) between sets of objects, e.g., the preferences of two users. We present CPMETRIC, a novel neural network to address the problem of metric learning for structured preference representations. We use the popular CP-net formalism to represent preferences and then leverage deep neural networks to learn a recently proposed metric function that is computationally hard to compute directly. CPMETRIC is a novel metric learning approach as we learn the Kendal Tau distance between compact representations of partial orders as opposed to the (possibly exponential) induced partial orders. We ﬁnd that CPMETRIC is able to learn the metric function with high accuracy, outperforming existing approximation algorithms on both the regression and classiﬁcation tasks using less computation time. This increased performance over existing direct approximation algorithms persists even when CPMETRIC is trained with only a small number of samples compared to the dimension of the solution space, indicating the network generalizes well.
1 Introduction
Preferences are central to individual and group decision making by both computer systems and humans. Due to this central role in decision making the study of representing [47], learning [24], and reasoning [21, 45] with preferences is a focus of study within computer science and in many other disciplines including psychology and sociology [25]. Individuals express their preferences in many different ways: pairwise comparisons, rankings, approvals (likes), positive or negative examples, and many more examples are collected in various libraries and databases [5, 42, 43]. A core task in working with preferences is understanding the relationship between preferences. This often takes the form of a dominance query, i.e., which item is more or most preferred, or distance measures, i.e., which object is the closest to my stated preference. These types of reasoning are important in many domains including recommender systems [23, 46], collective decision making [10], and value alignment systems [39, 40, 49], among others.
Having a formal structure to model preferences, especially one that directly models dependency, can be useful when reasoning about preferences. For example, it can support reasoning based on inference and causality, and provide more transparency and explainability as the preferences are explicitly represented so the model is scrutable [30]. A number of compact preference representation languages
Preprint. Under review.

have been developed in the literature for representing and reasoning with preferences; see the work of Amor et al. [4] for a survey of compact graphical models. In this paper we speciﬁcally focus on conditional preference structures (CP-nets) [8].
CP-nets are a compact graphical model used to capture qualitative conditional preferences over features (variables) [8]. Qualitative preferences are an important formalism as there there is experimental evidence that qualitative preferences may more accurately reﬂect humans’ preferences in uncertain information settings [1, 48]. CP-nets are a popular formalism for specifying preferences in the litterature and have been used for a number of applications including recommender systems [46] and product speciﬁcation [23, 53]. Consider a car that is described by values for all its possible features: make, model, color, and stereo options. A CP-net consists of a dependency graph and a set of statements of the form, “all else being equal, I prefer x to y.” For example, in a CP-net one could say “Given that the car is a Honda Civic, I prefer red to yellow.”, where condition sets the context for the preference statement over possible alternatives. These preferences are qualitative as there is no quantity expressing how much I prefer one action over another one.
A CP-net induces an ordering over all possible outcomes, i.e., all complete assignments to the set of features. This is a partial order if the dependency graph of the CP-net is acyclic, i.e., the conditionality of the statements does not create a cycle, as is often assumed in work with CP-nets [26]. The size of the description of the CP-net may be exponentially smaller than the partial order it describes. Hence, CP-nets are called a compact representation and reasoning and learning on the compact structure, instead of the full order, is an important topic of research. Recent work proposes the ﬁrst formal metric to describe the distance between CP-nets [41] and the related formalism of LP-trees [37] in a rigorous way. What is important is not the differences in the surface features of the CP-nets, e.g., a single statement or dependency, but rather the distance between their induced partial orders. Even a small difference in a CP-net could generate a very different partial order, depending on which feature is involved in the modiﬁcation. While the metrics proposed by Loreggia et al. [41] are well grounded, they are computationally hard to compute, in general, and approximations must be used.
Following work in metric learning over structured representations [6, 7], we wish to learn the distance between partial orders represented compactly as CP-nets. We do not want to work with the partial orders directly as they may be exponentially larger than the CP-net representation. Informally, given two CP-nets, we wish to estimate the distance between their induced partial orders using a neural network. Notice that this is a fundamentally different task to metric learning over graphs as, although we estimate the distance between graphs (partial orders), we start from a compact representation and not the induced graphs as input. There has been recent interest in deep metric learning which is similar to the work we consider here. In deep metric learning we are typically given pairs of input and want to learn an embedding representation of the data that preserves the distance between similar items [51]. Again, however, this is different from our work as we do not work with individual pairwise comparisons but rather compact structures.
The aim of this work is not introducing a new graph learning method, an important topic in machine learning [20, 33], but rather to merge work in decision theory with machine learning techniques. This has been done before in the area of preference learning, where preferences are inferred from data under a given noise function [24]. However, to our knowledge this is the ﬁrst attempt to use neural nets to approximate a metric between structured, graphical preference representations. In addition to being an interesting fundamental problem there are practical applications as well. The number of possible CP-nets grows extremely fast, from 481,776 for 4 binary features to over 5.24 × 1040 with 7 binary features [2]. However, the computation time of the approximation algorithm proposed by Loreggia et al. [41] scales linearly with the number of features, hence, new methods must be explored. Therefore, leveraging the inferential properties of neural networks may help us make CP-nets more useful as a preference reasoning formalism.
Contributions We formalize the problem of metric learning on CP-nets, a compact preference representation, that combines elements of graph embeddings, metric learning, and preference reasoning into one problem. We present CPMETRIC, a siamese network [11] trained using pairs of CP-nets represented through their normalized Laplacian matrices and list of cp-statements. We decompose the problem into two steps: (1) learning a vector representation of the CP-nets and (2) learning the distance metric itself. We explore the beneﬁts of transfer learning through the use of an autoencoder [29]. We evaluate our approach both quantitatively, by judging the accuracy and mean absolute error (MAE) of CPMETRIC, and qualitatively, by judging if given two CP-nets we can determine which is
2

closer to a reference point. CPMETRIC is able to learn a good approximation of the distance function and outperforms in terms of both accuracy and speed the current best approximation algorithms on both the regression and classiﬁcation tasks. CPMETRIC gives good performance even when the network is trained with a small number of samples.
2 CP-nets
Conditional Preference networks (CP-nets) are a graphical model for compactly representing conditional and qualitative preference relations [8]. CP-nets are comprised of sets of ceteris paribus preference statements (cp-statements). For instance, the cp-statement, “I prefer red wine to white wine if meat is served," asserts that, given two meals that differ only in the kind of wine served and both containing meat, the meal with red wine is preferable to the meal with white wine. CP-nets have been extensively used in the preference reasoning [9, 17, 47], preference learning [14] and social choice [10, 35, 44] literature as a formalism for working with qualitative preferences [21]. CP-nets have even been used to compose web services [53] and other decision aid systems [46].
Formally, a CP-net has a set of features (or variables) F = {X1, . . . , Xn} with ﬁnite domains D(X∞), . . . , D(X\). For each feature Xi, we are given a set of parent features P a(Xi) that can affect the preferences over the values of Xi. This deﬁnes a dependency graph in which each node Xi has P a(Xi) as its immediate predecessors. An acyclic CP-net is one in which the dependency graph is acyclic. Given this structural information, one needs to specify the preference over the values of each variable Xi for each complete assignment to the the parent variables, P a(Xi). This preference is assumed to take the form of a total or partial order over D(X ). A cp-statement for some feature Xi that has parents P a(Xi) = {x1, . . . , xn} and domain D(Xi) = {a1, . . . , am} is a total ordering over D(Xi) and has general form: x1 = v1, x2 = v2, . . . , xn = vn : a1 . . . am, where for each Xi ∈ P a(X1) : xi = vi is an assignment to a parent of Xi with vi ∈ D(X ). The set of cp-statements regarding a certain variable Xi is called the cp-table for Xi.

Most Preferred abcd

abcd

abcd

abcd

abcd

a > a¯ A b > ¯b B

C
(a ∧ b) (a¯ ∧ ¯b) (a ∧ ¯b) (a¯ ∧ b)

Dc c¯
c > c¯ c > c¯ c¯ > c c¯ > c

d > d¯ d¯ > d

abcd

abcd

abcd

abcd

abcd

abcd

abcd

abcd

abcd

abcd

Least Preferred

abcd

Figure 1: A CP-net with n = 4 features (left) and part of in the induced partial order (right). Note that the partial order is over all 2n = 16 possible combinations and arrows denote the dominance
relation. We have arranged the nodes so that each is one ﬂip between the levels.

Consider the CP-net depicted graphically in Figure 1 (left) with features are A, B, C, and D. Each variable has binary domain containing f and f if F is the name of the feature. All cp-statements in the CP-net are: a a, b b, (a ∧ b) : c c, (a ∧ b) : c c, (a ∧ b) : c c, (a ∧ b) : c c,
c : d d, c : d d. Here, statement a a represents the unconditional preference for A = a over A = a, while statement c : d d states that D = d is preferred to D = d, given that C = c. The semantics of CP-nets depends on the notion of a worsening ﬂip: a change in the value of a variable to a less preferred value according to the cp-statement for that variable. For example, in the CP-net above, passing from abcd to abcd is a worsening ﬂip since c is better than c given a and b. One outcome α is preferred to or dominates another outcome β (written α β) if and only if there is a

3

chain of worsening ﬂips from α to β. This deﬁnition induces a preorder over the outcomes, which is a partial order if the CP-net is acyclic [8], as depicted in Figure 1 (right).
The complexity of dominance and consistency testing in CP-nets is an area of active study in preference reasoning [26, 47]. Finding the optimal outcome of a CP-net is NP-hard [8] in general but can be found in polynomial time for acyclic CP-nets by assigning the most preferred value for each cp-table. Indeed, acyclic CP-nets induce a lattice over the outcomes as (partially) depicted in Figure 1 (right). The induced preference ordering, Figure 1 (right), can be exponentially larger than the CP-net Figure 1 (left), which motivates learning a metric using only the (more compact) CP-net.

3 Metric Learning on CP-nets

Metric learning algorithms aim to learn a metric (or distance function) over a set of training points or samples [51]. The importance of metrics has grown in recent years with the use of these functions in many different domains: from clustering to information retrieval and from recommender systems to preference aggregation. For instance, many clustering algorithms like the k-Means or classiﬁcation algorithm including k-Nearest Neighbor use a distance value between points [19, 38]. In many recommender systems a similarity function allows for a better proﬁling [52].

Formally, a metric space is a pair (M, d) where M is a set of elements and d is a function d : M × M → R where d satisﬁes four criteria. Given any three elements A, B, C ∈ M , d must satisfy: (1) d(A, B) ≥ 0, there must be a value for all pairs; (2) d(A, B) = d(B, A), d must be symmetric; (3) d(A, B) ≤ d(A, C) + d(C, B); d must satisfy the triangle inequality; and (4) d(A, B) = 0 if and only if A = B; d can be zero if and only if the two elements are the same.

Xing et al. [55] ﬁrst formalized the problem of metric learning, i.e., learning the metric directly from samples rather than formally specifying the function d. This approach requires training data, meaning that we have some oracle that is able to give the value of the metric for each pair. The success of deep learning in many different domains [15, 34] has lead many researchers to apply these approaches to the ﬁeld of metric learning, resulting in a number of important results [6, 7, 51].

In this work we focus on metric spaces (M , d) where M is a set of CP-nets. Given this, we want to learn the distance d which best approximates the Kendall tau distance (KTD) [31] between the induced partial orders. Informally, the Kendall tau distance between two orderings is the number of pairs that are discordant, i.e., not ordered in the same way, in both orderings. This distance metric extended to partial orders (Deﬁnition 1) was deﬁned and proved to be a metric on the space of CP-nets by Loreggia et al. [41]. To extend the classic KTD to CP-nets a penalty parameter p deﬁned for partial rankings [22] was extended to the case of partial orders. Loreggia et al. [41] assume that all CP-nets are acyclic and in minimal (non-degenerate) form, i.e., all arcs in the dependency graph have a real dependency expressed in the cp-statements, a standard assumption in the CP-net literature (see e.g., [2, 3, 8]).

Deﬁnition 1. Given two CP-nets A and B inducing partial orders P and Q over the same unordered

set of outcomes U : KT D(A, B) = KT (P, Q) =

∀i,j∈U,i=j

K

p i,j

(

P

,

Q

)

where

i

and

j

are

two

outcomes with i = j (i.e., iterate over all unique pairs), we have:

1. Kip,j(P, Q) = 0 if i, j are ordered in the same way or are incomparable in P and Q; 2. Kip,j(P, Q) = 1 if i, j are ordered inversely in P and Q; 3. Kip,j(P, Q) = p, 0.5 ≤ p < 1 if i, j are ordered in P and incomparable in Q (resp. Q, P ).

To make this distance scale invariant, i.e., a value in [0, 1], it is divided by |U |.

CP-nets present two important and interesting challenges when used for metric learning. The ﬁrst is that we are attempting to learn a metric via a compact representation of a partial order. We are not learning over the partial orders induced by the CP-nets directly, as they could be exponentially larger than the CP-nets. The second challenge is the encoding of the graphical structure itself. Graph learning with neural networks is still a active and open area of research [12, 20, 28] including the popular Graph Convolutional Neural Network (GraphGCN) [33] and methods to speed up graph learning [13]. Goyal and Ferrara [27] give a complete survey of recent work as well as a Python library of implementations for many of these techniques. Most of these works focus on ﬁnding good embeddings for the nodes of the network and then using collections of these learned embeddings to

4

represent the graph for, e.g., particular segmentation or link prediction tasks. None of these techniques have been applied to embedding graphs for metric learning.

4 Structure of CPMETRIC

The architecture of CPMETRIC is depicted in Figure 2. In this section we will discuss the encoding used for the CP-nets and the design of our autoencoders, depicted in Figure 3 that are used for transfer learning in this domain. We would like to leverage transfer learning in this domain since training examples become prohibitively expensive to compute at higher values of n as computing KTD requires exponential time in the size of the CP-net. Hence, if we can learn a good encoding for CP-nets it may be possible to train a network for small n and use it for problems with larger CP-nets.

Encoder

Adjacency Matrix

Conv2D

Conv2D Fully connected

8 output filters 16 output filters 16 nodes

Kernel size (3x3) Kernel size (3x3)

CPMetric Network
Concatenate

Fully connected 1024 nodes

cp-statements

Concatenate

Fully connected M classes

Adjacency Matrix

Conv2D

Conv2D Fully connected

8 output filters 16 output filters 16 nodes

Kernel size (3x3) Kernel size (3x3)

Fully connected 128 nodes

cp-statements Encoder

Concatenate

Figure 2: Structure of CPMETRIC: CP-nets are provided to the encoder as a normalized Laplacian matrix and a list of cp-statements. The encoders output a compact representation of the CP-nets which is then concatenated and passed to the fully connected layers that connect to an m class classiﬁer over [0, 1] to predict KTD. For the regression task the network structure is the same except we change the output layer to be one node with a softmax activation layer.

In our task the metric space is (M, d) where M is a set of compact, graphical preferences that induce a
partial order and our goal is to learn the metric d only from the compact, graphical representation. The
key challenge is the need to ﬁnd a vector representation of not only the graph but the cp-statement. We
represent a CP-net I over m using two matrices. First is the adjacency matrix adjI which represents the dependency graph of the CP-net and is a m × m matrix of 0s and 1s. The second matrix represents the list of cp-statements cptI , which is a m × 2m−1 matrix, where each row represents a variable Xi ∈ F and each column represents a complete assignment for each of the variables in F \ Xi. The list is built following a topological ordering of variables in the CP-net. Each cell cptI (i, j) stores the preference value for the ith variable given the jth assignment to variables in F \ Xi.

In graph learning, the central research question is how to redeﬁne operators, such as convolution

and pooling, so as to generalize convolutional neural network (CNN) to graphs [20, 28]. The most

promising research uses a spectral formulation of the problem [12, 50]. The issue is that networks are

sensitive to isomorphisms of the adjacency matrix, hence directly using an adjacency matrix would

result in a siamese network that would not recognize isomorphic structures. We follow in the spirit

of the work by Kipf and Welling [33] for GCN and use a simple convolutional network structure

removing pooling layers from CPMETRIC, as we do not deﬁne any pooling operator over the graph

structure. In graph spectral analysis, the Laplacian matrix is preferred as it has better properties for

encoding, e.g., density, compared to just the adjacency matrix. The Laplacian matrix L = D − A,

where D is the degree matrix, a diagonal matrix whose ith diagonal element di is equal to the sum

of the weights of all the edges incident to vertex i, and A is the adjacency matrix representing the

graph.

The

normalized

Laplacian

L

=

I

−

D

1 2

×

A

×

D

1 2

[50].

While

the

Laplacian

matrix

is

5

still susceptible to exchanges of rows or columns, its spectrum (the vector of its eigenvalues) is an isomorphism invariant of a graph. The same graph can be represented using different structures (and this can be seen as a data augmentation technique) and we need all of these structures to learn the metric, so we cannot collapse to a single spectrum representation of the graph.
The set of training examples X = {x1, . . . , xn} is made up of pairs of CP-nets represented through their normalized Laplacians and the cp-statements. The set of corresponding labels Y = {y1, . . . , yn}T , where each yi ∈ Y, yi ∈ [0, 1] is the normalized value of KTD between the CP-nets in xi. Each xi ∈ X is then a tuple (LA, cptA, LB, cptB) representing a pair of CP-net (A, B) by their Laplacian, LA, and the encoding of their cp-statements, cptA.

Encoder

Adjaceny Matrix

Conv2D
8 output filters Kernel size (3x3)

Conv2D
16 output filters Kernel size (3x3)

Fully connected 16 nodes

Siamese Autoencoder
Adjaceny Matrix

cp-statements

Concatenate

cp-statements

Figure 3: Structure of Siamese Autoencoder: this version of the autoencoder uses a combined representation for the adjency matrix and the cp-statements.
The purpose of the two input components of CPMETRIC, labeled Encoder in Figure 2, is to output a compact representation of CP-nets. To improve performance with networks of this structure, a well-established practice is to train an autoencoder separately, and then transfer the weights to the main network [29, 36]. We will evaluate two different approaches to transfer learning in our setting. First, we use two different autoencoders: one for the normalized Laplacian matrix and the other for the cp-statements. The two autoencoders are trained separately and then weights are transferred to the main network. We denote this approach as Autoencoder in subsequent experiments. In the second approach, shown in Figure 3 and denoted as Siam. Autoencoder, we use a unique autoencoder designed to combine the two components of CP-nets. Informally, the output of two encoders are concatenated and then split into their respective components to be decoded. We conjecture that this combination should allow more information about the CP-net to be used.
5 Experiments
We train CPMETRIC to learn the KTD metric, varying the number of features of the CP-nets n ∈ {3, . . . , 7} and using two different autoencoder designs. We evaluate our networks on both the regression and classiﬁcation tasks and measure their performance against the current best approximation algorithm, I-CPD [41], for computing the KTD between two CP-nets. In the regression task the network computes the distance value exactly while in the classiﬁcation task we divide the output in m = 10 intervals and the network must select the correct interval.
5.1 Data Generation and Training
For each number of features n ∈ {3, . . . , 7} we generate 1000 CP-nets uniformly at random using the generators from Allen et al. [2, 3]. This set of CP-nets is split into a training-generative-set (900 CP-nets) and test-generative-set (100 CP-nets) 10 different ways to give us 10 fold cross validation. For each fold we compute the training and test dataset comprised of all, e.g., 9020 , possible pairs of CP-nets from the training-generative-set and test-generative-set, respectively, along with the value of KTD for that pair. While we generate the CP-nets themselves uniformly at random observe that this creates an unbalanced set of distances – it induces a normal distribution – and hence our sets are unbalanced. Figure 4 shows the distribution of of CP-net pairs over 20 intervals for all CP-nets
6

Number of CP-net Pairs

140000 Distribution of CP-net Pairs per Classes
120000 100000 80000 60000 40000 20000
Intervals 0 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20

N

I-CPD

Autoencoder Neural Network

3 0.69 (0.48) msec 4 1.09 (0.33) msec 5 1.85 (0.49) msec 6 3.16 (0.74) msec 7 4.65 (0.86) msec

0.087 (0.004) msec 0.098 (0.004) msec 0.100 (0.005) msec 0.114 (0.003) msec 0.138 (0.001) msec

Figure 4: Histogram of the number of CP-net pairs per interval across all experimental datasets. CP-nets pairs are not distributed uniformly in the class intervals.

Table 1: Comparison of the mean runtime for a single triple over 1000 trials on the qualitative comparison task of the neural network and I-CPD [41].

generated for n ∈ {3, . . . , 7}. While our classiﬁcation experiments are for m = 10 classes, dividing the interval into 20 classes provides a better visualization of the challenge of obtaining training samples at the edges of the distribution.
We ran a preliminary experiment on balancing our dataset by sub-sampling the training and test datasets. In these small experiments, performance was much worse than performance on the unbalanced dataset, e.g., for classiﬁcation the MAE for n = 3 was 0.626 and n = 4 was 0.4962 versus 0.2734 and 0.2548 for the unbalanced results (Figure 2). Because we are learning a metric, for each CP-net A, there is only one CP-net B such KT D(A, B) = 1 and only one CP-net C such KT D(A, C) = 0. Consequently, attempting to balance or hold out CP-nets from test or train can lead to poor performance. We conjecture that in order to improve this task we should perform some kind of data augmentation, but this would introduce more subjective assumptions on how and where data should be augmented [54].
All training was done on a machine with 2 x Intel(R) Xeon(R) CPU E5-2670 @ 2.60GHz and one NVidia K20 128GB GPU. We train CPMETRIC for 70 epochs using the Adam optimizer [32]. For each number of features of the CP-net n we use all 9200 pairs in the training-set. There are only 488 binary CP-nets with 3 features [2], hence, for n = 3 the training-set is 17K samples while for n > 3 the number of samples in the training-set is 800K. Both the Autoencoder and Siamese Autoencoder models are trained for 100 epochs using the Adam optimizer [32] using the same training-set. Model weights from the best performing epoch are saved and subsequently transferred to the deep neural network used to learn the distance function.

(a) Autoencoder loss for 100 epochs.

(b) Autoencoder loss for 10 epochs.

Figure 5: Performance of the autoencoder on the validation and training set across epochs. Note

The training and validation loss for the autoencoder is shown in Figure 5. Observe that the loss for the CPT representation approaches zero after only 3 epochs for both the training and validation phases. The same trend is true for the adjacency matrix, though the loss converges to ≈ 0.15.

5.2 Quantitative Performance: Classiﬁcation and Regression
The ﬁrst task for CPMETRIC is classifying the distance between two CP-nets, A and B, into the same one of m = 10 intervals of [0, 1] where the value of KTD lies. Table 2 gives the F-score, Cohen’s

7

Kappa (Cohen-κ) [16], and mean absolute error (MAE) for the task with no autoencoder and each of the two autoencoder variants. Cohen’s κ is a measure of inter-rater agreement where the two raters are the particular instance of CPMETRIC and the actual value of KTD. We measure mean absolute error as a value over the number of intervals between the value returned by CPMETRIC and KTD. For example, a MAE of 1.0 means that CPMETRIC is off by one interval, on average. In this setting, using a random classiﬁer to guess the interval with m = 10 possible intervals and a normal distribution like the one seen in Figure 4 would give an F-score ≈ 0.19.

No Autoencoder

Autoencoder

Siam. Autoencoder

I-CPD

N

F-score

Cohen-κ MAE

F-score

Cohen-κ MAE

F-score

Cohen-κ MAE MAE

3 0.6643 (0.0275) 0.6113 0.3449 0.7051 (0.0306) 0.6578 0.2986 0.7295 (0.0501) 0.6860 0.2734 0.4235 4 0.7424 (0.0096) 0.6762 0.2582 0.7483 (0.0085) 0.6824 0.2525 0.7459 (0.0088) 0.6796 0.2548 0.4515 5 0.7074 (0.0111) 0.6146 0.3015 0.7271 (0.0084) 0.6385 0.2833 0.7278 (0.0077) 0.6393 0.2831 0.3875 6 0.6945 (0.0130) 0.5799 0.3194 0.7157 (0.0198) 0.6073 0.2971 0.7161 (0.0141) 0.6081 0.2969 0.3645 7 0.6887 (0.0227) 0.5571 0.3256 0.6497 (0.0892) 0.4957 0.3830 0.6884 (0.0274) 0.5549 0.3266 0.3340

Table 2: Performance of CPMETRIC on the classiﬁcation task with and without the autoencoders. Numbers in parenthesis are standard deviations. Mean absolute error is computed as the number of intervals between the true and predicted values for the classiﬁcation task.

No Autoencoder Autoencoder Siam. Autoencoder I-CPD

3

0.0470

0.0426

4 0.0248 (0.0008) 0.0242 (0.0005)

5 0.0269 (0.0006) 0.0261 (0.0008)

6 0.0257 (0.0007) 0.0255 (0.0007)

7 0.0257 (0.0008) 0.0257 (0.0022)

0.0421 0.0243 (0.0007) 0.0262 (0.0008) 0.0256 (0.0006) 0.0252 (0.0015)

0.0576 0.0526 0.0463 0.0405 0.0373

Table 3: MAE of CPMETRIC on the regression task with and without the autoencoders. MAE is the mean over 10 folds and numbers in parenthesis are the standard deviations.

Looking at Table 2 we see that CPMETRIC achieves outperforms the I-CPD approximation algorithm across the test instances. The overall accuracy, measured as F-score, is above 70% across all CP-net sizes and we see that on average it is off by less than 0.5 intervals as measured by the MAE. The values for Cohen’s κ indicate good agreement between the two methods and this is borne out by high accuracy numbers. The most interesting overall effect in Table 2 is that the performance does not decay much as we increase the number of features. Indeed, the F-score remains very stable across the range. We interpret this to mean that CPMETRIC is learning a good generalization of the distance function even when the solution space is exponentially larger than the number of training examples.
Table 3 we see the results of the much harder regression task. Again we see that CPMETRIC is able to out perform the state of the art I-CPD approximation across the board. While for n = 3 the values are similar, for n ∈ {4, . . . 7} CPMETRIC is giving a ≈ 30% decrease in error, ≈ 0.015 absolute decrease. Looking at results from Table 1 we can see that CPMETRIC is doing this signiﬁcantly faster than I-CPD as well. It is interesting to note that in Table 3 all versions of our network are outperforming I-CPD, whether or not we ﬁrst train the autoencoder.
Turning to the question of transfer learning for this task we see that the use of the autoencoders strictly increases the performance of the network on the classiﬁcation and regression task. In both cases the best performing networks use one of the two autoencoder variants we tested. The Siamese Autoencoder slightly out performs the plain Autoencoder when looking at MAE for the classiﬁcation task, though the results are more mixed for F-score and Cohen-κ. In the regression task the Siamese Autoencoder is better at the end points and the two networks are statistically indistinguishable for n ∈ {4, 5, 6}. These results indicate that the use of an autoencoder can signiﬁcantly help in this task, though the exact design of that autoencoder remains an important question for future work. Important future work is using an autoencoder trained for a smaller number of features to bootstrap learning for larger numbers of features.

6 Conclusion
We present CPMETRIC, a novel neural network model to learn a metric (distance) function between partial orders induced from a CP-net, a compact, structured preference representation. To our knowledge this is the ﬁrst use of neural networks to learn structured preference representations. We leverage

8

recent research in metric learning and graph embeddings to achieve state of the art results on the task. We also demonstrate the value of transfer learning in this domain through the use of two novel autoencoders for the CP-net formalism. Important directions for future work include integrating novel graph learning techniques to our networks and extending our work to other formalisms including, e.g., PCP-nets [17] and LP-trees [37]. PCP-nets are a particularly interesting direction as they have been proposed as an efﬁcient way to model uncertainty over the preferences of a single or multiple agents [18]
References
[1] T. E. Allen, M. Chen, J. Goldsmith, N. Mattei, A. Popova, M. Regenwetter, F. Rossi, and C. Zwilling. Beyond theory and data in preference modeling: Bringing humans into the loop. In Proc. 4th ADT, 2015.
[2] T. E. Allen, J. Goldsmith, H. E. Justice, N. Mattei, and K. Raines. Uniform random generation and dominance testing for cp-nets. JAIR, 59:771–813, 2017.
[3] T.E. Allen, J. Goldsmith, H.E. Justice, N. Mattei, and K. Raines. Generating CP-nets uniformly at random. In Proc. 30th AAAI, 2016.
[4] N. B. Amor, D. Dubois, H. Gouider, and H. Prade. Graphical models for preference representation: An overview. In Proceedings of the 10th International Scalable Uncertainty Management (SUM 2016), pages 96–111, 2016.
[5] K. Bache and M. Lichman. UCI Machine Learning Repository, 2013. URL http://archive.ics. uci.edu/ml. University of California, Irvine, School of Information and Computer Sciences.
[6] Aurélien Bellet, Amaury Habrard, and Marc Sebban. A survey on metric learning for feature vectors and structured data. CoRR, abs/1306.6709, 2013.
[7] Aurélien Bellet, Amaury Habrard, and Marc Sebban. Metric Learning. Synthesis Lectures on Artiﬁcial Intelligence and Machine Learning. Morgan & Claypool Publishers, 2015.
[8] C. Boutilier, R. Brafman, C. Domshlak, H.H. Hoos, and D. Poole. CP-nets: A tool for representing and reasoning with conditional ceteris paribus preference statements. Journal of Artiﬁcial Intelligence Research, 21:135–191, 2004.
[9] Ronen I. Brafman and Yannis Dimopoulos. Extended semantics and optimization algorithms for CPnetworks. Computational Intelligence, 20(2):218–245, 2004.
[10] F. Brandt, V. Conitzer, U. Endriss, J. Lang, and A. D. Procaccia, editors. Handbook of Computational Social Choice. Cambridge University Press, 2016.
[11] Jane Bromley, James W. Bentz, L. Bottou, Isabelle Guyon, Yann LeCun, Cliff Moore, Eduard Sackinger, and Roopak Shah. Signature veriﬁcation using a “siamese” time delay neural network. IJPRAI, 7(4): 669–688, 1993.
[12] J. Bruna, W. Zaremba, A. Szlam, and Y. LeCun. Spectral networks and locally connected networks on graphs. arXiv, abs/1312.6203, 2013.
[13] J. Chen, T. Ma, and C. Xiao. FastGCN: Fast learning with graph convolutional networks via importance sampling. In Proc. 6th ICLR, 2018.
[14] Yann Chevaleyre, Frédéric Koriche, Jérôme Lang, Jérôme Mengin, and Bruno Zanuttini. Learning ordinal preferences on multiattribute domains: The case of CP-nets. In Preference Learning, pages 273–296. Springer, 2011.
[15] S. Chopra, R. Hadsell, and Y. LeCun. Learning a similarity metric discriminatively, with application to face veriﬁcation. In Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on, volume 1, pages 539–546, 2005.
[16] P. R. Cohen. Empirical Methods for Artiﬁcial Intelligence. MIT Press, 1995.
[17] C. Cornelio, J. Goldsmith, N. Mattei, F. Rossi, and K.B. Venable. Updates and uncertainty in CP-nets. In Proc. 26th AUSAI, 2013.
[18] C. Cornelio, U. Grandi, J. Goldsmith, N. Mattei, F. Rossi, and K.B. Venable. Reasoning with PCP-nets in a multi-agent context. In Proc. 14th AAMAS, 2015.
9

[19] T. Cover and P. Hart. Nearest neighbor pattern classiﬁcation. IEEE Trans. Inf. Theor., 13(1):21–27, September 2006. ISSN 0018-9448.
[20] M. Defferrard, X. Bresson, and P. Vandergheynst. Convolutional neural networks on graphs with fast localized spectral ﬁltering. In Proc. 30th NeurIPS, pages 3837–3845, 2016.
[21] C. Domshlak, E. Hüllermeier, S. Kaci, and H. Prade. Preferences in AI: An overview. AI, 175(7): 1037–1052, 2011.
[22] Ronald Fagin, Ravi Kumar, Mohammad Mahdian, D. Sivakumar, and Erik Vee. Comparing partial rankings. SIAM J. Discret. Math., 20(3):628–648, March 2006. ISSN 0895-4801. doi: 10.1137/05063088X.
[23] Sheik Mohammad Mostakim Fattah, Athman Bouguettaya, and Sajib Mistry. A CP-Net based qualitative composition approach for an IaaS provider. In International Conference on Web Information Systems Engineering, pages 151–166. Springer, 2018.
[24] J. Fürnkranz and E. Hüllermeier. Preference Learning. Springer, 2010.
[25] J. Goldsmith and U. Junker. Preference handling for artiﬁcial intelligence. AI Magazine, 29(4), 2009.
[26] J. Goldsmith, J. Lang, M. Truszczyn´ski, and N. Wilson. The computational complexity of dominance and consistency in CP-nets. Journal of Artiﬁcial Intelligence Research, 33(1):403–432, 2008.
[27] Palash Goyal and Emilio Ferrara. Graph embedding techniques, applications, and performance: A survey. CoRR, abs/1705.02801, 2017.
[28] M. Henaff, J. Bruna, and Y. LeCun. Deep convolutional networks on graph-structured data. arXiv, abs/1506.05163, 2015.
[29] G. E. Hinton and Ruslan R Salakhutdinov. Reducing the dimensionality of data with neural networks. Science, 313(5786):504–507, 2006.
[30] S. Kambhampati. Synthesizing explainable behavior for human-ai collaboration. In Proc. 18th AAMAS, 2019.
[31] M. G. Kendall. A new measure of rank correlation. Biometrika, 30(1/2):81–93, 1938.
[32] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv/1412.6980, 2014.
[33] T. N. Kipf and M. Welling. Semi-supervised classiﬁcation with graph convolutional networks. arXiv, abs/1609.02907, 2016.
[34] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classiﬁcation with deep convolutional neural networks. In Advances in neural information processing systems, pages 1097–1105, 2012.
[35] J. Lang and L. Xia. Sequential composition of voting rules in multi-issue domains. Mathematical Social Sciences, 57(3):304–324, 2009.
[36] Y. Lecun and Y. Bengio. Convolutional Networks for Images, Speech and Time Series, pages 255–258. The MIT Press, 1995.
[37] Minyi Li and Borhan Kazimipour. An efﬁcient algorithm to compute distance between lexicographic preference trees. In Proc. 27th IJCAI, pages 1898–1904, 2018.
[38] S. Lloyd. Least squares quantization in pcm. IEEE Trans. Inf. Theor., 28(2):129–137, September 2006. ISSN 0018-9448.
[39] A. Loreggia, N. Mattei, F. Rossi, and K. B. Venable. Preferences and ethical principles in decision making. In Proceedings of the 1st AAAI/ACM Conference on AI, Ethics, and Society (AIES), 2018.
[40] A. Loreggia, N. Mattei, F. Rossi, and K. B. Venable. Value alignment via tractable preference distance. In R. V. Yampolskiy, editor, Artiﬁcial Intelligence Safety and Security, chapter 18. CRC Press, 2018.
[41] A. Loreggia, N. Mattei, F. Rossi, and K. B. Venable. On the distance between CP-nets. In Proc. 17th AAMAS, 2018.
[42] N. Mattei and T. Walsh. PREFLIB: A library for preferences, HTTP://WWW.PREFLIB.ORG. In Proc. 3rd ADT, 2013.
10

[43] N. Mattei and T. Walsh. A PREFLIB.ORG Retrospective: Lessons Learned and New Directions. In U. Endriss, editor, Trends in Computational Social Choice, chapter 15, pages 289–309. AI Access Foundation, 2017.
[44] N. Mattei, M. S. Pini, F. Rossi, and K. B. Venable. Bribery in voting with CP-nets. AMAI, 68(1–3): 135–160, 2013.
[45] G. Pigozzi, A. Tsoukiàs, and P. Viappiani. Preferences in artiﬁcial intelligence. Annals of Mathematics and Artiﬁcial Intelligence, 77:361–401, 2015.
[46] P. Pu, B. Faltings, L. Chen, J. Zhang, and P. Viappiani. Usability guidelines for product recommenders based on example critiquing research. In F. Ricci, L. Rokach, B. Shapira, and P. B. Kantor, editors, Recommender Systems Handbook, pages 511–545. Springer, 2011.
[47] F. Rossi, K.B. Venable, and T. Walsh. A Short Introduction to Preferences: Between Artiﬁcial Intelligence and Social Choice. Morgan and Claypool, 2011.
[48] A.E. Roth and J.H. Kagel. The Handbook of Experimental Economics, volume 1. Princeton University Press Princeton, 1995.
[49] Stuart Russell, Daniel Dewey, and Max Tegmark. Research priorities for robust and beneﬁcial artiﬁcial intelligence. AI Magazine, 36(4):105–114, 2015.
[50] D. I. Shuman, S. K. Narang, P. Frossard, A. Ortega, and P. Vandergheynst. The emerging ﬁeld of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains. IEEE Signal Process. Mag., 30(3):83–98, 2013.
[51] K. Sohn. Improved deep metric learning with multi-class n-pair loss objective. In Advances in Neural Information Processing Systems (NeruIPS, pages 1857–1865, 2016.
[52] H. Wang, J. Zhang, C. Wan, S. Shao, R. Cohen, Junjie Xu, and P. Li. Web service selection for multiple agents with incomplete preferences. In 2010 IEEE/WIC/ACM International Conference on Web Intelligence (WI), pages 565–572, 2010.
[53] Hongbing Wang, Shizhi Shao, Xuan Zhou, Cheng Wan, and Athman Bouguettaya. Web service selection with incomplete or inconsistent user preferences. In Proc. 7th International Conference on Service-Oriented Computing, pages 83–98. Springer, 2009.
[54] S. C. Wong, A. Gatt, V. Stamatescu, and M. D McDonnell. Understanding data augmentation for classiﬁcation: When to warp? In Proc. of the 2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA), pages 1–6, 2016.
[55] E. P. Xing, A. Y. Ng, M. I. Jordan, and S. J. Russell. Distance metric learning with application to clustering with side-information. In Proc. 15th NeurIPS, pages 505–512, 2002.
11

