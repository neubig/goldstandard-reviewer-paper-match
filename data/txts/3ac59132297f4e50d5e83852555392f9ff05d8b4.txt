Derivative-Free Method For Composite
Optimization With Applications To
Decentralized Distributed Optimization
Aleksandr Beznosikov ∗ Eduard Gorbunov ∗∗ Alexander Gasnikov ∗∗∗
∗ Moscow Institute of Physics and Technology, Russia Sirius University of Science and Technology, Russia
(e-mail: beznosikov.an@phystech.edu). ∗∗ Moscow Institute of Physics Technology, Russia Sirius University of Science and Technology, Russia Institute for Information Transmission Problems RAS, Russia
(e-mail: eduard.gorbunov@phystech.edu). ∗∗∗ Moscow Institute of Physics and Technology, Russia
Sirius University of Science and Technology, Russia Institute for Information Transmission Problems RAS, Russia, Caucasus Mathematical Center, Adyghe State University, Russia
(e-mail: gasnikov@yandex.ru).

arXiv:1911.10645v5 [math.OC] 10 Sep 2020

Abstract: In this paper, we propose a new method based on the Sliding Algorithm from Lan (2016, 2019) for the convex composite optimization problem that includes two terms: smooth one and non-smooth one. Our method uses the stochastic noised zeroth-order oracle for the nonsmooth part and the ﬁrst-order oracle for the smooth part. To the best of our knowledge, this is the ﬁrst method in the literature that uses such a mixed oracle for the composite optimization. We prove the convergence rate for the new method that matches the corresponding rate for the ﬁrst-order method up to a factor proportional to the dimension of the space or, in some cases, its squared logarithm. We apply this method for the decentralized distributed optimization and derive upper bounds for the number of communication rounds for this method that matches known lower bounds. Moreover, our bound for the number of zeroth-order oracle calls per node matches the similar state-of-the-art bound for the ﬁrst-order decentralized distributed optimization up to to the factor proportional to the dimension of the space or, in some cases, even its squared logarithm.

Keywords: gradient sliding, zeroth-order optimization, decentralized distributed optimization, composite optimization

1. INTRODUCTION

In this paper we consider ﬁnite-sum minimization problem

1m

min f (x) =

fi(x),

(1)

x∈X ⊆Rn

m

i=1

where each fi is convex and diﬀerentiable function and X is closed and convex. Such kind of problems are highly widespread in machine learning applications Shalev-Shwartz and Ben-David (2014), statistics Spokoiny et al. (2012) and control theory Rao (2009). In particular, we are interested in the case when functions fi are stored on diﬀerent devices which are connected in a network Lan et al. (2017); Scaman et al. (2017, 2018, 2019); Dvinskikh et al. (2019); Dvinskikh and Gasnikov (2019); Gorbunov et al. (2019); Uribe et al. (2020). This scenario often appears when the goal is to accelerate the training of big machine learning models or when the information that deﬁnes fi is known only to the i-th worker.

In the centralized or parallel case, the general algorithmic scheme can be described in the following way:
1) each worker in parallel performs computations of either gradients or stochastic gradients of fi;
2) then workers send the results (not necessarily gradients that they just computed) to one predeﬁned node called master node;
3) master node processes received information and broadcast new information to each worker that is needed to get new iterate and then the process repeats.
However, such an approach has several problems, e.g. synchronization drawback or high requirements to the master node. There are a lot of works that cope with aforementioned drawbacks (see Stich (2018); Karimireddy et al. (2019); Alistarh et al. (2017); Wen et al. (2017)).
Another possible approach to deal with these drawbacks is to use decentralized architecture Bertsekas and Tsitsiklis (1989). Essentially it means that workers are able to com-

municate only with their neighbors and communications are simultaneous. We also want to mention that such an approach is more robust, e.g. it can be applied to timevarying (wireless) communication networks Rogozin and Gasnikov (2019).

1.1 Our contributions

We develop a new method called Zeroth-Order Sliding Algorithm (zoSA) for solving convex composite problem containing non-smooth part and L-smooth part which uses biased stochastic zeroth-order oracle for the non-smooth term and ﬁrst-order oracle for the smooth component which is, to the best of our knowledge, the ﬁrst method that uses zeroth-order and ﬁrst-order oracles for composite optimization problem in such a way (see the details in Section 3). We prove the convergence result for the proposed method that matches known results for the number of ﬁrstoracle calls. Regarding the non-smooth component, we prove that the required number of zeroth-order oracle calls is typically n times or, in some cases, log2 n times larger then the corresponding bound obtained for the number of ﬁrst-order oracle calls required for the non-smooth part which is natural for the derivative-free optimization (see Larson et al. (2019)). Moreover, we extend the proposed method to the case when the smooth term is additionally strongly convex.
Next, we show how to apply zoSA to the decentralized distributed optimization and get results that match the state-of-the-art results for the ﬁrst-order non-smooth decentralized distributed optimization in terms of the communication rounds.

2. NOTATION AND DEFINITIONS

We use x, y d=ef

n i=1

xiyi

to

denote

standard

inner

product of x, y ∈ Rn where xi corresponds to the i-th

component of x in the standard basis in Rn. It induces

2-norm in Rn in the following way x 2 d=ef x, x . We

denote p-norms as x p d=ef (

n i=1

|xi|p)1/p

for

p

∈

(1, ∞)

and for p = ∞ we use x ∞ d=ef max1≤i≤n |xi|. The dual

norm · ∗ for the norm · is deﬁned in the following way:

y ∗ d=ef max { x, y | x ≤ 1}. To denote maximal and

minimal positive eigenvalues of positive semideﬁnite matrix A ∈ Rn×n we use λmax(A) and λ+min(A) respectively

and we use χ(A) d=ef / λmax(A) λ+ (A) to denote condition min

number of A. Operator E[·] denotes full mathematical

expectation and operator Eξ[·] express conditional math-

ematical expectation w.r.t. all randomness coming from

random variable ξ. To deﬁne the Kronecker product of

two matrices A ∈ Rm×m and B ∈ Rn×n we use A ⊗ B ∈ Rnm×nm. The identity matrix of the size n × n is

denoted in our paper by In.

Since all norms in ﬁnite dimensional space are equivalent, there exist such constants C1, C2 and C3 that for all x ∈ Rn

x ∗ ≤ C1 x 2, x 2 ≤ C2 x ∗, x ≤ C3 x 2. (2) For example, if · = · 2, then C1 = C2 = C3 = 1 an√d if
· = · 1, then · ∗ = · ∞ and C1 = 1, C2 = C3 = n.

Deﬁnition 1. (L-smoothness). Function g is called L-smooth in X ⊆ Rn with L > 0 w.r.t. norm · when it is diﬀerentiable and its gradient is L-Lipschitz continuous in X, i.e.
∇g(x) − ∇g(y) ∗ ≤ L x − y , ∀x, y ∈ X.

One can show that L-smoothness implies (see Nesterov (2004))

g(x) ≤ g(y)+

∇g(y), x−y

L +

x−y

2,

∀x, y ∈ X. (3)

2

Deﬁnition 2. (s-neighborhood of a set). For a given set X ⊆ Rn and s > 0 the s-neighborhood of X w.r.t.
norm · is denoted by Xs which is deﬁned as Xs d=ef {z ∈ Rn | ∃ x ∈ X : y − x ≤ s}.

Deﬁnition 3. (Bregman divergence). Assume that function ν(x) is 1-strongly convex w.r.t. · -norm and diﬀerentiable on X function. Then for any two points x, y ∈ X we deﬁne Bregman divergence V (x, y) associated with ν(x) as follows:

V (x, y) d=ef ν(y) − ν(x) − ∇ν(x), y − x .

Note that 1-strong convexity of ν(x) implies

1 V (x, y) ≥

x−y

2.

(4)

2

Finally, we denote the Bregman-diameter of the set X

w.r.t. V (x, y) as DX,V d=ef max{ 2V (x, y) | x, y ∈ X}.

In view of (4) DX,V is an upper bound for the standard

diameter of the set DX d=ef max{ x − y | x, y ∈ X}.

When V (x, y) = 21

x−y

2 2

(standard

Euclidean

proximal

setup) we have DX,V = DX . If · = · 1 is 1-norm,

then in the case when X is a probability simplex, i.e.

X = {x ∈ Rn+ |

n i=1

xi

=

1},

and

the

distance

generating

function ν(x) is entropic, i.e. ν(x) =

n i=1

xi

ln

xi

,

we

have that V (x, y) is the Kullback-Lei√bler divergence, i.e.

V (x, y) = ni=1 xi ln xyii , and DX,V = 2 ln n (see Ben-Tal

and Nemirovski (2015)).

3. MAIN RESULT

3.1 Convex Case

We consider the composite optimization problem

min Ψ0(x) = f (x) + g(x),

(5)

x∈X

where X ⊆ Rn is a compact and convex set with diameter

DX in · -norm, function g is convex and L-smooth on X,

f is convex diﬀerentiable function on X. Assume that we

have an access to the ﬁrst-order oracle for g, i.e. gradient

∇g(x) is available, and to the biased stochastic zeroth-

order oracle for f (see also Gorbunov et al. (2018)) that

for a given point x returns noisy value f˜(x) such that

f˜(x) d=ef f (x, ξ) + ∆(x)

(6)

where ∆(x) is a bounded noise of unknown nature

|∆(x)| ≤ ∆

(7)

and random variable ξ is such that

E[f (x, ξ)] = f (x),

(8)

Additionally, we assume that for all x ∈ Xs (s ≤ DX )

∇f (x, ξ) 2 ≤ M (ξ), E[M 2(ξ)] = M 2.

(9)

This assumption implies that for all x ∈ Xs |f (x, ξ) − f (y, ξ)| ≤ M (ξ) x − y 2
and ∇f (x) 2 ≤ M.

In other words, one can consider f˜r(x) as a biased stochastic gradient of F (x) with bounded second moment and
apply Stochastic Gradient Sliding from Lan (2016, 2019)
with this stochastic gradient to solve problem (17).

Using this one can construct a stochastic approximation

of ∇f (x) via ﬁnite diﬀerences (see Nesterov and Spokoiny

(2017); Shamir (2017)):

f˜ (x) = n (f˜(x + re) − f˜(x − re))e

(10)

r

2r

where e is a random vector uniformly distributed on the

Euclidean sphere and

r < sC3

(11)

is a smoothing parameter. Inequality (11) guarantees that the considered approximation requires points only from sneighborhood of X since re ≤ rC3 (see (2)). Therefore, throughout the paper we assume that (11) holds. Following Shamir (2017) we assume that there exists such constant p∗ > 0 that

4

E[

e

4 ∗

]

≤

p∗

.

(12)

For example, when · = · 2 we have p∗ = 1 and for the

case when · = · 1 one can show that p∗ = O ln(n)/n

Algorithm 1 Zeroth-Order Sliding Algorithm (zoSA)
Input: Initial point x0 ∈ X and iteration limit N . Let βk ∈ R++, γk ∈ R+, and Tk ∈ N, k = 1, 2, . . ., be given and set x0 = x0. for k = 1, 2, . . . , N do
1. Set xk = (1 − γk)xk−1 + γkxk−1, and let hk(·) ≡ lg(xk, ·) be deﬁned in (22).
2. Set
(xk, x˜k) = PS(hk, xk−1, βk, Tk);
3. Set xk = (1 − γk)xk−1 + γkx˜k. end for Output: xN .
The PS (prox-sliding) procedure. procedure: (x+, x˜+) = PS(h, x, β, T ) Let the parameters pt ∈ R++ and θt ∈ [0, 1], t = 1, . . ., be given. Set u0 = u˜0 = x. for t = 1, 2, . . . , T do

(see Corollaries 2 and 3 from Shamir (2017)). Consider also the smoothed version

ut = argmin h(u) + f˜r(ut−1), u
u∈X

F (x) d=ef Ee[f (x + re)]

(13)

+βV (x, u) + βptV (ut−1, u) ,

(20)

of f (x) which is a diﬀerentiable in x function. In the

u˜t = (1 − θt)u˜t−1 + θtut.

(21)

following we summarize key properties of F (x).

end for

Lemma 1. (see also Lemma 8 from Shamir (2017)). Assume Set x+ = uT and x˜+ = u˜T .

that diﬀerentiable function f deﬁned on Xs satisfy end procedure:

∇f (x) 2 ≤ M with some constant M > 0. Then F (x)

deﬁned in (13) is convex, diﬀerentiable and F (x) satisﬁes

sup |F (x) − f (x)| ≤ rM ,

(14)

x∈X

n

∇F (x) = Ee f (x + re)e , (15)

√r

∇F (x) ∗ ≤ c˜p∗ nM,

(16)

where c˜ is some positive constant independent of n and p∗ is deﬁned in (12).

In other words, F (x) provides a good approximation of f (x) for small enough r. Therefore, instead of solving (5) directly one can focus on the problem

min Ψ(x) d=ef F (x) + g(x)

(17)

x∈X

with small enough r since the diﬀerence between optimal

values for (5) and (17) is at most rM . The following

lemma establishes useful relations between ∇F (x) and

f˜r(x) deﬁned in (10).

Lemma 2. (modiﬁcation of Lemma 10 from Shamir (2017)).

For f˜r(x) deﬁned in (10) the following inequalities hold:

E[f˜ (x)] − ∇F (x) ∗ ≤ n∆p∗ ,

(18)

r

r

E[ f˜ (x) 2] ≤ 2p2 cnM 2 + n2∆2 ,

(19)

r

∗

∗

r2

where c is some positive constant independent of n.

In the Algorithm 1 we use the following function

lg(x, y) d=ef g(x) + ∇g(x), y − x .

(22)

At each iteration of PS subroutine the new direction e is sampled independently from previous iterations. We emphasize that we do not need to compute values of F (x) which in the general case requires numerical computation of integrals over a sphere. In contrast, our method requires to know only noisy values of f deﬁned in (6).

Next, we present the convergence analysis of zoSA that relies on the analysis for the Gradient Sliding method from Lan (2016, 2019). The following lemma provides an analysis of the subroutine PS from Algorithm 1.
Lemma 3. (modiﬁcation of Proposition 8.3 from Lan (2019)). Assume that {pt}t≥1 and {θt}t≥1 in the subroutine PS of Algorithm 1 satisfy

θt = Pt−1 − Pt , (23) (1 − Pt)Pt−1

1

t = 0,

Pt = pt(1 + pt)−1Pt−1 t ≥ 1.

Then for any t ≥ 1 and u ∈ X:

β(1 − Pt)−1V (ut, u) + [Φ(u˜t) − Φ(u)] ≤ βPt(1 − Pt)−1V (u0, u)
+Pt(1 − Pt)−1 t (piPi−1)−1 (M˜ + δi ∗)2 i=1 2βpi

E[Ψ0(xN ) − Ψ0(x∗)] ≤ 2rM + 12LDX2 ,V N (N + 1)
+ n∆DX p∗ . (35) r
From (35) it follows that if

+ δi, u − ui−1 , (24)

where

Φ(u) = h(u) + F (u) + βV (x, u),

(25)

δt = f˜r(ut−1) − ∇F (ut−1).

(26)

M˜ = c√nC1M,
c is some positive constant independent of n, C1 is from (2).

Using the lemma above we derive the main result.

Theorem 1. Assume that {pt}t≥1, {θt}t≥1, {βk}k≥1, {γk}k≥1 in Algorithm 1 satisfy (23) and

γ1 = 1, βk − Lγk ≥ 0, k ≥ 1,

(27)

γkβk ≤ γk−1βk−1 , Γk(1 − PTk ) Γk−1(1 − PTk−1 ) Then

k ≥ 2.

(28)

E[Ψ(xN ) − Ψ(x∗)]

ΓN β1

N Tk

≤ 1 − PT1 V (x0, u) + ΓN

k=1 i=1

(M˜ 2 + σ2)γkPTk βkΓk(1 − PTk )p2i Pi−1

+ n∆DX p∗ ·

γk PTk

, (29)

r

Γk(1 − PTk )piPi−1

where x∗ is an arbitrary optimal point for (17), Pt is from (23),

1, Γk =

k = 1, (30)

(1 − γk)Γk−1, k > 1

and

2 def 2

2 n2∆2

σ = 4p∗ CnM + r2 ,

(31)

where C is some positive constant independent of n.

The next corollary suggests the particular choice of parameters and states convergence guarantees in a more explicit way.

Corollary 1. Suppose that {pt}t≥1, {θt}t≥1 are

t

2(t + 1)

pt = 2 , θt = t(t + 3) , ∀t ≥ 1, (32)

N is given, {βk}, {γk}, Tk are

2L

2

N (M˜ 2 + σ2)k2

βk = k , γk = k + 1 , Tk =

D˜ L2

(33)

for D˜ = 3DX 2 ,V/4. Then ∀N ≥ 1

E[Ψ(xN ) − Ψ(x∗)] ≤ 12LDX2 ,V + n∆DX p∗ . (34)

N (N + 1)

r

Finally, we extend the result above to the initial problem (5).

ε

ε2

r=Θ

, ∆=O

(36)

M

nM DX min{p∗, 1}

√

and ε = O ( nM DX ), s = Ω (ε/MC3), then the number

of evaluations for ∇g and f˜r, respectively, required by

Algorithm 1 to ﬁnd an ε-solution of (5), i.e. such xN that E[Ψ0(xN )] − Ψ0(x∗) ≤ ε, can be bounded by





LDX2 ,V

O

,

(37)

ε

 O

 LDX2 ,V DX2 ,V nM 2(C12 + p2∗)
ε + ε2  .

(38)

Let us discuss the obtained result and especially bounds

(37) and (38). First of all, consider Euclidean proximal

setup, i.e.

·

=

·

2,

V

(x, y)

=

1 2

x−y

22, DX,V = DX .

In this case we have p∗ = C1 = C2 = C3 = 1 and bound

(38) for the number of (6) oracle calls reduces to

O LDX2 + DX2 nM 2

ε

ε2

and the number of ∇g(x) computations remains the same. It means that our result gives the same number of ﬁrstorder oracle calls as in the original Gradient Sliding algorithm, while the number of the biased stochastic zeroth-order oracle calls is n times larger in the leading term than in the analogous bound from the original ﬁrstorder method. In the Euclidean case our bounds reﬂect the classical dimension dependence for the derivative-free optimization (see Larson et al. (2019)).

Secondly, we consider the case when X is the probability simplex in Rn and the proximal setup is entropic (see the end of Section 2). As we mentioned earlier in Section 2 and
in the beg√inning of this section, in this situation we have DX,V = 2 ln√n, DX = 2, p∗ = O (ln(n)/n) and C1 = 1, C2 = C3 = n. Then number of ∇g(x) calculations is

bounded by O (L ln2 n)/ε . As for the number of f˜r(x)

computations, we get the following bound:





L ln2 n M 2 ln2 n O  ε + ε2  .

Clearly, in this case we have only polylogarithmical dependence on the dimension instead.

3.2 Strongly Convex Case

In this section we additionally assume that g is µ-strongly convex w.r.t. Bregman divergence V (x, y), i.e. ∀x, y ∈ X
g(x) ≥ g(y) + ∇g(y), x − y + µV (x, y).

Corollary 2. Under the assumptions of Corollary 1 we Similarly to the original work Lan (2016) we use restarts

have that the following inequality holds for all N ≥ 1:

technique in this case and get Algorithm 2.

Algorithm 2 The Multi-phase Zeroth-Order Sliding Algorithm (M-zoSA)
Input: Initial point y0 ∈ X and iteration limit N0, initial estimate ρ0 (s.t. Ψ(y0) − Ψ∗ ≤ ρ0) for i = 1, 2, . . . , I do
Run zoSA with x0 = yi−1, N = N0, {pt} and {θt} in (32), {βk} and {γk}, {Tk} in (33) with D˜ = ρ0/µ2i, and yi is output. end for Output: yI .

The following theorem states the main complexity results for M-zoSA.

Theorem 2. For M-zoSA with N0 = 2 5L/µ we have

E[Ψ(yi) − Ψ(y∗)] ≤ ρ0 + 2n∆DX p∗ .

(39)

2i

r

Using this we derive the complexity bounds for M-zoSA.

Corollary 3. For all N ≥ 1 the iterates of M-zoSA satisfy

E[Ψ0(yi) − Ψ0(y∗)] ≤ 2rM + ρ0 + 2n∆DX p∗ . (40)

2i

r

From (40) it follows that if

ε

ε2

r=Θ

, ∆=O

(41)

M

nM DX min{p∗, 1}

√ and ε = O ( nM DX ), s = Ω (ε/MC3), then the number

of evaluations for ∇g and f˜r, respectively, required by

Algorithm 2 to ﬁnd a ε-solution of (5) can be bounded

by

L

O µ log2 max [1, ρ0/ε] ,

(42)

L

nM 2(C12 + p2∗)

O µ log2 max [1, ρ0/ε] +

µε

. (43)

4. FROM COMPOSITE OPTIMIZATION TO CONVEX OPTIMIZATION WITH AFFINE CONSTRAINTS AND DECENTRALIZED
DISTRIBUTED OPTIMIZATION
In this section we apply the obtained results to the convex optimization problems with aﬃne constraints and after that to the decentralized distributed optimization problem.

4.1 Convex Optimization with Aﬃne Constraints

As an intermediate step between the composite optimization problem (5) and decentralized distributed optimization we consider the following problem

min f (x),
Ax=0,x∈X

(44)

where A 0 and KerA = {0} and X is convex compact in Rn with diameter DX . The dual problem for (44) can
be written in the following way

min ψ(y), where

(45)

y

ϕ(y) = max { y, x − f (x)} ,
x∈X

ψ(y) = ϕ(A y) = max { y, Ax − f (x)}
x∈Q

= y, Ax(A y) − f (x(A y))

= A y, x(A y) − f (x(A y)),

where x(y) d=ef argmaxx∈X { y, x − f (x)}. The solution of

(45) with the smallest 2-norm is denoted in this paper as

y∗. This norm Ry d=ef y∗ 2 can be bounded as follows Lan

et al. (2017):

2

∇f (x∗)

2 2

Ry ≤ λ+

(A

. A)

min

Following Gasnikov (2018); Dvinskikh and Gasnikov

(2019); Gorbunov et al. (2019) we consider the penalized

problem

Ry2

2

min F (x) = f (x) +

x∈X

ε

Ax 2,

(46)

where ε > 0 is some positive number. It turns out (see the

details in Gorbunov et al. (2019)) that if we have such xˆ

that F (xˆ) − minx∈X F (x) ≤ ε then we also have

f (xˆ) − min f (x) ≤ ε,
Ax=0,x∈X

2ε Axˆ 2 ≤ Ry .

We notice that this result can be generalized in the follow-

ing way: if we have such xˆ that E[F (xˆ)]−minx∈X F (x) ≤ ε

then we also have

E[f (xˆ)] − min f (x) ≤ ε,
Ax=0,x∈X

E[

Axˆ

2] ≤

2ε .

(47)

2 Ry

Next, we consider the problem (46) as (5) with g(x) = Ry2 Ax 22/ε. Assume that ∇f (x) 2 ≤ M for all x ∈ X and for f we have an access to the biased stochastic oracle
deﬁned in (6). We are interested in the situation when ∇g(x) = 2Ry2A Ax/ε can be computed exactly. Moreover, it is easy to see that g(x) is 2Ry2λmax(A A)/ε-smooth w.r.t. 2norm. Applying Corollary 2 we get that in order to produce
such a point xˆ that satisﬁes (47) Algorithm 1 applied to
solve (46) requires





λmax(A A)Ry2DX2

O

 calculations of A Ax

ε2

and





O

λmax(A A)Ry2DX2 nDX2 M 2

+



ε2

ε2

calculations of f˜(x) since p∗ = C2 = C1 = 1 for the Euclidean case. As we mentioned at the end of Section 3,
this bound depends on dimension n in the classical way.

4.2 Decentralized Distributed Optimization

Now, we go back to the problem (1) and, following Scaman

et al. (2017), we rewrite it in the distributed fashion:

1m

min f (x) =

fi(xi),

x1 =...=xm

m

x1 ,...,xm ∈X

i=1

(48)

where x = (x1 , . . . , xm) ∈ Rnm. Recall that we consider the situation when fi is stored on the i-th node. In

this case one can interpret xi from (48) as a local variable

of i-th node and x1 = . . . = xn as a consensus condition

for the network. The common trick Scaman et al. (2017,

2018, 2019); Uribe et al. (2020) to handle this condition

is to rewrite it using the notion of Laplacian matrix. In

general, the Laplacian matrix W =

W ij

m,m i,j=1,1

∈

Rm×m

of the graph G with vertices V , |V | = m and edges V is

deﬁned as follows:

−1, if (i, j) ∈ E, 

W ij = deg(i), if i = j,

0

otherwise,

where deg(i) is degree of i-th node. In this paper we
focus only on the connected networks. In this case W has unique eigenvector 1m d=ef (1, . . . , 1) ∈ Rm associated to the eigenvalue 0. Using this one can show that for all vectors a = (a1, . . . , am) ∈ Rm we have the following equivalence:

a1 = . . . = am ⇐⇒ W a = 0.

(49)

Using the Kronecker product W d=ef W ⊗ In, which is also called Laplacian matrix for simplicity, one can generalize
(49) for the n-dimensional case:

x1 = . . . = xm ⇐⇒ W x = 0

and

√

x1 = . . . = xm ⇐⇒ W x = 0.

That is, instead of the problem (48) one can consider the

equivalent problem

1m

√ min
W x=0,

f (x) = m

fi(xi).

x1 ,...,xm ∈X

i=1

(50)

Next, we need to deﬁne parameters of f using local param-
eters of fi. Assume that for each fi we have fi(xi) 2 ≤ M for all xi ∈ X, all fi are convex functions, the starting point is x0 = (x0 , . . . , x0 ) and x∗ = (x∗ , . . . , x∗ ) is the optimality point for (50). Then, one can show (see Gorbunov et al. (2019) for the details) that ∇f (x) 2 ≤ M/√m on the set of such x that x1, . . . , xm ∈ X, DX2 m = mDX2 and Ry2 d=ef y∗ 22 ≤ M2/mλ+ min(W ).

Now we are prepared to apply results obtained in Section 4.1 to the problem (50√). Indeed, this problem can be viewed as (50) with A = W . Taking this into account, we conclude that one A Ax calculation corresponds to the calculation of W x which can be computed during one communication round in the network with Laplacian matrix W . This simple observation implies that in order to pro√duce such a point xˆ that satisﬁes (47) with xˆ = xˆ, A := W , X := Xn, Ry := Ry Algorithm 1 applied to the penalized problem (46) requires

O χ(W )M 2DX2 communication rounds ε2

and

O χ(W )M 2DX2 + nDX2 M 2

ε2

ε2

calculations of f˜(x) per node since p∗ = 1 for the Euclidean case. The bound for the communication rounds matches the lower bound from Scaman et al. (2018, 2019) and we conjecture that under our assumptions the obtained bound

for zeroth-order oracle calculations per node is optimal up to polylogarithmic factors in the class of methods with optimal number of communication rounds (see also Dvinskikh and Gasnikov (2019); Gorbunov et al. (2019)).
5. DISCUSSION
To conclude, the proposed method — zoSA — is the ﬁrst, to the best of our knowledge, 1/2-order method for the convex composite optimization: it uses zeroth-order oracle for the non-smooth term and the ﬁrst-order oracle for the smooth one. It has solid theory and is competitive in practice even with some ﬁrst-order methods (see our numerical experiments in the appendix).
As for the future work, it would be interesting to study zeroth-order distributed methods for the smooth decentralized distributed optimization using the technique from Gorbunov et al. (2019). Another direction for future research is in developing the analysis of the proposed method for the case when X is unbounded and, in particular, when X = Rn via recurrences techniques from Gorbunov et al. (2018, 2019).
ACKNOWLEDGEMENTS
The research of A. Beznosikov, E. Gorbunov and A. Gasnikov was partially supported by RFBR, project number 19-31-51001. The research of E. Gorbunov was also partially supported by the Ministry of Science and Higher Education of the Russian Federation (Goszadaniye) 07500337-20-03 and the research of A. Gasnikov was also partially supported by Yahoo! Research Faculty Engagement Program.
REFERENCES
Alistarh, D., Grubic, D., Li, J., Tomioka, R., and Vojnovic, M. (2017). QSGD: Communication-eﬃcient SGD via gradient quantization and encoding. In Advances in Neural Information Processing Systems, 1709–1720.
Ben-Tal, A. and Nemirovski, A. (2015). Lectures on Modern Convex Optimization (Lecture Notes). Personal web-page of A. Nemirovski.
Bertsekas, D.P. and Tsitsiklis, J.N. (1989). Parallel and distributed computation: numerical methods, volume 23. Prentice hall Englewood Cliﬀs, NJ.
Chang, C.C. and Lin, C.J. (2011). Libsvm: A library for support vector machines. ACM transactions on intelligent systems and technology (TIST), 2(3), 1–27.
Cohen, M.B., Lee, Y.T., Miller, G., Pachocki, J., and Sidford, A. (2016). Geometric median in nearly linear time. In Proceedings of the forty-eighth annual ACM symposium on Theory of Computing, 9–21. ACM.
Duchi, J.C., Jordan, M.I., Wainwright, M.J., and Wibisono, A. (2015). Optimal rates for zero-order convex optimization: The power of two function evaluations. IEEE Transactions on Information Theory, 61(5), 2788–2806.
Dvinskikh, D., Gorbunov, E., Gasnikov, A., Dvurechensky, P., and Uribe, C.A. (2019). On primal and dual approaches for distributed stochastic convex optimization over networks. In 2019 IEEE 58th Conference on Decision and Control (CDC), 7435–7440.

Dvinskikh, D. and Gasnikov, A. (2019). Decentralized and parallelized primal and dual accelerated methods for stochastic convex programming problems. arXiv preprint arXiv:1904.09015.
Gasnikov, A. (2018). Universal gradient descent. MIPT. Gorbunov, E., Dvinskikh, D., and Gasnikov, A. (2019).
Optimal decentralized distributed algorithms for stochastic convex optimization. arXiv preprint arXiv:1911.07363. Gorbunov, E., Dvurechensky, P., and Gasnikov, A. (2018). An accelerated method for derivative-free smooth stochastic convex optimization. arXiv preprint arXiv:1802.09022. Karimireddy, S.P., Rebjock, Q., Stich, S.U., and Jaggi, M. (2019). Error feedback ﬁxes signsgd and other gradient compression schemes. arXiv preprint arXiv:1901.09847. Lan, G. (2016). Gradient sliding for composite optimization. Mathematical Programming, 159(1-2), 201–235. Lan, G. (2019). Lectures on Optimization Methods for Machine Learning. H. Milton Stewart School of Industrial and Systems Engineering Georgia Institute of Technology, Atlanta, GA. Lan, G., Lee, S., and Zhou, Y. (2017). Communicationeﬃcient algorithms for decentralized and stochastic optimization. Mathematical Programming, 1–48. Larson, J., Menickelly, M., and Wild, S.M. (2019). Derivative-free optimization methods. Acta Numerica, 28, 287–404. Minsker, S. et al. (2015). Geometric median and robust estimation in banach spaces. Bernoulli, 21(4), 2308– 2335. Nemirovsky, A.S. and Yudin, D.B. (1983). Problem complexity and method eﬃciency in optimization. Nesterov, Y. (2004). Introductory Lectures on Convex Optimization: a basic course. Kluwer Academic Publishers, Massachusetts. Nesterov, Y. and Spokoiny, V.G. (2017). Random gradient-free minimization of convex functions. Foundations of Computational Mathematics, 17(2), 527–566. Rao, A.V. (2009). A survey of numerical methods for optimal control. Advances in the Astronautical Sciences, 135(1), 497–528. Rogozin, A. and Gasnikov, A. (2019). Projected gradient method for decentralized optimization over time-varying networks. arXiv preprint arXiv:1911.08527. Scaman, K., Bach, F., Bubeck, S., Lee, Y.T., and Massouli´e, L. (2017). Optimal algorithms for smooth and strongly convex distributed optimization in networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, 3027–3036. JMLR. org. Scaman, K., Bach, F., Bubeck, S., Lee, Y.T., and Massouli´e, L. (2019). Optimal convergence rates for convex distributed optimization in networks. Journal of Machine Learning Research, 20(159), 1–31. Scaman, K., Bach, F., Bubeck, S., Massouli´e, L., and Lee, Y.T. (2018). Optimal algorithms for non-smooth distributed optimization in networks. In Advances in Neural Information Processing Systems, 2745–2754. Shalev-Shwartz, S. and Ben-David, S. (2014). Understanding machine learning: From theory to algorithms. Cambridge university press. Shamir, O. (2017). An optimal algorithm for bandit and zero-order convex optimization with two-point feedback.

Journal of Machine Learning Research, 18(52), 1–11.

Spokoiny, V. et al. (2012). Parametric estimation. ﬁnite

sample theory. The Annals of Statistics, 40(6), 2877–

2909.

Stich, S.U. (2018). Local sgd converges fast and commu-

nicates little. arXiv preprint arXiv:1805.09767.

Uribe, C.A., Lee, S., Gasnikov, A., and Nedi, A.

(2020). A dual approach for optimal algorithms

in distributed optimization over networks.

Optimization Methods and Software, 0(0), 1–

40.

doi:10.1080/10556788.2020.1750013.

URL

https://doi.org/10.1080/10556788.2020.1750013.

Wen, W., Xu, C., Yan, F., Wu, C., Wang, Y., Chen,

Y., and Li, H. (2017). Terngrad: Ternary gradients

to reduce communication in distributed deep learning.

In Advances in Neural Information Processing Systems,

1509–1519.

APPENDIX. DERIVATIVE-FREE METHOD FOR COMPOSITE OPTIMIZATION WITH APPLICATIONS TO DECENTRALIZED DISTRIBUTED OPTIMIZATION

6. NUMERICAL EXPERIMENTS

ff((xx0N)) ff((xx**))

ff((xx0N)) ff((xx**))

100

10 1

10 2
10 3 0 100
9.99 × 10 1

zoGD GD zoSA
2500 5000

75C0a0 ll1s00o0f0W12x500 15000 17500 20000

9.98 × 10 1

9.97 × 10 1

9.96 × 10 1

9.95 × 10 1 9.94 × 10 1 9.93 × 10 1
0

zoGD GD
2500 5000

75C0a0 ll1s00o0f0W12x500 15000 17500 20000

10 2

10 3

10 4

10 5
10 6
0

zoGD GD zoSA 2500 5000 75C0a0 ll1s00o0f0W12x500 15000 17500 20000

(a) star

||WxN||

ff((xx0N)) ff((xx**))

ff((xx0N)) ff((xx**))

100

10 1

10 2
10 3 0 100
9.99 × 10 1

zoGD GD zoSA
2500 5000

75C0a0 ll1s00o0f0W12x500 15000 17500 20000

9.98 × 10 1

9.97 × 10 1

9.96 × 10 1

9.95 × 10 1 9.94 × 10 1 9.93 × 10 1
0

zoGD GD
2500 5000

75C0a0 ll1s00o0f0W12x500 15000 17500 20000

10 3

10 4 10 5
0

zoGD GD zoSA 2500 5000 75C0a0 ll1s00o0f0W12x500 15000 17500 20000
(b) complete graph

||WxN||

ff((xx0N)) ff((xx**))

ff((xx0N)) ff((xx**))

100

10 1

10 2
10 3
0
100
9.95 × 10 1 9.9 × 10 1 9.85 × 10 1 9.8 × 10 1 9.75 × 10 1 9.7 × 10 1 9.65 × 10 1
0

zoGD GD zoSA 500 1000 15C0a0 lls20o00f W25x00 3000 3500 4000
zoGD GD 500 1000 15C0a0 lls20o00f W25x00 3000 3500 4000

10 2

10 3

10 4 10 5 0

zoGD GD zoSA 500 1000 15C0a0 lls20o00f W25x00 3000 3500 4000
(c) chain

||WxN||

ff((xx0N)) ff((xx**))

ff((xx0N)) ff((xx**))

100

10 1

10 2

10 3

zoGD

GD

10 4

zoSA

0
100

1000 2C0a00lls of W300x0 4000 5000

9.9 × 10 1

9.8 × 10 1

9.7 × 10 1 9.6 × 10 1
0
10 2 10 3 10 4 10 5
0

zoGD GD 1000 2C0a00lls of W300x0 4000 5000
zoGD GD zoSA 1000 2C0a00lls of W300x0 4000 5000
(d) cycle

||WxN||

Fig. 1. zoSA, GD and zoGD applied to solve (51) with R = 102 for diﬀerent network topologies. First two rows shows how the relative functional gap changes for the methods during their work and the last row shows the evolution of W xN .

100

100

100

100

ff((xx0N)) ff((xx**))

ff((xx0N)) ff((xx**))

10 1

10 2
10 3
0
100
9.995 × 10 1

zoGD GD zoSA 10000 2000C0 all3s00o0f0Wx40000

50000 60000
zoGD GD

9.99 × 10 1

9.985 × 10 1

9.98 × 10 1
0
10 2 10 3 10 4 10 5 10 6 10 7 10 8 0

10000 2000C0 all3s00o0f0Wx40000 50000 60000
zoGD GD zoSA 10000 2000C0 all3s00o0f0Wx40000 50000 60000
(a) star

||WxN||

ff((xx0N)) ff((xx**))

ff((xx0N)) ff((xx**))

10 1

10 2
10 3
0
100
9.995 × 10 1

zoGD GD zoSA 10000 2000C0 all3s00o0f0Wx40000

50000 60000
zoGD GD

9.99 × 10 1

9.985 × 10 1

9.98 × 10 1
0

10000 2000C0 all3s00o0f0Wx40000 50000 60000

10 4

10 5 10 6
0

zoGD GD zoSA 10000 2000C0 all3s00o0f0Wx40000 50000 60000
(b) complete graph

||WxN||

ff((xx0N)) ff((xx**))

ff((xx0N)) ff((xx**))

10 1

10 2
10 3
0
100
9.98 × 10 1 9.96 × 10 1 9.94 × 10 1 9.92 × 10 1 9.9 × 10 1 9.88 × 10 1 9.86 × 10 1
0

zoGD GD zoSA
2000 4000

6C0a00lls 8o0f00Wx10000 12000 14000

zoGD GD
2000 4000

6C0a00lls 8o0f00Wx10000 12000 14000

10 3

10 4 10 5
0

zoGD GD zoSA 2000 4000 6C0a00lls 8o0f00Wx10000 12000 14000
(c) chain

||WxN||

ff((xx0N)) ff((xx**))

ff((xx0N)) ff((xx**))

10 1

10 2
10 3
0
100
9.98 × 10 1 9.96 × 10 1 9.94 × 10 1 9.92 × 10 1 9.9 × 10 1 9.88 × 10 1 9.86 × 10 1
0

zoGD GD zoSA
2000 4000

6C0a00lls 8o0f00Wx10000 12000 14000

zoGD GD
2000 4000

6C0a00lls 8o0f00Wx10000 12000 14000

10 3

10 4 10 5 10 6 0

zoGD GD zoSA 2000 4000 6C0a00lls 8o0f00Wx10000 12000 14000
(d) cycle

||WxN||

Fig. 2. zoSA, GD and zoGD applied to solve (51) with R = 103 for diﬀerent network topologies. First two rows shows how the relative functional gap changes for the methods during their work and the last row shows the evolution of W xN .

In our numerical experiments we use a machine with 4 cores, each is Intel(R) Core(TM) i7-9750H CPU @ 2.60 GHz. We implemented zoSA, mirror descent Nemirovsky and Yudin (1983) and zeroth-order version of mirror descent Duchi et al. (2015) for Euclidean setup, i.e. gradient descent (GD) and its zeroth-order version (zoGD). As we mentioned before, to the best of our knowledge, zoSA is the ﬁrst method for problems of the type (5) that uses ﬁrst-order oracle for the

smooth component g and zeroth-order oracle for the non-smooth component f . Therefore, we compare zoSA with GD and zoGD that are the state-of-the-art ﬁrst and zeroth-order methods respectively for convex non-smooth optimization problems.

6.1 Distributed Computation of Geometric Median

We consider the problem of searching geometric median Minsker et al. (2015); Cohen et al. (2016) of m vectors

b1, . . . , bm ∈ Rn:

1m

min f (x) =

x∈Rn

m

i=1

x − bi 2.

Following Section 4 we consider the following problem:

1m

min F (x) =

x∈Rnm

m

i=1

fi (xi )

√

xi − bi 2 + R

Wx

2 2

.

g(x)

(51)

f (x)

A√s it was mentioned before, if R = Ry2/ε, then F (x) − minx∈Rnm F (x) ≤ ε implies f (x) − min√W x=0 f (x) ≤ ε and √W x 2 ≤ 2ε/Ry. However, in practice one can use diﬀerent choices of R if it oﬀers to get faster such a point x that
W x 2 is small enough. In particular, we tried diﬀerent R, but the best result that we obtained are for R = 102 and R = 103.

In our experiments we emulate the work of the decentralized distributed system with given Laplacian matrix W on one machine in order to demonstrate the performance of zoSA on the decentralized distributed optimization problems. That is, we store x as a long vector and count number of W x computations since it corresponds to the number of communication rounds in the distributed system. In many real distributed networks communication is a bottleneck, therefore, the number of communication rounds measures, to some degree, the running time of the method.

We run zoSA, GD and zoGD on problem (51) with n = 10 and m = 100 for several standard topologies like star, cycle, chain, i.e. path, and complete graph. We construct vectors b1, . . . , bm as i.i.d. samples from normal distributed N (1, 2In) with the mean 1 = (1, . . . , 1) and the covariance matrix 2In and use the origin of Rnm as a starting point. One can ﬁnd the results of our numerical experiments on Figures 1 and 2. We notice that in these tests zoSA outperforms even GD which is a ﬁrst-order method.

6.2 Logistic Regression with Lasso Regularization

Next, we consider the logistic regression problem with lasso regularization for binary classiﬁcation:

f (x)

min Ψ0(x) = l1 x 1 +g(x)

(52)

x∈Rn

1m

g(x) = m

log (1 + exp (−yi · (Ax)i)) .

i=1

Here A ∈ Rm×n is a matrix of objects, y1, . . . , ym ∈ {−1, 1} are labels for these objects, m is the size of the dataset and x ∈ Rn is a vector of weights. We run zoSA, GD and zoGD on this problem for mushrooms dataset (m = 8124, n = 112) with l1 = 10−3, a5a dataset (m = 6414, n = 123) with l1 = 10−4 and german.numer dataset (m = 1000, n = 24) with l1 = 10−4 Chang and Lin (2011), see Figure 3. For the ﬁrst case zoSA shows the performance that is better than

0(xN) 0(x* ) 0(x0) 0(x* ) 0(xN) 0(x* ) 0(x0) 0(x* ) 0(xN) 0(x* ) 0(x0) 0(x* )

100

zoGD

GD

10 1

zoSA

10 2

10 3

10 4 0 5 10 15 20 25 30 35 40 Time, s
(a) mushrooms, l1 = 10−3

100
10 1 10 2 10 3
10 4 0

zoGD GD zoSA
5 10 T1im5 e, s20 25 30 (b) a5a, l1 = 10−4

100

zoGD

GD

10 1

zoSA

10 2

10 3 0 2 4 6 8 10 12 14 Time, s
(c) german.numer, l1 = 10−4

Fig. 3. zoSA, GD and zoGD applied to solve (52) for diﬀerent datasets and regularization parameters l1.

zoGD’s performance and worse than GD’s one which is reasonable for the method which uses a mixed oracle. However,

our method outperforms even GD on the second and the third datasets. There is no contradiction here: zoSA is based on Sliding Algorithm which has better complexity guarantees than GD and zoSA has the same complexity as Sliding Algorithm in terms calculations of ∇g(x).

6.3 Minimization of Nesterov’s Function with Lasso Regularization

In this section we consider the following problem:

f (x)

min Ψ0(x) = l1 x 1 +g(x)

(53)

x∈Rn

L g(x) =
8

n−1
x21 + (xi − xi+1)2 + x2n
i=1

− Lx1 . 4

Here g(x) is a convex and L-smooth function, which is one of the “worst” functions for the ﬁrst-order methods in the
class of convex and L-smooth functions Nesterov (2004), and f (x) has bounded gradients. We run zoSA, GD and zoGD on this problem with L = 4 and l1 = 10−3 for a given time. The results are presented in Figure 4. Naturally, zoSA

100

zoGD

10 1

GD zoSA

10 2

0(xN) 0(x* ) 0(x0) 0(x* )

10 3

10 4 0 10 20 Tim3e0, s 40 50 60

Fig. 4. zoSA, GD and zoGD applied to solve (53) with l1 = 10−3 and L = 4.
outperforms zoGD since zoSA uses ﬁrst-order oracle for the smooth part while zoGD uses only zeroth-order information about g(x). At the same time, our method is inferior to zoGD and it is, to some degree, also expected: ﬁrst-order oracle for f (x) gives more information about descent direction than zoSA obtains via zeroth-order oracle.

7. BASIC FACTS

Simple upper bound for a squared sum. For arbitrary integer n ≥ 1 and arbitrary set of positive numbers a1, . . . , an

we have

m

2

m

ai ≤ m a2i

(54)

i=1

i=1

H¨older inequality. For arbitrary x, y ∈ Rn the following inequality holds

x, y ≤ x ∗ · y

(55)

Cauchy-Schwarz inequality for random variables. Let ξ and η be real valued random variables such that E[ξ2] < ∞ and E[η2] < ∞. Then

E[ξη] ≤ E[ξ2]E[η2].

(56)

8. AUXILIARY RESULTS

Lemma 4. (Lemma 9 from Shamir (2017)). For any function g which is L-Lipschitz with respect to the

that if e is uniformly distributed on the Euclidean unit sphere, then

L2 [(g(e) − Eg(e))4] ≤ c

E

n

for some numerical constant c.

2-norm, it holds

Lemma 5. (Lemma 3.5 from Lan (2019)). Let the convex function p : X → R, the points x˜, y˜ ∈ X and scalars µ1, µ2 ≥ 0 be given. Let ν : X → R be a diﬀerentiable convex function and V (x, z):

V (x, z) = ν(z) − [ν(x) + ∇ν(x) (z − x)].

If then for any u ∈ X, we have

u˜ = argmin{p(u) + µ1V (x˜, u) + µ2V (y˜, u)}
u∈X

p(u˜) + µ1V (x˜, u˜) + µ2V (y˜, u˜) ≤ p(u) + µ1V (x˜, u) + µ2V (y˜, u) − (µ1 + µ2)V (u˜, u).

Lemma 6. (Lemma 3.17 from Lan (2019)). Let wk ∈ (0; 1], k = 1, 2, . . . be given. Also let us denote

1, Wk =

k = 1,

(1 − wk)Wk−1, k > 1.

Suppose that Wk > 0 for all k > 1 and that the sequence {δk}k≥0 satisﬁes δk ≤ (1 − wk)δk−1 + Bk, k = 1, 2, . . .

for some positive constants {Bk}k≥0. Then, we have

k Bi δk ≤ Wk(1 − w1)δ0 + Wk Wi .
i=1

9. MISSING PROOFS FROM SECTION 3.1

9.1 One Technical Lemma

Lemma 7. Assume that for the diﬀerentiable function f deﬁned on a closed and convex set X there exists such M that

∇f (x) 2 ≤ M ∀x ∈ X.

(57)

Then,

f (x) ≤ f (y) + ∇f (y), x − y + 2M C1 x − y , ∀x, y ∈ X.

Proof of Lemma 7. For arbitrary points x, y ∈ X we have

1
f (x) = f (y) + ∇f (y + τ (x − y)), x − y dτ
0 1
= f (y) + ∇f (y), x − y + ∇f (y + τ (x − y)) − ∇f (y), x − y dτ
0 1
(55)
≤ f (y) + ∇f (y), x − y + ∇f (y + τ (x − y)) − ∇f (y) ∗ · x − y dτ
0 1
(2),(57)
≤ f (y) + ∇f (y), x − y + 2M C1 x − y dτ
0
≤ f (y) + ∇f (y), x − y + 2M C1 x − y .

9.2 Proof of Lemma 1

First of all, Lemma 8 from Shamir (2017) implies that F (x) is convex, diﬀerentiable and inequality (15) holds. Next, we use the deﬁnition of F (x) and mean value theorem and get that for all x ∈ X

(57)
|F (x) − f (x)| = |E [f (x + re)] − f (x)| ≤ E [|f (x + re) − f (x)|] ≤ E [ ∇f (z(x, x + re)) 2 · re 2] ≤ rM, where z(x, x + re) is a convex combination of x and x + re.
Finally, using the symmetry of the distribution of e and (15) we get

∇F (x) 2 =

E

n f (x + re)e

2

∗

r

∗

n

n

2

= E 2r f (x + re)e + E 2r f (x − re) · (−e) ∗

n

2

= E 2r (f (x + re) − f (x − re)) e ∗

n2

2

≤ 4r2 E (f (x + re) − f (x − re)) e ∗

n2

22

= 4r2 E (f (x + re) − f (x − re)) e ∗

n2

22

= 4r2 E ((f (x + re) − α) − (f (x − re) − α)) e ∗ .

Next, we apply (54) and obtain

n2

22

n2

2

2

2

4r2 E ((f (x + re) − α) − (f (x − re) − α)) e ∗ ≤ 2r2 E (f (x + re) − α) + (f (x − re) − α) e ∗

n2

22

22

≤ 2r2 E (f (x + re) − α) e ∗ + E (f (x − re) − α) e ∗ .

Since the distribution of e is symmetric

n2

22

22

2r2 E (f (x + re) − α) e ∗ + E (f (x − re) − α) e ∗

n2

22

= r2 E (f (x + re) − α) e ∗

(56) n2 ≤ r2

E [ e 4∗]

E (f (x + re) − α)4 .

Taking α = E[f (x + re)] and using Lemma 4 together with the fact that f (x + re) is M r-Lipschitz w.r.t. e in terms of the · 2-norm (since ∇f (x) 2 ≤ M ) we get

n2p2∗ r2

4 n2p2∗ (M r)2

22

E (f (x + re) − α) ≤ r2 c n = cnp∗M ,

where c is some positive constant. That is, we proved that

√ which implies (16) with c˜ = c.

∇F (x)

2 ∗

≤ cnp2∗M 2,

9.3 Proof of Lemma 2

We prove this inequalities in the similar way as it was done in Lemma 10 (see Shamir (2017)). Let us start with (18):

E[f˜ (x)] = n E[(f˜(x + re) − f˜(x − re))e]

r

2r

n

= 2r (E[f (x + re, ξ)e] − E[f (x − re, ξ)e] + E[∆(x + re)e] − E[∆(x − re)e])

Taking into account the independence of e, ξ and (8) we have E[f (x + re, ξ)e] = Ee [Eξ[f (x + re, ξ)e]] = Ee [f (x + re)]]. Then,

E[f˜ (x)] − ∇F (x) ∗ =

n (Ee [f (x + re)e] − Ee [f (x − re)e] + E[∆(x + re)e] − E[∆(x − re)e]) − ∇F (x)

r

2r

∗

(15) n = 2r Ee[∆(x + re)e] − Ee[∆(x − re)e] ∗

(56) n

≤ r

Ee [|∆(x + re)|2] · Ee [ e 2∗]

(58)

Applying boundedness of ∆(x) and (12) to (58), we get (18).

Next, we prove the second part of the lemma:

E[ f˜r(x) 2∗] = E

n

2
f˜(x + re) − f˜(x − re) e

2r

∗

(54)
≤
(54)
≤
(7),(56)
≤
(12)
≤

n2 2r2 E
n2 2r2 E
n2 r2 Ee
n2 r2 E

2

2

n2

2

2

e ∗ (f (x + re, ξ) − f (x − re, ξ)) + 2r2 E e ∗ (∆(x + re) − ∆(x − re))

2

2 n2

22

2

e ∗ ((f (x + re, ξ) − α) − (f (x − re, ξ) − α)) + r2 E e ∗ ∆ (x + re) + ∆ (x − re)

e

2 ∗

(f (x + re, ξ) − α)2 + (f (x − re, ξ) − α)2

2n2∆2 + r2

E [ e 4∗]

2

2

2

2

2n2p2∗∆2

e ∗ (f (x + re, ξ) − α) + E e ∗ (f (x − re, ξ) − α) + r2 .

(59)

Since the distribution of e is symmetric we can rewrite the r.h.s. of (59) in the following way:

n2 r2 E

e

2 ∗

(f

(x

+

re,

ξ

)

−

α)2

+E

e

2 ∗

(f

(x

−

re,

ξ

)

−

α)2

+ 2n2p2∗∆2 r2

2n2 = r2 E

e

2 ∗

(f

(x

+

re,

ξ

)

−

α)2

Taking into account the independence of e and ξ we derive

+ 2n2p2∗∆2 . r2

2n2 r2 E

2

2 2n2p2∗∆2 2n2

e ∗ (f (x + re, ξ) − α) + r2 = r2 Eξ Ee

Next, using Cauchy-Schwarz inequality and (12) we obtain

e

2 ∗

(f

(x

+

re,

ξ

)

−

α)2

+ 2n2p2∗∆2 . r2

2n2 r2 Eξ Ee

e

2 ∗

(f

(x

+

re,

ξ

)

−

α)2

2n2p2∗∆2 (56) 2n2 + r2 ≤ r2 Eξ

Ee [ e 4∗] Ee (f (x + re, ξ) − α)4

+ 2n2p2∗∆2 r2

2n2p2∗ ≤ r2 Eξ

Ee (f (x + re, ξ) − α)4

+ 2n2p2∗∆2 . r2

In particular, taking α = Ee[f (x + re, ξ)] and using Lemma 4 with the fact that f (x + re, ξ) is rM (ξ)-Lipschitz w.r.t. e in terms of the · 2-norm we get

2n2p2∗ r2 Eξ

Ee (f (x + re, ξ) − α)4

where c is some positive constant.

2n2p2∗∆2 2n2p2∗

r2M 2(ξ) 2n2p2∗∆2 (9) 2

2 n2∆2

+ r2 ≤ r2 Eξ c n

+ r2 = 2p∗ cnM + r2 ,

9.4 Proof of Lemma 3
The proof of this lemma completely repeats the proof of Proposition 8.3 of Lan (2019). However, we put it here for consistency. Consider the following functions:
lF (ut−1, u) = F (ut−1) + ∇Fr(ut−1), u − ut−1 , ˜lF (ut−1, u) = F (ut−1) + f˜r(ut−1), u − ut−1 . These deﬁnitions imply that ˜lF (ut−1, u) − lF (ut−1, u√) = δt, u − ut−1 where δt is deﬁned in (26). Lemmas 7 and 1 imply F (ut) ≤ lF (ut−1, ut) + M˜ ut − ut−1 , where M˜ = c nC1M . Adding h(ut) + βV (x, ut) to this inequality and applying (25) we obtain
Φ(ut) ≤ h(ut) + lF (ut−1, ut) + βV (x, ut) + M˜ ut − ut−1 . From ˜lF (ut−1, u) − lF (ut−1, u) = δt, u − ut−1 we have
Φ(ut) ≤ h(ut) + lF (ut−1, ut) + βV (x, ut) + M˜ ut − ut−1 = h(ut) + ˜lF (ut−1, ut) − δt, ut − ut−1 + βV (x, ut) + M˜ ut − ut−1
(55)
≤ h(ut) + ˜lF (ut−1, ut) + βV (x, ut) + (M˜ + δt ∗) ut − ut−1 .
Applying Lemma 5 to (20), we obtain that for all u ∈ X

h(ut) + ˜lF (ut−1, ut) + βV (x, ut) + βptV (ut−1, ut) ≤ h(u) + ˜lF (ut−1, u) + βV (x, u) + βptV (ut−1, u) − β(1 + pt)V (ut, u) = h(u) + lF (ut−1, u) + δt, u − ut−1 + βV (x, u) +βptV (ut−1, u) − β(1 + pt)V (ut, u) ≤ Φ(u) + βptV (ut−1, u) − β(1 + pt)V (ut, u) + δt, u − ut−1 ,
where the last inequality follows from the convexity of F (see Lemma 1) and (25). Moreover, the strong convexity of V implies that

−βptV (ut−1, ut) + (M˜ +

δt ∗) ut − ut−1

≤ − βpt ut − ut−1 2

2
M˜ + δt ∗

≤

,

2βpt

2 + (M˜ +

δt ∗) ut − ut−1

where the last inequality follows from the simple fact that −at2/2 + bt ≤ b2/(2a) for any a > 0.

Combining previous three inequalities, we conclude that

Φ(ut) − Φ(u) ≤ βptV (ut−1, u) − β(1 + pt)V (ut, u) +

2
M˜ + δt ∗

2βpt

+ δt, u − ut−1 .

Now dividing both sides of the above inequality by 1 + pt and rearranging the terms, we obtain

βV (ut, u) + Φ(ut) − Φ(u) ≤ βpt V (ut−1, u) +

1 + pt

1 + pt

2
M˜ + δt ∗ +
2β(1 + pt)pt

δt, u − ut−1 , 1 + pt

which, in view of Lemma 6, implies that



2



β

t Φ(ui) − Φ(u)

t M˜ + δi ∗

δi, u − ui−1

V (ut, u) +

≤ βV (u0, u) + 

+

.

(60)

Pt

Pi(1 + pi)

 2βPi(1 + pi)pi Pi(1 + pi) 

i=1

i=1

By deﬁnition of u˜t (see (21)) and (23) we have

u˜t = Pt 1 − Pt
u˜t = Pt 1 − Pt

1 − Pt−1 u˜t−1 +

1 ut ,

Pt−1

Pt(1 + pt)

1 − Pt−2 u˜t−2 +

1

1

ut−1 +

ut

Pt−2

Pt−1(1 + pt−1)

Pt(1 + pt)

Pt t

1

= ... = 1 − Pt

Pi(1 + pi) ui.

i=1

(61)

Combining (60) and (61) we get the result.

9.5 Proof of Theorem 1

The proof of this theorem is almost identical to the proof of Theorem 8.2 from Lan (2019) and via performing similar steps one can get the following inequality which is an analogue of inequality (8.1.69) from Lan (2019). For convenience, we put below the full proof.
Using (24), deﬁnition of Φk and (xk, x˜k) we have that for all u ∈ X

βk(1 − PTk )−1V (xk, u) + [Φk(x˜k) − Φk(u)] ≤ βkPTk (1 − PTk )−1V (xk−1, u)

PT

Tk (M˜ +2βδkp,i ∗)2 + δk,i, u − uk,i−1

+

k

ki

1 − PTk i=1

piPi−1

(62)

First, notice that by the deﬁnition of xk and xk, we have xk − xk = γk(x˜k − xk−1). Using this observation, L-smoothness of g (see (3)), the deﬁnition of lg in (22) and the convexity of g, we obtain

g(xk) ≤ lg(xk, xk) + L2 xk − xk 2 = (1 − γk)lg(xk, xk−1) + γklg(xk, x˜k) + L2γk2 x˜k − xk−1 2 ≤ (1 − γk)g(xk−1) + γk [lg(xk, x˜k) + βkV (xk−1, x˜k)] −γkβkV (xk−1, x˜k) + L2γk2 x˜k − xk−1 2 ≤ (1 − γk)g(xk−1) + γk [lg(xk, x˜k) + βkV (xk−1, x˜k)] − γkβk − Lγk2 V (xk−1, x˜k)
≤ (1 − γk)g(xk−1) + γk [lg(xk, x˜k) + βkV (xk−1, x˜k)] , where the third inequality follows from the strong convexity of V and the last inequality follows from (30). By the convexity of F , we have
F (xk) ≤ (1 − γk)F (xk−1) + γkF (x˜k).
Summing up previous two inequalities, and using the deﬁnitions of Ψ and Φk(x˜k) d=ef F (x˜k) + lg(xk, x˜k) + βkV (xk−1, x˜k), we have
Ψ(xk) ≤ (1 − γk)Ψ(xk−1) + γkΦk(x˜k). Subtracting Ψ(u) from both sides of the above inequality, we obtain
Ψ(xk) − Ψ(u) ≤ (1 − γk)[Ψ(xk−1) − Ψ(u)] + γk[Φk(x˜k) − Ψ(u)]. Also note that by the deﬁnition of Φk and the convexity of g,
Φk(u) ≤ F (u) + g(u) + βkV (xk−1, u) = Ψ(u) + βkV (xk−1, u), ∀u ∈ X. Combining these two inequalities, we obtain for all u ∈ X

Ψ(xk) − Ψ(u) ≤ (1 − γk)[Ψ(xk−1) − Ψ(u)] + γk[Φk(x˜k) − Φk(u) + βkV (xk−1, u)].

(63)

Using (62) and (63), we get for all u ∈ X

Ψ(xk) − Ψ(u) ≤ (1 − γk)[Ψ(xk−1) − Ψ(u)] + γk

βk [V (xk−1, u) − V (xk, u)] 1 − PTk



2



PT Tk 1

M˜ + δk,i ∗

 

+

k

1 − PTk

 piPi−1 

2βk pi

+ δk,i, u − uk,i−1  .  

i=1



(64)

Using the above inequality and Lemma 6, we conclude that for all u ∈ X

Ψ(xN ) − Ψ(u) ≤ ΓN (1 − γ1)[Ψ(x0) − Ψ(u)]

N

βk γk

+ΓN Γk(1 − PTk ) [V (xk−1, u) − V (xk, u)]

k=1



2



N γkPT

Tk 1

M˜ + δk,i ∗

+ΓN

k
Γk(1 − PTk )

 piPi−1 

2ν βk pi

+ δk,i, u − uk,i−1  . 

k=1

i=1

(65)

From (28) it follows that for all u ∈ X

N

βk γk

β1γ1

βN γN

Γk(1 − PTk ) [V (xk−1, u) − V (xk, u)] ≤ Γ1(1 − PT1 ) V (x0, u) − ΓN (1 − PTN ) V (xN , u)

k=1

≤ β1 V (x0, u), (66) 1 − PT1

where the last inequality follows from the facts that γ1 = Γ1 = 1, PTN ≤ 1, and V (xN , u) ≥ 0. Inequality (66) and the fact that γ1 = 1 together with inequality (65) imply that for all u ∈ X

Ψ(xN ) − Ψ(u) ≤ βk V (x0, u) 1 − PT1

N
+ΓN

γk PTk

Tk 1

(M˜ 2 + δk,i 2∗) + δk,i, u − uk,i−1 .

k=1 Γk(1 − PTk ) i=1 piPi−1

βk pi

(67)

Next, we show that

E[||δk,i||2∗] ≤ σ2

(68)

for σ2 deﬁned in (31). For all x ∈ X we have

E[

δ

2∗]

=

E[

f˜r(x) − ∇F (x)

2∗] ≤ 2E

f˜r (x)

2 ∗

+

2E

∇F (x)

2 ∗

(19)
≤ 4p2∗

cnM 2 + n2∆2 r2

+2

∇F (x)

2 ∗

(1=6) 4p2∗

cnM 2 + n2∆2 r2

+ 2c˜2np2∗M 2

2

2 n2∆2

= 4p∗ CnM + r2 ,

where C d=ef c + c˜2/2. For the inner product we have the following bound:

(6) n

n

(7),(12) ∆nDX p∗

E[ δk,i, u − uk,i−1 ] = E[ ∆k,iek,i, u − uk,i−1 ] ≤ E[|∆k,i| · ek,i ∗ · u − uk,i−1 ] ≤

.

2r

2r

r

(69)

Taking mathematical expectation from the both sides of (67) and using (68) and (69) we obtain (29).

9.6 Proof of Corollary 1

Using recurrences (23) and (32) we obtain 2
Pt = (t + 1)(t + 2) , (70)

1 PTk ≤ PTk−1 ≤ . . . ≤ PT1 ≤ 3

(71)

and from relations (30) and (33) we derive that

2 Γk = k(k + 1) , (72)

which implies (27).

From (33), (70), (71) we derive (28). Simple calculations and relations (32), (70) imply

Tk

1

Tk i + 1

i=1 p2i Pi−1 = 2 i=1 i ≤ 4Tk,

(73)

Tk 1

1 Tk

1

= piPi−1 2

i = 4 Tk(Tk + 1).

i=1

i=1

(74)

Next, one can see from (33), (72), (73), (74) that

Tk γkPTk ≤ 4γkPTk Tk = 4k2 , Γ β (1 − P ) L(T + 3)
i=1 Γkβk(1 − PTk )p2i Pi−1 k k Tk k

(75)

Tk γkPTk ≤ γkPTk Tk(Tk + 1) = (Tk + 1)k .

i=1 Γk(1 − PTk )piPi−1

4Γk(1 − PTk )

2(Tk + 3)

(76)

Finally, inequalities (29), (71), (72), (75), (76) imply

E[Ψ(x ) − Ψ(x∗)] ≤ 2L [3V (x , x∗) + 4D˜ ] + 2n∆DX p∗ N (Tk + 1)k

N

N (N + 1)

0

rN (N + 1) (Tk + 3)

k=1

≤ N (N2L+ 1) [3V (x0, x∗) + 4D˜ ] + r2Nn∆(ND+X p1∗) N k
k=1

= 2L [3V (x0, x∗) + 4D˜ ] + n∆DX p∗ .

(77)

N (N + 1)

r

9.7 Proof of Corollary 2

The proof of (35) follows directly from (34) and (14). Using (35) and (36) we get (37). Finally,

N

(33) N

Tk ≤

i=1

i=1

4N (M˜ 2 + σ2)k2 3D2 L2 + 1
X,V

2 N 2(N + 1)(2N + 1)(M˜ 2 + σ2)

= 18

D2 L2

+N

X,V

2 (N + 1)4(M˜ 2 + σ2)

≤ 9

D2 L2

+N

(78)

X,V

and

2

2

2 n2∆2

σ = O p∗ CnM + r2

= O p2∗nM 2 ,

(79)

M˜ 2 = O nC12M 2 ,

(80)

√ where we used ε = O ( nM DX ). From (37) we know that N = O

/ LDX 2 ,V ε . Together with (78), (79), (80) it gives

(38).

10. MISSING PROOFS FROM SECTION 3.2

10.1 Proof of Theorem 2

We prove this result by induction. From (77) we have

E[Ψ(yi) − Ψ(y∗) | yi−1] ≤ 2L

3V (yi−1, y∗) + 4D˜ + n∆DX p∗ .

N0(N0 + 1)

r

Here we use that yi−1 is x0 and yi is output for M-zoSA after i-th iteration. Since Ψ is a sum of convex and µ-strongly convex function we have that Ψ is µ-strongly convex and

E[Ψ(yi) − Ψ(y∗) | yi−1] ≤ 2L N0(N0 + 1)

3 (Ψ(yi−1) − Ψ(y∗)) + 4D˜ µ

+ n∆DX p∗ . r

Taking the full expectation from the both sides of previous inequality, using the induction hypothesis and the deﬁnition of D˜ , we conclude that

E[Ψ(yi) − Ψ(y∗)] ≤ 2L 5ρ0 + 2L 6n∆DX + n∆DX ≤ ρ0 + 2n∆DX p∗ ,

N02 µ2i−1 N02 µr

r

2i

r

where the last inequality follows from the deﬁnition of N0.

10.2 Proof of Corollary 3

Combining inequalities (14) and (39) we get (40). Next, if r and ∆ satisfy (41), then 2rM + 2n∆DXp∗ = O(ε). Taking the total number of phases, i.e. restarts, I = log2 max [1, ρ0/ε] we get ρ2I0 = O(ε) and, as ar consequence, E [Ψ0(yi) − Ψ0(y∗)] = O(ε). Therefore, the total number of ∇g computations, which equals N0I, is bounded by (42).
Now let us derive a bound on the total number of f˜r computations. Without loss of generality, let us assume that ρ0 > ε. Using the previous bound on I and the deﬁnition of Tk, we get

I N0

I N0

Tk ≤

i=1 k=1

i=1 k=1

µN0(M˜ 2 + σ2)k2 2i + 1 ρ0L2

I
≤
i=1

µN0(M˜ 2 + σ2)

3i

3ρ0L2 (N0 + 1) 2 + N0

µN0(N0 + 1)3(M˜ 2 + σ2) I+1

≤

3ρ0L2

2 + N0I

4µ(N0 + 1)4(M˜ 2 + σ2)

≤

3εL2

+ N0I.

This inequality, the deﬁnition of N0 and inequalities (79) and (80) give the bound (43) for the total number of f˜r

computations.

