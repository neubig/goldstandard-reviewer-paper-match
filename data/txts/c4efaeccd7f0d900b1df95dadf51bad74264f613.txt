Strategic aspects of the probabilistic serial rule for the allocation of goods
HARIS AZIZ and SERGE GASPERS and NICK MATTEI and TOBY WALSH, NICTA and
University of New South Wales, Australia
and NINA NARODYTSKA, University of Toronto, Canada

arXiv:1401.6523v1 [cs.GT] 25 Jan 2014

The probabilistic serial (PS) rule is one of the most prominent randomized rules for the assignment problem. It is well-known for its superior fairness and welfare properties. However, PS is not immune to manipulative behaviour by the agents. We examine computational and non-computational aspects of strategising under the PS rule. Firstly, we study the computational complexity of an agent manipulating the PS rule. We present polynomial-time algorithms for optimal manipulation. Secondly, we show that expected utility best responses can cycle. Thirdly, we examine the existence and computation of Nash equilibrium proﬁles under the PS rule. We show that a pure Nash equilibrium is guaranteed to exist under the PS rule. For two agents, we identify two diﬀerent types of preference proﬁles that are not only in Nash equilibrium but can also be computed in linear time. Finally, we conduct experiments to check the frequency of manipulability of the PS rule under diﬀerent combinations of the number of agents, objects, and utility functions.
Categories and Subject Descriptors: F.2.2 [Analysis of Algorithms and Problem Complexity]: Nonnumerical Algorithms and Problems—Computations on discrete structures; I.2.11 [Artiﬁcial Intelligence]: Distributed Artiﬁcial Intelligence—Multiagent Systems; J.4 [Computer Applications]: Social and Behavioral Sciences—Economics
General Terms: Algorithms, Economics, Theory
Additional Key Words and Phrases: fair division, strategyproofness, random assignment, probabilistic serial rule, Nash dynamics, best responses.

1. INTRODUCTION
The assignment problem is one of the most fundamental and important problems in economics and computer science [see e.g., Bogomolnaia and Moulin 2001; Ga¨ rdenfors 1973; Hylland and Zeckhauser 1979; Aziz et al. 2013b; Saban and Sethuraman 2013a]. Agents express preferences over objects and, based on these preferences, the objects are allocated to the agents. A randomized or fractional assignment rule takes the preferences of the agents into account in order to allocate each agent a fraction of the object. If the objects are indivisible, the fraction can also be interpreted as the probability of receiving the object. Randomization is widespread in resource allocation since it is one of the most natural ways to ensure procedural fairness [Budish et al. 2013]. Randomized assignments have been used to assign public land, radio spectra to broadcasting companies, and US permanent visas to applicants [Footnote 1 in Budish et al. 2013].
Typical criteria for randomized assignment being desirable are fairness and welfare. The probabilistic serial (PS) rule is an ordinal randomized/fractional assignment rule that fares better on both counts than any other random assignment rule [Bogomolnaia and Heo 2012; Bogomolnaia and Moulin 2001; Budish et al. 2013; Katta and Sethuraman 2006; Kojima 2009; Yilmaz 2010; Saban and Sethuraman 2013b]. In particular, it satisﬁes strong envy-freeness and efﬁciency with respect to both stochastic dominance (SD) and downward lexicographic (DL) relations [Bogomolnaia and Moulin 2001; Schulman and Vazirani 2012; Kojima 2009]. SD is one of the most fundamental relations between fractional allocations because one allocation is SD-preferred over another iff for any utility representation consistent with the ordinal preferences, the

Emails: haris.aziz@nicta.com.au, sergeg@cse.unsw.edu.au, ninan@cs.toronto.edu, toby.walsh@nicta.com.au

Nicholas.Mattei@nicta.com.au,

Technical Report: January 2014.

2

H. Aziz et al.

former yields at least as much expected utility as the latter. DL is a reﬁnement of SD and based on lexicographic comparisons between fractional allocations. Generalizations of the PS rule have been recommended in many settings [see e.g., Budish et al. 2013]. The PS rule also satisﬁes some desirable incentive properties. If the number of objects is not more than the number of agents, then PS is weak strategyproof with respect to stochastic dominance [Bogomolnaia and Moulin 2001]. However, PS is not immune from manipulation.1
PS works as follows. Each agent expresses linear orders over the set of houses (we use the term house throughout the paper though we stress any object could be allocated with these mechanisms). Each house is considered to have a divisible probability weight of one, and agents simultaneously and with the same speed consume the probability weight of their most preferred house. Once a house has been consumed, the agent proceeds to eat the next most preferred house that has not been completely consumed. The procedure terminates after all the houses have been consumed. The random allocation of an agent by PS is the amount of each object he has eaten.2
We examine the following natural questions for the ﬁrst time: what is the computational complexity of an agent computing a different preference to report so as to get a better PS outcome? How often is a preference proﬁle manipulable under the PS rule?. 3 The complexity of manipulation of the PS rule has bearing on another issue that has recently been studied—preference proﬁles that are in Nash equilibrium. Ekici and Kesten [2012] showed that when agents are not truthful, the outcome of PS may not satisfy desirable properties related to efﬁciency and envy-freeness. Because the PS rule is manipulable it is important to understand how hard, computationally, it is for an agent to compute a beneﬁcial misreporting as this may make it difﬁcult in practice to exploit the mechanism. It is also interesting to identify preference proﬁles for which no agent has an incentive to unilaterally deviate to gain utility with respect to his actual preferences. Hence, we consider the following problem: for a preference proﬁle, does a (pure) Nash equilibrium exist or not and if it exists how efﬁciently can it be computed?
In order to compare random allocations, an agent needs to consider relations between random allocation. We consider three well-known relations between lotteries [see e.g., Bogomolnaia and Moulin 2001; Schulman and Vazirani 2012; Saban and Sethuraman 2013b; Cho 2012]: (i) expected utility (EU), (ii) stochastic dominance (SD), and (iii) downward lexicographic (DL). For EU, an agent seeks a different allocation that yields more expected utility. For SD, an agent seeks a different allocation that yields more expected utility for all cardinal utilities consistent with the ordinal preferences. For DL, an agent seeks an allocation that gives a higher probability to the most preferred alternative that has different probabilities in the two allocations. Throughout the paper, we assume that agents express strict preferences, i.e., they are not indifferent between any two houses.
Contributions. We initiate the study of computing best responses and checking for Nash equilibrium for the PS mechanism — one of the most established randomized rules for the assignment problem. We present a polynomial-time algorithm to compute

1Another well-established rule random serial dictator (RSD) is strategyproof but it is not envy-free and not as efﬁcient as PS [Bogomolnaia and Moulin 2001]. Moreover, in contrast to PS, the fractional allocations under RSD are #P-complete to compute [Aziz et al. 2013a]. 2Although PS was originally deﬁned for the setting where the number of houses is equal to the number of agents, it can be used without any modiﬁcation for fewer or more houses than agents [see e.g., Bogomolnaia and Moulin 2001; Kojima 2009]. 3This problem of computing the optimal manipulation has already been studied in great depth for voting rules [see e.g., Faliszewski and Procaccia 2010; Faliszewski et al. 2010].

Technical Report: January 2014.

Strategic aspects of the probabilistic serial rule

3

the DL best response for multiple agents and houses. The algorithm works by carefully simulating the PS rule for a sequence of partial preference lists. For the case of two agents4, we present a polynomial-time algorithm to compute an EU best response for any utilities consistent with the ordinal preferences. The result for the EU best response relies on an interesting connection between the PS rule and the sequential allocation rule for discrete objects. We leave open the problem of computing the expected utility response for arbitrary number of agents. The fact that a similar problem has also remained open for sequential allocation [Bouveret and Lang 2011] gives some indication of the challenge of the problem.
We then examine situations in which all agents are strategic. We ﬁrst show that expected utility best responses can cycle. Nash dynamics in matching theory has been active area of research especially for the stable matching problem [see e.g., Ackermann et al. 2011]. We then prove that a (pure) Nash equilibrium exists for any number of agents and houses. To the best of our knowledge, this is the ﬁrst proof of the existence of a Nash equilibrium for the PS rule. For the case of two agents we present two different linear-time algorithms to compute a preference proﬁle that is in Nash equilibrium with respect to the original preferences. One type of equilibrium proﬁle results in the same assignment as the one by original proﬁle.
Finally, we perform an experimental study of the frequency of manipulability of the PS mechanism. We investigate, under a variety of utility functions and preference distributions, the likelihood that some agent in a proﬁle has an incentive to misreport his preference. The experiments identify settings and utility models in which PS is less susceptible to manipulation.

2. PRELIMINARIES
An assignment problem (N, H, ) consists of a set of agents N = {1, . . . , n}, a set of houses H = {h1, . . . , hm} and a preference proﬁle = ( 1, . . . , n) in which i denotes a complete, transitive and strict ordering on H representing the preferences of agent i over the houses in H. Since each i will be strict throughout the paper, we will also refer to it simply as i.
A fractional assignment is a (n × m) matrix [p(i)(j)] such that for all i ∈ N , and hj ∈ H, 0 ≤ p(i)(j) ≤ 1; and for all j ∈ {1, . . . , n}, i∈N p(i)(j) = 1 The value p(i)(j) is the fraction of house hj that agent i gets. Each row p(i) = (p(i)(1), . . . , p(i)(m)) represents the allocation of agent i. A fractional assignment can also be interpreted as a random assignment where p(i)(j) is the probability of agent i getting house hj. We will also denote p(i)(j) by p(i)(hj).

Relations between random allocations. A standard method to compare lotter-

ies is to use the SD (stochastic dominance) relation. Given two random as-

signments p and q, p(i)

SD i

q(i) i.e., a player i SD prefers allocation p(i)

to q(i) if hj∈{hk:hk ih} p(i)(hj ) ≥ hj∈{hk:hk ih} q(i)(hj ) for all h ∈ H and

hj∈{hk:hk ih} p(i)(hj ) > hj∈{hk:hk ih} q(i)(hj ) for some h ∈ H.

Given two random assignments p and q, p(i)

DL i

q(i)

i.e.,

a

player

i

DL

prefers

allocation p(i) to q(i) if p(i) = q(i) and for the most preferred house h such that p(i)(h) =

q(i)(h), we have that p(i)(h) > q(i)(h).

When agents are considered to have cardinal utilities for the objects, we denote by

ui(h) the utility that agent i gets from house h. We will assume that total utility of an

agent equals the sum of the utilities that he gets from each of the houses. Given two

4The two-agent case is also of special importance since various disputes arise between two parties. Technical Report: January 2014.

4

H. Aziz et al.

random assignments p and q, p(i)

EU i

q(i)

i.e.,

a

player

i

EU

(expected

utility)

prefers

allocation p(i) to q(i) iff h∈H ui(h)p(i)(h) > h∈H ui(h)q(i)(h). Since for all i ∈ N , agent i compares assignment p with assignment q only with

respect to his allocations p(i) and q(i), we will sometimes abuse the notation and use

p

SD i

q

for

p(i)

SD i

q(i).

A

random

assignment

rule

takes

as

input

an

assignment

problem (N, H, ) and returns a random assignment which speciﬁes how much fraction

or probability of each house is allocated to each agent.

3. THE PROBABILISTIC SERIAL RULE AND ITS MANIPULATION
Recall that the Probabilistic Serial (PS) rule is a random assignment algorithm in which we consider each house as inﬁnitely divisible. At each point in time, each agent is consuming his most preferred house that has not completely been consumed and each agent has the same unit speed. Hence all the houses are consumed at time m/n and each agent receives a total of m/n unit of houses. The probability of house hj being allocated to i is the fraction of house hj that i has eaten. The PS fractional assignment can be computed in time O(mn). We refer the reader to [Bogomolnaia and Moulin 2001] or [Kojima 2009] for alternative deﬁnitions of PS. The following example adapted from [Section 7, Bogomolnaia and Moulin 2001] shows how PS works.

Example 3.1 (PS rule). Consider an assignment problem with the following preference proﬁle.

1: h1, h2, h3

2: h2, h1, h3

3: h2, h3, h1

Agents 2 and 3 start eating h2 simultaneously whereas agent 1 eats h1. When 2 and 3 ﬁnish h2, agent 3 has only eaten half of h1. The timing of the eating can be seen below.

Agent 1 Agent 2 Agent 3
0

h1

h1

h3

h2

h1

h3

h2

h3

h3

1 2

3 4

1

Time

3/4 0 1/4
The ﬁnal allocation computed by PS is P S( 1, 2, 3) = 1/4 1/2 1/4 . 0 1/2 1/2

Consider the assignment problem in Example 3.1. If agent 1 misreports his pref-

1/3 1/2 1/6

erences as follows: 1:

h2, h1, h3, then P S( 1, 2, 3) = 1/3 1/2 1/6 . Then, if 1/3 0 2/3

u1(h1) = 7, u1(h2) = 6, and u1(h3) = 0, then agent 1 gets more expected utility when

he reports 1. In the example, although truth-telling is a DL best response, it is not necessarily an EU best response for agent 1.

Examples 1 and 2 of [Kojima 2009] show that manipulating the PS mechanism can

lead to an SD improvement when each agent can be allocated more than one house.

In light of the fact that the PS rule can be manipulated, we examine the complex-

ity of a single agent computing a manipulation, in other words, the best response for the PS rule.5 We then study the existence and computation of Nash equilibria. For

E ∈ {SD, EU, DL}, we deﬁne the problem EBESTRESPONSE: given (N, H, ) and agent

5Note that if an agent is risk-averse and does not have information about the other agent’s preferences, then his maximin strategy is to be truthful. The reason is that if all all agents have the same preferences, then the optimal strategy is to be truthful.

Technical Report: January 2014.

Strategic aspects of the probabilistic serial rule

5

i ∈ N , compute a preference i for agent i such that there exists no preference i

such that P S(N, H, ( i , −i))

E i

P S(N, H, (

i,

−i)). For a constant m, the problem

EBESTRESPONSE can can be solved by brute force by trying out each of the m! prefer-

ences. Hence we won’t assume that m is a constant.

We establish some more notation and terminology for the rest of the paper. We will

often refer to the PS outcomes for partial lists of houses and preferences. We will de-

note by P S( Li , −i)(i), the allocation that agent i receives when his preferences are restricted to the list L where L is an ordered list of a subset of houses. When an agent

runs out of houses in his preference list, he does not eat any other houses. The length

of a list L is denoted |L|, and we refer to the kth house in L as L(k). In the PS rule,

the eating start time of a house is the time point at which the house starts to be eaten

by some agent. In Example 3.1, the eating start times of h1, h2 and h3 are 0, 0 and 0.5,

respectively.

4. LEXICOGRAPHIC BEST RESPONSE
In this section, we present a polynomial-time algorithm for DLBESTRESPONSE. Lexicographic preferences are well-established in the assignment literature [see e.g., Saban and Sethuraman 2013b; Schulman and Vazirani 2012; Cho 2012]. Let (N, H, ) be an assignment problem where N = {1, . . . , n} and H = {h1, . . . , hm}. We will show how to compute a DL best response for agent 1 ∈ N . It has been shown that when m ≤ n, then truth-telling is the DL best response but if m > n, then this need not be the case [Saban and Sethuraman 2013b; Schulman and Vazirani 2012; Kojima 2009].
Recall that a preference 1 is a DL best response for agent 1 if the fractional allocation agent 1 receives by reporting 1 is DL preferred to any fractional allocation agent 1 receives by reporting another preference. That is, there is no preference 1 such that his share of a house h when reporting 1 is strictly larger than when reporting
1 while the share of all houses he prefers to h (according to his true preference 1) is the same whether reporting 1 or 1 .
Our algorithm will iteratively construct a partial preference list for the i most preferred houses of agent 1. Without loss of generality, denote 1: h1, h2, . . . , hm.
For any i, 1 ≤ i ≤ m, denote Hi = {h1, . . . , hi}. A (partial) preference of agent 1 restricted to Hi is a preference over a subset of Hi. Note that a preference for Hi need not list all the houses in Hi. For the preference of agent 1 restricted to Hi, the PS rule computes an allocation where the preference of agent 1 is replaced with this preference and the preferences of all other agents remain unchanged. Recall that agent 1 can only be allocated a non-zero fraction of a house if this house is in the preference list he submits. The notions of DL best response and DL preferred fractional assignments with respect to a subset of houses Hi are deﬁned accordingly for restricted preferences of agent 1.
For a house h ∈ H, let P S1(L, h) denote the fraction of house h that the PS rule assigns to agent 1 when he reports the (partial) preference L.
We start with a simple lemma showing that a DL best response for agent 1 for the whole set H can be no better and no worse on Hi than a DL best response for Hi.
LEMMA 4.1. Let i ∈ {1, . . . , m}. A DL best response for agent 1 on H gives the same fractional assignment to the houses in Hi as a DL best response for agent 1 on Hi.
PROOF. We have that a preference for agent 1 on Hi can be extended to a preference for all houses that gives the same fractional allocation to agent 1 for the houses in Hi. Namely, the remaining houses H \ Hi can be appended to the end of his preference list, giving the same allocation to the houses in Hi as before.

Technical Report: January 2014.

6

H. Aziz et al.

On the other hand, consider a DL best response 1 for agent 1 on H, giving a fractional allocation p to agent 1. Restricting this preference to Hi gives a fractional allocation q for Hi. If q is DL preferred to p|Hi , i.e., the fractional allocation p restricted to Hi, then q = p|Hi , otherwise we would have a contradiction to 1 being a DL best response as per the previous argument that we can extend any preference for Hi to H giving the same fractional allocation to agent 1 for the houses in Hi.
Our algorithm will compute a list Li such that Li ⊆ Hi.6 The list Li will be a DL best response for agent 1 with respect to Hi. Suppose the algorithm has computed Li−1. Then, when considering Hi = Hi−1 ∪{hi}, it needs to make sure that the new fractional allocation restricted to the houses in Hi−1 remains the same (due to Lemma 4.1). For the preference to be optimal with respect to Hi, the algorithm needs to maximize the fractional allocation of hi to agent 1 under the previous constraint.
Our algorithm will compute a canonical DL best response that has several additional
properties.

Deﬁnition 4.2. A preference Li for Hi is no-0 if Li contains no house h with P S1(Li, h) = 0.

Any DL best response for agent 1 for Hi can be converted into a no-0 DL best response by removing the houses for which agent 1 obtains a fraction of 0.

Deﬁnition 4.3. For a no-0 preference Li for Hi, the stingy ordering for a position j is

determined by running the PS rule with the preference Li(1) ⊕ · · · ⊕ Li(j − 1) for agent

1 where ⊕ denotes concatenation. It orders the houses from

|Li | k=j

Li(k)

by

increasing

eating start times, and when 2 houses h, h have the same eating start time, we order

h before h iff h 1 h .

Intuitively, houses occurring early in this ordering are the most threatened by the other agents at the time point when agent 1 comes to position j. The following deﬁnition takes into account that the eating start times of later houses may change depending on agent 1’s ordering of earlier houses.

Deﬁnition 4.4. A preference Li for Hi is stingy if it is a no-0 DL best response for agent 1 on Hi, and for every j ∈ {1, . . . , i}, Li(j) is the ﬁrst house in the stingy ordering for this position such that there exists a DL best response starting with Li(1) ⊕ · · · ⊕ Li(j).

We note that, due to Lemma 4.1, there is a unique stingy preference for each Hi.

Example 4.5. Consider the following assignment problem.

1: h1, h2, h3, h4, h5, h6

2: h3, h6, h4, h5, h1, h2

The preferences h3, h1, h4, h2 and h3, h2, h4, h1 are both no-0 DL best responses for agent 1 with respect to H4, allocating h1(1), h2(1), h3(1/2), h4(1/2) to agent 1. When running the PS rule with h3 as the preference list, h4’s eating start time comes ﬁrst among {h1, h2, h4}. However, there is no DL best response for H4 starting with h3, h4. The next house in the stingy ordering is h1. The preference h3, h1, h4, h2 is the stingy preference for H4.

The next lemma shows that when agent 1 receives a house partially (a fraction different from 0 and 1) in a DL best response, a stingy preference would not order a less preferred house before that house.

6When we treat a list as a set we refer to the set of all elements occurring in the list.

Technical Report: January 2014.

Strategic aspects of the probabilistic serial rule

7

LEMMA 4.6. Let Li be a stingy preference for Hi. Suppose there is a hj ∈ Hi such that 0 < P S1(Li, hj) < 1. Then, P ⊆ Hj, where Li = P ⊕ hj ⊕ S.
PROOF. For the sake of contradiction, assume P contains a house hk such that hj 1 hk (i.e., j < k). Let K denote all houses hk in P such that hj 1 hk. Since Li is no-0, P S1(Li, hk) > 0 for all hk ∈ K. But then, removing the houses in K from Li gives a preference that is strictly DL preferred to Li since this increases agent 1’s share of hj while only the shares of less preferred houses decrease. This contradicts Li being a DL best response for Hi, and therefore proves the lemma.
The next lemma shows how the houses allocated completely to agent 1 are ordered in a stingy preference.
LEMMA 4.7. Let Li be a stingy preference for Hi. If hj, hk ∈ Hi are two houses such that P S1(Li, hj) = P S1(Li, hk) = 1, with Li = P ⊕ hj ⊕ M ⊕ hk ⊕ S, then either the eating start time of hj is smaller than hk’s eating start time when agent 1 reports P , or it is the same and hj 1 hk.
PROOF. Suppose not. But then, Li is not stingy since swapping hj and hk in Li gives the same fractional allocation to agent 1.
We now show that when iterating from a set of houses Hi−1 to Hi, the previous solution can be reused up to the last house that agent 1 receives partially.
LEMMA 4.8. Let Li−1 and Li be stingy preferences for Hi−1 and Hi, respectively. Suppose there is a h ∈ Hi−1 such that 0 < P S1(Li−1, h) < 1. Then the preﬁxes of Li−1 and Li coincide up to h.
PROOF. Suppose not. By Lemma 4.1, P S1(Li, h) = P S1(Li−1, h). Let Pi−1 = Pi denote a maximum common preﬁx of Li−1 and Li, and write Li−1 = Pi−1 ⊕ xi−1 ⊕ Mi−1 ⊕ h ⊕ Si−1 and Li = Pi ⊕ xi ⊕ Mi ⊕ h ⊕ Si. By Lemma 4.6, h 1 hi, and therefore, hi ∈ Si. Since Li−1 and Li are no-0, we have that P S1(Li−1, xi−1) > 0 and P S1(Li, xi) > 0. Now, if P S1(Li−1, xi−1) < 1, then since at least one other agent eats xi−1 concurrently with agent 1 when he reports Li−1, he loses a non-zero fraction of xi−1 when instead he reports Li and eats xi after having exhausted Pi, we have that P S1(Li, xi−1) < P S1(Li−1, xi−1), a contradiction to Lemma 4.1. Similarly, we obtain a contradiction when P S1(Li, xi) < 1. Therefore, P S1(Li−1, xi−1) = P S1(Li, xi) = 1. Now, by Lemma 4.1, we also have that P S1(Li−1, xi−1) = P S1(Li, xi) = 1. But only one of xi, xi−1 can come earlier in the stingy ordering. The other one contradicts Lemma 4.7.
We are now ready to describe how to obtain Li from Li−1. See Algorithm 1 for the pseudocode. The subroutine EST(N, H, ) executes the PS rule for (N, H, ) and for each item, records the ﬁrst time point where some agent starts eating it. It returns the eating start times est(h) for each house h ∈ H.
Let p be the last position in Li−1 such that the house Li−1(p) is partially allocated to agent 1. In case agent 1 receives no house partially, set p := 0 and interpret Li−1(p) as an imaginary house before the ﬁrst house of Li−1. By Lemma 4.8, we have that Li−1(s) = Li(s) for all s ≤ p. By Lemma 4.1, we have that the fractional assignment resulting from Li must wholly allocate all houses Li−1(p + 1), . . . , Li−1(|Li−1|) to agent 1, and allocate a share of 0 to all houses in Hi−1 \ Li−1.
It remains to ﬁnd the right ordering for {Li−1(s) : p + 1 ≤ s ≤ |Li−1|} ∪ {hi}. By Lemmas 4.6 and 4.7, the preﬁxes of Li−1 and Li coincide up to h. We will describe in the next paragraph how to determine the position q where hi should be inserted. Having determined this position one may then need to re-order the subsequent houses. This is because inserting hi in the list may change the eating start times of the subsequent

Technical Report: January 2014.

8

H. Aziz et al.

Input: (N, H, ) Output: DL Best response of agent 1

1 L1 ← h1

// Best response for agent 1 w.r.t. H1 = {h1}

2 for i = 2 to n do

// Compute a best response w.r.t. H2, . . . , Hn

3 p←0

4 if ∃q ∈ {1, . . . , i − 1} such that 0 < P S1(Li−1, Li−1(q)) < 1 then

5

p ← max{q ∈ {1, . . . , i − 1} : 0 < P S1(Li−1, Li−1(q)) < 1}

6 end if

7 for q ← p + 1 to |Li| + 1 do

// New house hi inserted after position p

8

Lqi ← Li−1(1) ⊕ · · · ⊕ Li−1(q − 1) ⊕ hi

9

while |Lqi | ≤ |Li−1| do

// Complete the list according to the stingy ordering

10

est ← EST(N, H, (Lqi , 2, . . . , n))

11

S ← {h ∈ Li−1 \ Lqi : est(h) is minimum}

12

hs ← ﬁrst house among S in 1

13

Lqi ← Lqi ⊕ hs

14

end while

15

if P S1(Lqi , hi) = 0 then

16

Lqi ← Li−1

17

end if

18 end for 19 q ← p 20 worse[p − 1] ← true

// Determine which Lqi is stingy

21 ﬁnished ← false

22 while ﬁnished = false do

23

if ∃h ∈ Hi−1 such that P S1(Lqi , h) = P S1(Li−1, h) then

24

worse[q] ← true

25

q ← q+1

26

else

27

worse[q] ← false

28

if P S1(Lqi , h1) > 0 and P S1(Lqi , h1) < 1 then

29

if worse[q − 1] = false then

30

q ← q−1

31

end if

32

ﬁnished ← true

33

else if P S1(Lqi , h1) = 1 then

34

est ← EST(N, H, (Lqi (1) ⊕ · · · ⊕ Lqi (q − 1), 2, . . . , n))

35

if ∃h ∈ {Lqi (q + 1), . . . , Lqi (|Lqi |)} such that est(h) ≤ est(hi) then

36

q ← q+1

37

else

38

ﬁnished = true

39

end if

40

end if

41

end if

42 end while 43 Li ← Lqi 44 end for

45 return Ln

Algorithm 1: DL best response for n agents

houses. This leads us to the following insertion procedure. The list Lqi obtained from Li−1 by inserting hi at position q, with p < q ≤ |Li| + 1, is determined as follows. Start with Lqi := Li−1(1) ⊕ · · · ⊕ Li−1(q − 1) ⊕ hi. While |Lqi | ≤ |Li−1|, we append to the end of Lqi the ﬁrst house among Li−1 \ Lqi in the stingy ordering for this position. After the while-loop terminates, run the PS rule for the resulting list Lqi . In case we obtain that P S1(Lqi , hi) = 0, we remove hi again from this list (and actually obtain Lqi = Li−1).
The position q where hi is inserted is determined as follows. Start with q := p. We have an array worse keeping track of whether the lists Lpi , . . . , Lii produce a worse outcome for agent 1 than the list Li−1. Set worse[p − 1] := true. As long as the list Li has

Technical Report: January 2014.

Strategic aspects of the probabilistic serial rule

9

not been determined, proceed as follows. Obtain Lqi from Li−1 by inserting hi at position q, as described earlier. Consider the allocation of agent 1 when he reports Lqi . If this allocation is not the same for the houses in Hi−1 as when reporting Li−1, then set worse[q] := true, otherwise set worse[q] := false. If worse[q], then increment q. This
is because, by Lemma 4.1, this preference would not be a DL best response with respect to Hi. Otherwise, if 0 < P S1(Lqi , hi) < 1, then we can determine hi’s position. If worse[q − 1], then set Li := Lqi , otherwise set Li := Liq−1. This position for hi is optimal since moving hi later in the list would decrease its share to agent 1. Otherwise, we have that worse[q] = false and P S1(Lqi , hi) ∈ {0, 1}. This will be the share agent 1 receives of hi. If P S1(Lqi , hi) = 0, then set Li := Li−1. Otherwise (P S1(Lqi , hi) = 1), it still remains to check whether the current position for hi gives a stingy preference. For this, run the PS rule with the preference Lqi (1) ⊕ · · · ⊕ Lqi (q − 1) for agent 1. If hi’s eating start time is smaller than the eating start time of each house Lqi (r) with r > q, then set Li := Lqi , otherwise increment q.
Thus, given Li−1, the preference Li can be computed by executing the PS rule O(m) times. The DL best response computed by the algorithm is Lm. Since the PS rule can be implemented to run in linear time O(nm), the running time of this DL best response algorithm is O(nm3).

THEOREM 4.9. DLBESTRESPONSE can be solved in O(nm3) time.

Example 4.10. Consider the following instance.

1: h1, h2, h3, h4, h5, h6, h7, h8, h9, h10 2: h8, h3, h5, h2, h10, h1, h6, h7, h4, h9 3: h9, h4, h7, h1, h2, h6, h5, h3, h8, h10

After having computed L2 = h1, h2, the algorithm is now to consider H3. Since P S1(L2, h1) = P S1(L2, h2) = 1, the algorithm ﬁrst considers L13 = h3, h2, h1. Note

that h1 and h2 have been swapped with respect to L2 since agent 2 starts eating h2

before agent 3 starts eating h1 when agent 1 reports the preference list consisting

of

only

h3.

It

turns

out

that

P S1(L13, h1)

=

P S1(L13, h2)

=

P

S

1(L

1 3

,

h3

)

=

1.

Thus,

worse[1] = false. Since h3 does not come ﬁrst in the stingy ordering, the algorithm

needs to verify whether moving h3 later will still give a DL best response with respect to H3. It then considers L23 = h1, h3, h2. However, this allocates only half of h3 to agent 1, implying worse[2] = true. Since worse[1] = false, the algorithm sets L3 = L13. The DL

best response computed by the algorithm is L10 = h3, h2, h1, h6.

Agent 1 h1 Agent 2 h5 Agent 3 h1 Agent 4 h1

h2 h2 h4 h4 h3 h3 h5 h6 h6 h7 h7 h4 h8 h8 h9 h9 h10 h10 h11 h11 h12 h12 h13 h13

0

1 3

1: h1, h2, h3, h4, . . . 3: h1, h8, h9, h10, h3, . . .

1

4 3

2

7 3

9 10 33

2: h5, h6, h7, h2, h4, h14 . . . 4: h1, h11, h12, h13, . . .

Fig. 1: Illustration of constructing a DL best response for agent 1 for the preference proﬁle speciﬁed above.

Technical Report: January 2014.

10

H. Aziz et al.

Example 4.11. Figure 1 depicts how the DL best response of agent 1 looks like. After h1 is inserted, the starting eating time h3 is before h4. But after h2 is inserted in to form L2, then the starting eating time of h4 comes before h3 because agent 2 won’t be able to eat h2. After h4 is inserted to build L4, it turns out that agent 2 will not be able to eat h4 at all. That is why h2 is shaded in the eating line of agent 2 because it will already be eaten by the time agent 2 considers eating it at time 10/3.
The DL optimal best response algorithm carefully builds up the DL optimal preferences list while ensuring it is stingy.
We note that a DL best response is also an SD best response. A best response was deﬁned as a response that is not dominated. Hence a DL-best response is one which no other response DL-dominates. This means that no other response SD-dominates (as DL is a reﬁnement of SD) it. Hence, a DL best response is also a SD best response. One may wonder whether an algorithm to compute the DL best response also provides us with an algorithm to compute an EU best response. However, a DL best response may not be an EU best response for three or more agents. Consider the preference proﬁle in Example 3.1. Since the number of houses is equal to the number of agents, reporting the truthful preference is a DL best response [Schulman and Vazirani 2012]. However, we have shown a different preference for agent 1 where he may obtain higher utility.

5. EXPECTED UTILITY BEST RESPONSE
In this section we present an algorithm to compute an EU best response for two agents for the PS rule. First, we reveal a tight connection between a well-known mechanism for sequential allocation of indivisible houses and the PS mechanism (Section 5.1). Then we demonstrate how the expected utility best response algorithm for the sequential allocation of indivisible houses proposed by Kohler and Chandrasekaran [1971] can be used to build a best response for the PS algorithm (Section 5.2).

5.1. A connection between allocation mechanisms for divisible and indivisible houses

We can obtain the same allocation given by the PS algorithm using the alternation

policy, which is a simple mechanism for dividing discrete houses between agents. The

alternating policy lets the agents take turns in picking the house that they value most:

the ﬁrst agent takes his most preferred house, then the second agent takes his most

preferred house from the remaining houses, and so on. We use the notation 1212 . . . to

denote the alternation policy. To obtain the allocation of the PS algorithm using the

alternation policy we split our houses into halves and treat them as indivisible houses

and adjust agents’ preferences over these halves in a natural way.

Recall that H = {h1, . . . , hm} is the set of houses. Assume 2: h1, . . . , hm and the

preference of agent 1 is a permutation of h1, . . . , hm as follows 1: hπ(1), . . . , hπ(m). We

denote i(k) the kth preferred house of the agent i, and by position of hi in 1.

−1 1

(hi

)

we

mean

the

We split each house hi, i = 1, . . . , m, into halves and treat these halves as indivisible houses. Given hi, we say that h1i and h2i are two halves of hi. Given the set of houses H, we denote H CLONED the set of all halves of all houses in H, so that

H CLONED

=

{h11

,

h21

,

.

.

.

,

h

1 m

,

h2m

}.

Given

1 and

2, we introduce proﬁles

CLONED
1

and

CLONED
2

that

are

obtained

by

straightforward

splitting

of

houses

into

halves

in

1 and

2:

= CLONED
1

h1π(1), h2π(1), . . . , h1π(m), h2π(m)

and

= CLONED
2

h11,

h21,

.

.

.

,

h1m,

h2m.

We

call

this

transformation the order-preserving bisection.

Deﬁnition 5.1. Let s be a preference over a subset of half-houses S ⊆ H CLONED. The preference s has the consecutivity property if and only if −s 1(h1i ) + 1 = −s 1(h2i )

Technical Report: January 2014.

Strategic aspects of the probabilistic serial rule

11

for all pairs h1i , h2i ∈ S. In other words, all half-houses of the same house are ranked consecutively in s.

The preference s= h11, h12, h22, h13, h23 has the consecutivity property over the set S =

{h11, h12, h22, h13, h23}, while s= h11, h12, h13, h22, h23 does not since h12 h13 h22. We observe

that

CLONED
1

and

CLONED
2

that

are

obtained

from

1 and

2 using the order-preserving

bisection, respectively, have the consecutivity property.

Next, we deﬁne the order-preserving join operation. It is the reverse operation for

the order-preserving bisection. Given a preference

CLONED
s

of

the

order-preserving

join operation merges all halve houses that are ordered consecutively into a single

house and leaves the other houses unchanged. Applying the order-preserving join to

= CLONED
s

h11,

h21,

h12,

h13,

h23,

h22.

gives

s= h1, h12, h3, h22.

Next, we show the main result of this section. The outcome of the alternation policy

over

CLONED
1

and

CLONED
2

is

identical

to

the

outcome

of

PS

over

1 and

2, where

CLONED
1

and

CLONED
2

are

obtained

by

the

order-preserving

bisection

from

1 and

2. In

the alternation policy 12, . . . , 12 we call a pair of consecutive steps 12 a round.

LEMMA 5.2. The allocation obtained by the PS algorithm over the preferences 1

and 2 of length m is the same as the allocation obtained by the alternation policy of

length 2m over the preferences

CLONED
1

and

. CLONED
2

PROOF. The proof is by induction on the number of steps of the PS rule. A step
in the PS rule starts when agent 1 starts eating a house and ﬁnishes when agent 1
ﬁnishes eating that house. For the base case, at time point 0, both the PS algorithm
and the alternation policy have not allocated a house to any agent.
Suppose the statement holds for i − 1 steps of the PS rule, where i ≥ 1. If both agents
have the same most preferred house hk among the remaining houses, then each of them gets half of this house in the PS rule. Consider the next round of the alternation policy: agent 1 gets a half of hk, h1k and agent 2 gets the other half of hk, h2k. Hence, the allocation is the same.
If the most preferred houses of the two agents are different, say the most preferred
house among the remaining houses of agent 1 is hj, and the most preferred of agent 2 is hk, then agent 1 completely receives house hj and agent 2 completely receives house hk in step i of the PS rule. In the alternation policy, agent 1 gets h1j , h2j and agent 2 gets h1k, h2k in the next two rounds. Hence, the allocation is the same.

Example 5.3. Consider two agents with preferences 1= h5, h6, h1, h3, h4, h2 and 2= h1, h2, h3, h4, h5, h6. The allocation obtained by the PS algorithm over 1 and 2
is P S( 1, 2) = 01 01 11//22 11//22 10 10 . The identical allocation given by the alternation

policy with

CLONED
1

and

Rounds
123456 2CLONED is h15 h25 h16 h26 h13 h14 .
h11 h21 h12 h22 h23 h24

5.2. Computing an EU best response

In this section we present an algorithm to compute an expected utility best response

for the PS mechanism. First, we recap our settings. We are given two agents 1 and 2

with proﬁles 1 and 2, respectively, over houses in H. We assume that agent 1 plays

strategically and agent 2 plays truthfully. The goal is to ﬁnd an expected utility best

response for agent 1 for the PS rule. To do so, we reuse an EU best response for the

alternation policy over split houses,

CLONED
1

and

. CLONED
2

Our

algorithm

is

based

on

Technical Report: January 2014.

12

H. Aziz et al.

Input: ({1, 2}, H, ( 1, 2)) where 2: h1, 2 . . . , 2 hm

Output: Best response

BEST
1

of

agent

1

1 Construct order-preserving bisection of

1 and

2:

CLONED
1

and

2CLONED .

2 Run Kohler and Chandrasekaran’s algorithm for two agents with preferences

CLONED
1

and

use the alternation policy. We obtain

. CLONED-BEST
1

3 if

CLONED-BEST 1

does

not

satisfy

consecutivity

then

4 Let W be a set of half-houses such that agent 1 gets a half-house h1 but does not get h2.

5 for all h1 ∈ W do

6

Suppose agent 2 gets h2 in the ith round.

7

Move h1 at the ith position in

. CLONED-BEST
1

8 end for

9 for all h1 ∈ W do

10

Rank h2 right after h1 in

. CLONED-BEST
1

11 end for

12 end if

13 Use order-preserving join to obtain

14 return

BEST
1

BEST
1

from

CLONED-BEST 1

Algorithm 2: EU best response for 2 agents

CLONED
2

and

the following lemma. Let

CLONED-BEST 1

be

an

expected

utility

best

response

for

agent

1

to

CLONED
2

for

the

alternation

policy.

LEMMA 5.4. Suppose

CLONED-BEST 1

has

the

consecutivity

property.

Then,

, BEST
1

ob-

tained by the order-preserving join from

CLONED-BEST 1

is

an

EU

best

response

to

2.

PROOF. The proof is by contradiction. Suppose,

BEST
1

is EU preferred to

. BEST
1

We transform

BEST
1

into

CLONED-BEST 1

using the order-preserving bisection. By

Lemma 5.2, if we run the alternation policy over

CLONED-BEST 1

and

, CLONED
2

the

agents

get the same allocation as by running PS. Hence,

CLONED-BEST 1

is

not

the

best

response

to

. CLONED
2

This

leads

to

a

contradiction.

Lemma 5.4 suggests a straightforward way to compute agent 1’s best response

BEST
1

for the PS algorithm. We run Kohler and Chandrasekaran’s algorithm that ﬁnds a best

response for the alternation policy given agents’ preferences

CLONED
1

and

. CLONED
2

If

CLONED-BEST 1

has

the

consecutivity

property

then

we

can

use

the

order-preserving

join

to

obtain

BEST
1

which

is

the

expected

utility

best

response

to

2 in PS by Lemma 5.4. The

main problem with this approach is that the algorithm of Kohler and Chandrasekaran

[1971] may return

CLONED-BEST 1

that

does

not

have

the

consecutivity

property

(we

pro-

vide such an example in the full report). However, we show in Algorithm 2 that we

can always ﬁnd another expected utility best response

CLONED-BEST 1

that has the con-

secutivity property. We need to delay the allocation of some half-houses that agent 1

gets. The modiﬁcations of the best response

CLONED-BEST 1

in

lines

3–12

produce

another

best response that has the consecutivity property for agent 1. A detailed description

of the algorithm from [Kohler and Chandrasekaran 1971] and a proof of correctness of

Algorithm 2 can be found in the full report.

Remark 5.5. The EU best response algorithm is independent of particular utilities
and holds for any utilities consistent with the ordinal preferences. Since PS for two agents only involves fractions 0, 12 , and 1, a DL best response is also equivalent to an EU best response. Hence we have proved that the DL best response algorithm in
Section 4 is also an EU best response algorithm for the case of two agents.

6. NASH DYNAMICS AND EQUILIBRIUM
In contrast to the previous sections where a single agent is strategic, we consider the setting when all the agents are strategic. We ﬁrst prove that for expected utility best

Technical Report: January 2014.

Strategic aspects of the probabilistic serial rule

13

responses, the preference proﬁle of the agents can cycle when agents have Borda utilities. This means that it is possible that self interested agents, acting unilaterally, may never stop reacting.
THEOREM 6.1. With 3 agents and 6 items where agents have Borda utilities, a series of expected utility best responses by the agents can lead to a cycle in the proﬁle.
Using a computer program we have found a sequence of best response that cycle. Checking the existence of a preference proﬁle that is in Nash equilibrium appears to be a challenging problem. The naive way of checking existence of Nash equilibrium requires going through O(m!n) proﬁles, which is super-polynomial even when n = O(1) or m = O(1). Although computing a Nash equilibrium is a challenging problem, we show that at least one (pure) Nash equilibrium is guaranteed to exist for any number of houses, any number of agents, and any preference relation over fractional allocations.7 The proof relies on showing that the PS rule can be modelled as a perfect information extensive form game.
THEOREM 6.2. A pure Nash equilibrium is guaranteed to exist under the PS rule for any number of agents and houses, and for any relation between allocations.
PROOF SKETCH. Let t0, . . . , tk be the k + 1 different time steps in the PS algorithm. Let g = GCD({ti+1 − ti : i ∈ {0, . . . , k − 1}}) where GCD denotes the greatest common divisor. The time interval length g is small enough such that the PS rule can be considered to have m/g stages of duration g. Each stage can be viewed as having n sub-stages so that in each stage, agent i eats g units of a house in sub-stage i of a stage. In each sub-stage only one agent eats g units of the most favoured house that is available. Hence we now view PS as consisting of a total of mn/g sub-stages and the agents keep coming in order 1, 2, . . . , n to eat g units of the most preferred house that is still available. If an agent ate g units of a house in a previous sub-stage then it will eat g units of the same house in the next sub-stage as long as the house has not been fully eaten. Consider a perfect information extensive form game tree. For a ﬁxed reported preference proﬁle, the PS rule unravels accordingly along a path starting at the root and ending at a leaf. Each level of the tree represents a sub-stage in which a certain agent has his turn to eat g units of his most preferred available house. Note that there is a one-to-one correspondence between the paths in the tree and the ways the PS algorithm can be implemented, depending on the reported preference.
A subgame perfect Nash equilibrium is guaranteed to exist for such a game via backward induction: starting from the leaves and moving towards the root of the tree, the agent at the speciﬁc node chooses an action that maximizes his utility given the actions determined for the children of the node. The subgame perfect Nash equilibrium identiﬁes at least one such path from a leaf to the root of the game. The path can be used to read out the most preferred house of each agent at each point. The information provided is sufﬁcient to construct a preference proﬁle that is in Nash equilibrium. Those houses that an agent did not eat at all can conveniently be placed at the end of the preference list. Such a preference proﬁle is in Nash equilibrium. Hence, a pure Nash equilibrium exists under the PS rule.
We also know that DL-Nash equilibrium is an SD-Nash equilibrium because if there is an SD deviation, then it is also a DL deviation. Our argument for the existence of a Nash equilibrium is constructive. However, naively constructing the extensive form game and then computing a sub-game perfect Nash equilibrium requires exponential space and time. It is an open question whether a sub-game perfect Nash equilibrium or

7We already know from Nash’s original result that a mixed Nash equilibrium exists for any game.

Technical Report: January 2014.

14

H. Aziz et al.

for that matter any Nash equilibrium preference proﬁle can be computed in polynomial time. We can prove the following theorem for the “threat proﬁle” whose construction is shown in Algorithm 3.

THEOREM 6.3. Under PS and for two agents, there exists a preference proﬁle that is in DL-Nash equilibrium and results in the same assignment as the assignment based on the truthful preferences. Moreover, it can be computed in linear time.

PROOF. The proof is by induction over the length of the preference lists constructed. The main idea of the proof is that if both agents compete for the same house then they do not have an incentive to delay eating it. If the most preferred houses do not coincide, then both the agents get them with probability one but will not get them completely if they delay eating them.
Let the original preferences of agent 1 and agent 2 be represented by lists P1 and P2. We present an algorithm to compute preferences Q1 and Q2 that are in DL-Nash equilibrium. Initialise Q1 and Q2 to empty lists. Now consider the maximal elements h from P1 and h from P2. Element h is appended to the list Q1 and h is appended to the list Q2. At the same time h is deleted from P1 and h is deleted from P2. Now if h = h , then h is appended to Q1 and h is appended to Q2. The process is repeated until Q1 and Q2 are complete lists and P1 and P2 are empty lists. The algorithm is described as Algorithm 3.
We now prove that P1 is a DL best response against P2 and P2 is a DL best response against P1. The proof is by induction over the length of the preference lists. For the ﬁrst elements in the preference lists P1 and P2, if the elements coincide, then no agent has an incentive to put the element later in the list since the element is both agents’ most preferred house. If the maximal elements do not coincide i.e. h = h , then 1 and 2 get h and h respectively with probability one. However they still need to express these houses as their most preferred houses because if they don’t, they will not get the house with probability one. The reason is that h is the next most preferred house after h for agent 2 and h is the next most preferred house after h for agent 1. Agent 1 has no incentive to change the position of h since h is taken by agent 2 completely before agent 1 can eat it. Similarly, agent 2 has no incentive to change the position of h since h is taken by agent 1 completely before agent 2 can eat it. Now that the positions of h and h have been completely ﬁxed, we do not need to consider them and we reason in the same manner over the updated lists P1 and P2.

The desirable aspect of the threat proﬁle is that since it results in the same assignment as the assignment based on the truthful preferences, the resultant assignment satisﬁes all the desirable properties of the PS outcome with respect to the original preferences. Due to Remark 5.5, we get the following corollary.

COROLLARY 6.4. Under PS and for 2 agents, there exists a preference proﬁle that is Nash equilibrium for any utilities consistent with the ordinal preferences. Moreover it can be computed in linear time.

In this next example, we show how Algorithm 3 is used to compute a preference proﬁle that is in DL-Nash equilibrium. The example also shows that it can be the case that one preference proﬁle is in DL-Nash equilibrium and the other is not, even if both proﬁles yield the same outcome.

Example 6.5 (Computing a threat proﬁle).

1: h1, h2, h3, h4

2: h2, h3, h1, h4

We now use Algorithm 3 to compute a preference proﬁle ( 1, 2) that is in DLNash equilibrium: 1= h1, h2, h3, h4 and 2= h2, h1, h3, h4. Note that P S( 1, 2) =

Technical Report: January 2014.

Strategic aspects of the probabilistic serial rule

15

Input: ({1, 2}, H, ( 1, 2)) Output: The “threat proﬁle” (Q1, Q2) where Qi is the preference list of agent i for i ∈ {1, 2}.

1 Let Pi be the preference list of agent i ∈ {1, 2} 2 Initialise Q1 and Q2 to empty lists. 3 while P1 and P2 are not empty do 4 Let h = ﬁrst(P1) and h = ﬁrst(P2) 5 Append h to Q1; Append h to Q2 6 Delete h from P1; Delete h from P2 7 if h = h then

8

Append h to Q1; Append h to Q2;

9 end if

10 end while

11 return (Q1, Q2).

Algorithm 3: Threat proﬁle DL-Nash equilibrium for 2 agents (which also is an EU Nash equilibrium)

1 0 1/2 1/2 0 1 1/2 1/2

. Although P S(

1,

2) = PS(

1,

2), we see that (

1,

2) is in DL-

Nash equilibrium but ( 1, 2) is not!

Next we show how our identiﬁed links with sequential allocation allocation of indivisible houses leads us to another Nash equilibrium proﬁle called the crossout proﬁle. The algorithm to compute the crossout proﬁle is stated as Algorithm 4.

Input: ({1, 2}, H, ( 1, 2)) Output: The “crossout proﬁle” (Q1, Q2) where Qi is the preference list of agent i for i ∈ {1, 2}. 1 Let Pi be the order-preserving bisection of preference list of agent i ∈ {1, 2} 2 Initialise Q1 and Q2 to empty lists. 3 while P1 and P2 are not empty do 4 Let h = last(P1); Prepend h to Q2; Delete h from P1 and P2; 5 Let h = last(P2); Prepend h to Q1; Delete h from P1 and P2; 6 end while 7 extend Q1 and Q2 to have the consecutivity property but the same allocation. 8 change Q1 and Q2 via order-preserving join of Q1 and Q2. 9 return (Q1, Q2).
Algorithm 4: Crossover proﬁle DL-Nash equilibrium for 2 agents (which also is an EU Nash equilibrium)
In Algorithm 4, the Nash equilibrium problem for PS is changed into the same problem for sequential allocation by changing each house into a half house. The idea behind the crossout proﬁle for the sequential allocation setting is that no agent will choose the least preferred object unless it is the only object left. Thus agent 2 will be forced to get the least preferred object of agent 1 [Levine and Stange 2012; Kohler and Chandrasekaran 1971]. In Algorithm 4, we use this idea recursively to build sequences of objects Q1 and Q2 for each agent that are allocated to them. If one agent gets a half house and the other agent gets the other half house, it can be proved that the positions of the half houses in Q1 and Q2 are same. This sequence of objects for each agent are then extended to preferences that give the same allocations under sequential allocation and which also satisfy the consecutivity property. The preferences for sequential allocation are then transformed via order-preserving join to obtain the crossover Nash equilibrium proﬁle for the PS rule. By Lemma 5.4, the preference proﬁle is in Nash equilibrium. Next we show that the threat proﬁle and crossout proﬁle are different and may also give different assignments.

Technical Report: January 2014.

16

H. Aziz et al.

Example 6.6 ( Crossout proﬁle). Consider the following proﬁle.

1: h1, h2, h3, h4

2: h2, h3, h1, h4

We now use Algorithm 4 to compute a preference proﬁle ( 1, 2) that is in DLNash equilibrium where 1= h2, h1, h4, h3 and 2= h2, h3, h4, h1. Note that P S( 1, 2 ) = 1 1/2 0 1/2 . The crossout Nash equilibrium proﬁle is different from the threat
0 1/2 1 1/2
Nash equilibrium proﬁle for the problem instance.

The complexity of computing a Nash equilibrium proﬁle for more than two agents still remains open. However we have presented a positive result for two agents — a case which captures various fair division scenarios.

7. EXPERIMENTS
In this section, we examine the likelihood that at least one agent would have an incentive to misreport his preferences to get more expected utility. To gain insight into this issue we have performed a series of experiments to determine the frequency that, for a given number of agents and houses, a proﬁle will have a beneﬁcial strategic reporting opportunity for a single agent. 8
In order to preform this experiment we need to generate preferences and utilities for each of the agents. We consider two different models to generate proﬁles. (i) In the Impartial Culture (IC) model, the assumption is that for each agent and a given number of houses, each of the |H|! preference orders over the houses is equally likely ( |H1|! ). (ii) In the Uniform Single Peaked (USP), the assumption is that all single peaked preference proﬁles are equally likely. Single peaked preferences are a proﬁle restriction introduced by Black [1948] and well studied in the social choice literature. Informally, in a single peaked proﬁle, given all possible 3-sets of houses, no agent ever ranks some particular house last in all 3 sets that it appears.
In order to evaluate if an agent has a better response we need to assign utilities to the individual houses for each agent. While there are a number of ways to model utility we have selected the following mild restrictions on utilities in order to gain an understanding of the manipulation opportunities. (i) In the Random model, we uniformly at random generate a real number between 0 and 1 for each house that is compatible with the generated preference order. We normalize these utilities such that each agent’s utility sums to a constant value that is the same for all agents. In our experiments each agent’s utility sums to the number of houses in the instance. (ii) In the Borda model, we assign |H|−1 utility to the ﬁrst house, |H|−2 to the second house, down to 0 utility for the least preferred house. (iii) In the Exponential (Exp) model, we assign utility 2|H|−1 to the ﬁrst house, 2|H|−2 to the second house, down to 0 utility for the least preferred house.
We generated for each pair in |N | = {1, . . . , 8}×|H| = {1, . . . , 8} 1,000 proﬁles according to a utility and preference distribution. For each of these instances, we searched to see if any agent could get more utility by misreporting his preferences, if so, then we say that proﬁle admitted a manipulation. Figure 2 show the percentage of instances that were manipulable for each of the domain, utility, number of agent, and number of house combinations (Borda is omitted for space).
Looking at Figure 2, we observe that as the utility and preference models become more restrictive, the opportunities for a single agent to manipulate becomes smaller.

8Independent from our work, Philipp [2013] also examined how susceptible PS can be to manipulation. Hugh-Jone et al. [2013] conducted laboratory experiments which do look at the manipulability of PS mathematically but according to the strategic behaviour of humans.

Technical Report: January 2014.

Strategic aspects of the probabilistic serial rule

17

The Random-IC experiment yields the most frequently manipulable proﬁles, strictly dominating all the other runs of the experiment for every combination except one (Random-USP with 3 houses and 3 agents). Each experiment with single peaked preferences (save one) is dominated by the experiment with the unrestricted preference proﬁles for the same utility model.

Fig. 2: Heatmap showing the percentage of manipulable instances for Random Utility and the Single Peaked Random Utility models on the left and Exponential Utility and the Single Peaked Exponential Utility models on the right.
The PS rule is strategyproof with respect to the DL relation in the case where the number of agents and the number of houses are equal. Our experiment with the Exp model (which is similar to the DL relation but not exact) found no manipulable instances when the number of agents is less than or equal to the number of houses. It is encouraging that the manipulation opportunities for Exp-USP are so low. In this setting each agent is valuing the houses along the same axis of preference and prefers their ﬁrst choice exponentially more than their second choice. As the number of houses relative to the number of agents grows, the opportunities to manipulate increase, maximizing around 99%.
8. CONCLUSIONS We conducted a detailed computational analysis of strategic aspects of the PS rule. Our study leads to a number of new research directions. PS is well-deﬁned even for indifferences [Katta and Sethuraman 2006]. It will be interesting to extend our results for strict preferences to the case with ties. Two interesting problems are still open. Firstly, What is the complexity of computing an expected utility best response for more than two agents? The problem is particularly intriguing because even for the related and conceptually simpler setting of discrete allocation, computing an expected utility best response for more than two agents has remained an open problem [Bouveret and Lang 2011]. Another problem is the complexity of computing a Nash equilibrium for more than two agents. It will also be interesting to examine coalitional manipulations
Technical Report: January 2014.

18

H. Aziz et al.

and coalitional Nash equilibria. Finally, an analysis of Nash dynamics under the PS rule is an intriguing research problem.
REFERENCES
ACKERMANN, H., GOLDBERG, P. W., MIRROKNI, V. S., RO¨ GLIN, H., AND VO¨ CKING, B. 2011. Uncoordinated two-sided matching markets. SIAM Journal on Computing 40, 1, 92–106.
AZIZ, H., BRANDT, F., AND BRILL, M. 2013a. The computational complexity of random serial dictatorship. Economics Letters 121, 3, 341–345.
AZIZ, H., BRANDT, F., AND STURSBERG, P. 2013b. On popular random assignments. In Proceedings of the 6th International Symposium on Algorithmic Game Theory (SAGT), B. Vo¨cking, Ed. Lecture Notes in Computer Science (LNCS) Series, vol. 8146. Springer-Verlag, 183–194.
BLACK, D. 1948. On the rationale of group decision-making. Journal of Political Economy 56, 1, 23–34.
BOGOMOLNAIA, A. AND HEO, E. J. 2012. Probabilistic assignment of objects: Characterizing the serial rule. Journal of Economic Theory 147, 2072–2082.
BOGOMOLNAIA, A. AND MOULIN, H. 2001. A new solution to the random assignment problem. Journal of Economic Theory 100, 2, 295–328.
BOUVERET, S. AND LANG, J. 2011. A general elicitation-free protocol for allocating indivisible goods. In Proceedings of the 22 International Joint Conference on Artiﬁcial Intelligence (IJCAI). 73–78.
BUDISH, E., CHE, Y.-K., KOJIMA, F., AND MILGROM, P. 2013. Designing random allocation mechanisms: Theory and applications. American Economic Review. Forthcoming.
CHO, W. J. 2012. Probabilistic assignment: A two-fold axiomatic approach. Unpublished manuscript.
EKICI, O. AND KESTEN, O. 2012. An equilibrium analysis of the probabilistic serial mechanism. Tech. rep., O¨ zyeg˘ in University, Istanbul. May.
FALISZEWSKI, P., HEMASPAANDRA, E., AND HEMASPAANDRA, L. 2010. Using complexity to protect elections. Communications of the ACM 53, 11, 74–82.
FALISZEWSKI, P. AND PROCACCIA, A. D. 2010. AI’s war on manipulation: Are we winning? AI Magazine 31, 4, 53–64.
GA¨ RDENFORS, P. 1973. Assignment problem based on ordinal preferences. Management Science 20, 331–340.
HUGH-JONE, D., KURINO, M., AND VANBERG, C. 2013. An experimental study on the incentives of the probabilistic serial mechanism. Tech. Rep. SP II 2013–204, Social Science Research Center Berlin (WZB). May.
HYLLAND, A. AND ZECKHAUSER, R. 1979. The efﬁcient allocation of individuals to positions. The Journal of Political Economy 87, 2, 293–314.
KATTA, A.-K. AND SETHURAMAN, J. 2006. A solution to the random assignment problem on the full preference domain. Journal of Economic Theory 131, 1, 231–250.
KOHLER, D. A. AND CHANDRASEKARAN, R. 1971. A class of sequential games. Operations Research 19, 2, 270–277.
KOJIMA, F. 2009. Random assignment of multiple indivisible objects. Mathematical Social Sciences 57, 1, 134—142.
LEVINE, L. AND STANGE, K. E. 2012. How to make the most of a shared meal: Plan the last bite ﬁrst. The American Mathematical Monthly 119, 7, 550–565.
PHILIPP, B. 2013. Simulation of boundedly rational manipulation strategies in one-sided matching markets. M.S. thesis, Faculty of Economics, University of Zurich.
SABAN, D. AND SETHURAMAN, J. 2013a. House allocation with indifferences: a generalization and a uniﬁed view. In Proceedings of the 14th ACM Conference on Electronic Commerce (ACMEC). 803–820.
SABAN, D. AND SETHURAMAN, J. 2013b. A note on object allocation under lexicographic preferences. Journal of Mathematical Economics.
SCHULMAN, L. J. AND VAZIRANI, V. V. 2012. Allocation of divisible goods under lexicographic preferences. Tech. Rep. arXiv:1206.4366, arXiv.org.
YILMAZ, O. 2010. The probabilistic serial mechanism with private endowments. Games and Economic Behavior 69, 2, 475–491.

Technical Report: January 2014.

Strategic aspects of the probabilistic serial rule

19

A. PSEUDOCODE OF PS
We write the formal deﬁnition of PS from [Kojima 2009] as an algorithm. For any h ∈ H ⊂ H, let N (h, H ) = {i ∈ N : a i b for every b ∈ H } be the set of agents whose most preferred house in H is h. PS is deﬁned as Algorithm 5.

Input: (N, H, ) Output: p the random assignment returned by PS

1 s ←− 0 (s is the stage of the algorithm)

2 HO ←− H; t0 ←− 0; p0ih ←− 0 for all i ∈ N and h ∈ H. 3 while Hs = ∅ do

4 ts+1(h) = sup{t ∈ [0, |H|] : i∈N psih + |N (h, Hs)|(t − ts) < 1} 5 ts+1 ←− minh∈Hs ts(h) 6 Hs = Hs \ {h ∈ Hs−1 : t(h) = ts}

7 for all i ∈ N and h ∈ H do

8

if i ∈ N (h, Hs) then

9

psih+1 ←− psih + ts+1 − t(s)

10

else

11

psih+1 ←− psih

12

end if

13 end for

14 s ←− s + 1
15 end while 16 return p = ps

Algorithm 5: PS

B. EXPECTED UTILITY BEST RESPONSE FOR THE ALTERNATION POLICY
In this section we recall the best response algorithm proposed in [Kohler and Chandrasekaran 1971] as we will use it to derive the best response algorithm for the PS algorithm.
We denote the algorithm from [Kohler and Chandrasekaran 1971] BESTEURESPONSEALGO. In particular, we describe BESTEURESPONSEALGO for the special case ki = 1 and ni = 2 so that we follow the alternation policy. We also assume that the number of houses is even as this is sufﬁcient for our purposes. These restrictions simplify the algorithm.
Following Kohler and Chandrasekaran [Kohler and Chandrasekaran 1971], we use a matrix V = Vi,j, i = 1, 2, j = 1, . . . , m, where Vi,j represents the utility value that the i-th player will gain if he selects the hj object. In our case, we assume that Vi,j = ui,j, i = 1, 2, j = 1, . . . , m, such that ui,j ∈ R and ui,j > ui,j iff hj i hj . As 2 ranks houses hj, j = 1, . . . , m, lexicographically, we have V2,j ≥ V2,j+1, j = 1, . . . , m − 1. Algorithm 6 shows a pseudocode for the simpliﬁed version of BESTEURESPONSEALGO.
We refer to J k as an ordered set formed at the kth stage of BESTEURESPONSEALGO. The ordered set Jm/2 is the optimal set of houses for agent 1 to choose, and agent 1 must choose them in the lexicographic order. We denote BESTEURESPONSE = BESTEURESPONSEALGO(V ). Note that the number of houses in BESTEURESPONSE is m/2.
Example B.1. Consider two agents with preferences 1= h5, h6, h1, h3, h4, h2 and 2= h1, h2, h3, h4, h5, h6. First, we form a matrix V . We select arbitrary numbers ui,j that satisfy conditions above, e.g.
Technical Report: January 2014.

20

H. Aziz et al.

Input: (Vi,j, i = 1, 2, j = 1, . . . , m) Output: the set of houses allocated to agent 1 as a result of his best response.
1 for k ∈ [1, m/2] do 2 Ik ←− {h2k−1, h2k} 3 end for 4 if −1 1(h1) < −1 1(h2) then 5 J 1 ←− {h1} 6 else 7 J 1 ←− {h2} 8 end if 9 for k ∈ [2, m/2] do 10 J k ←− {h2k−1, h2k} 11 end for 12 J 1 ←− J 1 13 for k ∈ [2, m/2] do 14 J k ←− {hj |hj ∈ J k−1 ∪ J k; V1j ≥ kth maximal of {V1l|hl ∈ J k−1 ∪ J k}} 15 end for 16 return J m/2.
Algorithm 6: BESTEURESPONSEALGO for sequential allocation for two agents

V= 413265 654321

The following table shows an execution of the algorithm on this example over proﬁles 1 and 2.

I1 {h1, h2}
J1 {h1} J1 {h1}

I2 {h3, h4}
J2 {h3, h4}
J2 {h1, h3}

I3 {h5, h6}
J3 {h5, h6}
J3 {h1, h5, h6}

Table I: An execution of BESTEURESPONSEALGO on Example B.1.

BESTEURESPONSE = J 3 = {h1, h5, h6}.

Given BESTEURESPONSE we deﬁne a proﬁle that corresponds to the best response

BEST
1

.

By

B

ESTE

U

RESPONS

E(i)

we

refer

to

the

house

at

the

ith

position.

First,

we

rank

houses in BESTEURESPONSE in the same order as they occur in BESTEURESPONSE,

so that

= BEST
1

(BESTEURESPONSE(1), . . . , BESTEURESPONSE(m/2). Then, after

BESTEURESPONSE(m/2), we rank houses that agent 2 gets in the same order as agent

2 obtains them. In Example B.1,

= BEST
1

h1,

h5,

h6,

h2,

h3,

h4.

C. A BEST RESPONSE WITHOUT THE CONSECUTIVITY PROPERTY (EXAMPLE)

Next we provide an example that shows that a best response returned by Algorithm 6

over

CLONED
1

and

CLONED
2

might

not

have

the

consecutivity

property.

Example C.1. Consider two agents from Example 5.3. We re-

call that if we split all houses into halves then we obtain pro-

ﬁles:

= CLONED
1

h15, h25, h16, h26, h11, h21, h13, h23, h14, h24, h12, h22

h11, h21, h12, h22, h13, h23, h14, h24, h15, h25, h16, h26.

and

= CLONED
2

Technical Report: January 2014.

Strategic aspects of the probabilistic serial rule

21

A matrix V is the following

V= 441133226655 665544332211

Table II shows an execution of BESTEURESPONSEALGO over proﬁles

and

. CLONED BESTEURESPONSE = J 6 = {h1, h1, h1, h2, h1, h2}. We

2

135566

BESTEURESPONSE with houses that are not allocated to agent 1 and obtain

CLONED
1
extend

CLONED-BEST 1

=

h11, h13, h15, h25, h16, h26, h21, h12, h22, h23, h14, h24.

I1

I2

{h11,h21} {h12,h22}

I3 {h13 ,h23 }

I4 {h14 ,h24 }

I5 {h15 ,h25 }

I6 {h16 ,h26 }

J1 {h11}

J2 {h12 ,h22 }

J3 {h13 ,h23 }

J4 {h14 ,h24 }

J5 {h15 ,h25 }

J6 {h16 ,h26 }

J1 {h11}

J2

J3

J4

J5

J6

{h11,h12} {h11,h13,h23} {h11,h13,h23,h14} {h11,h13,h23,h15,h25} {h11,h13,h15,h25,h16,h26}

Table II: An execution of BESTEURESPONSEALGO over proﬁles

CLONED 1

and

. CLONED
2

Unfortunately,

CLONED-BEST 1

does

not

have

the

consecutivity

property

and

Lemma

5.4

can not be applied. Note that agent 2 gets {h21, h12, h22, h23, h14, h24}.

In the next section, we show that we can always ﬁnd another

CLONED-BEST 1

that

has

the consecutivity property.

D. EXPECTED UTILITY BEST RESPONSE FOR THE PS MECHANISM (FULL PROOF).

In this section, we demonstrate that given

CLONED
1

and

CLONED
2

we

can

always

ﬁnd

the expected utility best response to

CLONED
2

that

has

the

consecutivity

property.

To

do so, we ﬁrst run BESTEURESPONSEALGO to obtain BESTEURESPONSE. Then we

demonstrate that it can be modiﬁed and extended to a proﬁle over H CLONED that has

the consecutivity property.

Given BESTEURESPONSE, we denote the ordered set of houses allocated to agent

j BEST-ALLOCj , j = 1, 2. Note that BEST-ALLOC1 = BESTEURESPONSE. Then

BEST-ALLOC1(i) and BEST-ALLOC2(i) are houses that are allocated to agent 1 and

agent 2, respectively, in the ith round of the alternation policy.

Example D.1. Consider Example C.1.

BEST-ALLOC1 = {h11, h13, h15, h25, h16, h26}.

and

BEST-ALLOC2 = {h21, h12, h22, h23, h14, h24}.
We say that BEST-ALLOC has the consecutivity property iff for all h1i , h2i ∈ BEST-ALLOC, h1i and h2i are ordered consecutively. We say that a half-house of hi is allocated to agent 1 if and only if agent 1 gets h1i and agent 2 gets h2i . We say that a full-house hi is allocated to agent 1 if and only if agent 1 gets h1i and h2i .
In the proof we often consider an ordered set of houses {hji1 , . . . , hjip } that obeys the following property: {hji1 2 . . . 2 hjip }. We will say these houses are lexicographically ordered as agent 2 orders his houses w.r.t. the lexicographic order by our assumption in Section 5.1.

Technical Report: January 2014.

22

H. Aziz et al.

First, we give an overview of the construction. Our construction is motivated by an

observation that if BEST-ALLOC1 and BEST-ALLOC2 have the consecutivity property

and half houses are obtained by agent 1 and 2 at the same round then it is straightfor-

ward to extend BEST-ALLOC1 to

CLONED-BEST 1

over

H CLONED

that

has

the

consecutivity

property. Consider the following example.

Example D.2. Suppose BEST-ALLOC1 = {h12, h22, h13, h14, h24, h16} and BEST-ALLOC2 = {h11, h21, h23, h15, h25, h26}. Note that half-houses are allocated in the same rounds in

BEST-ALLOC1 and BEST-ALLOC2. The 1st agent expected utility best response proﬁle

is

CLONED-BEST 1

=

h12, h22, h13, h14, h24, h16, h11, h21, h23, h15, h25, h26.

Note

that

CLONED-BEST 1

does

not

have consecutivity property.

Next we demonstrate how to change

CLONED-BEST 1

so

that

it

has

the

consecutivity

property and leads to the same allocation. For each half house h1i allocated to agent 1

we rank h2i right after h1i . We keep houses that are not allocated to agent 1 in the end of

the proﬁle. In this example, we rank h23 and h26 after h13 and h16, respectively. We obtain

the following proﬁle:

CLONED-BEST 1

=

h12, h22, h13, h23, h14, h24, h16, h26, h11, h21, h15, h25.

Note

that

inserting h2i after h1i does not change the allocation as we know that h2i is allocated to

agent 2 at the same round as h1i is allocated to agent 1. Hence, h2i will never be the

top element for agent 1 at any round and

CLONED-BEST 1

gives the same allocation as

BEST-ALLOC1.

Based on this observation, the goal of the construction is to transform BEST-ALLOC1 is such a way that half houses of hi that are allocated to different agents are allocated to them in the same round while preserving allocations of both agents. To
do so, we prove that an allocation of half houses and full houses in an execution
of BESTEURESPONSEALGO follows simple patterns. The ﬁrst property concerns full
houses : halves of full houses allocated to an agent are always allocated in consecutive rounds. The second key property concerns half houses. Let HGj = {hji1 , . . . , hjip } be the lexicographically ordered set of half houses allocated to agent j, j = 1, 2. Then allocation of half houses obeys the following order: agent 1 gets h1i1 at round kt1 then, possibly in later round kt1 , agent 2 gets h2i1 . Next, agent 1 gets h1i2 at round kt2 then, possibly in later round kt2 , agent 2 gets h2i1 , and so on. In other words, half houses are allocated to agents in lexicographic order and each half houses is allocated to both agents before
the next half houses is allocated. Based on these properties, we will prove that we can delay an allocation of h1ih to agent 1 till round kth and preserve the allocations.
We need to prove several useful properties of BESTEURESPONSE.
The next proposition states that if only half of hi is allocated to agent 1(2) then this half is h1i (h2i ). We use this observation to simplify notations.

PROPOSITION D.3. If hji is allocated to agent 1 and hji%2+1 is allocated to agent 2 then h1i is allocated to agent 1 and h2i is allocated to agent 2.

PROOF. Follows from BESTEURESPONSEALGO and agent 1 always prefers h1i .

CLONED
1

as

between

h1i

and

h2i

The next lemma shows that for all full houses allocated to i, both halves are allocated in consecutive rounds.

PROPOSITION D.4. If a full-house of hi is allocated to 1(2) then h1i and h2i are allocated to 1(2) in two consecutive rounds.

PROOF. For agent 1 it follows from construction of BEST-ALLOC1 in

BESTEURESPONSEALGO. For agent 2 it follows from the deﬁnition

, CLONED
2

as

Technical Report: January 2014.

Strategic aspects of the probabilistic serial rule

23

h1i and h2i are ordered consecutively in alternation policy to obtain BEST-ALLOC2.

, CLONED
2

and

the

fact

that

we

use

the

We denote HGj = {hji1 , . . . , hjip } the lexicographically ordered set of half-houses allocated to agent j, j = 1, 2. We show that utilities of these houses decrease monotonically given this order.

PROPOSITION D.5. V1h1i1 > . . . > V1h1ip for h1i1 , . . . , h1ip ∈ HG1 .

PROOF. By contradiction, suppose that h1t is a half-house that violates the state-

ment: V1h1 < V1h1 . The equality is not possible as we have strict preferences over

t −1

t

houses. We denote t = t − 1 to simplify notations. From BESTEURESPONSEALGO, it

follows that h1t was added to J t from Jt = {h1t , h2t } at the stage t and h1i was added j

to J t from Jt = {h1t , h2t } at the stage t . As h1t 2 h1t , t < t . In other words, h1t was added to the BESTEURESPONSE after h1t . As V1h1t < V1h1t = V1h2t , h2t is also added to

Jt at the stage t . As h1t is half-house allocated to agent 1, h2t was removed from Jt at some later stage t . However, it can not be removed before h1t which has a smaller utility. This leads to a contradiction as h1t ∈ BEST-ALLOC1 and h2t ∈/ BEST-ALLOC1.

The next lemma shows that BEST-ALLOC1 is point-wise at most as good as BEST-ALLOC2 with respect agent 2 preferences.

LEMMA D.6. BEST-ALLOC2(k) 2 BEST-ALLOC1(k) or BEST-ALLOC1(k) and BEST-ALLOC2(k) are halves of the same house k = 1, . . . , 2m.

PROOF. By induction on the number of rounds. The base case holds trivially as

BEST-ALLOC2(1) is in {h11, h21} and h11 and BEST-ALLOC2(1) = h21.

2 BEST-ALLOC1(1) or BEST-ALLOC1(1) = h11

Assume that the statement holds for i − 1 rounds. Consider the ith round.

Suppose, by contradiction, h := BEST-ALLOC1(i) 2 BEST-ALLOC2(i) =: h and h

and h are not halves of the same house. As h and h are allocated houses at the ith

round then these houses are top preferences of agent 1 and agent 2, respectively, after

i − 1th round. As h 2 h , there exists a round i < i such that h is the top preference

of agent 2 at this round. Moreover, h is available to agent 2 at this round as agent 1

only requests it at the ith round. Hence, h will be allocated to agent 2 at the i th round.

This contradicts the assumption that h is allocated to agent 1.

The next result is the key result the section on computing the best EU response. We consider half-houses GH1 = {h1i1 , . . . , h1ip } allocated to agent 1 and GH2 = {h2i1 , . . . , h2ip }
allocated to agent 2. GH1 and GH2 are lexicographically ordered. We show that, ﬁrst, h1i1 and h2i1 are allocated to agent 1 and agent 2, respectively, after that, h1i2 and h2i2 are allocated and so on.

LEMMA D.7. Suppose houses in GH1 are allocated in rounds ki11 , . . . , ki1p and houses in GH2 are allocated in rounds ki21 , . . . , ki2p . Then ki11 < ki21 < ki12 < ki22 < . . . < ki1p < ki2p .

PROOF. By contradiction, suppose that h1t is the ﬁrst half-house allocated to agent 1 that violates the statement so that kt1 < kt1 < . . . < kt2. In other words, ﬁrst, agent 1 gets h1t at the kt1th round and h1t , which is a half of another house ht , at the kt1 th round, and later agent 2 gets h2t at the kt2th round.
CLAIM 1. The following inequality holds:

h1t 2 h1t .

Technical Report: January 2014.

24

H. Aziz et al.

PROOF. This follows from the fact that houses in BEST-ALLOC1 = BESTEURESPONSE are lexicographically ordered and the fact that h1t is allocated before h1t to agent 1.

CLAIM 2. The following inequality holds:

kt2 < kt2 .

PROOF. This follows from the structure

CLONED
2

and

h1t

2 h1t (Claim 1).

From Claim 2 and our assumption hypothesis we have

kt1 < kt1 < . . . < kt2 < kt2 .

Suppose, hip and hiq are allocated to agent 1 at rounds kt2 and kt2 , respectively.

CLAIM 3. The following inequality holds: h1t 2 h1t 2 hip

2 hiq.

PROOF. Follows from Claim 2, kt1 < kt1 < . . . < kt2 < kt2 , and the fact that houses in BEST-ALLOC1 = BESTEURESPONSE are lexicographically ordered.

We schematically show an allocation in the relevant rounds in the following table. The top part of the table shows allocation at rounds kt1, kt1 , kt2 and kt2 . We use • to indicate that a house is allocated at a certain round but its label is not important for the proof.

Rounds

. . . kt1 . . . kt1 . . . kt2 kt2 + 1 . . . kt2 − 1 kt2 . . .

An allocation obtained from BESTEURESPONSEALGO

BEST-ALLOC1 BEST-ALLOC2

{. . . h1t . . . h1t . . . hip • . . . • hiq . . .} {. . . • . . . • . . . h2t his . . . hir h2t . . .}

New allocation

BEST-ALLOC1 ∪ {h2t } \ {h1t } {. . . h1t . . . h2t . . . h1p • . . . • h1q . . .} BEST-ALLOC2 ∪ {h1t } \ {h2t } {. . . • . . . • . . . his • . . . h1t h2t . . .}

Table III: A schematic representation of the proof of Claim 5

CLAIM 4. The following inequality holds:

V1h1t ≥ V1h1t . PROOF. Follows from Claim 1 and Proposition D.5.

Next we show that agent 1 can improve his outcome by deviating from BEST-ALLOC1 and obtain a contradiction to the assumption that BEST-ALLOC1 is a best response.
CLAIM 5. If agent 1 requests h2t instead of h1t at the kt1 round then agent 1 improves its outcome.

PROOF. First, we note that h2t is available for agent 1 at the kt1 round. Indeed, by our

assumption kt1 < kt2, hence, the house h2t is available to agent 1 at round kt1 . Second,

we show that even if agent 1 takes h2t instead of h1t at the kt1 th round, agent 1 can get

all houses BEST-ALLOC1 \ {h1t }. This shows that agent 1 improves his outcome.

From Claim 3, h1t

2 hip. From the structure of

CLONED
2

we

know

that

...

2 h1t

2

h2t

2

. . ..

Hence,

due

to

Lemma

D.6,

during

rounds

k

2 t

,

.

.

.

,

k

2 t

−

1,

the

top

houses

of

agent 2 are ranked higher than hip in his proﬁle. Also, the house h2t is not available

to agent 2 at the kt2 round. Hence, agent 2 is allocated the same houses in rounds

k

2 t

,

.

.

.

,

k

2 t

−

2

as

he

was

allocated

before

the

change

during

rounds

kt2

+

1

,

.

.

.

,

k

2 t

−

1

(see the second part of the table above).

Technical Report: January 2014.

Strategic aspects of the probabilistic serial rule

25

Consider the round kt2 − 1. As agent 1 was not allocated h1t at the kt1 th round, h1t is available for agent 2 at the kt2 −1-th round. Hence, agent 2 is allocated h1t at the kt2 −1th round and h2t at the kt2 th round. The remaining rounds are identical to allocation using BEST-ALLOC1. The new allocation of agent 1 is BEST-ALLOC1 ∪{h2t }\{h1t } which is strictly better than BEST-ALLOC1.

Claim 5 shows that agent 1 can improve his outcome and BESTEURESPONSE is not a best response. This leads to a contradiction.

We denote BEST-ALLOC−1 1(h2i ) the round when h2i is allocated.

Deﬁnition D.8. A pair BEST-ALLOC1 and BEST-ALLOC2 has the matching property if and only if for each pair of half-houses h1i and h2i such that h1i ∈ BEST-ALLOC1 and h2i ∈ BEST-ALLOC2, we have BEST-ALLOC−1 1(h1i ) = BEST-ALLOC−2 1(h2i ).

Example D.9. Consider BEST-ALLOC1

=

{h11, h15, h25, h13, h16, h26} and

BEST-ALLOC2 = {h21, h12, h22, h23, h14, h24}. These proﬁles have the matching prop-

erty as BEST-ALLOC−1 1(h11) = BEST-ALLOC−2 1(h21) and BEST-ALLOC−1 1(h13) =

BEST-ALLOC−2 1(h23).

Consider BEST-ALLOC1 = {h11, h13, h15, h25, h16, h26} and BEST-ALLOC2 =

{h21, h12, h22, h23, h14, h24}. These proﬁles do not have the matching property as

BEST-ALLOC−1 1(h13) = BEST-ALLOC−2 1(h23).

LEMMA D.10. For any BEST-ALLOC1 there exists BEST-ALLOC1 that has the consec-
utivity property and such the pair BEST-ALLOC1 and BEST-ALLOC2 has the matching
property. Moreover, the allocation obtained by agent 1 using BEST-ALLOC1 is the same as the allocation obtained using BEST-ALLOC1.

PROOF. We set BEST-ALLOC1 = BEST-ALLOC1. Note that BEST-ALLOC1 has the

consecutivity property as BEST-ALLOC1 does as by Proposition D.4 if a full-house of hi is allocated to 1(2) then h1i and h2i are allocated to 1(2) in two consecutive rounds.

Suppose, the pair BEST-ALLOC1 and BEST-ALLOC2 satisﬁes the statement up to

round kt1. As BEST-ALLOC1 has the consecutivity property, only the matching property can fail: h1t is allocated to agent 1 at the kt1 round and h2t is allocated to agent 2 at the kt2 round and kt1 < kt2.
We show that we can move h1t to round kt2 and move all houses allocated during

round

kt1

+

1

,

.

.

.

,

k

2 t

one

round

forward

in

BEST-ALLOC1.

These

shifts

preserve

the

same allocation for agent 1 and agent 2 and the consecutivity property.

By Lemma D.7 we know that none of the half-houses are allocated to agent 1 during

rounds kt1 + 1, . . . , kt2. Hence, only full houses are allocated between these rounds. This means that the number of rounds between kt1 + 1 and kt2 is even or 0.

We also observe that none of the half houses are allocated to agent 2 between rounds

kt1 + 1 and kt2 as h2t is the ﬁrst half-house allocated to agent 2 after round kt1. Moreover, agent 2 is not allocated houses greater than h2t during rounds kt1 + 1, . . . , kt2.
We move the house h1t to the position kt2 and shift all houses in positions kt1 + 1 and kt2 one round forward in BEST-ALLOC1. Note that we preserve consecutivity property

as all halves are moved together.

After

the

move,

agent

1

still

gets

the

same

houses

in

rounds

kt1

,

.

.

.

,

k

2 t

as

shifted

houses are allocated even in earlier rounds compared to BEST-ALLOC1 and agent 1 is allocated h1t in the same round as agent 2. Hence, allocations up to the round kt2 are

identical for BEST-ALLOC1 and BEST-ALLOC1 and both consecutivity and matching

properties hold.

Technical Report: January 2014.

26

H. Aziz et al.

We repeat the argument for the next half-house that violates the statement.

Example D.11. BEST-ALLOC1 = {h11, h13, h15, h25, h16, h26} and BEST-ALLOC2 = {h21, h12, h22, h23, h14, h24}. We do not need to move h11 as it is matched with h21. We move h13 to the fourth round so that it is allocated at the same round as h23.

Rounds

1 2345

6

An allocation obtained from BESTEURESPONSEALGO

BEST-ALLOC1 {h11, h13, h15, h25, h16, BEST-ALLOC2 {h21, h12, h22, h23, h14,

h26 } h24 }

New allocation with the matching property

BEST-ALLOC1 {h11, h15, h25, h13, h16, BEST-ALLOC2 {h21, h12, h22, h23, h14,

h26 } h24 }

Table IV: A schematic representation of Example D.11.

A proof of Lemma D.10 gives an correctness argument for lines 5–8 in Algorithm 2. In these lines we put half-houses allocated to agent 1 later in the ordering to ensure that the matching property holds, i.e. agents obtain half-houses in the same rounds.

LEMMA D.12. Consider BEST-ALLOC1 and BEST-ALLOC2 that satisfy consecutiv-

ity and matching properties. Then there exists a preference

CLONED-BEST 1

over

H CLONED

for agent 1 that has the consecutivity property and gives the same allocation as

BEST-ALLOC1.

PROOF. Given BEST-ALLOC1 that satisﬁes properties in the statement of the

lemma, we build a preference

CLONED-BEST 1

in

the

following

way.

We

keep

houses

as

they are ordered in BEST-ALLOC1. For each half-house h1i allocated to agent 1 we rank

h2i right after h1i . We put houses that are not allocated to agent 1 in an arbitrary order,

keeping halves together, at the end of the proﬁle. Note that inserting h2i after h1i does

not change the allocation as we know that h2i is allocated to agent 2 in the same round

as h1i is allocated to agent 1. Hence, h2i will never be the top element for agent 1 at any

round. Hence,

CLONED-BEST 1

gives

the

same

allocation

as

BEST-ALLOC1.

A proof of Lemma D.12 provides a correctness argument for lines 11– 9 in Algorithm 2.

In these lines we move half-houses obtained by agent 2 right after corresponding half-

houses obtained by agent 2.

By Lemma 5.4, given

CLONED-BEST 1

which

is

the

best

response

for

, CLONED
2

that

sat-

isﬁes the consecutivity property,

BEST
1

obtained

by

the

order-preserving

join

from

CLONED-BEST 1

is

the

best

response

for

2 using PS.

THEOREM D.13. For the case of two agents and the PS rule, a DL best response and an EU best response are equivalent.

PROOF. For two agents, PS assigns probabilities from the set {0, 1/2, 1}. Hence DL preferences can be represented by the EU preferences where the utility are exponential: the utility of a more preferred house is twice the utility of the next preferred house. Hence a response if a DL best response if it is an EU best response for exponential utilities. On the other we have shown that for two agents and the PS rule, an EU best response is the same for any utilities compatible with the preferences. Hence for two agents, an EU best response for any utilities is the same as the EU best response for exponential utilities which in turn is the same as a DL best response.

E. PROOF OF THEOREM ??
PROOF. Using a computer program we have found the following 15 step sequence which leads to a cycling of the preference proﬁle. We use U to denote the matrix of

Technical Report: January 2014.

Strategic aspects of the probabilistic serial rule

27

utilities of the agents over the items such that U [1][1] is the utility of agent 1 for house h1. We use P to represent the reported proﬁle of each agent, P [i][j] denotes the jth most preferred house of agent i. Note that P starts as the truthful reporting in our example. We use P S[i][j] to represent the fraction of house j that is eaten by agent i. We use EU [i] to be the expected utility of agent i. The initial preferences and utilities of the agents are

P0 =

h2 h3 h1 h4 h6 h5 h6 h5 h2 h1 h4 h3 h3 h6 h2 h1 h5 h4

354201
U0 = 2 3 0 1 4 5 . 235014

This yields the following allocation and utilities at the start

P0 =

h2 h3 h1 h4 h6 h5 h6 h5 h2 h1 h4 h3 h3 h6 h2 h1 h5 h4

P S0 =

1/2 1 0 1/2 0 0 0 0 0 1/4 3/4 1 1/2 0 1 1/4 1/4 0

7.5
EU0 = 8.25 . 6.25

In Step 1, agent 3 changes his report and improves his utility.

P1 =

h2 h3 h1 h4 h6 h5 h6 h5 h2 h1 h4 h3 h6 h3 h1 h2 h4 h5

P S1 =

5/12 1 1/4 1/3 0 0 1/6 0 0 1/3 1 1/2 5/12 0 3/4 1/3 0 1/2

7.9167
EU1 = 71667 . 6.5833

In Step 2, agent 1 changes his report in response.

P2 =

h3 h2 h1 h4 h5 h6 h6 h5 h2 h1 h4 h3 h6 h3 h1 h2 h4 h5

P S2 =

1/24 7/8 3/4 1/3 0 0 1/24 1/8 0 1/3 1 1/2 11/12 0 1/4 1/3 0 1/2

In Step 3, agent 3 again changes his report.

P3 =

h3 h2 h1 h4 h5 h6 h6 h5 h2 h1 h4 h3 h3 h6 h2 h1 h5 h4

P S3 =

1/2 5/8 1/2 3/8 0 0 0 0 0 5/16 15/16 3/4 1/2 3/8 1/2 5/16 1/16 1/4

In Step 4, agent 1 reacts again.

P4 =

h2 h1 h3 h4 h5 h6 h6 h5 h2 h1 h4 h3 h3 h6 h2 h1 h5 h4

P S4 =

1/2 1 0 1/2 0 0 0 0 0 1/4 3/4 1 1/2 0 1 1/4 1/4 0

8.1667 EU2 = 7.2917 .
5.0833
7.3750 EU3 = 7.8125 .
5.6875
7.500 EU4 = 8.250 .
6.250

In Step 5, agent 3 reacts again.

P5 =

h2 h1 h3 h4 h5 h6 h6 h5 h2 h1 h4 h3 h6 h2 h3 h1 h4 h5

P S5 =

7/8 3/4 1/16 5/16 0 0 1/8 0 0 3/8 1 1/2
0 1/4 15/16 5/16 0 1/2

In Step 6, agent 2 reacts.

P6 =

h2 h1 h3 h4 h5 h6 h6 h2 h1 h5 h3 h4 h6 h2 h3 h1 h4 h5

P S6 =

1/2 2/3 1/4 1/2 1/12 0 1/2 1/6 0 0 5/6 1/2
0 1/6 3/4 1/2 1/12 1/2

In Step 7, agent 3 reacts.

7.250 EU5 = 7.125 .
7.4375
6.833 EU6 = 7.333 .
6.333

Technical Report: January 2014.

28

H. Aziz et al.

P7 =

h2 h1 h3 h4 h5 h6 h6 h2 h1 h5 h3 h4 h6 h3 h1 h2 h5 h4

P S7 =

1/2 3/4 1/8 5/8 0 0 1/2 1/4 0 3/16 9/16 1/2 0 0 7/8 3/16 7/16 1/2

7.00
EU7 = 6.6875 . 6.8125

In Step 8, agent 1 changes his report.

P8 =

h2 h3 h1 h4 h5 h6 h6 h2 h1 h5 h3 h4 h6 h3 h1 h2 h5 h4

P S8 =

5/24 3/4 3/8 2/3 0 0 7/12 1/4 0 1/6 1/2 1/2 5/24 0 5/8 1/6 1/2 1/2

7.2083
EU8 = 6.5833 . 6.0417

In Step 9, agent 2 reacts.

P9 =

h2 h3 h1 h4 h5 h6 h6 h2 h5 h1 h3 h4 h6 h3 h1 h2 h5 h4

P S9 =

1/2 3/4 3/8 3/8 0 0 0 1/4 0 5/16 15/16 1/2 1/2 0 5/8 5/16 1/16 1/2

7.5
EU9 = 7.3125 . 6.1875

In Step 10, agent 3 reacts again.

P10 =

h2 h3 h1 h4 h5 h6 h6 h2 h5 h1 h3 h4 h3 h1 h2 h5 h4 h6

P S10 =

1/2 1 0 1/2 0 0 0 0 0 1/4 3/4 1 1/2 0 1 1/4 1/4 0

7.5
EU10 = 8.25 . 6.25

In Step 11, agent 2 reacts.

P11 =

h2 h3 h1 h4 h5 h6 h5 h2 h3 h6 h1 h4 h3 h1 h2 h5 h4 h6

P S11 =

1/2 1 0 1/2 0 0 0 00 0 11 1/2 0 1 1/2 0 0

7.5
EU11 = 9.0 . 6.0

In Step 12, agent 3 reacts.

P12 =

h2 h3 h1 h4 h5 h6 h5 h2 h3 h6 h1 h4 h3 h2 h5 h6 h1 h4

P S12 =

2/3 1 0 1/3 0 0 1/6 0 0 1/3 1 1/2 1/6 0 1 1/3 0 1/2

7.6667
EU12 = 7.1667 . 7.3333

In Step 13, agent 2 reacts.

P13 =

h2 h3 h1 h4 h5 h6 h6 h2 h3 h5 h1 h4 h3 h2 h5 h6 h1 h4

P S13 =

2/3 1 0 1/3 0 0 1/6 0 0 1/3 1/2 1 1/6 0 1 1/3 1/2 0

7.6667
EU13 = 7.6667 . 5.8333

In Step 14, agent 3 reacts again.

P14 =

h2 h3 h1 h4 h5 h6 h6 h2 h3 h5 h1 h4 h3 h1 h2 h5 h4 h6

P S14 =

1/2 1 0 1/2 0 0 0 0 0 1/4 3/4 1 1/2 0 1 1/4 1/4 0

7.5
EU14 = 8.25 . 6.25

In Step 15, agent 2 reacts once more to agent 3.

P15 =

h2 h3 h1 h4 h5 h6 h5 h2 h3 h6 h1 h4 h3 h1 h2 h5 h4 h6

P S15 =

1/2 1 0 1/2 0 0 0 00 0 11 1/2 0 1 1/2 0 0

7.5
EU15 = 9.0 . 6.0

This last step is the same proﬁle as step 11, which means we have cycled.

Technical Report: January 2014.

