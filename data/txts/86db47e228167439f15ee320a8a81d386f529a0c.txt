LEMON: Language-Based Environment Manipulation via Execution-Guided Pre-training
Qi Shi†∗ , Qian Liu♦∗, Bei Chen§, Yu Zhang†, Ting Liu†, Jian-Guang Lou§ †Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology, Harbin, China
♦Beihang University, Beijing, China; §Microsoft Research Asia, Beijing, China {qshi, zhangyu, tliu}@ir.hit.edu.cn
qian.liu@buaa.edu.cn; {bei.chen, jlou}@microsoft.com

arXiv:2201.08081v1 [cs.CL] 20 Jan 2022

Abstract
Language-based environment manipulation requires agents to manipulate the environment following natural language instructions, which is challenging due to the huge space of the environments. To address this challenge, various approaches have been proposed in recent work. Although these approaches work well for their intended environments, they are difﬁcult to generalize across environments. In this work, we propose LEMON, a general framework for language-based environment manipulation tasks. Speciﬁcally, we ﬁrst propose a uniﬁed approach to deal with various environments using the same generative language model. Then we propose an execution-guided pre-training strategy to inject prior knowledge of environments to the language model with a pure synthetic pre-training corpus. Experimental results on tasks including ALCHEMY, SCENE, TANGRAMS and PROPARA demonstrate the effectiveness of LEMON: it achieves new state-of-the-art results on ALCHEMY, SCENE and PROPARA, and the execution-guided pretraining strategy brings remarkable improvements on all experimental tasks.
1 Introduction
Building agents that can understand human language and accordingly manipulate the environment around them has been a long-standing goal of artiﬁcial intelligence (Winograd, 1971). By communicating with humans, these agents are expected to solve language-based environment manipulation (LEM) tasks, including collaborative building (Narayan-Chen et al., 2019), state tracking (Dalvi et al., 2018; Tandon et al., 2020) and instruction following (Andreas and Klein, 2015; Long et al., 2016; Suhr et al., 2019). Generally, these tasks are challenging due to the large exploration space of the environment itself and the complexity of
∗Work done during internship at Microsoft Research Asia.

Throw out first beaker. Pour sixth beaker into last one. It turns brown. Pour purple beaker into yellow one. Throw out two units of brown one.
Figure 1: An example from ALCHEMY (Long et al., 2016).
human-agent interactions. For example, in the environment shown in Figure 1, the agent needs to manipulate seven beakers with various colored liquid correctly according to the long instruction.
To address these challenges, recent work have proposed various specialized models to deal with different environments (Suhr and Artzi, 2018; Dalvi et al., 2018; Gupta and Durrett, 2019b; Tang et al., 2020). Although these models work well, they are difﬁcult to generalize across environments since they contain environment-speciﬁc modules. For example, Suhr and Artzi (2018) employ different encoder modules for different environments.
Different from previous work focusing on specialized models, we argue that with formulating LEM tasks as sequence generation problems, the family of generative language models (GLMs) such as BART (Lewis et al., 2020) can be an environment-generic agent for various environments. Taking advantage of GLMs, such a uniﬁed solution greatly reduces the difﬁculty of modeling LEM tasks. However, GLMs generally lack prior knowledge of downstream environments since they have not seen even similar ones during pre-training. To unleash the power of GLMs in downstream environments, we argue that GLMs should be continually pre-trained to understand these environments, and the pre-training should engage GLMs to ex-

Throw out last beaker. Pour fifth beaker into third one. Pour red
beaker into third one.

DRAIN(red(1), 1) ; ⋯ PERSON(purple, 1) ; ⋯
REMOVE(5) ; ⋯ MOVE(water, soil, leaf) ; ⋯

Figure 2: The illustration of the pre-training procedure of LEMON framework on ALCHEMY, SCENE, TANGRAMS, PROPARA (Left) and the ﬁne-tuning procedure of LEMON framework on ALCHEMY (Right).

plore as much of the environment space as possible. We believe if GLMs can understand the environment well, they will more easily manipulate the environment with respect to human language.
Inspired by the above, in this paper, we propose LEMON (for Language-based Environment Manipulation via ExecutiOn-guided Pre-traiNing), a general framework for LEM tasks, which consists of two parts: 1) A uniﬁed approach that uses the same protocol to tackle different LEM tasks. 2) An execution-guided pre-training strategy, which injects prior knowledge about environments into the GLM. For the ﬁrst part, we employ the popular BART (Lewis et al., 2020) as the model backbone, and take four representative tasks ALCHEMY, SCENE, TANGRAMS (Long et al., 2016) and PROPARA (Dalvi et al., 2018) as the testbed. For the pre-training part, it is to engage our model to explore the environment space. Considering that the environment space mainly consists of the state space (i.e., valid environment states) and the action space (i.e., possible actions to manipulate the environment), we suggest pre-training the model via synthesizing data involving these two spaces. Speciﬁcally, given an environment, we begin with randomly sampling its relevant initial states and programs 1, as shown in the left of Figure 2. With feeding the random initial state and the random program as input for LEMON, we leverage the goal state after executing the program as supervision for LEMON. Since the program execution is easy to carry out in symbolic environments 2,
1A program consists of a sequence of functions, of which each function is an action or a composition of actions.
2In this paper, we focus on symbolic environments instead of raw environments with only visual features. Compared to the latter, the former can be represented by semantic symbols,

our execution-guided pre-training is suitable for various symbolic environments. Meanwhile, since the random initial states and the programs can be sampled systematically, we can readily obtain a large-scale high-quality pre-training corpus without human labeling or data cleaning. To the best of our knowledge, LEMON is the ﬁrst work to explore pre-training in language-based environment manipulation. In summary, the main contributions of our framework LEMON are three-fold:
• We suggest a uniﬁed approach that can be tailored to various environments. By formulating LEM tasks as sequence generation problems, our approach leverages a generative language model to tackle them.
• We propose a novel execution-guided pretraining strategy, which can inject prior knowledge of environments by continually pretraining with only synthetic data.
• Experimental results on four tasks demonstrate that our uniﬁed approach is comparable or prior to previous systems, and our pretraining strategy further improves the performance by a signiﬁcant margin (e.g., +4.1% on ALCHEMY). Finally, our approach achieves new state-of-the-art results on ALCHEMY, SCENE and PROPARA.
2 LEMON Framework
We now discuss the LEMON framework (Figure 2) in more detail. Speciﬁcally, we introduce the uniﬁed approach for language-based environment ma-
and thus enjoys better controllability and interpretability. We leave exploration on raw environments for future work.

nipulation (§2.1) and the execution-guided pretraining (§2.2). As for LEMON instantiations for different tasks, we leave the descriptions to §3.
2.1 Uniﬁed Approach for LEM
As mentioned in §1, the existence of environmentspeciﬁc modules makes previous models difﬁcult to generalize across environments. To eliminate this issue, we propose a uniﬁed approach to tackle different environments.
Task Formulation An environment space consists of a state space and an action space. And a state can be further decomposed into a set of entities (e.g., beakers in ALCHEMY) and properties (e.g., colors in ALCHEMY). Generally, the goal of LEM tasks is to manipulate the environment state with natural language. Formally, given an initial environment state S0, the goal of LEM tasks is to predict the goal environment state S based on the human language instruction I. In most cases, the LEM task is performed in an interactive manner, which means that there would be a sequence of context-dependent instructions, rather than a single instruction. Again, given an initial environment state S0 and a sequence of natural language instructions I = (I1, I2, ..., IT ), where T stands for the total number of instructions in one conversation, the goal turns to predict the goal environment states at each step as S = (S1, S2, ..., ST ). In the following, we use the conversational formulation to illustrate.
Model Architecture With formulating LEM tasks as sequence generation problems, we leverage BART (Lewis et al., 2020), a powerful encoderdecoder language model, to generate the goal environment state token-by-token. Formally, at t-th step, the input to our model consists of three parts, namely the initial environment state S0, the current instruction It and the history (I1, I2, ..., It−1). Since we do not focus on context modeling, we directly concatenate (I1, I2, ..., It−1) and It to form It = (I1, I2, ..., It), which contains all historical instructions (Liu et al., 2020). The ﬁnal input to our model is the concatenation of S0 and It with a [SEP] token as a separator between them. The output of our model is the corresponding goal environment state St.
2.2 Execution-Guided Pre-training
We propose an execution-guided pre-training strategy to explore the environment space as much as

possible through synthetic data. In the following, we will introduce the pre-training task and the corpus generation in turn.
Pre-training Task As described in §1, to encourage the model to understand and explore the environment, LEMON adopts the program execution as the pre-training task. Formally, given a randomly sampled initial environment state S0 and a randomly sampled program A, the model is pretrained to predict the goal environment state S, as shown in Figure 2. Such a pre-training task fulﬁlls our expectations of both environment exploration and environment understanding, which can be explained from two aspects. From the input perspective, such a task involves all essential elements of an environment (i.e., state and action). Together with large-scale random sampling, it allows the model to fully explore the environment space. From the output perspective, such a task is challenging – the model must understand the environment to predict S correctly. Meanwhile, the program execution as a pre-training task is highly ﬂexible. As shown in Figure 2, it works well for four different tasks. In the implementation of pre-training, we ﬁrst concatenate S0 and A using the same [SEP] token as a separator and then feed the concatenated sequence into LEMON. The pre-training supervision, i.e., the goal environment state S, is obtained from a task-dependent executor. In LEM tasks, the executor is designed to interpret each task-dependent program and change the current environment state to another state accordingly. In practice, the executor can be easily implemented by a few heuristic rules, since the environments are symbolic.
Pre-training Corpus Generation Unlike most pre-training work that employs web crawling to collect pre-training corpus, we synthesize the pretraining corpus directly by randomly sampling the environment states and programs. Compared to human language, high-quality environment states and programs are easier to sample since they are highly structured. As introduced above, each pre-training example contains a sampled initial environment state, a sampled executable program, and a goal environment state obtained from the executor. One by one, the pre-training corpus can be generated by repeating the sampling process. Concretely, for the initial environment state sampling, it can be achieved by randomly selecting a valid value for

each property deﬁned in the corresponding environment. As for the program sampling, a valid program can be generated by randomly selecting a valid function and then randomly sampling from all suitable parameters of the selected function. The valid values for each property and function will be discussed later.
3 LEMON Instantiations
To demonstrate the capabilities of LEMON, we apply our framework on four exemplary tasks, namely, ALCHEMY, SCENE, TANGRAMS, and PROPARA. Examples of each task are shown in Figure 2, including visualizations of the initial environment state and the goal environment state, as well as a schematic representation of the program. In this section, for each task, we elaborate the deﬁnition of the environment and the applied program to instantiate LEMON.
3.1 ALCHEMY
Environment State Deﬁnition The environment state in ALCHEMY contains seven beakers, each containing up to four units of colored chemicals. Each environment state contains three properties, including beaker IDs (from 1 to 7), liquid colors (brown, green, orange, purple, red, and yellow), and liquid amounts (from 0 to 4). Figure 2 shows an example, and the example initial environment state can be represented as 1:r|2:o|3:r|4:g|5:y|6:oo|7:r in text, where different letters represent different colors. Note that if a beaker does not contain any liquid, it can be represented by . And | stands for the delimiter that splits the state of each beaker, which is also applicable for the following tasks.
Program Deﬁnition The action space of ALCHEMY contains three kinds of actions to manipulate the environment, namely, POUR, DRAIN and MIX. We use the program proposed by Guu et al. (2017), where the functions are the same as the actions deﬁned in the environment.
3.2 SCENE
Environment State Deﬁnition The environment state in SCENE contains ten positions, with up to one person in each position. A person is deﬁned by a shirt color and optionally a hat color. Formally, each environment state contains three properties, including position IDs (from 1 to 10), shirt colors (brown, green, orange, purple, red,

and yellow), and hat colors (the same as shirt colors). As shown in Figure 2, the example initial environment state can be represented as 1: |2:bp|3: |4:oy|5: (only ﬁve positions are shown in Figure 2 for brevity) in text, where the ﬁrst character in each position represents the shirt color and the second one represents the hat color. indicates either an empty position or a person without a hat. Note that the hat can only appear when the position is occupied.
Program Deﬁnition Four actions are deﬁned in the SCENE environment to manipulate the environment, namely, ENTER, LEAVE, MOVE and TRADEHATS. For the program, we use the one proposed by Suhr and Artzi (2018). The functions include PERSON, HAT, RMPERSON and RMHAT, which represent inserting / removing a person / hat in the state. The permutations of the deﬁned functions in the program are sufﬁcient to represent all actions deﬁned in the environment.
3.3 TANGRAMS
Environment State Deﬁnition The environment state in TANGRAMS contains a list of up to ﬁve unique objects. Similarly, the environment state can be represented by the object indexes (from 1 to 5) and the object names (A, B, C, D, and E). For example, the initial environment state in Figure 2 can be represented as 1:A|2:B|3:C|4:D|5:E. The same object cannot appear in one environment state. If the number of objects is less than 5, we ﬁll the sequence with to make it 5 in length.
Program Deﬁnition Three actions are involved to manipulate the TANGRAMS environment, namely, ADD, REMOVE and SWAP. And we use the program proposed by Suhr and Artzi (2018), which deﬁnes the functions including INSERT and REMOVE. Similar to the two kinds of programs mentioned above, permuting these two functions can achieve the goal of representing all actions deﬁned in the environment.
3.4 PROPARA
Environment State Deﬁnition The PROPARA environment describes real-world scientiﬁc processes such as photosynthesis, erosion, etc. Each environment state in PROPARA contains a set of entity participants and their corresponding locations, and the locations vary with the natural language procedural text being described. Unlike the three environments mentioned above, the properties of

Models
(Fried et al., 2018) (Huang et al., 2019) (Yeh and Chen, 2019)
(Long et al., 2016) (Guu et al., 2017) (Suhr and Artzi, 2018) w. REINFORCE (Suhr and Artzi, 2018) w. HEURISTIC LEMON
w.o. execution-guided pre-training

ALCHEMY

Inst 3utts 5utts Inst

Fully Supervised Approaches

–

– 72.0 –

–

– 76.4 –

–

– 76.1 –

Weakly Supervised Approaches

– 56.8 52.3 –

– 66.9 52.9 –

89.1 74.2 62.7 87.1

89.4 73.3 62.3 88.8

97.1 85.3 75.4 92.7 96.9 84.0 71.3 91.6

SCENE
3utts
– – –
23.2 64.8 73.9 78.9
85.8 83.1

5utts
72.7 74.5 75.1
14.7 46.2 62.0 66.4
72.3 68.9

TANGRAMS Inst 3utts 5utts

– – –
– – 86.6 86.6
92.3 92.8

– – –
64.9 65.8 80.8 81.4
82.4 83.4

69.6 72.3 72.5
27.6 37.1 62.4 60.1
60.0 56.7

Table 1: Experimental results on the test set of ALCHEMY, SCENE and TANGRAMS. Fully supervised approaches (in grey background) are the approaches that use annotated programs as labels, while weakly supervised approaches are the approaches that no golden program is provided. Although the comparisons are not fair, we report the results of fully supervised approaches for reference. Note that our ablation w.o. execution-guided pre-training is identical to ﬁne-tuning BART on the downstream task, and the same for Table 2.

an environment state in PROPARA are not ﬁxed, but are dynamically constructed from the natural language text. Figure 2 shows an example, where the initial state stands for participants water, light, carbon are located in locations soil, sun, cloud respectively. The environment state in PROPARA can be naturally represented in key-value format. For example, the initial state in Figure 2 can be represented as ent:water|light|carbon loc:soil|sun|cloud, here ent: and loc: are special tokens that indicate the boundaries of entity participants and locations, respectively.
Program Deﬁnition In the PROPARA environment, the procedural text describes four actions, namely, CREATE, MOVE, DESTROY and NONE. In practice, we use the program proposed by Dalvi et al. (2019), in which the functions also contain CREATE, MOVE and DESTROY, which are aligned with the action space of PROPARA.
4 Experiments
In this section, we compare LEMON with baseline methods on the tasks discussed in §3 to demonstrate its effectiveness. Due to space limitation, we do not introduce these baselines below. We refer readers to their papers for more details.
4.1 Data and Evaluation
ALCHEMY, SCENE & TANGRAMS These three tasks are introduced with different environments in the SCONE corpus (Long et al., 2016). Each human-agent interaction has 5 instructions. Following Long et al. (2016), we evaluate LEMON

with denotation accuracy. In addition, the evaluation metrics can be divided into the denotation accuracy of a single instruction (Inst), of the ﬁrst three instructions (3utts), and of the complete interactions (5utts).
PROPARA The task is introduced in the procedural text understanding dataset (Dalvi et al., 2018), and is designed to track entity states through natural language paragraphs. The evaluation metrics are composed of two levels: the sentence-level and the document-level. The sentence-level evaluates the model based on its prediction for the following three questions: Is entity Created, Moved or Destroyed in the process? When is entity Created, Moved or Destroyed? Where is entity Created, Moved or Destroyed? The sentence-level metrics include the accuracy of the above questions (Cat-1, Cat-2, Cat-3), and their micro / macro-average. The document-level evaluates the model based on its prediction on four document-level questions: What are the inputs? What are the outputs? What are the conversions? What are the moves? The documentlevel metrics report the average precision, recall, and F1 score of the four questions.
4.2 Experimental Setup
We use BART-Large in fairseq (Ott et al., 2019) to implement LEMON. During pre-training, we synthesize 1 million pre-training examples for each experimental task. The learning rate is set to 3×10−5 in all experiments of pre-training and ﬁne-tuning. As for other hyperparameters, we use ALCHEMY as a representative for ALCHEMY, SCENE and TANGRAMS below, since all hyperparameters on these

Models

EntNet (Henaff et al., 2017) QRN (Seo et al., 2017) ProLocal (Dalvi et al., 2018) ProGlobal (Dalvi et al., 2018) AQA (Ribeiro et al., 2019) ProStruct (Tandon et al., 2018) XPAD (Dalvi et al., 2019) LACE (Du et al., 2019) KG-MRC (Das et al., 2019) ProGraph (Zhong et al., 2020) IEN (Tang et al., 2020) NCET (Gupta and Durrett, 2019b) ETBERT (Gupta and Durrett, 2019a) DYNAPRO (Amini et al., 2020) TSLM (Rajaby Faghihi and Kordjamshidi, KOALA (Zhang et al., 2021)

2021)

LEMON w.o. execution-guided pre-training

Cat-1
51.6 52.4 62.7 63.0 61.6
– – – 62.9 67.8 71.8 73.7 73.6 72.4 78.8 78.5
81.7 78.8

Sentence-Level

Cat-2 Cat-3 Macro-Avg

18.8 7.8

26.1

15.5 10.9 26.3

30.5 10.4 34.5

36.4 35.9 45.1

40.1 18.6 39.4

–

–

–

–

–

–

–

–

–

40.0 38.2 47.0

44.6 41.8 51.4

47.6 40.5 53.3

47.1 41.0 53.9

52.6 –

–

49.3 44.5 55.4

56.8 40.9 58.8

53.3 41.3 57.7

58.3 43.3 57.2 42.9

61.1 59.6

Micro-Avg
26.0 26.5 34.0 45.4 40.1
– – – 46.6 51.5 53.0 54.0 – 55.5 58.4 57.5
60.7 59.2

Document-Level

Precision Recall

F1

54.7 60.9 81.7 61.7 62.0 74.3 70.5 75.3 69.3 67.3 69.8 67.1
– 75.2 68.4 77.7

30.7 39.4

31.1 41.1

36.8 50.7

48.8 51.9

45.1 52.3

43.0 54.5

45.3 55.2

45.4 56.6

49.3 57.6

55.8 61.0

56.3 62.3

58.5 62.5

–

–

58.0 65.5

68.9 68.6

64.4 70.4

74.8 69.8 72.2 69.9 68.1 69.0

Table 2: Experimental results of our method LEMON and baselines on the test set of PROPARA.

tasks are the same. During pre-training, the maximum training step is set to 10, 000 for ALCHEMY and 2, 000 for PROPARA, while the batch size is set to around 1, 000 for all tasks. During ﬁne-tuning, the maximum training step is set to 10, 000 for all tasks, while the batch size is set to 64 and 32 for ALCHEMY and PROPARA respectively.
4.3 Experimental Results
ALCHEMY & SCENE From Table 1, we can observe that LEMON outperforms previous bestperforming systems under weak supervision on both ALCHEMY and SCENE, with signiﬁcant improvements of 13.1% and 5.9% in the 5utts denotation accuracy, respectively. Notably, LEMON not only achieves new state-of-the-art performance among weakly supervised approaches, but also comes close to the performance of fully supervised approaches that leverage extra annotated programs. Moreover, the results also show that the execution-guided pre-training brings signiﬁcant improvements (e.g., 4.1% of ALCHEMY in the 5utts denotation accuracy), which demonstrates that our pre-training strategy provides considerable prior knowledge for LEMON to understand environments in advance.
TANGRAMS Similarly, the results on TANGRAMS in Table 1 show that our execution-guided pre-training strategy improves LEMON by 3.3% in the 5utts denotation accuracy, further illustrating the effectiveness of our approach. Nevertheless, LEMON does not perform as well compared to previous state-of-the-art method (Suhr and Artzi,

2018). We suppose this is because Suhr and Artzi (2018) carefully model the historical instructions, while LEMON directly concatenates them. We leave the ﬁne-grained context modeling of our approach for future work.
PROPARA Table 2 summarizes the results of the PROPARA task, in which LEMON achieves new state-of-the-art performance based on both the sentence-level and the document-level evaluation. On the sentence-level evaluation, LEMON shows stable improvements in most metrics compared to both previous approaches and LEMON w.o. execution-guided pre-training, which demonstrates that LEMON achieves an overall improvement in the understanding of procedural texts with respect to the environment. On the documentlevel evaluation, LEMON achieves an F1 score of 72.2%, which is 1.8% higher than the previous best-performing system KOALA (Zhang et al., 2021). Note the improvement is highly non-trivial since KOALA leverages external knowledge, which indicates that the prior knowledge LEMON learns during pre-training is more effective than external knowledge. Similarly, the execution-guided pretraining brings a 3.2% improvement, which again demonstrates that the pre-training in LEMON can signiﬁcantly facilitate the interaction procedure between natural language and environments.
4.4 Model Analysis
The Scale of Pre-training Corpus Previous work (Lewis et al., 2020) has shown that the scale of the pre-training corpus is an important factor

5utts Denotation Accuracy (%) F1 Score (%)

73 80

72

75

Alchemy

Scene

70

Tangrams 71

ProPara

65

70

60 0

69

0.1

0.5

1.0

2.0

Amount of Pre-training Corpus (Millions)

Figure 3: The performance of downstream tasks with respect to the pre-training corpus size. Following the evaluation setup, we plot the 5utts denotation accuracy on ALCHEMY, SCENE and TANGRAMS, while we plot the F1 score on PROPARA.

in pre-training, and thus we analyze the effect of our pre-training scale on downstream tasks. Figure 3 shows the performance of downstream tasks with respect to the size of the pre-training corpus, which are obtained from the development set of each task. As seen, the performance of the model generally improves by scaling up the pre-training corpus, consistent with previous observations on pre-training (Liu et al., 2021). Notably, the optimal size of the pre-training corpus varies with the downstream task.
Case Study Figure 4 shows two cases in ALCHEMY and SCENE, providing a more intuitive view of the role played by the execution-guided pre-training in LEMON. We display the initial environment states, the natural language instructions, and the goal environment states predicted with / without applying the execution-guided pretraining strategy, respectively. In the ﬁrst case (a), when pouring yellow liquid from the 5-th beaker into the 3-th beaker, the latter receives red liquid, which is clearly an inconsistent change. However, with pre-training, LEMON can predict the correct goal environment state via deeply understanding the actions conveyed by natural language. Similarly, in the second case (b), when swapping the hats in the last step, the model does not understand the TRADE-HAT action correctly, while it can be well understood to generate the goal state after pretraining. The above two cases indicate that the execution-guided pre-training strategy is able to inject prior knowledge of environments into LEMON and beneﬁt the downstream tasks.
5 Related Work
LEMON focuses on improving the performance of LEM tasks via execution-guided pre-training,

Throw out last beaker. Pour fifth beaker into third one. Pour red beaker into third one.
A person with a green shirt appears to the right of the person with a green shirt and
yellow hat. They trade hats.
Figure 4: Two cases of LEMON and LEMON w.o. pretraining in ALCHEMY and SCENE. The predictions of LEMON are more consistent with the semantics of the natural language instruction.
and thus our work is closely related to previous work which either target on LEM tasks or leverage program execution in their methods.
The ﬁrst line of our related work is the previous work on LEM tasks. According to the output, existing methods on LEM tasks can be mainly divided into two categories: program prediction and state prediction. Prior work always treat the LEM task as a program prediction problem (Long et al., 2016; Guu et al., 2017; Suhr and Artzi, 2018; Fried et al., 2018; Huang et al., 2019; Yeh and Chen, 2019; Dalvi et al., 2019). Speciﬁcally, they ﬁrst predict the program based on the initial environment state and the natural language instructions, and then execute the program to obtain the goal environment state consequently. However, these approaches have two shortcomings. First, they are environment-dependent and cannot be easily adapted to other environments. Second, they either rely on natural language-program pairs as supervision or require complex heuristic rules, which is costly. Recent approaches generally treat the LEM task as a state prediction problem by predicting the goal state directly (Dalvi et al., 2018; Du et al., 2019; Das et al., 2019; Tang et al., 2020; Rajaby Faghihi and Kordjamshidi, 2021; Zhang et al., 2021). These models can eliminate the data collection issue, but design complex models to encode environment states instead, to meet the need of different kinds of environments. Compared with the above work, LEMON has the following advantages: 1) The proposed uniﬁed approach does not require additional annotations and is easy to generalize across different environments. 2) The proposed execution-guided pre-training strategy can further improve the model performance with synthetic data only.

The second line of our related work is the execution-guided work, of which the most related work are ProTo (Zhao et al., 2021) and TAPEX (Liu et al., 2021). ProTo learns to execute given programs on the observed task speciﬁcations, which focuses on following a given program to perform the corresponding task. Different from ProTo, LEMON focuses on pre-training with program execution to enhance the downstream performance. Following a similar idea, TAPEX (Liu et al., 2021) improves the table pre-training by learning SQL execution over tables. Compared to TAPEX, LEMON enables us to systematically design the pre-training task and synthesize pre-training corpus based on environment properties, and makes it more generalizable to different environments.
6 Conclusion & Future Work
In this work, we propose LEMON, a general framework for language-based environment manipulation tasks that not only models different environments using the same protocol, but also injects prior knowledge of environments into our model. LEMON contains a uniﬁed approach and an execution-guided pre-training strategy. Speciﬁcally, the uniﬁed approach formulates the LEM task as a sequence generation task, which can be ﬂexibly applied to different environments. In addition, the execution-guided pre-training strategy injects prior knowledge into the model by synthesizing a large amount of data to simulate exploration in the environment, thus improving the downstream performance in different environments. Experimental results on four tasks demonstrate the effectiveness of LEMON: the execution-guided pre-training strategy brings signiﬁcant improvements on all of them and LEMON achieves the state-of-the-art performance on three of them. For future work, we hope to extend our approach to more complex environments and tasks such as image editing (Fu et al., 2020) and text editing (Faltings et al., 2021).
References
Aida Amini, Antoine Bosselut, Bhavana Dalvi Mishra, Yejin Choi, and Hannaneh Hajishirzi. 2020. Procedural reading comprehension with attribute-aware context ﬂow. In Conference on Automated Knowledge Base Construction, AKBC 2020, Virtual, June 22-24, 2020.
Jacob Andreas and Dan Klein. 2015. Alignment-based compositional semantics for instruction following.

In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1165–1174, Lisbon, Portugal. Association for Computational Linguistics.
Bhavana Dalvi, Lifu Huang, Niket Tandon, Wen-tau Yih, and Peter Clark. 2018. Tracking state changes in procedural text: a challenge dataset and models for process paragraph comprehension. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1595–1604, New Orleans, Louisiana. Association for Computational Linguistics.
Bhavana Dalvi, Niket Tandon, Antoine Bosselut, Wentau Yih, and Peter Clark. 2019. Everything happens for a reason: Discovering the purpose of actions in procedural text. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 4496–4505, Hong Kong, China. Association for Computational Linguistics.
Rajarshi Das, Tsendsuren Munkhdalai, Xingdi Yuan, Adam Trischler, and Andrew McCallum. 2019. Building dynamic knowledge graphs from text using machine reading comprehension. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net.
Xinya Du, Bhavana Dalvi, Niket Tandon, Antoine Bosselut, Wen-tau Yih, Peter Clark, and Claire Cardie. 2019. Be consistent! improving procedural text comprehension using label consistency. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 2347–2356, Minneapolis, Minnesota. Association for Computational Linguistics.
Felix Faltings, Michel Galley, Gerold Hintz, Chris Brockett, Chris Quirk, Jianfeng Gao, and Bill Dolan. 2021. Text editing by command. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 5259–5274, Online. Association for Computational Linguistics.
Daniel Fried, Jacob Andreas, and Dan Klein. 2018. Uniﬁed pragmatic models for generating and following instructions. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1951–1963, New Orleans, Louisiana. Association for Computational Linguistics.
Tsu-Jui Fu, Xin Wang, Scott Grafton, Miguel Eckstein, and William Yang Wang. 2020. SSCR: Iterative language-based image editing via self-supervised

counterfactual reasoning. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 4413–4422, Online. Association for Computational Linguistics.
Aditya Gupta and Greg Durrett. 2019a. Effective use of transformer networks for entity tracking. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 759– 769, Hong Kong, China. Association for Computational Linguistics.
Aditya Gupta and Greg Durrett. 2019b. Tracking discrete and continuous entity state for process understanding. In Proceedings of the Third Workshop on Structured Prediction for NLP, pages 7–12, Minneapolis, Minnesota. Association for Computational Linguistics.
Kelvin Guu, Panupong Pasupat, Evan Liu, and Percy Liang. 2017. From language to programs: Bridging reinforcement learning and maximum marginal likelihood. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1051–1062, Vancouver, Canada. Association for Computational Linguistics.
Mikael Henaff, Jason Weston, Arthur Szlam, Antoine Bordes, and Yann LeCun. 2017. Tracking the world state with recurrent entity networks. In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net.
Hsin-Yuan Huang, Eunsol Choi, and Wen-tau Yih. 2019. Flowqa: Grasping ﬂow in history for conversational machine comprehension. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net.
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7871–7880, Online. Association for Computational Linguistics.
Qian Liu, Bei Chen, Jiaqi Guo, Jian-Guang Lou, Bin Zhou, and Dongmei Zhang. 2020. How far are we from effective context modeling? an exploratory study on semantic parsing in context. In Proceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence, IJCAI 2020, pages 3580–3586. ijcai.org.
Qian Liu, Bei Chen, Jiaqi Guo, Morteza Ziyadi, Zeqi Lin, Weizhu Chen, and Jian-Guang Lou. 2021. TAPEX: table pre-training via learning a neural SQL executor. CoRR, abs/2107.07653.

Reginald Long, Panupong Pasupat, and Percy Liang. 2016. Simpler context-dependent logical forms via model projections. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1456– 1465, Berlin, Germany. Association for Computational Linguistics.
Anjali Narayan-Chen, Prashant Jayannavar, and Julia Hockenmaier. 2019. Collaborative dialogue in Minecraft. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5405–5415, Florence, Italy. Association for Computational Linguistics.
Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, and Michael Auli. 2019. fairseq: A fast, extensible toolkit for sequence modeling. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations), pages 48–53, Minneapolis, Minnesota. Association for Computational Linguistics.
Hossein Rajaby Faghihi and Parisa Kordjamshidi. 2021. Time-stamped language model: Teaching language models to understand the ﬂow of events. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 4560–4570, Online. Association for Computational Linguistics.
Danilo Ribeiro, Thomas Hinrichs, Maxwell Crouse, Kenneth Forbus, Maria Chang, and Michael Witbrock. 2019. Predicting state changes in procedural text using analogical question answering. In Proc. of ACS.
Min Joon Seo, Sewon Min, Ali Farhadi, and Hannaneh Hajishirzi. 2017. Query-reduction networks for question answering. In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net.
Alane Suhr and Yoav Artzi. 2018. Situated mapping of sequential instructions to actions with single-step reward observation. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2072– 2082, Melbourne, Australia. Association for Computational Linguistics.
Alane Suhr, Claudia Yan, Jack Schluger, Stanley Yu, Hadi Khader, Marwa Mouallem, Iris Zhang, and Yoav Artzi. 2019. Executing instructions in situated collaborative interactions. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2119–2130, Hong Kong, China. Association for Computational Linguistics.
Niket Tandon, Bhavana Dalvi, Joel Grus, Wen-tau Yih, Antoine Bosselut, and Peter Clark. 2018. Reasoning

about actions and state changes by injecting commonsense knowledge. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 57–66, Brussels, Belgium. Association for Computational Linguistics.
Niket Tandon, Keisuke Sakaguchi, Bhavana Dalvi, Dheeraj Rajagopal, Peter Clark, Michal Guerquin, Kyle Richardson, and Eduard Hovy. 2020. A dataset for tracking entities in open domain procedural text. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6408–6417, Online. Association for Computational Linguistics.
Jizhi Tang, Yansong Feng, and Dongyan Zhao. 2020. Understanding procedural text using interactive entity networks. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 7281–7290, Online. Association for Computational Linguistics.
Terry Winograd. 1971. Procedures as a representation for data in a computer program for understanding natural language. Technical report.
Yi-Ting Yeh and Yun-Nung Chen. 2019. Flowdelta: Modeling ﬂow information gain in reasoning for conversational machine comprehension. In Proceedings of the 2nd Workshop on Machine Reading for Question Answering, MRQA@EMNLP 2019, Hong Kong, China, November 4, 2019, pages 86–90. Association for Computational Linguistics.
Zhihan Zhang, Xiubo Geng, Tao Qin, Yunfang Wu, and Daxin Jiang. 2021. Knowledge-aware procedural text understanding with multi-stage training. In WWW ’21: The Web Conference 2021, Virtual Event / Ljubljana, Slovenia, April 19-23, 2021, pages 3512–3523. ACM / IW3C2.
Zelin Zhao, Karan Samel, Binghong Chen, and Le Song. 2021. Proto: Program-guided transformer for program-guided tasks. CoRR, abs/2110.00804.
Wanjun Zhong, Duyu Tang, Nan Duan, Ming Zhou, Jiahai Wang, and Jian Yin. 2020. A heterogeneous graph with factual, temporal and logical knowledge for question answering over dynamic contexts. CoRR, abs/2004.12057.

