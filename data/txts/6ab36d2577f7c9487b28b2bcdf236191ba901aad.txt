End-to-End Learning of Flowchart Grounded Task-Oriented Dialogs
Dinesh Raghu ∗ † 1 2, Shantanu Agarwal ∗ 1, Sachindra Joshi 2 and Mausam 1 1 Indian Institute of Technology, New Delhi, India 2 IBM Research, New Delhi, India
diraghu1@in.ibm.com, a.shantanu08@gmail.com, jsachind@in.ibm.com, mausam@cse.iitd.ac.in
Post-EMNLP Version: Contains Results on the New Hidden Test Set

arXiv:2109.07263v2 [cs.CL] 7 Dec 2021

Abstract
We propose a novel problem within end-toend learning of task oriented dialogs (TOD), in which the dialog system mimics a troubleshooting agent who helps a user by diagnosing their problem (e.g., car not starting). Such dialogs are grounded in domain-speciﬁc ﬂowcharts, which the agent is supposed to follow during the conversation. Our task exposes novel technical challenges for neural TOD, such as grounding an utterance to the ﬂowchart without explicit annotation, referring to additional manual pages when user asks a clariﬁcation question, and ability to follow unseen ﬂowcharts at test time. We release a dataset (FLODIAL) consisting of 2,738 dialogs grounded on 12 different troubleshooting ﬂowcharts. We also design a neural model, FLONET, which uses a retrieval-augmented generation architecture to train the dialog agent. Our experiments ﬁnd that FLONET can do zero-shot transfer to unseen ﬂowcharts, and sets a strong baseline for future research.
1 Introduction
Task oriented dialog (TOD) systems (Bordes and Weston, 2017) converse with users to help them with speciﬁc tasks such as calendar enquiry (Eric et al., 2017), restaurant reservation (Henderson et al., 2014), and tourist package recommendation (El Asri et al., 2017). These dialog systems (e.g., restaurant reservation system) are trained using past human-to-human dialogs and associated knowledge sources (e.g., a KB of restaurants).
Most existing TOD systems are conversational recommender systems that gather user requirements in the form of attributes (such as cuisine, location), query a KB and generate recommendations based on the retrieved results (e.g, restaurant, its phone number). While there have been recent
*D. Raghu and S.Agarwal contributed equally to this work. †D. Raghu is an employee at IBM Research. This work was carried out as part of PhD research at IIT Delhi.

Utterance Type
[T1] Problem Description [T2] Grounded on Flowchart [T3] Grounded on Supplementary Knowledge [T4] Chit-Chat [T5] Conversation Markers [T6] Hold Request [T7] Reconﬁrmation [T8] Dialog Closing

%
6.09 56.76 15.23
5.23 7.62 2.38 0.95 5.71

Table 1: Type of utterances and their proportions in a real-world troubleshooting dialog dataset.

efforts (Feng et al., 2020; Kim et al., 2020) to study non-recommendation TOD, several important tasks such as troubleshooting are still unexplored.
Troubleshooting is a common task handled by customer support agents. It involves understanding a user’s problem, narrowing down the root cause and providing a solution. Figure 1 shows an example dialog between an agent and a user troubleshooting a car problem. Support agents typically follow a ﬂowchart (utterances A1, A4 in our example) to diagnose user problems, but may refer to supplementary knowledge sources like FAQs (A3), if user asks a clariﬁcation question (U3).
In this paper, we propose the novel task of endto-end learning of a TOD system that troubleshoots user’s problems by using a ﬂowchart and a corpus of FAQs. Our task exposes novel research challenges for TOD system design. First, the system must learn to ground each utterance in the ﬂowchart without explicit supervision. Second, when required, the agent must refer to additional knowledge in the corpus of FAQs to issue clariﬁcations and add details not present in the ﬂowchart. Third, it must learn the general skill of following a ﬂowchart, which is tested in a zero-shot transfer setting with unseen ﬂowcharts shown at test time.
Before collecting a dataset for the task, we ﬁrst analyze a sample of 100 in-house troubleshooting dialogs with a human customer service agent. Table

……
Car won’t start flowchart
Support documents (FAQs) (a) Knowledge sources

no
N2 Starter spins?

N1 Starter cranks?
no
N3 Battery read over 12V?
N4 no Jump start the
car

Q: How to measure the car battery voltage? A: Using voltmeter
Q: How to use voltmeter to measure the battery voltage? A: To take a measurement, you have to touch the negative probe …
(b) Knowledge used

My Acura ILX is not starting. When I turn the key, the starter doesn't spin. This happened yesterday too and I missed an U1 important appointment
Does the voltage of your car battery read more than 12? A1
How do I check the car battery voltage? U2
You can check the car battery voltage using a voltmeter A2
How do I read battery voltage using a voltmeter? U3
In order to get a measurement, touch the black negative probe of the voltmeter to the battery's black … A3
The battery does not read more than 12. U4
Your battery is dead (for now). Find someone to help you jump start your car. This should be a quick fix.
A4
I have a friend who can help with that. Thanks for the tip. U5
I'm glad to be of help. Have a good day! A5
(c) Example dialog grounded on flowchart and support documents

Figure 1: Example ﬂowchart grounded TOD. It is grounded on two knowledge sources: ﬂowchart and FAQs.

1 summarizes the statistics on common utterances in such conversations. This analysis reafﬁrms the importance of supplementary knowledge (T3).
We crowdsource the ﬁrst version of our dataset, FLODIAL3 (Flowchart Grounded Dialogs), with these utterance types: problem description (T1), ﬂowchart following (T2), use of supplementary knowledge in the form of FAQs (T3), and closing utterances (T8). FLODIAL has 2,738 dialogs grounded on 12 different ﬂowcharts.
Since this is a new task, existing end-to-end TOD models are not directly applicable to it. We design a baseline network named FLONET4 – it follows the retrieval augmented generation framework (Lewis et al., 2020) and generates agent response in two steps. First, relevant information from the ﬂowchart and FAQ corpus is retrieved based on the dialog history. Then, this retrieved information and dialog history generate the agent response using an encoder-decoder. We evaluate FLONET in two different settings: (1) Seen Flowcharts (S-Flo) setting, tested on ﬂowcharts seen at train time, and (2) Unseen Flowcharts (U-Flo) setting, to evaluate FLONET’s zero-shot transfer ability in handling new ﬂowcharts unseen at train time. To summarize, the main contributions of this paper are:
1. We propose the novel problem of end-to-end learning of ﬂowchart grounded task oriented dialog.
2. We collect a new ﬂowchart grounded task-
3https://dair-iitd.github.io/FloDial 4https://github.com/dair-iitd/FloNet

oriented dialog (FLODIAL) dataset. 3. We propose a baseline solution (FLONET) for
the proposed problem and evaluate it in seen ﬂowchart and unseen ﬂowchart settings. We release all our resources for further research on the task.
2 Related Work
Dialog systems can be broadly divided into two types: task oriented (TOD) (Williams and Young, 2007; Bordes and Weston, 2017) and open domain dialog systems (Vinyals and Le, 2015; Serban et al., 2016). Task oriented dialogs systems can further be divided into end-to-end (Bordes and Weston, 2017; Raghu et al., 2019, 2021; Gangi Reddy et al., 2019) and traditional slot ﬁlling approaches (Williams and Young, 2007). Slot ﬁlling approaches require dialog state annotations in dialog transcripts. Our work falls under end-to-end approaches, which do not require any such intermediate annotations. We ﬁrst brieﬂy discuss existing TOD datasets and then review approaches for collecting dialog datasets. Finally, we discuss dialog systems related to FLONET. Dialog Datasets: Exisiting TOD datasets can be grouped based on the type of knowledge source on which the dialogs are grounded. Most of the existing datasets are for the recommendation task and grounded on structured KBs. Some notable KBgrounded datasets are MultiWOZ (Budzianowski et al., 2018), Stanford multi domain dataset (Eric et al., 2017), CamRest (Wen et al., 2016), Frames

(El Asri et al., 2017), schema guided dialogs (Rastogi et al., 2020) and taskmaster-1 (Byrne et al., 2019). Kim et al. (2020) augment MultiWOZ with utterances grounded on FAQs. The dialogs in datasets such as ShARC (Saeidi et al., 2018) and doc2dial (Feng et al., 2020) are grounded on snippets from unstructured text documents. To the best of our knowledge, FLODIAL is the ﬁrst TOD dataset that is grounded on ﬂowcharts and FAQs. Dialog Data Collection: Crowd sourcing frameworks for creating dialog datasets can be broadly grouped into three types. (1) Wizard-of-Oz framework (Kelley, 1984) pairs up two crowd-workers who play the roles of user and agent while conversing. The user is provided with a goal and the agent is given the knowledge necessary to achieve the goal. (2) Self-dialogs framework (Byrne et al., 2019) requires a single crowd-worker to write the entire dialog by playing both user and agent. (3) Dialog paraphrasing framework (Shah et al., 2018) systematically generates a dialog outline (user and agent utterance) and crowdsources paraphrases for each utterance to construct a dialog. We follow this framework for collecting FLODIAL, as it gives us adequate control over dialog ﬂow so that we can incorporate various utterance types in Table 1. Dialog Systems: Large scale pre-trained language models such as GPT2 (Radford et al., 2019) have been used for response generation in both open domain (Wolf et al., 2019; Zhang et al., 2020; Zhao et al., 2020) and TOD systems (Ham et al., 2020; Hosseini-Asl et al., 2020). A major challenge is GPT2’s limitation on the input size. For our setting, it becomes difﬁcult to feed a long input (ﬂowchart, dialog history, FAQ corpus) to GPT2. We overcome this by following the retrieval augment generation paradigm (Lewis et al., 2020) – we are probably the ﬁrst to apply it to a dialog setting.
The task of zero-shot response generation requires a model to generalize to new domains with just domain descriptors and no training dialogs. Existing approaches (Zhao and Eskenazi, 2018; Wu et al., 2019; Rastogi et al., 2020) model slots and intents as domain descriptors. We model ﬂowcharts as domain descriptors and expect the system to generalize to new ﬂowcharts unseen during train.
3 The FLODIAL Dataset
FLODIAL is a corpus of troubleshooting dialogs between a user and an agent collected using Amazon Mechanical Turk (AMT). The dataset is accompa-

nied with two knowledge sources over which the dialogs are grounded: (1) a set of troubleshooting ﬂowcharts and (2) a set of FAQs which contains supplementary information about the domain not present in the ﬂowchart – both are in English.
The data collection process uses the dialog paraphrasing framework (Shah et al., 2018) and is illustrated in Figure 2. At a high level, we ﬁrst systematically construct an outline for each dialog, then decompose the outline into multiple AMT paraphrasing tasks, and ﬁnally stitch the dialog using the collected paraphrases. Our data collection process has the following advantages: (i) systematic outline construction guarantees coverage of all paths in the ﬂowchart, and the desired balance of utterance types in dialogs, (ii) the process ensures the annotated labels5 are always correct and (iii) it provides diversity in the paraphrases collected.
3.1 Flowcharts and FAQs
We identify 12 ﬂowcharts6 on troubleshooting laptop and cars problems, such as overheating laptop, car won’t start and car brake failure. The ﬂowcharts encode agent questions as decision nodes and user responses as edges. The agent follows ﬂowcharts based on user responses to reach a terminal node (e.g., node N4 in Figure 1b) which contains the solution. We refer to the sequence of nodes and edges from root to a terminal node as a path in the ﬂowchart. One such path is shown in Figure 1b.
The ﬂowcharts usually contains precise instructions with no details. For example, node N4 in Figure 1b just says “does the battery read over 12V?" but does not provide details such as “which instrument is needed to measure the battery voltage?" or “how does one measure the battery voltage using a voltmeter?". For each ﬂowchart, we collect supplementary FAQs7 that contain details such as step-by-step instructions for a process (e.g., “how to jump start your car?") and other common doubts (e.g., “where is the ignition coil located?"). A few example FAQs are shown in Figure 1b.
3.2 Dialog Outline Construction
We systematically iterate over paths in the ﬂowchart and for each path we construct multiple outlines. Each outline consists of 3 major parts:
5We do not use these annotated labels during train, but use them to evaluate the performance of the dialog system.
6Downloaded with permission from www.ifitjams. com
7Collected in-house, refer Appendix A.8

Car Won’t Start

N1
Starter cranks?

Add to

Problem

no

Description

N2 Starter spins?

no

Q:

N3

A:

Battery

read over

12V?

Add user

digression

using FAQ1

no

N4 Jump start the
car
FAQ1 Q: How to measure the car battery voltage? A: Using voltmeter
(a) Dialog Outline

Problem Description Task Describe the following issue to a car mechanic. Primary Issue: car won't start Secondary Issue: you observed that the starter doesn’t crank
Non-Contextual Task Paraphrase: Does the starter spin on turning ON the car? Contextual Task Context: Does turning ON the car make the starter spin? Response Polarity: No Rules: Use at least one pronoun
Non-Contextual Task Paraphrase: Does the car battery reads more than 12 Volts? Non-Contextual Task Paraphrase: How to measure the car battery voltage? Contextual Task Context: How do I check the car battery voltage? Paraphrase: Using Voltmeter Contextual Task Context: Does the voltage of your car battery read more than 12? Response Polarity: No Rules: Don’t use pronouns and the word NO
Non-Contextual Task Paraphrase: The car battery is dead. Jump start the car to fix it.
Closing Task Context: Your battery is dead (for now). Find someone to help you jump start your car. This should be a quick fix. First mimic the user and thank the agent for the solution. Then mimic the agent and close the dialog.
(b) AMT Paraphrasing Tasks

Problem Description: Car Won’t Start + (N1, No) I have a Kia Telluride. The car refused to start as I was about to head to work this morning. I have had this car for the last 10 years. I also noticed that the starter does not crank on turning key.
Simple Exchange: (N2, No) Does turning ON the car make the starter spin?
It is not spinning when I turn the car ON. User Digression: (N3, No) + FAQ1
Does the voltage of your car battery read more than 12? How do I check the car battery voltage?
You can check the car battery voltage using a voltmeter The battery does not read more than 12.
Closing: N4 Your battery is dead (for now). Find someone to help you jump start your car. This should be a quick fix.
I have a friend who can help with that. Thanks for the tip. I'm glad to be of help. Have a good day!
(c) Dialog Constructed using Collected Paraphrases

Figure 2: An example of a dialog outline, AMT task creation and paraphrasing. Each dotted line box denotes a single component of the dialog. These components are independently paraphrased and then ﬁnally stitched together to construct one dialog. Each colored bubble in (b) denotes an AMT task and the matching bubble in (c) denotes the corresponding collected paraphrase. The last two paraphrases in (c) are for the closing task in (b). Paraphrases from non-contextual tasks are used in the corresponding contextual tasks, as denoted by the arrows.

problem description, ﬂowchart path traversal and closing. We now discuss each part in detail.
Problem Description: The problem description is the ﬁrst utterance in a dialog. It contains (1) the primary issue faced by the user, (2) secondary information, and (3) other information that may not be relevant for troubleshooting. The primary issue is phrased using title of the ﬂowchart. For example, for Figure 2 it will be car won’t start. The secondary information is any other information that may help in troubleshooting the primary issue. For example, the user could say that starter is not cranking. This secondary information is populated by sampling a random (node, edge) pair from the sampled ﬂowchart path. For example, (N1, no) is populated as a secondary information in Figure 2. By adding this to problem description, we mimic the setting where, an agent may need to skip a few nodes when following the ﬂowchart, based on information already present in the dialog history.
Flowchart Path Traversal: After the problem description, we consider each (node, edge) pair in the given ﬂowchart path. For each (node, edge) pair we toss a coin to decide if the pair should be represented as a simple exchange or as a complex exchange. A simple exchange is one where the

agent asks the question in the node and the user responds with the answer in the edge. (N 2, No) in Figure 2c is constructed as a simple exchange. Complex exchanges use at least four utterances to represent the information in the (node, edge) pair, e.g., (N 3, No) in Figure 2c. Complex exchange can be of two types: user-initiated digression and agent digression. The example illustrates user digression where the user asks for clariﬁcations to understand the agent question before responding with an answer. An agent digression is similar except that the agent proactively breaks a complex question into a sequence of simple ones. An example agent digression for (N 3, No) would be when the agent ﬁrst asks “Do you know how to measure the voltage of a car battery using a voltmeter?". If the user responds “no", the agent will then describe the procedure to measure the voltage, and then requests the user to check if the voltage is greater than 12V.
Closing: Closing contains the solution suggested by the agent followed by one or more exchanges to gracefully terminate the dialog. Typically, the users thank the agent and the agent terminates the dialog by acknowledging the user.

3.3 AMT Paraphrasing Tasks
We crowdsource paraphrases of each utterance in a dialog outline. Utterances corresponding to each component (problem description, node-edge pairs in the ﬂowchart path and closing) are paraphrased separately and then stitched together to construct a dialog. We deﬁne four types of paraphrasing tasks: non-contextual, contextual, problem description and closing tasks. In the non-contextual task, a single utterance from the outline is provided to the crowd workers to paraphrase. We requested the workers to provide two paraphrases for each utterance to improve diversity among paraphrases (Jiang et al., 2017; Yaghoub-Zadeh-Fard et al., 2019). In the contextual task, workers are asked to paraphrase in the context of a speciﬁc previously collected paraphrase. Problem descriptions tasks ask the worker to describe the troubleshooting problem using the primary issue and secondary issue as discussed in Section 3.2. In closing task, the worker gracefully terminates the dialog in the context of a troubleshooting solution collected from a non-contextual task. Examples of the four type of tasks can be seen in Figure 2b.
As most user responses in a ﬂowchart are yes/no, we design the yes/no paraphrasing task based on a study by Rossen-Knill et al. (1997). We add speciﬁc rules in the tasks for workers to follow when paraphrasing a yes/no user response. An example (in blue outline) is shown in Figure 2b.
3.4 Dialog Construction
We generate around 110 outlines for each ﬂowchart by equally dividing them amongst the paths in the ﬂowchart. We generate a total of 1,369 outlines and then collect paraphrases of the constructed outline components. Finally the component paraphrases are stitched together to construct 1,369 dialogs as shown in Figure 2c.
The paraphrases corresponding to an outline component are interchangeable across dialogs. We take advantage of this and generate an additional 1,369 dialogs by randomly interchanging paraphrases without breaking semantics. Our ﬁnal set has 2,738 dialogs with an avg of 15.56 utterances per dialog. The agent and user utterances have an average of 14.95 and 16.17 words in them.
3.5 Paraphrase Cleaning
To avoid error propagation, we manually verify all paraphrases and correct errors in grammar, spelling

and polarity. It took an author approximately 5 minutes per dialog for this step. An example of a polarity error is when the question ‘Do you have an open circuit?’ was paraphrased as ‘Do you have a closed circuit?’ by a crowd worker. Such paraphrases invert the semantics of (yes/no) edges from the given node and will break the correctness of a dialog, if not corrected. About 6% utterances were recollected as they violated instructions.
4 Task Deﬁnition & Baseline System
In this section, we deﬁne the problem of learning ﬂowchart grounded task oriented dialogs in an end-to-end manner without the use of intermediate labels. We then describe our proposed baseline model, FLONET, which retrieves necessary knowledge from ﬂowchart/FAQs and generates the agent response using the retrieved knowledge.
4.1 Task Deﬁnition
We represent a dialog d between a user u and an agent a as a sequence of utterances {cu1 , ca1, cu2 , ca2, . . . , cum, cam}, where m denotes the number of exchanges in the dialog. Let F = (N, E) be the ﬂowchart over which the dialog d is grounded, where the set of nodes N represents the agent questions and edges E represent the user responses. The number of outgoing edges from a node depends on the number of possible user responses for the agent question associated with the node. Let Q = {ql : al}Ll=1 be the set of frequently asked question and answer pairs (FAQs) associated with the ﬂowchart F. Our objective is to learn a next response predictor, which takes (1) the dialoghistory h = {cu1 , ca1, . . . , cui }, (2) a ﬂowchart (F ), and (3) a set of FAQs (Q) as input and predicts the next agent response (y = cai = y1y2 . . . yT ).
4.2 Baseline System: FLONET
Since it is a novel task, an existing TOD architecture does not directly apply on this problem. We design a baseline architecture named FLONET for predicting the agent responses in ﬂowchart grounded dialogs. FLONET is trained in an end-to-end manner without the need for any intermediate annotations such as (a) whether the given agent utterance is grounded on a ﬂowchart node or FAQs, or (b) the speciﬁc ﬂowchart node or FAQ on which the agent utterance is grounded.
FLONET follows the retrieval augmented generation framework (RAG) (Lewis et al., 2020; Guu

et al., 2020), which ﬁrst retrieves the necessary knowledge to generate the response and then generates the agent response one word at a time by using the retrieved knowledge. The framework consists of two main components, a retriever and a generator. The retriever pη(z|h) outputs a distribution over all documents based on the dialog history h. The ﬂowchart F and FAQs Q are represented as documents (discussed further in Section 4.2.1). The generator pθ(yt|h, z, y1:t−1) generates the agent response y word by word by using the dialog history h and a retrieved document z. We generate the response using RAG-Sequence model:

T

p(y|h) = pη(z|h) pθ(yt|h, z, y1:t−1) (1)

z∈N ∪Q

t=1

The overall network is trained by minimizing the negative log-likelihood of the response given by Equation 1. Following Lewis et al. (2020), we marginalize over all the documents using a topk approximation. We use top-5 documents in our training implementation due to memory constraints. During inference, only the top-1 document is used because the dialog’s agent responses need to be grounded on only one ﬂowchart node or FAQ. This is unlike RAG where multiple documents extracted from Wikipedia can contribute to the expected output. See Appendix A.3 for further details.

4.2.1 Retrievable Documents
The retrievable document set includes all ﬂowchart nodes and all FAQ QA pairs associated with the ﬂowchart. In the original RAG model, each (Wikipedia) document had a single dense embedding, based on which a document was retrieved and used. However, for our setting, the content of a ﬂowchart node will typically not be explicitly mentioned in the dialog history. Instead, the right node is best determined based on the ﬂowchart structure – the path to that node – as expressed in the dialog history. Similarly, for FAQs, a QA-pair will typically be matched on the question and the answer will be used in subsequent dialog.
Consequently, we represent each document as a key-value pair. The document-key is used by the retriever to compute pη(z|h) and the document-value is used by the generator during response generation. We construct a document for each node in F and for each FAQ in Q. The document-key of a ﬂowchart node is the sequence of utterances corresponding to the nodes and edges in the path from

the root. Its document-value is the agent utterance associated with it. For a FAQ, the document-key and value are the question and answer, respectively.
4.2.2 Retriever & Generator
The retriever scores each document z based on the dialog history. The dialog history is encoded using a hierarchical recurrent encoder (Sordoni et al., 2015). The encoder computes a dense representation of the history φh(h). The document-key is also encoded using a hierarchical recurrent encoder to compute its vector representation φz(z). For each document, we assign a score as negative of the Euclidean distance between φh(h) and φz(z). The top-k scores are then passed through a Softmax layer to compute pη(z|h). We use GPT2 as the generator pθ(y|h, z) and it receives a separate input for each retrieved document z. The input to GPT2 is constructed by concatenating all the utterances in the dialog history along with the document-value. GPT2 input is described in detail in Appendix A.2. The response is decoded using beam search.
4.2.3 Pre-training
To provide a good initialization to the retriever and the generator, we pre-train both the components separately. For each dialog history and response pair (h, y) in our dataset, we ﬁrst identify the document over which the response is grounded using weak supervision (Zhao et al., 2020). The document whose document-value has the highest BLEU score (Papineni et al., 2002) w.r.t. the response y is labeled as the pseudo grounded document.
The retriever is pre-trained using a contrastive loss (Hadsell et al., 2006) by using the pseudo grounded document as the positive example and any other random document as a negative example. The generator is pre-trained by minimizing the negative log likelihood of the response given the dialog history and the document-value of the pseudo grounded document. Following Wolf et al. (2019), we add a next-utterance classiﬁcation loss to the negative log likelihood loss. The classiﬁcation loss is applied on the output of a linear classiﬁcation layer which receives the last hidden state of the generator and outputs the probability of a given utterance being the correct agent response. We use randomly sampled incorrect utterances as negative examples to train the generator based classiﬁer.

Train Dialogs Val Dialogs Test Dialogs

S-Flo
1,470 374 484

U-Flo
1,470 374 498

Table 2: Statistics of the dataset split.

Model
TF-IDF + GPT2 FLONET (No PT) FLONET Oracle Ret. + GPT2

S-Flo

BLEU PPL

7.90 16.66 19.89

13.28 4.19 4.17

21.96

-

U-Flo

BLEU PPL

6.90 13.01 14.83

18.53 5.99 5.67

21.56

-

5 Experimental Setup & Results
5.1 Data Split
We create two different splits of the dialogs in FLODIAL. The S-Flo split is used for evaluating the ability of FLONET to generate responses by following ﬂowchart and FAQs. The U-Flo split is used to study the ability of FLONET to generalize to ﬂowcharts unseen during train in a zero-shot ﬂowchart grounded response generation setting.
We ﬁrst set aside the test dialogs for the S-Flo and the U-Flo split. The remaining dialogs are then divided into train and validation sets. This ensures a hidden test set for both the splits.The U-Flo test set is constructed using all the dialogs associated with 2 randomly sampled ﬂowcharts. To create the S-Flo test set, we sampled 17% of the dialogs associated with each ﬂowchart excluding the 2 ﬂowcharts used for the U-Flo test set. We create the train and validation sets using the remaining dialogs that are not a part of both the test sets. To generate the S-Flo train and validation sets, we divided the remaining dialogs associated with each ﬂowchart (excluding the 2 ﬂowcharts in U-Flo test set) as follows: 66% for train set and 17% for validation set. To generate the U-Flo split, we group dialogs associated with 8 ﬂowcharts as train set and dialogs from 2 ﬂowcharts as validation set. The UFlo split has mutually exclusive sets of ﬂowcharts in each set. Some statistics on the dataset split are shown in Table 2.
The split mentioned above is different from the one used in the published EMNLP version. The split described in the published version does not have a hidden test set whereas the split mentioned above ensures a hidden test set. For completeness, we report the published numbers in Appendix A.5
5.2 Evaluation Metrics
We measure the ability to generate responses using two standard metrics: BLEU and perplexity. As FLODIAL contains the labels of the document (ﬂowchart node or FAQ) over which each agent response is grounded on, we use recall@1 (R@1) to measure the retriever performance. We also com-

Table 3: Next response prediction performance.

Model
TF-IDF + GPT2 FLONET (No PT) FLONET

S-Flo

R@1 SR

0.304 0.749 0.793

0.002 0.260 0.318

U-Flo

R@1 SR

0.373 0.590 0.677

0.004 0.062 0.133

Table 4: Retriever performance of various models.

pute a task-speciﬁc metric called success rate (SR) which is measured as the fraction of dialogs for which an algorithm retrieved the correct ﬂowchartnode/FAQ for all the agent utterances in the dialog.
5.3 Implementation Details
The models were implemented using PyTorch (Paszke et al., 2019). We identify hyper-parameters using a grid-search and identiﬁed the best hyperparameters based on the evaluation of the held-out validation sets. Each hyper-parameter combination was run ten times. We sample word embedding size from {50, 100, 200, 300}, retriever learning rates (lrR)8 from {1E-2, 5E-3, 1E-3, 5E-4, 1E-4, 5E-5, 1E-5}, generator learning rates (lrG) from {6.25E-4, 2.5E-4, 6.25E-5, 2.5E-5, 6.25E-6, 2.5E6, 6.5E-7, 2.5E-7}, and dropout from increments of 0.02 between [0, 0.2]. Hidden size of the retriever was set to three times the word embedding size in all the settings. The word embeddings of the retriever were initialized with pre-trained GloVe embeddings (Pennington et al., 2014). The generator was built on top code made available by Wolf et al. (2019).9 The best hyper-parameter settings and other details are in Appendix A.1
5.4 Results
We report the performance of our baseline FLONET on both S-Flo and U-Flo splits of FLODIAL. We also report the numbers for two simple variants of FLONET: TF-IDF + GPT2 and FLONET (No PT). The former variant uses a simple TF-IDF technique
8aEb denotes a × 10b 9https://github.com/huggingface/ transfer-learning-conv-ai

Data Source
DH DH + FC DH + FC + FAQ

S-Flo

BLEU PPL

5.18 15.61 19.89

13.74 4.69 4.17

U-Flo

BLEU PPL

2.59 11.24 14.83

20.01 6.77 5.67

Table 5: Response prediction performance of FLONET with different knowledge sources. DH and FC indicates dialog history and ﬂowchart respectively.

Error Type
Retrieved Sibling Retrieved Parent Retrieved FAQ Retrieved Other Nodes

% Error (Count)

S-Flo

U-Flo

68.2 (178) 3.4 (9) 0.8 (2) 27.6 (72)

27.2 (193) 7.6 (54) 2.1 (15) 63.0 (447)

Table 6: Retriever errors (%) on utterances grounded on ﬂowcharts. Error counts are in parentheses.

to retrieve documents. The top retrieved document concatenated with the dialog history is fed as input to GPT2 for generating a response. FLONET (No PT) is FLONET without the pre-training described in Section 4.2.3.
Table 3 reports the response prediction performance of various systems on both data splits and Table 4 reports the performance of the respective retrievers. TF-IDF + GPT2 has has a poor response prediction performance in both the settings. The poor generalization is due to the TF-IDF retriever’s low R@1. This forces the generator to memorize the knowledge necessary to generate a response, rather than inferring it from the retrieved documents.
FLONET achieves a three point improvement in BLEU over the No PT variant on S-Flo, and a two point jump in BLEU in U-Flo setting. This shows that the heuristic pre-training contributes to the overall system performance of FLONET. The success rate of various systems is reported in Table 4. The success rate achieved by FLONET retriever in both settings are quite low. We hope this gets improved by further research on the dataset.
The oracle ret. + GPT2 in Table 3 is approximated by assuming a perfect retriever and training GPT2 with ground truth document. The gap in BLEU represents the value of annotation for our task, and the performance gain a better retriever may help achieve.
We also compare the performance of FLONET on the two data splits. We ﬁnd that while numbers are understandably worse in the U-Flo setting, the zero-shot transferred FLONET is still better than TF-IDF+GPT2’s S-Flo performance. This suggests that the model has acquired some general intelligence of following a ﬂowchart, even though there is signiﬁcant scope for further improvement.
Knowledge Sources: To understand the contribution of each knowledge source towards response generation, we trained 3 variants of FLONET: (i)

Digression Type
User Digression Agent Digression

S-Flo
BLEU R@1
29.27 0.88 17.67 0.32

U-Flo
BLEU
7.84 2.50

R@1
0.53 0.02

Table 7: Performance of the generator (BLEU) and the retriever (R@1) on the utterances grounded on FAQs.

using only the dialog history (DH), (ii) using the dialog history and the ﬂowchart (DH + FC), and (iii) using dialog history, ﬂowchart and FAQs (DH + FC + FAQ). The performance is summarized in Table 5. The S-Flo trend shows both the knowledge sources contribute to the overall performance. The U-Flo numbers prove that, unsurprisingly, knowledge sources are essential for generalization to new settings, with more than 12 points increase in BLEU.
6 Analysis & Research Challenges
We now investigate FLONET errors in the validation set, with the goal of identifying new research challenges posed by FLODIAL. We ﬁrst manually inspect the output of the generator, given the retrieved document. We ﬁnd that, by and large, the generator has learned its tasks well, which are deciding whether and how to use the retrieved document in generating a response. We attribute FLONET’s errors primarily to the retriever. FLONET makes retrieval errors in 17.2% and 46% of validation examples in S-Flo and U-Flo, respectively.
To further diagnose retriever errors, we split them into two categories based on whether the correct retrieval is a ﬂowchart node or a FAQ (digression). For the former case, Table 6 reports the nature of the error. In Table 6, retrieved sibling implies the retrieved node and the correct node are sibling nodes in the ﬂowchart. We notice that for a large fraction of errors, retriever returns a sibling node. This suggests that FLONET could not adequately ground user response to the given agent

question. More surprising around 27% of the errors in S-Flo are not even in the immediate neighborhood of the true node. A much larger value for U-Flo here also suggests poor retriever generalization. Since retriever performance in this task is closely tied with the ability to follow a ﬂowchart path, it leads to the following research question: how can a model incorporate ﬂowchart structure for better retriever performance?
Table 7 analyzes retrieval errors on digressions. We ﬁnd that the retriever gets a decent Recall@1 for user digressions but has a rather low performance for agent digressions. Moreover, BLEU scores suggest that generator has memorized some common digressions S-Flo, but naturally they do not generalize to U-Flo. This yields a fairly challenging research question: how do we improve retriever performance on agent digressions?
Finally, the challenge of zero-shot generalization to unseen ﬂowcharts gets to the core ability of following a conversation ﬂow, leading to the key research question: how do we improve performance on unseen ﬂowchart setting in FLODIAL?
7 Conclusion
We deﬁne the novel problem of end-to-end learning of ﬂowchart grounded task oriented dialog (TOD) for a troubleshooting scenario. We collect a new ﬂowchart grounded TOD dataset (FLODIAL), which contains 2,738 dialogs grounded on 12 different ﬂowcharts and 138 FAQs. We propose the ﬁrst baseline solution (FLONET) for our novel task using retrieval-augmented generation. We outline novel technical challenges for TOD research identiﬁed in our work. We release FLODIAL10 and all resources11 for use by the research community.
Acknowledgments
This work is supported by IBM AI Horizons Network grant, an IBM SUR award, grants by Google, Bloomberg and 1MG, a Visvesvaraya faculty award by Govt. of India, and the Jai Gupta chair fellowship by IIT Delhi. We thank Morris Rosenthal for providing us with permission to use the ﬂowcharts from www.ifitjams.com. We also thank the IIT Delhi HPC facility for computational resources.
10https://dair-iitd.github.io/FloDial 11https://github.com/dair-iitd/FloNet

Ethics Impact Statement
Crowd Worker Compensation: The crowd workers were compensated with approximately 2.5 USD for a creating paraphrases for a dialog with 15 utterances. On an average, the crowd workers spent a little less than a minute on each paraphrase. Potentially, a worker can paraphrase 4 dialogs in an hour and get compensated with 10 USD. Intellectual Property: Flowcharts used in our data collection process are based on the ﬂowcharts from www.ifitjams.com. We used these ﬂowcharts after receiving a written permission from the creator Morris Rosenthal. We include attribution to Morris Rosenthal in the acknowledgements section. Privacy: We now brieﬂy describe each task used for data collection and show how the task design ensures the collected data will not contain any sensitive personal information (SPI). We would like to emphasise that the authors of the paper meticulously went over each data point collected and removed the ones that did not comply with the rules in the task description.
Problem Description Task: Each participant was provided with an artiﬁcial scenario which includes a car/laptop model, a car/laptop model year, a car/laptop related problem that they are facing. They were requested to paraphrase this information into a natural language utterance. Since the scenario was provided by us, there was almost no room for providing SPI. The paraphrases deviating from the provided details were rejected.
Paraphrasing Task: The participants were requested to create paraphrases of a given sentence. This task has no room for providing SPI.
Closing Task: The participants were asked to close a conversation between a human agent and a car/laptop user. In this task, the user and the human agent refer to each other using a second-person pronoun (e.g., I hope this was helpful to you, I am happy that this solved your problem). This task also does not involve providing any SPI.
References
Antoine Bordes and Jason Weston. 2017. Learning end-to-end goal-oriented dialog. In International Conference on Learning Representations.
Paweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang Tseng, Iñigo Casanueva, Stefan Ultes, Osman Ra-

madan, and Milica Gasic. 2018. Multiwoz-a largescale multi-domain wizard-of-oz dataset for taskoriented dialogue modelling. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 5016–5026.
Bill Byrne, Karthik Krishnamoorthi, Chinnadhurai Sankar, Arvind Neelakantan, Ben Goodrich, Daniel Duckworth, Semih Yavuz, Amit Dubey, Kyu-Young Kim, and Andy Cedilnik. 2019. Taskmaster-1: Toward a realistic and diverse dialog dataset. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 4506–4517.
Layla El Asri, Hannes Schulz, Shikhar Kr Sarma, Jeremie Zumer, Justin Harris, Emery Fine, Rahul Mehrotra, and Kaheer Suleman. 2017. Frames: a corpus for adding memory to goal-oriented dialogue systems. In Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue, pages 207– 219.
Mihail Eric, Lakshmi Krishnan, Francois Charette, and Christopher D Manning. 2017. Key-value retrieval networks for task-oriented dialogue. In Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue, pages 37–49.
Song Feng, Hui Wan, Chulaka Gunasekara, Siva Patel, Sachindra Joshi, and Luis Lastras. 2020. Doc2dial: A goal-oriented document-grounded dialogue dataset. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 8118–8128.
Revanth Gangi Reddy, Danish Contractor, Dinesh Raghu, and Sachindra Joshi. 2019. Multi-level memory for task oriented dialogs. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 3744–3754, Minneapolis, Minnesota. Association for Computational Linguistics.
Kelvin Guu, Kenton Lee, Z. Tung, Panupong Pasupat, and Ming-Wei Chang. 2020. Realm: Retrievalaugmented language model pre-training. ArXiv, abs/2002.08909.
R. Hadsell, S. Chopra, and Y. LeCun. 2006. Dimensionality reduction by learning an invariant mapping. In 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’06), volume 2, pages 1735–1742.
Donghoon Ham, Jeong-Gwan Lee, Youngsoo Jang, and Kee-Eung Kim. 2020. End-to-end neural pipeline for goal-oriented dialogue systems using GPT-2. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 583–592, Online. Association for Computational Linguistics.

Matthew Henderson, Blaise Thomson, and Steve Young. 2014. Word-based dialog state tracking with re- current neural networks. In In Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 292– 299.
Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2020. The curious case of neural text degeneration. In International Conference on Learning Representations.
Ehsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu, Semih Yavuz, and Richard Socher. 2020. A simple language model for task-oriented dialogue. In Advances in Neural Information Processing Systems, volume 33, pages 20179–20191. Curran Associates, Inc.
Youxuan Jiang, Jonathan K. Kummerfeld, and Walter S. Lasecki. 2017. Understanding task design trade-offs in crowdsourced paraphrase collection. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 103–109, Vancouver, Canada. Association for Computational Linguistics.
John F Kelley. 1984. An iterative design methodology for user-friendly natural language ofﬁce information applications. ACM Transactions on Information Systems (TOIS), 2(1):26–41.
Seokhwan Kim, Mihail Eric, Karthik Gopalakrishnan, Behnam Hedayatnia, Yang Liu, and Dilek HakkaniTur. 2020. Beyond domain apis: Task-oriented conversational modeling with unstructured knowledge access. In Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 278–289.
Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980.
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2020. Retrieval-augmented generation for knowledgeintensive nlp tasks. In Advances in Neural Information Processing Systems, volume 33, pages 9459– 9474. Curran Associates, Inc.
Rensis Likert. 1932. A technique for the measurement of attitudes. Archives of psychology.
Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.

Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. 2019. Pytorch: An imperative style, high-performance deep learning library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32, pages 8024–8035. Curran Associates, Inc.
Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. Glove: Global vectors for word representation. In Empirical Methods in Natural Language Processing (EMNLP), pages 1532–1543.
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners.
Dinesh Raghu, Nikhil Gupta, and Mausam. 2019. Disentangling Language and Knowledge in TaskOriented Dialogs. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 1239–1255, Minneapolis, Minnesota. Association for Computational Linguistics.
Dinesh Raghu, Atishya Jain, Mausam, and Sachindra Joshi. 2021. Constraint based knowledge base distillation in end-to-end task oriented dialogs. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 5051–5061, Online. Association for Computational Linguistics.
Abhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara, Raghav Gupta, and Pranav Khaitan. 2020. Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 34, pages 8689–8696.
Deborah Rossen-Knill, Beverly Spejewski, Beth Ann Hockey, Stephen Isard, and Matthew Stone. 1997. Yes/no questions and answers in the map task corpus. Technical report, University of Pennsylvania, Institute for Research in Cognitive Science.
Marzieh Saeidi, Max Bartolo, Patrick Lewis, Sameer Singh, Tim Rocktäschel, Mike Sheldon, Guillaume Bouchard, and Sebastian Riedel. 2018. Interpretation of natural language rules in conversational machine reading. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2087–2097.
Iulian Vlad Serban, Alessandro Sordoni, Yoshua Bengio, Aaron C Courville, and Joelle Pineau. 2016. Building end-to-end dialogue systems using generative hierarchical neural network models. In AAAI, pages 3776–3784.

Pararth Shah, Dilek Hakkani-Tür, Gokhan Tür, Abhinav Rastogi, Ankur Bapna, Neha Nayak, and Larry Heck. 2018. Building a conversational agent overnight with dialogue self-play. arXiv preprint arXiv:1801.04871.
Alessandro Sordoni, Yoshua Bengio, Hossein Vahabi, Christina Lioma, Jakob Grue Simonsen, and JianYun Nie. 2015. A hierarchical recurrent encoderdecoder for generative context-aware query suggestion. CoRR, abs/1507.02221.
Oriol Vinyals and Quoc Le. 2015. A neural conversational model. Proceedings of the International Conference on Machine Learning, Deep Learning Workshop.
Tsung-Hsien Wen, Milica Gasic, Nikola Mrkšic´, Lina M. Rojas Barahona, Pei-Hao Su, Stefan Ultes, David Vandyke, and Steve Young. 2016. Conditional generation and snapshot learning in neural dialogue systems. In EMNLP, pages 2153–2162, Austin, Texas. ACL.
Jason D. Williams and Steve Young. 2007. Partially observable markov decision processes for spoken dialog systems. Computer Speech & Language, 21(2):393–422.
Thomas Wolf, Victor Sanh, Julien Chaumond, and Clement Delangue. 2019. Transfertransfo: A transfer learning approach for neural network based conversational agents. arXiv preprint arXiv:1901.08149.
Chien-Sheng Wu, Andrea Madotto, Ehsan HosseiniAsl, Caiming Xiong, Richard Socher, and Pascale Fung. 2019. Transferable multi-domain state generator for task-oriented dialogue systems. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 808–819.
Mohammad-Ali Yaghoub-Zadeh-Fard, Boualem Benatallah, Moshe Chai Barukh, and Shayan Zamanirad. 2019. A study of incorrect paraphrases in crowdsourced user utterances. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 295–306, Minneapolis, Minnesota. Association for Computational Linguistics.
Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, and William B Dolan. 2020. Dialogpt: Largescale generative pre-training for conversational response generation. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 270– 278.
Tiancheng Zhao and Maxine Eskenazi. 2018. Zeroshot dialog generation with cross-domain latent actions. In Proceedings of the 19th Annual SIGdial Meeting on Discourse and Dialogue, pages 1–10.

Xueliang Zhao, Wei Wu, Can Xu, Chongyang Tao, Dongyan Zhao, and Rui Yan. 2020. Knowledgegrounded dialogue generation with pre-trained language models. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 3377–3390, Online. Association for Computational Linguistics.

A Appendix
A.1 Training Details
FLONET is trained in two phases: pre-train and ﬁne-tune. In the pre-train phase, we use recall@1 and BLEU as the early stop criteria for the retriever and generator respectively. The recall is computed using the weakly supervised labels. The hyperparameters (embedding size, lrR, lrG, dropout) that achieved the best validation numbers in pretrain stage were (100, 1E-4, 6.25E-5, 0.01) and (200, 1E-4, 6.25E-5, 0) for S-Flo and U-Flo respectively. The best hyper-parameters that achieved the best BLEU in ﬁne tune phase were (100, 1E4, 2.5E-6, 0) and (200, 1E-5, 2.5E-7, 0) for SFlo and U-Flo respectively. The BLEU scores on held-out validation set were 20.91 and 10.82 for S-Flo and U-Flo respectively. We use AdamW optimizer (Kingma and Ba, 2014) for training and beam search for decoding with beam width of 5 and a maximum decode length set to 60 tokens.
All experiments were run on a single Nvidia V100 GPU with 32GB of memory. The S-Flo retriever, U-Flo retriever and generator have 3M, 23M and 117M trainable parameters respectively. Thus, FLONET has a total of 120M trainable parameters for S-Flo and 140M for U-Flo. FLONET has an average runtime of approximately 7 hours (80 mins per epoch) and 8 hours (82 mins per epoch) for S-Flo and U-Flo respectively.

A.2 GPT2 Input
FLONET uses GPT2 as the generator. Following Wolf et al. (2019), our input is constructed as shown in Figure 3. During inference, GPT2 take the retrieved document concatenated with the sequence of utterances from the dialog history as the input and predicts the agent response.

Component Type

Constructed Component

<Retrieved Document> [BOS] Is there a pinhole leak in hose or at clamps?

<User Utterance 1>
<Agent Utterance 1> ...
<Last User Utterance> <Agent Response>

[S1] I am facing a problem with my car’s engine. It seems to be overheating. My car is a Ford which I have had for 3 years. Can you please help me?
[S2] Is there any steam coming from your car’s engine?
...
[S1] I don’t see any leak in my car’s radiator.
[S2] Does the hose or clamps have any leak?

Figure 3: Breakdown of the components in GPT2 input and output.

A.3 GPT2 Inference

We experiment with various inference settings and

used the setting which performed the best in the

validation set. We experimented with beam search

with beam width of 5. We varied the number of

top-k documents to be used. In the case of Top-1

decoding, we use only the top retrieved document

to generate response candidates. For Top-5, we

take the top 5 retrieved documents and generate

candidate responses from each document. Each

candidate response score is computed as a product

of the probability of generating the candidate given

the retrieved document

T t=1

pθ

(yt

|h,

z

,

y1:t−1

)

and the probability of the retrieved document

pη(z|h). Lastly, we experimented with response

length normalization to avoid favouring shorter

sequences. The probability of each candidate is

given by (

T t=1

pθ

(yt

|h,

z

,

y1:t−1

))1/T

where

T

is

the length of the candidate. The validation BLEU

scores of various settings on the S-Flo split is

shown in table 8. We see that beam search on

top-1 document with length normalization resulted

in the best validation BLEU.

Decoding Technique
Beam

Top-k Top-5 Top-1

Length Norm.
No Yes
No Yes

Val BLEU
18.22 20.08
20.06 20.92

Table 8: Validation and test BLEU scores of various settings on the S-Flo split.

We also experimented with nucleus sampling (Holtzman et al., 2020) (p = 0.9). We found the validation BLEU was roughly three points lower than the BLEU achieved by beam search.
A.4 Qualitative Examples
Table 13 and 12 shows responses generated by various systems on examples from U-Flo and S-Flo validation set respectively. In Table 12, we see that FLONET and FLONET (No PT) generates responses similar to the gold response as they were able to generalize to unseen ﬂowcharts.
A.5 Results Reported in the EMNLP Version
A.5.1 Data Split To generate the S-Flo split, we divided the dialogs associated with each ﬂowchart as follows: 66% for train set, 17% for validation set and 17% for test

Model
TF-IDF + GPT2 FLONET (No PT) FLONET Oracle Ret. + GPT2

S-Flo

BLEU PPL

11.97 18.90 19.46

12.88 3.86 3.79

23.73

-

U-Flo

BLEU PPL

6.45 14.19 16.31

16.38 5.35 4.94

24.85

-

Model
TF-IDF + GPT2 FLONET (No PT) FLONET Oracle Ret. + GPT2

Relevance
S-Flo U-Flo
2.63 1.13 3.11 2.37 3.12 2.55
3.53 3.69

Table 9: Next response prediction performance. (From EMNLP Version)

Model
TF-IDF + GPT2 FLONET (No PT) FLONET

S-Flo

R@1 SR

0.334 0.768 0.814

0.002 0.260 0.337

U-Flo

R@1 SR

0.394 0.586 0.661

0.004 0.064 0.125

Table 10: Retriever performance of various models. (From EMNLP Version)

set. We randomly select a path in the ﬂowchart and push all the dialogs that follow the path to one set. To generate the U-Flo split, we group all dialogs associated with 8 ﬂowcharts as train set, all dialogs from 2 ﬂowcharts as validation set and the remaining 2 into test set. Thus, the U-Flo split has mutually exclusive sets of ﬂowcharts in each set.
In this split, some dialogs in U-Flo test set are present in S-Flo train/validation set and some dialogs in S-Flo test set are present in U-Flo train/validation set. As this overlap of dialogs was preventing us from creating a hidden test set we deﬁned a new split.
A.5.2 Results
Table 9 reports the response prediction performance of various systems on both data splits and Table 10 reports the performance of the respective retrievers.
We perform a human evaluation for the responses generated by FLONET and 3 other variants of FLONET along two dimensions: (i) relevance – the ability to generate responses that are relevant to the dialog context, and (ii) grammar – ability to generate grammatically correct and ﬂuent responses. Both the dimensions are evaluated on a Likert scale (0-4) (Likert, 1932).
We randomly sample 75 context-response pairs each from both S-Flo and U-Flo test sets and collect two sets of judgements for each pair. As we evaluate 4 systems, we collect a total of 1,200 labels from the judges. We report the human evaluation results in Table 11. We ﬁnd that FLONET’s rele-

Table 11: Human evaluation of various models.
vance scores are better than the baselines for both S-Flo and U-Flo.
A.6 Example Dialogs from FLODIAL
Two randomly selected dialogs from FLODIALare shown in Table 14. The ﬁrst dialog is grounded on the wireless network troubleshooting ﬂowchart and the second is grounded on car won’t start ﬂowchart.
A.7 AMT Tasks
Figure 4, 5, 6 and 7 show the instructions and examples provided to crowd-workers for problem description, non-contextual paraphrasing, contextual paraphrasing and closing task respectively.
A.8 FAQ Collection
For each ﬂowchart we collected a set of FAQs associated with it. We collect the FAQs in two steps: question collection and answer collection. In the question collection step, we displayed each ﬂowchart node question to novice (laptop or car) users and asked them if they understand the node question. If not, they were requested to come up with a follow-up question that would help them better understand the node question. We aggregated all the follow-up questions to create the set of FAQs associated with that ﬂowchart. In the answer collection step, in-house (laptop or car) expert provided answers for the questions collected in the ﬁrst step.

User
Agent User Gold Response TF-IDF + GPT2 FLONET (No PT) FLONET

I’ve had my Inﬁniti QX60 for 6 years now. It’s recently been making awful noises. I got stopped by the police on my way to work because the noise was no loud. Please help me ﬁx this.
The sound that is coming from your car, is it a clunking sound?
I do hear a clunking sound coming from the car.
Is it only when you drive over a bump or a dip that the car makes a noise?
Are the ticking noises heard only when the car is moving?
Does the car make a noise only when you drive over bumps or dips on the road?
Does the car make the noise only when you drive it over a bump or a dip on the road?

Table 12: Responses predicted by various algorithms for an example from the S-Flo validation set. The highlighted text shows that TF-IDF + GPT2 missed out on an important detail.

User
Agent User Agent User Agent User Gold Response
TF-IDF + GPT2
FLONET (No PT) FLONET

My Dell G5 15 5590 is having some issues. I got it about a year ago but within the last month the battery just refuses to work properly. I don’t understand what is happening here. This happens even if I plug it in overnight.
When the charger isn’t plugged in, can the laptop power up?
I can see that it can start up in that case.
Do you ﬁnd that the battery in your laptop quickly drains of power?
The battery drains too fast.
There will be a manufacture date on the laptop’s battery. Please check if it is older than a year and let me know.
How do I check that date on my battery?
In order to locate the manufacturing date, you need to remove the battery and ﬁnd a sticker on it with a multiﬁeld part number. The fourth ﬁeld in the number identiﬁes the date.
You can use a multimeter to measure the voltage of the AC power adapter. The voltage should be the same as the voltage printed on the adapter.I am glad I could help. Have
Remove the battery and you will ﬁnd a sticker on it with a multi-ﬁeld part number.
Please remove the battery and you will ﬁnd a sticker on it with a multiﬁeld part number. The fourth ﬁeld in the part number corresponds to the manufacturing date.

Table 13: Responses predicted by various algorithms for an example from the U-Flo validation set. The highlighted text points out that FLONET generated the best response compared to other models.

User
Agent User Agent User Agent User Agent User Agent User Agent User Agent User Agent
User Agent
User
Agent User Agent User Agent User Agent
User Agent
User Agent User Agent User Agent User Agent User Agent
User
Agent User Agent User Agent User Agent User Agent User Agent User Agent User Agent
User Agent

Hi, my Rivian R1T that I have had for only 1 year and I am already facing some issue with the brakes. I can’t use it to go to work and i have to call for a ride everytime. I need to ﬁx this soon. When you make use of the brakes, does the car stop moving? The brakes are able to stop the car from moving. Is the emergency brake functioning like it should? You know, I think it isn’t functioning like usual. Are you experiencing excessive dragging from one or more wheels? The wheel on the car turn with ease. Are the brakes soft until you pump them a few times? The brakes are not soft. They do not need to be pumped. Are there any noises heard after hitting the brakes? There is a distinct noise when I hit them. I hadn’t noticed this until just recently when I used them. When you apply the brakes, do they make a squealing noise? No, there is no squealing noises when the brakes are applied. Do you hear any noises like a clunk after applying the brakes? I checked just now. I can hear a clunk after I apply the brakes. There’s a loose bolt and this is causing the caliper to move too freely on the wheel assembly. Please tighten the bolt. This should ﬁx your braking problem. I tightened the loose caliper bolt, and it completely ﬁxed my braking issue. Thanks! Glad to help you. I hope you car runs smoothly now.
I work from home and I am trying to ﬁnish a project. I have a deadline and I cannot get my work done. For some reason, I can’t connect to the internet with my wireless network. Help me please. Can you see the wireless network you are attempting to connect to on your laptop? Yes, I can see it. Can you connect to the wiﬁ after disabling the router’s network security settings? In order to turn off security in my router, what do I do? Turn off or disable the security on the wireless router by opening the router settings in your browser. How can I access router settings from my browser? Try typing ’192.168.1.1’ or ’192.168.0.1’ in the address bar and you should see the router settings page. There you can log in to your router. Laptop doesn’t connect with the security disabled. Can the computer connect to the internet when you connect directly to the router using an Ethernet cable? It does not connect to the internet. It doesn’t connect even with an Ethernet cable. Do you know how to check your laptop’s ﬁrewall settings? I’ve checked the ﬁrewall settings before. Are the ﬁrewall settings blocking the internet connection? The ﬁrewall settings are not blocking my internet connection. Is the live internet LED on your router turned ON? I checked the live internet LED on the router. It is turned on. You are unable to connect to the internet because the router is malfunctioning. Replacing my malfunctioning router solved the issue. Thanks for your help. You’re welcome. Have a nice day.
My Ford Expedition has started to make strange ticking sounds and I need it ﬁxed immediately. I’m going on a date and it has to go perfectly, with no unpleasant car noises. The car is one year old and it’s already making these ticking sounds when it moves. does the car make ticking sounds when it is moving in neutral? The car does make a ticking sound when in neutral. Do you know if the frequency of the ticking noise decreases once you shift gears in your car? I don’t hear the sound decreasing when I shift gears. Are you hearing the ticking sound only when the car turns? I hear it all the time, not just during turns. Did you get new tires recently? They haven’t been changed recently. They are a few years old. Are the hub caps on your tires loose? The hub caps on my tires are not loose. The hub caps are secured very tightly. Have you inspected the treads in your car tires recently? I inspected the treads in my car tires yesterday. They look ﬁne to me. Is it only when you are driving at a slow speed that you hear the ticking sounds? I hear the ticking sounds from it at high speed too. Your problem seems to be a common warped rotor issue. You”ll need to examine both the rotor as well as the brake pads. Okay, I’ll have to look into those issues. Thank you so much for your help. I’m glad that I could help you today. Have a good day.

Table 14: Sample dialogs from FLODIAL

Task 1 - Problem Description Figure 4: Instructions provided to AMT workers for the problem description task.

Task 2 - Non-Contextual Paraphrasing
Figure 5: Instructions provided to AMT workers for the non-contextual paraphrasing task.

Task 3 - Contextual Paraphrasing Figure 6: Instructions provided to AMT workers for the contextual paraphrasing task.

Task 4 - Closing Figure 7: Instructions provided to AMT workers for the closing task.

