Proportional-Integral Projected Gradient Method for Conic Optimization

arXiv:2108.10260v2 [math.OC] 13 Dec 2021

Yue Yu, Purnanand Elango, Ufuk Topcu, Beh¸cet A¸cıkme¸se,
Oden Institute for Computational Engineering and Sciences, The University of Texas, Austin, TX, 78712 Department of Aeronautics and Astronautics, University of Washington, Seattle, WA, 98195

Abstract
Conic optimization is the minimization of a diﬀerentiable convex objective function subject to conic constraints. We propose a novel primal-dual ﬁrst-order method for conic optimization, named proportional-integral projected gradient method (PIPG). PIPG ensures that both the primal-dual gap and the constraint violation converge to zero at the rate of Op1{kq, where k is the number of iterations. If the objective function is strongly convex, PIPG improves the convergence rate of the primal-dual gap to Op1{k2q. Further, unlike any existing ﬁrst-order methods, PIPG also improves the convergence rate of the constraint violation to Op1{k3q. We demonstrate the application of PIPG in constrained optimal control problems.
Key words: Convex optimization, ﬁrst-order methods, optimal control

1 Introduction

Conic optimization is the minimization of a diﬀerentiable convex objective function subject to conic constraints:

minimize f pzq

z

(1)

subject to Hz ´ g P K, z P D,

where z P Rn is the solution variable, f : Rn Ñ R is a continuously diﬀerentiable and convex objective function, K Ă Rm is a closed convex cone and D Ă Rn is a closed convex set, H P Rmˆn and g P Rm are constraint parameters. By proper choice of cone K, conic optimization (1) generalizes linear programming, quadratic pro-
gramming, second-order cone programming, and semi-
deﬁnite programming [Ben-Tal and Nemirovski, 2001,
Boyd and Vandenberghe, 2004]. Conic optimization has
found applications in various areas, including signal pro-
cessing [Luo and Yu, 2006], machine learning [Ander-

1 Y. Yu and U. Topcu are with the Oden Institute for Computational Engineering and Sciences, The University of Texas, Austin, TX, 78712 (e-mails: yueyu@utexas.edu,utopcu@utexas.edu). P. Elango and B. Ac¸ıkme¸se are with the William E. Boeing Department of Aeronautics & Astronautics, University of Washington, Seattle, Washington, 98195 (e-mails: pelango@uw.edu,behcet@uw.edu,

sen et al., 2011], robotics [Majumdar et al., 2020], and aerospace engineering [Liu et al., 2017, Eren et al., 2017, Malyuta et al., 2021].
The goal of numerically solving optimization (1) is to compute a solution z‹ that achieves, up to a given numerical tolerance, zero violation of the constraints in (1) and zero primal-dual gap; the latter implies that z‹ is an optimal solution of optimization (1) [Boyd et al., 2011, He and Yuan, 2012, Chambolle and Pock, 2011, Chambolle and Pock, 2016b]. To this end, numerical methods iteratively compute a solution whose constraint violation and primal-dual gap are nonzero at ﬁrst but converge to zero as the number of iteration k increases.
Due to their low computational cost, ﬁrst-order methods have attracted increasing attention in conic optimization [Lan et al., 2011, Boyd et al., 2011, O’Donoghue et al., 2016, Chambolle and Pock, 2016a, Yu et al., 2020b]. Unlike second-order methods, such as interior point methods [Nesterov and Nemirovskii, 1994, Andersen et al., 2003], ﬁrst-order methods do not rely on computing matrix inverses. They consequently are suitable for implementation with limited computational resources.
The existing ﬁrst-order methods solve optimization (1) by solving two diﬀerent equivalent problems. The ﬁrst equivalent problem is the following optimization with equality constraints [Boyd et al., 2011, O’Donoghue

Preprint submitted to Automatica

15 December 2021

Table 1 Comparison of diﬀerent ﬁrst-order methods for conic optimization (1)

f is smooth & convex

f is smooth & strongly convex

Algorithms ADMM

# of proj. per iter.

D ?
Op1{ q

K or K˝ 1

convergence rates

primal-dual constraint

gap

violation

Op1{kq

Op1{kq

# of proj. per iter.

D Oplnp1{ qq

K or K˝ 1

convergence rates

primal-dual constraint

gap

violation

Op1{kq

Op1{kq

PIPGeq

1

PDHG

1

This work

1

1

Op1{kq

Op1{kq

1

1

Op1{kq

N/A

1

1

Op1{kq

Op1{kq

1

1

Op1{kq

Op1{kq

1

Op1{k2q

N/A

1

Op1{k2q

Op1{k3q

ą 0 is a tunable accuracy tolerance in ADMM, K˝ denotes the polar cone of K.

et al., 2016, Stellato et al., 2020, Yu et al., 2020b]:

minimize f pzq

z,y

(2)

subject to Hz ´ y “ g, y P K, z P D.

In particular, the alternating direction method of multipliers (ADMM) solves optimization (1) by computing one projection onto cone K and multiple projections onto set D in each iteration. ADMM ensures that both the constraint violation and the primal-dual gap converge to zero at rate of Op1{kq, where k is the number of iterations [Gabay and Mercier, 1976, Eckstein, 1989, Fortin and Glowinski, 2000, Boyd et al., 2011, He and Yuan, 2012, Wang and Banerjee, 2014]. The proportional-integral projected gradient method for equality constrained optimization (PIPGeq) achieves the same convergence rates as ADMM, while computing one projection onto cone K and only one projection onto set D in each iteration [Yu et al., 2020b]. Although variants of ADMM [Goldstein et al., 2014, Kadkhodaie et al., 2015, Ouyang et al., 2015, Xu, 2017] and PIPGeq [Xu, 2017, Yu et al., 2020b] can achieve accelerated convergence rates for strongly convex objective functions, such accelerations is not possible for optimization (2) because the objective function in (2) is independent of variable y and, as a result, not strongly convex.

Another problem equivalent to optimization (1) is the following saddle-point problem, where K˝ is the polar cone of K [Chambolle and Pock, 2011, Chambolle and Pock, 2016b]:

minimize maximize f pzq ` xHz ´ g, wy. (3)

zPD

wPK˝

In particular, the primal-dual hybrid-gradient method
(PDHG) solves saddle-point problem (3) by computing one projection onto cone K˝ and one projection onto set D in each iteration. PDHG ensures that the primal-dual gap converges to zero at the rate of Op1{kq when for convex f , and at an accelerated rate of Op1{k2q for strongly convex f [Chambolle and Pock, 2016a, Chambolle and
Pock, 2016b]. However, since the constraint Hz ´ g P K

is not explicitly considered in (3), the existing convergence results on PDHG do not provide any convergence rates of the violation of this constraint [Chambolle and Pock, 2016a, Chambolle and Pock, 2016b].
We compare the per-iteration computation and the convergence rates of ADMM, PIPGeq and PDHG in Tab. 1. None of these methods simultaneously has accelerated convergence rates (i.e., better than Op1{kq) for strongly convex f and guaranteed convergence rates on the constraint violation. To our best knowledge, whether there exists a ﬁrst-order method that achieves both convergence results remains an open question.
We answer this question aﬃrmatively by proposing a novel primal-dual ﬁrst-order method for conic optimization, named proportional-integral projected gradient method (PIPG). By combining the idea of proportional-integral feedback control and projected gradient method, PIPG ensures the following convergence results.
(1) For convex f , both the primal-dual gap and the constraint violation converge to zero at the rate of Op1{kq.
(2) For strongly convex f , the convergence rate can be improved to Op1{k2q for the primal-dual gap and Op1{k3q for the constraint violation.
PIPG generalizes both PDHG with constant step sizes [Chambolle and Pock, 2016b, Alg. 1] and PIPGeq [Yu et al., 2020b]. Compared with the existing methods, PIPG has the following advantages; see Tab. 1 for an overview. In terms of per-iteration cost, it computes one projection onto cone K˝ and one projection onto set D, which is the same as PIPGeq and PDHG and fewer times of projections than ADMM. In terms of its convergence rates, to our best knowledge, the Op1{k3q convergence rate of constraint violation has never been achieved before for general conic optimization. We numerically demonstrate these advantages of PIPG on several constrained optimal control problems.
The rest of the paper is organized as follows. After some preliminary results on convex analysis, Section 2 re-

2

views existing ﬁrst-order conic optimization methods. Section 3 introduces PIPG along with its convergence results. Section 4 demonstrate PIPG via numerical examples on constrained optimal control. Finally, Section 5 concludes and comments on future work.

2 Preliminaries and related work

This section reviews some basic results in convex analysis and several existing ﬁrst-order conic optimization methods.

2.1 Notation and preliminaries

We let N, R and R` denote the set of positive integer,

real, and non-negative real numbers, respectively. For

two vectors z, z1 P Rn, xz, z1y denotes their inner prod-

uct,

z

:“

a xz,

zy

denotes

the

2 norm of z, and

¨8

denotes the 8 norm of z, i.e., the maximum absolute

value of the entries of z. We let 1n and 0n denote the

n-dimensional vectors of all 1’s and all 0’s, respectively.

We also let In and 0mˆn denote the n ˆ n identity ma-

trix and the m ˆ n zero matrix, respectively. When their

dimensions are clear from the context, we omit the sub-

scripts and simply write vector 1, 0 and matrix I, 0. For

a matrix H P Rmˆn, HJ denotes its transpose, |||H|||

denotes its largest singular value. For a square matrix

M P Rnˆn, exppM q denotes the matrix exponential of

M , and

z

M

:“

a xz, M zy

for

all

z

P

Rn.

Given

two

sets S1 and S2, S1 ˆ S2 denotes their Cartesian product.

Let z, z1 P Rn and f : Rn Ñ R be a continuously diﬀerentiable function. The Bregman divergence from z to z1
associated with function f is given by

Bf pz, z1q :“ f pzq ´ f pz1q ´ x∇f pz1q, z ´ z1y. (4)

We say function f is µ-strongly convex for some µ P R`

if

µ

2

Bf pz, z1q ě z ´ z1

(5)

2

for all z, z1 P Rn. When (5) holds with µ “ 0, we say

function f is convex. We say function f is λ-smooth for

some λ P R` if

Bf pz, z1q ď λ z ´ z1 2

(6)

2

for all z, z1 P Rn.

Let D Ă Rn be a closed convex set, i.e., D contains all of its boundary points and γz ` p1 ´ γqz1 P D for any γ P r0, 1s and z, z1 P D. The projection of z P Rn onto
set D is given by

πDrzs :“ argmin z ´ y .

(7)

yPD

Let K Ă Rm be a closed convex cone, i.e., K is a closed
convex set and γw P K for any w P K and γ P R`. The polar cone of K is also a closed convex cone given by

K˝ :“ tw P Rm|xw, yy ď 0, @y P Ku.

(8)

2.2 Related work
We brieﬂy review three existing ﬁrst-order primal-dual conic optimization methods: ADMM, PIPGeq, and PDHG. In the following, let α, β, γ denote positive scalar step sizes, and tαjujPN, tβjujPN, tγjujPN denote sequences of positive scalar step sizes. For simplicity, we assume all methods are terminated after a ﬁxed number of iterations, denoted by k P N.
2.2.1 Alternating direction method of multipliers
As a special case of Douglas-Rachford splitting method [Eckstein, 1989, Fortin and Glowinski, 2000], alternating direction method of multipliers (ADMM) solves optimization (1) by solving the equivalent optimization (2) using Algorithm 1 [Gabay and Mercier, 1976, Boyd et al., 2011, He and Yuan, 2012].
Algorithm 1 ADMM
Input: k, α, z1 P D, y1 P K, w1 P Rm Output: zk 1: for j “ 1, 2, . . . , k ´ 1 do 2: zj`1 “ argmin f pzq ` α2 Hz ´ yj ´ g ` wj 2
zPD
3: yj`1 “ πKrHzj`1 ´ g ` wj s 4: wj`1 “ wj ` Hzj`1 ´ yj`1 ´ g 5: end for

Generally, the minimization in the line 2 of Algorithm 1 can only be solved approximately up to a numerical tolerance ą 0 using iterative?methods. Such methods need to compute at least Op1{ q projections onto set D if f is merely convex, and Opln 1 q projections if function f is strongly convex; see [Nesterov, 2018, Chp. 2] for a detailed discussion.
There has been many variants of ADMM developed in the literature. However, none of them lead to any signiﬁcant beneﬁts for optimization in (2). For example, [Ouyang et al., 2015] and [Xu, 2017, Alg. 1] simpliﬁed the minimization in the line (2) of Algorithm 1 by approximating function f using its linearization. However, solving the resulting approximate minimization still requires multiple projections onto set D. On the other hand, although the convergence of ADMM can be accelerated when the objective function is strongly convex [Goldstein et al., 2014, Kadkhodaie et al., 2015, Ouyang et al., 2015, Xu, 2017], such acceleration does not apply

3

to the optimization (2). The reason is because the objective function in (2) is not strongly convex with respect to (in fact, does not depend on) variable y.
2.2.2 Proportional-integral projected gradient method for equality constrained optimization
Motivated by applications in model predictive control, the proportional-integral projected gradient method for equality constrained optimization (PIPGeq) solves optimization (1) by solving the equivalent optimization (2) using Algorithm 2.
Algorithm 2 PIPGeq
Input: k, α, β, z1 P D, y1 P K, w1 P Rm. Output: zk. 1: for j “ 1, 2, . . . , k ´ 1 do 2: vj`1 “ wj ` βpHzj ´ yj ´ gq 3: zj`1 “ πDrzj ´ αp∇f pzj q ` HJvj`1qs 4: yj`1 “ πKryj ` αvj`1s 5: wj`1 “ wj ` βpHzj`1 ´ yj`1 ´ gq 6: end for
Unlike line 2 in Algorithm 1, line 3 in Algorithm 2 computes only one projection onto set D instead of multiple times. As a result, PIPGeq can achieve the same convergence rates as those of ADMM while lowering the periteration computation cost [Xu, 2017, Yu et al., 2020b].
2.2.3 Primal-dual hybrid gradient method
Motivated by applications in computational imaging, the primal-dual hybrid gradient method (PDHG) was ﬁrst introduced in [Chambolle and Pock, 2011] and later shown to be equivalent to Douglas-Rachford splitting method [O’Connor and Vandenberghe, 2020]. Later, another variant of PDHG was introduced in [Chambolle and Pock, 2016b], which is an instance of three-operator splitting methods [Vu˜, 2013, Condat, 2013, Chen et al., 2016, Davis and Yin, 2017, Yan, 2018]. To solve optimization (1), PDHG solves the equivalent convexconcave saddle point problem (3) instead. If function f is merely convex, PDHG uses Algorithm 3. If function f is µ-strongly convex for some µ ą 0, then PDHG uses Algorithm 4 instead.
Algorithm 3 PDHG with constant step sizes
Input: k, α, β, z1 P D, w1 P K˝. Output: zk. 1: for j “ 1, 2, . . . , k ´ 1 do 2: zj`1 “ πDrzj ´ αp∇f pzjq ` HJwjqs 3: wj`1 “ πK˝ rwj ` βpHp2zj`1 ´ zj q ´ gqs 4: end for
The primal-dual gap converges to zero at the rate of Op1{kq and Op1{k2q for Algorithm 3 and Algorithm 4, respectively [Chambolle and Pock, 2016b]. However, to our best knowledge, there is no convergence result on

Algorithm 4 PDHG with varying step sizes

Input:

k

,

t

α

j

,

β

j

,

γ

j

u

k j“1

,

µ,

z

1

P D, w1

P K˝.

Output: zk.

1: for j “ 1, 2, . . . , k ´ 1 do 2: wj`1 “ πK˝ rwj ` βj pHpzj ` γj pzj ´ zj´1qq ´ gqs
3: zj`1 “ πD ”zj ´ µααjj`1 p∇f pzj q ` HJwj`1qı

4: end for

the constraint violation for either Algorithm 3 or Algorithm 4.

3 Proportional-integral projected gradient method

We introduce a novel ﬁrst-order primal-dual method, named proportional-integral projected gradient method (PIPG), for conic optimization (1), and discuss its convergence rates in terms of the constraint violation and the primal-dual gap.

Algorithm 5 summarizes the proposed method, where k P N is the maximum number of iterations, and tαjukj“1 and tβjukj“1 are sequences of positive scalar step sizes that will be speciﬁed later. We note that, instead of max-
imum number of iterations, one can use alternative stopping criterions, such as the distance between Hzj ´ g
and K reaching a given tolerance.

Algorithm 5 PIPG

Input:

k

,

t

α

j

,

β

j

u

k j“1

,

z

1

P D, v1

P K˝.

Output: zk.

1: for j “ 1, 2, . . . , k ´ 1 do 2: wj`1 “ πK˝ rvj ` βj pHzj ´ gqs 3: zj`1 “ πDrzj ´ αj p∇f pzj q ` HJwj`1qs 4: vj`1 “ wj`1 ` βj Hpzj`1 ´ zj q

5: end for

The name PIPG is due to the following observations. First, if K “ t0nu, then K˝ “ Rm and line 2 and line 4
in Algorithm 5 become the following:

wj`1 “vj ` βj pHzj ´ gq, vj`1 “vj ` βj pHzj`1 ´ gq.

(9a) (9b)

Using (9b) one can show that

j
vj “ v1 ` ÿ βi´1pHzi ´ gq,
i“2
Hence vk is a weighted summation, or numerical integration, of Hzi ´ g from i “ 2 to i “ j. Further, (9a) states that wj adds a proportional term of Hzj ´ g to vj, hence wj in (9a) is a proportional-integral term of

4

Hzj ´ g. Second, if H is a zero matrix, then line 3 in Algorithm 5 becomes a projected gradient method that minimizes f over set D [Nesterov, 2018, Sec. 2.2.5]. Therefore Algorithm 5 can be interpreted as a combination of proportional-integral feedback control and the projected gradient method. Similar idea has also been popular in equality constrained optimization [Wang and Elia, 2010, Yu et al., 2020a, Yu and A¸cıkme¸se, 2020, Yu et al., 2020b].

Remark 1 Notice that the wj`1 in (9a) is otherwise identical to the vj`1 in (9b) except that (9a) uses zj whereas (9b) uses zj`1. Such scheme is also known as a prediction-correction step, which has been popular in many ﬁrst-order primal-dual methods, including the extra-gradient and mirror-prox method [Korpelevich, 1977, Nemirovski, 2004, Nesterov, 2007], the accelerated linearized ADMM [Ouyang et al., 2015, Xu, 2017], the primal-dual ﬁxed point methods [Krol et al., 2012, Chen et al., 2013, Chen et al., 2016, Yan, 2018] and the accelerated mirror descent method [Cohen et al., 2018].

Remark 2 One can verify that if αj ” α and βj ” β for j “ 1, 2, . . . , k, then Algorithm 5 is equivalent to Algorithm 3, the latter was ﬁrst introduced in [Chambolle and Pock, 2016b, Alg. 1].

Next, we will show the convergence results of Algorithm 5. To this end, we will frequently use the following quadratic distance function to closed convex cone K:

d pwq :“ minimize 1 w ´ v 2 ,

(10)

K

vPK 2

which is continuously diﬀerentiable and convex [Nesterov, 2018, Lem. 2.2.9]. We will also use the following Lagrangian function:

Lpz, wq :“ f pzq ` xHz ´ g, wy.

(11)

We make the following assumptions on optimization (1).

Assumption 1 (1) Function f : Rn Ñ R is continuously diﬀerentiable. There exists µ, λ P R` with µ ď λ such that f is µ-strongly convex and λsmooth, i.e.,

µ z ´ z1 2 ď Bf pz, z1q ď λ z ´ z1 2

2

2

for all z, z1 P Rn. (2) Set D Ă Rn and cone K Ă Rm are closed and con-
vex. (3) There exists z‹ P D and w‹ P K˝ such that

Lpz‹, wq ď Lpz‹, w‹q ď Lpz, w‹q

for all z P D and w P K˝.

Under the above assumptions, the quantity Lpz, w‹q ´ Lpz‹, wq, also known as the primal-dual gap evaluated at pz, wq, is non-negative [Boyd et al., 2011, He and Yuan, 2012, Chambolle and Pock, 2011, Chambolle and Pock,
2016b]. The following proposition provides a suﬃcient
condition on z and w under which the primal-dual gap Lpz, w‹q ´ Lpz‹, wq equals zero and z is an optimal solution of optimization (1).

Proposition 1 If there exists z P D and w P K˝ such

that

Lpz, wq ´ Lpz, wq ď 0,

(12)

for all z P D and w P K˝, then z is an optimal solution of

optimization (1), i.e., Hz ´ g P K and f pzq ď f pzq for

any z P D such that Hz ´ g P K.

Proof See Appendix A.

As our ﬁrst step, the following lemma proves a key inequality for our later discussions.

Lemma 1 Suppose that Assumption 1 holds and

t

w

j

,

z

j

,

v

j

u

k j“1

is

computed

using

Algorithm

5

where

αj, βj ą 0 and αjpλ ` σβjq “ 1 for some σ ě |||H|||2

and all j “ 1, 2, . . . k . Then

βjdKpHzj ´ gq ` Lpzj`1, wq ´ Lpz, wj`1q

ˆ1 ď

µ˙ ´

zj ´ z

2
`

1

vj ´ w 2

2αj 2

2βj

1 ´

zj`1 ´ z

2
´

1

vj`1 ´ w 2 ,

2αj

2βj

for all z P D, w P K˝, and j “ 1, 2, . . . , k.

Proof See Appendix B.

Equipped with Lemma 1, we are ready to prove the convergence results of Algorithm 5. The idea is to ﬁrst summing up the inequality in Lemma 1 corresponding to diﬀerent value of j, then using the Jensen’s inequality.

We start with the case where µ “ 0, i.e., function f is merely convex. The following theorem shows the convergence results of Algorithm 5 in this case.

Theorem 1 Suppose that Assumption 1 holds with µ “

0, and twj, zj, vjukj“1 is computed using Algorithm 5 with

αj

“

1 βσ`λ

and

βj

“

β

and

all

j

“

1, 2, . . . , k,

where

β ą 0 and σ ě |||H|||2. Let

k

1

k
ÿ

j

z˜ :“

z,

zk

:“

1

k
ÿ

zj`1,

wk

:“

1

k
ÿ

wj`1,

k j“1

k j“1

k j“1

5

and V 1pz, wq :“ 21α z1 ´ z 2 ` 21β v1 ´ w 2 for all z P D and w P K˝. Then z˜k, zk P D, wk P K˝, and

k

V 1pz‹, w‹q

dKpHz˜ ´ gq ď

,

βk

Lpzk, wq ´ Lpz, wkq ď V 1pz, wq , k

for all z P D, w P K˝.

Proof See Appendix C.

Theorem 1 shows that z˜k, zk P D. In addition, as k increases, the violation of constraint Hz˜k ´ g P K, measured by nonnegative distance dKpHz˜k ´ gq, converges
to zero, and the condition in (12) holds asymptotically
for zk and wk.

If µ ą 0, i.e., function f is strongly convex, then we can further improve the convergence results in Theorem 1 as follows.

Theorem 2 Suppose that Assumption 1 holds with µ ą 0 and twj, zj, vjukj“1 is computed using Algorithm 5 with
αj “ pj`1q2µ`2λ and βj “ pj`2σ1qµ for some σ ą |||H|||2
and all j “ 1, 2, . . . , k. Let

k

3

k
ÿ

j

z˜ :“ kpk2 ` 6k ` 11q pj ` 1qpj ` 2qz ,

j“1

zk :“ 2

k
ÿ pj ` 2qzj`1,

kpk ` 5q j“1

wk :“ 2

k
ÿ pj ` 2qwj`1,

kpk ` 5q j“1

and V 1pz, wq :“ µ`42λ z1 ´ z 2 ` σµ v1 ´ w 2 for all z P D and w P K˝. Then z˜k, zk P D, wk P K˝, and

k

12λσV 1pz‹, w‹q

dKpHz˜ ´ gq ď µ2kpk2 ` 6k ` 11q ,

Lpzk, wq ´ Lpz, wkq ď 4λV 1pz, wq , µkpk ` 5q

for all z P D, w P K˝.

Proof See Appendix D.
Remark 3 Unlike the results in [Chambolle and Pock, 2016b], Theorem 1 and Theorem 2 prove not only the

convergence of the primal-dual gap, but also the convergence of the constraints violation. In addition, if αj ” α and βj ” β for j “ 1, 2, . . . , k, then one can show that Algorithm 5 is equivalent to Algorithm 3; in other words, the results in Theorem 1 also apply to Algorithm 3.
Remark 4 When using varying step sizes, Algorithm 5 diﬀers from Algorithm 4 in the relation between step sizes and the iteration number: the one in Algorithm 5 is explicit, whereas the one in Algorithm 4 is implicitly deﬁned by a recursive formula [Chambolle and Pock, 2016b, Sec. 5.2]. Furthermore, we can prove the convergence rate of the constraint violation for Algorithm 5, whereas similar rate for Algorithm 4 is, to our best knowledge, does not exist in the literature.

4 Applications to constrained optimal control

We demonstrate the application of PIPG to constrained optimal control problems. In Section 4.1, we show how to formulate a typical constrained optimal control problem as an instance of conic optimization (1), and provide examples from mechanical engineering and robotics. In Section 4.2, we demonstrate the performance of PIPG via said examples, and compare it against the existing methods reviewed in Section 2.2. Throughout we let nx, nu, px, pu P N denote the dimension of diﬀerent vector spaces, ∆ P R` denote a positive sampling time period, and t P N denote a discrete time index.

4.1 Constrained optimal control

We consider the following linear time invariant system

d ds xpsq “ Acxpsq ` Bcupsq ` hc (13)
where x : R` Ñ Rnx and u : R` Ñ Rnu denote the state and input function, respectively. Matrix Ac P Rnxˆnx , Bc P Rnxˆnu , and vector hc P Rnx are known parameters.

If the input changes value only at discrete time instants, then we can simplify dynamics (13) as follows. Let ∆ P N` and xt :“ xpt∆q, ut :“ upt∆q for all t P N. Suppose that
upsq “ upt∆q, t∆ ď s ă pt ` 1q∆,
for all t P N. Then dynamics equation (13) is equivalent to the following

xt`1 “ Axt ` But ` h,

(14)

for all t P N, where

A “ exppAc∆q, B “ ´ş0∆ exppAcsqds¯ Bc,

´

¯

(15)

h “ ş0∆ exppAcsqds hc.

6

For further details on the above equivalence, we refer the interested readers to [Chen, 1999, Sec. 4.2.1].

Let txt`1, utuτt“´01 denote a length-τ input-state trajectory of system (14) for some τ P N, and txˆt`1, uˆtutτ“´11 denote a desired length-τ reference input-state trajectory.
A typical optimal control problem is the minimization of the diﬀerence between txt`1, utuτt“´01 and txˆt`1, uˆtuτt“´01 subject to various constraints:

minimize
tut ,xt`1 uτt“´01

τ ´1

1 2

řp

xt`1 ´ xˆt`1

2 Q

`

t“0

ut ´ uˆt 2Rq (16a)

subject to xt`1 “ Axt ` But ` h, 0 ď t ď τ ´ 1, (16b)

ut`1 ´ ut 8 ď γ, 0 ď t ď τ ´ 2, (16c) Ctxt ´ at ě 0, xt P X, 1 ď t ď τ, (16d)
Dtut ´ bt ě 0, ut P U, 0 ď t ď τ ´ 1. (16e)

In particular, the objective function in (16a) is

a quadratic distance between txt`1, utuτt“´01 and

txˆ

t

`1

,

uˆ

t

u

τ ´1 t“0

,

where

Q

P

Rnx ˆnx

and

R

P

Rnu ˆnu

are

given symmetric and positive deﬁnite weighting matri-

ces. The constraints in (16b) ensure that inpiut-state

trajectory tu0:τ´1, x1:τ u agree with the dynamics (14), where x0 P Rnx is the given initial state. The con-

straints in (16c) upper bound the elementwise diﬀerence

between two consecutive inputs by γ P R`, which pre-

vents frequent and large input variations [Betts, 2010,

Sec. 4.10]. The constraints in (16d) and (16e) describe

possible physical and operational constraints on states

and inputs, where Ct P Rpxˆnx , Dt P Rpuˆnu , at P Rpx , bt P Rpu , X Ă Rnx and U Ă Rnu are closed convex sets.

One can transform optimization (16) into a special case of optimization (1) using particular choices of the parameters. See Appendix E for the detailed transformation.

In the following, we will provide two illustrating examples of optimization (16) from mechanical engineering and robotics applications. For simplicity, all problem parameters will be unitless.

4.1.1 Oscillating masses control

We consider the problem of controlling a one-dimensional oscillating masses system using external forcing [Wang and Boyd, 2009, K¨ogel and Findeisen, 2011, Jerez et al., 2014]. The system consists of a sequence of N masses connected by springs to each other, and to walls on either side. Each mass has value 1, and each spring has a spring constant of 1. See Fig. 1 for an illustration.

We model the dynamics of the oscillating masses system

”

ıJ

as follows. At time t∆, we let xt “ rtJ sJt denote

the state of the system, where the i-th element of vector rt P RN and st P RN is the displacement and velocity of the i-th mass, respectively. Further, we let ut P RN denote the input to the system at time t, whose i-th
element is the external force exerted to the i-th mass.
We let x0 “ 02N be the state of the system at time 0. Let LN P RNˆN is a symmetric tri-diagonal matrix whose diagonal entries are 2, and its sub-diagonal and super-
diagonal entries are ´1. The discrete time dynamics of this system with sampling time period ∆ is given by (14)
and (15) where

«

ﬀ

«

ﬀ

Ac “

0NˆN IN ´LN 0NˆN

, Bc “

0N ˆN IN

, hc “ 02N .

...

Fig. 1. The oscillating masses system
We consider the following constraints at each discrete time t. The displacement, velocity and external force on each mass cannot exceed r´δ1, δ1s, r´δ2, δ2s and r´ρ, ρs, respectively, where δ1, δ2, ρ P R`. Further, for each external force, the maximum change in its magnitude within a sampling period ∆ is γ. The aforementioned constraints are given by (16c), (16d) and (16e) where

X “ tr P RN | r 8 ď δ1u ˆ ts P RN | s 8 ď δ2u,

U “ tu P RN | u ď ρu.

(17)

8

Here the conic constraints in (16d) and (16e) (i.e., Ctxt´ at ě 0 and Dtxt ´ bt ě 0) are not considered.

4.1.2 Quadrotor path planning

We consider the problem of ﬂying a quadrotor from its initial position to a target position while avoiding collision with cylinderical obstacles, see Fig. 3 for an illustration. For the quadrotor dynamics, we consider the 3DoF model of the Autonomous Control Laboratory (ACL) custom quadrotor [Szmuk, 2019, Ch.3]; see Fig. 5 and Fig. 5 for an illustration.

Fig. 2. Autonomous Control Laboratory custom quadrotor
We model the dynamics of the quadrotor as follows. At time t∆, the state of the quadrotor is given by xt “

7

”

ıJ

rtJ sJt , where rt P R3 and st P R3 denote the posi-

tion and velocity of the quadrotor’s center of mass, re-

spectively. We let x0 be the state of the system at time

0. The input of the quadrotor at time t is the thrust vector generated by its propellers, denoted by ut P R3. Let

m0 “ 0.35 be the mass of the quadrotor and g0 “ 9.8 be

the gravitational constant. The discrete time quadrotor

dynamics with sampling time period ∆ is given by (14)

and (15) where

«

ﬀ

«ﬀ

«ﬀ

Ac “ 03ˆ3 I3

1 , Bc “

03ˆ3 , hc “

05 .

03ˆ3 03ˆ3

m0 I3

´g0

obstacle target position

obstacle

obstacle

initial position

Fig. 3. The quadrotor path planning problem.

We consider the following constraints on the thrust vec-

tor of the quadrotor. Due to the maximum power limit

of the on-board motors, the magnitude of the thrust vec-

tor is upper bounded by ρ1 P R`. In addition, the vertical component of the thrust vector is lower bounded by

ρ2 P R` so the on-board motors are never turned oﬀ during the ﬂight. The elementwise diﬀerence between two

consecutive thrust vectors is upper bounded by γ P R` to ensure a smooth thrust trajectory. Further, to up-

per bound the tilting angle of the quadrotor, we let the

thrust vector be conﬁned to a vertical icecream cone with

”

ıJ

half-angle

θ

P

r0,

π 2

s.

Let

e

“

001

, we can write the

aforementioned constraints as (16c) and (16e) where

U “ u P R3 | u cos θ ď xu, ey, u ď ρ1 ( , (18)
Dt “ e, bt “ ρ2.

We also consider the following collision avoidance constraints. We want the position of the quadrotor to stay out of three vertical cylindrical region, i.e.,

M xt ´ oi

2
ěp

iq2,

(19)

”

ı

for all i “ 1, 2, 3, where M “ I2 02ˆ4 , oi P R2 and

i P R` for all i “ 1, 2, 3. However, the above constraints are nonconvex, which render the resulting problem com-

putationally challenging to solve. As a remedy, we consider the following linear approximation of (19):

xcit, xty ě ait,

(20)

for all i “ 1, 2, 3; see Fig. 3 for an illustration. In Ap-
pendix F, we provide the detailed procedure on computing cit P R6 and ait P R, and refer the interested reader to [Zagaris et al., 2018, Sec. 4] for a detailed discussion
on this approximation.

i
at yě i ,xt xc t
oi
i

Fig. 4. Linearization of the constraint in (19) using (20)
With the above approximation, we can write the state constraints of the quadrotor in the form of (16d) where

X “ tr P R3| r 8 ď δ1u ˆ ts P R3| s ď δ2u,

»ﬁ

»ﬁ

pc1t qJ

a1t

Ct “ ——pc2qJﬃﬃ , at “ ——a2ﬃﬃ , Kx “ R3 ,

(21)

t

t

`

–ﬂ

–ﬂ

pc3t qJ

a3t

for some δ1, δ2 P R`. Here the set X ensures the position and velocity of the quadrotor are bounded.

4.2 Numerical implementation and experiments

We now discuss the numerical implementation of Algorithm 5 and demonstrate its performance using the two examples of constrained optimal control problems in Section 4.1.

4.2.1 Eﬃcient projections

The key step of implementing PIPG method is to compute the projection onto cone K˝ and set D. These projections can be computed eﬃciently for the following rea-
sons. First, projections onto many common closed con-
vex cones and sets can be computed using simple for-
mulas, see [Bauschke and Combettes, 2017, Chp. 29] for
some popular examples. The projection formula for the
set U in (18) is given in [Bauschke et al., 2018, Cor. 7.3]. Second, let D1 Ă Rn1 and D2 Ă Rn2 be closed convex sets, x1 P Rn1 and x2 P Rn2 . Then one can verify the following:

«« ﬀﬀ «

ﬀ

πD1ˆD2 x1 “ πD1 rx1s .

x2

πD2 rx2s

8

Therefore, projections onto sets that are Cartesian products of sets with simple projection formulas, such as the set X in (17) and (21), also admit simple formulas.

4.2.2 Numerical experiments

We demonstrate the numerical performance of PIPG using the two examples of optimization (16), namely the oscillating masses problem and the quadrotor path planning problem discussed in Section 4.1. We summarize the values of diﬀerent problem parameters of these two examples in Appendix F.

We compare the performance of PIPG, ADMM, PIPGeq and PDHG using optimization (16) as follows. We initilize all methods using vectors whose entries are sampled from the standard normal distribution. We compare the performance of diﬀerent methods using the convergence of the following two quantities:

errorjopt :“

zj ´ z‹ 2

j

dKpHzj ´ gq

, errorfea :“

2,

z‹ 2

z‹

(22)

where zj P D is the candidate solution computed of op-

timization (16) at the j-th iteration for j “ 2, 3, . . . , k,

and z‹ be the ground truth optimal solution of optimiza-

tion (16) computed using commercial software Mosek

[MOSEK ApS, 2019]. In addition, we also consider a

restarting variant of PIPG where the iteration counter

j is periodically reset to 1. Such restarting scheme is a

popular heuristics for improving practical convergence

performance of primal-dual methods [Su et al., 2016, Xu,

2017].

The convergence results of diﬀerent methods in terms of of ejopt and ejopt using 100 independent random initializations are illustrated in Fig. 5. From these results we can see that PIPG clearly outperforms existing methods, especially when combined with the restarting heuristics. Note that, although the performance of ADMM is close to PIPG in the oscillating masses example, the periteration cost of ADMM is much higher than PIPG, as shown in Tab. 1. Therefore, PIPG still has clear advantage against ADMM.

5 Conclusions
We propose a novel primal-dual ﬁrst-order method for conic optimization, named PIPG. We prove the convergence rates of PIPG in terms of the constraint violation and the primal-dual gap. We demonstrate the application of PIPG using examples in constrained optimal control. However, several questions still remain open. For example, it is unclear whether our method allow realtime implementation more eﬃcient than interior point methods, or whether there are other restarting heuristcs better than the periodic one in Section 4. We aim to answer these open questions in our future work.

100 10−5 10−10

100 10−5 10−10 10−15

10−15 0

500 1000 1500 2000 10−20 0 j

500 1000 1500 2000 j

(a) errorjopt 100
10−5
10−10

100 10−5 10−10 10−15

(b) errorjfea
PIPG PIPG w/ restart PIPGeq ADMM PDHG

10−15 0

500 1000 1500 2000 10−20 0 j

500 1000 1500 2000 j

(c) errorjopt

(d) errorjfea

Fig. 5. Comparison of diﬀerent methods for oscillating masses problem (top row) and quadrotor path planning problem (bottom row). The shaded region shows the range of 100 different simulation results using independent random initializations.
A Proof of Proposition 1

We will use the following results.
Lemma 2 [Rockafellar, 2015, Thm. 27.4] Let set D Ă Rn be closed and convex and function f : Rn Ñ R be continuously diﬀerentiable and convex. If f pz‹q ď f pzq for all z P D, then x∇f pz‹q, z ´ z‹y ě 0 for any z P D.
Lemma 3 [Rockafellar and Wets, 2009, Cor. 6.21] If K Ă Rm is a closed convex cone, then K˝ is a closed convex cone and pK˝q˝ “ K.
We are now ready to prove Proposition 1.

Proof First, if (12) holds, then we immediately have

Lpz, wq ď Lpz, wq ď Lpz, wq

(A.1)

for all z P D and w P K˝. The ﬁst inequality above states that ´Lpz, wq ď ´Lpz, wq for all w P K˝, which, due to
Lemma 2, implies that

xHz ´ g, w ´ wy ď 0

(A.2)

9

for all w P K˝. By letting w “ 0 and w “ 2w in (A.2), we conclude that

xHz ´ g, wy “ 0.

(A.3)

Combining (A.2) and (A.3) gives xHz ´ g, wy ď 0 for all w P K˝. Hence Hz ´ g P pK˝q˝ “ K, where the last step
is due to Lemma 3.

Second, let z be such that z P D and Hz ´ g P K. Since w P K˝, using (8) we can show

Lpz, wq “ f pzq ` xHz ´ g, wy ď f pzq.

(A.4)

Further, using (A.1) and (A.3) we can show

f pzq “ Lpz, wq ď Lpz, wq.

(A.5)

By combining (A.4) and (A.5) we have f pzq ď f pzq. Since z is otherwise arbitrary except that z P D and Hz ´ g P K, the proof is completed.

B Proof of Lemma 1

We start with some basic results that are necessary for the proof later. First, using (4), one can verify the following identity:

x∇f pzq ´ ∇f pz1q, z2 ´ zy
“ Bf pz2, z1q ´ Bf pz2, zq ´ Bf pz, z1q, @z, z1, z2 P Rn. (B.1)
If f “ ¨ 2, the above identify becomes the following:

2xz ´ z1, z2 ´ zy “

z2 ´ z1

2
´

z2 ´ z

2
´

z ´ z1 2 .

(B.2)

Second, we will use Lemma 3, together with the following

existing results.

Lemma 4 [Nesterov, 2018, Lem. 2.2.7] If set D Ă Rn is closed and convex, then xπDrzs ´ z, z1 ´ πDrzsy ě 0 for any z P Rn and z1 P D.

Lemma 5 [Bauschke and Combettes, 2017, Thm. 6.30] If K Ă Rm is a closed convex cone, then πKrws`πK˝ rws “ w for all w P Rm.

We are now ready to prove Lemma 1.

Proof Let z, w, j be an arbitrary element in set D, cone K˝, and set t1, 2, . . . ku, respectively. We start with constructing an upper bound for Lpzj`1, wq ´ Lpz, wj`1q.
To this end, ﬁrst we use (11) and (4) to show the follow-
ing identities

Lpzj`1, wq ´ Lpz, wq “ Bf pzj`1, zq ` x∇f pzq ` HJw, zj`1 ´ zy,

(B.3)

Lpz, wq ´ Lpz, wj`1q “ xHz ´ g, w ´ wj`1y. (B.4)

Second, by applying Lemma 4 to the two projections in line 2 and 3 in Algorithm 5 we can show the following two inequalities
0 ď xwj`1 ´ vj ´ βjpHzj ´ gq, w ´ wj`1y, (B.5a) 0 ď xzj`1 ´ zj ` αj p∇f pzj q ` HJwj`1q, z ´ zj`1y,
(B.5b)

Third, line 4 in Algorithm 5 implies the following

0 “ xvj`1 ´ wj`1 ´ βj Hpzj`1 ´ zj q, w ´ vj`1y. (B.6)

Summing

up

(B.3),

(B.4),

1 βj

ˆ(B.5a),

1 αj

ˆ(B.5b)

and

1 βj

ˆ(B.6)

gives

the

following

inequality

Lpzj`1, wq ´ Lpz, wj`1q

ď Bf pzj`1, zq ` x∇f pzq ´ ∇f pzjq, zj`1 ´ zy

`

1 αj

xzj`1

´

zj, z

´

zj`1y

`

1 βj

xwj`1

´

vj, w

´

wj`1y

`

1 βj

xvj`1

´

wj`1, w

´

vj`1y

` xvj`1 ´ wj`1, Hpzj`1 ´ zj qy.

(B.7)

Our next step is to bound the inner product terms in

(B.7). To this end, ﬁrst we use (B.1) and (B.2) to show

the following identities

x∇f pzq ´ ∇f pzjq, zj`1 ´ zy “ Bf pzj`1, zj q ´ Bf pzj`1, zq ´ Bf pz, zj q,

(B.8)

2xzj`1 ´ zj , z ´ zj`1y

“

zj ´ z

2
´

zj`1 ´ z

2
´

zj`1 ´ zj 2 ,

(B.9)

2xwj`1 ´ vj , w ´ wj`1y

“

vj ´ w

2
´

wj`1 ´ w

2
´

wj`1 ´ vj 2 ,

2xvj`1 ´ wj`1, w ´ vj`1y

(B.10)

“

wj`1 ´ w

2
´

vj`1 ´ w

2
´

vj`1 ´ wj`1 2 .

(B.11)

Second, by completing the square we can show

2βj xvj`1 ´ wj`1, Hpzj`1 ´ zj qy ď vj`1 ´ wj`1 2 ` pβj q2 Hpzj`1 ´ zj q 2 . (B.12)

Notice that now all inner product terms in (B.7) can be
upper bounded. Finally, we further simplify these upper
bounds. To this end, ﬁrst we use the item 1 in Assumption 1 and the fact that |||H|||2 ď σ to show the following

Bf pzj`1, zj q ď λ2 zj`1 ´ zj 2 , ´Bf pz, zjq ď ´ µ2 zj ´ z 2 ,

(B.13a) (B.13b)

10

Hpzj`1 ´ zj q 2 ď σ zj`1 ´ zj 2 .

(B.13c)

Second, we let yj

:“

1 βj

pv

j

`

β

j

pH

z

j

´

g

q

´

wj

`1

q.

Apply-

ing Lemma 3 and Lemma 5 to the projection in line 2 of

Algorithm 5 we can show that βjyj P pK˝q˝ “ K. Since

K is a cone and βj ą 0, we know yj P K. Therefore,

using (10) and deﬁnition of yj we can show

dKpHzj ´ gq ď 12 Hzj ´ g ´ yj 2 “ 2pβ1j q2 wj`1 ´ vj 2 .

(B.14)

Finally,

summing

up

(B.7),

(B.8),

1 2αj

ˆ(B.9),

1 2βj

ˆ(B.10),

2β1j ˆ(B.11), 2β1j ˆ(B.12), (B.13a), (B.13b), β2j ˆ(B.13c),

and βjˆ(B.14), and using the assumption that

αjpλ ` σβjq “ 1 we obtain the desired results.

C Proof of Theorem 1

We will use the following result.

Lemma 6 [Nesterov, 2018, Lem. 3.1.1] If function f : Rn Ñ R is convex, then

ˆ

˙

f

řk 1 γj řkj“1 γkzj

ď

1 řk

γj

řk
j“1

γ

j

f

pzj

q

(C.1)

j“1

j“1

for any z1, z2, . . . , zk P Rn and γ1, γ2, . . . , γk P R`. We are now ready to prove Theorem 1.

Proof Let z, w, j be an arbitrary element in set D, K˝ and t1, 2, . . . ku, respectively. Let V jpz, wq “ 21α zj ´ z 2 ` 21β wj ´ w 2. Since αj “ βσ1`λ and βj “ β, the inequality in Lemma 1 implies the following:

Lpzj`1, wq ´ Lpz, wj`1q ` βdKpHzj ´ gq ď V jpz, wq ´ V j`1pz, wq,

for all z P D, w P K˝, and j “ 1, 2, . . . , k. Summing up this inequality for j “ 1, . . . , k gives

řk
j“1

`Lpzj`1,

wq

´

Lpz,

wj`1q

`

β dK pH z j

´

gq˘

ď V 1pz, wq ´ V k`1pz, wq ď V 1pz, wq,

(C.2)

for all z P D and w P K˝, where the last step is because V k`1pz, wq ě 0. From (10) and item 3 Assumption 1 we know that dKpHzj ´gq and Lpzj`1, w‹q´Lpz‹, wj`1q are

non-negative for all j. Hence (C.2) implies the following

řk
j“1

`Lpzj`1,

wq

´

Lpz,

wj`1q˘

ďV

1pz,

wq,

β

řk
j“1

dK pH z j

´

gq

ďV

1pz‹,

w‹q,

for all z P D, w P K˝, where the second inequality is obtained by letting z “ z‹ and w “ w‹ in (C.2).
Finally, applying the Jensen’s inequality in (6) to convex function Lp¨, wq, ´Lpz, ¨q, and dKp¨q in the above two inequalities, respectively, we obtain the desired results.

D Proof of Theorem 2 We will use Lemma 6 in the following proof.

Proof Let z, w, j be an arbitrary element in set D, K˝ and t1, 2, . . . ku, respectively. Let V jpz, wq “ 2α1j´1 zj ´ z 2` 2β1j´1 vj ´ w 2. Since αj “ pj`1q2µ`2λ
and βj “ pj`2σ1qµ , the inequality in Lemma 1 implies the following:

Lpzj`1, wq ´ Lpz, wj`1q ` pj`2σ1qµ dKpHzj ´ gq ď 12 p α1j ´ µq zj ´ z 2 ` 2β1j vj ´ w 2 ´ V j`1pz, wq,
(D.1) for all z P D, w P K˝, and j “ 1, 2, . . . , k. Let κ “ λ{µ ě 1, then one can verify the following

p

1 αj

´ µqpj

` 2κq

“

1 αj´1

pj

` 2κ ´ 1q,

1 βj

pj

`

2κq

ď

1 βj´1

pj

`

2κ

´

1q.

(D.2)

Hence multiplying (D.1) with pj ` 2κq then substituting in (D.2) we can show

pj ` 2κqpLpzj`1, wq ´ Lpz, wj`1qq
` pj`1qp2jσ`2κqµ dKpH zj ´ gq ď pj ` 2κ ´ 1qV jpz, wq ´ pj ` 2κqV j`1pz, wq,

for all z P D, w P K˝, and j “ 1, 2, . . . , k. Summing up this inequality for j “ 1, 2, . . . , k gives

řkj“1pj ` 2κqpLpzj`1, wq ´ Lpz, wj`1qq

`

řk
j“1

pj`1qp2jσ`2κqµ dKpH zj

´

gq

ď 2κV 1pz, wq ´ pk ` 2κqV k`1pz, wq ď 2κV 1pz, wq,

(D.3)

for all z P D and w P K˝, where the last step is because V k`1pz, wq ě 0. From (10) and item 3 in Assumption 1 we know that dKpHzj ´ gq and pzj`1, wj`1; z‹, w‹q are
non-negative for all j. Hence the above inequality implies

the following

řkj“1pj ` 2q`Lpzj`1, wq ´ Lpz, vj`1q˘ ď 2κV 1pz, wq,

řk
j“1

pj`1q2pσj`2qµ dKpH zj

´

gq

ď

2κV

1pz‹, w‹q,

for all z P D and w P K˝, where we used the fact that
κ ě 1, and the second inequality is obtained by letting z “ z‹ and w “ w‹ in (D.3).

11

Finally, applying the Jensen’s inequality in Lemma 6 to convex function Lp¨, wq, ´Lpz, ¨q, and dKp¨q in the above two inequalities, respectively, we obtain the desired results.

E Transformation from an optimal control problem to a conic optimization

We will use the following notation. We let b denotes the Kronecker product, and pDqτ denotes the Cartesian
product of τ copies of set D.

The optimization in (16) is a special case of (1) by letting

”

ıJ

z “ xJ1 xJ2 ¨ ¨ ¨ xJτ uJ0 uJ1 ¨ ¨ ¨ uJτ´1 ,

f pzq “ 1 zJP z ` xp, zy, 2

«

ﬀ

Iτ b Q 0

P“

,

0 Iτ b R

”

ıJ

p “ xˆJ1 xˆJ2 ¨ ¨ ¨ xˆJτ uˆJ1 uˆJ2 ¨ ¨ ¨ uˆJτ ,

»

ﬁ

AB

»ﬁ h

—— 0 — H “ —— 0
— —C –

E

ﬃ ﬃ

ﬃ

´Eﬃﬃ ,

ﬃ

0ﬃ ﬂ

——´γ1ﬃﬃ —ﬃ g “ ——´γ1ﬃﬃ ,
—ﬃ —aﬃ –ﬂ

0D

b

K “ 0nxτ ˆ R2`nupτ ´1q`τ ppx`puq, D “ X ˆ U,

where

«

ﬀ

00

A “ Iτnx ´

, B “ ´Iτ b B,

Iτ´1 b A 0

”

ı”

ı

E “ Ipτ ´1qnu 0 ´ 0 Ipτ ´1qnu ,

»

ﬁ

C1 0 ¨ ¨ ¨ 0

»

ﬁ

D1 0 ¨ ¨ ¨ 0

— —

0

C2 ¨ ¨ ¨

C “— — —0

...

...

–

0

ﬃ ﬃ

— —

0

..

ﬃ, ﬃ

D“— —

.ﬃ

—0

ﬂ

–

D2 ¨ ¨ ¨ ... ...

0

ﬃ ﬃ

..

ﬃ, ﬃ

.ﬃ

ﬂ

0 0 ¨ ¨ ¨ Cτ

0 0 ¨ ¨ ¨ Dτ

”

ıJ

”

ıJ

a “ aJ1 aJ2 ¨ ¨ ¨ aJτ , b “ bJ1 bJ2 ¨ ¨ ¨ bJτ ,

”

ıJ

h “ pAx0 ` h0qJ hJ1 ¨ ¨ ¨ hJτ´1 ,

X “ pXqτ , U “ pUqτ .

F Parameters of the optimal control problems in Section 4.2

Oscillating masses We let the number of masses to

be N “ 4. In (16), we let τ “ 30, Q “ I2N , R “ IN ,

”

ıJ

uˆt “ 0N and xˆt`1 “ 1JN 0JN for all t “ 0, 1, . . . , τ ´1.

We also let γ “ 0.5 in (16c), ∆ “ 0.25 in (15), and

δ1 “ δ2 “ ρ “ 2 in (17).

Quadrotor path planning In (16), we let τ “ 30,

«

ﬀ

Q“

I3 0 , R “ 0.5I3, uˆt “ 03, and xˆt`1 “
0 2.5I3

”

ıJ

rˆtJ`1 sˆJt`1 where sˆt`1 “ 03 and

»ﬁ

»ﬁ

2.5

´1.5

t ` 1 — ﬃ ˆ t ` 1˙— ﬃ

rˆt`1 “

—1.5ﬃ ` 1 ´

—´2.5ﬃ .

τ– ﬂ

τ– ﬂ

0

0

for all t “ 0, 1, 2, . . . , τ ´ 1. We also let γ “ 3 in (16c), ∆ “ 0.25 in (15). We let θ “ π{4, δ1 “ 3, δ2 “ 5, ρ1 “ 5, ρ2 “ 2 in (18). For all t “ 1, . . . , τ , we let
cit “ 2M Jpr˜t ´ oitq, ait “ r˜t 2 ` p iq2 ´ oi 2 ,

for i “ 1, 2, 3 in (21), where

«ﬀ

«ﬀ

«ﬀ

o1 “ ´1.5 , o2 “ 1.2 , o3 “ 1.5 ,

´1.5

´1.2

1.5

”

ı

2 “ 1.2, 3 “ 0.8, M “ I2 02ˆ4 ,

1 “ 0.8,

and r˜t is computed as follows. If rˆt ´ oi ě i for all
i “ 1, 2, 3, then r˜t “ rˆt. If there exists i P t1, 2, 3u such that rˆt ´ oi ă i, then r˜t “ oi ` rˆt´ioi prˆt ´ oiq. One can verify that rˆt ‰ oi for all t “ 1, 2, . . . , τ and
i “ 1, 2, 3 and there exists at most one i P t1, 2, 3u such that rˆt ´ oi ă i. Hence the r˜t computed in the above
manner is well deﬁned and unique.

References
[Andersen et al., 2003] Andersen, E. D., Roos, C., and Terlaky, T. (2003). On implementing a primal-dual interior-point method for conic quadratic optimization. Math. Program., 95(2):249– 277.
[Andersen et al., 2011] Andersen, M., Dahl, J., Liu, Z., Vandenberghe, L., Sra, S., Nowozin, S., and Wright, S. (2011). Interior-point methods for large-scale cone programming. Optim. Mach. Learn., 5583.

12

[Bauschke et al., 2018] Bauschke, H. H., Bui, M. N., and Wang, X. (2018). Projecting onto the intersection of a cone and a sphere. SIAM J. Optim., 28(3):2158–2188.

[Bauschke and Combettes, 2017] Bauschke,

H.

H.

and Combettes, P. L. (2017). Convex Analysis and Monotone

Operator Theory in Hilbert Spaces, volume 408. Springer.

[Ben-Tal and Nemirovski, 2001] Ben-Tal, A. and Nemirovski, A. (2001). Lectures on Modern Convex Optimization: Analysis, Algorithms, and Engineering Applications. SIAM.

[Betts, 2010] Betts, J. (2010). Practical Methods for Optimal Control and Estimation using Nonlinear Programming. SIAM, Philadelphia.

[Boyd et al., 2011] Boyd, S., Parikh, N., and Chu, E. (2011). Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers. Now Publishers Inc.

[Boyd and Vandenberghe, 2004] Boyd, S. P. and Vandenberghe, L. (2004). Convex Optimization. Cambridge University Press.

[Chambolle and Pock, 2011] Chambolle, A. and Pock, T. (2011). A ﬁrst-order primal-dual algorithm for convex problems with applications to imaging. J. Math. Imaging Vis., 40(1):120–145.

[Chambolle and Pock, 2016a] Chambolle, A. and Pock, T. (2016a). An introduction to continuous optimization for imaging. Acta Numerica, 25:161–319.

[Chambolle and Pock, 2016b] Chambolle, A. and Pock, T. (2016b). On the ergodic convergence rates of a ﬁrst-order primal–dual algorithm. Math. Program., 159(1-2):253–287.

[Chen, 1999] Chen, C.-T. (1999). Linear System Theory and Design. Oxford University Press, New York.

[Chen et al., 2013] Chen, P., Huang, J., and Zhang, X. (2013). A primal–dual ﬁxed point algorithm for convex separable minimization with applications to image restoration. Inverse Problems, 29(2):025011.

[Chen et al., 2016] Chen, P., Huang, J., and Zhang, X. (2016). A primal-dual ﬁxed point algorithm for minimization of the sum of three convex separable functions. Fixed Point Theory Appl., 2016(1):1–18.

[Cohen et al., 2018] Cohen, M., Diakonikolas, J., and Orecchia, L. (2018). On acceleration with noise-corrupted gradients. In Int. Conf. Mach. Learn., pages 1019–1028. PMLR.

[Condat, 2013] Condat, L. (2013). A primal–dual splitting method for convex optimization involving lipschitzian, proximable and linear composite terms. J. Optim. Theory Appl., 158(2):460–479.

[Davis and Yin, 2017] Davis, D. and Yin, W. (2017). A threeoperator splitting scheme and its optimization applications. Set-Valued Var. Anal., 25(4):829–858.

[Eckstein, 1989] Eckstein, J. (1989).

Splitting Methods

for Monotone Operators with Applications to Parallel

Optimization. PhD thesis, Massachusetts Inst. Technol.

[Eren et al., 2017] Eren, U., Prach, A., Ko¸cer, B. B., Rakovi´c, S. V., Kayacan, E., and A¸cıkme¸se, B. (2017). Model predictive control in aerospace systems: Current state and opportunities. J. Guid. Control Dyn., 40(7):1541–1566.

[Fortin and Glowinski, 2000] Fortin, M. and Glowinski, R. (2000). Augmented Lagrangian methods: Applications to the Numerical Solution of Boundary-Value Problems. Elsevier.

[Gabay and Mercier, 1976] Gabay, D. and Mercier, B. (1976). A dual algorithm for the solution of nonlinear variational problems via ﬁnite element approximation. Comput. Math. Appl., 2(1):17–40.

[Goldstein et al., 2014] Goldstein, T., O’Donoghue, B., Setzer, S., and Baraniuk, R. (2014). Fast alternating direction optimization methods. SIAM J. Imag. Sci., 7(3):1588–1623.

[He and Yuan, 2012] He, B. and Yuan, X. (2012). On the Op1{nq convergence rate of the douglas–rachford alternating direction method. SIAM J Numer. Anal., 50(2):700–709.

[Jerez et al., 2014] Jerez, J. L., Goulart, P. J., Richter, S., Constantinides, G. A., Kerrigan, E. C., and Morari, M. (2014). Embedded online optimization for model predictive control at megahertz rates. IEEE Trans. Automat. Control, 59(12):3238– 3251.

[Kadkhodaie et al., 2015] Kadkhodaie, M., Christakopoulou, K., Sanjabi, M., and Banerjee, A. (2015). Accelerated alternating direction method of multipliers. In Proc Int. Conf. Knowl. Discovery Data Mining, pages 497–506.

[K¨ogel and Findeisen, 2011] Ko¨gel, M. and Findeisen, R. (2011). Fast predictive control of linear systems combining Nesterov’s gradient method and the method of multipliers. In Proc. IEEE Conf. Decision Control and Eur. Control Conf., pages 501–506. IEEE.

[Korpelevich, 1977] Korpelevich, G. (1977). Extragradient method for ﬁnding saddle points and other problems. Matekon, 13(4):35–49.

[Krol et al., 2012] Krol, A., Li, S., Shen, L., and Xu, Y. (2012). Preconditioned alternating projection algorithms for maximum a posteriori ect reconstruction. Inverse problems, 28(11):115005.

[Lan et al., 2011] Lan, G., Lu, Z., and Monteiro, R. D. (2011). Primal-dual ﬁrst-order methods with Op1{ q iterationcomplexity for cone programming. Math. Program., 126(1):1– 29.

[Liu et al., 2017] Liu, X., Lu, P., and Pan, B. (2017). Survey of convex optimization for aerospace applications. Astrodynamics, 1(1):23–40.

[Luo and Yu, 2006] Luo, Z.-Q. and Yu, W. (2006). An introduction to convex optimization for communications and signal processing. IEEE J. Sel. Areas Commun., 24(8):1426– 1438.

[Majumdar et al., 2020] Majumdar, A., Hall, G., and Ahmadi, A. A. (2020). Recent scalability improvements for semideﬁnite programming with applications in machine learning, control, and robotics. Annu. Rev Control Robot. Auton. Syst., 3:331– 360.

[Malyuta et al., 2021] Malyuta, D., Yu, Y., Elango, P., and A¸cikme¸se, B. (2021). Advances in trajectory optimization for space vehicle control. arXiv preprint arXiv:2108.02335 [math.OC].

[MOSEK ApS, 2019] MOSEK ApS (2019). The MOSEK optimization toolbox for MATLAB manual. Version 9.0.

[Nemirovski, 2004] Nemirovski, A. (2004). Prox-method with rate of convergence Op1{tq for variational inequalities with Lipschitz continuous monotone operators and smooth convex-concave saddle point problems. SIAM J. Optim, 15(1):229–251.

[Nesterov, 2007] Nesterov, Y. (2007). Dual extrapolation and its applications to solving variational inequalities and related problems. Math. Program., 109(2):319–344.

[Nesterov, 2018] Nesterov, Y. (2018). Optimization, volume 137. Springer.

Lectures on Convex

[Nesterov and Nemirovskii, 1994] Nesterov, Y. and Nemirovskii, A. (1994). Interior-Point Polynomial Algorithms in Convex Programming. SIAM.

[Ouyang et al., 2015] Ouyang, Y., Chen, Y., Lan, G., and Pasiliao Jr, E. (2015). An accelerated linearized alternating

13

direction method of multipliers. SIAM J. Imag. Sci., 8(1):644– 681.

[O’Connor and Vandenberghe, 2020] O’Connor,

D.

and

Vandenberghe, L. (2020). On the equivalence of the primal-

dual hybrid gradient method and douglas–rachford splitting.

Math. Program., 179(1):85–108.

[O’Donoghue et al., 2016] O’Donoghue, B., Chu, E., Parikh, N., and Boyd, S. (2016). Conic optimization via operator splitting and homogeneous self-dual embedding. J. Optim. Theory Appl., 169(3):1042–1068.

[Rockafellar, 2015] Rockafellar, R. T. (2015). Convex Analysis. Princeton University Press.

[Rockafellar and Wets, 2009] Rockafellar, R. T. and Wets, R. J.B. (2009). Variational Analysis, volume 317. Springer Science & Business Media.

[Stellato et al., 2020] Stellato, B., Banjac, G., Goulart, P., Bemporad, A., and Boyd, S. (2020). OSQP: an operator splitting solver for quadratic programs. Math. Program. Comput., 12(4):637–672.

[Su et al., 2016] Su, W., Boyd, S., and Candes, E. J. (2016). A diﬀerential equation for modeling nesterov’s accelerated gradient method: Theory and insights. J. Mach. Learn. Res., 17(1):5312–5354.

[Szmuk, 2019] Szmuk, M. (2019). Successive Convexiﬁcation & High Performance Feedback Control for Agile Flight. PhD thesis, Dept. Aeronatu. & Astronaut., Univ. Washington.

[Vu˜, 2013] Vu˜, B. C. (2013). A splitting algorithm for dual monotone inclusions involving cocoercive operators. Adv. Comput. Math., 38(3):667–681.

[Wang and Banerjee, 2014] Wang, H. and Banerjee, A. (2014). Bregman alternating direction method of multipliers. Proc. Adv. Neural Inf. Process. Syst., 4(January):2816–2824.

[Wang and Elia, 2010] Wang, J. and Elia, N. (2010). Control approach to distributed optimization. In Proc. Allerton Conf. Commun. Control Comput., pages 557–561. IEEE.

[Wang and Boyd, 2009] Wang, Y. and Boyd, S. (2009). Fast model predictive control using online optimization. IEEE Trans. Control Syst. Technol., 18(2):267–278.

[Xu, 2017] Xu, Y. (2017). Accelerated ﬁrst-order primal-dual proximal methods for linearly constrained composite convex programming. SIAM J. Optim., 27(3):1459–1484.

[Yan, 2018] Yan, M. (2018). A new primal–dual algorithm for minimizing the sum of three functions with a linear operator. J. Sci. Comput., 76(3):1698–1717.

[Yu and A¸cıkme¸se, 2020] Yu, Y. and A¸cıkme¸se, B. (2020). RLC circuits-based distributed mirror descent method. IEEE Control Syst. Lett., 4(3):548–553.

[Yu et al., 2020a] Yu, Y., A¸cıkme¸se, B., and Mesbahi, M. (2020a). Mass–spring–damper networks for distributed optimization in non-Euclidean spaces. Automatica, 112:108703.

[Yu et al., 2020b] Yu, Y., Elango, P., and A¸cıkme¸se, B. (2020b). Proportional-integral projected gradient method for model predictive control. IEEE Control Syst. Lett.

[Zagaris et al., 2018] Zagaris, C., Park, H., Virgili-Llop, J., Zappulla, R., Romano, M., and Kolmanovsky, I. (2018). Model predictive control of spacecraft relative motion with convexiﬁed keep-out-zone constraints. J. Guid. Control Dyn., 41(9):2054– 2062.

14

