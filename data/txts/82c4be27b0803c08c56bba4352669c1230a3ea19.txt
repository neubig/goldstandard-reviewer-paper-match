1

Bandwidth Adaptive & Error Resilient MBR
Repair Regenerating Codes
Kaveh Mahdaviani∗, Ashish Khisti∗, and Soheil Mohajer† ∗ECE Dept., University of Toronto, Toronto, ON M5S3G4, Canada †ECE Dept., University of Minnesota, Minneapolis, MN 55455, USA
Email: {kaveh, akhisti}@comm.utoronto.ca, soheil@umn.edu

Exact

arXiv:1711.02770v1 [cs.IT] 7 Nov 2017

Abstract
Regenerating codes are efﬁcient methods for distributed storage in storage networks, where node failures are common. They guarantee low cost data reconstruction and repair through accessing only a predeﬁned number of arbitrarily chosen storage nodes in the network. In this work we consider two simultaneous extensions to the original regenerating codes framework introduced in [1]; i) both data reconstruction and repair are resilient to the presence of a certain number of erroneous nodes in the network and ii) the number of helper nodes in every repair is not ﬁxed, but is a ﬂexible parameter that can be selected during the runtime. We study the fundamental limits of required total repair bandwidth and provide an upper bound for the storage capacity of these codes under these assumptions. We then focus on the minimum repair bandwidth (MBR) case and derive the exact storage capacity by presenting explicit coding schemes with exact repair, which achieve the upper bound of the storage capacity in the considered setup. To this end, we ﬁrst provide a more natural extension of the well-known Product Matrix (PM) MBR codes [2], modiﬁed to provide ﬂexibility in the choice of number of helpers in each repair, and simultaneously be robust to erroneous nodes in the network. This is achieved by proving the non-singularity of family of matrices in large enough ﬁnite ﬁelds. We next provide another extension of the PM codes, based on novel repair schemes which enable ﬂexibility in the number of helpers and robustness against erroneous nodes without any extra cost in ﬁeld size compared to the original PM codes.1

I. INTRODUCTION

Many distributed storage systems (DSS) are at work these days to store huge digital contents, accessed by many users from different locations. These DSSs typically consist of many storage nodes each with limited storage capacity and service rate. These nodes collaborate to store and serve the data to the users, while from time to time a storage node or part of its data become inaccessible for various reasons. This event is referred to as a ”failure”. As the number of storage nodes increase, failures have become a norm in nowadays large scale DSSs.
Efﬁciency and robustness against data loss and data corruption is a key feature of any storage system. As a result, a reliable DSS is required to be able to guarantee the recovery of the stored data, referred to as data reconstruction, even if a certain number of nodes are unavailable. This requires a mechanism to store some redundancy in the DSS, which results in some storage overhead. Moreover, to maintain the level of redundancy the DSS needs to be capable of replacing any missing node by a new one which contains an equivalent data. This procedure is referred to as repair. In order to perform the repair, it is required to download some data from the remaining nodes in the DSS, which is referred to as the repair bandwidth. Therefore, efﬁciency of a reliable DSS could be measured in terms of its storage overhead and required repair bandwidth.
Among various methods of performing data reconstruction and repair, [1], [4] suggested a framework, named regenerating codes, for storage in a DSS consisting n storage nodes. In this framework, all the symbols in the storage network are considered to be elements of a Galois ﬁeld of appropriate size q, denoted by Fq. Each storage node is supposed to have per node storage capacity equal to α symbols. This framework suggests optimizing both storage overhead and repair bandwidth, while guarantees capability of data reconstruction using any arbitrary subset of k nodes, and repair using any arbitrary subset of d nodes, referred to as helpers, each providing β per node repair bandwidth. The aggregate amount of repair data is referred to as the total repair bandwidth as is denoted by γ = βd.
A regenerating code encodes a message consisting of source symbols from Fq into nα coded symbols to be stored on the n storage nodes in the system, such that data reconstruction and repair processes are possible as described. The maximum size of the source data that could be stored in such a DSS is named the total storage capacity of the coding scheme, which we denote by F . The aim of the code designer is to design a coding scheme which provides the largest possible total storage capacity F , for the set of given parameters (n, k, d, α, β). It has been shown in [1], [4] that F could be upper bounded for any regenerating coding scheme by

min (k,d)−1

γ

F ≤ min α, (d − i) d . (1)

i=0

Based on (1), It is shown that in an optimally efﬁcient regenerating code with a given total storage capacity, reducing the storage overhead requires increasing the repair bandwidth and vice-versa [1]. This result is known as the storage-bandwidth

1Parts of these results has been presented in IEEE International Symposium on Information Theory (ISIT’16) [3]

2

tradeoff. In particular, for given k, and d, the set of pairs of per node storage capacity and per node repair bandwidth, (α, β) achieving the equality in (1) are the optimal pairs. One could see that there is a trade-off between the two parameters α, and β. Among the possible optimal choices for α and β for a given value of F , one extreme point referred to as the minimum storage regenerating (MSR) codes, could be achieved by ﬁrst minimizing the per node storage capacity α as

for which the optimal value of β will be

F αMSR = k ,

F βMSR = k(d − k + 1) .

The other extreme point is obtained by ﬁrst minimizing the per node repair bandwidth β, as βMBR = α/d, and hence referred to as the minimum bandwidth regenerating (MBR) codes, which results in

2F d αMBR = k(2d − k + 1) ,

and hence

α

2F

βMBR = d = k(2d − k + 1) .

If any replacement node stores exactly the same data as of the corresponding failed node the regenerating code is called an exact repair code, and otherwise it is called a functional repair code. The existence of functional repair regenerating codes for any point in the trade-off described by (1), follows from the equivalence of functional repair regenerating code design problem to that of network coding for single source multicast [5]. However, exact repair regenerating codes are much more appealing from practical point of view e.g., for the fact that they can be tuned as systematic codes. For both MBR and MSR points exact repair codes exists for different parameters [2], [6]–[14].
The adopted models in the regenerating codes’ literature are typically considering the rigid symmetric repair in which a predetermined number d ≤ n−1 of helpers participate in the repair scenario, each providing β = γ/d repair symbols. However, for a distributed storage system, the capability to adapt to various conditions in which data reconstruction and repair could be performed increases the robustness signiﬁcantly. The varying capability of helpers for participating in an speciﬁc repair is not only limited to load unbalance or varying quality of connection, and could rise due to many other practical reasons such as geographical distance among the nodes in the storage network or topological and infrastructure asymmetry of the network. Besides loosing access to storage nodes, it has been shown that data corruption is a common problem in large scale DSS’s [15].
In this work we consider two simultaneous extensions to the original formulation of Dimakis et. al. [1]. One extra feature we consider in our setup is that the number of helpers chosen for repair can be adaptively selected, which allows for run-time optimization according to the dynamic state of the system. We refer to this property as bandwidth adaptivity. Such ﬂexibility adds a notable robustness to distributed storage systems with time-varying conditions such as peer-to-peer distributed storage systems where storage nodes join and leave the system frequently. It is also an important feature for systems with signiﬁcant load unbalance or heterogeneous connectivity where the number of available nodes for repair vary for different repair cases. The importance of this feature has been addressed by other researchers [8], [13], [16]–[19]. Yet none of these works have addressed the MBR exact repair case.
As the second extension to the original regenerating codes, in our model we also encounter the presence of error in the system by adopting an adversarial intruder which can compromise up to a ﬁxed number b < k/2 of nodes, and following [20], [21] we will refer to it as limited power adversarial intruder. Such intruder is considered to be omniscient, i.e. knows the original data stored in the system and the coding scheme, and can control the data stored in, and being transferred by no more than b nodes under his control.
In [20] an upper bound for the capacity of distributed storage systems is presented in the presence of different intruders including the limited power omniscient intruder described above. Exact repair coding schemes are also proposed for MBR and MSR modes in [20], [21] to achieve this upper bound. However, none of these results consider bandwidth adaptivity.
Note that the code design for bandwidth adaptive functional repair regenerating codes simply reduces to the network coding for single source multicast problem. However, for the exact repair regenerating codes, this problem has only been considered for the MSR case, and a solution is provided in [8] based on interference alignment, which achieves optimality in asymptotically large per node storage capacity α, and repair bandwidth β. Recently, a few other bandwidth adaptive exact repair MSR codes have been introduced which provide optimality with ﬁnite values for α, and β [13], [22], [23].
In this work we focus on the natural extension of MBR mode with bandwidth adaptivity and error resiliency, and present exact repair coding schemes which we show are optimal. To the best of our knowledge, this work is the ﬁrst non-asymptotic exact repair code construction for such a setting. The main contributions of this work are explained in Section III-B, after brieﬂy reviewing the related works and formally deﬁning the setup in the next two sections.

3
II. BACKGROUND AND RELATED WORKS
A. Background on Error Resiliency
The introduction of errors into the data stored or transmitted over the network has been the subject of interest for a long time. In applications such as the distributed storage systems, where the integrity of the stored data is the highest priority, any practical scheme has to encounter an appropriate mechanism for dealing with the issue of introducing and propagating errors. While the source of error can also be non-adversarial, such as random errors introduced naturally through the I/O process in the storage nodes or during the data transmission, in order to provide performance guarantee levels it is common to consider adversarial models for the error source. In this work we consider a malicious intruder controlling a subset of storage nodes in the system as considered in [20], [21], [24]–[28]. The intruder model in these works, which has also been referred to as the ”Byzentine intruder”, will be referred to as ”limited power omniscient adversary” in this work. In this model, the adversarial intruder could control anything about the data transmitted from, or stored in a ﬁxed number, namely b, of the storage nodes, and has complete knowledge of the coding scheme and the encoded message. The formal deﬁnition of a reliable and error resilient distributed storage system under such a limited power omniscient adversary is given as follows.
Deﬁnition 1 (Error Resilient Regenerating Code). An error resilient regenerating code, C(n, k, d, b, α, γ), is a regenerating code with n nodes, among which at most b nodes provide adversarial compromised data. The code should be capable of performing two operations; i) Genuine repair for any failed node, in which the genuine content of the failed node is regenerated by accessing any d remaining nodes, and downloading β = γ/d repair symbols from each of them. ii) Genuine data reconstruction, in which the whole stored data is reconstructed by accessing the content of any k nodes.
In [20], an upper bound was derived for the total storage capacity of an error resilient regenerating code, which is a network version of the Singleton bound [29], [30]. Note that however, the model considered in [20] does not require the repair procedure to be error-free, and hence allows propagation of error during the repair procedure. The following theorem rephrases this upper bound.
Theorem 1. [20] The total storage capacity of any error resilient regenerating code, C(n, k, d, b, α, γ), is upper bounded as follows.
F ≤ k−1 min α, (d − i) γ . (2) i=2b d
Moreover, [20] also provides an explicit exact repair code construction for the MBR case in the special case of d = n − 1 based on the exact repair regenerating code introduced in [6], which achieves the total storage capacity upper bound presented in Theorem 1. However, [20] leaves this as an open problem whether or not the upper bound of (2) is tight for exact repair error resilient regenerating codes in any other case.
Rashmi et. al. [21], [31] later included the error-free repair mechanism in the model considered in [20], and showed that the upper bound of (2) is tight for the MBR exact repair regenerating codes with any choice of ﬁxed parameters k, and d ≥ k. They also proved the tightness of upper bound for MSR exact repair regenerating codes with d ≥ 2(k − 1) based on the PM exact repair regenerating codes introduced in [2]. In the presented coding scheme for MBR and MSR cases in [31], the number of accessed nodes for repair and data reconstruction procedures can be chosen in the run-time. As a result by increasing the number of accessed nodes, and proportionally increasing the total required data transmission, the maximum number of erroneous nodes against which the procedure remains secure also increases. This concept is referred to as ”on-demand security”. However, this is different from the bandwidth adaptivity property, presented in our work, in which, the maximum number of erroneous nodes is predeﬁned, and increasing the number of accessed nodes helps by reducing the total repair bandwidth.
In [32], the omniscient adversary is considered to be able to replace the content of an affected node only once, and the total storage capacity bounds and achievable schemes for this setting are provided. The paper also considers the MSR setting without restrictions on the number of times that adversary can compromise the contents of affected nodes, and provides schemes that are optimal for a speciﬁc choice of the parameters.
In [27], [28], a similar setup is considered and a ”progressive decoding” mechanism is introduced to reduce the computational complexity of repair and reconstruction procedures. These papers use a cyclic redundancy check (CRC) to confront errors in the repair and reconstruction procedures. However, CRC based schemes have this problem that the CRC may also be compromised by the adversary in the omniscient adversarial model.
Many other researchers have also considered the error resiliency problem in regenerating codes along with other properties [13], [25], [26], [33]–[36]. For instance, [26] considered multiple failure repair with cooperation among replacement nodes, and shows such cooperation could be adversely affective in the presence of an intruder. Efﬁciency in updating the stored data is considered in [33], while [34] considered limitations on the knowledge of the intruder. In [25] Polytope codes are used to provide error resiliency. Recently, [13], [36] presented new error resilient coding schemes to address the maximum storage capacity in presence of an intruder. The schemes presented in [13] also achieve bandwidth adaptivity in the MSR case. In this work we consider bandwidth adaptivity along with the error resiliency, and focus on the coding schemes that achieve the minimum repair bandwidth.

4
B. Background on Bandwidth Adaptive Repair
The adopted models in the regenerating codes’ literature are typically considering the rigid symmetric repair in which a ﬁxed number d ≤ n − 1 of helpers participate in the repair scenario, each providing β = γ/d repair symbols. However, in practical systems, run-time optimization is of great interest. In particular, for a distributed storage system, the capability of adaptation to various conditions such that optimal repair procedure could be performed provides a lot of robustness. Such capabilities enables the system to maintain its functionality when some of the nodes are not able to provide enough repair bandwidth, e.g. due to being overloaded by an unbalanced load or due to temporarily loosing the quality of their links. In such conditions, it is valuable if the coding scheme is capable of performing the repair by accessing more helpers and receive less repair data from each. With such capability, we do not need to ignore the nodes with lowered capability of service and can still let them participate as much as they can, which could provide a potentially signiﬁcant collective gain compared to the rigid setting. We will also show that accessing large number of helpers can even reduce not only the per node but also the total repair bandwidth, which in turn reduces the overall trafﬁc load in such conditions.
Similarly, we are interested to be able to perform repair based on the repair data provided by a small number of helpers as long as they are able to provide enough information to compensate for the absence of more helpers. Such conditions happen when a large number of nodes are inaccessible or have poor channel qualities but instead a few strong helpers are available. Then the coding scheme could ignore the poor helpers and expedite the repair based on the small group of strong helpers.
We will refer to a regenerating code capable of such ﬂexibility in repair as a bandwidth adaptive regenerating code. Note that the dynamic capability of service for storage nodes is a well-known characteristic for many practical distributed systems such as peer-to-peer systems or heterogeneous network topologies [37]–[42].
It was ﬁrst in [16] that Shah et. al. extend the regenerating code design problem in [1], [4] to include more ﬂexibility. In [16] the authors consider the number of participating helpers to be selected independently in each repair or reconstruction. Moreover, they also relax the constraint of downloading the same amount of information from each node in both repair and reconstruction to allow asymmetric participation of helpers, as long as all helpers contribute less than a ﬁxed upper bound, βmax, for repair. While the setting considered by Shah et. al. provides much more ﬂexibility in repair and reconstruction, the total repair bandwidth in their setting is always larger than that of the original regenerating codes formulations, except for the MSR case, where both settings achieve the same total repair bandwidth. Moreover, the coding scheme presented in [16] performs functional repair.
The ﬁrst work to address bandwidth adaptivity in the original setting of regenerating codes was [43]. In [43] Wang et. al. introduced a functional repair coding scheme which works in the MSR mode and supports bandwidth adaptivity. Later [17] also considered a similar setup and introduced functional repair MSR coding schemes with bandwidth adaptivity, while their main focus was on the derivation of the storage-repair-bandwidth trade-off for the functional coordinated repair in regenerating codes. Note, however, that none of these works address the exact repair with bandwidth adaptivity in regenerating codes.
Aggrawal et. al. [18] analysed the mean-time-to-failure (MTTF) in the regenerating codes with and without bandwidth adaptivity. This analysis is based on a birth-death process model in which the population of available storage node randomly changes with appropriately chosen rates. They showed that bandwidth adaptivity provides a signiﬁcant gain in terms of MTTF.
In exact repair regenerating codes, Cadambe et. al. were the ﬁrst to address the bandwidth adaptivity as an important property for regenerating codes in [8]. They presented an exact repair coding scheme for the MSR mode with bandwidth adaptivity in the repair procedure, based on Interference Alignment. The code presented by Cadambe et. al. is the ﬁrst exact repair regenerating code with bandwidth adaptivity, however, their coding scheme only asymptotically achieves the optimal trade-off, when α and β tend to inﬁnity with proper ratio. Recently, bandwidth adaptive exact repair regenerating codes have been introduced for various parameters in the MSR case [13], [22], [23]. In this work we focus on the MBR setting with error resiliency.
III. MODEL AND RESULTS
A. Model
In this section we will brieﬂy introduce the setup for a bandwidth adaptive and error resilient (BAER) distributed storage system and the coding scheme of our interest. This model is a modiﬁed version of the original regenerating code’s setup introduced in [1], [4].
Throughout this work we consider a predeﬁned ﬁnite ﬁled, Fq of size q, as the code alphabet, such that all the symbols and operations through the network belong to Fq.
Deﬁnition 2 (BAER Regenerating Code and Flexibility Degree). Consider the set of parameters n, k, D = {d1, · · · , dδ}, b, α, and a total repair bandwidth function γ : D → [α, ∞). A BAER regenerating code C(n, k, D, b, α, γ(·)) is a regenerating code with per node storage capacity α, which performs repair and data reconstruction processes in a distributed storage network of n nodes, when up to b out of n nodes are allowed to be erroneous, and provide adversarial data. Moreover, in any repair process the number of helpers, d, can be chosen arbitrarily from the set D. The choice of helper nodes is also arbitrary and each of the chosen helpers then provides γ(d)/d repair symbols. Similarly, in any data reconstruction process the data collector accesses any arbitrary set of k nodes and downloads α symbols from each. Moreover, the number of elements in the set D is referred to as ﬂexibility degree of the code, and is denoted by δ.

5

Remark 1. Note that when erroneous nodes are present in the system the repair process should prevent the propagation of the errors. In other words, the repair of any node should replace that with a node that stores genuine data, which is the data that the coding scheme would have stored in the replacement node if no compromised node exists in the network.

Deﬁnition 3 (Total Storage Capacity). For the set of parameters n, k, D = {d1, · · · , dδ}, b, α, and a given function γ : D → [α, ∞), the total storage capacity of a BAER distributed storage system is the maximum size of the ﬁle that could be stored in a network of n storage nodes with per node storage capacity α, using a BAER regenerating code C(n, k, D, b, α, γ(·)). We will denote the total storage capacity of such a system by F (n, k, D, b, α, γ(·)), or simply F , whenever the parameters of
the system could be inferred from the context.

Deﬁnition 4 (Optimal Codes). Consider a set of parameters n, k, D = {d1, · · · , dδ}, b. For a given total storage capacity F , a BAER regenerating code C(n, k, D, b, α, γ(·)) is optimal, if it realizes the total storage capacity F , and for any other BAER regenerating code C′(n, k, D, b, α′, γ′(·)), realizing total storage capacity F , with,
α′ ≤ α,

we have

∃d ∈ D, γ(d) < γ′(d).

Remark 2. It is obvious that for any optimal coding scheme, there exists no redundancy among the symbols stored in a single storage node. In other words, none of the symbols stored in a single storage node in an optimal BAER regenerating code can be calculated as a function of other symbols, otherwise, removing that symbol will reduce α, while all the repair and data reconstruction procedures are still possible with the same data transmission as before. Through the rest of this work, we will only consider optimal BAER regenerating codes and hence assume there exists no per node redundancy.

It worth to mention that optimal BAER codes do not necessarily exist for all sets of parameters n, k, D = {d1, · · · , dδ}, b, α, γ(·). For example having a large α and a very small γ(d) for some d ∈ D, makes genuine repair with d helper impossible if no per node redundancy is allowed. This will be studied in details in the following sections and we will characterize the set
properties of the sets of parameters for which optimal BAER codes exist. Since there are many parameters involved in the presented setting, hereafter we will consider n, k, D, b, α to be ﬁxed and
mainly focus on exploring the tension between F and γ(·). However, the results of this work still capture the overall trade-off between all the parameters. The following deﬁnitions set the scene for studying the tension between F and γ(·), for ﬁxed
values of other parameters.

Deﬁnition 5 (Set Oα, and Set Γα). For a given set of parameters n, k, D = {d1, · · · , dδ}, b, and a ﬁxed per node storage capacity α, we deﬁne the set of all optimal BAER regenerating codes with the same per node storage capacity α as Oα. Moreover, we denote the set of all the total repair bandwidth functions pertaining to optimal codes in Oα by Γα. In other words,
Γα = {γ(·)|C′(n, k, D, b, α, γ(·)) ∈ Oα}.

Note that from Remark 2 we know that all codes in Oα have zero per node redundancy. Moreover, the optimal codes in Oα may have different total storage capacities, F , and total repair bandwidth functions, γ(·). The following deﬁnition addresses
this set. As mentioned above, for a given set of parameters n, k, D, b, and α, we may have a set of optimal BAER regenerating
codes Oα, with different total repair bandwidth functions, γ(·). As a result, γ can be optimized for any given d ∈ D. The natural question is whether the minimal values of γ(d) can be simultaneously achieved for all values of d ∈ D in an optimal BAER code. While optimal BAER regenerating codes correspond to the Pareto optimal functions γ(·), in this work we consider
the strongest deﬁnition for optimality as will be introduced in the following deﬁnitions. Surprisingly, we will show that such
strong optimality is achievable for the minimum repair bandwidth BAER regenerating codes.

Deﬁnition 6 (MBR BAER Codes). For a set of parameters n, k, D, b, α, the MBR BAER code is an optimal BAER regenerating code with total repair bandwidth function γMBR(·), such that

γMBR(d) = min γ(d).
γ (·)∈Γα
In other words, γMBR(d) is the minimum possible repair bandwidth for all values of d ∈ D, among all optimal BAER codes with ﬁxed parameters n, k, D, b, and α. We also denote the total storage capacity associated with parameters n, k, D, b, α, and γMBR(·), by FMBR(n, k, D, b, α, γMBR(·)), or FMBR for short. Moreover, the BAER regenerating codes with parameters n, k, D, b, α, and γMBR(·), realizing FMBR are referred to as MBR BAER codes.

Note that since the γMBR(·) is deﬁned to be the point-wise minimum of the total repair bandwidth functions in Γα, there is no guarantee that there exists a non-trivial MBR BAER code for a given set of parameters. In this work we will show that non-trivial MBR BAER codes exists for a wide range of parameters.

6

B. Main Results
In this work we focus on the MBR mode with exact repair. Considering the set of parameters n, k, b, α, and a set D = {d1, · · · , dδ}, for some ﬂexibility degree δ > 1, such that

2b < k ≤ d1 ≤ · · · ≤ dδ,

(3)

and

α = lcm(d1 − 2b, · · · , dδ − 2b)a,

(4)

for some integer a ≥ 1. Through this work we will use the notation dmin = d1 to emphasise the fact that this is the smallest element is the set D.

Remark 3. Regarding the constraint (4) on the per node storage capacity, note that in practice the per node storage capacity is usually very large, e.g. a few Terabytes, hence this constraint is not adding any practical limitation.

We ﬁrst characterize the minimum total repair bandwidth function such that the storage capacity is positive, and hence determine the MBR mode for the described setting. The following theorem describes this result.

Theorem 2. Consider a BAER regenerating code with parameters n, k, b, α, and the set D = {d1, · · · , dδ} satisfying conditions (3), and (4). Then assuming zero per node redundancy, the minimum total repair bandwidth function is given by

γMBR(d) = αd , ∀d ∈ D.

(5)

d − 2b

The proof of this result is provided in Section VI-B. We also determine the total storage capacity of a BAER regenerating code in the MBR mode, and provide an upper bound for the total storage capacity of the general mode. We summarize these results in the following theorem.

Theorem 3. Consider a BAER regenerating code with parameters n, k, b, α, and the set D = {d1, · · · , dδ} satisfying conditions (3), and (4). Using the notation dmin = d1, for any MBR BAER code, as introduced in Theorem 2 with the total repair bandwidth function,
γMBR(d) = αd , ∀d ∈ D, d − 2b
the total storage capacity is given by

k−2b−1

α

FMBR =

(dmin − 2b − j) (dmin − 2b)

j=0

= α (k − 2b) dmin − b − k − 1 .

(6)

dmin − 2b

2

Moreover, the following upper bound holds for the total storage capacity of any BAER regenerating code, associated with the arbitrary total repair bandwidth function γ(·).

F ≤ k−2b−1 min α, min (d − 2b − j) γ(d) . (7) j=0 d∈D d

Note that the results in the above theorems hold for both the exact repair as well as the functional repair. The upper bound (7) is derived based on two modiﬁcations in the standard information ﬂow graph which was originally introduced in [1]; i) Considering a genie assisting the decoder in each repair or data reconstruction by determining a subset of accessed nodes of size 2b which contains all the compromised nodes among the selected ones, and ii) Allowing the number of helper nodes d ∈ D to change independently in every term of the right-hand-side expression to minimize the resulting upper bound. The detailed proof is provided in Section VI-B and Appendix C. In this wrok we provide two achievablity schemes in the MBR mode based on an extension of the MBR PM regenerating codes. These schemes are described in Section IV, and Section V. More speciﬁcally, we show that universally optimal exact repair BAER regenerating code exists for the MBR mode by providing explicit code constructions. To the best of our knowledge the only other bandwidth adaptive exact repair regenerating code constructions presented so far are MSR codes [8], [13], [22], [23]. In this work we present two different schemes for the bandwidth adaptive and error resilient repair procedure in the MBR mode. Both schemes are capable of performing exact repair. The ﬁrst scheme has a larger code alphabet ﬁeld size requirement while the second scheme reduces the ﬁeld size requirement to that of the MBR PM codes, while has larger per node storage capacity requirement.

7

IV. FIRST CODING SCHEME
For an arbitrary ﬂexibility degree δ > 1, we introduce an exact repair MBR BAER code C(n, k, D, b, α, γ(·)), for D = {d1, · · · , dδ}, where the parameters satisfy the conditions given in (3), and (4). This coding scheme achieves the total storage capacity FMBR as given in (6). We also use the notation dmin to denote
dmin = min{d} = d1.
d∈D
The presented code construction could be considered as a generalization of the Product Matrix (PM) MBR codes introduced by Rashmi et. al. [2], in which we use the PM codes as basic components. However, the repair scheme is properly redesigned to provide bandwidth adaptivity and error resiliency properties as deﬁned in Section III. We use examples throughout the discussions to better illustrate the ideas and proposed encoding/decoding algorithms. For the rest of this section let s = [s1, · · · , sFMBR] denote the source data symbols, where FMBR is given in (6).
As mentioned before, we will consider all the symbols and operations to belong to a Galois ﬁled Fq, referred to as the code alphabet. In particular we consider Fq to be simple extension ﬁled over a base ﬁeld Fp for a large enough prime p. Let g ∈ Fq denote the primitive element of the code alphabet, and Fp[x] denote the ring of polynomials with coefﬁcients from Fp, and ̺(x) ∈ Fp[x], denote the minimal polynomial of g, then we have,
Fq ≃ Fp[x]/ ̺(x) .
We provide a discussion on the ﬁeld size requirement for the coding scheme at the end of this section, after introducing the coding scheme.

A. Construction for b = 0
In this subsection we assume there is no compromised node in the network, i. e., no node provides erroneous data. We show that in this case an MBR bandwidth adaptive code C(n, k, D, b = 0, α, γ(·)), for an arbitrary ﬂexibility degree δ, is achievable through a simple concatenation of α/dmin MBR PM codes, with parameters n′ = n, k′ = k, d′ = dmin, α′ = dmin, β′ = 1, as in [2]. We will refer to these MBR PM codes as component codes. More speciﬁcally, we choose each component code to be an MBR PM code capable of performing data reconstruction using k nodes, and exact repair using dmin helpers only. This simple scheme then provides exact repair and bandwidth adaptivity, but it is not error resilient. In the following subsections we will show how we can achieve an MBR BAER exact-repair coding scheme by modifying this naive concatenation scheme.
For the encoding of the concatenated scheme, we ﬁrst partition the source data symbols s = [s1, · · · , sFMBR] into α/dmin disjoints partitions, each of size

FMBR
α dmin

= k(k + 1) + k(dmin − k), 2

where FMBR is given in (6). We encode each partition separately for the set of n storage nodes using one of the component codes to produce dmin encoded symbols to be stored on each storage node. Then concatenating the encoded symbols provided by all the α/dmin component codes for each node, we form a vector of size α encoded symbols to be stored in each node. The following ﬁgure illustrates this process.
The following example illustrates this procedure.

Example 1. Let the number of nodes be n = 5, δ = 2 and set k = 2, dmin = d1 = 3, d2 = 4, and b = 0. To satisfy (4) let α = 12, and from (6) we have FMBR = 20. We will use the Galois ﬁled F7 as the code alphabet. Let the source symbols be s = [s1, · · · , s20]. We partition s into α/dmin = 4 partitions each containing 5 source symbols as s(1) = [s1, · · · , s5], · · · , s(4) = [s16, · · · , s20], and encode each partition separately. To this end, we then form data matrices M1, · · · , M4 based on the symbols in s(1), · · · , s(4) respectively,

 s1 s2 s4 

 s16 s17 s19 

M1 =  s2 s3 s5  , · · · , M4 =  s17 s18 s20  .

s4 s5 0

s19 s20 0

Next, we pick a Vandermonde matrix of size n × dmin = 5 × 3,

 1 e1 (e1)2   ψ1 

 1 e2 (e2)2 





ψ2 

Ψ= 

...

 =  ..  ,  .

1 e5 (e5)2 ψ5

8


    
···
    

    
···
    

    
···
    
···

FMBR

FMBR

FMBR

α dmin

α dmin

···

s=[

···

···

···

α dmin
··· ]

···

PM

PM

PM

encoder

encoder

···

encoder

···

x1 = [ · · ·

···

···

··· ]

x2 = [ · · ·

···

···

··· ]

xn = [ · · · · · · · · · · · · ]

                                

xi = [ xi(1)

xi(2)

xi(z) ]

Fig. 1. The encoding process for the simple concatenation scheme.

where ej’s are distinct non-zero elements of the code alphabet F7. Then following the encoding mechanism of PM MBR codes, the vector of encoded symbols to be stored on some storage node ℓ ∈ {1, · · · , 5} is obtained as
xℓ = [xℓ(1), xℓ(2), xℓ(3), xℓ(4)],
where,
xℓ(i) = ψℓMi. △
When a storage node fails, in order to perform a repair, we perform α/dmin separate repairs, each corresponding to one component code. Repair of each component code requires dmin helpers and one repair symbol from each helper. The set of helpers for any two different component codes could have an intersection of arbitrary size between zero and dmin. The ﬂexibility required in the choice of the number of helpers comes from the choice of the size of intersections between the sets of helpers for different code components.
The following lemma guarantees this concatenated coding scheme can perform a symmetric repair with d helpers and per node repair bandwidth γ(d)/d, and hence is bandwidth adaptive for d ∈ D.
Lemma 1. For any d ∈ D, the concatenated coding scheme is capable of performing symmetric repair with d helpers, and per node repair bandwidth
β(d) = γ(d) = α . dd
Recall that (4) guarantees that β(d) is integer for all d ∈ D.
Proof. Any node in the network has one coded segment for each MBR PM component code, and therefore could serve as a helper, providing one repair symbol to repair the lost coded segment in that component code. The repair will be performed separately for each of the α/dmin MBR PM component codes, and each component code’s repair requires dmin repair symbols from distinct helpers. Then we only need to show there exists an assignment of code components to the helpers such that each helper is assigned to exactly α/d code components, and each code component is assigned to exactly dmin distinct helpers.
To guarantee the possibility of this assignment we simply introduce an assignment bipartite graph with α/dmin vertices on the left denoted by V (representing the code components) and d vertices on the right denoted by U (representing the selected helpers). It is enough to show there exists a regular bipartite graph with left degree dmin and right degree β(d) = α/d for each choice of d ∈ D. Algorithm 1 creates such a bipartite graph using the ideas introduced in the well-known Havel-Hakimi algorithm [44], [45]. The proof of correctness of this algorithm is provided in Appendix A.
Note that the total repair bandwidth is always α, which is the minimum possible total bandwidth required to repair a node of capacity α and hence the bandwidth adaptivity in this naive concatenation based scheme is achieved at no extra cost for

9

Algorithm 1 Bipartite graph construction
1: Input: Two sets of vertices V, U , and parameter dmin. 2: Set d = |U |. 3: Initiate a bipartite graph with vertex sets V, U and no edges. 4: for each vertex v ∈ V do 5: Create W ⊂ U of dmin vertices in U with least degrees. 6: Connect v PtoSfarallg trheeplavceermtiecnetss in W 7: end for

v1

v1

u1

v2

v2

u2

v3

v3

u3

v4

v4

V

U

V

(a)

Fig. 2. The bipartite assignment graphs generated by Algorithm 1 for Example 2.

u1 u2 u3 u4 U (b)

every choice of d ∈ D. Since MBR PR codes are optimal then this bandwidth adaptive version is also MBR and universally optimal for all d ∈ D, though it is not yet error resilient.
Example 2. Let us continue with the code in Example 1, with n = 5, δ = 2, k = 2, dmin = d1 = 3, d2 = 4, and b = 0. Assume that node 5 is failed and being replaced through a repair and there are four other nodes still available in the network, namely nodes 1, 2, 3, 4. In this example there are two options for d, the number of helpers. One option is to chose d = dmin = 3 and select an arbitrary subset of size three from the available storage nodes. Without loss of generality, assume the set of selected helpers is H1 = {1, 2, 3}. Each helper node h ∈ H1 sends α/dmin = 4 repair symbols and each component code needs dmin = 3 distinct helpers to provide one repair symbol each. The helper assignment graph in this case is the complete bipartite graph with |V| = 4, and |U| = 3, in which every node in V is connected to every node in U, as depicted in Fig. 2
(a). Therefore, each helper will provide one repair symbol for every component code. Another choice in this example is to select d = d2 = 4. The selected set of helpers is then H2 = {1, 2, 3, 4}. Since we have
α/dmin = 4 code components, we denote the set of vertices in V by {v1, · · · , v4}, where vi represents the ith code component. The vertices in U are denoted by {u1, · · · , u4}, where uh represents the helper node h. Moreover, let’s represent the set of neighbours of a vertex vi by N (vi). Then one possible realization of the helper assignment bipartite graph created by Algorithm 1 is represented by N (v1) = {u1, u2, u3}, N (v2) = {u1, u2, u4}, N (v3) = {u1, u3, u4}, and ﬁnally N (v4) = {u2, u3, u4}, as depicted in Fig. 2 (b). Then for instance the helper node 1 will send three repair symbols including one for component code 1, one for component code 2, and one for component code 3, but no repair symbol for component code 4. Similarly, the encoded symbols on the failed node 5, pertaining to the component code 2, namely x5(2), will be repaired based on the corresponding repair symbols received from helper nodes 1, 2, and 4.
△
In order to perform data reconstruction, we can simply download the content of any k nodes in the system and this will provide each component code with the required data to perform separate data reconstructions.

B. Encoding for Storage with b > 0
In this subsections we describe an MBR bandwidth adaptive and error resilient (BAER) coding scheme with parameters n, k, D = {d1, · · · , dδ}, for an arbitrary ﬂexibility degree δ, and per node storage capacity α such that (3) and (4) are satisﬁed. This scheme is capable of performing exact repair while there are up to b erroneous nodes in the network.
Let

λ = dmin − 2b, κ = k − 2b,

(8)

and z = α. λ
Also let O be a λ×λ zero matrix. The ﬁrst step in the encoding process is to partition the source data symbols s = [s1, · · · , sFMBR ] into z disjoints partitions, and arrange the source data symbols of the ith partition in the form of the data submatrix Mi, i ∈

10

{1, · · · , z}. Each of the data submatrices Mi, i ∈ {1, · · · , z} is a symmetric matrix satisfying the structural properties of data matrix in a Product Matrix MBR code, capable of performing exact repair using λ helpers, and data reconstruction by accessing κ nodes. In other words,

Mi = NL⊺ii OLi′ , i ∈ {1, · · · , z},

where Ni is a symmetric κ × κ matrix, and Li is a κ × (λ − κ) matrix, and ﬁnally O′ is a (λ − κ) × (λ − κ) zero matrix.
Moreover, ⊺ denotes matrix transpose. The overall data matrix M ∈ Fαq ×α, is then formed as a block diagonal matrix consisting of z submatrices M1, · · · , Mz as
the diagonal blocks in the following form.

M1 O · · · O 

 O M2 · · · O 

M

=

 

..

.

...

...

...

 . 

(9)

O · · · O Mz

Similar to the original MBR Product Matrix codes the encoding for storage over each node is performed using a node-speciﬁc

coefﬁcient vector. The coefﬁcient vector in this construction is a row of an n × α Vandermonde matrix Ψ,

 1 e1 (e1)2 · · · (e1)α−1 

 1 e2 (e2)2 · · · (e2)α−1 

Ψ

=

 

..

..

. .

... . . .

...

 , 

(10)

1 en (en)2 · · · (en)α−1

where, ei, i ∈ {1, · · · , n} are distinct non-zero elements of Fq. Without loss of generality we simply use

ei = gi,

(11)

where g is the primitive element of Fq. Let’s denote the ℓth row of Ψ by ψℓ, which is the coefﬁcient vector for the ℓth storage node.The vector of encoded symbols
to be stored on node ℓ ∈ {1, · · · , n}, denoted by xℓ is obtained as

xℓ = ψℓM.

Note that xℓ is an α dimensional vector and hence the per node storage capacity is satisﬁed. Also, the encoded vector for each node could be considered as concatenation of the encoded vectors of all the z MBR PM code components with data
matrices M1, · · · , Mz. To show this, we introduce the following partitioning for each node-speciﬁc coefﬁcient vector ψℓ as

ψℓ = [ψℓ(1), · · · , ψℓ(z)], ℓ ∈ {1, · · · , n}, (12)

where, each segment ψℓ(i) is a 1 × λ vector. Then for each node ℓ we have,

xℓ = [ψℓ(1)M1, · · · , ψℓ(z)Mz].

Example 3. Consider the following set of parameters δ = 2, n = 6, k = 3, dmin = d1 = 4, d2 = 5, b = 1, and the code alphabet in use is Fq, with primitive element g. Assume α = 6 to satisfy (4). We have λ = 2, κ = 1, and the number of component codes is z = α/λ = 3. Moreover, from (6), we have FMBR = 6. Let’s assume the source symbols are s = [s1, · · · , s6]. Finally, the data matrix M , and the corresponding Vandermonde matrix Ψ will be

s1 s2 0 0 0 0 

 M1 O O 

 s2 

0

0

0

0

0 

0

0

s3 s4

0

0

 

,

M =  OO MO2 MO3  =  0 0 s4 0 0 0 

 0 0 0 0 s5 s6 

0 0 0 0 s6 0

and

1 g

1 g2

Ψ

=

 

..

..

. .

1 g6

g2 · · · g2 2 · · ·
... . . . g6 2 · · ·

g5 

g2

5


..  .

.

g6 5

11

Then, for instance, for node 1 the coefﬁcient vector is ψ1 = [1, g, g2, · · · , g5],
and the encoded vectors is x1 = ψ1M = [(s1 + gs2), s2, (g2s3 + g3s4), g2s4, (g4s5 + g5s6), g4s6]. △

C. Data Reconstruction with b > 0

The decoding procedure for both data reconstruction as well as the repair is performed using a scheme which will be referred

to as the ”test-group decoding”. This decoding scheme enables the decoder to both recover the required data, and simultaneously

authenticate the ingenuity of the recovered message. We describe the test-group decoding as an iterative procedure. In data

reconstruction, the data collector accesses a set S of k storage nodes.

Each iteration uses one test-group T , which is a distinct subset of S, consisting k − b nodes, and the entire process continues

for at most

k k−b

iterations. For a given iteration with a test-group T , we examine all of its

k−b k−2b

subsets H of size k − 2b,

and perform data reconstruction using the data provided by nodes in H. This gives an estimate for the data matrix M , which

we denote by Mˆ H. Recall that the code components are designed for parameters κ = k − 2b and λ = d − 2b, and hence data

reconstruction from nodes in H can be performed as for standard product matrix codes [2].

In order to calculate an estimate for data reconstruction, based on H ⊂ T , |H| = k − 2b note that each storage node

contains z coded segments, each pertaining to one component code. Therefore, the data collector could easily perform the data

reconstruction for each of the z component codes separately based on the corresponding segments provided by nodes in H

using the same method introduced for the original Product Matrix codes [2]. As mentioned in Section IV-B, each component

code is designed to perform reconstruction based on κ = k − 2b storage nodes. Then assuming H is compromised-free, the

corresponding segments of the codewords provided by the k −2b nodes in H are sufﬁcient for reconstruction in each component

code.

Once all the estimates are calculated for a test-group, the decoder proceeds by checking the consistency of the estimates.

The decoder stops whenever it ﬁnds a test-group such that all its estimates are consistent and outputs the consistent estimate

as the decoded data. The following lemma guarantees this procedure will always succeed.

Lemma 2. Assuming the maximum number of compromised nodes is b, if all the estimates produced in the test-group decoding for a single test-group T are consistent, then all of them are correct. Moreover, the test-group decoding will always ﬁnd a
consistent test-group.

Proof. First note that any test-group T consists of k − b nodes and the decoder produces an estimate based on any subset of H of size k − 2b in T . Since the maximum number of compromised nodes is b, then at least one of the subsets in any test-group T is guaranteed to be compromised-free. Therefore, at least one of the estimates in each test-group is genuine and if all the estimates in the test-group are consistent then all of them should match with the genuine estimate.
Now to prove that the test-group decoder always ﬁnds a consistent test-group, simply note that the maximum number of compromised nodes is b. Hence, there exists at least one subset of size k − b, in any set of k selected nodes, S, which does not contain any compromised node. Since the test-group decoder uses all possible choices of test-groups before it terminates,
it always processes a compromised-free test-group, which is consistent.

The test-group decoding for data reconstruction is summarized in Algorithm 2.

Algorithm 2 Test-group decoding for data reconstruction

1: Inpot: k, b, and xℓ for all accessed node.

2: Consistency ← False

3: while ¬(Consistency) do

4: T ← A new subset of helpers of size k − b

5: for each subset H ⊂ T do

6:

Calculate Mˆ H

7: end for 8: if Mˆ H matrices are the same ∀H ⊂ T then

9:

Consistency ← True

10:

Output ← Mˆ H for some H ⊂ consistent T

11: end if

12: end while

12

D. Repair Scheme with b > 0

1) Encoding for Repair with b > 0: In order to perform the encoding for a repair process, we use a Vandermonde matrix Ω ∈ Fzq×z, with z = α/(dmin − 2b), as,

 gi1 0 gi1 1 · · · gi1 z−1 

 

gi2

0

gi2 1 · · ·

gi2

z−1  

Ω =  ... ... . . . ...  , (13)

giz 0 giz 1 · · · giz z−1

where,

i1 < i2 < · · · < iz,

and, for any ℓ1, ℓ2 such that 1 ≤ ℓ1 < ℓ2 ≤ z we have,

iℓ2 − iℓ1 > αn.

This matrix Ω will be used to adjust the dimension of the vector of repair symbols provided by each helper based on the selected parameter d.
When a node f in the network fails, we can choose any subset H of size d of other nodes as helpers such that 2b < k ≤ dmin ≤ d ≤ dδ. To describe the encoding process for repair at helper node h ∈ H, we deﬁne the following notations. Let
zd = α ≤ z. d − 2b

and, Ωzd denote the submatrix of Ω, consisting of the ﬁrst zd columns. Note that Ωzd is a Vandermonde matrix for any d ∈ D. Moreover, for any node ℓ ∈ {1, · · · , n}, let Φℓ denote an α × z block-diagonal matrix with λ × 1 diagonal blocks
ψ⊺ℓ (1), · · · , ψ⊺ℓ (z) as

 ψ⊺(1)
ℓ

o⊺λ

···

o⊺λ 

 o⊺λ ψ⊺ℓ (2) · · · o⊺λ 

Φℓ =  .. .

...

...

..  , .

(14)

o⊺λ

· · · o⊺λ ψ⊺ℓ (z)

where o⊺λ denotes a λ × 1 zero vector. Each helper node h ∈ H then produces a vector rh,f of repair symbols for the failed node f as

rh,f = xhΦf Ωzd .

(15)

Note that this will be a row vector of length α/(d − 2b), then the per node repair bandwidth corresponding to the chosen parameter d is

γ(d)

α

β(d) = d = d − 2b .

(16)

Example 4. Let’s continue the Example 3 with δ = 2, n = 6, k = 3, dmin = d1 = 4, d2 = 5, b = 1, α = 6 and z = 3.

Assuming node f = 1 is failed and choosing d = dmin = 4, we have

1 0 0 

g 0 0 





 1 gi1

Φ1 =  00 gg32 00  , Ωzdmin = Ω =  1 gi2

 0

0

g

4

 

1 gi3

0 0 g5

gi1 2 

gi2

2

 

.

gi3 2

Similarly, if we choose d = d2 = 5, we have

1 Ωzd2 =  1
1

gi1  gi2  , gi3

△

13

2) Decoding for Repair with b > 0: On the decoder side, again the test-group decoder iteratively selects a test-group T of size d − b, which has not been used before. Then for any subset H ⊂ T of size d − 2b, the decoder calculates an estimate xˆH,f for the lost coded vector xf , and checks if all the calculated estimates match in the current test-group. If there is an inconsistency, the decoder terminates this iteration and starts the next iteration by selecting a new test-group until it ﬁnds a
consistent one. An estimate in a consistent test-group is considered as the output.
Next we describe the process of calculating the estimate xˆH,f , based on one arbitrary subset H = {h1, · · · , hd−2b}. First note that for each h ∈ H, assuming it is not a compromised node, we have

rh,f = xhΦf Ωzd = ψh(1)M1ψ⊺f (1), · · · , ψh(z)Mzψ⊺f (z) Ωzd ,

= ψf (1)M1ψ⊺h(1), · · · , ψf (z)Mzψ⊺h(z) Ωzd ,

(17)

= xf ΦhΩzd ,

where, (17) is due to the fact that each ψℓ(i)Miψ⊺ℓ′(i) term is a scalar, and Mi is a symmetric matrix. The decoder then concatenates all the received repair vectors from helpers in H to create a 1 × α vector ρH,f as

ρH,f = [rh1,f , · · · , rhd−2b,f ] = xf Φh1 Ωzd , · · · , Φhd−2b Ωzd .

(18)

We deﬁne the α × α matrix ΘH as,

ΘH = Φh1 Ωzd , · · · , Φhd−2b Ωzd = Φh1 , · · · , Φhd−2b I(d−2b) ⊗ Ωzd ,

(19)

where I(d−2b) is the identity matrix of size (d − 2b), and ⊗ represents the Kronecker product. Note that if matrix ΘH is
invertible, the decoder will be able to produce an estimate xˆH,f , for xf , for any subset H, |H| = d − 2b, of the test-group, T as

xˆH,f = ρH,f ΘH(−1).

(20)

The following lemma guarantees that ΘH(−1) always exists.

Lemma 3. For any f ∈ {1, · · · , n}, any parameter d ∈ D and a subset of the helper nodes H, with |H| = d − 2b, the matrix ΘH, deﬁned in (19), is invertible, provided that the code alphabet Fq is large enough.

For the proof of this lemma please see Appendix B. A similar discussion as in Lemma 2 shows that the test-group decoding will always ﬁnds a consistent test-group in the data reconstruction and any estimate in a consistent test-group is correct. To summarize, the test-group decoding for the repair is described in Algorithm 3.

Algorithm 3 Test-group decoding for repair

1: Input: d, f , b, rh,f , for all helper node h. 2: Consistency ← False
3: while ¬(Consistency) do
4: T ← A new test-group of size d − b 5: for each subset H ⊂ T with |H| = d − 2b do

6:

Calculate ρH,f , ΘH,f as deﬁned in (18) and (19)

7:

Calculate xˆH,f ← ρH,f ΘH(−,f1)

8: end for

9: if xˆH,f = xˆH′,f ∀H, H′ ⊂ T then

10:

Consistency ← True

11:

Output ← xˆH,f for some H ⊂ consistent T

12: end if

13: end while

Remark 4. The repair procedure presented above requires a large ﬁeld size. This large ﬁeld size requirement is mainly due
to the speciﬁc procedure used for calculating estimates xˆH,f . We refer to Appendix B for details. In the following section we present an alternative coding scheme that reduces the ﬁeld size requirement to |Fq| = n.

14

Remark 5. One may notice that the test-group decoding is a framework that could be used jointly with any coding scheme that provides a mechanism for deriving estimates for the content of the failed node based on the repair data provided by any subset of size d − 2b, d ∈ D. However, it worth mentioning that when b > 0, the simple concatenation scheme, described in subsectionIV-A, fails to achieve optimal total repair bandwidth when under the test-group decoding framework for the repair. The following example illustrates this fact.

Example 5. Let b = 1, and consider k = 3 > 2b, D = {4, 5}, and α = 6 to satisfy (4). For the simple concatenation scheme to be able to perform repair with dmin = 4 helpers using the test-group decoding, we need to be able to derive an estimate for the coded content of any failed node based on the data provided by dmin − 2b = 2 helpers. Therefore, each code component needs to be capable of performing repair with 2 helpers. Hence, it is clear from the properties of the Product Matrix MBR codes that per node storage capacity of each code component is also 2. We then conclude that since the overall per node capacity is considered to be α = 6 we have

α

6

z = dmin − 2b = 2 = 3,

code components. Now consider a repair based on dmin = 4 helpers. As described in Algorithm 3, we need to be able to derive an estimate for the content of the failed node based on every subset of size d − 2b helpers, for any d ∈ D. In this case, then we need every subset of 2 helpers to provide enough repair data to perform a repair in all the z = 3 code components. We then conclude that every helper should provide a repair symbol for every code component, which results in β(d = 4) = 3, and γ(d = 4) = 12. This matches the per node repair bandwidth of the coding scheme presented in this section as given by

(16),

α

6

β(d) = d − 2b = 4 − 2 = 3.

However, when we consider the case of d = 5, then from (16) we have β(5) = 2, and γ(d = 5) = 5β(d = 5) = 10, in

the presented coding scheme. On the other hand, γ(d = 5) = 10 in the simple concatenation scheme, forces at least one of

the code components to have less than 4 helpers. Let the selected set of helpers be denoted by {h1, · · · , h5}, and without

loss of generality, assume that only h1, h2 and h3 are providing repair symbols for the code component 1. Then there exists

at least one subset of helpers of size d − 2b = 5 − 2 = 3, namely H = {h3, h4, h5}, in which only one helper provides

repair symbol for code component 1. Therefore, the test-group decoding is impossible for simple concatenation scheme with

γ(d = 5) = 10.

△

V. AN ALTERNATIVE CODING SCHEME WITH SMALL FIELD SIZE
The coding scheme presented in this section shares many aspects with the scheme presented in Section IV. We use the similar extension of PM MBR codes for encoding the data to be stored in the network. We also use the test-group decoding scheme for data reconstruction and repair, while the procedure for calculating the estimates in the test-group decoding for repair is totally different here. The aim of this alternative solution is to avoid the large ﬁeld size requirement of the previous scheme. The ﬁeld size requirements in the previous is imposed by the mechanism of calculating estimates for test-group decoding in the repair, which is based on the non-singularity of matrix ΘH. In the scheme presented in this section, we provide a different repair procedure which still uses the test-group decoding but works with ﬁeld size Fq of size n.

A. Encoding for Storage and Data Reconstruction Procedure
Consider the set of parameters n, k, D = {d1, · · · , dδ}, for an arbitrary ﬂexibility degree δ, b, and α, such that (3) and (4) are satisﬁed. In the coding scheme presented in this section the code alphabet Fq only needs to contain n distinct non-zero elements. However, in order to achieve such a small ﬁeld size, we require the per node storage capacity to satisfy some more constraints as will be discussed later in subsection V-D2. Through this section we continue to use the notation dmin = min{d ∈ D} = d1.
In order to perform the encoding for storage, we ﬁrst partition the source data symbols s = [s1, · · · , sFMBR ] into z = α/(dmin − 2b) disjoint subsets and arrange them in the form of the overall data matrix M , as introduced in (9). Next we use the rows of the same Ψ Vandermonde matrix as introduced in (10) as the node-speciﬁc coefﬁcient vectors, to encode the data to be stored on each storage node ℓ ∈ {1, · · · , n} as

xℓ = ψℓM,

where, as before, ψℓ denotes the ℓth row of the matrix Ψ. Moreover, for some primitive element g of the code alphabet Fq, without loss of generality we consider (11) as the choice for the Vandermone matrix Ψ. In other words, we choose

1 g

g2 · · · gα−1 

 1 (g2) (g2)2 · · · (g2)α−1 

Ψ

=

 

..

..

. .

... . . .

..  . .

1 (gn) (gn)2 · · · (gn)α−1

15



























M

=

 



























α
... }dmin − 2b
ξ ...
...


                        . . .  

Fig. 3. The structure of the data matrix M , with its submatrices Mi′, i ∈ {1, · · · , ζ}, depicted as diagonal green squares. Each ξ × ξ submatrix Mi′ is itself a block diagonal matrix with (dmin − 2b) × (dmin − 2b) diagonal blocks, Mj , j ∈ {(i − 1)c + 1, · · · , ic} depicted as small blue squares.

Since the encoded consent of the storage nodes is exactly similar to the coding scheme introduced in Section IV-B, we can use the same data reconstruction procedure as presented in Algorithm 2. As a result, the data reconstruction procedure is guaranteed to reconstruct genuine data in the presence of up to b erroneous nodes.
In order to describe the repair procedure, we ﬁrst need to present some notations and deﬁnitions in the following subsection.

B. Notations and Preliminaries for Repair Procedure

We begin this section by ﬁrst introducing some new notations and deﬁnitions, and a Lemma which will be used to describe the repair scheme. Then we describe the repair based on a single group of helpers of size d ∈ D. Note that, all through

the procedure we always require all the helpers to perform similar procedures on their content and hence the provided repair

symbols are always symmetric. As a result, the choice of helpers do not change the procedure and the same scheme could be

performed based on any other subset of helpers of the same size. The only determinant parameter is the size of the group of

helpers to be used for generating a single estimate.

Let

ξ = (d − 2b) (dmin − 2b),

(21)

(dmin − 2b)

which results in ξ ≤ (d − 2b) < 2ξ. Also let

ζ = α. ξ

We will assume ζ is an integer for any choice of d ∈ D.

One can consider the data matrix M , as follows,

 M1′ O O · · · O 

 O M2′ O · · · O 

M

=

 

..

.

...

..  , .

O O · · · O Mζ′

where, Mi′, i ∈ {1, · · · , ζ} is an ξ × ξ block diagonal matrix with c = dminξ−2b diagonal blocks, M(i−1)c+1, M(i−1)c+2, · · · , Mic. This structure is depicted in Fig 3.
Accordingly, for each node, ℓ, we consider a partitioning on its node-speciﬁc coefﬁcient vector, ψℓ, as well as its coded content, xℓ, to disjoint consequent segments of size ξ as follows

ψℓ = [ϕℓ(1), ϕℓ(2), · · · , ϕℓ(ζ)], xℓ = [χℓ(1), χℓ(2), · · · , χℓ(ζ)].

16

Φm,ǫ(e, v, u) = φ : u
v

(1)

(2)

(3)

Fig. 4. The result of performing the merge operator Φm,ǫ on vectors v, and u. Segment (1) is of length m − ξ and consists only of entries of vector v. Segment (2) is of length 2ξ − m and its entries are combinations of entries of v and u. Segment (3) is also of length m − ξ and its entries come from u,
scaled by a constant.

Therefore, each segment χℓ(i) is associated with the submatrix Mi′ of the data matrix as

χℓ(i) = ϕℓ(i)Mi′, i ∈ {1, · · · , ζ}.

(22)

We now present the following deﬁnition and its following lemma, which would be used through the repair scheme.

Deﬁnition 7 (Merge Operator). Consider an element e ∈ Fq, and vectors v, u ∈ Fξq, and denote the ith element of v and u by vi and ui respectively. For integers m, ǫ, such that 2ξ > m ≥ ξ, and ǫ > 1, the merge operator Φm,ξ : Fq × Fξq × Fξq → Fm q , is deﬁned as

Φm,ǫ(e, v, u) = φ = [φ1, φ2, · · · , φm],

where,





vi

for i ∈ {1, · · · , m − ξ},

φi = vi + em−ǫξui+ξ−m for i ∈ {m − ξ + 1, · · · , ξ},

(23)

 em−ǫξui+ξ−m

for i ∈ {ξ + 1, · · · , m}.

In other words,

Φm,ǫ(e, v, u) = [v, 0, · · · , 0] + em−ǫξ[0, · · · , 0, u].

(24)

m−ξ

m−ξ

Figure 4 depicts the deﬁnition of the merge operator as deﬁned above. The following lemma presents an important observation, connecting the outcome of the merge operator performed on two segments of the coded content in a helper node and its counterpart in the failed node. In order to present the lemma, we need the following notation. For each node ℓ in the network, let eℓ be the element in the code alphabet Fq associated with the coefﬁcient vector assigned to node ℓ, and consider an integer m, such that ξ ≤ m < 2ξ. We will use the notation ψℓ,m for the following 1 × m vector,
ψℓ,m = [e0ℓ , e1ℓ , · · · , em ℓ −1].
Note that ψℓ,m indeed, denotes the ﬁrst m entries of the node-speciﬁc coefﬁcient vector ψℓ
Lemma 4. Consider the elements eh, and ef , in the code alphabet Fq, associated with the coefﬁcient vectors of a helper node h and the failed node f respectively. For an integers m such that ξ ≤ m < 2ξ, and two integers i, j ∈ {1, · · · , ζ} with i < j, let ǫ = j − i + 1. Then we have,

e(hi−1)ξ

Φ

m

,

ǫ

(e

f

,

χ

f

(i

),

χ

f

(j

))ψ

⊺ h

,

m

= e(fi−1)ξ

Φ

m

,

ǫ

(e

h

,

χ

h

(i

),

χ

h

(j

))ψ

⊺ f,

m

.

Proof. From (24) it is easy to see that

Φm,ǫ(ef , χf (i), χf (j)) = [χf (i), 0, · · · , 0] + em f −ǫξ[0, · · · , 0, χf (j)].

(25)

m−ξ

m−ξ

Now, using (22) we can rewrite the two terms on the right hand side above as,

[χ (i), 0, · · · , 0] = e(i−1)ξψ Mi′ O1 ,

(26)

f

f

f,m O1⊺ O2

m−ξ

17

and

em−ǫξ[0, · · · , 0, χ (j)] = em−(j−i+1)ξ e(j−m)ξψ

O2 O1⊺
′

f

f

f

f,m O1 Mj

m−ξ

= e(i−1)ξ ψ

O2

O1⊺
′

.

f

f,m O1 Mj

(27)

where, O1 and O2 are all zero matrices of size ξ × (m − ξ) and (m − ξ) × (m − ξ) respectively. Let Λi,j denote the m × m symmetric matrix deﬁned as,

Λi,j =

Mi′

O1

+

O2

O1⊺
′

.

O1⊺ O2

O1 Mj

Therefore, from (25), (26), and (27) we have,

Φm,ǫ(ef , χf (i), χf (j)) = e(fi−1)ξψf,mΛi,j .

(28)

Similarly, one can show that

Φm,ǫ(eh, χh(i), χh(j)) = e(hi−1)ξψh,mΛi,j .

(29)

Then we have,

e(hi−1)ξ

Φ

m

,

ǫ

(e

f

,

χf

(i

),

χ

f

(j

))ψ

⊺ h

,

m

= e(hi−1)ξ ef(i−1)ξψf,mΛi,j ψ⊺h,m = e(hi−1)ξ e(fi−1)ξ ψf,mΛi,j ψ⊺h,m ⊺ = ef(i−1)ξ e(hi−1)ξ ψh,mΛi,j ψ⊺f,m .

(30)

In the above, (30) follows from the fact that ψf,mΛi,jψ⊺h,m is a scalar. Hence, using (27) we have,

ef(i−1)ξ e(hi−1)ξ

ψh,mΛi,j ψ⊺f,m

= e(fi−1)ξ

Φ

m

,

ǫ

(e

h

,

χ

h

(i

),

χ

h

(j

))ψ

⊺ f,

m

,

which completes the proof.

Based on the Lemma 4, we now introduce ”m-merged repair symbol from segments i and j” in the following deﬁnition.

Deﬁnition 8. [m-merged Repair Symbol] For the ﬁxed ξ, and any integer m, ξ ≤ m < 2ξ, each helper h can merge two segments χh(i), and χh(j) of its coded content by setting ǫ = j − i + 1 and create a repair symbol as

ρm,h,f (i, j) = e(fi−1)ξ

Φ

m

,

ǫ

(e

h

,

χ

h

(i

),

χ

h

(j

))ψ

⊺ f,

m

.

(31)

We will refer to this repair symbol as the ”m-merged repair symbol from segments i and j”.

Lemma 4 then guarantees that such a repair symbols provides a linear equation in terms of the symbols resulting from merging segments χf (i), and χf (j). The coefﬁcient of this linear equation is given by
eh(i−1)ξ ψh,m.

C. Repair Scheme

Now we have everything ready to describe the repair scheme. In order to provide the required error resiliency, we use

the test-group decoder scheme as described in the previous Section. However, here we use different encoding and estimate

calculation procedures. To this end, for a set of d helpers,

d d−2b

parallel decoding procedures calculate all possible estimates

for xˆf,H, for any subset H of size d − 2b of the selected helpers. The decoder then decides the correct decoding result by

checking the consistency among all estimates derived from subsets of any test-group T with |T | = d − b, as described in

Algorithm 3.

In the rest of this subsection we will describe the repair scheme, based on a set of d helpers, in the form of an iterative

process. In each iteration we have an encoding step which is performed similarly by all the participating helpers, and produces

some repair symbols. We also have a decoding step in each iteration which is performed at the repair decoder. The goal of the

decoding procedure is to calculate an estimate for the coded content of the failed node based on every subset of size d − 2b

of the selected helpers. Every encoding step is the same for all the helpers and in every decoding step the procedure to be

performed for calculating the estimate based on all subsets is similar. Therefore in the rest of this discussion, we only focus

of a single arbitrary subset of size d − 2b.

18

Let f denote the index of the failed node, and denote the coded content of the failed node as

xf = [χf (1), · · · , χf (ζ)],
where each χf (i) is referred to as a segment, and contains ξ entries. In the process of calculating an estimate xˆf , the decoder calculates an estimate for every single entry of every single segment. The number of iterations for a repair procedure depends on the selected parameter d, and its corresponding ξ as deﬁned in (21). Recall that from the deﬁnition of ξ for a given d ∈ D we have

ξ ≤ d − 2b < 2ξ

If we have ξ = d − 2b, then the number of entries to be estimated in each segment matches the number of the helpers from which the test-group decoder needs to calculate an estimate. In this case the repair scheme consists of only one iteration as follows. Each helper h produces one repair symbol from each segment of its coded content, xh, as

⊺
rh,i = χh(i) ϕf (i) , i ∈ {1, · · · , ζ}

and sends the repair symbols to the repair decoder. Note that for i ∈ {1, · · · , ζ} then we have,

⊺
rh,i = χh(i) ϕf (i)
= ϕh(i)Mi′ ϕf (i) ⊺
= ϕf (i)Mi′ ϕh(i) ⊺
⊺
= χf (i) ϕh(i) (32)

At the repair decoder, fro each segment i, stacking all the repair symbols rhℓ,i received from each subset of helpers H = {h1, · · · , hd−2b}, from (32) we have,

⊺

⊺

[rh1,i, · · · , rhd−2b,i] = χf (i) ϕh1 (i) , · · · , ϕhd−2b (i) , i ∈ {1, · · · , ζ} (33)

It is easy to check that the coefﬁcient matrix on the right hand side of the above equation is (d − 2b) × (d − 2b), and it is invertible, since it could be decomposed to a diagonal full ranks matrix multiplied into a Vandermonde matrix. Therefore, the decoder is able to calculate every segment χf (i) based on the repair symbols provided by the helpers in H = {h1, · · · , hd−2b}, and the repair scheme terminates at the end of this single iteration.
On the other hand, when we have ξ < d − 2b < 2ξ, the number of entries in each segment χf (i) is larger than d − 2b, and hence the linear equations system introduced in (33) is not uniquely solvable. As a result, the single iteration introduced above is not applicable. In this case the repair scheme has more than one iteration. In the rest of this subsection we describe these
iterations. We use a numerical example, evolving through the description of procedures, to better illustrate the procedures. In the ﬁrst iteration every helper forms disjoint groups consisting of two consecutive segments of its coded content, and uses
the merge operator Φ(d−2b),1 introduced in the previous subsection, to merge the segments in each group. Let Ig = {2g −1, 2g}, denote the set of indices of the segment in group g, then we the result of the merge operator in group g at helper h in iteration one is,

φh,1,g = Φ(d−2b),1(eh, χh(2g − 1), χh(2g)).

(34)

Finally each helper h creates one (d − 2b)-merged repair symbol from each group of two segments, as deﬁned in Deﬁnition 8. For instance, the repair symbol from helper h based on the group g in iteration one, is created as

rh,1,g = ef(2g−2)ξ φh,j,g ψ⊺f,(d−2b) = ρ(d−2b),h,f (2g − 1, 2g).

Similar to (34), let us denote

φf,1,g = Φ(d−2b),1(ef , χf (2g − 1), χf (2g)). Hence, using Lemma 4, we have
rh,1,g = ρ(d−2b),h,f (2g − 1, 2g) = φf,1,g eh(2g−2)ξψ⊺h,(d−2b) . Then, the repair symbols provided by any subset, H = {h1, · · · , h(d−2b)}, of size (d − 2b) of the helpers provides a linear equation system in terms of the entries in segments χf (2g − 1) and χf (2g), for any group g, as follows,

rh1,1,g, · · · , rh(d−2b),1,g = φf,1,g ψ⊺h1,(d−2b), · · · , ψ⊺h(d−2b),(d−2b) .

19

φf,1,g : χf (2g − 1)

χf (2g)

(2)

(1)

(2)

Fig. 5. An active segment χ(i); all active entries (depicted in blue) have indices less than known entries (depicted in green).

χ(i) :

ξ τ

Fig. 6. An active segment χ(i); all active entries (depicted in blue) have indices less than known entries (depicted in green).

In the above, the columns of the coefﬁcient matrix on the right hand side are linearly independent, and the matrix is indeed a (d − 2b) × (d − 2b) Vandermonde matrix, which is invertible. Therefore the repair decoder is able to calculate all the entries in φf,1,g, for every group g, based on the repair symbols provided by each subset of helpers of size d − 2b in the ﬁrst iteration. However, notice that the entries in φf,1,g can be categorized into two categories as depicted in Fig. 5, where category (1) contains 2ξ − (d − 2b) entries and category (2) consists of 2(d − 2b − ξ) entries in total.
The entries in category (2) are either the same as a single entry from χf (2g − 1), or a scaled version of a single entry in χf (2g), where the scaling factor is edf−2b−ξ. Then calculating each of the entries in category (2) of φf,1,g recovers the value of one entry from the lost coded vector xf . On the other hand, each of the entries in category (1) of φf,1,g is formed by a linear combination of one entry from χf (2g − 1) and one entry from χf (2g). Therefore, by recovering the value of each entry in category (1) of φf,1,g, the decoder is only able to calculate one entry from χf (2g − 1) in terms of an entry from χf (2g).
Note that in the process of calculating an estimate of xf , the decoder needs to calculates an estimate for every single entry of every single segment. At the end of the iteration one, as explained above, the decoder calculates some estimates for some of the entries, some other entries are estimated in terms of some other entries, and for the rest of the entries we have not calculated any estimate yet. In order to keep track of this process, we assign a label to each entry of xf . We set the label for all entries which are already estimated as ”known”. At the end of iteration one, known entries include all entries of xf corresponding to an entry in category (2) of φf,1,g, for all g.
The entries of xf which are not known yet at the end of iteration one, are the entries which have been combined to form an entry of category (1) in φf,1,g, for some g. As described above, among these entries, we can estimate each entry from χf (2g −1) in terms of another entry in χf (2g) at the end of iteration one. We label all such entries in χf (2g −1) as ”inactive”. The decoder does not need to work on calculating the estimate of the inactive entries any more, since their explicit estimate will be evaluated once all the other entries are estimated.
All the other entries then need to be estimated yet in the following iterations and hence we label them as ”active”. We refer to an entry with ”active” label as an active entry. If the decoder calculates an explicit estimate for an active entry in some later iteration, the label for that entry changes to ”known”. Similarly, the decoder may calculate an estimate for it in terms of another active entry and hence change its label to ”inactive”.
At each iteration we also refer to a segment χf (i) as active if it contains at least one active entry. The repair procedure terminates when there is no active entry left. We will show that both the number of active segments as well as the number of active entries in each active segment reduces as we move through the steps of the decoding.
It is easy to check all the following properties are satisﬁed at the end of iteration one.
• The number of active entries in each active segment will always be the same for all active segments in each iteration. • Any active segment will only contain either active or known entries. In other words, an active segment will never contain
an inactive entry. • In each active segment the indices of the active entries are always less than the indices of the known entries (see Fig. 6).
The decoder will then proceed through the next iterations by keeping all these properties as invariants, as will be described in the following.
Let τj denote the number of active entries in each active segment at the beginning of iteration j. Since all entries in all

20

segments are active at the beginning of the repair procedure, then we have

τ1 = ξ

Also let non-negative integers µj and σj be such that

(d − 2b) = µjτj + σj, 0 ≤ σj < µj.

(35)

Example 6. Consider the parameters δ = 2, n = 6, k = 3, dmin = d1 = 4, dδ = d2 = 5, b = 1, and assume α = 12. The content of each node i consists of xi = [xi,1, · · · , xi,12], and at the beginning all 12 entries are active. We will consider the case d = 5, and assume node f = 6 is failed, helpers are {1, · · · , 5}, and we focus on the procedure of calculating an estimate
based on the subset H = {1, 2, 3}. From (21) we have ξ = 2. Moreover, we have,

χℓ(1) = [xℓ,1, xℓ,2], χℓ(2) = [xℓ,3, xℓ,4], χℓ(3) = [xℓ,5, xℓ,6],

χℓ(4) = [xℓ,7, xℓ,8], χℓ(5) = [xℓ,9, xℓ,10], χℓ(6) = [xℓ,11, xℓ,12].

In step j = 1 then τ1 = ξ = 2 and from (35) we have, µ1 = 1, and σ1 = 1.

△

The rest of the repair procedure then depend on whether σj > 0 or σj = 0. In the following we will ﬁrst assume σj > 0, and then at the end of this subsection we describe the case of σj = 0.
1) Case of σj > 0: When σj > 0, we group each µj + 1 consequent active segments. Each helper then modiﬁes each group
by merging the last two active segments in each group. Let

Ig = {i1, i2, · · · , iµj , iµj+1}, and, i1 < i2 < · · · < iµj < iµj+1.

(36)

denote the set of indices of the active segments in the gth group. Each helper h then use the merge operator Φmj,ǫj,g for

mj = ξ + σj ,

(37)

and

ǫj,g = iµj+1 − iµj + 1,

(38)

to merge the last two segments in the group as follows

φh,j,g = Φmj,ǫj,g (eh, χh(iµj ), χh(iµj+1)).

(39)

Example 7. Let’s continue Example 6. In step 1, there are 3 groups,

I1 = {1, 2}, I2 = {3, 4}, I3 = {5, 6}.

Moreover from (37) we have,

m1 = ξ + σ1 = 3, ǫ1,1 = ǫ1,2 = ǫ1,3 = 1.

Then each helper h merges, φh,1,1 = Φ3,1(eh, [xh,1, xh,2], [xh,3, xh,4]) = xh,1, (xh,2 + e−h 1xh,3), (e−h 1xh,4) ,
and similarly,
φh,1,2 = xh,5, (xh,6 + e−h 1xh,7), (e−h 1xh,8) , φh,1,3 = xh,9, (xh,10 + e−h 1xh,11), (e−h 1xh,12) .
△

Finally each helper h creates one repair symbol from each modiﬁed group of active segments. For instance in iteration j, the repair symbol from helper h based on the active segments in group g is created as

rh,j,g = e(fiµj −1)ξφh,j,gψ⊺f,mj +

χh(i)ϕ⊺f (i).

i∈Ig \{iµj ,iµj +1}

= ρmj ,h,f (iµj , iµj +1) +

χh(i)ϕ⊺f (i).

i∈Ig \{iµj ,iµj +1}

(40)

Note that for each helper h, and each active segment indexed i we have

χh(i)ϕ⊺f (i) = ϕh(i)Mi′ϕ⊺f (i) = ϕf (i)Mi′ϕ⊺h(i)
= χf (i)ϕ⊺h(i). (41)

21

φf,j,g : χf (iµj )

χf (iµj+1)

Fig. 7. The three categories of entries in φf,j,g.

(2) (1) (2) (3)

Moreover, using Lemma 4, we have

ρmj ,h,f (iµj , iµj+1) = φf,j,g e(hiµj −1)ξψ⊺h,mj .

(42)

Therefore, from (41) and (42) it is clear that

rh,j,g = [χf (i1), · · · , χf (iµj − 1), φf,j,g]ϑ⊺h,g,

(43)

where,

ϑh,g = [ϕh(i1), · · · , ϕh(iµj − 1), e(hiµj −1)ξψh,mj ]. (44)

In (43), each active segment χf (i), i ∈ Ig \ {iµj , iµj+1} consists of τj active entries and ξ − τj known entries. Moreover, the entries of φf,j,g could be divided into three categories, as depicted in Fig. 7; (1) Entries formed by combining two active entries in χf (iµj ), and χf (iµj+1), depicted in cyan color, (2) Entries formed either from one active entry or from combining an active entry by a known entry, depicted in blue color, and (3) Known entries depicted in green color.
Hence, the repair symbols provided by any subset, H = {h1, · · · , h(d−2b)}, of size (d − 2b) of the helpers provides a linear equation system in terms of the entries in segments χf (i), i ∈ Ig, for any group g, as follows,

rh1,j,g, · · · , rh(d−2b),j,g = [χf (i1), · · · , χf (iµj − 1), φf,j,g]Θg.

(45)

In the above, the columns of the coefﬁcient matrix for group g, namely Θg, are,

Θg = [ϑ⊺h1,g , · · · , ϑ⊺h(d−2b),g ].
Example 8. Following the setting considered in Example 6, in iteration one of the repair scheme, we have three groups; I1 = {1, 2}, I2 = {3, 4}, I3 = {5, 6}. Moreover, as described in last examples we have m1 = 3, ξ = 2, and µ1 = ǫ1,1 = ǫ1,2 = ǫ1,3 = 1. From the ﬁrst group, using (40), each helper h then provides the repair symbol
rh,1,1 = e0f φh,1,1ψ⊺f,m1 = xh,1, (xh,2 + e−h 1xh,3, e−h 1xh,4) 1, ef , e2f ⊺ .
According to Lemma 4, we have

rh,1,1 = xf,1, (xf,2 + e−f 1xf,3), e−f 1xf,4

1

,

e

h

,

e

2 h

⊺.

Therefore, using rh1,1,1, rh2,1,1, and rh3,1,1 from any subset of d − 2b = 3 helpers H = {h1, h2, h3}, the decoder recovers xf,1, (xf,2 + e−f 1xf,3), and xf,4.
Similarly, in the second and third groups, the decoder uses the received repair symbols from helpers in H to recover xf,5, (xf,6 + e−f 1xf,7), xf,8, and xf,9, (xf,10 + e−f 1xf,11), xf,12, respectively. As a result, at the end of iteration one, entries xf,1, xf,4, xf,5, xf,8, xf,9, and xf,12 become ”known”. Moreover, for entries xf,2, xf,6, and xf,10, we label them as ”inactive”,

since they could be recovered based on the remaining ”active” entries xf,3, xf,7, and xf,11. Note that based on this relabelling

at the end of iteration one, then the remaining ”active” segments are χf (2), χf (4), and χf (6), which only have one ”active”

entry and one ”known” entry each.

△

In general, as mentioned in the beginning of this subsection, in iteration j of the repair procedure, any entry in the active segments is either active or known. Therefore, if τj < ξ the repair decoder has ξ − τj known entries in each of the active segments χf (i), i ∈ Ig. Removing the known entries from the equation system in (45) the repair decoder updates the system as

rh′ 1,j,g, · · · , rh′ (d−2b),j,g = χ′f (i1), · · · , χ′f (iµj − 1), φ′f,j,g Θ′g,

(46)

22

where the whole vector χ′f (i1), · · · , χ′f (iµj − 1), φ′f,j,g ,
is of size 1 × (d − 2b), and results from [χf (i1), · · · , χf (iµj − 1), φf,j,g] by removing the known entries. Also the updated coefﬁcient matrix Θ′g is derived from Θg by removing the rows corresponding to the known entries. It is easy to check that Θ′g is a (d − 2b) × (d − 2b) invertible matrix.2 The repair decoder then recovers the value of all the entries in

χ′f (i1), · · · , χ′f (iµj − 1), φ′f,j,g
for each group g. Note that the entries in the above vector consists of all the active entries in segments χf (i), i ∈ Ig \ {iµj , iµj+1}, along with unknown entries in φf,j,g (category (1), and (2) as depicted in Fig. 7). As a result, all the active entries in segments χf (i), i ∈ Ig \ {iµj , iµj+1} will be recovered, and their labels become known.
Let us now focus on the remaining entries in φf,j,g. Recovering each entry in category (2) reveals the value of one active entry either in χf (iµj ), or in χf (iµj+1), for which then the label changes from active to known. However, entries in category (1), are formed by combining two active entries; one from χf (iµj ), and the other from χf (iµj+1). Therefore, recovering the value of entries in this category, the decoder changes the labels of corresponding active entries pertaining to χf (iµj ) from active to inactive, and leaves the corresponding active entries from χf (iµj+1) to remain active. It is easy to check that the number of entries in category (1) is τj − σj . Moreover, one can easily check that the remaining active entries in segment χf (iµj+1), which are the entries participating in the formation of category (1) entries in φf,j,g, are all located at the leftmost part of χf (iµj+1). This guarantees that the invariants described in the beginning of this subsection will be preserved through the steps of the decoding.
In summary, at the end of iteration j we have, • All entries in segments χf (i), i ∈ Ig \ {iµj , iµj+1} are recovered, for each group g. • All entries in segment χf (iµj ) are either recovered or calculated in terms of a remaining active entry in χf (iµj+1). • The number of active entries in χf (iµj+1) is reduced from τj to τj − σj . In order to start the next iteration then we simply update the value of τj+1, namely the number of active entries remaining in each active segment, as

τj+1 = τj − σj .

(47)

It worth mentioning that, while σj > 0, both the number of active segments as well as the number of active entries in each active segment, τj , decrease in each step.
2) Case of σj = 0: When σj = 0, then we start by taking groups of size µj active segments and do everything similar to the case of σj > 0, excepting that we do not have any merging modiﬁcation on the last two segments. Therefore, (40) changes
to

rh,j,g = χh(i)ϕ⊺f (i).

(48)

i∈Ij

Moreover, at the end of an iteration with σj = 0, all active entries in each group will be recovered, which will also result in the recovery of all the inactive entries, and the decoding ends.

Example 9. Let’s consider the second iteration of repair for the setting described in the Example 6. As explained in the previous
examples, at the end of iteration one, the only remaining active entries are xf,3, xf,7, and xf,11, and the only remaining active segments are χf,2, χf,4, and χf,6, where each of them has only one remaining active entry. This is consistent with (47) as τ2 = τ1 − σ1 = 2 − 1 = 1. Then from (35) we have µ2 = 3, and σ2 = 0, and hence, we will have only one group of active segments in this iteration, with the index set I1 = {2, 4, 6}.
In this iteration, as σ2 = 0, we do not need any merging and, using (48), each helper h simply creates the repair symbol

rh,2,1 = [xh,3, xh,4][e2f , e3f ]⊺ + [xh,7, xh,8][e6f , e7f ]⊺ + [xh,11, xh,12][e1f0, e1f1]⊺. = [xf,3, xf,4][e2h, e3h]⊺ + [xf,7, xf,8][e6h, e7h]⊺ + [xf,11, xf,12][e1h0, e1h1]⊺.

However, note that xf,4, xf,8, and xf,12 are known from the previous iteration and can be removed from the above equation. Then from rh1,2,1, rh2,2,1, and rh3,2,1, provided by any subset H = {h1, h2, h3} of helpers, the decoder forms the reduced linear equation system as described by (46) as,

 rh′


,2,1

 e2h e2h e2h 

′

1
,2,1



=

[xf,3,

xf ,7 ,

xf,11]

 e61
h

e6 2
h

e63  ,
h

 rh3

1

2

3

rh′ 3,2,1

e1h01 e1h02 e1h03

2The rows are linearly independent as they are rows of a Vandermonde matrix.

23

and recovers the remaining active entries xf,3, xf,7, and xf,11. Finally, using the equations corresponding to the inactive entries

derived in the previous iteration, as explained in Example 8, the decoder recovers the inactive entries as well and ﬁnishes the

decoding.

△

The repair procedure for the presented coding scheme is summarized in the following algorithm.

Algorithm 4 The repair procedure

1: Input: d, f , b.

2: Calculate ξ using (21).

3: Form all segments and initiate the label for all segments and all of their entries as ”active”.

4: Initiate τ1 = ξ. 5: Set j = 1, and calculate µj and σj , using (35) 6: while σj ¿0 do 7: Form groups of segments each of size µj + 1. 8: Calculate mj and ǫj,g, for each group g, using (37) and (38). 9: At each helper h, merge the last two segments in each group g, to derive φh,j,g, using (39). 10: At each helper h, calculate rh,j,g for every group g using (40). 11: At the decoder for each subset H = {h1, · · · , hd−2b}, form the system (45), and solve.

12: Update the labels for entries and segments.

13: Update the value of τj using (47). 14: Update j = j + 1.

15: end while

16: Form groups of segments each of size µj.

17: At each helper h, calculate rh,j,g for every group g using (48).

18: At the decoder for each subset of helpers H = {h1, · · · , hd−2b}, form the system (45), and solve.

19: Form the estimate xˆf,H for each subset of helpers H = {h1, · · · , hd−2b}.

20: Initiate all Consistency ← False

21: while ¬(Consistency) do

22: T ← A new test-group of size d − b

23: if xˆH,f = xˆH′,f ∀H, H′ ⊂ T then

24:

Consistency ← True

25:

Output ← xˆH,f for some H ⊂ consistent T

26: end if

27: end while

D. Discussions

1) Repair bandwidth: Now let’s calculate the required repair bandwidth for the above scheme. As described in the previous subsections, in each iteration, each helper provides only one repair symbol for each group of active segments. Let gj denote the number of active segments groups in iteration j, and denote the total number of iterations by J. Then the total number of repair symbols provided by each helper through the repair is

J

β(d) = gj.

(49)

j=1

Moreover, the decoder starts by setting the label ”active” for all α entries. Then in each iteration, the decoder recovers exactly (d − 2b) active entries in each group of active segments, either directly or in terms of another active entry. As a result, the number of entries for which the label changes form ”active” to either ”known” or ”inactive” in iteration j is gj(d − 2b), and we have

J

α = gj(d − 2b).

(50)

j=1

Then from (49), and (50) we have, α
β(d) = d − 2b .
2) Discussion on α: In the provided repair scheme we require that for any d ∈ D, the number of active segments is always divisible by the number of segments in each group. In other words, denoting the total number of iterations in decoding by J, we require α to be divisible by ξ, µJ , and (µj + 1) for all j ∈ {1, · · · , J − 1}.

24

VI. TOTAL STORAGE CAPACITY OF BAER DISTRIBUTED STORAGE SYSTEMS

A. Lower Bound

We can now derive a lower bound on the total storage capacity based on the coding schemes presented in the previous section.

Corollary 1. For the set of parameters δ, n, k, b, α, and the set D = {d1, · · · , dδ}, such that condition (3), and (4) are satisﬁed, and the total repair bandwidth function

αd

γ(d) = d − 2b ,

(51)

the storage capacity for a BAER distributed storage system is lower bounded as

F ≥ α(k − 2b) dmin − b − (k − 1) .

(52)

dmin − 2b

2

Proof. The achievable storage capacity, F , of the proposed coding schemes is equal to the number of independent elements of matrix M . According to the structure of the matrix M in (9), this quantity is z times the total storage capacity of one MBR Product Matrix component code. Hence we have

F = z κ(κ + 1) + κ(λ − κ) = zκ λ − (κ − 1) .

2

2

Replacing λ = dmin − 2b, κ = k − 2b, and z = α/δ we get the lower bound in (52).

B. Upper Bound
In the proofs of this section we will use a lemma proved in [20] for the conventional regenerating codes. We restate the lemma in the setting considered in this work below while the proof follows similarly as provided in [20].
Lemma 5. In a BAER regenerating code C(n, k, D, b, α, γ(·)), in any data reconstruction, the data provided by any subset of size k − 2b of the k selected nodes should be sufﬁcient for uniquely decoding the source data stored in the network. Moreover, in any repair, the repair data provided by any subset of size d − 2b of the d selected helpers should be sufﬁcient for uniquely decoding the lost data.
Proof. Since the proof is similar for both data reconstruction and repair processes, we will use the notation a to refer to either d or k for the repair and data reconstruction respectively, and provide a single proof based on a which works for both cases. Consider a scenario (either a repair or reconstruction) in which a set of a nodes are selected to provide data. Also, assume the message (either the source data stored in the network or the content of a failed node) is m1 ∈ M, where, M = Fαq ×α for data reconstruction and M = Fαq for repair. Moreover, for any subset L of the a selected nodes, let yL(m) denote the collective data provided by nodes in L if the message to be recovered is m ∈ M.
We provide a proof by contradiction. Assume there exists a subset of selected nodes L∗, |L∗| = a − 2b such that
yL∗ (m1) = yL∗ (m2), m1 = m2.
Note that the BAER setup allows the intruder to control any subset of nodes of size less than b + 1. Then we can assume an intruder compromises a subset L′ of size b among the a selected nodes not in L∗ to provide yL′(m2). Therefore the receiver will have no guarantee to recover the genuine message m1, which contradicts the fact that BAER regenerating code should be capable of performing genuine repair and data reconstructions.
Having this lemma along with Corollary 1, we are now ready to prove Theorem 2.
Proof of Theorem 2. First note that the data stored in a single node does not have any redundancy. In other words if some part of the data stored in a single node is a function of the rest of the data we can improve the storage-bandwidth trade-off in the whole system by simply removing the redundant part from each node. Hence, α is an information theoretic lower bound on the required repair bandwidth. In particular, using Lemma 5 we conclude that in any BAER regenerating code, the collective repair bandwidth provided by any subset of helpers of size d − 2b should be at least α. As a result for any BAER regenerating code we have
β(d)(d − 2b) = γ(d) (d − 2b) ≥ α, ∀d ∈ D. d
However, since Corollary 1 assures this is achievable by a single code for all d ∈ D, we will then have (5) of Theorem 2.

25

Remark 6. Note that Theorem 2, introduces limits for dmin, and k in an MBR BAER code. The lower limit 2b for k, dmin could be justiﬁed using Lemma 5. Since for the choice of d < 2b, or k < 2b there exists no subset of size d − 2b, or k − 2b of
nodes, and hence the storage capacity of the BAER regenerating code supporting such a d or k is zero (trivial code).

Lemma 6. For any BAER regenerating code C(n, k, D, b, α, γ(·)), the total storage capacity F is upper bounded as follows

F ≤ k−2b−1 min α, min (d − 2b − j) γ(d) . (53) j=0 d∈D d

In speciﬁc, for the MBR case we have,

FMBR ≤ α(k − 2b) dmin − b − k − 1 .

(54)

dmin − 2b

2

The proof is provided in Appendix C. Finally the proof of Theorem 3 simply follows from (52) in Corollary 1, and Lemma 6.

VII. CONCLUSION
We considered a modiﬁed setup for the regenerating codes in which error resiliency and bandwidth adaptivity (BAER) are required to be satisﬁed simultaneously, and studied the storage-bandwidth trade-off in the modiﬁed BAER setup for regenerating codes. Focusing on the minimum repair bandwidth point of the storage-bandwidth tradeoff, we derived the total repair bandwidth function in the bandwidth adaptive scheme along with the corresponding storage capacity through proposing exact repair coding schemes, and providing the converse proofs. We showed that for the MBR case, optimality is achievable in strongest form (i.e., point-wise rather than Pareto optimality). We also presented an upper bound on the storage capacity of the BAER setup for the general case.

APPENDIX A PROOF OF THE CORRECTNESS OF ALGORITHM 1
Lemma 7. The result of Algorithm 1 is a bipartite graph with all the vertices in V having degree dmin, and the all vertices in U having degree β(d) = α/d, for any d ∈ D.

Proof. Algorithm 1 starts with all the vertices having degree zero and connects each vertex in V to dmin vertices in U, one at a time, in iterations of the for loop. Hence, we only need to prove that all vertices in U will have the required degrees. Every time a vertex in U is connects to a new vertex in V its degree increases by one. Then we only need to show that the degree of all the vertices in U will be β(d) = α/d when the algorithm terminates. To this end, we will ﬁrst show that in every iteration of the for loop, the maximum difference between the degrees of the vertices in U is one, using proof by contradiction.
Assume that at the end of iteration i∗ for the ﬁrst time we have at least two vertices u1, u2 ∈ U, such that deg(u2)−deg(u1) > 1. The algorithm never changes the degree of a node in U by more than one. Then at the end of iteration i∗ − 1 we should
have

deg(u2) − deg(u1) = 1.

(55)

Moreover, we conclude that in iteration i∗ the algorithm should have connected u2 to some vertex in V, while the degree of u1 is remained unchanged in this iteration. However, this is contradictory since the algorithm is choosing the subset W ⊂ U from the nodes with the least degree, and if u1 ∈/ W in iteration i∗, then u1 could not be in W as from (55) we know deg(u2) > deg(u1).
Next we show that in all iterations the degree of any vertex in U remain less than or equal to β(d) = α/d. Again we use proof by contradiction. Assume in some iteration the degree of one vertex u∗ ∈ U increases to β(d) + 1. Since we have already
shown that

deg(u∗) − deg(u′) ≤ 1, ∀u′ ∈ U

then at the end of this iteration the degree of any vertex in U should be at least β(d). Therefore at the end of this iteration we

have,

deg(u) =

deg(u) + deg(u∗) ≥ (|U| − 1)β(d) + (β(d) + 1) = (d − 1) α + α + 1 = α + 1.

(56)

u∈U

u∈U \{u∗}

dd

However, the sum of the degrees of all the vertices in U should be equal to the sum of the degrees of all the nodes in V at the end of any iteration, and we know at the end of any iteration we have,

deg(v) ≤ |V|dmin = α.

(57)

v∈V

26

Hence, (56) and (57) are contradictory. Finally, since the algorithm adds dmin to the sum of the degrees of nodes in U at any iteration for |V| = α/dmin iterations, then at the end of the for loop, we have,

deg(u) = dmin|V| = α.

(58)

u∈U

We have already shown that at the end of the last iteration of the loop we have,

deg(u) ≤ β(d) = α = α ,

(59)

d |U|

Then from (58) and (59) we conclude that for any u ∈ U, at the end of the last iteration of the loop deg(u) = β(d).

APPENDIX B PROOF OF LEMMA 3
Recall that the code alphabet Fq, q = pm is a simple extension ﬁeld over a ﬁnite ﬁeld Fp, such that p is a large enough prime number, and g ∈ Fq denotes the primitive element of Fq. Also, Fp[x] denotes the ring of polynomials with coefﬁcients from Fp, and let ̺(x) ∈ Fp[x] denote the minimal polynomial of g.
Consider the subset H = {h1, · · · , hd−2b} of helpers, and recall that each helper node hi has a node speciﬁc coefﬁcient vector ψhi , namely,
ψhi = ghi 0 , ghi 1 , · · · , ghi α−1 .
Without loss of generality, assume that

h1 < h2 < · · · < hd−2b.

(60)

Also, from (13) the structure of the matrix Ωzd is given as,

 gi1 0

 

gi2

0

Ωzd =  ..

.

giz 0

gi1 1 · · ·

gi2 1 · · ·

...

...

giz 1 · · ·

gi1 zd−1 

gi2

zd−1  

..

, 

.

giz zd−1

where,

i1 < i2 < · · · < iz,

(61)

and, for any ℓ1, ℓ2 such that 1 ≤ ℓ1 < ℓ2 ≤ z we have,

iℓ2 − iℓ1 > αn.

(62)

We denote,

ω1 

ω2 

Ωzd

=

 

..

 ,

.

ωz

where, for j ∈ {1, · · · , z},

ωj = gij 0 , gij 1 , · · · , gij zd−1 .

(63)

Then from the deﬁnitions of the matrices Φh, h ∈ H, given by (14), we have,

 ω1 ⊗ ψ⊺(1) 

 gi1 0 ψ⊺(1) · · ·
h

gi1

h
 ω2 ⊗ ψ⊺(2) 

 

gi2

0 ψ⊺(2)

···

gi2

ΦhΩzd

=

 

h
..

 

=





h

..

..

 . 

.

.

ωz ⊗ ψ⊺h(z)

giz 0 ψ⊺(z) · · · giz
h

zd−1 ψ⊺(1) 

zd −1

h
ψ⊺(2)



.

h

 .

..

 

zd−1 ψ⊺(z)
h

27

Therefore, by stacking matrices Φhi Ωzd for hi ∈ H, we obtain,

 ω1 ⊗ V1 

 gi1 0 V1 · · · gi1 zd−1 V1 

 ω2 ⊗ V2 

 

gi2

0 V2

···

gi2

zd −1

V2

 

ΘH = Φh1 Ω⊺zd, · · · , Φhd−2b Ω⊺zd = Π  ...  = Π  ... . . . ...  , (64)

ωz ⊗ Vz

giz 0 Vz · · · giz zd−1 Vz

where Π is an appropriate column permutation matrix and the matrices Vℓ, ℓ ∈ {1, · · · , z} are transposed Vandermonde matrices of size (dmin − 2b) × (d − 2b) as,

Vℓ = ψ⊺h1 (ℓ) ψ⊺h2 (ℓ) · · · ψ⊺hd−2b (ℓ) .

Note that multiplying Π from right does not change the rank. Hence, in order to show that ΘH is invertible it sufﬁces to prove the determinant of the following matrix is non-zero,

 ω1 ⊗ V1   gi1 0 V1 · · · gi1 zd−1 V1 

 ω2 ⊗ V2 

 

gi2

0 V2

···

gi2

zd−1

V2

 

ΞH = ... = ... . . . ... . (65)

ωz ⊗ Vz

giz 0 Vz · · · giz zd−1 Vz

The sketch of the proof is as follows:

• We show that every element in ΞH can be represented in the form of an exponent of g. • We show the determinant of ΞH can be represented as a polynomial f (x) ∈ Fp[x], evaluated at g. • We show f (x) is non-trivial.
• We show that (for large enough ﬁeld size) g can not be a root of f (x) and hence the determinant is non-zero.

Some of the ideas used in this proof are similar to [46]. Observe that each block giℓ j Vℓ in ΞH is a (dmin − 2b) × (d − 2b) submatrix. Then every entry of the matrix ΞH, is a product of two powers of the primitive element g. In particular for the element ΞH(r, c), located in row r and column c, we
have

ΞH(r, c) = giℓ ℓ′ Vℓ(r − (dmin − 2b)ℓ, ℓ′ + 1)

= giℓ ℓ′ ghℓ′′ (r−1)

= gℓ′iℓ+(r−1)hℓ′′ ,

(66)

where,

ℓ = ⌈ r ⌉, ℓ′ = ⌈ c ⌉ − 1, ℓ′′ = c mod (d − 2b).

dmin − 2b

d − 2b

Denoting the set of all permutations on {1, · · · , α} by Sα, the Leibniz extension for the determinant is given by,

α

|ΞH| =

(−1)sgn(σ) ΞH(i, σ(i)) .

(67)

σ∈Sα

i=1

From (66) we know every element ΞH(i, σ(i)) can be represented as an exponent of g. Then for any σ ∈ Sα, we use pow(σ) to denote the exponent of g associated with the permutation σ as follows

α
gpow(σ) = ΞH(i, σ(i)),
i=1

and we can rewrite (67) as

|ΞH| =

(−1)sgn(σ)gpow(σ) .

σ∈Sα

(68)

Therefore, from (64) and (66), for large enough prime3 p, it is clear that there exists a polynomial f (x) ∈ Fp[x], such that

|ΞH| = f (g).

(69)

We refer to the polynomial f (g) as the determinant polynomial in the rest of this appendix.

3p should be large enough to make sure any coefﬁcient in the polynomial is smaller than p, and hence is an element of Fp. However, the number of terms in the determinant expansion is ﬁnite for any ﬁnite α, and hence is the largest possible coefﬁcient.

28

dmin − 2b dmin − 2b dmin − 2b dmin − 2b

dmin − 2b
block row 1 block row 2

dmin − 2b

block row z

block block column 1 column 2

block column z

Fig. 8. The partitioning of rows and columns of the ΞH matrix into block rows and block columns, along with the green diagonal submatrices containing all the entries ΞH(j, σ(j)), for any σ ∈ F .

Note that in (68), each term is associated with one of the permutations on the set {1, · · · , α}. In the rest of this appendix
we consider each permutation on the set {1, · · · , α} as a bijective mapping from the set of rows of the matrix ΞH to the set of its columns. Moreover, we refer to the ith group of dmin − 2b consequent rows in matrix ΞH as the ith block row. Similarly, the ith group of dmin − 2b consequent columns in matrix ΞH is referred to as the ith block column, as depicted in Fig. 8.
Finally, let F denote the family of permutations on the set {1, · · · , α}, which are mapping the rows in each block row i to
the columns in the block column i, for each i ∈ {1, · · · , zd}. In other words for any permutation σ ∈ F , all entries ΞH(j, σ(j))
are located in the green squares in Fig. 8.

Lemma 8. For any permutation σ on the set {1, · · · , α}, if σ ∈/ F , then there exists another permutation σ′, such that,

pow(σ) < pow(σ′).

(70)

Proof. We prove this lemma by constructing the permutation σ′ based on the permutation σ ∈/ F , such that σ′ is different from σ in exactly two pairs of rows and columns, and (70) is satisﬁed.
Let i denote the ﬁrst block row such that σ maps some row r1 in block row i to some column c1 in a block column j = i. Then from the deﬁnition of the family F we conclude j > i. Moreover, since the mapping induced by any permutation is bijective and the size of block rows and block columns are the same, then there should exist a column c2 in the block column i which is mapped by the permutation σ to some row r2 in a row block i′ = i. Again, we conclude that i′ > i, and hence we conclude

r2 > r1.

(71)

To summarize, we have

σ(r1) = c1, σ(r2) = c2.

We now claim that the permutation σ′ deﬁned as follows satisﬁes (70),



 c2 r = r1,

σ′(r) = c1 r = r2,

(72)

σ(r) otherwise.

Figure 9 depicts the process of deriving σ′ from σ.

29

c2

c1

  
  

block row

r1

i

r2

block row

i′

     

block column j′ = i

block column j

Fig. 9. The process of deriving the permutation σ′ from σ, by switching between the the pair of entries denoted by red circles and the pair of entries denoted by blue circles.

Note that the exponent of the term associated with a permutation σ in f (x) is the sum of all the exponents of g in the entries ΞH(r, σ(r)). From (72) it is clear that entries ΞH(r, σ(r)) = ΞH(r, σ′(r)), for all r except r1, and r2. Moreover, from (66), for some integers ℓ1, ℓ2 ∈ {1, · · · , d − 2b}, we have

ΞH(r1, σ(r1)) = gii ΞH(r2, σ(r2)) = gii′

⌊

c1 d−2b

⌋

⌊

c2 d−2b

⌋

ghℓ1 ghℓ2

(r1−1) , (r2−1) .

(73)

Similarly from (72) we have

ΞH(r1, σ′(r1)) = gii ΞH(r2, σ′(r2)) = gii′

⌊

c2 d−2b

⌋

⌊

c1 d−2b

⌋

ghℓ2 ghℓ1

(r1−1) , (r2−1) .

(74)

Note that since j > i, then we conclude that c1 > c2, and as a result, ⌊ c1 ⌋ ≥ ⌊ c2 ⌋. d − 2b d − 2b
Then we have pow(σ′) − pow(σ) = (ii′ − ii) ⌊ d −c12b ⌋ − ⌊ d −c22b ⌋ + (hℓ1 − hℓ2 )(r2 − r1). (75)

Now, we have two cases as follows.

Case 1:

⌊ c1 ⌋ − ⌊ c2 ⌋ > 0. d − 2b d − 2b

In this case, note that hℓ1, hℓ2 ∈ {1, · · · , n}, and r1, r2 ∈ {1, · · · , α}, then we have,

(hℓ1 − hℓ2 )(r2 − r1) ≥ −αn,

and hence using (61), and (62) we have pow(σ′) − pow(σ) > 0.

30

Case 2:

⌊ c1 ⌋ − ⌊ c2 ⌋ = 0. d − 2b d − 2b

In this case, considering the structure of the matrix ΞH, as presented in (65), from (60) we conclude that hℓ2 > hℓ1 . Therefore, from (71) we have (hℓ1 − hℓ2)(r2 − r1) > 0, and hence pow(σ′) − pow(σ) > 0.

Corollary 2. In the representation of the determinant of matrix ΞH introduced in (68), the term(s) with highest exponent of g are associated to permutation(s) in the family F .

Lemma 9. For the matrix ΞH, as introduced in (65), let f (x) denote the polynomial introduced in (69). Then the term with highest exponent of g in f (g) is unique.

Proof. Based on the Corollary 2, the highest exponent of g appears in permutation(s) from the family F . Hence, to prove this lemma we only need to show there exists a unique permutation σ∗ ∈ F , such that pow(σ∗) is the maximum among all other permutations in F . To this end, we ﬁrst note that from (66) it is clear that every entity of the matrix ΞH can be considered
as the product of two components. The ﬁrst component is in the form

giℓ ℓ′ ,

(76)

for some ℓ ∈ {1, · · · , z}, and ℓ′ ∈ {0, · · · , zd − 1}. We refer to this component as the omega component. The other component is in the form

ghℓ′′ r−1 ,

(77)

for some hℓ′′ ∈ H, and r ∈ {1, · · · , α}. We refer to this component as the phi component. Likewise, each term in f (g), associated with a permutation σ, which is written as
α
ΞH(i, σ(i)),
i=1
can be decomposed into two components. One component is the product of all the omega components of the entities ΞH(i, σ(i)), and the we refer to it as the omega component, and the other part is the product of all the phi components of ΞH(i, σ(i))’s and is referred to as the phi component.
Since any permutation in F maps all the rows in block row i to all the columns in block column i, it is then easy to check that the omega component of all the terms associated with permutations in F are the same. To complete the proof we then only need to show that the phi component of the term associated with a unique permutation σ∗ ∈ F has the largest exponent of g.
From the structure of the matrix ΞH, as presented in (65), we can see that each column is associated with one of the helpers hℓ ∈ H, such that the exponent of g in the phi component of all the entities in that column is a multiple of hℓ. Let’s refer to such hℓ as the helper index of the column. Moreover, from (77) and using the ”rearrangement inequality” [47] Section 10.2, Theorem 368, we conclude that the exponent of g in the phi component of a term associated with a permutation σ ∈ F is maximized when in each block row i, the helper index of the column assigned to each row r increases with as r increases. Note that, this mapping in each block row is well deﬁned since the size of each block column is dmin − 2b ≤ d − 2b for any d ∈ D, and hence each helper index only appears at most once in each block column. Therefore, the permutation deﬁned based on the maximizing assignment is unique in F . This completes the proof.

The following example illustrates the unique permutation associated with the maximum exponent of g in the expression of the determinant |ΞH| as represented in (68).

Example 10. Consider n = 6, k = 4, D = {4, 5}, and b = 1. Then notice that dmin = 4, and setting α = 6 satisﬁes (4.

Assume node f = 1 is failed and consider a repair based on d = 5 helpers. We then focus on a subset H = {h1, h2, h3} of

helpers of size d − 2b = 3 for this example, such that 1 ≤ h1 < h2 < h3 ≤ n. From (65) we have,

 V1 ΞH =  V2
V3

gi1 V1  gi2 V2  ,
gi3 V3

for some i1, i2, and i3 satisfying (61), and (62), and

V1 =

gh1 0 gh1 1

gh2 0 gh2 1

gh3 0 gh3 1 , V2 =

gh1 2 gh1 3

gh2 2 gh2 3

gh3 2 gh3 3 , V3 =

gh1 4 gh1 5

gh2 4 gh2 5

gh3 4 gh3 5 .

31

Note that in this example zd = α/(d − 2b) = 6/3 = 2, and each submatrix Vj, j ∈ {1, 2, 3} is of size (dmin − 2b) × (d − 2b) = 2 × 3. Moreover, each block row and block column is of size dmin − 2b = 2. Finally the elements ΞH(i, σ∗(i)), for the permutation σ∗ corresponding to the maximum exponent of g in (68) are illustrated in red as follows











ΞH

=

 









gh1 0 gh1 1
gh1 2 gh1 3
gh1 4 gh1 5

gh2 0 gh2 1
gh2 2 gh2 3
gh2 4 gh2 5

gh3 0 gh3 1
gh3 2 gh3 3
gh3 4 gh3 5

gh1 0 gi1 gh1 1 gi1
gh1 2 gi2 gh1 3 gi2
gh1 4 gi2 gh1 5 gi2

gh2 0 gi1 gh2 1 gi1
gh2 2 gi2 gh2 3 gi2
gh2 4 gi2 gh2 5 gi2

gh3 0 gi1 

gh3 1 gi1

 

gh3 2 gi2 

gh3 3 gi2

 

gh3 4 gi2 

gh3 5 gi2

As illustrated above, in the second row and column blocks, the permutation σ∗ assigns the forth row of ΞH to column three,

and the third row to column four, since column three has helper index h3 which is by assumption larger than the helper index

of column four, namely h1.

△

Note that in the Leibniz expansion for the determinant of ΞH, each term is a power of the primitive element of Fq, namely g. Moreover, using the result of Lemma 9 we conclude that the term associated with σ(i) = i, provides the largest exponent of g which is unique, and hence does not get cancelled by any other term in the expansion. Then the polynomial f (x) is non-trivial as the coefﬁcient of the term with highest power in f (x) is one. Let deg(f ) denote the degree of the polynomial f (x), and assume the degree of the expansion ﬁeld Fq over Fp, namely m, is larger than deg(f ). In other words, assume

logp(q) > deg(f ).

(78)

Now we use the following well-known result to show that the g could not be a root of the polynomial f (x).

Theorem 4. [48] Let Fq be a ﬁnite ﬁeld with q = pm elements, for some prime number p. Also let g be a primitive element in Fq, with the minimal polynomial ̺(x) ∈ Fp[x]. If f (x) ∈ Fp[x] with f (g) = 0, then ̺(x)|f (x).

The above result holds due to the fact that the minimal polynomial is irreducible, and the ring of polynomials is an integral domain.
Using (78), it is clear that the polynomial f (x) is not divisible by the minimal polynomial ̺(x), and hence using Theorem 4, we conclude that the determinant of the matrix ΞH is non-zero, which in turn proves the non-singularity of ΘH.
Remark 7 (Field size requirement). Note that in order to satisfy (78) and guarantee f (x) ∈ Fp[x], we need both p and q to be large enough. For the sake of completeness here we provide lower bounds on each one that guarantee the required conditions, although they might not necessarily be the tightest lower bounds.
Having

p > α!

guarantees f (x) ∈ Fp[x]. Moreover, selecting i1, · · · , iz as

ij = αn(j − 1) + 1, satisﬁes both (61) and (62). The largest exponent of g, realized in the term associated with the permutation σ∗, is then upper bounded by
α2n 1 + z2 .

Finally the upper bound on the required ﬁeld size is (α!)(α2n(1+z2)) .

This is of course very huge for practical settings, however, note that the goal of this appendix is to provide a proof for the
the non-singularity of the matrix ΘH. We present a different coding scheme for practical settings in Section V, which reduces the ﬁeld size requirement to n.

APPENDIX C PROOF OF LEMMA 6
Proof. The proof follows ideas similar to [1], [20], and [18]. However, to derive an upper bound on the capacity of a BAER setting, we introduce a genie-aided version of this code. Then we derive the upper bound on the capacity F , by ﬁnding an appropriate cut-set in the information ﬂow graph corresponding to the genie-aided version.

32

In the genie-aided version of C(n, k, D, b, α, γ(·)), when we select the set of d helper nodes for a repair, the genie identiﬁes a subset of size d − 2b of the selected helpers as genuine helpers, and we will only receive repair data from them. Similarly, in the download process after choosing the set of k nodes, the genie identiﬁes a subset of size k − 2b of genuine nodes among them, and the data collector only collects data from this subset. From Lemma 5 we know that limiting the connections in the
genie-aided version will not reduce the storage capacity. Hence, the storage capacity of the genie-aided version is an upper bound for F ; the storage capacity of the original setting.

PSfrag replacements
∞ ∞

α

1in

1out

α

2in

2out

d − 2b

α

ℓ1in

ℓ1out

α

α α

d′ − 2b − 1

ℓ2in

ℓ2out

DC α

∞

α

S

nin

nout

d′′ − k + 1

α ℓk−2bin ℓk−2bout

Fig. 10. The information ﬂow graph of the genie-aided version of a BAER regenerating code C(n, k, D, b, α, γ(·)).

To derive an upper bound on the storage capacity of the genie-aided version, we will consider the information ﬂow graph
as introduced in [1]. The information ﬂow graph is a directed acyclic graph (DAG) model to represent the ﬂow of information
during a sequence of repairs and data reconstructions in the network. The source of information is represented as a single node
which has only out-going edges, and any data collector is represented as a single node which only has in-coming edges. Every storage node ℓ, which has once been used in the network, is represented by a pair of nodes ℓin, and ℓout in the DAG such that an edge with capacity α takes the ﬂow of information from ℓin to ℓout. This edge represents the per node storage capacity constraint for node ℓ, hence we refer to such edges as storage edges. In addition to storage edges there are three other types of edges in the information ﬂow graph, namely the download edges, the repair edges, and the source edges. Download edges have capacity α and take information ﬂow from ℓout to a data collector node if ℓ is among the genuine selected nodes for the data collector. Repair edges take information ﬂow from ℓout to ℓ′in if ℓ′ is a replacement node in the distributed storage network, and ℓ is one of the selected genuine helpers for the repair. The capacity of repair edges in the information ﬂow graph is then γ(d)/(d − 2b), for the chosen parameter d in the corresponding repair. Finally, we also consider a set of n source edges with inﬁnite capacity, taking information ﬂow from the source node to the input node of initial n storage nodes in the network.
Figure 10 depicts one example of an information ﬂow graph.
Corresponding to any speciﬁc sequence of repair and data reconstruction processes, there exists a speciﬁc information ﬂow
graph. Any cut-set in the DAG model for an information ﬂow graph consists of a set of edges such that after removing them,
there is no path from the source to the data collector. As a result, the sum capacity of all the edges in a cut-set provides
an upper bound on the capacity of information which could be stored in the corresponding distributed storage network and
restored by a data collector after the sequence of repairs associated to the information ﬂow graph is performed. We are going
to consider the information ﬂow graph depicted in Fig. 10.
As depicted in the Fig 10 in our scenario a data collector is downloading the data stored in the network by accessing a set of k − 2b genuine nodes in the genie-aided setting. These nodes are indexed as ℓ1, · · · , ℓk−2b. We assume that each one of the nodes ℓ1, · · · , ℓk−2b is a replacement node, added to the network through a repair procedure. We also assume for any i ∈ {1, · · · , k − 2b}, the repair for node ℓi is performed after the repair for any node ℓj, j < i, and all of the nodes ℓj, j ∈ {1, · · · , i − 1} are used as genuine helpers in the repair of the node ℓi, as depicted in Fig. 10. However, note that we let the number of helpers participating in each repair to be independently chosen from the set D.
We now describe the procedure of forming a cut-set for the information ﬂow graph described above, by choosing a subset of storage or repair edges. For any i ∈ {1, · · · , k − 2b}, we either choose its storage edge, or all the d − 2b − i + 1 repair edges coming from the genuine helpers not in the set {ℓ1, · · · , ℓi−1} to node ℓiin. In order to choose we compare α, the capacity of the storage edge for node ℓi, with the sum of the capacities of the described repair edges, and whichever is smaller its corresponding edges will be added to the cut-set. Then, considering all the possible choices for the number of helpers in all the k − 2b repair procedures, we can ﬁnd the following upper-bound on the total storage capacity using the best cut-set achieved
by this scheme as follows,

F ≤ k−2b min α, min ((d − 2b − i + 1)β(d)) = k−2b−1 min α, min (d − 2b − j) γ(d) .

d∈D i=1

j=0 d∈D d

33

In the case of the MBR mode however, we know from Theorem 2,

αd γMBR(d) = d − 2b . As a result, for any j ∈ {0, · · · , k − 2b − 1} we get

min (d − 2b − j) γMBR(d)

d∈D

d

= (dmin − 2b − j) α , dmin − 2b

and hence,

k−2b−1

α

FMBR ≤

min α, (dmin − 2b − j) dmin − 2b .

j=0

= α(k − 2b) dmin − b − k − 1 .

dmin − 2b

2

REFERENCES
[1] A. G. Dimakis, P. B. Godfrey, Y. Wu, M. J. Wainwright, and K. Ramchandran, “Network coding for distributed storage systems,” IEEE Transactions on Information Theory, vol. 56, no. 9, pp. 4539–4551, Sep. 2010.
[2] K. V. Rashmi, N. B. Shah, and P. V. Kumar, “Optimal exact regenerating codes for distributed storage at the MSR and MBR points via a product-matrix construction,” IEEE Transactions on Information Theory, vol. 57, no. 8, pp. 5227–5239, August 2011.
[3] K. Mahdaviani, A. Khisti, and S. Mohajer, “Bandwidth adaptive & error resilient regenerating codes with minimum repair bandwidth,” in Proc. IEEE International Symposium on Information Theory (ISIT), Barcelona, Spain, July 2016, pp. 235–239.
[4] A. G. Dimakis, P. B. Godfrey, M. Wainwright, and K. Ramchandran, “Network coding for distributed storage systems,” in Proc. IEEE International Conference on Computer Communications (INFOCOM), Anchorage, Alaska, USA, May 2007, pp. 2000–2008.
[5] Y. Wu, A. Dimakis, and K. Ramchandran, “Deterministic regenerating codes for distributed storage,” in Proc. Annual Allerton Conference on Control, Computing, and Communication (Allerton), Urbana-Champaign, IL, USA, September 2007.
[6] K. V. Rashmi, N. B. Shah, P. V. Kumar, and K. Ramchandran, “Explicit construction of optimal exact regenerating codes for distributed storage,” in Proc. Annual Allerton Conference on Control, Computing, and Communication (Allerton), Urbana-Champaign, IL, USA, September 2009.
[7] V. Cadambe, C. Huang, and J. Li, “Permutation code: optimal exact-repair of a single failed node in MDS code based distributed storage systems,” in Proc. IEEE International Symposium on Information Theory (ISIT), Saint Petersburg, Russia, Aug. 2011, pp. 1225–1229.
[8] V. Cadambe, S. Jafar, H. Maleki, K. Ramchandran, and C. Suh, “Asymptotic interference alignment for optimal repair of MDS codes in distributed storage,” IEEE Transactions on Information Theory, vol. 59, no. 5, pp. 2974–2987, May 2013.
[9] M. N. Krishnan and P. V. Kumar, “On MBR codes with replication,” in Proc. IEEE International Symposium on Information Theory (ISIT), Barcelona, Spain, July 2016, pp. 71–75.
[10] B. Sasidharan, M. Vajha, and P. V. Kumar, “An explicit, coupled-layer construction of a high-rate MSR code with low sub-packetization level, small ﬁeld size and d < (n − 1),” Available online: https://arxiv.org/abs/1701.07447, 2017.
[11] I. Tamo, Z. Wang, and J. Bruck, “Zigzag codes: MDS array codes with optimal rebuilding,” IEEE Transactions on Information Theory, vol. 59, no. 3, pp. 1597–1616, March 2013.
[12] Z. Wang, I. Tamo, and J. Bruck, “Explicit minimum storage regenerating codes,” IEEE Transactions on Information Theory, vol. 62, no. 8, pp. 4466–4480, Aug. 2016.
[13] M. Ye and A. Barg, “Explicit constructions of high-rate MDS array codes with optimal repair bandwidth,” IEEE Transactions on Information Theory, vol. 63, no. 4, pp. 2001–2014, April 2017.
[14] ——, “Explicit constructions of optimal-access MDS codes with nearly optimal sub-packetization,” Available online: https://arxiv.org/abs/1605.08630, 2017.
[15] L. N. Bairavasundaram, A. C. Arpaci-Dusseau, R. H. Arpaci-Dusseau, G. R. Goodson, and B. Schroeder, “An analysis of data corruption in the storage stack,” ACM Transactions on Storage, vol. 4, no. 3, pp. 8:1–8:28, Nov. 2008.
[16] N. B. Shah, K. V. Rashmi, and P. V. Kumar, “A ﬂexible class of regenerating codes for distributed storage,” in Proc. IEEE International Symposium on Information Theory (ISIT), Austin, Texas, USA, June 2010, pp. 1943–1947.
[17] A.-M. Kermarrec, N. L. Scouarnec, and G. Straub, “Repairing multiple failures with coordinated and adaptive regenerating codes,” in Proc. IEEE International Symposium on Network Coding (NetCod), Beijing, China, July 2011, pp. 1–6.
[18] V. Aggarwal, C. Tian, V. A. Vaishampayan, and Y.-F. R. Chen, “Distributed data storage systems with opportunistic repair,” in Proc. IEEE International Conference on Computer Communications (INFOCOM), Toronto, Canada, April–May 2014, pp. 1833–1841.
[19] M. Hajiaghayi and H. Jafarkhani, “MDS codes with progressive engagement property for cloud storage systems,” Available online: https://arxiv.org/abs/1605.06927, 2016.
[20] S. Pawar, S. E. Rouayheb, and K. Ramchandran, “Securing dynamic distributed storage systems against eavesdropping and adversarial attacks,” IEEE Transactions on Information Theory, vol. 57, no. 10, pp. 6734–6753, October 2011.
[21] K. V. Rashmi, N. B. Shah, K. Ramchandran, and P. V. Kumar, “Regenerating codes for errors and erasures in distributed storage,” in Proc. IEEE International Symposium on Information Theory (ISIT), Cambridge, MA, USA, July 2012, pp. 1202–1206.
[22] K. Mahdaviani, S. Mohajer, and A. Khisti, “Product matrix MSR codes with bandwidth adaptive exact repair,” Available online: https://arxiv.org/abs/1708.03402, 2017.
[23] ——, “Product matrix minimum storage regenerating codes with ﬂexible number of helpers,” in Proc. IEEE Information Theory Workshop (ITW), Kaohsiung, Taiwan, Nov. 2017.
[24] S. Pawar, S. E. Rouayheb, and K. Ramchandran, “Securing dynamic distributed storage systems from malicious nodes,” in Proc. IEEE International Symposium on Information Theory (ISIT), Saint-Petersburg, Russia, June 2011, pp. 1452–1456.
[25] O. Kosut, “Polytope codes for distributed storage in the presence of an active omniscient adversary,” in Proc. IEEE International Symposium on Information Theory (ISIT), Istanbul, Turkey, July 2013, pp. 897–901.
[26] F. Oggier and A. Datta, “Byzantine fault tolerance of regenerating codes,” in Proc. IEEE International Conference on Peer-to-Peer Computing (P2P), Kyoto, Japan, Sept. 2011, pp. 112–121.
[27] Y. S. Han, R. Zheng, and W. H. Mow, “Exact regenerating codes for byzantine fault tolerance in distributed storage,” in Proc. IEEE International Conference on Computer Communications (INFOCOM), Orlendo, FL, USA, March 2012, pp. 2498–2506.

34
[28] Y. Han, H.-T. Pai, R. Zheng, and W. H. Mow, “Efﬁcient exact regenerating codes for byzantine fault tolerance in distributed networked storage,” IEEE Transactions on Communications, vol. 62, no. 2, pp. 385–397, Feb. 2014.
[29] Y. Komamiya, “Application of logical mathematics to information theory,” in Proc. 3rd Japan. Nat. Cong. Appl. Math., 1953, p. 437. [30] R. C. Singleton, “Maximum distance q-nary codes,” IEEE Transactions on Information Theory, vol. 10, no. 2, pp. 116 – 118, Feb. 1964. [31] N. B. Shah, K. V. Rashmi, K. Ramchandran, and P. V. Kumar, “Information-theoretically secure erasure codes for distributed storage,” Available online:
https://arxiv.org/pdf/1508.03787.pdf, 2015. [32] N. Silberstein, A. S. Rawat, and S. Vishwanath, “Error resilience in distributed storage via rank-metric codes,” in Proc. Annual Allerton Conference on
Control, Computing, and Communication (Allerton), Urbana-Champaign, IL, USA, Oct. 2012. [33] Y. S. Han, H.-T. Pai, R. Zheng, and P. K. Varshney, “Update-efﬁcient error-correcting product-matrix codes,” IEEE Transactions on Communications,
vol. 63, no. 6, pp. 1925–1938, June 2015. [34] R. Bitar and S. E. Rouayheb, “Securing data against limited-knowledge adversaries in distributed storage systems,” in Proc. IEEE International Symposium
on Information Theory (ISIT), Hong Kong, June 2015. [35] B. Wang, H. Kan, and K. W. Shum, “Hermitian codes in distributed storage systems with optimal error-correcting capacity,” in Proc. IEEE International
Symposium on Information Theory (ISIT), Hong Kong, June 2015. [36] J. Li, T. Li, and J. Ren, “Optimal construction of regenerating code through rate-matching in hostile networks,” IEEE Transactions on Information
Theory, vol. 63, no. 7, pp. 4414–4429, July 2017. [37] “Spacemonkey project,” http://www.spacemonkey.com. [38] “Tahoe: The least-authority ﬁle system,” http://www.tahoe-lafs.org/trac/tahoe-lafs. [39] F. Dabek, F. Kaashoek, D. Karger, R. Morris, and I. Stoica, “Wide-area cooperative storage with CFS,” in Proc. ACM Symposium on Operating Systems
Principles (SOSP), Chateau Lake Louise, Banff, Canada, October 2001, pp. 202–215. [40] S. Ghemawat, H. Gobioff, and S.-T. Leung, “The Google ﬁle system,” in Proc. ACM Symposium on Operating Systems Principles (SOSP), NewYork,
USA, October 2003. [41] S. Rhea, P. Eaton, D. Geels, H. Weatherspoon, B. Zhao, and J. Kubiatowicz, “Pond: The OceanStore prototype,” in Proc. USENIX Conference on File
and Storage Technologies (FAST), San Francisco, USA, March-April 2003. [42] R. Bhagwan, K. Tati, Y.-C. Cheng, S. Savage, and G. M. Voelker, “Total recall: System support for automated availability management,” in Proc. USENIX
Conference on Networked System Design and Implementation (NSDI), San Francisco, USA, March 2004. [43] X. Wang, Y. Xu, Y. Hu, and K. Ou, “MFR: Multi-loss ﬂexible recovery in distributed storage systems,” in Proc. IEEE International Conference on
Communications (ICC), Cape Town, South Africa, May 2010, pp. 1–5. [44] V. Havel, “A remark on the existence of ﬁnite graphs,” Cˇ asopis pro peˇstova´n´ı matematiky (in Czech), vol. 80, pp. 477–480, 1955. [45] S. L. Hakimi, “On realizability of a set of integers as degrees of the vertices of a linear graph. i,” Journal of the Society for Industrial and Applied
Mathematics, vol. 10, pp. 496–506, 1962. [46] P. Almeida, D. Napp, and R. Pinto, “A new class of superregular matrices and MDP convolutional codes,” Linear Algebra and its Applications, vol.
439, no. 7, pp. 2145–2157, 2013. [47] G. H. Hardy, J. E. Littlewood, and G. Po´lya, Inequalities, 2nd ed. Cambridge University Press, 1952. [48] T. W. Hungerford, Algebra. New York: Springer-Verlag, 1974.

