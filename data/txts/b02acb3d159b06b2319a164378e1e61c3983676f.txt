Benchmarking the Combinatorial Generalizability of Complex Query Answering on Knowledge Graphs

arXiv:2109.08925v2 [cs.CL] 5 Nov 2021

Zihao Wang‚àó Department of CSE
HKUST zwanggc@cse.ust.hk

Hang Yin‚àó Department of Mathematical Sciences
Tsinghua University h-yin20@mails.tsinghua.edu.cn

Yangqiu Song Department of CSE, HKUST Peng Cheng Laboratory, Shenzhen, China
yqsong@cse.ust.hk

Abstract
Complex Query Answering (CQA) is an important reasoning task on knowledge graphs. Current CQA learning models have been shown to be able to generalize from atomic operators to more complex formulas, which can be regarded as the combinatorial generalizability. In this paper, we present EFO-1-QA, a new dataset to benchmark the combinatorial generalizability of CQA models by including 301 different queries types, which is 20 times larger than existing datasets. Besides, our benchmark, for the Ô¨Årst time, provide a benchmark to evaluate and analyze the impact of different operators and normal forms by using (a) 7 choices of the operator systems and (b) 9 forms of complex queries. SpeciÔ¨Åcally, we provide the detailed study of the combinatorial generalizability of two commonly used operators, i.e., projection and intersection, and justify the impact of the forms of queries given the canonical choice of operators. Our code and data can provide an effective pipeline to benchmark CQA models.
1 Introduction
Knowledge graphs, such as Freebase [3], Yago [18], DBPedia [2], and NELL [5] are graph-structured knowledge bases that can facilitate many fundamental AI-related tasks such as reasoning, question answering, and information retrieval [9]. Different from traditional well-deÔ¨Åned ontologies, knowledge graphs often have the Open World Assumption (OWA), where the knowledge can be incomplete to support sound reasoning. On the other hand, the graph-structured data naturally provide solutions to higher-order queries such as ‚Äúthe population of the largest city in Ohio State.‚Äù
Given the OWA and scales of existing knowledge graphs, traditional ways of answering muti-hop queries can be difÔ¨Åcult and time-consuming [16]. Recently, several studies use learning algorithms to reason over the vector space to answer logical queries of complex types, e.g., queries with multiple projections [7], Existential Positive First-Order (EPFO) queries [10, 15, 1], and the so called Ô¨Årst order queries, i.e., EPFO queries with the negation operator [16, 19, 13]. These tasks are usually called Complex Query Answering (CQA). Unlike the traditional link predictors that only model entities and relations [4], CQA models also consider logical connectives (operators) such as conjunction (‚àß), disjunction (‚à®), and negation (¬¨) by parameterized operations [10, 15, 16] or non-parameterized operations such as logical t-norms [1, 13].
‚àóEqual Contribution
35th Conference on Neural Information Processing Systems (NeurIPS 2021) Track on Datasets and Benchmarks.

Natural Language:

Find a movie about love or a movie starred by the actor who has won the Oscar but not the golden globe.

Logical Formula:

? ùõº‚àÉùõΩ. IsAbout(ùõº, Love) ‚à® [HasActor(ùõº, ùõΩ) ‚àß Won(ùõΩ, Oscar) ‚àß ¬¨ Won(ùõΩ, Golden globe)]

Set Operations:

MovieHasActor(ActorWon(Oscar) ‚à© Not(ActorWon(Golden globe))) ‚à™ MoveIsAbout(Love)

OpsTree Oscar

ActorWon

Intersection

MovieHasActor

Union

Operators

Golden Globe

inupe

ActorWon Negation Love MovieIsAbout

Query Type (LISP-like): (u,(p,(e)),(p,(i,(p,(e)),(n,(p,(e))))))

Figure 1: An example of EFO-1 query. The same query are represented in natural language (which is only used for interpreting the query and we do not consider semantic parsing from natural language to logical forms), Ô¨Årst-order logical formula, set operations, and OpsTree. The query type can be represented in the LISP-like grammar.

One of the advantages of learning based methods is that the learned embeddings and parameterization in the vector space can generalize queries from atomic operations to more complex queries. It has been observed there are out-of-distribution generalization phenomena of learning models [1] on the Q2B dataset [15] (5 types to train but 4 unseen types to generalize) and the BetaE dataset [16] (10 types to train and 4 unseen types to generalize). This can be explained by the fact that complex queries are all composed by atomic operations such as projection, conjunction, disjunction, and negation. This idea evokes the combinatorial generalization, that is, the model generalizes to novel combinations of already familiar elements [21]. However, compared to the huge combinatorial space of the complex queries (see Section 2 and 3), existing datasets [15, 16] only contains queries from very few types, which might be insufÔ¨Åcient for the investigation of the combinatorial generalization ability of learning models. Moreover, there is no agreement about how to present the complex queries by operators and normal forms. For example, some approaches treat the negation as the atomic operation [16, 13] while others replace the negation by the set difference (intersection combined with negation) [19, 12]. The impact of the representation of the complex query using learning algorithms is also unclear.
In this paper, we aim to benchmark the combinatorial generalizability of learning models for the CQA on knowledge graphs. We extend the scope from a few hand-crafted query types to the family of Existential First-Order queries with Single Free Variable (EFO-1) (see Section 2) by providing a complete framework from the dataset construction to the model training and evaluation. Based on our framework, the combinatorial generalizability of CQA models that fully supports EFO-1 queries [13, 16, 12] are evaluated and discussed. Our contribution are in three-fold.
‚Ä¢ Large-scale dataset of combinatorial queries. We present the EFO-1-QA dataset to benchmark the combinatorial generalizability of CQA models. EFO-1-QA largely extends the scope of previous datasets by including 301 query types, which is 20 times larger than existing datasets. The evaluation results over three knowledge graphs show that the our set is generally harder than existing ones.
‚Ä¢ Extendable framework. We present a general framework for (1) iterating through the combinatorial space of EFO-1 query types, (2) converting queries to various normal forms with related operators, (3) sampling queries and their answer sets, and (4) training the CQA models and evaluating the CQA checkpoints. Our framework can be applied to generate new data as well as train and evaluate the models.
‚Ä¢ New Ô¨Åndings for normal forms, training, and generalization. In our dataset, each query is transformed into at most 9 different forms that are related to 7 choices of operators. Therefore, for the Ô¨Årst time, a deep analysis of normal forms are available in our benchmark. How the normal form affects the combinatorial generalization is discussed and new observations are revealed. Moreover, we also explore how training query types affect the generalization. We Ô¨Ånd that increasing training query types is not always beneÔ¨Åcial for CQA tasks, which leads to another open problem about how to train the CQA models.

2 Complex Queries on KG
In this section, we introduce the Existential First Order Queries with Single Free Variable (EFO-1) on the knowledge graphs. Here we give an intuitive example of EFO-1 queries and the related concepts

2

Table 1: EFO-1 formula for 14 query types in BetaE dataset. The grammar of the EFO-1 formula are given in the Appendix B.

BetaE
1p 2p 3p 2i 3i ip pi 2in

EFO-1 formula
(p,(e)) (p,(p,(e))) (p,(p,(p,(e)))) (i,(p,(e)),(p,(e))) (i,(i,(p,(e)),(p,(e))),(p,(e))) (p,(i,(p,(e)),(p,(e)))) (i,(p,(p,(e))),(p,(e))) (i,(p,(e)),(n,(p,(e))))

BetaE
3in inp pin pni 2u-DNF up-DNF 2u-DM up-DM

EFO-1 formula
(i,(p,(e)),(i,(p,(e)),(n,(p,(e))))) (p,(i,(p,(e)),(n,(p,(e))))) (i,(p,(p,(e))),(n,(p,(e)))) (i,(n,(p,(p,(e)))),(p,(e))) (u,(p,(e)),(p,(e))) (u,(p,(p,(e))),(p,(p,(e)))) (n,(i,(n,(p,(e))),(n,(p,(e))))) (p,(n,(i,(n,(p,(e))),(n,(p,(e))))))

in Figure 1. Compared to the query families considered in the existing works [10, 15, 16], EFO-1 is a family of queries that are most general. The formal deÔ¨Ånition and self-contained formal derivation of EFO-1 query family from Ô¨Årst-order queries can be found in the Appendix A. Notably, the formal derivation of EFO-1 queries enables and guarantees the logical equivalent query representation in set operations and Operators Tree (OpsTree). SpeciÔ¨Åcally, the fomally derivied OpsTree is the composition of set functions including intersection, union, negation, projection, and entity anchors. This presentation is also widely but informally introduced in existing CQA models [15, 16, 19].
We consider the EFO-1 queries at the abstract level and the grounded level. At the abstract level, the structure of a query is speciÔ¨Åed, but the projection or the entities are not given. At the grounded level, the projections and entities are instantiated (see Section 3 for how to ground the queries). We call queries without the instantiation query types. When the query type is given, one can ground the projections and entities in a KG to obtain the speciÔ¨Åc EFO-1 query.
3 The Construction of EFO-1-QA Benchmark

In this section, we cover the detailed framework of the construction of EFO-1-QA benchmark. Our framework includes (1) the generation and normalization of EFO-1 query types following the deÔ¨Ånitions in Section 2; (2) grounding query types to speciÔ¨Åc knowledge graph to get the queries and sampling the answer set; (3) constructing the computational graph to conduct the end-to-end training and evaluation. (4) Evaluation the model with metrics that emphasis on the generalizability. In our practice, we keep the EFO-1-QA dataset as practical as possible and follow the common practice of BetaE dataset. Our benchmark contains 301 different query types (in the Original form) and is at least 20 times larger than the previous works [15, 16, 12]. Moreover, the overall dataset construction and inference pipeline is general enough. It can be applied to EFO-1 queries of any complexity and any properly parametrized operators.
3.1 Generation of EFO-1 Query Types
Since EFO-1 queries can be represented by the OpsTree, we employ a LISP-like language [14] to describe the EFO-1 query types. The string generated by our grammar is called an EFO-1 formula (see Appendix B for more details about the grammars). Follow our derivation of EFO-1 queries from the FO queries (see Appendix A), Ô¨Åve operators are naturally introduced by the Skolemization process, including entity e (0 operand), projection p (1 operand), negation n (1 operand), intersection i (2 operands), and union u (2 operands). SpeciÔ¨Åcally, Table 1 give the example of the EFO-1 formulas for 14 query types in the BetaE dataset [16]. We can parse any EFO-1 formula to the OpsTree according the our grammar.
In EFO-1-QA benchmark, the EFO-1 formulas are generated by a depth Ô¨Årst search of the Grammar 2 in the Appendix B with the [e,p,i,u,n] operators. The grammar explicitly follows the practice of bounded negation. That is, we only generate the negation operator when it is one operand of an intersection operator. The produced OpsTree is binary.
Instead of producing endless query types in the combinatorial spaces of EFO-1 queries, we keep the generated types as realistic as possible by following two practical constraints: (1), we set the
3

Abstract Level

EFO-1 Formula (Original) Normal Forms (DNF+MultiIUD)

EFO-1 queries are generated by the grammar (Appendix A)

(i,(n,(p,(p,(e)))), (p,(u,(p,(e)), (p,(e)))))

Grounded Level

Parser backward grounding the p,e ops

nppe

i

pe

KG

pu

(Section 3.2)

pe

{o:i,

a:[{o:n, {o:p,

a:{o:p, a:[[169], {o:p, a:[[168], {o:e, a:[2711]}]}]}},
a:[[277], {o:u, a:[{o:p, a:[[7], {o:e, a:[6724]}]}, {o:p, a:[[276], {o:e, a:[8671]}]}]}]}]}

JSON-like grounded query on KG (Appendix D)

(u,(D,(p,(p,(e))), (p,(p,(e)))), (D,(p,(p,(e))), (p,(p,(e)))))
(Section 2.3)

OpsTree

nppe

i

pe

pu

pe

Answer set by query the KGs

(Section 3.2)

[14467, 12707, 14408, 14536, 7720, 9931, 11159, 6359, ‚Ä¶]

Different choice of operators

Parametrized Ops Set inupe

Computational Graph (Section 3.3)

backward propagation

nppe

i

pe

pu

pe

forward inference

Evaluation Protocol (Section 3.4)

Scores

Figure 2: Framework of constructing the EFO-1-QA benchmark. The query types are deÔ¨Åned by the EFO-1 formula, which is generated the Grammar 2 in the Appendix B and generated at the abstract level. The EFO-1 formula can be converted to different normal forms and represented in the different operators. A parser is employed to produce the OpsTree from the EFO-1 formula. Queries are grounded by the backward DFS of the OpsTree on the full graph and the answers are sampled by the forward execution of the OpsTree on the partial graph as explained in Section 3.3. The OpsTree can also be used to build the computational graph with the parameterized operators, which are used to train and infer the CQA models by the backward propagation and forward inference. Finally, the estimated query embeddings are evaluated by the Evaluation Protocol with 5 metrics given in the Section 3.5.

Table 2: Number of EFO-1 query types with respect to the maximum length of projection chains and number of anchor nodes for EFO-1-QA and BetaE dataset. The boldface indicates the queries that are not discussed sufÔ¨Åciently in the BetaE dataset.

Max length
of projection
chains 1

# anchor nodes

EFO-1-QA

BetaE

2 3 Sum 1 2 3 Sum

1

1 3 12 16 1 3 2

6

2

1 10 91 102 1 6 0

7

3

1 13 169 183 1 0 0

1

Sum

3 26 272 301 3 9 2 14

maximum length of projection/negation chains to be 3. That is, we consider no more than three projections/negations in any paths from the target root node to anchor leaf nodes, which follows the 3p setting in Table 1. (2), we limit the number of anchor nodes to no more than 3, which follows the 3i setting in Table 1. As a result, we generate 301 different query types, more details can be found in Table 2.
3.2 Normalization of EFO-1 Query Types
Interestingly, in the context of learning based CQA models, the logically equivalent transformation of query types may lead to computationally different structures. On the one hand, different choices of operators lead to different parameterizations and generalization performances. For example, the set difference operator [12] is reported to perform differently from the negation operator [16]. On the other hand, different normal forms also affect the learning based CQA models. SpeciÔ¨Åcally, different forms alters the query structure, i.e., OpsTree, and might result in different depths or various number
4

Table 3: The normal forms of logical queries, related choice of operators and the number of types of each normal form considered in EFO-1-QA benchmark.

(Normal) Forms
Original DM DM + I Original + d DNF DNF + d DNF + IU DNF + IUd DNF + IUD

Operators
[e,p,i,u,n] [e,p,i,n] [e,p,I,n] [e,p,i,u,d] [e,p,i,u,n] [e,p,i,u,d] [e,p,I,U,n] [e,p,I,U,d] [e,p,I,U,D]

Comment
Sort multiple operands by the alphabetical order Replace the u with i,n by De Morgan‚Äôs rule Replace i in DM by I Replace i-n structure by binary d operator Disjunctive Normal Form derived by the Appendix C Replace the n in DNF by binary d Replace the binary i,u in DNF by I,U Replace n in DNF+IU by binary d Replace the n in DNF+IU by multi-difference D

of inputs of the speciÔ¨Åc operator (see the DNF formula and the DNF+IU formula in the Appendix D Table 12) and Ô¨Ånally affect the performance. For example, DNF has been claimed to be better than the De Morgan by [16] when evaluating on 2u and up queries.
However, the impact of the operators and normal forms are not clearly justiÔ¨Åed in previous works because they are also entangled with parametrization, optimization, and other issues. Our benchmark, to the best of our knowledge, is the Ô¨Årst to justify the impact of operators and normal forms from the aspect of the dataset. Our LISP-like language is general enough to be compatible with all those different query types. Here we list ohow EFO-1-QA benchmark considers the impact from choices of operators (see the Grammar 3 in the Appendix B) and normal forms.
(A) Choice of the Operators. We have introduced the [e,p,i,u,n] operator system by Skolemization. In BetaE dataset [16], multi-intersection operator I and multi-union operator U that accept more than two inputs to conduct the intersection and union are chosen in the [e,p,I,U,n] system. In this case, the ‚Äú3i‚Äù type in Table 1 can be rewritten as (I,(p,(e)),(p,(e)),(p,(e))). Moreover, the set difference operator d or the generalized multi-difference operator D are introduced in [12] to replace the negation operator n for EFO-1 queries with the bounded negation assumption. The rationale behind the bounded negation is that the negation should be bounded by a set intersection operation because the set complement against all entities is not practically useful. So one can replace each intersection-negation structure with the set difference, resulting in [e,p,i,u,d] or [e,p,I,U,D] systems. However, the removal of the negation operator made it impossible to apply the De Morgan‚Äôs law, which can represent the union operator u by intersection i and negation n. More comment of the operators can also be found in the Appendix B. To summarize, we consider 7 choices of operators to represent the EFO-1 queries, see Table 3.
(B) Choice of Normal Forms. Normal forms, such as Disjunctive Normal Forms (DNF) [8], are equivalent classes of query types. Normalization, i.e., converting queries into normal forms, is effective to reduce the number of query types and rectify the estimation process while preserving the logical equivalence. The participation of different operator systems makes the choices of normal forms more complicated. In this work, all 9 different forms with 7 different choices of operators are shown in Table 3. This 9 normal forms are selected by enumerating all possible combinations of operators, see Appendix H. The example of each form and how they are transformed are shown in Table 12 in the Appendix D. After obtaining a query from the generation procedure, we transform them to DNF and other seven forms. Most of the conversions are straightforward except the conversion from the original form to the DNF.
3.3 Grounding EFO-1 Queries and Sampling the Answer Sets
Given the speciÔ¨Åc knowledge graph, we can ground the query types with the containing relations and entities. We consider the knowledge graph G and its training subgraph Gtrain, such that Gtrain ‚äÇ G. To emphasis on the generalizability of CQA models that are trained on Gtrain, the queries are grounded to the entire graph G and we pick the answers that can be obtained on the G but not the Gtrain. We note that this procedure follows the protocol in [15] and prevents the data leakage.
Grounding Query Types. The grounding means to assign speciÔ¨Åc relations and entities from the G to the p and e operators in the OpsTree. We conduct the grounding process in the reverse order, i.e.,

5

from the target root node to the leaf anchor nodes, as shown in Figure 2. We Ô¨Årst sample an entity as the seed answer at the root node and go through the tree. During the iterating, the inputs of each operator are derived by its output. For the set operators such as intersection, union, and negation, we select the inputs sets while guaranteeing the output. For the projection operator, we sample the relation from the reverse edges in the G that leaves the speciÔ¨Åc output entity. For the entity operator, i.e., the anchor nodes, we sample the head entity given the relation and the tail entity. In this way, we ensure grounded queries to have at least one answer. The sampling procedure for the negation operator is a bit more complicated and we leave the details in the Appendix F. In order to store the grounded relation and query information, we employ the JSON format to serialize the information. The details of the JSON string can be found in the Appendix E.
Sampling Answer Sets. Once the query is grounded, we can sample the answer by the execution of the OpsTree in the full knowledge graph G. The execution procedure of each operator is deÔ¨Åned in the Table 11. The full answer set Afull is obtained on the G and the trivial answer set Atrivial is obtained by sampling the training subgraph Gtrain. As we stated, we focus on the answer set A = Afull ‚àí Atrivial that cannot be obtained by simply memorizing the known training graph Gtrain. SpeciÔ¨Åcally, we pick the queries whose answer sizes are between 1 and 100, which follows the practice of BetaE dataset [16].
For each query type, we can produce one data sample by a grounding and sampling process. We note that the grounding and sampling process does not rely on a speciÔ¨Åc graph. In this work, we sample the benchmark dataset on three knowledge graphs, including FB15k [20], FB15k-237 [4], and NELL [5] with 5000, 8000, and 4000 queries. More details about how the dataset is organized can be found in the Appeidix G.
3.4 From OpsTree to Computational Graph
Similar to the sampling process where the answers are drawn by the forward computation of the OpsTree, we can also construct the end-to-end computational graph with the parameterized operators in the same topology to estimate the answer embeddings. Therefore, we can train and evaluate the CQA models over the constructed computational graphs of all EFO-1 queries. Practically, we can even use any provided checkpoints to initialize the parameterized operators and conduct the inference. Therefore, the EFO-1-QA provides a general test framework of CQA checkpoints with no need to know how the checkpoints are obtained.
3.5 Evaluation Protocol
The CQA models are evaluated by the ranking based metrics in the EFO-1-QA benchmark. Basically, the ranking of all entities are expected to be obtained after the inference. For example, the entities can be ranked by their ‚Äúdistances‚Äù to the estimated answer embedding. We use following metrics to evaluate the generalizability of CQA models, including MRR and HIT@K that have been widely used in previous works [16, 1, 12].
‚Ä¢ MRR. For each answer entity in the answer set, we consider its ranking with E ‚àí Afull. That is, the ranking of the given answer against all non-answer entities. The Mean Reciprocal Rank (MRR) for a query is the average of the MRR of all answers of this query. The MRR of a query can be 1 if all the answers are ranked before the rest non-answer entities. Then the query MRR are averaged to the speciÔ¨Åc query types or the entire dataset.
‚Ä¢ HIT@K. Similar to MRR, HIT@K is computed for each answer by its ranking in E ‚àí Afull and then averaged for the query. In our practice, we consider K = 1, 3, 10.
‚Ä¢ Retrieval Accuracy (RA). Previous metrics focus on the answer entity against non-answer entities, which deviates from the real-world retrieval task. In this paper, we propose the RA score to evaluate how well a model retrieves the entire answer set. The computation of RA score is decomposed into two steps, i.e., (1) to estimate the size of the answer set as N , (2) to compute the accuracy of the top-N answers against the true answer set.
We note that EFO-1-QA also supports the counting task. However, since not all the CQA models are designed to count the number of answers, we assume that the ground-truth of the answer size is known and only consider the second step of computing the RA score in this paper. We call the RA
6

Table 4: Review of existing CQA datasets, where * means the DNF/DM is required.

CQA Dataset

Support Operators

Support Support Num. of Num. of Test

EPFO epiIuUndD

EFO-1 Forms

Query Types

. Q2B dataset [15]          *



1

9

HypE dataset [6]          *



1

9

BetaE dataset [16]          *

*

2

14

EFO-1-QA (ours)          



9

301

Table 5: Benchmark results of MRR (%) on different dataset. The results of the BetaE dataset are obtained from the original paper [16, 13].

CQA Model

Dataset

FB15k-237

FB15k

NELL

EPFO Neg. ALL EPFO Neg. ALL EPFO Neg. ALL

BetaE

BetaE 20.9 5.4 15.4 41.6 11.8 31.0 24.6 5.9 17.9

+DNF+IU EFO-1-QA 11.8 7.5 9.7 23.7 16.8 20.3 12.7 8.3 10.6

LogicE

BetaE 22.3 5.6 16.3 44.1 12.5 32.8 28.6 6.2 20.6

+DNF+IU EFO-1-QA 12.8 8.1 10.5 25.4 18.2 21.9 15.6 10.4 13.1

score with the known answer size as the RA-Oracle. Moreover, as this benchmark focuses on the generalization property of CQA models, we do not report the evaluation in the entailment setting [19].
4 Related Datasets and the Comparison to EFO-1-QA Benchmark
Existing datasets are constructed along with the CQA models, for the purpose of indicating that their models are capable to solve some certain types of queries by providing a few examples. Thus, those datasets contain very limited query types, normal forms and operators, see Table 4. However, EFO-1-QA benchmark focuses on how well CQA models work on the whole EFO-1 query space and considering the impact of operators and normal forms.
Table 2 already shows that EFO-1-QA benchmark contains much more query types, supported operators and normal forms than BetaE dataset [16], thereby provides a more comprehensive evaluation result. Meanwhile, we compare results of both BetaE [16] and LogicE [13] between EFO-1-QA benchmark and BetaE dataset [16] in Table 5. We note that the EFO-1-QA benchmark is generally harder than BetaE dataset when averaging results from all query types on three KGs. Moreover, our comprehensive benchmark brings us many new insights and helps us to refresh the observations from previous dataset. Finding 1: Negation queries ares not signiÔ¨Åcantly harder. We further separate the query types into two subgroups, i.e., the EPFO queries and the negation queries. Table 5 shows that results from two dataset have very different distribution of the scores in those two subgroups. This can be explained by the fact that the Ô¨Åve negation query types in the BetaE dataset are biased and cannot represent the general performance of the negation queries.
In short, we can conclude that the EFO-1-QA benchmark is more comprehensive, generally harder, and fairer than existing datasets.
5 The Empirical Evaluation of the Benchmark
In this section, we present the evaluation results of the complex query answering models that are compatible to the EFO-1 queries.
5.1 Complex Query Answering Models
We summarize existing CQA models by their supported operators as well as supported query families in Table 13. Only three CQA models fully support EFO-1 family by their original implementation. Therefore, in our evaluation, we focus on these models, including BetaE [16], LogicE [13], and NewLook [12]. These models are trained on the BetaE training set and evaluated on EFO-1-QA
7

Table 6: Benchmark results (%) for all three models and their corresponding normal forms.

Knowledge Graph
FB15k -237
FB15k
NELL

CQA Moddel
Normal Form
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle

DM
8.48 4.35 8.54 16.25 11.49
17.18 10.46 18.76 30.30 21.83
8.93 5.58 9.38 15.27 12.08

BetaE
DM +I
8.50 4.37 8.56 16.27 11.51
17.22 10.51 18.81 30.35 21.89
8.94 5.59 9.39 15.29 12.09

DNF +IU
9.67 4.89 9.69 18.73 13.69
20.31 12.05 22.10 36.74 27.51
10.58 6.52 11.12 18.32 14.98

DM
10.00 5.26 10.19 19.04 13.63
20.53 12.68 22.71 35.93 26.92
11.13 7.26 11.89 18.38 15.25

LogicE
DM +I
10.01 5.27 10.21 19.06 13.65
20.55 12.70 22.73 35.96 26.95
11.14 7.27 11.89 18.39 15.26

DNF +IU
10.46 5.42 10.61 20.01 14.37
21.89 13.14 24.17 39.33 29.38
13.07 8.31 14.01 22.04 18.39

NewLook

DNF DNF +IUd +IUD

9.11 4.80 9.14 17.17 12.43

9.13 4.81 9.15 17.20 12.45

19.80 11.96 21.58 35.28 26.57

19.87 11.99 21.66 35.44 26.66

9.88 6.04 10.35 17.10 14.15

9.90 6.04 10.36 17.13 14.16

benchmark. SpeciÔ¨Åcally, the BetaE is trained by the original implementation released by the authors 2 and evaluated in our framework. LogicE and NewLook are re-implemented, trained and tested by our framework. The NewLook implementation is adapted to Ô¨Åt into the generalization evaluation, see the Appendix I.
5.2 Benchmark Results
The benchmark result is shown in Table 6 for three models with Ô¨Åve supported normal forms in total on three KGs. Besides the Ô¨Åndings in Table 5, the average HIT@1 of NewLook is reported to be 37.0 in their paper [12] but is 10.1 on our EFO-1-QA. This can be caused by the hardness of our dataset and our implementation prevent the data leakage. We also group the 301 query types into 9 groups by their depth and width. The detailed results of FB15K-237 can be found in Table 7. For FB15K and NELL, the corresponding results are listed in the Table 15 and Table 16 in the Appendix L. Detailed analysis in the Appendix L justiÔ¨Åes the impact of query structures, for the Ô¨Årst time.
6 Analysis of the [e,p,i,u,n] System
As discussed in Section 3.1, a CQA model may model queries with multiple choices of operators, which are different in computing while equivalent in logic. We here focus on the canonical choice of [e,p,i,u,n] since this system is naturally derived by Skolemization, represents EFO-1 queries without any assumptions such as bounded negation. The best model LogicE in Table 6 is picked in this section.
6.1 Combinatorial Generalizability of Operators
Since the projection operator plays a pivotal role in query answering as shown in Appendix L, For projection, we train models by {1p}, {1p,2p}, and {1p,2p,3p} queries and evaluate on 1p,2p,3p,4p,5p3. The experiment result is shown in the Table 8. We can see that training on deeper query types beneÔ¨Åts the generalization power as the performances on unseen query types are improved. However, the performance on 1p decreases at the same time.
2https://github.com/snap-stanford/KGReasoning 31p,2p,and 3p are shown in Table 1, 4p and 5p are deÔ¨Åned similarly.
8

Table 7: Benchmark results(%) on FB15k-237. The mark ‚Ä† indicates the query groups that previous datasets have not fully covered. The boldface indicates the best scores. The best scores of the same model are underlined.

CQA Model BetaE
LogicE
NewLook

Normal Form
DM
DM +I
DNF +IU
DM
DM +I
DNF +IU
DNF +IUd
DNF +IUD

Metric
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle

(1,1)
18.79 10.63 20.37 36.19 14.38
18.79 10.63 20.37 36.19 14.38
18.79 10.63 20.37 36.19 14.38
20.71 11.66 23.02 39.81 15.64
20.71 11.66 23.02 39.81 15.64
20.71 11.66 23.02 39.81 15.64
22.31 13.55 24.62 40.53 17.66
22.31 13.55 24.62 40.53 17.66

Query type groups (# anchor nodes, max length of Projection chains)

(1,2) (1,3) (2,1) (2,2)‚Ä† (2,3)‚Ä† (3,1‚Ä†) (3,2)‚Ä†

9.72 4.63 9.61 19.80 14.40

9.64 4.68 9.44 19.38 16.99

12.76 7.07 13.47 24.27 14.09

8.48 4.13 8.37 16.82 12.07

8.10 3.89 8.02 16.03 13.04

11.34 5.99 11.99 21.99 12.51

8.58 4.42 8.66 16.41 10.86

9.72 4.63 9.61 19.80 14.40

9.64 4.68 9.44 19.38 16.99

12.76 7.07 13.47 24.27 14.09

8.48 4.13 8.37 16.82 12.07

8.10 3.89 8.02 16.03 13.04

11.39 6.05 12.01 22.01 12.58

8.59 4.43 8.68 16.43 10.88

9.72 4.63 9.61 19.80 14.40

9.64 4.68 9.44 19.38 16.99

14.39 7.78 15.11 28.04 16.87

9.28 4.48 9.12 18.55 13.58

8.86 4.20 8.74 17.67 14.69

13.14 6.83 13.86 25.82 15.39

9.76 4.93 9.79 18.90 12.93

10.70 5.20
10.66 21.25 15.27

10.18 5.25 9.96
19.48 17.28

15.66 8.81
16.72 29.66 17.49

10.01 5.00
10.07 19.66 13.97

9.41 4.83 9.43 18.12 14.75

13.71 7.38
14.57 26.33 15.62

10.12 5.27
10.33 19.38 12.99

10.70 5.20 10.66 21.25 15.27

10.18 5.25 9.96 19.48 17.28

15.66 8.81
16.72 29.66 17.49

10.01 5.00
10.07 19.66 13.97

9.41 4.83 9.43 18.12 14.75

13.76 7.41 14.67 26.41 15.64

10.14 5.28 10.35 19.42 13.01

10.70 5.20 10.66 21.25 15.27

10.18 5.25 9.96 19.48 17.28

15.86 8.69 16.85 30.62 17.94

10.27 5.06 10.31 20.26 14.46

9.67 4.87 9.66 18.70 15.31

14.06 7.36 14.90 27.48 15.99

10.56 5.41 10.71 20.39 13.64

11.19 5.62 11.40 22.18 16.32

10.39 5.18 10.38 20.47 17.79

16.02 9.42
17.31 29.10 17.53

9.46 4.85 9.44 18.20 13.00

9.29 4.85 9.19 17.58 14.66

11.54 6.17
12.03 22.21 12.40

8.62 4.47 8.62 16.34 10.85

11.19 5.62 11.40 22.18 16.32

10.39 5.18 10.38 20.47 17.79

16.02 9.42
17.31 29.10 17.53

9.46 4.85 9.44 18.20 13.00

9.29 4.85 9.19 17.58 14.66

11.59 6.19
12.06 22.33 12.43

8.65 4.48 8.65 16.41 10.88

(3,3)‚Ä†
8.09 4.16 8.11 15.43 11.48
8.12 4.19 8.14 15.47 11.52
9.32 4.72 9.28 17.95 13.83
9.54 5.06 9.67 18.04 13.61
9.56 5.07 9.69 18.06 13.63
10.06 5.27 10.16 19.06 14.48
8.95 4.74 8.93 16.76 12.91
8.96 4.74 8.94 16.78 12.92

AVG.
8.48 4.35 8.54 16.25 11.49
8.50 4.37 8.56 16.27 11.51
9.67 4.89 9.69 18.73 13.69
10.00 5.26
10.19 19.04 13.63
10.01 5.27 10.21 19.06 13.65
10.46 5.42
10.61 20.01 14.37
9.11 4.80 9.14 17.17 12.43
9.13 4.81 9.15 17.20 12.45

For the intersection, we train models by {1p,2i} and {1p,2i,3i}4 queries and evaluate on 2i,3i,4i queries.5 As shown in Table 9, adding 3i to training queries helps with the performance on 3i,4i while detriment performance on 2i.
Finding 2: More training query types do not necessarily lead to better performance. Adding more queries to train is not helpful to all query types, since it may beneÔ¨Åt some query types while impairing others. Our observation indicates the interaction mechanisms between query types is not clear. Thus, how to properly train the CQA models is still open.
Finding 3: More complex queries do not necessarily have to worse performance. We can see that the more complex p queries are, the worse performance they have. However, for i queries, more complex i/I has better performance. In the combinatorial space where those two operators are combined, we cannot even conclude more complex queries have worse performance. This might support our observation that negation queries are not signiÔ¨Åcantly harder since negation operator is assumed to be bounded by an intersection operator.
41p is also included in training to ensure the performance the projection. 52i and 3i are shown in Table 1, 4i is deÔ¨Åned as (i,(i,(i,(p,(e)),(p,(e))),(p,(e))),(p,(e))).
9

Table 8: Generalization performance of projection on FB15k-237 in MRR (%).

Training

1p 2p 3p 4p 5p

1p

19.36 4.98 3.95 3.17 2.93

1p,2p

19.22 9.01 7.98 7.22 7.15

1p,2p,3p 17.81 9.45 9.59 9.52 9.32

Table 9: Generalization performance of intersection on FB15k-237 in MRR (%).

Training
1p,2i 1p,2i,3i

multi-input I

2i

3i

4i

32.24 41.66 52.37 31.97 42.67 52.70

binary input i

2i

3i

4i

32.24 41.66 51.78 31.97 42.32 52.10

Table 10: Impact of normal forms of LogicE on FB15k-237. Each cell indicates the winning rate of the form by its row against the form by its column.

Outperform Rate %
Original DM DM+I DNF DNF+IU

Original
0.00 14.04 39.39 46.67 56.67

DM
85.96 0.00
58.67 87.77 79.69

DM+I
60.61 41.33
0.00 71.50 88.40

DNF
53.33 12.23 28.50
0.00 58.33

DNF+IU
43.33 20.31 11.60 41.67
0.00

6.2 Impact of the Normal Forms
To study the impact of different normal forms, except for the averaged results in Table6, we also compares every normal forms with LogicE [13] as our evaluation model and the results are shown in Table 10 and Table 14 in the Appendix K. ‚Ä¢ DM vs. DNF. Formulas with unions can be modeled in two different ways: (1) transformed into Disjunctive Normal Form (DNF) as showed in Appendix C, (2) with union converted to intersection and negation by the De Morgan‚Äôs law (DM). In Table 10, we Ô¨Ånd that DNF outperforms DM in about 90% cases, whether DM uses I or not. However, there are still some cases where DM can outperform DNF. ‚Ä¢ Original vs. DNF+IU. DNF+IU outperforms all other normal forms. Moreover, it is a universal form to support all circumstances, making itself the most favorable form. Interestingly, the original form, meanwhile, outperform the DNF, suggesting it has its own advantage in modeling. Finding 4: There is no rule of thumb for choosing the best normal form. When evaluated on BetaE dataset, one may observe that the DNF is always better than DM. However, in EFO-1-QA, our evaluation shows that there is no normal form that can outperform others in every query types. Thus, how to choose the normal form for speciÔ¨Åc query type to obtain the best inference-time performance is also an open problem.
7 Conclusion
In this paper, we present a framework to investigate the combinatorial generalizability of CQA models. With this framework, the EFO-1-QA benchmark dataset is constructed. Comparisons between existing dataset shows that EFO-1-QA data is more comprehensive, generally harder and fairer. The detailed analysis justiÔ¨Åes, for the Ô¨Årst time, the impact of the choices of different operators and normal forms. Notably, our evaluation leads four insightful Ô¨Åndings that refreshes the observations on previous datasets. Two Ô¨Åndings also leads to the open problems for training and inference the CQA models. We hope that our framework, dataset, and Ô¨Åndings can facilitate the related research towards combinatorial generalizable CQA models.
Acknowledgement
The authors of this paper were supported by the NSFC Fund (U20B2053) from the NSFC of China, the RIF (R6020-19 and R6021-20) and the GRF (16211520) from RGC of Hong Kong, the MHKJFS (MHP/001/19) from ITC of Hong Kong.
10

References
[1] Erik Arakelyan, Daniel Daza, Pasquale Minervini, and Michael Cochez. Complex query answering with neural link predictors. In ICLR. OpenReview.net, 2021.
[2] S√∂ren Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary G. Ives. Dbpedia: A nucleus for a web of open data. In ISWC/ASWC, volume 4825 of Lecture Notes in Computer Science, pages 722‚Äì735. Springer, 2007.
[3] Kurt D. Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In SIGMOD, pages 1247‚Äì1250, 2008.
[4] Antoine Bordes, Nicolas Usunier, Alberto Garc√≠a-Dur√°n, Jason Weston, and Oksana Yakhnenko. Translating embeddings for modeling multi-relational data. In NIPS, pages 2787‚Äì2795, 2013.
[5] Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr Settles, Estevam R. Hruschka Jr., and Tom M. Mitchell. Toward an architecture for never-ending language learning. In AAAI. AAAI Press, 2010.
[6] Nurendra Choudhary, Nikhil Rao, Sumeet Katariya, Karthik Subbian, and Chandan K. Reddy. Self-supervised hyperboloid representations from logical queries over knowledge graphs. In WWW, pages 1373‚Äì1384. ACM / IW3C2, 2021.
[7] Rajarshi Das, Shehzaad Dhuliawala, Manzil Zaheer, Luke Vilnis, Ishan Durugkar, Akshay Krishnamurthy, Alex Smola, and Andrew McCallum. Go for a walk and arrive at the answer: Reasoning over paths in knowledge bases using reinforcement learning. In ICLR (Poster). OpenReview.net, 2018.
[8] Brian A Davey and Hilary A Priestley. Introduction to Lattices and Order. Cambridge University Press, 2002.
[9] Lisa Ehrlinger and Wolfram W√∂√ü. Towards a deÔ¨Ånition of knowledge graphs. In SEMANTiCS (Posters, Demos, SuCCESS), volume 1695 of CEUR Workshop Proceedings. CEUR-WS.org, 2016.
[10] William L. Hamilton, Payal Bajaj, Marinka Zitnik, Dan Jurafsky, and Jure Leskovec. Embedding logical queries on knowledge graphs. In NeurIPS, pages 2030‚Äì2041, 2018.
[11] Bhushan Kotnis, Carolin Lawrence, and Mathias Niepert. Answering complex queries in knowledge graphs with bidirectional sequence encoders. In AAAI, pages 4968‚Äì4977. AAAI Press, 2021.
[12] Lihui Liu, Boxin Du, Heng Ji, ChengXiang Zhai, and Hanghang Tong. Neural-answering logical queries on knowledge graphs. In KDD, pages 1087‚Äì1097. ACM, 2021.
[13] Francois P. S. Luus, Prithviraj Sen, Pavan Kapanipathi, Ryan Riegel, Ndivhuwo Makondo, Thabang Lebese, and Alexander G. Gray. Logic embeddings for complex query answering. CoRR, abs/2103.00418, 2021.
[14] John McCarthy, Michael I Levin, Paul W Abrahams, Daniel J Edwards, and Timothy P Hart. LISP 1.5 Programmer‚Äôs Manual. MIT Press, 1965.
[15] Hongyu Ren, Weihua Hu, and Jure Leskovec. Query2box: Reasoning over knowledge graphs in vector space using box embeddings. In ICLR. OpenReview.net, 2020.
[16] Hongyu Ren and Jure Leskovec. Beta embeddings for multi-hop logical reasoning in knowledge graphs. In NeurIPS, 2020.
[17] Alan JA Robinson and Andrei Voronkov. Handbook of Automated Reasoning, volume 1. Elsevier, 2001.
[18] Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. Yago: a core of semantic knowledge. In WWW, pages 697‚Äì706. ACM, 2007.
11

[19] Haitian Sun, Andrew O. Arnold, Tania Bedrax-Weiss, Fernando Pereira, and William W. Cohen. Faithful embeddings for knowledge base queries. In NeurIPS, 2020.
[20] Kristina Toutanova and Danqi Chen. Observed versus latent features for knowledge base and text inference. In ACL Workshop on Continuous Vector Space Models and Their Compositionality, pages 57‚Äì66, 2015.
[21] Ivan I Vankov and Jeffrey S Bowers. Training neural networks to encode symbols enables combinatorial generalization. Philosophical Transactions of the Royal Society B, 375(1791):20190309, 2020.
12

Appendix
A The Formal DeÔ¨Ånition and Derivation of EFO-1 Query Family
A.1 First Order Queries, A Self-Contained Guide
The First-Order (FO) query is a very expressive family of logical queries given by the following deÔ¨Ånitions. The Ô¨Årst-order logic handles the set of variables V ars = {x1, ..., xn} and set of functions {f1, ..., fm}. We say f is a function of arity k ‚â• 0 if f has k inputs. Functions of arity 0 are called constants. Then we give the formal deÔ¨Ånition of terms. DeÔ¨Ånition 1 (T erms). The set of terms is deÔ¨Åned inductively as follows:
‚Ä¢ V ars ‚äÇ T erms. ‚Ä¢ If t1, ..., tk ‚àà T erms and f is a k-ary function, then f (t1, ..., tk) ‚àà T erms. ‚Ä¢ Nothing else in T erms.
In Ô¨Årst-order logic we also have the predicates {P1, ..., Pl}. The predicate P is of arity k when it takes k terms as the input. Each predicate indicates whether the speciÔ¨Åc type of relation exists amongst its inputs by returning True of False. We note that a predicate of arity 0 is a proposition of the propositional logic. Then we give the formal deÔ¨Ånition of the Ô¨Årst-order formula. DeÔ¨Ånition 2 (First-Order Formula). The set of Formulas can be deÔ¨Åned inductively as follows:
‚Ä¢ If t1, ..., tk ‚àà T erms and P is a k-ary predicate, then P (t1, ..., tk) ‚àà F ormulas. (Atomic formulas).
‚Ä¢ If œÜ ‚àà F ormulas and œà ‚àà F ormulas, then ‚Äì ¬¨œÜ ‚àà F ormulas, ‚Äì œÜ ‚àß œà ‚àà F ormulas, ‚Äì œÜ ‚à® œà ‚àà F ormulas,
where ‚àß, ‚à®, and ¬¨ are connectives. We note that in some deÔ¨Ånition, one may consider the logical implication connective =‚áí . However, our deÔ¨Ånition is complete since implication can be represented by ‚àß, ‚à®, and ¬¨.
‚Ä¢ If œÜ ‚àà F ormulas and x ‚àà V ars, then ‚Äì ‚àÉx.œÜ ‚àà F ormulas, ‚Äì ‚àÄx.œà ‚àà F ormulas,
where ‚àÄ and ‚àÉ are the universal and the existential quantiÔ¨Åers, respectively.
A Ô¨Årst order formula can be converted to various normal forms. The key idea of normal form is that the derived formula is logically equivalent to the original formula. In formally, the prenex normal form is to move all the quantiÔ¨Åers before in the front. Here we give the formal deÔ¨Ånition of the prenex normal form. DeÔ¨Ånition 3 (Prenex Normal Form). The prenex normal form of a formula is derived by executing the following six conversions until there is nothing to do.
‚Ä¢ Convert ¬¨(‚àÄx.œÜ) to ‚àÉx.(¬¨œÜ); ‚Ä¢ Convert ¬¨(‚àÉx.œÜ) to ‚àÄx.(¬¨œÜ); ‚Ä¢ Convert (‚àÄx.œÜ) ‚àß œà to ‚àÄx.(œÜ ‚àß œà);
13

‚Ä¢ Convert (‚àÄx.œÜ) ‚à® œà to ‚àÄx.(œÜ ‚à® œà); ‚Ä¢ Convert (‚àÉx.œÜ) ‚àß œà to ‚àÉx.(œÜ ‚àß œà); ‚Ä¢ Convert (‚àÉx.œÜ) ‚à® œà to ‚àÉx.(œÜ ‚à® œà);

where œÜ, œà ‚àà F ormula.

Then we can give rise to the formal deÔ¨Ånition of the Ô¨Årst-order query over the knowledge graph by considering the following Ô¨Årst-order formula in the prenex normal form form [17]:

F = y1, ..., ym.f (x1, ..., xn, y1, ..., ym; P, O),

(1)

where is either the existential quantiÔ¨Åer ‚àÉ or the universal quantiÔ¨Åer ‚àÄ, f is the Ô¨Årst-order formula with logical connectives (‚àß, ‚à®, ¬¨), predicates p ‚àà P , and constant object o ‚àà O. {x1, ..., xn} are n > 0 free logical variables and {y1, ...ym} are m quantiÔ¨Åed logical variables. In the knowledge graph, the predicate p ‚àà P is related to the speciÔ¨Åc relation r. p(a, b) is True if and only if the entity a, b has the relation r.
The answer set AF of F contains n-tuples of objects A = (a1, ..., an) ‚àà AF , such that, any instantiation of F by considering the assignment of free variables xi = ai, 1 ‚â§ i ‚â§ n is true if and only if (a1, ..., an) ‚àà AF .

A.2 EFO-1 Queries on KG
We consider a knowledge graph G = (E, R), where E is the set of entities and R is the set of relation triples. Then we formally list the conditions that narrow FO queries down to Existential First Order Query with the single free variable (EFO-1 queries). Our conditions follow what have been considered in [16, 13, 12, 10],6 including:
(1) only existential quantiÔ¨Åers = ‚àÉ, (2) predicates induced by relations: prel(ahead, atail) = True ‚áê‚áí (head, rel, tail) ‚àà R, and (3) single free logical variable in each query. (4) Exists a feasible topological ordering determined by predicate is O < y1 < ¬∑ ¬∑ ¬∑ < ym < x,
(p(a, b) ‚àà F gives a partial ordering of a < b), and we require that for ‚àÄyi, i = 1 . . . m, at least one of the followings is true:
‚Ä¢ ‚àÉp ‚àà P, ‚àÉt, 1 ‚â§ t < i, s.t. p(yt, yi) ‚àà F ‚Ä¢ ‚àÉp ‚àà P, o ‚àà O, s.t. p(o, yi) ‚àà F Similarly, at least one of the following must be true:
‚Ä¢ ‚àÉp ‚àà P, ‚àÉj, i < j ‚â§ m, s.t. p(yi, yj) ‚àà F ‚Ä¢ ‚àÉp ‚àà P, s.t. p(yi, x) ‚àà F
Based on (1), one can conduct Skolemization [17] by replacing all existentially quantiÔ¨Åed logical variables by corresponding Skolem functions. The intuition of Skolemization is to replacement of ‚àÉy by a concrete choice function computing y from all the arguments y depends on. The chosen function is also known as the Skolem function. SpeciÔ¨Åcally, in the context of knowledge graph a Skolem function is induced from the predicate p by producing all entities that satisfy p given the known entity. In this paper, we also use the term ‚Äúprojection‚Äù to indicate the Skolem function following [15, 16].
By (2), all Skolem functions are equivalent to the forward and backward relations in G. According to (3), there will be only one target node. Then by (4), guaranteed by the topological ordering and following requirements, we will obtain a tree of operators (OpsTree) , whose root represents the target variable and leaves are the known entities, i.e., anchor nodes. An example of EFO-1 query is shown in Figure 1.
Though some work [16] claimed to consider the ‚ÄúÔ¨Årst-order query‚Äù and represent them in the OpsTree, they actually considers the EFO-1 queries that formally derived in this paper. Our formal derivation of EFO-1 queries from the Ô¨Årst-order queries shows that there are still gaps towards the truely Ô¨Årst order queries. Thus, we still have a long way to achieve the logical completeness.
6This family is also called by Skolem set logic in [13].

14

B The LISP-like Grammar for EFO-1 Query Types

Here we present the LISP-like grammar for the EFO-1 query types. The string generated by our grammar is called an EFO-1 formula. Each EFO-1 formula is a set of nested arguments segmented by parentheses. The Ô¨Årst argument indicates the speciÔ¨Åc operator and the other arguments (if any) are the operands of the speciÔ¨Åc operator. Our grammar is context free and the preliminary version considers the [e,p,i,u,n] operators.

Grammar 1: EFO-1

Formula

:= Intersection|Union|Projection|Negation

Intersection := (i,Formula,Formula)

Union

:= (u,Formula,Formula)

Negation

:= (n,Formula)

Projection := (p,Formula|Entity)

Entity

:= (e)

where | is the pipe symbol to indicate multiple available replacement.
In our implementation, we follow the assumption of bounded negation, where the Negation only appears in one of the operands of intersection. Then, the grammar is modiÔ¨Åed into

Grammar 2: EFO-1 Formula Intersection Union Negation Projection Entity

with the bounded negation := Intersection|Union|Projection := (i,Formula,Formula|Negation) := (u,Formula,Formula) := (n,Formula) := (p,Formula|Entity) := (e)

Moreover, the LISP-like grammar is Ô¨Çexible enough and can be extended by other operators. For example, the following grammar supports multiIUD and bounded negation.

Grammar 3: Extended EFO-1 with the bounded negation

Formula

:= Intersection|Union|Projection|Difference

|Multi-Intersection|Multi-Union|Multi-Difference

Difference Intersection Union Negation Projection Entity

:= (d,Formula,Formula) := (i,Formula,Formula) := (u,Formula,Formula) := (n,Formula) := (p,Formula|Entity) := (e)

Multi-Intersection := (I,Multi-I-Operands)

Multi-Union

:= (U,Multi-U-Operands)

Multi-Difference := (D,Multi-D-Operands)

Multi-I-Operands := (Formula|Negation),Multi-I-Operands

|(Formula|Negation),Formula

Multi-U-Operands := Formula,Multi-U-Operands

|Formula,Formula

Multi-D-Operands := Formula,Multi-D-Operands

|Formula,Formula

Based on the formal description above, we are able to discuss the combinatorial space of EFO-1 queries as well as various normal forms with different choice of operators.

15

Table 11: The operators that are considered in the grammar of EFO-1 formula.

Operator e p
i u n
d I U D

Input Entity id ei Entity set S and projection function P roj Entity sets S1 and S2 Entity sets S1 and S2 Entity set S
Entity sets S1 and S2 Entity sets S1, S2, ..., Sn Entity sets S1, S2, ..., Sn Entity sets S1, S2, ..., Sn

Output Set S = {ei} Set T = {P roj(e) : e ‚àà S}
Set T = S1 ‚à© S2 Set T = S1 ‚à™ S2 Set T = S¬Ø
Set T = S1 ‚àí S2 Set T = ‚à©nk=1Sk Set T = ‚à™nk=1Sk Set T = S1 ‚àí S2 ‚àí ¬∑ ¬∑ ¬∑ ‚àí Sn

Explanation
Create a singleton set from one entity Project a set of entities to another set of entities Take the intersection of two sets Take the union of two sets Take the complement of one set against all entities Take the set difference of S1 and S2 Take the intersection of n sets. n > 2 Take the union of n sets. n > 2 Take the difference of multiple sets

B.1 JustiÔ¨Åcation of Operators
Here we present the precise deÔ¨Ånitions of the operators that are considered in our grammars in the Table 11. The operators can be directly used in the sampling process in Section 3.3. The operator e is also known as the anchor node in this paper.
B.2 Generate EFO-1 Formulas
We employ the depth-Ô¨Årst search based algorithm to iterate through the Grammar 2. The generated formula can be considered as a binary tree. The generation process terminates when the number of Projection p and Negation n reaches the threshold. The termination threshold is not consistent to the grouping criteria in the Table 2 which only considers the Projection operator. For the generation, we consider the negation additionally in order to avoid the endless generation of negations.
C Transformation to Disjunctive Normal Form

Transforming the EFO-1 queries to DNF is more complicated than EPFO queries considered in [15], even with the straight forward [e,p,i,u,n] operators. Notably, the order of some operators must not be changed for EFO-1 queries, such as i & p7 or n & p8. Here we list the procedures to transform general EFO-1 queries with [e,p,i,u,n] to a DNF.
1. De Morgan‚Äôs Law If the operand of a negation operator is intersection or union, switch the positions of negation and intersection/union with De Morgan‚Äôs law.
2. Negation cancellation If the operand of a negation operator is another negation, remove those two negation operators.
3. p-u switch If the operand of a projection operator is an union, switch the position of union and projection. The projection operator should be duplicated while switching.
4. i-u switch If one of the operands of an intersection operator is an union, We apply A‚à©(B ‚à™C) = (A ‚à© B) ‚à™ (A ‚à™ C) to switch the union operator and the intersection operator.
7f (A ‚à© B) ‚äÇ f (A) ‚à© f (B), where f is the projection function and A and B are sets. 8f (A) ‚äÇ f (A) where f is the projection function, ¬∑ is the negation operator and A is a set.
16

The Ô¨Årst two procedures make the negation operator lower than union and intersection operator and the last two procedures make the union higher than the intersection operator. We follow those 4 procedures until no more changes happens. In this way, we get a DNF of the original formula. Since some operators cannot be switched, the DNF of EFO-1 query types may not ensure all intersection operators right below the unions. But for the DNF of Ô¨Årst order logical formulas, all conjunctions are right below the disjunctions, see Example 1. We note that this type of queries has not been discussed so far in the current literature.
Example 1. Considering the DNF of EFO-1 queries

f1(f2(A) ‚à© f3(B)) ‚à™ f4(C)

(2)

where fi is the projection functions and ABC are sets. The query type can be presented by (u,(p,(i,(p,(e)),(p,(e)))),(p,(e)). We note that This EFO-1 query can be re-written as the Ô¨Årst order formula with the single free variable Œ± and the existential quantiÔ¨Åed variable Œ≤.

?Œ±‚àÉŒ≤[p1(Œ≤, Œ±) ‚àß p2(A, Œ≤) ‚àß p3(B, Œ≤)] ‚à® p4(C, Œ±),

(3)

where pi are the corresponding predicates from projection function fi, i = 1, ..., 5. Though the EFO-1 query has intersection as the input of f1, we still call this query a DNF.

We note that the DNF transformation will exponentially increase the complexity of the queries because of the step 4 [16].

D Example of Different Normal Forms
An example is also presented to show the difference of different normal forms in the Table 12. We note that the example contains 5 anchor nodes to reveal all the features though in EFO-1-QA dataset, sampled data only contains no more than 3 anchor nodes.

17

Table 12: An example for different normal forms, operator systems and an example.

Normal Forms Original DM DM+I DNF Original + d DNF + d
DNF + IU
DNF+IUd
DNF+IUD

Operator System [e,p,i,u,n] [e,p,i,n] [e,p,I,n] [e,p,i,u,n] [e,p,i,u,d] [e,p,i,u,d]
[e,p,I,U,n]
[e,p,I,U,d]
[e,p,I,U,D]

EFO-1 Formula Example (indented for clearance)
(i,(i,(n,(p,(e))), (p,(i,(n,(p,(e))), (p,(e))))),
(u,(p,(e)), (p,(p,(e)))))
(i,(i,(n,(p,(e))), (p,(i,(n,(p,(e))), (p,(e))))),
(n,(i,(n,(p,(e))), (n,(p,(p,(e)))))))
(I,(n,(p,(e))), (p,(i,(n,(p,(e))), (p,(e)))), (n,(i,(n,(p,(e))), (n,(p,(p,(e)))))))
(u,(i,(i,(i,(n,(p,(p,(e)))), (p,(p,(e)))),
(n,(p,(e)))), (p,(e))), (i,(i,(i,(n,(p,(p,(e)))),
(p,(p,(e)))), (n,(p,(e)))), (p,(p,(e))))) (i,(d,(p,(d,(p,(e)),
(p,(e)))), (p,(e))), (u,(p,(e)), (p,(p,(e))))) (u,(i,(d,(d,(p,(p,(e))),
(p,(p,(e)))), (p,(e))), (p,(e))), (i,(d,(d,(p,(p,(e))),
(p,(p,(e)))), (p,(e))), (p,(p,(e))))) (U,(I,(n,(p,(e))), (n,(p,(p,(e)))), (p,(e)), (p,(p,(e)))), (I,(n,(p,(e))), (n,(p,(p,(e)))), (p,(p,(e))), (p,(p,(e))))) (U,(d,(d,(I,(p,(e)),
(p,(p,(e)))), (p,(e))) (p,(p,(e)))), (d,(d,(I,(p,(p,(e))),
(p,(p,(e)))), (p,(e))) (p,(p,(e))))) (U,(D,(I,(p,(e)), (p,(p,(e)))), (p,(e)), (p,(p,(e)))), (D,(I,(p,(p,(e))), (p,(p,(e)))), (p,(e)), (p,(p,(e)))))

E JSON Serialization of Grounded Queries
Compared to LISP-like description of the query types, the serialization of the grounded queries should also keep the grounded relations and entities. We employ the JSON format to store the query structure and the instantiation. For each query, we maintain two key value pairs. The Ô¨Årst key is o, which indicates the operator and has the string object from e,p,i,u,n,d,I,U,D. The second key is a, which indicates the arguments as a list object. For the grounded projection operator, the Ô¨Årst argument is the corresponding relation id and the second argument is another JSON string of its input. For the grounded entity operator, the only argument is the corresponding entity id. For other logical or set operators, their arguments are the strings for the inputs in the JSON format.
18

F Grounding Query Types with Meaningful Negation
When grounding the query types, we can barely require the query to be valid: for example, a query like ‚ÄôFind one that has won the Oscar but not the Turing award.‚Äô is valid while the ‚Äôbut not the Turing award‚Äô part is meaningless since there‚Äôs actually no one who wins both the Oscar and the Turing award. Therefore, a better alternative should be ‚ÄôFind one who wins the Oscar but not the Golden Globe.‚Äô in consideration of this reason. With the bounded negation assumption, and for the sake of simplicity, we may only consider the case of (i, (subquery1), (n, subquery2)) to illustrate our sampling method: we need to Ô¨Ånish the sampling in the subqeuery1 Ô¨Årst, then we randomly select an entity in the answer set of subquery1 and require the subquery2 to exclude it if possible. This sampling method creates more realistic grounded queries and those grounded queries are apparently harder in our experiments since those negation queries must be understood by the model to get the correct answer set.
G Dataset Format
We organize our dataset conceptually into two tables. The Ô¨Årst table stores the information about query types, the columns of which include different normal forms of the formula in LISP-language, the formula ID, and other statistics. The second table is to store the information of the grounded queries with columns for easy and hard answer set, JSON string for different normal forms and the formula ID that indicating the query type. Those two tables can be joined by the formula ID. In our practice, we split the second table by the formula ID and store each sub-table in a Ô¨Åle named by the formula ID. The data sample is also provided with the supplementary materials.
H The Choice of Normal Forms
Here we explain the reasons why we choose those normal forms and in Table 3. The key difference is the way we model the union operator: DM form replace union with intersection and negation while DNF form requires union operator only appear at the root of the OpsTree, which create two basic types of forms. The original form is also kept for the purpose of comparison. Then we face the choice of IU/iu and the choice of d/D/n, which can make six combinations in total. In DNF forms, the combination [e,p,i,u,D] are Ô¨Åltered out for it lacks practical meaning. More importantly, it is either the same as [e,p,I,U,D] or the same as [e,p,i,u,d] when the number of anchor node is restricted to be no more than three. In DM forms, the difference is not allowed as it violates the hypothesis of bounded negation. The choice of I/i offers us two variants: DM and DM+I. In original forms, we only offer the choice of d/n to avoid complex transformation and keep the queries as ‚Äòoriginal‚Äô as possible. In total: Ô¨Åve DNF forms, two DM forms, and two original forms makes nine forms we listed in Table 3.
I Implementation Details of NewLook
Some details of NewLook is not fully covered in the original paper [12] while the released version9 is not suitable to justify the combinatorial generalizability. Here we list several details of our implementation of NewLook. Group Division In the released version, the connectivity tensor œÑ is generated by entire graph.
Accessing the entire graph contradicts the Open Word Assumption. In our reproduction, we
9https://github.com/lihuiliullh/NewLook
19

Table 13: Review of existing CQA models, where * means the DNF is required and ‚Ä† means the bounded negation must be assumed. For EmQL, the difference operator is claimed to be available, however, it does not indicate how to train this operator as intersection and union.

CQA Model

Support Operators

Support Support

e p i I u U n d D EPFO EFO-1

GQE [10]

         *



Q2B [15]

         *



EmQL [19]

 



‚Ä†

BiQE [11]

         *



HypE [6]

         *



BetaE [16]

         *

*

CQD [1]

    



LogicE [13]          *

*

NewLook [12]          *

*‚Ä†

Table 14: Number of different query types of [e,p,i,u,n] system.

Original DM DM+I DNF DNF+IU

Original

0 57 132 15

90

DM

57 0

75 148

256

DM+I

132 75

0 223

181

DNF

15 148 223

0

84

DNF+IU

90 256 181 84

0

only use the training edges to avoid leaking the information of unseen edges and the number of group is set to 200. Intersection The origin mathematical formulas have been proven to be impractical since zi will be inÔ¨Ånity when xui = xut , and we Ô¨Åx this problem by adding a small value = 0.01 in the denominator. Difference The update method of x has not been shown, so we implement this by intuition: (xut )j = 1 ‚áê‚áí (xu1 )j = 1, (xui )j = 0, ‚àÄi = 2, . . . , k. Loss function The value of hyper-parameter Œª is not provided, so we set it to 0.02. MLP The hyperparameter of MLP is not given, so we let all MLP be a two-layer network with hidden dimension as 1,600 and ReLU activation.
J Short Review of Existing CQA Models
We compared the details of different CQA models in Table 13. We can see that most of the CQA models support the EPFO queries but only three CQA models support EFO-1 query.
K The Normal Forms in [e,p,i,u,n] System
To justify the impact of normal forms, we select the query types that has different EFO-1 formula representation when two normal forms are Ô¨Åxed. The number of the query types that are picked given two normal forms are shown in the Table 14.
L Additional Experimental Results

Here we list detailed experiment results and add some discussions on them. Due to the large number of the query types, we group and report the queries by the maximum projection length and number of anchor nodes in Table 7, ??, and ??. These three tables are the results on FB15k-237, FB15k, NELL, correspondingly .
20

Our analysis mainly focus on FB15k-237 shown in Table7, but FB15k and NELL also shows similar phenomena. Impact of the Max Projection Length. It shows a clear descending trend of performance as the query depth increases in all models. NewLook [12] call this phenomenon ‚Äúcascading error‚Äù as error propagates in each projection operation. In fact, projection plays a pivotal role in all CQA models. For example, CQD [1] only trains queries of type (p,(e)) and uses logical t-norms to represent union and intersection. Beta [16] doubles training steps for query types only containing projection. Moreover, the operator of anchor entity is always projection: as queries like (u,(e),(e)) or (i,(e),(e)) are not allowed, which makes projection be indispensable. For all reasons above, we believe the modeling of projection operation is the fundamental factor to Ô¨Ånal results. Impact of the Number of Anchor Nodes. A query type with more anchor nodes is not necessarily harder. For example, in depth 2 and 3, queries with 3 anchor nodes have higher scores than those with 2 anchor nodes. This is partially because of the feature of the intersection: we Ô¨Ånd that (I,(p,(e)),(p,(e)),(p,(e))) has much higher score than (I,(p,(e)),(p,(e))), and all of the three models also report similar results in their own experiments. On the contrary, (U,(p,(e)),(p,(e)),(p,(e))) is harder than (U,(p,(e)),(p,(e))) , and other queries with U show similar results. This different behaviour is reasonable, as intersection shrinks answer size while union enlarges it. The averaged answer size of each group is listed in Table17. The Choice of Operators. The NewLook model [12] uses difference to replace negation in its query representation, which leads to the fact that DNF+IUd and DNF+IUD are the only two forms that NewLook can fully support. In Table 7, since all possible query types with one anchor node are 1p,2p,3p, the leading performance of NewLook on those queries illustrates that NewLook model projection operation better. However, in more complex query types, LogicE outperforms NewLook, indicating that difference operator D/d might not be a better alternative to negation operator n. Additionally, the multi operator D performs slightly better than the binary d. In additional, we also report the detailed performances of EPFO and Negation queries on each knowledge graph as categorized by Beta [16], see Table 16-21. We can see from the results that our benchmark is generally harder and fairer than existing datasets [16].
21

Table 15: Benchmark results(%) on FB15k. The mark ‚Ä† indicates the query groups that previous datasets have not fully covered. The boldface indicates the best scores. The best scores of the same model are underlined.

CQA Model BetaE
LogicE
NewLook

Normal Form
DM
DM +I
DNF +IU
DM
DM +I
DNF +IU
DNF +IUd
DNF +IUD

Metric
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle

(1,1)
51.86 39.09 59.20 76.20 47.46
51.86 39.09 59.20 76.20 47.46
51.86 39.09 59.20 76.20 47.46
61.56 49.63 69.51 82.40 58.57
61.56 49.63 69.51 82.40 58.57
61.56 49.63 69.51 82.40 58.57
58.82 46.87 66.32 80.51 55.31
58.82 46.87 66.32 80.51 55.31

Query type groups (# anchor nodes, max length of Projection chains)

(1,2) (1,3) (2,1) (2,2)‚Ä† (2,3)‚Ä† (3,1‚Ä†) (3,2)‚Ä†

25.48 17.06 27.40 42.36 33.05

23.55 15.63 25.60 38.82 32.94

30.24 19.75 35.09 50.50 33.02

19.14 11.44 21.01 34.32 24.65

17.46 10.76 18.79 30.53 24.36

26.69 16.66 31.13 46.44 29.03

17.73 10.67 19.45 31.65 21.55

25.48 17.06 27.40 42.36 33.05

23.55 15.63 25.60 38.82 32.94

30.24 19.75 35.09 50.50 33.02

19.14 11.44 21.01 34.32 24.65

17.46 10.76 18.79 30.53 24.36

26.78 16.77 31.20 46.51 29.14

17.78 10.71 19.51 31.70 21.59

25.48 17.06 27.40 42.36 33.05

23.55 15.63 25.60 38.82 32.94

38.81 25.37 45.48 65.55 44.67

21.24 12.50 23.30 38.67 28.46

19.47 11.78 20.89 34.65 28.37

33.96 20.88 39.69 60.68 39.64

20.92 12.25 22.89 38.33 27.08

29.76 20.51 32.56 47.94 37.90

25.41 17.24 27.71 41.17 35.18

38.00 25.16 44.89 62.15 43.69

22.89 14.05 25.56 40.27 29.73

20.22 12.80 21.99 34.76 28.38

32.90 20.48 39.10 56.90 37.87

21.31 12.92 23.74 37.89 26.84

29.76 20.51 32.56 47.94 37.90

25.41 17.24 27.71 41.17 35.18

38.00 25.16 44.89 62.15 43.69

22.89 14.05 25.56 40.27 29.73

20.22 12.80 21.99 34.76 28.38

32.98 20.56 39.19 56.98 37.96

21.33 12.95 23.77 37.91 26.88

29.76 20.51 32.56 47.94 37.90

25.41 17.24 27.71 41.17 35.18

40.83 26.88 48.51 67.44 47.36

23.91 14.40 26.74 42.82 31.56

21.22 13.15 23.10 37.19 30.37

34.92 21.16 41.63 62.16 40.79

22.66 13.34 25.20 41.37 29.16

30.93 22.02 33.76 48.54 39.14

26.12 17.88 28.59 42.01 36.06

40.49 28.02 46.29 65.33 45.99

22.07 13.55 24.24 38.99 29.05

20.69 13.09 22.37 35.60 29.39

30.15 17.64 35.06 55.62 35.25

19.22 11.16 20.97 35.23 24.82

30.93 22.02 33.76 48.54 39.14

26.12 17.88 28.59 42.01 36.06

40.49 28.02 46.29 65.33 45.99

22.07 13.55 24.24 38.99 29.05

20.69 13.09 22.37 35.60 29.39

30.42 17.73 35.48 56.27 35.54

19.35 11.21 21.14 35.56 24.99

(3,3)‚Ä†
15.54 9.43 16.74 27.42 20.63
15.60 9.48 16.81 27.48 20.69
18.45 10.87 19.76 33.44 26.26
18.47 11.39 20.12 32.39 25.31
18.49 11.40 20.14 32.41 25.33
19.85 11.86 21.54 35.75 27.91
18.48 11.22 19.92 32.70 25.88
18.51 11.23 19.94 32.76 25.92

AVG.
17.18 10.46 18.76 30.30 21.83
17.22 10.51 18.81 30.35 21.89
20.31 12.05 22.10 36.74 27.51
20.53 12.68 22.71 35.93 26.92
20.55 12.70 22.73 35.96 26.95
21.89 13.14 24.17 39.33 29.38
19.80 11.96 21.58 35.28 26.57
19.87 11.99 21.66 35.44 26.66

22

Table 16: Benchmark results(%) on NELL. The mark ‚Ä† indicates the query groups that previous datasets have not fully covered. The boldface indicates the best scores. The best scores of the same model are underlined.

CQA Model BetaE
LogicE
NewLook

Normal Form
DM
DM +I
DNF +IU
DM
DM +I
DNF +IU
DNF +IUd
DNF +IUD

Metric
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle

(1,1)
28.75 20.41 31.79 45.28 24.59
28.75 20.41 31.79 45.28 24.59
28.75 20.41 31.79 45.28 24.59
35.23 25.74 40.27 53.28 30.69
35.23 25.74 40.27 53.28 30.69
35.23 25.74 40.27 53.28 30.69
33.59 24.78 37.19 51.89 29.50
33.59 24.78 37.19 51.89 29.50

Query type groups (# anchor nodes, max length of Projection chains)

(1,2) (1,3) (2,1) (2,2)‚Ä† (2,3)‚Ä† (3,1‚Ä†) (3,2)‚Ä†

10.01 5.87
10.53 17.71 14.63

9.96 6.15 10.28 17.16 15.42

13.06 8.25
14.29 22.41 14.27

8.95 5.35 9.38 15.90 12.71

8.85 5.47 9.22 15.25 12.87

8.94 5.23 9.47 16.07 10.98

8.71 5.39 9.11 14.98 11.63

10.01 5.87
10.53 17.71 14.63

9.96 6.15 10.28 17.16 15.42

13.06 8.25
14.29 22.41 14.27

8.95 5.35 9.38 15.90 12.71

8.85 5.47 9.22 15.25 12.87

8.97 5.25 9.53 16.10 11.00

8.73 5.40 9.12 15.01 11.65

10.01 5.87 10.53 17.71 14.63

9.96 6.15 10.28 17.16 15.42

14.84 9.22 16.21 25.84 17.47

10.06 5.96 10.51 18.02 14.69

10.02 6.13 10.46 17.45 14.89

10.55 5.99 11.27 19.34 13.78

10.27 6.25 10.76 17.90 14.39

13.53 8.62 14.28 23.05 19.62

13.75 8.92
14.73 22.80 20.32

16.16 10.32 17.85 27.52 18.94

11.40 7.20 12.16 19.24 16.33

11.35 7.52 12.02 18.52 16.16

11.06 6.44 11.97 19.97 14.41

10.75 6.82 11.45 18.09 14.77

13.53 8.62 14.28 23.05 19.62

13.75 8.92
14.73 22.80 20.32

16.16 10.32 17.85 27.52 18.94

11.40 7.20 12.16 19.24 16.33

11.35 7.52 12.02 18.52 16.16

11.07 6.49 11.95 19.96 14.40

10.75 6.84 11.44 18.10 14.77

13.53 8.62 14.28 23.05 19.62

13.75 8.92 14.73 22.80 20.32

18.19 11.45 20.13 31.35 22.08

12.94 8.05 13.90 22.15 18.84

13.00 8.42 13.86 21.61 18.87

12.40 6.98 13.41 23.01 16.62

12.48 7.71 13.33 21.49 17.55

12.06 7.12 12.73 21.72 18.03

11.42 6.79 12.00 20.31 17.76

16.55 10.59 18.00 28.47 19.27

10.30 6.22 10.82 17.98 15.07

10.52 6.47 10.99 18.12 15.85

9.50 5.33 10.00 17.63 12.21

8.91 5.28 9.31 15.70 12.50

12.06 7.12 12.73 21.72 18.03

11.42 6.79 12.00 20.31 17.76

16.55 10.59 18.00 28.47 19.27

10.30 6.22 10.82 17.98 15.07

10.52 6.47 10.99 18.12 15.85

9.53 5.34 10.05 17.68 12.24

8.94 5.29 9.34 15.75 12.53

(3,3)‚Ä†
8.85 5.60 9.31 15.00 12.16
8.86 5.60 9.31 15.03 12.16
10.64 6.63 11.19 18.27 15.30
11.05 7.36 11.79 17.94 15.23
11.06 7.37 11.80 17.95 15.23
13.22 8.57 14.16 21.94 18.75
10.08 6.25 10.53 17.24 14.76
10.09 6.26 10.54 17.25 14.76

AVG.
8.93 5.58 9.38 15.27 12.08
8.94 5.59 9.39 15.29 12.09
10.58 6.52
11.12 18.32 14.98
11.13 7.26 11.89 18.38 15.25
11.14 7.27 11.89 18.39 15.26
13.07 8.31
14.01 22.04 18.39
9.88 6.04 10.35 17.10 14.15
9.90 6.04 10.36 17.13 14.16

Table 17: Average number of answers of queries.

Knowledge Graph
FB15k-237 FB15k NELL

Query type groups (# anchor nodes, max length of Projection chains)
(1,1) (1,2) (1,3) (2,1) (2,2) (2,3) (3,1) (3,2) (3,3)
3.22 17.56 23.44 12.37 18.49 22.61 13.16 17.60 21.22 4.09 20.07 24.26 15.34 20.42 24.02 15.38 19.37 23.02 3.13 20.54 22.23 16.66 22.08 22.87 19.22 21.18 22.84

23

CQA Model BetaE
LogicE NewLook

Table 18: Benchmark results(%) on EPFO queries of FB15k-237.

Normal Form
DM
DM +I
DNF +IU
DM
DM +I
DNF +IU
DNF +IUD

Metric
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle

(1,1)
18.79 10.63 20.37 36.19 14.38
18.79 10.63 20.37 36.19 14.38
18.79 10.63 20.37 36.19 14.38
20.71 11.66 23.02 39.81 15.64
20.71 11.66 23.02 39.81 15.64
20.71 11.66 23.02 39.81 15.64
22.31 13.55 24.62 40.53 17.66

(# anchor nodes, max length of projection chains)

(1,2) (1,3) (2,1) (2,2) (2,3) (3,1) (3,2)

9.72 4.63 9.61 19.80 14.40

9.64 4.68 9.44 19.38 16.99

15.51 9.53 16.97 27.44 16.00

10.00 5.39
10.35 18.96 13.47

8.78 4.44 8.88 16.96 13.66

15.05 9.71
16.52 25.45 15.11

11.09 6.60
11.67 19.72 12.99

9.72 4.63 9.61 19.80 14.40

9.64 4.68 9.44 19.38 16.99

15.51 9.53 16.97 27.44 16.00

10.00 5.39
10.35 18.96 13.47

8.78 4.44 8.88 16.96 13.66

15.19 9.92
16.58 25.52 15.32

11.12 6.62
11.72 19.77 13.03

9.72 4.63 9.61 19.80 14.40

9.64 4.68 9.44 19.38 16.99

17.97 10.59 19.43 33.10 20.17

11.35 5.96
11.59 21.84 15.98

9.77 4.85 9.82 19.08 15.81

19.11 11.85 20.86 33.62 21.34

13.41 7.72
14.01 24.46 16.90

10.70 5.20 10.66 21.25 15.27

10.18 5.25 9.96 19.48 17.28

19.49 12.07 21.36 34.59 21.13

12.16 6.68
12.62 22.86 16.49

10.35 5.56
10.55 19.51 15.82

19.07 12.38 20.65 32.51 20.77

13.50 8.03
14.32 24.13 16.62

10.70 5.20 10.66 21.25 15.27

10.18 5.25 9.96 19.48 17.28

19.49 12.07 21.36 34.59 21.13

12.16 6.68
12.62 22.86 16.49

10.35 5.56
10.55 19.51 15.82

19.13 12.42 20.81 32.62 20.79

13.52 8.04
14.34 24.16 16.66

10.70 5.20 10.66 21.25 15.27

10.18 5.25 9.96 19.48 17.28

19.79 11.90 21.56 36.03 21.81

12.59 6.79 13.03 23.85 17.31

10.68 5.62
10.86 20.27 16.55

20.21 12.67 21.97 35.48 22.04

14.50 8.44
15.31 26.30 18.08

11.19 5.62 11.40 22.18 16.32

10.39 5.18 10.38 20.47 17.79

21.66 13.74 23.85 37.48 24.11

12.76 7.09 13.22 23.66 17.73

10.77 5.85 10.83 20.04 16.85

21.76 14.24 23.66 36.82 24.15

14.74 8.88 15.49 26.06 18.63

(3,3)
9.33 5.16 9.58 17.23 12.57
9.37 5.20 9.64 17.29 12.63
11.05 5.99
11.29 20.70 15.79
11.16 6.34
11.55 20.43 15.37
11.17 6.34
11.58 20.45 15.39
11.95 6.68
12.34 21.99 16.64
11.95 6.84
12.27 21.66 16.92

AVG.
9.98 5.63 10.35 18.30 12.93
10.02 5.66 10.40 18.35 12.98
11.81 6.50
12.17 22.01 16.23
12.00 6.91
12.53 21.86 15.94
12.02 6.91
12.56 21.89 15.95
12.78 7.22
13.31 23.48 17.16
12.92 7.52 13.40 23.28 17.59

24

Table 19: Benchmark results(%) on queries with negation of FB15k-237.

CQA Model BetaE
LogicE
NewLook

Normal Form
DM
DM +I
DNF +IU
DM +I
DM+I
DNF +IU
DNF +IUd
DNF +IUD

Metric
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle

(# anchor nodes, max length of projection chains)

(2,1) (2,2) (2,3) (3,1) (3,2) (3,3)

7.24 2.15 6.47 17.92 10.26

6.19 2.25 5.41 13.61 9.99

5.84 2.03 5.14 12.96 10.95

9.49 4.14 9.72 20.26 11.21

7.22 3.24 7.02 14.61 9.70

6.47 2.85 6.17 13.07 10.04

7.24 2.15 6.47 17.92 10.26

6.19 2.25 5.41 13.61 9.99

5.84 2.03 5.14 12.96 10.95

9.48 4.12 9.73 20.26 11.20

7.22 3.24 7.03 14.62 9.71

6.47 2.85 6.17 13.08 10.05

7.24 2.15 6.47 17.92 10.26

6.19 2.25 5.41 13.61 9.99

5.84 2.03 5.14 12.96 10.95

10.16 4.32 10.36 21.92 12.41

7.78 3.42 7.50 15.88 10.78

7.04 3.04 6.64 14.32 11.25

8.01 2.28 7.44 19.80 10.21

6.80 2.48 6.23 14.87 10.18

6.28 2.39 5.67 13.48 11.19

11.03 4.88
11.54 23.24 13.04

8.29 3.77 8.17 16.81 11.02

7.42 3.38 7.19 14.89 11.30

8.01 2.28 7.44 19.80 10.21

6.80 2.48 6.23 14.87 10.18

6.28 2.39 5.67 13.48 11.19

11.07 4.90 11.59 23.31 13.06

8.31 3.79 8.19 16.85 11.04

7.44 3.39 7.22 14.92 11.32

8.01 2.28 7.44 19.80 10.21

6.80 2.48 6.23 14.87 10.18

6.28 2.39 5.67 13.48 11.19

10.99 4.70
11.37 23.48 12.96

8.42 3.77 8.22 17.18 11.23

7.58 3.41 7.30 15.20 11.63

4.73 0.80 4.25 12.34 4.37

4.50 1.48 3.77 10.01 5.90

4.38 6.43 5.30 5.00 1.50 2.14 2.08 1.97 3.71 6.21 4.90 4.54 9.35 14.91 11.06 10.32 7.36 6.52 6.63 7.65

4.73 0.80 4.25 12.34 4.37

4.50 1.48 3.77 10.01 5.90

4.38 6.50 5.35 5.02 1.50 2.16 2.10 1.97 3.71 6.26 4.95 4.56 9.35 15.08 11.18 10.35 7.36 6.57 6.67 7.67

AVG.
6.92 3.04 6.66 14.12 9.99
6.92 3.04 6.67 14.12 9.99
7.46 3.21 7.12 15.33 11.08
7.93 3.57 7.76 16.11 11.24
7.94 3.58 7.79 16.14 11.26
8.05 3.57 7.82 16.42 11.49
5.17 1.99 4.74 10.85 7.10
5.20 2.00 4.76 10.92 7.14

25

CQA Model BetaE
LogicE NewLook

Table 20: Benchmark results(%) on EPFO queries of FB15k.

Normal Form
DM
DM +I
DNF +IU
DM
DM +I
DNF +IU
DNF +IUD

Metric
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle

(1,1)
51.86 39.09 59.20 76.20 47.46
51.86 39.09 59.20 76.20 47.46
51.86 39.09 59.20 76.20 47.46
61.56 49.63 69.51 82.40 58.57
61.56 49.63 69.51 82.40 58.57
61.56 49.63 69.51 82.40 58.57
58.82 46.87 66.32 80.51 55.31

(# anchor nodes, max length of projection chains)

(1,2) (1,3) (2,1) (2,2) (2,3) (3,1) (3,2)

25.48 17.06 27.40 42.36 33.05

23.55 15.63 25.60 38.82 32.94

32.07 23.82 35.86 47.78 33.80

20.42 13.37 22.30 34.22 25.61

18.66 12.02 20.17 31.56 25.21

28.51 21.38 31.63 42.08 29.44

20.26 13.74 22.24 32.91 23.42

25.48 17.06 27.40 42.36 33.05

23.55 15.63 25.60 38.82 32.94

32.07 23.82 35.86 47.78 33.80

20.42 13.37 22.30 34.22 25.61

18.66 12.02 20.17 31.56 25.21

28.76 21.69 31.84 42.24 29.74

20.38 13.85 22.39 33.04 23.55

25.48 17.06 27.40 42.36 33.05

23.55 15.63 25.60 38.82 32.94

44.93 32.24 51.44 70.36 51.28

23.92 15.14 26.11 41.48 31.96

21.26 13.34 22.91 36.92 30.44

44.04 31.69 49.79 69.08 51.04

26.31 17.14 28.88 44.66 33.54

29.76 20.51 32.56 47.94 37.90

25.41 17.24 27.71 41.17 35.18

42.92 31.77 48.83 63.89 48.91

25.26 16.89 27.88 41.68 32.53

21.77 14.30 23.75 36.38 29.93

39.51 29.03 44.87 59.37 44.83

25.46 17.30 28.24 41.32 31.38

29.76 20.51 32.56 47.94 37.90

25.41 17.24 27.71 41.17 35.18

42.92 31.77 48.83 63.89 48.91

25.26 16.89 27.88 41.68 32.53

21.77 14.30 23.75 36.38 29.93

39.63 29.16 44.94 59.50 44.98

25.47 17.32 28.24 41.35 31.42

29.76 20.51 32.56 47.94 37.90

25.41 17.24 27.71 41.17 35.18

47.17 34.35 54.27 71.83 54.42

26.96 17.47 29.86 45.92 35.59

23.08 14.76 25.19 39.54 32.52

44.33 31.62 50.68 69.46 51.76

28.13 18.42 31.22 47.54 35.88

30.93 22.02 33.76 48.54 39.14

26.12 17.88 28.59 42.01 36.06

52.60 40.51 59.44 75.89 58.44

28.84 19.61 31.81 47.17 37.32

24.06 15.92 26.21 40.03 33.49

50.64 38.06 57.66 75.04 57.14

30.87 21.24 34.30 49.94 38.70

(3,3)
17.36 11.22 18.88 29.27 22.08
17.46 11.31 18.99 29.38 22.19
21.48 13.40 23.22 37.49 29.74
21.04 13.79 23.06 35.19 27.97
21.05 13.80 23.07 35.21 27.99
23.01 14.55 25.15 39.82 31.59
24.51 16.22 26.81 40.86 33.14

AVG.
18.97 12.56 20.72 31.41 23.36
19.07 12.65 20.83 31.51 23.46
23.71 15.18 25.84 40.66 31.67
23.30 15.61 25.68 38.24 30.02
23.31 15.63 25.69 38.27 30.04
25.42 16.48 28.01 43.19 33.77
27.31 18.52 30.08 44.62 35.65

26

Table 21: Benchmark results(%) on queries with negation of FB15k.

CQA Model BetaE
LogicE
NewLook

Normal Form
DM
DM +I
DNF +IU
DM
DM +I
DNF +IU
DNF +IUd
DNF +IUD

Metric
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle

(# anchor nodes, max length of projection chains)

(2,1) (2,2) (2,3) (3,1) (3,2) (3,3)

26.59 11.62 33.56 55.93 31.46

17.23 8.54 19.08 34.46 23.21

13.48 6.58 14.17 27.09 21.50

25.77 14.29 30.88 48.63 28.83

16.36 9.00 17.94 30.97 20.53

13.14 7.07 13.93 24.98 18.73

26.59 11.62 33.56 55.93 31.46

17.23 8.54 19.08 34.46 23.21

13.48 6.58 14.17 27.09 21.50

25.78 14.31 30.88 48.64 28.83

16.36 9.00 17.94 30.97 20.53

13.14 7.07 13.93 24.98 18.72

26.59 11.62 33.56 55.93 31.46

17.23 8.54 19.08 34.46 23.21

13.48 6.58 14.17 27.09 21.50

28.92 15.48 34.64 56.48 33.95

18.00 9.60 19.65 34.90 23.57

14.46 7.53 15.20 28.11 21.69

28.17 11.94 37.01 58.66 33.25

19.34 9.80 22.08 38.16 25.52

15.04 7.80 16.13 29.35 23.21

29.59 16.20 36.21 55.66 34.38

19.06 10.54 21.30 36.02 24.38

15.10 8.25
16.26 28.70 21.81

28.17 11.94 37.01 58.66 33.25

19.34 9.80 22.08 38.16 25.52

15.04 7.80 16.13 29.35 23.21

29.65 16.25 36.31 55.71 34.45

19.09 10.57 21.34 36.04 24.42

15.12 8.26 16.29 28.73 21.82

28.17 11.94 37.01 58.66 33.25

19.34 9.80 22.08 38.16 25.52

15.04 7.80 16.13 29.35 23.21

30.22 15.92 37.10 58.51 35.30

19.69 10.59 21.94 38.03 25.51

15.69 8.33 16.80 30.39 23.07

16.28 3.04 20.00 44.20 21.08

11.92 4.45 12.89 26.73 16.65

9.46 3.67 9.59 20.83 15.73

19.90 7.42 23.76 45.90 24.30

12.89 5.69 13.74 27.26 17.30

10.55 4.66 10.85 21.98 16.34

16.28 3.04 20.00 44.20 21.08

11.92 4.45 12.89 26.73 16.65

9.46 3.67 9.59 20.83 15.73

20.30 7.56 24.38 46.89 24.74

13.10 5.77 14.00 27.76 17.56

10.61 4.68 10.91 22.12 16.43

AVG.
15.31 8.29 16.73 29.15 20.26
15.32 8.29 16.72 29.15 20.26
16.79 8.82 18.23 32.69 23.21
17.66 9.65
19.64 33.55 23.72
17.69 9.67
19.68 33.57 23.74
18.24 9.70
20.21 35.33 24.84
12.05 5.18 12.79 25.63 17.18
12.18 5.23 12.96 25.96 17.35

27

CQA Model BetaE
LogicE NewLook

Table 22: Benchmark results(%) on EPFO queries of NELL.

Normal Form
DM
DM +I
DNF +IU
DM
DM +I
DNF +IU
DNF +IUD

Metric
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle

(1,1)
28.75 20.41 31.79 45.28 24.59
28.75 20.41 31.79 45.28 24.59
28.75 20.41 31.79 45.28 24.59
35.23 25.74 40.27 53.28 30.69
35.23 25.74 40.27 53.28 30.69
35.23 25.74 40.27 53.28 30.69
33.59 24.78 37.19 51.89 29.50

(# anchor nodes, max length of projection chains)

(1,2) (1,3) (2,1) (2,2) (2,3) (3,1) (3,2)

10.01 5.87 10.53 17.71 14.63

9.96 6.15 10.28 17.16 15.42

15.81 10.57 17.44 26.27 16.46

10.06 6.34
10.69 17.33 14.04

9.54 6.08 9.98 16.14 13.66

11.85 7.65
12.98 19.99 13.70

10.63 7.14
11.28 17.38 13.80

10.01 5.87 10.53 17.71 14.63

9.96 6.15 10.28 17.16 15.42

15.81 10.57 17.44 26.27 16.46

10.06 6.34
10.69 17.33 14.04

9.54 6.08 9.98 16.14 13.66

11.95 7.76
13.15 20.05 13.82

10.64 7.16
11.29 17.40 13.82

10.01 5.87 10.53 17.71 14.63

9.96 6.15 10.28 17.16 15.42

18.48 12.02 20.33 31.41 21.26

11.90 7.37
12.57 20.85 17.33

11.06 6.94
11.59 19.00 16.29

15.41 9.66
16.96 26.67 19.83

13.54 8.89
14.41 22.59 18.88

13.53 8.62 14.28 23.05 19.62

13.75 8.92 14.73 22.80 20.32

19.42 13.21 21.61 31.69 21.75

12.66 8.47 13.61 20.64 17.89

12.04 8.13
12.83 19.40 16.97

14.99 9.85
16.59 24.98 18.71

13.08 9.00
14.09 20.83 17.66

13.53 8.62 14.28 23.05 19.62

13.75 8.92 14.73 22.80 20.32

19.42 13.21 21.61 31.69 21.75

12.66 8.47 13.61 20.64 17.89

12.04 8.13
12.83 19.40 16.97

15.03 9.94
16.58 24.97 18.74

13.09 9.02
14.10 20.83 17.68

13.53 8.62 14.28 23.05 19.62

13.75 8.92 14.73 22.80 20.32

22.48 14.90 25.02 37.42 26.45

15.23 9.88 16.51 25.50 22.08

14.18 9.30 15.23 23.42 20.48

17.91 11.26 19.84 30.98 23.47

16.28 10.81 17.61 26.78 22.83

12.06 7.12 12.73 21.72 18.03

11.42 6.79 12.00 20.31 17.76

22.09 14.66 24.27 37.14 26.10

13.59 8.62 14.47 23.13 20.28

12.16 7.69 12.79 20.64 18.24

17.73 11.33 19.23 30.46 23.87

14.70 9.61
15.71 24.53 21.10

(3,3)
9.90 6.51 10.50 16.39 13.36
9.90 6.51 10.50 16.41 13.36
12.35 7.99
13.10 20.77 17.61
12.24 8.41
13.12 19.46 16.72
12.25 8.42
13.14 19.47 16.73
15.19 10.13 16.37 24.78 21.50
13.21 8.65 13.95 21.92 19.28

AVG.
10.29 6.77 10.93 17.05 13.64
10.29 6.78 10.94 17.06 13.65
12.73 8.24
13.53 21.45 17.90
12.75 8.74
13.72 20.36 17.23
12.76 8.75
13.74 20.36 17.24
15.63 10.38 16.90 25.62 21.89
13.81 9.02
14.67 23.03 19.89

28

Table 23: Benchmark results(%) on queries with negation of NELL.

CQA Model BetaE
LogicE
NewLook

Normal Form
DM
DM +I
DNF +IU
DM
DM +I
DNF +IU
DNF +IUd
DNF +IUD

Metric
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle
MRR HIT@1 HIT@3 HIT@10 RA-Oracle

(# anchor nodes, max length of projection chains)

(2,1) (2,2) (2,3) (3,1) (3,2) (3,3)

7.56 3.62 7.98 14.68 9.89

7.30 3.86 7.42 13.77 10.73

6.57 3.42 6.68 12.30 10.23

7.49 4.02 7.72 14.12 9.62

7.67 4.43 7.93 13.69 10.46

7.47 4.41 7.74 13.18 10.58

7.56 3.62 7.98 14.68 9.89

7.30 3.86 7.42 13.77 10.73

6.57 3.42 6.68 12.30 10.23

7.48 3.99 7.72 14.13 9.60

7.69 4.45 7.95 13.72 10.48

7.49 4.42 7.75 13.20 10.60

7.56 3.62 7.98 14.68 9.89

7.30 3.86 7.42 13.77 10.73

6.57 3.42 6.68 12.30 10.23

8.12 4.16 8.42 15.68 10.75

8.49 4.82 8.78 15.36 11.96

8.39 4.85 8.68 15.00 12.26

9.62 4.56 10.34 19.20 13.32

9.51 5.30 9.98 17.13 13.98

9.05 5.47 9.31 15.59 13.48

9.09 4.74 9.66 17.47 12.26

9.48 5.64 10.01 16.61 13.20

9.50 5.99 10.03 15.94 13.26

9.62 4.56 10.34 19.20 13.32

9.51 5.30 9.98 17.13 13.98

9.05 5.47 9.31 15.59 13.48

9.09 4.76 9.64 17.46 12.23

9.48 5.65 10.00 16.61 13.19

9.50 5.99 10.04 15.95 13.26

9.62 4.56 10.34 19.20 13.32

9.51 5.30 9.98 17.13 13.98

9.05 5.47 9.31 15.59 13.48

9.65 4.83 10.19 19.02 13.20

10.42 6.03 11.01 18.63 14.68

10.63 6.51 11.25 18.20 15.13

5.46 2.45 5.46 11.14 5.60

5.35 2.62 5.33 10.25 7.25

5.08 5.39 5.77 5.98 2.40 2.33 2.93 3.10 5.01 5.38 5.84 6.04 9.71 11.21 10.91 11.09 7.87 6.39 7.84 8.81

5.46 2.45 5.46 11.14 5.60

5.35 2.62 5.33 10.25 7.25

5.08 5.44 5.81 5.99 2.40 2.35 2.94 3.11 5.01 5.45 5.88 6.05 9.71 11.28 11.00 11.12 7.87 6.43 7.89 8.83

AVG.
7.53 4.36 7.79 13.44 10.47
7.54 4.37 7.80 13.46 10.49
8.34 4.74 8.62 15.09 11.96
9.46 5.74 9.99 16.33 13.21
9.47 5.75 9.99 16.34 13.20
10.43 6.16 11.02 18.34 14.77
5.82 2.96 5.88 10.97 8.21
5.85 2.97 5.91 11.03 8.24

29

