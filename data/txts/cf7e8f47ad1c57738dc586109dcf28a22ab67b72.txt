A SUPER* Algorithm to Optimize Paper Bidding in Peer Review

Tanner Fiez University of Washington
ﬁezt@uw.edu

Nihar B. Shah Carnegie Mellon University
nihars@cs.cmu.edu

Lillian Ratliff University of Washington
ratlifﬂ@uw.edu

arXiv:2007.07079v2 [cs.AI] 31 Jul 2020

Abstract
A number of applications involve sequential arrival of users, and require showing each user an ordering of items. A prime example (which forms the focus of this paper) is the bidding process in conference peer review where reviewers enter the system sequentially, each reviewer needs to be shown the list of submitted papers, and the reviewer then “bids” to review some papers. The order of the papers shown has a signiﬁcant impact on the bids due to primacy effects. In deciding on the ordering of papers to show, there are two competing goals: (i) obtaining sufﬁciently many bids for each paper, and (ii) satisfying reviewers by showing them relevant items. In this paper, we begin by developing a framework to study this problem in a principled manner. We present an algorithm called SUPER∗, inspired by the A∗ algorithm, for this goal. Theoretically, we show a local optimality guarantee of our algorithm and prove that popular baselines are considerably suboptimal. Moreover, under a community model for the similarities, we prove that SUPER∗ is near-optimal whereas the popular baselines are considerably suboptimal. In experiments on real data from ICLR 2018 and synthetic data, we ﬁnd that SUPER∗ considerably outperforms baselines deployed in existing systems, consistently reducing the number of papers with fewer than requisite bids by 50-75% or more, and is also robust to various real world complexities.

1 Introduction
It is well known that peer review is essential for ensuring the quality and scientiﬁc value of research (Black et al., 1998; Thurner and Hanel, 2011; Bianchi and Squazzoni, 2015). A fundamental challenge in peer review is matching or assigning papers to qualiﬁed and willing reviewers. Common methods to deal with this problem often rely on access to a similarity matrix containing scores for each paper-reviewer pair expressing the estimated match quality between them. The similarity matrix is often obtained using feature-based or proﬁle-based matching mechanisms that leverage keywords and available reviewer publications (Charlin and Zemel, 2013; Price and Flach, 2017). A number of automated methods to match papers with reviewers using similarity scores have been proposed that optimize objectives such as cumulative similarity or fairness notions (Karimzadehgan et al., 2008; Garg et al., 2010; Tang et al., 2010; Long et al., 2013; Stelmakh et al., 2019b).
A shortcoming of automating the paper matching process stems from the failure to actively incorporate reviewers within the paper assignment phase of the review process. The outright dependence on the similarity scores can be problematic since the preferences of reviewers can change frequently and the similarity scores themselves can be noisy. Bidding has emerged as an important mechanism for aiding in and improving the peer review process under the guise that active engagement of the reviewer leads to assignments more aligned with their preferences and hence, enhanced review quality (Di Mauro et al., 2005).
In typical peer review process, when the bidding process opens, reviewers enter the system in an arbitrary sequential order. Upon entering, a list of papers is shown to them and they are asked to place bids on papers they would prefer to review. Following the bidding process, bids can be incorporated into the reviewer-paper assignment mechanism. It is known that the order of papers presented to reviewers in the bidding stage can greatly impact the number of bids that a paper receives (Cabanac and Preuss, 2013). From the perspective of the platform, there are two competing goals: (i) ensure that each paper has a sufﬁcient number of bids, and (ii) ensure individual reviewer satisfaction by showing relevant papers.
With regard to goal (i), the platform aims to select a display order for each reviewer such that at the end of the bidding process, each paper has at least a certain number of bids. The main objective of ensuring a minimum number of bids on each paper is to improve review quality for all papers (Shah et al., 2018b). The well-documented primacy

1

effect (Murphy et al., 2006) suggests that papers shown on top of the ordering are the ones on which reviewers are more likely to bid. Consequently, this objective strongly suggests that papers with few bids should be placed higher in the list. Indeed, Cabanac and Preuss (2013) make the following remark:
“It is advised to counterbalance order effects during the bidding phase of peer review by promoting the submissions with fewer bids to potential referees. This manipulation intends to better share bids out among submissions in order to attract qualiﬁed referees for all submissions. ”
With regard to goal (ii), the platform aims to display ‘well-matched’ papers to each reviewer. That is, the set of papers to be displayed is composed of papers on which the reviewer is most likely to bid. There are several reasons to select well-matched papers. It is generally assumed that reviewers are more likely to place bids on papers they are qualiﬁed to review (Rodriguez et al., 2007). Furthermore, reviewers that place positive bids on papers are more likely to give a review with high conﬁdence and voice sharp opinions of acceptance or rejection that help guide ﬁnal decisions on papers (Cabanac and Preuss, 2013). A number of comprehensive surveys also indicate that a primary motivation of reviewers is the ability to help and contribute to the work of colleagues (Mulligan et al., 2013; Ware, 2008). Failing to display relevant papers to reviewers can result in several unintended negative consequences. If irrelevant papers are shown early in the order to a reviewer, it may cause the reviewer to opt-out and disengage with the system even if further down the list there was an option that they would have happily bid on. Similarly, a poorly selected ordering may result in signiﬁcantly fewer bids from a reviewer.
Competing objectives of this form are not unique to peer review systems and they appear in a number of applications. A ﬁtting example is an intermediary between distinct user groups that seeks to facilitate interactions and satisfy each party. For example, in online labor markets, the platform must ensure each job obtains a sufﬁcient number of applicants and that workers are presented with tasks they are qualiﬁed enough for to be considered. Similarly, in online e-commerce marketplaces, as the platform decides how to show products to users, there is a deﬁnite trade-off between satisfying merchants offering products that need to be sold and users that want to be shown relevant items. In this paper, we maintain peer review as a running example and comment further on relevant applications of our work in a concluding discussion section.
In peer review, it is recognized that actively engaging reviewers in the paper assignment process via bidding can greatly improve the review process. If administered inadequately, bidding can in fact have a signiﬁcant negative impact on the quality of the review process. In the words of Rodriguez et al. (2007),
“Since bidding is the preliminary component of the manuscript-to-referee matching algorithm, sloppy bidding can have dramatic effects on which referees actually review which submissions.”
A study on the 2016 Neural Information Processing Systems (NeurIPS) conference revealed the distribution of bids arising from a typical bidding process leaves signiﬁcant challenges to match papers with reviewers (Shah et al., 2018b). It was observed that a considerable number of reviewers do not place a sufﬁcient number of bids and papers commonly fail to obtain as many bids as the number of reviewers needed. This phenomenon is detailed in Shah et al. (2018b) amongst the 3,200 reviewers and 2,400 papers.
“Moreover, there are 148 reviewers with no (positive or negative) bids and 1201 reviewers with at most 2 positive bids... We thus observe that a large number of reviewers do not even provide positive bids amounting to the number of papers they would review. As a consequence of the low number of bids by reviewers, we are left with 278 papers with at most 2 positive bids and 816 papers with at most 5 positive bids... There is thus a signiﬁcant fraction of papers with fewer positive bids than the number of requisite reviewers.”
The study also found that there were 1090 papers with no positive bids from the area chairs. The inability to elicit meaningful bidding information in NeurIPS is far from an aberration. In a study of the 2005 Joint Conference on Digital Libraries, 146 out of the 264 submissions did not obtain any bids (Rodriguez et al., 2007). The shortfalls of existing bidding systems shift the onus of the reviewing assignments away from the participants and to the paper matching mechanisms.
Despite the importance of the bidding process in peer review, there is not yet much fundamental research on the problem of optimizing the display order during the bidding process, and much less so in consideration of the two objectives identiﬁed in this paper. In practice, the display order is typically determined via heuristics such as a ﬁxed ordering (e.g., order of submission), or in decreasing order of the relevance of the papers to that reviewer, or in increasing order of the number of bids received by the paper until then.
2

A key reason that bidding can fail is that papers are suboptimally displayed to the reviewers. Consider a paper that is not an ideal match for any reviewer in the system. If papers are ranked for display simply by how well-matched they are to reviewers, this particular paper may be shown far down in the ranking for each reviewer and hence, not receive many, if any, bids. The risk of this scenario is elevated for interdisciplinary research, which is know to face signiﬁcant impediments as a consequence of the lack of ideally matched peers (Travis and Collins, 1991; Porter and Rossini, 1985).
On the other hand, if papers are inversely ranked by the number of bids they have obtained, then papers with fewer bids are more likely to be shown higher on the list regardless of how well-matched they are to any particular reviewer. This display order may cause reviewer dissatisfaction, which in the worst case could result in zero bids. Similarly, ordering heuristics that are based on a ﬁxed baseline may lead to bias in the review process. Indeed, in the report of a study of 42 peer-reviewed conferences in Computer Science, it was observed that under a ﬁxed ordering (based on the submission time), the number of bids on papers is heavily inﬂuenced by the order of submission times of the papers (Cabanac and Preuss, 2013). It was concluded that the later the paper is submitted, the fewer bids it will receive.
Given the ﬂaws of existing peer review bidding systems, we study the important problem of selecting the ordering of papers to display to each arriving reviewer in a principled manner.
1.1 Our contributions
The key contributions of this paper are summarized as follows.
Problem identiﬁcation and formulation (Section 2). The bidding process is highly consequential, yet one of the most understudied components of the conference peer-review process. We identify a key source of unfairness and inefﬁciency in the bidding process, and develop principled methods to address it. A key challenge is suitably formalizing the peer review bidding process, for which to the best of our knowledge there are no prior formulations. We formulate an objective function that captures the competing goals of the platform while reﬂecting the underlying decision-making process of reviewers. The framework developed in this paper to analyze the problem is an important step toward future improvements on bidding systems.
Algorithm design (Section 3). We present a sequential decision-making algorithm called SUPER∗ to address this problem. The algorithm takes as input the “similarities” between each reviewer-paper pair and the bids made by all past reviewers, and outputs the ordering of papers to show to any current reviewer.
Theoretical results (Section 4). We show two sets of theoretical results. We ﬁrst consider a notion of ‘local’ performance: the performance with respect to a single reviewer. We prove that SUPER∗ is locally optimal whereas all popular baselines are considerably suboptimal. Our second set of theoretical results are based on a community model, where we prove that SUPER∗ is near-optimal (globally) and all popular baselines are considerably suboptimal.
Experiments on real and synthetic data (Section 5). We run extensive experiments using similarity scores from ICLR 2018 and on synthetic data. The experiments reveal that the SUPER∗ algorithm outperforms all popular baselines. For instance, it consistently reduces the number of papers with fewer than requisite bids by 50-75% while maintaining individual reviewer satisfaction. In addition, we see that SUPER∗ is very robust to model mismatches and complexities of the real-world review process.
The code for the algorithm is available at github.com/fiezt/Peer-Review-Bidding.
1.2 Related Work
The paper ordering problem for the bidding process in peer review bears a strong resemblance to the learning to rank problem (Singh and Joachims, 2019; Yadav et al., 2019; Svore et al., 2011; Momma et al., 2019; Aslanyan and Porwal, 2019; Cao et al., 2007). Typically, the goal of learning to rank is to learn an overall ranking of items via supervised methods or by querying users, where the latter provides further information on the relative ranking of items. In peer review, the objective of ﬁnding a ranking most suitable for an arriving reviewer during the bidding process is analogous to learning to rank methods that consider the utility of rankings for users along with the impact on the items being ranked (Singh and Joachims, 2019; Yadav et al., 2019). Moreover, the bidding model considered in this work is motivated from that which is commonly adopted in learning to rank models (Aslanyan and Porwal, 2019).
3

As formulated in this paper, the goal for the design of the bidding process in peer review is to optimize for multiple criteria reﬂecting the objectives of the reviewers and the papers, respectively. This is not unlike the methods of Singh and Joachims (2019) and Yadav et al. (2019), which consider a fairness objective in combination with a ranking quality objective, or the multi-objective learning to rank problems studied by Svore et al. (2011) and Momma et al. (2019). In the works of Singh and Joachims (2019) and Yadav et al. (2019), the objective of ensuring fairness is encoded as a constraint in the optimization problems. Similarly, Svore et al. (2011) optimize a linear combination of ranking measures referred to as a ‘graded measure’ and Momma et al. (2019) convert a constrained optimization problem into an unconstrained problem by penalizing constraint violations in the objective. In each of the aforementioned works, the ranking measures are separable in the arriving users, meaning that the contribution of any individual user to the overall objective is independent of the other users.
The problem of paper ordering in peer review given multiple objectives is also abstractly similar to online recommendation systems similarly facing competing objectives (Rodriguez et al., 2012; Agarwal et al., 2011; Jambor and Wang, 2010). However, a prevailing approach is to convert the multi-objective problem to a constrained optimization problem (Rodriguez et al., 2012; Jambor and Wang, 2010). Both the approach of incorporating objectives as constraints in the optimization problem formulations and combining objectives in a linear fashion is considered by Agarwal et al. (2011). Analogous to the learning to rank problem, the objectives are separable in the users.
The objective in the peer review problem as formulated in this paper presents unique challenges not addressed in the aforementioned works on learning to rank and recommendation systems. Notably, it is not separable between the reviewers since it depends on the number of bids on each paper after each reviewer has arrived and placed bids on the papers. Being applicable to more general multi-criteria settings, our approach to the design of the bidding processes in peer review may also be applied to the learning to rank problem. This is a direction worthy of further study.
Our work also contributes to a growing literature on improving various aspects of the peer review process such as reviewer assignment (Charlin and Zemel, 2013; Garg et al., 2010; Lian et al., 2018; Stelmakh et al., 2019b; Kobren et al., 2019), biases (Tomkins et al., 2017; Stelmakh et al., 2019a), subjectivity (Noothigattu et al., 2018), miscalibration (Roos et al., 2012; Wang and Shah, 2019), strategic behavior (Aziz et al., 2019; Xu et al., 2019), and others (Church, 2005; Wing, 2011; Lawrence and Cortes, 2014; Shah et al., 2018a; Kang et al., 2018; Jecmen et al., 2020; Ding et al., 2020; Stelmakh et al., 2020a,b). The present paper addresses the bidding process in conference peer review, which has largely been unexplored in past literature. The concurrent work of Meir et al. (2020), which appeared after an initial workshop version of our work (Fiez et al., 2019), is the only work besides our own that we are aware of to focus on methods for improving bidding in peer review. However, their approach is to design a market for bidding, which is entirely different from ours.
2 Problem Formulation
Consider d ≥ 2 papers and n ≥ 2 reviewers indexed as {1, . . . , d} and {1, . . . , n} respectively.1 For each reviewerpaper pair, we have access to a similarity score that captures the similarity between the reviewer and the paper. We use the notation Si,j ∈ [0, 1] to denote the given similarity between any reviewer i ∈ [n] and paper j ∈ [d]. A higher similarity score indicates a greater relevance of the paper to that reviewer. There are several systems in use today that compute similarities (Price et al., 2010; Charlin and Zemel, 2013), and in our work, we treat them as being given.
In the bidding period, reviewers sequentially arrive into the system and place bids on the papers. In our work, for any reviewer and paper, we only consider the existence of a bid or not, and do not consider the possibility of multiple bidding options. We assume for simplicity that all n reviewers arrive exactly once, and that a reviewer arrives after the previous reviewer has completed their bidding.2 We do not make any assumptions on the arrival order of the reviewers. The problem is to determine the ordering of papers to show each reviewer on arrival in the interest of inﬂuencing the papers they decide to bid on while ensuring individual satisfaction. When deciding the paper ordering for any reviewer, the bids made by all reviewers who arrived in the past along with the paper orderings presented to them are known, but the bids made by the current or future reviewers are unknown. Let Πd denote the set of all possible d! permutations of the d papers. In what follows, for any reviewer i ∈ [n], we let πi ∈ Πd denote the ordering (permutation) of the papers shown to reviewer i. We also use the notation πi(j) to denote the position of paper j ∈ [d] in the ordering πi.
Gain function (objective). Any algorithm to determine the ordering of papers must trade-off between two competing objectives: ensuring each paper receives a sufﬁcient number of bids and ensuring each reviewer gets to see relevant
1Henceforth, for any positive integer κ, we will use the standard shorthand [κ] to denote the set {1, . . . , κ}. 2However, in Section 5.1, we show that our algorithm is empirically robust to violations of these assumptions.
4

papers early in the ordering. A combination of the objectives comprise our “gain function,” which is the objective we
aim to optimize. We begin by discussing each objective component. Paper-side gain: The paper-side gain is associated with a given function γp : R≥0 → R≥0. At the end of the
entire bidding process, the paper-side gain Gp is

Gp = γp(gj),
j∈[d]

where gj is the number of bids received by paper j ∈ [d]. We assume the function γp is non-decreasing and concave. The non-decreasing property represents an improved gain if there are more bids, and the concavity property√captures diminishing returns.3 An example of a choice for the paper-side gain is the square-root function γp(x) = x. This function is increasing, smooth, and captures the diminishing returns property. The reader may keep this function in mind as a running example for concreteness. A second example is γp(x) = min{x, r} for a given parameter r ≥ 1, which emphasizes having at least r bids per paper.
Reviewer-side gain: This objective captures the desideratum that the reviewers should be shown papers with
high relevance early in the paper ordering. The reviewer-side gain is associated with some predetermined function γr : [d] × [0, 1] → R≥0. Given this function, the reviewer-side gain Gr is deﬁned as:

Gr =

γr(πi(j), Si,j ).

i∈[n] j∈[d]

The function γr is assumed to be non-increasing in the position (its ﬁrst argument) and non-decreasing in the similarity (its second argument). One example choice of this function, which the reader may choose to keep in mind as a running example, is the Discounted Cumulative Gain or DCG used commonly in data mining (Ja¨rvelin and Keka¨la¨inen, 2000). In our setting, the function is given by
2Si,j − 1 γr(πi(j), Si,j) = log2(πi(j) + 1) , (1)
where we have set the “relevance” parameter in DCG to be the similarity Si,j. Overall gain function: Finally, we assume there is a trade-off parameter λ ≥ 0, chosen by the program chairs,
which trades off between these two objectives so that the overall gain function is given by

G = Gp + λGr.

(2)

The goal is to determine the orderings of papers to show each reviewer to maximize the expected overall gain, E G , where the expectation is taken over the randomness in the bids made by the reviewers (see reviewer bidding model below) and any randomness in the algorithm.4
Reviewer bidding model. An important aspect of any system that displays a list to users is the presence of primacy effects. In the context of our problem, the primacy effect means a reviewer is more likely to bid on a paper shown at the top of the list rather than later (Murphy et al., 2006). A second aspect of bidding is that a reviewer is more likely to bid on papers with greater similarity, although the reviewer may not bid on exactly the papers with the highest similarity since the similarities are noisy representations of their reviewing interests.
Thus in order to model reviewer bidding, we revert to literature on position-based click models that have a nearly identical setting (where clicks are analogous to our bids). We model the bidding via a given function f : [d] × [0, 1] → [0, 1], where f (πi(j), Si,j) is non-increasing in the position that a paper is shown (the ﬁrst argument) and non-decreasing in the similarity score (the second argument). Any reviewer i ∈ [n] bids on paper j ∈ [d] independently with probability
pi,j = f (πi(j), Si,j ).
3Our algorithm easily adapts to paper-side gains that may also be a function of the similarity scores of the reviewers who bid; for example, a higher gain for bids from expert reviewers. We omit this detail for sake of brevity.
4For the pedantic reader, a (deterministic) algorithm is a mapping from [0, 1]n×d × ([n] × 2[n] × {0, . . . , n}d)n to (Πd)n. In this representation, the ﬁrst input argument is the similarity matrix. The second argument represents, for each of the arriving reviewers, the identity of the current reviewer, the identities of the past reviewers, and the number of bids so far for each paper. The output space is simply an ordering of the d papers for each reviewer. A stochastic algorithm outputs a probability distribution over the output space.

5

As a running example throughout the paper, note that in position-based click models, the click probability decomposes into a product of relevance and position bias (Chuklin et al., 2015). Moreover, the literature considers the click probability to decay logarithmically as a function of the position (Aslanyan and Porwal, 2019). The translation of these models into our setting gives rise to the example bidding function
f (πi(j), Si,j ) = Si,j . (3) log2(πi(j) + 1)
Baselines. We consider the following three methods of ordering papers as baselines. Random baseline (RAND): A commonplace practice (Cabanac and Preuss, 2013) is to show papers to reviewers
in some ﬁxed order, such as in order of submission of the papers. As a baseline, we consider a better variant of this practice, in which each reviewer is shown an independently and randomly selected paper ordering.
Similarity baseline (SIM): A second common practice, followed in several conference management systems today, is to order the papers according to their similarities. In other words, any reviewer i ∈ [n] is shown the papers in order of the values in {Si,j}j∈[d] (where the paper with maximum similarity is shown at the top, and so on). Any ties are broken by showing papers with fewer bids higher, and further ties are broken uniformly at random.
Bid baseline (BID): A third baseline shows papers to greedily optimize the minimum bid count. Each reviewer is shown papers in increasing order of the number of bids received so far (from the reviewers who arrived previously). Any ties are broken in favor of the paper with a higher similarity, and further ties are broken uniformly at random.

3 Algorithm
The key challenge in designing a suitable algorithm for the problem at hand stems from the fact that the paper-side gain is coupled (non-separable) across the orderings of papers presented to all reviewers so the impact of each individual paper ordering cannot be fully realized until the entire bidding process is complete. Conversely, the reviewer-side gain is decoupled (separable) across reviewers. This means the reviewer-side gain that can be obtained from any given reviewer is independent of the ordering of papers presented to any other reviewer. Thus, an algorithm for this problem is required to make local decisions, where the effect of the decision on the global gain (or cost) is only partially known. This perspective is reminiscent of the classical A∗ algorithm (Hart et al., 1968), and using A∗ as an inspiration, we now present an algorithm which we call SUPER∗ for our problem5.
The A∗ algorithm operates with a goal of ﬁnding the minimum cost path between a pair of vertices in a costweighted graph. For any node in consideration, it considers two functions: a function which captures the cost so far and a second function—called the “heuristic”—which captures some estimate of the cost from the current node to the destination. The A∗ algorithm then ﬁnds a path based on these two functions. Before moving to a description of SUPER∗, we discuss such a heuristic in the context of the problem at hand.

3.1 Heuristic for Future Bids
In a manner analogous to the A∗ algorithm, at any point in time SUPER∗ keeps track of the gains so far and also takes as input a heuristic that captures the “unseen” events. The heuristic in A∗ provides, for every vertex in the given graph, an estimate of the cost incurred in the future. Analogously, the heuristic in SUPER∗ provides, for every arrival of a reviewer, an estimate of the number of bids each paper will receive in the future. Formally, let us index the reviewers as i ∈ [n] in the order of arrival (note that this order is unknown a priori). The heuristic comprises a collection of vectors {h1, . . . , hn}, where each hi ∈ [0, n − i]d represents an estimate of the number of bids each of the d papers will receive from all future reviewers {i + 1, . . . , n}. The vector hi is provided to the SUPER∗ algorithm on arrival of the ith reviewer. Two examples of heuristic functions that we consider in the subsequent narrative are described as follows.
• Zero heuristic: hi = 0 for every i ∈ [n].

• Mean heuristic: This function computes the expected number of bids each paper will receive if the permu-

tations shown to all future reviewers are chosen independently and uniformly at random. Formally: hi,j =

1 d

n i =i+1

j ∈[d] f (j , Si ,j) ∀ i ∈ [n − 1], j ∈ [d].

5The name SUPER∗ stands for SUperior PERmutations and also indicates the inspiration from A∗.

6

We set hn = 0 for any heuristic, implying there are no bids placed after the last reviewer. This is analogous to setting the heuristic value to zero for the target vertex in the A∗ algorithm.

3.2 Intuition Behind the Algorithm
We ﬁrst provide some intuition about the SUPER∗ algorithm, and subsequently present a formal description. Since a
primary impediment to designing an algorithm is the inability to fully realize the impact of a paper ordering on the paper-side gain until the end of the bidding process, we begin by considering the scenario where (n − 1) reviewers have already departed, and the problem is to determine the ordering of papers to show the ﬁnal reviewer. In this scenario, we have access to the bids of all (n − 1) reviewers that have already arrived and the orderings of papers presented to them. We use the notation gn−1,j ∈ {0, . . . , n − 1} to denote the number of bids received by any paper j ∈ [d] at the time of arrival of the last reviewer. The values {gn−1,1, . . . , gn−1,d} are thus known at the time when the ﬁnal reviewer arrives. As a result, we can formulate an optimization problem for the ﬁnal reviewer n to maximize the expected gain from (2) in the following manner. For every j ∈ [d], let Bn,j denote a Bernoulli random variable with mean pi,j = f (πn(j), Sn,j), independent of all else. The random variable Bn,j represents the bid of the ﬁnal reviewer on paper j ∈ [d]. The optimization problem can be written as

max

E[γp(gn−1,j + Bn,j )] + λ γr(πn(j), Sn,j ),

(4)

πn ∈Πd

j∈[d]

j∈[d]

where the expectation is taken over the distribution of the random variables Bn,1, . . . , Bn,d.
Observe that the constraint set for the optimization problem in (4) is the set Πd of all permutations. This set is, in
general, not very well behaved (Ailon et al., 2008; Shah et al., 2016), which makes even this one-step optimization a challenge. As we discuss later in the formal algorithm description along with Theorem 1 and its proof, SUPER∗ for the
ﬁnal reviewer optimally solves (4) and it is computationally efﬁcient manner (see Proposition 1 in Appendix B.1). The aforementioned subproblem forms the starting point for the SUPER∗ algorithm. Now that we know to handle a single (last) reviewer in an optimal fashion, we now describe the SUPER∗ algorithm for a general reviewer, say, i ∈ [n]. When reviewer i arrives, we have access to the number of bids made by all past reviewers on any paper j ∈ [d], which we denote by gi−1,j ∈ {0, . . . , i − 1}.
We now recall the A∗ algorithm: for any vertex, A∗ considers the cost “g” so far and a heuristic estimate “h” of the subsequent cost. Then, considering the cost of any vertex as “g + h”, the A∗ algorithm takes the one-step optimal action given by selecting the neighboring vertex with the smallest value of “g + h”. In an analogous fashion, SUPER∗
considers the number of bids so far (gi−1) and takes as input a heuristic (hi) for the number of bids in the future. Then, considering the number of bids from all other reviewers as “gi−1 + hi”, the SUPER∗ algorithm takes the action which is the one-step optimal action. In other words, SUPER∗ solves for each paper ordering using:

max

E[γp(gi−1,j + hi,j + Bi,j )] + λ γr(πi(j), Si,j ),

(5)

πi ∈Πd

j∈[d]

j∈[d]

where Bi,j is a Bernoulli random variable with mean pi,j = f (πi(j), Si,j) and is independent of all else. As for the ﬁnal reviewer, SUPER∗ solves this problem in an efﬁcient manner for any arbitrary reviewer (see Proposition 1 in
Appendix B.1).

3.3 Formal Algorithm Description
The SUPER∗ algorithm is presented in Algorithm 1. To determine a paper ordering to show any reviewer, SUPER∗ calls a procedure to efﬁciently solve (5). We give a general method in Algorithm 2 and a faster method in Algorithm 3 that is applicable for a special class of reviewer-side gain and bidding functions.
General version. In the general version of SUPER∗, Algorithm 2 is called to return a paper ordering that is a solution to (5) each time a reviewer arrives. In the proof of Theorem 1, we show that the optimization problem over the set of permutations given in (4) to ﬁnd the optimal paper ordering for the ﬁnal reviewer can be reformulated as an integer linear programming problem with a totally unimodular constraint set. The totally unimodular property of the constraint set guarantees that the solution of a relaxed linear program is in fact the integer optimal solution. The application of this reduction from an optimization problem over permutations to a linear programming problem for any

7

Algorithm 1: SUPER∗
Input: γp : R≥0 → R≥0, paper-side gain function γr : [d] × [0, 1] → R≥0, reviewer-side gain function f : [d] × [0, 1] → [0, 1], bidding model λ ≥ 0, trade-off parameter S ∈ [0, 1]n×d, similarity matrix.
Algorithm:
1. Initialize bids on each paper to zero: g0 ← 0d
2. For each reviewer arrival i ∈ [n]
(a) Compute or input heuristic hi ∈ [0, n − i]d (b) πi ← FindPaperOrder (c) Present papers in the order πi and observe bids bi ∈ {0, 1}d (d) Update paper bid counts: gi = gi−1 + bi

Algorithm 2: FindPaperOrder 1. Compute weight matrix w ∈ Rd×d such that
wj,k = λγr(k, Si,j ) + f (k, Si,j )(γp(gi−1,j + hi,j + 1) − γp(gi−1,j + hi,j )) ∀ j ∈ [d], k ∈ [d]

2. Solve linear program to obtain x∗ ∈ Rd×d:

x∗ ∈ arg max
x∈[0,1]d×d

wj,k xj,k
j∈[d] k∈[d]

s.t.

xj,k = 1 ∀ j ∈ [d],

xj,k = 1 ∀ k ∈ [d]

k∈[d]

j∈[d]

with ties broken arbitrarily between the set of maximizing solutions 3. πi(j) = k such that x∗j,k = 1 for each j ∈ [d] Output: πi

Algorithm 3: FindPaperOrderEfficient 1. Compute weights for each j ∈ [d]:
αi,j = f S (Si,j )(γp(gi−1,j + hi,j + 1) − γp(gi−1,j + hi,j )) + λγrS (Si,j )
2. πi = σ(αi), where σ : Rd → [d]d returns the rank from maximum to minimum of each input in place and breaks ties arbitrarily.
Output: πi
given reviewer forms the technique given in Algorithm 2 to efﬁciently obtain a solution to (5). Finally, the per-reviewer time complexity of the general version of SUPER∗ given the evaluations of the heuristic is O(d3) (see Proposition 1 in Appendix B.1) as a consequence of the call to solve a linear assignment problem in Algorithm 2. Faster specialized version. Given a bidding model that can be decomposed as f (πi(j), Si,j) = f S(Si,j)f π(πi(j)) where f S : [0, 1] → [0, 1] is non-decreasing and f π : [d] → [0, 1] is non-increasing, along with a reviewer-side gain

8

function that can be decomposed as γr(πi(j), Si,j) = γrS(Si,j)f π(πi(j)) where γrS : [0, 1] → R≥0 is non-decreasing, SUPER∗ calls Algorithm 3 to return a paper ordering that is a solution to (5) each time a reviewer arrives. In the proof of Proposition 1 in Appendix B.1, we show for this model class that the problem from (4) to ﬁnd the optimal paper ordering for the ﬁnal reviewer after evaluating the expectation can be reformulated as

max

αn,j f π(πn(j))

(6)

πn ∈Πd

j∈[d]

for some non-negative weights {αn,j}j∈[d]. The problem in (6) admits a simple solution: f π is non-increasing on the domain, so the objective is maximized by presenting papers in decreasing order of the weights {αn,j}j∈[d]. Obtaining this solution only requires sorting the weights, which has a time complexity of O(d log(d)). The application of this problem reformulation for the given model class and any reviewer forms the technique given in Algorithm 3 to obtain a solution to (5).
Before moving on to present our theoretical results, we comment on the relevance of this model class. Importantly, the DCG reviewer-side gain function and bidding model f (Si,j, πi(j)) = Si,j/ log2(πi(j) + 1), which we have mentioned as running examples that can be kept in mind, satisfy the decomposition for which SUPER∗ is computationally efﬁcient. This choice of functions is standard in the past literature on ranking models and click behavior (Ja¨rvelin and Keka¨la¨inen, 2000; Aslanyan and Porwal, 2019), meaning that the time complexity result for this model class is quite relevant.

4 Theoretical Results
We now present the main theoretical results of this paper. Complete proofs of all results are in Appendix A.
4.1 Local Optimality
The property of local optimality, as the name suggests, means that the algorithm is optimal with respect to the reviewer under consideration. Achieving even a good local performance in a computationally efﬁcient manner is challenging due to the optimization over permutations in (4). The following results show that SUPER∗, which is computationally efﬁcient, is locally optimal.
The result is ﬁrst presented in terms of the ﬁnal reviewer for simplicity and extended to a general reviewer subsequently. In the following theorem, since we consider only the ﬁnal reviewer, note that the heuristic for SUPER∗ is irrelevant because the heuristic value for the ﬁnal reviewer is always set to zero.
Theorem 1. Given any history of paper orderings and bids from reviewers that arrived previously, the paper ordering given by SUPER∗ to the ﬁnal reviewer maximizes the expected gain conditioned on the history.
In other words, the expected amount by which the gain is increased from the ﬁnal reviewer is maximized. To generalize the previous result to a local optimality result for any reviewer, let the immediate gain from a reviewer be deﬁned as the difference between the gain after and before the reviewer arrived.
Corollary 1. Given any history of paper orderings and bids from reviewers that arrived previously, the paper ordering given to any reviewer by SUPER∗ with zero heuristic maximizes the expected immediate gain from that reviewer conditioned on the history.
The property of local optimality also implies optimality of SUPER∗ (with any heuristic) when the paper-side gain function is linear. We refer the reader to Appendix B.2 for more details.
We now show that an analogous statement cannot be made regarding the other baseline methods. In fact, in contrast to SUPER∗, all the popular baselines are considerably suboptimal. Theorem 2. Consider a model with the paper-side gain function γp(gj) = √gj, the reviewer-side gain function γr(πi(j), Si,j) = (2Si,j − 1)/ log2(πi(j) + 1), and the bidding function f (πi(j), Si,j) = Si,j/ log2(πi(j) + 1). There exists a constant c > 0 such that for every d ≥ 2 and λ ≥ 0, in the worst case for the ﬁnal reviewer:
(a) SIM is suboptimal by an additive factor of at least cd/ log22(d); (b) BID is suboptimal by an additive factor of at least cd max{1, λ}/ log22(d); (c) RAND is suboptimal by an additive factor of at least cd max{1, λ}/ log22(d).

9

Theorems 1 and 2 in tandem show that SUPER∗ not only is locally optimal but can outperform currently popular algorithms by a wide margin.
4.2 Global Optimality Under a Community Model
We now transition to consider the global performance of the algorithms. Given our focus on the application of peer review, we are motivated to give guarantees on the performance of SUPER∗ for similarity matrix classes that would be encountered in a real conference.
A common characteristic of networks is community structure (Newman and Girvan, 2004; Porter et al., 2009), where nodes can be grouped into clusters and links between groups are not as common. This phenomena has been documented in social and biological networks among others (Girvan and Newman, 2002). Pertinent to this work, empirical investigations have revealed community structures in scientiﬁc collaboration networks (Newman, 2001). Given this close connection, and the fact that scientiﬁc research is highly specialized, it is intuitive that communities exist in major conferences pertaining to different subtopics.
We explore the possible existence of such structure in the ICLR 2018 similarity matrix that was reconstructed by Xu et al. (2019) and is of size n = 2435 and d = 935. Recall that the ICLR similarity matrix is of size (2435 × 935). To begin, we investigate the spectral properties of the similarity matrix from ICLR 2018, and in particular, whether it is low rank. We plot the singular values of the similarity matrix in Figure 1a, where the (heuristic) elbow method suggests a low rank (≈ 10). In Figure 1b we plot the entries of the similarity matrix after permuting its rows and columns according to the spectral co-clustering algorithm (Dhillon, 2001). The result suggests the ICLR 2018 similarity matrix exhibits some characteristics of a noisy block diagonal structure.

Papers

0

500

1000

1500

2000

0

0.07

200

0.06

0.05

400

0.04

600

0.03

0.02

800

0.01

Reviewers

0.00

(a)

(b)

Figure 1: (a) The 50 singular values (excluding the maximum singular value) of ICLR 2018 similarity matrix, which shows low-rank structure. (b) Similarity scores of the permuted ICLR matrix as a heatmap indicating the block diagonal structure.

In what follows, we now perform an associated theoretical analysis of the algorithms under such community structures of the similarity matrix. We begin by proposing a simple model which we call the ‘noiseless community model’.
Noiseless community model. Informally, the noiseless community model we study is a set of similarity matrices that up to a permutation of rows and columns belong to a subclass of block diagonal matrices. Formally, let 0q×q and 1q×q denote q × q matrices of all zeros and all ones respectively. Deﬁne an mq × mq block diagonal matrix B as:

1q×q 0q×q · · · 0q×q

0q×q 1q×q · · · 0q×q

B= 

..

.

... . . . ...  .

0q×q 0q×q · · · 1q×q

Finally, denote by Pmq×mq the set of all mq × mq permutation matrices. Recall that a permutation matrix is a matrix obtained by permuting the rows of an identity matrix. Also recall that left multiplying a matrix by a permutation matrix permutes the rows of the matrix and right multiplying a matrix by a permutation matrix permutes the columns of the matrix. With this background, the noiseless community model is deﬁned as the following set of similarity matrices for

10

m ≥ 2 and q ≥ 2: Noiseless Community Model = {S ∈ Rmq×mq : S = P (sB)P , s ∈ [0.01, 1], P, P ∈ Pmq×mq}. (7)

The number of reviewers is given by n = mq and the number of papers is by d = mq. In words, this is the set of all similarity matrices obtained via a permutation of the rows and columns of the block matrix B.
We begin our theoretical results for this section by showing that under the noiseless community formulation, both SUPER∗ and SIM are optimal, whereas BID and RAND fare poorly. Recall that d = n = mq in the noiseless community model. Theorem 3. Consider a model with a paper-side gain function γp(gj) = √gj, the reviewer-side gain function γr(πi(j), Si,j) = (2Si,j −1)/ log2(πi(j)+1), and the bidding function f (πi(j), Si,j) = 1{πi(j) = 1}1{Si,j > s/2}. Then, under the noiseless community model from (7), for all m ≥ 2, q ≥ 2 and λ ≥ 0:
(a) SUPER∗ with zero heuristic is optimal; (b) SIM is optimal. In contrast, there exists a constant c > 0 such that for every m ≥ 2, q ≥ 2 and λ ≥ 0: (c) BID is suboptimal by an additive factor of at least cλd/ log22(d); (d) RAND is suboptimal by an additive factor of at least cd.
Although SIM is optimal in the noiseless community model, this optimality turns out to be quite brittle. As we show below, even an inﬁnitesimally small amount of noise makes SIM considerably suboptimal. In contrast, SUPER∗ is robust enough and suffers by only a small amount.
Noisy community model. More formally, we ﬁrst deﬁne a ‘noisy community model’. Under this model, we assume that the similarity matrix is generated by ﬁrst selecting any similarity matrix S from the noiseless community model deﬁned in (7), and then adding noise to its entries as:

S = s − νi,j if Si,j = s

(8)

i,j

νi,j

if Si,j = 0,

where νi,j is drawn independently and uniformly from (0, ξ) for each reviewer-paper pair, for some small value ξ to be deﬁned subsequently.
The next result shows that even under an arbitrarily small perturbation ξ from a noiseless community model, the baselines become signiﬁcantly suboptimal. In contrast, SUPER∗ is robust to the noise and is near-optimal. Recall that d = n = mq in the noisy community model.
Theorem 4. Consider the gain and bidding functions from Theorem 3 and the noisy community model given in (8) with any noise bound satisfying ξ ≤ (1 + λ)−1e−emq. Then, for all m ≥ 2, q ≥ 2, and λ ≥ 0:
(a) SUPER∗ with zero heuristic is within at least an additive factor of 0.0001 of the optimal. Moreover, there exists a constant c > 0 such that for every m ≥ 2, q ≥ 2, and λ ≥ 0, with respect to SUPER∗ with zero heuristic:
(b) SIM is suboptimal by an additive factor of at least cd; (c) BID is suboptimal by an additive factor of at least cλd/ log22(d); (d) RAND is suboptimal by an additive factor of at least cd.
This result thus establishes the global optimality of the proposed SUPER∗ algorithm under the community model, while in contrast all popular baselines are considerably suboptimal.

5 Experimental Results
We now empirically evaluate SUPER∗ (with zero and mean heuristics) and compare it with the baselines SIM, BID, and RAND (discussed earlier in Section 2). The experimentation methodology is as follows for any chosen set of model parameters including the gain functions, bidding probability, trade-off parameter, and number of reviewers and papers. Given a ﬁxed similarity matrix, we shufﬂe the rows of the matrix to randomize the sequence of reviewer arrivals and simulate each of the algorithms. Then, for each algorithm, we record the gain along with the number of papers that end up with bid counts in the intervals {0, 1, 2}, {3, 4, 5}, {6, 7, 8}, and {9+}. We repeat this process 20 times

11

Relative gain Number of papers
Relative gain Number of papers

800
600
400
200
0 0.0 0.2 0.4 0.6 0.8 1.0 Tradeoﬀ parameter λ
(a)

500

400

300

200

100

0 {0,1,2} {3,4,5} {6,7,8} Number of bids
(b)

{9+}

250
200
150
100
50
0 0.0 0.2 0.4 0.6 0.8 1.0 Tradeoﬀ parameter λ
(c)

500

400

300

200

100

0 {0,1,2} {3,4,5} {6,7,8} Number of bids
(d)

{9+}

Figure 2: ICLR experiment with the default model conﬁguration. Legend for each bid distribution plot (b, d): within each bidcount interval, the bars correspond to the algorithms given in the legend and are presented in an order consistent with the legend itself when read from left to right and (d) only includes SUPER∗ with mean heuristic, SUPER∗ with zero heuristic, and SIM.
for a given similarity matrix if it is ﬁxed and draw a similarity matrix at random for each run if the score structure being simulated is a distribution. To evaluate performance, we show the means of the relative gains (additive gains relative to the gain of a baseline) across the runs and include error bars representing the standard error of the mean. Moreover, we present the mean number of papers across the repeated simulations that ﬁnish with bid counts in each of the previously given bid count intervals. The code and data to reproduce each of the experiments is available at github.com/fiezt/Peer-Review-Bidding.
5.1 ICLR Similarity Matrix
To begin our experiments, we perform evaluations on a similarity matrix from the ICLR 2018 conference discussed earlier in Section 4. Recall that the similarity matrix consists of n = 2435 reviewers and d = 935 papers. In the following experiments, we run a simulation using a default model conﬁguration, then we explore the impact of changing components of the model, and we ﬁnish by exploring the robustness of the algorithm to various real-world complexities.
Default model conﬁguration. We begin by evaluating a default model conﬁguration that is considered throughout the the remainder of the experiments unless otherwise speciﬁed. The model consists of the paper-side gain function γp(gj) = min{gj, 6}, the reviewer-side gain function γr(πi(j), Si,j) = (2Si,j − 1)/ log2(πi(j) + 1), and the bidding probability model f (πi(j), Si,j) = Si,j/ log2(πi(j) + 1). We remark that the paper-side gain function is a natural choice given that conferences often assign three reviewers to each paper and as such they may seek twice the number of bids per paper. Moreover, recall that for this pair of reviewer-side gain and bidding functions, the efﬁcient routine in Algorithm 3 can be called in place of Algorithm 2 in SUPER∗ to retrieve a paper ordering, which is what we implement.
The results of the experiment are presented in Figure 2. In Figures 2a–2b we compare SUPER∗ to each baseline and in Figures 2c–2d we zoom in and only show the results for SUPER∗ and SIM. In terms of the gain results shown in Figures 2a and 2c, each version of SUPER∗ outperforms the baseline algorithms, while BID outperforms SIM when minimal weight λ is given to the reviewer-side gain and vice versa when a signiﬁcant amount of weight λ is given to the reviewer-side gain. In Figures 2b and 2d, the distribution of the bid counts obtained for the algorithms are shown with λ = 0.8, which was chosen since this parameter choice gave nearly equal paper-side and weighted reviewer-side gain for RAND. While BID has a similar number of papers with fewer than the minimum number of desired bids as each version of SUPER∗, the gain demonstrates why it is not a generally adopted method. As a result of showing papers of limited relevance early in the paper orderings to elicit bids on papers with few bids, the overall gain is signiﬁcantly smaller than SIM and SUPER∗ since the reviewer-side gain is worse. The distributions also illustrate that both versions of SUPER∗ end the bidding process with approximately a 60% reduction of the number of papers with fewer than the desired minimum number of bids compared to SIM and RAND.
12

Relative gain

500
400
300
200
100
0 0.0 0.1 0.2 0.3 0.4 0.6 Tradeoﬀ parameter λ
(a)

Number of papers

500

400

300

200

100

0 {0,1,2} {3,4,5} {6,7,8} Number of bids
(b)

{9+}

Relative gain

20
10
0
−10
−20
−30 0.0 0.1 0.2 0.3 0.4 0.6 Tradeoﬀ parameter λ
(c)

Number of papers

500

400

300

200

100

0 {0,1,2} {3,4,5} {6,7,8} Number of bids
(d)

{9+}

Number of papers

2000 600
1500
400 1000

500

200

0 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 Tradeoﬀ parameter λ
(e)

0 {0,1,2} {3,4,5} {6,7,8} Number of bids
(f)

{9+}

Relative gain

600
400
200
0 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 Tradeoﬀ parameter λ
(g)

Number of papers

500

400

300

200

100

0 {0,1,2} {3,4,5} {6,7,8} Number of bids
(h)

{9+}

Relative gain

Figure 3: ICLR 2018 experiment with variations of the default model conﬁguration. In Figures 3a–3d, the paper-side gain function is changed. In Figures 3e–3h, the reviewer-side gain and bidding function are changed. Legend for each bid distribution plot (b, d, f, h): within each bid-count interval, the bars correspond to the algorithms given in the legend and are presented in an order consistent with the legend itself when read from left to right and (d, h) only includes SUPER∗ with mean heuristic, SUPER∗ with zero heuristic, and SIM.
Vreasruyltisngaremsohdoewl npawrhaemnettheersp. apWere-sindoewgacionnsfiudnecrtivoanriiasticohnasnogfedthferodmefaγupl(tgmj)od=el mcoinn{sigdje,r6a}tiotno. γpIn(gFj)igu=res√3gaj–. 3Idn, Figures 3a–3b we compare SUPER∗ to each baseline and in Figures 3c–3d we zoom in and only show the results for SUPER∗ and SIM. In Figures 3b and 3d, the distribution of the bid counts obtained for the algorithms are shown with λ = 0.4, which was chosen since this parameter choice gave nearly equal paper-side and weighted reviewer-side gain for RAND. For this model conﬁguration, BID and RAND are signiﬁcantly suboptimal in terms of the gain. SUPER∗ with the mean heuristic outperforms SIM by a marginal amount in terms of the gain, while SIM outperforms SUPER∗ with the zero heuristic by a marginal amount in terms of the gain. The bid distributions show that each version of SUPER∗ ends the bidding process with a smaller number of papers obtaining fewer than six bids compared to SIM. Compared to the default paper-side gain function, the discrepancy is not as signiﬁcant since SUPER∗ is optimizing an objective that rewards getting more than ﬁve bids per paper even though the returns are diminishing.
In Figures 3a–3d, the default paper-side gain function is considered, but the reviewer-side gain function is changed to γr(πi(j), Si,j) = (2Si,j − 1)/ πi(j) and the bidding function is changed to f (πi(j), Si,j) = Si,j/ πi(j). The effect of this change is that the probability of obtaining a bid on a paper from a reviewer decays faster with the position the paper is shown and similarly the reviewer-side gain from a paper diminishes faster as a function of the position the paper is shown to a reviewer. In Figures 3e–3f we compare SUPER∗ to each baseline and in Figures 3g–3h we zoom in and only show the results for SUPER∗ and SIM. In Figures 3f and 3h, the distribution of the bid counts obtained for the algorithms are shown with λ = 1.2, which was chosen since this parameter choice gave nearly equal paperside and weighted reviewer-side gain for RAND. For this model conﬁguration, each version of SUPER∗ signiﬁcantly outperforms each of the baselines in terms of the gain. The bid count distributions show SUPER∗ with zero and mean heuristic reduce the number of papers with fewer than three bids by 35% and 60% compared to SIM, respectively. Moreover, both versions of SUPER∗ end up with half as many papers obtaining fewer than six bids compared to BID.

13

Relative gain

Bid probability mismatch Similarity mismatch Subset of reviewers arrive Concurrent arrivals Subset of papers bid on

1250
1000
750
500
250
0 0.0 0.2 0.4 0.6 0.8 1.0 Tradeoﬀ parameter λ
(a)

Relative gain

800
600
400
200
0 0.0 0.2 0.4 0.6 0.8 1.0 Tradeoﬀ parameter λ
(b)

Relative gain

600
400
200
0 0.0 0.2 0.4 0.6 0.8 1.0 Tradeoﬀ parameter λ
(c)

Relative gain

800
600
400
200
0 0.0 0.2 0.4 0.6 0.8 1.0 Tradeoﬀ parameter λ
(d)

Relative gain

600
400
200
0 0.0 0.2 0.4 0.6 0.8 1.0 Tradeoﬀ parameter λ
(e)

600

400

200

0 {0,1,2} {3,4,5} {6,7,8} Number of bids

{9+}

(f)

Number of papers

500

400

300

200

100

0 {0,1,2} {3,4,5} {6,7,8} Number of bids

{9+}

(g)

Number of papers

400

300

200

100

0 {0,1,2} {3,4,5} {6,7,8} Number of bids

{9+}

(h)

Number of papers

500

400

300

200

100

0 {0,1,2} {3,4,5} {6,7,8} Number of bids

{9+}

(i)

Number of papers

500

400

300

200

100

0 {0,1,2} {3,4,5} {6,7,8} Number of bids

{9+}

(j)

Number of papers

Figure 4: ICLR 2018 experiments of robustness to real-world complexities. Legend for each bid distribution plot (f)–(j): within each bid-count interval, the bars correspond to the algorithms given in the legend and are presented in an order consistent with the legend itself when read from left to right.
Robustness to real-world complexities. The previous experiments were performed under settings faithful to the model described earlier in Section 2. We now evaluate the robustness of SUPER∗ to the models by evaluating the performance under various vagaries and complexities of real-world peer review. For this set of experiments, we consider that SUPER∗ is optimizing the default model conﬁguration described previously in this section. The results of the following simulations that consider deviations from the model being optimized are given in Figure 4. For each experiment we show the gains of each of the algorithms relative to RAND across a sweep of the parameter λ and the bid count distributions for each of algorithms with λ = 0.8 as selected for the default model previously.
We begin looking at model mismatch for the bidding function. In Figures 4a and 4f, the situation is considered in which the actual bids are performed under the bidding function f (πi(j), Si,j) = Si,j/ πi(j), whereas SUPER∗ assumes f (πi(j), Si,j) = Si,j/ log2(πi(j) + 1). The results show each version of SUPER∗ is robust to this deviation and outperforms the baselines in terms of the gain. Moreover, SUPER∗ with zero heuristic is especially robust since it is not as dependent on the model of bids as SUPER∗ with mean heuristic. The bid count distributions show that SUPER∗ with mean heuristic reduces the number of papers with fewer than three bids by 85% relative to SIM, and SUPER∗ with zero heuristic reduces the number of papers with fewer than six bids by 50% compared to BID. In Figures 4b and 4g, we consider that the probability of a reviewer bidding on a paper is actually given by f (πi(j), Si,j) = (Si,j + N (0, σ2))/ log2(πi(j) + 1) where σ = 0.01 and we remark that the mean of the similarity scores is approximately 0.03 so the noise magnitude is not insigniﬁcant. We clip the noisy bid probabilities to guarantee that they remain in the interval [0, 1]. We observe that SUPER∗ is again robust to this model mismatch and outperforms the baselines in terms of the gain and each version ends up reducing the fewer the number of papers having below the minimum desired number of bids by approximately 60% compared to SIM and RAND.
In practice, not all reviewers may participate in the bidding process. We consider that only three quarters of the reviewers arrive, but this is unknown a priori to the algorithms. This proportion is roughly based on the number of reviewers that were found to not place any positive bids during the NeurIPS 2016 review process (Shah et al., 2018b). The results under this real-world complexity are shown in Figures 4c and 4h. Moreover, reviewers may not actually arrive sequentially. Figures 4d and 4i consider the setting where Poisson(1) reviewers arrive at each time, and the algorithm must present paper orderings to all these reviewers simultaneously. For this pair of real-world complexities, SUPER∗ remains quite robust and generally performs favorably compared to the baselines in terms of both the gain and the bid count distributions. It is worth noting that when not all reviewers arrive, SUPER∗ with zero heuristic
14

Relative gain

Homogeneous

Low rank

Community

Interdisciplinary

1500

1000

500

0

250

500

750

1000

Number of reviewers and papers

(a)

Relative gain

600

400

200

0

250

500

750

1000

Number of reviewers and papers

(b)

Relative gain

4000

3000

2000

1000

0

250

500

750

1000

Number of reviewers and papers

(c)

Relative gain

800

600

400

200

0

250

500

750

1000

Number of reviewers and papers

(d)

500

400

300

200

100

0 {0,1,2} {3,4,5} {6,7,8} Number of bids
(e)

{9+}

Number of papers

400

300

200

100

0 {0,1,2} {3,4,5} {6,7,8} Number of bids
(f)

{9+}

Number of papers

400

300

200

100

0 {0,1,2} {3,4,5} {6,7,8} Number of bids
(g)

{9+}

Number of papers

80

60

40

20

0 {0,1,2} {3,4,5} {6,7,8} Number of bids
(h)

{9+}

Number of papers

Figure 5: Experiments on synthetic similarity scores under the default model conﬁguration. Legend for each bid distribution plot (e)–(h): within each bid-count interval, the bars correspond to the algorithms given in the legend and are presented in an order consistent with the legend itself when read from left to right.
outperforms SUPER∗ with zero heuristic since it does attempt to account for bids that may come from reviewers that have not arrived.
A common feature in peer review bidding systems is the ability for a reviewer to search papers by subject area or keyword and then only bid within the resulting subset of papers. We now evaluate the robustness of SUPER∗ to this type of reviewer behavior in the following manner. In our simulations, on arrival of any reviewer, one quarter of the papers are randomly selected and required to be shown to the reviewer (these are the papers that are assumed to meet the search query). The remaining papers are not presented to the reviewer, are bid on with probability zero, and do not factor into the reviewer-side gain. The algorithms compute the paper orderings over only the selected subset of papers. The results of this experiment are shown in Figures 4e and 4j. We observe that SUPER∗ with zero heuristic outperforms the rest of the algorithms in terms of the gain while obtaining a favorable bid distribution. SUPER∗ with mean heuristic is not quite as robust since fewer bids come from future reviewers than anticipated when computing the mean heuristic – if one has estimates of the amount of selection done by reviewers via search, then this issue may be mitigated by appropriately scaling down the heuristic value.
5.2 Synthetic Similarities
We perform several simulations on synthetic similarity scores comparing the algorithms as presented in Figure 5. For this set of simulations, we consider the default model conﬁguration from the previous section. Moreover, for each similarity structure we let the number of reviewers and the number of papers (n, d) be among the set of pairs {(250, 250), (500, 500), (750, 750), (1000, 1000)} and ﬁx the trade-off parameter to be λ = 0.8 since this gave roughly equal paper-side and weighted reviewer-side gains for RAND with n = d = 750.
Homogeneous similarity scores. We consider a synthetic similarity matrix structure where each entry is drawn from at random from a Beta distribution with parameters α = 1 and β = 15. This distribution is highly skewed and the expected value of a draw from it is 0.0625. The results of this experiment are given in Figures 5a and 5e. The
15

gain of SUPER∗ with each heuristic exceeds that of each of the baselines and similarly the bid count distributions show SUPER∗ with each heuristic ends up with at least 50% fewer papers obtaining under the minimum desired by the paper-side gain function compared to the baselines. We tried other homogeneous similarity structures and observed similar trends throughout.
Low rank structure. We experimented with the following low rank structure to generate the similarity scores. The similarity matrix is split into 10 groups of reviewers which correspond to a block of rows in the matrix. The similarity scores for block ∈ {1, . . . , 10} are given by the rank-1 matrix u(v ) where u is a n/10-dimensional vector of ones and v is a d-dimensional vector with each entry drawn at random from a Beta distribution with parameters α = and β = 60. This set of parameter choices for the distribution was made so that the scores were near the scale of the ICLR similarity matrix and to create a disparity in similarity scores between the blocks. Combining the blocks forms a similarity matrix of rank 10 where within each block the reviewers are identical and between the blocks the similarity score distribution changes. The structure can be viewed as if there are 10 types of reviewers with varying levels of relevance to the papers. The result of the experiment with this similarity matrix structure is shown in Figures 5b and 5f. We again see that SUPER∗ with each heuristic outperforms the baselines in terms of the gain and they obtain a favorable distribution of the bid counts with a 50% reduction in the number of papers with fewer than six bids compared to SIM and RAND.
Community model structure. We now consider a community model type block structure as motivated in Section 4. To form this similarity matrix, we create a block matrix where each submatrix is of dimension 25 × 25. The similarity score of each entry in the submatrix ( , k) is 0 if = k and 0.7 if = k. In other words the matrix is block diagonal. We then add noise to each similarity score drawn uniformly at random from the interval [0, 0.05]. The results are given in Figures 5c and 5g. BID and RAND are highly suboptimal in terms of the gain and bid count distribution since they end up showing papers with similarity scores near zero early in the paper orderings even if later on there are reviewers to arrive which are closely matched to the papers. Remarkably, SUPER∗ with each heuristic reduces the number of papers with fewer than the minimum number of desired bids by at least 90% compared to BID and RAND. Moreover, SUPER∗ with each heuristic outperforms SIM in terms of the gain and reduces the number of papers with fewer than six bids by over 60%. This happens since for papers with close similarity scores, SUPER∗ shows the paper with fewer bids ahead if the similarity score is only marginally smaller.
Interdisciplinary papers. To conclude our simulations, we consider the impact our algorithm could have on interdisciplinary papers. As mentioned in Section 1, such papers face additional challenges in the peer review process owing to the lack of ideally matched peers. To simulate this phenomena, we consider a similarity matrix structure where there are two groups of reviewers of equal size and then three groups of papers which make up 40%, 40%, and 20% of the papers, respectively. Each reviewer in group one has similarity scores of 0.17, 0.005, and 0.085 with the respective paper groups and each reviewer in group two has similarity scores of 0.005, 0.17, and 0.085 with the respective paper groups. This reﬂects a scenario where the reviewer pool has two distinct areas of expertise and there is a set of interdisciplinary papers (paper group with similarity score of 0.075 with all reviewers). We show the results of the experiment in Figures 5d and 5h. In terms of the gain, SUPER∗ and SIM perform signiﬁcantly outperform BID and RAND. For the bid count distribution in Figure 5h, we only consider the interdisciplinary papers. SUPER∗ with each heuristic mitigates negative impacts on the interdisciplinary papers as the number with an insufﬁcient number of bids is curtailed by 65% and 50% compared to SIM and RAND. This is a result of the fact that SUPER∗ works to trade-off the paper-side and reviewer-side objectives so the interdisciplinary papers end up not always being shown after the papers matching the reviewers expertise as occurs for SIM.
6 Discussion
This work develops a principled framework to improve bidding in peer review. We develop a sequential decisionmaking algorithm called SUPER∗ to optimize the process and show that it empirically outperforms baseline methods on real conference data and has several compelling theoretical guarantees.
This work leads to several interesting and potentially impactful open problems:
• An obvious open problem is that of developing an online algorithm that is globally optimal for every similarity matrix. Conversely, showing possible computational hardness of the problem as a negative result could be a path of future work.
• In several automated reviewer-paper assignment methods, bids and and similarities are combined to form the
16

scores used to compute the assignment (Shah et al., 2018b). Given the tight connection between the bidding and matching systems, it is natural to design methods for jointly optimizing the components that govern the assignment process.
• Finally, given the online nature of reviewer arrivals and the need to immediately show the paper ordering to an arriving reviewer, it is of interest to solve the passive problem. That is, develop an algorithm which selects the paper orderings to present to each reviewer before any of the reviewers arrive, which can be presented to a reviewer in the event of insufﬁcient computational time. We also think that a solution to the passive problem would serve as an effective heuristic function for SUPER∗.
Although our work primarily focuses on peer review, there are a number of other applications for which this work is relevant. One such application is crowdsourcing, where a common goal of the crowdsourcing platform is to ensure that each task gets sufﬁciently many qualiﬁed workers. From the perspective of the worker, it has been documented quite extensively that workers put a non-trivial emphasis on a task if it is of interest to them (Kaufmann et al., 2011; Hossain, 2012). This means there is a trade-off of ensuring each worker is satisﬁed while ensuring a minimum number of workers for each job. As such, it is reasonable to formulate the crowdsourcing problem as a multi-objective optimization problem using analogous approach to the one presented in this paper for the bidding process in peer review. Indeed, the crowdsourcing platform in this formulation seeks to optimize both for a task-side objective, which ensures each task gets a sufﬁcient number of workers selecting it, and for a user-side objective, which is to present relevant tasks to users.
Another potentially viable application is crowdfunding and microlending platforms such as Kiva or KickStarter. In crowdfunding, users pledge toward funding a project, and the project is only funded if the cumulative contributions of the crowd meet a known target threshold. The platforms seek to maximize the number of funded projects by deciding, when, how often, and to which users the projects are displayed. Past work (Jain and Jamieson, 2018) has modeled the optimization as a multi-armed bandit problem where the goal is to maximize the number of funded projects with a minimum amount of user impressions. This problem has a fundamental trade-off between showing relevant projects to users while ensuring that the projects themselves are given a fair shot to be funded. As such, a model-dependent approach such of ours could be of potential interest.
A ﬁnal potential application outside of peer review for our work is in recommender systems and online advertising where there is the common trade-off between exploration (gaining sufﬁcient feedback on all items) and exploitation (showing the most relevant items to users). In recommender systems, the cold start problem refers to the situation where the system is just beginning to interact with users or items are freshly included in the catalogue and no past user interaction information is available. The common trade-off arises again where there is a need to show relevant items to users, while the system beneﬁts from gaining feedback on items for which the utility is unknown. Our framework easily adapts to a changing action set and could be relevant to this task.
Acknowledgments
This work was supported by NSF grants CIF 1763734, CAREER: CIF 1942124 and CRII: CIF 1755656. Tanner Fiez was also supported by the DoD NDSEG Fellowship Program.
References
D. Agarwal, B.-C. Chen, P. Elango, and X. Wang. Click shaping to optimize multiple objectives. In SIGKDD, pages 132–140, 2011.
N. Ailon, M. Charikar, and A. Newman. Aggregating inconsistent information: ranking and clustering. Journal of the ACM (JACM), 55(5):23, 2008.
G. Aslanyan and U. Porwal. Position bias estimation for unbiased learning-to-rank in ecommerce search. In ACM International Symposium on String Processing and Information Retrieval, pages 47–64. Springer, 2019.
H. Aziz, O. Lev, N. Mattei, J. S. Rosenschein, and T. Walsh. Strategyproof peer selection using randomization, partitioning, and apportionment. Artiﬁcial Intelligence, 275:295–309, 2019.
17

F. Bianchi and F. Squazzoni. Is three better than one? simulating the effect of reviewer selection and behavior on the quality and efﬁciency of peer review. In Winter Simulation Conference, pages 4081–4089. IEEE, 2015.
N. Black, S. Van Rooyen, F. Godlee, R. Smith, and S. Evans. What makes a good reviewer and a good review for a general medical journal? Journal of the American Medical Association, 280(3):231–233, 1998.
R. Burkard, M. Dell’Amico, and S. Martello. Assignment problems, revised reprint, volume 106. SIAM, 2012.
G. Cabanac and T. Preuss. Capitalizing on order effects in the bids of peer-reviewed conferences to secure reviews by expert referees. Journal of the American Society for Information Science and Technology, 64(2):405–415, 2013.
Z. Cao, T. Qin, T.-Y. Liu, M.-F. Tsai, and H. Li. Learning to rank: from pairwise approach to listwise approach. In ICML, pages 129–136, 2007.
L. Charlin and R. Zemel. The toronto paper matching system: an automated paper-reviewer assignment system. In ICML Workshop on Peer Reviewing and Publishing Models, 2013.
A. Chuklin, I. Markov, and M. d. Rijke. Click models for web search. Synthesis Lectures on Information Concepts, Retrieval, and Services, 7(3):1–115, 2015.
K. Church. Reviewing the reviewers. Computational Linguistics, 31(4):575–578, 2005.
I. S. Dhillon. Co-clustering documents and words using bipartite spectral graph partitioning. In SIGKDD, pages 269–274, 2001.
N. Di Mauro, T. M. Basile, and S. Ferilli. Grape: An expert review assignment component for scientiﬁc conference management systems. In International conference on industrial, engineering and other applications of applied intelligent systems, pages 789–798. Springer, 2005.
W. Ding, N. B. Shah, and W. Wang. On the privacy-utility tradeoff in peer-review data analysis. arXiv:2006.16385, 2020.
T. Fiez, N. Shah, and L. Ratliff. A super* algorithm to optimize paper bidding in peer review. In ICML workshop on Real-world Sequential Decision Making: Reinforcement Learning And Beyond, 2019.
N. Garg, T. Kavitha, A. Kumar, K. Mehlhorn, and J. Mestre. Assigning papers to referees. Algorithmica, 58(1): 119–136, Sep 2010.
M. Girvan and M. E. Newman. Community structure in social and biological networks. Proceedings of the national academy of sciences, 99(12):7821–7826, 2002.
P. Hart, N. Nilsson, and B. Raphael. A formal basis for the heuristic determination of minimum cost paths. IEEE Trans. Systems Science and Cybernetics, 4(2):100–107, 1968.
M. Hossain. Users’ motivation to participate in online crowdsourcing platforms. In International Conference on Innovation Management and Technology Research, pages 310–315. IEEE, 2012.
L. Jain and K. Jamieson. Firing bandits: Optimizing crowdfunding. In ICML, pages 2206–2214, 2018.
T. Jambor and J. Wang. Optimizing multiple objectives in collaborative ﬁltering. In RecSys, pages 55–62, 01 2010.
K. Ja¨rvelin and J. Keka¨la¨inen. IR evaluation methods for retrieving highly relevant documents. In ACM SIGIR, pages 41–48, 2000.
S. Jecmen, H. Zhang, R. Liu, N. B. Shah, V. Conitzer, and F. Fang. Mitigating manipulation in peer review via randomized reviewer assignments. In ICML Workshop on Incentives in Machine Learning, 2020.
D. Kang, W. Ammar, B. Dalvi, M. van Zuylen, S. Kohlmeier, E. Hovy, and R. Schwartz. A dataset of peer reviews (peerread): Collection, insights and nlp applications. arXiv:1804.09635, 2018.
M. Karimzadehgan, C. Zhai, and G. Belford. Multi-aspect expertise matching for review assignment. In Conference on Information and knowledge management, pages 1113–1122, 2008.
18

N. Kaufmann, T. Schulze, and D. Veit. More than fun and money. worker motivation in crowdsourcing-a study on mechanical turk. In Americas Conference on Information Systems, volume 11, pages 1–11, 2011.
A. Kobren, B. Saha, and A. McCallum. Paper matching with local fairness constraints. In SIGKDD, 2019.
E. L. Lawler. Combinatorial optimization, 1976.
N. Lawrence and C. Cortes. The nips experiment. http://inverseprobability.com/2014/12/16/ the-nips-experiment, 2014.
J. W. Lian, N. Mattei, R. Noble, and T. Walsh. The conference paper assignment problem: Using order weighted averages to assign indivisible goods. In AAAI, 2018.
C. Long, R. C.-W. Wong, Y. Peng, and L. Ye. On good and fair paper-reviewer assignment. In International Conference on Data Mining, pages 1145–1150. IEEE, 2013.
R. Meir, J. Lang, J. Lesca, N. Kaminsky, and N. Mattei. A market-inspired bidding scheme for peer review paper assignment. In Games, Agents, and Incentives Workshop at AAMAS, 2020.
M. Momma, A. B. Garakani, and Y. Sun. Multi-objective relevance ranking. In SIGIR 2019 eCom, 2019.
A. Mulligan, L. Hall, and E. Raphael. Peer review in a changing world: An international study measuring the attitudes of researchers. Journal of the American Society for Information Science and Technology, 64(1):132–161, 2013.
J. Murphy, C. Hofacker, and R. Mizerski. Primacy and recency effects on clicking behavior. Journal of ComputerMediated Communication, 11(2):522–535, 2006.
M. E. Newman. The structure of scientiﬁc collaboration networks. Proceedings of the national academy of sciences, 98(2):404–409, 2001.
M. E. Newman and M. Girvan. Finding and evaluating community structure in networks. Physical review E, 69(2): 026113, 2004.
R. Noothigattu, N. Shah, and A. Procaccia. Loss functions, axioms, and peer review. In ICML Workshop on Incentives in Machine Learning, 2018.
A. L. Porter and F. A. Rossini. Peer review of interdisciplinary research proposals. Science, technology, & human values, 10(3):33–38, 1985.
M. A. Porter, J.-P. Onnela, and P. J. Mucha. Communities in networks. Notices of the AMS, 56(9):1082–1097, 2009.
S. Price and P. A. Flach. Computational support for academic peer review: a perspective from artiﬁcial intelligence. Communications of the ACM, 60(3):70–79, 2017.
S. Price, P. A. Flach, and S. Spiegler. Subsift: a novel application of the vector space model to support the academic research process. In Workshop on Applications of Pattern Analysis, pages 20–27, 2010.
M. Rodriguez, C. Posse, and E. Zhang. Multiple objective optimization in recommender systems. In RecSys, pages 11–18, 2012.
M. A. Rodriguez, J. Bollen, and H. Van de Sompel. Mapping the bid behavior of conference referees. Journal of Informetrics, 1(1):68–82, 2007.
M. Roos, J. Rothe, J. Rudolph, B. Scheuermann, and D. Stoyan. A statistical approach to calibrating the scores of biased reviewers: The linear vs. the nonlinear model. In 6th Multidisciplinary Workshop on Advances in Preference Handling, 2012.
N. Shah, S. Balakrishnan, A. Guntuboyina, and M. Wainwright. Stochastically transitive models for pairwise comparisons: Statistical and computational issues. In ICML, pages 11–20, 2016.
N. B. Shah, B. Tabibian, K. Muandet, I. Guyon, and U. Von Luxburg. Design and analysis of the NIPS 2016 review process. The Journal of Machine Learning Research, 19(1):1913–1946, 2018a.
19

N. B. Shah, B. Tabibian, K. Muandet, I. Guyon, and U. Von Luxburg. Design and analysis of the nips 2016 review process. JMLR, 19(1):1913–1946, 2018b.
A. Singh and T. Joachims. Policy learning for fairness in ranking. In NeurIPS, pages 5427–5437, 2019.
I. Stelmakh, N. Shah, and A. Singh. On testing for biases in peer review. In NeurIPS, 2019a.
I. Stelmakh, N. B. Shah, and A. Singh. Peerreview4all: Fair and accurate reviewer assignment in peer review. In ALT, pages 828–856, 2019b.
I. Stelmakh, N. Shah, and A. Singh. Catch me if i can: Detecting strategic behaviour in peer assessment. In ICML Workshop on Incentives in Machine Learning, 2020a.
I. Stelmakh, N. Shah, A. Singh, and H. Daum III. Prior and prejudice: The bias against resubmissions in conference peer review. arXiv, 2020b.
K. Svore, M. Volkovs, and C. Burges. Learning to rank with multiple objective functions. In WWW, pages 367–376, 03 2011.
W. Tang, J. Tang, and C. Tan. Expertise matching via constraint-based optimization. In International Conference on Web Intelligence and Intelligent Agent Technology, volume 1, pages 34–41. IEEE, 2010.
S. Thurner and R. Hanel. Peer-review in a world with rational scientists: Toward selection of the average. The European Physical Journal B, 84(4):707–711, 2011.
A. Tomkins, M. Zhang, and W. D. Heavlin. Reviewer bias in single-versus double-blind peer review. Proceedings of the National Academy of Sciences, 114(48):12708–12713, 2017.
G. D. L. Travis and H. M. Collins. New light on old boys: Cognitive and institutional particularism in the peer review system. Science, Technology, & Human Values, 16(3):322–341, 1991.
J. Wang and N. B. Shah. Your 2 is my 1, your 3 is my 9: Handling arbitrary miscalibrations in ratings. In AAMAS, pages 864–872, 2019.
M. Ware. Peer review in scholarly journals: Perspective of the scholarly community–results from an international study. Information Services & Use, 28(2):109–112, 2008.
J. Wing. Yes, computer scientists are hypercritical. Communications of the ACM, 2011.
Y. Xu, H. Zhao, X. Shi, and N. Shah. On strategyproof conference review. In IJCAI, pages 616–622, 2019.
H. Yadav, Z. Du, and T. Joachims. Fair learning-to-rank from implicit feedback. arXiv:1911.08054, 2019.

Appendices

Table of Contents

A Proofs

21

A.1 Proof of Theorem 1: Local Optimality of SUPER∗ for Final Reviewer . . . . . . . . . . . . . . . . . 21

A.2 Proof of Corollary 1: Local Optimality of SUPER∗ for Any Reviewer . . . . . . . . . . . . . . . . . 23

A.3 Proof of Theorem 2: Suboptimality of Baselines for Final Reviewer . . . . . . . . . . . . . . . . . . 24

A.3.1 Notation and Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24

A.3.2 Suboptimality of SIM for Final Reviewer . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25

A.3.3 Suboptimality of BID for Final Reviewer . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29

A.3.4 Suboptimality of RAND for Final Reviewer . . . . . . . . . . . . . . . . . . . . . . . . . . . 31

A.3.5 Proofs of Lemmas 1–7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33

20

A.4 Proof of Theorem 3: Noiseless Community Model Result . . . . . . . . . . . . . . . . . . . . . . . . 39 A.4.1 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 A.4.2 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 A.4.3 Optimal Policy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 A.4.4 Optimality of SUPER∗ with Zero Heuristic . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 A.4.5 Optimality of SIM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 A.4.6 Suboptimality of BID . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 A.4.7 Suboptimality of RAND . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47 A.4.8 Proofs of Lemmas 8–10 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
A.5 Proof of Theorem 4: Noisy Community Model Result . . . . . . . . . . . . . . . . . . . . . . . . . . 51 A.5.1 Notation and Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 A.5.2 Analyzing SUPER∗ with Zero Heuristic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 A.5.3 Suboptimality of SIM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54 A.5.4 Suboptimality of BID . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56 A.5.5 Suboptimality of RAND . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60 A.5.6 Near-Optimality of SUPER∗ with Zero Heuristic . . . . . . . . . . . . . . . . . . . . . . . . 61 A.5.7 Proofs of Lemmas 14–15 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62

B Additional Results

65

B.1 Time Complexity of SUPER∗ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65

B.2 SUPER∗ Optimality for Linear Paper-Side Gain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66

A Proofs
In this section, we present proofs of the theoretical results presented in the main text. We begin by formally deﬁning the history of information available to an algorithm when a reviewer arrives and restating important notation that will be found throughout the proofs.
Deﬁnition 1 (History). The history of information available to an algorithm when reviewer i ∈ [n] arrives is deﬁned as Hi−1 = {π , b : = 1, . . . , i − 1}, where π ∈ Πd is the paper ordering that was presented to reviewer and b ∈ {0, 1}d contains the bid realizations on each paper from reviewer .
Notation. We let d ≥ 2 denote the number of papers and n ≥ 2 denote the number of reviewers. We use the notation Si,j ∈ [0, 1] to denote the given similarity score between any reviewer i ∈ [n] and paper j ∈ [d]. In general, we let i index a reviewer and j index a paper. We commonly use the set notation [κ] = {1, 2, . . . , κ} for any positive integer κ. Πd denotes the set of d! permutations of d papers. For any reviewer i ∈ [n], we let πi ∈ Πd denote the ordering (permutation) of the papers shown to reviewer i. We use the notation πi(j) to denote the position of paper j ∈ [d] in the ordering πi. The notation Bi,j represents the random variable of reviewer i ∈ [n] biding on paper j ∈ [d] which follows a Bernoulli distribution with parameter pi,j = f (πi(j), Si,j). We use the notation gi−1,j ∈ {0, . . . , i − 1} to denote the number of bids received by any paper j ∈ [d] at the time of arrival of reviewer i ∈ [n] and gj to denote the number of bids at the end of the bidding process on paper j ∈ [d]. The heuristic estimating the number of bids paper j ∈ [d] will obtain from reviewers {i + 1, . . . , n} is denoted as hi,j and it is provided to the SUPER∗ algorithm on arrival of reviewer i ∈ [n]. Finally, we abbreviate ‘with probability’ by w.p and use the terminology almost surely to mean with probability one and almost never to mean with probability zero.

A.1 Proof of Theorem 1: Local Optimality of SUPER∗ for Final Reviewer
In this proof, we show that selecting the optimal ordering to present to the ﬁnal reviewer can be simpliﬁed to a tractable optimization problem. The SUPER∗ algorithm solves exactly this problem to determine an ordering of papers to present the ﬁnal reviewer, and is hence an optimal algorithm for the ﬁnal reviewer.
The optimization problem for the ﬁnal reviewer n to maximize the expected gain conditioned on the history is

max

E[γp(gj)|Hn−1] + λ

E[γr(πi(j), Si,j )|Hn−1]

(9)

πn ∈Πd

j∈[d]

i∈[n] j∈[d]

21

where the expectation is taken over the randomness in the bid to be placed by the reviewer. Conditioned on the history Hn−1, the ﬁnal number of bids on any paper j ∈ [d] given by gj is the sum of the deterministic number of bids prior to the ﬁnal reviewer denoted as gn−1,j and a Bernoulli random variable Bn,j with parameter pn,j = f (πn(j), Sn,j) representing the random bid of the ﬁnal reviewer. We incorporate this fact and remove terms independent of the
optimization variable from the problem in (9) to equivalently obtain

max

E[γp(gn−1,j + Bn,j )] + λ γr(πn(j), Sn,j )

(10)

πn ∈Πd

j∈[d]

j∈[d]

where the expectation on the reviewer-side gain is removed as it is independent of the random reviewer bids. We now simplify the paper-side gain term by expanding the expectation for each j ∈ [d]. Observe that

γp(gn−1,j + Bn,j ) = γp(gn−1,j + 1) w.p. f (πn(j), Sn,j )

γp(gn−1,j )

w.p. 1 − f (πn(j), Sn,j).

Therefore,

E[γp(gn−1,j + Bn,j )] = f (πn(j), Sn,j )(γp(gn−1,j + 1) − γp(gn−1,j )) + γp(gn−1,j ).

(11)

Substituting (11) into (10) and removing the term independent of the optimization variable gives the problem

max

f (πn(j), Sn,j )(γp(gn−1,j + 1) − γp(gn−1,j )) + λ γr(πn(j), Sn,j ).

(12)

πn ∈Πd

j∈[d]

j∈[d]

We now reformulate (12) into the following equivalent integer linear programming problem:

max
x∈Rd×d
s.t.

f (k, Sn,j )(γp(gn−1,j + 1) − γp(gn−1,j ))xj,k + λ

γr(k, Sn,j )xj,k

j∈[d] k∈[d]

j∈[d] k∈[d]

xj,k = 1 ∀ j ∈ [d],
k∈[d]

xj,k = 1 ∀ k ∈ [d],
j∈[d]

xj,k ∈ {0, 1} ∀ j, k ∈ [d].

In this formulation, x is a d × d matrix for which xj,k is an indicator of paper j ∈ [d] being shown at position k ∈ [d]. The constraint k∈[d] xj,k = 1 ∀ j ∈ [d] ensures each paper is included strictly once in the ordering shown to the reviewer. The constraint j∈[d] xj,k = 1 ∀ k ∈ [d] ensures strictly one paper is selected to be shown at each position. The ﬁnal constraint ensures that each index of x is integer valued. This integer linear programming problem is known
as a linear sum assignment problem.
The key step of this proof is to recall that the linear sum assignment problem can be solved as a linear program. Indeed, the ﬁnal constraint ensuring an integer solution can be relaxed to 0 ≤ xj,k ≤ 1 ∀ j, k ∈ [d] and the optimal solution of the relaxed linear program will be the integer optimal solution. This property of the linear sum assignment
problem is a consequence of the relaxed linear program containing a totally unimodular constraint set which guarantees
the optimal solution to be the integral solution (see, e.g., Chapter 4 in Burkard et al., 2012).
The optimization problem arising from recognizing that the integer constraint can be relaxed is given by

max
x∈Rd×d

wj,k xj,k
j∈[d] k∈[d]

(13)

s.t.

xj,k = 1 ∀ j ∈ [d],

xj,k = 1 ∀ k ∈ [d], 0 ≤ xj,k ≤ 1 ∀ j, k ∈ [d],

k∈[d]

j∈[d]

where

wj,k = f (k, Sn,j )(γp(gn−1,j + 1) − γp(gn−1,j )) + λγr(k, Sn,j ) ∀ j, k ∈ [d].

(14)

This formulation shows that the paper ordering for the ﬁnal reviewer that maximizes the expected gain conditioned on the history can be obtained efﬁciently by solving a linear program.

22

Local optimality of SUPER∗ for ﬁnal reviewer. To determine the ordering of papers to show any reviewer i ∈ [n] for the general class of assumed gain and bidding functions, SUPER∗ calls Algorithm 2. Algorithm 2 solves the
optimization problem in (13) using the weights

wj,k = f (k, Si,j )(γp(gi−1,j + hi,j + 1) − γp(gi−1,j + hi,j )) + λγr(k, Si,j ) ∀ j, k ∈ [d].

(15)

Given any heuristic function, the heuristic for the ﬁnal reviewer is such that hn = 0. This means SUPER∗ selects the paper ordering for the ﬁnal reviewer by solving the optimization problem from (13–14) to maximize the expected gain conditioned on the history. As a result, we conclude SUPER∗ is locally optimal for the ﬁnal reviewer with any
heuristic function.

A.2 Proof of Corollary 1: Local Optimality of SUPER∗ for Any Reviewer
The immediate gain from any reviewer i ∈ [n] is the difference between the gain after and before the reviewer arrived. Formally, the immediate gain from any reviewer i ∈ [n] is given by the quantity

Gi =

γp

j∈[d]

B ,j
∈[i]

− γp

B ,j
∈[i−1]

+ λ γr(πi(j), Si,j),
j∈[d]

where B ,j is a Bernoulli random variable representing the random bid of a reviewer ∈ [n] on a paper j ∈ [d] that depends on the position the paper was shown to the reviewer.
The optimization problem to maximize the immediate expected gain from reviewer i ∈ [n] conditioned on the history (see Deﬁnition 1) is thus given by

max
πi ∈Πd

E γp
j∈[d]

B ,j
∈[i]

− γp

B ,j
∈[i−1]

Hi−1 + λ E[γr(πi(j), Si,j )].
j∈[d]

Since ∈[i−1] B ,j is the deterministic bid count gi−1,j conditioned on the history Hi−1 for each paper j ∈ [d] and the reviewer-side gain from reviewer i ∈ [n] is deterministic given a ﬁxed paper ordering πi ∈ Πd, the previous
optimization problem is equivalently given by

max

E[γp(gi−1,j + Bi,j ) − γp(gi−1,j )] + λ γr(πi(j), Si,j ).

(16)

πi ∈Πd

j∈[d]

j∈[d]

We now evaluate the expectation in (16) using (11) and then simplify to obtain the optimization problem

max

f (πi(j), Si,j )(γp(gi−1,j + 1) − γp(gi−1,j )) + λ γr(πi(j), Si,j ).

(17)

πi ∈Πd

j∈[d]

j∈[d]

The problem in (17) is equivalent to that given in (12) from the proof of Theorem 1 up to the reviewer index. Consequently, we follow the steps after (12) in the proof of Theorem 1 to simplify (17) into a tractable representation. In doing so, we get that the problem in (17) is equivalent to the linear program in (13) with the weights

wj,k = f (k, Si,j )(γp(gi−1,j + 1) − γp(gi−1,j )) + λγr(k, Si,j ) ∀ j, k ∈ [d].
Local optimality of SUPER∗ with zero heuristic for any reviewer. To determine the ordering of papers to show any reviewer i ∈ [n] for the general class of assumed gain and bidding functions, SUPER∗ calls Algorithm 2. Algorithm 2 solves the optimization problem in (13) using the weights

wj,k = f (k, Si,j )(γp(gi−1,j + hi,j + 1) − γp(gi−1,j + hi,j )) + λγr(k, Si,j ) ∀ j, k ∈ [d].
For any reviewer i ∈ [n], given the zero heuristic function, hi = 0 by deﬁnition. This means SUPER∗ with zero heuristic selects the paper ordering for any reviewer by solving the optimization problem to maximize the immediate expected gain conditioned on the history, so we conclude it is locally optimal for any reviewer.

23

A.3 Proof of Theorem 2: Suboptimality of Baselines for Final Reviewer
The organization of this proof is as follows. In Section A.3.1, we present notation and preliminary information common to the analysis for each of the baselines. We prove the suboptimality bounds for the SIM, BID, and RAND baselines separately in Sections A.3.2, A.3.3, and A.3.4, respectively. Combining the results for each of the baselines proves the theorem statement. We conclude in Section A.3.5 with proofs of technical lemmas invoked in the analysis of the baselines.

A.3.1 Notation and Preliminaries

We denote the gain from the ﬁnal reviewer n of an arbitrary algorithm ALG presenting a potentially random paper

ordering πnALG to the reviewer as

GnALG = GpA,LnG + λGrA,LnG.

The paper-side gain from the ﬁnal reviewer GpA,LnG is given by

GpA,LnG =

γp

Bi,j − γp

Bi,j ,

j∈[d]

i∈[n]

i∈[n−1]

where again Bi,j is a Bernoulli random variable representing the random bid of a reviewer i ∈ [n] on a paper j ∈ [d] that depends on the position the paper was shown to the reviewer. The reviewer-side gain from the ﬁnal reviewer GrA,LnG is given by

GrA,LnG =

γ

r

(π

ALG n

(j

),

Sn,j

).

j∈[d]

Accordingly,

GnALG =

γp

Bi,j − γp

Bi,j

j∈[d]

i∈[n]

i∈[n−1]

+λ

γ

r

(π

ALG n

(j

),

Sn,j

).

j∈[d]

The expected gain from the ﬁnal reviewer conditioned on the history of bids and paper orderings Hn−1 (see Deﬁnition 1) is given by
E[GnALG|Hn−1] = E[GpA,LnG|Hn−1] + λE[GrA,LnG|Hn−1]

where the expectation is with respect to the randomness in the algorithm and the bids from the ﬁnal reviewer. Observe

that

E[GpA,LnG|Hn−1] = EπALG n

f (πnALG(j), Sn,j )(γp(gn−1,j + 1) − γp(gn−1,j ))

j∈[d]

since i∈[n−1] Bi,j is the deterministic quantity gn−1,j for each j ∈ [d] conditioned on Hn−1 and Bn,j is a Bernoulli

random variable with parameter pn,j

=

f

(π

ALG n

(j

),

Sn,j

)

for

each

j

∈

[d] given the ﬁxed paper ordering πnALG.

Moreover,

E[GrA,LnG|Hn−1] = EπALG n

γ

r

(π

ALG n

(j

)

,

Sn,j

)

.

j∈[d]

It follows that

E[GnALG|Hn−1] = EπALG n

f (πnALG(j), Sn,j )(γp(gn−1,j + 1) − γp(gn−1,j )) + λ

γ

r

(

π

ALG n

(

j

),

Sn,j

)

.

j∈[d]

j∈[d]

The given biding function can be decomposed into the form

f (πi(j), Si,j) =

Si,j

= Si,j f π(πi(j))

(18)

log2(πi(j) + 1)

where

f π(πi(j)) =

1

log2(πi(j) + 1)

24

denotes the component of the bidding function f that only depends on the paper ordering and is independent of the similarity score. The reviewer-side gain function can similarly be decomposed into the form

γr(πi(j), Si,j ) = (2Si,j − 1)f π(πi(j)).

(19)

Using the decomposed forms of the bidding function and the reviewer-side gain function from (18) and (19), the expected gain from the ﬁnal reviewer n of an arbitrary algorithm ALG is given by

E[GnALG|Hn−1] = E[GpA,LnG|Hn−1] + λE[GrA,LnG|Hn−1]

= EπALG n

Sn,j (γp(gn−1,j + 1) − γp(gn−1,j ))f π(πnALG(j)) + λ (2Sn,j − 1)f π(πnALG(j)) .

j∈[d]

j∈[d]

(20)

The optimal paper ordering for the ﬁnal reviewer is thus given by the solution to the following optimization problem

πn∗ = arg max

αn,j f π(πn(j))

(21)

πn ∈Πd

j∈[d]

where

αn,j = Sn,j (γp(gn−1,j + 1) − γp(gn−1,j )) + λ(2Sn,j − 1) ∀ j ∈ [d].

(22)

The optimal solution to (21) ranks papers in a decreasing order of their corresponding values in {αn,j}j∈[d] since the function f π is decreasing in the decision variable. This observation will be used to obtain an explicit form of πn∗ for each problem we subsequently construct to show the suboptimality of the baselines. From Theorem 1, SUPER∗ with any heuristic is optimal for the ﬁnal reviewer, which means πnSUPER∗ = πn∗ . See that πnSUPER∗ is a non-random quantity
given a deterministic tie-breaking mechanism and the expected gain is independent of the tie-breaking mechanism.
Thus, without loss of generality, we assume ties are broken by the paper indexes in favor of j < j for SUPER∗.
We need to compare the expected gain obtained from the ﬁnal reviewer using the SUPER∗ algorithm presenting the optimal paper ordering πnSUPER∗ = πn∗ with any baseline ALG ∈ {SIM, BID, RAND} presenting a potentially random ordering πnALG. Therefore, we analyze the quantity

E[GnSUPER∗ − GnALG|Hn−1] = E[GpS,UnPER∗ − GpA,LnG|Hn−1] + λE[GrS,UnPER∗ − GrA,LnG|Hn−1]

= EπALG n

Sn,j (γp(gn−1,j

+

1)

−

γ

p

(gn

−

1,j

))(f

π

(π

SUPER∗ n

(

j

))

−

f π(πnALG(j)))

j∈[d]

+λ

(2Sn,j

−

1)(f

π

(π

SUPER∗ n

(

j

))

−

f π(πnALG(j)))

(23)

j∈[d]

for each baseline ALG ∈ {SIM, BID, RAND}. The SIM and BID algorithms are deterministic for the ﬁnal reviewer conditioned on the history, up to the tie-breaking mechanism. The RAND algorithm is random, so the expectation over the paper ordering in (23) is necessary when analyzing RAND. In the remainder of the proof, we analyze SIM, then BID, and ﬁnish with RAND.

A.3.2 Suboptimality of SIM for Final Reviewer
In this section, we prove the worst case performance of the SIM baseline for the ﬁnal reviewer.
Intuition. The SIM algorithm directly optimizes the expected reviewer-side gain since it shows papers in a decreasing order of the similarity scores. Consequently, it obtains the maximum expected reviewer-side gain that can be achieved. However, the algorithm gives no attention to the number of bids on each paper, which play an important role in the expected paper-side gain that can be obtained upon the arrival of the ﬁnal reviewer. This point suggests that SIM may be suboptimal for the combined objective.
To build intuition for when this can occur, consider that there is only a pair of papers j and j . Moreover, suppose paper j has only marginally higher similarity score than paper j , but paper j has signiﬁcantly more bids than paper j . In this scenario, the expected reviewer-side gain of any paper ordering is nearly equal. However, showing paper j ahead of paper j results in signiﬁcantly higher expected paper-side gain owing to the diminishing returns of bids from the paper-side gain function. Since SIM instead shows paper j ahead of paper j , it would be suboptimal. The following construction now generalizes this observation.

25

Construction. We now construct a problem instance that will be used to prove SIM is signiﬁcantly suboptimal for the ﬁnal reviewer in the worst case. Consider the similarity scores for the ﬁnal reviewer to be Sn,j = 1 − 1/(j ) for each paper j ∈ [d], where = (1 + λ)eee and λ ≥ 0 is the ﬁxed and given trade-off parameter. In this construction, the similarity scores for the ﬁnal reviewer are nearly equal, but they are increasing in the paper index. For the time being, assume the number of papers d is even. At the end of this section, we handle when the number of papers d is odd. Let the number of bids on the papers from previous reviewers be

gn−1,j = 0, if j ∈ {1, . . . , d/2} 1, if j ∈ {d/2 + 1, . . . , d}.

The bid counts are such that papers among the top half of the similarity scores obtained a bid in the past, and papers among the bottom half of the similarity scores did not obtain any bids from previous reviewers.
We now derive the explicit form of the optimal paper ordering for the ﬁnal reviewer. Recall from (22) that the weights of the optimization problem for the ﬁnal reviewer given in (21) are deﬁned by

αn,j = Sn,j (γp(gn−1,j + 1) − γp(gn−1,j )) + λ(2Sn,j − 1) ∀ j ∈ [d].

(24)

Moreover,

from

the

structure

of

the

optimization

problem

in

(21),

if

αn,j

>

αn,j

,

then

π

SUPER∗ n

(j

)

<

πnSUPER∗ (j

)

so

that paper j is shown ahead of paper j in the ranking. Observe that αn,j is increasing in the similarity score Sn,j and

decreasing in the number of bids gn−1,j for each j ∈ [d]. Consequently, if a pair of papers j, j ∈ [d] are such that

gn−1,j = gn−1,j

and Sn,j > Sn,j , then αn,j > αn,j

and

in

turn,

π

SUPER n

∗

(j

)

<

πnSUPER∗ (j

).

We now show that in the optimal ordering for this instance, each paper with zero bids is shown ahead of each paper

with a non-zero number of bids. Among the set of papers with zero bids, namely those indexed by {1, . . . , d/2}, the

minimum similarity score Sn,j and minimum weight αn,j occur at j = 1. Among the set of papers with a non-zero

number of bids, namely those indexed by {d/2 + 1, . . . , d}, the maximum similarity score Si,j and maximum weight

αn,j occur at j = d. Thus, if αn,1 − αn,d > 0, then we can conclude each paper with zero bids is shown ahead of

each paper with a non-zero number of bids. To prove this, we need the following lemma, the proof of which can be

found in Section A.3.5.1.

Lemma 1. For γp(x) = √x, any λ ≥ 0, d ≥ 2, and = (1 + λ)eee , it must be that

(γp(1) − γp(0))(1 − 1/ ) − (γp(2) − γp(1))(1 − 1/(d )) + λ(2(1−1/ ) − 2(1−1/(d ))) ≥ 1/2.

(25)

From the given similarity scores and bid counts, and then applying Lemma 1, we obtain αn,1 − αn,d = (γp(1) − γp(0))(1 − 1/ ) − (γp(2) − γp(1))(1 − 1/(d )) + λ(2(1−1/ ) − 2(1−1/(d ))) ≥ 1/2.

Therefore, the optimal paper ordering shows all papers with zero bids ahead of every paper with a non-zero number of bids. Moreover, recall if a pair of papers j, j ∈ [d] are such that gn−1,j = gn−1,j and Sn,j > Sn,j , then αn,j > αn,j . This fact allows us to determine that among each group of papers (zero and non-zero bids), the optimal paper ordering
presents the papers in decreasing order of the similarity scores. Combining the previous conclusions, SUPER∗ shows the optimal paper ordering

SUPER∗

d/2 − j + 1,

if j ∈ {1, . . . , d/2}

πn

(j) = d + d/2 + 1 − j, if j ∈ {d/2 + 1, . . . , d}.

(26)

The SIM algorithm shows papers in a decreasing order of the similarity scores so that πnSIM(j) = d − j + 1 for j ∈ [d]. Observe that for this problem, SUPER∗ shows the papers with zero bids much earlier in the paper ordering than SIM. We now move on to lower bounding (23) for this construction and begin by considering the expected paper-side gain.
Bounding the expected paper-side gain. Substituting the similarity scores, the number of bids on each paper, and the (deterministic) paper orderings presented by each algorithm for this construction into the paper-side component

26

of (23), we obtain

d/2
E[GpS,UnPER∗ − GpS,InM|Hn−1] = (γp(1) − γp(0)) (1 − 1/(j ))(f π(d/2 − j + 1) − f π(d − j + 1))
j=1

d

+ (γp(2) − γp(1))

(1 − 1/(j ))(f π(d + d/2 + 1 − j) − f π(d − j + 1)).

j=d/2+1

Manipulating the indexing of the sum over the last half of the papers gives

d/2
E[GpS,UnPER∗ − GpS,InM|Hn−1] = (γp(1) − γp(0)) (1 − 1/(j ))(f π(d/2 − j + 1) − f π(d − j + 1))
j=1
d/2
+ (γp(2) − γp(1)) (1 − 1/((j + d/2) ))(f π(d − j + 1) − f π(d/2 − j + 1)).
j=1

Noting that (f π(d/2 − j + 1) − f π(d − j + 1)) = −(f π(d − j + 1) − f π(d/2 − j + 1)), we obtain

d/2
E[GpS,UnPER∗ − GpS,InM|Hn−1] = (γp(1) − γp(0)) (1 − 1/(j ))(f π(d/2 − j + 1) − f π(d − j + 1))
j=1
d/2
− (γp(2) − γp(1)) (1 − 1/((j + d/2) ))(f π(d/2 − j + 1) − f π(d − j + 1)).
j=1

For every j ∈ [d/2], we have f π(d/2 − j + 1) − f π(d − j + 1) > 0 since d/2 − j + 1 < d − j + 1 and f π(πi(j)) = 1/ log2(πi(j) + 1) is a decreasing function on the domain R>0. Moreover, for every j ∈ [d/2], 1 − 1/(j ) ≥ 1 − 1/ and 1 − 1/((j + d/2) ) ≤ 1 − 1/(d ), and the given paper-side gain function γp is increasing on the domain R≥0. Thus,
E[GpS,UnPER∗ − GpS,InM|Hn−1] ≥ ((γp(1) − γp(0))(1 − 1/ ) − (γp(2) − γp(1))(1 − 1/(d )))
d/2
(f π(d/2 − j + 1) − f π(d − j + 1)).
j=1

Finally, manipulating the indexing of the sum gives

E[GpS,UnPER∗ − GpS,InM|Hn−1] ≥ ((γp(1) − γp(0))(1 − 1/ ) − (γp(2) − γp(1))(1 − 1/(d )))

d/2

(27)

(f π(j) − f π(j + d/2)).

j=1

We now bound the expected reviewer-side gain including the trade-off parameter λ from (23). The steps that follow are analogous to those exercised in bounding the expected paper-side gain.
Bounding the expected reviewer-side gain. Substituting the values of the similarity scores, the number of bids on each paper, and the (deterministic) paper orderings presented by each algorithm into the reviewer-side component of (23), we obtain

d/2
λE[GrS,UnPER∗ − GrS,InM|Hn−1] = λ (2(1−1/(j )) − 1)(f π(d/2 − j + 1) − f π(d − j + 1))
j=1

d

+λ

(2(1−1/(j )) − 1)(f π(d + d/2 + 1 − j) − f π(d − j + 1)).

j=d/2+1

27

Manipulating the indexing of the sum over the last half of the papers results in

d/2
λE[GrS,UnPER∗ − GrS,InM|Hn−1] = λ (2(1−1/(j )) − 1)(f π(d/2 − j + 1) − f π(d − j + 1))
j=1
d/2
+ λ (2(1−1/((j+d/2) )) − 1)(f π(d − j + 1) − f π(d/2 − j + 1)).
j=1

Noting that f π(d/2 − j + 1) − f π(d − j + 1) = −(f π(d − j + 1) − f π(d/2 − j + 1)), we obtain

d/2
λE[GrS,UnPER∗ − GrA,LnG|Hn−1] = λ (2(1−1/(j )) − 1)(f π(d/2 − j + 1) − f π(d − j + 1))
j=1
d/2
− λ (2(1−1/((j+d/2) )) − 1)(f π(d/2 − j + 1) − f π(d − j + 1)).
j=1

For every j ∈ [d/2], we have f π(d/2 − j + 1) − f π(d − j + 1) > 0 since d/2 − j + 1 < d − j + 1 and f π(πi(j)) =
1/ log2(πi(j) + 1) is a decreasing function on the domain R>0. Furthermore, observe that for every j ∈ [d/2], 1 − 1/(j ) ≥ 1 − 1/( ) and 1 − 1/((j + d/2) ) ≤ 1 − 1/(d ). This set of facts leads to the bound

λE[GrS,UnPER∗ − GrS,InM|Hn−1] ≥ λ 2(1−1/ ) − 2(1−1/(d ))

d/2
(f π(d/2 − j + 1) − f π(d − j + 1)).
j=1

To ﬁnish this sequence of steps, we manipulate the indexing of the sum to conclude

E[GrS,UnPER∗ − GrS,InM|Hn−1] ≥ λ 2(1−1/ ) − 2(1−1/(d ))

d/2
(f π(j) − f π(j + d/2)).
j=1

(28)

Completing the lower bound. Combining the bounds on the expected paper-side and reviewer-side gain terms from (27) and (28), we obtain an initial lower bound given by

d/2

E[GnSUPER∗ − GnSIM|Hn−1] ≥ C (f π(j) − f π(j + d/2)),

(29)

j=1

where for ease of notation we deﬁne

C = (γp(1) − γp(0))(1 − 1/ ) − (γp(2) − γp(1))(1 − 1/(d )) + λ(2(1−1/ ) − 2(1−1/(d ))).

(30)

We apply Lemma 1 to get that C ≥ 1/2. The following lemma, the proof of which can be found in Section A.3.5.2, provides a bound on the sum in (29).
Lemma 2. Let f π(x) = 1/ log2(x + 1). Fix d to be an even integer such that d ≥ 2. Then,

d/2

(f π(j) − f π(j + d/2)) ≥

d .

j=1

16

log

2 2

(

d)

From (29) along with the fact that C ≥ 1/2 and Lemma 2, we obtain

E[GSUPER∗ − GSIM|Hn−1] ≥

d .

(31)

n

n

32

log

2 2

(d

)

Lemma 2, and consequently the bound in (31), are applicable when d is even. The following lemma shows that
an equivalent result (up to constants) holds when the number of papers d is odd. The bound is obtained by looking at an identical problem construction for d = d − 1 papers, and then including an additional paper that has a similarity score of zero with the ﬁnal reviewer and one previous bid. This change is such that both SUPER∗ and SIM show the
additional paper last, and moreover, the expected gain from paper d is zero since the similarity score is zero.

28

Lemma 3. If d is odd, then in the worst case for the ﬁnal reviewer under the assumptions of Theorem 2,

E[GSUPER∗ − GSIM|Hn−1] ≥

d .

n

n

64

log

2 2

(d

)

The proof of Lemma 3 is in Section A.3.5.3. Combining the bound from (31) which holds for d even with the bound from Lemma 3 which holds for d odd, we
ﬁnd that for every d ≥ 2 and λ ≥ 0,

E[GSUPER∗ − GSIM|Hn−1] ≥

d .

n

n

64

log

2 2

(d

)

This proves the claim in Theorem 2 stating that there exists a constant c > 0 such that for every d ≥ 2 and λ ≥ 0, SIM is suboptimal by an additive factor of at least cd/ log22(d) in the worst case for the ﬁnal reviewer.

A.3.3 Suboptimality of BID for Final Reviewer
In this section, we prove the worst case performance of the BID baseline for the ﬁnal reviewer.
Intuition. The BID algorithm greedily optimizes the minimum bid count since it shows papers in an increasing order of the number of bids received previously. The underlying problem with this method is that the paper ordering selected for any reviewer is independent of the similarity scores for that reviewer (up to serving as a tie-breaking mechanism). Since the paper-side gain function and the reviewer-side gain function both depend on the similarity scores, this property of BID leads to suboptimality in terms of both the expected paper-side gain and the reviewer-side gain.
To build some intuition for when BID is suboptimal, consider there is only a pair of papers j and j . Moreover, suppose paper j has a much higher similarity score than paper j and paper j has only one more bid than j . In this scenario, the expected reviewer-side gain from showing paper j ahead of paper j is signiﬁcantly higher than showing paper j ahead of paper j. Moreover, since the probability of obtaining a bid on paper j is signiﬁcantly higher at a given position in the paper ordering than for paper j and the number of bids on the papers are nearly equal, the expected paper-side gain is also maximized if paper j is shown ahead of paper j . Since BID instead shows paper j ahead of paper j, it would be suboptimal for both paper-side and reviewer-side gain. The following construction now generalizes this observation.
Construction. We now construct a problem instance that will be used to prove BID is signiﬁcantly suboptimal for the ﬁnal reviewer in the worst case. Consider the similarity scores for the ﬁnal reviewer as

Sn,j = 1, if j ∈ {1, . . . , d/2} 0, if j ∈ {d/2 + 1, . . . , d}.
For now, assume the number of papers d is even. We handle when the number of papers d is odd at the end of this proof. Let the number of bids on the papers from previous reviewers be such that

gn−1,j = 1, if j ∈ {1, . . . , d/2} 0, if j ∈ {d/2 + 1, . . . , d}.
In words, half of the papers have a similarity score of one and have recieved bids, and the other half of the papers have a similarity score of zero and have obtained no bids.
We now derive the optimal paper ordering for the ﬁnal reviewer. Recall from (22) that the weights of the optimization problem for the ﬁnal reviewer given in (21) are deﬁned by
αn,j = Sn,j (γp(gn−1,j + 1) − γp(gn−1,j )) + λ(2Sn,j − 1) ∀ j ∈ [d].
Moreover, from the structure of the optimization problem in (21), if αn,j > αn,j , then πnSUPER∗ (j) < πnSUPER∗ (j ) so that paper j is shown ahead of paper j in the ranking. Observe that for each j ∈ {1, . . . , d/2}, αn,j is a ﬁxed number. Similarly, for each j ∈ {d/2 + 1, . . . , d}, αn,j is a ﬁxed number. If αn,j − αn,j > 0 for any j ∈ {1, . . . , d/2} and

29

j ∈ {d/2 + 1, . . . , d}, then we can conclu√de each paper with a bid is shown ahead of each paper without a bid. We consider j = 1 and j = d. Since γp(x) = x and αn,d = 0,

√

αn,1 − αn,d = γp(2) − γp(1) + λ = 2 − 1 + λ ≥ 1/3 + λ.

(32)

Consequent of the fact λ ≥ 0, we conclude αn,1 − αn,d > 0, which means SUPER∗ shows each paper with a bid ahead

of each paper without a bid. Finally, since αn,j is a ﬁxed number for each j ∈ {1, . . . , d/2} and αn,j is a ﬁxed number

for each j

∈

{d/2

+

1, . . . , d},

as

long

as

π

SUPER n

∗

(j

)

<

πnSUPER∗ (j

)

for

every

j, j

pair, then the paper ordering is

optimal. In other words, any paper ordering which shows the papers with a bid in an arbitrary order followed by the

papers without a bid in an arbitrary order is optimal.

We

conclude

π

SUPER∗ n

(

j

)

=

j

for

each

j

∈

[d],

where

without

loss

of

generality,

to

simplify

the

analysis,

we

assume

if a pair of papers have equal weights in the optimization problem, then ties are broken in order of the paper indexes

since the tie-breaking mechanism will not change the expected gain the paper ordering obtains from the ﬁnal reviewer.

The BID baseline will show papers in an increasing order of the number of bids so that

BID

j + d/2, if j ∈ {1, . . . , d/2}

πn (j) = j − d/2, if j ∈ {d/2 + 1, . . . , d}.

This paper ordering is derived from recalling that BID breaks ties by the similarity scores and further ties are broken uniformly at random. However, without loss of generality, to simplify the analysis, we assume if a pair of papers have equal similarity scores and bid counts, then ties are broken in order of the paper indexes since the tie-breaking mechanism among this set of papers will not impact the expected gain. We now move on to lower bounding (23) for this construction.
Bounding the expected gain. Substituting the similarity scores, the number of bids on each paper, and the (deterministic) paper orderings presented by each algorithm for this construction into (23), we obtain

d/2

d/2

E[GnSUPER∗ − GnBID|Hn−1] = (γp(2) − γp(1))(f π(j) − f π(j + d/2)) + λ (f π(j) − f π(j + d/2))

j=1

j=1

where the terms for papers in the set {d/2 + 1, . . . , d} dropped out since the similarity scores are zero. Simplifying the expression, we obtain

d/2

E[GnSUPER∗ − GnBID|Hn−1] = (γp(2) − γp(1) + λ) (f π(j) − f π(j + d/2)).

(33)

j=1

From (32), we get

γp(2) − γp(1) + λ ≥ 1/3 + λ.

(34)

Moreover, from Lemma 2,

d/2

(f π(j) − f π(j + d/2)) ≥

d .

(35)

j=1

16

log

2 2

(

d)

Combining (33), (34), and (35), we obtain

E[GSUPER∗ − GBID|Hn−1] ≥

1λ +

d

(36)

n

n

48 16 log22(d)

whenever the number of papers d is even. Lemma 2 and the bound in (36) are applicable when d is even. The following lemma shows that an equivalent
result (up to constants) holds when the number of papers d is odd. The approach to obtain the result is similar to that for deriving Lemma 3. We obtain the bound for an odd number of papers d by looking at an identical problem construction for d = d − 1 papers, and then include an additional paper that has a similarity score of zero with the ﬁnal reviewer and one previous bid. This change is such that both SUPER∗ and BID show the additional paper last, and moreover, the expected gain from paper d is zero since the similarity score is zero.

30

Lemma 4. If d is odd, then in the worst case for the ﬁnal reviewer under the assumptions of Theorem 2,

E[GnSUPER∗ − GnBID|Hn−1] ≥

1λ +
96 32

d log22(d) .

The proof of Lemma 4 is in Section A.3.5.4. Combining the bound from (36) which holds for d even with the bound from Lemma 4 which holds for d odd, we
ﬁnd that for every d ≥ 2 and λ ≥ 0,

E[GSUPER∗ − GBID|Hn−1] ≥

1λ +

d .

(37)

n

n

96 32 log22(d)

This proves the claim in Theorem 2 that there exists a constant c > 0 such that for all d ≥ 2 and λ ≥ 0, BID is suboptimal by an additive factor of at least cd max{1, λ}/ log22(d) in the worst case for the ﬁnal reviewer.

A.3.4 Suboptimality of RAND for Final Reviewer
In this section, we prove the the worst case performance of the RAND baseline for the ﬁnal reviewer.
Intuition. The RAND algorithm selects an ordering of papers to show a reviewer uniformly at random from the set of permutations. Since this method is agnostic to the similarity scores and the number of bids, RAND can select highly suboptimal paper orderings with some non-zero probability.
To see when this can occur, consider the example that provided intuition for the suboptimality of BID in Section A.3.3 that consisted of only a pair of papers j and j . In this example, paper j has a much higher similarity score than paper j and paper j has only one more bid than j . The expected reviewer-side gain from showing paper j ahead of paper j is signiﬁcantly higher than showing paper j ahead of paper j. Moreover, since the probability of obtaining a bid on paper j is signiﬁcantly higher at a given position in the paper ordering than for paper j and the number of bids on the papers are nearly equal, the expected paper-side gain is also maximized if paper j is shown ahead of paper j . Since there are only two permutations of the papers that can be selected, with probability 1/2, RAND would show paper j ahead of paper j and be suboptimal for both paper-side and reviewer-side gain. The problem construction from Section A.3.3 is sufﬁcient to generalize this observation. For completeness, we repeat the construction below.
Construction. In the remainder of the proof, we show the problem construction from Section A.3.3 can be used to prove RAND is signiﬁcantly suboptimal for the ﬁnal reviewer in the worst case. In this construction, the similarity scores for the ﬁnal reviewer are
Sn,j = 1, if j ∈ {1, . . . , d/2} 0, if j ∈ {d/2 + 1, . . . , d}.
For now, assume the number of papers d is divisible by four. We deal with a number of papers d that is not divisible by four at the end of this section. The number of bids on the papers from previous reviewers are

gn−1,j = 1, if j ∈ {1, . . . , d/2} 0, if j ∈ {d/2 + 1, . . . , d}.

In

Section

A.3.3,

we

showed

that

SUPER∗

selects

the

optimal

ordering

π

SUPER∗ n

(

j

)

=

j

for

each

j

∈

[d].

The

RAND

baseline will select a paper ordering πnRAND uniformly at random from the set of permutations Πd.

Bounding the expected gain. For this construction, we need to lower bound (23). As an initial step, we simplify
the quantity by substituting the similarity scores, the number of bids on each paper, and the paper ordering presented by SUPER∗ to obtain

E[GnSUPER∗ − GnRAND|Hn−1] = EπRAND n

d/2
(γp(2) − γp(1))(f π(j) − f π(πnRAND(j)))
j=1
d/2
+ λ (f π(j) − f π(πnRAND(j))) ,
j=1

31

where the terms for papers in the set {d/2 + 1,√. . . , d} dropped out since the similarity scores are zero. Combining the sums and using the fact that γp(2) − γp(1) = 2 − 1 ≥ 1/3 gives

d/2

E[GnSUPER∗ − GnRAND|Hn−1] ≥ EπRAND (1/3 + λ) (f π(j) − f π(πnRAND(j))) .

(38)

n

j=1

Before proceeding, we provide some intuition that guides the remainder of the proof. The expression in (38) only depends on the positions RAND shows the papers in the set {1, . . . , d/2} to the ﬁnal reviewer. Recalling that the given function f π is decreasing on the domain R>0, we can observe that the number of positive summand in
dj=/21(f π(j) − f π(πnRAND(j))) increases with the number of papers from the set {1, . . . , d/2} that are not presented in the set of positions {1, . . . , d/2} from a selection πnRAND and the remaining summand are zero. This point suggests if with probability bounded away from zero, sufﬁciently many papers from the set {1, . . . , d/2} are not presented in the set of positions {1, . . . , d/2} in the ordering selected by RAND, then it should be suboptimal in expectation.
Toward formalizing this line of reasoning, the following lemma provides a lower bound on the probability that RAND selects a paper ordering that shows fewer than d/4 papers from the set {1, . . . , d/2} in the set of positions {1, . . . , d/2}. The proof is given in Section A.3.5.5.
Lemma 5. Assume d is divisible by four and consider a set of papers [d]. Let E be the event that a permutation π of the paper set [d] drawn uniformly at random from Πd has fewer than d/4 of the papers {1, . . . , d/2} in the positions {1, . . . , d/2}. Then, P(E) ≥ 1/6.
Deﬁne T1 ⊂ Πd as the set of paper orderings with fewer than d/4 of the papers from the set {1, . . . , d/2} in the set of positions {1, . . . , d/2} and T2 ⊂ Πd as the set containing the remaining paper orderings so that T1 ∪ T2 = Πd. Now, beginning from (38), we evaluate and bound the expectation as follows:

E[GnSUPER∗ − GnRAND|Hn−1] = (1/3 + λ)

d/2
P(πnRAND = πn) (f π(j) − f π(πn(j)))

πn ∈T1

j=1

d/2

+ (1/3 + λ)

P(πnRAND = πn) (f π(j) − f π(πn(j)))

πn ∈T2

j=1

d/2
≥ (1/3 + λ)P(πnRAND ∈ T1) min (f π(j) − f π(πn(j)))
πn ∈T1 j=1

d/2
+ (1/3 + λ)P(πnRAND ∈ T2) min (f π(j) − f π(πn(j))).
πn ∈T2 j=1

Observe that minπn∈T2 dj=/21(f π(j) − f π(πn(j))) = 0 since the optimal paper ordering that shows each paper in the set {1, . . . , d/2} in the set of positions {1, . . . , d/2} is contained in T2. Moreover, from Lemma 5, P(πnRAND ∈ T1) ≥ 1/6. This results in the bound

d/2

E[GSUPER∗ − GRAND|Hn−1] ≥

1λ +

min

(f π(j) − f π(πn(j))).

(39)

n

n

18 6 πn∈T1

j=1

We now need to reason about the minimizer of minπn∈T1 dj=/21(f π(j) − f π(πn(j))). Equivalently, we can ﬁnd the

maximizer of maxπn∈T1

d/2 j=1

f π(πn(j)).

Since

the

given

function

fπ

is

decreasing

on

the

domain

R>0,

the

quantity

d/2 j=1

f π(πn(j))

is

maximized

when

the

papers

in

the

set

{1,

.

.

.

,

d/2}

are

shown

the

earliest

in

the

ordering

πn

that

is feasible subject to the constraint that fewer than d/4 papers from the set {1, . . . , d/2} are presented in the set of

positions {1, . . . , d/2}. This means

j,

if j ∈ {1, . . . , d/4 − 1}





j + d/4 + 1, if j ∈ {d/4, . . . , d/2} πn(j) = j − d/4 − 1, if j ∈ {d/2 + 1, . . . , 3d/4 + 1} (40)




j,

if j ∈ {3d/4 + 2, . . . , d}

32

is a minimizer of dj=/21(f π(j) − f π(πn(j))) among the set T1. Substituting the paper ordering from (40) as the minimizer into (39), we obtain

d/2
E[GnSUPER∗ − GnRAND|Hn−1] ≥ 118 + λ6 (f π(j) − f π(j + d/4 + 1)). (41)
j=d/4

The following lemma provides a bound on the sum in (41). Lemma 6. Let f π(x) = 1/ log2(x + 1) and ﬁx d ≥ 4 and divisible by four. Then,

d/2

(f π(j) − f π(j + d/4 + 1)) ≥

d .

j=d/4

32

log

2 2

(d

)

The proof of Lemma 6 can be found in Section A.3.5.6. Combining (41) and Lemma 6 results in the following bound whenever d is divisible by four:

E[GSUPER∗ − GRAND|Hn−1] ≥

1λ +

d .

(42)

n

n

576 192 log22(d)

The next lemma shows that if the number of papers d is not divisible by four, an equivalent result (up to constants) holds. For d ∈ {2, 3}, the bound is rather immediate since we can compute the probability that RAND selects the paper ordering BID shows for this construction and then apply the bound from (37) on the suboptimality of BID that holds for any d. For d > 3 and not divisible by four, the bound is obtained by looking at an identical problem construction for the maximum d < d divisible by four and then including d − d papers with a similarity score of zero and one previous bid. This change is such that the bound from (42) applies as a function of d , so the result then follows immediately.

Lemma 7. If d is not divisible by four, then in the worst case for the ﬁnal reviewer under the assumptions of Theorem 2,

E[GnSUPER∗ − GnRAND|Hn−1] ≥

1

λ

+

1728 576

d log22(d) .

The proof of Lemma 7 can be found in Section A.3.5.7. Combining the bound from (42) which holds for d divisible by four with the bound from Lemma 7 which holds
for d not divisible by four, we ﬁnd that for every d ≥ 2 and λ ≥ 0,

E[GnSUPER∗ − GnRAND|Hn−1] ≥

1

λ

+

1728 576

d log22(d) .

This proves there is a constant c > 0 such that for all d ≥ 2 and λ ≥ 0, RAND is suboptimal by an additive factor of at least cd max{1, λ}/ log22(d) in the worst case for the ﬁnal reviewer as claimed in Theorem 2.

A.3.5 Proofs of Lemmas 1–7

In this section, we present the proofs of technical lemmas stated in the primary proof of Theorem 2. √
A.3.5.1 Proof of Lemma 1. Recall from the lemma statement, γp(x) = x. Moreover, the ﬁxed and given quantities are λ ≥ 0, d ≥ 2, and = (1 + λ)eee . We derive the following bound justiﬁed below:

(γp(1)−γp(0))(1 − 1/ ) − (γp(2) − γp(1))(1 − 1/(d )) + λ(2(1−1/ ) − 2(1−1/(d )))

≥ (γp(1) − γp(0))(1 − 1/ ) − (γp(2) − γp(1)) + λ(2(1−1/ ) − 2)

(43)

= (γp(1) − γp(0))(1 − ((1 + λ)eee )−1) − (γp(2) − γp(1)) + λ(2(1−1/((1+λ)eee ) − 2)

(44)

≥ (0.99)(γp(1) − γp(0)) − (γp(2) − γp(1)) − 0.01

(45)

≥ 1/2.

(46)

33

We obtain (43) using the fact that (1−1/(d )) ≤ 1 for any given d. Equation (44) follows from plugging in the explicit form of = (1 + λ)eee . To see the inequality in (45), observe that (1 − ((1 + λ)eee )−1) is an increasing function of λ. Consequently, (1 − ((1 + λ)eee )−1) ≥ (1 − (eee )−1) ≥ 0.99. Furthermore, the quantity λ(2(1−1/((1+λ)eee )) − 2) is a decreasing function of λ, from which we determine
λ(2(1−1/((1+λ)eee )) − 2) ≥ lim λ (2(1−1/((1+λ )eee )) − 2) = −e−ee log(4) ≥ −0.01.
λ →∞

Then, we obtain the ﬁnal bound in (46) as follows: √
(0.99)(γp(1) − γp(0)) − (γp(2) − γp(1)) − 0.01 = 0.99 − ( 2 − 1) − 0.01 ≥ 1/2.

A.3.5.2 Proof of Lemma 2. Recall that f π(x) = 1/ log2(x + 1). Fixing d = 2, we obtain

d/2

(f π(j) − f π(j + d/2)) = f π(1) − f π(2)

j=1

=1−1 log2(2) log2(3)

≥1

1

(47)

4 log22(2)

1

d

= 8 log22(d) . (48)

The inequality in (47) follows from the fact that log2(3) − 1 ≥ 1/2 and log2(3) ≤ 2 log2(2). Now consider d ≥ 4 and d even. We derive a bound as follows that is justiﬁed below:

d/2

d/4

(f π(j) − f π(j + d/2)) ≥ (f π(j) − f π(j + d/2))

(49)

j=1

j=1

≥ d (f π( d/4 ) − f π(d/2))

(50)

4

d =
4

1

−

1

log2( d/4 + 1) log2(d/2 + 1)

d =
4

log2(d/2 + 1) − log2( d/4 + 1) log2(d/2 + 1) log2( d/4 + 1)

≥ d log2(3) − 1

(51)

4

log22(d)

≥1

d .

(52)

16 log22(d)

The inequality in (49) follows from the fact that f π(j) ≥ f π(j + d/2) for every j ∈ [d/2] since f π is a decreasing function on the domain R>0. Similarly, we obtain (50) using the observation that f π(j)−f π(j +d/2) ≥ f π( d/4 )− f π(d/2) for every j ∈ [ d/4 ] since f π is a decreasing function on the domain R>0. To see how (51) is derived,
observe that

log2(d/2 + 1) − log2( d/4 + 1) ≥ log2(d/2 + 1) − log2(d/4 + 1) ≥ log2(3) − 1

(53)

where the ﬁnal inequality in (53) follows since log2(d/2 + 1) − log2(d/4 + 1) is increasing in d and d ≥ 4 by assumption. Moreover, log2(d/2 + 1) log2( d/4 + 1) ≤ log22(d) for d ≥ 4. The ﬁnal inequality in (52) holds since log2(3) − 1 ≥ 1/2 and d/4 = d/4 − (d mod 4)/4 ≥ d/8 for d ≥ 4.
Combining the bound for d = 2 from (48) and the bound for d ≥ 4 and even from (52), we conclude

d/2
(f π(j) − f π(j + d/2)) ≥ 1 j=1 16

d log22(d) ,

whenever d ≥ 2 and even.

34

A.3.5.3 Proof of Lemma 3. In this proof, we show a simple adaptation of the problem construction from Sec-
tion A.3.2 results in a suboptimality bound on SIM for the ﬁnal reviewer when the number of papers d is odd that
matches (up to constants) the bound given in (31) that holds whenever the paper count d is even. Fix d odd and let d = d − 1 (and hence d is an even number). We consider an identical problem construction for
the papers j ∈ [d ] as from Section A.3.2 and then include a paper d that has a similarity score of zero and one bid. This change is such that for the given class of functions in the model, SUPER∗ and SIM show the paper d after the
papers in the set [d ] and the expected gain from paper d is deterministically zero since the similarity score is zero. In particular, let the similarity scores for the ﬁnal reviewer be Sn,j = 1 − 1/(j ) for each paper j ∈ [d ], where
= (1 + λ)eee and λ ≥ 0 is the ﬁxed and given trade-off parameter. Moreover, let Sn,d = 0. Set the number of bids on the papers from previous reviewers to be

gn−1,j = 0, if j ∈ {1, . . . , d /2} 1, if j ∈ {d /2 + 1, . . . , d}.

In Section A.3.2, we showed if a pair of papers j, j are such that gn−1,j = gn−1,j and Sn,j > Sn,j , then

π

SUPER n

∗

(j

)

<

πnSUPER∗ (j

).

Since

paper

j

= d is such that for every paper j ∈ {d /2 + 1, . . . , d }, gn−1,j = gn−1,j

and

Sn,j

>

Sn,j

,

we

ﬁnd

π

SUPER∗ n

(

j

)

<

πnSUPER∗ (j

).

From

(26),

this

means

for

this

construction

π

SUPER n

∗

(d

)

=

d

and that SUPER∗ shows the paper ordering

 − j + 1,
d /2

∗



πnSUPER (j) = d + d /2 + 1 − j,

j,

if j ∈ {1, . . . , d /2} if j ∈ {d /2 + 1, . . . , d } if j ∈ {d}.

The SIM algorithm shows papers in a decreasing order of the similarity scores so that

SIM

d − j + 1, if j ∈ {1, . . . , d }

πn (j) = j,

if j ∈ {d}.

Observe that this construction is identical to the problem construction from Section A.3.2 for papers in the set [d ]. Moreover, from (20) it is clear that the expected gain from papers with zero similarity score is zero independent of the paper ordering. This allows us to conclude that the bound given in (31) for d even applies to this construction as a function of d . In other words, given d odd, we obtain

E[GnSUPER∗ − GnSIM|Hn−1] ≥ 312

d log22(d ) .

Moreover, since d = d − 1, whenever d is odd,

E[GnSUPER∗ − GnSIM|Hn−1] ≥ 312

d−1 ≥ 1

log22(d − 1)

64

d log22(d) ,

where the ﬁnal inequality follows from the facts that log22(d − 1) ≤ log22(d) and d − 1 ≥ d/2 for d ≥ 2.

A.3.5.4 Proof of Lemma 4. In this proof, we show a simple adaptation of the problem construction from Section A.3.3 leads to a suboptimality bound on BID for the ﬁnal reviewer when the number of papers is odd that matches (up to constants) the bound given in (36) that holds whenever the number of papers d is even. This approach is analogous to the method to obtain a suboptimality bound for SIM with an odd number of papers using the bound that held for an even number of papers from Lemma 3.
Fix d odd and let d = d − 1 (and hence d is an even number). We consider an identical problem construction for the papers j ∈ [d ] as from Section A.3.3 and then include a paper d that has a similarity score of zero and one bid. This change is such that for the given class of functions in the model, SUPER∗ and BID show the paper d after the papers in the set [d ] and the expected gain from paper d is deterministically zero since the similarity score is zero.
Let the similarity scores for the ﬁnal reviewer be

Sn,j = 1, if j ∈ {1, . . . , d /2} 0, if j ∈ {d /2 + 1, . . . , d}

35

and the number of bids on the papers from previous reviewers be

 1, 
gn−1,j = 0,
1,

if j ∈ {1, . . . , d /2} if j ∈ {d /2 + 1, . . . , d } if j = d.

We now derive the optimal paper ordering for the ﬁnal reviewer. Recall from (22) that the weights of the optimization problem for the ﬁnal reviewer given in (21) are deﬁned by

αn,j = Sn,j (γp(gn−1,j + 1) − γp(gn−1,j )) + λ(2Sn,j − 1) ∀ j ∈ [d].

Moreover,

from

the

structure

of

the

optimization

problem

in

(21),

if

αn,j

>

αn,j

,

then

π

SUPER∗ n

(j

)

<

πnSUPER∗ (j

)

so

that paper j is shown ahead of paper j in the ranking. Observe that for each paper j ∈ {1, . . . , d /2}, αn,j is a ﬁxed

number. Similarly, for each j ∈ {d /2 + 1, . . . , d } ∪ {d}, αn,j is a ﬁxed number. In Section A.3.3, we showed if a

pair of papers j, j are such that gn−1,j = 1 and gn−1,j = 0 along with Sn,j = 1 and Sn,j = 0, then αn,j > αn,j

so

that

π

SUPER n

∗

(j

)

<

πnSUPER∗ (j ).

This

immediately

guarantees

π

SUPER n

∗

(j

)

<

πnSUPER∗ (j ) for each pair of papers

j ∈ {1, . . . , d /2}, j

∈

{d

/2

+

1,

.

.

.

,

d

}

∪

{d}.

We

conclude

π

SUPER n

∗

(j

)

=

j

for

each

j

∈

[d],

where

without

loss

of generality, to simplify the analysis, we assume if a pair of papers have equal weights in the optimization problem,

then ties are broken in order of the paper indexes since the tie-breaking mechanism will not change the expected gain

the paper ordering obtains from the ﬁnal reviewer.

The BID baseline will show papers in an increasing order of the number of bids so that

 j + d /2,  πnBID(j) = j − d /2,
j

if j ∈ {1, . . . , d /2} if j ∈ {d /2 + 1, . . . , d } if j = d.

This paper ordering is derived from recalling that BID breaks ties by the similarity scores and further ties are broken uniformly at random. However, without loss of generality, to simplify the analysis, we assume if a pair of papers have equal similarity scores and bid counts, then ties are broken in order of the paper indexes since the tie-breaking mechanism among this set of papers will not impact the expected gain.
The construction in this proof and the paper orderings selected by SUPER∗ and BID are identical to the problem construction and paper orderings selected by SUPER∗ and BID from Section A.3.3 for papers in the set [d ]. From (20) it is clear that the expected gain from papers with zero similarity score is zero independent of the paper ordering. This allows us to conclude that the bound given in (36) for d even applies to this construction as a function of d . In other words, given d odd, we obtain

E[GnSUPER∗ − GnBID|Hn−1] ≥

1λ +
48 16

d log22(d ) .

Since d = d − 1, whenever d is odd,

E[GnSUPER∗ − GnBID|Hn−1] ≥

1λ +
48 16

d−1

≥

1λ +

log22(d − 1)

96 32

d log22(d) ,

where the ﬁnal inequality follows from the facts that log22(d − 1) ≤ log22(d) and d − 1 ≥ d/2 for d ≥ 2.
A.3.5.5 Proof of Lemma 5. Recall that from the lemma statement, the number of papers d is assumed to be divisible by four. Let E denote the event that a permutation π of the paper set [d] drawn uniformly at random from Πd has fewer than d/4 of the papers from the set [d/2] in the position set [d/2].
The probability of the event E can be explained in the following manner. The number of outcomes presenting j papers from the paper set [d/2] in the position set [d/2] consists of d/j2 combinations of potential papers that can be selected from the paper set [d/2] and d/j2 combinations of potential positions in the position set [d/2]. Moreover, there are j! permutations of the selected papers in the chosen positions. Given that there are j papers selected from the paper set [d/2] placed in the position set [d/2], there are d/d2/−2 j combinations of papers from the paper set {d/2 + 1, . . . , d} that can be placed in the remaining spots in the position set [d/2]. This set of papers can be permuted

36

(d/2−j)! ways in the given set of positions, and the remaining d/2 papers can be permuted (d/2)! ways in the position set {d/2 + 1, . . . , d}. To obtain the ﬁnal probability of the event E, we sum the number of outcomes for each j < d/4 and then normalize by the total number of outcomes d!. Accordingly,

1 d/4−1 d/2 P(E) = d! j
j=0

d/2 (j!)

d/2

(d/2 − j)!(d/2)!

j

d/2 − j

1 d/4−1 d/2 =
d! j=0 j

d/2 (j!)

(d/2)!

(d/2 − j)!(d/2)!

j

(d/2 − j)!j!

(d/2)!(d/2)! d/4−1 d/2 2

=

.

(54)

d! j=0 j

We now recall some facts about the binomial coefﬁcients. The symmetry property of the binomial coefﬁcients

implies nk = n−nk for 0 ≤ k ≤ n and Vandermonde’s identity says that m+r n = rk=0 mk r−nk and as a

corollary mn =

m k=0

2nm . Using this set of facts, we work toward a lower bound on P(E) by obtaining a simpliﬁed

form of the sum dj=/40−1 d/j2 2. Observe that

d/4−1 j=0

d/2 2 d/4 =
j j=0

d/2 2 j−

d/2 2 d/4

1 d/4 =
2 j=0

d/2 2 1 d/4 +
j 2 j=0

d/2 2 j−

d/2 2 .
d/4

From the symmetry property, d/2 2 =

d/2

2
, so we get

j

d/2−j

d/4−1 d/2 2 1 d/4 d/2 2 1 d/4 d/2 2 d/2 2

=

j

2

+

j

2

d/2 − j − d/4 .

j=0

j=0

j=0

Manipulating the indexing of the sum dj=/40 d/d2/−2 j 2, we obtain

d/4−1 j=0

d/2 2 1 d/4 =
j 2 j=0

d/2 2 1 d/2

+

j

2

j=d/4

d/2 2 j−

d/2 2 .
d/4

Now, moving the term 1 d/2 2 out of the sum 1 d/2 d/2 2 results in

2 d/4

2 j=d/4 j

d/4−1 j=0

d/2 2 1 d/4 =
j 2 j=0

d/2 2 1 d/2

+

j

2

j=d/4+1

d/2 2 1 j −2

d/2 2 .
d/4

Furthermore,

d/4−1 j=0

d/2 2 1 d/2 =
j 2 j=0

d/2 2 1 j −2

d/2 2 .
d/4

Finally, applying Vandermonde’s identity as given above, we get

d/4−1 d/2 2 1 d 2 1 d/2 2 j = 2 d/2 − 2 d/4 . (55)
j=0

37

Combing (54) with (55) and then simplifying, we get

P(E) = (d/2)!(d/2)! 2d!

d

d/2 2

d/2 − d/4

(d/2)!(d/2)! =
2d!

d!

− (d/2)!(d/2)!

(d/2)!(d/2)!

2d!

= 1 − (d/2)!(d/2)!

2

2d!

(d/2)! 2 .
(d/4)!(d/4)!

(d/2)! 2 (d/4)!(d/4)!

The quantity (d/2)2!d(!d/2)!

(d/2)!

2
is decreasing in d. Consequently, for every d ≥ 4,

(d/4)!(d/4)!

(d/2)!(d/2)! 2d!

(d/2)! 2 ≤ 1 .

(d/4)!(d/4)!

3

This allows us to conclude

P(E) ≥ 1/2 − 1/3 = 1/6.

A.3.5.6 Proof of Lemma 6. This proof follows in a similar manner to the proof of Lemma 2. Recall that f π(x) = 1/ log2(x + 1). Fixing d ≥ 4 and divisible by four, we obtain the following bound justiﬁed below:

d/2

3d/8

(f π(j) − f π(j + d/4 + 1)) ≥

(f π(j) − f π(j + d/4 + 1))

(56)

j=d/4

j=d/4

≥ 3d + 1 − d (f π( 3d/8 ) − f π(d/2))

(57)

8

4

= 3d + 1 − d

1

−

1

8

4 log2( 3d/8 + 1) log2(d/2 + 1)

= 3d + 1 − d log2(d/2 + 1) − log2( 3d/8 + 1)

8

4 log2(d/2 + 1) log2( 3d/8 + 1)

≥ 3d + 1 − d log2(3) − log2(12/8 + 1)

(58)

8

4

log22(d)

1

d

= 32 log22(d) . (59)

The inequality in (56) follows from the fact that f π(j) ≥ f π(j+d/4+1) for every j ∈ {d/4, . . . , 3d/8 } since f π is a decreasing function on the domain R>0. Similarly, we obtain (57) using the observation that f π(j)−f π(j+d/4+1) ≥ f π( 3d/8 ) − f π(d/2) for every j ∈ {d/4, . . . , 3d/8 } since f π is a decreasing function on the domain R>0. To
see how (58) is derived, observe that

log2(d/2 + 1) − log2( 3d/8 + 1) ≥ log2(d/2 + 1) − log2(3d/8 + 1) ≥ log2(3) − log2(12/8 + 1), (60)
where the ﬁnal inequality in (60) follows since log2(d/2 + 1) − log2(3d/8 + 1) is increasing in d and d ≥ 4 by assumption. Moreover, log2(d/2 + 1) log2( 3d/8 + 1) ≤ log22(d) for d ≥ 4. The ﬁnal inequality in (59) holds since log2(3) − log2(12/8 + 1) ≥ 1/4 and
3d/8 + 1 − d/4 ≥ 3d/8 − d/4 ≥ d/8.

A.3.5.7 Proof of Lemma 7. Let us begin with d ∈ {2, 3}. It is immediate that RAND selects the paper ordering of BID with probability at least 1/6 since |Πd| ≤ 6. Moreover, any paper ordering selected by RAND cannot obtain higher expected gain from the ﬁnal reviewer than SUPER∗ since it is optimal for the ﬁnal reviewer. Accordingly,
combined with the bound on BID from (37) which holds for any d ≥ 2, we obtain for d ∈ {2, 3},

E[GSUPER∗ − GRAND|Hn−1] ≥

1λ +

d .

(61)

n

n

488 192 log22(d)

38

We now focus on d > 3 and not divisible by four. The problem construction we consider is similar to that from Lemma 4 where the number of papers was odd and it was derived from including a paper with zero similarity score and a bid as an extra paper to the problem construction from Section A.3.3. We follow the same approach, but let d be the maximum number divisible by four such that d < d and consider an identical problem construction for the papers in the set [d ], but then include d − d extra papers with zero similarity and a bid. This change is such that the papers in the set {d + 1, . . . , d} are shown after the papers in the set [d ] by SUPER∗ and the expected gain from them is deterministically zero since the similarity scores are zero.
In particular, let the similarity scores for the ﬁnal reviewer be

Sn,j = 1, if j ∈ {1, . . . , d /2} 0, if j ∈ {d /2 + 1, . . . , d}

and the number of bids on the papers from previous reviewers be

 1, 
gn−1,j = 0,
1,

if j ∈ {1, . . . , d /2} if j ∈ {d /2 + 1, . . . , d } if j ∈ {d + 1, . . . , d}.

Following

the

exact

reasoning

from

the

proof

of

Lemma

4,

we

conclude

π

SUPER∗ n

(j

)

=

j

for

each

j

∈

[d].

For this construction and RAND, we need to lower bound (23). We simplify the expression by substituting the sim-

ilarity scores and the number of bids on each paper, and the paper ordering presented by SUPER∗ for this construction

to obtain
d /2

E[GnSUPER∗ − GnRAND|Hn−1] = EπRAND (γp(2) − γp(1) + λ) n

(f π(j) − f π(πnRAND(j))) .

j=1

where the terms for papers in the set {d /2 + 1, . . . , d} dropped out since the similarity scores are zero. From this

point, it is clear that the analysis beginning from (38) in Section A.3.4 can be repeated as a function of d to obtain the

bound

E[GnSUPER∗ − GnRAND|Hn−1] ≥

1λ +
576 192

d log22(d ) .

Since d ≥ d − 3, we obtain for d > 3 and not divisible by four,

E[GSUPER∗ − GRAND|Hn−1] ≥

1λ +

d−3

≥

1

λ

+

d

(62)

n

n

576 192 log22(d − 3)

1728 576 log22(d)

where the ﬁnal inequality follows from the facts that log22(d − 3) ≤ log22(d) and d − 3 ≥ d/3 for d ≥ 5. Combining the bound from (61) for d ∈ {2, 3} with the bound from (62) for d > 3 and not divisible by four, we
conclude for every d ≥ 2 and not divisible by four,

E[GnSUPER∗ − GnRAND|Hn−1] ≥

1

λ

+

1728 576

d log22(d) .

A.4 Proof of Theorem 3: Noiseless Community Model Result
In this proof, we show for the noiseless community model deﬁned in Section 4.2 that SUPER∗ with zero heuristic and SIM are optimal. Moreover, we prove that BID and RAND are signiﬁcantly suboptimal. The organization of this proof is as follows. In Section A.4.1, we present additional notation that is needed in the proof. Section A.4.2 presents simplifying preliminary analysis that is needed throughout the proof to analyze the expected paper-side and reviewer-side gains of the algorithms. In Section A.4.3, we characterize the optimal policy for the noiseless community model. We show in Sections A.4.4 and A.4.5 that SUPER∗ with zero heuristic and SIM are equivalent to the optimal policy, respectively. We prove the suboptimality bounds for BID and RAND in Sections A.4.6 and A.4.7, respectively. Combining the results from the sections of this proof gives the stated result of Theorem 3. We relegate the proofs of technical lemmas needed for this result to Section A.4.8.

39

A.4.1 Notation

Theorem 3 holds for any similarity matrix S belonging to the noiseless community model deﬁned in Section 4.2 and formally in (7). From this point on in the proof, any reference to a similarity matrix S is such that it belongs to the noiseless community model. Recall that the number of reviewers is given by n = mq and the number of papers is given by d = mq where m ≥ 2 and q ≥ 2.
We now state some additional notation for the proof and recall the class of gain and bidding functions assumed in this claim. Let us deﬁne for each reviewer i ∈ [n] the set

Di = {j ∈ [d] : Si,j = s},

(63)

which comprises the papers on the block diagonal of the noiseless community model similarity matrix for the reviewer up to a permutation of rows and columns. Similarly, deﬁne for each paper j ∈ [d] the set

Dj = {i ∈ [n] : Si,j = s},

(64)

which comprises the reviewers on the block diagonal of the noiseless community model similarity matrix for the paper

up to a permutation of rows and columns. Observe that |Di| = q for each reviewer i ∈ [n] and |Dj| = q for each

paper j ∈ [d]. In the remainder of the proof, we simply refer to the set Di as the papers on the block diagonal for a

reviewer i ∈ [n] and the set Dj as the reviewers on the block diagonal for a paper j ∈ [d], and omit the wording of up

to a permutation of rows and columns for brevity. Similarly, if a reviewer-paper pair (i, j) is such that Si,j = s so that

i ∈ Di and j ∈ Di, we say the reviewer-paper pair is on the block diagonal and omit that this is up to a permutation of
rows and columns. Moreover, we denote by Dic the complement of the set Di for any reviewer i ∈ [n], which contains each paper j ∈ [d] not in the set Di and corresponds to the papers not on the block diagonal for the reviewer. Similarly,
we let Djc denote the complement of the set Dj for any paper j ∈ [d], which contains each reviewer i ∈ [n] not in the set Dj and corresponds to the reviewers not on the block diagonal for the paper. Finally, if a reviewer-paper pair (i, j)
is such that Si,j = s so that i ∈ Dic and j ∈ Dic, we say the reviewer-paper pair is off the block diagonal. For each

complement set, we again omit the wording of up to a permutation of rows and columns.

We denote the expected gain of any algorithm ALG presenting a potentially random sequence of paper orderings

π1ALG, . . . , πnALG as

E[GALG] = E[GpALG] + λE[GrALG],

where the expectation is with respect to the randomness in the bids placed by reviewers and any randomness in the algorithm and λ ≥ 0 is the trade-off parameter. The expected paper-side gain is given by the quantity

E[GpALG] = E

γp(gj) ,

(65)

j∈[d]

where gj = i∈[n] Bi,j is random the number of √bids on paper j ∈ [d] at the end of the bidding process and the paper-side gain function for this result is γp(x) = x. Recall that Bi,j is a Bernoulli random variable denoting the random bid of reviewer i ∈ [n] on paper j ∈ [d]. From the assumptions of Theorem 3, the success probability of Bi,j for any reviewer i ∈ [n] and paper j ∈ [d] is given by the bidding function

f

(π

ALG i

(j

)

,

Si,j

)

=

1{πiALG(j)

=

1}1{Si,j

>

s/2}.

(66)

In the remainder of the proof, if πiALG(j) = 1, we often say the paper is shown in the highest or top position of the paper ordering. The expected reviewer-side gain is given by

E[GrALG] = E

γ

r

(π

ALG i

(j

),

Si,j

)

,

(67)

i∈[n] j∈[d]

where for this result the reviewer-side gain function is

γ (πALG(j), S ) =

2Si,j − 1

= (2Si,j − 1)γπ(πALG(j)).

(68)

r

i,j log2(πiALG(j) + 1)

ri

We let

γπ(πALG(j)) =

1

(69)

ri

log2(πiALG(j) + 1)

denote the component of the reviewer-side gain function that only depends on the position the paper is in.

40

A.4.2 Preliminaries

The focus of this section is to simplify the expressions for the expected paper-side gain and expected reviewer-side gain from (65) and (67) respectively, using the similarity matrix structure and the given class of gain and bidding functions. There are several immediate characteristics of the reviewer bidding behavior and the relation between the similarity scores as a result of the given bidding function from (66) and the noiseless community model similarity score structure from (7) that we reference throughout the proof:

• If the reviewer-paper pair (i, j) is on the block diagonal of the noiseless community model similarity matrix S so that i ∈ Dj and j ∈ Di, then paper j ∈ [d] is bid on almost surely by reviewer i ∈ [n] when πiALG(j) = 1 and almost never when πiALG(j) = 1.
• If the reviewer-paper pair (i, j) is not on the block diagonal of the noiseless community model similarity matrix S so that i ∈ Djc and j ∈ Dic, then paper j ∈ [d] is bid on almost never by reviewer i ∈ [n] independent of πiALG(j).
• If the reviewer-paper pair (i, j) is on the block diagonal of the noiseless community model matrix S so that i ∈ Dj and j ∈ Di, and the reviewer-paper pair (i, j ) is not on the block diagonal of the noiseless community model matrix S so that i ∈ Djc and j ∈ Dic, then Si,j > Si,j .

Observe that the statements above further imply that each reviewer bids on at most one paper almost surely. We now show that the expected paper-side gain from any paper j ∈ [d] only depends on the positions it is shown
to reviewers i ∈ [n] by some algorithm ALG for which the reviewer-paper pair (i, j) is on the block diagonal of the similarity matrix. Indeed, the expected paper-side gain for any paper j ∈ [d] simpliﬁes to be

q

E[γp(gj)] = E γp

Bi,j = E γp

Bi,j = P = 1{πiALG(j) = 1} γp( ). (70)

i∈[n]

i∈Dj

=0

i∈Dj

The preceding equation follows from the fact that the the bid from any reviewer i ∈ Djc on paper j ∈ [d] is zero almost surely independent of the position the paper is shown, and since any reviewer i ∈ Dj bids on the paper j ∈ [d] almost
surely if πiALG(j) = 1 and almost never if πiALG(j) = 1.
To obtain a ﬁnal simpliﬁed version of the expected paper-side gain given in (65), we sum (70) over the paper set

[d] and get that
q

E[GpALG] = E[γp(gj)] =

P = 1{πiALG(j) = 1} γp( ).

(71)

j∈[d]

j∈[d] =0

i∈Dj

It is now clear from (71) that to analyze the expected paper-side gain of any algorithm ALG, we only need to determine the distribution on the number of times each paper is shown in the highest position to reviewers for which the reviewerpaper pair is on the block diagonal of the similarity matrix.
We now turn to deriving a simpliﬁed form of the expected reviewer-side gain given in (67). Beginning from (67), we substitute in the form of the reviewer-side gain function from (68) and then plug in the similarity scores of the noiseless community model matrix to obtain

E[GrALG] = E

(2Si,j − 1)γrπ(πiALG(j)) = E (2s − 1)

γrπ(πiALG(j)) .

(72)

i∈[n] j∈[d]

i∈[n] j∈Di

To be clear, the ﬁnal equality above follows from the facts that Di ∪ Dic = [d] for each reviewer i ∈ [n] and Si,j = s for j ∈ Di and Si,j = 0 for j ∈ Dic. It is now evident that the expected reviewer-side gain only depends on the positions the papers on the block diagonal for each individual reviewer are presented.

A.4.3 Optimal Policy
In this section, we characterize the optimal policy for the noiseless community model and the given class of gain and bidding functions. To do so, we independently explain how the expected paper-side and reviewer-side gain are maximized. Then, we show that they can be simultaneously maximized to obtain the optimal policy.

41

Policy to maximize the expected paper-side gain. The expected paper-side gain is maximized by any policy that shows a paper among the set with the minimum number of bids within Di in the highest position to each reviewer i ∈ [n]. We now characterize the maximum expected paper-side gain that can be obtained and then show that the aforementioned policy achieves it.
From the characteristics of the reviewer bidding behavior given in Section A.4.2, each reviewer bids on at most one paper almost surely. This means that the maximum number of bids that can be obtained by any policy is equal to the number of reviewers n = mq almost surely. The expected paper-side gain from (65) for the given paper-side gain function is the sum of the expected value of a strictly concave function of the number of bids on a paper over each the d = mq papers. Consequently, since the maximum number of bids that be obtained by any algorithm is equal to the number of papers almost surely, the expected paper-side gain is maximized if the bids are evenly distributed among the papers so that each paper has exactly one bid almost surely. It then immediately follows that the maximum expected paper-side gain that can be obtained from any algorithm ALG is

E[GpALG] = E[γp(gj)] = γp(1) = mq.

(73)

j∈[d]

j∈[d]

We now show that any policy presenting a paper among the set with a minimum number of bids within Di in the highest position to each reviewer i ∈ [n] maximizes the expected paper-side gain. For any given reviewer i ∈ [n], the q papers in Di are each in Di for q − 1 other reviewers i ∈ [n] and also in Dic for each of the remaining reviewers i ∈ [n]. If a paper from Di is shown in the highest position to reviewer i ∈ [n], then it is bid on almost surely.
Moreover, any paper that is not shown in the highest position to the reviewer is bid on with probability zero. Together,
this means that upon the arrival of each reviewer i ∈ [n], there is a paper in Di with zero bids that has not been shown in the highest position to any reviewer previously almost surely. Consequently, each paper j ∈ [d] is shown exactly once almost surely in the highest position to some reviewer i ∈ Dj. It then follows from the decomposition in (70)
that the expected paper-side gain of this policy ALG is

E[GpALG] = E[γp(gj)] = γp(1) = mq.

(74)

j∈[d]

j∈[d]

We conclude that the policy maximizes the expected paper-side gain since it was shown in (73) that the maximum expected paper-side gain that can be obtained is mq.

Policy to maximize the expected reviewer-side gain. The expected reviewer-side gain as given in (72) is decoupled
between each of the reviewers. Moreover, the expected reviewer-side gain from any reviewer i ∈ [n] only depends on the positions that papers in the set Di are shown. Since the function γrπ as given in (69) is decreasing on the domain R>0, as long as each paper in the set Di is shown before the papers in the set Dic, then the expected reviewer-side gain from any reviewer i ∈ [n] is maximized. This means that if a policy shows papers this way for each reviewer i ∈ [n],
then the expected reviewer-side gain is maximized.

Overall optimal policy. The expected paper-side and reviewer-side gains can be simultaneously maximized. Indeed,
if a paper among the set with the minimum number of bids from Di is shown in the highest position to each reviewer i ∈ [n], then the expected paper-side gain is maximized. Furthermore, if the remaining papers in Di are shown ahead of each paper in Dic for each reviewer i ∈ [n], then the expected reviewer-side gain is maximized. It then follows that this is the optimal policy. We refer to such a policy as OPT in the remainder of the proof.

A.4.4 Optimality of SUPER∗ with Zero Heuristic
We show in this section that SUPER∗ with zero heuristic is equivalent to the optimal policy under the noiseless community model for the given class of gain and bidding functions.
Informal description of SUPER∗ with zero heuristic policy. Recall that as explained in Section 3 and formally characterized in Section 4, SUPER∗ with zero heuristic is designed to maximize the immediate expected gain from each reviewer conditioned on the history. We show that the immediate expected paper-side and reviewer-side gain from any reviewer i ∈ [n] are both maximized by showing a paper with the minimum number of bids among Di in the highest position, followed by the remaining papers in Di in any order, and then the papers from Dic in any order.
The immediate expected paper-side gain from any reviewer i ∈ [n] is maximized by showing a paper with the minimum number of bids among Di in the highest position in the paper ordering. To see why, observe that the immediate expected paper-side gain from any paper that is not shown in the highest position is zero since the probability

42

of it being bid on is zero. Moreover, the probability of a paper being bid on that is shown in the highest position is only non-zero if it is in the set of papers Di. Then, since the given paper-side gain function is strictly concave so the returns of bids are diminishing, we determine that the immediate expected paper-side gain from the paper shown in the highest position of the ordering is maximized if it is a paper with the minimum number of bids among Di.
The expected reviewer-side gain from any reviewer i ∈ [n] is maximized as long as papers in Di are shown ahead of Dic. This follows from the fact that the expected reviewer-side gain as given in (72) is decoupled between the reviewers. Furthermore, the expected reviewer-side gain from any reviewer i ∈ [n] only depends on the positions that papers in the set Di are shown. Since the function γrπ as given in (69) is decreasing on the domain R>0, as long as each paper in the set Di is shown before the papers in the set Dic, then the expected reviewer-side gain from the reviewer is maximized.
Formal description of SUPER∗ with zero heuristic policy. We now formally state the policy of SUPER∗ with zero heuristic policy for the noiseless community model and the given gain and bidding functions. The proof of Lemma 8 is given in Section A.4.8.
Lemma 8. Under the assumptions of Theorem 3, SUPER∗ with zero heuristic shows a paper among the set with the minimum number of bids from Di in the highest position to each reviewer i ∈ [n]. Moreover, the remaining papers in Di are shown in an arbitrary order ahead of the papers in Dic which are also shown in arbitrary order to each reviewer i ∈ [n].
The policy of SUPER∗ with zero heuristic given in Lemma 8 is equivalent to the optimal policy derived in Section A.4.3. We conclude SUPER∗ with zero heuristic is optimal for the noiseless community model with the given class of gain and bidding functions.
A.4.5 Optimality of SIM
The SIM policy shows papers to each reviewer in decreasing order of the similarity scores with ties between a pair of papers broken in favor of the paper with fewer bids and any remaining ties are broken uniformly at random. The similarity score of each paper j ∈ Di is greater than the similarity score of each paper j ∈ Dic for each reviewer. By deﬁnition of the policy, the previous fact immediately implies that for each reviewer i ∈ [n], SIM shows each paper in Di ahead of each paper in Dic. Moreover, the tie-breaking mechanism of SIM guarantees that a paper with the minimum number of bids among Di is shown in the highest position of the paper ordering to each reviewer i ∈ [n]. This policy is equivalent to the optimal policy given in Section A.4.3, and hence SIM is optimal for the noiseless community model with the given class of gain and bidding functions.
A.4.6 Suboptimality of BID
We now prove the suboptimality of BID for the noiseless community model.
Intuition and BID policy. The BID algorithm presents papers in an increasing order of the number of bids and ties between papers are broken in favor of the paper with the higher similarity score. In this section, we go on to show that this policy maximizes the expected paper-side gain. This follows from the fact that almost surely a paper with zero bids and a similarity score exceeding the threshold necessary for a reviewer to bid on a paper is shown in the highest position to each reviewer and bid on. However, for the noiseless community model similarity class, the algorithm is suboptimal for the combined objective since the expected reviewer-side gain obtained is suboptimal. The fundamental problem with BID is that, except for as a tie-breaking mechanism, the similarity scores are ignored by the algorithm. For the given bidding model, papers which are not shown in the highest position are bid on with probability zero. Consequently, showing papers with fewer bids closer, but not in the highest position, cannot improve the expected paper-side gain and reduces the expected reviewer-side gain.
Bounding the expected paper-side gain. Recall from Section A.4.3 that any policy presenting a paper among the set with a minimum number of bids within Di in the highest position to each reviewer i ∈ [n] maximizes the expected paper-side gain. We now follow similar arguments from Section A.4.3 to determine that BID shows a paper among the set with a minimum number of bids among Di in the highest position to each reviewer i ∈ [n] almost surely so that is maximizes the expected paper-side gain.
For any given reviewer i ∈ [n], the q papers in Di are in Di for the same q − 1 other reviewers i ∈ [n] and also in Dic for each of the remaining reviewers i ∈ [n]. For any reviewer i ∈ [n], any paper j ∈ Dic is bid on almost never
43

and any paper j ∈ Di is only bid on with non-zero probability if shown in the highest position to the reviewer. This means that upon the arrival of each reviewer i ∈ [n], there is a paper in Di with zero bids almost surely. Furthermore, the similarity score of any paper in Di is greater than the similarity score of any paper in Dic for each reviewer i ∈ [n]. Hence, BID shows a paper in Di with zero bids in the highest position to each reviewer i ∈ [n] almost surely since
papers are shown in increasing order of the number of bids and ties are broken in favor of the paper with the higher
similarity score. The structure of the bidding function guarantees that if a paper in Di is shown in the highest position of the paper ordering to reviewer i ∈ [n], then it is bid on by the reviewer almost surely. Consequently, each paper j ∈ [d] is shown exactly once almost surely in the highest position to some reviewer i ∈ Dj. It then follows from the decomposition in (70) that the expected paper-side gain of BID for every m ≥ 2, q ≥ 2, and λ ≥ 0, is given by

E[GpBID] = E[γp(gj)] = γp(1) = mq.

j∈[d]

j∈[d]

From the expected paper-side gain of OPT given in (74), we conclude that for every m ≥ 2, q ≥ 2, and λ ≥ 0,

E[GpOPT] − E[GpBID] = 0.

(75)

Bounding the expected reviewer-side gain. We now show that the optimal policy OPT obtains signiﬁcantly more

expected reviewer-side gain than BID. This requires deriving a suitable lower bound on the following expression based

on (72):

λE[GrOPT − GrBID] = λE

(2s − 1) (γrπ(πiOPT(j)) − γr(πiBID(j))) .

(76)

i∈[n]

j∈Di

Let us begin by deﬁning a “good event” for any reviewer and paper under which if the paper has probability zero of being bid on then it is not bid on and if the paper has probability one of being bid on then it is bid on. Formally, for any reviewer k ∈ [n], paper j ∈ [d], and paper ordering πkALG given by an algorithm ALG, we deﬁne

EkA,LjG ={πkALG(j) = 1, Sk,j > s/2, Bk,j = 1} ∪ {πkALG(j) = 1, Bk,j = 0} ∪ {Sk,j < s/2, Bk,j = 0}.

Moreover, for each reviewer i ∈ [n], deﬁne the following event Ei = ∪ik−=11 ∪dj=1 {EkO,PjT ∪ EkB,IjD} which says the good event held for each reviewer that arrived previously for every paper and observe that the complement of this event
occurs on a measure zero space by the structure of the bidding function given in (66). Consequently, from the law of
total expectation, an equivalent form of (76) is given by

λE[GrOPT − GrBID] = λE

(2s − 1)E

(γrπ(πiOPT(j)) − γr(πiBID(j))) Ei .

(77)

i∈[n]

j∈Di

Recall from the derivation of the expected paper-side gain of OPT in Section A.4.3 and BID in this section that each algorithm obtains exactly one bid almost surely from each reviewer and on each paper. Deﬁne F as the set of initial mq/4 reviewers for which upon arrival of such a reviewer i ∈ F at least one paper on the block diagonal for the reviewer given by Di has received a bid previously. Observe that OPT obtains at least as much expected reviewerside gain as BID from each reviewer since it was shown in Section A.4.3 that the policy maximizes the expected
reviewer-side gain from each individual reviewer. As a result, we get the following lower bound on (77):

λE[GrOPT − GrBID] ≥ λE (2s − 1)E

(γrπ(πiOPT(j)) − γr(πiBID(j))) Ei .

(78)

i∈F

j∈Di

We now separate papers into relevant groups deﬁned upon arrival for each reviewer i ∈ F given the event Ei. Let Ti,1 be the set of papers in Di with zero bids and Ti,2 be the set of papers in Di with one bid. Denote by Ti,3 the set of papers in Dic with zero bids and Ti,4 as the papers in Dic with one bid. Moreover, we let Ni,k = |Ti,k| for k ∈ {1, 2, 3, 4} denote the number of papers in each set and deﬁne i = Ni,1 + 1. Using this notation, (78) is
equivalently

λE[GrOPT − GrBID] ≥ λE (2s − 1)E

(γrπ(πiOPT(j)) − γr(πiBID(j))) Ei .

(79)

i∈F

j ∈Ti,1 ∪Ti,2

As shown in Section A.4.3, OPT shows a paper with the minimum number of bids among Di in the highest position of the paper ordering to each reviewer i ∈ F . Again, this paper corresponds to a paper in the set Ti,1 with zero bids.

44

After this paper, the remaining papers in Di are shown in any arbitrary order. This group of papers contains papers among Ti,1 ∪ Ti,2. Since it has no impact on the expected gain in the analysis that follows, without loss of generality,
consider that OPT shows the papers in Ti,1 ahead of the papers in Ti,2. The BID policy shows a paper with the minimum number of bids among Di in the highest position of the paper
ordering to each reviewer i ∈ F almost surely as proved earlier. See that such a paper corresponds to a paper in the set Ti,1 with zero bids. After this paper, the remaining papers with zero bids, which by deﬁnition belong to Ti,1 ∪ Ti,3, are shown with ties broken in favor of the paper with the higher similarity score. Since each paper in Di has a higher similarity score than each paper in Dic, we conclude that BID shows the remaining papers in Ti,1 after the paper shown in the highest position.
Consequently, the papers in Ti,1 are shown among the positions {1, . . . , Ni,1} by both OPT and BID conditioned on the event Ei. This allows us to simplify (79) and get that

λE[GrOPT − GrBID] ≥ λE (2s − 1)E

(γrπ(πiOPT(j)) − γr(πiBID(j))) Ei .

(80)

i∈F

j∈Ti,2

As we just showed, conditioned on the event Ei, OPT shows the papers in Ti,2 in an arbitrary order immediately after the papers in Ti,1 to each reviewer i ∈ F . This means that the papers in Ti,2 are shown among the position set { i, . . . , i + Ni,2 − 1} by OPT to each reviewer i ∈ F conditioned on Ei.
In contrast, BID shows the papers in Ti,2 after the papers in Ti,1 ∪ Ti,3, but before the papers in Ti,4. Indeed, the papers in Ti,3 each have zero bids and the papers in Ti,2 each have one bid, so by deﬁnition of the policy, BID shows the papers in Ti,3 ahead of the papers in Ti,2. Furthermore, by deﬁnition of the sets, the similarity score of each paper in Ti,2 is greater than the similarity score of each paper in Ti,4, which combined with the tie-breaking mechanism of BID ensures that papers in Ti,2 are shown ahead of the papers in Ti,4 even though the number of bids are equal. This means that the papers in Ti,2 are shown among the position set { i + Ni,3, . . . , i + Ni,2 + Ni,3 − 1} by BID to each reviewer i ∈ F conditioned on Ei.
From this set of facts and continuing from (80), we obtain

i +Ni,2 −1

λE[GrOPT − GrBID] ≥ λE (2s − 1) E

(γrπ(j) − γrπ(j + Ni,3)) Ei .

(81)

i∈F

j= i

Minimizing over i ∈ F in (81) and using the deﬁnition |F| = mq/4 , we get the bound

i +Ni,2 −1

λE[GrOPT − GrBID] ≥ λE (2s − 1)( mq/4 ) min E

(γrπ(j) − γrπ(j + Ni,3)) Ei .

(82)

i∈F

j= i

Moreover, for every m ≥ 2 and q ≥ 2, it holds that

mq/4 = mq/4 − (mq mod 4)/4 ≥ mq/8,

(83)

and by deﬁnition of the noiseless community model

2s − 1 ≥ 20.01 − 1 ≥ 1/150.

(84)

Combining (82), (83), and (84), we have

i +Ni,2 −1

λE[GOPT − GBID] ≥

λ E min E

(γπ(j) − γπ(j + Ni,3)) Ei .

(85)

r

r

1200 i∈F

r

r

j= i

Toward the goal of bounding the right-hand side of (85), we now work on verifying the following claim. Claim 1. For each reviewer i ∈ F and conditioned on the event Ei,

Ni,3 ≥ mq − q − m − mq/4 + Ni,2 + 1 ≥ Ni,2 ≥ 1.

(86)

Recall that Ni,3 denotes the number of papers in Dic with zero bids upon the arrival of reviewer i ∈ F . By deﬁnition, the number of papers in Dic is mq − q. To bound Ni,3, we need to bound the maximum number of papers Dic that

45

could have been bid on previously upon the arrival of the reviewer. Observe that upon the arrival of the reviewer, there could be at most ( mq/4 − 1) − (Ni,2 − 1) reviewers from F that previously arrived and bid on a paper in Dic. This follows from the fact that |F| = mq/4 and each reviewer bids on at most one paper almost surely from the structure
of the bidding function given in (66), so the total number of bids from this set of reviewers previously is at most
( mq/4 − 1). Furthermore, of the ( mq/4 − 1) bids from the reviewer set F, the number of bids on papers which are in Di instead of Dic is given by (Ni,2 − 1) since prior to the arrival of the reviewer a paper in Di had to be bid on by deﬁnition of the reviewer set F. Finally, at most (m − 1) papers in Dic are bid on before the arrival of the reviewer from previous reviewers which do not belong to F since there are m blocks in the similarity matrix. Accordingly, the number of papers with a bid in Dic is at most (m − 1) + ( mq/4 − 1) − (Ni,2 − 1). We conclude that the number of papers in Dic without a bid given by Ni,3 for any reviewer i ∈ F conditioned on Ei is bounded below as follows

Ni,3 ≥ mq − q − m − mq/4 + Ni,2 + 1.

(87)

We now show

mq − q − m − mq/4 + Ni,2 + 1 ≥ Ni,2.

(88)

To see (88), observe that

mq − q − m − mq/4 + 1 ≥ mq − q − m − mq/4 + 1 = 3mq/4 − q − m + 1.

(89)

The quantity (3mq/4 − q − m + 1) is increasing in m and q for m ≥ 2, q ≥ 2. Using this fact, we get that for every

m ≥ 2 and q ≥ 2,

3mq/4 − q − m + 1 ≥ 0.

(90)

Combining (89) and (90) immediately implies that (88) holds. Finally, Ni,2 ≥ 1 for each reviewer i ∈ F conditioned on the event Ei by deﬁnition of the reviewer set, which proves the ﬁnal inequality of (86).
Using the result from (86), we now prove the following claim to bound the right-hand side of (85). Claim 2. Conditioned on the event Ei, for each reviewer i ∈ F it must be that

i +Ni,2 −1

(γπ(j) − γπ(j + Ni,3)) ≥ 2

1 .

(91)

r

r

5 log22(mq)

j= i

To begin, for any i ∈ F conditioned on the event Ei we get that

i +Ni,2 −1

i +Ni,2 −1

(γrπ(j) − γrπ(j + Ni,3)) ≥

(γrπ(j) − γrπ(j + mq − q − m − mq/4 + Ni,2 + 1)). (92)

j= i

j= i

The inequality in (92) relies upon the facts that i ≥ 1 for each reviewer i ∈ F by deﬁnition and the function γrπ as given in (69) is decreasing on the domain R>0. As a result of each property, we can invoke the lower bound on Ni,3 from (86) to get the stated bound in (92). Moreover, i + Ni,2 − 1 = |Di| = q by deﬁnition for any i ∈ F given the event Ei, so an equivalent form of the bound in (92) is

i +Ni,2 −1

q

(γrπ(j) − γrπ(j + Ni,3)) ≥ (γrπ(j) − γrπ(j + mq − q − m − mq/4 + Ni,2 + 1)). (93)

j= i

j= i

Now, since i ≥ 1 for each reviewer i ∈ F by deﬁnition, the function γrπ as given in (69) is decreasing on the domain R>0, and mq − q − m − mq/4 + Ni,2 + 1 ≥ 1 from (86), we determine that each summand in (93) is positive. Hence, to obtain a lower bound on (93), we take the maximum i over each reviewer i ∈ F. Recall that i − 1 = Ni,1, which gives the total number of papers in Di without a bid by deﬁnition. For each reviewer i ∈ F , there must be at least one paper with a bid in Di by deﬁnition of the reviewer set given the event Ei. Then, using the fact that |Di| = q, we get i − 1 = Ni,1 ≤ q − 1 so that i ≤ q for any reviewer i ∈ F given the event Ei. Hence, (93)
is lower bounded as follows:

i +Ni,2 −1

(γrπ(j) − γrπ(j + Ni,3)) ≥ γrπ(q) − γrπ(mq − m − mq/4 + Ni,2 + 1).

(94)

j= i

46

Combining the fact that Ni,2 ≥ 1 for each reviewer i ∈ F conditioned on the event Ei by deﬁnition of the reviewer set with (86), we obtain

mq − m − mq/4 + Ni,2 + 1 ≥ mq − m − mq/4 + 2 ≥ q + 1.

(95)

Since γrπ as given in (69) is decreasing on the domain R>0, the inequality in (95) immediately implies

γrπ(mq − m − mq/4 + Ni,2 + 1) ≤ γrπ(mq − m − mq/4 + 2).

(96)

Then, combining (94) and (96) results in the bound

i +Ni,2 −1

(γrπ(j) − γrπ(j + Ni,3)) ≥ γrπ(q) − γrπ(mq − m − mq/4 + 2).

(97)

j= i

To bound (γrπ(q) − γrπ(mq − m − mq/4 + 2)), we need the following result proved in Section A.4.8.2. Lemma 9. Fix m ≥ 2, q ≥ 2, and let γrπ(x) = 1/ log2(x + 1). Then,

γrπ(q) − γrπ(mq − m − mq/4 + 2) ≥ 52

1 log22(mq) .

Applying Lemma 9 to (97), we arrive at the lower bound claimed in (91). Then, relating (91) back to (82), for every m ≥ 2, q ≥ 2, and λ ≥ 0, the following bound holds

λE[GOPT − GBID] ≥ 1

λmq .

(98)

r

r

3000 log22(mq)

Observe that the expectation in the right-hand side of (98) is dropped since it is not a random variable.
Completing the bound. Combining the bounds on the expected paper-side and reviewer-side gain between OPT and BID given in (77) and (98), we ﬁnd for every m ≥ 2, q ≥ 2, λ ≥ 0,

E[GOPT − GBID] = E[GpOPT − GpBID] + λE[GrOPT − GrBID]

≥1 3000

λmq log22(q) .

We conclude that there exists a constant c > 0 such that for every m ≥ 2, q ≥ 2, and λ ≥ 0, BID is suboptimal by an additive factor of at least cλmq/ log22(mq) for the noiseless community model.

A.4.7 Suboptimality of RAND

In this section, we show the suboptimality of RAND for the noiseless community model.

Intuition and RAND policy. The RAND algorithm selects a paper ordering uniformly at random from the set of permutations of papers. For the given class of gain and bidding functions, this is problematic since to obtain a bid from a reviewer, a paper from the block diagonal for the reviewer must be shown in the highest position. Since at least half of the papers are not on the block diagonal of the similarity matrix for any reviewer, there is a signiﬁcant probability that RAND fails to induce a bid from each reviewer. This causes the algorithm to be suboptimal for the expected paper-side gain.

Bounding the expected paper-side gain. Recall from (70) that the expected paper-side gain from any paper j ∈ [d]

is given by
q

E[γp(gj)] = P = 1{πiRAND(j) = 1} γp( ).

(99)

=0

i∈Dj

To bound this quantity for a given paper, we need to characterize the distribution of the number of times the paper is shown in the highest position to reviewers for which it is on the block diagonal.

47

The RAND algorithm selects a paper ordering uniformly at random from the set of paper permutations. This means the probability of paper any paper j ∈ [d] being shown in the highest position to any reviewer i ∈ [n] is 1/mq since there are d = mq papers. Consequently, the number of times paper j ∈ [d] is shown in the highest position to reviewers in the set Dj follows a binomial distribution with q trials, since the cardinality of Dj is q, and a success probability of 1/mq. This means the expected paper-side gain from any paper j ∈ [d] given in (99) for RAND is equivalently

qq 1 E[γp(gj)] = mq
=0

1 − 1 q− γp( ). mq

(100)

To bound (100), we need the following lemma that bounds the expectation of the square root of a binomial random variable with n trials and success probability p.

Lemma 10.

Fix n ≥ 2 and p ∈ [0, 1]. Then, n n pk(1 − p)n−k√k ≤ np(1 − p)n−1 k
k=0

√ 1− 2
2

√

2

+ np

.

2

The proof of Lemma 10 is provided in Section A.4.8.3.

We can directly apply Lemma 10 to (100) since the given paper-side gain function is the square root function. The number of trials is q ≥ 2 and the success probability is 1/mq, so for any paper j ∈ [d], we obtain

qq 1 E[γp(gj)] = mq
=0

1 − 1 q− γp( ) ≤ 1

mq

m

1− 1 mq

√ q−1 1 − 2
2

√ 2
+. 2m

(101)

The bound in the right-hand side of (101) is decreasing in m and q for m ≥ 2 and q ≥ 2. This means for every m ≥ 2,

q ≥ 2, and any paper j ∈ [d],

√

E[γp(gj)] ≤ 6 +

2 .

16

To get a ﬁnal bound on the expected paper-side gain of the algorithm, we sum the previous bound over the number of

papers and obtain

E[GpRAND] = E[γp(gj )] ≤
j∈[d]

√ 6+ 2
mq. 16

(102)

Combining (102) with the expected paper-side gain of the optimal policy which was shown to be mq in Section A.4.3,

this implies for every m ≥ 2, q ≥ 2, and λ ≥ 0,

E[GpOPT − GpRAND] ≥ mq −

√ 6+ 2
mq. 16

(103)

Bounding the expected reviewer-side gain. We compare the expected reviewer-side gain of the optimal algorithm OPT and RAND. Previously in Section A.4.3 we showed that the optimal algorithm maximizes the expected reviewerside gain. This means that the expected reviewer-side gain of RAND cannot exceed that from the optimal policy OPT. Consequently, for every m ≥ 2, q ≥ 2, and λ ≥ 0 we get the bound

λE[GrOPT − GrRAND] ≥ 0.

(104)

Completing the bound. Combining the bounds on the expected paper-side and reviewer-side gain between the optimal algorithm OPT and RAND given in (103) and (104), for every m ≥ 2, q ≥ 2, and λ ≥ 0, we get that

E[GOPT − GRAND] = E[GpOPT − GpRAND] + λE[GrOPT − GrRAND] √
≥ mq − 6 + 2 mq ≥ mq/2. 16
We conclude that there exists a constant c > 0 such that for every m ≥ 2, q ≥ 2, and λ ≥ 0, RAND is suboptimal by an additive factor of at least cmq for the noiseless community model.

48

A.4.8 Proofs of Lemmas 8–10

In this section, we present the proofs of technical lemmas stated in the primary proof of Theorem 3.
A.4.8.1 Proof of Lemma 8. In the proof of Corollary A.2 given in Section A.2, we showed in (17) that SUPER∗ with zero heuristic solves the problem

πiSUPER∗ = arg max
πi ∈Πd

f (πi(j), Si,j )(γp(gi−1,j + 1) − γp(gi−1,j )) + λ γr(πi(j), Si,j )

j∈[d]

j∈[d]

(105)

in order to determine the ordering of papers πiSUPER∗ to present to reviewer i ∈ [n] so that the immediate expected gain is maximized conditioned on the history of bids from reviewers that arrived previously. Recalling that the bidding function is f (πi(j), Si,j) = 1{πi(j) = 1}1{Si,j > s/2}, the optimization problem in (105) is equivalent to

πiSUPER∗ = arg max 1{πi(j) = 1}1{Si,j > s/2}(γp(gi−1,j + 1) − γp(gi−1,j )) + λ γr(πi(j), Si,j ). (106)

πi∈Πd j∈[d]

j∈[d]

Observe that Di ∪ Dic = [d]. Moreover, if j ∈ Di, then Si,j > s/2 since Si,j = s by deﬁnition of the noiseless community model similarity matrix and s ∈ [0.01, 1]. Analogously, if j ∈ Dic, then Si,j < s/2 since Si,j = 0 by deﬁnition of the noiseless community model similarity matrix and s ∈ [0.01, 1]. This allows us to simplify (106) to
the following problem:

πiSUPER∗ = arg max
πi ∈Πd

1{πi(j) = 1}(γp(gi−1,j + 1) − γp(gi−1,j )) + λ γr(πi(j), Si,j ).

j∈Di

j∈[d]

(107)

The given paper-side gain function γp is such that γp(gi−1,j +1)−γp(gi−1,j) is decreasing as a function of the number of bids gi−1,j. As a result, the expected paper-side gain term from (107), which is given by

1{πi(j) = 1}(γp(gi−1,j + 1) − γp(gi−1,j )),
j∈Di

(108)

is maximized by showing a paper j ∈ Di with the minimum number of bids in the highest position of the paper ordering. Moreover, the given reviewer-side gain function γr from (68) is decreasing in the position πi(j) in which a paper is shown and increasing in the similarity score Si,j. Consequently, the expected reviewer-side gain term from (107), which is given by

γr(πi(j), Si,j ),

(109)

j∈[d]

is maximized by showing papers in decreasing order of the similarity scores. The similarity score is Si,j = s ∈ [0.01, 1] for papers in Di and the similarity score is Si,j = 0 for papers in Dic by deﬁnition of the noiseless community model. Accordingly, the expected reviewer-side gain term in (109) is maximized as long as each paper in Di is shown earlier in the paper ordering than each paper in Dic.
Since the expected paper-side and reviewer-side gain terms of (107) given by (108) and (109) respectively can be
simultaneously maximized by showing any of the papers with the minimum number of bids among Di in the highest position, followed by the remaining papers in Di in any arbitrary order, and then the papers in Dic in any arbitrary order, we conclude this is the policy of SUPER∗ with zero heuristic.

A.4.8.2 Proof of Lemma 9. Recall that γrπ = 1/ log2(x + 1). Moreover, ﬁx m ≥ 2 and q ≥ 2. Simplifying the expression we seek to bound, we obtain

γrπ(q) − γrπ(mq − m −

mq/4

+ 2) =

1

−

1

log2(q + 1) log2(mq − m − mq/4 + 2 + 1)

= log2(mq − m − mq/4 + 2 + 1) − log2(q + 1) . log2(mq − m − mq/4 + 2 + 1) log2(q + 1)

We now lower bound the numerator of the right-hand side of (110). For any ﬁxed m ≥ 2 and q ≥ 2,

(110)

log2(mq − m − mq/4 + 2 + 1) − log2(q + 1) ≥ log2(2q − q/2 + 1) − log2(q + 1).

(111)

49

To see why, observe that mq − m − mq/4 is non-decreasing as a function of m for m ≥ 2 and q ≥ 2. The non-decreasing property follows from the fact that

(m + 1)q − (m + 1) − (m + 1)q/4 = mq − m + q − 1 − mq/4 + q/4 ≥ mq − m + q − 1 − ( mq/4 + q/4 + 1) = mq − m − mq/4 + q − q/4 − 2 ≥ mq − m − mq/4 .

To get the ﬁnal inequality, consider

q − q/4 − 2 = q − q/4 + (q mod 4)/4 − 2 = 3q/4 + (q mod 4)/4 − 2

(112)

and notice that for q = 2, (112) is zero, and for q > 2, (112) is positive.
Now, see that log2(2q − q/2 + 1) − log2(q + 1) is increasing as a function of q since 2q − q/2 > q for q ≥ 2. Accordingly, for every m ≥ 2 and q ≥ 2,

log2(2q − q/2 + 1) − log2(q + 1) ≥ log2(4) − log2(3) ≥ 2/5.

(113)

To ﬁnish, we obtain a lower bound on (110) by ﬁnding an upper bound on the denominator in the right-hand side.
Observe that log2(mq − m − mq/4 + 2 + 1) ≤ log2(mq) since m + mq/4 ≥ 3 and log2(q + 1) ≤ log2(mq) for every m ≥ 2 and q ≥ 2. Then, combined with (110), (111), and (113), we obtain the stated result of

γrπ(q) − γrπ(mq − m − mq/4 + 2) ≥ 52

1 log22(mq) .

A.4.8.3

Proof of Lemma 10. Given n ≥ 2 and p ∈ [0, 1], we need to prove the bound

nn

√

√

√

2

2

pk(1 − p)n−k k ≤ np(1 − p)n−1 1 −

+ np

.

k=0 k

2

2

To begin, observe that Then, since

n n pk(1 − p)n−k√k = n n pk(1 − p)n−k√k.

k

k

k=0

k=1

(114)

n pk =

n!

pk = np

k

k!(n − k)!

k

(n − 1)!

pk−1 = np

(k − 1)!(n − k)!

k

n − 1 pk−1, k−1

we can simplify (114) to obtain

nn

√

n √k

pk(1 − p)n−k k = np

k=0 k

k=1 k

n − 1 pk−1(1 − p)n−k. k−1

From the fact that n √k
np k=1 k

√

√

k k

≤

2 2

n−1 k−1

for k ≥ 2, we bound (115) as follows:
n
pk−1(1 − p)n−k = np(1 − p)n−1 + np k=√2
≤ np(1 − p)n−1 + np 2 2

√ k k
n
k=2

n − 1 pk−1(1 − p)n−k k−1 n − 1 pk−1(1 − p)n−k. k−1

Relating (116) back to (115), we get

n n pk(1 − p)n−k√k ≤ np(1 − p)n−1 + np √2 n n − 1 pk−1(1 − p)n−k.

k

2

k−1

k=0

k=2

(115)
(116) (117)

50

√

From addition and subtraction of np(1 − p)n−1

2 2

into the right-hand side of (117), we obtain

n n pk(1 − p)n−k√k ≤ np(1 − p)n−1 1 − √2 + np √2 n n − 1 pk−1(1 − p)n−k.

k

2

2

k−1

k=0

k=1

Now, see that from an indexing manipulation

n

n−1

n−1
pk−1(1 − p)n−k =

n−1

pk(1 − p)n−1−k.

k=1 k − 1

k=0 k

Moreover, from the Binomial theorem,

n−1 n − 1 pk(1 − p)n−1−k = (p + (1 − p))n−1 = 1. k=0 k

Combining (118), (119), and (120) gives the ﬁnal result of n n pk(1 − p)n−k√k ≤ np(1 − p)n−1 k
k=0

√ 1− 2
2

√

2

+ np

.

2

(118) (119) (120)

A.5 Proof of Theorem 4: Noisy Community Model Result
In this proof, we show for the noisy community model that SUPER∗ with zero heuristic is near optimal and each of the baselines is signiﬁcantly suboptimal with respect to SUPER∗ with zero heuristic. The organization of this proof is as follows. In Section A.5.1, we present notation and preliminary analysis that is needed throughout the proof. In Section A.5.2, we analyze SUPER∗ with zero heuristic and compute the expected paper-side gain for the similarity matrix class. We prove the suboptimality bounds for the SIM, BID, and RAND baselines with respect to SUPER∗ with zero heuristic separately in Sections A.5.3, A.5.4, and A.5.5 respectively. We ﬁnish the proof in Section A.5.6 by showing that SUPER∗ with zero heuristic is near optimal. Combining the results in each section of this proof gives the stated result of the theorem. Proofs of technical lemmas needed only for this proof can be found in Section A.5.7. The proofs of technical lemmas used in this proof, but introduced in the proof of Theorem 3, are given in Section A.4.8. Finally, we remark that a number of methods for proving this result are similar to that from the proof of Theorem 3 and we point out in several places where this is the case as well as where the techniques differ.

A.5.1 Notation and Preliminaries
The notation and terminology in this proof follow that from the proof of Theorem 3 in Section A.4.1 since the gain and bidding functions are shared between the results and the noisy community model is based on the noiseless community model. The primary adjustment is that any reference to a similarity matrix S refers to that from the noisy community model, which is generated by selecting some similarity matrix S from the noiseless community model as given in in (7), and then adding noise in the manner described in (8). Recall that the noise in the similarity score for each reviewer-paper pair (i, j) denoted by νi,j is drawn independently and uniformly from (0, ξ) where ξ ≤ (1+λ)−1e−emq for the given trade-off parameter λ ≥ 0. We also follow the notation from the proof of Theorem 3 in Section A.4.1, in terms of terminology of reviewers and papers on the block diagonal and keep the sets Di for all i ∈ [n] and Dj for all j ∈ [d] from (63) and (64) deﬁned in terms of the noiseless community model similarity matrix now given by S .
In an analogous manner to the preliminaries section of the proof of Theorem 3, we present several characteristics of the reviewer bidding behavior and the similarity scores that are needed throughout the proof. This set of rather immediate results also enable a decomposition of the expected paper-side gain equivalent to that for the noiseless community model from the proof of Theorem 3 given in (70).
We begin by showing if a paper is on the block diagonal for a reviewer, then it is bid on almost surely when shown in the highest position of the paper ordering to the reviewer and almost never when it is not.
Lemma 11. Under the assumptions of Theorem 4, if the reviewer-paper pair (i, j) is on the block diagonal of the noiseless community model matrix S so that i ∈ Dj and j ∈ Di, then in the noisy community model matrix Si,j > s/2. Moreover, the paper j ∈ [d] is bid on by reviewer i ∈ [n] almost surely when πiALG(j) = 1 and almost never when πiALG(j) = 1.

51

Proof of Lemma 11. If the reviewer-paper pair (i, j) is on the block diagonal of the noiseless community model matrix

S , then by deﬁnition Si,j = s and Si,j = s − νi,j where the noise νi,j is drawn uniformly at random from the interval (0, ξ). Moreover, recall that s ∈ [0.01, 1] and ξ ≤ (1 + λ)−1e−emq. Accordingly, for λ ≥ 0, m ≥ 2, and q ≥ 2, we

obtain

ξ ≤ (1 + λ)−1e−emq ≤ e−4e < 0.01/2 ≤ s/2.

(121)

Since νi,j ∈ (0, ξ), we immediately get Si,j > s − ξ. Then applying (121), we conclude that Si,j > s/2. Finally, since

the

probability

of

reviewer

i

bidding

on

paper

j

is

given

by

the

quantity

f

(π

ALG i

(j

),

Si,j

)

=

1{πiALG(j)

=

1}1{Si,j

>

s/2}, the reviewer bids on the paper almost surely when πiALG(j) = 1 and almost never when πiALG(j) = 1.

We now show that if a paper is not on the block diagonal for a given reviewer, then the reviewer bids on the paper almost never independent of the position the paper is shown.

Lemma 12. Under the assumptions of Theorem 4, if the reviewer-paper pair (i, j) is not on the block diagonal of
the noiseless community model matrix S so that i ∈ Djc and j ∈ Dic, then in the noisy community model matrix Si,j < s/2. Moreover, paper j ∈ [d] is bid on almost never by reviewer i ∈ [n] independent of πiALG(j).

Proof of Lemma 12. If the reviewer-paper pair (i, j) is not on the block diagonal of the noiseless community model
matrix S , then by deﬁnition Si,j = 0 and Si,j = νi,j where the noise νi,j is drawn uniformly at random from the interval (0, ξ). Since νi,j ∈ (0, ξ), we immediately get Si,j < ξ. Then applying (121), we conclude that Si,j < s/2. Finally, since the probability of reviewer i bidding on paper j is given by the quantity f (πiALG(j), Si,j) = 1{πiALG(j) = 1}1{Si,j > s/2}, the reviewer bids on the paper almost never independent of the position the paper is shown to the reviewer given from πiALG(j).

Observe that Lemmas 11 and 12 imply that each reviewer bids on at most one paper almost surely. Moreover, they can also be combined to determine that any paper on the block diagonal for a reviewer is guaranteed to have a higher similarity score than any paper not on the block diagonal for the reviewer.

Lemma 13. Under the assumptions of Theorem 4, if the reviewer-paper pair (i, j) is on the block diagonal of the
noiseless community model matrix S so that i ∈ Dj and j ∈ Di, and the reviewer-paper pair (i, j ) is not on the block diagonal of the noiseless community model matrix S so that i ∈ Djc and j ∈ Dic, then in the noisy community model matrix Si,j > Si,j .

We now apply the preceding results to show that the expected paper-side gain from a given paper j ∈ [d] only depends on the positions it is shown to reviewers i ∈ [n] by some algorithm ALG for which the reviewer-paper pair (i, j) is on the block diagonal of the similarity matrix. The expected paper-side gain for any paper j ∈ [d] simpliﬁes
to be

E[γp(gj)] = E γp

Bi,j

i∈[n]

= E γp

Bi,j

i∈Dj

q
=P
=0

= 1{πiALG(j) = 1} γp( ).
i∈Dj

(122)

The above equation follows from Lemma 12, which indicates that the the bid from any reviewer i ∈ Djc is zero almost surely independent of the position the paper is shown, and from Lemma 11, which guarantees any reviewer i ∈ Dj bids on the paper j ∈ [d] almost surely if πiALG(j) = 1 and almost never if πiALG(j) = 1. As mentioned at the beginning of this section, this decomposition of the expected paper-side gain for the noisy community model in (122) is equivalent
to that for the noiseless community model given in (70).

A.5.2 Analyzing SUPER∗ with Zero Heuristic
In this section, we present a preliminary analysis of SUPER∗ with zero heuristic for the noisy community model similarity matrix class with the given gain and bidding functions. We begin by characterizing the behavior of SUPER∗ with zero heuristic. Following deriving the policy, the expected paper-side gain of the algorithm is computed. The analysis of the expected reviewer-side gain is deferred to the sections showing the suboptimality of the baselines with respect to SUPER∗ with zero heuristic (speciﬁcally, see Sections A.5.3 and A.5.4). However, we do provide intuition in this section for why the expected reviewer-side gain is nearly optimal.

52

Intuition and SUPER∗ with zero heuristic policy. The given bidding function is such that only the paper shown in the highest position to a reviewer has a non-zero probability of being bid on. Intuitively Lemma 11 and Lemma 12 suggest that to optimize the expected paper-side gain, the algorithm should seek to show a paper on the block diagonal for the reviewer in the highest position. Moreover, since the given paper-side gain function exhibits diminishing returns in the number of bids, showing the paper on the block diagonal with fewest bids maximizes the immediate expected paper-side gain.
The given reviewer-side gain function is decreasing in the position a paper is shown and increasing in the similarity score of the paper. This indicates that to maximize the immediate expected reviewer-side gain, papers should be shown in a decreasing order of the similarity scores to the reviewer. For the given noisy community model similarity class, the similarity scores of papers on the block diagonal for a given reviewer are signiﬁcantly higher than the similarity scores of papers off the block diagonal for the given reviewer as was formalized in Lemma 13. Furthermore, the noise is bounded in a small interval. Consequently, the similarity scores for papers on the block diagonal for a reviewer are nearly identical and the similarity scores for papers off the block diagonal for a reviewer are also nearly identical. This suggests that as long as papers on the block diagonal are shown ahead of papers off the block diagonal for a reviewer, then the expected reviewer-side gain from a given reviewer should be close to the maximum that can be obtained.
The high-level view of the objective the algorithm is optimizing indicates that the immediate expected paper-side gain can be maximized with minimal cost to the immediate expected reviewer-side gain. This can be achieved by showing the paper on the block diagonal for the reviewer with the minimum number of bids in the highest position and the remaining papers in a decreasing order of the similarity scores. The following lemma formalizes the intuition that has been given.
Lemma 14. Under the assumptions of Theorem 4, when reviewer i ∈ [n] arrives, if there is a paper in Di with zero bids and each paper in Di has at most one bid, then SUPER∗ with zero heuristic shows the reviewer the paper with the maximum similarity score among the papers without a bid in Di at the highest position followed by the remaining papers in a decreasing order of the similarity scores.
The proof of Lemma 14 is provided in Section A.5.7.1. It turns out that the conditions of Lemma 14, namely the existence of a paper in Di with zero bids and each paper in Di having at most one bid upon the arrival of reviewer i ∈ [n], are met using SUPER∗ with zero heuristic almost surely. We now formally characterize this statement and then compute the expected paper-side gain of the algorithm.
Computing the expected paper-side gain. Consider a group of q reviewers denoted by R for which Di = Di for every pair of reviewers i, i ∈ R, meaning that the papers on the block diagonal for the reviewers are equivalent. Observe that from the structure of the noisy community model, for every reviewer i ∈ R, it also holds that Di ⊂ Dic for all i ∈ Rc, meaning that the papers on the block diagonal for each reviewer in R are off the block diagonal for all reviewers in Rc. Moreover, there are m such blocks of reviewers analogous to the given group R.
Upon the initial arrival of a reviewer i from R, from Lemma 12 each paper in Di has zero bids almost surely since they are off the block diagonal for all reviewers that arrived previously. From Lemma 14, SUPER∗ with zero heuristic shows this reviewer the paper in Di with the maximum similarity score in the highest position of the paper ordering. Lemma 11 guarantees that this paper is bid on by the reviewer almost surely and the rest of the papers in Di are bid on almost never by the reviewer.
We now consider the next arrival of a reviewer i from R and note that Di = Di by deﬁnition of this set of reviewers. Between the arrivals of reviewers i and i , none of the papers in Di obtain any more bids almost surely since again from Lemma 12 any paper that is off the block diagonal for a reviewer is bid on almost never independent of the position the paper is shown. This means each paper in Di has zero bids almost surely except for the paper that has a bid from reviewer i almost surely. Accordingly, we apply Lemma 14 to determine that SUPER∗ with zero heuristic shows this reviewer the paper with the maximum similarity score among the papers without a bid within Di in the highest position of the paper ordering. Then, Lemma 11 guarantees that this paper is bid on by the reviewer almost surely and the rest of the papers in Di are bid on almost never by the reviewer.
Repeatedly applying this argument, upon the ﬁnal arrival of a reviewer i from R, each paper in Di has exactly one bid except for one paper that remains without a bid almost surely. We note again that by deﬁnition of this set of reviewers Di = Di. From Lemma 14, SUPER∗ with zero heuristic shows the ﬁnal paper without a bid within Di in the highest position of the paper ordering and Lemma 11 ensures that this paper is bid on by the reviewer almost surely and the rest of the papers in Di are bid on almost never by the reviewer.
Following the arrival of reviewer i , the papers in Di never appear on the block diagonal for a reviewer again and ﬁnish with exactly one bid almost surely after each being shown in the highest position of the paper ordering
53

exactly once to some reviewer for which they are on the block diagonal almost surely. The line of reasoning applied to the group of reviewers R can be duplicated for each of the m blocks of reviewers which share papers on the block
diagonal. In doing so, it immediately follows from the decomposition in (122) that the expected paper-side gain of SUPER∗ with zero heuristic for every m ≥ 2, q ≥ 2, and λ ≥ 0, is given by

E[G

SUPER∗ p

]

=

E[γp(gj)] =

γp(1) = mq.

j∈[d]

j∈[d]

(123)

Identically as in the derivation of the optimal expected paper-side gain for the noiseless community model given in Section A.4.3, this is the optimal expected paper-side gain that can be obtained since each reviewer bids on at most one paper almost surely and the given paper-side gain function is strictly concave so evenly distributing the bids over the papers maximizes the expected paper-side gain.
Properties of SUPER∗ with zero heuristic for the noisy community model similarity matrix. Since the conditions of Lemma 14 are satisﬁed for each reviewer almost surely, SUPER∗ with zero heuristic shows each reviewer i ∈ [n] the paper with the maximum similarity score among the papers without a bid in Di followed by the remaining papers in a decreasing order of the similarity scores. This fact leads to several properties of the algorithm for this similarity matrix class. From Lemma 13, Si,j > Si,j for j ∈ Di, j ∈ Dic. This means the paper with the maximum similarity score among the papers without a bid in Di is equivalently the paper with the maximum similarity score among the papers without a bid. This results in the following property of the algorithm.
Property 1. SUPER∗ with zero heuristic presents the paper with the maximum similarity score among the papers without a bid in the highest position of the paper ordering and the remaining papers in a decreasing order of the similarity scores to each reviewer i ∈ [n] almost surely.

Similarly, using Lemma 13, we can determine that the algorithm shows each paper that is on the block diagonal of the similarity matrix for the reviewer ahead of each paper off the block diagonal.
Property 2. SUPER∗ with zero heuristic shows every paper in Di ahead of every paper in Dic to each reviewer i ∈ [n] almost surely.

The ﬁnal property that again follows from Lemma 13 is that the algorithm shows the papers off the block diagonal in a decreasing order of the similarity scores.
Property 3. SUPER∗ with zero heuristic shows papers among Dic in a decreasing order of the similarity scores to each reviewer i ∈ [n] almost surely.
The properties of SUPER∗ with zero heuristic provided are going to assist the comparison of the expected reviewerside gain with that from the baselines and the optimal policy. As discussed previously, intuitively Property 2 should guarantee that the algorithm obtains near-optimal expected reviewer-side gain since the noise in the similarity scores is bounded in a small interval and the similarity scores of papers on the block diagonal are much higher than that for papers off the block diagonal for a reviewer.

A.5.3 Suboptimality of SIM
In this section, we analyze SIM for the noisy community model similarity matrix class with the given gain and bidding functions.
Intuition and SIM policy. The SIM algorithm presents papers in a decreasing order of the similarity scores. This approach maximizes the expected reviewer-side gain since the given reviewer-side gain function is decreasing in the position a paper is shown and increasing in the similarity score of the paper. However, for the noisy community model similarity matrix class, the algorithm is suboptimal for the combined objective since the expected paper-side gain is far from optimal. As shown in the analysis of SUPER∗ with zero heuristic, to maximize the expected paper-side gain, each paper should only be shown in the highest position of the paper ordering to a reviewer once almost surely. Moreover, this must be when the paper is on the block diagonal for a reviewer so that it obtains a bid almost surely. The problem with SIM for this similarity matrix class is that it is oblivious to the number of bids on papers. As a result, the algorithm may show a paper in the highest position of the paper ordering to a reviewer that has only marginally higher similarity score, but many more bids, than another option. While this may result in a scarce amount more gain from

54

the reviewer-side objective, we show it is costly in terms of the paper-side objective. We formalize this by showing
SIM is signiﬁcantly suboptimal for the expected paper-side gain, and that it only achieves a marginal amount more expected reviewer-side gain than SUPER∗ with zero heuristic.

Bounding the expected paper-side gain. Recall from (122) that the expected paper-side gain from any paper j ∈ [d]

is given by
q

E[γp(gj)] = P = 1{πiSIM(j) = 1} γp( ).

(124)

=0

i∈Dj

To bound this quantity for a given paper, we need to characterize the distribution of the number of times the paper is
shown in the highest position of the paper ordering to reviewers for which it is on the block diagonal. Toward this goal, let us consider any reviewer i ∈ [n] and the probability of each paper being shown in the highest
position of the paper ordering for the reviewer. For the given reviewer, the set of papers on the block diagonal is given by Di and this set has cardinality q. Moreover, from Lemma 13, Si,j > Si,j for j ∈ Di, j ∈ Dic. This result says the similarity score of any paper on the block diagonal for the reviewer is greater than the similarity score of any paper off
the block diagonal for the reviewer.
The SIM algorithm shows papers in a decreasing order of the similarity scores, which combined with Lemma 13, guarantees that the probability of any paper j ∈ Dic being shown in the highest position of the paper ordering is zero. For any paper j ∈ Di, the similarity score is given by Si,j = s − νi,j. The noise νi,j for each reviewer-paper pair (i, j) is drawn independently and uniformly at random from a bounded interval. This implies that the probability of any paper j ∈ Di being shown in the highest position to the reviewer is 1/q since there are q papers in the set.
Recall that Dj for any paper j ∈ [d] denotes the reviewers i ∈ [n] for which the reviewer-paper pair (i, j) is on the block diagonal of the similarity matrix. From the preceding reasoning, the probability of paper j ∈ [d] being shown in the highest position to each reviewer i ∈ Dj is 1/q. Consequently, the number of times paper j ∈ [d] is shown in the highest position to reviewers in the set Dj follows a Binomial distribution with q trials since the cardinality of Dj is q and a success probability of 1/q. This means the expected paper-side gain from any paper j ∈ [d] given in (124) for
SIM, is equivalently expressed as

qq1 E[γp(gj)] = q
=0

1 − 1 q− γp( ). q

(125)

To bound (125), we can directly apply Lemma 10, which bounds the expectation of the square root of a binomial

random variable, and obtain

qq1 E[γp(gj)] = q
=0

1 − 1 q− γp( ) ≤ q

√

1 − 1 q−1 1 − 2

q

2

√ 2
+. 2

(126)

The bound in (126) is decreasing in q for q ≥ 2. This means for every q ≥ 2 and any paper j ∈ [d],

√

E[γp(gj)] ≤ 2 +

2 .

4

To get the expected paper-side gain of the algorithm, we sum this bound over the number of papers and obtain

E[GpSIM] = E[γp(gj)] ≤
j∈[d]

√ 2+ 2
mq. 4

(127)

Combining (127) with the expected paper-side gain of SUPER∗ with zero heuristic from (123), this implies for every

m ≥ 2, q ≥ 2, and λ ≥ 0,

E[GpSUPER∗ − GpSIM] ≥ mq −

√ 2+ 2
mq. 4

(128)

Bounding the expected reviewer-side gain. We now turn our attention to comparing the expected reviewer-side gain of SUPER∗ with zero heuristic and SIM. We need to bound

λE[GrSUPER∗ − GrSIM] = λE

(γr(πiSUPER∗ (j), Si,j ) − γr(πiSIM(j), Si,j )) .

i∈[n] j∈[d]

(129)

55

Toward doing so, recall Property 2, which says SUPER∗ with zero heuristic shows every paper in Di ahead of every paper in Dic to each reviewer i ∈ [n] almost surely. Moreover, Property 3 says the papers among Dic are shown in decreasing order of the similarity scores to each reviewer i ∈ [n] almost surely. In comparison, SIM shows papers in decreasing order of the similarity scores to each reviewer i ∈ [n]. From Lemma 13, the similarity scores of papers in Di are greater than the similarity scores of papers in Dic for each reviewer i ∈ [n]. Combining this fact with the policy of SUPER∗ with zero heuristic and SIM, we can see that the algorithms show the papers among Dic in identical positions almost surely. This means the reviewer-side gain from this set of papers is equivalent for each of
the algorithms almost surely.
Since the noise is bounded in a small interval, we expect that the ordering among papers in Di would not impact the expected reviewer-side gain signiﬁcantly as long as they are shown before the papers in Dic. The following result formalizes this intuition and provides a bound.

Lemma 15. Let πi denote the paper ordering that presents papers in decreasing order of the similarity scores. Moreover, denote by πi any paper ordering that shows each paper in Di ahead of each paper in Dic and papers among Dic in a decreasing order of the similarity scores. Then, under the assumptions of Theorem 4, the following bound holds
for every m ≥ 2, q ≥ 2, and λ ≥ 0:

λ

γr(πi (j), Si,j) − γr(πi (j), Si,j ) ≥ −qe−emq log(4).

j∈[d]

The proof of Lemma 15 is provided in Section A.5.7.2.
The result of Lemma 15 immediately applies to (129) for each reviewer conditioned on the almost sure events given the characteristics of SUPER∗ with zero heuristic and SIM mentioned earlier and since it holds for any realization of the noise in the similarity scores. Combining (129) with Lemma 15 and noting that there are n = mq reviewers, we obtain for every m ≥ 2, q ≥ 2, and λ ≥ 0,

λE[GrSUPER∗ − GrSIM] = λE

(γr(πiSUPER∗ (j), Si,j ) − γr(πiSIM(j), Si,j )) ≥ −mq2e−emq log(4).

i∈[n] j∈[d]

(130)

Finally, see that for every m ≥ 2 and q ≥ 2,

−mq2e−emq log(4) ≥ −8e−4e log(4) ≥ −0.0001

(131)

since −mq2e−emq log(4) is negative and increasing as a function of m and q for m ≥ 2 and q ≥ 2. From (130) and (131), we get that for every m ≥ 2, q ≥ 2, and λ ≥ 0,

λE[GrSUPER∗ − GrSIM] ≥ −0.0001.

(132)

Completing the bound. Combining the bounds on the expected paper-side and reviewer-side gain between SUPER∗ with zero heuristic and SIM given in (128) and (132), we get that for every m ≥ 2, q ≥ 2, and λ ≥ 0,
E[GSUPER∗ − GSIM] = E[GpSUPER∗ − GpSIM] + λE[GrSUPER∗ − GrSIM] √
≥ mq − 2 + 2 mq − 0.0001 4
≥ mq/10.

We conclude that there is a constant c > 0 such that for every m ≥ 2, q ≥ 2, and λ ≥ 0, SUPER∗ with zero heuristic obtains an additive factor of at least cmq more expected gain than SIM in the noisy community model.

A.5.4 Suboptimality of BID
We now analyze BID for the noisy community model with the given gain and bidding functions. We remark that much of the analysis in this section follows very similarly to that for BID given in Section A.4.6 from the proof of Theorem 3 regarding the noiseless community model since the reviewer bidding behavior is identical in the noisy community model as characterized by Lemmas 11, 12, and 13. The primary adjustments are in the analysis of the expected reviewer-side gain with respect to SUPER∗ with zero heuristic.

56

Bounding the expected paper-side gain. For any given reviewer i ∈ [n], the q papers in Di are each in Di for q − 1 other reviewers i ∈ [n] and also in Dic for each of the remaining reviewers i ∈ [n]. For any reviewer i ∈ [n], any paper j ∈ Dic is bid on almost never from Lemma 12 and any paper j ∈ Di is only bid on with non-zero probability if shown in the highest position to the reviewer from Lemma 11. This means that upon the arrival of each reviewer
i ∈ [n], there is a paper in Di with zero bids that has not been shown in the highest position to any reviewer previously almost surely. Furthermore, from Lemma 13, the similarity score of any paper in Di is greater than the similarity score of any paper in Dic for each reviewer i ∈ [n]. Therefore, BID shows a paper in Di with zero bids in the highest position to each reviewer i ∈ [n] almost surely since papers are shown in increasing order of the number of bids and
ties are broken in favor of the paper with the higher similarity score. Lemma 11 guarantees that if a paper in Di is shown in the highest position of the paper ordering to reviewer i ∈ [n], then it is bid on by the reviewer almost surely.
Consequently, each paper j ∈ [d] is shown exactly once almost surely in the highest position to some reviewer to some
reviewer i ∈ Dj. It then follows from the decomposition in (122) that the expected paper-side gain of BID for every m ≥ 2, q ≥ 2, and λ ≥ 0, is given by

E[GpBID] = E[γp(gj)] = γp(1) = mq.

j∈[d]

j∈[d]

From the expected paper-side gain of SUPER∗ with zero heuristic given in (123), we conclude that for every

m ≥ 2, q ≥ 2, and λ ≥ 0,

E[G

SUPER∗ p

]

−

E[GpBID]

=

0.

(133)

Before moving on to the expected reviewer-side gain, we point out that SUPER∗ with zero heuristic and BID show the same paper in the highest position to each reviewer almost surely as direct result of Lemma 14, the deﬁnition of the BID policy, and the derivations of the expected paper-side gain for each algorithm.

Property 4. SUPER∗ with zero heuristic and BID show the same paper in the highest position of the paper ordering to each reviewer almost surely.

As we now show, the suboptimality of BID stems from the fact that after the paper shown in the highest position, the remaining papers are presented in increasing order of the number of bids, whereas SUPER∗ with zero heuristic
shows the remaining papers in decreasing order of the similarity scores.

Bounding the expected reviewer-side gain. We now focus on showing SUPER∗ with zero heuristic obtains signif-

icantly more expected reviewer-side gain than BID. This requires deriving a suitable lower bound on the following

expression:

λE[GrSUPER∗ − GrBID] = λE

(γr(πiSUPER∗ (j), Si,j ) − γr(πiBID(j), Si,j )) .

(134)

i∈[n] j∈[d]

Let us begin by deﬁning a “good event” for any reviewer and paper under which if the paper has probability zero of being bid on then it is not bid on and if the paper has probability one of being bid on then it is bid on. Formally, for any reviewer k ∈ [n], paper j ∈ [d], and paper ordering πkALG given by an algorithm ALG, we deﬁne

EkA,LjG ={πkALG(j) = 1, Sk,j > s/2, Bk,j = 1} ∪ {πkALG(j) = 1, Bk,j = 0} ∪ {Sk,j < s/2, Bk,j = 0}.

Moreover, for each reviewer i ∈ [n], deﬁne the following event Ei = ∪ki−=11 ∪dj=1 {EkS,UjPER∗ ∪ EkB,IjD} which says the good event held for each reviewer that arrived previously for every paper and observe that the complement of this
event occurs on a measure zero space by the structure of the bidding function given in (66). Consequently, from the
law of total expectation, an equivalent form of (134) is given by

λE[GrSUPER∗ − GrBID] = λE

E

(

γ

r

(

π

SUPER i

∗

(j

),

Si,j )

−

γr (πiBID (j ),

Si,j ))

Ei

.

i∈[n] j∈[d]

(135)

From Property 4, SUPER∗ with zero heuristic and BID show the same paper in the highest position of the paper ordering to any reviewer i ∈ [n] given the event Ei. Moreover, from Property 1, SUPER∗ with zero heuristic presents the remainder of the papers in a decreasing order of the similarity scores given the event Ei. This implies that for each reviewer i ∈ [n], SUPER∗ with zero heuristic obtains at least as much reviewer-side gain as BID given the event
Ei since the reviewer-side gain function is increasing in the similarity score and decreasing in the position a paper is

57

shown. Deﬁne F as the initial set of mq/4 reviewers for which upon arrival of such a reviewer i ∈ F at least one paper on the block diagonal for the reviewer given by Di has received a bid previously, where we recall that SUPER∗
with zero heuristic and BID each obtain exactly one bid from each reviewer and on each paper almost surely as proved in the analysis of the expected paper-side gains. From (135) and the fact that SUPER∗ with zero heuristic obtains at least as much expected reviewer-side gain as BID from each reviewer given the event E, we obtain

λE[GrSUPER∗ − GrBID] ≥ λE

E

(

γ

r

(

π

SUPER i

∗

(j

)

,

Si,j )

−

γr (πiBID (j ),

Si,j ))

Ei

.

i∈F j∈[d]

(136)

We now separate papers into relevant groups deﬁned upon arrival for each reviewer i ∈ F. Let Ti,1 be the set of
papers containing only the paper that each algorithm shows in the highest position that has zero bids and belongs to the set Di. Let Ti,2 denote the remaining set of papers in Di with zero bids and Ti,3 be the set of papers in Di with one bid. Denote by Ti,4 the set of papers in Dic with zero bids and Ti,5 as the papers in Dic with one bid. Moreover, we let Ni,k = |Ti,k| for k ∈ {1, 2, 3, 4, 5} denote the number of papers in each set and deﬁne i = Ni,1 + Ni,2 + 1.
Accordingly, (136) is equivalently

λE[GrSUPER∗ − GrBID] ≥ λE

E

(γ

r

(π

SUPER i

∗

(j

)

,

Si,j )

−

γr (πiBID (j ),

Si,j ))

Ei

i∈F

j ∈Ti,1 ∪Ti,2 ∪Ti,3 ∪Ti,4 ∪Ti,5

. (137)

From Property 4, SUPER∗ with zero heuristic and BID show the same paper in the highest position of the paper ordering to each reviewer i ∈ [n] given Ei. This allows us to simplify (137) and get that

λE[GrSUPER∗ − GrBID] ≥ λE

E

(γ

r

(π

SUPER i

∗

(j

)

,

Si,j )

−

γr (πiBID (j ),

Si,j ))

Ei

.

i∈F

j ∈Ti,2 ∪Ti,3 ∪Ti,4 ∪Ti,5

(138)

Given event Ei, SUPER∗ with zero heuristic shows papers among Ti,2 ∪ Ti,3 in decreasing order of the similarity scores followed by papers among Ti,4 ∪ Ti,5 in decreasing order of the similarity scores consequent of Properties 1, 2, and 3.
Now consider an algorithm ALG that shows papers from Ti,k ahead of papers from Ti,k+1 for each k ∈ {1, 2, 3, 4}. Moreover, let this algorithm present papers among each group Ti,k for k ∈ {1, 2, 3, 4, 5} in decreasing order of the similarity scores. The given reviewer-side gain function is decreasing in the position a paper is shown and increasing
in the similarity score. This means the expected reviewer-side gain from any reviewer is maximized by showing papers in decreasing order of the similarity scores. Consequently, the expected reviewer-side gain of SUPER∗ with
zero heuristic from each reviewer is at least as much as that from ALG. This fact leads to a lower bound on (138) of

λE[GrSUPER∗ − GrBID] ≥ λE

E

(γr(πiALG(j), Si,j ) − γr(πiBID(j), Si,j )) Ei

i∈F

j ∈Ti,2 ∪Ti,3 ∪Ti,4 ∪Ti,5

(139)

where now Ei = ∪ik−=11 ∪dj=1 {EkA,LjG ∪ EkB,IjD}. The BID policy shows papers in Ti,2 ∪ Ti,4 ahead of papers in Ti,3 ∪ Ti,5. Moreover, papers in Ti,2 are shown
ahead of papers in Ti,4 and papers in Ti,3 ahead of papers in Ti,5. Papers among each group Ti,k for k ∈ {2, 3, 4, 5} are shown in decreasing order of the similarity scores. This characterization of the BID policy follows from deﬁnition,
since papers are shown in increasing order of the number of bids with ties broken by the similarity scores. Recall that the similarity scores of papers in Ti,2 ∪ Ti,3 are greater than the similarity scores of papers in Ti,4 ∪ Ti,5 from Lemma 13. It is now clear that ALG and BID show papers among Ti,2 ∪ Ti,5 in identical positions given the event Ei. Combining this fact with (139), we get that

λE[GrSUPER∗ − GrBID] ≥ λE

E

(γr(πiALG(j), Si,j ) − γr(πiBID(j), Si,j )) Ei .

i∈F

j ∈Ti,3 ∪Ti,4

(140)

We now separate the sum over papers in Ti,3 from the sums over papers in Ti,4 in (140) to obtain

λE[GrSUPER∗ − GrBID] ≥ λE

E

(γr(πiALG(j), Si,j ) − γr(πiBID(j), Si,j )) Ei

i∈F j∈Ti,3

+E

(γr(πiALG(j), Si,j ) − γr(πiBID(j), Si,j )) Ei .

i∈F j∈Ti,4

(141)

58

The ALG policy shows papers in Ti,3 followed by papers in Ti,4, with each group of papers being presented in decreasing order of the similarity scores to each reviewer given the event Ei. In contrast, the BID policy shows papers in
Ti,4 followed by papers in Ti,3, with each group of papers being presented in decreasing order of the similarity scores.
This means that BID shows each paper in Ti,3 later in the paper ordering by Ni,4 positions compared to ALG to each reviewer given Ei. Analogously, ALG shows each paper in Ti,4 later in the paper ordering by Ni,3 positions compared to BID to each reviewer given Ei. This set of facts and continuing from (137), leads to the bound

λE[GrSUPER∗ − GrBID] ≥ λE

E

(γr(πiALG(j), Si,j ) − γr(πiALG(j) + Ni,4, Si,j )) Ei

i∈F j∈Ti,3

−E

(γr(πiBID(j), Si,j ) − γr(πiBID(j) + Ni,3, Si,j )) Ei .

i∈F j∈Ti,4

(142)

From the decomposed form of the reviewer-side gain function in (69), an equivalent form of (142) is

λE[GrSUPER∗ − GrBID] ≥ λE

E

(2Si,j − 1)(γrπ(πiALG(j)) − γrπ(πiALG(j) + Ni,4)) Ei

i∈F j∈Ti,3

−E

(2Si,j − 1)(γrπ(πiBID(j)) − γrπ(πiBID(j) + Ni,3)) Ei .

i∈F j∈Ti,4

(143)

The similarity scores of papers in Ti,3 are given by Si,j = s − νi,j and the similarity score of papers in Ti,4 are Si,j = νi,j. Recall that the noise is bounded in the interval (0, ξ). Combining this with the fact that the function γrπ
from (69) is decreasing on the domain R>0, we bound (143) as follows

λE[GrSUPER∗ − GrBID] ≥ λE (2s−ξ − 1) E

(γrπ(πiALG(j)) − γrπ(πiALG(j) + Ni,4)) Ei

i∈F j∈Ti,3

− (2ξ − 1) E

(γrπ(πiBID(j)) − γrπ(πiBID(j) + Ni,3)) Ei .

i∈F j∈Ti,4

(144)

Now recall that ALG shows the papers in Ti,3 after the papers in Ti,1 ∪ Ti,2. Similarly, BID shows the papers in Ti,4 after the papers in Ti,1 ∪ Ti,2. Recall that i = Ni,1 + Ni,2 + 1. From this notation and (144), we obtain

λE[GrSUPER∗ − GrBID] ≥ λE (2s−ξ − 1) E
i∈F

i +Ni,3 −1
(γrπ(j) − γrπ(j + Ni,4)) Ei
j= i

i +Ni,4 −1

− (2ξ − 1) E

(γrπ(j) − γrπ(j + Ni,3)) Ei .

i∈F

j= i

(145)

Following the exact techniques to prove Claim 1 in Section A.4.6 for the expected reviewer-side gain analysis of BID in the noiseless community model, we get that for each reviewer i ∈ F and conditioned on the event Ei,

Ni,4 ≥ mq − q − m − mq/4 + Ni,3 + 1 ≥ Ni,3 ≥ 1.

(146)

Now, toward the goal of bounding (145), we perform the following indexing manipulations:

i +Ni,4 −1
(γrπ(j) − γrπ(j + Ni,3)) =
j= i
=
=

i +Ni,4 −1
γrπ(j) −
j= i

i +Ni,3 +Ni,4 −1
γrπ (j )
j= i+Ni,3

i +Ni,3 −1
γrπ(j) −
j= i

i +Ni,3 +Ni,4 −1
γrπ (j )
j= i+Ni,4

i +Ni,3 −1
(γrπ(j) − γrπ(j + Ni,4)).
j= i

(147) (148)

59

To obtain (147), we used the fact from (146) that Ni,4 ≥ Ni,3 for any reviewer i ∈ F given the event Ei. Then from (144) and (148), we get

λE[GrSUPER∗ − GrBID] ≥ λE (2s−ξ − 2s)

i +Ni,3 −1

E

(γrπ(j) − γrπ(j + Ni,4)) Ei .

i∈F

j= i

(149)

Minimizing over i ∈ F in (149) and using the deﬁnition |F| = mq/4 , we have

i +Ni,3 −1

λE[GrOPT − GrBID] ≥ λE (2s − 1)( mq/4 ) min E
i∈F

(γrπ(j) − γrπ(j + Ni,4)) Ei .
j= i

Moreover, for every m ≥ 2, q ≥ 2, it holds that

(150)

mq/4 = mq/4 − (mq mod 4)/4 ≥ mq/8.

(151)

By deﬁnition of the noisy community model and the given bound on ξ, for every m ≥ 2, q ≥ 2, and λ ≥ 0, we get

2s−ξ − 2ξ = 2s−(1+λ)−1e−emq − 2(1+λ)−1e−emq ≥ 20.01−e−4e − 2e−4e ≥ 1/150.

(152)

Combining (150), (151), and (152), we have

i +Ni,3 −1

λE[GSUPER∗ − GBID] ≥

λ E min E

(γπ(j) − γπ(j + Ni,4)) Ei .

r

r

1200 i∈F

r

r

j= i

(153)

Then, applying exactly the same techniques to prove Claim 2 in Section A.4.6 for the expected reviewer-side gain analysis of BID in the noiseless community model, for every i ∈ F conditioned on the event Ei, we have

i +Ni,3 −1

min

(γπ(j) − γπ(j + Ni,4)) ≥ 2

i∈F

r

r

5

j= i

1 log22(mq) .

(154)

Finally, combining (154) with (153), for every m ≥ 2, q ≥ 2, and λ ≥ 0, the following bound holds

λE[GrOPT − GrBID] ≥ 30100

λmq log22(mq) .

(155)

Observe that the expectation in the right-hand side of (155) is dropped since it is not a random variable.
Completing the bound. Combining the bounds on the expected paper-side and reviewer-side gain between SUPER∗ with zero heuristic and BID given in (133) and (155), we ﬁnd for every m ≥ 2, q ≥ 2, λ ≥ 0,

E[GSUPER∗ − GBID] = E[GpSUPER∗ − GpBID] + λE[GrSUPER∗ − GrBID]

≥1 3000

λmq log22(mq) .

We conclude that there exists a constant c > 0 such that for every m ≥ 2, q ≥ 2, and λ ≥ 0, SUPER∗ with zero heuristic obtains an additive factor of at least cλmq/ log22(mq) more expected gain than BID for the noisy community
model.

A.5.5 Suboptimality of RAND
In this section, we analyze RAND for the noisy community model similarity class with the given gain and bidding functions. A signiﬁcant amount of the analysis in this section follows identically to that from analyzing RAND in the noiseless community model from Section A.4.7 and the reason for the suboptimal behavior is identical.

60

Bounding the expected paper-side gain. Recall from (122) that the expected paper-side gain from any paper j ∈ [d]

is given by
q

E[γp(gj)] = P = 1{πiRAND(j) = 1} γp( ).

(156)

=0

i∈Dj

We remark that the decomposition of the expected paper-side gain from any paper given in (156) for RAND in the noisy

community model is identical to that given in (99) for RAND in the noiseless community model. Since the RAND policy

is independent of the similarity scores and the reviewer bids, the distribution of the number of times a paper is shown

in the highest position to reviewers for which it is on the block diagonal is identical in the noisy community model as

it is in the noiseless community model. Accordingly, we directly bound the expected paper-side gain of RAND in the

noisy community model using the bound from (102) derived in Section A.4.7 for RAND in the noiseless community model. Then, combining with the expected paper-side gain of SUPER∗ with zero heuristic from (123), we get that for

every m ≥ 2, q ≥ 2, and λ ≥ 0,

E[GpSUPER∗ − GpRAND] ≥ mq −

√ 6+ 2
mq. 16

(157)

Bounding the expected reviewer-side gain. We now need to compare the expected reviewer-side gain of SUPER∗
with zero heuristic and RAND. The SIM algorithm obtains the maximum expected reviewer-side gain that can be
achieved since the reviewer-side gain function is increasing in the similarity score and decreasing in the position a paper is shown. Consequently, the bound on the expected reviewer-side gain from (132) between SUPER∗ with zero heuristic and SIM applies to RAND. Using the bound from (132), we get that for every m ≥ 2, q ≥ 2, and λ ≥ 0,

λE[GrSUPER∗ − GrRAND] ≥ −0.0001.

(158)

Completing the bound. Combining the bounds on the expected paper-side and reviewer-side gain between SUPER∗ with zero heuristic and RAND given in (157) and (158), for every m ≥ 2, q ≥ 2, and λ ≥ 0,

E[GSUPER∗ − GRAND] = E[GpSUPER∗ − GpRAND] + λE[GrSUPER∗ − GrRAND] √
≥ mq − 6 + 2 mq − 0.0001 ≥ mq/2. 16
We conclude that there exists a constant c > 0 such that for every m ≥ 2, q ≥ 2, and λ ≥ 0, SUPER∗ with zero heuristic obtains an additive factor of at least cmq more expected gain than RAND in the noisy community model.

A.5.6 Near-Optimality of SUPER∗ with Zero Heuristic

In this section, we show that SUPER∗ with zero heuristic is nearly optimal. We let OPT denote the optimal algorithm for the expected gain.

Bounding the expected paper-side gain. As explained in Section A.5.2, the expected paper-side gain of SUPER∗ with zero heuristic is the maximum that can be achieved. Indeed, this is consequent of the facts that each reviewer bids on at most one paper almost surely and the given paper-side gain function is strictly concave so evenly distributing the bids over the papers maximizes the expected paper-side gain. We conclude that for every m ≥ 2, q ≥ 2, and λ ≥ 0,

E[G

SUPER∗ p

]

−

E[GpOPT]

≥

0.

(159)

Bounding the expected reviewer-side gain. The SIM algorithm obtains the maximum expected reviewer-side gain that can be achieved since the reviewer-side gain function as given in (68) is increasing in the similarity score and decreasing in the position a paper is shown, which means showing papers in decreasing order of the similarity scores to each reviewer maximizes the expected reviewer-side gain. Consequently, the bound on the expected reviewer-side gain from (132) between SUPER∗ with zero heuristic and SIM applies to the optimal algorithm. Using the bound from (132), we get that for m ≥ 2, q ≥ 2, and λ ≥ 0,

λE[GrSUPER∗ − GrOPT] ≥ −0.0001.

(160)

61

Completing the bound. Combining the bounds on the expected paper-side and reviewer-side gain between SUPER∗ with zero heuristic and OPT given in (159) and (160), we get that for every m ≥ 2, q ≥ 2, and λ ≥ 0,
E[GSUPER∗ − GOPT] = E[GpSUPER∗ − GpOPT] + λE[GrSUPER∗ − GrOPT] ≥ −0.0001.
We conclude SUPER∗ with zero heuristic is always within at least an additive factor of 0.0001 of the optimal in the noisy community model.

A.5.7 Proofs of Lemmas 14–15

In this section, we present the proofs of technical lemmas invoked in the primary proof of Theorem 4.
A.5.7.1 Proof of Lemma 14. In the proof of Corollary A.2 given in Section A.2, we showed in (17) that SUPER∗ with zero heuristic solves the problem

πiSUPER∗ = arg max
πi ∈Πd

f (πi(j), Si,j )(γp(gi−1,j + 1) − γp(gi−1,j )) + λ γr(πi(j), Si,j )

j∈[d]

j∈[d]

(161)

in order to determine the ordering of papers πiSUPER∗ to present to reviewer i ∈ [n] so that the immediate expected gain is maximized conditioned on the history of bids from reviewers that arrived previously. Recalling that the bidding function is f (πi(j), Si,j) = 1{πi(j) = 1}1{Si,j > s/2}, the optimization problem in (161) is equivalent to

πiSUPER∗ = arg max 1{πi(j) = 1}1{Si,j > s/2}(γp(gi−1,j + 1) − γp(gi−1,j )) + λ γr(πi(j), Si,j ). (162)

πi∈Πd j∈[d]

j∈[d]

Observe that Di ∪ Dic = [d]. Moreover, if j ∈ Di, then Si,j > s/2 from Lemma 11. Analogously, if j ∈ Dic, then Si,j < s/2 from Lemma 12. This allows us to simplify (162) to the following problem:

πiSUPER∗ = arg max
πi ∈Πd

1{πi(j) = 1}(γp(gi−1,j + 1) − γp(gi−1,j )) + λ γr(πi(j), Si,j ).

j∈Di

j∈[d]

(163)

Given the assumption that there is a paper in Di with zero bids and each paper in Di has at most one bid, we need to prove SUPER∗ with zero heuristic shows the paper with the maximum similarity score among the papers without a bid in Di followed by the remaining papers in a decreasing order of the similarity scores. To do so, we analyze
the solution to (163) when the paper with the maximum similarity score has zero bids and when the paper with the maximum similarity score has one bid. For each scenario, we show SUPER∗ with zero heuristic presents the paper
with the maximum similarity score among the papers without a bid in the highest position and the remaining papers
in a decreasing order of the similarity scores. This is equivalent to the stated result we seek to prove since from Lemma 13, Si,j > Si,j for j ∈ Di, j ∈ Dic, which guarantees the paper with the maximum similarity score belongs to the set Di and the paper with the maximum similarity score among the papers without a bid belongs to the set Di.
Before analyzing each scenario, we recall some key properties of the functions in the optimization problem given in (163) under the assumptions. The given paper-side gain function γp is such that the quantity γp(gi−1,j + 1) − γp(gi−1,j) is decreasing as a function of the number of bids gi−1,j. As a result, the expected paper-side gain term
from (163), which is given by

1{πi(j) = 1}(γp(gi−1,j + 1) − γp(gi−1,j )),
j∈Di

(164)

is maximized by showing the paper j ∈ Di with the minimum number of bids in the highest position of the paper ordering. Moreover, the given reviewer-side gain function γr from (68) is decreasing in the position πi(j) in which a paper is shown and increasing in the similarity score Si,j. Consequently, the expected reviewer-side gain term from (163), which is given by

γr(πi(j), Si,j ),

(165)

j∈[d]

is maximized by showing papers in decreasing order of the similarity scores.

62

Solution when the paper with the maximum similarity score has zero bids. If the paper with the maximum similarity score has zero bids, then the solution to (163) is to present the papers in decreasing order of the similarity scores. To see why this solution is optimal, observe that it maximizes each component of (163) given in (164) and (165) since the paper with the maximum similarity score has the minimum number of bids among the set Di and papers are in decreasing order of the similarity scores. This solution is equivalent to presenting the paper with the maximum similarity score among the papers without a bid in the highest position and the remaining papers in a decreasing order of the similarity scores since the paper with the maximum similarity score has zero bids.

Solution when the paper with the maximum similarity score has one bid. To determine the solution to (163)
when the paper with the maximum similarity score has one bid, we consider groups of candidate solutions. We group
potential solutions into the set of paper orderings that show a paper with at least one bid in the highest position (group
1) and the set of paper orderings that show a paper without a bid in the highest position (group 2). For each group of
paper orderings, we ﬁnd the solution that maximizes the objective of the optimization problem in (163). To resolve
which is optimal, we compare the objective values of the solutions from each group.
Analyzing Group 1. For this group, the solution is constrained to the set of paper orderings that show a paper
with at least one bid in the highest position. The solution among this group that maximizes the objective of (163) is to
show papers in decreasing order of the similarity scores. We call this candidate solution πi . The candidate solution πi can be seen to be optimal among the group since it maximizes (164) subject to the
constraint of the group and it maximizes (165). Indeed, solution πi maximizes (164) subject to the constraint of the group since the paper with the maximum similarity score has the minimum number of bids among the papers in Di with at least one bid. Moreover, solution πi maximizes (165) since papers are shown in decreasing order of the similarity scores.
Analyzing Group 2. For this group, the solution is constrained to the set of paper orderings that show a paper
without a bid in the highest position. The solution among this group that maximizes the objective of (163) is to show
the paper with the maximum similarity score among the papers with zero bids in the highest position and then present
the remaining papers in decreasing order of the similarity scores. We call this candidate solution πi . The candidate solution πi can be seen to be optimal among the group since it maximizes (164) and it maxi-
mizes (165) subject to the constraint of the group as we now show. From assumption, there is at least one paper in Di with zero bids. The similarity score of any paper in Di is greater than the similarity score of any paper in Dic from Lemma 13. This implies that the paper with the maximum similarity score among the papers with zero bids is in Di. Therefore, we conclude solution πi maximizes (164) since the paper with the maximum similarity score among the papers with zero bids is in Di and it has the minimum number of bids among the papers in Di. Moreover, solution πi maximizes (165) subject to the constraint of the group since the paper with maximum similarity among the set of papers with zero bids is shown in the highest position and the remaining papers are shown in decreasing order of the
similarity scores.
Comparing candidate solutions πi and πi . We now compare the objective of (163) for the candidate solutions πi and πi . Our goal is to show the objective given πi is greater than the objective given πi . This is to say, we wish to show the following quantity is positive

1{πi (j) = 1} − 1{πi (j) = 1} (γp(gi−1,j + 1) − γp(gi−1,j)) + λ

γr(πi (j), Si,j ) − γr(πi (j), Si,j ) .

j∈Di

j∈[d]

(166)

To simplify notation, let the quantity in (166) be denoted by C. Since πi shows a paper in Di with one bid in the highest position and πi shows a paper in Di with zero bids in the highest position, we obtain

C = (γp(1) − γp(0)) − (γp(2) − γp(1)) + λ

γr(πi (j), Si,j ) − γr(πi (j), Si,j ) .

j∈[d]

Since πi presents papers in decreasing order of the similarity scores and πi shows the papers in Dic in a decreasing order of the similarity scores after the papers in Di, we can apply Lemma 15 to get

C ≥ (γp(1) − γp(0)) − (γp(2) − γp(1)) − qe−emq log(4).

(167)

Observe that −qe−emq log(4) is negative and an increasing as a function of m and q on the domain m ≥ 2 and q ≥ 2. This means for every m ≥ 2 and q ≥ 2,

−qe−emq log(4) ≥ −2e−4e log(4) ≥ −0.01.

(168)

63

Moreover, for the given paper-side gain function, √
(γp(1) − γp(0)) − (γp(2) − γp(1)) = 2 − 2

(169)

Combining (167), (168), and (169), we obtain √
C ≥ 2 − 2 − 0.01 > 0.
Since C > 0, we can conclude the objective of (163) given πi is greater than the objective of (163) given πi . This means that the solution when the paper with the maximum similarity score has one bid is to show the paper with the maximum similarity score among the papers with zero bids in the highest position and then present the remaining papers in decreasing order of the similarity scores.
Combining the solutions. We have now derived the solution to (163) when the paper with the maximum similarity score has not obtained a bid previously and when the paper with the maximum similarity score has obtained exactly one bid previously. For each scenario, we showed SUPER∗ with zero heuristic presents the paper with the maximum similarity score among the papers without a bid in the highest position and the remaining papers in a decreasing order of the similarity scores. This allows us to conclude that if there is a paper in Di with zero bids and each paper in Di has at most one bid, then SUPER∗ with zero heuristic shows the paper with the maximum similarity score among the papers without a bid in Di followed by the remaining papers in a decreasing order of the similarity scores.
A.5.7.2 Proof of Lemma 15. From the stated result, πi denotes the paper ordering that presents papers in decreasing order of the similarity scores. Recall that Di denotes the set of papers on the block diagonal of the similarity matrix for any reviewer i ∈ [n]. Moreover, πi is any paper ordering that shows each paper in Di ahead of each paper in Dic and papers among Dic in a decreasing order of the similarity scores. Given this information, we need to bound

λ (γr(πi (j), Si,j) − γr(πi (j), Si,j)).
j∈[d]

Each paper ordering πi and πi shows the papers in Dic in a decreasing order of the similarity scores after the papers in Di since from Lemma 13, Si,j > Si,j for j ∈ Di, j ∈ Dic. This means papers in Dic are shown in identical positions by each paper ordering, so we get

λ (γr(πi (j), Si,j) − γr(πi (j), Si,j) = λ (γr(πi (j), Si,j) − γr(πi (j), Si,j)).

j∈[d]

j∈Di

Equivalently, from the decomposed form of the given reviewer-side gain function from (68),

λ (γr(πi (j), Si,j ) − γr(πi (j), Si,j ) = λ (2Si,j − 1)γrπ(πi (j)) − λ (2Si,j − 1)γrπ(πi (j)).

j∈[d]

j∈Di

j∈Di

By deﬁnition, the similarity score of each paper j ∈ Di is given by Si,j = s − νi,j. Moreover, νi,j is bounded in (0, ξ), so s − ξ < s − νi,j < s. This fact leads to the lower bound

λ (γr(πi (j), Si,j) − γr(πi (j), Si,j) ≥ λ(2s−ξ − 1) γrπ(πi (j)) − λ(2s − 1) γrπ(πi (j)).

j∈[d]

j∈Di

j∈Di

Each paper ordering πi and πi shows the papers in Di in some order among the set of positions {1, . . . , q} since there are q papers in Di by deﬁnition and each paper in Di is shown ahead of each paper in Dic. From this observation, we obtain
λ (γr(πi (j), Si,j ) − γr(πi (j), Si,j ) ≥ λ(2s−ξ − 2s) γrπ(j),

j∈[d]

j∈[q]

which is equivalently

λ (γr(πi (j), Si,j ) − γr(πi (j), Si,j ) ≥ λ(2s−ξ − 2s)

1 log2(j + 1)

j∈[d]

j∈[q]

64

from the deﬁnition of γrπ given in (69). Since λ(2s−ξ − 2s) ≤ 0 and 1/ log2(j + 1) ≤ 1 for each j ∈ [q], we obtain
λ (γr(πi (j), Si,j) − γr(πi (j), Si,j ) ≥ λq(2s−ξ − 2s).
j∈[d]
Recall that ξ ≤ (1 + λ)−1e−emq, which means
λ (γr(πi (j), Si,j ) − γr(πi (j), Si,j ) ≥ λq(2s−(1+λ)−1e−emq − 2s).
j∈[d]
Now, see that λ(2s−(1+λ)−1e−emq − 2s) is non-positive and a decreasing function of λ and s on the domain λ ≥ 0 and s ≥ 0.01. This means for every λ ≥ 0 and s ≥ 0.01, the following relation holds
λ(2s−(1+λ)−1e−emq − 2s) ≥ λ(21−(1+λ)−1e−emq − 2) ≥ lim λ (21−(1+λ )−1e−emq − 2)
λ →∞
= −e−emq log(4).
Consequently, we conclude
λ (γr(πi (j), Si,j) − γr(πi (j), Si,j) ≥ −qe−emq log(4).
j∈[d]
B Additional Results
In this section, we formally state and prove a pair of results that were mentioned informally in the main paper. We characterize the time complexity per-reviewer of the SUPER∗ algorithm for the general model and for a selected set of gain and bidding functions that admit a computationally efﬁcient solution. Moreover, we show that SUPER∗ with any heuristic is globally optimal given a linear paper-side gain. This result is a corollary of the fact that SUPER∗ is locally optimal as shown in Theorem 1.
B.1 Time Complexity of SUPER∗
The following proposition characterizes the time complexity of the SUPER∗ algorithm for each reviewer given the evaluations of the heuristic for the general form and a relevant class of gain and bidding functions that admits a computational efﬁcient solution.
Proposition 1. SUPER∗ has a time complexity of O(d3) per-reviewer given the evaluations of the heuristic function. The time complexity of SUPER∗ improves to O(d log(d)) given a bidding function that can be decomposed into the form f (πi(j), Si,j) = f π(πi(j))f S(Si,j) where f π : [d] → [0, 1] is non-increasing and f S : [0, 1] → [0, 1] is non-decreasing, along with a reviewer-side gain function that can be decomposed into the form γr(πi(j), Si,j) = f π(πi(j))γrS(Si,j) where γrS : [0, 1] → R≥0 is non-decreasing.
Proof of Proposition 1. We partition this proof by ﬁrst examining the time complexity under the general model and then after which we consider the time complexity for the special case. General time complexity. We begin by showing the time complexity of SUPER∗ for a reviewer given the heuristic evaluations under the general class of gain and bidding functions. The general form of the SUPER∗ algorithm calls Algorithm 2 upon the arrival of a reviewer to determine the ordering of papers to show the reviewer. The optimization problem in Algorithm 2 is in the form of the linear assignment problem. It is well known that the Hungarian algorithm can solve for the optimal solution of a linear assignment problem with a time complexity of O(d3) (see, e.g., Chapter 8 in Lawler, 1976). As a result, SUPER∗ has a time complexity of O(d3) for the general class of gain and bidding functions under consideration for each reviewer given the evaluations of the heuristic function.
65

Special case time complexity. In the proof of Theorem 1, we showed that the optimal paper ordering to present the ﬁnal reviewer could be obtained by solving the linear program given in (13) with the weights from (14). The general version of SUPER∗ determines the ordering of papers to present any reviewer by calling Algorithm 2, which solves the linear program given in (13) using the weights from (15). We now show an equivalence between that solution method and a sorting algorithm for the class of gain and bidding functions given in the claim.
Prior to deriving the linear program in (13) as a method to obtain the optimal solution for the ﬁnal reviewer in the proof of Theorem 1, we showed in (12) that the optimization problem for the ﬁnal reviewer was of the form

max
πn ∈Πd

f (πn(j), Sn,j )(γp(gn−1,j + 1) − γp(gn−1,j )) + λ γr(πn(j), Sn,j ).

j∈[d]

j∈[d]

Given the function forms f (πn(j), Sn,j) = f π(πn(j))f S(Sn,j) where f π : [d] → [0, 1] is non-increasing and f S : [0, 1] → [0, 1] is non-decreasing, and γr(πn(j), Sn,j) = f π(πn(j))γrS(Sn,j) where γrS : [0, 1] → R≥0 is non-
decreasing, the problem can be reformulated as

max
πn ∈Πd

αn,j f π(πn(j))
j∈[d]

(170)

where

αn,j = f S (Sn,j )(γp(gn−1,j + 1) − γp(gn−1,j )) + λγrS (Sn,j ) ∀ j ∈ [d].

Consequently, for the class of gain and bidding functions given in the claim, an equivalent form of the general SUPER∗ algorithm that calls Algorithm 2 to determine the ordering of papers to show any reviewer i ∈ [n] instead solves the problem in (170) using weights

αi,j = f S (Si,j )(γp(gi−1,j + hi,j + 1) − γp(gi−1,j + hi,j )) + λγrS (Si,j ) ∀ j ∈ [d].

(171)

The optimal solution to a problem of the form in (170) is simply to present the papers in decreasing order of their corresponding values of αi,j since the function f π is non-increasing. The sorting procedure requires a time complexity of just O(d log(d)). Since Algorithm 3 solves the problem in (170) using the weights in (171), we conclude that the per-reviewer time complexity of SUPER∗ for the given class of gain and bidding functions and given the evaluations
of the heuristic is O(d log(d)).

B.2 SUPER∗ Optimality for Linear Paper-Side Gain
In this section, we show that SUPER∗ with any heuristic is optimal when the paper-side gain function is linear. This property of the algorithm follows rather directly from the local optimality result in Theorem 1 since for this type of paper-side gain function, the global optimization problem is decoupled between each reviewer.
Proposition 2. SUPER∗, with any heuristic, is optimal when the paper-side gain function is linear.
Proof of Proposition 2. The optimization objective over the set of reviewers is deﬁned as

max
π1 ,...,πn ∈Πd

E[γp(gj)] + λ

E[γr(πi(j), Si,j)],

j∈[d]

i∈[n] j∈[d]

where the expectation is taken over the randomness in the bids made by the reviewers. Under a linear paper-side gain function, the problem is equivalently formulated as

max
π1 ,...,πn ∈Πd

E

Bi,j + λ

γr(πi(j), Si,j ),

j∈[d] i∈[n]

i∈[n] j∈[d]

where Bi,j denotes the random bid of reviewer i on paper j and the expectation on the reviewer-side gain went away since it is deterministic given a paper ordering for any reviewer. Using the structure of the bidding model, we can simplify the expectation over the paper-side gain to obtain the objective function

max
π1 ,...,πn ∈Πd

f (πi(j), Si,j) + λ

γr(πi(j), Si,j ).

i∈[n] j∈[d]

i∈[n] j∈[d]

66

The paper-side and reviewer-side gains are now decoupled between the ordering presented to each reviewer. Consequently, the optimal paper-ordering to present to each reviewer i ∈ [n] is given by the solution to the optimization

problem

max
πi ∈Πd .

f (πi(j), Si,j) + λ γr(πi(j), Si,j).

j∈[d]

j∈[d]

(172)

The SUPER∗ algorithm solves the following problem to determine the ordering of papers to present each reviewer i ∈ [n]:

max
πi ∈Πd

f (πi(j), Si,j )(γp(gi−1,j + hi,j + 1) − γp(gi−1,j + hi,j )) + λ γr(πi(j), Si,j ).

j∈[d]

j∈[d]

Under a linear paper-side gain, the optimization problem the SUPER∗ algorithm solves for each reviewer simpliﬁes to

the problem

max
πi ∈Πd

f (πi(j), Si,j) + λ γr(πi(j), Si,j)

j∈[d]

j∈[d]

since the number of bids and the heuristic cancels. We showed in the proof of Proposition 1 that the SUPER∗ algorithm
solves this problem efﬁciently, and exactly. Since the problem is equivalent to that in (172) which gives the optimal solution for each reviewer, the SUPER∗ algorithm is optimal with a linear paper-side gain function.

67

