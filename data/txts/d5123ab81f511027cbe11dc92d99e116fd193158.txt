Minimization of Age-of-Information in Remote Sensing with Energy Harvesting

Akanksha Jaiswal, Arpan Chattopadhyay

arXiv:2010.07626v3 [cs.IT] 6 May 2021

Abstract—In this paper, minimization of time-averaged age-ofinformation (AoI) in an energy harvesting (EH) source equipped remote sensing setting is considered. The EH source opportunistically samples one or multiple processes over discrete time instants, and sends the status updates to a sink node over a time-varying wireless link. At any discrete time instant, the EH node decides whether to probe the link quality using its stored energy, and further decides whether to sample a process and communicate the data based on the channel probe outcome. The trade-off is between the freshness of information available at the sink node and the available energy at the energy buffer of the source node. To this end, an inﬁnite horizon Markov decision process theory is used to formulate the problem of minimization of time-averaged expected AoI for a single energy harvesting source node. The following two scenarios are considered: (i) single process with channel state information at transmitter (CSIT), (ii) multiple processes with CSIT. In each scenario, for probed channel state, the optimal source node sampling policy is shown to be a threshold policy involving the instantaneous age of the process(es), the available energy in the buffer and the instantaneous channel quality as the decision variables. Finally, numerical results are provided to demonstrate the policy structures and trade-offs.
Index Terms—Age-of-information, remote sensing, Markov decision process (MDP).
I. INTRODUCTION
In recent years, the need for combining the physical systems with the cyber-world has attracted signiﬁcant research interest. These cyber-physical systems (CPS) are supported by ultralow power, low latency IoT networks, and encompass a large number of applications such as vehicle tracking, environment monitoring, intelligent transportation, industrial process monitoring, smart home systems etc. Such systems often require deployment of sensor nodes to monitor a physical process and send the real time status updates to a remote estimator over a wireless network. However, for such critical CPS applications, minimizing mean packet delay without accounting for delay jitter can often be detrimental for the system performance. Also, mean delay minimization does not guarantee delivery of the observation packets to the sink node in the same order in which they were generated, thereby often resulting in unnecessarily dedicating network resources towards delivering outdated observation packets despite the availability of a freshly generated observation packet in the system. Hence, it is necessary to take into account the freshness of information of the data packets, apart from the mean packet delay.

Figure 1: Pictorial representation of a remote sensing system where an EH source samples one of N number of processes at a time and sends the observation packet to a sink node.
Recently, a metric named Age of Information (AoI) has been proposed [1] as a measure of the freshness of the information update. In this setting, a sensor monitoring a system generates time stamped status update and sends it to the sink over a network. At time t, if the latest monitoring information available to the sink node comes from a packet whose timestamped generation instant was t , then the AoI at the sink node is computed as (t − t ). Thus, AoI has emerged as an alternative performance metric to mean delay [2].
However, timely delivery of the status updates is often limited by energy and bandwidth constraints in the network. Recent efforts towards designing EH source nodes (e.g., source nodes equipped with solar panels) have opened a new research paradigm for IoT network operations. The energy generation process in such nodes are very uncertain and typically modeled as a stochastic process. The harvested energy is stored in an energy buffer as energy packets, and used for sensing and communication as and when needed. This EH capability signiﬁcantly improves network lifetime and eliminates the need for frequent manual battery replacement, but poses a new challenge towards network operations due to uncertainty in the available energy at the source nodes at any given time.
Motivated by the above challenges, we consider the problem of minimizing the time-averaged expected AoI in a remote sensing setting, where a single EH source probes the channel state, samples one or multiple processes and sends the observation packets to the sink node over a fading channel. Energy generation process is modeled as a discrete-time i.i.d. process, and a ﬁnite energy buffer is considered. Two variants of the problem are considered: (i) single process with CSIT, (ii) multiple processes with CSIT. Channel state probing and process sampling for time-averaged expected AoI minimization problem is formulated as an MDP, and the threshold nature of the optimal policy is established analytically for each case. Numerical results validate the theoretical results and intuitions.

Akanksha Jaiswal is with the Department of Electrical Engineering, Indian Institute of Technology, Delhi. Email: akanksha.jaiswal@ee.iitd.ac.in, Arpan Chattopadhyay is with the Department of Electrical Engineering and the Bharti School of Telecom Technology and Management, Indian Institute of Technology, Delhi. Email: arpanc@ee.iitd.ac.in.
This work was supported by the faculty seed grant and professional development allowance (PDA) of IIT Delhi.

A. Related work
Initial efforts towards optimizing AoI mostly involved the analysis of various queueing models; e.g., [1] for analysing a single source single server queueing system with FCFS service discipline, [3] for LCFS service discipline for M/M/1 queue,

[4] and [5] for multi-source single sink system with M/M/1 queueing at each source, [6] for AoI performance analysis for multi-source single-sink inﬁnite-buffer queueing system where unserved packets are substituted by available newer ones, etc.
On the other hand, a number of papers have considered AoI minimization problem under EH setting: [7] for derivation of average AoI for a single source having ﬁnite battery capacity, [8] for derivation of the minimal age policy for EH two hop network, [9] for average AoI expression for single source EH server, [10] for AoI minimization for wirelessly powered user, [11] for sampling, transmission scheduling and transmit power selection for single source single sink system over inﬁnite time horizon where delay is dependent on packet transmit energy.
There have also been several other works on developing optimal scheduling policy for minimizing AoI for EH sensor networks [12]–[20]. For e.g., [12] has investigated optimal online policy for single sensor single sink system with a noiseless channel, for inﬁnite, ﬁnite and unit size battery capacity; for the ﬁnite battery size, it has provided energy aware status update policy. The paper [13] has considered a multi-sensor single sink system with inﬁnite battery size, and proposed a randomized myopic scheduling scheme. In [14], the optimal online status update policy to minimize the long run average AoI for EH source with updating erasures have been proposed. It has been shown that the best effort uniform updating policy is optimal when there is no feedback and besteffort uniform updating with retransmission (BUR) policy is optimal when feedback is available to the source. The authors of [15] examined the problem of minimizing AoI under a constraint on the count of status updates. The authors of [16] addressed AoI minimization problem for cognitive radio communication system with EH capability; they formulated optimal sensing and updating for perfect and imperfect sensing as a partially observable Markov decision process (POMDP). Information source diversity, i.e., multiple sources tracking the same process but with dissimilar energy cost, and sending status updates to the EH monitoring node with ﬁnite battery size, has been considered in [17] with an MDP formulation, but no structure was provided for the optimal policy. In [18], reinforcement learning has been used to minimize AoI for a single EH sensor with HARQ protocol, but no clear intuition on the policy structure was provided. The authors of [20] have developed a threshold policy for minimizing AoI for a single sensor single sink system with erasure channel and no channel feedback. For a system with Poisson energy arrival, unit battery size and error-free channel, it has shown that a threshold policy achieves average age lower than that of zero-wait policy; based on this, lower bound on average age for general battery size and erasure channel has been derived. In [21], the authors have proposed optimal sampling threshold policy using MDP formulation for a system consists of multiple sources RF powered by the destination.
B. Our contributions and organization
1) We formulate the problem of minimizing the timeaveraged expected AoI in an EH remote sensing system with a single source monitoring one or multiple processes, as an MDP with two stage action model,

which is different from standard MDP in the literature. Under the assumptions of i.i.d. time-varying channel with CSIT, channel state probing capability at the source, and ﬁnite battery size, we derive the optimal policy structures which turn out to be simple threshold policies. The source node, depending on the current age of a process, decides whether to probe the channel or not. Afterwards, based on the channel probe outcome, the source node decides whether to sample the process and send an observation packet, or to remain idle. Thus, the MDP involves taking action in two stages at each time instant. 2) We prove convergence of an analogue of value iteration for this two-stage MDP. 3) Numerical analysis shows that the threshold for multiple processes turns out to be a function of the relative age of the processes. 4) We also prove certain interesting properties of various cost functions and some properties of the thresholds as a function of energy and age of the process.
The rest of the paper is organized as follows. System model has been explained in Section II. AoI minimization for the single source single process case is addressed in Section III. AoI minimization policy for multiple process sensing is provided in Section IV. Numerical results are provided in Section V, followed by the conclusions in Section VI. All proofs are provided in the appendices.
II. SYSTEM MODEL
We consider an EH source capable of sensing one out of N different processes at a time, and reporting the observation packet to a sink node over a fading channel; see Figure 1. Time is discretized with the discrete time index t ∈ {0, 1, 2, 3, · · ·}. At each time, the source node can decide whether to estimate the quality of the channel from the source to the sink, or not. If the source node decides to probe the channel state, it can further decide whether to sample a process and communicate the data packet to the sink, or not, depending on the instantaneous channel quality. The source has a ﬁnite energy buffer of size B units, where Ep unit of buffer energy is used to probe channel state information and Es unit of buffer energy is used in sensing and communication. The energy packet generation process in the energy buffer is assumed to be an i.i.d. process with known mean. In case the energy buffer in a source node is full, the newly generated energy packets will not be accommodated unless Ep unit of energy packet is spent in probing. Let A(t) denote the number of energy packet arrivals to the energy buffer at time t, and E(t) denote the energy available to the source at time t, for all t ≥ 0.
We denote by p(t) the probability of packet transmission success from the source to the sink node at time t. In this paper, we consider fading channel where p(t) ∈ {p1, p2, · · · , pm} is i.i.d. across t, with P(p(t) = pj) = qj for all j ∈ {1, 2, · · · , m}. The channel state corresponding to channel success probability pj is denoted by Cj, and the packet success probability corresponding to channel state Cj is given by

p(Cj) = pj. Let us also denote by r(t) ∈ {0, 1} the indicator that the packet transmission from the source to the sink at time t is successful. Hence, P(r(t) = 1|C(t) = Cj) = pj for all j ∈ {1, 2, · · · , m}. It is assumed that the channel state C(t) is learnt perfectly via a channel probe.
At time t, let b(t) ∈ {0, 1} denote the indicator of deciding to probe the channel, and a(t) ∈ {0, 1, · · · , N } denote the identity of the process being sampled, with a(t) = 0 meaning that no process is sampled, and b(t) = 0 meaning that the channel is not probed. Also, b(t) = 0 implies a(t) = 0. The set of possible actions or decisions is denoted by A = {{0, 0} ∪ {1 × {0, 1, 2, · · · , N }}}, where a generic action at time t is denoted by (b(t), a(t)).
Let us denote by τk(t) =. sup{0 ≤ τ < t : a(τ ) = k, r(τ ) = 1} the last time instant before time t, when process k was sampled and the observation packet was successfully delivered to the sink. The age of information (AoI) for the k-th process at time t is given by Tk(t) = (t−τk(t)). However, if a(t) = k and r(t) = 1, then Tk(t) = 0 since the current observation of the k-th process is available to the sink node.
A generic scheduling policy is a collection of mappings {µt}t≥0 from the available energy level, probed channel capability, and process sampling and data transmission history summarized in the AoI of various processes, to A, which basically decides the decision rule at each time. Thus, the decision rule µt at time t takes the current state s(t) as input and maps it to one decision in the action space A. If µt = µ for all t ≥ 0, the policy is called stationary, else non-stationary.
We seek to ﬁnd a stationary scheduling policy µ that minimizes the expected AoI, summed over nodes and averaged over time. In other words, we seek to solve the following mathematical problem:

1T N

min

Eµ (Tk (t))

(1)

µT

t=0 k=1

III. SINGLE SOURCE SENSING SINGLE PROCESS
In this section, we derive the optimal channel probing, source activation and data transmission policy for a single EH source sampling a single process (N = 1), which will provide insights to develop process sampling policy for N > 1.
Here, we formulate (1) as a long-run average cost MDP with state space S =. {0, 1, · · · , B} × Z+ and an intermediate state space V = {0, 1, . . . .., B} × Z+ × {C1, C2, · · · , Cm} where a generic state s = (E, T ) which means that the energy buffer has E energy packets, and the source was last activated T slots ago. A generic intermediate state v = (E, T, C) which additionally means that the current channel state C, obtained via probing, has packet success probability p(C). The action space A = {{0, 0} ∪ {1 × {0, 1}}} with a(t), b(t) ∈ {0, 1}. At each time, if the source node decides not to probe the channel state then it will not perform sampling, and thus b(t) = 0, a(t) = 0, and the expected single-stage AoI cost is c(s(t), b(t), a(t)) = T . However, if the source node decides to probe the channel state, the expected single-stage AoI cost is c(v(t), b(t) = 1, a(t) = 0) = T , and c(v(t), b(t) = 1, a(t) = 1) = T (1 − p(C)), where the expectation is taken over packet success probability p(C). We ﬁrst formulate the average-cost

MDP problem as an α-discounted cost MDP problem with
α ∈ (0, 1), and derive the optimal policy, from which the
solution of the average cost minimization problem can be
obtained by taking α → 1. 1) Optimality equation: Let J∗(E, T ) be the optimal value
function for state (E, T ) in the discounted cost problem, and let W ∗(E, T, C) be the cost-to-go from an intermediate state (E, T, C). The Bellman equations are given by:

J∗(E ≥ Ep + Es, T ) = min T + αEAJ∗(min{E + A, B}, T + 1),

V ∗(E, T )

V ∗(E, T ) =

m
qj W ∗(E, T, Cj )

j=1

W ∗(E, T, C) = min{T + αEAJ∗(E − Ep + A, T + 1), T (1 − p(C)) + αp(C)EAJ∗(E − Ep − Es + A, 1) + α(1 − p(C))EAJ∗(E − Ep − Es + A,

T + 1)}

J∗(E < Ep + Es, T ) = T + αEAJ∗(min{E + A, B}, T + 1)

(2)

The ﬁrst expression in the minimization in the R.H.S. of the ﬁrst equation in (2) is the cost of not probing channel state (b(t) = 0), which includes single-stage AoI cost T and an α discounted future cost with a random next state (min{E + A, B}, T + 1), averaged over the distribution of the number of energy packet generation A. The quantity V ∗(E, T ) is the expected cost of probing the channel state, which explains the second equation in (2). At an intermediate state (E, T, C), if a(t) = 0, a single stage AoI cost T is incurred and the next state becomes (E − Ep + A, T + 1); if a(t) = 1, the expected AoI cost is T (1 − p(C)) (expectation taken over the packet success probability p(C)), and the next random state becomes (E − Ep − Es + A, 1) and (E − Ep − Es + A, T + 1) if r(t) = 1 and r(t) = 0, respectively. The last equation in (2) follows similarly since b(t) = 0, a(t) = 0 is the only possible action when E < Ep + Es.
Substituting the value of V ∗(E, T ) in the ﬁrst equation of (2), we obtain the following Bellman equations:

J∗(E ≥ Ep + Es, T ) = min T + αEAJ∗(min{E + A, B}, T + 1),

EC min{T + αEAJ∗(E − Ep + A, T + 1),
T (1 − p(C)) + αp(C)EAJ∗(E − Ep − Es + A, 1) + α(1 − p(C))EAJ∗(E − Ep − Es +

A, T + 1)}

J∗(E < Ep + Es, T ) = T + αEAJ∗(min{E + A, B}, T + 1)

(3)

2) Policy structure:
Proposition 1. The value function J(k)(s) converges to J∗(s) as k tends to ∞.

Proof. See Appendix A.

We provide the convergence proof of value iteration since we have a two-stage decision process as opposed to traditional MDP where a single action is taken.
Lemma 1. For N = 1, the value function J∗(E, T ) is increasing in T and W ∗(E, T, C) is decreasing in p(C).

Proof. See Appendix B.
Conjecture 1. For N = 1, the optimal probing policy for the α-discounted AoI cost minimization problem is a threshold policy on T . For any E ≥ Ep + Es, the optimal action is to probe the channel state if and only if T ≥ Tth(E) for a threshold function Tth(E) of E.
Theorem 1. For N = 1, at any time, if the source decides to probe the channel, then the optimal sampling policy is a threshold policy on p(C). For any E ≥ Ep + Es and probed channel state, the optimal action is to sample the source node if and only if p(C) ≥ pth(E, T ) for a threshold function pth(E, T ) of E and T .
Proof. See Appendix C.
The policy structure supports the following two intuitions. Firstly, given E and T , the source decides to probe the channel state if AoI is greater than some threshold value. Secondly, given E and T and probed channel state, if the channel quality is better than a threshold, then the optimal action is to sample the process and communicate the observation to the sink node. We will later numerically observe in Section V some intuitive properties of Tth(E) as a function of E and λ, and pth(E, T ) as a function of E, T and λ.

IV. SINGLE SOURCE SENSING MULTIPLE PROCESSES

In this section, we ﬁnd the optimal policy for channel

probing, source activation, process sampling and data commu-

nication in order to solve Problem (1), when a single source

can sample N different processes, one at a time.

Here we formulate the α-discounted cost version of (1)

as an MDP with a generic state s = (E, T1, T2, · · · , TN )

which means that the energy buffer has E energy packets,

and the k-th process was last activated Tk slots ago. Also, a

generic intermediate state v = (E, T1, T2, · · · , TN , C) which

additionally means that the current channel state C is learnt

by probing, has packet success probability p(C). The action

space A = {{0, 0}∪{1×{0, 1, 2, · · · , N }}} with b(t) ∈ {0, 1}

and a(t) ∈ {0, 1, · · · , N }. At each time, if the source node

decides not to probe the channel state then it will not sample

any process, thus b(t) = 0, a(t) = 0 and the expected single

stage AoI cost is c(s(t), b(t), a(t)) =

N i=1

Ti.

However,

if

the

source node decides to probe the channel state, the expected

single stage AoI cost is c(v(t), b(t) = 1, a(t) = 0) =

N i=1

Ti

and c(v(t), b(t) = 1, a(t) = k) = i=k Ti + Tk(1 − p(C))

where the expectation is taken over packet success probability

p(C ).

1) Optimality equation: In this case, the Bellman equations

are given by:

J ∗(E ≥ Ep + Es, T1, T2, · · · , TN )

N

= min

Ti + αEAJ∗(min{E + A, B}, T1 + 1, T2 + 1, · · · ,

i=1

TN + 1), V ∗(E, T1, T2, · · · , TN )

V ∗(E, T1, T2, · · · , TN )

m

=

qj W ∗(E, T1, T2, · · · , TN , Cj )

j=1

W ∗(E, T1, T2, · · · , TN , C)
N
= min{ Ti + αEAJ∗(E − Ep + A, T1 + 1, T2 + 1, · · · , TN + 1),
i=1

min
1≤k≤N

Ti + Tk(1 − p(C)) + αp(C)EAJ∗(E − Ep − Es + A,
i=k

T1 + 1, T2 + 1, · · · , Tk = 1, Tk+1 + 1, · · · , TN + 1) +

α(1 − p(C))EAJ∗(E − Ep − Es + A, T1 + 1, T2 + 1, · · · , TN + 1) }

J ∗(E < Ep + Es, T1, T2, · · · , TN )

N

=

Ti + αEAJ∗(min{E + A, B}, T1 + 1, T2 + 1, · · · , TN + 1) (4)

i=1

The ﬁrst expression in the minimization in the R.H.S. of

the ﬁrst equation in (4) is the cost of not probing channel

state (b(t) = 0), which includes single-stage AoI cost

N i=1

Ti

and an α discounted future cost with a random next state

(min{E+A, B}, T1+1, T2+1, · · · , TN +1), averaged over the

distribution of the number of energy packet generation A. The quantity V ∗(E, T1, T2, · · · , TN ) is the optimal expected cost of

probing the channel state, which explains the second equation

in (4). At an intermediate state (E, T1, T2, · · · , TN , C), if

a(t) = 0, a single stage AoI cost

N i=1

Ti

is

incurred

and

the

next state becomes (E − Ep + A, T1 + 1, T2 + 1, · · · , TN + 1);

if a(t) = k, the expected AoI cost is i=k Ti + Tk(1 − p(C)) (expectation taken over the packet success probability

p(C)), and the next random state becomes (E − Ep − Es +

A, T1 + 1, T2 + 1, · · · , Tk = 1, Tk+1 + 1, · · · , TN + 1) and (E − Ep − Es + A, T1 + 1, T2 + 1, · · · , TN + 1) if r(t) = 1

and r(t) = 0, respectively. The last equation in (4) follows

similarly since b(t) = 0, a(t) = 0 is the only possible action

when E < Ep + Es. Substituting the value of V ∗(E, T1, T2, · · · , TN ) in the ﬁrst

equation of (4), we obtain the Bellman equations (5)

2) Policy structure:

Lemma 2. For N > 1, the value function J ∗(E, T1, T2, · · · , TN ) is increasing in each of T1, T2, · · · , TN and W ∗(E, T1, T2, · · · , TN , C) is decreasing in p(C).
Proof. See Appendix D.

Let us deﬁne T = [T1, T2, · · · , TN ] and T−k = [T1, T2, · · · , Tk−1, Tk+1, · · · , TN ].
Conjecture 2. For N > 1, the optimal probing policy for the α-discounted AoI cost minimization problem is a threshold policy on arg max1≤k≤N Tk. For any E ≥ Ep + Es, the optimal action is to probe the channel state if and only if arg max1≤k≤N Tk ≥ Tth(E, T−k) for a threshold function Tth(E, T−k) of E and T−k.
Theorem 2. For N > 1, after probing the channel state, the optimal source activation policy for the α-discounted cost problem is a threshold policy on p(C). For any E ≥ Ep + Es and probed channel state, the optimal action is to sample the process arg max1≤k≤N Tk if and only if p(C) ≥ pth(E, T ) for a threshold function pth(E, T ) of (E, T ).
Proof. See Appendix E.

The policy structure upholds the two intuitions, (i) for a given E and (T1, T2, · · · , TN ), the source decides to probe

N

J ∗(E ≥ Ep + Es, T1, T2, · · · , TN ) = min

Ti + αEAJ∗(min{E + A, B}, T1 + 1, T2 + 1, · · · , TN + 1),

i=1

N
EC min{ Ti + αEAJ∗(E − Ep + A, T1 + 1, T2 + 1, · · · , TN + 1),

i=1

min
1≤k≤N

Ti + Tk(1 − p(C)) + αp(C)EAJ∗(E − Ep − Es + A, T1 + 1,
i=k

T2 + 1, · · · , Tk = 1, Tk+1 + 1, · · · , TN + 1)

+α(1 − p(C))EAJ∗(E − Ep − Es + A, T1 + 1, T2 + 1, · · · , TN + 1) }

N

J ∗(E < Ep + Es, T1, T2, · · · , TN ) =

Ti + αEAJ∗(min{E + A, B}, T1 + 1, T2 + 1, · · · , TN + 1)

(5)

i=1

the channel state if highest AoI is greater than some threshold

value, (ii) for a given E and (T1, T2, · · · , TN ) and probed

channel state, if the channel condition is better than a thresh-

old, then the optimal action is to sample the process with

highest AoI and send the observation to the sink node.

We will later numerically demonstrate some intuitive prop-

erties of Tth(E, T−k) as a function of E, T−k and λ and

(a)

pth(E, T1, T2, · · · , TN ) as a function of E, (T1, T2, · · · , TN )

and λ in Section V.

V. NUMERICAL RESULTS
A. Single source, single process (N = 1)
We consider ﬁve channel states (m = 5) with channel state occurrence probabilities q = [0.2, 0.2, 0.2, 0.2, 0.2] and the corresponding packet success probabilities p = [0.9, 0.7, 0.5, 0.3, 0.1]. Energy arrival process is i.i.d. Bernoulli(λ) with energy buffer size B = 12, Ep = 1 unit, Es = 1 unit, and the discount factor α = 0.99. Numerical exploration revealed that, there exists a threshold policy on T in decision making for channel state probing; see Figure 2(a). It is observed that this Tth(E) decreases with E since higher available energy in the energy buffer allows the EH node to probe the channel state more aggressively. Similar reasoning explains the observation that Tth(E) decreases with λ. For probed channel state, Figure 2(b) shows the variation of pth(E, T ) with E, T, λ. It is observed that pth(E, T ) decreases with E, since the EH node tries to sample the process more aggressively if more energy is available in the buffer. Similarly, higher value of T results in aggressive sampling, and hence pth(E, T ) decreases with T . By similar arguments as before, we can explain the observation that this pth(E, T ) decreases with λ.
B. Single source, multiple processes (N > 1)
We choose N = 3, α = 0.99, B = 12, Ep = 1, Es = 1 and the same channel model and parameters as in Section V-A. Figure 3(a) shows the variation on the threshold on T1 for given T2, T3, for channel state probing. It is observed that Tth(E, T2, T3) decreases with E and λ. Extensive numerical work also demonstrated that this threshold decreases with each of T2, T3. For probed channel state, Figure 3(b) shows that pth(E, T1, T2, T3) decreases with E and λ. Further numerical analysis also demonstrated that this threshold decreases with each of T1, T2, T3 .

(b)
Figure 2: For N = 1, (a) Variation of Tth(E) with E, λ and (b) Variation of pth(E, T ) with E, T, λ.
(a)
(b)
Figure 3: For N = 3, (a) Variation of Tth(E, T2, T3) with E, T2, T3, λ and (b) Variation of pth(E, T1, T2, T3) with E, T1, T2, T3, λ.
VI. CONCLUSIONS In this paper, we derived the optimal policy structures for minimizing the time-averaged expected AoI under an energy-harvesting source. We considered single and multiple

processes, i.i.d. time varying channels, and channel probing capability at the source. The optimal source sampling policy turned out to be a threshold policy. Numerical results illustrated the policy structures and trade-offs. We will extend this work for unknown energy generation rate in our future research endeavours.

REFERENCES
[1] S. Kaul, R. Yates, and M. Gruteser, “Real-time status: How often should one update?” in 2012 Proceedings IEEE INFOCOM. IEEE, 2012, pp. 2731–2735.
[2] R. Talak, S. Karaman, and E. Modiano, “Can determinacy minimize age of information?” arXiv preprint arXiv:1810.04371, 2018.
[3] S. K. Kaul, R. D. Yates, and M. Gruteser, “Status updates through queues,” in 2012 46th Annual Conference on Information Sciences and Systems (CISS). IEEE, 2012, pp. 1–6.
[4] R. D. Yates and S. K. Kaul, “The age of information: Real-time status updating by multiple sources,” IEEE Transactions on Information Theory, vol. 65, no. 3, pp. 1807–1827, 2018.
[5] S. K. Kaul and R. D. Yates, “Timely updates by multiple sources: The m/m/1 queue revisited,” in 2020 54th Annual Conference on Information Sciences and Systems (CISS). IEEE, 2020, pp. 1–6.
[6] A. Kosta, N. Pappas, A. Ephremides, and V. Angelakis, “Age of information performance of multiaccess strategies with packet management,” Journal of Communications and Networks, vol. 21, no. 3, pp. 244–255, 2019.
[7] S. Farazi, A. G. Klein, and D. R. Brown, “Age of information in energy harvesting status update systems: When to preempt in service?” in 2018 IEEE International Symposium on Information Theory (ISIT). IEEE, 2018, pp. 2436–2440.
[8] A. Arafa and S. Ulukus, “Age-minimal transmission in energy harvesting two-hop networks,” in GLOBECOM 2017-2017 IEEE Global Communications Conference. IEEE, 2017, pp. 1–6.
[9] S. Farazi, A. G. Klein, and D. R. Brown, “Average age of information for status update systems with an energy harvesting server,” in IEEE INFOCOM 2018-IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS). IEEE, 2018, pp. 112–117.
[10] H. Hu, K. Xiong, Y. Zhang, P. Fan, T. Liu, and S. Kang, “Age of information in wireless powered networks in low snr region for future 5g,” Entropy, vol. 20, no. 12, p. 948, 2018.
[11] A. Arafa and S. Ulukus, “Age minimization in energy harvesting communications: Energy-controlled delays,” in 2017 51st Asilomar Conference on Signals, Systems, and Computers. IEEE, 2017, pp. 1801–1805.
[12] X. Wu, J. Yang, and J. Wu, “Optimal status update for age of information minimization with an energy harvesting source,” IEEE Transactions on Green Communications and Networking, vol. 2, no. 1, pp. 193–204, 2017.
[13] J. Yang, X. Wu, and J. Wu, “Optimal scheduling of collaborative sensing in energy harvesting sensor networks,” IEEE Journal on Selected Areas in Communications, vol. 33, no. 3, pp. 512–523, 2015.
[14] S. Feng and J. Yang, “Age of information minimization for an energy harvesting source with updating erasures: With and without feedback,” arXiv preprint arXiv:1808.05141, 2018.
[15] B. T. Bacinoglu, E. T. Ceran, and E. Uysal-Biyikoglu, “Age of information under energy replenishment constraints,” in 2015 Information Theory and Applications Workshop (ITA). IEEE, 2015, pp. 25–31.
[16] S. Leng and A. Yener, “Age of information minimization for an energy harvesting cognitive radio,” IEEE Transactions on Cognitive Communications and Networking, vol. 5, no. 2, pp. 427–439, 2019.
[17] E. Gindullina, L. Badia, and D. Gündüz, “Age-of-information with information source diversity in an energy harvesting system,” arXiv preprint arXiv:2004.11135, 2020.
[18] E. T. Ceran, D. Gündüz, and A. György, “Reinforcement learning to minimize age of information with an energy harvesting sensor with harq and sensing cost,” in IEEE INFOCOM 2019-IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS). IEEE, 2019, pp. 656–661.
[19] A. Arafa, J. Yang, and S. Ulukus, “Age-minimal online policies for energy harvesting sensors with random battery recharges,” in 2018 IEEE International Conference on Communications (ICC). IEEE, 2018, pp. 1–6.
[20] B. T. Bacinoglu and E. Uysal-Biyikoglu, “Scheduling status updates to minimize age of information with an energy harvesting sensor,” in 2017 IEEE International Symposium on Information Theory (ISIT). IEEE, 2017, pp. 1122–1126.
[21] M. A. Abd-Elmagid, H. S. Dhillon, and N. Pappas, “A reinforcement learning framework for optimizing age of information in rfpowered communication systems,” IEEE Transactions on Communications, vol. 68, no. 8, pp. 4747–4760, 2020.

APPENDIX A PROOF OF PROPOSITION 1
We prove maxs∈S |J (k)(s) − J ∗(s)|↑ 0 as k ↑ ∞. Let us deﬁne the error ek = maxs∈S |J (k)(s) − J ∗(s)| and J(0)(s) as initial estimate for J∗(s). For any state s, we can establish relation between the error at time k+1 to the error at time k in the following way:
J (k+1)(E ≥ Ep + Es, T )
= min T + αEAJ(k)(min{E + A, B}, T + 1),

EC min{T + αEAJ (k)(E − Ep + A, T + 1),

T (1 − p(C)) + αp(C)EAJ(k)(E − Ep − Es + A, 1) +

α(1 − p(C))EAJ(k)(E − Ep − Es + A, T + 1)}

(6)

We assume there exists an optimal value function J∗(E, T ) for the discounted cost problem and substituting J(k)(E, T ) by J (k)(E, T ) ≤ J (∗)(E, T ) + ek in (6) we get following
equation:

J (k+1)(E ≥ Ep + Es, T ) ≤ min T + αEA(J∗(min{E + A, B}, T + 1) + ek),

EC min{T + αEA(J∗(E − Ep + A, T + 1) + ek),

T (1 − p(C)) + αp(C)EA(J∗(E − Ep − Es + A, 1) + ek)

+α(1 − p(C))EA(J∗(E − Ep − Es + A, T + 1) + ek)}

(7)

Similarly, substituting J (k)(E, T ) by J (k)(E, T ) ≥ J(∗)(E, T ) − ek in (6) we get following equation:

J (k+1)(E ≥ Ep + Es, T ) ≥ min T + αEA(J∗(min{E + A, B}, T + 1) − ek),

EC min{T + αEA(J∗(E − Ep + A, T + 1) − ek),

T (1 − p(C)) + αp(C)EA(J∗(E − Ep − Es + A, 1) − ek)

+α(1 − p(C))EA(J∗(E − Ep − Es + A, T + 1) − ek)}

(8)

Combining the results obtained from equations (7) and (8), we get:
J ∗(E ≥ Ep + Es, T ) − αek ≤ J (k+1)(E ≥ Ep + Es, T ) ≤ J ∗(E ≥ Ep + Es, T ) + αek (9)

|J (k+1)(E ≥ Ep + Es, T ) − J ∗(E ≥ Ep + Es, T )|≤ αek

(10)

max|J (k+1)(s) − J ∗(s)|≤ αek

(11)

s∈S

ek+1 ≤ αek

(12)

Thus, equation (12) gives the relation between the error at time k+1 to the error at time k. By backward substitution we get,

max|J (k)(s) − J ∗(s)|≤ αk max|J (0)(s) − J ∗(s)|

(13)

s∈S

s∈S

From equation (13), as k ↑ ∞, the error reduces to zero. Hence, J (k)(s) converges to J ∗(s).

APPENDIX B PROOF OF LEMMA 1 We prove this result by value iteration:
J (k+1)(E ≥ Ep + Es, T )
= min T + αEAJ(k)(min{E + A, B}, T + 1),

EC min{T + αEAJ (k)(E − Ep + A, T + 1),

T (1 − p(C)) + αp(C)EAJ(k)(E − Ep − Es + A, 1) + α(1 − p(C))EAJ(k)(E − Ep − Es + A, T + 1)}

J (k+1)(E < Ep + Es, T )

= T + αEAJ(k)(min{E + A, B}, T + 1)

(14)

Let us start with J(0)(s) = 0 for all s ∈ S. Clearly, J (1)(E ≥ Ep+Es, T ) = min{T, EC (min{T, T (1−p(C))})} = min{T, EC (T (1−p(C))} and J (1)(E < Ep +Es, T ) = T . Hence, for any given E, the value function J(1)(E, T ) is an
increasing function of T and decreasing function of p(C). As induction hypothesis, we assume that J(k)(E, T ) is also
increasing function of T .
Now,

J (k+1)(E ≥ Ep + Es, T ) = min T + αEAJ(k)(min{E + A, B}, T + 1),

EC min{T + αEAJ (k)(E − Ep + A, T + 1),

T (1 − p(C)) + αp(C)EAJ(k)(E − Ep − Es + A, 1) +

α(1 − p(C))EAJ(k)(E − Ep − Es + A, T + 1)}

(15)

We need to show that J (k+1)(E ≥ Ep + Es, T ) is also increasing in T . The ﬁrst term inside the minimization operation in (15) is increasing in T , by the induction hypothesis and
from the fact that expectation is a linear operation. On the other
hand, the second term has linear expectation over channel state
and another minimization operator. Also, the ﬁrst and second
terms inside the second minimization operation in (15) are increasing in T by the induction hypothesis and the linearity of expectation operation. Thus, J (k+1)(E ≥ Ep + Es, T ) is also increasing in T . By similar arguments, we can claim that J (k+1)(E < Ep + Es, T ) is increasing in T . Now, since J(k)(·) ↑ J∗(·) as k ↑ ∞ by proof of Proposition 1, J∗(E, T ) is also increasing in T . Hence, the lemma is proved.

APPENDIX C PROOF OF THEOREM 1
From (3), it is obvious that for probed channel state the optimal decision for E ≥ Ep + Es is to sample the source if and only if the cost of sampling is lower than the cost of not sampling the source, i.e., T + αEAJ∗(E − Ep + A, T + 1) ≥ T (1 − p(C)) + αEAJ∗(E − Ep − Es + A, T + 1) −
αp(C) EAJ ∗(E − Ep − Es + A, T + 1) − EAJ ∗(E − Ep −

Es +A, 1) . Now, by Lemma 1, EAJ ∗(E −Ep −Es +A, T +
1) − EAJ∗(E − Ep − Es + A, 1) is non-negative. Thus the R.H.S. decreases with p(C), whereas the L.H.S. is independent of p(C). Hence, for probed channel state the optimal action is to sample if and only if p(C) ≥ pth(E, T ) for some suitable threshold function pth(E, T ).

APPENDIX D PROOF OF LEMMA 2
The proof is similar to the proof of Lemma 1 and it follows from the convergence of value iteration as given below:

J (k+1)(E ≥ Ep + Es, T1, T2, · · · , TN )

N

= min

Ti + αEAJ(k)(min{E + A, B}, T1 + 1, T2 + 1, · · · ,

i=1

N
TN + 1), EC min{ Ti + αEAJ (k)(E − Ep + A, T1 + 1, T2 + 1,

i=1

· · · , TN + 1), min
1≤k≤N

Ti + Tk(1 − p(C)) + αp(C)EAJ (k)(E
i=k

−Ep − Es + A, T1 + 1, T2 + 1, · · · , Tk = 1, Tk+1 + 1, · · · , TN + 1) +α(1 − p(C))EAJ (k)(E − Ep − Es + A, T1 + 1, T2 + 1, · · · ,

TN + 1) }

J (k+1)(E < Ep + Es, T1, T2, · · · , TN )

N

=

Ti + αEAJ(k)(min{E + A, B}, T1 + 1, T2 + 1, · · · , TN + 1)

i=1

(16)

Let us start with J(0)(s) = 0 for all s ∈ S.

Clearly, J (1)(E ≥ Ep + Es, T1, T2, · · · , TN ) =

min{

N i=1

Ti

,

EC

(min{

N i=1

Ti,

min1≤k≤N

(

i=k Ti

+

Tk(1 − p(C)))}} and J (1)(E < Ep + Es, T1, T2, · · · , TN ) =

N i=1

Ti.

Hence,

for

any

given

E,

the

value

function

J (1)(E, T1, T2, · · · , TN ) is an increasing function of

T1, T2, · · · , TN . As induction hypothesis, we assume that

J (k)(E, T1, T2, · · · , TN ) is also increasing function of

T1, T2, · · · , TN . Now,

APPENDIX E PROOF OF THEOREM 2

It is obvious that J∗(·) is invariant to any permutation of (T1, T2, · · · , TN ). Hence, by Lemma 2,

arg min1≤k≤N

i=k Ti+Tk(1−p(C))+αp(C)EAJ (k)(E−

Ep − Es + A, T1 + 1, T2 + 1, · · · , Tk = 1, Tk+1 + 1, · · · , TN + 1) + α(1 − p(C))EAJ (k)(E − Ep − Es + A, T1 + 1, T2 +

1, · · · , TN + 1) = arg max1≤k≤N Tk, i.e., the best process to activate is k∗ =. arg max1≤k≤N Tk in case one process has to be activated. For probed channel state, it
is optimal to sample a process if and only if the cost
of sampling this process is less than or equal to the
cost of not sampling this process, which translates into Tk∗ + αEAJ ∗(E − Ep + A, T1 + 1, T2 + 1, · · · , TN + 1) ≥ Tk∗ (1 − p(C)) + αEAJ ∗(E − Ep − Es + A, T1 + 1, T2 +

1, · · · , TN + 1) − αp(C) EAJ ∗(E − Ep − Es + A, T1 + 1, T2 + 1, · · · , TN + 1) − EAJ ∗(E − Ep − Es + A, T1 + 1, T2 +

1, · · · , Tk = 1, Tk+1 + 1, · · · , TN + 1) . Now, by Lemma 2,
EAJ ∗(E−Ep−Es+A, T1+1, T2+1, · · · , TN +1)−EAJ ∗(E− Ep −Es +A, T1 +1, T2 +1, · · · , Tk = 1, Tk+1 +1, · · · , TN +1) is non negative. Thus, the R.H.S. is decreasing in p(C) and the L.H.S. is independent of p(C). Hence, the threshold structure of the optimal sampling policy is proved.

J (k+1)(E ≥ Ep + Es, T1, T2, · · · , TN )

N

= min

Ti + αEAJ(k)(min{E + A, B}, T1 + 1, T2 + 1, · · · ,

i=1

N
TN + 1), EC min{ Ti + αEAJ (k)(E − Ep + A, T1 + 1, T2 + 1,

i=1

· · · , TN + 1), min
1≤k≤N

Ti + Tk(1 − p(C)) + αp(C)EAJ (k)(E
i=k

−Ep − Es + A, T1 + 1, T2 + 1, · · · , Tk = 1, Tk+1 + 1, · · · , TN + 1) +α(1 − p(C))EAJ (k)(E − Ep − Es + A, T1 + 1, T2 + 1, · · · ,

TN + 1) }

(17)

We seek to show that J (k+1)(E ≥ Ep +Es, T1, T2, · · · , TN ) is also increasing in each of T1, T2, · · · , TN . The ﬁrst term inner to the minimization operation in (17) is increasing in
each of T1, T2, · · · , TN , utilizing the induction hypothesis and linear property of expectation operation. On the other hand,
the second term has expectation over channel state and another
minimization operator. Also, the ﬁst and second term of second
minimization operator is increasing in each of T1, T2, · · · , TN by using induction hypothesis and the linearity of expectation operation. Thus, J (k+1)(E ≥ Ep + Es, T1, T2, · · · , TN ) is also increasing in each of T1, T2, · · · , TN . Similarly, we can assert that J (k+1)(E < Ep +Es, T1, T2, · · · , TN ) is increasing in each of T1, T2, · · · , TN . Now, since J (k)(·) ↑ J ∗(·) as k ↑ ∞, J∗(E, T1, T2, · · · , TN ) is also increasing in each of T1, T2, · · · , TN . Hence, the lemma is proved.

