Distributed Learning with Compressed Gradient Differences

arXiv:1901.09269v2 [cs.LG] 2 Jun 2019

Konstantin Mishchenko KAUST, Saudi Arabia
konstantin.mishchenko@kaust.edu.sa

Eduard Gorbunov MIPT, Russia
eduard.gorbunov@phystech.edu

Martin Taka´cˇ Lehigh University, USA
takac@lehigh.edu

Peter Richta´rik KAUST, Saudi Arabia and MIPT, Russia
peter.richtarik@kaust.edu.sa

Abstract
Training large machine learning models requires a distributed computing approach, with communication of the model updates being the bottleneck. For this reason, several methods based on the compression (e.g., sparsiﬁcation and/or quantization) of updates were recently proposed, including QSGD [1], TernGrad [19], SignSGD [2], and DQGD [7]. However, none of these methods are able to learn the gradients, which renders them incapable of converging to the true optimum in the batch mode, incompatible with non-smooth regularizers, and slows down their convergence. In this work we propose a new distributed learning method—DIANA—which resolves these issues via compression of gradient differences. We perform a theoretical analysis in the strongly convex and nonconvex settings and show that our rates are superior to existing rates. Our analysis of block-quantization and differences between 2 and ∞ quantization closes the gaps in theory and practice. Finally, by applying our analysis technique to TernGrad, we establish the ﬁrst convergence rate for this method.
1 Introduction
Big machine learning models are typically trained in a distributed fashion, with the training data distributed across several workers, all of which compute in parallel an update to the model based on their local data. For instance, they can all perform a single step of Gradient Descent (GD) or Stochastic Gradient Descent (SGD). These updates are then sent to a parameter server which performs aggregation (typically this means just averaging of the updates) and then broadcasts the aggregated updates back to the workers. The process is repeated until a good solution is found.
When doubling the amount of computational power, one usually expects to see the learning process ﬁnish in half time. If this is the case, the considered system is called to scale linearly. For various reasons, however, this does not happen, even to the extent that the system might become slower with more resources. At the same time, the surge of big data applications increased the demand for distributed optimization methods, often requiring new properties such as ability to ﬁnd a sparse solution. It is, therefore, of great importance to design new methods that are versatile, efﬁcient and scale linearly with the amount of available resources. In fact, the applications vary a lot in their desiderata. There is a rising interest in federated learning [8], where the main concerns include the communication cost and ability to use local data only in an attempt to provide a certain level of privacy. In high-dimensional machine learning problems, non-smooth 1-penalty is often utilized, so one wants to have a support for proximable regularization. The efﬁciency of deep learning, in contrast, is dependent on heavy-ball momentum and nonconvex convergence to criticality, while
Preprint. Under review.

method

lin. rate loc. data non-smooth momentum block quant.

DIANA (New!)











QSGD [1]











TernGrad [19]











DQGD [7]











QSVRG [1]











Table 1: Comparison of DIANA and related methods. Here “lin. rate” means that linear convergence

either to a ball around the optimum or to the optimum was proved, “loc. data” describes whether or

not authors assume that fi is available at node i only, “non-smooth” means support for a non-smooth

regularizer, “momentum” says whether or not authors consider momentum in their algorithm, and

“block quant.” means theoretical justiﬁcation for using block quantization.

sampling from the full dataset might not be an issue. In our work, we try to address all of these questions.

Communication as the bottleneck. The key aspects of distributed optimization efﬁciency are computational and communication complexity. In general, evaluating full gradients is intractable due to time and memory restrictions, so computation is made cheap by employing stochastic updates. On the other hand, in typical distributed computing architectures, communication is much slower (see Figure 6 for our experiments with communication cost of aggregating and broadcasting) than a stochastic update, and the design of a training algorithm needs to ﬁnd a trade-off between them. There have been considered several ways of dealing with this issue. One of the early approaches is to have each worker perform a block descent step, which leads to the Hydra family of methods [15, 4]. By choosing the size of the block, one directly chooses the amount of data that needs to be communicated. An alternative idea is for each worker to do more work between communication rounds (e.g., by employing a more powerful local solver, such as a second order method), so that computation roughly balances out with communication. The key methods in this sphere include CoCoA and its variants [5, 12, 11, 10, 18], DANE [17], DiSCO [20, 13], DANCE [6] and AIDE [14].

Update compression via randomized sparsiﬁcation and/or quantization. Practitioners suggested a number of heuristics to ﬁnd a remedy for the communication botlleneck. Of special interest to this paper is the idea of compressing SGD updates, proposed in [16]. Building off of this work, [1] designed a variant of SGD that guarantees convergence with compressed updates. Other works with SGD update structure include [9, 2, 7]. Despite proving a convergence rate, [1] also left many new questions open and introduced an additional, unexplained, heuristic of quantizing only vector blocks. Moreover, their analysis implicitly makes an assumption that all data should be available to each worker, which is hard and sometimes even impossible to satisfy. In a concurrent with [1] work [19], the Terngrad method was analyzed for stochastic updates that in expectation have positive correlation with the vector pointing to the solution. While giving more intuition about convergence of quantized methods, this work used ∞ norm for quantization, unlike 2-quantization of [1].

The problem. Let fi : Rd → R is a loss of model x obtained on data points belonging to distribution Di, i.e., fi(x) := Eζ∼Di φ(x, ζ). and R : Rd → R ∪ {+∞} be a proper closed convex regularizer.

In this paper we focus on the problem of training a machine learning model via regularized empirical

risk minimization:

n

minx∈Rd

f (x)

+

R(x)

:=

1 n

fi(x) + R(x).

(1)

i=1

We do not assume any kind of similarity between distributions D1, . . . , Dn.

Notation. By sign(t) we denote the sign of t ∈ R (-1 if t < 0, 0 if t = 0 and 1 if t > 0). The j-th element of a vector x ∈ Rd is denoted as x(j). For x = (x(1), . . . , x(d)) ∈ Rd and p ≥ 1, we let
x p = ( i |x(i)|p)1/p. Note that x 1 ≥ x p ≥ x ∞ for all x. By x 0 we denote the number of nonzero elements of x. Detailed description of the notation is in Table 6 in the appendix.

2 Contributions
DIANA. We develop a distributed gradient-type method with compression of gradient differences, which we call DIANA (Algorithm 1). Rate in the strongly convex case. We show that when applied to the smooth strongly convex minimization problem with arbitrary closed convex regularizer, DIANA has the iteration complexity

2

Algorithm 1 DIANA (n nodes)

input

learning rates α > 0 and {γk}k≥0, initial vectors x0, h01, . . . , h0n

∈ Rd and h0

=

1 n

n i=1

h0i ,

quantization parameter p ≥ 1, sizes of blocks {dl}m l=1, momentum parameter 0 ≤ β < 1

1: v0 = ∇f (x0)

2: for k = 0, 1, . . . do 3: Broadcast xk to all workers

4: for i = 1, . . . , n in parallel do

5:

Sample gik such that E[gik | xk] = ∇fi(xk) and let ∆ki = gik − hki

6:

Sample ∆ˆ ki ∼ Quantp(∆ki , {dl}m l=1) and let hki +1 = hki + α∆ˆ ki and gˆik = hki + ∆ˆ ki

7: end for

8:

∆ˆ k = n1

n i=1

∆ˆ ki

;

gˆk = n1

n i=1

gˆik

=

hk

+

∆ˆ k;

vk = βvk−1 + gˆk

9:

xk+1 = proxγkR xk − γkvk ; hk+1 = n1

n i=1

hki +1

=

hk

+

α∆ˆ k

10: end for

O max d/m, κ 1 + 1/n d/m ln 1/ε , to a ball with center at the optimum (see Sec 4, Thm 2
and Cor 1 for the details). In the case of decreasing stepsize we show O (1/ε) iteration complexity (see Sec 4.1, Thm 5 and Cor 2 for the details). Unlike in [7], in a noiseless regime our method converges to the exact optimum, and at a linear rate.
Rate in the nonconvex case. We prove that DIANA also works for smooth nonconvex problems with an indicator-like regularizer and get the iteration complexity O 1/ε2 max L2(f(x0)−f∗)2/n2α2p, σ4/(1+nαp)2 (see Sec 5, Thm 4 and Cor 3 for the details).
DIANA with momentum. We study momentum version of DIANA for the case of smooth nonconvex objective with constant regularizer and fi = f (see Sec K, Thm 7 and Cor 7 for the details). We summarize a few key features of our complexity results established in Table 1.
First rate for Terngrad. We provide ﬁrst convergence rate of TernGrad and provide new tight analysis of 1-bit QSGD under less restrictive assumptions for both smooth strongly convex objectives with arbitrary closed convex regularizer and nonconvex objective with indicator-like regularizer (see Sec 3 for the detailed comparison). Both of these methods are just special cases of our Algorithm 2 which is also a special case of Algorithm 1 with α = 0 and h0i = 0 for all i. We show that Algorithm 2 has O (κ/nαp) iteration complexity of convergence to the ball with center at the optimum in the case of the smooth strongly convex minimization problem with arbitrary closed convex regularizer (see Sec L, Thm 10) and O 1/ε2 max L2(f(x0)−f(x∗))2/n2α2p, σ4/(1+nαp)2 in the case of nonconvex minimization problem with indicator-like regularizer (see Thm 8 and Cor 8).
QSGD and Terngrad with momentum. We study momentum version of DIANA for α = 0, h0i = 0 and, in particular, we propose momentum versions of (1-bit) QSGD and TernGrad the case of smooth nonconvex objective with constant regularizer and fi = f (see Sec L.4, Thm 9 and Cor 9).
Optimal norm power. We ﬁnd the answer for the following question: which p norm to use for quantization in order to get the best iteration complexity of the algorithm? It is easy to see that all the bounds that we propose depend on 1/αp where αp is an increasing function of 1 ≤ p ≤ ∞ (see Lemma 1 for the details). That is, for both Algorithm 1 and 2 the iteration complexity reduces when p is growing and the best iteration complexity for our algorithms is achieved for p = ∞. This implies that TernGrad has better iteration complexity than 1-bit QSGD.
First analysis for block-quantization. We give a ﬁrst analysis of block-quantization (i.e. bucketquantization), which was mentioned in [1] as a useful heuristic.
3 The Algorithm
In this section we describe our main method—DIANA. However, we ﬁrst need to introduce several key concepts and ingredients that come together to make the algorithm. In each iteration k of DIANA, each node will sample an unbiased estimator of the local gradient. We assume that these gradients have bounded variance.
3

Assumption 1 (Stochastic gradients). For every i = 1, 2, . . . , n, E[gik | xk] = ∇fi(xk). Moreover, the variance is bounded:

E

gik − ∇fi(xk)

2 2

≤ σi2.

(2)

Note that gk := n1

n i=1

gik

is

an

unbiased

estimator

of

∇f (xk):

n

E[gk | xk] = n1 ∇fi(xk) = ∇f (xk).

(3)

i=1

Let σ2 := n1

n i=1

σi2.

By

independence

of

the

random

vectors

{gik

−

∇fi (xk )}ni=1 ,

its

variance

is

bounded above by

E

gk − ∇f (xk)

2 2

| xk

≤ σn2 .

(4)

Quantization. DIANA applies random compression (quantization) to gradient differences, which are then communicated to a parameter server. We now deﬁne the random quantization transformations used. Our ﬁrst quantization operator transforms a vector ∆ ∈ Rd into a random vector ∆ˆ ∈ Rd whose entries belong to the set {−t, 0, t} for some t > 0.
Deﬁnition 1 (p-quantization). Let ∆ ∈ Rd and let p ≥ 1. If ∆ = 0, we deﬁne ∆ = ∆. If ∆ = 0, we deﬁne ∆ by setting

∆(j) = ∆ psign(∆(j))ξ(j), j = 1, 2, . . . , d,

(5)

where ξ(j) ∼ Be |∆(j)|/ ∆ p are Bernoulli random variables1. Note that

∆ = ∆ p sign(∆) ◦ ξ,

(6)

where sign is applied elementwise, and ◦ denotes the Hadamard (i.e. elementwise) product. We say that ∆ is p-quantization of ∆. When sampling ∆, we shall write ∆ ∼ Quantp(∆).

In addition, we consider a block variant of p-quantization operators. These are deﬁned and their properties studying in Section in the appendix.
Communication cost. If b bits are used to encode a ﬂoat number, then at most C(∆ˆ ) := ∆ˆ 10/2(log ∆ˆ 0 + log 2 + 1) + b bits are needed to communicate ∆ˆ with Elias coding (see Theorem 3.3 in [1]). In our next result, we given an upper bound on the expected communication cost.
Theorem 1 (Expected sparsity). Let 0 = ∆ ∈ Rd˜ and ∆ ∼ Quantp(∆) be its p-quantization. Then

E ∆ 0 = ∆∆ p1 ≤ ∆ 10−1/p ≤ d˜1−1/p, (7)

Cp := EC(∆) ≤

∆

1/2 1

(log

d˜

+

log

2

+

1)

+

b.

(8)

∆

1/2 p

All expressions in (7) and (8) are increasing functions of p.

Proximal step. Given γ > 0, the proximal operator for the regularizer R is deﬁned as proxγR(u) :=

arg minv

γR(v) + 12

v−u

2 2

. The proximal operator of a closed convex function is nonexpan-

sive. That is, for any γ > 0 and u, v ∈ Rd,

proxγR(u) − proxγR(v) 2 ≤ u − v 2.

(9)

DIANA. In DIANA, each machine i ∈ {1, 2, . . . , n} ﬁrst computes a stochastic gradient gik at current iterate xk. We do not quantize this information and send it off to the parameter server as that approach would not converge for R = 0. Instead, we maintain memory hki at each node i (initialized to arbitrary values), and quantize the difference δik := gik − hki instead. Both the node and the parameter server update hki in an appropriate manner, and a proximal gradient descent step is taken with respect to direction vk = βvk−1 + gˆk, where 0 ≤ β ≤ 1 is a momentum parameter, whereas
1That is, ξ(j) = 1 with probability |∆(j)|/ ∆ p (observe that this quantity is always upper bounded by 1) and ξ(j) = 0 with probability 1 − |∆(j)|/ ∆ p.

4

Block quant.
     

Loc. data Nonconvex Strongly Convex R Momentum





























































Table 2: Summary of iteration complexity results.

α>0
     

Theorem
4 7 2, 5 8 9 10, 11

gˆk is an unbiased estimator of the full gradient, assembled from the memory hki and the transmitted quantized vectors. Note that we allows for block quantization for more ﬂexibility. In practice, we
want the transmitted quantized vectors to be much easier to communicate than the full dimensional vector in Rd, which can be tuned by the choice of p deﬁning the quantization norm, and the choice
of blocks.

Relation to QSGD and TernGrad. If the initialization is done with h0 = 0 and α = 0, our method

reduces to either 1-bit QSGD or TernGrad with p = 2 and p = ∞ respectively. We unify them in

the Algorithm 2. We analyse this algorithm (i.e. DIANA with α = 0 and h0i = 0) in three cases:

i) smooth strongly convex objective with arbitrary closed convex regularizer; ii) smooth nonconvex

objective with constant regularizer; iii) smooth nonconvex objective with constant regularizer for the

momentum version of the algorithm. We notice, that in the original paper [19] authors do not provide

the rate of convergence for TernGrad and we get the convergence rate for the three aforementioned

situations as a special case of our results. Moreover, we emphasize that our analysis is new even

for 1-bit QSGD, since in the original paper [1] authors consider only the case of bounded gradients

(E

gk

2 2

≤

B2), which is very restrictive assumption, and they do not provide rigorous analysis

of block-quantization as we do. In contrast, we consider more general case of block-quantization

and assume only that the variance of the stochastic gradients is bounded, which is less restrictive

assumption since the inequality E

gk

2 2

≤

B2

implies

E

gk − ∇f (xk)

2 2

≤

E

gk

2 2

≤

B2.

We obtain the convergence rate for arbitrary p ≥ 1 for the three aforementioned cases (see Theorems 8, 9, 10, 11 and Corollaries 8, 9, 10 for the details) and all obtained bounds becomes better when p is growing, which means that TernGrad has better iteration complexity than QSGD and, more generally, the best iteration complexity attains for ∞ norm quantization.

4 Theory: Strongly Convex Case

Let us introduce two key assumptions of this section.

Assumption 2 (L–smoothness). We say that a function f is L-smooth if

f (x) ≤ f (y) + ∇f (y), x − y + L2 x − y 22, ∀x, y.

(10)

Assumption 3 (µ-strong convexity). f is µ-strongly convex, i.e.,

f (x) ≥ f (y) + ∇f (y), x − y + µ2 x − y 22, ∀x, y.

(11)

For 1 ≤ p ≤ +∞, deﬁne

αp(d) := inf

x

2 2

.

x=0,x∈Rd x 1 x p

(12)

Lemma 1. αp is increasing as a function of p and decreasing as a function of d. In particular, α1 ≤ α2 ≤ α∞, and moreover, α1(d) = 1/d, α2(d) = 1/√d, α∞(d) = 2/(1+√d) and, as a consequence, for

all

positive

integers

d

and
√

d

the√following

relations

holds

α1(d)

=

α1(d)d/d,

α2(d)

=

α2(d)

d/d,

and α∞(d) = α∞(d)(1+ d)/(1+ d).

Theorem 2. Assume the functions f1, . . . , fn are L–smooth and µ–strongly convex. Choose stepsizes α > 0 and γk = γ > 0, block sizes {dl}m l=1, where d = max dl, and parameter c > 0
l=1,...,m
satisfying the following relations:

11++nnccαα2 ≤ αp := αp(d), (13)

γ ≤ min αµ , (µ+L)2(1+cα) .

(14)

5

p

iteration complexity

1 max 2md , (κ + 1)A ; A = 12 − n1 + ndm

√

√

2 max 2√md , (κ + 1)B ; B = 12 − n1 + n√dm

κ = Θ(n) O n + md
O n + md

κ = Θ(n2) O n2 + nmd
√
O n2 + n√md

∞ max 1 +

d , (κ + 1)C ;

C=

1 − 1 + 1+

d m

m

2n

2n

O n + md

√
O n2 + n√md

Table 3: The leading term of the iteration complexity of DIANA in the strongly convex case (Thm 2, Cor 1 and Lem 1). Logarithmic dependence on 1/ is suppressed. Condition number: κ := L/µ.

Deﬁne the Lyapunov function

V k := xk − x∗ 2 + cγ2 n hk − h∗ 2,

2

n

i

i2

i=1

(15)

where x∗ is the solution of (1) and h∗ := ∇f (x∗). Then for all k ≥ 0,

EV k ≤ (1 − γµ)kV 0 + µγ (1 + ncα) σn2 . (16)

This implies that as long as k ≥ γ1µ log V 0 , we have EV k ≤ + µγ (1 + ncα) σn2 .

In particular, if we set γ to be equal to the minimum in (14), then the leading term in the iteration complexity bound is 1/γµ = max {1/α, (µ+L)(1+cα)/2µ} .

Corollary 1. Let κ = L/µ, α = αp/2, c = 4(1−αp)/nα2p, and γ = min α/µ, (L+µ)2(1+cα) . Then the conditions (13) and (14) are satisﬁed, and the leading iteration complexity term is equal to

1/γµ = max {2/αp, (κ + 1) (1/2 − 1/n + 1/nαp)} .

(17)

This is a decreasing function of p, and hence p = +∞ is the optimal choice.

In Table 3 we calculate the leading term (17) in the complexity of DIANA for p ∈ {1, 2, +∞}, each for two condition number regimes: n = κ (standard) and n = κ2 (large).
Matching the rate of gradient descent for quadratic size models. Note that as long as the model size is not too big; in particular, when d = O(min{κ2, n2}), the linear rate of DIANA with p ≥ 2 is O(κ log(1/ )), which matches the rate of gradient descent.
Optimal block quantization. If the dimension of the problem is large, it becomes reasonable to quantize vector’s blocks, also called blocks. For example, if we had a vector which consists of 2 smaller blocks each of which is proportional to the vector of all ones, we can transmit just the blocks without any loss of information. In the real world, we have a similar situation when different parts of the parameter vector have different scale. A straightforward example is deep neural networks, layers of which have pairwise different scales. If we quantized the whole vector at once, we would zero most of the update for the layer with the smallest scale.
Our th√eory says that if we have n workers, then the iteration complexity increase of quantization is about d/n. However, if quantization is applied to a block of size n2, then this number becomes 1, implying that the complexity remains the same. Therefore, if one uses about 100 workers and splits the parameter vector into parts of size about 10,000, the algorithm will work as fast as SGD, while communicating bits instead of ﬂoats!
Some consideration related to the question of optimal number of nodes are included in Section E.

4.1 Decreasing stepsizes

We now provide a convergence result for DIANA with decreasing step sizes, obtaining a O(1/k) rate.

Theorem 3. Assume that f is L-smooth, µ-strongly convex and we have access to its gradients with bounded noise. Set γk = µk2+θ with some θ ≥ 2 max αµ , (µ+L)2(1+cα) for some numbers α > 0 and c > 0 satisfying 11++nnccαα2 ≤ αp. After k iterations of DIANA we have

EV k ≤ 1 max V 0, 4 (1+ncα)σ2 ,

ηk+1

nθµ

where η := µθ , V k =

xk − x∗

2 2

+

cγk n

gradient noise.

n i=1

h0i − h∗i

2 2

and

σ

is

the

standard

deviation

of

the

6

Corollary 2. If we choose α = αp , c = 4(1−α2 p) , θ = 2 max µ , (µ+L)(1+cα) =

2

nαp

α

2

αµp max 4, 2(κn+1) + (κ+1)n(n−2) αp , then there are three regimes: i) if 1 = max 1, nκ , καp ,

then θ = Θ αµp and to achieve EV k ≤ ε we need at most O α1p max V 0, (1−nαµp2)σ2 1ε iter-

ations; ii) if nκ = max 1, nκ , καp , then θ = Θ nLαp and to achieve EV k ≤ ε we need at most O nκαp max V 0, (1−µαLp)σ2 1ε iterations; iii) if καp = max 1, nκ , καp , then θ = Θ (L) and to achieve EV k ≤ ε we need at most O κ max V 0, (1−αp)σ2 1 iterations.
µLnαp ε

5 Theory: Nonconvex Case

In this section we consider the nonconvex case under the following assumption which we call bounded data dissimilarity.
Assumption 4 (Bounded data dissimilarity). We assume that there exists a constant ζ ≥ 0 such that for all x ∈ Rd
n1 ni=1 ∇fi(x) − ∇f (x) 22 ≤ ζ2. (18)

In particular, Assumption 4 holds with ζ = 0 when all fi’s are the same up to some additive constant (i.e. each worker samples from one dataset). We note that it is also possible to extend our analysis to a more general assumption with extra O( ∇f (x) 2) term in the right-hand side of (18). However, this would overcomplicate the theory without providing more insight.
Theorem 4. Assume that R is constant and Assumption 4 holds. Also assume that f is L-smooth, stepsizes α > 0 and γk = γ > 0 and parameter c > 0 satisfying 11++nnccαα2 ≤ αp, γ ≤ L(1+22cα) and xk is chosen randomly from {x0, . . . , xk−1}. Then

k2 2

Λ0

(1 + 2cnα)Lγ σ2

4cαLγ ζ 2

E

∇f (x

)

2≤

+ k γ(2 − Lγ − 2cαLγ) 2 − Lγ − 2cαLγ

n

+

,

2 − Lγ − 2cαLγ

where Λk := f (xk) − f ∗ + c L2γ2 n1

n i=1

hki − h∗i 22.

Corollary 3. Set α = αp , c = 4(1−α2 p) , γ =

nαp √ , h0 = 0 and run the algorithm

2

nαp

L(4+(n−4)αp) K

for K iterations. Then, the ﬁnal accuracy is at most √2 L(4+(n−4)αp) Λ0 + √1 (4−3αp)σ2 +

K

nαp

K 4+(n−4)αp

8(1−αp)ζ2√ .
(4+(n−4)αp) K

Moreover, if the ﬁrst term in Corollary 3 is leading and 1/n = Ω(αp), the resulting complexity is O(1/√K), i.e. the same as that of SGD. For instance, if sufﬁciently large mini-batches are used, the former condition holds, while for the latter it is enough to quantize vectors in blocks of size O(n2).

6 Implementation and Experiments
Following advice from [1], we encourage the use of blocks when quantizing large vectors. To this effect, a vector can decomposed into a number of blocks, each of which should then be quantized separately. If coordinates have different scales, as is the case in deep learning, it will prevent undersampling of those with typically smaller values. Moreover, our theoretical results predict that applying quantization to blocks or layers will result in superlinear acceleration. In our convex experiments, the optimal values of α were usually around mini 1/√di, where the minimum is taken with respect to blocks and di are their sizes.
Finally, higher mini-batch sizes make the sampled gradients less noisy, which in turn is favorable to more uniform differences gik − hki and faster convergence.
Detailed description of the experiments can be found in Section M as well as extra numerical results.

7

DIANA with momentum works best. We implement DIANA, QSGD, TernGrad and DQGD in Python2
using MPI4PY for processes communication. This is then tested on a machine with 24 cores, each is
Intel(R) Xeon(R) Gold 6146 CPU @ 3.20GHz. The problem considered is binary classiﬁcation with
logistic loss and 2 penalty, chosen to be of order 1/N , where N is the total number of data points. We experiment with choices of α, choice of norm type p, different number of workers and search for optimal block sizes. h0i is always set to be zero vector for all i. We observe that for ∞-norm the optimal block size is signiﬁcantly bigger than for 2-norm. Here, however, we provide Figure 1 to show how vast the difference is with other methods.

100

Functional accuracy

10 1

TernGrad

10 2

QSGD DQGD

DIANA momentum

10 3

10 4

0

2

4 Number6of epochs8

10

12

Figure 1: Comparison of the DIANA (β = 0.95) with QSGD, TernGrad and DQGD on the logistic regression problem for the ”mushrooms” dataset.

DIANA vs MPI. In Figure 2 we compare the performance of DIANA vs. doing a MPI reduce operation with 32bit ﬂoats. The computing cluster had Cray Aries High Speed Network. However, for DIANA we used 2bit per dimension and have experienced a strange scaling behaviour, which was documented also in [3]. In our case, this affected speed for alexnet and vgg a beyond 64 or 32 MPI processes respectively. For more detailed experiments, see Section M.
Train and test accuracy on Cifar10. In the next experiments, we run QSGD [1], TernGrad [19], SGD with momentum and DIANA on Cifar10 dataset for 3 epochs. We have selected 8 workers and run each method for learning rate from {0.1, 0.2, 0.05}. For QSGD, DIANA and TernGrad, we also tried various quantization bucket sizes in {32, 128, 512}√. For QSGD we have chosen 2, 4, 8 quantization levels. For DIANA we have chosen α ∈ {0, 1.0/ quantization bucket sizes } and have selected initial h = 0. For DIANA and SGD we also run a momentum version, with a momentum parameter in {0, 0.95, 0.99}. For DIANA we also run with two choices of norm 2 and ∞. For each experiment we have selected softmax cross entropy loss. Cifar10-DNN is a convolutional DNN described here https://github.com/kuangliu/pytorch-cifar/blob/master/models/lenet.py.
In Figure 3 we show the best runs over all the parameters for all the methods. We notice that DIANA and SGD signiﬁcantly outperform other methods.

images/second images/second images/second images/second

300000 250000

method FP32 Diana

LeNet, batch size: 64

200000

150000

100000

50000

04

8 16 MPI 32 64 128

250000 200000

method FP32 Diana

CifarNet, batch size: 32

150000

100000

50000

04

8 16 MPI 32 64 128

alexnet v2, batch size: 128

method

30000

FP32

Diana

25000

Diana - MultiGather

20000

15000

10000

5000

04

8 16 MPI 32 64 128

vgg a, batch size: 32

3000

method FP32

2500

Diana Diana - MultiGather

2000

1500

1000

500

04

8 16 MPI 32 64 128

Figure 2: Comparison of performance (images/second) for various number of GPUs/MPI processes and sparse communication DIANA (2bit) vs. Reduce with 32bit ﬂoat (FP32).

References
[1] Dan Alistarh, Demjan Grubic, Jerry Li, Ryota Tomioka, and Milan Vojnovic. QSGD: Communication-efﬁcient SGD via gradient quantization and encoding. In Advances in Neural Information Processing Systems, pages 1709–1720, 2017.
2The code will be made available online upon acceptance of this work.
8

Train Accuracy Test Accuracy

0.5

method QSGD

TernGrad

0.4

SGD DIANA

0.3

Cifar10-DNN

0.5

method

QSGD

TernGrad

0.4

SGD DIANA

0.3

Cifar10-DNN

0.2

0.2

0.1

0.1

0.0

0.5

1.0

1.5

2.0

2.5

3.0

epoch

0.0

0.5

1.0

1.5

2.0

2.5

3.0

epoch

Figure 3: Evolution of training (left) and testing (right) accuracy on Cifar10, using 4 algorithms: DIANA, SGD, QSGD and TernGrad. We have chosen the best runs over all tested hyper-parameters.

[2] Jeremy Bernstein, Yu-Xiang Wang, Kamyar Azizzadenesheli, and Animashree Anandkumar. signSGD: Compressed optimisation for non-convex problems. In Jennifer Dy and Andreas Krause, editors, Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pages 560–569, Stockholmsmssan, Stockholm Sweden, 10–15 Jul 2018. PMLR.
[3] Sudheer Chunduri, Paul Coffman, Scott Parker, and Kalyan Kumaran. Performance analysis of mpi on cray xc40 xeon phi system. 2017.
[4] Olivier Fercoq, Zheng Qu, Peter Richta´rik, and Martin Taka´cˇ. Fast distributed coordinate descent for minimizing non-strongly convex losses. IEEE International Workshop on Machine Learning for Signal Processing, 2014.
[5] Martin Jaggi, Virginia Smith, Martin Taka´cˇ, Jonathan Terhorst, Sanjay Krishnan, Thomas Hofmann, and Michael I. Jordan. Communication-efﬁcient distributed dual coordinate ascent. In Advances in Neural Information Processing Systems 27, 2014.
[6] Majid Jahani, Xi He, Chenxin Ma, Aryan Mokhtari, Dheevatsa Mudigere, Alejandro Ribeiro, and Martin Taka´cˇ. Efﬁcient distributed hessian free algorithm for large-scale empirical risk minimization via accumulating sample strategy. arXiv:1810.11507, 2018.
[7] Sarit Khirirat, Hamid Reza Feyzmahdavian, and Mikael Johansson. Distributed learning with compressed gradients. arXiv preprint arXiv:1806.06573, 2018.
[8] Jakub Konecˇny´, H Brendan McMahan, Felix X Yu, Peter Richta´rik, Ananda Theertha Suresh, and Dave Bacon. Federated learning: Strategies for improving communication efﬁciency. arXiv preprint arXiv:1610.05492, 2016.
[9] Jakub Konecˇny´ and Peter Richta´rik. Randomized distributed mean estimation: Accuracy vs communication. arXiv preprint arXiv:1611.07555, 2016.
[10] Chenxin Ma, Martin Jaggi, Frank E. Curtis, Nathan Srebro, and Martin Taka´cˇ. An accelerated communication-efﬁcient primal-dual optimization framework for structured machine learning. arXiv:1711.05305, 2017.
[11] Chenxin Ma, Jakub Konecˇny´, Martin Jaggi, Virginia Smith, Michael I. Jordan, Peter Richta´rik, and Martin Taka´cˇ. Distributed optimization with arbitrary local solvers. Optimization Methods and Software, 32(4):813–848, 2017.
[12] Chenxin Ma, Virginia Smith, Martin Jaggi, Michael I. Jordan, Peter Richta´rik, and Martin Taka´cˇ. Adding vs. averaging in distributed primal-dual optimization. In The 32nd International Conference on Machine Learning, pages 1973–1982, 2015.
[13] Chenxin Ma and Martin Taka´cˇ. Partitioning data on features or samples in communicationefﬁcient distributed optimization? OptML@NIPS 2015, arXiv:1510.06688, 2015.
[14] Sashank J Reddi, Jakub Konecˇny´, Peter Richta´rik, Barnaba´s Po´czo´s, and Alex Smola. AIDE: Fast and communication efﬁcient distributed optimization. arXiv preprint arXiv:1608.06879, 2016.
[15] Peter Richta´rik and Martin Taka´cˇ. Distributed coordinate descent method for learning with big data. Journal of Machine Learning Research, 17(75):1–25, 2016.
[16] Frank Seide, Hao Fu, Jasha Droppo, Gang Li, and Dong Yu. 1-bit stochastic gradient descent and its application to data-parallel distributed training of speech dnns. In Fifteenth Annual Conference of the International Speech Communication Association, 2014.

9

[17] Ohad Shamir, Nati Srebro, and Tong Zhang. Communication-efﬁcient distributed optimization using an approximate Newton-type method. In Proceedings of the 31st International Conference on Machine Learning, PMLR, volume 32, pages 1000–1008, 2014.
[18] V. Smith, S. Forte, C. Ma, M. Taka´cˇ, M. I. Jordan, and M. Jaggi. CoCoA: A general framework for communication-efﬁcient distributed optimization. Journal of Machine Learning Research, 18:1–49, 2018.
[19] Wei Wen, Cong Xu, Feng Yan, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li. Terngrad: Ternary gradients to reduce communication in distributed deep learning. In Advances in Neural Information Processing Systems, pages 1509–1519, 2017.
[20] Yuchen Zhang and Lin Xiao. DiSCO: Distributed optimization for self-concordant empirical loss. In Proceedings of the 32nd International Conference on Machine Learning, PMLR, volume 37, pages 362–370, 2015.
10

Appendix

A Basic Identities and Inequalities

Smoothness and strong convexity. If f is L-smooth and µ-strongly convex, then for any vectors x, y ∈ Rd we have
∇f (x) − ∇f (y), x − y ≥ µµ+LL x − y 22 + µ +1 L ∇f (x) − ∇f (y) 22. (19)

Norm of a convex combination. For any 0 ≤ α ≤ 1 and x, y ∈ Rd, we have

αx + (1 − α)y

2 2

=

α

x

2 2

+

(1

−

α)

y

2 2

−

α(1

−

α)

x−y

22.

(20)

Variance decomposition. The (total) variance of a random vector g ∈ Rd is deﬁned as the trace of its covariance matrix:

V[g] := Tr E (g − Eg)(g − Eg)

= E Tr (g − Eg)(g − Eg)

=

E

g − Eg

2 2

d

=

E(g(j) − Eg(j))2.

j=1

For any vector h ∈ Rd, the variance of g can be decomposed as follows:

E

g − Eg

2 2

=

E

g−h

2 2

−

Eg − h 22.

(21)

B Block p-quantization

We now introduce a block version of p-quantization. We found these quantization operators to have
better properties in practice.
Deﬁnition 2 (block-p-quantization). Let ∆ = (∆(1), ∆(2), . . . , ∆(m)) ∈ Rd, where ∆(1) ∈ Rd1 , . . . , ∆(m) ∈ Rdm , d1 + . . . + dm = d and dl > 1 for all l = 1, . . . , m. We say that ∆ˆ is p-quantization of ∆ with sizes of blocks {dl}m l=1 and write ∆ˆ ∼ Quantp(∆, {dl}m l=1) if ∆ˆ (l) ∼ Quantp(∆) for all l = 1, . . . , m.

In other words, we quantize blocks called blocks of the initial vector. Note that in the special case when m = 1 we get full quantization: Quantp(∆, {dl}m l=1) = Quantp(∆). Note that we do not assume independence of the quantization of blocks or independence of ξ(j). Lemma 2 in the
appendix states that ∆ˆ is an unbiased estimator of ∆, and gives a formula for its variance.

Next we show that the block p-quantization operator ∆ˆ introduced in Deﬁnition 2 is an unbiased estimator of ∆, and give a formula for its variance.
Lemma 2. Let ∆ ∈ Rd and ∆ˆ ∼ Quantp(∆). Then for l = 1, . . . , m

E∆ˆ (l) = ∆(l),

E

∆ˆ (l) − ∆(l)

2 2

= Ψl(∆),

(22)

E∆ˆ = ∆,

E

∆ˆ − ∆

2 2

= Ψ(∆),

(23)

where x = (x(1), x(2), . . . , x(m)), Ψl(x) :=

x(l) 1 x(l) p −

x(l)

2 2

≥

0, and Ψ(x)

:=

m

Ψl(x) ≥ 0. Thus, ∆ˆ is an unbiased estimator of ∆. Moreover, the variance of ∆ˆ is a decreasing

l=1

function of p, and is minimized for p = ∞.

Proof. Note that the ﬁrst part of (23) follows from the ﬁrst part of (22) and the second part of (23) follows from the second part of (22) and

m

∆ˆ − ∆

2 2

=

∆ˆ (l) − ∆(l) 22.

l=1

11

Therefore, it is sufﬁcient to prove (22). If ∆(l) = 0, the statements follow trivially. Assume ∆(l) = 0. In view of (5), we have

E∆ˆ (j)(l) = ∆(l) psign(∆(j)(l))Eξ(j) = ∆(l) psign(∆(j)(l))|∆(j)(l)|/ ∆(l) p = ∆(j)(l),

which establishes the ﬁrst claim. We can write

E

∆ˆ (l) − ∆(l)

2 2

=

E

(∆ˆ (j)(l) − ∆(j)(l))2

j

= E (∆ˆ (j)(l) − E∆ˆ (j)(l))2
j

(=5)

∆(l)

2 p

sign2(∆(j)(l))E(ξ(j) − Eξ(j))2

j

=

∆(l)

2 p

sign2(∆(j)(l)) |∆∆((jl))(l)p| (1 − |∆∆((jl))(l)p| )

j

=

|∆(j)(l)|( ∆(l) p − |∆(j)(l)|)

j

= ∆(l) 1 ∆(l) p − ∆(l) 2.

C Proof of Theorem 1

Let 1[·] denote the indicator random variable of an event. ∆ psign(∆(j))ξ(j), where ξ(j) ∼ Be(|∆(j)|/ ∆ p). Therefore,

In view of (5), ∆ˆ (j) =

d

d

∆ˆ 0 = 1[∆ˆ (j)=0] =

1[ξ(j ) =1] ,

j=1

j : ∆(j)=0

which implies that

d

E ∆ˆ = E

1

d

=

E1

d |∆(j)|

=

=

0

[ξ(j ) =1]

[ξ(j ) =1]

∆p

j : ∆(j)=0

j : ∆(j)=0

j : ∆(j)=0

∆ 1. ∆p

To establish the ﬁrst clam, it remains to recall that for all x ∈ Rd and 1 ≤ q ≤ p ≤ +∞, one has

the bound

x p≤

x q≤

x

1/q−1/p 0

x

p,

and apply it with q = 1. √
The proof of the second claim follows the same pattern, but uses the concavity of t → t and
Jensen’s inequality in one step.

D Proof of Lemma 1

αp(d) is increasing as a function of p because · p is decreasing as a function of p. Moreover, αp(d) is decreasing as a function of d since if we have d < b then

αp(b) = inf
x=0,x∈Rb

x

2 2

x1xp

inf
x=0,x∈Rbd

x 22 = inf x 1 x p x=0,x∈Rd

x 22 , x1xp

where Rdb := {x ∈ Rb : x(d+1) = . . . = x(b) = 0}. It is known that

is tight. Therefore,

α1(d) = inf
x=0,x∈Rd

x

2 2

1

x 2=d

1

xx 12 ≥ √1d , and that this bound

12

and

α2(d) = inf

x

2

=

1 √

.

x=0,x∈Rd x 1

d

Let us now establish that α∞(d) = 2√ . Note that
1+ d

x 22 = x1x∞

x x∞

2 x x∞ 2
x 1 x∞

=
∞

2 x
x ∞ 2.
x x∞ 1

Therefore, w.l.o.g. one can assume that x ∞ = 1. Moreover, signs of coordinates of vector x do

not inﬂuence aforementioned quantity either, so one can consider only x ∈ Rd+. In addition, since

x ∞ = 1, one can assume that x(1) = 1. Thus, our goal now is to show that the minimal value of

the function

1 + x2(2) + . . . + x2(d) f (x) =
1 + x(2) + . . . + x(d)

on the set M = {x ∈ Rd | x(1) = 1, 0 ≤ x(j) ≤ 1, j = 2, . . . , d} is equal to 1+2√d . By CauchySchwartz inequality: x2(2) + . . . + x2(d) ≥ (x(2)+d..−.+1x(d))2 and it becomes equality if and only if all
x(j), j = 2, . . . , d are equal. It means that if we ﬁx x(j) = a for j = 2, . . . , d and some 0 ≤ a ≤ 1
than the minimal value of the function

g(a) = 1 + ((dd−−1)1a)2 = 1 + (d − 1)a2 1 + (d − 1)a 1 + (d − 1)a

on [0, 1] coincides with minimal value of f on M . The derivative

2(d − 1)a (d − 1)(1 + (d − 1)a2) g (a) = 1 + (d − 1)a − (1 + (d − 1)a)2

has the same sign on [0, 1] as the difference a − 21(1++(d(d−−11)a)a2) , which implies that g attains its minimal value on [0, 1] at such a that a = 21(1++(d(d−−11)a)a2) . It remains to ﬁnd a ∈ [0, 1] which satisﬁes

a = 1 + (d − 1)a2 , a ∈ [0, 1] ⇐⇒ (d − 1)a2 + 2a − 1 = 0, a ∈ [0, 1]. 2(1 + (d − 1)a)

√
This quadratic equation has unique positive solution a∗ = −1d+−1 d = 1+1√d < 1. Direct calculations

show that g(a∗) = 2√ . It implies that α(d) = 2√ .

1+ d

1+ d

E Strongly Convex Case: Optimal Number of Nodes

In practice one has access to a ﬁnite data set, consisting of N data points, where N is very large, and wishes to solve an empirical risk minimization (“ﬁnite-sum”) of the form

N

minx∈Rd

f (x)

=

1 N

φi(x) + R(x),

(24)

i=1

where each φi is L–smooth and µ-strongly convex. If n ≤ N compute nodes of a distributed system are available, one may partition the N functions into n groups, G1, . . . , Gn, each of size |Gi| = N/n, and deﬁne fi(x) = Nn i∈Gi φi(x). Note that f (x) = n1 ni=1 fi(x) + R(x). Note that each fi is also L–smooth and µ–strongly convex.

This way, we have ﬁt the original (and large) problem (24) into our framework. One may now
ask the question: How many many nodes n should we use (other things equal)? If what we care
about is iteration complexity, then insights can be ga√ined by investigating Eq. (17√). For instance, if p = 2, then the complexity is W (n) := max 2 d/√m, (κ + 1) 1/2 − 1/n + d/n√m . The optimal choice is to choose n so that the term −1/n + √d/n√m becomes (roughly) equal to 1/2: −1/n + √d/n√m = 1/2. This gives the formula for the optimal number of nodes n∗ = n(d) := 2 d/m − 1 , and the resulting iteration complexity is W (n∗) = max 2√d/√m, κ + 1 . Note

that n(d) is increasing in d. Hence, it makes sense to use more nodes for larger models (big d).

13

F Quantization Lemmas

Consider iteration k of the DIANA method (Algorithm 1). Let EQk be the expectation with respect to

the

randomness

inherent

in

the

quantization

steps

∆ˆ ki

∼

Quant

p

(∆

k i

,

{

dl

}m l=1

)

for

i

=

1, 2, . . . , n

(i.e. we condition on everything else).

Lemma 3. For all iterations k ≥ 0 of DIANA and i = 1, 2, . . . , n we have the identities

EQk gˆik = gik,

EQk

gˆik − gik

2 2

=

Ψ(∆ki )

(25)

and

1n

1n

EQk gˆk = gk := n gik,

EQk

gˆk − gk

2 2

=

n2

Ψ(∆ki ).

(26)

i=1

i=1

Furthermore, letting h∗ = ∇f (x∗), and invoking Assumption 1, we have

Egˆk = ∇f (xk),

1n

σ2

E

gˆk − h∗

2 2

≤

E

∇f (xk) − h∗

2 2

+

n2

EΨ(∆ki ) + n . (27)

i=1

Proof.

(i) Since gˆik = hki + ∆ˆ ki and ∆ki = gik − hki , we can apply Lemma 2 and obtain

EQk gˆik

=

hki

+

EQk

∆ˆ

k i

(=23)

hki

+

∆ki

=

gik .

Since gˆik − gik = ∆ˆ ki − ∆ki , applying the second part of Lemma 1 gives the second identity in (25).

(ii) The ﬁrst part of (26) follows directly from the ﬁrst part of (25):

EQk gˆk = EQk

1n gˆik
n
i=1

1n

k (25) 1 n k (26) k

= n

EQk gˆi = n

gi = g .

i=1

i=1

The second part in (26) follows from the second part of (25) and independence of gˆ1k, . . . , gˆnk.

(iii) The ﬁrst part of (27) follows directly from the ﬁrst part of (26) and the assumption that gik is and unbiased estimate of ∇fi(xk). It remains to establish the second part of (27). First, we shall decompose

EQk

gˆk − h∗

2 2

(=21)

EQk

gˆk − EQk gˆk

2 2

+

EQk gˆk − h∗

2 2

(=26)

EQk

gˆk − gk

2 2

+

gk − h∗

2 2

(26) 1 n

k

k

∗2

= n2 Ψ(∆i ) + g − h 2.

i=1

Further, applying variance decomposition (21), we get

E

gk − h∗

2 2

|

xk

(=21)

E

gk − E[gk

| xk]

2 2

| xk

+

E[gk | xk] − h∗

2 2

(=3)

E

gk − ∇f (xk)

2 2

| xk

+

∇f (xk) − h∗

2 2

(4) σ2

k

∗2

≤

+ ∇f (x ) − h n

2.

Combining the two results, we get

1n

σ2

E[EQk

gˆk − h∗

2 2

|

xk ]

≤

n2

E Ψ(∆ki ) | xk + n + ∇f (xk) − h∗ 22.

i=1

After applying full expectation, and using tower property, we get the result.

14

Lemma 4. Let x∗ be a solution of (1) and let h∗i = ∇fi(x∗) for i = 1, 2, . . . , d. For every i, we can estimate the ﬁrst two moments of hki +1 as

EQk hki +1 = (1 − α)hki + αgik,

EQk

hki +1 − h∗i

2 2

=

(1

−

α)

hki − h∗i

2 2

+

α

gik − h∗i

2 2

−

α

m

∆ki

2 2

−

α

∆ki (l) 1 ∆ki (l) p .

l=1
(28)

Proof. Since

hik+1 = hki + α∆ˆ ki

(29)

and ∆ki = gik − hki , in view of Lemma 2 we have

EQk hki +1

(=29)

hki

+

α

EQ

k

∆ˆ

k i

(=23)

hki

+

α∆ki

=

(1

−

α)hki

+

αgik ,

(30)

m

which establishes the ﬁrst claim. Further, using

∆ki

2 2

=

∆ki (l)

2 2

we

obtain

l=1

EQk

hki +1 − h∗i

2 2

(=21) (30)=+(29)

(=23)

EQk hki +1 − h∗i

2 2

+

EQk

hki +1 − EQk hki +1

2 2

(1 − α)hki + αgik − h∗i

2 2

+

α2EQk

∆ˆ ki

−

EQk

∆ˆ

k i

2 2

m

(1 − α)(hki − h∗i ) + α(gik − h∗i )

2 2

+

α2

( ∆ki (l) 1 ∆ki (l) p −

l=1

∆ki (l) 22)

(=20)

(1 − α)

hki − h∗i

2 2

+

α

gik − h∗i

2 2

−

α(1

−

α)

∆ki

2 2

m

+α2

(

∆ki (l)

1

∆ki (l)

p) − α2

∆ki

2 2

l=1

m

=

(1 − α)

hki − h∗i

2 2

+

α

gik − h∗i

2 2

+

α2

( ∆ki (l) 1 ∆ki (l) p) − α ∆ki 22.

l=1

Lemma 5. We have

E

gˆk − h∗

2 2

|

xk

≤

∇f (xk) − h∗

2 2

+

1 −1
αp

1n

σ2

n2 i=1 ∇fi(xk) − hki 22 + αpn . (31)

Proof. Since αp = αp( max dl) and αp(dl) = inf

x

2 2

, we have for a particular

l=1,...,m

x=0,x∈Rdl x 1 x p

choice of x = ∆ki (l) that αp ≤ αp(dl) ≤ ∆ki (l∆) ki1(l∆) ki22(l) p . Therefore,

m

m

m

Ψ(∆ki ) = Ψl(∆ki ) = ( ∆ki (l) 1 ∆ki (l) ∞− ∆ki (l) 2) ≤

l=1

l=1

l=1

1 −1
αp

∆ki (l)

2 2

=

1 −1
αp

This can be applied to (27) in order to obtain

1n

σ2

E

gˆk − h∗

2 2

|

xk

≤

∇f (xk) − h∗

2 2

+

n2

E Ψ(∆ki ) | xk + n

i=1

1n 1

σ2

≤

∇f (xk) − h∗

2 2

+

n2

α − 1 E ∆ki 22 | xk + n .

i=1 p

Note that for every i we have E ∆ki | xk = E gik − hki | x = ∇fi(xk) − hki , so

E

∆ki

2 2

|

xk

(=21)

∇fi(xk) − hki

2 2

+

E

gik − ∇fi(xk)

2 2

| xk

≤

∇fi(xk) − hki

2 2

+

σi2.

Summing the produced bounds, we get the claim.

∆ki 22.

15

G Proof of Theorem 2

Proof. Note that x∗ is a solution of (1) if and only if x∗ = proxγR(x∗ − γh∗) (this holds for any γ > 0). Using this identity together with the nonexpansiveness of the proximaloperator, we shall
bound the ﬁrst term of the Lyapunov function:

EQk

xk+1 − x∗

2 2

=

EQk

proxγR(xk − γgˆk) − proxγR(x∗ − γh∗)

2 2

(9)

≤

EQk

xk − γgˆk − (x∗ − γh∗)

2 2

=

xk − x∗

2 2

−

2γEQk

gˆk − h∗, xk − x∗

+ γ2EQk

gˆk − h∗

2 2

(=26)

xk − x∗

2 2

−

2γ

gk − h∗, xk − x∗

+ γ2EQk

gˆk − h∗ 22.

Next, taking conditional expectation on both sides of the above inequality, and using (3), we get

E

EQk

xk+1 − x∗

2 2

|

xk

≤

xk − x∗

2 2

−

2γ

∇f (xk) − h∗, xk − x∗

+ γ2E

EQk

gˆk − h∗

2 2

|

xk

.

Taking full expectation on both sides of the above inequality, and applying the tower property and Lemma 3 leads to

E

xk+1 − x∗

2 2

≤

E

xk − x∗

2 2

−

2γE

∇f (xk) − h∗, xk − x∗

+ γ2E

gˆk − h∗

2 2

(27)

≤

E

xk − x∗

2 2

−

2γE

∇f (xk) − h∗, xk − x∗

γ2 n

γ2σ2

+γ2E

∇f (xk) − h∗

2 2

+

n2

EΨ(∆ki ) + n

i=1

≤

E

xk − x∗

2 2

−

2γE

∇f (xk) − h∗, xk − x∗

γ2 n

γ2 n

γ2σ2

+ n

E

∇fi(xk) − h∗i

2 2

+

n2

EΨ(∆ki ) + n , (32)

i=1

i=1

where the last inequality follows from the identities ∇f (xk) = n1 and an application of Jensen’s inequality.

n i=1

fi (xk ),

h∗

=

1 n

n i=1

h∗i

Averaging over the identities (28) for i = 1, 2, . . . , n in Lemma 4, we get

1n n EQk
i=1

k+1 ∗ 2 1 − α n hi −hi 2 = n
i=1

αn hki −h∗i 22+
n
i=1

αn gik−h∗i 22−
n
i=1

m

∆ki

2 2

−

α

∆ki (l) 1 ∆ki (l) p .

l=1

Applying expectation to both sides, and using the tower property, we get

1n

k+1 ∗ 2 1 − α n

k ∗2 α n

k ∗2 α n

n E hi −hi 2 = n

E hi −hi 2+ n E gi −hi 2− n E

i=1

i=1

i=1

i=1

m

∆ki

2 2

−

α

∆ki (l) 1 ∆ki (l) p .

l=1
(33)

Since

E[ gik − h∗i 22 | xk] (=21) ∇fi(xk) − h∗i 22 + E[ gik − ∇fi(xk) 22 | xk] (≤2) ∇fi(xk) − h∗i 22 + σi2,

the second term on the right hand side of (33) can be bounded above as

E

gik − h∗i

2 2

≤

E

∇fi(xk) − h∗i

2 2

+

σi2.

(34)

Plugging (34) into (33) leads to the estimate

1n

k+1

∗2

1−α n

k ∗2 α n

k

∗2

2

n E hi − hi 2 ≤ n

E hi − hi 2 + n E ∇fi(x ) − hi 2 + ασ

i=1

i=1

i=1

αn

m

−

E

∆ki

2 2

−

α

∆ki (l) 1 ∆ki (l) p .

(35)

n

i=1

l=1

16

Adding (32) with the cγ2 multiple of (35), we get an upper bound one the Lyapunov function:

(1 − α)cγ2 n

EV k+1

≤

E

xk − x∗

2 2

+

E

hki − h∗i

2 2

n

i=1

γ2(1 + αc) n

+

E

∇fi(xk) − h∗i

2 2

−

2γE

∇f (xk) − h∗, xk − x∗

n

i=1

γ2 n m + n2 E
i=1 l=1

∆ki (l) 1 ∆ki (l) p −

∆ki (l)

2 2

− nαc

∆ki (l)

2 2

−

α

∆ki (l)

1

∆ki (l)

p

:=Tik (l)

γ2σ2

+(ncα + 1) .

(36)

n

We now claim that due to our choice of α and c, we have Tik(l) ≤ 0 for all ∆ki (l) ∈ Rdl , which means that we can bound this term away by zero. Indeed, note that Tki(l) = 0 for ∆ki (l) = 0. If ∆ki (l) = 0, then Tki(l) ≤ 0 can be equivalently written as

1 + ncα2

∆ki (l)

2 2

≤ ∆k(l) ∆k(l) .

1 + ncα

i

1i

p

However, this inequality holds since in view of the ﬁrst inequality in (13) and the deﬁnitions of αp and αp(dl), we have

1 + ncα2 (13)

(12)

1 + ncα ≤ αp ≤ αp(dl) = x=0i,nx∈f Rdl

x 22 ≤ x1xp

∆ki (l) 22 . ∆ki (l) 1 ∆ki (l) p

Therefore, from (36) we get

(1 − α)cγ2 n

EV k+1

≤

E

xk − x∗

2 2

+

E

hki − h∗i

2 2

n

i=1

γ2(1 + αc) n

+

E

∇fi(xk) − h∗i

2 2

−

2γE

∇f (xk) − h∗, xk − x∗

n

i=1

γ2σ2

+(ncα + 1) .

(37)

n

The next trick is to split ∇f (xk) into the average of ∇fi(xk) in order to apply strong convexity of each term:

E ∇f (xk) − h∗, xk − x∗

1n

=

E ∇fi(xk) − h∗i , xk − x∗

n

i=1

(19) 1 n

≥

E

µL xk − x∗ 22 + 1

∇fi(xk) − h∗i

2 2

n

µ+L

µ+L

i=1

µL

1 1n

=

E

xk − x∗

2 2

+

E ∇fi(xk) − h∗i 22.(38)

µ+L

µ+Ln

i=1

Plugging these estimates into (37), we obtain

EV k+1 ≤

2γµL 1−
µ+L

(1 − α)cγ2 n

E

xk − x∗

2 2

+

E

hki − h∗i

2 2

n

i=1

+ γ2(1 + αc) − 2γ µ+L

1n

γ2σ2

E

∇fi(xk) − h∗i

2 2

+

(ncα

+

1)

(.39)

n

n

i=1

17

Notice that in view of the second inequality in (14), we have γ2(1+αc)− µ2+γL ≤ 0. Moreover, since

fi is µ–strongly convex, we have µ

xk − x∗

2 2

≤

∇fi(xk) − h∗i , xk − x∗ . Applying the Cauchy-

Schwarz inequality to further bound the right hand side, we get the inequality µ xk − x∗ 2 ≤

∇fi(xk) − h∗i 2. Using these observations, we can get rid of the term on the second line of (39)

and absorb it with the ﬁrst term, obtaining

(1 − α)cγ2 n

γ2σ2

EV k+1 ≤ 1 − 2γµ + γ2µ2 + cαγ2µ2 E xk−x∗ 22+

E hki −h∗i 22+(ncα+1)

.

n

n

i=1

(40) It follows from the second inequality in (14) that 1 − 2γµ + γ2µ2 + cαγ2µ2 ≤ 1 − γµ. Moreover,

the ﬁrst inequality in (14) implies that 1 − α ≤ 1 − γµ. Consequently, from (40) we obtain the

recursion

EV k+1 ≤ (1 − γµ)EV k + (ncα + 1) γ2σ2 . n

Finally, unrolling the recurrence leads to

EV k ≤ (1 − γµ)kV 0 + k−1(1 − γµ)lγ2(1 + ncα) σ2 n
l=0

≤ (1 − γµ)kV 0 + ∞ (1 − γµ)lγ2(1 + ncα) σ2 n
l=0

= (1 − γµ)kV 0 + γ (1 + ncα) σ2 .

µ

n

H Proof of Corollary 1

Corollary 4. Let κ = L , α = αp , c = 4(1−α2 p) , and γ = min α ,

2

. Then the

µ

2

nαp

µ (L+µ)(1+cα)

conditions (13) and (14) are satisﬁed, and the leading term in the iteration complexity bound is

equal to

1

2

11 1

= max , (κ + 1) − +

.

(41)

γµ

αp

2 n nαp

This is a decreasing function of p. Hence, from iteration complexity perspective, p = +∞ is the

optimal choice.

Proof. Condition (14) is satisﬁed since γ = min αµ , (L+µ)2(1+cα) . Now we check that (13) is also

satisﬁed:

1 + ncα2 1

1 + n · 4(1n−αα2 p) · α42p 1

=

p

·

1 + ncα αp

1 + n · 4(1−αp) · αp αp

nα2p

2

= 2 − αp αp + 2(1 − αp)

= 1.

Since

α

=

αp

and

c

=

4(1−αp )
2

we

have

2

nαp

1 + αc = 1 + 2(1 − αp) = 1 − 2 + 2

nαp

n nαp

and, therefore,

1

1 L+µ

2

11 1

= max ,

(1 + cα) = max , (κ + 1) − +

,

γµ

α 2µ

αp

2 n nαp

which is a decreasing function of p, because αp increases when p increases.

18

I Strongly convex case: decreasing stepsize
Lemma 6. Let a sequence {ak}k satisfy inequality ak+1 ≤ (1 − γkµ)ak + (γk)2N for any positive γk ≤ γ0 with some constants µ > 0, N > 0, γ0 > 0. Further, let θ ≥ γ20 and take C such that N ≤ µ4θ C and a0 ≤ C. Then, it holds
ak ≤ µ kC+ 1
θ
if we set γk = µk2+θ .

Proof. We will show the inequality for ak by induction. Since inequality a0 ≤ C is one of our assumptions, we have the initial step of the induction. To prove the inductive step, consider

ak+1 ≤ (1 − γkµ)ak + (γk)2N ≤ 1 − 2µ

θC

C

+ θµ

.

µk + θ µk + θ

(µk + θ)2

To show that the right-hand side is upper bounded by µ(k+θC1)+θ , one needs to have, after multiplying both sides by (µk + θ)(µk + µ + θ)(θC)−1,

2µ

µk + µ + θ

1−

(µk + µ + θ) + µ

≤ µk + θ,

µk + θ

µk + θ

which is equivalent to

µk + µ + θ

µ−µ

≤ 0.

µk + θ

The last inequality is trivially satisﬁed for all k ≥ 0.

Theorem 5. Assume that f is L-smooth, µ-strongly convex and we have access to its gradients with bounded noise. Set γk = µk2+θ with some θ ≥ 2 max αµ , (µ+L)2(1+cα) for some numbers α > 0 and c > 0 satisfying 11++nnccαα2 ≤ αp. After k iterations of DIANA we have

EV k ≤ 1 max V 0, 4 (1 + ncα)σ2 ,

ηk + 1

nθµ

where η := µθ , V k =

xk − x∗

2 2

+

cγk n

gradient noise.

n i=1

h0i − h∗i

2 2

and

σ

is

the

standard

deviation

of

the

Proof. To get a recurrence, let us recall an upper bound we have proved before:
EV k+1 ≤ (1 − γkµ)EV k + (γk)2(1 + ncα) σ2 . n
Having that, we can apply Lemma 6 to the sequence EV k. The constants for the lemma are: N = (1 + ncα) σn2 , C = max V 0, 4 (1+nnθcµα)σ2 , and µ is the strong convexity constant.

Corollary 5. If we choose α = αp , c = 4(1−α2 p) , θ = 2 max µ , (µ+L)(1+cα) =

2

nαp

α

2

αµp max 4, 2(κn+1) + (κ+1)n(n−2) αp , then there are three regimes:

1) if 1 = max 1, nκ , καp , then θ = Θ αµp O α1p max V 0, (1−nαµp2)σ2 1ε iterations;

and to achieve EV k ≤ ε we need at most

2) if nκ = max 1, nκ , καp , then θ = Θ nLαp

O κ max V 0, (1−αp)σ2 1 iterations;

nαp

µL

ε

and to achieve EV k ≤ ε we need at most

19

3) if καp = max

1,

κ n

,

καp

, then θ = Θ (L) and to achieve EV k ≤ ε we need at most

O κ max V 0, (1−αp)σ2 1 iterations.

µLnαp ε

Proof.

First of all, let us show that c =

4(1−αp )
2

and α satisfy inequality

1+ncα2

≤ αp:

nαp

1+ncα

1 + ncα2 1 1 + ncα αp

1 + n · 4(1n−αα2 p) · α42p 1

=

p

·

4(1−αp) · αp αp

1 + n · nα2

2

p

= 2 − αp αp + 2(1 − αp)

= 1.

Moreover, since

1 + cα = 1 + 2(1 − αp) = 2 + (n − 2)αP

nαp

nαp

we can simplify the deﬁnition of θ:

µ (µ + L) (1 + cα)

θ = 2 max ,

α

2

µ

2(κ + 1) (κ + 1)(n − 2)

=

max 4,

+

αp

n

n αp

µ

κ

= Θ αp max 1, n , καp .

Using Theorem 5, we get in the case:

1) if 1 = max 1, nκ , καp , then θ = Θ αµp , η = Θ (αp), 4(1+nnθcµα)σ2 = Θ (1−nαµp2)σ2 and to achieve EV k ≤ ε we need at most O α1p max V 0, (1−nαµp2)σ2 1ε iterations;
2) if nκ = max 1, nκ , καp , then θ = Θ nLαp , η = Θ ακpn , 4(1+nnθcµα)σ2 = Θ (1−µαLp)σ2 and to achieve EV k ≤ ε we need at most O nκαp max V 0, (1−µαLp)σ2 1ε iterations;
3) if καp = max 1, nκ , καp , then θ = Θ (L), η = Θ κ1 , 4(1+nnθcµα)σ2 = Θ (1µ−Lαnpα)pσ2 and to achieve EV k ≤ ε we need at most O κ max V 0, (1µ−Lαnpα)pσ2 1ε iterations.

J Nonconvex analysis

Theorem 6. Assume that R is constant and Assumption 4 holds. Also assume that f is L-smooth, stepsizes α > 0 and γk = γ > 0 and parameter c > 0 satisfying 11++nnccαα2 ≤ αp, γ ≤ L(1+22cα) and
xk is chosen randomly from {x0, . . . , xk−1}. Then

k2 2

Λ0

(1 + 2cnα)Lγ σ2

4cαLγ ζ 2

E

∇f (x

)

2≤

+ k γ(2 − Lγ − 2cαLγ) 2 − Lγ − 2cαLγ

n

+

,

2 − Lγ − 2cαLγ

where Λk := f (xk) − f ∗ + c L2γ2 n1

n i=1

hki − h∗i 22.

20

Proof. The assumption that R is constant implies that xk+1 = xk − γgˆk and h∗ = 0. Moreover, by smoothness of f

Ef (xk+1) (≤10) Ef (xk) + E ∇f (xk), xk+1 − xk + L2 E xk+1 − xk 22

(26) k

k 2 Lγ2 k 2

≤

Ef (x ) − γE ∇f (x ) 2 +

E gˆ 2

2

(27)

Lγ2

Lγ2 1 n

Lγ2 n

≤ Ef (xk) − γ − 2

E

∇f (xk)

2 2

+

2

n2

E Ψ(∆ki ) + 2n2

σi2.

i=1

i=1

Denote Λk := f (xk) − f ∗ + c L2γ2 n1

n i=1

hki − h∗i

22. Due to Assumption 4 we can rewrite the

equation (28) after summing it up for i = 1, . . . , n in the following form

1n E
n i=1

hki +1 − h∗i

2 2

|

xk

1−α n

αn

≤

hki − h∗i +

E

gik − h∗i

2 2

|

xk

n

n

i=1

i=1

m

−α

∆ki

2 2

−

α

∆ki (l) 1 ∆ki (l) p

l=1

1−α n

2α n

2α n

≤

hki − h∗i +

E

gik

2 2

|

xk

+

h∗i − h∗

2 2

n

n

n

i=1

i=1

i=1

0

m

−α

∆ki

2 2

−

α

∆ki (l) 1 ∆ki (l) p

l=1

(4) 1 − α n

2α n

2α n

≤

hki − h∗i +

∇fi (xk )

2 2

+

σi2 + 2αζ2

n

n

n

i=1

i=1

i=1

m

−α

∆ki

2 2

−

α

∆ki (l) 1 ∆ki (l) p

l=1

(4)+(21)
≤

1−α n

hki − h∗i

+ 2α

∇f (xk)

2 2

+

2ασ2

+

4αζ 2

n

i=1

m

−α

∆ki

2 2

−

α

∆ki (l) 1 ∆ki (l) p ,

l=1

If we add it the bound above, we get

k+1

k+1 ∗ Lγ2 1 n

k+1

∗2

EΛ

= Ef (x ) − f + c 2n

E hi − hi 2

i=1

≤ Ef (xk) − f ∗ − γ

Lγ 1 − − cαLγ
2

Lγ2 1 n

E

∇f (xk)

2 2

+

(1

−

α)c

E

hki − h∗i

2 2

2n

i=1

Lγ2 1 n m + 2 n2 E
i=1 l=1

( ∆ki (l) 1 ∆ki (l) p −

∆ki (l)

2 2

)

−

ncα(

∆ki (l)

2 2

−

α

∆ki (l)

1

∆ki (l)

p)

:=Tik (l)

+ (1 + 2cnα) Lγ2 σ2 + 2cαLγ2ζ2. 2n

We now claim that due to our choice of α and c, we have Tik(l) ≤ 0 for all ∆ki (l) ∈ Rdl , which means that we can bound this term away by zero. Indeed, note that Tki(l) = 0 for ∆ki (l) = 0. If ∆ki (l) = 0, then Tki(l) ≤ 0 can be equivalently written as

1 + ncα2

∆ki (l)

2 2

≤ ∆k(l) ∆k(l) .

1 + ncα

i

1i

p

21

However, this inequality holds since in view of the ﬁrst inequality in (13) and the deﬁnitions of αp and αp(dl), we have

1 + ncα2 (13)

(12)

1 + ncα ≤ αp ≤ αp(dl) = x=0i,nx∈f Rdl

Putting all together we have

x 22 ≤ x1xp

∆ki (l) 22 . ∆ki (l) 1 ∆ki (l) p

Lγ2 1 n

Lγ

EΛk+1 ≤ Ef (xk) − f ∗ + c

E

hki − h∗i

2 2

−

γ

1−

− cαLγ

E

∇f (xk)

2 2

2n

2

i=1

+(1 + 2cnα) Lγ2 σ2 + 2cαLγ2ζ2. 2n

Due to γ ≤ L(1+22cα) the coefﬁcient before

∇f (xk)

2 2

is

positive.

Therefore, we can rearrange the

terms and rewrite the last bound as

k2

EΛk − EΛk+1

(1 + 2cnα)Lγ σ2

4cαLγ ζ 2

E[

∇f (x

)

2]

≤

2 γ(2

−

Lγ

−

2cαLγ)

+

2

−

Lγ

−

2cαLγ

n

+

.

2 − Lγ − 2cαLγ

Summing from 0 to k − 1 results in telescoping of the right-hand side, giving

k−1
E[ ∇f (xl) 22] ≤ 2

Λ0 − EΛk

(1 + 2cnα)Lγ σ2

4cαLγ ζ 2

+k

+k

.

γ(2 − Lγ − 2cαLγ) 2 − Lγ − 2cαLγ n 2 − Lγ − 2cαLγ

l=0

Note that EΛk is non-negative and, thus, can be dropped. After that, it sufﬁces to divide both sides

by k and rewrite the left-hand side as E

∇f (xk)

2 2

where

expectation

is

taken

w.r.t.

all

randomness.

Corollary 6. Set α = αp , c = 4(1−α2 p) , γ =

nαp √ , h0 = 0 and run the algorithm

2

nαp

L(4+(n−4)αp) K

for K iterations. Then, the ﬁnal accuracy is at most √2 L(4+(n−4)αp) Λ0 + √1 (4−3αp)σ2 +

K

nαp

K 4+(n−4)αp

8(1−αp)ζ2√ .
(4+(n−4)αp) K

Proof. Our choice of α and c implies

cα = 2(1 − αp) , 1 + 2cα = 4 + (n − 4)αp , 1 + 2cnα = 4 − 3αp .

nαp

nαp

αp

Using this and the inequality γ =

nαp √ ≤

nαp

we get 2 − Lγ − 2cαLγ =

L(4+(n−4)αp) K

L(4+(n−4)αp )

2−(1+2cα)Lγ ≥ 1. Putting all together we obtain K2 γ(2−LγΛ−02cαLγ) +(1+2cnα) 2−LγL−γ2cαLγ σn2 +

4cαLγζ2 ≤ √2 L(4+(n−4)αp) Λ0 + √1 (4−3αp)σ2 + 8(1−αp)ζ2√ .

2−Lγ−2cαLγ

K

nαp

K 4+(n−4)αp (4+(n−4)αp) K

K Momentum version of DIANA

Theorem 7. Assume that f is L-smooth, R ≡ const, h0i = 0 and Assumption 4 holds. Choose 0 ≤ α < αp, β < 1 − α and γ < 2L1(−2ωβ−2 1) , such that (1−ββ2)2α ≤ 1−β2−γ22LLγ2(δ2ω−1) , where δ :=

1+ n2 α1p − 1 Then

1 + 1−αα−β and ω := n−n 1 + nα1 p , and sample xk uniformly from {x0, . . . , xk−1}.

k 2 4(f (z0) − f ∗)

Lσ2

E ∇f (x ) 2 ≤

γk

+ 2γ (1 − β)2n

+ 3γ2 L2β2ζ2 (1 − β)5n

1 −1 .
αp

3 −2
αp

+ 2γ2 L2β2σ2 (1 − β)5n

3 −2
αp

22

Proof. The main idea of the proof is to ﬁnd virtual iterates zk whose recursion would satisfy zk+1 = zk − 1−γβ gˆk. Having found it, we can prove convergence by writing a recursion on f (zk). One possible choice is deﬁned below:

zk := xk − γβ vk−1,

(42)

1−β

where for the edge case k = 0 we simply set v−1 = 0 and z0 = x0. Although zk is just a slight perturbation of xk, applying smoothness inequality (10) to it produces a more convenient bound than the one we would have if used xk. But ﬁrst of all, let us check that we have the desired recursion for zk+1:

zk+1 (=49) xk+1 − γβ vk 1−β
= xk − γ vk 1−β

= xk − γβ vk−1 − γ gˆk

1−β

1−β

(=49) zk − γ gˆk. 1−β

Now, it is time to apply smoothness of f :

Ef (zk+1) ≤ E f (zk) + ∇f (zk), zk+1 − zk + L2 zk+1 − zk 22

(49)

k

γ

kk

Lγ2

k2

=

E f (z ) −

∇f (z ), gˆ

1−β

+ 2(1 − β)2 gˆ 2 .

(43)

The scalar product in (50) can be bounded using the fact that for any vectors a and b one has

−

a, b

=

12 (

a−b

2 2

−

a

2 2

−

b 22). In particular,

γ −
1−β

∇f (zk), ∇f (xk)

γ =
2(1 − β) γ
≤ 2(1 − β)

∇f (xk) − ∇f (zk)

2 2

−

∇f (xk)

2 2

−

L2

xk − zk

2 2

−

∇f (xk)

2 2

∇f (zk)

2 2

γ3L2β2 k−1 2

γ

k2

= 2(1 − β)3 v 2 − 2(1 − β) ∇f (x ) 2.

The next step is to come up with an inequality for E vk 22. Since we initialize v−1 = 0, one can show by induction that
k
vk = βlgˆk−l.
l=0
Deﬁne B := kl=0 βl = 1−1β−kβ+1 . Then, by Jensen’s inequality

E

vk

2 2

=

B2E

k βl

2

k βl

gˆk−l ≤ B2

E gˆk−l 22.

B

B

l=0

2

l=0

Since α < αp ≤ αp(dl) ≤ ∆ki (l∆) ki1(l∆) ki22(l) p for all i, k and l, we have

∆ki (l)

2 2

−

α

∆ki (l)

1

∆ki (l)

p ≥ (αp − α)

∆ki (l)

1

∆ki (l)

p≥0

for the case when ∆ki (l) = 0. When ∆ki (l) = 0 we simply have

∆ki (l)

2 2

−

α

∆ki (l)

1

∆ki (l) p =

0. Taking into account this and the following equality

m

∆ki

2 2

−

α

l=1

m
∆ki (l) 1 ∆ki (l) p =
l=1

∆ki (l)

2 2

−

α

∆ki (l)

1

∆ki (l)

p

,

23

we get from (28)

E

hki

2 2

≤

(1 − α)E

hki −1

2 2

+ αE

gik−1

2 2

≤

(1 − α)2E

hki −2

2 2

+ α(1 − α)E

gik−2

2 2

+ αE

gik−1

2 2

k−1

≤

. . . ≤ (1 − α)k

h0i

2 2

+α

(1 − α)jE

gik−1−j

2 2

0

j=0

k−1

k−1

=α

(1 − α)jE

∇fi(xk−1−j )

2 2

+

α

(1 − α)j σi2

j=0

j=0

k−1 j

k−1−j 2

σi2

≤ α (1 − α) E ∇fi(x

) 2 + α · 1 − (1 − α)

j=0

k−1

=α

(1 − α)jE

∇fi(xk−1−j )

2 2

+

σi2.

j=0

Under our special assumption inequality (31) gives us

1

1n

σ2

E gˆk 22 ≤ E ∇f (xk) 22 + αp − 1 n2 i=1 E ∇fi(xk) − hki 22 + αpn

≤2

∇fi (xk )

22 +2

hki

2 2

≤ E ∇f (xk) 22 + n22

1 −1
αp

n

2

∇fi (xk )

2 2

+

n2

i=1

1 −1
αp

n

σ2

E

hki

2 2

+

i=1 αpn

(18)

21

≤ 1+

−1

n αp

E ∇f (xk) 22 + n2

1 −1

ζ2 + 2

αp

n2

1 −1
αp

n

σ2

E

hki

2 2

+

i=1 αpn

21

≤ 1+

−1

n αp

E ∇f (xk) 22 + 2nα2

1 −1
αp

n k−1

(1 − α)jE

∇fi(xk−1−j )

2 2

i=1 j=0

1

2σ2 + 2ζ2 σ2

+

−1

+

αp

n

αpn

(18)

21

≤ 1+

−1

n αp

E ∇f (xk) 22 + 2nα

1 −1
αp

k−1

(1 − α)jE

∇f (xk−1−j )

2 2

j=0

+ 1 − 1 2σ2 + 2ζ2 + σ2 + 2α 1 − 1 k−1(1 − α)jζ2 αp n αpn n αp j=0

21

≤ 1+

−1

n αp

E ∇f (xk) 22 + 2nα

1 −1
αp

k−1

(1 − α)jE

∇f (xk−1−j )

2 2

j=0

1

2σ2 + 3ζ2 σ2

+

−1

+.

αp

n

αpn

Using this, we continue our evaluation of E vk 22:

k

2

E

vk

2 2

≤

B

βl 1 +

1 −1

l=0 n αp

E

∇f (xk−l)

2 2

1

2α k k−l−1

+B

−1

βl(1 − α)jE

∇f (xk−l−1−j )

2 2

αp n l=0 j=0

k
+B βl
l=0

1

2σ2 + 3ζ2 σ2

−1

+

.

αp

n

αpn

24

Now we are going to simplify the double summation:

k k−l−1

k k−l−1

βl(1 − α)jE

∇f (xk−l−1−j )

2 2

=

βl(1 − α)k−l−1−j E

∇f (xj)

2 2

l=0 j=0

l=0 j=0

k−1

k−j−1

=

E

∇f (xj)

2 2

βl(1 − α)k−l−1−j

j=0

l=0

k−1

(1 − α)k−j − βk−j

=

E

∇f (xj)

2 2

·

1−α−β

j=0

k

(1 − α)k−j

≤

E

∇f (xj)

2 2

·

1−α−β

j=0

1

k

=

(1 − α)j E ∇f (xk−j ) 22.

1−α−β

j=0

k
Note that B := βl ≤ 1−1β . Putting all together we get
l=0

δk

σ2

3

3ζ 2

1

E vk 22 ≤ 1 − β

(1 − α)lE

∇f (xk−l)

2 2

+

n(1 − β)2

α − 2 + n(1 − β)2

−1 , α

l=0

p

p

where δ := 1 + n2 α1p − 1 1 + 1−αα−β , and as a result

γ3L2β2

γ3L2β2δ k−1

γ3L2β2σ2 3

E

vk−1

2 2

≤

2(1 − β)4

(1 − α)k−1−lE

∇f (xl)

2 2

+

2n(1 − β)5

−2 α

2(1 − β)3

p

l=0

3γ 3 L2 β 2 ζ 2 + 2n(1 − β)5

1 −1 .
αp

To sum up, we have

E f (zk+1) ≤ E f (zk) − 2(1 γ− β) 1 − 1L−γωβ E ∇f (xk) 22

Lγ2α(ω − 1) γ3L2β2δ k−1

+ 2(1 − β)2 + 2(1 − β)4

(1 − α)k−1−lE

∇f (xl)

2 2

l=0

σ2 +
n

3 −2
αp

Lγ2

γ3L2β2

2(1 − β)2 + 2(1 − β)5

3γ 3 L2 β 2 ζ 2 + 2n(1 − β)5

1 −1 .
αp

Telescoping this inequality from 0 to k − 1, we get

Ef (zk) − f (z0) ≤ k σ2 n

3 −2
αp

Lγ2

γ3L2β2

2(1 − β)2 + 2(1 − β)5

3γ 3 L2 β 2 ζ 2 + k 2n(1 − β)5

1 −1
αp

γ k−2 +
2 l=0

Lγα(ω − 1) γ2L2β2δ (1 − β)2 + (1 − β)4

k−1
(1 − α)k −1−l
k =l+1

E

∇f (xl)

2 2

γ k−2 +
2 l=0

Lγω

1

(1 − β)2 − 1 − β

E

∇f (xl)

2 2

+ γ2 (1L−γωβ)2 − 1 −1 β E ∇f (xk−1) 22

σ2 ≤k
n

3 −2
αp

Lγ2

γ3L2β2

2(1 − β)2 + 2(1 − β)5

3γ 3 L2 β 2 ζ 2 + k 2n(1 − β)5

1 −1
αp

γ k−1 +
2 l=0

γ2L2β2δ

Lγ

1

(1 − β)4α + (1 − β)2 (2ω − 1) − 1 − β

E

∇f (xl)

2 2

25

It holds f ∗ ≤ f (zk) and our assumption on β implies that γ(12−Lβ2β)42αδ + (1−Lγβ)2 (2ω − 1) − 1−1β ≤ − 12 , so it all results in

1 k−1

4(f (z0) − f ∗)

Lσ2

3

L2β2σ2 3

∇f (xl)

2 2

≤

γk + 2γ (1 − β)2n α − 2 + 2γ2 (1 − β)5n α − 2

k l=0

p

p

3γ 2 L2 β 2 ζ 2 + n(1 − β)5

1 −1 .
αp

Since xk is sampled uniformly from {x0, . . . , xk−1}, the left-hand side is equal to E ∇f (xk) 22. Also note that z0 = x0.
Corollary 7. If we set γ = 2√k1L−(2βω2−1) and β such that (1−ββ2)2α ≤ 4k(2δω−1) with k > 1, then the accuracy after k iterations is at most

1 8L(2ω − 1)(f (x0) − f ∗)

(1 + β)σ2

3

√k 1 − β2 + (2ω − 1)αpn(1 − β) αp − 2

1 (1 + β)4β2σ2 +
k 2(1 − β)(2ω − 1)αpn

3 −2
αp

1 3(1 + β)4β2ζ2 +
k 4(1 − β)(2ω − 1)αpn

1 −1 .
αp

Proof. Our choice of γ = √ 1−β2 implies that
2 kL(2ω−1)

β2

4k (2ω − 1)

β2

1 − β2 − 2Lγ (2ω − 1)

(1 − β)2α ≤ δ ⇐⇒ (1 − β)2α ≤

γ2L2δ .

After that it remains to put γ = 2√k1L−(2βω2−1) in 4(f(zγ0k)−f∗) + 2γ (1−Lβσ)22n α3p − 2 + 2γ2 (L1−2ββ2)σ52n α3p − 2 + 3γn2(1L−2ββ2)5ζ2 α1p − 1 to get the desired result.

26

L Analysis of DIANA with α = 0 and h0i = 0
L.1 Convergence Rate of TernGrad
Here we give the convergence guarantees for TernGrad and provide upper bounds for this method. The method coincides with Algorithm 2 for the case when p = ∞. In the original paper [19] no convergence rate was given and we close this gap.
To maintain consistent notation we rewrite the TernGrad in notation which is close to the notation we used for DIANA. Using our notation it is easy to see that TernGrad is DIANA with h01 = h02 = . . . = h0n = 0, α = 0 and p = ∞. Firstly, it means that hki = 0 for all i = 1, 2, . . . , n and k ≥ 1. What is more, this observation tells us that Lemma 3 holds for the iterates of TernGrad too. What is more, in the original paper [19] the quantization parameter p was chosen as ∞. We generalize the method and we don’t restrict our analysis only on the case of ∞ sampling.
As it was in the analysis of DIANA our proofs for TernGrad work under Assumption 1.

Algorithm 2 DIANA with α = 0 & h0i = 0; QSGD for p = 2 (1-bit)/ TernGrad for p = ∞ (SGD), [1, 19]

input learning rates {γk}k≥0, initial vector x0, quantization parameter p ≥ 1, sizes of blocks {dl}m l=1, momentum parameter 0 ≤ β < 1
1: v0 = ∇f (x0)

2: for k = 1, 2, . . . do

3: Broadcast xk to all workers

4: for i = 1, . . . , n do in parallel do

5:

Sample gik such that E[gik | xk] = ∇fi(xk); Sample gˆik ∼ Quantp(gik, {dl}m l=1)

6: end for

7:

gˆk = n1

n i=1

gˆik

;

vk = βvk−1 + gˆk;

xk+1 = proxγkR xk − γkvk

8: end for

L.2 Technical lemmas
First of all, we notice that since TernGrad coincides with Diana, having hki = 0, i, k ≥ 1, α = 0 and p = ∞, all inequalities from Lemma 3 holds for the iterates of TernGrad as well because ∆ki = gik and ∆ˆ ki = gˆik. Lemma 7. Assume γ ≤ L((n−n1α)pαp+1) . Then
2γµ 1 − γL((n − 1)αp + 1) ≥ γµ. (44) 2nαp

Proof. Since γ ≤ L((n−n1α)pαp+1) we have 2γµ 1 − γL((n − 1)αp + 1) 2nαp

1 ≥ 2γµ 1 −
2

= γµ.

Lemma 8. Assume γ ≤ L(1+κ(1−1αp)/(nαp)) , where κ := Lµ is the condition number of f . Then

r ≥ γµ,

(45)

where r = 2µγ − γ2 µL + L2(1−αp) .
nαp

Proof. Since γ ≤ L(1+κ(1−1αp)/(nαp)) = µnαpLµ+nLα2p(1−αp) we have nαpr = γ 2µnαp − γ µnαpL + L2(1 − αp) ≥ γµnαp,
whence r ≥ γµ.

27

Lemma 9. Assume γ ≤ (µ+L)(22n+α(np−2)αp) . Then

2γµ − γ2µ2 1 + 2(1 − αp) ≥ γµ.

(46)

nαp

Proof. Since γ ≤ (µ+L)(22n+α(np−2)αp) we have

γµ ≤

2µnαp

≤ (µ + L)nαp = nαp ,

(µ + L)(2 + (n − 2)αp) (µ + L)(2 + (n − 2)αp) 2 + (n − 2)αp

whence

2γµ − γ2µ2 1 + 2(1 − αp) ≥ 2γµ − γµ nαp

1 + 2(1 − αp) = 2γµ − γµ = γµ.

nαp

2 + (n − 2)αp

nαp

Lemma 10. Assume that each function fi is L-smooth and R is a constant function. Then for the iterates of Algorithm 2 with γk = γ we have

k+1

k

γ2L

k 2 γ2L 1

EΘ

≤ EΘ +

−γ E 2

∇f (x ) 2 + 2n2

−1 α

n
E

gik

2 2

p

i=1

γ2Lσ2

+

,

(47)

2n

where Θk = f (xk) − f (x∗) and σ2 := n1

n i=1

σi2.

Proof. Since R is a constant function we have xk+1 = xk − γgˆk. Moreover, from the L-smoothness of f we have

EΘk+1 ≤ EΘk + E ∇f (xk), xk+1 − xk + L2 xk+1 − xk 22

k

k 2 γ2L

k2

=

EΘ − γE

∇f (x ) 2 +

E 2

gˆ

2

(27)

γ2L

γ2L n m

≤ EΘk +

2

−γ

E

∇f (xk)

2 2

+ 2n2

E

gik(l) 1

gik(l) p −

gik (l)

2 2

i=1 l=1

γ2L n + 2n2 σi2,
i=1

where the ﬁrst equality follows from xk+1 − xk = gˆk, E gˆk | xk

tower property of mathematical expectation. By deﬁnition αp(dl) =

sup
x=0,x∈Rdl

x1 xp

x

2 2

−1
and αp = αp( max dl) which implies
l=1,...,m

= ∇f (xk) and the

inf

x

2 2

=

x=0,x∈Rdl x 1 x p

E

gik(l) 1

gik(l) p −

gik (l)

2 2

=

≤

m

Since

gik

2 2

=

gik (l)

2 2

we

have

l=1

EΘk+1 ≤ EΘk + γ2L − γ E 2

where σ2 = n1

n i=1

σi2.

E

gik (l)

2 2

gik(l) 1 gik(l) p

gk(l) 2 − 1

i

2

1 −1

E gk(l) 2.

αp

i

2

k 2 γ2L ∇f (x ) 2 + 2n2

1 −1
αp

n
E
i=1

≤ 1 − 1 E gk(l) 2

αp(dl)

i

2

k 2 γ2Lσ2

gi 2 +

, 2n

28

L.3 Nonconvex analysis

Theorem 8. Assume that R is constant and Assumption 4 holds. Also assume that f is L-smooth, γ ≤ L((n−n1α)pαp+1) and xk is chosen randomly from {x0, . . . , xk−1}. Then

E ∇f (xk) 2 ≤ 2 2 kγ

f (x0) − f (x∗) 2 − γ L((n−n1α)pαp+1)

γL σ2 + (1 − αp)ζ2

+

.

nαp

Proof. Recall that we deﬁned Θk as f (xk) − f (x∗) in Lemma 10. From (47) we have

k+1

k

γ2L

k 2 γ2L 1

EΘ

≤ EΘ +

−γ E 2

∇f (x ) 2 + 2n2

−1 α

n
E

k 2 γ2Lσ2

gi 2 +

. 2n

p

i=1

Using variance decomposition

E

gik

2 2

=

E

∇fi (xk )

2 2

+E

gik − ∇f (xk)

2 2

≤E

∇fi (xk )

2 2

+ σi2

we get

1n E
n i=1

gik

2 2

1n

≤

E

∇fi (xk )

2 2

+ σ2

n

i=1

(21)

k 2 1n

k

k2

2

= E ∇f (x ) 2 + n E ∇fi(x ) − ∇f (x ) 2 + σ

i=1

(18)

≤

E

∇f (xk)

2 2

+

ζ2

+

σ2.

Putting all together we obtain

k+1

k γ2L (n − 1)αp + 1

k 2 γ2Lσ2

EΘ

≤ EΘ +

·

2

nαp

− γ E ∇f (x ) 2 + 2nαp

+ γ2Lζ2(1 − αp) . (48) 2nαp

Since γ ≤ L((n−n1α)pαp+1) the factor γ22L · (n−n1α)αpp+1 − γ is negative and therefore

E

∇f (xk)

2 2

EΘk − EΘk+1

γL σ2 + (1 − αp)ζ2

≤

+

.

γ 1 − γ L((n−2n1α)αpp+1)

2nαp − γL((n − 1)αp + 1)

Telescoping the previous inequality from 0 to k − 1 and using γ ≤ L((n−n1α)pαp+1) we obtain

1 k−1 E
k l=0

∇f (xl)

2 2

2

EΘ0 − EΘk

γL σ2 + (1 − αp)ζ2

≤

+

.

k γ 2 − γ L((n−n1α)pαp+1)

nαp

It remains to notice that left-hand side is just E

∇f (xk)

2 2

, Θk

≥ 0 and Θ0

= f (x0)−f (x∗).

Corollary 8. If we choose γ =

nαp √

L((n−1)αp+1) K

√2 L (n−1)αp+1 f (x0) − f (x∗) + √1 σ2+(1−αp)ζ2 .

K

nαp

K (1+(n−1)αp)

then the rate we get is

Proof. Our choice of γ =

nαp √ ≤

nαp

implies that 2 − γ L((n−1)αp+1) ≥

L((n−1)αp+1) K

L((n−1)αp +1)

nαp

1. After that it remains to notice that for our choice of γ =

nαp √

L((n−1)αp+1) K

we have 2

f (x0)−f (x∗)

+ γL(σ2+(1−αp)ζ2) ≤ √2 L (n−1)αp+1 f (x0) − f (x∗) +

K γ 2−γ L((n−n1α)pαp+1)

nαp

K

nαp

√1K σ(12++((n1−−α1)pα)pζ)2 .

29

L.4 Momentum version

Theorem 9. Assume that f is L-smooth, R ≡ const, α = 0, hi = 0 and Assumption 4 holds. Choose β < 1 and γ < 12−Lβω2 such that (1−β2β)3 ≤ 1−βγ22−L22ωLγω , where ω := n−n 1 + nα1 p and sample
xk uniformly from {x0, . . . , xk−1}. Then

k 2 4(f (z0) − f ∗)

Lσ2

2 L2β2σ2

2 L2β2(1 − αp)ζ2

E ∇f (x ) 2 ≤

γk

+ 2γ αpn(1 − β)2 + 2γ (1 − β)5αpn + 2γ 2(1 − β)5αpn .

Proof. The main idea of the proof is to ﬁnd virtual iterates zk whose recursion would satisfy zk+1 = zk − 1−γβ gˆk. Having found it, we can prove convergence by writing a recursion on f (zk). One possible choice is deﬁned below:

zk := xk − γβ vk−1,

(49)

1−β

where for the edge case k = 0 we simply set v−1 = 0 and z0 = x0. Although zk is just a slight perturbation of xk, applying smoothness inequality (10) to it produces a more convenient bound than the one we would have if used xk. But ﬁrst of all, let us check that we have the desired recursion for zk+1:

zk+1 (=49) xk+1 − γβ vk 1−β
= xk − γ vk 1−β

= xk − γβ vk−1 − γ gˆk

1−β

1−β

(=49) zk − γ gˆk. 1−β

Now, it is time to apply smoothness of f :

Ef (zk+1) ≤ E f (zk) + ∇f (zk), zk+1 − zk + L2 zk+1 − zk 22

(49)

k

γ

kk

Lγ2

k2

=

E f (z ) −

∇f (z ), gˆ

1−β

+ 2(1 − β)2 gˆ 2 .

(50)

Under our special assumption inequality (31) simpliﬁes to

1

1n

σ2

E gˆk 22 | xk ≤ ∇f (xk) 22 + αp − 1 n2 i=1 ∇fi(xk) 22 + αpn

(18)

≤

∇f (xk)

2 2

+

1 −1
αp

n1 ∇f (xk) 22 +

1 −1
αp

ζ2 σ2 +.
n αpn

The scalar product in (50) can be bounded using the fact that for any vectors a and b one has

−

a, b

=

12 (

a−b

2 2

−

a

2 2

−

b 22). In particular,

γ −
1−β

∇f (zk), ∇f (xk)

γ =
2(1 − β) γ
≤ 2(1 − β)

∇f (xk) − ∇f (zk)

2 2

−

∇f (xk)

2 2

−

L2

xk − zk

2 2

−

∇f (xk)

2 2

∇f (zk)

2 2

γ3L2β2 k−1 2

γ

k2

= 2(1 − β)3 v 2 − 2(1 − β) ∇f (x ) 2.

The next step is to come up with an inequality for E vk 22. Since we initialize v−1 = 0, one can show by induction that
k
vk = βlgˆk−l.
l=0

30

Deﬁne B := kl=0 βl = 1−1β−kβ+1 . Then, by Jensen’s inequality

E

vk

2 2

=

B2E

k βl

2

k βl

gˆk−l ≤ B2

E

gˆk−l

2 2

B

B

l=0

2

l=0

k
≤ B βl
l=0

n−1 1

k−l 2

1

ζ2 σ2

n

+

E ∇f (x

nαp

) 2+

−1 αp

+

.

n αpn

Note that B ≤ 1−1β , so

γ3L2β2

k−1 2 γ3L2β2 σ2 γ3L2β2 (1 − αp)ζ2

γ3L2β2 k−1 k−1−l

l2

2(1 − β)3 E v

2

≤

2(1

−

β)5

+ αpn 2(1

−

β)5

αpn

+ω 2(1 − β)4

β

E ∇f (x ) 2

l=0

with ω := n−n 1 + nα1 p . We, thus, obtain

k+1

k

γ

Lγω

k2

Lγ2σ2

γ3L2β2σ2

Ef (z

)

≤

Ef (z ) − 2(1 − β)

1− 1−β

E ∇f (x ) 2 + 2nαp(1 − β)2 + 2(1 − β)5αpn

γ3L2β2(1 − αp)ζ2

γ3L2β2 k−1 k−1−l

l2

+ 2(1 − β)5αpn + ω 2(1 − β)4 β

E ∇f (x ) 2.

l=0

Telescoping this inequality from 0 to k − 1, we get

Ef (zk) − f (z0) ≤ k

Lγ2σ2 + γ3L2β2σ2 + γ3L2β2(1 − αp)ζ2

2αpn(1 − β)2 2(1 − β)5αpn

2(1 − β)5αpn

γ k−2 +
2 l=0

ω γ2L2β2 k−1 βk −1−l + Lγω − 1

(1 − β)4

(1 − β)2 1 − β

k =l+1

∇f (xl)

2 2

+ γ2 (1L−γωβ)2 − 1 −1 β E ∇f (xk−1) 22

≤k

Lγ2σ2 + γ3L2β2σ2 + γ3L2β2(1 − αp)ζ2

2αpn(1 − β)2 2(1 − β)5αpn

2(1 − β)5αpn

γ k−1 +
2 l=0

γ2L2β2

Lγω

1

ω (1 − β)5 + (1 − β)2 − 1 − β

∇f (xl) 22.

It holds f ∗ ≤ f (zk) and our assumption on β implies that ω γ(12−L2ββ)52 + (1L−γβω)2 − 1−1β ≤ − 12 , so it all results in

1 k−1

l 2 4(f (z0) − f ∗)

Lσ2

2 L2β2σ2

2 L2β2(1 − αp)ζ2

k

∇f (x ) 2 ≤

γk

+ 2γ αpn(1 − β)2 + 2γ (1 − β)5αpn + 2γ 2(1 − β)5αpn .

l=0

Since xk is sampled uniformly from {x0, . . . , xk−1}, the left-hand side is equal to E ∇f (xk) 22. Also note that z0 = x0.

Corollary 9. If we set γ = 21√−kβL2ω , where ω = n−n 1 + nα1 p , and β such that (1−β2β)3 ≤ 4kω with k > 1, then the accuracy after k iterations is at most

1 8Lω(f (x0) − f ∗) (1 + β)σ2

√

+

+ 1 (1 + β)4β2σ2 + 1 (1 + β)4β2(1 − αp)ζ2 .

k

1 − β2

ωαpn(1 − β) k 2(1 − β)ωαpn k 2(1 − β)ωαpn

Proof. Our choice of γ = 1√−β2 implies that
2 kLω

β2

1 − β2 − 2Lγω

β2

(1 − β)3 ≤ γ2L2ω ⇐⇒ (1 − β)3 ≤ 4kω.

After that it remains to put γ = 21√−kβL2ω in 4(f(zγ0k)−f∗) + 2γ αpnL(1σ−2 β)2 + 2γ2 (1L−2ββ)25σα2pn + k1 (1+2β()14−ββ2)(ω1−αpαnp)ζ2 to get the desired result.

31

L.5 Strongly convex analysis

Theorem 10. Assume that each function fi is µ-strongly convex and L-smooth. Choose stepsizes γk = γ > 0 satisfying
γ ≤ 2nαp . (51) (µ + L)(2 + (n − 2)αp)
If we run Algorithm 2 for k iterations with γk = γ, then

E xk − x∗ 22 ≤ (1 − γµ)k x0 − x∗ 22 + µγ

where σ2 := n1

n i=1

σi2

and

h∗i

=

∇fi(x∗).

σ2 2(1 − αp) n ∗ 2

nαp + n2αp

hi 2 ,

i=1

Proof. In the similar way as we did in the proof of Theorem 2 one can derive inequality (32) for the iterates of TernGrad:

E

xk+1 − x∗

2 2

≤

E

xk − x∗

2 2

−

2γE

∇f (xk) − h∗, xk − x∗

γ2 n

γ2 n

γ2σ2

+ n

E

∇fi(xk) − h∗i

2 2

+

n2

EΨ(gik) + n .

i=1

i=1

By deﬁnition αp(dl) = inf
x=0,x∈Rdl
which implies

= x

2 2

x1 xp

sup
x=0,x∈Rdl

x1 xp

x

2 2

−1
and αp = αp( max dl)
l=1,...,m

E Ψl(gik)

=E

gik(l) 1 gik(l) p −

gik (l)

2 2

=E

gik (l)

2 2

gik(l) 1 gik(l) p

gk(l) 2 − 1

i

2

≤

1

− 1 E gk(l) 2 ≤

1 −1

E gk(l) 2.

αp(dl)

i

2

αp

i

2

Moreover,

m

gik

2 2

=

l=1

gik(l) 22,

This helps us to get the following inequality

m
Ψ(gik) = Ψl(gik).
l=1

E

xk+1 − x∗

2 2

≤

E

xk − x∗

2 2

−

2γE

∇f (xk) − h∗, xk − x∗

γ2 n

γ2

+ n

E

∇fi(xk) − h∗i

2 2

+

n2

i=1

1 −1
αp

n
E
i=1

k 2 γ2σ2

gi 2 +

. n

Using

tower

property

of

mathematical

expectation

and

E

gik

2 2

|

xk

=

E

gik − ∇fi(xk)

2 2

| xk

+

∇fi (xk )

2 2

≤ σi2 +

∇fi (xk )

2 2

we

obtain

E

gik

2 2

≤

E

∇fi (xk )

2 2

+

σi2

≤

2E

∇fi(xk) − h∗i

2 2

+

2

h∗i

2 2

+

σi2,

where the last inequality follows from the fact that for all x, y ∈ Rn the inequality

x+y

2 2

≤

2

x

2 2

+

y

2 2

holds. Putting all together we have

E

xk+1 − x∗

2 2

≤

E

xk − x∗

2 2

−

2γE

∇f (xk) − h∗, xk − x∗

γ2 +
n

1 + 2(1 − αp) nαp

n

E

∇fi(xk) − h∗i

2 2

i=1

2γ2(1 − αp) n + n2αp
i=1

∗ 2 γ2σ2

hi

2+

. nαp

32

Using the splitting trick (38) we get

E

xk+1 − x∗

2 2

≤

1 − µ2γ+µLL E xk − x∗ 22

1 +

γ2

1 + 2(1 − αp)

−

2γ

n

nαp

µ+L

2γ2(1 − αp) n + n2αp
i=1

∗ 2 γ2σ2

hi

2+

. nαp

n

E

∇fi(xk) − h∗i

2 2

i=1

(52)

Since γ ≤ (µ+L)(22n+α(np−2)αp) the term γ2 1 + 2(1n−ααp p) − µ2+γL is non-negative. Moreover,

since fi

is µ–strongly convex, we have µ

xk − x∗

2 2

≤

∇fi(xk) − h∗i , xk − x∗ . Applying the

Cauchy-Schwarz inequality to further bound the right hand side, we get the inequality µ xk −

x∗ 2 ≤ ∇fi(xk) − h∗i 2. Using these observations, we can get rid of the second term in the (52)

and absorb it with the ﬁrst term, obtaining

E

xk+1 − x∗

2 2

≤

1 − 2γµ + γ2µ2 1 + 2(1 − αp) nαp

E

xk − x∗

2 2

2γ2(1 − αp) n + n2αp
i=1

∗ 2 γ2σ2 hi 2 + nαp

(46)

k ∗ 2 2 σ2 2(1 − αp) n ∗ 2

≤ (1 − γµ)E x − x 2 + γ nαp + n2αp

hi 2 .

i=1

Finally, unrolling the recurrence leads to

E xk − x∗

2 2

≤

(1

−

γµ)k

≤ (1 − γµ)k

= (1 − γµ)k

x0 − x∗ x0 − x∗ x0 − x∗

k−1

2 2

+

(1 − γµ)lγ2

l=0

σ2 2(1 − αp) n nαp + n2αp
i=1

∞

2 2

+

(1 − γµ)lγ2

l=0

σ2 2(1 − αp) n nαp + n2αp
i=1

22 + µγ

σ2 2(1 − αp) n ∗ 2

nαp + n2αp

hi 2 .

i=1

h∗i

2 2

h∗i

2 2

L.6 Decreasing stepsize

Theorem 11. Assume that f is L-smooth, µ-strongly convex and we have access to its gradients with bounded noise. Set γk = µk2+θ with some θ ≥ (µ+L)(22n+α(np−2)αp) . After k iterations of Algorithm 2 we have

k

∗2

1

0 ∗ 2 4 σ2 2(1 − αp) n ∗ 2

E x − x 2 ≤ ηk + 1 max

x − x 2, µθ

+ nαp

n2αp

hi 2 ,

i=1

where η := µθ , σ2 = n1

n i=1

σi2

and

h∗i

=

∇fi(x∗).

Proof. To get a recurrence, let us recall an upper bound we have proved before in Theorem 10:

k+1

∗2

k

k

∗2

k 2 σ2 2(1 − αp) n ∗ 2

E x − x 2 ≤ (1 − γ µ)E x − x 2 + (γ ) nαp + n2αp

hi 2 .

i=1

Having that, we can apply Lemma 6 to the sequence E xk − x∗ 22. The

stants for the Lemma are: N =

+ σ2
nαp

2(1−αp ) n2 αp

n i=1

h∗i

2 2

and C

max

x0 − x∗

22,

4 µθ

nσα2 + 2(n12−ααp)

n i=1

h∗i

2 2

.

p

p

con=

33

Corollary 10. If we choose θ = (µ+L)(22n+α(np−2)αp) , then to achieve E xk − x∗ 22 ≤ ε we

need at most O κ(1n+αnpαp) max

x0 − x∗ 22, (1+nnααpp)µL

+ σ2
nαp

1−αp n2 αp

n i=1

h∗i

2 2

1ε itera-

tions, where κ := Lµ is the condition number of f .

Proof. If θ = (µ+L)(22n+α(np−2)αp) = Θ L(1n+αnpαp) , then η = Θ κ(1n+αnpαp) and µ1θ = Θ µL(n1+αpnαp) . Putting all together and using the bound from Theorem 11 we get the desired result.

34

M Detailed Numerical Experiments
M.1 Performance of DIANA, QSGD and Terngrad on the Rosenbrock function
In Figure 4 we illustrate the workings of DIANA, QSGD and TernGrad with 2 workers on the 2dimensional (nonconvex) Rosenbrock function:
f (x, y) = (x − 1)2 + 10(y − x2)2, decomposed into average of f1 = (x+16)2 +10(y −x2)2 +16y and f2 = (x−18)2 +10(y −x2)2 − 16y + const. Each worker has access to its own piece of the Rosenbrock function with parameter a = 1 and b = 10. The gradients used are not stochastic, and we use 1-bit version of QSGD, so it also coincides with QGD in that situation. For all methods, its parameters were carefully tuned except for momentum and α, which were simply set to 0.9 and 0.5 correspondingly. We see that DIANA vastly outperforms the competing methods.

Diana

6

QSGD/QGD

TernGrad

Optimum

4

2

0

2

43

2

1

0

1

2

Figure 4: Illustration of the workings of DIANA, QSGD and TernGrad on the Rosenbrock function.

M.2 Logistic regression
We consider the logistic regression problem with 2 and 1 penalties for mushrooms dataset from LIBSVM. In our experiments we use 1-penalty coefﬁcient l1 = 2 · 10−3 and 2-penalty coefﬁcient l2 = Ln . The coefﬁcient l1 is adjusted in order to have sparse enough solution (≈ 20% non-zero values). The main goal of this series of experiment is to compare the optimal parameters for 2 and ∞ quantization.
M.2.1 What α is better to choose?
We run DIANA with zero momentum (β = 0) and obtain in our experiments that, actually, it is not important what α to choose for both 2 and ∞ quantization. The only thing that we need to control is that α is small enough.
M.2.2 What is the optimal block-size?
Since α is not so important, we run DIANA with α = 10−3 and zero momentum (β = 0) for different block sizes (see Figure 5). For the choice of ∞ quantization in our experiments it is always better to use full quantization. In the case of 2 quantization it depends on the regularization: if the regularization is big then optimal block-size ≈ 25 (dimension of the full vector of parameters is d = 112), but if the regularization is small it is better to use small block sizes.
M.2.3 DIANA vs QSGD vs TernGrad vs DQGD
We compare DIANA (with momentum) with QSGD, TernGrad and DQGD on the ”mushrooms” dataset (See Figure )

35

Functional accuracy

100 10 1 10 2 10 3 10 4 0 100 10 1 10 2 10 3 10 4
0 100
10 1

Number of workers = 10, p = 2

block size=6

100

block size=25

block size=112

10 1

Functional accuracy

10 2

10 3

10

20 Time (in3s0econds) 40

50

60

Number of workers = 20, p = 2

block size=6 block size=25 block size=112

10 4 0
100 10 1

Functional accuracy

10 2

10 3

10

20 Time (in3s0 econds) 40

50

60

Number of workers = 10, p = 2

block size=6 block size=25 block size=122

10 4 0
100
10 1

Number of workers = 10, p = inf block size=6 block size=25 block size=112

10

20 Time (in3s0econds) 40

50

60

Number of workers = 20, p = inf

block size=6 block size=25 block size=112

10

20 Time (in3s0econds) 40

50

60

Number of workers = 10, p = inf

block size=6 block size=25 block size=122

Functional accuracy

Functional accuracy

Functional accuracy

10 2
10 3 0
100
10 1

10 2

10 3

50

Tim10e0 (in second1s50)

200

250

Number of workers = 20, p = 2

block size=6 block size=25 block size=122

0 100 10 1

50

Tim10e0 (in second1s50)

200

250

Number of workers = 20, p = inf

block size=6 block size=25 block size=122

Functional accuracy

Functional accuracy

10 2 10 2

10 3 0

10 3

50

Tim10e0 (in second1s50)

200

250

0

50

Tim10e0 (in second1s50)

200

250

Figure 5: Comparison of the inﬂuence of the block sizes on convergence for ”mushrooms” (ﬁrst row), ”a5a” (second row) datasets.

M.3 MPI - broadcast, reduce and gather
In our experiments, we are running 4 MPI processes per physical node. Nodes are connected by Cray Aries High Speed Network. We utilize 3 MPI collective operations, Broadcast, Reduce and Gather. When implementing DIANA, we could use P2P communication, but based on our experiments, we found that using Gather to collect data from workers signiﬁcantly outperformed P2P communications.
36

Dataset

n d Number of workers Quantization Optimal block size (approx.)

mushrooms 8124 112

10

2

25

mushrooms 8124 112

10

∞

112

mushrooms 8124 112

20

2

25

mushrooms 8124 112

20

∞

112

a5a

6414 122

10

2

25

a5a

6414 122

10

∞

112

a5a

6414 122

20

2

25

a5a

6414 122

20

∞

112

Table 4: Approximate optimal number of blocks for different dataset and conﬁgurations. Momentum

equals zero for all experiments.

log10(time)

Communication 4 vs. 128 MPI processes

101

type Broadcast FP64

100

Broadcast FP32 Reduce FP64

10 1

Reduce FP32

Gather 2bit

10 2

MPI

4

10 3

128

10 4

10 5

10

6
10

12

14

16

18

20

22

24

26

28

log2(d)

Figure 6: Typical communication cost using broadcast, reduce and gather for 64 and 32 FP using 4 (solid) resp 128 (dashed) MPI processes. See suppl. material for details about the network.

In Figure 7 we show the duration of different communications for various MPI processes and message length. Note that Gather 2bit do not scale linearly (as would be expected). It turns out, we are not the only one who observed such a weird behavior when using cray MPI implementation (see [3] for a nice study obtained by a team from Argonne National Laboratory). To correct for the unexpected behavior, we have performed MPI Gather multiple times on shorter vectors, such that the master node obtained all data, but in much faster time (see Multi-Gather 2bit).

37

time [seconds]

10 1 10 2
4
100 10 1

Message length: 224

type

Broadcast FP64

100

Broadcast FP32

Reduce FP64

Reduce FP32

Gather 2bit

10 1

time [seconds]

8 16 MPI 32 64 128
Message length: 226
type Broadcast FP64 Broadcast FP32 Reduce FP64 Reduce FP32 Gather 2bit Multi-Gather 2bit

time [seconds]

10 2 4
100 10 1

Message length: 225
type Broadcast FP64 Broadcast FP32 Reduce FP64 Reduce FP32 Gather 2bit Multi-Gather 2bit
8 16 MPI 32 64 128
Message length: 227
type Broadcast FP64 Broadcast FP32 Reduce FP64 Reduce FP32 Gather 2bit Multi-Gather 2bit

time [seconds]

10 2 4

8 16 MPI 32 64 128

4 8 16 MPI 32 64 128

Figure 7: Time to communicate a vectors with different lengths for different methods as a function of # of MPI processes. One can observe that Gather 2bit is not having nice scaling. We also show that the proposed Multi-Gather communication still achieves a nice scaling when more MPI processes are used.

38

time [seconds]$

time [seconds]$

# of MPI processes: 4

101

type

100

Broadcast FP32 Reduce FP32

10 1

Gather 2bit

10 2

10 3

10 4

10 5

10 12 14 16 18 20 22 24 26 28 log2(d)

# of MPI processes: 16

101

type

100

Broadcast FP32 Reduce FP32

Gather 2bit

10 1

Multi-Gather 2bit

10 2

10 3

10 4

10 5 10 12 14 16 18 20 22 24 26 28 log2(d)

# of MPI processes: 64

101

type

100

Broadcast FP32 Reduce FP32

Gather 2bit

10 1

Multi-Gather 2bit

10 2

10 3

10 4

10 5 10 12 14 16 18 20 22 24 26 28 log2(d)

time [seconds]$

time [seconds]$

time [seconds]$

# of MPI processes: 8

101

type

100

Broadcast FP32 Reduce FP32

10 1

Gather 2bit

10 2

10 3

10 4

10 5

10 12 14 16 18 20 22 24 26 28 log2(d)

# of MPI processes: 32

101

type Broadcast FP32

100

Reduce FP32 Gather 2bit

10 1

Multi-Gather 2bit

10 2

10 3

10 4

10 5 10 12 14 16 18 20 22 24 26 28 log2(d)

# of MPI processes: 128

type

100

Broadcast FP32

Reduce FP32

10 1

Gather 2bit Multi-Gather 2bit

10 2

10 3

10 4

10 12 14 16 18 20 22 24 26 28 log2(d)

time [seconds]$

Figure 8: The duration of communication for MPI Broadcast, MPI Reduce and MPI Gather. We show how the communication time depends on the size of the vector in Rd (x-axis) for various # of MPI processes. In this experiment, we have run 4 MPI processes per computing node. For Broadcast and Reduce we have used a single precision ﬂoating point number. For Gather we used 2bits per dimension. For longer vectors and large number of MPI processes, one can observe that Gather has a very weird scaling issue. It turned out to be some weird behaviour of Cray-MPI implementation.

39

time [seconds]$

time [seconds]$

# of MPI processes: 4

# of MPI processes: 8

time [seconds]$

101

type

Broadcast FP64

100

Broadcast FP32

Reduce FP64

10 1

Reduce FP32

10 2

10 3

101

type Broadcast FP64

100

Broadcast FP32 Reduce FP64

10 1

Reduce FP32

10 2

10 3

10 4

10 4

10 5

10 5

10

6
10

12

14

16

18

20

22

24

26

28

10 12 14 16 18 20 22 24 26 28

log2(d)

log2(d)

# of MPI processes: 16

101

type Broadcast FP64

100

Broadcast FP32 Reduce FP64

10 1 Reduce FP32

# of MPI processes: 32

type

101

Broadcast FP64

Broadcast FP32

100

Reduce FP64

Reduce FP32

10 1

time [seconds]$

10 2

10 2

10 3

10 3

10 4

10 4

10 5

10 5

10 12 14 16 18 20 22 24 26 28 log2(d)

10 12 14 16 18 20 22 24 26 28 log2(d)

# of MPI processes: 64

type

101

Broadcast FP64

Broadcast FP32

100

Reduce FP64

Reduce FP32

10 1

10 2

10 3

10 4

10 5 10 12 14 16 18 20 22 24 26 28 log2(d)

time [seconds]$

# of MPI processes: 128

101

type Broadcast FP64

100

Broadcast FP32 Reduce FP64

10 1 Reduce FP32

10 2

10 3

10 4

10

5
10

12

14

16

18

20

22

24

26

28

log2(d)

Figure 9: The duration of communication for MPI Broadcast, MPI Reduce for single precision
(FP32) and double precision (FP64) ﬂoating numbers. We show how the communication time depends on the size of the vector in Rd (x-axis) for various # of MPI processes. In this experiment, we
have run 4 MPI processes per computing node. We have used Cray implementation of MPI.

time [seconds]$

40

M.4 Performance of GPU

In Table 5 we list the DNN networks we have experimented in this paper.

model

d # classes

input

LeNet CifarNet alexnet v2 vgg a

3.2M 1.7M 50.3M 132.8M

10 10 1,000 1,000

28 × 28 × 3 32 × 32 × 3 224 × 224 × 3 224 × 224 × 3

Table 5: Deep Neural Networks used in the experiments. The structure of the DNN is taken from https://github.com/tensorflow/models/tree/master/research/slim.

Figure 10 shows the performance of a single P100 GPU for different batch size, DNN network and operation.

105

images / second

104

model

vgg a

LeNet

103

alexnet v2 CifarNet

operation

gradient

function value

16 32 64 128 256 512 1024 2048 batch size

Figure 10: The performance (images/second) of NVIDIA Tesla P100 GPU on 4 different problems as a function of batch size. We show how different choice of batch size affects the speed of function evaluation and gradient evaluation. For vgg a, we have run out of memory on GPU for batch size larger than 128 (gradient evaluation) and 256 for function evaluation. Clearly, this graph suggest that choosing small batch size leads to small utilization of GPU. Note that using larger batch size do not necessary reduce the training process.

41

M.5 Diana vs. TenGrad, SGD and QSGD
In Figure 11 we compare the performance of DIANA vs. doing a MPI reduce operation with 32bit ﬂoats. The computing cluster had Cray Aries High Speed Network. However, for DIANA we used 2bit per dimension, we have experienced an weird scaling behaviour, which was documented also in[3]. In our case, this affected speed for alexnet and vgg a beyond 64 or 32 MPI processes respectively. For more detailed experiments, see Section M.3. In order to improve the speed of Gather, we impose a Multi-Gather strategy, when we call Gather multiple-times on shorter vectors. This signiﬁcantly improved the communication cost of Gather (see Figure 8) and leads to much nicer scaling – see green bars – DIANA-MultiGather in Figure 11).

images/second

300000 250000

method FP32 Diana

LeNet, batch size: 64

200000

150000

100000

50000

04

8 16 MPI 32 64 128

alexnet v2, batch size: 128

method

30000

FP32

Diana

25000

Diana - MultiGather

20000

15000

10000

5000

04

8 16 MPI 32 64 128

images/second

images/second

250000 200000

method FP32 Diana

CifarNet, batch size: 32

150000

100000

50000

04

8 16 MPI 32 64 128

vgg a, batch size: 32

3000

method FP32

2500

Diana Diana - MultiGather

2000

1500

1000

500

04

8 16 MPI 32 64 128

images/second

Figure 11: Comparison of performance (images/second) for various number of GPUs/MPI processes and sparse communication DIANA (2bit) vs. Reduce with 32bit ﬂoat (FP32). We have run 4 MPI processes on each node. Each MPI process is using single P100 GPU. Note that increasing MPI from 4 to 8 will not bring any signiﬁcant improvement for FP32, because with 8 MPI processes, communication will happen between computing nodes and will be signiﬁcantly slower when compare to the single node communication with 4MPI processes.

In the next experiments, we run QSGD [1], TernGrad [19], SGD with momentum and DIANA on Mnist dataset and Cifar10 dataset for 3 epochs. We have selected 8 workers and run each method for learning rate from {0.1, 0.2, 0.05}. For QSGD, DIANA and TernGrad, we also tried various quantization bucket sizes in {32, 128, 512}. F√or QSGD we have chosen 2, 4, 8 quantization levels. For DIANA we have chosen α ∈ {0, 1.0/ quantization bucket sizes } and have selected initial h = 0. For DIANA and SGD we also run a momentum version, with a momentum parameter in {0, 0.95, 0.99}. For DIANA we also run with two choices of norm 2 and ∞. For each experiment we have selected softmax cross entropy loss. Mnist-Convex is a simple DNN with no hidden layer, Mnist-DNN is a convolutional NN described here https://github.com/floydhub/ mnist/blob/master/ConvNet.py and Cifar10-DNN is a convolutional DNN described here https://github.com/kuangliu/pytorch-cifar/blob/master/models/lenet.py. In Figure 12 we show the best runs over all the parameters for all the methods. For Mnist-Convex SGD and DIANA makes use of the momentum and dominate all other algorithms. For Mnist-DNN situation is very similar. For Cifar10-DNN both DIANA and SGD have signiﬁcantly outperform other methods.
42

Train Accuracy Train Accuracy

Mnist-Convex
0.9

0.8

0.7

0.6

0.5

0.4

method

0.3

SGD DIANA

0.2

TernGrad

QSGD

0.1 0.0 0.5 1.0 1.5 2.0 2.5 3.0

epoch

Mnist-DNN

0.8

0.6

0.4

method

SGD

0.2

DIANA QSGD

TernGrad

0.0 0.5 1.0 1.5 2.0 2.5 3.0 epoch

0.5

method QSGD

TernGrad

0.4

SGD DIANA

Cifar10-DNN

0.3

Train Accuracy

0.2

0.1

0.0

0.5

1.0

1.5

2.0

2.5

3.0

epoch

Mnist-Convex
0.9

0.8

0.7

0.6

0.5

0.4

method

0.3

SGD DIANA

0.2

TernGrad

0.1

QSGD

0.0 0.5 1.0 1.5 2.0 2.5 3.0

epoch

Mnist-DNN

0.8

0.6

0.4

method

SGD

0.2

DIANA QSGD

TernGrad

0.0 0.5 1.0 1.5 2.0 2.5 3.0 epoch

0.5

method

QSGD

TernGrad

0.4

SGD DIANA

Cifar10-DNN

0.3

Test Accuracy

0.2

0.1

0.0

0.5

1.0

1.5

2.0

2.5

3.0

epoch

Test Accuracy Test Accuracy

Figure 12: Evolution of training and testing accuracy for 3 different problems, using 4 algorithms: DIANA, SGD, QSGD and TernGrad. We have chosen the best runs over all tested hyper-parameters.

In Figure 13 show the evolution of sparsity of the quantized gradient for the 3 problems and DIANA, QSGD and TernGrad. For Mnist-DNN, it seems that the quantized gradients are becoming sparser as the training progresses.

43

density density

Mnist-Convex
0.6

0.5

method

DIANA- 2

0.4

DIANA-

QSGD 2bit

0.3

QSGD 4bit QSGD 8bit

TernGrad

0.2

0.1 0.0 0.5 1.0 1.5 2.0 2.5 3.0 epoch

Mnist-DNN

0.40

method

0.35

DIANA- 2 DIANA-

0.30

QSGD 2bit QSGD 4bit

0.25

QSGD 8bit TernGrad

0.20

0.15

0.10

0.05 0.0 0.5 1.0 1.5 2.0 2.5 3.0 epoch

Cifar10-DNN

0.25

density

0.20

method

DIANA- 2

DIANA-

0.15

QSGD 2bit

QSGD 4bit

0.10

QSGD 8bit TernGrad

0.05

0.0

0.5

1.0

1.5

2.0

2.5

3.0

epoch

Figure 13: Evolution of sparsity of the quantized gradient for 3 different problems and 3 algorithms.

44

M.6 Computational Cost

time [seconds]

101

10 1

10 3

oper

FP32

10 5

Bin 4MPI Processes Bin 8MPI Processes

Bin 16MPI Processes

Bin 32MPI Processes

10 7

Bin 64MPI Processes

Bin 128MPI Processes

10 12 14 16 18 20 22 24 26 log2(d)

Figure 14: Comparison of a time needed to update weights after a reduce vs. the time needed to update the weights when using a sparse update from DIANA using 4-128 MPI processes and 10% sparsity.

45

Notation f (x) R(x) n d sign(t) x(j) x(l)
x p, p ≥ 1

Deﬁnition
Objective function, f (x) = n1 Regularizer

n i=1

fi

(x)

Size of the dataset

Dimension of vector x

The sign of t (−1 if t < 0, 0 if t = 0 and 1 if t > 1)

The j-th element of x ∈ Rd
m
The l-th block of x = (x(1) , x(2) , . . . , x(m) ) , x(l) ∈ Rdl , dl = d

p norm of x: x p =

d
|x(j)|p

l=1
1 p
for 1 ≤ p < ∞

j=1

x0 L µ κ gik gk σi2
σ2

hki ∆ki

Quantp(∆)

Quantp

(∆

,

{dl

}

m l=1

)

dl

m

α, γk

β

∆ˆ ki ∆ˆ

gˆik gˆk

vk

hk+1

proxγR(u)

Ψl(x)

Ψ(x)

αp(d)

x ∞ = max x ∞
j=1,...,d

Number of nonzero elements of x

Lipschitz constant of the gradient of f w. r. t. 2 norm

Strong convexity constant of f w. r. t. 2 norm

Condition number of function f : κ = Lµ

Stochastic gradient of function fi at the point x = xk Stochastic gradient of function f at the point x = xk: gk = n1
Variance of the stochastic gradient gik
n
Variance of the stochastic gradient gk: σ2 = n1 σi2
i=1

n i=1

gik

Stochastic approximation of the ∇fi(x∗); hki +1 = hki + α∆ˆ ki ∆ki = gik − hki

Full p-quantization of vector ∆

Block p-quantization of vector ∆ with block sizes {dl}m l=1

Size of the l-th block for quantization

Number of blocks for quantization

Learning rates

Momentum parameter

Block p-quantization of ∆ki = gik − hki

∆ˆ k = n1

n i=1

∆ˆ ki

Stochastic approximation of ∇fi(xk); gˆik = hki + ∆ˆ ki

gk = n1

n i=1

gik

Stochastic gradient with momentum: vk = βvk−1 + gˆk

hk+1 = n1

n i=1

hki +1

arg min

γR(v) + 12

v−u

2 2

v

Variance of the l-th quantized block: Ψl(x) = x(l) 1

x(l) p −
m

x(l)

2 2

Variance of the block p-quantized vector: Ψ(x) = Ψl(x)

l=1

αp(d) = inf

x

2 2

x=0,x∈Rd x 1 x p

d

d = max dl

l=1,...,m

αp
c x∗ h∗i Vk
ζ δ, ω η, θ, N, C EQk

αp = αp(d) Such number that 11++nnccαα2 ≤ αp

Solution of the problem (1)

h∗i = ∇fi(x∗)

Lyapunov function V k =

xk − x∗

2 2

+

cγ2 n

n i=1

hki − h∗i

Bounded data dissimilarity parameter: n1

n i=1

∇fi(x) − ∇f (x)

2 2

≤ ζ2

Parameters for the proof of momentum version of DIANA

Parameters for the decreasing stepsizes results

Expectation w. r. t. the randomness coming from quantization

Table 6: The table of all notations we use in this paper.

46

First appearance Eq.(1) Eq. (1) Eq. (1) Eq. (7) Eq. (6) Eq. (6)
Def. 2
Eq. (10)
Eq. (7) Eq. (10) Eq. (11) Cor. 1 Eq. (2) Eq. (3) Eq. (2)
Eq. (3)
Alg. 1 Alg. 1 Def. 1 Def. 2 Def. 2 Def. 2 Alg. 1 Alg. 1 Alg. 1 Alg. 1 Alg. 1 Alg. 1 Alg. 1 Alg. 1 Alg. 1 Eq. (22)
Eq. (23)
Eq. 12
Th. 2
Th. 2 Th. 2 Eq. (15) Th. 2 Th. 2 Eq. (18) Th. 7 Th. 5 Lem. 3

