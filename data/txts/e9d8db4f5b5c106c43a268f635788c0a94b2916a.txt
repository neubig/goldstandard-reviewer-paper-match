Stochastic Gradient Descent-Ascent: Uniﬁed Theory and New Eﬃcient Methods
Aleksandr Beznosikov1∗ Eduard Gorbunov1∗† Hugo Berard2∗ Nicolas Loizou3
1 Moscow Institute of Physics and Technology, Russian Federation 2 Mila, Universit´e de Montr´eal, Canada 3 Johns Hopkins University, USA

arXiv:2202.07262v1 [math.OC] 15 Feb 2022

Abstract
Stochastic Gradient Descent-Ascent (SGDA) is one of the most prominent algorithms for solving min-max optimization and variational inequalities problems (VIP) appearing in various machine learning tasks. The success of the method led to several advanced extensions of the classical SGDA, including variants with arbitrary sampling, variance reduction, coordinate randomization, and distributed variants with compression, which were extensively studied in the literature, especially during the last few years. In this paper, we propose a uniﬁed convergence analysis that covers a large variety of stochastic gradient descent-ascent methods, which so far have required diﬀerent intuitions, have diﬀerent applications and have been developed separately in various communities. A key to our uniﬁed framework is a parametric assumption on the stochastic estimates. Via our general theoretical framework, we either recover the sharpest known rates for the known special cases or tighten them. Moreover, to illustrate the ﬂexibility of our approach we develop several new variants of SGDA such as a new variance-reduced method (L-SVRGDA), new distributed methods with compression (QSGDA, DIANA-SGDA, VR-DIANA-SGDA), and a new method with coordinate randomization (SEGA-SGDA). Although variants of the new methods are known for solving minimization problems, they were never considered or analyzed for solving min-max problems and VIPs. We also demonstrate the most important properties of the new methods through extensive numerical experiments.

1 Introduction

Min-max optimization and, more generally, variational inequality problems (VIPs) appear in a wide range of research areas including but not limited to statistics [Bach, 2019], online learning [Cesa-Bianchi and Lugosi, 2006], game theory [Morgenstern and Von Neumann, 1953], and machine learning [Goodfellow et al., 2014]. Motivated by applications in these areas, in this paper, we focus on solving the following regularized VIP: Find x∗ ∈ Rd such that

F (x∗), x − x∗ + R(x) − R(x∗) ≥ 0 ∀x ∈ Rd,

(1)

where F : Rd → Rd is some operator and R : Rd → R is a regularization term (a proper lower semicontinuous convex function), which is assumed to have a simple structure. This problem is quite general and covers a wide range of possible problem formulations. For example, when operator F (x) is the gradient of a convex function f , then problem (1) is equivalent to the
∗Equal contribution. †Corresponding author: eduard.gorbunov@phystech.edu.

1

composite minimization problem [Beck, 2017], i.e., minimization of f (x) + R(x). Problem (1) is also a more abstract formulation of the min-max problem

min max f (x1, x2),

(2)

x1∈Q1 x2∈Q2

with convex-concave f . In that case, x = (x1 , x2 ) , F (x) = (∇x1f (x1, x2) , −∇x2f (x1, x2) ) ,

and R(x) = δQ1(x1) + δQ2(x2), where δQ(·) is an indicator function of the set Q [Alacaoglu and

Malitsky, 2021]. In addition to formulate the constraints, regularization R allows us to enforce

some properties to the solution x∗, e.g., sparsity [Candes et al., 2008, Beck, 2017].

More precisely, we are interested in the situations when operator F is accessible through

the calls of unbiased stochastic oracle. This is natural when F has an expectation form F (x) =

Eξ∼D [Fξ (x)]

or

a

ﬁnite-sum

form

F (x)

=

1 n

n i=1

Fi

(x).

In

the

context

of

machine

learning,

D

corresponds to some unknown distribution on the data, n corresponds to the number of samples,

and Fξ, Fi denote vector ﬁelds corresponding to the samples ξ, and i, respectively [Gidel et al.,

2019, Loizou et al., 2021].

One of the most popular methods for solving (1) is Stochastic Gradient Descent-Ascent1

(SGDA) [Dem’yanov and Pevnyi, 1972, Nemirovski et al., 2009]. However, besides its rich his-

tory, SGDA only recently was analyzed without using strong assumptions on the noise [Loizou

et al., 2021] such as uniformly bounded variance. In the last few years, several powerful al-

gorithmic techniques like variance reduction [Palaniappan and Bach, 2016, Yang et al., 2020]

and coordinate-wise randomization [Sadiev et al., 2021], were also combined with SGDA result-

ing in better algorithms. However these methods were analyzed under diﬀerent assumptions,

using diﬀerent analysis approaches, and required diﬀerent intuitions. Moreover, to the best of

our knowledge, fruitful directions such as communication compression for distributed versions

of SGDA or linearly converging variants of coordinate-wise methods for regularized VIPs were

never considered in the literature before.

All of these facts motivate the importance and necessity of a novel general analysis of SGDA

unifying several special cases and providing the ability to design and analyze new SGDA-like

methods ﬁlling existing gaps in the theoretical understanding of the method.

In this work, we develop such uniﬁed analysis.

1.1 Technical Preliminaries
Throughout the paper, we assume that operator F is µ-quasi-strongly monotone and -starcocoercive: there exist constants µ ≥ 0 and > 0 such that for all x ∈ Rd

F (x) − F (x∗), x − x∗ ≥ µ x − x∗ 2,

(3)

F (x) − F (x∗) 2 ≤ F (x) − F (x∗), x − x∗ ,

(4)

where x∗ = projX∗(x) := arg miny∈X∗ y − x is the projection of x on the solution set X∗ of (1). If µ = 0, inequality (3) is known as variational stability condition Hsieh et al. [2020], which is weaker than standard monotonicity: F (x) − F (y), x − y ≥ 0 for all x, y ∈ Rd. It is worth mentioning that there exist examples of non-monotone operators satisfying (3) with µ > 0 [Loizou et al., 2021]. Condition (4) is a relaxation of standard cocoercivity F (x) − F (y) 2 ≤
F (x) − F (y), x − y . At this point let us highlight that it is possible for an operator F to satisfy (4) and not be Lipschitz continuous [Loizou et al., 2021]. This emphasizes the wider
1This name is usually used in the min-max setup. Although we consider a more general problem formulation, we keep the name SGDA to highlight the connection with min-max problems.

2

applicability of the -star-cocoercivity compared to -cocoercivity. We emphasize that in our convergence analysis we do not assume -cocoercivity nor L-Lipschitzness of F .
We consider SGDA for solving (1) in its general form:
xk+1 = proxγkR(xk − γkgk), (5)
where gk is an unbiased estimator of F (xk), γk > 0 is a stepsize at iteration k, and proxγR(x) := arg miny∈Rd {R(y) + y−x 2/2γ} is a proximal operator deﬁned for any γ > 0 and x ∈ Rd. While gk gives an information about operator F at step k, proximal operator is needed to take into account regularization term R. We assume that function R is such that proxγR(x) can be easily computed for all x ∈ Rd. This is a standard assumption satisﬁed for many practically interesting regularizers [Beck, 2017]. By default we assume that γk ≡ γ > 0 for all k ≥ 0.
1.2 Our Contributions
Our main contributions are summarized below.
Uniﬁed analysis of SGDA. We propose a general assumption on the stochastic estimates and the problem (1) (Assumption 2.1) and show that several variants of SGDA (5) satisfy this assumption. In particular, through our approach we cover SGDA with arbitrary sampling [Loizou et al., 2021], variance reduction, coordinate randomization, and compressed communications. Under Assumption 2.1 we derive general convergence results for quasi-strongly monotone (Theorem 2.2) and monotone problems (Theorem 2.5).
Extensions of known methods and analysis. As a by-product of the generality of our theoretical framework, we derive new results for the proximal extensions of several known methods such as proximal SGDA-AS [Loizou et al., 2021] and proximal SGDA with coordinate randomization [Sadiev et al., 2021]. Moreover, we close some gaps on the convergence of known methods, e.g., we derive the ﬁrst convergence guarantees in the monotone case for SGDA-AS [Loizou et al., 2021] and SAGA-SGDA [Palaniappan and Bach, 2016] and we obtain the ﬁrst result on the convergence of SAGA-SGDA for (averaged star-)cocoercive operators.
Sharp rates for known special cases. For the known methods ﬁtting our framework our general theorems either recover the best rates known for these methods (SGDA-AS) or tighten them (SGDA-SAGA, Coordinate SGDA).
New methods. The ﬂexibility of our approach allows us to develop and analyze several new variants of SGDA. Guided by algorithmic advances for solving minimization problems we propose a new variance-reduced method (L-SVRGDA), new distributed methods with compression (QSGDA, DIANA-SGDA, VR-DIANA-SGDA), and a new method with coordinate randomization (SEGA-SGDA). We show that the proposed new methods ﬁt our theoretical framework and, using our general theorems, we obtain tight convergence guarantees for them. Although the analogs of these methods are known for solving minimization problems [Hofmann et al., 2015, Kovalev et al., 2020, Alistarh et al., 2017, Mishchenko et al., 2019, Horv´ath et al., 2019, Hanzely et al., 2018], they were never considered for solving minmax and variational inequality problems. Therefore, by proposing and analyzing these new methods we close several gaps in the literature on SGDA. For example, VR-DIANA-SGDA is the ﬁrst SGDA-type linearly converging distributed stochastic method with compression and SEGA-SGDA is the ﬁrst linearly converging coordinate method for solving regularized VIPs.
Numerical evaluation. In numerical experiments, we illustrate the most important properties of the new methods. The numerical results corroborate our theoretical ﬁndings.
3

1.3 Closely Related Work
Analysis of SGDA. SGDA is usually analyzed under uniformly bounded variance assumption. That is, E[ gk − F (xk) 2 | xk] ≤ σ2 is typically assumed to get convergence guarantees [Nemirovski et al., 2009, Mertikopoulos and Zhou, 2019, Yang et al., 2020]. This assumption rarely holds, especially for unconstrained VIPs: it is easy to construct an example of (1) with F being a ﬁnite sum of linear operators such that the variance is unbounded. Lin et al. [2020] provide a convergence analysis of SGDA under a relative random noise assumption allowing to handle some special cases not covered by uniformly bounded variance assumption. However, relative noise is also a quite strong assumption and usually requires a special type of noise appearing in coordinate methods2 or in the training of overparameterized models [Vaswani et al., 2019]. In their recent work, Loizou et al. [2021] proposed a new weak condition called expected cocoercivity. This assumption ﬁts our theoretical framework (see Section 3) and does not imply strong conditions on the variance of the stochastic estimator but it is stronger than star-cocoercivity of operator F .
Variance reduction for VIPs. The ﬁrst variance-reduced variants of SGDA (SVRGDA and SAGA-SGDA – analogs of SVRG [Johnson and Zhang, 2013] and SAGA [Defazio et al., 2014]) for solving (1) with strongly monotone operator F having a ﬁnite-sum form with Lipschitz summands were proposed in Palaniappan and Bach [2016]. For two-sided PL min-max problems without regularization Yang et al. [2020] proposed a variance-reduced version of SGDA with alternating updates. Since the considered class of problems includes non-strongly-convex-nonstrongly-concave min-max problems, the rates from Yang et al. [2020] are inferior to Palaniappan and Bach [2016]. There are also several works studying variance-reduced methods based on different methods rather than SGDA. Chavdarova et al. [2019] proposed a combination of SVRG and Extragradient (EG) [Korpelevich, 1976] called SVRE and analyzed the method for strongly monotone VIPs without regularization and with cocoercive summands Fi. The cocoercivity assumption was relaxed to averaged Lipschitzness in Alacaoglu and Malitsky [2021], where the authors proposed another variance-reduced version of EG (EG-VR) based on Loopless variant of SVRG [Hofmann et al., 2015, Kovalev et al., 2020]. Loizou et al. [2020] studied stochastic Hamiltonian gradient descent (SHGD), and propose the ﬁrst stochastic variance reduced Hamiltonian method, named L-SVRHG, for solving stochastic bilinear games and and stochastic games satisfying a “suﬃciently bilinear” condition. Moreover, Loizou et al. [2020] provided the ﬁrst set of global non-asymptotic last-iterate convergence guarantees for a stochastic game over a non-compact domain, in the absence of strong monotonicity assumptions.
Communication compression for VIPs. While distributed methods with compression were extensively studied for solving minimization problems both for unbiased compression operators [Alistarh et al., 2017, Wen et al., 2017, Mishchenko et al., 2019, Horv´ath et al., 2019, Li et al., 2020, Khaled et al., 2020, Gorbunov et al., 2021b] and biased compression operators [Seide et al., 2014, Stich et al., 2018, Karimireddy et al., 2019, Beznosikov et al., 2020a, Gorbunov et al., 2020b, Qian et al., 2021b, Richt´arik et al., 2021], much less is known for min-max problems and VIPs. To the best of our knowledge, the ﬁrst work on distributed methods with compression for min-max problems is Yuan et al. [2014], where the authors proposed a distributed version of Dual Averaging [Nesterov, 2009] with rounding and showed a convergence to the neighborhood of the solution that cannot be reduced via standard tricks like increasing the batchsize or decreasing the stepsize. More recently, Beznosikov et al. [2021b] proposed new distributed
2For example, see inequality (60) from Appendix H in the case when there is no regularization term, i.e., when R(x) ≡ 0 and, as a result, F (x∗) = 0 for all x∗ ∈ X∗.
4

variants of EG with unbiased/biased compression for solving (1) with (strongly) monotone and Lipschitz operator F . Beznosikov et al. [2021b] obtained the ﬁrst linear convergence guarantees on distributed VIPs with compressed communication.

2 Uniﬁed Analysis of SGDA
In this section, we describe our theoretical framework.

2.1 Key Assumption
We start by introducing the following parametric assumption, which is a central part of our approach.

Assumption 2.1. We assume that for all k ≥ 0 the estimator gk from (5) is unbiased: Ek gk = F (xk), where Ek[·] denotes the expectation w.r.t. the randomness at iteration k. Next, we assume that there exist non-negative constants A, B, C, D1, D1 ≥ 0, ρ ∈ (0, 1] and a sequence of (possibly random) non-negative variables {σk}k≥0 such that for all k ≥ 0

Ek gk − g∗,k 2 ≤ 2A F (xk) − g∗,k, xk − x∗,k + Bσk2 + D1,

(6)

Ek σk2+1 ≤ 2C F (xk) − g∗,k, xk − x∗,k + (1 − ρ)σk2 + D2,

(7)

where x∗,k = projX∗ (xk) and g∗,k = F (x∗,k).

While unbiasedness of gk is a standard assumption, inequalitites (6)-(7) are new and require clariﬁcations. For simplicity, assume that σk2 ≡ 0, F (x∗) = 0 for all x∗ ∈ X∗, and focus on (6). In this case, (6) gives an upper bound for the second moment of the stochastic estimate gk. For example, such a bound follows from expected cocoercivity assumption [Loizou et al.,
2021], where A denotes some expected/averaged (star-)cocoercivity constant and D1 stands for the variance at the solution (see also Section 3). When F is not necessary zero on X∗, the shift g∗,k helps to take this fact into account. Finally, the sequence {σk2}k≥0 is typically needed to capture the variance reduction process, parameter B is typically some numerical constant,
C is another constant related to (star-)cocoercivity, and D2 is the remaining noise that is not handled by variance reduction process. As we show in the next sections, inequalitites (6)-(7)
hold for various SGDA-type methods.
We point out that Assumption 2.1 is inspired by similar assumptions appeared in Gorbunov
et al. [2020a, 2021a]. However, the diﬀerence between our assumption and the ones appeared
in these papers is signiﬁcant: Gorbunov et al. [2020a] focuses only on solving minimization
problems and as a result, their assumption includes a much simpler quantity (function suboptimality), instead of the F (xk) − g∗,k, xk − x∗,k , in the right-hand sides of (6)-(7). The
assumption proposed in Gorbunov et al. [2021a] is closer to ours, but it is designed speciﬁcally for analyzing Stochastic EG, it does not have {σk2}k≥0 sequence, and works only for (1) with R(x) ≡ 0.

2.2 Quasi-Strongly Monotone Case
Under Assumption 2.1 and quasi-strong monotonicity of F , we derive the following general result.

5

Theorem 2.2. Let F be µ-quasi-strongly monotone with µ > 0 and let Assumption 2.1 hold. Assume that 0 < γ ≤ min {1/µ, 1/2(A+CM)} for somea M > B/ρ. Then the iterates of SGDA,
given by (5), satisfy:

Bk

γ2(D1 + M D2)

E[Vk] ≤ 1 − min γµ, ρ − M

V0

+

min

{γµ,

ρ

−

. B/M }

(8)

where the Lyapunov function Vk is deﬁned by Vk = xk − x∗,k 2 + M γ2σk2 for all k ≥ 0.
aWhen B = 0, we suppose M = 0 and B/M := 0 in all following expressions.

The above theorem states that SGDA (5) converges linearly to the neighborhood of the solution. The size of the neighborhood is proportional to the noises D1 and D2. When D1 = D2 = 0, i.e., the method is variance reduced, it converges linearly to the exact solution in expectation. However, in general, to achieve any predeﬁned accuracy, one needs to reduce the size of the neighborhood somehow. One possible way to that is use a proper stepsize schedule. We formalize this discussion in the following result.

Corollary 2.3. Let the assumptions of Theorem 2.2 hold. Consider two possible cases.

1. Let D1 = D2 = 0. Then, for any K ≥ 0, M = 2B/ρ, and γ = min {1/µ, 1/2(A+2BC/ρ)}, the iterates of SGDA, given by (5), satisfy:

µ

ρ

E[VK ] ≤ V0 exp − min 2(A + 2BC/ρ) , 2 K .

2. Let D1 + M D2 > 0. Then, for any K ≥ 0 and M = 2B/ρ one can choose {γk}k≥0 as follows:

if K ≤ h , µ

γk = 1 , h

if K > h and k < k0, γk = 1 , (9)

µ

h

if K > h and k ≥ k0, µ

2

γk

=

µ(κ

+

k

−

, k0)

where h = max {2(A + 2BC/ρ), 2µ/ρ}, κ = 2h/µ and k0 = K/2 . For this choice of γk, the iterates of SGDA, given by (5), satisfy:

E[VK ] ≤ 32hV0 exp

µ −K

+ 36(D1 + 2BD2/ρ) .

µ

h

µ2K

2.3 Monotone Case
When µ = 0, we additionally assume that F is monotone. Similar to minimization, in the case of µ = 0, the squared distance to the solution is not a valid measure of convergence. To introduce an appropriate convergence measure, we make the following assumption.
Assumption 2.4. There exists a compact convex set C (with the diameter ΩC := maxx,y∈C x− y ) such that X∗ ⊂ C.
In this settings, we focus on the following quantity called a restricted gap-function [Nesterov,

6

2007] deﬁned for any z ∈ Rd and any C ⊂ Rd satisfying Assumption 2.4:

GapC(z) := max [ F (u), z − u + R(z) − R(u)] .

(10)

u∈C

Assumption 2.4 and function GapC(z) are standard for the convergence analysis of methods for solving (1) with monotone F [Nesterov, 2007, Alacaoglu and Malitsky, 2021]. Additional discussion is left to Appendix D.2.
Under these assumptions, Assumption 2.1, and star-cocoercivity of F we derive the following general result.

Theorem 2.5. Let F be monotone, -star-cocoercive and let Assumptions 2.1, 2.4 hold. Assume that 0 < γ ≤ 1/2(A+BC/ρ). Then for all K ≥ 0 the iterates of SGDA, given by (5), satisfy:

E GapC

1 K xk K
k=1

3 maxu∈C x0 − u 2 ≤ 2γK

+ 8γ 2Ω2C + (4A + + 8BC/ρ) · x0 − x∗,0 2

K

K

+ (4 + (4A + + 8BC/ρ) γ) γBσ02 ρK

+γ(2 + γ (4A + + 8BC/ρ))(D1 + 2BD2/ρ)

+9γ max F (x∗) 2,

(11)

x∗ ∈X ∗

where GapC() is the restricted gap-function from (10).

The above result establishes O(1/K) rate of convergence to the accuracy proportional to the stepsize γ multiplied by the noise term D1 + 2BD2/ρ and maxx∗∈X∗ F (x∗) 2. We notice that if R ≡ 0 in (1), then F (x∗) = 0, meaning that in this case, the last term from (11) equals
zero. Otherwise, even in the deterministic case one needs to use small stepsizes to ensure the
convergence to any predeﬁned accuracy (see Corollary D.4 in Appendix D.2).

3 SGDA with Arbitrary Sampling

We start our consideration of special cases with a standard SGDA (5) with gk = Fξk (xk), ξk ∼ D under so-called expected cocoercivity assumption from Loizou et al. [2021], which we properly
adjust to the setting of regularized VIPs.

Assumption 3.1 (Expected Cocoercivity). We assume that stochastic operator Fξ(x), ξ ∼ D is such that for all x ∈ Rd

ED Fξ(x) − Fξ(x∗) 2 ≤ D F (x) − F (x∗), x − x∗ ,

(12)

where x∗ = projX∗(x).

When R(x) ≡ 0, this assumption recovers the original one from Loizou et al. [2021]. We also emphasize that for operator F Assumption 3.1 implies only star-cocoercivity.
Following Loizou et al. [2021], we mainly focus on ﬁnite-sum case and its stochastic reformulation: we consider a random sampling vector ξ = (ξ1, . . . , ξn) ∈ Rn having a distribution

7

D

such

that

ED [ξi ]

=

1

for

all

i

∈

[n].

Using

this

we

can

rewrite

F (x)

=

1 n

n i=1

Fi(x)

as

1n F (x) = n ED[ξiFi(x)] = ED [Fξ(x)] , (13)
i=1

where

Fξ (x)

=

1 n

n i=1

ξi

Fi

(x).

Such

a

reformulation

allows

to

handle

a

wide

range

of

samplings:

the only assumption on D is ED[ξi] = 1 for all i ∈ [n]. Therefore, this setup is often referred to

as arbitrary sampling [Richt´arik and Tak´ac, 2020, Loizou and Richt´arik, 2020a,b, Gower et al.,

2019, 2021, Hanzely and Richt´arik, 2019, Qian et al., 2019, 2021a]. We elaborate on several

special cases in Appendix E.4.

In this setting, SGDA with Arbitrary Sampling (SGDA-AS)3 ﬁts our framework.

Proposition 3.2. Let Assumption 3.1 hold. Then, SGDA-AS satisﬁes Assumption 2.1 with
A = D, D1 = 2σ∗2 := 2 maxx∗∈X∗ ED Fξ(x∗) − F (x∗) 2 , B = 0, σk2 ≡ 0, C = 0, ρ = 1, D2 = 0.

Plugging these parameters to Theorem 2.2 we recover the result4 from Loizou et al. [2021] when R(x) ≡ 0 and generalize it to the case of R(x) ≡ 0 without sacriﬁcing the rate. Applying Corollary 2.3, we establish the rate of convergence to the exact solution.

Corollary 3.3. Let F be µ-quasi-strongly monotone and Assumption 3.1 hold. Then for all K > 0 there exists a choice of γ (see (47)) for which the iterates of SGDA-AS, satisfy:

E[ xK − x∗,K 2] = O where Ω20 = x0 − x∗,0 2.

DΩ20 exp

µ −K

+ σ∗2

,

µ

D

µ2K

For the diﬀerent stepsize schedule, Loizou et al. [2021] derive the convergence rate O(1/K + 1/K2) which is inferior to our rate, especially when σ∗2 is small. In addition, Loizou et al. [2021] consider explicitly only uniform minibatch sampling without replacement as a special case of arbitrary
sampling. In Appendix E.4, we discuss another prominent sampling strategy called importance
sampling. In Section 6, we provide numerical experiments verifying our theoretical ﬁndings and
showing the beneﬁts of importance sampling over uniform sampling for SGDA.

4 SGDA with Variance Reduction

In this section, we focus on variance reduced variants of SGDA for solving ﬁnite-sum prob-

lems

F (x)

=

1 n

n i=1

Fi

(x).

We

start

with

the

Loopless

Stochastic

Variance

Reduced

Gradient

Descent-Ascent (L-SVRGDA), which is a generalization of the L-SVRG algorithm proposed in

Hofmann et al. [2015], Kovalev et al. [2020]. L-SVRGDA (see Alg. 2) follows the update rule (5)

with

gk = Fjk (xk) − Fjk (wk) + F (wk), (14)

wk+1 = xk, with prob. p,

(15)

wk, with prob. 1 − p,

3For the pseudo-code of SGDA-AS see Algorithm 1 in Appendix E. 4In the main part of the paper, we focus on µ-quasi strongly monotone case with µ > 0. For simplicity, we provide here the rates of convergence to the exact solution. Further details, including the rates in monotone case, are left to the Appendix.

8

where in kth iteration jk is sampled uniformly at random from [n]. Here full operator F is computed once wk is updated, which happens with probability p. Typically, p is chosen as p ∼ 1/n ensuring that the expected cost of 1 iteration equals O(1) oracle calls, i.e., computations of Fi(x) for some i ∈ [n].
We introduce the following assumption about operators Fi.
Assumption 4.1 (Averaged Star-Cocoercivity). We assume that there exists a constant > 0 such that for all x ∈ Rd
1 n Fi(x) − Fi(x∗) 2 ≤ F (x) − F (x∗), x − x∗ , (16) n
i=1
where x∗ = projX∗(x).

For example, if Fi is i-cocoercive for i ∈ [n], then (16) holds with ≤ maxi∈[n] i. Next, if

Fi is Li-Lipschitz for all i ∈ [n] and F is µ-quasi strongly monotone, then (16) is satisﬁed for

∈ [L, L2/µ], where L2 = n1

n i=1

L2i .

Moreover, for the analysis of variance reduced variants of SGDA we also use uniqueness of

the solution.

Assumption 4.2 (Unique Solution). We assume that the solution set X∗ of problem (1) is a singleton: X∗ = {x∗}.

These assumptions are suﬃcient to derive validity of Assumption 2.1 for L-SVRGDA estimator.

Proposition 4.3. Let Assumptions 4.1 and 4.2 hold. Then, L-SVRGDA satisﬁes Assump-

tion 2.1 with A =

,

B

=

2,

σk2

=

1 n

n i=1

Fi(wk) − Fi(x∗) 2, C = p /2, ρ = p, D1 = D2 = 0.

Plugging these parameters in our general results on the convergence of SGDA-type algorithms we derive the convergence results for L-SVRGDA, see Table 1 and Appendix F.1 for the details. Moreover, in Appendix F.2, we show that SAGA-SGDA [Palaniappan and Bach, 2016] ﬁts our framework and using our general analysis we tighten the convergence rates for this method.
We compare our convergence guarantees with known results in Table 1. We note that by neglecting importance sampling scenario, in the worst case, our convergence results match the best-known results for SGDA-type methods, i.e., ones derived in Palaniappan and Bach [2016]. Indeed, this follows from ∈ [L, L2/µ]. Next, when the diﬀerence between and is not signiﬁcant, our complexity results match the one derived in Chavdarova et al. [2019] for SVRE, which is EG-type method. Although in general, might be smaller than , our analysis does not require cocoercivity of each Fi and it works for R(x) ≡ 0. Finally, Alacaoglu and Malitsky [2021] derive a better rate (when n = O(L2/µ2)), but their method is based on EG. Therefore, our results match the best-known ones in the literature on SGDA-type methods.

5 Distributed SGDA with Compression

In

this

section,

we

consider

the

distributed

version

of

(1),

i.e.,

we

assume

that

F (x)

=

1 n

n i=1

Fi

(x),

where {Fi}ni=1 are distributed across n devices connected with parameter-server in a centralized

fashion. Each device i has an access to the computation of the unbiased estimate of Fi at the

given point. Typically, in these settings, the communication is a bottleneck, especially when n

9

Table 1: Summary of the complexity results for variance reduced methods for solving (1). By complexity

we mean the number of oracle calls required for the method to ﬁnd x such that E[ x − x∗ 2] ≤ ε.

Dependencies on numerical and logarithmic factors are hidden. By default, operator F is assumed

to be µ-strongly monotone and, as the result, the solution is unique. Our results rely on µ-quasi

strong monotonicity of F (3), but we also assume uniqueness of the solution. Methods supporting

R(x) ≡ 0 are highlighted with ∗. Our results are highlighted in green. Notation: , L = averaged

cocoercivity/Lipschitz constants depending on the sampling strategy, e.g., for uniform sampling 2 =

1 n

n i=1

2i ,

L2

=

1 n

n i=1

L2i

and

for

importance

sampling

= n1

star-cocoercivity constant from Assumption 4.1.

n i=1

i,

L

=

1 n

n i=1

Li;

= averaged

Method

Citation

Assumptions

Complexity

SVRE (1) EG-VR ∗(1)

[Chavdarova et al., 2019] [Alacaoglu and Malitsky, 2021]

Fi is i-cocoer. Fi is Li-Lip.

n+ µ

n

+

√ n

L

µ

SVRGDA ∗ SAGA-SGDA ∗
VR-AGDA

[Palaniappan and Bach, 2016] [Palaniappan and Bach, 2016]
[Yang et al., 2020]

Fi is Li-Lip. Fi is Li-Lip. Fi is Lmax-Lip.(2) min

n + Lµ22

n + Lµ22

n + , n L9max
µ9

2/3 L3max µ3

L-SVRGDA ∗

This paper

As. 4.1

n+ µ

SAGA-SGDA ∗

This paper

As. 4.1

n+ µ

(1) The method is based on Extragradient update rule. (2) Yang et al. [2020] consider saddle point problems satisfying so-called two-sided PL condition,

which is weaker than strong-convexity-strong-concavity of the objective function.

and d are huge. This means that in the naive distributed implementations of SGDA, communication rounds take much more time than local computations on the clients. Various approaches are used to circumvent this issue.
One of them is based on the usage of compressed communications. We focus on the unbiased compression operators.

Deﬁnition 5.1. Operator Q : Rd → Rd (possibly randomized) is called unbiased compressor/quantization if there exists a constant ω ≥ 1 such that for all x ∈ Rd

E[Q(x)] = x, E[ Q(x) − x 2] ≤ ω x 2.

(17)

In this paper, we consider compressed communications in the direction from clients to the

server. The simplest method with compression – QSGDA (Alg. 4) – can be described as SGDA

(5)

with

gk

=

1 n

tion5.

n i=1

Q(gik

).

Here

gik

are

stochastic

estimators

satisfying

the

following

assump-

Assumption 5.2 (Bounded variance). All stochastic realizations gik are unbiased and have bounded variance, i.e., for all i ∈ [n] and k ≥ 0 the following holds:

E[gik] = Fi(xk), E[ gik − Fi(xk) 2] ≤ σi2.

(18)

Despite its simplicity, QSGDA was never considered in the literature on solving min-max problems and VIPs. It turns out that under such assumptions QSGDA satisﬁes our Assumption 2.1.
5We use this assumption for illustrating the ﬂexibility of the framework. It is possible to consider Arbitrary Sampling setup as well.

10

Proposition 5.3. Let F be -star-cocoercive and Assumptions 4.1, 5.2 hold. Then, QSGDA

satisﬁes

Assumption

2.1

with

A

=

3 2

+

9ω 2n

,

B

=

0,

σk2

≡

0,

D1

=

3(1+3ω)nσ2+9ωζ∗2 ,

C

=

0,

ρ

=

1,

D2

=

0,

where

σ2

=

1 n

n i=1

σi2,

ζ∗2

:=

1 n

maxx∗∈X ∗

n i=1

Fi(x∗) 2.

As for the other special cases, we derive the convergence results for QSGDA using our general
theorems (see Table 2 and Appendix G.1 for the details). The proposed method is simple, but
have a signiﬁcant drawback: even in the deterministic case (σ = 0), QSGDA does not converge linearly unless ζ∗2 = 0. However, when the data on clients is arbitrary heterogeneous the dissimilarity measure ζ∗2 is strictly positive and can be large (even when R(x) ≡ 0).
To resolve this issue, we propose a more advanced scheme based on DIANA update [Mishchenko
et al., 2019, Horv´ath et al., 2019] – DIANA-SGDA (Alg. 5). In a nutshell, DIANA-SGDA is SGDA (5) with gk deﬁned as follows:

∆ki = gik − hki , hki +1 = hki + αQ(∆ki ),

k k 1n

k

g = h + n Q(∆i ),

i=1

k+1 1 n k+1

k

1n

k

h = n hi = h + α n Q(∆i ),

i=1

i=1

(19) (20) (21)

where the ﬁrst two lines correspond to the local computations on the clients and the last two lines – to the server-side computations. Taking into account the update rule for hk+1, one can notice that DIANA-SGDA requires workers to send only vectors Q(∆ki ) to the server at step k, i.e., the method uses only compressed workers-server communications.
As we show next, DIANA-SGDA ﬁts our framework.

Proposition 5.4. Let Assumptions 4.1, 4.2, 5.2 hold. Suppose that α ≤ 1/(1+ω). Then,

DIANA-SGDA

with

quantization

(17)

satisﬁes

Assumption

2.1

with

σk2

=

1 n

n i=1

hki −Fi(x∗) 2

and A =

1 2

+

ω n

, B = 2nω , D1 = (1+nω)σ2 , C = α2 , ρ = α, D2 = ασ2, , where σ2 = n1

n i=1

σi2.

DIANA-SGDA can be considered as a variance-reduced method, since it reduces the term

proportional to ωζ∗2 that the bound for QSGDA contains (see Table 2 and Appendix G.2 for

the details). As the result, when σ = 0, i.e., workers compute Fi(x) at each step, DIANA-SGDA

enjoys linear convergence to the exact solution.

Next,

when

local

operators

Fi

have

a

ﬁnite-sum

form

Fi(x)

=

1 m

m j=1

Fij

(x),

one

can

combine L-SVRGDA and DIANA-SGDA as follows: consider the scheme from (19)-(21) with

gik = Fijk (xk) − Fijk (wk) + F (wik),

(22)

wk+1 = xk, with prob. p,

(23)

i

wik, with prob. 1 − p,

where jk is sampled uniformly at random from [n]. We call the resulting method VR-DIANASGDA (Alg. 6) and we note that its analog for solving minimization problems (VR-DIANA) was proposed and analyzed in Horv´ath et al. [2019].
To cast VR-DIANA-SGDA as special case of our general framework, we need to make the following assumption.

11

Table 2: Summary of the complexity results for distributed methods with unbiased compression for

solving distributed (1) with F = n1

n i=1

Fi

(x).

By

complexity

we

mean

the

number

of

communication

rounds required for the method to ﬁnd x such that E[ x − x∗ 2] ≤ ε. Dependencies on numerical and

logarithmic factors are hidden. Dependencies on numerical and logarithmic factors are hidden. E stands

for

the

setup,

when

Fi(x)

=

Eξi [Fξi (x)];

Σ

denotes

the

case,

when

Fi(x)

=

1 m

m j=1

Fij

(x).

By

default,

operator F is assumed to be µ-strongly monotone and, as the result, the solution is unique. Our

results rely on µ-quasi strong monotonicity of F (3), but we also assume uniqueness of the solution.

Methods supporting R(x) ≡ 0 are highlighted with ∗. Our results are highlighted in green. Notation:

σ2 = n1

n i=1

σi2

–

averaged

upper

bound

for

the

variance

(see

Assumption

5.2

for

the

deﬁnition

of

σi2);

ω

=

quantization

parameter

(see

Deﬁnition

5.1);

ζ∗2

=

1 n

maxx∗∈X∗

n i=1

Fi(x∗) 2; Lmax = maxi∈[n] Li;

= averaged star-cocoercivity constant from Assumption 5.5.

Setup

Method

Citation

Assumptions

Complexity

QSGDA ∗ E DIANA-SGDA ∗

This paper This paper

As. 4.1, 5.2 As. 4.1, 5.2

µ + nωµ + (1+ωn)µσ22ε+ωζ∗2 ω + µ + nωµ + (1n+µω2)εσ2

MASHA1 ∗(1)

[Beznosikov et al., 2021b]

Fi is Li-Avg. Lip.(2)

Lmax
m+ω+

(m+ω

)(1+

ω n

)

µ

Σ VR-DIANA-SGDA ∗

This paper

As. 4.1, 5.5

m + ω + µ + (1+ωn)µ( + ) + (1+ω) mnmaxµ{m,ω}

(1) The method is based on Extragradient update rule. (2) This means that for all x, y ∈ Rd and i ∈ [n] the following inequality holds: m1 Fij (y) 2 ≤ L2i x − y 2.

m j=1

Fij(x) −

Assumption 5.5. We assume that there exists a constant > 0 such that for all x ∈ Rd 1 n m Fij(x) − Fij(x∗) 2 ≤ F (x) − F (x∗), x − x∗ , (24) nm
i=1 j=1
where x∗ = projX∗(x).

Using Assumption 5.5 in combination with previously introduced conditions, we get the following result.

Proposition 5.6. Let F be -star-cocoercive and Assumptions 4.1, 4.2, 5.5 hold. Suppose that α ≤ min p3 , 1+1ω . Then, VR-DIANA-SGDA satisﬁes Assumption 2.1 with A = 2 +

n

+

ω( n+ ) ,

B

=

2(ωn+1) , σk2

=

1 n

n i=1

hki − Fi(x∗)

2+

1 nm

n i=1

m j=1

Fij(wik) − Fij(x∗) 2,

C

=

pl 2

+

α(

+

), ρ = α, D1 = D2 = 0.

Since D1 = D2 = 0, our general results imply linear convergence of VR-DIANA-SGDA when µ > 0 (see the details in Appendix G.3). That is, VR-DIANA-SGDA is the ﬁrst linearly converging distributed SGDA-type method with compression. We compare it with MASHA1 [Beznosikov et al., 2021b] in Table 2. Firstly, let us note that MASHA1 is a method based on EG, and its convergence guarantees depend on the Lipschitz constants. In addition, we note that the complexity of MASHA1 could be better than the one of VR-DIANA-SGDA when cocoercivity constants are large compared to Lipschitz ones. However, our compleixty bound has better dependency on quantization parameter ω, number of clients n, and the size of the local dataset m. These parameters can be large meaning that the improvement is noticeable.
12

6 Numerical Experiments
To illustrate our theoretical results, we conduct several numerical experiments on quadratic games, which are deﬁned through the aﬃne operator:
1n F (x) = n Aix + bi, (25)
i=1
where each matrix Ai ∈ Rd×d is non-symmetric with all eigenvalues having strictly positive real part. Enforcing all the eigenvalues to have strictly positive real part ensures that the operator is strongly monotone and cocoercive. We consider two diﬀerent settings: (i) problem without constraints, and (ii) problem that has 1 regularization and constraints forcing the solution to lie in the ∞-ball of radius r. In all experiments, we use a constant step-size for all methods which was selected manually using a grid-search and picking the best performing step-size for each methods. For further details about the experiments see Appendix B.

Uniform sampling (US) vs Important sampling (IS). We note that Loizou et al. [2021] which studies SGDA-AS does not consider IS explicitly. Although we show the theoretical beneﬁts of IS in comparison to US in Appendix E.4, here we provide a numerical comparison to illustrate the superiority of IS (on both constrained and unconstrained quadratic games). We choose the matrices Ai such that max = maxi i ¯. In this case, our theory predicts that IS should perform better than US. We provide the results in Fig. 1. We observe that indeed SGDA with IS converges faster and to a smaller neighborhood than SGDA with US. This observation perfectly corroborates our theory.

Distance to optimality Distance to optimality

104 103 102 101 100 10−1 10−2 10−3
0

SGDA with IS

SGDA

100

SGDA with IS SGDA

10−1

10−2

10−3

50

100

150

200

250

300

Number of oracles call

0

25

50

75

100

125

150

175

200

Number of oracles call

Figure 1: Uniform sampling (US) vs Importance sampling (IS). Left: Without constraint. Right: With constraints. As expected by theory IS converges faster and to a smaller neighborhood than US.

Comparison of variance reduced methods. In this experiment, we test the performance

of our proposed L-SVRGDA (Alg. 2) and compare it to other variance reduced methods on

quadratic games, see Fig. 2. In particular, we compare it to SVRG [Palaniappan and Bach,

2016], SVRE [Chavdarova et al., 2019], EG-VR [Alacaoglu and Malitsky, 2021] and VR-AGDA

[Yang et al., 2020]. In the constrained setting, we only compare L-SVRGDA to SVRG and

EG-VR, since they are the only methods from this list that handle constrained settings. For

loopless

variants

we

choose

p

=

1 n

and

for

the

non-loopless

variants

we

pick

the

number

of

inner-

loop iteration to be n. We observe that all methods converge linearly and that L-SVRGDA is

competitive with the other considered variance-reduced methods, converging slightly faster than

all of them.

13

Distance to optimality Distance to optimality

100 10−2 10−4 10−6
0

L-SVRGDA SVRG EG-VR VR-AGDA SVRE

2000

4000

6000

8000

Number of oracles call

10000

10−1 10−3 10−5 10−7
0

L-SVRGDA SVRG EG-VR

2000

4000

6000

8000

Number of oracles call

10000

Figure 2: Comparison of variance reduced methods Left: Without constraints. Right: With constraints. We observe that L-SVRGDA is very competitive, and outperforms all the other methods.

Distributed setting. In our last experiment, we consider a distributed version of the quadratic

game,

in

which

we

assume

that

F (x)

=

1 n

n i=1

Fi(x)

with

each

{Fi}ni=1

having

similar

form

to

(25). The information about operator Fi is stored on node i only. We compare the distributed

methods proposed in the paper: QSGDA, DIANA-SGDA, and VR-DIANA-SGDA. For the quan-

tization we use the RandK sparsiﬁcation [Beznosikov et al., 2020a] with K = 5. We show our

ﬁndings in Fig.3, where the performance is measured both in terms of number of oracle calls

and the number of bits communicated from workers to the server. In Fig.3 we can clearly see

the advantage of using quantization in terms of reducing the communication cost compared to

the baseline SGDA. We also observe that VR-DIANA-SGDA achieves linear convergence to the

solution. However, DIANA-SGDA performs similarly to QSGDA since the noise σ2 is larger than

the dissimilarity constant ζ∗2. To illustrate further the diﬀerence between DIANA-SGDA and

QSGDA, we conduct additional experiments with full-batched methods (σ = 0) in Appendix B.

Distance to optimality Distance to optimality

100 100
10−2

10−1

10−4

10−2

10−6

10−3

SGDA QSGDA

10−8

SGDA QSGDA

10−4

DIANA-SGDA VR-DIANA-SGDA

10−10

DIANA-SGDA VR-DIANA-SGDA

10−5 0

5000 10000 15000 20000 25000 30000

103

104

105

106

107

108

Number of oracles call

Number of bits communicated

Figure 3: Comparison of algorithms in distributed setting Left: Number of oracle calls. Right: Number of bits communicated.

7 Conclusion and Future Work
This paper develops a uniﬁed approach to analyzing and designing a wide class of SGDA-type methods for regularized VIPs (1). In our work, we focus on analyzing such methods for solving star-cocoercive quasi-strongly monotone and monotone problems. We believe that our work could open up many avenues for further development and research. For example, it would be interesting to extend our uniﬁed approach to problems that are neither quasi-strongly monotone nor monotone. We conjecture that similar ideas to the ones presented in this work can be used
14

for analyzing methods that do not ﬁt scheme (5), e.g., Stochastic Extragradient and Stochastic Optimistic Gradient.
References
A. Alacaoglu and Y. Malitsky. Stochastic variance reduction for variational inequality methods. arXiv preprint arXiv:2102.08352, 2021.
A. Alacaoglu, Y. Malitsky, and V. Cevher. Forward-reﬂected-backward method with variance reduction. Computational optimization and applications, 80(2):321–346, 2021.
D. Alistarh, D. Grubic, J. Li, R. Tomioka, and M. Vojnovic. Qsgd: Communication-eﬃcient sgd via gradient quantization and encoding. Advances in Neural Information Processing Systems, 30:1709– 1720, 2017.
W. Azizian, F. Iutzeler, J. Malick, and P. Mertikopoulos. The last-iterate convergence rate of optimistic mirror descent in stochastic variational inequalities. In Conference on Learning Theory, pages 326–358. PMLR, 2021.
F. Bach. The “η-trick” or the eﬀectiveness of reweighted least-squares, 2019.
H. H. Bauschke, P. L. Combettes, et al. Convex analysis and monotone operator theory in Hilbert spaces, volume 408. Springer, 2011.
A. Beck. First-order methods in optimization. Society for Industrial and Applied Mathematics (SIAM), 2017.
A. Beznosikov, S. Horv´ath, P. Richt´arik, and M. Safaryan. On biased compression for distributed learning. arXiv preprint arXiv:2002.12410, 2020a.
A. Beznosikov, A. Sadiev, and A. Gasnikov. Gradient-free methods with inexact oracle for convexconcave stochastic saddle-point problem. In International Conference on Mathematical Optimization Theory and Operations Research, pages 105–119. Springer, 2020b.
A. Beznosikov, V. Samokhin, and A. Gasnikov. Distributed saddle-point problems: Lower bounds, optimal algorithms and federated gans. arXiv preprint arXiv:2010.13112, 2020c.
A. Beznosikov, V. Novitskii, and A. Gasnikov. One-point gradient-free methods for smooth and nonsmooth saddle-point problems. In International Conference on Mathematical Optimization Theory and Operations Research, pages 144–158. Springer, 2021a.
A. Beznosikov, P. Richt´arik, M. Diskin, M. Ryabinin, and A. Gasnikov. Distributed methods with compressed communication for solving variational inequalities, with theoretical guarantees. arXiv preprint arXiv:2110.03313, 2021b.
E. J. Candes, M. B. Wakin, and S. P. Boyd. Enhancing sparsity by reweighted 1 minimization. Journal of Fourier analysis and applications, 14(5):877–905, 2008.
Y. Carmon, Y. Jin, A. Sidford, and K. Tian. Variance reduction for matrix games. Advances in Neural Information Processing Systems, 32, 2019.
N. Cesa-Bianchi and G. Lugosi. Prediction, learning, and games. Cambridge university press, 2006.
T. Chavdarova, G. Gidel, F. Fleuret, and S. Lacoste-Julien. Reducing noise in GAN training with variance reduced extragradient. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch´e-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019.
C. Daskalakis, S. Skoulakis, and M. Zampetakis. The complexity of constrained min-max optimization. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing, pages 1466–1478, 2021.
15

D. Davis and W. Yin. A three-operator splitting scheme and its optimization applications. Set-valued and variational analysis, 25(4):829–858, 2017.
A. Defazio, F. Bach, and S. Lacoste-Julien. SAGA: A fast incremental gradient method with support for non-strongly convex composite objectives. Advances in neural information processing systems, 27, 2014.
V. F. Dem’yanov and A. B. Pevnyi. Numerical methods for ﬁnding saddle points. USSR Computational Mathematics and Mathematical Physics, 12(5):11–52, 1972.
J. Diakonikolas, C. Daskalakis, and M. Jordan. Eﬃcient methods for structured nonconvex-nonconcave min-max optimization. In International Conference on Artiﬁcial Intelligence and Statistics, pages 2746–2754. PMLR, 2021.
G. Gidel, H. Berard, G. Vignoud, P. Vincent, and S. Lacoste-Julien. A variational inequality perspective on generative adversarial networks. In International Conference on Learning Representations (ICLR), 2019.
I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems, volume 27. Curran Associates, Inc., 2014.
E. Gorbunov, F. Hanzely, and P. Richtarik. A Uniﬁed Theory of SGD: Variance Reduction, Sampling, Quantization and Coordinate Descent. In S. Chiappa and R. Calandra, editors, Proceedings of the Twenty Third International Conference on Artiﬁcial Intelligence and Statistics, volume 108 of Proceedings of Machine Learning Research, pages 680–690. PMLR, 26–28 Aug 2020a.
E. Gorbunov, D. Kovalev, D. Makarenko, and P. Richtarik. Linearly converging error compensated sgd. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages 20889–20900. Curran Associates, Inc., 2020b. URL https: //proceedings.neurips.cc/paper/2020/file/ef9280fbc5317f17d480e4d4f61b3751-Paper.pdf.
E. Gorbunov, H. Berard, G. Gidel, and N. Loizou. Stochastic extragradient: General analysis and improved rates. arXiv preprint arXiv:2111.08611, 2021a.
E. Gorbunov, K. P. Burlachenko, Z. Li, and P. Richtarik. MARINA: Faster non-convex distributed learning with compression. In M. Meila and T. Zhang, editors, Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 3788–3798. PMLR, 18–24 Jul 2021b. URL https://proceedings.mlr.press/v139/gorbunov21a. html.
E. Gorbunov, N. Loizou, and G. Gidel. Extragradient method: O(1/K) last-iterate convergence for monotone variational inequalities and connections with cocoercivity. arXiv preprint arXiv:2110.04261, 2021c.
R. Gower, O. Sebbouh, and N. Loizou. Sgd for structured nonconvex functions: Learning rates, minibatching and interpolation. In International Conference on Artiﬁcial Intelligence and Statistics, pages 1315–1323. PMLR, 2021.
R. M. Gower, N. Loizou, X. Qian, A. Sailanbayev, E. Shulgin, and P. Richt´arik. SGD: General Analysis and Improved Rates. In Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pages 5200–5209, 2019.
Y. Han, G. Xie, and Z. Zhang. Lower complexity bounds of ﬁnite-sum optimization problems: The results and construction. arXiv preprint arXiv:2103.08280, 2021.
F. Hanzely and P. Richt´arik. Accelerated coordinate descent with arbitrary sampling and best rates for minibatches. In The 22nd International Conference on Artiﬁcial Intelligence and Statistics, pages 304–312. PMLR, 2019.
16

F. Hanzely, K. Mishchenko, and P. Richt´arik. SEGA: Variance reduction via gradient sketching. Advances in Neural Information Processing Systems, 31, 2018.
T. Hofmann, A. Lucchi, S. Lacoste-Julien, and B. McWilliams. Variance reduced stochastic gradient descent with neighbors. Advances in Neural Information Processing Systems, 28, 2015.
S. Horv´ath, D. Kovalev, K. Mishchenko, S. Stich, and P. Richt´arik. Stochastic distributed learning with gradient quantization and variance reduction. arXiv preprint arXiv:1904.05115, 2019.
Y.-G. Hsieh, F. Iutzeler, J. Malick, and P. Mertikopoulos. On the convergence of single-call stochastic extra-gradient methods. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch´e-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019.
Y.-G. Hsieh, F. Iutzeler, J. Malick, and P. Mertikopoulos. Explore aggressively, update conservatively: Stochastic extragradient methods with variable stepsize scaling. Advances in Neural Information Processing Systems, 33, 2020.
R. Johnson and T. Zhang. Accelerating stochastic gradient descent using predictive variance reduction. Advances in Neural Information Processing Systems, 26, 2013.
A. Juditsky, A. Nemirovski, and C. Tauvel. Solving variational inequalities with stochastic mirror-prox algorithm. Stochastic Systems, 1(1):17–58, 2011.
S. P. Karimireddy, Q. Rebjock, S. Stich, and M. Jaggi. Error feedback ﬁxes signsgd and other gradient compression schemes. In International Conference on Machine Learning, pages 3252–3261. PMLR, 2019.
A. Khaled, O. Sebbouh, N. Loizou, R. M. Gower, and P. Richt´arik. Uniﬁed analysis of stochastic gradient methods for composite convex and smooth optimization. arXiv preprint arXiv:2006.11573, 2020.
G. M. Korpelevich. The extragradient method for ﬁnding saddle points and other problems. Matecon, 12:747–756, 1976.
D. Kovalev, S. Horv´ath, and P. Richt´arik. Don’t jump through hoops and remove those loops: SVRG and Katyusha are better without the outer loop. In Algorithmic Learning Theory, 2020.
C. J. Li, Y. Yu, N. Loizou, G. Gidel, Y. Ma, N. L. Roux, and M. I. Jordan. On the convergence of stochastic extragradient for bilinear games with restarted iteration averaging. arXiv preprint arXiv:2107.00464, 2021.
Z. Li, D. Kovalev, X. Qian, and P. Richtarik. Acceleration for compressed gradient descent in distributed and federated optimization. In International Conference on Machine Learning, pages 5895–5904. PMLR, 2020.
H. Lin, J. Mairal, and Z. Harchaoui. Catalyst acceleration for ﬁrst-order convex optimization: from theory to practice. Journal of Machine Learning Research, 18(1):7854–7907, 2018.
T. Lin, Z. Zhou, P. Mertikopoulos, and M. Jordan. Finite-time last-iterate convergence for multi-agent learning in games. In International Conference on Machine Learning, pages 6161–6171. PMLR, 2020.
S. Liu, S. Lu, X. Chen, Y. Feng, K. Xu, A. Al-Dujaili, M. Hong, and U.-M. O’Reilly. Min-max optimization without gradients: Convergence and applications to black-box evasion and poisoning attacks. In International Conference on Machine Learning, pages 6282–6293. PMLR, 2020.
N. Loizou and P. Richt´arik. Convergence analysis of inexact randomized iterative methods. SIAM Journal on Scientiﬁc Computing, 42(6):A3979–A4016, 2020a.
N. Loizou and P. Richt´arik. Momentum and stochastic momentum for stochastic gradient, newton, proximal point and subspace descent methods. Computational Optimization and Applications, 77(3): 653–710, 2020b.
17

N. Loizou, H. Berard, A. Jolicoeur-Martineau, P. Vincent, S. Lacoste-Julien, and I. Mitliagkas. Stochastic hamiltonian gradient methods for smooth games. In International Conference on Machine Learning, pages 6370–6381. PMLR, 2020.
N. Loizou, H. Berard, G. Gidel, I. Mitliagkas, and S. Lacoste-Julien. Stochastic gradient descent-ascent and consensus optimization for smooth games: Convergence analysis under expected co-coercivity. Advances in Neural Information Processing Systems, 34, 2021.
L. Luo, G. Xie, T. Zhang, and Z. Zhang. Near optimal stochastic algorithms for ﬁnite-sum unbalanced convex-concave minimax optimization. arXiv preprint arXiv:2106.01761, 2021.
Y. Malitsky and M. K. Tam. A forward-backward splitting method for monotone inclusions without cocoercivity. SIAM Journal on Optimization, 30(2):1451–1472, 2020.
P. Mertikopoulos and Z. Zhou. Learning in games with continuous action sets and unknown payoﬀ functions. Mathematical Programming, 173(1):465–507, 2019.
K. Mishchenko, E. Gorbunov, M. Tak´aˇc, and P. Richt´arik. Distributed learning with compressed gradient diﬀerences. arXiv preprint arXiv:1901.09269, 2019.
K. Mishchenko, D. Kovalev, E. Shulgin, P. Richtarik, and Y. Malitsky. Revisiting stochastic extragradient. In S. Chiappa and R. Calandra, editors, Proceedings of the Twenty Third International Conference on Artiﬁcial Intelligence and Statistics, volume 108 of Proceedings of Machine Learning Research, pages 4573–4582. PMLR, 26–28 Aug 2020.
O. Morgenstern and J. Von Neumann. Theory of games and economic behavior. Princeton university press, 1953.
A. Nemirovski, A. Juditsky, G. Lan, and A. Shapiro. Robust stochastic approximation approach to stochastic programming. SIAM Journal on Optimization, 19(4):1574–1609, 2009.
Y. Nesterov. Dual extrapolation and its applications to solving variational inequalities and related problems. Mathematical Programming, 109(2):319–344, 2007.
Y. Nesterov. Primal-dual subgradient methods for convex problems. Mathematical programming, 120 (1):221–259, 2009.
B. Palaniappan and F. Bach. Stochastic variance reduction methods for saddle-point problems. In Advances in Neural Information Processing Systems, pages 1416–1424, 2016.
L. D. Popov. A modiﬁcation of the arrow-hurwicz method for search of saddle points. Mathematical notes of the Academy of Sciences of the USSR, 28(5):845–848, 1980.
X. Qian, Z. Qu, and P. Richt´arik. Saga with arbitrary sampling. In International Conference on Machine Learning, pages 5190–5199. PMLR, 2019.
X. Qian, Z. Qu, and P. Richt´arik. L-svrg and l-katyusha with arbitrary sampling. Journal of Machine Learning Research, 22(112):1–47, 2021a.
X. Qian, P. Richt´arik, and T. Zhang. Error compensated distributed sgd can be accelerated. Advances in Neural Information Processing Systems, 34, 2021b.
P. Richt´arik and M. Tak´ac. Stochastic reformulations of linear systems: algorithms and convergence theory. SIAM Journal on Matrix Analysis and Applications, 41(2):487–524, 2020.
P. Richt´arik, I. Sokolov, and I. Fatkhullin. EF21: A new, simpler, theoretically better, and practically faster error feedback. In Advances in Neural Information Processing Systems, 2021.
A. Sadiev, A. Beznosikov, P. Dvurechensky, and A. Gasnikov. Zeroth-order algorithms for smooth saddlepoint problems. In International Conference on Mathematical Optimization Theory and Operations Research, pages 71–85. Springer, 2021.
18

F. Seide, H. Fu, J. Droppo, G. Li, and D. Yu. 1-bit stochastic gradient descent and its application to data-parallel distributed training of speech dnns. In Fifteenth Annual Conference of the International Speech Communication Association, 2014.

C. Song, Z. Zhou, Y. Zhou, Y. Jiang, and Y. Ma. Optimistic dual extrapolation for coherent nonmonotone variational inequalities. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages 14303–14314. Curran Associates, Inc., 2020.

S. U. Stich. Uniﬁed optimal analysis of the (stochastic) gradient method. arXiv:1907.04232, 2019.

arXiv preprint

S. U. Stich, J.-B. Cordonnier, and M. Jaggi. Sparsiﬁed sgd with memory. In Proceedings of the 32nd International Conference on Neural Information Processing Systems, pages 4452–4463, 2018.

V. Tominin, Y. Tominin, E. Borodich, D. Kovalev, A. Gasnikov, and P. Dvurechensky. On accelerated methods for saddle-point problems with composite structure. arXiv preprint arXiv:2103.09344, 2021.

S. Vaswani, F. Bach, and M. Schmidt. Fast and faster convergence of sgd for over-parameterized models and an accelerated perceptron. In The 22nd International Conference on Artiﬁcial Intelligence and Statistics, pages 1195–1204. PMLR, 2019.

B. C. Vu˜. A splitting algorithm for dual monotone inclusions involving cocoercive operators. Advances in Computational Mathematics, 38(3):667–681, 2013.

Z. Wang, K. Balasubramanian, S. Ma, and M. Razaviyayn. Zeroth-order algorithms for nonconvex minimax problems with improved complexities. arXiv preprint arXiv:2001.07819, 2020.

W. Wen, C. Xu, F. Yan, C. Wu, Y. Wang, Y. Chen, and H. Li. Terngrad: ternary gradients to reduce communication in distributed deep learning. In Proceedings of the 31st International Conference on Neural Information Processing Systems, pages 1508–1518, 2017.

J. Yang, N. Kiyavash, and N. He. Global convergence and variance reduction for a class of nonconvexnonconcave minimax problems. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages 1153–1165. Curran Associates, Inc., 2020.

T. Yoon and E. K. Ryu. Accelerated algorithms for smooth convex-concave minimax problems with O(1/k2) rate on squared gradient norm. In International Conference on Machine Learning, pages
12098–12109. PMLR, 2021.

D. Yuan, Q. Ma, and Z. Wang. Dual averaging method for solving multi-agent saddle-point problems with quantized information. Transactions of the Institute of Measurement and Control, 36(1):38–46, 2014.

D. L. Zhu and P. Marcotte. Co-coercivity and its role in the convergence of iterative schemes for solving variational inequalities. SIAM Journal on Optimization, 6(3):714–726, 1996.

19

Contents

1 Introduction

1

1.1 Technical Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2

1.2 Our Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3

1.3 Closely Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4

2 Uniﬁed Analysis of SGDA

5

2.1 Key Assumption . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5

2.2 Quasi-Strongly Monotone Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5

2.3 Monotone Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6

3 SGDA with Arbitrary Sampling

7

4 SGDA with Variance Reduction

8

5 Distributed SGDA with Compression

9

6 Numerical Experiments

13

7 Conclusion and Future Work

14

A Further Related Work

22

B Missing Details on Numerical Experiments

24

B.1 Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24

B.2 QSGDA vs DIANA-SGDA: Comparison in the Full-Batch Regime . . . . . . . . . . . . . . . 24

B.3 Distributed Quadratic Games with Constraints . . . . . . . . . . . . . . . . . . . . . . . . 25

C Auxiliary Results and Technical Lemmas

26

D Proof of The Main Results

28

D.1 Quasi-Strongly Monotone Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28

D.2 Monotone Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30

E SGDA with Arbitrary Sampling: Missing Proofs and Details

38

E.1 Proof of Proposition 3.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38

E.2 Analysis of SGDA-AS in the Quasi-Strongly Monotone Case . . . . . . . . . . . . . . . . . 38

E.3 Analysis of SGDA-AS in the Monotone Case . . . . . . . . . . . . . . . . . . . . . . . . . . 39

E.4 Missing Details on Arbitrary Sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39

F SGDA with Variance Reduction: Missing Proofs and Details

42

F.1 L-SVRGDA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42

F.1.1 Proof of Proposition 4.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42

F.1.2 Analysis of L-SVRGDA in the Quasi-Strongly Monotone Case . . . . . . . . . . . . 43

F.1.3 Analysis of L-SVRGDA in the Monotone Case . . . . . . . . . . . . . . . . . . . . . 43

F.2 SAGA-SGDA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44

F.2.1 SAGA-SGDA Fits Assumption 2.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44

F.2.2 Analysis of SAGA-SGDA in the Quasi-Strongly Monotone Case . . . . . . . . . . . 45

F.2.3 Analysis of SAGA-SGDA in the Monotone Case . . . . . . . . . . . . . . . . . . . . 46

F.3 Discussion of the Results in the Monotone Case . . . . . . . . . . . . . . . . . . . . . . . . 46

G Distributed SGDA with Compression: Missing Proofs and Details

48

G.1 QSGDA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48

G.1.1 Proof of Proposition 5.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48

G.1.2 Analysis of QSGDA in the Quasi-Strongly Monotone Case . . . . . . . . . . . . . . 49

G.1.3 Analysis of QSGDA in the Monotone Case . . . . . . . . . . . . . . . . . . . . . . . 50

G.2 DIANA-SGDA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50

20

G.2.1 Proof of Proposition 5.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50 G.2.2 Analysis of DIANA-SGDA in the Quasi-Strongly Monotone Case . . . . . . . . . . . 51 G.2.3 Analysis of DIANA-SGDA in the Monotone Case . . . . . . . . . . . . . . . . . . . 52 G.3 VR-DIANA-SGDA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53 G.3.1 Proof of Proposition 5.6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53 G.3.2 Analysis of VR-DIANA-SGDA in the Quasi-Strongly Monotone Case . . . . . . . . 57 G.3.3 Analysis of VR-DIANA-SGDA in the Monotone Case . . . . . . . . . . . . . . . . . 58 G.4 Discussion of the Results in the Monotone Case . . . . . . . . . . . . . . . . . . . . . . . . 59

H Coordinate SGDA

60

H.1 CSGDA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60

H.1.1 CSGDA Fits Assumption 2.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60

H.1.2 Analysis of CSGDA in the Quasi-Strongly Monotone Case . . . . . . . . . . . . . . 60

H.1.3 Analysis of CSGDA in the Monotone Case . . . . . . . . . . . . . . . . . . . . . . . 61

H.2 SEGA-SGDA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61

H.2.1 SEGA-SGDA Fits Assumption 2.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62

H.2.2 Analysis of SEGA-SGDA in the Quasi-Strongly Monotone Case . . . . . . . . . . . 62

H.2.3 Analysis of SEGA-SGDA in the Monotone Case . . . . . . . . . . . . . . . . . . . . 62

H.3 Comparison with Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63

21

A Further Related Work
The references necessary to motivate our work and connect it to the most relevant literature are included in the appropriate sections of the main body of the paper. Here we present a broader view of the literature, including some more references to papers of the area that are not directly related with our work.
Stochastic methods for solving VIPs. Although this paper is devoted to SGDA-type methods, we brieﬂy mention here the works studying other popular stochastic methods for solving VIPs based on diﬀerent algorithmic schemes such as Extragradient (EG) method [Korpelevich, 1976] and Optimistic Gradient (OG) method [Popov, 1980]. The ﬁrst analysis of Stochastic EG for solving (quasi-strongly) monotone VIPs was proposed in Juditsky et al. [2011] and then was extended and generalized in various ways [Mishchenko et al., 2020, Hsieh et al., 2020, Beznosikov et al., 2020c, Li et al., 2021, Gorbunov et al., 2021a]. Stochastic OG was studied in Gidel et al. [2019], Hsieh et al. [2019], Azizian et al. [2021]. In addition, lightweight second-order methods like stochastic Hamiltonian methods and stochastic consensus optimization were studied in Loizou et al. [2020], and Loizou et al. [2021], respectively.
Variance reduction for VIPs. In Section 1.3, we provided the most relevant variance reduced methods to our setting. Here we expand this discussion a bit more providing more details on some of the results and some extra references related to acceleration.
We should highlight that the rates from Alacaoglu and Malitsky [2021] match the lower bounds from Han et al. [2021]. Under additional assumptions similar results were achieved in Carmon et al. [2019]. Alacaoglu et al. [2021] developed variance-reduced method (FoRB-VR) based on Forward-Reﬂected-Backward algorithm [Malitsky and Tam, 2020], but the derived rates are inferior to those from Alacaoglu and Malitsky [2021].
Using Catalyst acceleration framework of Lin et al. [2018], Palaniappan and Bach [2016], Tominin et al. [2021] achieve (neglecting extra logarithmic factors) similar rates as in Alacaoglu and Malitsky [2021] and Luo et al. [2021] derive even tighter rates for min-max problems. However, as all Catalystbased approaches, these methods require solving an auxiliary problem at each iteration, which reduces their practical eﬃciency.
On quasi-strong monotonicity and star-cocoercivity. In this work we focus on quasistrongly monotone VI problems, a class of structured non-monotone operators for which we are able to provide tight convergence guarantees and avoid the standard issues (cycling and divergence of the methods) appearing in the more general non-monotone regime.
Since in general non-monotone problems, ﬁnding approximate ﬁrst-order locally optimal solutions is intractable [Daskalakis et al., 2021, Diakonikolas et al., 2021], it is reasonable to consider class of problems that satisfy special structural assumptions on the objective function for which these intractability barriers can be bypassed. Examples of problems belong in this category are the ones of our work which satisfy (3) or, for example, the two-sided PL condition [Yang et al., 2020] or the error-bound condition [Hsieh et al., 2020]. It is worth highlighting that quasi-strong monotone problems were considered in Mertikopoulos and Zhou [2019], Song et al. [2020], Loizou et al. [2021], Gorbunov et al. [2021a] as well.
Cocoercivity is a classical assumption in the literature on VIPs [Zhu and Marcotte, 1996] and operator splittings [Davis and Yin, 2017, Vu˜, 2013]. It can be interpreted as an intermediate notion between monotonicity and strong monotonicity. In general, it is stronger than monotonicity and Lipschitzness of the operator, e.g., simple bilinear games are non-cocoercive. From Cauchy-Swartz’s inequality, one can show that a -co-coercive operator is -Lipschitz. In single-objective minization, one can prove the converse statement by using convex duality. Thus, a gradient of a function is L–co-coercive if and only if the function is convex and L-smooth (i.e. L-Lipschitz gradients) [Bauschke et al., 2011]. However, in general, a L-Lipchitz operator is not L–co-coercive. Star-cocoercivity is a new notion recently introduced in Loizou et al. [2021] and is weaker than classical cocoercivity and can be achieved via a proper transformation of quasi-monotone Lipschitz operator [Gorbunov et al., 2021c]. Moreover, any µ-quasi strongly monotone L-Lipschitz operator F is -star-cocoercive with ∈ [L, L2/µ] and there exist examples of operators that are quasi-strongly monotone and star-cocoercive but neither monotone nor Lipschitz [Loizou et al., 2021].
22

Coordinate and zeroth-order methods for solving min-max problems and VIPs. Coordinate methods for solving VIPs are rarely considered in the literature. The most relevant results are given in the literature on zeroth-order methods for solving min-max problems. Although some of them can be easily extended to the coordinate versions of methods for solving VIPs, these methods are usually considered and analyzed for min-max problems. The closest work to our paper is Sadiev et al. [2021]: they propose and analyze several zeroth-order variants of SGDA and Stochastic EG with twopoint feedback oracle for solving strongly-convex-strongly-concave and convex-concave smooth min-max problems with bounded domain. Moreover, Sadiev et al. [2021] consider ﬁrmly smooth convex-concave min-max problems which is an analog of cocoercivity for min-max problems. There are also papers focusing on diﬀerent problems like non-sonvex-strongly-concave smooth min-max problems [Liu et al., 2020, Wang et al., 2020], non-smooth strongly-convex-strongly-concave and convex-concave min-max problems [Beznosikov et al., 2020b] and on diﬀerent methods like ones that use one-point feedback oracle [Beznosikov et al., 2021a]. These works are less relevant to our paper than Sadiev et al. [2021]. Moreover, the results derived in these papers are inferior to the ones from Sadiev et al. [2021].
23

B Missing Details on Numerical Experiments

B.1 Setup
We consider the special case of (1) with F and R deﬁned as follows:

1n F (x) = n Fi(x),
i=1

Fi(x) = Aix + bi,

R(x) = λ x 1 + δB (0)(x) = λ x 1 + 0, if x ∞ ≤ r,

(26)

r

+∞, if x ∞ > r,

where each matrix Ai ∈ Rd×d is non-symmetric with all eigenvalues with strictly positive real part, bi ∈ Rd, r > 0 is the radius of ∞-ball, and λ ≥ 0 is regularization parameter. One can show (see
Example 6.22 from Beck [2017]) that for the given R(x) prox operator has an explicit formula:

proxγR(x) = sign (x) min {max {|x| − γλ, 0} , r} ,

(27)

where sign(·) and | · | are component-wise operators. The considered problem generalizes the following quadratic game:

1n1

1

x1m∞ in≤r xm2 a∞x≤r n i=1 2 x1 A1,ix1 + x1 A2,ix2 − 2 x2 A3,ix2 + b1,ix1 − b2,ix2 + λ x1 1 − λ x2 1

with µiI A1,i LiI and µiI A3,i LiI. Indeed, the above problem is a special case of (1)+(26) with

x = x1 , Ai = A1,i A2,i , bi = b1,i ,

x2

−A2,i A3,i

b2,i

R(x) = λ x1 1 + λ x2 1 + δBr(0)(x1) + δBr(0)(x2).

In our experiments, to generate the non-symmetric matrices Ai ∈ Rd×d deﬁned in (26), we ﬁrst sample real random matrices Bi where the elements of the matrices are sampled from a normal distribution. We then compute the eigendecomposition of the matrices Bi = QiDiQ−i 1, where the Di are diagonal matrices with complex numbers on the diagonal. Next, we construct the matrices Ai = (QiD+i Q−i 1) where (M)i,j = (Mi,j) and D+i is obtained by transforming all the elements of Di to have positive real part. This process ensures that the eigenvalues of Ai all have positive real part, and thus that F (x) is strongly monotone and cocoercive. The bi ∈ Rd are sampled from a normal distribution with variance 100/d. For all the experiments we choose n = 1000 and d = 100. For the distributed experiments we
simulate m = 10 nodes on a single machine with 2 CPUs. For further details, the code is made available
at: https://github.com/hugobb/sgda.

B.2 QSGDA vs DIANA-SGDA: Comparison in the Full-Batch Regime
To illustrate the diﬀerence between QSGDA and DIANA-SGDA, we conduct an additional experiment Fig. 4. We consider the full-batch version of QSGDA and DIANA-SGDA. This enables us to separate the noise coming from the quantization from the noise coming from the stochasticity. We observe that when using full-batch DIANA-SGDA converges linearly to the solution while QSGDA only converges to a neighborhood of the solution.
24

Distance to optimality

101 10−1 10−3 10−5 10−7
0

QSGDA DIANA-SGDA

2000

4000

6000

Number of oracles call

8000

10000

Figure 4: QSGDA vs DIANA-SGDA: DIANA-SGDA converges linearly to the solution while QSGDA only converges to a neighborhood of the solution.

B.3 Distributed Quadratic Games with Constraints
Similarly to the distributed experiment on quadratic games provided in Section 6, we provide another distributed experiment on quadratic games but with constraints in Fig. 5. Overall, the methods behavior is similar to the unconstrained case.

Distance to optimality Distance to optimality

100 10−1

SGDA QSGDA DIANA-SGDA VR-DIANA-SGDA

100 10−2 10−4

10−2 10−3

10−6 10−8 10−10

SGDA QSGDA DIANA-SGDA VR-DIANA-SGDA

10−4 0

2500 5000 7500 10000 12500 15000 17500 20000

103

104

105

106

107

108

Number of oracles call

Number of bits communicated

Figure 5: Results on distributed quadratic games with constraints. Letf: Number of oracle calls. Right: Number of bits communicated between nodes.

25

C Auxiliary Results and Technical Lemmas

Useful inequalities. In our proofs, we often apply the following inequalities that hold for any a, b ∈ Rd and α > 0:

a + b 2 ≤ 2 a 2 + 2 b 2,

(28)

a, b ≤ 1 a 2 + α b 2.

(29)

2α

2

Useful lemmas. The following lemma from Stich [2019] allows us to derive the rates of convergence to the exact solution.

Lemma C.1 (Simpliﬁed version of Lemma 3 from Stich [2019]). Let the non-negative sequence {rk}k≥0 satisfy the relation
rk+1 ≤ (1 − aγk)rk + cγk2
for all k ≥ 0, parameters a > 0, c ≥ 0, and any non-negative sequence {γk}k≥0 such that γk ≤ 1/h for some h ≥ a, h > 0. Then, for any K ≥ 0 one can choose {γk}k≥0 as follows:

if K ≤ h , a
h if K > and k < k0,
a h if K > and k ≥ k0, a

γk = 1 , h

γk = 1 , h

2

γk

=

a(κ

+

k

−

, k0)

where κ = 2h/a and k0 = K/2 . For this choice of γk the following inequality holds:

rK ≤ 32hr0 exp

aK −

+ 36c .

a

2h

a2K

In the analysis of monotone case, we rely on the classical result from proximal operators theory.
Lemma C.2 (Theorem 6.39 (iii) from Beck [2017]). Let R be a proper lower semicontinuous convex function and x+ = proxγR(x). Then for all z ∈ Rd the following inequality holds:
x+ − x, z − x+ ≥ γ R(x+) − R(z) .

Finally, we rely on the following technical lemma for handling the sums arising in the proofs for the monotone case.

Lemma C.3. Let K > 0 be a positive integer and η1, η2, . . . , ηK be random vectors such that Ek[ηk] := E[ηk | η1, . . . , ηk−1] = 0 for k = 2, . . . , K. Then


K

2 K

E  ηk  = E[ ηk 2].

k=1

k=1

(30)

26

Proof. We start with the following derivation:


K

2

E  ηk  = E[ ηK 2] + 2E

K −1
ηK , ηk


K −1

2

+E

ηk 

k=1

k=1

k=1

= E[ ηK 2] + 2E EK

K −1
ηK , ηk


K−1

2

+E

ηk 

k=1

k=1

= E[ ηK 2] + 2E

K −1
EK [ηK ], ηk


K −1

2

+E

ηk 

k=1

k=1


K −1

2

= E[ ηK 2] + E 

ηk  .

k=1

Applying similar steps to E

K −1

2

k=1 ηk , E

K −2

2

k=1 ηk , . . . , E

2k=1 ηk 2 , we get the result.

27

D Proof of The Main Results
In this section, we provide complete proofs of our main results.

D.1 Quasi-Strongly Monotone Case
We start with the case when F satisﬁes (3) with µ > 0. For readers convenience, we restate the theorems below.

Theorem D.1 (Theorem 2.2). Let F be µ-quasi-strongly monotone with µ > 0 and Assumption 2.1 hold. Assume that
0 < γ ≤ min 1 , 1 (31) µ 2(A + CM )
for some M > B/ρ. Then for the Lyapunov function Vk = xk − x∗,k 2 + M γ2σk2, and for all k ≥ 0 we have

Bk

γ2(D1 + M D2)

E[Vk] ≤ 1 − min γµ, ρ − M

E[V0]

+

min

{γµ,

ρ

−

. B/M }

(32)

Proof. First of all, we recall a well-known fact about proximal operators: for any solution x∗ of (1) we

have

x∗ = proxγR(x∗ − γF (x∗)).

(33)

Using this and non-expansiveness of proximal operator, we derive

xk+1 − x∗,k+1 2 ≤ = ≤ =

xk+1 − x∗,k 2 proxγR(xk − γgk) − proxγR(x∗,k − γF (x∗,k)) 2 xk − γgk − x∗,k − γF (x∗,k) 2 xk − x∗,k 2 − 2γ xk − x∗,k, gk − F (x∗,k) + γ2 gk − F (x∗,k) 2.

Next, we take an expectation Ek[·] w.r.t. the randomness at iteration k and get

Ek xk+1 − x∗,k+1 2 = xk − x∗,k 2 − 2γ xk − x∗,k, F (xk) − F (x∗,k) +γ2Ek gk − F (x∗,k) 2

(6)
≤ xk − x∗,k 2 − 2γ xk − x∗, F (xk) − F (x∗,k) +γ2 2A xk − x∗,k, F (xk) − F (x∗,k) + Bσk2 + D1 .

Summing up this inequality with (7) multiplied by M γ2, we obtain

Ek xk+1 − x∗,k+1 2 + M γ2Ek[σk2+1] ≤ xk − x∗,k 2 − 2γ xk − x∗,k, F (xk) − F (x∗,k)

+ γ2 2A xk − x∗,k, F (xk) − F (x∗,k) + Bσk2 + D1

+ M γ2 2C xk − x∗,k, F (xk) − F (x∗,k) + (1 − ρ)σk2 + D2

= xk − x∗,k 2 + M γ2

1−ρ+ B M

σk2 + γ2(D1 + M D2)

− 2γ (1 − γ(A + CM )) xk − x∗,k, F (xk) − F (x∗,k) .

(34)

Since

γ

≤

1 2(A+CM )

the

factor

−2γ (1 − γ(A + CM ))

is

non-positive.

Therefore,

applying

strong

quasi-

monotonicity of F , we derive

Ek xk+1 − x∗,k+1 2 + M γ2σk2+1

≤ (1 − 2γµ (1 − γ(A + CM ))) xk − x∗,k 2 +M γ2 1 − ρ + MB σk2 + γ2(D1 + M D2).

28

Using

γ

≤

1 2(A+CM )

and

the

deﬁnition

Vk

=

xk − x∗,k 2 + M γ2σk2, we get

Ek [Vk+1] ≤ (1 − γµ) xk − x∗,k 2 + M γ2 1 − ρ + MB σk2 + γ2(D1 + M D2) ≤ 1 − min γµ, ρ − B Vk + γ2(D1 + M D2). M

Next, we take the full expectation from the above inequality and establish the following recurrence:

E [Vk+1] ≤ 1 − min γµ, ρ − B E[Vk] + γ2(D1 + M D2).

(35)

M

Unrolling the recurrence, we derive

E [Vk] ≤ 1 − min γµ, ρ − B k E[V0] + γ2(D1 + M D2) k−1 1 − min γµ, ρ − B t M t=0 M

≤ 1 − min γµ, ρ − B k E[V0] + γ2(D1 + M D2) ∞ 1 − min γµ, ρ − B t M t=0 M

Bk

γ2(D1 + M D2)

= 1 − min γµ, ρ − M

E[V0]

+

min

{γµ,

ρ

−

, B/M }

which ﬁnishes the proof.

Using this and Lemma C.1, we derive the following result about the convergence to the exact solution.

Corollary D.2 (Corollary 2.3). Let the assumptions of Theorem 2.2 hold. Consider two possible cases.
1. Let D1 = D2 = 0. Then, for any K ≥ 0, M = 2B/ρ, and

γ = min 1 , 1 (36) µ 2(A + 2BC/ρ)

we have

µ

ρ

E[VK ] ≤ E[V0] exp − min 2(A + 2BC/ρ) , 2 K .

(37)

2. Let D1 + M D2 > 0. Then, for any K ≥ 0 and M = 2B/ρ one can choose {γk}k≥0 as follows:

if K ≤ h , µ

γk = 1 , h

if K > h and k < k0, γk = 1 , (38)

µ

h

h if K > and k ≥ k0,
µ

2

γk

=

µ(κ

+

k

−

, k0)

where h = max {2(A + 2BC/ρ), 2µ/ρ}, κ = 2h/µ and k0 = K/2 . For this choice of γk the following inequality holds:

2(A + 2BC/ρ) 2

µ

ρ

E[VK ] ≤ 32 max

µ

, ρ

E[V0] exp

− min

2(A + 2BC/ρ) , 4

K

+ 36(D1 + 2BD2/ρ) .

(39)

µ2K

Proof. The ﬁrst part of the corollary follows from Theorem 2.2 due to

1 − min γµ, ρ − B M

K

ρ

= 1 − min γµ, 2

K ≤ exp − min γµ, ρ K . 2

29

Plugging (36) in the above inequality, we derive (37). Next, we consider the case when D1 + M D2 > 0. First, we notice that (35) holds for non-constant stepsizes γk such that

1

1

0 < γk ≤ min µ , 2(A + CM ) .

Therefore, for any k ≥ 0 we have

E [Vk+1]

≤ = M =2B/ρ

1 − min γkµ, ρ − B M

E[Vk] + γk2(D1 + M D2)

(1 − min {γkµ, ρ/2}) E[Vk] + γk2(D1 + 2BD2/ρ).

Secondly, we assume that for all k ≥ 0

ρ

1

0 < γk ≤ min 2µ , 2(A + CM ) .

Applying this to the recurrence for E[Vk], we obtain

E [Vk+1] ≤ (1 − γkµ) E[Vk] + γk2(D1 + 2BD2/ρ).

It remains to apply Lemma C.1 with rk = E[Vk], a = µ, c = D1 + 2BD2/ρ, and h = max {2(A + 2BC/ρ), 2µ/ρ} to the above recurrence.

D.2 Monotone Case
Next, we consider the case when µ = 0. Before deriving the proof, we provide additional discussion of the setup.
We emphasize that the maximum in (10) is taken over the compact set C containing the solution set X∗. Therefore, the quantity GapC(z) is a valid measure of convergence [Nesterov, 2007]. We point out that the iterates xk do not have to lie in C. Our analysis works for the problems with unbounded and bounded domains (see Nesterov [2007], Alacaoglu and Malitsky [2021] for similar setups).
Another popular convergence measure for the case when R(x) ≡ 0 in (1) is F (xk) 2. Although the squared norm of the operator is a weaker guarantee, it is easier to compute in practice and better suited for non-monotone problems [Yoon and Ryu, 2021]. Nevertheless, F (xk) 2 is not a valid measure of convergence for (1) with R(x) ≡ 0. Therefore, we focus on GapC(z) in the monotone case.6

Theorem D.3 (Theorem 2.5). Let F be monotone, -star-cocoercive and Assumptions 2.1, 2.4 hold. Assume that 1
0 < γ ≤ 2(A + BC/ρ) . (40)
Then for the function GapC(z) from (10) and for all K ≥ 0 we have

E GapC

1 K xk K
k=1

3 maxu∈C x0 − u 2 ≤ 2γK

+ 8γ 2Ω2C + (4A + + 8BC/ρ) · x0 − x∗,0 2

K

K

+ (4 + (4A + + 8BC/ρ) γ) γBσ02 ρK

+γ(2 + γ (4A + + 8BC/ρ))(D1 + 2BD2/ρ) +9γ max F (x∗) 2.
x∗ ∈X ∗

(41)

6When R(x) ≡ 0, our analysis can be modiﬁed to get the guarantees on the squared norm of the operator.

30

Proof. First, we apply the classical result about proximal operators (Lemma C.2) with x+ = xk+1, x = xk − γgk, and z = u for arbitrary point u ∈ Rd:
xk+1 − xk + γgk, u − xk+1 ≥ γ R(xk+1) − R(u) .

Multiplying by the factor of 2 and making small rearrangement, we get 2γ gk, u − xk + 2 xk+1 − xk, u − xk + 2 xk+1 − xk + γgk, xk − xk+1 ≥ 2γ R(xk+1) − R(u)

implying

2γ F (xk), xk − u + R(xk+1) − R(u)

≤ 2 xk+1 − xk, u − xk + 2γ F (xk) − gk, xk − u +2 xk+1 − xk, xk − xk+1 + 2γ gk, xk − xk+1 .

Next, we use a squared norm decomposition a + b 2 = a 2 + b 2 + 2 a, b , and obtain
2γ F (xk), xk − u + R(xk+1) − R(u) ≤ xk+1 − xk 2 + xk − u 2 − xk+1 − u 2 +2γ F (xk) − gk, xk − u −2 xk+1 − xk 2 + 2γ gk, xk − xk+1 .

Then, due to 2 a, b ≤ a 2 + b 2 we have
2γ F (xk), xk − u + R(xk+1) − R(u) ≤ xk+1 − xk 2 + xk − u 2 − xk+1 − u 2 +2γ F (xk) − gk, xk − u −2 xk+1 − xk 2 + γ2 gk 2 + xk − xk+1 2
= xk − u 2 − xk+1 − u 2 +2γ F (xk) − gk, xk − u + γ2 gk 2.

Monotonicity of F implies F (u), xk − u ≤ F (xk), xk − u , allowing us to continue our derivation as follows:
2γ F (u), xk − u + R(xk+1) − R(u) ≤ xk − u 2 − xk+1 − u 2 +2γ F (xk) − gk, xk − u + γ2 gk 2
= xk − u 2 − xk+1 − u 2 +2γ F (xk) − gk, xk − u +γ2 gk − g∗,k + g∗,k 2
(28)
≤ xk − u 2 − xk+1 − u 2 +2γ F (xk) − gk, xk − u +2γ2 gk − g∗,k 2 + 2γ2 g∗,k 2.
31

Summing up the above inequality for k = 0, 1, . . . , K − 1, we get

K −1
2γ
k=0

F (u), xk − u + R(xk+1) − R(u)

K −1

K −1

≤

xk − u 2 −

xk+1 − u 2

k=0

k=0

K −1

+2γ2

g∗,k 2

k=0

K −1
+2γ F (xk) − gk, xk − u

k=0

K −1

+2γ2

gk − g∗,k 2

k=0

K −1

= x0 − u 2 − xK − u 2 + 2γ2

g∗,k 2

k=0

K −1
+2γ F (xk) − gk, xk − u

k=0

K −1

+2γ2

gk − g∗,k 2.

k=0

Next, we divide both sides by 2γK

1 K−1 F (u), xk − u + R(xk+1) − R(u) ≤ x0 − u 2 − xK − u 2 + γ K−1 g∗,k 2

K k=0

2γK

K k=0

+ 1 K−1 F (xk) − gk, xk − u K
k=0

+ γ K−1 gk − g∗,k 2 K
k=0

and, after small rearrangement, we obtain

1 K−1 F (u), xk+1 − u + R(xk+1) − R(u) ≤ x0 − u 2 − xK − u 2 + F (u), xK − x0

K k=0

2γK

K

+ γ K−1 g∗,k 2 K
k=0

+ 1 K−1 F (xk) − gk, xk − u K
k=0

+ γ K−1 gk − g∗,k 2. K
k=0

Applying Jensen’s inequality for convex function R, we get R K1

K −1 k=0

xk+1

≤ K1

K −1 k=0

R(xk+1).

32

Plugging this in the previous inequality, we derive for u∗ being a projection of u on X∗

F (u),

1 K−1 xk+1 K
k=0

− u + R 1 K−1 xk+1 − R(u) K
k=0

≤ x0 − u 2 − xK − u 2 + F (u), xK − x0 + γ K−1 g∗,k 2

2γK

K K k=0

+ 1 K−1 F (xk) − gk, xk − u + γ K−1 gk − g∗,k 2

K

K

k=0

k=0

(29)
≤

x0 − u 2 −

xK − u 2 +

xK − x0 2 + 4γ F (u) − F (u∗) + F (u∗) 2

2γK

4γK

K

+ γ K−1 g∗,k 2 + 1 K−1 F (xk) − gk, xk − u + γ K−1 gk − g∗,k 2

K

K

K

k=0

k=0

k=0

(28)
≤

x0 − u 2 −

xK − u 2 +

x0 − u 2 +

xK − u 2 + 8γ F (u) − F (u∗) 2

2γK

2γK

K

+ γ K−1 g∗,k 2 + 8γ F (u∗) 2 + 1 K−1 F (xk) − gk, xk − u

K

K

k=0

k=0

+ γ K−1 gk − g∗,k 2 K
k=0

(4)
≤

x0 − u 2 + 8γ 2 u − u∗ 2 + 9γ max

F (x∗) 2

γK

K

x∗ ∈X ∗

+ 1 K−1 F (xk) − gk, xk − u + γ K−1 gk − g∗,k 2.

K

K

k=0

k=0

Next, we take maximum from the both sides in u ∈ C, which gives GapC

1 K

side by deﬁnition (10), and take the expectation of the result:

K k=1

xk

in the left-hand

E GapC

1 K xk K
k=1

≤ E maxu∈C x0 − u 2 + 8γ 2E maxu∈C u − u∗ 2

γK

K

+9γ max F (x∗) 2
x∗ ∈X ∗

+1E K

K −1
max F (xk) − gk, xk − u
u∈C k=0

γ K−1 +K E
k=0

gk − g∗,k 2

≤ E maxu∈C x0 − u 2 + 8γ 2Ω2C + 9γ max F (x∗) 2

γK

K

x∗ ∈X ∗

+1E K

K −1
max F (xk) − gk, xk − u
u∈C k=0

γ K−1 +K E
k=0

gk − g∗,k 2 .

(42)

In the last step, we also use that X∗ ⊂ C and ΩC := maxx,y∈C x − y (Assumption 2.4). It remains to upper bound the terms from the last two lines of (42). We start with the ﬁrst one.

33

Since

K−1

E

F (xk) − gk, xk

k=0

K −1

E

F (xk) − gk, x0

k=0

K −1

=E

E[F (xk) − gk | xk], xk

k=0

K −1

=

E[F (xk) − gk], x0 = 0,

k=0

= 0,

we have

1 E max K−1 F (xk) − gk, xk − u K u∈C
k=0

= 1 E K−1 F (xk) − gk, xk K
k=0

+1E K

K −1
max F (xk) − gk, −u
u∈C k=0

= 1 E max K−1 F (xk) − gk, −u K u∈C
k=0

= 1 E K−1 F (xk) − gk, x0 K
k=0

+1E K

K −1
max F (xk) − gk, −u
u∈C k=0

= E max 1 K−1(F (xk) − gk), x0 − u u∈C K
k=0



(29)

γK

≤ E max

1 K−1(F (xk) − gk) 2 + 1

  x0 − u 2 

u∈C  2 K k=0

2γK 



γ

K −1

2 1

=

E  (F (xk) − gk)  +

max x0 − u 2.

2K k=0

2γK u∈C

We notice that E[F (xk) − gk | F (x0) − g0, . . . , F (xk−1) − gk−1] = 0 for all k ≥ 1, i.e., conditions of Lemma C.3 are satisﬁed. Therefore, applying Lemma C.3, we get

1 E max K−1 F (xk) − gk, xk − u K u∈C
k=0

≤ γ K−1 E[ F (xk) − gk 2] 2K k=0

+ 1 max x0 − u 2.

(43)

2γK u∈C

Combining (42) and (43), we derive

E GapC

1 K xk K
k=1

≤ 3 maxu∈C x0 − u 2 + 8γ 2Ω2C + 9γ max F (x∗) 2

2γK

K

x∗ ∈X ∗

γ K−1 + 2K E
k=0

gk − F (xk) 2 + γ K−1 E K
k=0

gk − g∗,k 2

(28)
≤

3 maxu∈C x0 − u 2 + 8γ 2Ω2C + 9γ max

F (x∗) 2

2γK

K

x∗ ∈X ∗

γ K−1 +K E
k=0

F (xk) − g∗,k 2 + 2γ K−1 E K
k=0

gk − g∗,k 2 .

34

Using -star-cocoercivity of F together with the ﬁrst part of Assumption 2.1, we continue our derivation as follows:

E GapC

1 K xk K
k=1

≤ 3 maxu∈C x0 − u 2 + 8γ 2Ω2C + 2γD1 + 9γ max F (x∗) 2

2γK

K

x∗ ∈X ∗

γ(4A + ) K−1 +K E
k=0

F (xk) − g∗,k, xk − x∗,k

2γB K−1 2

+K

E σk

k=0

= 3 maxu∈C x0 − u 2 + 8γ 2Ω2C + 2γD1 + 9γ max F (x∗) 2

2γK

K

x∗ ∈X ∗

γ(4A + ) K−1 +K E
k=0

F (xk) − g∗,k, xk − x∗,k

+ 2γB K

1+ 1 ρ

K −1

2 2γB K−1

2

E σk − ρK

E σk .

k=0

k=0

Next, we use the second part of Assumption 2.1 and get

E GapC

1 K xk K
k=1

≤ 3 maxu∈C x0 − u 2 + 8γ 2Ω2C + 2γD1 + 9γ max F (x∗) 2

2γK

K

x∗ ∈X ∗

γ(4A + ) K−1 +K E
k=0

F (xk) − g∗,k, xk − x∗,k

+ 2γB K

1+ 1 ρ

K −1
E 2C F (xk−1) − g∗,k−1, xk−1 − x∗,k−1
k=1

+ 2γB K

1+ 1 ρ

K −1
E (1 − ρ)σk2−1 + D2
k=1

+ 2γB K

1+ 1 ρ

2 2γB K−1 2

σ0 − ρK

E σk

k=0

≤ 3 maxu∈C x0 − u 2 + 8γ 2Ω2C + 2γB(1 + 1/ρ) σ2

2γK

K

K

0

+2γ (D1 + B(1 + 1/ρ)D2)

+9γ max
x∗ ∈X ∗

F (x∗) 2 + γ(4A + K

) K−1 E
k=0

F (xk) − g∗,k, xk − x∗,k

+ 2γB K

1+ 1 ρ

K −2
E 2C F (xk) − g∗,k, xk − x∗,k + (1 − ρ)σk2
k=0

2γB K−1 2

− ρK

E σk

k=0

≤ 3 maxu∈C x0 − u 2 + 8γ 2Ω2C + 2γB(1 + 1/ρ) σ2

2γK

K

K

0

+2γ (D1 + B(1 + 1/ρ)D2) + 9γ max F (x∗) 2
x∗ ∈X ∗

+ (4A +

γ K−1

+ 4BC(1 + 1/ρ))

E

K k=0

F (xk) − g∗,k, xk − x∗,k

+ 2γB (1 − ρ) K

1+ 1 ρ

K −2

2 2γB K−1

2

E σk − ρK

E σk .

k=0

k=0

35

Since (1 − ρ) (1 + 1/ρ) = −ρ + 1/ρ ≤ 1/ρ, the last row is non-positive and we have

E GapC

1 K xk K
k=1

≤ 3 maxu∈C x0 − u 2 + 8γ 2Ω2C + 2γB(1 + 1/ρ) σ2

2γK

K

K

0

+2γ (D1 + B(1 + 1/ρ)D2) + 9γ max F (x∗) 2
x∗ ∈X ∗

+ γ (4A +

+ 4BC(1 + 1/ρ)) K−1

K

E

k=0

F (xk) − g∗,k, xk − x∗,k

(44) .

Note that inequality (34) from the proof of Theorem 2.2 is derived using Assumption 2.1 only. With M = B/ρ it gives

E xk+1 − x∗,k+1 2 + γ2ρB E[σk2+1] ≤ E xk − x∗,k 2 + γ2ρB E σk2 + γ2(D1 + BD2/ρ) −2γ (1 − γ(A + BC/ρ)) E xk − x∗,k, F (xk) − g∗,k .

Since γ ≤ 1/2(A+BC/ρ) we obtain γE xk − x∗,k, F (xk) − g∗,k

≤ E xk − x∗,k 2 + γ2ρB E σk2 − E xk+1 − x∗,k+1 2 − γ2ρB E[σk2+1] + γ2(D1 + BD2/ρ).

Plugging this inequality in (44), we derive

E GapC

1 K xk K
k=1

≤ 3 maxu∈C x0 − u 2 + 8γ 2Ω2C + 2γB(1 + 1/ρ) σ2

2γK

K

K

0

+2γ (D1 + B(1 + 1/ρ)D2) + 9γ max F (x∗) 2
x∗ ∈X ∗

+ (4A +

1 K−1

+ 4BC(1 + 1/ρ)) ·

E

K k=0

xk − x∗,k 2

− (4A +

1 K−1

+ 4BC(1 + 1/ρ)) ·

E

K k=0

xk+1 − x∗,k+1 2

+ (4A +

γ2B K−1

2

2

+ 4BC(1 + 1/ρ)) · ρK

E σk − σk+1

k=0

+γ2 (4A + + 4BC(1 + 1/ρ)) · (D1 + BD2/ρ)

≤ 3 maxu∈C x0 − u 2 + 8γ 2Ω2C + (4A + + 8BC/ρ) · x0 − x∗,0 2

2γK

K

K

+ (4 + (4A + + 8BC/ρ) γ) γBσ02 ρK

+γ (2 + γ (4A + + 8BC/ρ))(D1 + 2BD2/ρ) + 9 max F (x∗) 2 ,
x∗ ∈X ∗

where in the last inequality we use 1 + 1/ρ ≤ 2/ρ.

Corollary D.4. Let the assumptions of Theorem 2.5 hold. Then, for all K one can choose γ as

1

Ω0,C √ρ

Ω0,C

Ω0,C

γ = min 4A + + 8BC/ρ , σ0√B , K(D1 + 2BD2/ρ) , G∗√K ,

(45)

where Ω0 := x0 − x∗,0 2 and Ω0,C, σ0, and G∗ are some upper bounds for maxu∈C x0 − u , σ0, and

36

maxx∗∈X∗ F (x∗)

respectively. This choice of γ implies E GapC

1 K

K k=1

xk

equals

(A + + BC/ρ)(Ω20,C + Ω20) + Ω2C

√ Ω0,C σ0 B

Ω0,C ( D1 + BD2/ρ + G∗)

O K + √ρK + √K .

Proof. First of all, the choice of γ from (45) implies (40) since 1 ≤ 1.
4A + + 8BC/ρ 2 (A + BC/ρ)

Using (11), the deﬁnitions of Ω0,C, σ0, G∗, and γ ≤ 1/(4A+ , +8BC/ρ) we get

E GapC

1 K xk K
k=1

≤ 3 maxu∈C x0 − u 2 + 8γ 2Ω2C + (4A + + 8BC/ρ) · x0 − x∗,0 2

2γK

K

K

+ (4 + (4A + + 8BC/ρ) γ) γBσ02 ρK

+γ (2 + γ (4A + + 8BC/ρ))(D1 + 2BD2/ρ) + 9 max F (x∗) 2
x∗ ∈X ∗

≤ 3Ω20,C + 8γ 2Ω2C + (4A + + 8BC/ρ)Ω20

2γK

K

K

+ (4 + (4A + + 8BC/ρ) γ) γBσ02 ρK

+γ (2 + γ (4A + + 8BC/ρ))(D1 + 2BD2/ρ) + 9G2∗

≤ 3Ω20,C + 8γ 2Ω2C + (4A + + 8BC/ρ)Ω20 + 5γBσ02

2γK

K

K

ρK

+3γ D1 + 2BD2 + 3G2∗ . ρ

Finally, we apply (45):

E GapC

1 K xk K
k=1

≤

3Ω20,C

+ 1 · 8 2Ω2C

2 min

1

,

, Ω0,C √ρ
√

√

Ω0,C

, Ω0√,C K

K

4A+ +8BC/ρ σ0 B

K(D1+2BD2/ρ) G∗ K

+ (4A +

+ 8BC/ρ)Ω20 Ω0,C √ρ γBσ02

+ √·

K

σ0 B ρK

+

Ω0,C

· 3 D1 + 2BD2 + Ω√0,C · 9G2∗

K(D1 + 2BD2/ρ)

ρ

G∗ K

(A + + BC/ρ)(Ω20,C + Ω20) + Ω2C

√ Ω0,C σ0 B

=O

K + √ρK

+ Ω0,C(

D1 + BD2/ρ + G∗) √

.

K

37

E SGDA with Arbitrary Sampling: Missing Proofs and Details
Algorithm 1 SGDA-AS: Stochastic Gradient Descent-Ascent with Arvitrary Sampling 1: Input: starting point x0 ∈ Rd, distribution D, stepsize γ > 0, number of steps K 2: for k = 0 to K − 1 do 3: Sample ξk ∼ D independently from previous iterations and compute gk = Fξk (xk) 4: xk+1 = proxγR(xk − γgk)
5:
6: end for

E.1 Proof of Proposition 3.2

Proposition E.1 (Proposition 3.2). Let Assumption 3.1 hold. Then, SGDA satisﬁes Assumption 2.1 with

A = D,

B = 0,

σk2 ≡ 0, D1 = 2σ∗2 := 2 max ED
x∗ ∈X ∗
C = 0, ρ = 1, D2 = 0.

Fξ(x∗) − F (x∗) 2 ,

Proof. To prove the result, it is suﬃcient to derive an upper bound for Ek gk − F (x∗,k) 2 :

Ek gk − F (x∗,k) 2
where σ∗2 := maxx∗∈X∗ ED with

= ED Fξk (xk) − F (x∗,k) 2 ≤ 2ED Fξk (xk) − Fξk (x∗,k) 2 + 2ED Fξk (x∗,k) − F (x∗,k) 2
(12)
≤ 2 D F (xk) − F (x∗,k), xk − x∗,k + 2σ∗2,
Fξ(x∗) − F (x∗) 2 . The above inequality implies that Assumption 2.1 holds

A = D,

B = 0,

σk2 ≡ 0, D1 = 2σ∗2 := 2 max ED
x∗ ∈X ∗
C = 0, ρ = 1, D2 = 0.

Fξ(x∗) − F (x∗) 2 ,

E.2 Analysis of SGDA-AS in the Quasi-Strongly Monotone Case
Plugging the parameters from the above proposition in Theorem 2.2 and Corollary 2.3 we get the following results.

Theorem E.2. Let F be µ-quasi strongly monotone, Assumption 3.1 hold, and 0 < γ ≤ 1/2 D. Then, for all k ≥ 0 the iterates produced by SGDA-AS satisfy

E xk − x∗,k 2 ≤ (1 − γµ)k x0 − x0,∗ 2 + 2γσ∗2 .

(46)

µ

Corollary E.3 (Corollary 3.3). Let the assumptions of Theorem E.2 hold. Then, for any K ≥ 0 one

38

can choose {γk}k≥0 as follows:

if K ≤ 2 D , µ

1

γk

=

2

,
D

if K > 2 D and k < k0, γk = 1 ,

(47)

µ

2D

if K > 2 D and k ≥ k0, µ

2

γk

=

4

D

+ µ(k

, − k0)

where k0 = K/2 . For this choice of γk the following inequality holds for SGDA-AS:

E[ xK − x∗,K 2] ≤ 64 D x0 − x∗,0 2 exp µ

µ −K
2D

+ 72σ∗2 . µ2K

E.3 Analysis of SGDA-AS in the Monotone Case
In the monotone case, using Theorem 2.5, we establish the new result for SGDA-AS.

Theorem E.4. Let F be monotone -star-cocoercive and Assumptions 2.1, 2.4, 3.1 hold. Assume that γ ≤ 1/2 D. Then for GapC(z) from (10) and for all K ≥ 0 the iterates produced by SGDA-AS satisfy

E GapC

1 K xk K
k=1

≤ 3 maxu∈C x0 − u 2 + 8γ 2Ω2C + (4 D + ) x0 − x∗,0 2

2γK

K

K

+2γ(2 + γ (4 D + ))σ∗2 + 9γ max F (x∗) 2.
x∗ ∈X ∗

Next, we apply Corollary D.4 and get the following rate of convergence to the exact solution.

Corollary E.5. Let the assumptions of Theorem E.4 hold. Then ∀K > 0 and

γ = min

1 , √Ω0,C , Ω√0,C

(48)

4 D + 2Kσ∗ G∗ K

the iterates produced by SGDA-AS satisfy

E GapC

1 K xk K
k=1

( D + )(Ω20,C + Ω20) + Ω2C Ω0,C(σ∗ + G∗)

=O

+

√

.

K

K

As we already mentioned before, the above result is new for SGDA-AS: the only known work on SGDA-AS [Loizou et al., 2021] focuses on the µ-quasi-strongly monotone case only with µ > 0. Moreover, neglecting the dependence on problem/noise parameters, the derived convergence rate O (1/K + 1/√K) is standard for the analysis of stochastic methods for solving monotone VIPs [Juditsky et al., 2011].

E.4 Missing Details on Arbitrary Sampling

In the main part of the paper, we discuss the Arbitrary Sampling paradigm and, in particular, using our

general theoretical framework, we obtain convergence guarantees for SGDA under Expected Cocoercivity

assumption (Assumption 3.1). In this section, we give the particular examples of arbitrary sampling

ﬁtting this setup. In all the examples below, we focus on a special case of stochastic reformulation from (13) and assume that for all i ∈ [n] operator Fi is ( i, X∗)-cocoercive, i.e., for all i ∈ [n] and x ∈ Rd we

have

Fi(x) − Fi(x∗) 2 ≤ i Fi(x) − Fi(x∗), x − x∗ ,

(49)

where x∗ is the projection of x on X∗. Note that (49) holds whenever Fi are cocoercive.

39

Uniform Sampling. We start with the classical uniform sampling: let P {ξ = nei} = 1/n for all i ∈ [n], where ei ∈ Rn is the i-th coordinate vector from the standard basis in Rn. Then, E[ξi] = 1 for
all i ∈ [n] and Assumption 3.1 holds with D = maxi∈[n] i:

ED Fξ(x) − Fξ(x∗) 2

= n1 n Fi(x) − Fi(x∗) 2
i=1
(4≤9) 1 ( i Fi(x) − Fi(x∗), x − x∗ ) n
≤ max i F (x) − F (x∗), x − x∗
i∈[n]

In this case, Corollaries E.3 and E.5 imply the following rate for SGDA in µ-quasi strongly monotone and monotone cases respectively:

E[ xK − x∗,K 2] ≤ 64 maxi∈[n] i x0 − x∗,0 2 exp −

µ

K + 72σ∗2,US ,

µ

2 maxi∈[n] i

µ2K

E GapC

1 K xk K
k=1

(maxi∈[n] i + )(Ω20,C + Ω20) + Ω2C Ω0,C (σ∗,US + G∗)

=O

+

√

,

K

K

where

σ∗2,US

:=

maxx∗ ∈X ∗

1 n

n i=1

Fi(x∗) − F (x∗) 2.

Importance Sampling. Next, we consider a non-uniform sampling strategy – importance sampling:

let P ξ = ein / i = i/n for all i ∈ [n], where

= n1

n i=1

i.

Then, E[ξi] = 1 for all i ∈ [n] and

Assumption 3.1 holds with D = :

ED Fξ(x) − Fξ(x∗) 2

n

2

=

i (Fi(x) − Fi(x∗))

i=1 n i

n

=

Fi(x) − Fi(x∗) 2

i=1 n i

(49)
≤ n

Fi(x) − Fi(x∗), x − x∗

≤ F (x) − F (x∗), x − x∗

In this case, Corollaries E.3 and E.5 imply the following rate for SGDA in µ-quasi strongly monotone and monotone cases respectively:

E[ xK − x∗,K 2]

≤

64

x0 − x∗,0 2 exp

µ −K

+ 72σ∗2,IS ,

µ

2

µ2K

E GapC

1 K xk K
k=1

( + )(Ω20,C + Ω20) + Ω2C Ω0,C (σ∗,IS + G∗)

=O

+

√

,

K

K

where

σ∗2,IS

:=

maxx∗ ∈X ∗

1 n

ni i=1

2
(x∗) − F (x∗) . We emphasize that ≤ maxi∈[n] i and, in fact, i Fi

might be much smaller than maxi∈[n] i. Therefore, compared to SGDA with uniform sampling, SGDA with importance sampling has better exponentially decaying term in the quasi-strongly monotone case and converges faster to the neighborhood, if executed with constant stepsize. Moreover, σ∗2,IS ≤ σ∗2,US, when maxx∗∈X∗ Fi(x∗) ∼ i. In this case, SGDA with importance sampling has better O(1/K) term
than SGDA with uniform sampling as well.

Minibatch Sampling With Replacement. Let ξ = 1b

b i=1

ξi,

where

ξi

are

i.i.d.

samples

from

some distribution D satisfying (13) and Assumption 3.1. Then, the distribution of ξ satisﬁes (13)

and Assumption 3.1 as well with the same constant D. Therefore, minibatched versions of uniform

sampling and importance sampling ﬁt the framework as well with

D

=

maxi∈[n]

i, σ∗2

=

σ∗2,US b

and

D=

, σ∗2

=

. σ∗2,IS
b

40

Minibatch Sampling Without Replacement. For given batchsize b ∈ [n] we consider the

following sampling strategy:

for each subset S ⊆ [n] such that |S| = b we have P

ξ

=

n b

i∈S ei =

b!(nn−! b)! , i.e., S is chosen uniformly at random from all b-element subsets of [n]. In the special case, when

R(x) ≡ 0, Loizou et al. [2021] show that this sampling strategy satisﬁes (13) and Assumption 3.1 with

D = n(b − 1) + n − b max i,

σ∗2 =

n − b σ2 .
∗,US

(50)

b(n − 1) b(n − 1) i∈[n]

b(n − 1)

Clearly, both parameters are smaller than corresponding parameters for minibatched version of uniform
sampling with replacement, which indicates the theoretical beneﬁts of sampling without replacement.
Plugging the parameters from (50) in Corollaries E.3 and E.5, we get the rate of convergence for this sampling strategy. Moreover, in the quasi-strongly monotone case, to guarantee E[ xK − x∗,K 2] ≤ ε for
some ε > 0, the method requires

Kb = O max

b + (n − b) maxi∈[n] i

µ

n

µ

D x0 − x∗,0 2 (n − b)σ∗2,US

log

µε

, nµ2ε

b = O max

− n1 maxi∈[n] i + maxi∈[n] i , (n − b)σ∗2,US

µ

nµ2ε

oracle calls, (51)

where O(·) hides numerical and logarithmic factors. One can notice that the ﬁrst term in the maximum

linearly increases in b (since

cannot

be

smaller

than

1 n

maxi∈[n]

i),

while

the

second

term

linearly

decreases in b. The ﬁrst term in the maximum is lower bounded by (nn−b) maxiµ∈[n] i . Therefore, if

maxi∈[n] i ≥ σ∗2µ,εUS , the the ﬁrst term in the maximum is always larger than the second one, meaning

that the optimal batchsize, i.e., the batchsize that minimizes oracle complexity (51) neglecting the

logarithmic terms, equals b∗ = 1. Next, if maxi∈[n] i < σ∗2µ,εUS , then there exists a positive value of b such that the ﬁrst term in the maximum equals the second term. This value equals

n σ∗2,US − µε maxi∈[n] i .
σ∗2 + µε n − maxi∈[n] i

One can easily verify that it is always smaller than n, but it can be non integer and it can be smaller than 1 as well. Therefore, the optimal batchsize is



1,

b∗ = max 1, (n σ∗2,US−µε maxi∈[n] i)

 

σ∗2+µε(n −maxi∈[n] i)

if maxi∈[n] i ≥ σ∗2µ,εUS , , otherwise.

We notice that Loizou et al. [2021] derive the following formula for the optimal batchsize (ignoring numerical constants):



1,

b∗ = max 1, (n σ∗2,US−µε(maxi∈[n] i− ))

 

σ∗2+µε(n −maxi∈[n] i)

if maxi∈[n] i − ≥ σ∗2µ,εUS , , otherwise.

However, in terms of O(·) both formulas give the same complexity result.

41

F SGDA with Variance Reduction: Missing Proofs and Details
In this section, we provide missing proofs and details for Section 4.
F.1 L-SVRGDA
Algorithm 2 L-SVRGDA: Loopless Stochastic Variance Reduced Gradient Descent-Ascent 1: Input: starting point x0 ∈ Rd, probability p ∈ (0, 1], stepsize γ > 0, number of steps K 2: Set w0 = x0 and compute F (w0) 3: for k = 0 to K − 1 do 4: Draw a fresh sample jk from the uniform distribution on [n] and compute gk = Fjk (xk)− Fjk (wk) + F (wk) 5: wk+1 = xk, with probability p, wk, with probability 1 − p, 6: xk+1 = proxγR(xk − γgk) 7: end for

F.1.1 Proof of Proposition 4.3

Lemma F.1. Let Assumption 4.1 hold. Then for all k ≥ 0 L-SVRGDA satisﬁes

Ek gk − F (x∗,k) 2 ≤ 2 F (xk) − F (x∗,k), xk − x∗,k + 2σk2,

(52)

where

σk2

:=

1 n

n i=1

Fi(wk) − Fi(x∗,k) 2.

Proof. Since gk = Fjk (xk) − Fjk (wk) + F (wk), we have

Ek gk − F (x∗,k) 2

= Ek Fjk (xk) − Fjk (wk) + F (wk) − F (x∗,k) 2

= n1 n Fi(xk) − Fi(wk) + F (wk) − F (x∗,k) 2
i=1

≤ n2 n Fi(xk) − Fi(x∗,k) 2
i=1

2n +n

Fi(wk) − Fi(x∗,k) − (F (wk) − F (x∗,k)) 2

i=1

≤ n2 n Fi(xk) − Fi(x∗,k) 2 + n2 n Fi(wk) − Fi(x∗,k) 2

i=1

i=1

(16)
≤ 2 F (xk) − F (x∗,k), xk − x∗,k + 2σk2.

Lemma F.2. Let Assumptions 4.1 and 4.2 hold. Then for all k ≥ 0 L-SVRGDA satisﬁes

where

σk2

:=

1 n

Ek σk2+1 ≤ p F (xk) − F (x∗,k), xk − x∗,k + (1 − p)σk2,

n i=1

Fi(wk) − Fi(x∗,k) 2.

(53)

42

Proof. Using the deﬁnitions of σk2+1 and wk+1 (see (15)), we derive

Ek σk2+1

=
As=. 4.2
=
(16)
≤

1n n Ek
i=1

Fi(wk+1) − Fi(x∗,k+1) 2

1n n Ek
i=1

Fi(wk+1) − Fi(x∗,k) 2

pn n i=1

Fi(xk) − Fi(x∗,k) 2 + 1 −n p n
i=1

Fi(wk) − Fi(x∗,k) 2

p F (xk) − F (x∗,k), xk − x∗,k + (1 − p)σk2.

The above two lemmas imply that Assumption 2.1 is satisﬁed with certain parameters.

Proposition F.3 (Proposition 4.3). Let Assumptions 4.1 and 4.2 hold. Then, L-SVRGDA satisﬁes Assumption 2.1 with

A= ,

B = 2,

σ2 = 1 n kn
i=1

Fi(wk) − Fi(x∗) 2,

C=p , 2

ρ = p,

D1 = D2 = 0.

F.1.2 Analysis of L-SVRGDA in the Quasi-Strongly Monotone Case Plugging the parameters from the above proposition in Theorem 2.2 and Corollary 2.3 with M = p4 we get the following results.

Theorem F.4. Let F be µ-quasi strongly monotone, Assumptions 4.1, 4.2 hold, and 0 < γ ≤ 1/6 . Then for all k ≥ 0 the iterates produced by L-SVRGDA satisfy

E xk − x∗ 2 ≤ (1 − min {γµ, p/2})k V0,

(54)

where V0 = x0 − x∗ 2 + 4γ2σ02/p.

Corollary F.5. we have

Let the assumptions of Theorem F.4 hold. Then, for p = n, γ = 1/6 E[ xk − x∗ 2] ≤ V0 exp − min µ , 1 K . 6 2n

and any K ≥ 0

F.1.3 Analysis of L-SVRGDA in the Monotone Case Next, using Theorem 2.5, we establish the convergence of L-SVRGDA in the monotone case.

Theorem F.6. Let F be monotone, -star-cocoercive and Assumptions 2.1, 2.4, 4.1, 4.2 hold. Assume that γ ≤ 1/6 . Then for GapC(z) from (10) and for all K ≥ 0 the iterates of L-SVRGDA satisfy

E GapC

1 K xk K
k=1

≤ 3 maxu∈C x0 − u 2 + 8γ 2Ω2C + 12 +

2γK

K

x0 − x∗,0 2 K

+ 4 + 12 +

γ 2γσ02 + 9γ max F (x∗) 2.

pK

x∗ ∈X ∗

Applying Corollary D.4, we get the rate of convergence to the exact solution.

43

Corollary F.7. Let the assumptions of Theorem F.6 hold and p = 1/n. Then ∀K > 0 one can choose

γ as

γ = min

1 , 1 , Ω√0,C .

(55)

12 + 2n G∗ K

This choice of γ implies

E GapC

1 K xk K
k=1

 ( + )(Ω20,C + Ω20) +
= O K

 n Ω20,C + Ω2C Ω0,C G∗
+ √ . K

Proof. First of all, (16), (4), and Cauchy-Schwarz inequality imply

σ2 = 1 n F (x0) − F (x∗) 2

0

n

i

i

i=1

(16)
≤ F (x0) − F (x∗), x0 − x∗

≤ F (x0) − F (x∗) · x0 − x∗

≤

x0 − x∗ 2 ≤ max x0 − u 2 ≤ Ω20,C.

u∈C

Next, applying Corollary D.4 with σ0 := Ω0,C, we get the result.

F.2 SAGA-SGDA
In this section, we show that SAGA-SGDA [Palaniappan and Bach, 2016] ﬁts our theoretical framework and derive new results for this method under averaged star-cocoercivity.
Algorithm 3 SAGA-SGDA [Palaniappan and Bach, 2016]
1: Input: starting point x0 ∈ Rd, stepsize γ > 0, number of steps K 2: Set wi0 = x0 and compute Fi(wi0) for all i ∈ [n] 3: for k = 0 to K − 1 do 4: Draw a fresh sample jk from the uniform distribution on [n] and compute gk = Fjk (xk)−
Fjk (wjkk ) + n1 ni=1 Fi(wik) 5: Set wjkk+1 = xk and wik+1 = wik for i = jk 6: xk+1 = proxγR(xk − γgk) 7: end for

F.2.1 SAGA-SGDA Fits Assumption 2.1

Lemma F.8. Let Assumption 4.1 hold. Then for all k ≥ 0 SAGA-SGDA satisﬁes

Ek gk − F (x∗,k) 2 ≤ 2 F (xk) − F (x∗,k), xk − x∗,k + 2σk2,

(56)

where

σk2

:=

1 n

n i=1

Fi(wik) − Fi(x∗,k) 2.

Proof. For brevity, we introduce a new notation: Sk = n1 ni=1 Fi(wik). Since gk = Fjk (xk) − Fjk (wjkk ) + 44

Sk, we have Ek

gk − F (x∗,k) 2

= Ek Fjk (xk) − Fjk (wjkk ) + Sk − F (x∗,k) 2

= n1 n Fi(xk) − Fi(wik) + Sk − F (x∗,k) 2
i=1

≤ n2 n Fi(xk) − Fi(x∗,k) 2
i=1

2n +n
i=1

Fi(wik) − Fi(x∗,k) − (Sk − F (x∗,k)) 2

≤ n2 n Fi(xk) − Fi(x∗,k) 2 + n2 n Fi(wik) − Fi(x∗,k) 2

i=1

i=1

(16)
≤ 2 F (xk) − F (x∗,k), xk − x∗,k + 2σk2.

Lemma F.9. Let Assumptions 4.1 and 4.2 hold. Then for all k ≥ 0 SAGA-SGDA satisﬁes

where

σk2

:=

1 n

Ek σk2+1 ≤ n F (xk) − F (x∗,k), xk − x∗,k + (1 − 1/n)σk2,

n i=1

Fi(wik) − Fi(x∗,k) 2.

Proof. Using the deﬁnitions of σk2+1 and wik+1, we derive

Ek σk2+1

=
As=. 4.2
=
(16)
≤

1n n Ek
i=1

Fi(wik+1) − Fi(x∗,k+1) 2

1n n Ek
i=1

Fi(wik+1) − Fi(x∗,k) 2

1n n2
i=1

Fi(xk) − Fi(x∗,k) 2 + 1 −n1/n n
i=1

Fi(wik) − Fi(x∗,k) 2

n F (xk) − F (x∗,k), xk − x∗,k + (1 − 1/n)σk2.

(57)

The above two lemmas imply that Assumption 2.1 is satisﬁed with certain parameters.

Proposition F.10. Let Assumptions 4.1 and 4.2 hold. Then, SAGA-SGDA satisﬁes Assumption 2.1 with

A= ,

B = 2,

σ2 = 1 n kn
i=1

Fi(wik) − Fi(x∗) 2,

C = 2n ,

ρ = 1, n

D1 = D2 = 0.

F.2.2 Analysis of SAGA-SGDA in the Quasi-Strongly Monotone Case Applying Theorem 2.2 and Corollary 2.3 with M = 4n, we get the following results. Theorem F.11. Let F be µ-quasi strongly monotone, Assumptions 4.1, 4.2 hold, and 0 < γ ≤ 1/6 .

45

Then for all k ≥ 0 the iterates produced by SAGA-SGDA satisfy

E xk − x∗ 2 ≤ (1 − min {γµ, 1/2n})k V0,

(58)

where V0 = x0 − x∗ 2 + 4nγ2σ02.

Corollary F.12. Let the assumptions of Theorem F.11 hold. Then, for γ = 1/6

have

E[ xK − x∗ 2] ≤ V0 exp − min µ , 1 K . 6 2n

and any K ≥ 0 we

F.2.3 Analysis of SAGA-SGDA in the Monotone Case Next, using Theorem 2.5, we establish the convergence of SAGA-SGDA in the monotone case.

Theorem F.13. Let F be monotone, -star-cocoercive and Assumptions 2.1, 2.4, 4.1, 4.2 hold. Assume
that γ ≤ 1/6 . Then for GapC(z) from (10) and for all K ≥ 0 the iterates produced by SAGA-SGDA satisfy

E GapC

1 K xk K
k=1

≤ 3 maxu∈C x0 − u 2 + 8γ 2Ω2C + 12 +

2γK

K

x0 − x∗,0 2 K

+ 4 + 12 +

γ 2γσ02 + 9γ max F (x∗) 2.

pK

x∗ ∈X ∗

Applying Corollary D.4, we get the rate of convergence to the exact solution.

Corollary F.14. Let the assumptions of Theorem F.13 hold. Then ∀K > 0 one can choose γ as

γ = min

1 , 1 , Ω√0,C ,

(59)

12 + 2n G∗ K

This choice of γ implies

E GapC

1 K xk K
k=1

 ( + )(Ω20,C + Ω20) +
= O K

 n Ω20,C + Ω2C Ω0,C G∗
+ √ . K

Proof. Since σ0 for SAGA-SGDA and L-SVRGDA are the same, the proof of this corollary is identical to the one for Corollary F.7.

F.3 Discussion of the Results in the Monotone Case

Among the papers mentioned in the related work on variance-reduced methods (see Section ??), only

Alacaoglu and Malitsky [2021], Carmon et al. [2019], Alacaoglu et al. [2021], Tominin et al. [2021],

Luo et al. [2021] consider monotone (convex-concave) and Lipschitz (smooth) VIPs (min-max problems)

without assuming strong monotonicity (strong-convexity-strong-concavity) of the problem. In this case,
√
Alacaoglu and Malitsky [2021] derive O n + KnL convergence rate (neglecting the dependence on the

quantities like Ω20,C = maxu∈C x0 − u 2), which is optimal for the considered setting [Han et al., 2021]. Under additional assumptions a similar rate is derived in Carmon et al. [2019]. Tominin et al. [2021], Luo

et al. [2021] also achieve this rate but using Catalyst. Finally, Alacaoglu et al. [2021] derive O

n

+

nL K

,

which is worse than the one from Alacaoglu and Malitsky [2021].

√

Our results for monotone and star-cocoercive regularized VIPs give O nK + + √GK∗ rate, which is

√
typically worse than O n + KnL rate from Alacaoglu and Malitsky [2021] due to the relation between

46

cocoercivity constants and Lipschitz constants (even when R(x) ≡ 0, i.e., G∗ = 0). However, in general, it is possible that star-cocoercivity holds, while Lipschitzness does not [Loizou et al., 2021]. Moreover, we emphasize here that Alacaoglu and Malitsky [2021] and other works do not consider SGDA as the basis for their methods. To the best of our knowledge, our results are the ﬁrst ones for variance-reduced SGDA-type methods derived in the monotone case without assuming (quasi-)strong monotonicity.
47

G Distributed SGDA with Compression: Missing Proofs and Details
In this section, we provide missing proofs and details for Section 5.

G.1 QSGDA
In this section (and in the one about DIANA-SGDA), we assume that each Fi has an expectation form: Fi(x) = Eξi∼Di [Fξi (x)].

Algorithm 4 QSGDA: Quantized Stochastic Gradient Descent-Ascent

1: Input: starting point x0 ∈ Rd, stepsize γ > 0, number of steps K

2: for k = 0 to K − 1 do

3: Broadcast xk to all workers

4: for i = 1, . . . , n in parallel do

5:

Compute gik and send Q(gik) to the server

6: end for

7:

gk

=

1 n

n i=1

Q(gik

)

8: xk+1 = proxγR xk − γgk

9: end for

G.1.1 Proof of Proposition 5.3

Proposition G.1 (Proposition 5.3). Let F be -star-cocoercive and Assumptions 4.1, 5.2 hold. Then, QSGDA with quantization (17) satisﬁes Assumption 2.1 with

A = 32 + 92ωn , D1 = 3(1 + 3ω)nσ2 + 9ωζ∗2 , σk2 = 0, B = 0, C = 0, ρ = 1, D2 = 0,

where σ2 = n1

n i=1

σi2

and

ζ∗2

=

1 n

maxx∗∈X∗

n i=1

Fi(x∗) 2 .

n
Proof. Since gk = n1 Q gik , Q g1k
i=1
are independent for ﬁxed xk, we have

, . . . , Q gnk

are

independent

for

ﬁxed

g1k

,

.

.

.

,

g

k n

,

and

g1k

,

.

.

.

,

g

k n

Ek gk − F (x∗,k) 2

 1n

2

= Ek 

Q gik − F (x∗,k) 

n i=1

 1n

2

= Ek 

Q gik − gik + gik − Fi(xk) + F (xk) − F (x∗,k) 

n i=1

 1n

2

 1n

2

≤ 3Ek 

[Q gik − gik]  + 3Ek 

[gik − Fi(xk)] 

n i=1

n i=1

+3 F (xk) − F (x∗,k) 2

3n

k

k2

3n

k

k2

= n2 Ek Q gi − gi + n2 Ek gi − Fi(x )

i=1

i=1

+3 F (xk) − F (x∗,k) 2 .

48

Next, we use Assumption 5.2, σ2 = n1

n i=1

σi2,

and

the

deﬁnition

of

quantization

(17)

and

get

Ek gk − F (x∗,k) 2

≤ 3nω2 n Ek gik 2 + 3nσ2 + 3 F (xk) − F (x∗,k) 2
i=1

≤ 3nω2 n Ek gik − Fi(xk) + Fi(xk) − Fi(x∗,k) + Fi(x∗,k) 2
i=1

+ 3σ2 + 3 F (xk) − F (x∗,k) 2 n

≤ 9nω2 n Ek gik − Fi(xk) 2 + 9nω2 n Ek Fi(xk) − Fi(x∗,k) 2

i=1

i=1

9ω n + n2 Ek
i=1

Fi(x∗,k) 2 + 3nσ2 + 3 F (xk) − F (x∗,k) 2

(1≤8) 9nω2 n Ek Fi(xk) − Fi(x∗,k) 2 + 3 F (xk) − F (x∗,k) 2
i=1

9ω n + n2 Ek
i=1

Fi(x∗,k) 2 + 3(1 +n3ω)σ2 .

Star-cocoercivity of F and Assumption 4.1 give

Ek gk − F (x∗,k) 2 ≤ ≤

3 + 9ω n

F (xk) − F (x∗,k), xk − x∗,k

9ω n + n2 Ek
i=1

Fi(x∗,k) 2 + 3(1 +n3ω)σ2

3 + 9ω n

F (xk) − F (x∗,k), xk − x∗,k

+ 9ω max n F (x∗) 2 + 3(1 + 3ω)σ2 .

n2 x∗∈X∗

i

n

i=1

G.1.2 Analysis of QSGDA in the Quasi-Strongly Monotone Case Applying Theorem 2.2 and Corollary 2.3, we get the following results.

Theorem G.2. Let F be µ-quasi strongly monotone, -star-cocoercive, Assumptions

and 1

0<γ≤

.

3 + 9nω

Then, for all k ≥ 0 the iterates produced by QSGDA satisfy

4.1, 5.2 hold,

E xk − x∗ 2 ≤ (1 − γµ)k x0 − x∗ 2 + γ 3(1 + 3ω)σ2 + 9ωζ∗2 . nµ

Corollary G.3. Let the assumptions of Theorem G.2 hold. Then, for any K ≥ 0 one can choose

49

{γk}k≥0 as follows:

if K ≤ 1 · 3 + 9ω ,

µ

n

if K > 1 · 3 + 9ω

µ

n

and k < k0,

−1
γk = 3 + 9ω , n
−1
γk = 3 + 9ω , n

if K > 1 · 3 + 9ω

µ

n

and k ≥ k0,

γk =

2,

(6 + 18ω /n + µ(k − k0))

where k0 = K/2 . For this choice of γk the following inequality holds:

E[ xK − x∗,K 2] ≤ 32(3 + 9ω /n) x0 − x∗,0 2 exp −

µ

K

µ

(3 + 9ω /n)

+ 36 · 3(1 + 3ω)σ2 + 9ωζ∗2 .

µ2K

n

G.1.3 Analysis of QSGDA in the Monotone Case Next, using Theorem 2.5, we establish the convergence of QSGDA in the monotone case.

Theorem G.4. Let F be monotone, -star-cocoercive and Assumptions 2.1, 2.4, 4.1, 5.2 hold. Assume
−1
that γ ≤ 3 + 9nω . Then for GapC(z) from (10) and for all K ≥ 0 the iterates produced by QSGDA satisfy

E GapC

1 K xk K
k=1

≤ 3 maxu∈C x0 − u 2 + 8γ 2Ω2C + 7 + 18ω

2γK

K

n

x0 − x∗,0 2 ·
K

+γ 2 + γ +9γ max
x∗ ∈X ∗

7 + 18ω n
F (x∗) 2

· 3(1 + 3ω)σ2 + 9ωζ∗2 n

Applying Corollary D.4, we get the rate of convergence to the exact solution.

Corollary G.5. Let the assumptions of Theorem G.4 hold. Then ∀K > 0 one can choose γ as

√

γ = min

1,

Ω0,C n

, Ω√0,C .

7 + 18nω 3K(1 + 3ω)σ2 + 9Kωζ∗2 G∗ K

This choice of γ implies

E GapC

1 K xk K
k=1

=O

+ ω /n (Ω20,C + Ω20) + Ω2C

√

√

√

Ω0,C(σ 1 + ω + G∗ n + ζ∗ ω)

+

√

.

K

nK

G.2 DIANA-SGDA
G.2.1 Proof of Proposition 5.4
The following result follows from Lemmas 1 and 2 from Horv´ath et al. [2019]. It holds in our settings as well, since it does not rely on the exact form of Fi(xk).

50

Algorithm 5 DIANA-SGDA: DIANA Stochastic Gradient Descent-Ascent Mishchenko et al. [2019], Horv´ath et al. [2019]

1:

Input:

starting

points

x0

,

h01

,

.

.

.

,

h

0 n

∈ Rd,

h0

=

1 n

steps K

2: for k = 0 to K − 1 do

3: Broadcast xk to all workers

4: for i = 1, . . . , n in parallel do

5:

Compute gik and ∆ki = gik − hki

6:

Send Q(∆ki ) to the server

7:

hki +1 = hki + αQ(∆ki )

8: end for n n

9:

gk

=

hk

+

1 n

Q(∆ki )

=

1 n

(hki + Q(∆ki ))

i=1

i=1

10: xk+1 = proxγR xk − γgk

n

n

11:

hk+1 = hk + α n1

Q(∆ki )

=

1 n

hki

i=1

i=1

12: end for

n i=1

h0i

,

stepsizes

γ, α

>

0,

number

of

Lemma G.6 (Lemmas 1 and 2 from Horv´ath et al. [2019]). Let Assumptions 4.2, 5.2 hold. Suppose that α ≤ 1/(1+ω). Then, for all k ≥ 0 DIANA-SGDA satisﬁes

Ek gk Ek gk − F (x∗) 2
Ek σk2+1

= F (xk),
≤ 1 + 2nω n1 n Fi(xk) − Fi(x∗) 2 + 2ωnσk2 + (1 +nω)σ2 ,
i=1
≤ (1 − α)σk2 + αn n Fi(xk) − Fi(x∗) 2 + ασ2,
i=1

n

where

σk2

=

1 n

hki − Fi(x∗)

2

and

σ2

=

1 n

i=1

n i=1

σi2.

The lemma above implies that Assumption 2.1 is satisﬁed with certain parameters.

Proposition G.7 (Proposition 5.4). Let Assumptions 4.1, 4.2, 5.2 hold.

Suppose

that

α

≤

1 1+ω

.

Then,

DIANA-SGDA

with

quantization

(17)

satisﬁes

Assumption

2.1

with

σk2

=

1 n

n i=1

hki − Fi(x∗) 2

and

A= 1+ω 2n

,

B = 2ω ,

(1 + ω)σ2

D1 =

,

C=α ,

ρ = α,

D2 = ασ2.

n

n

2

Proof. To get the result, one needs to apply Assumption 4.1 to estimate n1 Lemma G.6.

n i=1

Fi(xk) − Fi(x∗) 2 from

G.2.2 Analysis of DIANA-SGDA in the Quasi-Strongly Monotone Case Applying Theorem 2.2 and Corollary 2.3 with M = α4ωn , we get the following results.
Theorem G.8. Let F be µ-quasi strongly monotone, Assumptions 4.1, 4.2, 5.2 hold, α ≤ 1/(1+ω), and 0<γ≤ 1 . 1 + 6nω

51

Then, for all k ≥ 0 the iterates produced by DIANA-SGDA satisfy

E

xk − x∗ 2

≤

1 − min

α γµ,

2

k

γ2σ2(1 + 5ω)

E[V0]

+

n

·

min

{γµ,

, α/2}

where V0 = x0 − x∗ 2 + 4ωγ2σ02/αn.

Corollary G.9. Let the assumptions of Theorem 5.4 hold. Then, for any K ≥ 0 one can choose α = 1/(1+ω) and {γk}k≥0 as follows:

if K ≤ h , µ
h if K > and k < k0,
µ h if K > and k ≥ k0, µ

γk = 1 , h

γk = 1 , h

2

γk

=

2h

+

µ(k

−

, k0)

where h = max holds:

1 + 6nω

, 2µ(1 + ω) , k0 = K/2 . For this choice of γk the following inequality

E[ xK − x∗,K 2] ≤ 32 max

1 + 6nω µ

, 2(1 + ω) V0 exp − min

36(1 + 5ω)σ2 + µ2nK .

µ ,1 K (1 + 6nω ) 1 + ω

G.2.3 Analysis of DIANA-SGDA in the Monotone Case Next, using Theorem 2.5, we establish the convergence of DIANA-SGDA in the monotone case.

Theorem G.10. Let F be monotone, Assume that

-star-cocoercive and Assumptions 2.1, 2.4, 0<γ≤ 1 .
1 + 4nω

4.1, 4.2, 5.2 hold.

Then for GapC(z) from (10) and for all K ≥ 0 the iterates produced by DIANA-SGDA satisfy

E GapC

1 K xk K
k=1

≤ 3 maxu∈C x0 − u 2 + 8γ 2Ω2C + 2 + 12ω +

2γK

K

n

+ 4 + γ 2 + 12ω + n

γBσ02 ρK

x0 − x∗,0 2 K

+γ 2 + γ 2 + 12ω + n
+9γ max F (x∗) 2.
x∗ ∈X ∗

(1 + 5ω)σ2 n

Applying Corollary D.4, we get the rate of convergence to the exact solution.

Corollary G.11. Let the assumptions of Theorem G.10 hold. Then ∀K > 0 one can choose γ as


 γ = min


+ 2 + 12ω n

−1 √

αn

,

,

2ω σ



Ω0,C

,

Ω√0,C

 ,

K(1+3ω)/n G∗ K 

52

This choice of γ implies that E GapC

1 K

K k=1

xk

equals

 (+
O

+ ω /n)(Ω20,C + Ω20) + Ω2C Ω20,C

√ ω Ω0,C(

K + √αnK +



(1+ω)σ2/n + G∗)

√

.

K

Proof. The proof follows from the next upper bound σ02 for σ02 with initialization h0i = Fi(x0)

σ2 = 1 n F (x0) − F (x∗) 2

0

n

i

i

i=1

≤ F (x0) − F (x∗), x0 − x∗

≤ F (x0) − F (x∗) · x0 − x∗

≤

x0 − x∗ 2 ≤ max x0 − u 2 ≤ Ω20,C.

u∈C

Next, applying Corollary D.4 with σ0 := Ω0,C, we get the result.

G.3 VR-DIANA-SGDA

In

this

section,

we

assume

that

each

Fi

has

a

ﬁnite-sum

form:

Fi(x)

=

1 m

m j=1

Fij

(x).

Algorithm 6 VR-DIANA-SGDA: VR-DIANA Stochastic Gradient Descent-Ascent Horv´ath et al. [2019]

n

1:

Input:

starting

points

x

0

,

h01

,

.

.

.

,

h

0 n

∈

Rd,

h0

=

1 n

h0i , probability p ∈ (0, 1] stepsizes

i=1

γ, α > 0, number of steps K,

2: for k = 0 to K − 1 do

3: Broadcast xk to all workers

4: for i = 1, . . . , n in parallel do

5:

Draw a fresh sample jik from the uniform distribution on [m] and compute gik =

Fijk (xk) − Fijk (wik) + Fi(wik)

i

i

6:

wk+1 = xk, with probability p,

i

wik, with probability 1 − p,

7:

∆ki = gik − hki

8:

Send Q(∆ki ) to the server

9:

hki +1 = hki + αQ(∆ki )

10: end for n n

11:

gk

=

hk

+

1 n

Q(∆ki )

=

1 n

(hki + Q(∆ki ))

i=1

i=1

12: xk+1 = proxγR xk − γgk

n

n

13:

hk+1 = hk + α n1

Q(∆ki )

=

1 n

hki

i=1

i=1

14: end for

G.3.1 Proof of Proposition 5.6 Lemma G.12 (Modiﬁcation of Lemmas 3 and 7 from Horv´ath et al. [2019]). Let F be -star-cocoercive

53

and Assumptions 4.1, 4.2, 5.5 hold. Then for all k ≥ 0 VR-DIANA-SGDA satisﬁes

Ek gk Ek gk − F (x∗)

= F (xk),

≤ + 2 + 2ω( + )

n

n

F (xk) − F (x∗), xk − x∗ + 2(ωn+ 1) σk2,

where σ2 = Hk + Dk with Hk = n hk − Fi(x∗) 2 and Dk = n m Fij (wk) − Fij (x∗) 2.

k

n

nm

i

i

i=1

i=1 j=1

Proof. First of all, we derive unbiasedness:

E gk

1n

k

k

k

= n E Q(gi − hi ) + hi

i=1

1n

k

k

k

= n E gi − hi + hi

i=1

= 1 n Fi(xk) = F (xk). n i=1

By deﬁnition of the variance we get

EQ gk − F (x∗) 2 = EQ gk − F (x∗) 2 + EQ gk − EQ gk 2 .

T1

T2

Next, we derive the upper bounds for terms T1 and T2 separately. For T2 we use unbiasedness of quantization and independence of workers:

 1n

2

T2 = EQ 

Q(gik − hki ) − (gik − hki ) 

n i=1

1n = n2 EQ
i=1

Q(gik − hki ) − (gik − hki ) 2

(17) ω n ≤ n2
i=1

gik − hki 2 .

Taking Ek[·] from the both sides of the above inequality, we derive

ωn Ek [T2] ≤ n2 Ek
i=1

gik − hki 2

ωn = n2
i=1

Ek gik − hki 2 + Ek

gik − hki − Ek gik − hki 2

ωn = n2
i=1

Fi(xk) − hki 2 + Ek

gik − Fi(xk) 2

ωn = n2
i=1

Fi(xk) − hki 2 + Ek

2

Fijk (xk) − Fijk (wik) − Ek Fijk (xk) − Fijk (wik)

i

i

i

i

ωn ≤ n2
i=1

Fi(xk) − hki 2 + Ek

2

Fijk (xk) − Fijk (wik)

i

i

2ω n ≤ n2
i=1

hki − Fi(x ) 2 + Fi(xk) − Fi(x ) 2

2ω n

k2

k2

+ n2

Ek Fijk (wi ) − Fijk (x ) + Ek Fijk (x ) − Fijk (x )

.

i

i

i

i

i=1

Since jik is sampled uniformly at random from [m], we have

2ω n

k

2

k

2

Ek [T2]

≤

n2

hi − Fi(x ) + Fi(x ) − Fi(x )

i=1

2ω n m

+ mn2

Ek

i=1 j=1

Fij (wik) − Fij (x ) 2 + Ek

Fij (xk) − Fij (x ) 2

(16),(24)
≤

2ω Hk + 2ω Dk + 2ω( + ) F (xk) − F (x∗), xk − x∗ .

n2

mn2

n

54

In last line, we also use the deﬁnitions of Hk, Dk. For T1 we use deﬁnition of gk:

T1 =

1n

k

k

k

2 ∗

n EQ Q(gi − hi ) + hi − F (x ) =

i=1

1n k

2 ∗

n gi − F (x ).

i=1

Next, we estimate Ek[T1] similarly to Ek[T2]:

 1n

2 1 n

2

 1n

2

Ek [T1] = Ek 

gik − F (x∗)  =

E gik − F (x∗) + Ek 

gik − E gik 

n i=1

n i=1

n i=1 2

= F (xk) − F (x∗) 2 + n12 n Ek
i=1

gik − Fi(xk) 2

(4)
≤ F (xk) − F (x∗), xk − x∗

1n + n2 E
i=1

2

Fijk (xk) − Fijk (wik) − Ek Fijk (xk) − Fijk (wik)

i

i

i

i

≤ F (xk) − F (x∗), xk − x∗ + n12 n Ek
i=1

2

Fijk (xk) − Fijk (wik)

i

i

= F (xk) − F (x∗), xk − x∗ + m1n2 n m Fij (xk) − Fij (wik) 2
i=1 j=1

≤ F (xk) − F (x∗), xk − x∗ + 2 n m mn2
i=1 j=1

Fij (wik) − Fij (x ) 2 + Fij (xk) − Fij (x ) 2

(24)
≤

+2

F (xk) − F (x∗), xk − x∗ + 2 Dk.

n

mn2

Finally, summing E [T1] and E [T2] we get

E gk − F (x∗) 2 = E [T1 + T2]

≤ + 2 F (xk) − F (x∗), xk − x∗ + 2 Dk

n

mn2

+ 2ω Hk + 2ω Dk + 2ω( + ) F (xk) − F (x∗), xk − x∗

n2

mn2

n

≤ + 2 + 2ω( + ) F (xk) − F (x∗), xk − x∗ + 2ω Hk + 2(ω + 1) Dk,

n

n

n2

mn2

which

concludes

the

proof

since

σk2

=

Hk n

+

nDmk .

Lemma G.13 (Modiﬁcation of Lemmas 5 and 6 from Horv´ath et al. [2019]). Let F be -star-cocoercive

and Assumptions 4.1, 4.2, 5.5 hold. Suppose that α ≤ min

p3 ;

1 1+ω

. Then for all k ≥ 0 VR-DIANA-

SGDA satisﬁes

Ek σk2+1 ≤ (1 − α)σk2 + p + 2α( + ) F (xk) − F (x∗), xk − x∗ ,

where σ2 = Hk + Dk with Hk = n hk − Fi(x∗) 2 and Dk = n m Fij (wk) − Fij (x∗) 2.

k

n

nm

i

i

i=1

i=1 j=1

55

Proof. We start with considering Hk+1:

Ek H k+1

n

= Ek

hki +1 − Fi(x ) 2

i=1

n

n

=

hki − Fi(x ) 2 + Ek 2 αQ(gik − hki ), hki − Fi(x ) + α2 Q(gik − hki ) 2

i=1

i=1

(1≤7) Hk + n Ek 2α gik − hki , hki − Fi(x ) + α2(ω + 1) gik − hki 2 .

i=1

Since α ≤ 1/(ω+1), we have

Ek H k+1

n

≤ Hk + Ek

α gik − hki , gik + hki − 2Fi(x )

i=1

n

= Hk + Ek

α gik − Fi(x ) + Fi(x ) − hki , gik − Fi(x ) + hki − Fi(x )

i=1

n

= Hk + Ek

α gik − Fi(x ) 2 − hki − Fi(x ) 2

i=1

n

= Hk(1 − α) + Ek

α gik − Fi(x ) 2

i=1

n

≤ Hk(1 − α) +

2αEk gik − Fi(xk) 2 + 2α Fi(xk) − Fi(x ) 2

i=1

n

2

= Hk(1 − α) + Ek 2α Fijk (xk) − Fijk (wik) − Ek Fijk (xk) − Fijk (wik)

i

i

i

i

i=1

n

+2α

Fi(xk) − Fi(x ) 2

i=1

n k

k k2

k

2

≤ H (1 − α) +

Ek 2α Fijk (x ) − Fijk (wi ) + 2α Fi(x ) − Fi(x )

i

i

i=1

k

2α n m

k

2

k

2

≤ H (1 − α) + m

Fij (x ) − Fij (x ) + Fij (wi ) − Fij (x )

i=1 j=1

(16),(24)
≤

n
+2α

Fi(xk) − Fi(x ) 22

i=1

Hk(1 − α) + 2α n m m i=1 j=1

Fij (wikj ) − Fij (x ) 22

+2αn( + ) F (xk) − F (x∗), xk − x∗ = Hk(1 − α) + 2α Dk + 2αn( + ) F (xk) − F (x∗), xk − x∗ .
m

Next, we consider Dk+1

n
Ek Dk+1 =

m
Ek

Fij (wik+1) − Fij (x ) 2

i=1 j=1

nm
= (1 − p) Fij (wikj ) − Fij (x ) 22 + p Fij (xk) − Fij (x ) 22
i=1 j=1

(24)
≤ Dk (1 − p) + nmp F (xk) − F (x∗), xk − x∗ .

56

It remains put the upper bounds on Dk+1, Hk+1 together and use the deﬁnition of σk2+1:

Ek σk2+1 = Ek Hnk+1 + Ek nDmk+1

≤ (1 − α) Hk + (1 + 2α − p) Dk + p + 2α( + )

n

nm

With

α

≤

p 3

we

get

−p

≤

−3α,

implying

F (xk) − F (x∗), xk − x∗

Ek σk2+1 ≤ (1 − α) Hnk + (1 − α) nDmk + p + 2α( + ) F (xk) − F (x∗), xk − x∗ = (1 − α)σk2 + p + 2α( + ) F (xk) − F (x∗), xk − x∗ .

The above two lemmas imply that Assumption 2.1 is satisﬁed with certain parameters.

Proposition G.14 (Proposition 5.6). Let F be -star-cocoercive and Assumptions 4.1, 4.2, 5.5 hold.

Suppose that α ≤ min

p3 ;

1 1+ω

. Then, VR-DIANA-SGDA satisﬁes Assumption 2.1 with

A = + + ω( + ) , B = 2(ω + 1) ,

2n

n

n

σ2 = 1 n kn
i=1

hki − Fi(x∗) 2 + n1m n m
i=1 j=1

Fij (wik) − Fij (x∗) 2 ,

pl

p1

C = 2 + α( + ) , ρ = α ≤ min 3 ; 1 + ω , D1 = D2 = 0.

G.3.2 Analysis of VR-DIANA-SGDA in the Quasi-Strongly Monotone Case Applying Theorem 2.2 and Corollary 2.3 with M = 4(ωn+α1) , we get the following results.

Theorem G.15. Let F be µ-quasi strongly monotone, -star-cocoercive and Assumptions 4.1, 4.2, 5.5

hold. Suppose that α ≤ min

p3 ;

1 1+ω

and

0<γ≤

−1

+ 10(ω + 1)( + ) + 4(ω + 1)pl .

n

αn

Then for all k ≥ 0 the iterates of VR-DIANA-SGDA satisfy

E xk − x∗ 2 ≤ (1 − min {γµ, 1/αn})k V0,

where V0 =

x0 − x∗

2

+

4(ω+1)γ nα

2

σ02

.

Corollary G.16. Let the assumptions of Theorem G.15 hold. Then, for p = m1 , α = min

31m ,

1 1+ω

,

−1

γ = + 10(ω + 1)( + ) + 4(ω + 1) max{3m, 1 + ω}

n

nm

57

and any K ≥ 0 we have E[ xk − x∗ 2] ≤ V0 exp − min

µ , 1, 1 K . + 10(ω+n1)( + ) + 4(ω+1) manxm{3m,1+ω} 6m 2(1 + ω)

G.3.3 Analysis of VR-DIANA-SGDA in the Monotone Case

Next, using Theorem 2.5, we establish the convergence of VR-DIANA-SGDA in the monotone case.

Theorem G.17. Assume that

Let F be monotone, -star-cocoercive and Assumptions 2.1, 2.4,

0<γ≤

−1

+ 6(ω + 1)( + ) + 2(ω + 1)pl

n

αn

4.1, 4.2, 5.5 hold.

and α = min

p3 ,

1 1+ω

.

Then for GapC(z) from (10) and for all K ≥ 0 the iterates produced by

VR-DIANA-SGDA satisfy

E GapC

1 K xk K
k=1

≤ 3 maxu∈C x0 − u 2 + 8γ 2Ω2C

2γK

K

+ 3 + 12(ω + 1)( + ) + 8(ω + 1)pl

n

αn

x0 − x∗,0 2 ·
K

+ 4 + γ 3 + 12(ω + 1)( + ) + 8(ω + 1)pl

n

αn

+9γ max F (x∗) 2.
x∗ ∈X ∗

γBσ02 ρK

Applying Corollary D.4, we get the rate of convergence to the exact solution.

Corollary G.18. Let the assumptions of Theorem G.17 hold. Then ∀K > 0 one can choose p = m1 ,

α = min

31m ,

1 1+ω

and γ as

γ = min

1,

3 + 12(ω+n1)( + ) + 8(ω+1) mamx{n3m,1+ω}

√

Ω0,C n

, Ω√0,C .

Ω0,C 2 max{3m, 1 + ω}(ω + 1)( + ) G∗ K

This choice of α and γ implies

E GapC

1 K xk K
k=1

=O

+ (ω+1)( + )/n + (ω+1) max{m,ω} /mn (Ω20,C + Ω20) + Ω2C K

Ω20,C max{m, ω}(ω + 1)( + ) Ω0,CG∗

+

√

+√

.

nK

K

58

Proof. The proof follows from the next upper bound σ02 for σ02 with initialization h0i = Fi(x0) and wi = x0

σ2 = 1 n m F (x0) − F (x∗) 2 + 1 n F (x0) − F (x∗) 2

0

nm

ij

ij

n

i

i

i=1 j=1

i=1

≤ ( + ) F (x0) − F (x∗), x0 − x∗

≤ ( + ) F (x0) − F (x∗) · x0 − x∗

≤ ( + ) x0 − x∗ 2 ≤ ( + ) max x0 − u 2 ≤ ( + ) Ω20,C.
u∈C

Next, applying Corollary D.4 with σ0 := ( + ) Ω0,C, we get the result.

G.4 Discussion of the Results in the Monotone Case

Beznosikov et al. [2021b] also consider monotone case and derive the following rate for MASHA1 (neglecting the dependence on Lipschitz parameters and the quantities like Ω20,C = maxu∈C x0 − u 2): O (m + ω)(1 + ω/n) K1 . In general, due to the term proportional to 1/√K and due to the relation

between (star-)cocoercivity co√nstants and Lipschitz constants our rate

O (1n+Kω) + (1+ω)mmnaKx{m,ω} +

max{√m,ω}(1+ω) + √G∗

nK

K

our rate is worse than the one from Beznosikov

et al. [2021b] (even when R(x) ≡ 0, i.e., G∗ = 0). However, when the diﬀerence between cocoercivity and Lipschitz constants is not signiﬁcant, and m, n or ω are suﬃciently large, our result might be better. Moreover, we emphasize here that Beznosikov et al. [2021b] do not consider SGDA as the basis for their methods. To the best of our knowledge, our results are the ﬁrst ones for distributed SGDA-type methods with compression derived in the monotone case without assuming (quasi-)strong monotonicity.

59

H Coordinate SGDA
In this section, we focus on the coordinate versions of SGDA. To denote i-th component of the vector x we use [x]i. Vectors e1, . . . , ed ∈ Rd form a standard basis in Rd.
H.1 CSGDA
Algorithm 7 CSGDA: Coordinate Stochastic Gradient Descent-Ascent 1: Input: starting point x0 ∈ Rd, stepsize γ > 0, number of steps K 2: for k = 0 to K − 1 do 3: Sample uniformly at random j ∈ [d] 4: gk = dej[F (xk)]j 5: xk+1 = proxγR xk − γgk 6: end for

H.1.1 CSGDA Fits Assumption 2.1 Proposition H.1. Let F be -star-cocoercive. Then, CSGDA satisﬁes Assumption 2.1 with
A = d , D1 = 2d max F (x∗) 2 , σk2 = 0, B = 0, C = 0, ρ = 1, D2 = 0.
x∗∈X ∗

Proof. First of all, for all a ∈ Rd and for random index j uniformly distributed on [d] we have

Ej [ ej [a]j 2] = d1

di=1[a]2j

=

1 d

a

2.

Using this and gk = dej[F (xk)]j, we derive

Ek gk − F (x∗,k) 2

= Ek dej [F (xk) − F (x∗,k)]j + dej [F (x∗,k)]j − F (x∗,k) 2

≤ 2Ek dej [F (xk) − F (x∗,k)]j 2 + 2Ek dej [F (x∗,k)]j − F (x∗,k) 2

= 2d F (xk) − F (x∗,k) 2 + 2Ek dej [F (x∗,k)]j − Ek[dej [F (x∗,k)]j ] 2

≤ 2d F (xk) − F (x∗,k) 2 + 2Ek dej [F (x∗,k)]j 2

= 2d F (xk) − F (x∗,k) 2 + 2d F (x∗,k) 2.

(60)

Finally, the star-cocoercivity of F implies

Ek gk − F (x∗,k) 2

≤ 2d F (xk) − F (x∗,k), xk − x∗ + 2d F (x∗,k) 2 ≤ 2d F (xk) − F (x∗,k), xk − x∗ + 2d max F (x∗) 2 .
x∗∈X ∗

H.1.2 Analysis of CSGDA in the Quasi-Strongly Monotone Case Applying Theorem 2.2 and Corollary 2.3, we get the following results.

Theorem H.2. Let F be µ-quasi strongly monotone and -star-cocoercive, 0 < γ ≤ 1/2d . Then for

all k ≥ 0

E xk − x∗ 2 ≤ (1 − γµ)k x0 − x∗,0 2 + 2γd · max F (x∗) 2 . µ x∗∈X∗

Corollary H.3. Let the assumptions of Theorem H.2 hold. Then, for any K ≥ 0 one can choose

60

{γk}k≥0 as follows:

if K > 2d µ
if K > 2d µ

if K ≤ 2d , µ
and k < k0, and k ≥ k0,

1 γk = 2d ,
1 γk = 2d ,
γk = µ(4d

2, + µ(k − k0))

where k0 = K/2 . For this choice of γk the following inequality holds:

E[VK ] ≤ 64d µ

x0 − x∗,0 2 exp

µK −

2d

72d

+

µ2K

· max
x∗∈X ∗

F (x∗) 2 .

H.1.3 Analysis of CSGDA in the Monotone Case Next, using Theorem 2.5, we establish the convergence of CSGDA in the monotone case.

Theorem H.4. Let F be monotone, -star-cocoercive and Assumptions 2.1, 2.4 hold. Assume that γ ≤ 1/2d . Then for GapC(z) from (10) and for all K ≥ 0 the iterates produced by CSGDA satisfy

E GapC

1 K xk K
k=1

≤ 3 maxu∈C x0 − u 2 + 8γ 2Ω2C + 5d x0 − x∗,0 2

2γK

K

K

+20γd · max F (x∗) 2 .
x∗∈X ∗

Applying Corollary D.4, we get the rate of convergence to the exact solution.

Corollary H.5. Let the assumptions of Theorem H.4 hold. Then ∀K > 0 one can choose γ as

This choice of γ implies

γ = min 1 , Ω√0,C . 5d G∗ 2dK

E GapC

1 K xk K
k=1

d (Ω20,C + Ω20) + Ω2C dΩ0,C G∗ Ω0,C G∗

=O

+

+√

.

K

K

K

H.2 SEGA-SGDA
In this section, we consider a modiﬁcation of SEGA [Hanzely et al., 2018] – the linearly converging coordinate method for composite optimization problems working even for non-separable regularizers.
Algorithm 8 SEGA-SGDA: SEGA Stochastic Gradient Descent-Ascent Hanzely et al. [2018]
1: Input: starting point x0 ∈ Rd, stepsize γ > 0, number of steps K 2: Set h0 = 0 3: for k = 0 to K − 1 do 4: Sample uniformly at random j ∈ [d] 5: hk+1 = hk + ej([F (xk)]j − hkj ) 6: gk = dej([F (xk)]j − hkj ) + hk 7: xk+1 = proxγR xk − γgk 8: end for

61

H.2.1 SEGA-SGDA Fits Assumption 2.1
The following result from Hanzely et al. [2018] does not rely on the fact that F (x) is the gradient of some function. Therefore, it holds in our settings as well.

Lemma H.6 (Lemmas A.3 and A.4 from Hanzely et al. [2018]). Let Assumption 4.2 hold. Then for all k ≥ 0 SEGA-SGDA satisﬁes

Ek gk − F (x∗) 2 Ek σk2+1

≤ 2d F (xk) − F (x∗) 2 + 2dσk2, ≤ 1 − d1 σk2 + d1 F (xk) − F (x∗) 2,

where σk2 = hk − F (x∗) 2.

The lemma above implies that Assumption 2.1 is satisﬁed with certain parameters.

Proposition H.7. Let F be -star-cocoercive and Assumption 4.2 holds. Then, SEGA-SGDA satisﬁes Assumption 2.1 with σk2 = hk − F (x∗) 2 and
1 A = d , B = 2d, D1 = 0, C = 2d , ρ = d , D2 = 0.
Proof. The result follows from Lemma H.6 and star-cocoercivity of F .

H.2.2 Analysis of SEGA-SGDA in the Quasi-Strongly Monotone Case Applying Theorem 2.2 and Corollary 2.3 with M = 4d2, we get the following results.

Theorem H.8. Let F be µ-quasi strongly monotone, -star-cocoercive, Assumption 4.2 holds, and

0

<

γ

≤

1 6d

.

Then,

for

all

k

≥

0

the

iterates

produced

by

SEGA-SGDA

satisfy

E xk − x∗ 2 ≤ 1 − min γµ, 1 2d

k
· V0,

where V0 = x0 − x∗ 2 + 4d2γ2σ02.

Corollary

H.9.

Let the assumptions of Theorem H.8 hold.

Then, for γ

=

1 6d

and any K ≥ 0 we have

E[ xk − x∗ 2] ≤ V0 exp − min µ , 1 K . 6d 2d

H.2.3 Analysis of SEGA-SGDA in the Monotone Case Next, using Theorem 2.5, we establish the convergence of CSGDA in the monotone case.

Theorem H.10. Let F be monotone, -star-cocoercive and Assumptions 2.1, 2.4, 4.2 hold. Assume
that γ ≤ 1/6d . Then for GapC(z) from (10) and for all K ≥ 0 the iterates produced by SEGA-SGDA satisfy

E GapC

1 K xk K
k=1

≤ 3 maxu∈C x0 − u 2 + 8γ 2Ω2C + 13d · x0 − x∗,0 2

2γK

K

K

+ (4 + 13γd ) 2dγσ02 + 9γ · max

K

x∗ ∈X ∗

F (x∗) 2 .

Applying Corollary D.4, we get the rate of convergence to the exact solution.

62

Corollary H.11. Let the assumptions of Theorem H.10 hold. Then ∀K > 0 one can choose γ as

This choice of γ implies

γ = min 1 , √Ω0,C , Ω√0,C . 13d 2G∗d G∗ K

E GapC

1 K xk K
k=1

d (Ω20,C + Ω20) + Ω2C dΩ0,C G∗ Ω0,C G∗

=O

+

+√

.

K

K

K

Proof. The proof follows from the next upper bound σ02 for σ02 with initialization h0 = 0 σ02 = h0 − F (x∗) 2 = F (x∗) 2 ≤ G2∗.

H.3 Comparison with Related Work
The summary of rates in the (quasi-) strongly monotone case is provided in Table 3. First of all, our results are the ﬁrst convergence for solving regularized VIPs via coordinate methods. In particular, SEGA-SGDA is the ﬁrst linearly converging coordinate method for solving regularized VIPs. Next, when q = 2 in zoVIA from Sadiev et al. [2021], i.e., Euclidean proximal setup is used, our rate for SEGA-SGDA is better than the one derived for zoVIA in Sadiev et al. [2021] since ≤ L2/µ. Finally, zoscESVIA might have better rate, but it is based on EG and it uses approximation of each component of operator F at each iteration, which makes one iteration of the method costly.
In the monotone case, our result and the results from Sadiev et al. [2021] are comparable modulo the diﬀerence between star-cocoercivity and Lipschitz constants.

Table 3: Summary of the complexity results for zeroth-order methods with two-points feedback oracles
for solving (1). By complexity we mean the number of oracle calls required for the method to ﬁnd x such that E[ x − x∗ 2] ≤ ε. By default, operator F is assumed to be µ-strongly monotone and, as the
result, the solution is unique. Our results rely on µ-quasi strong monotonicity of F (3). Methods supporting R(x) ≡ 0 are highlighted with ∗. Our results are highlighted in green. Notation: q = the
parameter depending on the proximal setup, q = 2 in Euclidean case and q = +∞ in the 1-proximal setup; G∗ = maxx∗∈X∗ F (x∗) , which is zero when R(x) ≡ 0.

Method

Citation

Assumptions Complexity

zoscESVIA (1) [Sadiev et al., 2021] F is L-Lip.(2)

O d Lµ

zoVIA CSGDA ∗ SEGA-SGDA ∗

[Sadiev et al., 2021] This paper This paper

F is L-Lip.(2)
F is -cocoer. F is -cocoer.
As. 4.2

O d2/q Lµ22 O d µ + dµG2ε2∗
O d + dµ

(1) The method is based on Extragradient update rule. Moreover, at each step full
operator is approximated. (2) The problem is deﬁned on a bounded set.

63

