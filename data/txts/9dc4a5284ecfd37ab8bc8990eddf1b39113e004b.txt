The Source-Target Domain Mismatch Problem in Machine Translation
Jiajun Shen † Peng-Jen Chen † Matt Le† Junxian He•∗ Jiatao Gu† Myle Ott† Michael Auli† Marc’Aurelio Ranzato† †Facebook AI Research •Carnergie Mellon University
{jiajunshen,pipibjc,mattle,jgu,myleott,michaelauli,ranzato}@fb.com junxianh@cs.cmu.edu

arXiv:1909.13151v2 [cs.CL] 16 Jun 2020

Abstract
While we live in an increasingly interconnected world, different places still exhibit strikingly different cultures and many events we experience in our every day life pertain only to the speciﬁc place we live in. As a result, people often talk about different things in different parts of the world. In this work we study the effect of local context in machine translation and postulate that particularly in low resource settings this causes the domains of the source and target language to greatly mismatch, as the two languages are often spoken in further apart regions of the world with more distinctive cultural traits and unrelated local events. We ﬁrst formalize the concept of sourcetarget domain mismatch, propose a metric to quantify it, and provide empirical evidence corroborating our intuition that organic text produced by people speaking very different languages exhibits the most dramatic differences. We conclude with an empirical study of how source-target domain mismatch affects training of machine translation systems for low resource language pairs. In particular, we ﬁnd that it severely affects back-translation, but the degradation can be alleviated by combining back-translation with self-training and by increasing the relative amount of target side monolingual data.
1 Introduction
The use of language greatly varies with the geographic location (Firth, 1935; Johnstone, 2010). Even within places where people speak the same language (Britain, 2013), there is a lot of lexical variability due to change of style and topic distribution, particularly when considering content
∗ Work done while internship at the Facebook AI Research lab.
Equal contribution.

posted on social media, blogs and news outlets. For instance, while a primary topic of discussion between British sport fans is cricket, American sport fans are more likely to discuss other sports such as baseball (Leech and Fallon, 1992).
The effect of local context in the use of language is even more extreme when considering regions where different languages are spoken. Despite the increasingly interconnected world we live in, people in different places tend to talk about different things. There are several reasons for this, from cultural differences due to geographic separation and history, to the local nature of many events we experience in our every day life; e.g., the trafﬁc congestion in Taipei is not affected by a heavy snowfall in New York City.
This phenomenon has not only interesting socio-linguistic aspects but it has also strong implications in machine translation (Bernardini and Zanettin, 2004). In particular, machine translation of low-resource language pairs aims at automatically translating content in two languages that are often spoken in very distant geographic locations by people with rather different cultures. In machine learning terms and at a very high level of abstraction, this is akin to the problem of aligning two very high dimensional and sparsely populated point clouds. The learning problem is difﬁcult because not only very few correspondences are provided to the learner, but also because the distributions of points is rather different.
As of today, most machine translation research has been based on the often implicit assumption that content in the two languages is comparable. Sentences comprising the parallel dataset used for training are assumed to cover the same topic distribution, regardless of the originating language. Similarly, monolingual corpora are assumed to be comparable, i.e. to cover the same distribution of topics albeit in two different languages.
The major contribution of this work is to raise

awareness in the machine translation community that this assumption does not hold for the vast majority of language pairs, which are distant and lowresource, and for the vast majority of the content produced every day on the Internet by means of blogs, social platforms and news outlets.
In §3, we ﬁrst propose a formal deﬁnition of source-target domain mismatch (STDM). This abstraction precisely characterizes the problem and exposes the assumptions needed to formulate a practical deﬁnition of a metric, which we dub STDM score and describe in §4. The STDM score quantiﬁes the degree of domain mismatch between a set of parallel sentences originating in the source and target language. Empirically, this score indicates an overall larger mismatch for data originating in more distant language and for more organic content, like the one derived from social media data; see §4.2 for details. This suggests that applying methods proven to work well on most popular WMT benchmarks may generalize poorly to less constrained settings and low resource languages.
Therefore, we conclude by analyzing the consequences of STDM on low resource machine translation in §5. We surmise that STDM may negatively impact the effectiveness of backtranslation (Sennrich et al., 2015), which is de facto the best known approach to leverage monolingual data in low resource settings. In particular, even if the backward model was perfect, backtranslation may be less effective when there is considerable STDM, since the back-translated data is out-of-domain relative to the source domain from which we aim to translate.
To validate this conjecture, in §6 we work with a synthetic benchmark that enables us to precisely control the amount of STDM. We then assess the effectiveness of back-translation as a function of the amount of STDM, as well as other factors such as the amount of data available. We ﬁnd that backtranslation is sensitive to STDM, but this can be compensated by adding more target-side monolingual data and by combining back-translation with self-training (Yarowski, 1995). In §6.2 we conﬁrm our ﬁndings on two actual low resource language pairs, Nepali-English and English-Myanmar.
Our conclusion is that STDM is an intrinsic property of the translation task, particularly for distant languages and uncurated content. In these conditions, STDM can affect generalization of MT systems, but the degradation depends on several

factors, such as the amount of data originating in each language and the particular language pair.
2 Related Work
The observation that topic distributions and various kinds of lexical variabilities depend on the local context has been known and studied for a long time. For instance, Firth (1935) says “Most of the give-and-take of conversation in our everyday life is stereotyped and very narrowly conditioned by our particular type of culture”. In her seminal work, Johnstone (2010) analyzed the role of place in language, focusing on lexical variations within the same language, a subject further explored by Britain (2013). Some of these works were the basis for later studies that introduced computational models for how language changes with geographic location (Mei et al., 2006; Eisenstein et al., 2010).
Moving to cross-lingual analyses, there has been work at the intersection of linguistics and cognitive science (Pederson et al., 1998) showing how certain linguistic codings vary across languages, and how these affect how people form mental concepts. In the ﬁeld of topic modeling, there has been a new sub-ﬁeld emerging over the past 10 years focusing on modeling multilingual corpora (Mimno et al., 2009; Boyd-Graber and Blei, 2009; Gutierrez et al., 2016). However, only recently had researchers dropped assumptions on the use of parallel and comparable corpora (Hao and Paul, 2018; Yang et al., 2019). While some works do investigate issues related to STDM (Gutierrez et al., 2016), like how named entities receive a different distribution over words in different languages (Lin et al., 2018), none of these works have analyzed how the overall topic distribution of data originating in the source and target language differ.
In machine translation, researchers have often made an explicit assumption on the use of comparable corpora (Fung and Yee, 1998; Munteanu et al., 2004; Irvine and Callison-Burch, 2013), i.e. corpora in the two languages that roughly cover the same set of topics. Unfortunately, monolingual corpora are seldom comparable in practice. Leech and Fallon (1992) analyzes two comparable corpora, one in American English and the other in British English, and demonstrate differences that reﬂect the cultures of origin. Similarly, Bernardini and Zanettin (2004) observes that parallel datasets

built for machine translation exhibit strong biases in the selection of the original documents, making the text collection not quite comparable.
The non-comparable nature of machine translation datasets is even more striking when considering low resource language pairs, for which differences in local context and cultures are more pronounced. Recent studies (Søgaard et al., 2018; Neubig and Hu, 2018) have warned that removing the assumption on comparable corpora strongly deteriorates performance of lexicon induction techniques which are at the foundation of machine translation.
To the best of our knowledge, no prior work has so far made explicit the intrinsic mismatch between source and target domain in machine translation, both when considering the portion of the parallel dataset originating in the source and target language, and when considering the source and target monolingual corpora. We believe that this is an important characteristic of machine translation tasks, particularly when the content is derived from blogs, social media platforms, and news outlets. In fact, any attempt at making corpora comparable would change the nature of the original task, as we are usually interested in translating content originating in the source language.
Back-translation (Sennrich et al., 2015) has been the workhorse of modern neural MT, enabling very effective use of target side monolingual data. Back-translation is beneﬁcial because it helps regularizing the model and adapting to new domains (Burlot and Yvon, 2018). However, the typical setting of current MT benchmarks as popularized by recent WMT competitions (Bojar et al., 2019) is a mismatch between training and test sets, as opposed to a mismatch between source and target domains as in this work. In this setting, vast amounts of target monolingual data in the domain of the test set can be leveraged very effectively by back-translation. Unfortunately, backtranslation is much less effective when dealing with STDM, as we will show in §6.1. Zheng et al. (2019) tackles this problem by adding tags to examples (Caswell et al., 2019) to let the model know whether the data originates from the source or target domain. We employ this technique also in our experiments.
There has been some work attempting to make better use of source side monolingual data, as this is in-domain with the text we would like to

translate at test time. Uefﬁng (2006) proposed to improve a statistical MT system using selftraining (Yarowski, 1995), a direction later pursued by Zhang and Zong (2016) for neural MT. In our work, we consider the iterative variant proposed by He et al. (2020), whereby all model parameters are subject to training and noise is added to the input. Chinea-Rios et al. (2017) showed that self-training can be used to adapt to a different domain after selecting from a source monolingal dataset sentences that are similar to the test domain. Li et al. (2019) compares back-translation and self-training with respect to input sensitivity and prediction margin. None of this works however analyze how these methods fair when there is source-target domain mismatch which is the focus of this work. In this work, we also report improvements when combining self-training with backtranslation. This is consistent with earlier ﬁndings by Park et al. (2017), who however combined forward and back-traslated data to alleviate biases in the corresponding MT systems as opposed to compensate for domain effects.
Kilgarriff and Rose (1998) proposed a controlled setting to study metrics to assess similarity between corpora in the same language by deﬁning a mixture between two known corpora. In §4.1, we will use the same method but we apply it to corpora in two languages as required for machine translation. Finally, Fothergill et al. (2016) also deﬁnes a metric in the topic space, albeit for corpora in the same language. In our case, working in the topic space makes our measures more robust to translationese effects (Zhang and Toral, 2019), which could otherwise be a greater confounding factor in the assessment of STDM (§4.2.1).
3 The STDM Problem
In this section we formalize the deﬁnition of Source-Target Domain Mismatch (STDM); this is an intrinsic property of the data which is independent of the particular machine translation system under consideration. We assume there exists a latent concept space shared across all languages. The process to generate a sentence follows the standard data generation process used in topic modeling, whereby we ﬁrst sample a distribution over topics, πi ∼ Π where i is an index over topics, and then a distribution over words for each topic, wij ∼ πi, where j indexes the words in the dictionary. Next, we assume there are two dis-

D< l a t e x i t s h a 1 _ b a s e 6 4 = " + 4 g 7 Q r H z 8 q u N x 3 p L p Z Z Q A i m e 8 g E = " > A A A G T X i c h V R b a x N B F N 7 W p K 3 x 1 u q j L w d L I Y t r y E Z B Q Q p t T c E H K 5 V e I Z s s s 5 N J M 8 3 e 2 J k t W b b z B 3 0 R f P N f + O K D I u L s p X G T b O N A 4 G T O 9 8 3 5 z j d n x / J t y n i z + W 1 p + U 6 l u r K 6 d r d 2 7 / 6 D h 4 / W N x 6 f M i 8 M M D n B n u 0 F 5 x Z i x K Y u O e G U 2 + T c D w h y L J u c W a N 3 S f 7 s i g S M e u 4 x j 3 z S d d C F S w c U I y 6 3 z I 0 K 3 j I c x I c Y 2 X F b w D Y Y M d T H W q S a F A x h x n R b 1 x o N 7 a O o / c M d i B 7 L k O M e M y 9 T 3 G W G O z D Z D J J n y K j H z V G K H N 0 g e R H Z F r 3 Y c C x v H K N w L G 6 E h N r V j J B D S f L r 0 f V Y r W 3 J 6 m A w 6 s C U s s K h u x O h 9 V S p B o a F g j g S 5 q V 6 u 2 h p g 4 F D H 6 a O k f m M W g B + E H W D D w l H q i z y A g z b u w C p D a 4 h U V e A 3 b Q m 2 r v 7 p Z x x w o H n 4 N 7 C O z o u p e W S y s i 7 E + c z 1 F i Y I y 2 7 B X X R L c y 3 z s s l 7 Z V L S r r P C 6 r / O 7 j c 5 v l a 3 O P I F g v M T v / L m e 8 j U 5 9 k 5 P k T K T 1 e x L R m / J N D c p 2 M s r r g b l n o m D H T u M j 0 W l a 8 L 1 1 M v 5 S Z G W y L H C i g A z A l 9 C 1 I H d C d 8 s X M m y S u 5 h I x a 9 N U f k g X 5 I d U I + 6 C v E s y / m 0 9 l v j O Q r / g O s g R y x 0 s A 8 t 5 K G B r x Q / 7 y F z f b D a a 6 Y L 5 Q M + D T S V f h + b 6 V 6 P v 4 d A h L s c 2 Y q y j N 3 3 e j V H A K b a J q B k h I z 7 C I 3 R B O j J 0 k U N Y N 0 5 f Q w F b c q c P A y + Q P 5 d D u l t k x M h h L H I s i U x E s t l c s l m W 6 4 R 8 8 K Y b U 9 c P O X F x V m g Q 2 s A 9 S J 5 W 6 N O A Y G 5 H M k A 4 o F I r 4 C E K E O b y A a 5 J E / T Z l u e D 0 1 Z D f 9 l o f X q 1 u b O X 2 7 G m P F W e K X V F V 1 4 r O 8 p 7 5 V A 5 U X D l c + V 7 5 W f l V / V L 9 U f 1 d / V P B l 1 e y j l P l K m 1 s v o X x g E X Y w = = < / l a t e x i t >

Sdistribution

Latent Space
over topics distribution

over

words

Source Language
TEST
parallel

politics sports travel

D< l a t e x i t s h a 1 _ b a s e 6 4 = " n M o p 9 S 8 + 0 C E h G A Z F r 3 4 n Z G Q i 1 Q 4 = " > A A A G T X i c h V R b a x N B F N 5 q 0 t Z 4 a / X R l 4 O l k M U 1 Z K u g I I W 2 p u C D l Y q 9 Q T Z Z Z i e T Z p q 9 s T N b d t n O H / R F 8 M 1 / 4 Y s P i o i z l 8 Z N s o 0 D g Z M 5 3 z f n O 9 + c H c u 3 K e P t 9 r e l W 7 d r 9 e W V 1 T u N u / f u P 3 i 4 t v 7 o h H l h g M k x 9 m w v O L M Q I z Z 1 y T G n 3 C Z n f k C Q Y 9 n k 1 B q / T f O n l y R g 1 H O P e O y T n o P O X T q k G H G 5 Z a 7 X 8 K b h I D 7 C y E 4 6 A r b B S K A Z a b F q U j C E m d B t X W u 1 t A + i 8 Q 9 3 I P o s R 0 Z 9 Z l 5 k u I s c d 2 C y G S T P k X G f m + M M O b 5 G 8 j K y I / q J 4 V h e l K A w E t d C Q u 1 y R s i h J P n N + C p S G 5 u y O h i M O j C l r H T o 7 k R o M 1 O q g W G h I I m F e a H e L F r a Y O D Q h 6 l j Z D 6 n l o D v R d P g I 8 K R K o s 8 B 8 P 2 z k F q g y t I 1 Z V g 1 6 2 J z u 5 + J S d K O f A M 3 B t 4 n 4 4 q a Y W k K v L u x P k c F Q l z r O W 3 o C 6 6 h f n W e b W k v W p J a f d F Q f V / B 1 f b P F + L e x z Z Y o H Z 2 X 8 5 8 w N k 6 p O M P H 8 i p c / L m K 0 Z / + S Q X K W j r C 6 4 W x Y 6 Z s I 0 L n K 9 l p X s S x e z L 2 V m B j u i A A r o A k w J f Q N S B / S m f D G L J o m r u U T M 2 j S V H 9 E F + R H V i L s g 7 5 K c f 1 O P F b 6 z 0 C + 5 D n L E C g e r w H I e S t h G + c M + M t c 2 2 q 1 2 t m A + 0 I t g Q y n W o b n 2 1 R h 4 O H S I y 7 G N G O v q b Z / 3 E h R w i m 0 i G k b I i I / w G J 2 T r g x d 5 B D W S 7 L X U M C m 3 B n A 0 A v k z + W Q 7 Z Y Z C X I Y i x 1 L I l O R b D a X b l b l u i E f v u 4 l 1 P V D T l y c F x q G N n A P 0 q c V B j Q g m N u x D B A O q N Q K e I Q C h L l 8 g B v S B H 2 2 5 f n g Z K u l v 2 h t f X y 5 s b N X 2 L G q P F G e K k 1 F V 1 4 p O 8 o 7 5 V A 5 V n D t c + 1 7 7 W f t V / 1 L / U f 9 d / 1 P D r 2 1 V H A e K 1 N r e e U v x 4 U X Z A = = < / l a t e x i t >

T

distribution

over

topics

NYC erest emite ome andu Ev Yos R athm K
distribution over words

mono
human translation

Target Language
human translation
parallel

politics sports travel

NYC erest emite ome andu Ev Yos R athm K

mono

Figure 1: Toy illustration of STDM in MT. There are two domains, the source domain DS (top) and the target domain DT (bottom). We postulate that in a latent concept space these two domains differ because the topic distributions are different (e.g., in the source domain politics is more popular than travel) and because for the same topic the word distributions are different (e.g., the word “Everest” is more common than “Yosemite” in the travel topic of the target domain). On the right hand side, we show how STDM manifests in machine translation datasets. All data originating in the source language belongs to the source domain, this includes a portion of the parallel dataset, the source side monolingual dataset and the test set we eventually would like to translate. Empty boxes represent human translated data in the parallel training dataset.

tinct domains, the source domain DS and the target domain DT . These two domains differ in both the distribution over topics Π, and the distribution over words given a certain topic πi, as depicted in Fig. 1. For the sake of conciseness, we will refer to zs and zt as sentences in the concept space generated from domain DS and DT , respectively.
Let’s imagine now that we have generated two sets of sentences in each domain. What we observe in practice is their realization in each language, src(zs) and tgt(zt), where src and tgt map sentences from the concept space to the source and target language, respectively. Finally, let’s denote with hs→t and ht→s the functions representing human translations of source sentences in the target language and vice versa.
In the simplest setting, a machine translation dataset is composed of parallel and monolingual datasets. Using the notation introduced above, the parallel dataset is denoted by P = {(src(zs), hs→t(src(zs))}zs∼DS ∪ {(ht→s(tgt(zt)), tgt(zt)}zt∼DT . The ﬁrst set originates in the source language and belongs to the source domain, while the second set originates in the target language and belongs to the target domain. We then have a source side monolingual dataset, MS = {src(zs)}zs∼DS , and a target side

Figure 2: Topic distribution of Wikipedia pages written in English and Chinese.
monolingual dataset, MT = {tgt(zt)}zt∼DT , belonging to the source and target domains, respectively. The test set which we would like to eventually translate contains sentences in the source language, all belonging to the source domain. The existence of distinct source and target domains and datasets derived from these two domains as described above deﬁne the STDM problem.
In most domain adaptation studies for machine translation, it is assumed that DS = DT but the test domain differs from the training domain. Here instead, the test domain is in the same domain as the portion of the training set originating in the source language. We would like to a) understand the effects of such mismatch and b) understand how to best leverage the out-of-domain data originating from the target language (target monolingual dataset and portion of the parallel dataset originating in the target language).
We conclude with a disclaimer for the critical reader. In reality, there may not exist a shared concept space across all languages, since some concepts may be unique to a language. Moreover, the granularity of how topics are deﬁned is arbitrary. Finally, in practice there may be not two but multiple domains and multiple languages. Despite these limitations and assumptions, we will show in the following sections that this simple framework has reasonable empirical support and that it can help us deﬁne a useful metric. We will analyze the implications for learning machine translation systems in §5.
3.1 Empirical Evidence
In this section we ﬁrst provide anecdotal evidence that documents originating in different languages possess different distributions over topics. We train two topic classiﬁers, one for Chinese and the other for English, using the Wikipedia annotated

data from Yuan et al. (2018). We apply this classiﬁer to 20,000 documents randomly sampled from English and Chinese Wikipedia. Fig. 2 shows that according to this classiﬁer, English Wikipedia has more pages about entertainment and religion than Chinese Wikipedia, for instance.
Second, we provide empirical support for the claim that corpora originating in different places may have different word distributions for the same set of topics. Towards this end, we summarize Leech and Fallon (1992)’s seminal study who analyzed the Brown corpus and the LOB corpus of British and American English text, respectively. These are examples of corpora comprising text extracted from the same proportion of text categories and using essentially the same sampling procedure for their construction. Yet the authors ﬁnd a different usage of vocabulary, particularly for gender related words. The authors conclude that “... we may propose a picture of US culture in 1961 – masculine to the point of machismo, militaristic, ... – contrasting with one of British culture as more given to temporizing and talking... and to family and emotional life...”. All together, empirical evidence suggests that STDM can be attributed to both differences in the topic distribution as well as word distributions for the same topic.
4 Metric: The STDM Score
Given the framework introduced in §3, in this section we are going to discuss a practical way to measure STDM. Ideally, we would like to measure a distance between two sample distributions, zs ∼ DS and zt ∼ DT . Unfortunately, we have no access to such latent space. What we observe are realizations in the source and target language. However, it is also an open research question (Hao and Paul, 2018; Yang et al., 2019) how to compare the distribution of {src(zs)} against {tgt(zt)}, since these are two possibly incomparable corpora in different languages.
In this work, we therefore leverage the existence of a parallel corpus and compare the distribution of AT = {tgt(zt)}zt∼DT with AS = {hs→t(src(zs))}zs∼DS . The underlying assumption is that the effect of translationese (Baker, 1993; Zhang and Toral, 2019; Toury, 2012) is negligible compared to the actual STDM, and therefore, we can ignore changes to the distribution brought by the mapping hs→t. We will validate this assumption in §4.2.1.

Next, we assume that what contributes the most
to STDM are changes between the topic distribu-
tions of source and target domains. Under this
additional assumption, we deﬁne the score as a measure of the topic discrepancy between AS and AT . Let A = AS ∪ AT be the concatenation
of the corpus originating in the source and tar-
get language. We ﬁrst extract topics using LSA
(but any other method could be considered). Let A ∈ R(nS+nT )×k be the TF-IDF matrix derived from A where the ﬁrst nS rows are representations taken from AS, the bottom nT rows are representations of AT , and k is the number of words
in the dictionary. The SVD decomposition of A
yields: A = U SV = (U (S))( (S)V ) = U¯ V¯ . Matrix U¯ collects topic representations of the original documents; let’s denote by U¯ S the ﬁrst nS rows corresponding to AS and U¯ T the remaining nT rows corresponding to AT . Let C = U¯ U¯ = CCSSTS CCTSTT , where CSS = U¯ S U¯ S , CST = U¯ SU¯ T and CT T = U¯ T U¯ T . The STDM
score is deﬁned as:

sST + sTS

1 nA nB

score = sSS + sTT , with sAB = nAnB

CiA,jB

i=1 j=1

where sAB measures the average similarity between documents of set A to documents of set B. The score measures the cross-corpus similarity normalized by the within corpus similarity. In the extreme setting where DS and DT are fully disjoint, then we would have that the off-diagonal block CST is going to be a zero matrix and therefore the score is equal to 0. When the two domains perfectly match instead, sSS = sTT = sST = sTS, and therefore, the score is equal to 1. In practice, we expect a score in the range [0, 1].

4.1 A Controlled Setting
Similarly to Kilgarriff and Rose (1998), we introduce a synthetic benchmark to ﬁnely control the domain of the target originating data, and therefore the amount of STDM. The objective is to assess whether the STDM score deﬁned in Eq. 1 captures well the expected amount of mismatch.
The key idea of this controlled setting is to use a convex combination of data from two sufﬁciently different domains as target originating data, which comprises the target side monolingual data and half of the parallel training data.
In this work we use EuroParl (Koehn, 2005) as our source originating data, while our target

α

0 0.25 0.5 0.75 1.0

STDM score 0.29 0.55 0.78 0.93 0.99

Table 1: STDM score as a function of the parameter α controlling the STDM in the synthetic setting.

WMT MTNT SMD

De-En 0.79
0.81

Fi-En 0.79
0.71

Ru-En 0.76
0.71

Ne-En -
0.64

Zh-En 0.65
0.71

Ja-En -
0.69 0.61

Table 2: STDM score on several language pairs using parallel data from WMT, MTNT and from a social media platform (SMD) test sets.

originating data contains a mix of data from EuroParl and OpenSubtitles (Lison and Tiedemann, 2016). Speciﬁcally, we consider a French to English translation task with a parallel dataset composed of 10,000 sentences from EuroParl (which is assumed to originate in French) and 10,000 sentences from the target domain (which is assumed to originate in English).
Let α ∈ [0, 1], the domain of the target originating data is set to: α EuroParl + (1 − α) OpenSubtitles. For instance, when α = 0 then the target domain (OpenSubtitles) is totally out-ofdomain with respect to the source domain (EuroParl). When α = 1 instead, the target domain matches perfectly the source domain. For intermediate values of α, the match is only partial. Notice that even when α = 0, we assume that the parallel dataset is comprised of two halves, one originating from the EuroParl domain (the “French originating” data) and one from OpenSubtitles (the “English originating” data).
Next, we evaluate the STDM score as a function of α. As we can see from Table 1 and as expected, the STDM score increases fairly linearly as we increase the value of α.
4.2 Empirical Evaluation of STDM on Various Datasets
We now evaluate the STDM score on real data. We consider six language pairs, German-English, Finnish-English, Russian-English, NepaliEnglish, Chinese-English and Japanese-English. We analyze datasets from WMT, MTNT (Michel and Neubig) and from a social media platform (SMD). For each language, we sample 5000 sentences from WMT newstest sets and MTNT dataset, and 20000 sentences from SMD. We then merge all these datasets and their English translations to compute a common set of topics, making

STDM scores comparable across language pairs and datasets.
The results in Table 2 are striking. First, WMT datasets, except for Chinese, show relatively mild signs of STDM and negligible difference across language pairs, suggesting that the data curation process of WMT datasets have made source and target originating corpora rather comparable. The distribution of WMT Chinese originating data instead is rather different because it contains much more local news, while the other languages are mostly about international news which are largely language independent. Interestingly, En-De data derived from social media data has even milder STDM, Fi-En and Ru-En have more substantial STDM. Instead, MTNT and SMD exhibit strong signs of STDM for distant languages like Nepali, Chinese and Japanese. This agrees well with our intuition that STDM is more severe for more distant languages associated to more diverse cultures.
4.2.1 The Effect of Translationese
In §3 we have made the assumption that the effect of translationese is negligible when estimating STDM. However, there are previous studies showing clear artifacts in (human) translations (Baker, 1993; Zhang and Toral, 2019; Toury, 2012). In this section we aim at assessing whether our STDM score is affected by translationese.
We consider the WMT’17 De-En dataset from Ott et al. (2018) which contains double translations of source and target originating sentences. From this, we construct paired inputs and labels, {(hs→t(ht→s(tgt(zt))), 1)} ∪ {(tgt(zt), 0)}, and train two classiﬁers to predict whether or not the input is translationese. The ﬁrst classiﬁer takes as input a TF-IDF representation w of the sentence, while the second classiﬁer takes only the corresponding topic distribution: V¯ w. On this binary task a linear classiﬁer achieves 58% accuracy on the test set with TF-IDF input representations, and only 52% when given just the topic distribution. If we apply the same binary classiﬁer in the topic space to discriminate between sentences originating in the source and target domain (tgt(zt) VS. hs→t(src(zs))), the accuracy increases to 64%.
We conclude that once we control for domain effect (by discriminating the same set of sentences in their original form versus their double translationese form), the accuracy is much lower than previously reported (Zhang and Toral, 2019), and working in the topic space further removes trans-

lationese artifacts. Therefore, the STDM score computed in the topic space is unlikely affected by such artifacts and captures the desired discrepancy between the source and the target domains.
5 The Effect of STDM in Machine Translation
In this section, we turn our attention to how STDM affects training of machine translation systems. We consider state-of-the-art neural machine translation (NMT) systems based on the transformer architecture (Vaswani et al., 2017) with subword vocabularies learned via byte-pair encoding (BPE) (Sennrich et al., 2015). In order to adapt to the different domains, we employ domain tagging (Zheng et al., 2019) by adding a domain token to the input source sentence1. We also use label smoothing (Szegedy et al., 2016) and dropout (Srivastava et al., 2014) to improve generalization, as we focus on low resource language pairs where models tend to severely overﬁt. Finally, we explore ways to leverage both target and source side monolingual data via back-translation and self-training which we review next.
We simplify our notation and denote with xs = src(zs) and yt = tgt(zt) the source and target originating sentences, ys = hs→t(xs) and xt = ht→s(yt) the corresponding human translations, and yˆs and xˆt the corresponding machine translations. The superscript always speciﬁes the domain. We assume access to a parallel dataset P = {(xs, ys)} ∪ {(xt, yt)}, a source side monolingual dataset Ms = {xs} and a target side monolingual dataset Mt = {yt}.
5.1 Back-Translation (BT)
Back-translation (BT) (Sennrich et al., 2015) is a very effective data augmentation technique that leverages Mt. The algorithm proceeds in three steps. First, a reverse machine translation system is trained from tar←g−et to source using the provided parallel data: θ = arg maxθ E(x,y)∼P log p(x|y; θ). Then, the reverse model is used to translate the targe←t−monolingual data: xˆt ≈ arg maxz p(z|yt; θ ), for yt ∼ Mt. The maximization is typically approximated by beam search. Finally, the forward model is trained over the concatenation o→−f the original parallel and back-translated data: θ =
1In the controlled setting of §6.1 we found that tagging a small but consistent improvement by almost 1 BLEU point.

1 Data: Given a parallel dataset P and a source monolingual dataset Ms with N s examples;

2 Noise: Let n(x) be a function that adds noise to the input

by dropping, swapping and blanking words;

3 Hyper-params: Let k be the number of iterations and

A1 < · · · < Ak ≤ NS be the number of samples to add

at each iteration;

4 Train a forward model: −→ θ = arg maxθ E(x,y)∼P log p(y|x; θ);

5 for t in [1 . . . k] do

6

forward-translate data:

(yˆs,

v)

≈

arg

maxz

p(z|xs;

−→ θ ),

for

xs

∈

Ms,

where v is the model score;

7

Let M¯ s ⊂ Ms containing the top-At highest scoring

examples according to v;

8

re-train forward model:

−→

θ = arg maxθ E(x,y)∼Q log p(y|x; θ) with

Q = P ∪ {n(xs), yˆs}xs∼M¯ s .

end

Algorithm 1: Self-Training algorithm.

arg maxθ E(x,y)∼Q log p(y|x; θ) with Q = P ∪ {xˆt, yt}yt∼Mt. In practice, the parallel data is weighted more in the loss, with a weight selected via hyper-parameter search on the validation set.
BT generally improves ﬂuency and generalization, but has potential weaknesses when there is STDM. Even if the reverse model were to produce perfect translations, back-translated data belongs to the target domain, and it is therefore outof-domain with the data we wish to translate, i.e., source sentences belonging to the source domain. We will verify this conjecture empirically in §6.1.
5.2 Self-Training (ST)
Self-Training (ST) (He et al., 2020; Yarowski, 1995), shown in Alg. 1, is another method for data augmentation that instead leverages Ms. First, a baseline forward model is trained on the parallel data (line 4). Second, this initial model is applied to the source monolingual data (line 6). Finally, the forward model is re-trained from random initialization by augmenting the original parallel dataset with the forward-translated data. As with BT, the parallel dataset receives more weight in the loss.
One beneﬁt of this approach is that the synthetic parallel data added to the original parallel data is in-domain, unlike back-translated data. However, the model may reinforce its own mistakes since synthetic targets are produced by the model itself. Accordingly, we make the algorithm iterative and add only the examples for which the model was most conﬁdent (line 3, loop in line 5 and line 7). In our experiments we iterate three times. We also inject noise to the input sentences, in the form of

word swap and drop (Lample et al., 2018), to further improve generalization (line 8).
5.3 Combining BT and ST
BT and ST are complementary to each other. While BT beneﬁts from correct targets, the synthetic data is out-of-domain when there is STDM. Conversely, ST beneﬁts from in-domain source sentences but synthetic targets may be inaccurate. We therefore consider their combination as an additional baseline approach.
The combined learning algorithm proceeds in three steps. First, we train an initial forward and reverse model using the parallel dataset. Second, we back-translate target side monolingual data using the reverse model (see §5.1) and iteratively forward translate source side monolingual data using the forward model (see §5.2 and Alg. 1). We then retrain the forward model from random initialization using the union of the original parallel dataset, the synthetic back-translated data, and the synthetic forward translated data at the last iteration of the ST algorithm.
6 Machine Translation Results
In this section, we ﬁrst study the effect of STDM on NMT using the controlled setting introduced in §4.1 which enables us to assess the inﬂuence of various factors, such as the extent to which target originating data is out-of-domain, and the effect of monolingual data size. We then report experiments on genuine low resource language pairs, namely Nepali-English and English-Myanmar.
We tune model hyperparameters (e.g., number of layers and hidden state size) and BPE size on the validation set. Based on cross-validaiton, when training on datasets with less than 300k parallel sentences (including those from ST or BT), we use a 5-layer transformer with 8M parameters. The number of attention heads, embedding dimension and inner-layer dimension are 2, 256, 512, respectively. When training on bigger datasets, we use a bigger transformer with 5 layers, 8 attention heads, 1024 embedding dimension, 2048 innerlayer dimension and a total of 110M parameters. We report SACREBLEU (Post, 2018).
6.1 Controlled Setting
In the default setting, we have a parallel dataset with 20,000 parallel sentences. 10,000 are indomain source originating data (EuroParl) and the

Figure 3: BLEU score in Fr-En as a function of the amount of STDM. The target domain is fully out-ofdomain when α = 0, and fully in-domain when α = 1.
remaining 10,000 are target originating data from a mix of domains, controlled by α ∈ [0, 1]: α EuroParl + (1 − α) OpenSubtitles. The source side monolingual dataset has 100,000 French sentences from EuroParl. The target side monolingual dataset has 100,000 English sentences from: α EuroParl + (1−α) OpenSubtitles. Finally, the test set consists of novel French sentences from EuroParl which we translate in English.
Varying amount of STDM. In Fig. 3, we benchmark our baseline approaches while varying α (see §4.1), which controls the overlap between source and target domain.
First, we observe improved BLEU (Papineni et al., 2002) scores for all methods as we increase α. Second, there is a big gap between the baseline trained on parallel data only and methods which leverage monolingual data. Third, combining ST and BT works better than each individual method, conﬁrming that these approaches are complementary. Finally, BT works better than ST but the gap reduces as the target domain becomes increasingly different from the source domain (small values of α). In the extreme case of STDM (α = 0), ST outperforms BT. In fact, we observe that the gain of BT over the baseline decreases as α decreases, despite that the amount of monolingual data and parallel data remains constant across these experiments, thus showing that BT is less effective in the presence of STDM.
Varying amount of monolingual data. We next explore how the quantity of monolingual data affects performance and if the relative gain of ST over BT when α = 0 disappears as we provide BT with more monolingual data. The experiment in Fig. 4 shows that a) the gain in BLEU tapers off exponentially with the amount of data (notice the log-scale in the x-axis), b) for the same amount of

Figure 4: BLEU as a function of the amount of monolingual data when α = 0.

Figure 6: BLEU score as a function of the proportion of parallel data originating in the source and target domain domain. When β = 0 all parallel data originates from OpenSubtitles, when β = 1 all parallel data originates from EuroParl. Source and target monolingual corpora have 900,000 sentences from EuroParl and OpenSubtitles, respectively. The blue curves show BLEU in the forward direction (Fr-En translation of EuroParl data). The red curves show BLEU in the reverse direction (En-Fr translation of OpenSubtitles sentences).

Figure 5: BLEU when using only source originating in-domain data (blue bars) or also out-of-domain target originating data (green bars) for α = 0.
monolingual data ST is always better than BT and by roughly the same amount, and c) BT would require about 3 times more target monolingual data (which is out-of-domain) to yield the performance of ST. Therefore, increasing the amount of data can compensate for domain mismatch.
Varying amount of in-domain data. Now we explore whether, in the presence of extreme STDM (α = 0), it may be worth restricting the training data to only contain in-domain source originating sentences. In this case, the parallel set is reduced to 10,000 EuroParl sentences, the target side monolingual data is removed and backtranslation is performed on the target side of the parallel dataset. Fig. 5 demonstrates that in all cases it is better to include the out-of-domain data originating on the target side (green bars). Particularly in the low resource settings considered here, neural models beneﬁt from all available examples even if these are out-of-domain.
Finally, we investigate how to construct a parallel dataset when STDM is signiﬁcant (α = 0), i.e. the target domain is OpenSubtitles. If we have a translation budget of 20,000 sentences, is it best to translate 20,000 sentences from EuroParl or to also include sentences from OpenSubtitles? This is not obvious when training with BT, since the backward model may beneﬁt from in-domain

OpenSubtitles data. In order to answer this question, we consider a parallel dataset with 20,000 sentences deﬁned as: β EuroParl + (1 − β) OpenSubtitles, with β ∈ [0, 1]. When β = 0, the parallel dataset is out-of-domain; when β = 1 the parallel data is all in-domain. The target side monolingual dataset is ﬁxed and contains 900,000 sentences from OpenSubtitles.
Fig. 6 shows that taking all sentences from EuroParl (β = 1) is optimal when translating from French (EuroParl) to English (blue curves). At high values of β, we observe a slight decrease in accuracy for models trained only on backtranslated data (dotted line), conﬁrming that BT loses its effectiveness when the reverse model is trained on out-of-domain data. However, this is compensated by the gains brought by the additional in-domain parallel sentences (dashed line). In the more natural setting in which the model is trained on both parallel and back-translated data (dash-dotted line), we see monotonic improvement in accuracy with β. A similar trend is observed in the other direction (English to French, red lines). Therefore, if the goal is to maximize translation accuracy in both directions, an intermediate value of β (≈ 0.5) is more desirable.
6.2 Low-Resource MT
We now test our approaches on two lowresource language pairs, Nepali-English (Ne-En) and English-Myanmar (En-My). Nepali and Myanmar are spoken in regions with unique local

Model baseline BT ST ST + BT

Ne → En 20.4 22.3 22.1 22.9

En → My 28.1 30.0 31.9 32.4

Table 3: BLEU scores for the Nepali to English and English to Myanmar translation task.

context that is very distinct from English-speaking regions, and thus these make good language pairs for studying the STDM setting in real life.
Data. The Ne-En parallel dataset is composed of 40,000 sentences originating in Nepali and only 7,500 sentences originating in English. There are 5,000 sentences in the validation and test sets all originating in Nepali. We also have 1.8M monolingual sentences in Nepali and English, collected from public posts from a social media platform. This dataset closely resembles our idealized setting of Fig. 1. The STDM score of this dataset is 0.64 (see Tab. 2) and is analogous to our synthetic setting (§6.1) where α is low but β is large.
The En-My parallel data is taken from the Asian Language Treebank (ALT) corpus (Thu et al., 2016; Ding et al., 2018, 2019) with 18,088 training sentences all originating from English news. The validation and test sets have 1,000 sentences each, all originating from English. Following Chen et al. (2019), we use 5M English sentences from NewsCrawl as source side monolingual data and 100K Myanmar sentences from Common Crawl as target side monolingual data. We cannot compute an STDM score (§4) since we have no parallel data originating in Myanmar. Comparing to our controlled setting this dataset would have β equal to 1 and presumably a small value of α, an ideal setting for ST.
Models. On both datasets, the parallel data baseline is a 5-layer transformer with 8 attention heads, 512 embedding dimensions and 2048 inner-layer dimensions, which consists of 42M parameters. When training with BT and ST, we use a 6-layer transformer with 8 attention heads, 1024 embedding dimensions, 2048 inner-layer dimensions, resulting in 186M parameters.
Results. In Table 3, we observe that on the NeEn task augmenting the parallel dataset with either forward- or back-translated monolingual data achieves almost 2 BLEU points improvement over

the supervised baseline. On the En-My task BT slightly outperforms the baseline, while ST improves by +2.5 BLEU, since source side monolingual data is in-domain with the test set, while target side monolingual data is scarce and out-ofdomain. On both tasks, we observe that combining ST and BT outperforms each individual method.
7 Practical Tips
Given these considerations and ﬁndings, how can we best set up a machine traslation system on a distant and possibly low-resource language pair? Our ﬁrst recommendation is to be aware of possible STDM, and (i) check whether origin language information is available. If this is available, then it may be possible to (ii) qualitatively look at the data to assess the extent of STDM, and quantitatively measure STDM as described in §4. Next, (iii) be aware that when STDM is severe, BT performance suffers (Fig. 3). However, (iv) we may be able to combat this by increasing the amount of target side (out-of-domain) monolingual data (Fig. 4) and (v) by combining BT with ST (Fig. 3).
Of course, the relative ratio of monolingual data in the source and target side and the actual degradation brought by STDM depend on the particular language pair. The more distant are the two languages, the more difﬁcult the learning task and the more data is needed to learn it. And ﬁnally, the less parallel data there is, the more monolingual data will be needed to compensate. Therefore, there is an overall intricate dependency between all these factors, which we currently do not have neither theoretical nor practical tools to analyze and which certainly merits future investigation.
8 Final Remarks
In this work we introduced the problem of sourcetarget domain mismatch in machine translation. We have formally deﬁned STDM (§3) and proposed a practical method to measure it (§4). While the commonly used WMT datasets exhibit mild STDM, we ﬁnd that less curated datasets in more distant and often lower resource language pairs (§4.2) exhibit much stronger STDM. We then investigated the effects of STDM on commonly used algorithms for training machine translation systems and conclude that popular methods like BT are indeed affected. Looking forward, we are interested in investigating better approaches to analyze and cope with STDM, to extend this study to

the more realistic multilingual setting with multiple domains, and to build public benchmarks that exhibit this natural phenomenon.
9 Acknowledgments
The authors would like to thank Marco Baroni, Silvia Bernardini, Randy Scansani, Alberto Barrón-Cedeño, Adriano Ferraresi, and Adina Williams for pointing to relevant references in the socio-linguistic literature and for general suggestions. They also wish to thank Sergey Edunov for various tips on training MT systems at scale.
References
Mona Baker. 1993. Corpus linguistics and translation studies: Implications and applications. Text and technology: In honour of John Sinclair, 233:250.
Silvia Bernardini and Federico Zanettin. 2004. When is a universal not a universal. Translation universals: do they exist? John Benjamin publisher Edited by Anna Mauranen and Pekka Kujammak, pages 51–62.
Ondˇrej Bojar, Christian Federmann, Mark Fishel, Yvette Graham, Barry Haddow, Matthias Huck, Philipp Koehn, and Christof Monz. 2019. Findings of the 2019 conference on machine translation (wmt19). In Proc. of WMT.
Jordan Boyd-Graber and David M. Blei. 2009. Multilingual topic models for unaligned text. In Conference on Uncertainty in Artiﬁcial Intelligence.
David Britain. 2013. Space, Diffusion and Mobility. Wiley publishers; Book Editor(s): J.K. Chambers Natalie Schilling First. Chapter 22.
Franck Burlot and FranÃg˘ois Yvon. 2018. Using monolingual data in neural machine translation: a systematic study. In Empirical Methods in Natural Language Processing.
Isaac Caswell, Ciprian Chelba, and David Grangier. 2019. Tagged back-translation. In Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers), pages 53–63, Florence, Italy. Association for Computational Linguistics.

Peng-Jen Chen, Jiajun Shen, Matt Le, Vishrav Chaudhary, Ahmed El-Kishky, Guillaume Wenzek, Myle Ott, and Marc’Aurelio Ranzato. 2019. Facebook aiâA˘ Z´ s wat19 myanmarenglish translation task submission. In Workshop on Asian Translation.
Mara Chinea-Rios, Alvaro Peris, and Francisco Casacuberta. 2017. Adapting neural machine translation with parallel synthetic data. In Conference on Machine Translation (WMT).
Chenchen Ding, Hnin Thu Zar Aye, Win Pa Pa, Khin Thandar Nwet, Khin Mar Soe, Masao Utiyama, and Eiichiro Sumita. 2019. Towards Burmese (Myanmar) morphological analysis: Syllable-based tokenization and part-of-speech tagging. ACM Transactions on Asian and Low-Resource Language Information Processing (TALLIP), 19(1):5.
Chenchen Ding, Masao Utiyama, and Eiichiro Sumita. 2018. NOVA: A feasible and ﬂexible annotation system for joint tokenization and part-of-speech tagging. ACM Transactions on Asian and Low-Resource Language Information Processing (TALLIP), 18(2):17.
Jacob Eisenstein, Brendan OâA˘ Z´ Connor, Noah A. Smith, and Eric P. Xing. 2010. A latent variable model for geographic lexical variation. In Annual Meeting of the Association for Computational Linguistics.
John Rupert Firth. 1935. On sociological linguistics. Transactions of the Royal Society, pages 67–69.
Richard Fothergill, Paul Cook, and Timothy Baldwin. 2016. Evaluating a topic modelling approach to measuring corpus similarity. In LREC.
Pascale Fung and Lo Yuen Yee. 1998. An ir approach for translating new words from nonparallel, comparable texts. In The 17th International Conference on Computational Linguistics.
E.D. Gutierrez, Ekaterina Shutova annd Patricia Lichtenstein, Gerard de Melo, and Luca Gilardi. 2016. Detecting cross-cultural differences using a multilingual topic model. In Conference of the Association for Computational Linguistics.

Shudong Hao and Michael J. Paul. 2018. Learning multilingual topics from incomparable corpora. In International Conference on Computational Linguistics (COLING).
Junxian He, Jiatao Gu, Jiajun Shen, and Marc’Aurelio Ranzato. 2020. Revisiting selftraining for neural sequence generation. In International Conference on Learning Representations.
Ann Irvine and Chris Callison-Burch. 2013. Combining bilingual and comparable corpora for low resource machine translation. In Proceedings of the eighth workshop on statistical machine translation, pages 262–270.
Barbara Johnstone. 2010. Language and place. R. Mesthrie and W. Wolfram, editors, Cambridge Handbook of Sociolinguistics. Cambridge University Press.
Adam Kilgarriff and Tony Rose. 1998. Measures for corpus similarity and homogeneity. In Conference on Empirical Methods in Natural Language Processing.
Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. MT Summit.
Guillaume Lample, Myle Ott, Alexis Conneau, Ludovic Denoyer, and Marc’Aurelio Ranzato. 2018. Phrase-based & neural unsupervised machine translation. In Empirical Methods in Natural Language Processing (EMNLP).
Geoffrey Leech and Roger Fallon. 1992. Computer corpora: What do they tell us about culture? ICAME Journal Computers in English Linguistics, (16).
Guanlin Li, Lemao Liu, Guoping Huang, Conghui Zhu, Tiejun Zhao, and Shuming Shi. 2019. Understanding data augmentation in neural machine translation: Two perspectives towards generalization. In Empirical Methods in Natural Language Processing.
Bill Yuchen Lin, Frank F. Xu, Kenny Q. Zhu, and Seung won Hwang. 2018. Mining crosscultural differences and similarities in social media. In Conference of the Association for Computational Linguistics.

P. Lison and J. Tiedemann. 2016. Opensubtitles2016: Extracting large parallel corpora from movie and tv subtitles. In 10th International Conference on Language Resources and Evaluation (LREC).
Qiaozhu Mei, Chao Liu, and Hang Su. 2006. A probabilistic approach to spatiotemporal theme pattern mining on weblogs. In WWW.
Paul Michel and Graham Neubig. Mtnt: A testbed for machine translation of noisy text. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing.
David Mimno, Hanna M. Wallach, Jason Naradowsky, David A. Smith, and Andrew McCallum. 2009. Polylingual topic models. In Conference on Empirical Methods in Natural Language Processing.
D.S. Munteanu, A. Fraser, and D. Marcu. 2004. Improved machine translation performance via parallel sentence extraction from comparable corpora. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).
Graham Neubig and Junjie Hu. 2018. Rapid adaptation of neural machine translation to new languages. In Conference on Empirical Methods in Natural Language Processing (EMNLP), Brussels, Belgium.
Myle Ott, Michael Auli, David Grangier, and MarcâA˘ Z´ Aurelio Ranzato. 2018. Analyzing uncertainty in neural machine translation. In International Conference on Machine Learning.
K. Papineni, S. Roukos, T. Ward, and W.J. Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics.
Jaehong Park, Jongyoon Song, and Sungroh Yoon. 2017. Building a neural machine translation system using only synthetic parallel data. CoRR, abs/1704.00253.
Eric Pederson, Eve Danziger, David Wilkins, Stephen Levinson, Sotaro Kita, and Gunter Senft. 1998. Semantic typology and spatial conceptualization. Language, 74(3).

Matt Post. 2018. A call for clarity in reporting BLEU scores. In Proceedings of the Third Conference on Machine Translation: Research Papers, pages 186–191, Belgium, Brussels. Association for Computational Linguistics.
Rico Sennrich, Barry Haddow, and Alexandra Birch. 2015. Improving neural machine translation models with monolingual data. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 86–96.
Anders Søgaard, Sebastian Ruder, and Ivan Vulic. 2018. On the limitations of unsupervised bilingual dictionary induction. In Conference of the Association for Computational Linguistics (ACL).
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: A simple way to prevent neural networks from overﬁtting. Journal of Machine Learning Research, 15.
Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. 2016. Rethinking the inception architecture for computer vision. In IEEE conference on computer vision and pattern recognition.
Ye Kyaw Thu, Win Pa Pa, Masao Utiyama, Andrew Finch, and Eiichiro Sumita. 2016. Introducing the asian language treebank (alt). In LREC.
Gideo Toury. 2012. Descriptive translation studies and beyond: Revised edition. John Benjamins Publishing.
Nicola Uefﬁng. 2006. Using monolingual sourcelanguage data to improve mt performance. In IWSLT.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention Is All You Need. In Proc. of NIPS.
Weiwei Yang, Jordan Boyd-Graber, and Philip Resnik. 2019. A multilingual topic model for learning weighted topic links across corpora with low comparability. In Conference on Empirical Methods in Natural Language Processing.

David Yarowski. 1995. Unsupervised word sense disambiguation rivaling supervised methods. In Annual Meeting of the Association for Computational Linguistics.
Michelle Yuan, Benjamin Van Durme, and Jordan Boyd-Graber. 2018. Multilingual anchoring: Interactive topic modeling and alignment across languages. In Neural Information Processing Systems.
Jiajun Zhang and Chengqing Zong. 2016. Exploiting source-side monolingual data in neural machine translation. In Empirical Methods in Natural Language Processing.
Mike Zhang and Antonio Toral. 2019. The effect of translationese in machine translation test sets. arXiv, abs/1906.08069.
Renjie Zheng, Hairong Liu, Mingbo Ma, Baigong Zheng, and Liang Huang. 2019. Robust machine translation with domain sensitive pseudosources: Baidu-OSU WMT19 MT robustness shared task system report. In Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1), pages 559–564, Florence, Italy. Association for Computational Linguistics.

