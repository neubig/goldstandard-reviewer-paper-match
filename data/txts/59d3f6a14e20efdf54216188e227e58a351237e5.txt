Learning to Disentangle GAN Fingerprint for Fake Image Attribution
Tianyun Yang12, Juan Cao12∗, Qiang Sheng12, Lei Li12, Jiaqi Ji3, Xirong Li3, Sheng Tang12 1 Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China 2University of Chinese Academy of Sciences, Beijing, China 3Renmin University of China
{yangtianyun19z,caojuan,shengqiang18z,lilei17b,ts}@ict.ac.cn {2019104238,xirong}@ruc.edu.cn

arXiv:2106.08749v1 [cs.CV] 16 Jun 2021

Abstract
Rapid pace of generative models has brought about new threats to visual forensics such as malicious personation and digital copyright infringement, which promotes works on fake image attribution. Existing works on fake image attribution mainly rely on a direct classiﬁcation framework. Without additional supervision, the extracted features could include many content-relevant components and generalize poorly. Meanwhile, how to obtain an interpretable GAN ﬁngerprint to explain the decision remains an open question. Adopting a multi-task framework, we propose a GAN Fingerprint Disentangling Network (GFD-Net) to simultaneously disentangle the ﬁngerprint from GAN-generated images and produce a content-irrelevant representation for fake image attribution. A series of constraints are provided to guarantee the stability and discriminability of the ﬁngerprint, which in turn helps content-irrelevant feature extraction. Further, we perform comprehensive analysis on GAN ﬁngerprint, providing some clues about the properties of GAN ﬁngerprint and which factors dominate the ﬁngerprint in GAN architecture. Experiments show that our GFD-Net achieves superior fake image attribution performance in both closed-world and open-world testing. We also apply our method in binary fake image detection and exhibit a signiﬁcant generalization ability on unseen generators.
1. Introduction
The progressive generation technology has produced extremely realistic generated images, which raises big challenges to visual forensics. Dedicated research efforts are paid [9, 32, 24, 36, 15, 27, 3, 10] to detect generated images in recent years. However, only real/fake classiﬁcation is not the end: For malicious and illegal content, law enforcers need to identify its owner; For GAN developers, GAN mod-

Input Image
Input Image Input Image

Content-Irrelevant

Content-Relevant

Feature Extractor

Real/GAN1/GAN2/.../GANN

Encoder

(a) direct classification Content-Irrelevant

GAN Fingerprint Decoder

Real/GAN1/GAN2/.../GANN (b) proposed method

Figure 1. Comparison between (a) direct classiﬁcation method and (b) our method for fake image attribution. Features extracted by direct classiﬁcation unavoidably contain content-relevant components, while our method disentangles GAN ﬁngerprint from input images, and simultaneously produce a content-irrelevant representation for fake image attribution.

els needs experienced experts to design with laborious trialand-error testings and some have high commercial value, which should be protected. To these ends, we aim at the task of fake image attribution, i.e., attributing the origin of fake images.
In previous works, Marra et al. [25] take averaged noise image as the GAN ﬁngerprint, showing each GAN leaves its speciﬁc ﬁngerprint on the images it generates. Yu et al. [33] decouple the GAN ﬁngerprint into model ﬁngerprint and image ﬁngerprint. Speciﬁcally, they take the model’s output feature as image ﬁngerprint and the parameters in the last layer as model ﬁngerprint. Then attribution is achieved by the interaction between image and model ﬁngerprint. Frank et al. [10] leverage a frequency-domain view and take the discrete cosine transform (DCT) transformed image as classiﬁer’s input for source identiﬁcation.
While encouraging, there are two problems in existing

works: First, how to visualize GAN ﬁngerprint remains an open question. Although Marra et al. [25] and Yu et al. [33] propose to visualize the ﬁngerprint by averaged noise residual and auto-encoder reconstruction residual, the visualized ﬁngerprints still contain many redundant noise, which makes it hard to observe the difference between different GANs and the shared properties in the images from the same GAN. Therefore, we aim at generating GAN ﬁngerprints that are common and stable among images generated by the same GAN and distinct between different GANs.
Second, without additional supervision, direct classiﬁcation methods would harvest any useful features to help classiﬁcation, which may include many content-relevant information such as explicit artifacts as shown in Figure 1(a). However, a qualiﬁed GAN ﬁngerprint should remain stable no matter what content the GAN generates. Although the learned representation by classiﬁer-based method is discriminative enough to handle seen images, it may generalize poorly on images with different content. Therefore, we intend to make the model focus on content-irrelevant features.
In this paper, we propose a GAN Fingerprint Disentangling Network (GFD-Net) (Figure 1b). GFD-Net has two goals: 1) disentangle ﬁngerprints from GAN-generated images; 2) produce a content-irrelevant representation for fake image attribution. The two goals are achieved by the joint learning among a generator G, a discriminator D and an auxiliary classiﬁer C. G serves as a ﬁngerprint extractor, we overlap the extracted ﬁngerprint from G with a real image to obtain a ﬁngerprinted image. D and C make the learned ﬁngerprint content-irrelevant and discriminative by supervising the ﬁngerprinted image. The ﬁngerprint learning in turn helps G to extract content-irrelevant features that represent a certain GAN speciﬁcally. Thus we use the bottleneck feature of G for fake image attribution.
To demonstrate the effectiveness of GFD-Net, we conduct cross-dataset fake image attribution experiments and apply our method on cross-generator fake image detection. Extensive experiments demonstrate the superior generalization ability of our method.
With the disentangled ﬁngerprints, we further investigate the properties of GAN ﬁngerprint and qualitatively analyze which factors in GAN architecture dominate the ﬁngerprint. We show that GAN ﬁngerprint is mostly inﬂuenced by the construction and combination of layers, while changing feature channel number has less effect on it. To summarize, the contributions of this work include:
• We propose a GAN Fingerprint Disentangling Network (GFD-Net), which can disentangle the ﬁngerprint from GAN-generated images and simultaneously produce content-irrelevant representation for fake image attribution.

• We successfully extract GAN ﬁngerprints that are common and stable among images generated by the same GAN and distinct between different GANs. With the learned ﬁngerprint, we investigate the properties of GAN ﬁngerprints and qualitatively analyze how GAN architecture dominates GAN ﬁngerprint.
• Extensive experiments demonstrate that GFD-Net has superior generalization ability in not only fake image attribution but also fake image detection.
2. Related Work
Fake image detection. Along with the rapid development of generation technology, concerns are raised about the malicious use of generated images. Some researchers have paid effort to address the problem of fake image detection [9, 32, 24, 36, 15, 27, 3, 10]. Among these works, the generalization ability of the detection method has been paid close attention to. Some works [9, 10, 36] exploited the common checkerboard artifacts caused by upsampling operation in GAN architecture, and model this artifact in the frequency domain. Liu et al. [24] analyzed texture statistics of fake images and adopted the Gram matrix to capture global or long-range texture for better generalization ability. Wang et al. [32] experimented on images created from a variety of CNN models and revealed that there exist common artifacts generalized from one model to another. Jeon et al. [15] designed a transferable framework to improve the transferability of GAN image detection. Chai et al. [3] proposed to use classiﬁers with limited receptive ﬁelds to focus on local common artifacts shared by different GANs. However, these works explore little on the inherent difference between images from different GANs. We propose a novel network to disentangle the interpretable ﬁngerprint for each GAN. Fake image attribution. Fake image attribution can be classiﬁed into passive attribution [20, 34, 35] and positive attribution [25, 33, 33]. Works on positive attribution insert artiﬁcial ﬁngerprint [34, 35] or inject key [20] directly to the generation model and then decouple the ﬁngerprint or key when tracing the source model. Compared with positive attribution, passive attributing is more challenging and applicable. Marra et al. [25] ﬁnd averaged noise residual can represent the GAN ﬁngerprint. Frank et al. [10] observe the discrepant DCT frequency spectrums exhibited by images generated from different GAN architectures, and then send the DCT frequency spectrum into classiﬁers for source identiﬁcation. Yu et al. [33] decouple GAN ﬁngerprint into model ﬁngerprint and image ﬁngerprint. Speciﬁcally, they take the model’s output feature as image ﬁngerprint and the parameters in the last layer as model ﬁngerprint Then attribution is achieved by the interaction between model and image ﬁngerprint. However, the extracted ﬁngerprints by these works tend to contain content-relevant information

and thus lack generalization. In our work, we aim at using a learning-based method to disentangle content-irrelevant features from the input image for fake image attribution.

3. Proposed Method

3.1. Problem Formulation
Given an image xy with source y ∈ Y = {real, GAN1, GAN2, . . . , GANN }, where GAN1, . . . , GANN have different architectures. The goal of image attribution is to learn a mapping D(xy) → y [34]. There are two goals in our learning process: 1) to learn a contentirrelevant feature representation for fake image attribution, and 2) to visualize GAN ﬁngerprints that are common and stable among images generated by the same GAN and distinct between different GANs.

3.2. Network Structure

Figure 2 shows the overall architecture of GFD-Net. The

network adopts a GAN-like framework, which comprises a

generator G, a discriminator D, and an auxiliary classiﬁer

C. The ﬁngerprint generator G uses a U-Net [30] structure

with skip connections from the encoder Genc to the decoder Gdec. Genc projects the input image xy into a latent vector z, and then Gdec transforms xy into a ﬁngerprint f with the

same size as the input image.

Unlike conventional generators, we add a classiﬁcation

head H on z to make the learned feature more discrimi-

native. The classiﬁcation head comprises an average pool-

ing layer and a fully-connected layer, which takes the latent

code z as input and outputs the source prediction yˆ.

After getting the ﬁngerprint, we add it on a randomly selected real image xreal to generate a ﬁngerprinted image xf p :

xfp = xy + f

(1)

Then the ﬁngerprinted image xfp is sent to a discriminator D and an auxiliary classiﬁer C.
For the discriminator D, we use a PatchGAN architecture with 3 convolutional layers following the implementation in [14]. The objective of D is to classify the input image x as real and ﬁngerprint image xfp as fake. For the auxiliary classiﬁer C, we use a ResNet-50 [12] architecture. C is trained to predict the source of an image, which aims at making the ﬁngerprinted image classiﬁed as the same class as the input image.

3.3. Loss Functions

Having deﬁned the overall structure, we now move on to discuss how we formulate our objective for learning. Auxiliary Classiﬁcation Loss. The auxiliary classiﬁcation loss is added on the auxiliary classiﬁer, which is proposed to make the learned ﬁngerprint distinct between different

GANs. Based on a prior that if the learned ﬁngerprint is representative of its class, then when it is added on a real image, the ﬁngerprinted image should own similar properties with the input image that generate the ﬁngerprint. Thus, we employ an auxiliary classiﬁcation loss on the ﬁngerprinted image xfp and constrain it to be classiﬁed as the same class as the input image (i.e., C(xfp) → y) by minimizing

LcGls = LCE (C(xfp), y)

(2)

The auxiliary classiﬁer C is trained previously on the input images with multiples source by minimizing

LcCls = LCE (C(xy), y)

(3)

Adversarial Loss. The auxiliary classiﬁcation loss is proposed to make the learned ﬁngerprint representative of its class. However, with only an auxiliary classiﬁcation loss, the learned ﬁngerprint would still contain content-relevant information and become unstable within the same class. Hence, an adversarial loss is proposed to suppress the learning of content-relevant features.
The adversarial loss is introduced between the generator and discriminator aiming at making the ﬁngerprinted image xfp realistic. In this way, the generated ﬁngerprint f is expected to be visually imperceptible when added to a real image, which mediately forces the generator G to extract content-irrelevant features from input images. The adversarial losses for the discriminator and the generator are formulated as
LaDdv = E[log(1 − D(xfp))] + E[log(D(x)] (4)
LaGdv = E[log(D(xfp))]

When training D by minimizing LaDdv, D is encouraged to distinguish between ﬁngerprinted images and real GAN images (the input images). When training the generator G, the ﬁngerprinted images are expected to fool D. With D as a supervision, the generator learns to extract stable contentirrelevant ﬁngerprints from input images. Perceptual Loss. To further make the ﬁngerprinted image visually consistent with the real image and restrain the content-relevant information on the ﬁngerprinted image, we adopt a VGG-16 perceptual loss [16] between ﬁngerprint image and corresponding real image.

LpGercept = F (xfp) − F (xreal) 2

(5)

where · 2 denotes l2 distance, F denotes a VGG feature extraction model. Latent Classiﬁcation Loss. The latent classiﬁcation loss is added on the classiﬁcation head, which has two functions: 1) It makes the encoder learn discriminative feature of each class and helps the generation of representative ﬁngerprint. 2) The ﬁngerprint learning process in turn helps the encoder

Input Image

Real Image Fingerprint Fingerprinted Image

Figure 2. Overall framework of GFD-Net. (1) The generator G takes in an image xy with source y as input and outputs a ﬁngerprint, then the ﬁngerprint is added on a real image to composite a ﬁngerprinted image. (2) The auxiliary classiﬁer C supervises the ﬁngerprinted image to be classiﬁed as the class of the input image, and thus forces the generator G to generate ﬁngerprint with discriminative properties. (3) The discriminator D forces the ﬁngerprinted image to be realistic, and thus demands G to generate visually imperceptible and content-irrelevant ﬁngerprint. (4) A perceptual loss is applied on the ﬁngerprinted image and corresponding real image to further suppress content-irrelevant clues on the learned ﬁngerprint. (5) The ﬁngerprint learning process helps the encoder Genc to learn a representation which is both content-irrelevant and discriminative. Then a classiﬁcation head H is added on the latent code z for fake image attribution.

to produce a content-irrelevant representation, then the la-

tent classiﬁcation loss is optimized to map the latent code z

to the source y for fake image attribution and is formulated

as

LzG = LCE(H(z), y)

(6)

where LCE is the cross entropy loss for classiﬁcation.

3.4. Overall Objective

Combining all components described above, our two objectives are achieved: 1) The generator G takes an image as input and outputs the ﬁngerprint corresponding to its source. 2) Beneﬁt from ﬁngerprint learning, the encoder Genc produces a content-irrelevant and discriminative representation which facilitates fake image attribution. The classiﬁcation head H attributes the input image to its source.
The training process contains two steps: In the ﬁrst step, we train generator G with D and C ﬁxed. In the next step, we keep G ﬁxed and train D and C. Overall, the objective for the generator (include the classiﬁcation head) is formulated as

LG = ω1LzG + ω2LaGdv + ω3LcGls + ω4LpGercept

(7)

and the objective for the discriminator and the auxiliary classiﬁer is formulated as

LD,C = LcCls + LaDdv

(8)

where ωi(i = 1, . . . , 4) are non-negative weights.

4. Experiments
4.1. Setup
Baselines. We compare GFD-Net with the following methods: 1) PRNU [25]: a method using photo-response non-

uniformity (PRNU) patterns as the ﬁngerprint for fake image attribution. 2) DCT [10]: a frequency-based method that uses DCT transformed images for fake image attribution and detection. 3) AttNet [33]: a PatchGAN-like classiﬁer for fake image attribution. 4) CNNDetect [32]: a fake image detection method which uses ResNet-50 as classiﬁer. 5) PatchForensics [3]: use classiﬁers with limited receptive ﬁelds to focus on common artifacts generalized between different GAN models. 6) Xception [7] and DenseNet [13]: two widely-used CNNs for image representation.
Implementation details. Adam optimizer is used with initial learning rate 1e-4. We use a step decay scheduler with gamma as 0.9 and step size as 500. We set ω1, ω2, ω3 and ω4 as 10,1e-1,1,1 for fake image attribution experiment and 10,1e-2,1,1 for fake image detection experiment.
Datasets. For fake image attribution in Section 4.2, we consider following GAN architectures: ProGAN [17], MMDGAN [1], SNGAN [26] and InfoMaxGAN [21], StyleGAN [18], StyleGAN2 [19]. For fake image detection in Section 4.3, we use ForenSynths dataset [32], which include 13 synthesis algorithms: ProGAN, StyleGAN, StyleGAN2, whichfaceisreal(WFIR)1, BigGAN [2], CycleGAN [37], StarGAN [6], GauGAN [28], Cascaded Reﬁnement Networkd(CRN) [5], Implicit Maximun Likelihood Estimation(IMLE) [22], Second Order Attention Network (SAN) [8], Seeing In The Dark(SITD) [4] and FaceForensics++(FF++) [31].
Evaluation Metric. We use classiﬁcation accuracy to evaluate the performance.
1https://www.whichfaceisreal.com/

Real

GAN1

GAN2

GAN3

GAN4

Multi-class Classification

Real

GAN1 GAN3

GAN2 GAN4

Generator 1 Real Generator 1 Real

Binary Classification

Generator 2 Real Generator 3 Real

Generator N ...

Real Real

(a) cross-dataset fake image attribution

(b) cross-generator fake image detection

Figure 3. Illustration of our two generalization experiments: (1) In cross-dataset fake image attribution experiment, we evaluate the generalization ability on fake images generated by GANs trained on different dataset. (2) In cross-generator fake image detection, we evaluate the generalization ability on images from different generators.

4.2. Cross-Dataset Fake Image Attribution
In this section, we conduct experiments on cross-dataset fake image attribution as illustrated in Figure 3(a). To avoid the resolution inﬂuence, two experiments are implemented on 128 px and 1024 px resolution GANs respectively. For each resolution, we test in closed world and open world, depending on whether or not the images in the testing set are generated by the same set of GAN models used in training. We compare with PRNU, DCT and AttNet that are originally proposed for fake image attribution.
4.2.1 Evaluation on 128px GANs
The experiment is conducted on 5 classes: real, ProGAN, MMDGAN, SNGAN and InfoMaxGAN. For each GAN architecture, we use two models trained respectively on CelebA dataset [23] and LSUN bedroom dataset [29]. We sample 20k images equally from CelebA, ProGAN-CelebA, MMDGAN-CelebA, SNGAN-CelebA and InfoMaxGANCelebA and then split each set into 15k training, 1k validation, and 4k for closed world testing. To evaluate the generalization capability across training dataset, we conduct open world testing on LSUN, ProGAN-LSUN, MMDGANLSUN, SNGAN-LSUN, and InfoMaxGAN-LSUN with 4k images for each class. -CelebA/LSUN means the model is trained on CelebA/LSUN dataset. To make the models focus on local patterns, we resize all images from 128px to 512px, then in training and testing we random and center crop the images to 224px patches.
The comparison results are listed in Table 1. In closed world testing, all methods achieve good performance (> 90% accuracy) and our method performs perfectly (∼ 100% accuracy). However, in open world testing, the performance degrades cross all methods, which demonstrates the training data of generation models largely inﬂuences the accuracy of fake image attribution. Our method achieves state-of-theart performance in open-world testing, showing our method captures more content invariant features relating to the ar-

Method
PRNU [25] DCT [10] AttNet [33] GFD-Net(Ours)

Closed-world
92.23 94.40 99.44 99.99

Open-world
18.57 51.26 65.18 78.72

Table 1. Accuracy(%) on 128px cross-dataset fake image attribution. The best results in each column are boldfaced.

chitecture of GAN networks.
4.2.2 Evaluation on 1024px GANs
The experiment is conducted on 4 classes: real, StyleGAN, StyleGAN2 and ProGAN. We sample 10k real images equally from FFHQ [2] and CelebAHQ, and 20k generated images equally from the public available StyleGANFFHQ, StyleGAN2-FFHQ and ProGAN-CelebHQ, resulting in a dataset with 20k images for each class. Then we split each set into 15k training, 1k validation, and 4k for closed world testing. To evaluate the generalization ability, we conduct open world testing on several StyleGAN and StyleGAN2 models trained on diverse datasets collected from 2. The open-world StyleGAN models include 10 models trained respectively on Yellow, Model, Asian stars, kids, elders, adults, people wearing glasses, male, female, and people with a smile. The open-world StyleGAN2 models include 4 models trained on Yellow, Model, Asian stars and kids. We generate 4k images from each model for testing. The generated samples are shown in the supplementary material. We apply random crop in training and center crop in testing on the images to 224 pixels.
The results in Table 2 show that GFD-Net consistently outperforms baseline methods when tested on open-world StyleGAN and StyleGAN2 models. Speciﬁcally, the performance of PRNU, DCT and AttNet degrades largely on StyleGAN2-model and StyleGAN2-Asian-star, which may
2http://www.seeprettyface.com/mydataset.html

Method

Closed world

open world StyleGAN

Yellow Model Asian star kid elder adult glass male female smile

PRNU [25] DCT [10] AttNet [33] GFD-Net(Ours)

76.32 99.95 99.20 99.43

67.73 50.83 93.53 97.85

67.33 38.75 89.53 92.40

57.45 33.35 76.90 92.30

62.53 59.63 71.68 60.98 65.88 35.43 48.88 43.38 43.55 40.15 98.13 99.08 99.13 99.48 99.68 98.80 99.08 99.23 99.50 99.63

71.08 41.52 99.05 99.28

73.15 49.69 98.91 99.30

open world StyleGAN2

Yellow Model Asian star kid

17.63 30.78 99.00 99.78

9.58 0.20 0.00 63.95

6.70 0.78 0.36 84.48

15.35 5.03 96.65 99.95

Table 2. Accuracy(%) on 1024px cross-dataset fake image attribution. The best results in each column are boldfaced.

Method

Unconditional GAN

ProGAN StyleGAN StyleGAN2 WFIR BigGAN

PRNU [3] DCT [10] AttNet [33] Xception [7] DenseNet [13] PatchForensics [3] CNNDetect [32]

54.03 69.06 67.21 83.90 93.30 85.31 94.04

47.88 78.94 54.76 54.34 73.21 72.27 67.58

48.29 66.94 65.14 50.71 63.78 71.25 57.97

45.9 67.95 49.35 50.10 80.70 70.35 63.15

46.85 57.58 50.65 52.68 57.55 69.54 55.68

GFD-Net (DenseNet) GFD-Net (ResNet50)

93.85 95.53

76.73 80.20

69.47 66.26

79.45 74.05

62.78 64.65

Test set Accuracy

Conditional GAN

CycleGAN StarGAN GauGAN

48.26 71.04 50.83 63.55 73.66 69.22 63.97

41.22 98.50 57.63 50.03 86.47 68.71 73.29

50.87 73.92 48.06 55.73 60.72 67.43 55.71

75.85 78.73

96.90 93.40

67.73 67.94

Perceptual loss

CRN IMLE

51.97 61.59 43.83 68.71 97.66 63.47 98.32

50.92 71.29 47.50 94.48 94.45 61.18 96.26

98.13 97.16 92.39 94.31

Low-level vision

SAN STID

51.07 25.06 49.64 48.21 57.28 61.12 54.79

48.06 82.50 55.28 58.33 77.22 61.14 86.67

61.10 56.09

83.61 85.00

Total

DeepFake Avg. FF++

50.62 46.72 50.53 50.08 59.94 60.50 90.82

48.92 67.01 53.11 60.24 75.07 67.81 73.71

87.75 90.47

80.81 79.92

Table 3. Accuracy(%) on cross-generator fake image detection. The best and second-best results in each column are boldfaced and underlined respectively. In the last column, we show the averaged accuracy over all test sets.

be because the datasets used to train the two models are very different from FFHQ dataset used to train the closedworld model. However, our model can still maintain certain accuracy on these two models, showing the generalization ability of our method in open-world fake image attribution.
4.3. Cross-Generator Fake Image Detection
Direct binary fake image detection would probably ﬁt to some explicit artifacts and thus hinder generalization. Our method can extract content irrelevant traces from fake images, which is also helpful for improving transfer performance on real/fake classiﬁcation. In this section, we evaluate our method on cross-generator fake image detection as illustrated in Figure 3(b). We use ForenSynths dataset for experiment. We train solely on ProGAN-airplane vs. LSUN-airplane and test on 13 test sets from 13 synthesis algorithms. We apply random crop in training and center crop in testing on the images to 224 pixels. No data augmentation is included for fair comparison. Two our models are trained with DenseNet and ResNet as backbone, denoted as GFD-Net(ResNet50) and GFD-Net(DenseNet) respectively.
Table 3 summarizes the results. Comparing the results, we have following ﬁndings: 1) GFD-Net shows better transferability than baselines on the average. Although GFDNet does not always outperforms all baselines, it usually gets a second highest accuracy which is very close to the highest, indicating that our method captures the commonshared fake traces on the test sets. 2) Comparing GFD-

Method
G G+D G+C G+D+C G+D+C +Lpercept

Closed-world
99.99 99.97 99.99 99.99 99.99

Open-world
74.77 72.86 74.70 76.40 78.72

Table 4. Quantitative analysis on 128px cross-dataset fake image attribution. The best results in each column are boldfaced.

Net(ResNet50) and CNNDetect which both use ResNet50 as the backbone, large improvements can be observed on most test sets especially on StyleGAN, CycleGAN, StarGAN, and GauGAN. Similar large improvements can also be found when comparing GFD-Net(DenseNet) and DenseNet, the accuracy on StarGAN, GauGAN and FF++ improves at least 10%. Note that GFD-Net(ResNet50) and GFD-Net(DenseNet) only use the encoder with a classiﬁcation head at inference time, which have the same architectures with ResNet50 and DenseNet. This result demonstrates that the ﬁngerprint learning process in our model helps the generator to capture more generalized fake traces from input images and thus improves the generalization ability.
4.4. Ablation Study
4.4.1 Quantitative Analysis
To conﬁrm the effectiveness of each component, we evaluate how generalization capacity is improved on 128px fake

StyleGAN

StyleGAN2

ProGAN(1024)

ProGAN(128)

MMDGAN

SNGAN

InfoMaxGAN

Figure 4. Generated ﬁngerprints by our method on images from StyleGAN, StyleGAN2, ProGAN(1024), ProGAN(128), MMDGAN, SNGAN and InfoMaxGAN.

image attribution. Our baseline is the generator G with a classiﬁcation head. We compare G, G+D, G+C, G+D+C and G+D+C+Lpercept. The results are reported in Table 4. In closed-world testing, all methods has good performance, the difference mainly exists in open-world testing. In open-world testing, the baseline model can achieve an accuracy of 74.77%. Adding C or D alone to the baseline model doesn’t improve the performance. However, with C and D both added, the accuracy increases from 74.77% to 76.40%, which demonstrates that D and C functions collaboratively to help improve the generalization ability. With Lpercept further added, the accuracy further increases from 76.40% to 78.72%, showing Lpercept also helps the generator to capture generalized content-irrelevant features.
4.4.2 Qualitative Analysis
We do qualitative analyses to demonstrate the effect of each component on ﬁngerprint generation. In Figure 5, we visualize the ﬁngerprints generated by G+C, G+D+C and G+D+C+Lpercept. The ﬁrst row contains an input image

generated by SNGAN and extracted ﬁngerprints from the input image by different networks. The second row contains a real image and ﬁngerprinted images (add extracted ﬁngerprints in the ﬁrst row on the real image).
Comparing the generation results, with auxiliary classiﬁer C only (Figure 5b), the generator can extract a ﬁngerprint with periodic patterns. However, the ﬁngerprint contains much semantic information such as eyes, nose, and eyebrow, which are evidently exhibited on the ﬁngerprinted image. With D added (Figure 5c), the semantic content is largely suppressed and clear texture is shown on the extracted ﬁngerprint, which demonstrates that adversarial learning helps the generator extract content-irrelevant patterns from the input image. Though the ﬁngerprint leaves little traces on the ﬁngerprinted image, some subtle traces can still be perceived (in the green box). With Lpercept added (Figure 5d), the traces in the green box are eliminated, which indicates that the perceptual loss further inhibits the generator from learning semantic clues from the input image.

Input Image

Generated Fingerprints

Real Image Real Image

Fingerprinted Images

(a)

(b)

(c)

(d)

Figure 5. Qualitative analysis on ﬁngerprint generation. (a) Input image from SNGAN (top) and real image (bottom). (b)(c)(d) Generated ﬁngerprint (top) and ﬁngerprinted image (bottom) by G+C, G+C+D and G+C+D+Lpercept, respectively.

4.5. Fingerprint Analysis
What do GAN ﬁngerprints look like? Figure 4 visualizes the ﬁngerprints extracted from StyleGAN, StyleGAN2, ProGAN(1024), ProGAN(128), MMDGAN, SNGAN and InfoMaxGAN. Fingerprints of 1024px GAN are extracted from cropped patches. Our model successfully disentangles ﬁngerprints from GAN images, which are common and stable among all generated by the same GAN and different between different GANs. We ﬁnd that the ﬁngerprints share similar periodic characteristics among all types of generalized images. The difference between different types mainly exists in the thickness, stretch direction, and bending of the ﬁngerprint. We also ﬁnd GAN ﬁngerprints exist globally in images no matter in textured regions or smooth regions.
Qualitative analysis on GAN Fingerprints. We calculate the gray-level co-occurrence matrix (GLCM) [11] from the generated ﬁngerprints. From the GLCM, we compute texture correlation Cdθ, which measures how correlated a pixel is to its neighbor at d distance offset and θ direction offset. We calculate Cdθ on the ﬁngerprints generated from 1000 samples for each GAN, where d ∈ {2, 4, 8, 16} and θ ∈ {0, π/4, π/2, 3π/4}. Then for each ﬁngerprint image, we get a 4 × 4 correlation matrix for every combination of d and θ. We reshape the matrix into a vector and calculate its mean and variance. As Figure 6 shows, the ﬁngerprints of different GANs have distinct correlation vectors, indicating each GAN has its speciﬁc property. The correlation is relatively larger in positions such as (2, π/4), (2, 3π/4) and (4, 3π/4), showing a stronger correlation between adjacent pixels in π/4 and 3π/4 direction.
Which factors dominate GAN ﬁngerprints? We generate images awith the publicly available StyleGAN2 models with six conﬁgurations (Conﬁg A to F, where A and F correspond to ofﬁcial StyleGAN and StyleGAN2 respectively). Then we extract ﬁngerprints from these images with our ﬁngerprint generator. The result in Figure 7 shows that: 1)

Figure 6. Means and variances of GLCM correlation vectors calculated on generated images from StyleGAN, StyleGAN2, ProGAN(1024), ProGAN(128), MMDGAN, SNGAN and InfoMaxGAN.

A: Baseline StyleGAN

B: + Weight demodulation

C: + Lazy regularization

D: +Path length regularization E: + No growing, new G & D arch F: + Large Network

Figure 7. Fingerprint extraction results of StyleGAN2 with Conﬁg A ∼ F.
The image generated by Conﬁg E model has the same ﬁngerprint with Conﬁg F (StyleGAN2). 2) Fingerprints under Conﬁg B,C, and D appear to be a combination of the StyleGAN and StyleGAN2 ﬁngerprint. Comparing these architectures, instance normalization is replaced by a demodulation operation from Conﬁg A to B, which injects StyleGAN2 ﬁngerprint onto the image. From Conﬁg D to E, the feedforward generator and discriminator are replaced by a skip generator and a residual discriminator, which results in a pure StyleGAN2 ﬁngerprint on the image. From Conﬁg E to F, the number of feature maps is doubled, which has little inﬂuence on the ﬁngerprint. The results demonstrate that the construction and combination of layers (replace instance normalization with demodulation operation and change feed-forward network to skip-and-residual network) have larger inﬂuence on the ﬁngerprint, while changing feature channel number have less effect.
5. Conclusion
We propose GFD-Net to disentangle the ﬁngerprint from GAN-generated images and attributing fake images to their

sources simultaneously. Experiment results demonstrate the effectiveness and generalization ability of the network in not only fake image attribution but also detection. We further analyze different GAN ﬁngerprints, showing they share similar periodic patterns and distinct in the speciﬁc textures. We also ﬁnd GAN ﬁngerprint is mostly dominated by the construction and combination of layers. We believe our work advances both fake image attribution and detection, and would bring some insights to GAN dissection.
References
[1] Mikołaj Bin´kowski, Dougal J. Sutherland, Michael Arbel, and Arthur Gretton. Demystifying MMD GANs. In International Conference on Learning Representations, 2018. 4
[2] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale GAN training for high ﬁdelity natural image synthesis. In International Conference on Learning Representations, 2019. 4, 5
[3] Lucy Chai, David Bau, Ser-Nam Lim, and Phillip Isola. What makes fake images detectable? understanding properties that generalize. In European Conference on Computer Vision, pages 103–120. Springer, 2020. 1, 2, 4, 6
[4] Chen Chen, Qifeng Chen, Jia Xu, and Vladlen Koltun. Learning to see in the dark. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3291–3300, 2018. 4
[5] Qifeng Chen and Vladlen Koltun. Photographic image synthesis with cascaded reﬁnement networks. In Proceedings of the IEEE international conference on computer vision, pages 1511–1520, 2017. 4
[6] Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, and Jaegul Choo. Stargan: Uniﬁed generative adversarial networks for multi-domain image-to-image translation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 8789–8797, 2018. 4
[7] Franc¸ois Chollet. Xception: Deep learning with depthwise separable convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1251–1258, 2017. 4, 6
[8] Tao Dai, Jianrui Cai, Yongbing Zhang, Shu-Tao Xia, and Lei Zhang. Second-order attention network for single image super-resolution. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11065–11074, 2019. 4
[9] Ricard Durall, Margret Keuper, and Janis Keuper. Watch your up-convolution: Cnn based generative deep neural networks are failing to reproduce spectral distributions. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7890–7899, 2020. 1, 2
[10] Joel Frank, Thorsten Eisenhofer, Lea Scho¨nherr, Asja Fischer, Dorothea Kolossa, and Thorsten Holz. Leveraging frequency analysis for deep fake image recognition. In International Conference on Machine Learning, pages 3247–3258. PMLR, 2020. 1, 2, 4, 5, 6

[11] Robert M Haralick, Karthikeyan Shanmugam, and Its’ Hak Dinstein. Textural features for image classiﬁcation. IEEE Transactions on systems, man, and cybernetics, (6):610–621, 1973. 8
[12] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016. 3
[13] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. Densely connected convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4700–4708, 2017. 4, 6
[14] Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with conditional adversarial networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1125–1134, 2017. 3
[15] Hyeonseong Jeon, Young Oh Bang, Junyaup Kim, and Simon Woo. T-gd: Transferable gan-generated images detection framework. In International Conference on Machine Learning, pages 4746–4761. PMLR, 2020. 1, 2
[16] Justin Johnson, Alexandre Alahi, and Li Fei-Fei. Perceptual losses for real-time style transfer and super-resolution. In European conference on computer vision, pages 694–711. Springer, 2016. 3
[17] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017. 4
[18] Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative adversarial networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4401–4410, 2019. 4
[19] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improving the image quality of stylegan. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8110–8119, 2020. 4
[20] Changhoon Kim, Yi Ren, and Yezhou Yang. Decentralized attribution of generative models. arXiv preprint arXiv:2010.13974, 2020. 2
[21] Kwot Sin Lee, Ngoc-Trung Tran, and Ngai-Man Cheung. Infomax-gan: Improved adversarial image generation via information maximization and contrastive learning. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 3942–3952, 2021. 4
[22] Ke Li, Tianhao Zhang, and Jitendra Malik. Diverse image synthesis from semantic layouts via conditional imle. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 4220–4229, 2019. 4
[23] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In Proceedings of the IEEE international conference on computer vision, pages 3730–3738, 2015. 5
[24] Zhengzhe Liu, Xiaojuan Qi, and Philip HS Torr. Global texture enhancement for fake face detection in the wild. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8060–8069, 2020. 1, 2

[25] Francesco Marra, Diego Gragnaniello, Luisa Verdoliva, and Giovanni Poggi. Do gans leave artiﬁcial ﬁngerprints? In 2019 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR), pages 506–511. IEEE, 2019. 1, 2, 4, 5, 6
[26] Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for generative adversarial networks. In International Conference on Learning Representations, 2018. 4
[27] Lakshmanan Nataraj, Tajuddin Manhar Mohammed, BS Manjunath, Shivkumar Chandrasekaran, Arjuna Flenner, Jawadul H Bappy, and Amit K Roy-Chowdhury. Detecting gan generated fake images using co-occurrence matrices. Electronic Imaging, 2019(5):532–1, 2019. 1, 2
[28] Taesung Park, Ming-Yu Liu, Ting-Chun Wang, and Jun-Yan Zhu. Gaugan: semantic image synthesis with spatially adaptive normalization. In ACM SIGGRAPH 2019 Real-Time Live!, pages 1–1. 2019. 4
[29] Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015. 5
[30] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. Unet: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer-assisted intervention, pages 234–241. Springer, 2015. 3
[31] Andreas Rossler, Davide Cozzolino, Luisa Verdoliva, Christian Riess, Justus Thies, and Matthias Nießner. Faceforensics++: Learning to detect manipulated facial images. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 1–11, 2019. 4
[32] Sheng-Yu Wang, Oliver Wang, Richard Zhang, Andrew Owens, and Alexei A Efros. Cnn-generated images are surprisingly easy to spot... for now. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8695–8704, 2020. 1, 2, 4, 6
[33] Ning Yu, Larry S Davis, and Mario Fritz. Attributing fake images to gans: Learning and analyzing gan ﬁngerprints. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 7556–7566, 2019. 1, 2, 4, 5, 6
[34] Ning Yu, Vladislav Skripniuk, Sahar Abdelnabi, and Mario Fritz. Artiﬁcial gan ﬁngerprints: Rooting deepfake attribution in training data. arXiv e-prints, pages arXiv–2007, 2020. 2, 3
[35] Ning Yu, Vladislav Skripniuk, Dingfan Chen, Larry Davis, and Mario Fritz. Responsible disclosure of generative models using scalable ﬁngerprinting. arXiv preprint arXiv:2012.08726, 2020. 2
[36] Xu Zhang, Svebor Karaman, and Shih-Fu Chang. Detecting and simulating artifacts in gan fake images. In 2019 IEEE International Workshop on Information Forensics and Security (WIFS), pages 1–6. IEEE, 2019. 1, 2
[37] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation using cycleconsistent adversarial networks. In Proceedings of the IEEE international conference on computer vision, pages 2223– 2232, 2017. 4

