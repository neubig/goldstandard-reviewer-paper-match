arXiv:2108.02126v1 [cs.GT] 4 Aug 2021

I Will Have Order! Optimizing Orders for Fair Reviewer Assignment
Justin Payan1[0000−0001−7601−3500] and Yair Zick1[0000−0002−0635−6230]
University of Massachusetts Amherst, Amherst MA 01002, USA {jpayan, yzick}@umass.edu
Abstract. Scientiﬁc advancement requires eﬀective peer review. Papers should be reviewed by experts in the subject area, but it is equally important that reviewer quality is fairly distributed amongst papers. We model reviewer assignment as an instance of a fair allocation problem, presenting an extension of the classic round-robin mechanism, called Reviewer Round Robin (RRR). Round-robin mechanisms are a standard tool to ensure envy-free up to one item (EF1) allocations. However, fairness often comes at the cost of decreased eﬃciency. To overcome this challenge, we carefully select an approximately optimal round-robin order. Applying a relaxation of submodularity, γ-weak submodularity, we show that greedily inserting papers into an order yields a (1 + γ2)-approximation to the maximum welfare attainable by our round-robin mechanism under any order. Our approach outputs highly eﬃcient EF1 allocations for three real conference datasets, outperforming several state-of-the-art paper assignment methods in fairness, eﬃciency and runtime.
Keywords: Fair Allocation · Envy-Free up to One Item · Reviewer Assignment
1 Introduction
Peer review plays a prominent role in nearly every aspect of academia. In addition to screening scientiﬁc contributions, peer review is also a major component in grant applications, book reviews, and academic promotions. Peer review serves a number of functions: selecting the best manuscripts, assessing originality, providing feedback, pointing out unacknowledged prior work, deciding the signiﬁcance of new work, as well as ﬂagging fraudulent or plagiarised work [27]. The results of peer review impact hiring, promotion, and tenure decisions indirectly through gatekeeping of prestige. Given the broad application of peer review and its signiﬁcant gatekeeping role, it is imperative that this process be as objective as possible.
One important parameter is whether reviewers possess the proper expertise for their assigned papers. Selecting reviewers for submitted papers is therefore a crucial ﬁrst step of any reviewing process. In large conferences such as NeurIPS/ICML/AAAI/IJCAI, reviewer assignment is largely automated through systems such as the Toronto Paper Matching System (TPMS) [15], Microsoft

2

J. Payan and Y. Zick

CMT1, or OpenReview2. Inappropriately assigned reviewers may lead to failures: misinformed decisions, reviewer disinterest, and a general mistrust of the peer-review process.
Accuracy and fairness are two important criteria in reviewer assignment [30], and fair division in general [9]. Overall assignment accuracy enables global objectives, such as maintaining quality standards for conferences, grants, and journals. However, it is imperative that we do not sacriﬁce review quality on some papers to obtain higher overall matching scores. Papers which receive poorly matched reviewers may be unfairly rejected or receive unhelpful feedback, causing the authors real harm. We thus desire algorithms which are globally accurate and fair.
To accomplish these goals, we consider the fair reviewer assignment problem as an instance of a fair allocation problem. The theory of fair allocation oﬀers a principled way of discussing fairness and optimality in assignment problems.
Our principal fairness criterion is envy: one paper envies another paper if it prefers the other’s assigned reviewers over its own. It is generally not possible to obtain envy-free allocations for indivisible items [9], so we focus on the criterion of envy-free up to one item (EF1) [12, 25]. We require that for all pairs of papers, either paper i does not envy paper j, or paper j has a reviewer r such that paper i would not envy j if that reviewer were dropped. In standard fair allocation settings, the well-known round-robin (RR) mechanism produces EF1 allocations by setting an order of agents, and letting them select one item at a time. However, the constraint that no paper can be reviewed by the same reviewer twice makes round-robin not EF1. To mitigate this problem, we present a variation on classic RR, which we term Reviewer Round Robin (RRR).
While RR mechanisms are known to satisfy fairness constraints, their eﬃciency guarantees are highly dependent on the order in which players pick items. For example, consider a stylized setting where there are two papers (i and j) and two reviewers (r1 and r2): paper i views both reviewers as equally qualiﬁed, and assigns them an aﬃnity score of 5 each; paper j is highly aﬃliated with r1, but has zero aﬃliation with r2, assigning a score of 10 to r1 and 0 to r2. A roundrobin mechanism that lets i pick ﬁrst runs the risk of having i pick r1, leaving j with r2. Letting j pick ﬁrst would have resulted in a much better outcome, without compromising on fairness. Prior works show that it is generally diﬃcult to identify optimal picking sequences [3, 4, 10, 21], which raises the question: can we identify approximately optimal player orders? This is where our work comes in.

1.1 Our Contributions
We run a combinatorial search for orders of papers that yield high eﬃciency allocations under the RRR mechanism. To do so, we examine the problem of ﬁnding an optimal paper order via the lens of submodular optimization. To do
1 https://cmt3.research.microsoft.com/ 2 https://github.com/openreview/openreview-matcher

I Will Have Order! Optimizing Orders for Fair Reviewer Assignment

3

so, we optimize a function on partial player sequences, which varies according to the welfare of the RRR allocation respecting that partial sequence. Though this function is not submodular in general, we can capture its distance from submodularity via a variable γ. Our main theoretical result (Theorem 2), which is of independent interest, shows that a simple greedy approach maximizes this function up to a factor of 1 + γ2.
We implement our greedy RRR algorithm, and test it on three real-world conference datasets. We compare our approach to four other state-of-the-art paper assignment frameworks. Not only is RRR the only provably EF1 approach, it is considerably faster than the only other method with comparable fairness metrics. Finally, RRR maintains high utility guarantees, consistently outperforming its computationally feasible competitors.

1.2 Related work
The reviewer assignment problem has been extensively studied (see [32] for a survey). Most works model the problem as a mixed-integer linear program; the Toronto Paper Matching System (TMPS) is perhaps the most notable early work presenting this formulation [15, 16]. Most works assume a list of submitted papers and available reviewers, along with a matrix of aﬃnities for each reviewer-paper pair [15, 22]. It is assumed that these aﬃnities accurately model the expected review quality provided by each reviewer for each paper. In general, existing work has sought to maximize the sum of the aﬃnities of all reviewer-paper pairs (the utilitarian social welfare) subject to load constraints on reviewers and coverage requirements for papers [15, 17, 22, 31].
A number of prior works consider fairness objectives in peer review, though none of them consider envy-freeness up to one item. Hartvigsen et al. [20] ensure that at least one qualiﬁed reviewer is assigned to each paper. Kobren et al. [22] present two algorithms, FairFlow and FairIR, that maximize the sum of paper scores subject to the constraint that every paper must receive a paper score above a speciﬁed threshold. O’Dell et al. [28] maximize the minimum paper score, noting that this objective may be at odds with maximizing the sum of paper scores. The PeerReview4All algorithm from Stelmakh et al. [31] extends the maxmin objective by maximizing the minimum paper score, then maximizing the next smallest paper score, etc. There are important connections to social choice objectives; maximizing the minimum paper score is equivalent to maximizing egalitarian welfare, while PeerReview4All maximizes the leximin criterion. A number of works study fair assignment of papers to reviewers, allowing reviewers to express preferences over papers by bidding [2, 19, 24]. This setting aims to be fair to the reviewers rather than the papers, as is the case for our work3. Other works target reviewer assignments with properties besides fairness or eﬃciency; Long et al. [26] avoid conﬂicts of interest, while Kou et al. [23] and Ahmed et al.
3 We argue that it is more appropriate to treat reviewers, rather than papers, as goods: paper reviewing is generally viewed as a chore, not a beneﬁt (the current submission being an obvious exception), whereas papers do beneﬁt from appropriate reviews.

4

J. Payan and Y. Zick

[1] focus on assigning sets of reviewers with diverse interests and full coverage of the paper’s topics.
Existing work on fair allocation of indivisible items is also relevant. Bei et al. [7] and Barman et al. [5] study the price of fairness, the ratio between the maximum utilitarian welfare and the maximum utilitarian welfare for any fair allocation, for various fairness deﬁnitions. Caragiannis et al. [13] ﬁnd the price of envy-freeness to be Θ(n) for n agents, when an envy-free all√ocation exists. Bei et al. [7] show that the worst-case price of round-robin is O( n log(mn)) for n agents and m√goods, while Barman et al. [5] conclusively determine the price of EF1 is Θ( n) [5]. Barman et al. [6] show that maximizing the utilitarian welfare subject to EF1 is not polynomial-time approximable. Maximizing the utilitarian welfare under round-robin is also NP-complete. Aziz et al. [4] present a problem top-k PossibleSet, which given a class of allocation mechanisms (such as round-robin) determines if an agent a can receive their top-k goods. They show this problem is NP-complete for round-robin allocations. Following techniques from Aziz et al. [3], a simple reduction from top-k PossibleSet to the problem of determining if a given welfare is achievable through roundrobin proves that maximizing USW over round-robin orders is NP-complete. These results suggest that approximately maximizing the welfare over roundrobin allocations is a reasonable objective, especially for small log(mn).
Two works in fair allocation are particularly relevant for fair reviewer assignment, but they both have important limitations in our setting. Aziz et al. [2] present an algorithm which takes a constraint W as input, and outputs a W -satisfying EF1 allocation if possible. W can include a minimum threshold on utilitarian welfare, and it can also incorporate arbitrary constraints on allocations. Unfortunately, the runtime of CRR in our setting is Θ(nkT ), where n is the number of papers, k is the number of reviewers per paper, and T is the complexity of checking W (which is quite demanding). Biswas and Barman [8] present a modiﬁcation of the round-robin mechanism that assigns a complete EF1 allocation when items are partitioned into categories and agents can receive a limited number of items from each category. Their framework almost applies to reviewer assignment, but they do not include a way to limit the total number of items received by each agent. In addition, they oﬀer no eﬃciency guarantees beyond completeness.

2 Preliminaries
We represent reviewer assignment as a problem of allocating indivisible goods, with papers as agents and reviewers as goods. To simplify notation, given a set X and an element y, we often write X + y instead of X ∪ {y}. We are given a set of papers N = {1, . . . , n}, and a set of reviewers R = {r1, r2, . . . , rm}. Each paper i has a valuation over reviewers vi : R → R≥0, which deﬁnes how much value each reviewer provides to the paper. The value typically models alignment between reviewer expertise and paper topics, and can incorporate other relevant

I Will Have Order! Optimizing Orders for Fair Reviewer Assignment

5

notions like reviewer bids and conﬂicts of interest; several works study how these values are generated [15, 22], and are orthogonal to our work.
Papers generally receive more than one reviewer, so we deﬁne valuation functions over sets of reviewers. We assume additive valuation functions, where for all papers i ∈ N and subsets S ⊆ R, vi(S) = vi(r). An assignment or alloca-
r∈S
tion of reviewers to papers is an ordered tuple A = (A1, A2, . . . An) where each Ai ⊆ R is a set of distinct reviewers assigned to paper i. We can refer to Ai as paper i’s bundle.
Each reviewer r ∈ R has an upper bound cr on the number of papers they can review. No reviewer can be assigned to the same paper twice. To ensure a roughly even distribution of reviewers, we will require that each paper receives at most k reviewers. When all n papers are assigned k distinct reviewers, we call that allocation complete (and incomplete otherwise). We try to achieve complete allocations whenever possible.
We now discuss our notion of fairness. An allocation A is considered envy-free if for all pairs of papers i and j, vi(Aj) ≤ vi(Ai). This criterion is not achievable in general (consider the example of two papers and one reviewer r whose capacity is cr = 1), so we relax the criterion. An allocation A is envy-free up to one item (EF1) if for all pairs of papers i and j, there is a reviewer r ∈ Aj such that vi(Aj \ {r}) ≤ vi(Ai).
The utilitarian social welfare (“utilitarian welfare” or “USW”) of an allocation A is the sum of the papers’ valuations under that allocation:
USW(A) = vi(Ai).
i∈N
USW is a natural objective in the context of reviewer assignment, and has been used in many prior works on this topic [15, 17, 22, 31].
We also use the Nash social welfare or “NSW” as a second measure of eﬃciency in our experimental evaluation:
NSW(A) = vi(Ai).
i∈N
Nash welfare is another common eﬃciency measure, and allocations with high NSW provide a balance of eﬃciency and fairness [14].
For round-robin, we deﬁne an order on papers i ∈ N as a tuple O = (S, o), where S ⊆ N is the set of papers in the order and o : S → [|S|] is a permutation on S mapping papers to positions. We slightly abuse notation and say that a paper i ∈ O if i ∈ S. For any i, j ∈ O, we say that i ≺O j if and only if o(i) < o(j). We sometimes write i ≺ j when O is clear from context. We can think of an order O = (S, o) as an ordered list [o1, o2, . . . o|S|] such that ol = o−1(l) for all positions l. We use the notation O + i to indicate the order (S′, o′) that appends i to the end of O. Formally, S′ = S ∪ {i}, o′(j) = o(j) for j ∈ S, and o′(i) = |S′|.

6

J. Payan and Y. Zick

3 Fair and Eﬃcient Reviewer Assignment

3.1 Reviewer Round-Robin
We ﬁrst describe how to obtain EF1 reviewer assignments, before turning our attention to eﬃciency. To ensure EF1, our allocations will draw on the simple and well-known round-robin mechanism for assigning goods to agents. Given an ordered list of agents, round-robin proceeds in rounds. Each round, we iterate over the agents in the assigned order, allowing each agent to pick the highest valued remaining good. The process terminates when all goods have been chosen. The resulting allocation is EF1 for additive valuations by a simple argument [14]. For any agent i, we divide the item selections into rounds speciﬁc to that agent i. Round t(i0) includes the ﬁrst item chosen by all agents 1 through i − 1. Each round t(i1), t(i2), . . . t(is) consists of agent i selecting an item ﬁrst, followed by all other agents and ending with agent i − 1 or the last agent which receives the ﬁnal good in the ﬁnal round. For all rounds after t(i0), agent i prefers the item it selected over any other agent’s item selected in that round (in the last round, some agents may get nothing). Thus agent i prefers its own bundle to the bundle of any agent j ≻ i, and it prefers its own bundle to that of any agent j′ ≺ i if we ignore j′’s good from round t(i0).

Table 1. The naive constrained round-robin, where each agent takes the best reviewer they do not already have, fails for the example valuations shown below on 4 papers and 6 reviewers. Suppose cr = 2 for all r and k = 3. If we apply naive constrained roundrobin with the papers in increasing numerical order, we obtain the allocation (A1 = {r1, r5, r6}, A2 = {r4, r1, r3}, A3 = {r4, r5, r2}, A4 = {r3, r2, r6}). However, v4(A2 \r) ≥ 5 for all r ∈ A2, while v4(A4) = 4+ǫ. In contrast, the allocation (A1 = {r1, r5, r6}, A2 = {r4, r1, r2}, A3 = {r4, r5, r3}, A4 = {r3, r2, r6}) is EF1.

r1

r2

r3

r4

r5

r6

1

2

0

0

1

0.5

ǫ

2

3

1

2

10

0

0

3

0

ǫ

0

10

1

0

4

2

1

3

10

0

ǫ

In our setting, we have two additional constraints that are not present in the setting examined by Caragiannis et al. [14]. Papers must select at most k reviewers, and the reviewers must be distinct. A trivial modiﬁcation of roundrobin allows us to satisfy the ﬁrst constraint — proceed for exactly k rounds, then stop. We might naively update round-robin to satisfy the distinctness constraint as well, by allowing each paper to take the best reviewer they do not already have. However, the argument from Caragiannis et al. [14] fails. To see why, suppose a paper i selects a reviewer r in one round. In the next round, i may still prefer r over any other reviewer, but cannot select it. The paper may be forced to select a

I Will Have Order! Optimizing Orders for Fair Reviewer Assignment

7

Algorithm 1 Reviewer Round Robin (RRR)

Require: Reviewers R, limits cr, order O, valuation functions vi, bundle size limit k 1: Initialize allocation A as Ai ← ∅ for all papers i ∈ O 2: Initialize the ﬁrst-assigned reviewer of each agent to be Fi ← ∅ for all i 3: for Round t ∈ {1, . . . k} do 4: for i ∈ O in increasing order do

5:

for Reviewer r in decreasing order of vi(r) (break ties lexicographically) do

6:

if r is currently assigned to fewer than cr papers, and r ∈/ Ai then

7:

i attempts to take r

8:

if No j ≺ i that has attempted to take r envies Ai ∪ {r} and

no j ≻ i that has attempted to take r envies (Ai ∪ {r}) \ Fi then

9:

Ai ← (Ai ∪ {r})

10:

If t = 1, Fi ← {r}

11:

Move to the next paper

12:

If no new reviewer is assigned to i, return A

13: return A

much worse reviewer, allowing another paper to take that desired “second copy” of r. A more detailed counterexample is shown in Table 1.
We present a modiﬁcation of the round-robin mechanism that produces reviewer assignments which satisfy all constraints and are EF1. Algorithm 1 forbids any selection that violates a crucial invariant for proving EF1. This invariant derives from the proof of EF1 in the additive case. Any time a paper would select a reviewer such that EF1 would be violated, we forbid the selection and require the paper to select a diﬀerent reviewer. EF1 violations can only arise when another paper preferred to take that reviewer but could not, either because it had already taken it, or because it would have caused an EF1 violation for that paper as well. Papers always attempt to select reviewers in preference order. Thus when a paper i attempts to select a reviewer r, we only need to check for EF1 violations against the other papers that have attempted to select r in the past. Theorem 1 proves that Algorithm 1 produces EF1 allocations which satisfy all reviewer assignment constraints.
Theorem 1. Algorithm 1 terminates with an EF1 allocation where papers receive all distinct reviewers, no reviewer r is assigned to more than cr papers, and all papers have no more than k reviewers.
Proof. The algorithm assigns at most one reviewer to each paper in each round for k rounds, so the constraint that all papers receive at most k reviewers is satisﬁed. In addition, the algorithm always checks that r ∈/ Ai and the number of papers which already have r is no more than cr before assigning r to i. Thus no paper receives duplicate reviewers and reviewer upper bounds are satisﬁed.
We now prove that the returned allocation is EF1. Consider some arbitrary paper j; we show that j does not envy any other paper by more than 1 reviewer. As in the original round-robin argument, we divide the assignments of reviewers to papers into rounds t(j0), t(j1), . . . , t(js), where s ≤ k (s < k only when the

8

J. Payan and Y. Zick

algorithm terminates early). Round t(j0) contains the assignments made during

iteration 1 of Algorithm 1 to papers 1, . . . , j −1. Rounds t(j1) through tj(s−1) begin

with the assignment of a new reviewer to j and end with the assignment of a

new reviewer to j − 1, while round t(js) begins with assignment to j and ends

with assignment to some paper after j.

Consider the bundle A(it′) assigned to some paper i = j after the end of

some

round

t′

∈

{

t

(0) j

,

t

(1) j

,

.

.

.

t

(s) j

}

.

Recall

that

Fi

is

the

set

containing

the

ﬁrst

reviewer assigned to i in Algorithm 1. We will deﬁne modiﬁed bundles Bit′ for all

i,

and

prove

by

induction

that

vj

(B

( i

t′

)

)

≤

vj (A(jt′)).

For

all

t′,

let

Bi(t′ )

=

Ai(t′ )

if j ≺ i, and let Bi(t′) = (Ai(t′) \ Fi) if j ≻ i. For the base case, we see that after round t(j0), |Bi(t(j0))| = 0 for all i and

(t(0) )

(t(0) )

(t(0) )

|Aj j | = 0, so vj (Aj j ) = vj (Bi j ) = 0.

Now suppose that after round t′ − 1, we have vj(A(jt′−1)) ≥ vj(Bi(t′−1)) for

all i. Suppose there is some i such that after round t′, vj(Bi(t′)) > vj (Aj(t′)).

j selects a reviewer in all rounds except t(j0), and because valuations are non-

negative i must select a reviewer in round t′ to obtain vj(Bi(t′)) > vj(Aj(t′)). By

the inductive hypothesis and the fact that valuations are additive, j must prefer

the reviewer i chose in t′ (ri) to the reviewer j chose in t′ (rj ). Because j chose

ﬁrst in t′, this means that j attempted to take ri either in t′ or earlier and i

must have checked for envy against j.

If i ≺ j, then for i to successfully take ri we would require vj (Aj(t′)) ≤

vj (Ai(t′−1)

\

Fi

∪

{ri})

=

vj

(B

( i

t′

)

).

Similarly,

if

j

≺

i,

then

for

i

to

successfully

take

ri

we

require

vj (Aj(t′))

≤

vj (A(it′−1)

∪

{ri})

=

vj

(B

( i

t′

)

).

In both relative orders of j and i, we contradict our earlier assumption that

vj (Bi(t′)) > vj (Aj(t′)). This implies that vj (A(jt′)) ≥ vj (Bi(t′)) for all i and t′, in

particular t′ = t(js). Since Bi(t(js)) is either Ai(t(js)) = Ai or Ai \ Fi with |Fi| = 1,

we have that the ﬁnal allocation is EF1.

⊓⊔

It is fairly straightforward to show that RRR always returns a complete, EF1 allocation when the number of reviewers is large.

Proposition 1. Given a reviewer assignment problem with m reviewers, n papers, and k paper bundle size limits, where m ≥ kn, Algorithm 1 always returns a complete and EF1 allocation.

Proof. Algorithm 1 only refuses to assign a reviewer r to a paper i when r is assigned to too many papers, r has already been assigned to i, or some other paper that has attempted to take r “objects” to the assignment. Thus if we have assigned l < kn distinct reviewers under Algorithm 1, it must be the case that there is a reviewer r that has not been considered by any paper. Because

I Will Have Order! Optimizing Orders for Fair Reviewer Assignment

9

there are at least kn distinct reviewers, we can see that during any round of the algorithm, there will be such an unconsidered reviewer. Thus in any round, a paper can always select some reviewer that has never been considered by any paper, and the selection will not be refused. This proves that the allocation returned by Algorithm 1 is complete, and we have EF1 from Theorem 1. ⊓⊔
We hypothesize in Conjecture 1 that it is not always possible to assign all papers k reviewers and still achieve EF1; the existence of an instance that does not admit a complete EF1 assignment is left as an open problem.
Conjecture 1. There exists a reviewer assignment problem with papers N , reviewers R, valuation functions {vi}i∈N , reviewer load bounds {cr}r∈R, and paper bundle size limit k such that no allocation A is complete and EF1.

3.2 Optimizing Orders for RRR
We have shown how to provably obtain an EF1 allocation of reviewers to papers, but we have no welfare guarantees for this mechanism. In this section, we present a simple greedy approach to maximize the USW of the RRR mechanism by optimizing over the ordering of the papers. We deﬁne a function USWRRR(O, k, R, {cr}r∈R, {vi}i∈N ), which represents the USW from running Algorithm 1 on agents in the order O with reviewers R, reviewer limits cr, valuation functions vi, and paper bundle size limit k. When it is clear from context, we will drop most of the arguments, writing USWRRR(O) to indicate that we run Algorithm 1 with the order O and all other parameters deﬁned by the current problem instance. Our algorithm will maintain an order O, always adding the paper i which maximizes USWRRR(O + i).
The algorithm is presented in Algorithm 2. It returns an order on agents, which can be directly input to Algorithm 1 to obtain an EF1 allocation of reviewers. This algorithm is very simple and ﬂexible. It admits trivial parallelization, as the function USWRRR can be independently computed for each paper. One can also reduce runtime by subsampling the remaining papers at each step. Subsampling weakens the approximation guarantee in theory; while we do not attempt to analyze the approximation ratio of the subsampling approach in this work, we run our largest experiments with this variant, and still maintain good allocations. Let us now establish the welfare guarantees of Algorithm 2.
We ﬁrst review some important concepts and deﬁne terms which will be used in the proof. A matroid [29] is a pair (E, I) with ground set E and independent sets I, which must satisfy ∅ ∈ I. Independent sets must satisfy the inclusion property: ∀A ⊆ B ∈ I, A ∈ I, and the exchange property: ∀A, B ∈ I with |A| < |B|, ∃e ∈ B such that A ∪ {e} ∈ I. A partition matroid is deﬁned using categories B1, B2, . . . Bb and capacities d1, d2, . . . db; the independent sets are I = {I ⊆ E : ∀i, |I ∩ Bi| ≤ di}. Given two matroids over the same ground set (E, I1) and (E, I2), the intersection of the two matroids is the pair (E, {I : I ∈ (I1 ∩ I2)}). Note that the intersection of two matroids may not be a matroid [29].

10

J. Payan and Y. Zick

We also use the notion of a submodular set function; submodular functions formalize the notion of diminishing marginal gains. For a set function f : 2E → R,
a set X ⊆ E, and an element e ∈ (E \ X), we can write the marginal gain of adding e to X under f as ρfe (X) = f (X + e) − f (X) or simply ρe(X) if f is understood from context. Given a set E, a function f : 2E → R is submodular if for all X ⊆ Y ⊆ E and e ∈ E \ Y , ρfe (X) ≥ ρfe (Y ). A set function is monotone if for all X ⊆ Y ⊆ E, f (X) ≤ f (Y ). We deﬁne the notion of γ-weak submodularity
for monotone, non-negative functions. Given a monotone, non-negative function f : 2E → R≥0, we say that f is γ-weakly submodular if for all X ⊆ Y ⊆ E and e ∈ E \ Y , γρfe (X) ≥ ρfe (Y ). Note that when γ = 1 we recover submodularity and we always have γ ≥ 1.
We show that Algorithm 2 is equivalent to greedily maximizing a γ-weakly
submodular function over the intersection of two partition matroids; its approx-
imation guarantee worsens for larger values of γ.
Consider tuples of the form (i, j) where i is a paper and j represents a
position in an order. We deﬁne a mapping between sets of tuples to orders.
Consider the set E = {(i, j) : 1 ≤ i, j ≤ n}. We deﬁne two partition matroids (E, I1) and (E, I2), where I1 = {I ⊆ E : ∀(i, j), (i′, j′) ∈ I, j = j′ =⇒ i = i′}, and I2 = {i ⊆ E : ∀(i, j), (i′, j′) ∈ I, i = i′ =⇒ j = j′}. Intuitively, I1 forbids duplicating papers, while I2 forbids duplicating positions. Any set P in the intersection of these two matroids can be converted into a paper order OP by sorting P on the position elements and outputting the paper elements in
that order. Formally, given any set P ∈ (I1 ∩ I2), we can construct an order OP = (SP , oP ) by taking SP = {i ∈ N : ∃j, (i, j) ∈ P }. For all (i, j) ∈ P , let j′ = |{(k, l) ∈ P : l ≤ j}| and set oP (i) = j′. An example of this process is given in Table 2. We can extend this mapping to all subsets of E by sorting on the
position elements as a primary key and paper elements as a secondary key, then
deleting all but the ﬁrst tuple for each paper.

Table 2. Example showing how sets P ⊆ E map to orders, and the resulting allocations from executing round-robin. This example assumes each paper receives 2 reviewers, and each reviewer can be assigned to at most 1 paper. The scores (in order) for each reviewer for paper 1 are {9, 3, 5, 9, 4, 4}, for paper 2 are {10, 4, 0, 10, 6, 5}, and for paper 3 are {1, 1, 2, 2, 4, 4}. P ⊆ E is the set of tuples which map to the order OP , and RRR(OP ) is the allocation resulting from running Algorithm 1 with order OP .

P
∅ {(3, 3)} {(1, 1), (2, 2), (3, 3)} {(2, 2), (1, 3), (2, 3), (3, 3)}

OP
[] [3] [1, 2, 3] [2, 1, 3]

RRR(OP )
{}, {}, {} {}, {}, {r5, r6} {r1, r3}, {r4, r6}, {r5, r2} {r4, r3}, {r1, r6}, {r5, r2}

USWRRR(OP )
0 8 25 34

With these constructions deﬁned, we now see that maximizing the USW for any round-robin allocation is equivalent to the problem max USWRRR(OP )
P ∈(I1∩I2)

I Will Have Order! Optimizing Orders for Fair Reviewer Assignment

11

for the matroids deﬁned above. We will show that Algorithm 2 greedily maxi-
mizes a monotonically increasing version of our function over our two partition
matroids. Next, we show that when our function is γ-weakly submodular, we can provide a γ-dependent approximation ratio.
To make USWRRR(OP ) monotonically increasing, we will multiply by a factor of |P |α, where α is deﬁned as the smallest positive number such that f (P ) = USWRRR(OP )|P |α is monotonically increasing. We ﬁrst prove that Algorithm 2 greedily maximizes f (P ). More formally, we prove Lemma 1 that the algorithm selects the element i that maximizes f (P + (i, j)) at each iteration.

Lemma 1. Let f (P ) = USWRRR(OP )|P |α for some α such that f is monotonically non-decreasing. Suppose that Algorithm 2 selects agent it at each round t, and denote the resulting set of tuples as Pt. Then for all t, (it, t) maximizes f (Pt−1 + (i, j)) over (I1 ∩ I2) \ Pt−1.

Proof. We ﬁrst show that any greedy maximizer for USWRRR is also a greedy maximizer of f . Suppose that USWRRR(OP +(i,j)) ≥ USWRRR(OP +(i′,j′)). Because |P + (i, j)|α = (|P | + 1)α = |P + (i′, j′)|α, we have

USW(OP +(i,j))|P + (i, j)|α ≥ USW(OP +(i′,j′))|P + (i′, j′)|α,

RRR

RRR

as desired.

We also must prove that we can always simply append to the end of the cur-

rent ordering (rather than perhaps selecting an arbitrary tuple (i, j)). Formally,

we want to show that at any point in the algorithm, there is a tuple (i, |O|) that

maximizes USWRRR(O + (i, j)). This is shown via a strong induction argument.

For the base case, if some tuple (i, j) maximizes USWRRR([] + (i, j)), then it is

easy to see that []+ (i, j) = [i] = []+ (i, 1). Inductively, assume that we have a set

P = {(i1, 1), (i2, 2), . . . (i|P |, |P |)} and some tuple (i, j) maximizes f (P + (i, j))

such that P + (i, j) ∈ (I1 ∩ I2). Necessarily, j > |P |, since all other positions j′ ≤ |P | have been ﬁlled in P . Therefore, for any available position k, we have

that OP +(i,k) = [i1, i2, . . . i|P |, i] and thus f (P + (i, k)) is the same for all allowed

k. So without loss of generality, we can assume that we can always select the

best agent in the next available position (as we do in Algorithm 2).

⊓⊔

The greedy algorithm for maximizing f (P ) terminates when |P | = n, so we must also ensure Algorithm 2 terminates with an order on all n papers. Although Algorithm 2 only considers USWRRR(O), which may not be monotonically increasing, by construction it continues until a full order over all papers is reached. Therefore, Algorithm 2 is exactly equivalent to greedily maximizing f .
We are now ready to prove Theorem 2. Our proof is inspired by the proof in [18] that a similar greedy algorithm gives a p+1 1 -approximation for maximizing a monotone submodular function over the intersection of p matroids. However, the introduction of γ-weak submodularity changes the nature of the proof. Directly applying the techniques in [18] would result in a trivial bound. To obtain our guarantee, we must also rely on the fact that at each step t, we select exactly one tuple of the form (it, t). The optimal solution also selects exactly one

12

J. Payan and Y. Zick

Algorithm 2 Greedy Reviewer Round Robin (GRRR)
Require: m reviewers R, limits {cr}r∈R, n papers N , valuation functions {vi}i∈N , bundle size limit k
1: O ← [] 2: for t ∈ {1, . . . n} do 3: O ← O + i where i maximizes USWRRR(O + i, k, R, {cr}r∈R, {vi}i∈N ) over all
i∈ N \O 4: return O

such tuple as well, thus the overlap between the tuples considered in round t by GRRR and the optimal solution is at most 1.

Theorem 2. Suppose that f is the monotonically increasing, γ-weakly submod-

ular function f (P ) = USWRRR(OP )|P |α. The set P alg returned by Algorithm 2

satisﬁes

f (P alg) ≥

1 1+γ

2

f

(P

∗

),

where

OP ∗

is

the

optimal

paper

order

for

RRR.

Proof. Let Pt represent the subset of P alg after the t-th step of Algorithm 2, where we add the element (it, t) to Pt−1. Let (i∗t , t) denote the pair in P ∗ which places paper i∗t in position t. Denote L = |S∗ \ Salg|. Consider the elements of S∗ \ Salg = {(i∗t1 , t1), . . . (i∗tL , tL)}, ordered so that t1 < t2 < . . . tL. Let Plalg denote P alg ∪ {(i∗t1 , t1), . . . (i∗tl , tl)} (with P0alg = P alg). We bound f (P ∗):

L

f (P ∗) ≤ f (P alg ∪ P ∗) = f (P alg) + ρ(i∗ ,tl)(Pla−lg1),

(1)

tl

l=1

where the inequality in (1) holds by monotonicity of f . By γ-weak submodularity of f , we have that

ρ(i∗ ,tl)(Pla−lg1) ≤ γρ(i∗ ,tl)(P alg).

(2)

tl

tl

Equality 1 and inequality 2 imply that f (P ∗) is upper bounded by

L

n

f (P alg) + γ ρ(i∗ ,t )(P alg) ≤ f (P alg) + γ ρ(i∗,t)(P alg),

(3)

tl l

t

l=1

t=1

with inequality (3) holding by monotonicity of f . By γ-weak submodularity of

f , we know that for all t, ρ(i∗,t)(P alg) ≤ γρ(i∗,t)(Pt−1). Applying this to (3), we

t

t

get

n

f (P ∗) ≤ f (P alg) + γ2 ρ(i∗,t)(Pt−1).

(4)

t

t=1

Next, we claim that for all t,

ρ(i∗,t)(Pt−1) ≤ ρ(it,t)(Pt−1).

(5)

t

I Will Have Order! Optimizing Orders for Fair Reviewer Assignment

13

At step t, the greedy algorithm chose to add (it, t) to Pt−1, with it maximizing

f (Pt−1

+ (it, t)).

If

(i

∗ t

,

j

)

is

not

present

in

Pt−1

for

any

j,

then

the

greedy

algorithm would have considered adding (i∗t , t) and determined that it was better.

Suppose that (i∗t , j) ∈ Pt−1 for some j. The greedy algorithm proceeds by ﬁlling

positions from left to right, so j ≤ t − 1. By the deﬁnition of our mapping from

sets

to

orders,

i∗t

will

take

position

j

and

ignore

(i

∗ t

,

t

).

Thus

ρ(i∗ ,t) (Pt−1 )

=

0

≤

t

ρ(it,t)(Pt−1). In either case, inequality (5) holds. Combining (4) with (5) yields

n
f (P ∗) ≤ f (P alg) + γ2 ρ(it,t)(Pt−1) = f (P alg) + γ2f (P alg) = (1 + γ2)f (P alg),
t=1

completing the proof.

⊓⊔

When γ = 1 (f is submodular), Theorem 2 yields a 12 -approximation guarantee, which beats the 31 -approximation guarantee provided by Fisher et al. [18]. The greedy algorithm is a tight 12 -approximation for submodular maximization in the unconstrained regime [11], which our result matches even though we operate in a constrained (albeit less general) space.

4 Experimental Results
We run experiments on the three conference datasets used in [22]: Medical Imaging and Deep Learning (MIDL), Conference on Computer Vision and Pattern Recognition (CVPR), and the 2018 iteration of CVPR. A summary of the data statistics appears in Table 3. We note that for CVPR’18, while aﬃnities are between 0 and 11, most are between 0 and 1. In addition, reviewer load bounds vary by reviewer but range between 2 and 9. Because of the size of the CVPR’18 dataset, we subsample 100 papers at each iteration of Algorithm 2 rather than testing every available paper and report means and standard deviations over 5 runs. An implementation of GRRR and all baselines are available on GitHub4.

Table 3. Data summary for all three datasets. Here, n is the number of papers; m is the number of reviewers; val. range is the range of reviewer scores; k is the bound on the number of reviewers per paper; rev. load is the bound on papers/reviewer.

Name: n
MIDL: 118
CVPR: 2623 CVPR’18: 5062

m
177
1373 2840

val. range k

[−1, 1]

3

[0, 1]

3

[0, 11]

3

rev. load
4
6 {2, . . . , 9}

We compare against the FairIR and FairFlow algorithms [22], the Toronto Paper Matching System [15], and PeerReview4All [31]. Following Kobren et al. [22]
4 https://github.com/justinpayan/ReviewerAssignmentCode

14

J. Payan and Y. Zick

Table 4. Results on all three conferences. We pick the best of 100 random remaining papers each iteration during GRRR for CVPR’18, so we report the mean and standard deviation over 5 runs. When the minimum paper score is 0, the Nash Welfare is also 0. In this case, we report the Nash Welfare as 0 and report the Nash Welfare of the remaining papers in parentheses.

MIDL CVPR 2018

Alg.
FairFlow FairIR TPMS PR4A GRRR
FairFlow FairIR TPMS PR4A GRRR
FairFlow FairIR TPMS PR4A GRRR

USW
1.67 1.71 1.71 1.68 1.68
1.67 2.05 2.08 1.96 1.82
17.94 22.18 22.23 21.48 20.83 ± .01

NSW
1.62 1.65 1.65 1.64 1.63
1.56 1.84 0.00 (1.99) 1.89 0.00 (1.72)
17.38 21.57 21.11 21.12 19.57 ± .02

Min Score
0.94 0.93 0.90 0.92 0.83
0.77 0.27 0.00 0.77 0.00
11.26 7.19 1.37 12.68 1.78 ± .01

EF1 Viol.
0 0 0 0 0
8813 35262 473545 82 0
37 18 134 2 0

and Stelmakh et al. [31], we only run one iteration of PeerReview4All (PR4A) on CVPR and CVPR’18. On those two conferences, PR4A maximizes the minimum paper score, but stops before maximizing the next smallest score. We run FairIR and FairFlow using the default conﬁguration of the algorithms in the code from [22]. We also implemented the Constrained Round Robin algorithm [2], implementing the test for W -satisﬁability as a greedy heuristic followed by a Gurobi implementation of the fully speciﬁed linear program. We use USW ≥ 1.68 as the W criterion for this experiment. CRR is approximately 40 times slower than GRRR on MIDL, taking 400 seconds instead of 10. GRRR admits parallelism, and takes about 18 hours to run on CVPR. Extrapolating these results, we can expect CRR to require a month of computation time or longer on CVPR (it did not terminate in our experiments). Given its infeasible runtime, we did not continue to compare against CRR as a baseline. All experiments were run on a Xeon E5-2680v4 processor with 128 GB memory.
We report the USW, NSW, minimum paper score, and number of EF1 violations for each algorithm. When the lowest-scoring paper receives a bundle worth 0, the NSW is equal to 0. When this occurs, we denote the NSW as 0, but display the NSW on all positively scoring papers in parentheses. We report the USW normalized by the number of papers n (equivalent to the mean paper score), and for NSW we report the geometric mean (as in the deﬁnition given in Section 2). Thus USW and NSW are directly comparable, representing the arithmetic and geometric mean paper scores respectively. For an allocation A,

I Will Have Order! Optimizing Orders for Fair Reviewer Assignment

15

the number of EF1 violations is the number of pairs of papers i = j failing EF1. Note that there are ≤ n2 − n total potential violations.
The results on all three datasets are summarized in Table 4. First, we note that no algorithm has EF1 violations on MIDL, so EF1 is very easily achieved on this conference. The CVPR conferences have a more interesting proﬁle of EF1 violations, but no algorithm besides ours achieves EF1 on all three conferences. Although GRRR obtains a minimum paper score of 0 on CVPR (and also a NSW of 0 as a result), only three papers receive a score of 0. This small problem may be rectiﬁed by increasing the assignment limits of a few reviewers or allowing a small number of EF1 violations for these three papers.

Table 5. Statistics to estimate amount of inequality for GRRR and all three baseline fair reviewer assignment algorithms. After running each algorithm, we compute the bottom 10% of papers by score and the bottom 25% by score, then report the mean and standard deviation for both low-percentile blocks. We also report the Gini coeﬃcient of all paper scores and the sum of the envy across all paper pairs, where lower is better for both.

MIDL CVPR 2018

Alg.
FairFlow FairIR PR4A GRRR
FairFlow FairIR PR4A GRRR
FairFlow FairIR PR4A GRRR

Lowest 10% Lowest 25% Gini
1.037 ± .056 1.161 ± .118 .143 1.049 ± .075 1.185 ± .132 .147 1.069 ± .082 1.211 ± .135 .127 0.995 ± .095 1.164 ± .157 .145
0.851 ± .033 0.920 ± .067 .207 0.755 ± .111 0.886 ± .141 .231 1.0651 ± .150 1.324 ± .247 .145 0.898 ± .176 1.110 ± .217 .183
11.580 ± .176 12.702 ± 1.245 .142 12.151 ± 1.513 15.564 ± 3.088 .119 15.280 ± .952 16.668 ± 1.348 .103 8.923 ± 2.890 12.22 ± 3.528 .168

Envy
.944 .501 .448 .834
4.606e4 7.100e4 0.928e4 2.240e4
7771 5547 1367 2.884e4

GRRR is the only algorithm to achieve the EF1 goal, but it is not clear

if its allocations are more globally fair than those of the other algorithms. To

more directly measure inequality, we compute the mean and standard deviation

of paper scores in low percentiles of paper scores (10% and 25%). We consider

allocations to be more fair if they allocate higher scores to these disadvantaged

papers. We also calculate the Gini coeﬃcient for each allocation, a standard

measure of inequality. A higher Gini coeﬃcient indicates more inequality, so

lower is better for this metric. Finally, we report the sum of the total envy over

all pairs i and j,

(vi(Aj ) − vi(Ai)). The results are summarized in Table 5.

i,j∈N

We report statistics for only one run of our subsampled GRRR on CVPR’18.

Interestingly, we ﬁnd that PR4A performs best across all datasets and fairness

metrics. However, GRRR consistently outperforms FairFlow and is signiﬁcantly

16

J. Payan and Y. Zick

better than FairIR on CVPR (which appears to be the most challenging dataset, based on the number of EF1 violations in Table 4).

Table 6. Estimated α and γ parameters for all three conference datasets. Values of
α close to 0 indicate the USWRRR function is close to monotonically increasing on that dataset. The approximation ratio for Algorithm 2 is 1 + γ2, so higher γ yields a looser approximation guarantee. We did not ﬁnd any pairs O and i ∈/ O such that USWRRR(O + i) < USWRRR(O) for MIDL, so α can be set arbitrarily close to 0.

MIDL CVPR 2018

α
0.01∗ 1.03 0.505

γ
1.210 50.615 17.410

To give an indication of the practical guarantees of Theorem 2, we estimate α and γ on all three datasets. For any order O and any paper i ∈/ O, we must have that USWRRR(O + i)|O + i|α ≥ USWRRR(O)|O|α. When USWRRR(O + i) > USWRRR(O), any positive α will satisfy this inequality. We estimate α by sampling orders O and papers i ∈/ O, and we take our estimate to be slightly greater than the maximum α found for any O and paper i. For MIDL, we found that no sampled O and i violate monotonicity, so we set α to be 0.01. Using our estimated α values, we then estimate γ. Here, we sample X and Y so that X ⊆ Y , and e ∈/ Y . We then note that we need γ ≥ ρρee((XY )) for all samples. Similarly to our α estimate, we compute ρρee((XY )) for all samples and then estimate γ to be slightly greater than the maximum value. We found in all experiments that our chosen α parameter led to all positive marginal gains during the γ estimation, improving our conﬁdence in the α estimates. The results are displayed in Table 6. The approximation guarantee is meaningful (about 4) for MIDL, but not for the other two datasets.
5 Conclusion
The reviewer assignment problem provides interesting constraints, complicating the standard fair allocation setting. In this work, we demonstrate that a greedy approach ﬁnds EF1 allocations with high USW in the reviewer assignment setting. We hope that our approach of optimizing over orders for roundrobin allocations inspires more study of optimal round-robin allocations. We left Conjecture 1 open, and providing a counterexample would further justify RRR. Finally, there are many applications of diﬀerent fairness, eﬃciency, robustness, or non-manipulability constraints from the fair allocation literature to problems in peer review, which could bring some much-needed rigor to this fundamental process.

I Will Have Order! Optimizing Orders for Fair Reviewer Assignment

17

Acknowledgments
We would like to thank Vignesh Viswanathan for helpful discussions. This work was performed in part using high performance computing equipment obtained under a grant from the Collaborative R&D Fund managed by the Massachusetts Technology Collaborative.

Bibliography
[1] Ahmed, F., Dickerson, J.P., Fuge, M.: Diverse weighted bipartite b-matching. In: Proceedings of the 26th International Joint Conference on Artiﬁcial Intelligence (IJCAI), pp. 35–41 (2017)
[2] Aziz, H., Huang, X., Mattei, N., Segal-Halevi, E.: The constrained round robin algorithm for fair and eﬃcient allocation. arXiv preprint arXiv:1908.00161 (2019)
[3] Aziz, H., Kalinowski, T., Walsh, T., Xia, L.: Welfare of sequential allocation mechanisms for indivisible goods. In: Proceedings of the 22nd European Conference on Artiﬁcial Intelligence (ECAI), pp. 787–794 (2016)
[4] Aziz, H., Walsh, T., Xia, L.: Possible and necessary allocations via sequential mechanisms. In: Proceedings of the 24th International Joint Conference on Artiﬁcial Intelligence (IJCAI) (2015)
[5] Barman, S., Bhaskar, U., Shah, N.: Optimal bounds on the price of fairness for indivisible goods. In: Proceedings of the 16th International Workshop on Internet and Network Economics (WINE), pp. 356–369, Springer (2020)
[6] Barman, S., Ghalme, G., Jain, S., Kulkarni, P., Narang, S.: Fair division of indivisible goods among strategic agents. In: Proceedings of the 18th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), pp. 1811–1813 (2019)
[7] Bei, X., Lu, X., Manurangsi, P., Suksompong, W.: The price of fairness for indivisible goods. In: Proceedings of the 28th International Joint Conference on Artiﬁcial Intelligence (IJCAI), pp. 81–87 (2019)
[8] Biswas, A., Barman, S.: Fair division under cardinality constraints. In: Proceedings of the 27th International Joint Conference on Artiﬁcial Intelligence (IJCAI), pp. 91–97 (2018)
[9] Bouveret, S., Chevaleyre, Y., Maudet, N.: Fair allocation of indivisible goods. In: Brandt, F., Conitzer, V., Endriss, U., Lang, J., Procaccia, A.D. (eds.) Handbook of computational social choice, chap. 12, pp. 284–309, Cambridge University Press (2016)
[10] Bouveret, S., Lang, J.: A general elicitation-free protocol for allocating indivisible goods. In: Proceedings of the 22nd International Joint Conference on Artiﬁcial Intelligence (IJCAI), pp. 73–78 (2011)
[11] Buchbinder, N., Feldman, M., Naor, J., Schwartz, R.: A tight linear time (1/2)approximation for unconstrained submodular maximization. In: Proceedings of the 53rd Symposium on Foundations of Computer Science (FOCS), pp. 649–658 (2012)
[12] Budish, E.: The combinatorial assignment problem: Approximate competitive equilibrium from equal incomes. Journal of Political Economy 119, 1061–1061 (12 2011)
[13] Caragiannis, I., Kaklamanis, C., Kanellopoulos, P., Kyropoulou, M.: The eﬃciency of fair division. Theory of Computing Systems 50(4), 589–610 (2012)

18

J. Payan and Y. Zick

[14] Caragiannis, I., Kurokawa, D., Moulin, H., Procaccia, A.D., Shah, N., Wang, J.: The unreasonable fairness of maximum Nash welfare. ACM Transactions on Economics and Computation (TEAC) 7(3), 1–32 (2019)
[15] Charlin, L., Zemel, R.: The toronto paper matching system: an automated paperreviewer assignment system. In: Proceedings of the 2013 ICML Workshop on Peer Reviewing and Publishing Models (2013)
[16] Charlin, L., Zemel, R., Boutilier, C.: A framework for optimizing paper matching. In: Proceedings of the 27th Annual Conference on Uncertainty in Artiﬁcial Intelligence (UAI), pp. 86–95 (2011)
[17] Conry, D., Koren, Y., Ramakrishnan, N.: Recommender systems for the conference paper assignment problem. In: Proceedings of the 3rd ACM Conference on Recommendation Systems (RecSys), pp. 357–360 (2009)
[18] Fisher, M.L., Nemhauser, G.L., Wolsey, L.A.: An analysis of approximations for maximizing submodular set functions—II. In: Balinski, M.L., Hoﬀman, A.J. (eds.) Polyhedral Combinatorics, pp. 73–87, Springer Berlin Heidelberg, Berlin, Heidelberg (1978)
[19] Garg, N., Kavitha, T., Kumar, A., Mehlhorn, K., Mestre, J.: Assigning papers to referees. Algorithmica 58(1), 119–136 (2010)
[20] Hartvigsen, D., Wei, J.C., Czuchlewski, R.: The conference paper-reviewer assignment problem. Decision Sciences 30(3), 865–876 (1999)
[21] Kalinowski, T., Narodytska, N., Walsh, T.: A social welfare optimal sequential allocation procedure. In: Proceedings of the 23rd International Joint Conference on Artiﬁcial Intelligence (IJCAI), pp. 227–233 (2013)
[22] Kobren, A., Saha, B., McCallum, A.: Paper matching with local fairness constraints. In: Proceedings of the 25th International Conference on Knowledge Discovery and Data Mining (KDD), pp. 1247–1257 (2019)
[23] Kou, N.M., U, L.H., Mamoulis, N., Gong, Z.: Weighted coverage based reviewer assignment. In: Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data, pp. 2031–2046 (2015)
[24] Lian, J.W., Mattei, N., Noble, R., Walsh, T.: The conference paper assignment problem: Using order weighted averages to assign indivisible goods. In: Proceedings of the 32nd AAAI Conference on Artiﬁcial Intelligence (AAAI), pp. 1138–1145 (2018)
[25] Lipton, R.J., Markakis, E., Mossel, E., Saberi, A.: On approximately fair allocations of indivisible goods. In: Proceedings of the 5th ACM Conference on Electronic Commerce (EC), pp. 125–131 (2004)
[26] Long, C., Wong, R.C.W., Peng, Y., Ye, L.: On good and fair paper-reviewer assignment. In: Proceedings of the 13th IEEE International Conference on Data Mining (ICDM), pp. 1145–1150, IEEE (2013)
[27] Mulligan, A., Hall, L., Raphael, E.: Peer review in a changing world: An international study measuring the attitudes of researchers. Journal of the American Society for Information Science and Technology 64(1), 132–161 (2013)
[28] O’Dell, R., Wattenhofer, M., Wattenhofer, R.: The paper assignment problem. Technical Report/ETH Zurich, Department of Computer Science 491 (2005)
[29] Oxley, J.: Matroid Theory. Oxford Graduate Texts in Mathematics, Oxford Univerity Press, 2nd edn. (2011)
[30] Shah, N.B.: Principled methods to improve peer review. Tech. rep., Carnegie Mellon University (2019)
[31] Stelmakh, I., Shah, N.B., Singh, A.: PeerReview4All: Fair and accurate reviewer assignment in peer review. In: Proceedings of the 30th International Conference on Algorithmic Learning Theory (ALT), pp. 828–856 (2019)

I Will Have Order! Optimizing Orders for Fair Reviewer Assignment

19

[32] Wang, F., Chen, B., Miao, Z.: A survey on reviewer assignment problem. In: Proceedings of the 21st International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, pp. 718–727, Springer (2008)

