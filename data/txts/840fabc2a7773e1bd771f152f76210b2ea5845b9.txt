Conditional Poisson Stochastic Beam Search
Clara Meister Afra Amini Tim Vieira Ryan Cotterell , ETH Zu¨rich Johns Hopkins University University of Cambridge clara.meister@inf.ethz.ch aamini@student.ethz.ch tim.vieira@gmail.com ryan.cotterell@inf.ethz.ch

arXiv:2109.11034v2 [cs.CL] 21 Oct 2021

Abstract
Beam search is the default decoding strategy for many sequence generation tasks in NLP. The set of approximate K-best items returned by the algorithm is a useful summary of the distribution for many applications; however, the candidates typically exhibit high overlap and may give a highly biased estimate for expectations under our model. These problems can be addressed by instead using stochastic decoding strategies. In this work, we propose a new method for turning beam search into a stochastic process: Conditional Poisson stochastic beam search. Rather than taking the maximizing set at each iteration, we sample K candidates without replacement according to the conditional Poisson sampling design. We view this as a more natural alternative to Kool et al. (2019)’s stochastic beam search (SBS). Furthermore, we show how samples generated under the CPSBS design can be used to build consistent estimators and sample diverse sets from sequence models. In our experiments, we observe CPSBS produces lower variance and more efﬁcient estimators than SBS, even showing improvements in high entropy settings.1
1 Introduction
Many NLP tasks require the prediction of structured outputs, such as sentences or parse trees, either during decoding or as part of a training algorithm. For today’s neural architectures, beam search (Reddy, 1977) has become the decoding algorithm of choice due to its efﬁciency and empirical performance (Serban et al., 2017; Edunov et al., 2018; Yang et al., 2019; Meister et al., 2020b). Beam search is a deterministic method, which invites a natural question: What is the proper stochastic generalization of beam search? Several recent papers have investigated this question (Kool et al., 2019, 2020; Shi et al., 2020). Here we build
1Our codebase is publically available at https://github. com/rycolab/cpsbs.

Set Size Operator
argmax
sample

K =1 Greedy Search
Ancestral Sampling

K >1 Beam Search Conditional Poisson Beams

Table 1: A comparison of beam-based decoding algorithms for sequence models, by solution set size and objective. The argmax and sample variants are related through annealing: As the annealing parameter of the distribution τ → 0, sampling turns into computing an argmax (see §3).

on this line of work and introduce an alternative stochastic beam search that the authors contend is a more faithful stochasticization of the original algorithm in that it recovers standard beam search as a special case. We name our algorithm conditional Poisson stochastic beam search (CPSBS) as we draw on the conditional Poisson sampling scheme (Ha´jek, 1964) in its construction. The relationship between CPSBS and other common decoding strategies is displayed visually in Table 1.
At every iteration, CPSBS replaces the top-K operator in the beam search algorithm with conditional Poisson sampling, resulting in a decoding strategy that generates samples-withoutreplacement. Importantly, annealing our sampling distribution at each time step turns local sampling into a local top-K computation and thereby recovers beam search. We subsequently show that these samples can be used to construct a statistically consistent estimator for the expected value of an arbitrary function of the output.
In our experiments with neural machine translation models, we observe that CPSBS leads to better estimates of expected BLEU and conditional model entropy than SBS and the sum-and-sample estimator (Kool et al., 2020), distinctly outperforming Monte Carlo sampling for both small sample sizes and low temperatures. Furthermore, we ﬁnd that CPSBS can be used as a diverse sampling strategy.

We take these results as conﬁrmation that CPSBS is a useful tool in the newfound arsenal of sampling strategies for neural sequence models.

2 Beam Search
In this section, we overview the necessary background on neural sequence models and beam search in order to motivate our algorithm in §3.

Neural Sequence Models. We consider locally normalized probabilistic models over sequences y:

|y|

p(y) = p(yt | y<t)

(1)

t=1

where y is a member of a set of well-formed outputs Y. In the context of language generation models, well-formed outputs are sequences of tokens y = y1, y2, . . . from a vocabulary V ; all y ∈ Y begin and end with special tokens BOS and EOS, respectively. We use y<t to represent the subsequence y1, . . . , yt−1 . In this work, we consider the setting where the maximum sequence length is upper-bounded; we denote this upper bound T > 0. Without loss of generality, we may condition p on an input x, as is necessary for machine translation and other conditional generation tasks.

Beam Search. Beam search is a commonly used search heuristic for ﬁnding an approximate solution to the following optimization problem:

y = argmax log p(y)

(2)

y∈Y

Its most straightforward interpretation is as a pruned version of breadth-ﬁrst search, where the breadth of the search is narrowed to the top-K candidates. However, here we will present beam search in a nonstandard lens (Meister et al., 2020a, 2021) in order to emphasize the connection with our stochastic generalization in §3. Speciﬁcally, we present the algorithm as iteratively ﬁnding the highest-scoring set under a speciﬁc set function.
Under this paradigm, the initial beam Y0 contains only the BOS token. At subsequent steps t = 1, . . . , T , beam search selects the K highestscoring candidates from the set Yt−1 ◦ V that we deﬁne below:2

Yt−1 ◦ V =def {y ◦ y | y ∈ Yt−1 and y ∈ V } (3)

2Sequences already ending in EOS are not extended by y ∈ V and are simply added to the set “as is.”

where ◦ is sequence concatenation. Those candi-
date sets with collectively higher probability under
the model p have higher score. This process con-
tinues until all y ∈ Yt end in EOS, or t = T . For notational ease, we deﬁne Bt =def Yt−1 ◦ V ; throughout this paper, we will assume |Bt| = N and identify the elements of Bt = {y≤(1t), . . . , y≤(Nt )} with the integers {1, . . . , N }.
We can formulate the time-step dependent set
function whose argmax beam search ﬁnds as

Qt(Yt | Yt−1) ∝def n∈Yt wn if |Yt| = K (4)

0

otherwise

where wn is the weight of the nth element of Bt. To recover beam search, we set our weights equal to probabilities under a model p, i.e., wn = p y≤(nt) . Note that we leave the constraint that Y ⊆ Bt implicit in Eq. (4). As should be clear from notation, this set function only assigns nonzero scores to subsets of Yt−1 ◦ V of size exactly K and the assigned score is proportional to the product of the probability of the candidates under the model p. Putting this all together, beam search may be viewed as the following iterative process:

Y0 = {BOS}

(5)

Yt = argmax Qt(Yt | Yt−1) (6)
Yt ⊆Bt

return YT

(7)

3 Conditional Poisson Stochastic Beams
Our paper capitalizes on a very simple observation: Rather than taking its argmax, we may renormalize Eq. (4) into a distribution and sample-withoutreplacement a size K set at each iteration:

Y0 = {BOS}

(8)

Yt ∼ Qt(· | Yt−1)

(9)

return YT

(10)

This recursion corresponds to performing conditional Poisson sampling (CPS; Ha´jek 1964; see App. A for overview), a common sampling-withoutreplacement design (Tille´, 2006),3 at every time step. Thus we term this scheme conditional Poisson stochastic beam search. CPSBS gives us a
3A sampling design is a probability distribution over sets of samples.

probability distribution over sets of candidates of
size K, i.e., the ﬁnal beam YT . We denote the CPSBS distribution P and we write YT ∼ P to indicate that YT is the stochastic beam at the end of a sampling run. We may write P (YT ) as a marginal probability, summing over all sequences of beams that could have resulted in YT :4

T

P (YT ) = · · ·

Qt(Yt | Yt−1) (11)

Y1 YT −1 t=1

Note the structural zeros of Qt prevent any incompatible sequence of beams. We provide a theoretical analysis of the scheme in §4 and an empirical analysis in §5.

Normalizing Qt(· | Yt−1). At each time step t, we compute Qt(· | Yt−1)—a distribution over subsets of size K of a base set Bt—using the CPS design. The normalizing constant for this distribution is deﬁned as

Zt =def

wn

Yt⊆Bt, n∈Yt |Yt|=K

(12)

Despite there being exponentially many summands, we can sum over all KN subsets in O(N K) time via the following recurrence relation:5

n W
k


1  = W n−1 k  0

+ wnW

n−1 k−1

if k = 0 or n = k
if k ∈ (0, n)
otherwise

We give complete pseudocode in App. C. Correctness of this algorithm is shown in Kulesza and Taskar (2012). The normalizing constant can then be efﬁciently computed as
N Zt = W K (13)

Sampling from Qt(· | Yt−1). We can efﬁciently sample sets from Qt(· | Yt−1) using the algorithm below:
1: Yt ← ∅ Initialization 2: for n = N . . . 1 : 3: k ← K − |Yt| Number of remaining elements

4This formulation reveals that it is wildly intractable to com-
pute P (YT ). 5The reader may recognize this recurrence as the weighted generalization of Pascal’s triangle, nk = n−k 1 + nk−−11 , which is why we chose the notation W nk .

4: Add the nth element of Bt to Yt with prob.

wn W

n−1 k−1

W nk

5: return Yt

Guaranteed to have size K

In words, the algorithm considers adding each element one at a time until K elements have been sampled. Notice that line 4 adjusts the probability of sampling item n given that |Yt| items have already been sampled, which ensures that exactly K elements are sampled at termination.

Setting wn. The weight assigned to the nth item of Bt directly affects its probability of being included in the sampled set, i.e., Pr y≤(nt) ∈ Yt , also termed an item’s inclusion probability. In this paper, we write πQt y≤(nt) | Yt−1 to denote the inclusion probability under the distribution
Qt(· | Yt−1), deﬁned as:

πQt y≤(nt) | Yt−1

(14)

=def Qt(Yt | Yt−1)1{y≤(nt) ∈ Yt}
Yt

One strategy is to choose wn at time step t such that πQt y≤(nt) | Yt−1 ≈ p(y≤(nt)). This choice recovers beam search when we anneal our chosen weights wn → wn1/τ : as the temperature parameter τ → 0, the CP distribution will assign probability 1 to the set containing the top-K elements.6
Finding wn’s that result in pre-speciﬁed inclusion probabilities is possible, but it requires solving a numerical optimization problem (Aires, 1999; Grafstro¨m, 2009). Further, in CPSBS, we will be sampling from a different distribution at each time step and it would be quite slow to solve the numerical optimization problem each iteration. Luckily, the choice of wn = p(y≤(nt))/(1 − p(y≤(nt))) yields a good approximation to the target inclusion probabilities in both theory and practice (Ha´jek, 1981; Bondesson et al., 2006; Aires, 1999).

4 Statistical Estimation with Conditional Poisson Stochastic Beam Search
In this section, we discuss statistical estimation with CPSBS samples. To that end, we construct two estimators with different properties. However,
6In the event of ties, annealed CP will converge to a distribution that breaks ties uniformly at random.

only the second estimator provides good performance in practice, which is discussed later in §5.

4.1 The Horvitz–Thompson Estimator
We build upon the Horvitz–Thompson (HT) estimator (Horvitz and Thompson, 1952), which is a common technique for estimation from samplingwithout-replacement (SWOR) schemes.
Let f : Y → Rd be a function whose expected value under p we seek to approximate:

Ey∼p [f (y)] = p(y)f (y) (15)
y∈Y

The Monte Carlo estimator of the above quantity is

def 1 M

(m)

GMC =

f (y )

(16)

M

m=1

where y(m) i.∼i.d. p. However, in the special case of sampling from a ﬁnite population—which is extremely common in NLP—it can be very wasteful. For example, if a distribution is very peaked, it will sample the same item repeatedly; this could lead to inaccurate approximations for some f . As a consequence, the mean square error (MSE) of the estimator with respect to Ey∼p [f (y)] can be quite high for small M . Indeed, we see this empirically in §5.1.
Taking samples without replacement allows us to cover more of the support of p in our estimate of Ey∼p [f (y)]. However, we must take into account that our samples are no longer independent, i.e.,
i.i.d.
y(m) ∼ p. We now deﬁne the HT estimator, using notation speciﬁcally for the case of CPSBS:

def

p(y)

GHT =

f (y)

(17)

πP (y)

y∈YT

As should be clear from notation, we assume YT ∼ P ; further, we use πP (y) to denote the inclusion probability of y under CPSBS, i.e., the probability of sampling a set YT ∼ P that contains the element y:

πP (y) = P (YT )1{y ∈ YT }

(18)

YT

= ···

T
Qt(Yt | Yt−1)1 {y≤t ∈ Yt}

Y1

YT t=1

In Eq. (17), the distribution πP may be viewed as a proposal distribution in the sense of importance sampling (Owen, 2013) and 1/πP (y) as the

corresponding importance weight corrections. If we can exactly compute πP , then the HT estimator is unbiased7 (see App. B.1 for proof). However, the summation in Eq. (18) is intractable so we resort to estimation.

4.2 Estimating Inclusion Probabilities
In this section, we develop statistical estimators of the inclusion probabilities under conditional Poisson stochastic beam search. Note that in order to maintain the unbiasedness of the HT estimator, we must estimate the reciprocal inclusion probabilities.8 However, these are not straightforward to estimate. Thus, we attempt to estimate the inclusion probabilities directly and take the reciprocal of this estimator. This strategy leads to a consistent, but biased, estimator. An important caveat: the analysis in this section only applies to the estimators of the inclusion probabilities themselves. Further analysis may be undertaken to analyze the variance of the HT estimators that make use of these estimators.

4.2.1 Na¨ıve Monte Carlo
One obvious way to derive an inclusion probability estimator is via Monte Carlo estimation:

1 def 1 M
πPMC(y) = M
m=1

y ∈ YT(m)

(19)

where Y (m) ∼ P .

Proposition 4.1. Eq. 19 has the following two properties:

i)

πMC P

is an unbiased estimator of πP

and

V [πPMC] = M1 πP (y) − πP (y)2 (20)

ii) 1/πPMC is a consistent estimator of 1/πP with asymptotic variance

1

1

Va πPMC(y) = M

1

1

πP (y)3 − πP (y)2

(21)

Here Va denotes the asymptotic variance, which is the variance after the number of samples M is
7Note that it is common to normalize Eq. (17) by the sum of importance weights, i.e., divide GHT by the sum
y∈Y T πQt (y). While this leads to a biased estimator, it can signiﬁcantly reduce variance, which is often worthwhile. 8Since by Jensen’s inequality E [1/X] ≥ 1/E [X] for
X ∈ R+, the reciprocal of an unbiased estimate of πP (y) is not an unbiased estimate of 1/πP (y)

large enough such that the central limit theorem has kicked in (Bickel and Docksum, 2015).

Proof. Proof given in App. B.2.

Qualitatively, what this result tells us is that if we are asking about the inverse inclusion probability of a candidate with a low inclusion probability, our estimator may have very high variance. Indeed, it is unlikely that we could derive an estimator without this qualitative property due to the presence of the inverse. Moreover, the estimator given in Eq. (19) is not of practical use: If we are interested in the inverse inclusion probability of a speciﬁc candidate y, then we may have to sample a very large number of beams until we eventually sample one that actually contains y. In practice, what this means is that our estimate of the inclusion probably for a rare y will often be zero, which we cannot invert.9 Instead, we pursue an importance sampling strategy for estimating πP (y), which we outline in the next section.

4.2.2 Importance Sampling

We now turn to an inclusion probability estimator that is based on importance sampling. Recall from Eq. (18) that the inclusion probability for y is a massive summation over sequences of possible beams Y1, . . . , YT that could have generated y. Rather than computing the sum, we will estimate the sum through taking samples. Our procedure starts by generating hindsight samples Y1, . . . , YT from the following proposal distribution that is conditioned on y:

def Qt(Yt | Yt−1)

Qt(Yt | Yt−1, y) =

(22)

πQt(y≤t | Yt−1)

In words, Qt is Qt conditioned on its sets Yt containing the preﬁx y≤t (thus it is always the case that y≤t ∈ Yt).10 For brevity, we omit an explicit notational dependence of Yt and Qt on y.

Lemma 4.1. The joint proposal distribution

P (Y1, . . . , YT ) =def

T t=1

Qt(Yt

|

Yt−1)

may

be

ex-

9One solution would be to smooth our estimates of the inclusion probabilities, adding a small ε to ensure that we do not
divide by zero, but the authors ﬁnd our next approach to be
more methodologically sound. 10This proposal distribution can be realized through a
minor modiﬁcation of our algorithm in §3, where w(y) corresponding to y≤(nt) is placed at the beginning and added to Yt deterministically.

pressed in terms of P as follows:

P (Y1, . . . , YT )

P (Y1, . . . , YT ) = T

(23)

t=1 πQt(y≤t | Yt−1)

where we deﬁne P (Y1, . . . , YT ) =def

T t=1

Qt(Yt

|

Yt−1) as the joint probability of the beams

Y1, . . . , YT under the original distributions Qt. We

omit that both P and P are conditioned on Y0.

Proof. See App. B.2.

In terms of computation, Eq. (22) makes use of the fact that the per-time-step inclusion probability πQt(y≤t) for a given Qt can be computed efﬁciently with dynamic programming using the following identity:

πQt(y≤(nt) | Yt−1) =def Qt(Yt)1
Y
= wn ∂Z Z ∂wn

y≤(nt) ∈ Yt (24)

For completeness, we give pseudocode in App. C. Given samples Y (m) ∼ P for P deﬁned in Eq. (23)
T
with respect to a given y, we propose the following
unbiased estimator of inclusion probabilities:

def 1 M T

(m)

πPIS(y) = M

πQt(y≤t | Yt−1 )

m=1 t=1

(25)

where y≤t is a preﬁx of y. One simple derivation of Eq. (25) is as an importance sampler. We start with the equality given in Eq. (18) and perform the standard algebraic manipulations witnessed in importance sampling:

P (YT )1{y ∈ YT }

(26)

YT

= · · · P (Y1, . . . , YT )1{y ∈ YT }

Y1

YT

= · · · P (Y1, . . . , YT ) P (Y1, . . . , YT )

Y1

YT

P (Y1, . . . , YT )

= · · · P (Y1, . . . , YT ) P (Y1, . . . , YT )

Y1

YT

P (Y1, . . . , YT )

T (i)
= · · · P (Y1, . . . , YT ) πQt(y≤t | Yt−1)

Y1

YT

t=1

where equality (i) above follows from Lemma 4.1. This derivation serves as a simple proof that Eq. (25) inherits unbiasedness from Eq. (17).

Proposition 4.2. Eq. (25) has the following two properties:

i)

πIS P

is an unbiased estimator of πP ;

ii) The estimator of the inverse inclusion probabilities 1/πPIS(y) is consistent with the following upper bound on the asymptotic variance:

1

1 r−1

Va πPIS(y) ≤ M πP (y)2 (27)

where we assume that the following bound:

Tt=1 πQt(y≤t | Yt−1) ≤ r (28) πP (y)

holds for all Y1, . . . , YT .

Proof. Proof given in App. B.2.

Proposition 4.2 tells us that we can use Eq. (25)

to construct a consistent estimator of the inverse

inclusion probabilities. Moreover, assuming

Pr (y ∈ YT ) > 0, then we have that the importance

sampling yields an estimate πPIS(y) > 0, unlike

the Monte Carlo estimator πPMC(y). We further

see that, to the extent that

T t=1

πQt

(y≤t

|

Yt−1)

approximates πP (y), then we may expect the

variance of Eq. (25) to be small—speciﬁcally in

comparison to the na¨ıve Monte Carlo estimator in

Eq. (19)—which is often the case for estimators

built using importance sampling techniques when

a proposal distribution is chosen judiciously

(Rubinstein and Kroese, 2016). Thus, given our

estimator in Eq. (25), we can now construct a

practically useful estimator for Ey∼p [f (y)] using

the HT estimator in Eq. (17). In the next section,

we observe that this estimator is quite efﬁcient in

the sequence model setting.

5 Experiments

We repeat the analyses performed by Kool et al. (2019), running experiments on neural machine translation (NMT) models; for reproducibility, we use the pretrained Transformer model for WMT’14 (Bojar et al., 2014) English–French made available by fairseq11 (Ott et al., 2019). We evaluate on the En-Fr newstest2014 set, containing 3003 sentences. Further details can be found in App. D. Our implementation of CPSBS modiﬁes the beam
11https://github.com/pytorch/fairseq/tree/master/ examples/translation

search algorithm from the fairseq library. We additionally consider the beam search, stochastic beam search, diverse beam search, and ancestral sampling algorithms available in fairseq.

5.1 Statistical Estimators for Language Generation Models

Estimators have a large number of applications in machine learning. For example, the REINFORCE algorithm (Williams, 1992) constructs an estimator for the value of the score function; minimum-Bayes risk decoding (Kumar and Byrne, 2004) uses an estimate of risk in its optimization problem. In this section, we compare estimators for sentence-level BLEU score and conditional model entropy for NMT models. Notably, NMT models that are trained to minimize cross-entropy with the empirical distribution12 are not peaky distributions (Ott et al., 2018a; Eikema and Aziz, 2020); thus, standard estimation techniques, e.g., Monte Carlo, should generally provide good results. However, we can vary the annealing parameter of our model in order to observe the behavior of our estimator with both high- and low-entropy distributions, making this a comprehensive case study. Here the annealed model distribution is computed as

1

pτ (yt | y<t) ∝ p (yt | y<t) τ

(29)

where we should expect a standard Monte Carlo estimator to provide good results at τ close to 1 when p is naturally high entropy. We test our estimator in this setting so as to give a comparison in a competitive setting. Speciﬁcally, we assess the performance of our estimator of Ey∼p(y|x)[f (y)] given in Eq. (17)—using inclusion probability estimates from Eq. (25) with M = 1 and with importance weight normalization—in comparison to three other approaches: Monte Carlo (MC) sampling, the sum-and-sample (SAS) estimator, and stochastic beam search (SBS).

Monte Carlo. Under the Monte Carlo sampling scheme with sample size K, we estimate the expected value of f under our model using Eq. (16) with a sample y(1), . . . , y(K) i.∼i.d. p.

Sum and Sample. The sum-and-sample estimator (Botev et al., 2017; Liu et al., 2019; Kool et al., 2020) is an unbiased estimator that takes as input a deterministically chosen set Y of size K − 1 and
12Label-smoothing (Szegedy et al., 2016) is typically also employed, which leads to even higher entropy distributions.

BLEU Score

BLEU Score

30

26.5 27

30

28 26

25.5

26

26

25

25

25

24

20

10

20

30

40

50

10

20

30

40

50

10

20

30

40

50

10

20

30

40

50

34

34

36

33

34

34

33

32

32

32

32

31

30

30

31

30

28

29 30 28 26

24

10

20

30

40

50

10

20

30

40

50

10

20

30

40

50

10

20

30

40

50

30

25

30

22

25

25

20

20

20

20

15

18

15 10

15

10

20

30

40

50

10

5

10

20

30

40

50

10

20

30

40

50

10

20

30

40

50

Sample Size

Sample Size

Sample Size

Sample Size

SAS MC SBS CPSBS

BLEU Score

Figure 1: BLEU score estimates for three different sentences using estimators for respective decoding methods. τ indicates scaling temperature; τ values and sentences are chosen to mimic (Kool et al., 2019).

samples an additional y from the remaining elements, supp(p) \ Y , where we obtain the set Y using beam search in our experiments. Formally, the SAS estimator can be written as:

K −1

GSAS =def

p(y(k))f (y(k))

k=1

K −1
+ 1 − p(y(k))

(30) f (y )

k=1

Stochastic Beam Search. Stochastic beam search (Kool et al., 2019, 2020) is a SWOR algorithm likewise built on top of beam search. The algorithm makes use of truncated Gumbel random variables at each iteration, resulting in a sampling design equivalent to performing the Gumbeltop-k trick (Vieira, 2014) on the distribution p. Estimators built using SBS likewise follow the Horvitz–Thompson scheme of Eq. (17); we refer the reader to the original work for inclusion probability computations. They suggest normalizing the estimator by the sum of sample inclusion probabilities to help reduce variance; we therefore likewise perform this normalization in our experiments.
To assess the error of our estimator, we compute its root MSE (RMSE) with respect to a baseline result. While computing the exact value of an expectation is typically infeasible in the sequence model setting, we can average our (unbiased) MC estimator in Eq. (16) over multiple runs to create a good baseline. Speciﬁcally, we compute our MC estimator 50 times for a large sample size

(K = 200); variances are reported in App. D. Probabilistic models for language generation typ-
ically have large vocabularies. In this setting, the computation of Eq. (12) is inefﬁcient due to the large number of items in the set that are assigned very small probability under the model. We experiment with truncating this distribution such that the set of possible extensions of a sequence consist only of the highest probability tokens within the core n% of probability mass (0.99 in our experiments), similar to the process in nucleus sampling (Holtzman et al., 2020). We compare this approach to the original algorithm design in App. D and see that empirically, results are virtually unchanged; the following results use this method. We also compare the decoding time of different sampling methods in Fig. 7.
BLEU Score Estimation. BLEU (Papineni et al., 2002) is a widely used automatic evaluation metric for the quality of machine-generated translations. Estimates of BLEU score are used in minimum risk training (Shen et al., 2016) and reinforcement learning-based approaches (Ranzato et al., 2016) to machine translation. As such, accurate and lowvariance estimates are critical for the algorithms’ performance. Formally, we estimate the expected value of f (y) = BLEU(x, y), whose dependence on x we leave implicit, under our NMT model p for reference translation x. For comparison, we use the same sentences and similar annealing tempera-
12We refer the reader to the original work (Kool et al., 2019) for equations for inclusion probability estimates.

RMSE

2

4

6

2 3 4

112

1

2

0

0

0

10

20

30

40

50

10

20

30

40

50

10

20

30

40

50

10

20

30

40

50

Sample Size

Sample Size

Sample Size

Sample Size

SAS MC SBS CPSBS

RMSE

(a) RMSE of BLEU score estimator for different temperatures. Results are averaged across several sentences.

1.6

2

6

1.4

1.5

2

1.2 4 1

1

0.5

1

2

SAS MC SBS CPSBS

0.8

0

10 20 30 40 50

10 20 30 40 50

10 20 30 40 50

10 20 30 40 50

Sample Size

Sample Size

Sample Size

Sample Size

(b) RMSE of conditional model entropy estimator for various temperatures. Results are averaged across several sentences. We see a larger bias under both CPSBS and SBS at higher temperatures in these experiments.

Figure 2: RMSE evaluations.

tures13 τ evaluated by Kool et al. (2019). We repeat the sampling 20 times and plot the value and standard deviation (indicated by shaded region) of different estimators in Fig. 1. From Fig. 1, we can see that CPSBS has lower variance than our baseline estimators across all temperatures and data points.14 Especially in the low temperature setting, our estimator converges rapidly with minor deviation from the exact values even for small sample sizes. Additionally, in Fig. 2a we see that the RMSE is typically quite low except at higher temperatures. In such cases, we observe the effects of biasedness, similar to Kool et al. (2019)’s observations.
Conditional Entropy Estimation. We perform similar experiments for estimates of a model’s conditional entropy, i.e., f (y) = − log p(y | x), whose dependence on x we again leave implicit. We show results in Fig. 2b, with plots of the value in App. D since results are quite similar to Fig. 1. We see further conﬁrmation that our estimator built on CPSBS is generally quite efﬁcient.
5.2 Diverse Sampling
We show how CPSBS can be used as a diverse set sampling design for language generation models. We generate a sample of translations YT ∼ P , i.e., according to the CPSBS scheme, where weights are set as wn = p(y≤(nt))/(1 − p(y≤(nt))) at each time step, as recommended in §3. In Fig. 3, we show the trade-off between minimum, average and maximum sentence-level BLEU score (as a quality
13Results for τ = 0.05 converged rapidly for all estimators, thus not providing an interesting comparison.
14The sampling distribution at n = 1 is not the same across strategies, hence the difference in variances even at n = 1.

45

40

35

BLEU Score

30

25

20

Sampling

SBS

DiverseBS

15

CPSBS

0.2

0.25

0.3

0.35

0.4

0.45

0.5

0.55

Diversity

Figure 3: Average (± min and max) BLEU score versus diversity for sample size k = 5. Points correspond to different annealing temperatures {0.1, . . . , 0.8}. Results for k = 10, 20 show very similar trends.

measure) and n-gram diversity, where we deﬁne ngram diversity D as the average fraction of unique vs. total n-grams for n = 1, 2, 3, 4 in a sentence:

4 #unique n-grams in K strings

D=

(31)

n=1 # n-grams in K strings

Metrics are averaged across the corpus. We follow the experimental setup of Kool et al. (2019), using the newstest2014 dataset and comparing three different decoding methods: SBS, diverse beam search (DiverseBS; Vijayakumar et al., 2018) and ancestral sampling. As in their experiments, we vary the annealing temperature in the range {0.1, 0.2, . . . , 0.8} as a means of encouraging diversity; for DiverseBS we instead vary the strength parameter in the same range. Interestingly, we see that temperature has virtually no effect on the

diversity of the set of results returned by CPSBS. Despite this artifact, for which the authors have not found a theoretical justiﬁcation,15 the set returned by CPSBS is still overall more diverse (position on x-axis) than results returned by DiverseBS and reﬂect better min, max, and average BLEU in comparison to random sampling. SBS provides a better spectrum for the diversity and BLEU tradeoff; we thus recommend SBS when diverse sets are desired.
6 Conclusion
In this work, we present conditional Poisson stochastic beam search, a sampling-withoutreplacement strategy for sequence models. Through a simple modiﬁcation to beam search, we turn this mainstay decoding algorithm into a stochastic process. We derive a low-variance, consistent estimator of inclusion probabilities under this scheme; we then present a general framework for using CPSBS to construct statistical estimators for expectations under sequence models. In our experiments, we observe a reduction in mean square error, and an increase in sample efﬁciency, when using our estimator in comparison to several baselines, showing the beneﬁts of CPSBS.
Acknowledgements
We thank Darcey Riley, as well as our anonymous reviewers, for their helpful feedback.
References
Nibia Aires. 1999. Algorithms to ﬁnd exact inclusion probabilities for conditional Poisson sampling and Pareto πps sampling designs. Methodology and Computing in Applied Probability, 1(4):457–469.
Peter J. Bickel and Kjell A. Docksum. 2015. Mathematical Statistics: Basic ideas and Selected Topics. CRC Press.
Ondˇrej Bojar, Christian Buck, Christian Federmann, Barry Haddow, Philipp Koehn, Johannes Leveling, Christof Monz, Pavel Pecina, Matt Post, Herve Saint-Amand, Radu Soricut, Lucia Specia, and Alesˇ Tamchyna. 2014. Findings of the 2014 workshop on statistical machine translation. In Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 12–58, Baltimore, Maryland, USA. Association for Computational Linguistics.
15While scaling sampling weights by a constant should not change the distribution P , an exp transformation of weights—which is the computation performed by temperature annealing—should.

Lennart Bondesson, Imbi Traat, and Anders Lundqvist. 2006. Pareto sampling versus Sampford and conditional Poisson sampling. Scandinavian Journal of Statistics, 33(4):699–720.
Aleksandar Botev, Bowen Zheng, and David Barber. 2017. Complementary sum sampling for likelihood approximation in large scale classiﬁcation. In Proceedings of the International Conference on Artiﬁcial Intelligence and Statistics.
Martin Bu¨cker, George Corliss, Paul Hovland, Uwe Naumann, and Boyana Norris. 2006. Automatic Differentiation: Applications, Theory, and Implementations (Lecture Notes in Computational Science and Engineering). Springer-Verlag, Berlin, Heidelberg.
Sergey Edunov, Myle Ott, Michael Auli, and David Grangier. 2018. Understanding back-translation at scale. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 489–500, Brussels, Belgium. Association for Computational Linguistics.
Bryan Eikema and Wilker Aziz. 2020. Is MAP decoding all you need? The inadequacy of the mode in neural machine translation. In Proceedings of the 28th International Conference on Computational Linguistics, pages 4506–4520, Barcelona, Spain (Online). International Committee on Computational Linguistics.
Anton Grafstro¨m. 2009. Non-rejective implementations of the Sampford sampling design. Journal of Statistical Planning and Inference, 139(6):2111– 2114.
J. Ha´jek. 1981. Sampling from a Finite Population. Statistics Series. Marcel Dekker.
Jaroslav Ha´jek. 1964. Asymptotic theory of rejective sampling with varying probabilities from a ﬁnite population. Annals of Mathematical Statistics, 35(4):1491–1523.
Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2020. The curious case of neural text degeneration. In Proceedings of the 7th International Conference on Learning Representations.
D. G. Horvitz and D. J. Thompson. 1952. A generalization of sampling without replacement from a ﬁnite universe. Journal of the American Statistical Association, 47(260):663–685.
Wouter Kool, Herke Van Hoof, and Max Welling. 2019. Stochastic beams and where to ﬁnd them: The Gumbel-top-k trick for sampling sequences without replacement. In Proceedings of the 36th International Conference on Machine Learning.
Wouter Kool, Herke van Hoof, and Max Welling. 2020. Estimating gradients for discrete random variables by sampling without replacement. In Proceedings of the 8th International Conference on Learning Representations.

Alex Kulesza and Ben Taskar. 2012. Determinantal point processes for machine learning. Foundations and Trends® in Machine Learning, 5(2–3):123–286.
Shankar Kumar and William Byrne. 2004. Minimum Bayes-risk decoding for statistical machine translation. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics: HLT-NAACL 2004, pages 169–176, Boston, Massachusetts, USA. Association for Computational Linguistics.
Runjing Liu, Jeffrey Regier, Nilesh Tripuraneni, Michael Jordan, and Jon Mcauliffe. 2019. RaoBlackwellized stochastic gradients for discrete distributions. In Proceedings of the 36th International Conference on Machine Learning.
Clara Meister, Ryan Cotterell, and Tim Vieira. 2020a. If beam search is the answer, what was the question? In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2173–2185, Online. Association for Computational Linguistics.
Clara Meister, Martina Forster, and Ryan Cotterell. 2021. Determinantal beam search. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 6551–6562, Online. Association for Computational Linguistics.
Clara Meister, Tim Vieira, and Ryan Cotterell. 2020b. Best-ﬁrst beam search. Transactions of the Association for Computational Linguistics, 8:795–809.
Myle Ott, Michael Auli, David Grangier, and Marc’Aurelio Ranzato. 2018a. Analyzing uncertainty in neural machine translation. In Proceedings of the 35th International Conference on Machine Learning.
Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, and Michael Auli. 2019. fairseq: A fast, extensible toolkit for sequence modeling. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations), pages 48–53, Minneapolis, Minnesota. Association for Computational Linguistics.
Myle Ott, Sergey Edunov, David Grangier, and Michael Auli. 2018b. Scaling neural machine translation. In Proceedings of the Third Conference on Machine Translation: Research Papers, pages 1–9, Brussels, Belgium. Association for Computational Linguistics.
Art B. Owen. 2013. Monte Carlo theory, methods and examples.
Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: A method for automatic evaluation of machine translation. In Proceedings

of the 40th Annual Meeting on Association for Computational Linguistics, pages 311–318.
Marc’Aurelio Ranzato, Sumit Chopra, Michael Auli, and Wojciech Zaremba. 2016. Sequence level training with recurrent neural networks. In Proceedings of the 4th International Conference on Learning Representations.
Raj Reddy. 1977. Speech understanding systems: A summary of results of the ﬁve-year research effort at Carnegie Mellon University. Technical report.
Reuven Y. Rubinstein and Dirk P. Kroese. 2016. Simulation and the Monte Carlo Method, 3rd edition. Wiley Publishing.
Iulian Vlad Serban, Tim Klinger, Gerald Tesauro, Kartik Talamadupula, Bowen Zhou, Yoshua Bengio, and Aaron Courville. 2017. Multiresolution recurrent neural networks: An application to dialogue response generation. In Proceedings of the ThirtyFirst AAAI Conference on Artiﬁcial Intelligence.
Shiqi Shen, Yong Cheng, Zhongjun He, Wei He, Hua Wu, Maosong Sun, and Yang Liu. 2016. Minimum risk training for neural machine translation. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1683–1692, Berlin, Germany. Association for Computational Linguistics.
Kensen Shi, David Bieber, and Charles Sutton. 2020. Incremental sampling without replacement for sequence models. In Proceedings of the 37th International Conference on Machine Learning.
C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna. 2016. Rethinking the inception architecture for computer vision. In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2818–2826, Los Alamitos, CA, USA. IEEE Computer Society.
Yves Tille´. 2006. Sampling Algorithms. Springer.
Tim Vieira. 2014. Gumbel-max trick and weighted reservoir sampling.
Ashwin Vijayakumar, Michael Cogswell, Ramprasaath Selvaraju, Qing Sun, Stefan Lee, David Crandall, and Dhruv Batra. 2018. Diverse beam search for improved description of complex scenes. In Proceedings of the Thirty-Second AAAI Conference on Artiﬁcial Intelligence, 1.
Ronald J. Williams. 1992. Simple statistical gradientfollowing algorithms for connectionist reinforcement learning. Machine Learning, 8(3–4):229–256.
Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, and Quoc V. Le. 2019. XLNet: Generalized autoregressive pretraining for language understanding. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alche´-Buc,

E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32. Curran Associates, Inc.

A Conditional Poisson Sampling

Here we provide a brief overview of the sampling design at the core of CPSBS: conditional Poisson sampling. We consider a base set B where |B| = N and we map the elements of B = {y(1), . . . , y(N)} to the integers {1, . . . , N }. As a warm up, we ﬁrst consider (unconditional) Poisson sampling, also known as a Bernoulli point process. To sample a subset Y ⊆ B, we do as follows: for each element y ∈ B, we ﬂip a coin where the odds of heads is w(y). Then, we simply take Y to be the subset of elements whose coin ﬂips were heads. However, this sampling scheme clearly does not guarantee a sample of K items, which can cause problems in our application; sampling more than K items would make the stochastic beam search process inefﬁcient while sampling fewer than K—or even 0—items may not leave us with a large enough set at the end of our iterative process.
If instead, we condition on the sets always having a prescribed size K, i.e., reject samples where |Y | = K, we arrive at the conditional Poisson process. Formally, the conditional Poisson distribution is deﬁned over Y ⊆ B as follows,

Q(Y ) ∝def y∈Y w(y) if |Y | = K

(32)

0

otherwise

By analyzing Eq. (32), we can see that sets with the largest product of weights are the most likely to be sampled; further, this distribution is invariant to rescaling of weights due to the size requirement. This is similar to the conditions under which beam search chooses the set of K largest weight, i.e., highest scoring, elements. Indeed, we note the extreme similarity between Eq. (4) and Eq. (32), the only difference being a dependence on a prior set. However, unlike beam search, sets with a lower weight product now have the possibility of being chosen.

B Proofs
B.1 Unbiasedness of the Horvitz–Thompson Estimator
Proposition B.1. Given a SWOR design Q over the set B = {1, . . . , N } with inclusion probabilities π(n), the Horvitz–Thompson estimator (Eq. (17)) gives us an unbiased estimator of En∼p f (n), where f : B → Rd is a function whose expectation under p we seek to approximate.

Proof.

N p(n)

E [GHT] = E

Y ∼Q

Y ∼Q

f (n) π(n)

n=1

=E

p(n) 1{n ∈ Y } f (n)

Y ∼Q n∈B π(n)

=

p(n) f (n)

E

1{n ∈ Y }

n∈B π(n)

Y ∼Q

p(n)

=

f (n) π(n)

n∈B π(n)

= p(n) f (n)
n∈B

= E f (n)
n∼p

(33a) (33b) (33c) (33d) (33e) (33f)

B.2 Proofs of Expected Values and Variances of Inclusion Probability Estimators

Lemma 4.1. The joint proposal distribution P (Y1, . . . , YT ) =def terms of P as follows:

T t=1

Qt(Yt

|

Yt−1)

may

be

expressed

in

P (Y1, . . . , YT )

P (Y1, . . . , YT ) = T

(23)

t=1 πQt(y≤t | Yt−1)

where we deﬁne P (Y1, . . . , YT ) =def

T t=1

Qt(Yt

|

Yt−1)

as

the

joint

probability

of

the

beams

Y1, . . . , YT

under the original distributions Qt. We omit that both P and P are conditioned on Y0.

Proof. Consider the probability of sampling Y1, . . . , YT according to P . Algebraic manipulation reveals:

P (Y1, . . . , YT ) = Qt(Y1 | Y0) · · · Qt(YT | YT −1) πQt(y≤1 | Y0) πQt(y≤T | YT −1)

= P (Y1, . . . , YT )

T t=1

πQt (y≤t

|

Yt−1)

which proves the identity.

(34a) (34b)

Proposition 4.1. Eq. 19 has the following two properties:

i)

πMC P

is an unbiased estimator of πP

and

V [πPMC] = M1 πP (y) − πP (y)2 (20)

ii) 1/πPMC is a consistent estimator of 1/πP with asymptotic variance

1

1

1

1

Va πPMC(y) = M πP (y)3 − πP (y)2 (21)

Here Va denotes the asymptotic variance, which is the variance after the number of samples M is large enough such that the central limit theorem has kicked in (Bickel and Docksum, 2015).

Proof. i) The estimator is easily shown to be unbiased:

1 def 1 M

E

πM P

C

(y

)

=

M

m=1

y ∈ YT(m)

= πP (y)

and its variance may be derived as follows:

V [πPMC(y)] =def V

1

M
1 y ∈ Y (m)

M

T

m=1

= M1 V 1 y ∈ YT(m)

= M1 E 1 y ∈ YT(m) 2 − E 1 y ∈ YT(m) 2

= M1 πP (y) − πP (y)2

ii) By the strong law of large numbers, we have

lim

1

M
1 y ∈ Y (m)

M→∞ M

T

m=1

= πP (y)

(35)
(36a) (36b) (36c) (36d)
(37)

Since 1/x is continuous, we may appeal to the continuous mapping theorem to achieve consistency:

1

1

1

lim

=

=

(38)

M →∞ 1 M

M m=1

1

y ∈ YT(m)

limM →∞

1 M

M m=1

1

y ∈ YT(m)

πP (y)

We can compute the asymptotic variance by the delta rule:

Va

1

=

1

V

[

πIS P

(y

)]

πPMC (y)

M πP (y)4

1 πP (y) − πP (y)2

= M

πP (y)4

(apply the delta rule) (plugging in the variance computed above)

1 =
M

1

1

πP (y)3 − πP (y)2

(39a) (39b) (39c)

Proposition 4.2. Eq. (25) has the following two properties:

i)

πIS P

is an unbiased estimator of πP ;

ii) The estimator of the inverse inclusion probabilities 1/πPIS(y) is consistent with the following upper bound on the asymptotic variance:

1

1 r−1

Va πPIS(y) ≤ M πP (y)2 (27)

where we assume that the following bound:

Tt=1 πQt(y≤t | Yt−1) ≤ r (28) πP (y)

holds for all Y1, . . . , YT .

Proof. i) We ﬁrst prove that the estimator of the inclusion probabilities is unbiased through the following manipulation:

E [πPIS(y)] = E

1MT

(m)

M

πQt(y≤t | Yt−1 )

m=1 t=1

T

=

P (Y1, . . . , YT ) πQt(y≤t | Yt−1)

Y1,...,YT

t=1

P (Y1, . . . , YT ) T

=

P (Y1, . . . , YT )

πQt(y≤t | Yt−1)

Y ,...,Y

P (Y1, . . . , YT ) t=1

1

T

= P (Y1, . . . , YT ) P (Y1, . . . , YT )

Y1,...,YT

P (Y1, . . . , YT )

(Lemma 4.1)

(40a) (40b) (40c) (40d)

=

P (Y1, . . . , YT )

Y1,...,YT

=

P (Y1, . . . , YT ) 1

Y1,...,YT

= πP (y)

y ∈ YT

(deﬁnition of YT )

(40e) (40f) (40g)

ii) To show consistency, we appeal to the strong law of large number and the continuous mapping theorem. By the strong law of large numbers, we have that

1MT

(m)

lim M→∞ M

πQt(y≤t | Yt−1 ) = πP (y)

(41)

m=1 t=1

Since 1/x is continuous, we have

lim
M →∞ 1 M

M m=1

1

=

T t=1

πQt (y≤t

|

Yt−(m1 ) )

limM →∞

1 M

1 =
πP (y)

1

M m=1

T t=1

πQt (y≤t

|

Yt−(m1 ) )

(42a)

which shows consistency. Now, we derive a bound on the asymptotic variance of the inverse inclusion probabilities: Suppose,

Tt=1 πQt(y≤t | Yt−1) ≤ r, ∀ Y1, . . . , YT (43) πP (y)

We start with the variance of importance sampling. This is a standard result (Rubinstein and Kroese, 2016). Then we proceed with algebraic manipulation integrating the assumption above:

1
Y1,...,YT

2
y ∈ YT P (Y1, . . . , YT )2 − πP (y)2
P (Y1, . . . , YT )

T
= P (Y1, . . . , YT ) πQt(y≤t | Yt−1) − πP (y)2

Y1,...,YT

t=1

≤

P (Y1, . . . , YT )πP (y)r − πP (y)2

Y1,...,YT
= πP (y)πP (y)r − πP (y)2 = πP (y)2r − πP (y)2 = (r − 1)πP (y)2

(44a)
(44b)
(44c) (44d) (44e) (44f)

We can compute the asymptotic variance by the delta rule:

1 Va πIS(y)
P
which proves the result.

=

1

V

[

πIS P

(y

)]

M πP (y)4

(apply the delta rule)

1 (r − 1)πP (y)2

≤ M

πP (y)4

(plugging in the above bound)

1 (r − 1) = M πP (y)2

(45a) (45b) (45c)

C Pseudocode

Algorithm 1 Dynamic program algorithm for Z Input: K: Size of subset
w1, . . . , wN : weights for each element of the base set Output: W : elementary symmetric polynomials of w1, . . . , wN ; Z = WN,K

1: W ← 0(K+1)×(N+1)

2: W0,: = 0; W:,0 = 1

3: for n = 1, . . . , N :

4: for k = 1, . . . , K :

5:

Wn,k ← Wn−1,k + wnWn−1,k−1

6: return W

Algorithm 2 Dynamic program for calculating inclusion probabilities π

Input: K: Size of subset

w1, . . . , wN : weights for each element of the base set

1: Run Alg. 1 to compute W

2: .The code below was derived by manually apply algorithmic differentiation (Bu¨cker et al., 2006) to Alg. 1.
3: W ← 0(K+1)×(N+1) Initialize adjoints
4: w.. ← 0N
5: WN,K = 1 Initialize output value to 1 6: for n = N, . . . , 1 :

7:

for k
.

=

K.,

.

.

.

,

1

:

8:

w.n += Wn,k Wn. −1,k−1

9:

W. n−1,k−1 +=. Wn,k wn

10:

Wn−1,k += Wn,k

11: Apply Eq. (24)
12: π ← 0N
13: for n = 1 . . . N :
14: πn ← wZn w. n
return π

D Experimental Setup and Additional Results
We use a Transformer-based model trained according to Ott et al. (2018b) on the WMT’14 English-French dataset.16 We use the pre-trained model checkpoints made available by fairseq.17 Data preprocessing steps, model hyperparameters and baseline performances can be found in the original work and on the fairseq website. All evaluations are performed on the wmt14.v2.en-fr.newstest2014 version of the newstest data set. We show additional results using the setup in §5 in Figs. 4 to 6. We provide an empirical runtime analysis in Fig. 7. Table 2 shows the variance of baseline estimator value for the three sentences used in RMSE experiments.

Entropy

Entropy

12

4

6

30

10

5

25

3

8

20

4

2

6

15

3

4 10

12 5

10

20

30

40

50

10

20

30

40

50 5

10

20

30

40

50

10

20

30

40

50

2.5

3

12

4

10

2

2.5

3

8

2

1.5

6

1.5

2

4

1

1

1

2

10

20

30

40

50

3

10

20

30

40

50

10

20

30

40

50

10

20

30

40

50

10

20

2.5

6

8

15

2

4

6

1.5

10

1

2

4

5 0.5

10

20

30

40

50

10

20

30

40

50

10

20

30

40

50

10

20

30

40

50

Sample Size

Sample Size

Sample Size

Sample Size

SAS MC SBS CPSBS

Entropy

Figure 4: Entropy estimates for three different sentences using estimators for respective decoding methods. τ indicates scaling temperature. Values are chosen to mimic (Kool et al., 2019).

BLEU Score

50 40 30 20 10 0
10

20

30

40

Sample Size

120 100
80 60 40 20 0

50

10

20

30

40

Sample Size

30

20

10

0

50

10

20

30

40

Sample Size

MC SBS CPSBS
50

Figure 5: BLEU score estimates using unnormalized versions of SBS and CPSBS estimators.

Sentence# 1500 Sentence# 2000 Sentence# 2500

BLEU Estimator Temperature
0.1 0.2 0.3 0.5
0.00 0.00 0.03 0.08 0.01 0.04 0.04 0.08 0.07 0.09 0.25 0.84

Entropy Estimator Temperature
0.1 0.2 0.3 0.5
0.00 0.01 0.07 0.10 0.00 0.00 0.00 0.02 0.00 0.01 0.03 0.04

Table 2: Variance of baseline estimator (MC for k = 200 in 50 iterations) for the three sentences.

16available at http://statmt.org/wmt14/translation-task.html 17https://github.com/pytorch/fairseq/tree/master/examples/translation

BLEU Score

34 33 32 31 30 29
5

10

15

Sample Size

34

33

32

31

30

20

5

10

15

Sample Size

36

34

32

30

28

20

5

10

15

Sample Size

MC SBS CPSBS(+Nucleus) CPSBS(-Nucleus)
20

Figure 6: BLEU score estimates for CPSBS both with and without truncation of the sampling distribution. We see that our estimator with truncation provides virtually the same results.

Time (Seconds)

12

10

8

6

4

2 5

10

15

Sample Size

12 10 8 6 4 2 20

5

10

15

Sample Size

12 10
8 6 4 2 20

5

10

15

Sample Size

14 12 10 8 6 4 2 20

5

10

15

Sample Size

CPSBS SBS MC
20

Figure 7: A comparison between decoding time of different sampling methods. The y-axis shows the average decoding time of the three sentences as before. The x-axis shows the number of samples taken for each sentence. All methods are tested on CPU.

