Econometrica, Vol. 68, No. 5 ŽSeptember, 2000., 1127᎐1150
A SIMPLE ADAPTIVE PROCEDURE LEADING TO CORRELATED EQUILIBRIUM1
BY SERGIU HART AND ANDREU MAS-COLELL2
We propose a new and simple adaptive procedure for playing a game: ‘‘regret-matching.’’ In this procedure, players may depart from their current play with probabilities that are proportional to measures of regret for not having used other strategies in the past. It is shown that our adaptive procedure guarantees that, with probability one, the empirical distributions of play converge to the set of correlated equilibria of the game.
KEYWORDS: Adaptive procedure, correlated equilibrium, no regret, regret-matching, simple strategies.
1. INTRODUCTION
THE LEADING NONCOOPERATIVE EQUILIBRIUM NOTIONS for N-person games in strategic Žnormal. form are Nash equilibrium Žand its reﬁnements. and correlated equilibrium. In this paper we focus on the concept of correlated equilibrium.
A correlated equilibriumᎏa notion introduced by Aumann Ž1974.ᎏcan be described as follows: Assume that, before the game is played, each player receives a private signal Žwhich does not affect the payoffs.. The player may then choose his action in the game depending on this signal. A correlated equilibrium of the original game is just a Nash equilibrium of the game with the signals. Considering all possible signal structures generates all correlated equilibria. If the signals are Žstochastically. independent across the players, it is a Nash equilibrium Žin mixed or pure strategies. of the original game. But the signals could well be correlated, in which case new equilibria may obtain.
Equivalently, a correlated equilibrium is a probability distribution on N-tuples of actions, which can be interpreted as the distribution of play instructions given to the players by some ‘‘device’’ or ‘‘referee.’’ Each player is givenᎏprivatelyᎏ instructions for his own play only; the joint distribution is known to all of them. Also, for every possible instruction that a player receives, the player realizes that the instruction provides a best response to the random estimated play of the other playersᎏassuming they all follow their instructions.
There is much to be said for correlated equilibrium. See Aumann Ž1974, 1987. for an analysis and foundational arguments in terms of rationality. Also, from a
1 October 1998 Žminor corrections: June 1999.. Previous versions: February 1998; November 1997; December 1996; March 1996 Žhandout.. Research partially supported by grants of the U.S.-Israel Binational Science Foundation, the Israel Academy of Sciences and Humanities, the Spanish Ministry of Education, and the Generalitat de Catalunya.
2 We want to acknowledge the useful comments and suggestions of Robert Aumann, Antonio Cabrales, Dean Foster, David Levine, Alvin Roth, Reinhard Selten, Sylvain Sorin, an editor, the anonymous referees, and the participants at various seminars where this work was presented.
1127

1128

SERGIU HART AND ANDREU MAS-COLELL

practical point of view, it could be argued that correlated equilibrium may be the most relevant noncooperative solution concept. Indeed, with the possible exception of well-controlled environments, it is hard to exclude a priori the possibility that correlating signals are amply available to the players, and thus ﬁnd their way into the equilibrium.
This paper is concerned with dynamic considerations. We pose the following question: Are there simple adapti¨e procedures always leading to correlated equilibrium?
Foster and Vohra Ž1997. have obtained a procedure converging to the set of correlated equilibria. The work of Fudenberg and Levine Ž1999. led to a second one. We introduce here a procedure that we view as particularly simple and intuitive Žsee Section 4 for a comparative discussion of all these procedures.. It does not entail any sophisticated updating, prediction, or fully rational behavior. Our procedure takes place in discrete time and it speciﬁes that players adjust strategies probabilistically. This adjustment is guided by ‘‘regret measures’’ based on observation of past periods. Players know the past history of play of all players, as well as their own payoff matrix Žbut not necessarily the payoff matrices of the other players.. Our Main Theorem is: The adaptive procedure generates trajectories of play that almost surely converge to the set of correlated equilibria.
The procedure is as follows: At each period, a player may either continue playing the same strategy as in the previous period, or switch to other strategies, with probabilities that are proportional to how much higher his accumulated payoff would have been had he always made that change in the past. More precisely, let U be his total payoff up to now; for each strategy k different from his last period strategy j, let VŽ k. be the total payoff he would have received if he had played k every time in the past that he chose j Žand everything else remained unchanged.. Then only those strategies k with VŽ k. larger than U may be switched to, with probabilities that are proportional to the differences VŽ k. y U, which we call the ‘‘regret’’ for having played j rather than k. These probabilities are normalized by a ﬁxed factor, so that they add up to strictly less than 1; with the remaining probability, the same strategy j is chosen as in the last period.
It is worthwhile to point out three properties of our procedure. First, its simplicity; indeed, it is very easy to explain and to implement. It is not more involved than ﬁctitious play ŽBrown Ž1951. and Robinson Ž1951.; note that in the two-person zero-sum case, our procedure also yields the minimax value.. Second, the procedure is not of the ‘‘best-reply’’ variety Žsuch as ﬁctitious play, smooth ﬁctitious play ŽFudenberg and Levine Ž1995, 1999.. or calibrated learning ŽFoster and Vohra Ž1997..; see Section 4 for further details.. Players do not choose only their ‘‘best’’ actions, nor do they give probability close to 1 to these choices. Instead, all ‘‘better’’ actions may be chosen, with probabilities that are proportional to the apparent gains, as measured by the regrets; the procedure could thus be called ‘‘regret-matching.’’ And third, there is ‘‘inertia.’’ The strategy played in the last period matters: There is always a positive probability of

CORRELATED EQUILIBRIUM

1129

continuing to play this strategy and, moreover, changes from it occur only if there is reason to do so.
At this point a question may arise: Can one actually guarantee that the smaller set of Nash equilibria is always reached? The answer is deﬁnitely ‘‘no.’’ On the one hand, in our procedure, as in most others, there is a natural coordination device: the common history, observed by all players. It is thus reasonable to expect that, at the end, independence among the players will not obtain. On the other hand, the set of Nash equilibria is a mathematically complex set Ža set of ﬁxed-points; by comparison, the set of correlated equilibria is a convex polytope., and simple adaptive procedures cannot be expected to guarantee the global convergence to such a set.
After this introductory section, in Section 2 we present the model, describe the adaptive procedure, and state our result Žthe Main Theorem.. Section 3 is devoted to a ‘‘stylized variation’’ of the procedure of Section 2. It is a variation that lends itself to a very direct proof, based on Blackwell’s Ž1956a. Approachability Theorem. This is a new instrument in this ﬁeld, which may well turn out to be widely applicable.
Section 4 contains a discussion of the literature, together with a number of relevant issues. The proof of the Main Theorem is relegated to the Appendix.

2. THE MODEL AND MAIN RESULT
Let ⌫ s Ž N, ŽS i.ig N , Žui.ig N . be a ﬁnite N-person game in strategic Žnormal. form: N is the set of players, Si is the set of strategies of player i, and ui : Ł ig N Si ª ‫ ޒ‬is player i’s payoff function. All sets N and Si are assumed to be ﬁnite. Denote by S [ Ł ig N Si the set of N-tuples of strategies; the generic element of S is s s Ž si.ig N , and syi denotes the strategy combination of all players except i, i.e., syi s Ž siX .iX / i. We focus attention on the following solution concept:
DEFINITION: A probability distribution ␺ on S is a correlated equilibrium of ⌫ if, for every i g N, every j g Si and every k g Si we have3
Ý ␺ Ž s. w ui Ž k , syi . y ui Ž s.x F 0.
sgS : s isj
If in the above inequality we replace the right-hand side by an ␧ ) 0, then we obtain the concept of a correlated ␧-equilibrium.
Note that every Nash equilibrium is a correlated equilibrium. Indeed, Nash equilibria correspond to the special case where ␺ is a product measure, that is, the play of the different players is independent. Also, the set of correlated equilibria is nonempty, closed and convex, and even in simple games Že.g., ‘‘chicken’’. it may include distributions that are not in the convex hull of the Nash equilibrium distributions.
3 We write Ýsg S : sisj for the sum over all N-tuples s in S whose ith coordinate si equals j.

1130

SERGIU HART AND ANDREU MAS-COLELL

Suppose now that the game ⌫ is played repeatedly through time: t s 1, 2, . . . .

At

time

t q 1,

given

a

history

of

play

h

t

s

Ž

s␶

.␶ts

1

g

Ł

t ␶

s

1

S

,

we

postulate

that

each

player

igN

chooses

s

i tq

1

g

S

i

according

to

a

probability

distribution4

ptiq1 g ⌬ŽS i. which is deﬁned in the following way:

For every two different strategies j, k g Si of player i, suppose i were to

replace strategy j, every time that it was played in the past, by strategy k; his

payoff at time ␶ , for ␶ F t, would become

Ž2.1a.

½ W␶iŽ j, k. [

ui Ž k , s␶yi . , ui Ž s␶ . ,

if s␶i s j, otherwise .

The resulting difference in i’s average payoff up to time t is then

Ž2.1b.

Ý Ý 1 t

1t

Dti Ž j, k . [

W␶i Ž j, k . y

ui Ž s␶ .

t ␶s1

t ␶s1

Ý 1

s

ui Ž k , s␶yi . y ui Ž s␶ . .

t ␶Ft : s isj

␶

Finally, denote

Ž2.1c. Rti Ž j, k . [ Dti Ž j, k . qs maxÄ Dti Ž j, k . , 04 .

The

expression

R

i t

Ž

j,

k

.

has

a

clear

interpretation

as

a

measure

of

the

Žaverage.

‘‘regret’’ at period t for not having played, every time that j was played in the

past, the different strategy k.
Fix ␮ ) 0 to be a large enough number.5 Let j g Si be the strategy last chosen by player i, i.e., j s sti. Then the probability distribution ptiq1 g ⌬ŽSi. used by i at time t q 1 is deﬁned as

Ž2.2.

¡1 ptiq1Ž k . [ ␮ Rit Ž j, k . ,

~ Ý ptiq1Ž j. [ 1 y

ptiq1Ž k . .

¢ kgS i : k/j

for all k / j,

Note that the choice of ␮ guarantees that ptiq1Ž j. ) 0; that is, there is always a

positive probability of playing the same strategy as in the previous period. The

play

p

i 1

g

⌬

Ž

S

i

.

at

the

initial

period

is

chosen

arbitrarily.6

4 We write ⌬ŽQ. for the set of probability distributions over a ﬁnite set Q. 5 The parameter ␮ is ﬁxed throughout the procedure Žindependent of time and history.. It sufﬁces to take ␮ so that ␮ ) 2 M iŽ mi y 1. for all i g N, where M i is an upper bound for < uiŽи.< and mi is the number of strategies of player i. Even better, we could let ␮ satisfy ␮ ) Ž mi y 1.< uiŽ k, syi . y
uiŽ j, syi .< for all j, k g S i, all syi g Syi, and all i g N Žand moreover we could use a different ␮i for
each player i.. 6 Actually, the procedure could start with any ﬁnite number of periods where the play is arbitrary.

CORRELATED EQUILIBRIUM

1131

Informally, Ž2.2. may be described as follows. Player i starts from a ‘‘reference

point’’: his current actual play. His choice next period is governed by propensi-

ties to depart from it. It is natural therefore to postulate that, if a change occurs,

it should be to actions that are perceived as being better, relative to the current

choice. In addition, and in the spirit of adaptive behavior, we assume that all

such better choices get positive probabilities; also, the better an alternative

action seems, the higher the probability of choosing it next time. Further, there is also inertia: the probability of staying put Žand playing the same action as in the last period. is always positive.

More precisely, the probabilities of switching to different strategies are

proportional to their regrets relative to the current strategy. The factor of

proportionality is constant. In particular, if the regrets are small, then the

probability of switching from current play is also small. For every t, let zt g ⌬ŽS. be the empirical distribution of the N-tuples of
strategies played up to time t. That is, for every7 s g S,

Ž2.3.

1 zt Ž s. [ t Ä␶ F t : s␶ s s4

is the relative frequency that the N-tuple s has been played in the ﬁrst t

periods. We can now state our main result.

MAIN THEOREM: If e¨ery player plays according to the adapti¨e procedure Ž2.2.,
then the empirical distributions of play zt con¨erge almost surely as t ª ϱ to the set of correlated equilibrium distributions of the game ⌫ .

Note that convergence to the set of correlated equilibria does not imply that
the sequence zt converges to a point. The Main Theorem asserts that the following statement holds with probability one: For any ␧ ) 0 there is T0 s T0Ž␧ . such that for all t ) T0 we can ﬁnd a correlated equilibrium distribution ␺t at a distance less than ␧ from zt. ŽNote that this T0 depends on the history; it is an ‘‘a.s. ﬁnite stopping time.’’. That is, the Main Theorem says that, with probability one, for any ␧ ) 0, the Žrandom. trajectory Ž z1, z2 , . . . , zt, . . . . enters and then stays forever in the ␧-neighborhood in ⌬ŽS. of the set of correlated equilibria. Put differently: Given any ␧ ) 0, there exists a constant Ži.e., independent of history. t0 s t0Ž␧ . such that, with probability at least 1 y ␧ , the empirical distributions zt for all t ) t0 are in the ␧-neighborhood of the set of correlated equilibria. Finally, let us note that because the set of correlated equilibria is nonempty and compact, the statement ‘‘the trajectory Ž zt. converges to the set of correlated equilibria’’ is equivalent to the statement ‘‘the trajectory Ž zt. is such that for any ␧ ) 0 there is T1 s T1Ž␧ . with the property that zt is a correlated ␧-equilibrium for all t ) T1.’’
We conclude this section with a few comments Žsee also Section 4.: Ž1. Our adaptive procedure Ž2.2. requires player i to know his own payoff matrix Žbut not those of the other players. and, at time t q 1, the history ht;
7 We write < Q< for the number of elements of a ﬁnite set Q.

1132

SERGIU HART AND ANDREU MAS-COLELL

actually, the empirical distribution zt of Ž s1, s2 , . . . , st. sufﬁces. In terms of computation, player i needs to keep record of the time t together with the miŽ mi y 1. numbers DtiŽ j, k. for all j / k in Si Žand update these numbers every period..
Ž2. At every period the adaptive procedure that we propose randomizes only
over the strategies that exhibit positive regret relative to the most recently
played strategy. Some strategies may, therefore, receive zero probability. Sup-
pose that we were to allow for trembles. Speciﬁcally, suppose that at every period we put a ␦ ) 0 probability on the uniform tremble Žeach strategy thus being played with probability at least ␦rmi.. It can be shown that in this case the empirical distributions zt converge to the set of correlated ␧-equilibria Žof course, ␧ depends on ␦ , and it goes to zero as ␦ goes to zero.. In conclusion, unlike most adaptive procedures, ours does not rely on trembles Žwhich are usually needed, technically, to get the ‘‘ergodicity’’ properties.; moreover, our
result is robust with respect to trembles. Ž3. Our adaptive procedure depends only on one parameter,8 ␮. This may be
viewed as an ‘‘inertia’’ parameter Žsee Subsections 4Žg. and 4Žh..: A higher ␮
yields lower probabilities of switching. The convergence to the set of correlated equilibria is always guaranteed Žfor any large enough ␮; see footnote 5., but the speed of convergence changes with ␮.
Ž4. We know little about additional convergence properties for zt. It is easy to see that the empirical distributions zt either converge to a Nash equilibrium in pure strategies, or must be inﬁnitely often outside the set of correlated equilibria Žbecause, if zt is a correlated equilibrium from some time on, then9 all regrets are 0, and the play does not change.. This implies, in particular, that interior Žrelative to ⌬ŽS.. points of the set of correlated equilibria that are not pure Nash equilibria are unreachable as the limit of some zt Žbut it is possible that they are reachable as limits of a subsequence of zt..
Ž5. There are other procedures enjoying convergence properties similar to ours: the procedures of Foster and Vohra Ž1997., of Fudenberg and Levine Ž1999., and of Theorem A in Section 3 below; see the discussion in Section 4.
The delimitation of general classes of procedures converging to correlated equilibria seems, therefore, an interesting research problem.10

3. NO REGRET AND BLACKWELL APPROACHABILITY
In this section Žwhich can be viewed as a motivational preliminary. we shall replace the adaptive procedure of Section 2 by another procedure that, while related to it, is more stylized. Then we shall analyze it by means of Blackwell’s Ž1956a. Approachability Theorem, and prove that it yields convergence to the
8 Using a parameter ␮ Žrather than a ﬁxed normalization of the payoffs. was suggested to us by Reinhard Selten.
9 See the Proposition in Section 3. 10 See Hart and Mas-Colell Ž1999. and Cahn Ž2000. for such results.

CORRELATED EQUILIBRIUM

1133

set of correlated equilibria. In fact, the Main Theorem stated in Section 2, and
its proof in Appendix 1, were inspired by consideration and careful study of the
result of this section. Furthermore, the procedure here is interesting in its own right Žsee, for instance, the Remark following the statement of Theorem A, and Žd. in Section 4..
Fix a player i and recall the procedure of Section 2: At time t q 1 the
transition probabilities, from the strategy played by player i in period t to the strategies to be played at t q 1, are determined by the stochastic matrix deﬁned by the system Ž2.2.. Consider now an invariant probability vector qti s Ž qtiŽ j..jg Si g ⌬ŽSi. for this matrix Žsuch a vector always exists.. That is, qti satisﬁes

Ý Ý 1

1

qti Ž j . s k/j qti Ž k . ␮ Rit Ž k , j . q qti Ž j . 1 y k/j ␮ Rit Ž j, k . ,

for every j g Si. By collecting terms, multiplying by ␮, and formally letting RitŽ j, j. [ 0, the above expression can be rewritten as

Ž3.1.

Ý

qti Ž k . Rit Ž k , j . s qti Ž j .

Ý

R

i t

Ž

j,

k

.

,

kgS i

kgS i

for every j g Si. In this section we shall assume that play at time t q 1 by player i is
determined by a solution qti to the system of equations Ž3.1.; i.e., ptiq1Ž j. [ qtiŽ j.. In a sense, we assume that player i at time t q 1 goes instantly to the invariant distribution of the stochastic transition matrix determined by Ž2.2.. We now state
the key result.

THEOREM A: Suppose that at e¨ery period t q 1 player i chooses strategies

according to a probability ¨ector qti that satisﬁes Ž3.1.. Then player i’s regrets

R

i t

Ž

j,

k

.

con¨ erge

to

zero

almost

surely

for

e¨ ery

j, k

in

Si

with

j / k.

REMARK: Note thatᎏin contrast to the Main Theorem, where every player uses Ž2.2.ᎏno assumption is made in Theorem A on how players different from i choose their strategies Žexcept for the fact that for every t, given the history up to t, play is independent among players.. In the terminology of Fudenberg and Levine Ž1999, 1998., the adaptive procedure of this section is ‘‘Žuniversally. calibrated.’’ For an extended discussion of this issue, see Subsection 4Žd..
What is the connection between regrets and correlated equilibria? It turns out
that a necessary and sufﬁcient condition for the empirical distributions to
converge to the set of correlated equilibria is precisely that all regrets converge
to zero. More generally, we have the following proposition.

PROPOSITION: Let Ž st .ts1, 2, . . . be a sequence of plays Ži.e., st g S for all t. and let11 ␧ G 0. Then: limsuptªϱ RtiŽ j, k. F ␧ for e¨ery i g N and e¨ery j, k g S i with
11 Note that both ␧ ) 0 and ␧ s 0 are included.

1134

SERGIU HART AND ANDREU MAS-COLELL

j / k, if and only if the sequence of empirical distributions zt Ž deﬁned by Ž2.3.. con¨erges to the set of correlated ␧-equilibria.

PROOF: For each player i and every j / k in Si we have

Ý 1
Dti Ž j, k . s t ␶Ft : s isj
␶

ui Ž k , s␶yi . y ui Ž j, s␶yi .

s Ý zt Ž s. w ui Ž k , syi . y ui Ž j, syi .x .
sgS : s isj

On any subsequence where zt converges, say ztX ª ␺ g ⌬ŽS., we get
DtiX Ž j, k . ª Ý ␺ Ž s. w ui Ž k , syi . y ui Ž j, syi .x .
sgS : s isj

The result is immediate from the deﬁnition of a correlated ␧-equilibrium and

Ž2.1c..

Q. E. D.

Theorem A and the Proposition immediately imply the following corollary.

COROLLARY: Suppose that at each period t q 1 e¨ery player i chooses strategies
according to a probability ¨ector qti that satisﬁes Ž3.1.. Then the empirical distributions of play zt con¨erge almost surely as t ª ϱ to the set of correlated equilibria of the game ⌫ .

Before addressing the formal proof of Theorem A, we shall present and
discuss Blackwell’s Approachability Theorem. The basic setup contemplates a decision-maker i with a Žﬁnite. action set Si.
For a ﬁnite indexing set L, the decision-maker receives an < L<-dimensional vector payoff ¨ Ž si, syi. g ‫ ޒ‬L that depends on his action si g S i and on some external action syi belonging to a Žﬁnite. set Syi Žwe will refer to yi as the ‘‘opponent’’.. The decision problem is repeated through time. Let st s Ž sti, syt i. g Si = Syi denote the choices at time t; of course, both i and yi may use
randomizations. The question is whether the decision-maker i can guarantee that the time average of the vector payoffs, Dt [ Ž1rt.Ý␶ F t¨ Ž s␶ . ' Ž1rt.Ý␶ F t¨ Ž s␶i , s␶yi., approaches a predetermined set Žin ‫ ޒ‬L..
Let C be a convex and closed subset of ‫ ޒ‬L. The set C is approachable by the decision-maker i if there is a procedure12 for i that guarantees that the average vector payoff Dt approaches the set C Ži.e.,13 distŽ Dt , C . ª 0 almost surely as t ª ϱ., regardless of the choices of the opponent yi. To state Blackwell’s result,
12 In the repeated setup, we refer to a Žbehavior. strategy as a ‘‘procedure.’’ 13 distŽ x, A. [ minÄ5 x y a5 : ag A4, where 5 и 5 is the Euclidean norm. Strictly speaking, Blackwell’s
deﬁnition of approachability requires also that the convergence of the distance to 0 be uniform over the procedures of the opponent; i.e., there is a procedure of i such that for every ␧ ) 0 there is t0 ' t0Ž␧ . such that for any procedure of yi we have PwdistŽ Dt , C . - ␧ for all t ) t0 x ) 1 y ␧. The Blackwell procedure Ždeﬁned in the next Theorem. guarantees this as well.

CORRELATED EQUILIBRIUM

1135

let wC denote the support function of the convex set C, i.e., wC Ž ␭. [ supÄ␭ и c : c g C4 for all ␭ in ‫ ޒ‬L. Given a point x g ‫ ޒ‬L which is not in C, let FŽ x. be the Žunique. point in C that is closest to x in the Euclidean distance, and put ␭Ž x. [ xy FŽ x.; note that ␭Ž x. is an outward normal to the set C at the point FŽ x..

BLACKWELL’S APPROACHABILITY THEOREM: Let C ; ‫ ޒ‬L be a con¨ex and closed set, with support function wC . Then C is approachable by i if and only if for e¨ery ␭ g ‫ ޒ‬L there exists a mixed strategy q␭ g ⌬ŽSi. such that14
Ž3.2. ␭ и¨ Ž q␭, syi . F wC Ž ␭. , for all syi g Syi.
Moreo¨er, the following procedure of i guarantees that distŽ Dt, C . con¨erges almost surely to 0 as t ª ϱ: At time t q 1, play q␭Ž Dt. if Dt f C, and play arbitrarily if Dt g C.

We will refer to the condition for approachability given in the Theorem as the

Blackwell condition, and to the procedure there as the Blackwell procedure. To

get some intuition for the result, assume that Dt is not in C, and let HŽ Dt. be

the half-space of ‫ ޒ‬L that contains C Žand not Dt. and is bounded by the

supporting hyperplane to C at FŽ Dt. with normal ␭Ž Dt.; see Figure 1. When i

uses the Blackwell procedure, it guarantees that ¨ Ž q␭Ž D ., syi . lies in HŽ Dt . for

yi

in

Syi

Žby

Ž3.2...

Therefore,

given

D,

the

t
expectation

of

the

next

period

all s

t

FIGURE 1.ᎏApproaching the set C. 14 ¨ Ž q, syi . denotes the expected payoff, i.e., Ýsig S i qŽ si.¨ Ž si, syi.. Of course, only ␭ / 0 with wC Ž ␭. - ϱ need to be considered in Ž3.2..

1136

SERGIU HART AND ANDREU MAS-COLELL

payoff Ew¨ Ž stq1. ¬ Dt x will lie in the half-space HŽ Dt . for any pure choice sytqi1 of yi at time t q 1, and thus also for any randomized choice of yi. The expected
average vector payoff at period t q 1 Žconditional on Dt. is

t

1

Ew Dtq1 ¬ Dt x s t q 1 Dt q t q 1 Ew ¨ Ž stq1 . ¬ Dt x .

When t is large, Ew Dtq1 ¬ Dt x will thus be inside the circle of center FŽ Dt . and radius 5 ␭Ž Dt .5. Hence

distŽ Ew Dtq1 ¬ Dt x , C . F Ew Dtq1 ¬ Dt x y F Ž Dt . - ␭Ž Dt .

s distŽ Dt , C .

Žthe ﬁrst inequality follows from the fact that FŽ Dt. is in C .. A precise computation shows that the distance not only decreases, but actually goes to zero.15 For proofs of Blackwell’s Approachability Theory, see16 Blackwell Ž1956a., or Mertens, Sorin, and Zamir Ž1995, Theorem 4.3..
We now prove Theorem A.

PROOF OF THEOREM A: As mentioned, the proof of this Theorem consists of an application of Blackwell’s Approachability Theorem. Let

L[ÄŽ j, k. gSi=Si : j/k4,

and deﬁne the vector payoff ¨ Ž si, syi. g ‫ ޒ‬L by letting its Ž j, k. g L coordinate be

w

¨

Ž

s

i

,

syi

.

x

Ž

j

,

k

.

[

½

uiŽ 0,

k

,

syi

.

y

uŽ

j

,

syi

.

,

if si s j, otherwise .

Let C be the nonpositive orthant ‫ޒ‬yL [ Ä x g ‫ ޒ‬L : x F 04. We claim that C is approachable by i. Indeed, the support function of C is given by wC Ž ␭. s 0 for all ␭ g ‫ޒ‬qL and wC Ž ␭. s ϱ otherwise; so only ␭ g ‫ޒ‬qL need to be considered. Condition Ž3.2. is

Ý ␭Ž j, k . Ý q␭Ž si . w ¨ Ž si, syi .x Ž j, k . F 0,

Ž j, k .gL

s igS i

or

Ž3.3.

Ý ␭Ž j, k . q␭Ž j . w ui Ž k , syi . y ui Ž j, syi .x F 0
Ž j, k .gL

15 Note that one looks here at expected average payoffs; the Strong Law of Large Numbers for Dependent Random Variablesᎏsee the Proof of Step M10 in the Appendixᎏimplies that the
actual average payoffs also converge to the set C. 16 The Blackwell condition is usually stated as follows: For every x f C there exists qŽ x. g ⌬ŽSi.
such that w x y FŽ x.x и w¨ Ž qŽ x., syi . y FŽ x.x F 0, for all syi g Syi. It is easy to verify that this is
equivalent to our formulation. We further note a simple way of stating the Blackwell result: A
convex set C is approachable if and only if any half-space containing C is approachable.

CORRELATED EQUILIBRIUM

1137

for all syi g Syi. After collecting terms, the left-hand side of Ž3.3. can be written as

Ž3.4a.

Ý ␣ Ž j . ui Ž j, syi . ,
jgS i

where

Ž3.4b.

␣ Ž j. [ Ý q␭Ž k. ␭Ž k, j. yq␭Ž j. Ý ␭Ž j, k..

kgS i

kgS i

Let q␭ g ⌬ŽSi. be an invariant vector for the nonnegative Si = Si matrix with entries ␭Ž j, k. for j / k and 0 for j s k Žsuch a q␭ always exists.. That is, q␭ satisﬁes

Ž3.5.

Ý q␭Ž k . ␭Ž k, j. sq␭Ž j. Ý ␭Ž j, k . ,

kgS i

kgS i

for every j g Si. Therefore ␣ Ž j. s 0 for all j g Si, and so inequality Ž3.3. holds

true Žas an equality 17 . for all syi g Syi. The Blackwell condition is thus satisﬁed

by the set C s ‫ޒ‬yL. Consider Dt, the average payoff vector at time t. Its Ž j, k.-coordinate is

Ž1rt.Ý␶ F tw¨ Ž s␶ .xŽ j, k. s DtiŽ j, k.. If Dt f ‫ޒ‬yL, then the closest point to Dt in

‫ޒ‬yL is FŽ Dt . s w Dt xy Žsee Figure 2., hence ␭Ž Dt . s Dt y w Dt xys w Dt xqs

Ž

R

i t

Ž

j,

k ..Ž j, k.g L,

which

is

the

vector

of

regrets

at

time

t.

Now

the

given

strategy

FIGURE 2.ᎏApproaching C s ‫ޒ‬yL.
17 Note that this is precisely Formula Ž2. in the Proof of Theorem 1 in Hart and Schmeidler Ž1989.; see Subsection 4Ži..

1138

SERGIU HART AND ANDREU MAS-COLELL

of i at time t q 1 satisﬁes Ž3.1., which is exactly condition Ž3.5. for ␭ s ␭Ž Dt..

Hence player i uses the Blackwell procedure for ‫ޒ‬yL, which guarantees that the

average

vector

payoff

Dt

approaches

‫ޒ‬yL ,

or

R

i t

Ž

j,

k

.

ª

0

a.s.

for

every

j / k.

Q. E. D.

REMARK: The proof of Blackwell’s Approachability Theorem also provides
bounds on the speed of convergence. In our case, one gets the following: The
expectation Ew RitŽ j, k.x of the regrets is of the order of 1r 't , and the probabil-
ity that zt is a correlated ␧-equilibrium for all t ) T is at least 1 y ceycT Žfor an appropriate constant c ) 0 depending on ␧ ; see Foster and Vohra Ž1999, Section 4.1... Clearly, a better speed of convergence18 for the expected regrets
cannot be guaranteed, since, for instance, if the other players play stationary
mixed strategies, then the errors are of the order 1r 't by the Central Limit
Theorem.

4. DISCUSSION
This section discusses a number of important issues, including links and comparisons to the relevant literature.
Ža. Foster and Vohra. The seminal paper in this ﬁeld of research is Foster and Vohra Ž1997.. They consider, ﬁrst, ‘‘forecasting rules’’ᎏon the play of othersᎏthat enjoy good properties, namely, ‘‘calibration.’’ Second, they assume that each player best-replies to such calibrated forecasts. The resulting procedure leads to correlated equilibria. The motivation and the formulation are quite different from ours; nonetheless, their results are close to our results Žspeciﬁcally, to our Theorem A., since their calibrated forecasts are also based on regret measures.19
Žb. Fudenberg and Le¨ine. The next important paper is Fudenberg and Levine Ž1999. Žsee also their book Ž1998... In that paper they offer a class of adaptive procedures, called ‘‘calibrated smooth ﬁctitious play,’’ with the property that for every ␧ ) 0 there are procedures in the class that guarantee almost sure convergence to the set of correlated ␧-equilibria Žbut the conclusion does not hold for ␧ s 0.. The formal structure of these procedures is also similar to that of our Theorem A, in the sense that the mixed choice of a given player at time t is determined as an invariant probability vector of a transition matrix. However, the transition matrix Žand therefore the stochastic dynamics. is different from the regret-based transition matrix of our Theorem A. To understand further the similarities and differences between the Fudenberg and Levine procedures and our own, the next two Subsections, Žc. and Žd., contain a detour on the concepts of ‘‘universal consistency’’ and ‘‘universal calibration.’’
18 Up to a constant factor. 19 These regrets are deﬁned on an ␧-grid on ⌬ŽSyi ., with ␧ going to zero as t goes to inﬁnity. Therefore, at each step in their procedure one needs to compute the invariant vector for a matrix of an increasingly large size; by comparison, in our Theorem A the size of the matrix is ﬁxed, mi = mi.

CORRELATED EQUILIBRIUM

1139

Žc. Uni¨ersal Consistency. The term ‘‘universal consistency’’ is due to Fudenberg and Levine Ž1995.. The concept goes back to Hannan Ž1957., who proved the following result: There is a procedure Žin the setup of Section 2. for player i
that guarantees, no matter what the other players do, that

Ž4.1.

Ý Ý 1 t

1t

limsup max

ui Ž k , s␶yi . y

ui Ž s␶ . F 0 a.s.

tªϱ kgS i t ␶s1

t ␶s1

In other words, i’s average payoff is, in the limit, no worse than if he were to play any constant strategy k g Si for all ␶ F t. This property of the Hannan
procedure for player i is called uni¨ersal consistency by Fudenberg and Levine Ž1995. Žit is ‘‘universal’’ since it holds no matter how the other players play.. Another universally consistent procedure was shown by Blackwell Ž1956b. to result from his Approachability Theorem Žsee also Luce and Raiffa Ž1957, pp. 482᎐483...
The adaptive procedure of our Theorem A is also universally consistent. Indeed, for each j in Si, Ž4.1. is guaranteed even when restricted to those periods when player i chose that particular j; this being true for all j in Si, the
result follows. However, the application of Blackwell’s Approachability Theorem
in Section 3 suggests the following particularly simple procedure. At time t, for each strategy k in Si, let

Ž4.2a. Ž4.2b.

Ý 1 t

D

i t

Ž

k

.

[

ui Ž k , s␶yi . y ui Ž s␶ . ,

t ␶s1

Ý ptiq1Ž k . [

Dti Ž k . q , Dti Ž kX . q

kXgS i

if the denominator is positive, and let ptiq1 g ⌬ŽSi. be arbitrary otherwise. The strategy of player i is then, at time t q 1, to choose k in Si with probability

ptiq1Ž k.. These probabilities are thus proportional to the ‘‘unconditional regrets’’

w

D

i t

Ž

k

.xq

Žby comparison to the

‘‘conditional on

j’’ regrets

of Section 2.. We

then have the following theorem.

THEOREM B: The adapti¨e procedure Ž4.2. is uni¨ersally consistent for player i.

The proof of Theorem B is similar to the proof of Theorem A in Section 3 and is omitted.
Fudenberg and Levine Ž1995. propose a class of procedures that turn out to be universally ␧-consistent:20 ‘‘smooth ﬁctitious play.’’ Player i follows a smooth ﬁctitious play behavior rule if at time t he plays a mixed strategy ␴ i g ⌬ŽSi. that maximizes the sum of his expected payoff Žwith the actions of the remaining
20 That is, the right-hand side of Ž4.1. is ␧ ) 0 instead of 0.

1140

SERGIU HART AND ANDREU MAS-COLELL

players distributed as in the empirical distribution up to t. and ␭¨ iŽ␴ i., where ␭ ) 0 and ¨ i is a strictly concave smooth function deﬁned on i’s strategy simplex, ⌬ŽSi., with inﬁnite length gradient at the boundary of ⌬ŽSi.. The result of Fudenberg and Levine is then that, given any ␧ ) 0, there is a sufﬁciently small ␭ such that universal ␧-consistency obtains for player i. Observe that, for small ␭, smooth ﬁctitious play is very close to ﬁctitious play Žit amounts to
playing the best response with high probability and the remaining strategies with low but positive probability.. The procedure is, therefore, clearly distinct from Ž4.2.: In Ž4.2. all the better, even if not best, replies are played with signiﬁcant probability; also, in Ž4.2. the inferior replies get zero probability. Finally, it is
worth emphasizing that the tremble from best response is required for the
Fudenberg and Levine result, since ﬁctitious play is not guaranteed to be consistent. In contrast, the procedure of Ž4.2. has no trembles.
The reader is referred to Hart and Mas-Colell Ž1999., where a wide class of universally consistent procedures is exhibited and characterized Žincluding as special cases Ž4.2. as well as smooth ﬁctitious play..
Žd. Uni¨ersal Calibration. The idea of ‘‘universal calibration,’’ also introduced21 by Fudenberg and Levine Ž1998, 1999., is that, again, regret measures go to zero
irrespective of the other players’ play. The difference is that, now, the set of
regret measures is richer: It consists of regrets that are conditional on the
strategy currently played by i himself. Recall the Proposition of Section 3: If
such universally calibrated strategies are played by all players, then all regrets
become nonpositive in the limit, and thus the convergence to the correlated
equilibrium set is guaranteed. The procedure of Theorem A is universally calibrated; so Žup to ␧ . is the
‘‘calibrated smooth ﬁctitious play’’ of Fudenberg and Levine Ž1999.. The two
procedures stand to each other as, in the unconditional version, Theorem B
stands to ‘‘smooth ﬁctitious play.’’ The procedure Ž2.2. of our Main Theorem is not universally calibrated. If only
player i follows the procedure, we cannot conclude that all his regrets go to
zero; adversaries who know the procedure used by player i could keep his regrets positive.22 Such sophisticated strategies of the other players, however, are outside the framework of our studyᎏwhich deals with simple adaptive
behavior. In fact, it turns out that the procedure of our Main Theorem is
guaranteed to be calibrated not just against opponents using the same procedure, but also against a wide class of behaviors.23
We regard the simplicity of Ž2.2. as a salient point. Of course, if one needs to
guarantee calibration even against sophisticated adversaries, one may have to
give up on simplicity and resort to the procedure of Theorem A instead.

21 They actually call it ‘‘calibration’’; we prefer the term ‘‘universal calibration,’’ since it refers to
any behavior of the opponents Žas in their ‘‘wconditionalx universal consistency’’.. 22 At each time t q 1, let them play an Ž N y 1.-tuple of strategies that minimizes the expected
Žrelative to ptiq1. payoff of player i; for an example, see Fudenberg and Levine Ž1998, Section 8.10.. 23 Namely, such that the dependence of any one choice of yi on any one past choice of i is small,
relative to the number of periods; see Cahn Ž2000..

CORRELATED EQUILIBRIUM

1141

Že. Better-reply ¨s. Best-reply. Note that all the procedures in the literature reviewed above are best-reply-based: A player uses Žalmost. exclusively actions that are Žalmost. best-replies to a certain belief about his opponents. In contrast,
our procedure gives signiﬁcant probabilities to any actions that are just better Žrather than best.. This has the additional effect of making the behavior
continuous, without need for approximations. Žf. Eigen¨ector Procedures. The procedure of our Main Theorem differs from
all the other procedures leading to correlated equilibria Žincluding that of our Theorem A. in an important aspect: It does not require the player to compute, at every step, an invariant Žeigen-. vector for an appropriate positive matrix. Again, the simplicity 24 of Ž2.2. is an essential property when discussing nonso-
phisticated behavior; this is the reason we have sought this result as our Main
Theorem. Žg. Inertia. A speciﬁc and most distinctive feature by which the procedure of
our Main Theorem differs from those of Theorem A and the other works
mentioned above is that in the former the individual decisions privilege the most recent action taken: The probabilities used at period t q 1 are best thought of as
propensities to depart from the play at t.
Viewed in this light, our procedure has signiﬁcant inertial characteristics. In
particular, there is a positive probability of moving from the strategy played at t only if there is another that appears better Žin which case the probabilities of
playing the better strategies are proportional to the regrets relative to the period t strategy..25
Žh. Friction. The procedure Ž2.2. exhibits ‘‘friction’’: There is always a positive probability of continuing with the period t strategy.26 To understand the role played by friction,27 suppose that we were to modify the procedure Ž2.2. by
requiring that the switching probabilities be rescaled in such a way that a switch occurs if and only if there is at least one better strategy Ži.e., one with positive regret.. Then the result of the Main Theorem may not hold. For example, in the familiar two-person 2 = 2 coordination game, if we start with an uncoordinated
strategy pair, then the play alternates between the two uncoordinated pairs.
However, no distribution concentrated on these two pairs is a correlated
equilibrium.
It is worth emphasizing that in our result the breaking away from a bad cycle,
like the one just described, is obtained not by ergodic arguments but by the probability of staying put Ži.e., by friction.. What matters is that the diagonal of

24 For a good test of the simplicity of a procedure, try to explain it verbally; in particular, consider
the procedure of our Main Theorem vs. those requiring the computation of eigenvectors. 25 It is worth pointing out that if a player’s last choice was j, then the relative probabilities of
switching to k or to kX do not depend only on the average utilities that would have been obtained if j had been changed to k or to kX in the past, but also on the average utility that was obtained in those periods by playing j itself Žit is the magnitude of the increases in moving from j to k or to kX that matters..
26 See Sanchirico Ž1996. and Section 4.6 in Fudenberg and Levine Ž1998. for a related point in a
best-reply context. 27 See Step M7 in the Proof of the Main Theorem in the Appendix.

1142

SERGIU HART AND ANDREU MAS-COLELL

the transition matrix be positive, rather than that all the entries be positive Žwhich, indeed, will not hold in our case..
Ži. The set of correlated equilibria. The set of correlated equilibria of a game is,
in contrast to the set of Nash equilibria, geometrically simple: It is a convex set Žactually, a convex polytope. of distributions. Since it includes the Nash equilibria we know it is nonempty. Hart and Schmeidler Ž1989. Žsee also Nau and McCardle Ž1990.. provide an elementary Žnonﬁxed point. proof of the nonempti-
ness of the set of correlated equilibria. This is done by using the Minimax
Theorem. Speciﬁcally, Hart and Schmeidler proceed by associating to the given
N-person game an auxiliary two-person zero-sum game. As it turns out, the
correlated equilibria of the original game correspond to the maximin strategies of player I in the auxiliary game. More precisely, in the Hart᎐Schmeidler
auxiliary game, player I chooses a distribution over N-tuples of actions, and
player II chooses a pair of strategies for one of the N original players Žinterpreted as a play and a suggested deviation from it.. The payoff to auxiliary
player II is the expected gain of the designated original player if he were to
follow the change suggested by auxiliary player II. In other words, it is the
‘‘regret’’ of that original player for not deviating. The starting point for our research was the observation that ﬁctitious play applied to the Hart᎐Schmeidler auxiliary game must converge, by the result of Robinson Ž1951., and thus yield optimal strategies in the auxiliary game, in particular for player Iᎏhence,
correlated equilibria in the original game. A direct application of this idea does
not, however, produce anything that is simple and separable across the N players Ži.e., such that the choice of each player at time t is made independently of the other players’ choices at tᎏan indispensable requirement..28 Yet,
our adaptive procedure is based on ‘‘no-regret’’ ideas motivated by this analysis and it is the direct descendantᎏseveral modiﬁcations laterᎏof this line of research.29
Žj. The case of the unknown game. The adaptive procedure of Section 2 can be modiﬁed30 to yield convergence to correlated equilibria also in the case where players neither know the game, nor observe the choices of the other players.31 Speciﬁcally, in choosing play probabilities at time t q 1, a player uses information only on his own actual past play and payoffs Žand not on the payoffs that would have been obtained if his past play had been different.. The construction

28 This needed ‘‘decoupling’’ across the N original players explains why applying linear program-
ming-type methods to reach the convex polytope of correlated equilibria is not a fruitful approach. The resulting procedures operate in the space of N-tuples of strategies S Žmore precisely, in ⌬ŽS.., whereas adaptive procedures should be deﬁned for each player i separately Ži.e., on ⌬ŽSi...
29 For another interesting use of the auxiliary two-person zero-sum game, see Myerson Ž1997.. 30 Following a suggestion of Dean Foster.
31 For similar constructions, see: Ba˜nos Ž1968., Megiddo Ž1980., Foster and Vohra Ž1993., Auer
et al. Ž1995., Roth and Erev Ž1995., Erev and Roth Ž1998., Camerer and Ho Ž1998., Marimon Ž1996, Section 3.4., and Fudenberg and Levine Ž1998, Section 4.8.. One may view this type of result in
terms of ‘‘stimulus-response’’ decision behavior models.

CORRELATED EQUILIBRIUM

1143

is based on replacing DtiŽ j, k. Žsee Ž2.1b.. by

1 Cti Ž j, k . [ t

Ý Ý p␶i Ž j.

pi Ž k . ui Ž s␶ . y

ui Ž s␶ . .

␶Ft : s␶isk ␶

␶Ft : s␶isj

Thus, the payoff that player i would have received had he played k rather than j is estimated by the actual payoffs he obtained when he did play k in the past.
For precise formulations, results and proofs, as well as further discussions, the reader is referred to Hart and Mas-Colell Ž2000..

Center for Rationality and Interacti¨e Decision Theory, Dept. of Economics, and Dept. of Mathematics, The Hebrew Uni¨ersity of Jerusalem, Feldman Bldg., Gi¨atRam, 91904 Jerusalem, Israel; hart@math.huji.ac.il; http:rrwww.ma.huji.ac.ilr ; hart
and Dept. de Economia i Empresa, and CREI, Uni¨ersitat Pompeu Fabra, Ramon Trias Fargas 25᎐27, 08005 Barcelona, Spain; mcolell@upf.es; http:rrwww.econ. upf.esrcreirmcolell.htm

Manuscript recei¨ed No¨ember, 1997; ﬁnal re¨ision recei¨ed July, 1999.

APPENDIX : PROOF OF THE MAIN THEOREM
This appendix is devoted to the proof of the Main Theorem, stated in Section 2. The proof is inspired by the result of Section 3 ŽTheorem A.. It is however more complex on account of our transition probabilities not being the invariant measures that, as we saw in Section 3, ﬁtted so well with Blackwell’s Approachability Theorem.
As in the standard proof of Blackwell’s Approachability Theorem, the proof of our Main Theorem is based on a recursive formula for the distance of the vector of regrets to the negative orthant. However, our procedure Ž2.2. does not satisfy the Blackwell condition; it is rather a sort of iterative approximation to it. Thus, a simple one-period recursion Žfrom t to t q 1. does not sufﬁce, and we have to consider instead a multi-period recursion where a large ‘‘block’’ of periods, from t to t q¨, is combined together. Both t and ¨ are carefully chosen; in particular, t and ¨ go to inﬁnity, but ¨ is relatively small compared to t.
We start by introducing some notation. Fix player i in N. For simplicity, we drop reference to the index i whenever this cannot cause confusion Žthus we write Dt and Rt instead of Dti and Rti , and so on.. Let m [ < Si < be the number of strategies of player i, and let M be an upper bound on i’s possible payoffs: MG < uiŽ s.< for all s in S. Denote L [ ÄŽ j, k. g Si = Si : j / k4; then ‫ ޒ‬L is the mŽ m y 1.-dimensional Euclidean space with coordinates indexed by L. For each t s 1, 2, . . . and each Ž j, k. in L, put32
At Ž j, k . s 1Äsisj4w ui Ž k , syt i . y ui Ž st .x , t
Ý 1
Dt Ž j, k . s t ␶s1 A␶ Ž j, k . , Rt Ž j, k . s Dqt Ž j, k . ' w Dt Ž j, k .xq.
We shall write At for the vector Ž AtŽ j, k..j/ k g ‫ ޒ‬L; the same goes for Dt , Dqt , Rt , and so on. Let
32 We write 1G for the indicator of the event G.

1144

SERGIU HART AND ANDREU MAS-COLELL

⌸tŽи, и . denote the transition probabilities from t to t q 1 Žthese are computed after period t, based on ht .:

~¡¢ Ý ⌸tŽ j, k. [

1 ␮ RtŽ j, k., 1y 1 R Ž j, kX .,
kX/j ␮ t

if k / j, if k s j.

Thus, at time t q 1 the strategy used by player i is to choose each k g Si with probability
ptiq1Ž k. s ⌸tŽ sti, k.. Note that the choice of ␮ guarantees that ⌸tŽ j, j. ) 0 for all j g S i and all t. Finally, let

␳t [ wdistŽ Dt , ‫ޒ‬yL .x2

be the squared distance Žin ‫ ޒ‬L. of the vector Dt to the nonpositive orthant ‫ޒ‬yL. Since the closest point to Dt in ‫ޒ‬yL is33 Dyt , we have ␳t s 5 Dt y Dyt 5 2 s 5 Dqt 5 2 s Ý j/ kw Dqt Ž j, k.x2.
It will be convenient to use the standard ‘‘O’’ notation: For two real-valued functions f Žи. and gŽи. deﬁned on a domain X, ‘‘ f Ž x. s OŽ gŽ x..’’ means that there exists a constant K- ϱ such that < f Ž x.< F KgŽ x. for all x in34 X. We write P for Probability, and E for Expectation. From now on, t, ¨, and w will denote positive integers; ht s Ž s␶ .␶ F t will be histories of length t; j, k, and si will be elements of Si; s and syi will be elements of S and Syi, respectively. Unless stated otherwise, all
statements should be understood to hold ‘‘for all t, ¨, ht , j, k, etc.’’; where histories ht are concerned, only those that occur with positive probability are considered.
We divide the proof of the Main Theorem into 11 steps, M1᎐M11, which we now state formally;
an intuitive guide follows.
ⅷ Step M1:

¨

Ý Ži.

EwŽ t q¨ .2 ␳tq¨ ¬ ht x F t 2␳t q 2 t Rt и Ew Atqw ¬ ht x q OŽ¨ 2 . ; and

ws 1

Žii.

Ž t q¨ .2 ␳tq¨ y t 2␳t s OŽ t¨ q¨ 2 . .

Deﬁne

␣t, w Ž j, syi . [ Ý ⌸t Ž k , j . P w stqw s Ž k , syi . ¬ ht x y P w stqw s Ž j, syi . ¬ ht x .
kgS i

ⅷ Step M 2:

Ý Ý Rt и Ew Atqw ¬ ht x s ␮

␣t , w Ž j, syi . ui Ž j, syi . .

syi gSyi jgS i

ⅷ Step M 3:

Rtq¨ Ž

j,

k. yRtŽ

j,

ž k. sO

¨ t

/

.

For each t ) 0 and each history ht , deﬁne an auxiliary stochastic process ˆŽ stqw .ws0, 1, 2, . . . with values in S as follows: The initial value is ˆst s st , and the transition probabilities are35

Ł P w ˆstqw s s ¬ˆst , . . . , ˆstqwy1 x [

⌸tiXŽ ˆstiqX wy1 , s iX . .

iXg N

33 We write w x xy for minÄ x, 04, and Dyt for the vector Žw DtŽ j, k.xy.Ž j, k.g L. 34 The domain X will usually be the set of positive integers, or the set of vectors whose coordinates are positive integers. Thus when we write, say, f Žt, ¨ . s OŽ¨ ., it means < f Žt, ¨ .< F K¨ for all ¨ and t. The constants K will always depend only on the game Žthrough N, m, M, and so on. and
on the parameter ␮. 35 We write ⌸tiX for the transition probability matrix of player iX Žthus ⌸t is ⌸ti..

CORRELATED EQUILIBRIUM

1145

ŽThe ˆs-process is thus stationary: It uses the transition probabilities of period t at each period t q w,
for all w G 0..
ⅷ Step M4:

Deﬁne

Pw

stqw s s ¬ ht

x

y P w ˆstqw s s ¬ ht x

sO

ž

w2 t

/

.

␣ˆt, w Ž j, syi . [ Ý ⌸t Ž k , j . P w ˆstqw s Ž k , syi . ¬ ht x y P w ˆstqw s Ž j, syi . ¬ ht x .
kgS i

ⅷ Step M5:

␣t, w Ž

j,

syi . y ␣ˆt , w Ž

j,

syi . s O

ž

w2 t

/

.

ⅷ Step M6:

␣ˆt , w Ž j, syi . s P w ˆsytqi w s syi ¬ ht x w ⌸t wq 1 y ⌸t w x Ž sti , j . ,

where

⌸tw 'Ž⌸t.w

is

the

w th

power of the

matrix

⌸t,

and

w

⌸

t

w

q

1

y

⌸

t

w

xŽ

s

i t

,

j.

denotes

the

Ž sti, j.

element of the matrix ⌸twq 1 y ⌸tw.

ⅷ Step M 7:

␣ˆt , w Ž j, sy1 . s OŽ wy1 r2 . .

ⅷ Step M 8:

EwŽ t q¨ .2 ␳tq¨ ¬ ht x F t 2␳t q OŽ ¨ 3 q t¨ 1r2 . .
For each n s 1, 2, . . . , let tn [ ? n5r3@ be the largest integer not exceeding n5r3. ⅷ Step M 9:

Ew tn2q 1 ␳tnq1 ¬ htn x F tn2 ␳tn q OŽ n2 . .

ⅷ Step M10:

lim ␳t s 0 a.s.
nªϱ n

ⅷ Step M11:

lim Rt Ž j, k . s 0 a.s.
tª ϱ
We now provide an intuitive guide to the proof. The ﬁrst step ŽM1Ži.. is our basic recursion equation. In Blackwell’s Theorem, the middle term on the right-hand side vanishes Žit is F 0 by Ž3.2... This is not so in our case; Steps M2᎐M8 are thus devoted to estimating this term. Step M2 yields an expression similar to Ž3.4., but here the coefﬁcients ␣ depend also on the moves of the other players. Indeed, given ht , the choices stiqw and sytqiw are not independent when w ) 1 Žsince the transition probabilities change with time.. Therefore we replace the process Ž stqw .0 F w F ¨ by
another process Žˆstqw .0 F w F ¨ , with a stationary transition matrix Žthat of period t.. For w small
relative to t, the change in probabilities is small Žsee Steps M3 and M4., and we estimate the total difference ŽStep M5.. Next ŽStep M6., we factor out the moves of the other players Žwhich, in the
ˆs-process, are independent of the moves of player i. from the coefﬁcients ␣ˆ. At this point we get the

1146

SERGIU HART AND ANDREU MAS-COLELL

difference between the transition probabilities after w periods and after w q 1 periods Žfor comparison, in formula Ž3.4. we would replace both by the invariant distribution, so the difference vanishes.. This difference is shown ŽStep M7. to be small, since w is large and the transition matrix has all its diagonal elements strictly positive.36 Substituting in M1Ži. yields the ﬁnal recursive formula ŽStep M8.. The proof is now completed ŽSteps M9᎐M11. by considering a carefully chosen subsequence of periods Žtn.ns1, 2, . . . .
The rest of this Appendix contains the proofs of the Steps M1᎐M11.

ⅷ PROOF OF STEP M1: Because Dyt g ‫ޒ‬yL we have

Ý t

1¨

2

␳tq¨ F 5 Dtq¨ y Dyt 5 2 s

Dt q

A

t

q

w

y

D

y t

tq¨

t q¨ ws1

Ý t 2

2t ¨

s

2 5 Dt y Dyt 5 2 q

2

Ž Atqw y Dyt . и Ž Dt y Dyt .

Žtq¨ .

Ž t q¨ . ws1

¨2 q Žtq¨ .2

Ý 1 ¨

2

A

tq

w

y

D

y t

¨ ws1

Ý t 2

2t ¨

¨2

F

2 ␳t q

2

Atqw и Rt q

2 mŽ m y 1.16 M 2 .

Žtq¨ .

Ž t q¨ . ws1

Žtq¨ .

Indeed: < uiŽ s.< F M, so < AtqwŽ j, k.< F 2 M and < DtŽ j, k.< F 2 M, yielding the upper bound on the third

term. As for

the

second

term, note

that

R

t

s

D

q t

s

D

t

y

D

y t

and

Dyt и Dqt s 0. This

gives the

bound

of Žii.. To get Ži., take conditional expectation given the history ht Žso ␳t and Rt are known.. Q. E. D.

ⅷ PROOF OF STEP M2: We have

Ý Ew Atqw Ž j, k . ¬ ht x s ␾ Ž j, syi . w ui Ž k , syi . y ui Ž j, syi .x , syi

where ␾Ž j, syi . [ Pw stqw s Ž j, syi . ¬ ht x. So

Ý Ý Ý Rt и Ew Atqw ¬ ht x s

Rt Ž j, k . ␾ Ž j, syi . w ui Ž k , syi . y ui Ž j, syi .x

j k/j

syi

Ý Ý Ý Ý s

ui Ž j, syi .

Rt Ž k , j .␾ Ž k , syi . y Rt Ž j, k . ␾ Ž j, syi .

syi j

k/ j

k/j

Žwe have collected together all terms containing uiŽ j, syi ... Now, RtŽ k, j. s ␮⌸tŽ k, j. for k / j, and Ýk / j RtŽ j, k. s ␮Ž1 y ⌸tŽ j, j.. by deﬁnition, so

Ý Ý Rt и Ew Atqw ¬ ht x s ␮ syi

ui Ž j, syi .
j

Žnote that the last sum is now over all k in Si..

Ý ⌸t Ž k , j .␾ Ž k , syi . y ␾ Ž j, syi .
k

Q. E. D.

ⅷ PROOF OF STEP M3: This follows immediately from
¨
Ý Ž t q¨ . w Dtq¨ Ž j, k . y Dt Ž j, k .x s Atqw Ž j, k . y¨Dt Ž j, k . , ws 1
together with < AtqwŽ j, k.< F 2 M and < DtŽ j, k.< F 2 M.
36 For further discussion on this point, see the Proof of Step M7.

Q. E. D.

CORRELATED EQUILIBRIUM

1147

ⅷ PROOF OF STEP M4: We need the following Lemma, which gives bounds for the changes in the w-step transition probabilities as a function of changes in the 1-step transitions.

LEMMA: Let Ž Xn.nG 0 and ŽYn.nG 0 be two stochastic processes with ¨alues in a ﬁnite set B. Assume X0 s Y0 and
P w Xn s bn ¬ X0 s b0 , . . . , Xny1 s bny1 x y P w Yn s bn ¬ Y0 s b0 , . . . , Yny1 s bny1 x F ␤n
for all n G 1 and all b0 , . . . , bny1, bn g B. Then
P w Xnq w s bnqw ¬ X0 s b0 , . . . , Xny1 s bny1 x
w
Ý yP w Ynqw s bnqw ¬ Y0 s b0 , . . . , Yny1 s bny1 x F < B < ␤nqr rs 0
for all n G 1, w G 0, and all b0 , . . . , bny1, bnqw g B.

PROOF: We write PX and PY for the probabilities of the two processes Ž Xn.n and ŽYn.n, respectively Žthus PX w bnqw ¬ b0 , . . . , bny1 x stands for Pw Xnqw s bnqw ¬ X0 s b0 , . . . , Xny1 s bny1 x, and so on.. The proof is by induction on w.

PX w bnqw ¬ b0 , . . . , bny1 x

s Ý PX w bnqw ¬ b0 , . . . , bn x PX w bn ¬ b0 , . . . , bny1 x
bn

w

Ý Ý F PY w bnqw ¬ b0 , . . . , bn x PX w bn ¬ b0 , . . . , bny1 x q < B < ␤nqr

bn

rs 1

w

Ý Ý F PY w bnqw ¬ b0 , . . . , bn x Ž PY w bn ¬ b0 , . . . , bny1 x q ␤n . q < B < ␤nqr

bn

rs 1

w
Ý F PY w bnqw ¬ b0 , . . . , bny1 x q < B < ␤n q < B < ␤nqr rs 1

Žthe ﬁrst inequality is by the induction hypothesis.. Exchanging the roles of X and Y completes

the proof.

Q. E. D.

We proceed now with the proof of Step M4. From t to t q w there are < N < w transitions Žat each

period, think of the players moving one after the other, in some arbitrary order.. Step M3 im-

plies that each transition probability for the ˆs-process differs from the corresponding one for
the s-process by at most OŽwrt., which yields, by the Lemma, a total difference of < N < w < S < OŽwrt.

s OŽw2rt..

Q. E. D.

ⅷ PROOF OF STEP M5: Immediate by Step M4.

Q. E. D.

ⅷ PROOF OF STEP M6: Given ht , the random variables ŽˆstiqX w .w are independent over the
different players iX in N; indeed, the transition probabilities are all determined at time t, and the players randomize independently. Hence:
P w ˆstqw s Ž j, syi . ¬ ht x s P w ˆsytqi w s syi ¬ ht x P w ˆstiqw s j ¬ ht x ,
implying that

␣ˆt, w Ž j, syi . s P w ˆsytqiw s syi ¬ ht x Ý ⌸t Ž k , j . P w ˆstiqw s k ¬ ht x y P w ˆstiqw s j ¬ ht x .
kgS i

1148

SERGIU HART AND ANDREU MAS-COLELL

Now Pwˆstiqw s j ¬ ht x is the probability of reaching j in w steps starting from sti, using the transition

probability matrix ⌸t. Therefore Pwˆstiqw s j ¬ ht x is the Ž sti, j.-element of the wth power ⌸tw ' Ž ⌸t .w

of

⌸t,

i.e.,

w

⌸

t

w

xŽ

s

i t

,

j..

Hence

␣ˆt, w Ž j, syi . s P w ˆsytqiw s syi ¬ ht x Ý ⌸t Ž k , j . w ⌸tw x Ž sti , k . y w ⌸tw x Ž sti , j .
kgS i
completing the proof. s P w ˆsytqi w s syi ¬ ht x ww ⌸twq 1 x Ž sti , j . y w ⌸tw x Ž sti , j .x ,

Q. E. D.

ⅷ PROOF OF STEP M7: It follows from M6 using the following Lemma Žrecall that ⌸tŽ j, j. ) 0 for all j g S i..

LEMMA: Let ⌸ be an m = m stochastic matrix with all of its diagonal entries positi¨e. Then w ⌸ wq 1 y ⌸ w xŽ j, k. s OŽwy1r2 . for all j, k s 1, . . . , m.

PROOF:37 Let ␤ ) 0 be a lower bound on all the diagonal entries of ⌸ , i.e., ␤ [ min j ⌸ Ž j, j.. We can then write ⌸ s ␤ I q Ž1 y ␤ . ⌳, where ⌳ is also a stochastic matrix. Now

Ý ž / w

⌸ ws

w r

␤ wyrŽ1y␤ . r ⌳r,

rs 0

and similarly for ⌸ wq 1. Subtracting yields

Ý ž / wq1

⌸ wq 1 y ⌸ w s

␥r

w r

␤ wyrŽ1y␤ . r ⌳r,

rs 0

where ␥r [ ␤ Žw q 1.rŽw q 1 y r . y 1. Now ␥r ) 0 if r ) q [ Žw q 1.Ž1 y ␤ ., and ␥r F 0 if r F q; together with 0 F ⌳rŽ j, k. F 1, we get

Ý ž / Ý ž / ␥r

w r

␤ wy r Ž1 y ␤ . r F w ⌸ wq1 y ⌸ w x Ž j, k . F

␥r

w r

␤ wyrŽ1y␤ . r .

rF q

r)q

Consider the left-most sum. It equals

Ý ž / Ý ž / wq1 ␤ wq1yrŽ1y␤ . r y r

w r

␤ wyr Ž1 y ␤ . r s Gwq 1Ž q . y Gw Ž q . ,

rF q

rFq

where GnŽи. denotes the cumulative distribution function of a sum of n independent Bernoulli random variables, each one having the value 0 with probability ␤ and the value 1 with probability 1 y ␤. Using the normal approximation yields Ž⌽ denotes the standard normal cumulative distribution function.:

Gwq 1Ž q .

y Gw Ž q.

s⌽

Ž

x.

y⌽

Ž

y.

qO

ž

1
'Ž wq1.

/

q

O

ž

1
'w

/,

where

' ' qy Ž wq1.Ž1y␤ .

qywŽ1y␤ .

x[

and y [

;

Žwq1. ␤ Ž1y␤ .

w␤ Ž1 y ␤ .

37 If ⌸ were a strictly positive matrix, then ⌸ wq 1 y ⌸ w ª 0 would be a standard result, because then ⌸ w would converge to the invariant matrix. However, we know only that the diagonal
elements are positive. This implies that, if w is large, then with high probability there will be a
positive fraction of periods when the process does not move. But this number is random, so the probabilities of going from j to k in w steps or in w q 1 steps should be almost the same Žsince it is like having r ‘‘stay put’’ transitions versus r q 1..

CORRELATED EQUILIBRIUM

1149

the two error terms OŽŽw q 1.y1r2 . and OŽwy1r2 . are given by the Berry-Ess´een Theorem Žsee
Feller Ž1965, Theorem XVI.5.1... By deﬁnition of q we have x s 0 and y s OŽwy1r2 .. The

derivative of ⌽ is bounded, so ⌽ Ž x. y ⌽ Ž y. s OŽ x y y. s OŽwy1r2 .. Altogether, the left-most sum

is OŽwy1r2 .. A similar computation applies to the right-most sum.

Q. E. D.

ⅷ PROOF OF STEP M8: Steps M5 and M7 imply ␣t, wŽ j, syi . s OŽw 2rt q wy1r2 .. The formula of Step M2 then yields

RtиEw

Atqw

¬ht

x

sO

ž

w2 t

q wy1r2

/

.

Adding over w s 1, 2, . . . , ¨ Žnote that Ý¨ws 1w ␭ s OŽ¨ ␭q1. for ␭ / y1. and substituting into Step

M1Ži. gives the result.

Q. E. D.

ⅷ PROOF OF STEP M9: We use the inequality of Step M8 for t s tn and ¨ s tnq1 y tn. Because ¨ s ?Ž n q 1.5r3 @ y ? n5r3 @ s OŽ n2r3., we have ¨ 3 s OŽ n2 . and t¨ 1r2 s OŽ n5r3q1r3. s OŽ n2 ., and the

result follows.

Q. E. D.

ⅷ PROOF OF STEP M10: We use the following result Žsee Lo`eve Ž1978, Theorem 32.1.E..:

THEOREM ŽStrong Law of Large Numbers for Dependent Random Variables.: Let Xn be a sequence of random ¨ariables and bn a sequence of real numbers increasing to ϱ, such that the series Ýϱns1 varŽ Xn.rbn2 con¨erges. Then
Ý 1 n
bn ␯s1 w X␯ y Ew X␯ ¬ X1 , . . . , X␯y1 xx nªϱ 0 a. s.

6

We take bn [ tn2, and Xn [ bn ␳tn y bny1 ␳tny1 s tn2 ␳tn y tn2y1 ␳tny1. By Step M1Žii. we have

<

Xn

<

F

OŽ

tn¨

n

q

¨

2 n

.

s

OŽ

n7r

3

.,

thus

Ýn varŽ xn.rbn2 s ÝnOŽ n14r3.rn20r3 s ÝnOŽ1rn2 . - ϱ.

Next,

Step M9 implies

Ý ž Ý / Ž1rbn . Ew X␯ ¬ X1 , . . . , X␯y1 x F O ny10r3 ␯ 2 s OŽ ny10r3n3 . s OŽ ny1r3 . ª 0.

␯F n

␯Fn

Applying the Theorem above thus yields that ␳tn, which is nonnegative and equals Ž1rbn.Ý␯ F n X␯ ,

must converge to 0 a.s.

Q. E. D.

ⅷ PROOF OF STEP M11: Since ␳t s Ýj/ kw Rt Ž j, k.x2, the previous Step M10 implies that

n

n

Rt Ž j, k. ª 0 a.s. n ª ϱ, for all j / k. When tn F t F tnq1, we have RtŽ j, k. y Rt Ž j, k. s OŽ ny1 . by

n

n

the inequality of Step M3, so RtŽ j, k. ª 0 a.s. t ª ϱ.

Q. E. D.

REFERENCES
AUER, P., N. CESA-BIANCHI, Y. FREUND, AND R. E. SCHAPIRE Ž1995.: ‘‘Gambling in a Rigged Casino: The Adversarial Multi-Armed Bandit Problem,’’ in Proceedings of the 36 th Annual Symposium on Foundations of Computer Science, 322᎐331.
AUMANN, R. J. Ž1974.: ‘‘Subjectivity and Correlation in Randomized Strategies,’’ Journal of Mathematical Economics, 1, 67᎐96.
ᎏᎏᎏ Ž1987.: ‘‘Correlated Equilibrium as an Expression of Bayesian Rationality,’’ Econometrica, 55, 1᎐18.
BA˜NOS, A. Ž1968.: ‘‘On Pseudo-Games,’’ The Annals of Mathematical Statistics, 39, 1932᎐1945.
BLACKWELL, D. Ž1956a.: ‘‘An Analog of the Minmax Theorem for Vector Payoffs,’’ Paciﬁc Journal of Mathematics, 6, 1᎐8.

1150

SERGIU HART AND ANDREU MAS-COLELL

ᎏᎏᎏ Ž1956b.: ‘‘Controlled Random Walks,’’ in Proceedings of the International Congress of Mathematicians 1954, Vol. III, ed. by E. P. Noordhoff. Amsterdam: North-Holland, pp. 335᎐338.
BROWN, G. W. Ž1951.: ‘‘Iterative Solutions of Games by Fictitious Play,’’ in Acti¨ity Analysis of
Production and Allocation, Cowles Commission Monograph 13, ed. by T. C. Koopmans. New York:
Wiley, pp. 374᎐376. CAHN, A. Ž2000.: ‘‘General Procedures Leading to Correlated Equilibria,’’ The Hebrew University of
Jerusalem, Center for Rationality DP-216. CAMERER, C., AND T.-H. HO Ž1998.: ‘‘Experience-Weighted Attraction Learning in Coordination
Games: Probability Rules, Heterogeneity, and Time-Variation,’’ Journal of Mathematical Psychol-
ogy, 42, 305᎐326. EREV, I., AND A. E. ROTH Ž1998.: ‘‘Predicting How People Play Games: Reinforcement Learning in
Experimental Games with Unique, Mixed Strategy Equilibria,’’ American Economic Re¨iew, 88, 848᎐881. FELLER, W. Ž1965.: An Introduction to Probability Theory and its Applications, Vol. II, 2nd edition.
New York: Wiley. FOSTER, D., AND R. V. VOHRA Ž1993.: ‘‘A Randomization Rule for Selecting Forecasts,’’ Operations
Research, 41, 704᎐709. ᎏᎏᎏ Ž1997.: ‘‘Calibrated Learning and Correlated Equilibrium,’’ Games and Economic Beha¨ior,
21, 40᎐55. ᎏᎏᎏ Ž1998.: ‘‘Asymptotic Calibration,’’ Biometrika, 85, 379᎐390. ᎏᎏᎏ Ž1999.: ‘‘Regret in the On-line Decision Problem,’’ Games and Economic Beha¨ior, 29, 7᎐35. FUDENBERG, D., AND D. K. LEVINE Ž1995.: ‘‘Universal Consistency and Cautious Fictitious Play,’’
Journal of Economic Dynamics and Control, 19, 1065᎐1089. ᎏᎏᎏ Ž1998.: Theory of Learning in Games. Cambridge, MA: The MIT Press. ᎏᎏᎏ Ž1999.: ‘‘Conditional Universal Consistency,’’ Games and Economic Beha¨ior, 29, 104᎐130. HANNAN, J. Ž1957.: ‘‘Approximation to Bayes Risk in Repeated Play,’’ in Contributions to the Theory
of Games, Vol. III, Annals of Mathematics Studies 39, ed. by M. Dresher, A. W. Tucker, and P.
Wolfe. Princeton: Princeton University Press, pp. 97᎐139. HART, S., AND A. MAS-COLELL Ž1999.: ‘‘A General Class of Adaptive Strategies,’’ The Hebrew
University of Jerusalem, Center for Rationality DP-192, forthcoming in Journal of Economic
Theory. ᎏᎏᎏ Ž2000.: ‘‘A Stimulus-Response Procedure Leading to Correlated Equilibrium,’’ The Hebrew
University of Jerusalem, Center for Rationality Žmimeo.. HART, S., AND D. SCHMEIDLER Ž1989.: ‘‘Existence of Correlated Equilibria,’’ Mathematics of Opera-
tions Research, 14, 18᎐25.
LO`EVE, M. Ž1978.: Probability Theory, Vol. II, 4th edition. Berlin: Springer-Verlag.
LUCE, R. D., AND H. RAIFFA Ž1957.: Games and Decisions. New York: Wiley. MARIMON, R. Ž1996.: ‘‘Learning from Learning in Economics,’’ in Ad¨ances in Economic Theory, ed.
by D. Kreps. Cambridge: Cambridge University Press. MEGIDDO, N. Ž1980.: ‘‘On Repeated Games with Incomplete Information Played by Non-Bayesian
Players,’’ International Journal of Game Theory, 9, 157᎐167. MERTENS, J.-F., S. SORIN, AND S. ZAMIR Ž1995.: ‘‘Repeated Games, Part A,’’ CORE DP-9420
Žmimeo.. MYERSON, R. B. Ž1997.: ‘‘Dual Reduction and Elementary Games,’’ Games and Economic Beha¨ior,
21, 183᎐202. NAU, R. F., AND K. F. MCCARDLE Ž1990.: ‘‘Coherent Behavior in Noncooperative Games,’’ Journal
of Economic Theory, 50, 424᎐444. ROBINSON, J. Ž1951.: ‘‘An Iterative Method of Solving a Game,’’ Annals of Mathematics, 54, 296᎐301. ROTH, A. E., AND I. EREV Ž1995.: ‘‘Learning in Extensive-Form Games: Experimental Data and
Simple Dynamic Models in the Intermediate Term,’’ Games and Economic Beha¨ior, 8, 164᎐212. SANCHIRICO, C. W. Ž1996.: ‘‘A Probabilistic Model of Learning in Games,’’ Econometrica, 64,
1375᎐1393.

