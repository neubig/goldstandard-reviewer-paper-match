Awakening Latent Grounding from Pretrained Language Models for Semantic Parsing
Qian Liu†∗ , Dejian Yang§, Jiahui Zhang†∗, Jiaqi Guo♦∗, Bin Zhou†, Jian-Guang Lou§ †Beihang University, Beijing, China §Microsoft Research, Beijing, China
♦Xi’an Jiaotong University, Xi’an, China †{qian.liu, 17231043, zhoubin}@buaa.edu.cn; ♦jasperguo2013@stu.xjtu.edu.cn
§{dejian.yang, jlou}@microsoft.com

arXiv:2109.10540v1 [cs.CL] 22 Sep 2021

Abstract
Recent years pretrained language models (PLMs) hit a success on several downstream tasks, showing their power on modeling language. To better understand and leverage what PLMs have learned, several techniques have emerged to explore syntactic structures entailed by PLMs. However, few efforts have been made to explore grounding capabilities of PLMs, which are also essential. In this paper, we highlight the ability of PLMs to discover which token should be grounded to which concept, if combined with our proposed erasingthen-awakening approach. Empirical studies on four datasets demonstrate that our approach can awaken latent grounding which is understandable to human experts, even if it is not exposed to such labels during training. More importantly, our approach shows great potential to beneﬁt downstream semantic parsing models. Taking text-to-SQL as a case study, we successfully couple our approach with two off-the-shelf parsers, obtaining an absolute improvement of up to 9.8%.
1 Introduction
Recent breakthroughs of Pretrained Language Models (PLMs) such as BERT (Devlin et al., 2019) and GPT3 (Brown et al., 2020) have demonstrated the effectiveness of self-supervised learning for a range of downstream tasks. Without being guided by structural information in training, PLMs show the potential for learning implicit syntactic structures and language semantic, which can be transferred to other tasks. To better understand and leverage what PLMs have learned, several work has emerged to probe or induce syntactic structures from PLMs. According to prior studies (Rogers et al., 2020), most existing work focuses on syntactic structures such as part of speech (Liu et al.,
∗Work done during an internship at Microsoft Research. The ﬁrst three authors contributed equally.

what war was george washington associated with?

Reign

Monarchs

1789-1802 George

1802-1826

John I

1826-1845 Andrew

(a). Structured Table

George Washington
(b). Knowledge Base

Colonial Beach U.S. President

Figure 1: Typical scenarios for grounding, here the linguistic tokens “george washington” can be grounded into different real-world concepts.

2019), constituency tree (Wu et al., 2020) and dependency tree (Hewitt and Manning, 2019; Jawahar et al., 2019), paying much less attention on language semantics (Tenney et al., 2019). However, as well known, semantic information is essential for high-level tasks like machine reading comprehension (Wang and Jiang, 2019).
Regarding to language semantics, an important branch is grounding, which is overlooked by most previous work. Broadly speaking, grounding means “connecting linguistic symbols to real-world perception or actions” (Roy, 2005). It is generally thought to be important for a variety of tasks, such as video descriptions (Zhou et al., 2019), visual question answering (Zhu et al., 2016) and semantic parsing (Guo et al., 2019). In this paper, we focus on single-modal scenarios, where grounding refers more speciﬁcally to mapping linguistic tokens into a real-world concept described in natural language. As shown in Figure 1, “george washington” can be grounded into either a cell value in a structured table, or an entity in knowledge bases.
In single-modal scenarios, grounding is especially important for semantic parsing, the task of translating a natural language sentence into its corresponding executable logic form. For earlier work, grounding is essential since earlier work almost conceptualized semantic parsing as grounding an

Concept Prediction Confidence

CP 0.92
0.65

Question
[CLS] How many total games were at
PLM

Concept
braly stadium [SEP] Venue

Grounding Module

0.14 0.10 0.21 0.01 0.14 0.18 0.06 0.16 0.02 0.03 0.05 0.12 0.04 0.11 0.08 0.27

Latent Grounding Awakening
Pseudo Alignment

CP

PLM

[CLS] How many total games were at braly george [SEP] Venue

Erasing

Figure 2: The illustration of ETA, which consists of a PLM module, a Concept Prediction (CP) module and a grounding module. Two models (gray and blue) are drawn here for illustration purposes, and they are indeed the same. The model training involves three steps: (1) The concept prediction module is trained to predict the conﬁdence of any concept occurring in a given question (Left). (2) The erasing mechanism erases tokens in the question sequentially, feeds them into CP, and obtains the conﬁdence differences (e.g., 0.92 − 0.65 = 0.27) as the pseudo alignment. Here we only demonstrate the process related to “stadium” (Bottom Right). (3) The pseudo alignment is employed to awaken the latent grounding, i.e., to supervise the grounding module (Top Right). We show only one concept “Venue” for the sake of brevity, which in practice is a sequence of concepts.

utterance to a task-speciﬁc meaning representation (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang et al., 2013; Cheng et al., 2017). As for modern approaches based on the encoder-decoder architecture, grounding also plays an important role and considerable work has demonstrated the positive effect of it (Guo et al., 2019; Dong et al., 2019; Liu et al., 2020a; Wang et al., 2020b; Chen et al., 2020). Despite its success, existing grounding methods mainly relied on heavy manual efforts like high-quality lexicons (Reddy et al., 2016) or adhoc heuristic rules like n-gram matching (Guo et al., 2019), suffering from poor ﬂexibility. To explore more ﬂexible methods, researchers recently tried a data-driven way: they collected grounding annotations as supervision to train grounding models (Li et al., 2020a; Lei et al., 2020; Shi et al., 2020). However, this modeling ﬂexibility in their approaches requires expensive annotations of grounding, which most of the time are not available.
To alleviate the above issues, we present a novel approach Erasing-then-Awakening (ETA)1. It is inspired by recent advances in interpretable machine learning (Samek et al., 2017), where the importance of individual pixels can be quantiﬁed with respect to the classiﬁcation decision. Similarly, our approach ﬁrstly quantiﬁes the contribution of each word with respect to each concept, by erasing it and probing the variation of concept prediction de-
1Our code is available at https://github.com/ microsoft/ContextualSP

cisions (elaborated later). Then it employs these contributions as pseudo labels to awaken latent grounding from PLMs. In contrast to prior work, our approach only needs supervision of concept prediction, which can be easily derived by downstream tasks (e.g., text-to-SQL) instead of full grounding supervision. Empirical studies on four datasets demonstrate that our approach can awaken latent grounding which is understandable to human experts. It is highly non-trivial because our approach is not exposed to any human-annotated grounding label in training. More importantly, we ﬁnd that the grounding can be easily coupled with downstream models to boost their performance, and the absolute improvement is up to 9.8%. In summarization, our contribution is as three-fold:
1. To the best of our knowledge, we are the ﬁrst one to highlight and demonstrate the possibility of awakening latent grounding from PLMs.
2. We propose a novel weakly supervised approach erasing-then-awakening, to awaken latent grounding from PLMs. Empirical studies on four datasets demonstrate that our approach can awaken latent grounding which is understandable to human experts.
3. Taking text-to-SQL as a case study, we successfully couple our approach with two offthe-shelf parsers. Experimental results on two benchmarks show the effectiveness of our approach on boosting downstream performance.

2 Method: Erasing-then-Awakening
In the task of grounding, we are given a question x = x1, · · · , xN and a concept set C = {c1, · · · , cK}, where each concept consists of several tokens. The goal of grounding is to ﬁnd out tokens (also known as mentions) in x which are relevant to concepts in C. Generally, the grounding procedure learns to create a N ×K matrix, which we call latent grounding. In some cases, a set of pairs is needed, of which each one explicitly shows a token and a concept is grounded. We call this kind of pairs as grounding pairs below.
As illustrated in Figure 2, our model consists of a PLM module, a CP module and a grounding module. In this section, we ﬁrst present the training procedure of ETA, which at a high-level involves three steps: (1) Train an auxiliary concept prediction module. (2) Erase tokens in a question to obtain the concept prediction conﬁdence differences as pseudo alignment. (3) Awaken latent grounding from PLMs by applying pseudo alignment as supervision. Then we introduce the procedure to produce grounding pairs in inference.
2.1 Training a Concept Prediction Module
Given x and C, the goal of the concept prediction module is to identify if each concept ck ∈ C is mentioned or not in the question x. Although it does not seem to be directly related to grounding, it is a pre-requisite for the erasing mechanism, which will be elaborated later. As for ck’s supervision lk ∈ {0, 1}, it is the weak supervision ETA relies on, and can be readily obtained through downstream task signals. Taking text-to-SQL as an illustration, each database schema (i.e., table, column and cell value) in an annotated SQL can be considered as mentioned in the question (lk = 1), with others as negative examples (lk = 0).
Once the supervision is prepared, the CP module is trained to conduct binary classiﬁcation over the representation of each concept. As done in previous work (Hwang et al., 2019), we ﬁrst concatenate the question and all concepts into a sequence as input to the PLM module. As illustrated in Figure 2, the input sequence starts with [CLS], with the question and each concept being separated by [SEP]. Then, the sequence is fed into the PLM module to produce deep contextual representations over each position. Denoting q1, q2, ..., qN and e1, e2, ..., eK as the token representations and

concept representations, they can be obtained by:
{qn}Nn=1, {ek}K k=1 = PLM [CLS],x,{[SEP], ck}K k=1 , (1)

where qn and ek correspond to the representations at the position of n-th question token and the ﬁrst token in ck respectively. Finally, each concept representation ek is passed to a classiﬁer to predict if it is mentioned in x as:

pk = Sigmoid(Wl ek),

(2)

where Wl is a learnable parameter. pk is the probability of ck mentioned in the question, which is referred to by concept prediction conﬁdence below.

2.2 Erasing Question Tokens
Once the concept prediction module is converged, we apply an erasing mechanism to assist in the following awakening phase. It follows a similar idea from the interpretable document classiﬁcation (Arras et al., 2016), where a word is considered important for the document classiﬁcation if removing it and classifying the modiﬁed document results in a strong decrease of the classiﬁcation score. In our case, a token is considered highly relevant to certain concepts if there is a large drop in these concept prediction conﬁdences after erasing the token. Therefore, we need the above mentioned concept prediction module to provide a reasonable concept prediction conﬁdence.
Concretely, as shown in Figure 2, the erasing mechanism erases the input sequentially, and feeds each erased input into the PLM module and the subsequent CP module. For example, with xn being substituted by a special token [UNK], we can obtain an erased input as [CLS], x1, · · · , xn−1,[UNK], xn+1, · · · , cK . Denoting pˆn,k the concept prediction conﬁdence for ck after erasing xn, we believe the difference between pˆn,k and pk reveals ck’s relevance to xn from a PLM’s view. The conﬁdence difference ∆n,k can be obtained by ∆n,k = lk· max(0, pk − pˆn,k). Repeating the above procedure on the input question sequentially, ∆ ∈ RN×K is ﬁlled completely.
2.3 Awakening Latent Grounding
As mentioned above, we believe ∆ reﬂects the relevance between each token and each concept from a PLM’s view. Therefore, we could directly use ∆ as ETA’s output. However, according to our preliminary study, the method performs poorly and

cannot produce high-quality alignment2. Different from directly using ∆, we employ it to “awaken” the latent grounding. To be speciﬁc, we introduce a grounding module upon representations of the PLM module and train it using ∆ as pseudo labels (i.e., pseudo alignment). The grounding module ﬁrst obtains grounding scores gn,k between each question token xn and each concept ck based on their deep contextual representations qn and ek as:

Week · (Wqqn)T

gn,k =

√

,

(3)

d

where We, Wq are learnable parameters and d is the dimension of ek. Then it normalizes the grounding scores into latent grounding α as:

αn,k = exp(gn,k) . (4) i exp(gi,k)

Finally, the grounding module is trained to maximize the likelihood with ∆ as the weight:

∆n,k · log αn,k.

(5)

nk

2.4 Producing Grounding Pair
Repeating erasing and awakening iteratively for epochs until the grounding module converges, we can readily produce grounding pairs. Formally, we aim to obtain a set of pairs, where each pair xn, ck indicates that xn is grounded to ck. Noticing ck may contain several tokens, we keep all probabilities in α·,k which exceeds τ /|ck|, where τ is a threshold and |ck| is the number of tokens in ck. Also, taking into account that xn should be grounded to only one concept, we keep only the highest probability over αn,·. Finally, for each pair xn, ck , it is thought to be a grounding pair if αn,k is kept and pk ≥ 0.5, otherwise it is not.

3 Experiments

In this section, we conduct experiments to evaluate if the latent grounding awakened by ETA is understandable to human experts. Here we accomplish the evaluation by comparing the grounding pairs produced by ETA with human annotations.

3.1 Experimental Setup Datasets We select two representative grounding tasks where human annotations are available: schema linking and entity linking. Schema linking
2More experimental results can be found in §3.3.

is to ground questions into database schemas, while entity linking is to ground questions into entities of knowledge bases. For schema linking, we select SPIDER-L (Lei et al., 2020) and SQUALL (Shi et al., 2020) as our evaluation benchmarks. As mentioned in §2.1, the supervision for our model is obtained from SQL queries. As for entity linking, we select WebQSPELand GraphQEL(Sorokin and Gurevych, 2018). The supervision for our model is obtained from SPARQL queries in a similar way.
Evaluation For schema linking, as done in previous work (Lei et al., 2020), we report the microaverage precision, recall and F1-score for both columns (ColP , ColR, ColF ) and tables (TabP , TabR, TabF ). For entity linking, we report the weak matching precision, recall and F1-score for entities (EntP , EntR, EntF ). The weak matching metric is a commonly used metric in previous work (Sorokin and Gurevych, 2018), which considers a prediction as correct whenever the correct entity is identiﬁed and the predicted mention boundary overlaps with the ground truth boundary. More details can be seen in §A.
Baselines For schema linking, we consider four strong baselines. (1) N-gram Matching enumerates all n-gram (n ≤ 5) phrases in a natural language question, and links them to database schemas by fuzzy string matching. (2) SIM computes the dot product similarity between each question token and schema using their PLM representations without ﬁne-tuning, to explore grounding capacities of unawakened PLMs. (3) CONTRAST learns by comparing the aggregated grounding scores of mentioned schemas with unmentioned ones in a contrastive learning style, as done in Liu et al. (2020b). Concretely, in training, CONTRAST is trained to accomplish the same concept prediction task as our approach. With a similar architecture to the Receiver used in Liu et al. (2020b), it ﬁrst computes the similarity score between each token and each concept, and then uses max pooling to aggregate the similarity scores of a concept over an utterance into a concept prediction score. Finally, a margin-based loss is used to encourage the baseline to give higher concept prediction scores on mentioned concepts than unmentioned concepts. (4) SLSQLL & ALIGNL. SLSQLL (ALIGNL) is a learnable schema linking module3 proposed in
3SLSQL and ALIGN use multi-task learning to simultaneously learn schema linking and SQL generation.

Model
N-gram Matching SIM + BERT CONTRAST + BERT ETA + BERT SLSQLL + BERT♥ (Lei et al., 2020) ALIGNL + BERT♥ (Shi et al., 2020)

ColP
61.4 16.6 83.7 86.1
82.6 –

ColR
69.1 8.0 68.4 79.3
82.0 –

SPIDER-L

ColF TabP

65.1 10.8 75.3 82.5

78.2 8.5 84.0 81.1

82.3 80.6

–

–

TabR
69.6 11.6 76.9 85.3
84.0 –

TabF
73.6 9.8 80.3 83.1
82.2 –

SQUALL

ColP ColR ColF

71.6 13.9 47.9 77.3

50.8 18.0 31.2 62.4

59.4 15.7 37.8 69.0

–

–

–

79.2 72.8 75.8

Table 1: Experimental results on schema linking dev sets. ♥ means the model uses schema linking supervision, while other learnable models use weak supervision. +BERT means using BERT as encoder, the same for Table 2.

Model
Heuristic (Sorokin and Gurevych, 2018) ETA + BERT VCG♥ (Sorokin and Gurevych, 2018) ELQ + BERT♥ (Li et al., 2020a)

WebQSPEL
EntP EntR EntF
30.2 60.8 40.4 76.6 72.5 74.5
82.4 68.3 74.7 90.0 85.0 87.4

GraphQEL(zero-shot)

EntP EntR EntF

-

-

-

43.1 42.1 42.7

54.1 30.6 39.0 60.1 57.2 58.6

Table 2: Experimental results on entity linking test sets. ♥ means the model uses entity linking supervision from WebQSPEL, while ETA uses the weak supervision derived from WebQSP. Following previous work (Sorokin and Gurevych, 2018), we use GraphQELonly in the evaluation phase to test the generalization ability of our model.

SLSQL (ALIGN). Unlike our method, these two methods are trained with the full schema linking supervision. Please refer to Shi et al. (2020) and Lei et al. (2020) for more details. Notably, for baselines which require a threshold, we tuned their thresholds based on dev sets for fair comparison.
For entity linking, we compare ETA with three powerful methods. (1) Heuristic picks the most frequent entity among the candidates found by string matching over Wikidata. (2) VCG (Sorokin and Gurevych, 2018) aggregates and mixes contexts of different granularities to perform entity linking. (3) ELQ (Li et al., 2020a) uses a bi-encoder to perform entity linking in one pass, achieving state-of-the-art performance on WebQSPELand GraphQEL. VCG and ELQ utilize entity linking supervision in training, while ETA does not.
Implementation For schema linking we follow the procedure in §2.4 to produce grounding pairs to evaluate, while for entity linking we further merge adjacent grounding pairs to produce spanlevel grounding pairs. We implement ETA in Pytorch (Paszke et al., 2019). With respect to PLMs in experiments, we use the uncased BERT-base (BERT)4 and BERT-large (BERTL) from Trans-
4Our approach is theoretically applicable to different PLMs. In this paper, we chose BERT as a representative and we leave exploration of different PLMs for future work.

formers library (Wolf et al., 2020). As for the optimizer, we employ AdamW (Loshchilov and Hutter, 2019). More details (e.g., learning rate) of each experiment can be found in §C.1.
3.2 Experimental Results
Table 1 shows the experimental results on the schema linking task. As shown, our method outperforms all weakly supervised methods and heuristicbased methods by a large margin. For example, on SPIDER-L, ETA + BERT achieves an absolute improvement of 7.2% ColF and 2.8% TabF over the best baseline CONTRAST. The same conclusion can be drawn from the experimental results on the entity linking task shown in Table 2. For instance, ETA + BERT can obtain a high EntF up to 74.5% on WebQSPEL, which is a satisfying performance for downstream tasks. All results above demonstrate the superiority of our approach on awakening latent grounding from PLMs. With respect to the reason that PLMs work well on both schema linking and entity linking, it may be because both schema linking and entity linking require text-based semantic matching (e.g., synonyms), which PLMs excel at.
Furthermore, it is very surprising that although not trained under ﬁne-grained grounding supervision, our model is comparable with or slightly worse than the fully supervised models across

Error Type Missed Grounding (43.1%) Technically Correct (21.0%)
Partially Correct (15.8%)
Wrong Grounding (10.1%)

Example Error

How many points did arnaud demare receive? GOLD: points→ “UCI world tour points”

PRED:

Total population of millbrook ﬁrst nation? GOLD: population→ “Population” PRED: population→ “Population”; nation→ “Community”

Who was the ﬁrst winning captain? GOLD: the ﬁrst→ “Year”; winning captain→ “Winning Captain” PRED: ﬁrst→ “Year”; winning captain→ “Winning Captain”

Were the matinee and evening performances held earlier than the 8th anniversary? GOLD: earlier→ “Date” PRED: matinee→ “Performance”; earlier→ “Date”

Table 3: Four main error types made by ETA along with their proportions on SQUALL dataset.

datasets. For instance, on SPIDER-L, our model exceeds the fully supervised baseline SLSQLL by 0.9 points on TabF . On SQUALL, our model holds a slightly worse performance than the fully supervised baseline ALIGNL. It is highly nontrivial since CONTRAST, the best weakly supervised baseline on SPIDER-L, is far from the fully supervised model on SQUALL, while our model has only a small drop. Besides, on WebQSPELand GraphQEL, although our model is inferior to the state-of-theart model ELQ, it also achieves a comparable performance with the fully supervised baseline VCG. These results provide strong evidence that PLMs do have very good grounding capabilities, and our approach can awaken them from PLMs.
3.3 Model Analysis
In this section, we try to answer four interesting research questions via a thorough analysis: RQ1. Does the grounding capability come mainly from the PLM? RQ2. Is the awakening phase necessary? RQ3. Do larger PLMs have better grounding capabilities? RQ4. What are the remaining errors?
RQ1 There is a long term debate in literature about if knowledge is primarily learned by PLMs, when extra parameters are employed in analysis (Hewitt and Liang, 2019). Similarly, since our approach depends on extra modules (e.g., grounding module), it faces the same dilemma: how can we know whether the latent grounding is learnt from PLMs or extra modules? Therefore, we apply our approach to a randomly initialized Transformer encoder (Vaswani et al., 2017), to probe the grounding capability of a model that has not been pretrained. To make it comparable, the encoder has the same architecture as BERT. However, it only gets a 40% ColF on SQUALL, not even as good

75 60 45 30 15
0

Awakening Pseudo Alignment Pseudo w/ Softmax
Pseudo w/ Sum
5 10 15 20 25

Figure 3: ColF score on the dev set of SQUALL at different training epochs. “Pseudo w/ Softmax” means normalizing pseudo alignment with Softmax, while “Pseudo w/ Sum” means normalizing through dividing each number by the sum of them.

as the N-gram baseline. Considering it contains the same extra modules as ETA + BERT, the huge gap between it and ETA + BERT supports the opinion that the latent grounding is mainly learnt from PLMs. Meanwhile, one concern shared by our reviewers is the risk of supervision exposure during training of the concept prediction module. In other words, our approach may “steal” some supervision in the concept prediction module to achieve good performance on grounding. However, the above experiment demonstrates that a non-pretrained model is far from strong grounding capability even with the same concept prediction module. We hope the ﬁnding will alleviate the concern.
RQ2 As mentioned in §2.3, the pseudo alignment ∆ can also be employed as the model prediction. Therefore, we conduct experiments to verify if our proposed awakening phase is necessary. As shown in Figure 3, even with various normalization methods (e.g., Softmax), ∆ does not produce satisfactory alignment. In contrast, our model consistently performs well. To investigate deeper, we conduct a careful analysis on ∆, and we are surprised to

SQL SELECT Avg(budget), Max(budget), Min(budget) FROM movie WHERE year < 2020

Decoder

𝑞1

𝑞1 ⋯ 𝑞𝑛−1 𝑞𝑛

PLMs

Encoder 𝑓⊕
𝑒1 ⋯ 𝑒𝑚

0.14 0.16 ⋯ 0.18 0.06

⋮

⋮

⋱

⋮

⋮⋯

0.11 0.33 ⋯ 0.48 0.55
⋯ ETA

[CLS] Find the average , maximum and ⋯ movies before 2002 . [SEP] Movie [SEP] budget ⋯ [SEP] Year

Question

Schema

Figure 4: The illustration of the solution to couple ETA with downstream text-to-SQL parsers.

ﬁnd that values of ∆ are generally small and not as signiﬁcantly different with each other as we would expect. Therefore, we believe the success of our approach stems from the fact that it encourages the grounding module to capture subtle differences and strength them.
RQ3 We apply our approach on BERT-large (BERTL) and conduct experiments on SPIDER-L. The results show BERTL brings an improvement of 2.5% ColF and 0.5% TabF , suggesting the possibility of awakening better latent grounding from larger PLMs. Nevertheless, the improvement may also come from more parameters, so the conclusion needs further investigation.
RQ4 We manually examine 20% of our model’s errors on the SQUALL dataset and summarize four main error types: (1) missed grounding - where our model did not ground any token to a concept, (2) technically correct - where our model was technically correct but the annotation was missing, (3) partially correct - where our model did not ﬁnd all tokens of a concept, (4) wrong grounding - where the model produced incorrect grounding. As shown in Table 3, only a small fraction of errors are wrong grounding, indicating that the main challenge of our approach is recall rather than precision.
4 Case Study: Text-to-SQL
The ETA model is proposed for general-purpose uses and intends to enhance different downstream semantic parsing models. To verify it, we take the text-to-SQL task as a case study. In this section, we ﬁrst present a general solution to couple ETA with different text-to-SQL parsers. Then, we conduct experiments on two off-the-shelf parsers to verify the effectiveness of ETA.
4.1 Coupling with Text-to-SQL Parsers
Inspired by Lei et al. (2020), we present a general solution to couple ETA with downstream parsers in

Model
ALIGNP ALIGNP + BERT ETA + BERT ALIGN ♥ ALIGN + BERT♥

Dev

Ex.Match
37.8 ± 0.6 44.7 ± 2.1 47.6 ± 2.5

Ex.Acc
56.9 ± 0.7 63.8 ± 1.1 66.6 ± 1.7

42.2 ± 1.5 61.3 ± 0.8 47.2 ± 1.2 66.5 ± 1.2

Test
Ex.Acc 46.6 ± 0.5 51.8 ± 0.4 53.8 ± 0.3
49.7 ± 0.4 54.1 ± 0.2

Table 4: Ex.Match and Ex.Acc results on the dev and test set of WTQ. + BERT means using BERT to enhance encoder. ♥ means the model uses extra schema linking supervision. Both are the same for Table 5.

Figure 4. As shown, we ﬁrst obtain a schema-aware representation for each question token, by fusing the token representation and its related schema representation according to the latent grounding α∈RN×K (gray matrix in Figure 4). Speciﬁcally, given a token representation qn and all schema representations e1, e2, ..., eK , the schema-aware representation q˜n for qn can be computed as:

q˜n = qn⊕ αn,k ek.

(6)

k

Then we feed every q˜n into a question encoder to generate hidden states, which are attended by a decoder to decode the SQL query. By contributing to the schema-aware representation, ETA is able to prompt the decoder to predict appropriate schemas during decoding. Notably, the encoder and decoder are not limited to speciﬁc modules, and we follow the paper settings in subsequent experiments.

4.2 Experimental Setup
Datasets and Evaluation We conduct experiments on two text-to-SQL benchmarks: WikiTableQuestions(WTQ) (Pasupat and Liang, 2015)5 and Spider (Yu et al., 2018b). Following previous work, we employ three kinds of evaluation metrics: Exact Match (Ex.Match), Exact Set Match (Ex.Set) and Execution Accuracy (Ex.Acc). Ex.Match evaluates the predicted SQL correctness by checking if it is equal to the ground-truth, while Ex.Set evaluates the structural correctness by checking the set match of each SQL clause in the predicted query with respect to the ground-truth. Ex.Acc evaluates the functional correctness of the predicted SQL by checking whether it yields the ground-truth answer.
5Note that the original WTQ only contains answer annotations, and here we use the version with SQL annotations provided by Shi et al. (2020). Our training data is a subset of the original train set, while the test data keeps the same.

Model
IRNet + BERT (Guo et al., 2019) IRNet v2 + BERT (Guo et al., 2019) BRIDGE + BERTL (Lin et al., 2020) RATSQL + BERTL (Wang et al., 2020a) SLSQLP + BERT SLSQLP + BERTL ETA + BERT ETA + BERTL

Dev
61.9 63.9 70.0 69.7 57.4 61.0 64.5 70.8

Test
54.7 55.0 65.0 65.6
59.5 65.3

Table 5: Ex.Set results on the dev and test set of Spider.

teacher 0.00

0.00

0.00

0.00

1.00

0.00

0.00

teacher.age 0.01

0.00

0.00

0.83

0.15

0.01

0.00

teacher.hometown 0.56

0.01

0.00

0.01

0.31

0.11

0.00

where is the youngest teacher from ?

Figure 5: The latent grounding produced by ETA + BERTL for the question “Where is the youngest teacher from?”.

Baselines On WTQ, our baselines include ALIGNP and ALIGN, where the former is a vanilla attention based sequence to sequence model and the latter enhances ALIGNP with an additional schema linking task (Shi et al., 2020). Similarly, on Spider, our main baselines are SLSQLP and its schema linking enhanced version SLSQL (Lei et al., 2020). SLSQLP is made up of a question encoder and a two-step SQL decoder. In the ﬁrst decoding step, a coarse SQL (i.e., without aggregation functions) is generated. Then the coarse SQL is used to synthesize the ﬁnal SQL in the second decoding step. Here we also report the performance of SLSQL + BERT (Oracle), where the learnable schema linking module is replaced with human annotations in inference. It represents the maximum potential beneﬁt of schema linking for the text-to-SQL task. Meanwhile, for a comprehensive comparison, we also compare our model with state-of-the-art models on the Spider benchmark6. We refer readers to their papers for details.
Implementation As for our approach, on WTQ, we employ ALIGNP7 as our base parser, while on Spider we select SLSQLP8 as our base parser. For both parsers, we try to follow the same hyperparameters as described in the paper to reduce other factors that may affect the performance. More implementation details can be found in §C.2.
4.3 Experimental Results
Table 4 and Table 5 show the experimental results of several methods on WTQ and Spider respectively. As observed, introducing ETA dramatically improves the performance of both base parsers, demonstrating its effectiveness on downstream tasks. Taking Spider as an illustration, our model ETA + BERT boosts SLSQLP + BERT by
6https://yale-lily.github.io/spider 7https://github.com/tzshi/squall 8https://github.com/WING-NUS/slsql

an absolute improvement 7.1% on the Ex.Set metric. As the PLM becomes larger (e.g., BERTL), the improvement becomes more signiﬁcant, up to 9.8%. Compared with state-of-the-art methods, our model ETA + BERTL also obtains a competitive performance, which is extremely impressive since it is based on a simple parser.
More interestingly, on both datasets, our model can achieve similar even better performance compared to methods which employ extra grounding supervision. For instance, in comparison with SLSQL + BERT on Spider, our ETA + BERT outperforms it by 3.7%. Taking into account that SLSQL utilizes additional supervision, the performance gain is very surprising. We attribute the gain to two possible reasons: (1) The PLMs already learn latent grounding which is understandable to human experts. (2) Compared with training with strong schema linking supervision, training with weak supervision alleviates the issue of exposure bias, and thus enhance the generalization ability of ETA.
Table 6 presents the model predictions of ETA + BERTL on three real cases. As observed, ETA has learned the grounding about adjective (e.g., oldest → age), entity (e.g., where → hometown) and semantic matching (e.g., registered → student enrolment). Meanwhile, grounding pairs provide us a useful guide to better understand the model predictions. Figure 5 visualizes the latent grounding for Q2 in Table 6, and more visualization can be found in §D.
5 Related Work
The most related work to ours is the line of inducing or probing knowledge in pretrained language models. According to the knowledge category, there are mainly two kinds of methods: one focuses on syntactic knowledge and the other pays attention to semantic knowledge. Under the category of syntac-

Question with Alignment
1. Show name1, country2, age3 for all singers4 ordered by age3 from the oldest3 to the youngest.
2. Where1 is the youngest2 teacher3 from?
3. For each semester1, what is the name2 and id3 of the one with the most students registered4?

SQL with Alignment
SELECT name1, country2, age3 FROM singer4 ORDER BY age3 DESC
SELECT hometown1 FROM teacher3 ORDER BY age2 ASC LIMIT 1
SELECT semester name2, semester id3 FROM semesters1 JOIN student enrolment4 ON semesters.semester id = student enrolment.semester id GROUP BY semester id3 ORDER BY COUNT(*) DESC LIMIT 1

Table 6: The predicted grounding pairs and SQLs of our best model on three real cases from the Spider dev set. The question token and the schema with the same subscript are grounded.

tic knowledge, several work showed that BERT embeddings encoded syntactic information in a structural form and can be recovered (Lin et al., 2019b; Warstadt and Bowman, 2020; Hewitt and Manning, 2019; Wu et al., 2020). However, recent work also showed that BERT did not rely on syntactic information for downstream task performance, and thus doubted the role of syntactic knowledge (Ettinger, 2020; Glavas and Vulic, 2020). As for semantic knowledge, although it is less explored than syntactic knowledge, previous work showed that BERT contained some semantic information, such as entity types (Ettinger, 2020), semantic roles (Tenney et al., 2019) and factual knowledge (Petroni et al., 2019). Different from the above work, we focus on the grounding capability, an under-explored branch of language semantics.
Our work is also closely related to entity linking and schema linking, which can be viewed as subareas of grounding on speciﬁc scenarios. Given an utterance, entity linking aims at ﬁnding all mentioned entities in it using a knowledge base as candidate pool (Tan et al., 2017; Chen et al., 2018; Li et al., 2020a), while schema linking tries to ﬁnd all mentioned schemas related to speciﬁc databases (Dong et al., 2019; Lei et al., 2020; Shi et al., 2020). Previous work generally either employed full supervision to train linking models (Li et al., 2020a; Lei et al., 2020; Shi et al., 2020), or treated linking as a minor pre-processing(Yu et al., 2018a; Guo et al., 2019; Lin et al., 2019a) and used heuristic rules to obtain the result. Our work is different from them since we optimize the linking model with weak supervision from downstream signals, which is ﬂexible and practicable. Similarly, Dong et al. (2019) utilized downstream supervision to train their linking model. Compared with them using policy gradient, our method is more efﬁcient since it directly learns the grounding module using pseudo alignment as supervision.

6 Conclusion & Future Work
In summary, we propose a novel weakly supervised approach to awaken latent grounding from pretrained language models via erasing. Only with downstream signals, our approach can induce latent grounding from pretrained language models which is understandable to human experts. More importantly, we demonstrate that our approach could be applied to off-the-shelf text-to-SQL parsers and signiﬁcantly improve their performance. For future work, we plan to extend our approach to more downstream tasks such as visual question answering. We also plan to utilize our approach to improve the error locator module in existing interactive semantic parsing systems (Li et al., 2020b).
Acknowledgement
We would like to thank all the anonymous reviewers for their constructive feedback and useful comments. We also thank Tao Yu and Bo Pang for evaluating our submitted models on the test set of Spider. The ﬁrst author Qian is supported by the Academic Excellence Foundation of Beihang University for PhD Students.
Ethical Considerations
This paper conducts experiments on several existing datasets covering the areas of entity linking, schema entity and text-to-SQL. All claims in this paper are based on the experimental results. Every experiment can be conducted on a single Tesla P100 or P40 GPU. No demographic or identity characteristics information is used in this paper.
References
Leila Arras, Franziska Horn, Gre´goire Montavon, Klaus-Robert Mu¨ller, and Wojciech Samek. 2016.

”what is relevant in a text document?”: An interpretable machine learning approach. CoRR, abs/1612.07843.
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual.
Lihan Chen, Jiaqing Liang, Chenhao Xie, and Yanghua Xiao. 2018. Short text entity linking with ﬁnegrained topics. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management, CIKM ’18, page 457–466, New York, NY, USA. Association for Computing Machinery.
Sanxing Chen, Aidan San, Xiaodong Liu, and Yangfeng Ji. 2020. A tale of two linkings: Dynamically gating between schema linking and structural linking for text-to-SQL parsing. In Proceedings of the 28th International Conference on Computational Linguistics, pages 2900–2912, Barcelona, Spain (Online). International Committee on Computational Linguistics.
Jianpeng Cheng, Siva Reddy, Vijay Saraswat, and Mirella Lapata. 2017. Learning structured natural language representations for semantic parsing. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 44–55, Vancouver, Canada. Association for Computational Linguistics.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.
Zhen Dong, Shizhao Sun, Hongzhi Liu, Jian-Guang Lou, and Dongmei Zhang. 2019. Data-anonymous encoding for text-to-SQL generation. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 5405–5414, Hong Kong, China. Association for Computational Linguistics.

Allyson Ettinger. 2020. What BERT is not: Lessons from a new suite of psycholinguistic diagnostics for language models. Transactions of the Association for Computational Linguistics, 8:34–48.
Goran Glavas and Ivan Vulic. 2020. Is supervised syntactic parsing beneﬁcial for language understanding? an empirical investigation. CoRR, abs/2008.06788.
Jiaqi Guo, Zecheng Zhan, Yan Gao, Yan Xiao, Jian-Guang Lou, Ting Liu, and Dongmei Zhang. 2019. Towards complex text-to-SQL in crossdomain database with intermediate representation. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4524–4535, Florence, Italy. Association for Computational Linguistics.
John Hewitt and Percy Liang. 2019. Designing and interpreting probes with control tasks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2733–2743, Hong Kong, China. Association for Computational Linguistics.
John Hewitt and Christopher D. Manning. 2019. A structural probe for ﬁnding syntax in word representations. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4129–4138, Minneapolis, Minnesota. Association for Computational Linguistics.
Wonseok Hwang, Jinyeung Yim, Seunghyun Park, and Minjoon Seo. 2019. A comprehensive exploration on wikisql with table-aware word contextualization. CoRR, abs/1902.01069.
Ganesh Jawahar, Benoˆıt Sagot, and Djame´ Seddah. 2019. What does BERT learn about the structure of language? In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3651–3657, Florence, Italy. Association for Computational Linguistics.
Wenqiang Lei, Weixin Wang, Zhixin Ma, Tian Gan, Wei Lu, Min-Yen Kan, and Tat-Seng Chua. 2020. Re-examining the role of schema linking in text-toSQL. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6943–6954, Online. Association for Computational Linguistics.
Belinda Z. Li, Sewon Min, Srinivasan Iyer, Yashar Mehdad, and Wen-tau Yih. 2020a. Efﬁcient onepass end-to-end entity linking for questions. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6433–6441, Online. Association for Computational Linguistics.

Yuntao Li, Bei Chen, Qian Liu, Yan Gao, JianGuang Lou, Yan Zhang, and Dongmei Zhang. 2020b. “what do you mean by that?” a parser-independent interactive approach for enhancing text-to-SQL. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6913–6922, Online. Association for Computational Linguistics.
Percy Liang, Michael I. Jordan, and Dan Klein. 2013. Learning dependency-based compositional semantics. Computational Linguistics, 39(2):389–446.
Kevin Lin, Ben Bogin, Mark Neumann, Jonathan Berant, and Matt Gardner. 2019a. Grammar-based neural text-to-sql generation. CoRR, abs/1905.13326.
Xi Victoria Lin, Richard Socher, and Caiming Xiong. 2020. Bridging textual and tabular data for crossdomain text-to-SQL semantic parsing. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 4870–4888, Online. Association for Computational Linguistics.
Yongjie Lin, Yi Chern Tan, and Robert Frank. 2019b. Open sesame: Getting inside BERT’s linguistic knowledge. In Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 241–253, Florence, Italy. Association for Computational Linguistics.
Nelson F. Liu, Matt Gardner, Yonatan Belinkov, Matthew E. Peters, and Noah A. Smith. 2019. Linguistic knowledge and transferability of contextual representations. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 1073–1094, Minneapolis, Minnesota. Association for Computational Linguistics.
Qian Liu, Bei Chen, Jiaqi Guo, Jian-Guang Lou, Bin Zhou, and Dongmei Zhang. 2020a. How far are we from effective context modeling? an exploratory study on semantic parsing in context twitter. In IJCAI, pages 3580–3586.
Qian Liu, Yihong Chen, Bei Chen, Jian-Guang Lou, Zixuan Chen, Bin Zhou, and Dongmei Zhang. 2020b. You impress me: Dialogue generation via mutual persona perception. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1417–1427, Online. Association for Computational Linguistics.
Ilya Loshchilov and Frank Hutter. 2019. Decoupled weight decay regularization. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net.
Panupong Pasupat and Percy Liang. 2015. Compositional semantic parsing on semi-structured tables. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the

7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1470–1480, Beijing, China. Association for Computational Linguistics.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. 2019. Pytorch: An imperative style, high-performance deep learning library. In Advances in Neural Information Processing Systems, volume 32, pages 8026–8037. Curran Associates, Inc.
Fabio Petroni, Tim Rockta¨schel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. 2019. Language models as knowledge bases? In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLPIJCNLP), pages 2463–2473, Hong Kong, China. Association for Computational Linguistics.
Siva Reddy, Oscar Ta¨ckstro¨m, Michael Collins, Tom Kwiatkowski, Dipanjan Das, Mark Steedman, and Mirella Lapata. 2016. Transforming dependency structures to logical forms for semantic parsing. Transactions of the Association for Computational Linguistics, 4:127–140.
Anna Rogers, Olga Kovaleva, and Anna Rumshisky. 2020. A primer in bertology: What we know about how bert works. Transactions of the Association for Computational Linguistics, 8:842–866.
Deb Roy. 2005. Grounding words in perception and action: computational insights. Trends in Cognitive Sciences, 9(8):389 – 396.
W. Samek, A. Binder, G. Montavon, S. Lapuschkin, and K. Mu¨ller. 2017. Evaluating the visualization of what a deep neural network has learned. IEEE Transactions on Neural Networks and Learning Systems, 28(11):2660–2673.
Tianze Shi, Chen Zhao, Jordan Boyd-Graber, Hal Daume´ III, and Lillian Lee. 2020. On the potential of lexico-logical alignments for semantic parsing to SQL queries. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1849–1864, Online. Association for Computational Linguistics.
Daniil Sorokin and Iryna Gurevych. 2018. Mixing context granularities for improved entity linking on question answering data across entity categories. In Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics, pages 65–75, New Orleans, Louisiana. Association for Computational Linguistics.

Chuanqi Tan, Furu Wei, Pengjie Ren, Weifeng Lv, and Ming Zhou. 2017. Entity linking for queries by searching Wikipedia sentences. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 68–77, Copenhagen, Denmark. Association for Computational Linguistics.
Ian Tenney, Patrick Xia, Berlin Chen, Alex Wang, Adam Poliak, R. Thomas McCoy, Najoung Kim, Benjamin Van Durme, Samuel R. Bowman, Dipanjan Das, and Ellie Pavlick. 2019. What do you learn from context? probing for sentence structure in contextualized word representations. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 49, 2017, Long Beach, CA, USA, pages 5998–6008.
Bailin Wang, Richard Shin, Xiaodong Liu, Oleksandr Polozov, and Matthew Richardson. 2020a. RATSQL: Relation-aware schema encoding and linking for text-to-SQL parsers. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7567–7578, Online. Association for Computational Linguistics.
Chao Wang and Hui Jiang. 2019. Explicit utilization of general knowledge in machine reading comprehension. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2263–2272, Florence, Italy. Association for Computational Linguistics.
Kai Wang, Weizhou Shen, Yunyi Yang, Xiaojun Quan, and Rui Wang. 2020b. Relational graph attention network for aspect-based sentiment analysis. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3229– 3238, Online. Association for Computational Linguistics.
Alex Warstadt and Samuel R. Bowman. 2020. Can neural networks acquire a structural bias from raw linguistic data? CoRR, abs/2007.06761.
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander Rush. 2020. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38–45, Online. Association for Computational Linguistics.

Zhiyong Wu, Yun Chen, Ben Kao, and Qun Liu. 2020. Perturbed masking: Parameter-free probing for analyzing and interpreting BERT. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4166–4176, Online. Association for Computational Linguistics.
Tao Yu, Zifan Li, Zilin Zhang, Rui Zhang, and Dragomir Radev. 2018a. TypeSQL: Knowledgebased type-aware neural text-to-SQL generation. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pages 588–594, New Orleans, Louisiana. Association for Computational Linguistics.
Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, Zilin Zhang, and Dragomir Radev. 2018b. Spider: A largescale human-labeled dataset for complex and crossdomain semantic parsing and text-to-SQL task. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3911–3921, Brussels, Belgium. Association for Computational Linguistics.
John M. Zelle and Raymond J. Mooney. 1996. Learning to parse database queries using inductive logic programming. In Proceedings of the Thirteenth National Conference on Artiﬁcial Intelligence and Eighth Innovative Applications of Artiﬁcial Intelligence Conference, AAAI 96, IAAI 96, Portland, Oregon, USA, August 4-8, 1996, Volume 2, pages 1050– 1055. AAAI Press / The MIT Press.
Luke Zettlemoyer and Michael Collins. 2005. Learning to map sentences to logical form: Structured classiﬁcation with probabilistic categorial grammars. In UAI ’05, Proceedings of the 21st Conference in Uncertainty in Artiﬁcial Intelligence, Edinburgh, Scotland, July 26-29, 2005, pages 658–666. AUAI Press.
Luowei Zhou, Yannis Kalantidis, Xinlei Chen, Jason J. Corso, and Marcus Rohrbach. 2019. Grounded video description. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019, pages 6578– 6587. Computer Vision Foundation / IEEE.
Yuke Zhu, Oliver Groth, Michael S. Bernstein, and Li Fei-Fei. 2016. Visual7w: Grounded question answering in images. In 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, Las Vegas, NV, USA, June 27-30, 2016, pages 4995–5004. IEEE Computer Society.

A Evaluation Details
A.1 Schema Linking
Let Ωcol be a set {(c, q)i|1 ≤ i ≤ N } which contains N gold (column-question token) tuples. Let Ωcol be a set {(c, q)j|1 ≤ j ≤ M } which contains M predicted (column-question token) tuples. We deﬁne the precision(ColP ), recall(ColR), F1score(ColF ) as:
|Γcol| , |Γcol| , 2ColP ColR Ωcol |Ωcol| ColP + ColR
where Γcol = Ωcol Ωcol. The deﬁnitions of TabP , TabR, TabF are similar. Note that the result reported in Table 8 of Shi et al. (2020) use a different evaluation metrics. Here we re-evaluate their model by the above mentioned metrics for fair comparison.
A.2 Entity Linking
Let Ω = {(e, [qs, qe])i|1 ≤ i ≤ N } be the gold entity-mention set and Ω = {(e, [qs, qe])j|1 ≤ j ≤ M } be the predicted entity-mention set, where e is the entity, qe, qs are the mention boundaries in the question q. In the weak matching setting, a prediction is correct only if the ground-truth entity is identiﬁed and the predicted mention boundaries overlap with the ground-truth boundaries. Therefore, the True-Positive prediction set is deﬁned as:
Γ = {e|(e, [qs, qe]) ∈ Ω, (e, [qs, qe]) ∈ Ω, [qs, qe] [qs, qe] = ∅}.
The corresponding precision(EntP ), recall(EntR) and F1(EntF ) are:
|Γ| , |Γ| , 2EntP EntR Ω |Ω| EntP + EntR
B Dataset Statistic
All details of datasets used in this paper are shown in Table 7.
C Implementation Details
For all experiments, we employ the AdamW optimizer and the default learning rate schedule strategy provided by Transformers library (Wolf et al., 2020).

C.1 Experiments on Grounding
SQUALL We use uncased BERT-base as the encoder. The learning rate is 3 × 10−5. The training epoch is 50 with a batch size of 16. The dropout rate and the threshold τ are set to 0.3 and 0.2 respectively. The training process lasts 6 hours on a single 16GB Tesla P100 GPU.
SPIDER-L We implement two versions: uncased BERT-base and uncased BERT-large. For both versions, the learning rate is 5 × 10−5 and the training epoch is 50. For BERT-base (BERT-large) version, the batch size and gradient accumulation step are set to 12 (6) and 6 (4). The dropout rate and the threshold τ are set to 0.3 and 0.2 respectively. As for training time, BERT-base (BERT-large) version is trained on a 24GB Tesla P40 and it takes about 16 (48) hours to ﬁnish the training process.
WebQSPEL& GraphQEL Due to the large amount of entity candidates, we ﬁrst use the candidate retrieval method proposed in (Sorokin and Gurevych, 2018) to reduce the number of candidates. After that, we still can not feed all candidates along with the question due to the maximum encoding length of BERT. Therefore, we divide the candidates into multiple chunks and feed each chunk (along with the question) into BERT sequentially.
In implementation, we use uncased BERT-base as the encoder. The learning rate is 1 × 10−5 The training epoch is 50 with a batch size of 16. The dropout rate and the threshold τ are set to 0.3 and 0.3 respectively. The training procedure ﬁnishes within 10 hours on a single Tesla M40 GPU.
C.2 Experiments on Text-to-SQL
For experiments of the text-to-SQL task, we employ the ofﬁcial code released along with Shi et al. (2020) (on WTQ) and Lei et al. (2020) (on Spider). When coupling ETA with these models, we ﬁrst produce a one-hot grounding matrix derived by grounding pairs and then feed it into them as described in §4.
WTQ We use uncased BERT-base as the encoder. The training epoch is 50 with a batch size of 8. The learning rate is 1 × 10−5 for the BERT module and 1 × 10−3 for other modules. The dropout rate is set to 0.2. The training process ﬁnishes within 16 hours on a single 16GB Tesla P100 GPU.
Meanwhile, we follow the previous work (Shi et al., 2020) to employ 5-fold cross-validation, and

Dataset
SQUALL SPIDER-L
WTQ Spider WebQSPEL GraphQEL

Train

#Q

#C

9, 030 7, 000 9, 030 7, 000 2, 974 2, 089

19, 185 28, 848
– – 3, 242 2, 253

Dev

#Q #C

2, 246 1, 034 2, 246 1, 034
– –

4, 774 4, 360
– – – –

Test

#Q #C

– – 4, 344 2, 147 1, 603 2, 075

– – – – 1, 806 2, 229

Table 7: Statistics for all datasets used in our experiments. For SQUALL and WTQ, we only show the size of Split-0, and details of other splits can be found in Table 8. #Q represents the number of questions, #C represents the number of concepts.

Split Train Dev
0 9, 030 2, 246 1 9, 032 2, 244 2 9, 028 2, 248 3 8, 945 2, 331 4 9, 069 2, 207
Table 8: The size of train set and dev set of ﬁve splits on SQUALL and WTQ.

D Latent Grounding Visualization
Figure 6 and Figure 7 show the latent grounding visualization corresponding to examples in Table 6.

Split Dev Test Ex.Match Ex.Acc Ex.Acc

0

45.10 64.43 53.57

1

47.39 67.01 54.17

2

47.24 65.93 53.61

3

45.99 65.72 53.41

4

52.38 69.73 52.41

Table 9: The experimental results of all splits on WTQ.

experimental results of all ﬁve splits on WTQ using ETA + BERT are shown in Table 9.
Spider We implement two versions: uncased BERT-base and uncased BERT-large. For BERTbase (BERT-large), the learning rate is 1.25 × 10−5 (6.25 × 10−6) for the BERT module and 1 × 10−4 (5 × 10−5) for other modules. The batch size and gradient accumulation step are set to 10 (6) and 5 (4) for BERT-base (BERT-large) version. The dropout rate is set to 0.3. As for training time, BERT-base (BERT-large) version is trained on a 24GB Tesla P40 and it takes about 36 (56) hours to ﬁnish the training process.

singer 0.00 0.01 0.00 0.02 0.00 0.00 0.00 0.00 0.97 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00

singer.name 0.01 0.37 0.05 0.19 0.00 0.00 0.00 0.00 0.36 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00

singer.country 0.00 0.02 0.04 0.89 0.00 0.01 0.00 0.00 0.03 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00

singer.age 0.00 0.00 0.00 0.00 0.00 0.31 0.00 0.00 0.01 0.00 0.00 0.35 0.00 0.00 0.22 0.00 0.00 0.10 0.00

show name , country ,

age for

all singersordered by age from the oldest to

the gest . youn

Figure 6: The latent grounding produced by ETA + BERTL for the question “Show name, country, age for all singers ordered by age from the oldest to the youngest.”.

semesters 0.00 0.00 0.88 0.00 0.00 0.00 0.00 0.05 0.01 0.02 0.00 0.00 0.01 0.00 0.00 0.00 0.01 0.01 0.00 student enrolment 0.00 0.00 0.04 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.07 0.87 0.00 semesters.semester id 0.01 0.02 0.39 0.01 0.01 0.01 0.01 0.05 0.06 0.30 0.02 0.02 0.05 0.01 0.00 0.00 0.01 0.03 0.00 semesters.semester name 0.00 0.01 0.73 0.00 0.00 0.00 0.01 0.14 0.02 0.05 0.00 0.01 0.01 0.00 0.00 0.00 0.00 0.00 0.00
for eachsemester , what is the name and id of the one with the moststudenrtesgistered ?
Figure 7: The latent grounding produced by ETA + BERTL for the question “For each semester, what is the name and id of the one with the most students registered?”.

