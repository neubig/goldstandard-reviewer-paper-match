arXiv:1412.5694v2 [cs.IT] 17 Feb 2015

Capacity-Approaching PhaseCode for Low-Complexity Compressive Phase Retrieval
Ramtin Pedarsani, Kangwook Lee, and Kannan Ramchandran Dept. of Electrical Engineering and Computer Sciences University of California, Berkeley {ramtin, kw1jjang, kannanr}@eecs.berkeley.edu
Abstract
In this paper, we tackle the general compressive phase retrieval problem. The problem is to recover (to within a global phase uncertainty) a K-sparse complex vector of length n, x ∈ Cn, from the magnitudes of m linear measurements, y = |Ax|, where A ∈ Cm×n can be designed, and the magnitudes are taken component-wise for vector Ax ∈ Cm. We propose a variant of the PhaseCode algorithm, ﬁrst introduced in [21], and show that, using an irregular left-degree sparse-graph code construction, the algorithm can recover almost all the K non-zero signal components using only slightly more than 4K measurements under some mild assumptions, with order-optimal time and memory complexity of O(K). It is known that the fundamental limit for the number of measurements in compressive phase retrieval problem is 4K − o(K) [6, 18]. To the best of our knowledge, this is the ﬁrst constructive capacity-approaching compressive phase retrieval algorithm: in fact, our algorithm is also order-optimal in complexity and memory.
As a second contribution of this paper, we propose another variant of the PhaseCode algorithm that is based on a Compressive Sensing framework involving sparse-graph codes. Our proposed algorithm is an instance of a more powerful “separation” architecture that can be used to address the compressive phase-retrieval problem in general. This modular design features a compressive sensing outer layer, and a trigonometric-based phase-retrieval inner layer. The compressive-sensing layer operates as a linear phase-aware compressive measurement subsystem, while the trig-based phase-retrieval layer provides the desired abstraction between the actually targeted nonlinear phase-retrieval problem and the induced linear compressive-sensing problem. Invoking this architecture based on the use of sparse-graph codes for the compressive sensing layer, we show that we can exactly recover a signal, to within a global phase, from only the magnitudes of its linear measurements using only slightly more than 6K measurements.
1 Introduction
The general compressive phase retrieval problem is to recover a K-sparse signal of length n, x ∈ Cn, to within a global phase uncertainty, from the magnitude of m linear measurements y = |Ax|, where A ∈ Cm×n is the measurement matrix that can be designed, and the magnitude is taken on each component of the vector Ax ∈ Cm.1 In many applications such as optics [16], X-ray crystallography [3,4], astronomy [5], ptychography [10], quantum optics [17], etc., the phase of the measurements is not available. Furthermore, in many applications the signal of interest is sparse in some domain. For example, compressive phase retrieval has been used in a recent work in quantum optics [17] to measure the transverse wavefunction of a photon.
1This can be easily extended to the case where the signal x is sparse with respect to some other basis, for example in Fourier domain, by a simple transformation of the measurement matrix.
1

The phase retrieval problem has been studied extensively in the literature. Here, we only provide a brief review of related works on compressive phase retrieval, and refer the readers to our earlier work [21] for a more extensive literature review.
To the best of our knowledge, the ﬁrst algorithm for compressive phase retrieval was proposed by Moravec et al. in [7]. This approach requires knowledge of the 1 norm of the signal, making it impractical in most scenarios. The authors in [18] showed that 4K − 1 measurements are theoretically sufﬁcient to reconstruct the signal, but did not propose any low-complexity algorithm for reconstruction. The “PhaseLift” method originally proposed for the non-sparse case [8], is also used for the sparse case in [13] and [14], requiring O(K2 log(n)) intensity measurements, and having a computational complexity of O(n3), making the method less practical for large-scale applications. An alternating minimization method is proposed in [15] for the sparse case with O(K2 log(n)) measurements and a computation complexity of O(K3n log(n)). Compressive phase-retrieval via generalized approximate message passing (PR-GAMP) is proposed in [9], with good performance in both runtime and noise robustness shown via simulations. Jaganathan et al. consider the phase retrieval problem from Fourier measurements [11, 12]. They propose an SDP-based algorithm, and show that the signal can be provably recovered with O(K2 log(n)) Fourier measurements [11]. Cai et al. propose proposed SUPER algorithm for compressive phase-retrieval in [1]. The SUPER algorithm uses O(K) measurements and features O(K log(K)) complexity with zero error ﬂoor asymptotically. Recently, Yapar et al. propose a fast compressive phase retrieval algorithm using 4K log(n/K) random Fourier measurements based on an algebraic phase retrieval stage and a compressive sensing step subsequent to it [20].
1.1 Main Contribution
The main contribution of this paper is to propose two variants of PhaseCode algorithm, which was ﬁrst introduced in [21]. The measurement matrix in PhaseCode algorithm is constructed based on a sparsegraph code. The work of [21], which features a regular left-degree distribution in its sparse-graph code design, establishes that, with high probability, all but a fraction 10−7 (error ﬂoor) of the non-zero signal components can be recovered using about 14K measurements with optimal time and memory complexity.
In this work, we ﬁrst consider an irregular left-degree distribution for the sparse-graph code construction. We show that under this construction, the PhaseCode algorithm can recover almost all the non-zero components of the signal using only slightly more than 4K measurements under some mild assumptions, with optimal time and memory complexity of O(K). It is well-known that 4K − o(K) measurements is the fundamental limit for unique recovery of K-sparse signal x [6, 18]. This shows that the irregular PhaseCode algorithm is capacity-approaching. We note a few caveats, which are why we call our algorithm capacity-approaching. First, our irregular PhaseCode has an arbitrarily small error ﬂoor, which is however still non-vanishing as K goes to inﬁnity. Secondly, in order to prove that the algorithm can exactly recover x, we need to make some mild assumptions on x.
Second, we propose a different two-layer PhaseCode algorithm: a compressive sensing layer and a phase retrieval layer.2 Our proposed algorithm is an instance of a more powerful “separation” architecture that can be used to address the compressive phase-retrieval problem in general. This modular design features a compressive sensing outer layer, and a trigonometric-based phase-retrieval inner layer. The compressivesensing layer operates as a linear phase-aware compressive measurement subsystem, while the trig-based phase-retrieval layer provides the desired abstraction between the targeted nonlinear phase-retrieval problem and the induced linear compressive-sensing problem. In the compressive sensing layer of the algorithm, we use the recent sparse-graph code based framework of [22], to design only m1 2K measurements that
2While we were writing this paper, we became aware that a similar approach was used in [20] in a contemporaneous work. Although the high-level modularity concepts are similar, the proposed algorithms are signiﬁcantly different. Principally, our measurement matrix is designed using sparse-graph codes, making our algorithm distinct from that of [20].
2

guarantee perfect recovery for the compressive sensing problem, and in the phase-retrieval layer of the algorithm, we use 3m1 − 2 deterministic measurements proposed in [21] that recover the phase of the m1 measurements in phase and magnitude. Thus, we show that the signal can be reconstructed perfectly using only slightly more than 6K measurements.
2 Problem deﬁnition
Consider a K-sparse complex signal x ∈ Cn of length n. Deﬁne A ∈ Cm×n to be the measurement matrix that needs to be designed. The phase retrieval problem is to recover the signal x from magnitude of linear measurements yi = |aix|, where ai is the i-th row of matrix A. Figure 1 illustrates the block diagram of our problem.

x input A
signal

y = |Ax|

|.|

Decoder

xˆ

estimated

magnitude

signal

measurements

Figure 1: Block diagram of the general compressive phase retrieval problem. The measurements are yi = |aix|, where ai is the i-th row of measurement matrix A. The objective is to design measurement matrix A and the decoding algorithm to guarantee high reliability, while having small sample complexity as well as small time and memory complexity.

The main objectives of the general compressive phase retrieval problem are to design matrix A, and the decoding algorithm to recover x, that satisfy the following objectives.
• The number of measurements m is as small as possible. Ideally, one wants m to be close to the fundamental limit of 4K − o(K) [6, 18].
• The decoding algorithm is fast with low computational complexity and memory requirements. Ideally, one wants the time complexity and the memory complexity of the algorithm to be O(K), which is optimal.
• The reliability of the recovery algorithm should be maximized. Ideally, one wants the probability of failure to be vanishing as the problem parameters K and m get large.

3 PhaseCode based on irregular left-degree sparse-graph codes

We consider the same architecture used in [21] to design our measurement matrix, A. We deﬁne A ∈ CpM×n

to be a row tensor product of a trigonometric modulation matrix, T ∈ Cp×n, and a code matrix, H ∈ CM×n.

The

row

tensor

product

of

matrices

T

and

H

is

deﬁned

as

follows.

If

A

=

T

⊗

H

=

[

AT1

,

AT2

,

.

.

.

,

A

T M

]

T

and Ai ∈ Cp×n, then, Ai(jk) = TjkHik, 1 ≤ j ≤ p, 1 ≤ k ≤ n. As an example, the row tensor product of

matrices

0.1 0.2 0.3

0 1 0

T = 0.4 0.5 0.6 and H =  1 1 0 

001

3

1

2

1

1

2

..
2

..

M

K

n

Figure 2: Illustration of a bipartite graph representation of the compressive phase-retrieval problem. In this graph, each left node refers to a signal component and each right node refers to a set of (four) measurements. The signal is K-sparse, so K of these left nodes are active as illustrated in the ﬁgure. The four measurements associated with each right node correspond to the trigonometric-based modulation measurements of Equation (1).

is  0 0.2 0 

 0 0.5 0 

A

=

T

⊗

H

=

 

0.1

0.2

0

 .

 

0.4

0.5

0

 

 

0

0

0.3

 

0 0 0.6

Our trigonometric modulation matrix is the same as the one we proposed in [21]; that is,

 eiω

ei2ω . . . einω 

T =  e−iω e−i2ω . . . e−inω  ,

(1)

 

cos(ω)

cos(2ω)

...

cos(nω)

 

eiω

ei2ω . . . einω

where ω = 2nπ and ω is a random phase uniformly distributed in [0, 2π). Now we recall the key idea of the PhaseCode algorithm.3 For more details, we refer the readers to [21].
The architecture of the PhaseCode algorithm is as follows. We consider a bipartite graph of n left nodes and M right nodes, where each left node is a signal component and each right node is a set of 4 measurements. One can think of the n left nodes as n slots in which K balls will be thrown arbitrarily. The n slots refer to the indices of the n-length signal, and the K balls refer to the K non-zero components of the signal. See Figure 2 as an illustration. Our goal is to design the bipartite graph such that the K locations (belonging to the integer set between 1 and n) of these balls (non-zero components) are detected. Furthermore, the relative phase and magnitude of the non-zero components need to be detected with the aid of the trigonometric modulation matrix. (See Subsection 3.1 and [21] for details.)
In order to explain our design for the phase-retrieval problem, it is illustrative for us to consider an equivalent ball-coloring problem in the following sense. The goal of this equivalent problem is to detect and color all the balls in the system, where we say that a ball is colored if it is detected that it corresponds to an active signal component in that slot, and it is recovered in magnitude and phase (upto a global phase). Thus,
3In this paper, we consider only the Unicolor PhaseCode algorithm proposed in [21].

4

→
Figure 3: This ﬁgure illustrates when a bin contains one or more colored balls and exactly one uncolored ball, then the uncolored ball gets colored.
when balls get colored, their locations and complex-amplitudes are detected, where we may think of the color as the global coordinate-system on which we describe the unknown signal components. Thus, the ballcoloring problem is equivalent to the targeted phase-retrieval problem. However, the rules needed to color these balls are not yet clear, and need to be speciﬁed. This is where our carefully-designed trignometricmodulated measurements of Eq. (1) come in. Concretely, in our proposed construction, these trig-modulated measurements are used to enforce the following coloring rule. If a right node of the bipartite graph is connected to n ≥ 2 balls and n − 1 of those balls are colored, the single uncolored ball can get colored. See Figure 3 as an illustration. What this means for our targeted phase-retrieval problem is that if we have already uncovered the locations and complex amplitudes (including phase) of n − 1 of the n signal components corresponding to a right node, then the trig-modulated measurements can be used to uncover the lone missing signal component; i.e., it too can be colored. Of course, at the outset of the algorithm, no balls are colored. Therefore, the algorithm requires an initial seeding phase which will jumpstart the process by ensuring that a few balls get colored. (We will show how this can be realized in Subsection 3.2.) Given that in the initial phase of the algorithm, there are only a few colored balls in the graph, the goal is to design a bipartite graph such that the coloring spreads like an epidemic until all the balls get colored. Given this exact equivalence to our original phase-retrieval problem, in the interests of illustrative clarity, from now on, we mainly focus on the ball coloring problem, and connect it back to the phase retrieval problem in Subsection 3.1.
As mentioned earlier, we design our code matrix based on a random bipartite graph model. Deﬁne ρi to be the probability that a randomly selected edge is connected to a right node of degree i, and λi to be the probability that a randomly selected edge is connected to a left node of degree i. Deﬁne the edge degree distributions or edge degree polynomials of right and left nodes as follows.
ρ(x) = ρixi−1;
i≥1
λ(x) = λixi−1.
i≥1
To analyze the PhaseCode algorithm, we use density evolution, which is a technique to analyze the performance of message passing algorithms on sparse-graph codes. We ﬁnd a recursion relating the probability that a randomly chosen ball or left node in the graph is not colored after j iterations of the algorithm, pj, to the same probability after j + 1 iterations of the algorithm, pj+1. Our analysis methodology is similar to that of [21] with the distinction that we now consider a different left-degree distribution. We ﬁrst use a tree-like assumption of the graph (i.e. the graph is free from cycles) and undertake a mean analysis using density evolution. Then, we relax the tree-like assumption, as well as ﬁnd concentration bounds to show that the
5

c pj+1
v
pj

Figure 4: Illustration of message passing algorithm and density evolution equation.

actual performance concentrates around the mean. Details follow. First, under the tree-like assumption of

the graph, one has

pj+1 = λ(1 + ρ1 − ρ(1 − pj)).

(2)

Here is a proof of Equation (2). A right node (bin) passes a message to a left node (ball) that the left node can be colored if all of its neighbors are colored. This happens with probability

∞
ρi(1 − pj)i−1 = ρ(1 − pj) − ρ1
i=2

Thus, the probability that ball v passes a message to bin c that it is not colored in iteration j + 1, is the probability that none of its other neighbor bins can tell v that it is colored in iteration j. See Figure 4 for an illustration. These messages are all independent if the bipartite graph is a tree. Assuming this, one has

pj+1 = λi[1 − (ρ(1 − pj) − ρ1)]i−1

i≥1

= λ(1 + ρ1 − ρ(1 − pj)).

(3)

Recall that our goal is to design a bipartite graph such that all the balls get colored with as few measurements as possible. The way that we design the bipartite graph is to connect the left nodes to right nodes uniformly at random according to some distribution. Then, for large K and M , the induced right node degree distribution is Poisson with parameter η = KMd¯, where d¯is the average degree of left nodes. Thus,

iM

i ηie−η ηi−1e−η

ρi = Kd¯P(random right node has degree i) = η i! = (i − 1)! .

Then,

ρ(x) = ηi−1e−η xi−1 = ηie−η xi = e−ηeηx = e−η(1−x).

(4)

i≥1 (i − 1)!

i≥0 i!

6

f(p) pj

1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1
0 0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
p

(a) The density evolution curve for parameters K = 105, = 0.3 and D = 103.

1
0.8
0.6
0.4
0.2
1 00 5 10 15 20 25 30 35
j
(b) The evolution of pj after each iteration for parameters K = 105, = 0.3 and D = 103.

Figure 5: Figure (a) illustrates the density evolution equation: pj+1 = f (pj). In order to track the evolution of pj, pictorially, one draws a vertical line from (pj, pj) to (pj, f (pj)), and then a horizontal line between (pj, f (pj)) and (f (pj), f (pj)). Since the two curves meet at (1, 1) if p0 = 1, then pj gets stuck at 1. However, if p0 = 1 − δ, for some δ > 0, pj decreases after each iteration, and it gets very close to 0 in ﬁnite number of iterations. Figure (b) illustrates the same phenomenon by showing the evolution of pj versus the iteration, j. Note that in this example, since = 0.3 and we are operating further away from the capacity, pj gets very close to 0 after only 25 iterations.

We design the left degree distribution λ(x) based on a truncated harmonic distribution as follows. Let

h(x) =

x i=1

1/i.

Then,

λi = 1 × 1 , 2 ≤ i ≤ D,

(5)

i − 1 h(D − 1)

where D is a (large) constant.

We design the number of right nodes to be M = K/(1 − ) K(1 + ). How to choose constants D and will be shortly clariﬁed in Lemma 3.2. The average degree of left nodes is d¯ = i1λi/i [19]. To see this, let E be the number of edges of the graph. Then, the number of left nodes of degree i is Eλi/i since

λi is the fraction of edges with degree i on the left. Thus, the number of left nodes is i Eλi/i. So the

average left degree is

d¯ = E = 1 .

i Eλi/i

i λi/i

Thus, with our design,

D
d¯ = (

λi )−1 = h(D − 1)

D

.

i=2 i

D−1

Consequently, the Poisson density parameter of the right-node degree distribution is:

K d¯

D

η = M = h(D − 1)D − 1 (1 − ).

Lemma 3.1. Let f (x) = λ(1 + e−η − e−ηx). The ﬁxed point equation x = f (x) has exactly two solutions, x∗1 = 1 and 0 < x∗2 < 1, in the interval x ∈ [0, 1]. Furthermore, if f (1) > 1, then f (x) < x for x ∈ (x∗2, 1).
Proof. First note that it is easy to prove the lemma for speciﬁc parameters by plotting the function. See for example Figure 6a. To formally show it, note that f (1) = 1 is one solution of the ﬁxed point equation, since

7

f(p) pj

1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1
0 0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
p

(a) The density evolution curve for parameters K = 105, = 0.1 and D = 103.

1

0.8

0.6

0.4

0.2

0

1

0

10 20 30 40 50 60 70 80 90

j

(b) The evolution of pj after each iteration for parameters K = 105, = 0.1
and D = 103.

Figure 6: Figure (a) illustrates the density evolution equation similar to Figure 6a. Figure (b) illustrates the same phenomenon shows the evolution of pj versus the iteration, j. Note that in this example, since = 0.1 and we are operating very close to the capacity, pj gets very close to 0 after around 90 iterations. The reason is that the gap between the two curves in (a) gets smaller as gets smaller.

λ(1) = 1. Also f (0) = λ(e−η) > 0. Thus, by continuity of f (x) and using the assumption that f (1) > 1, there is another ﬁxed point x∗2. Now since f (1) > 1, f (x) < x for x close to 1. In order to show that f (x) < x for all x ∈ (x∗2, 1), it is enough to show that f (x) − 1 = 0 has only one solution in x ∈ (0, 1). To this end, see that
f (x) = ηe−ηxλ (1 + e−η − e−ηx).
For ease of notation, let y = 1 + e−η − e−ηx and y ∈ (e−η, 1). Equivalently, we want to show that

C(1 + e−η − y)(1 + y + y2 + . . . + yD−2) = 1

has only one solution where C = η/h(D − 1). This is easy to see since D is large so y 1−C1−−CCe−η .
As shown in Lemma 3.1, given that f (1) > 1, the density evolution has a ﬁxed point at 1. The other ﬁxed point of the equation is approximately p∗ λ(e−η), which corresponds to the error ﬂoor of the algorithm. The intuition behind this is as follows. Assuming that one can get away from ﬁxed point 1 to 1 − δ for some small δ > 0, after a few iterations pj gets very close to p∗ as shown in Figures 6 and 5. However, pj cannot get smaller than p∗, so p∗ is the error ﬂoor of the algorithm. In the following lemma, we show that for any arbitrarily small numbers p∗ and , there exists a large enough constant D(p∗, ) such that f (1) > 1. This shows that with only 4M = 4K/(1 − ) 4K(1 + ) measurements, irregular PhaseCode
algorithm can recover almost all the non-zero signal components. So given that the coloring procedure starts (the density evolution equation can be started from 1 − δ), irregular PhaseCode is capacity-approaching.

Lemma 3.2. For any p∗ > 0 and any > 0, there exists a large enough constant D( , p∗) such that M = K(1 − )−1 K(1 + ) is the number of right nodes (bins), and pj converges to p∗ as j goes to inﬁnity, given that p1 = 1 − δ.

Proof. We show that if

D = max{( e )2/ , (1 + 1 )1/(1− )},

(6)

1−

p∗

8

then,

f (1) = ηe−η λi(i − 1) > 1,

(7)

i≥1

and the error ﬂoor which is approximately λ(e−η) is at most p∗; that is,

λie−η(i−1) ≤ p∗.

(8)

i≥1

This shows that in the density evolution equation, pj converges to p∗ as j goes to inﬁnity. This is illustrated

in Figure 5.

Recall that

D
d¯ = (

λi )−1 = h(D − 1)

D

.

i=2 i

D−1

Thus, since M = K/(1 − ),

K d¯

D

η = M = h(D − 1)D − 1 (1 − ).

First, we show that (8) in the following.

D −η(i−1)

1

D 1 −η(i−1)

λie

= h(D − 1) i − 1 e

i=2

i=2

≤1

∞
e−ηi

h(D − 1) i=1

e−η = h(D − 1)(1 − e−η) .

It is enough to show that h(D − 1)(eη − 1) ≥ p1∗ . We have

h(D − 1)(eη − 1) ≥ eη − 1

≥

elog

(D

).

D D−1

(1−

)

−

1

≥ D1− − 1

≥ 1, p∗

where the last inequality is due to (6). Second, we show that (7) is satisﬁed in the following.

ηe−η D µi(i − 1) = ηe−η h(DD−−11) (9) i=2

= D(1 − )e−h(D−1) DD−1 (1− )

(10)

≥ D(1 − )e−(1+log(D)) DD−1 (1− )

(11)

= 1 − D DD−−11

(12)

e

≥ 1 − D /2

(13)

e

≥ 1,

(14)

9

where (13) is due to (6) since D ≥ ( 1−e )2/ ≥ 2 implies that DD−−11 ≥ 2 , and (14) is due to (6). This shows that pj, j ≥ 1 is a strictly decreasing sequence which is lower bounded by p∗. Thus, pj → p∗ as j → ∞. This completes the proof.

Corollary 3.3. Given that p1 = 1 − δ, for any 1 > 0, there exists a constant ( 1) such that p ≤ p∗ + 1.

Proof. It is sufﬁcient to show that after each iteration, pj decreases by a constant amount, that is a function of 1. Let q( 1) = arg minp∈[p∗+ 1,1−δ] p−f (p). Let γ( ) = pm −f (pm), which is a strictly positive constant. Then,
pj+1 − pj = f (pj) − pj ≤ −γ.
Therefore, it takes at most ( 1) = 1−γp∗ < γ1 iterations so that p ≤ p∗ + 1.

In the density evolution analysis so far, we have shown that the average fraction of balls that remain
uncolored will be arbitrarily close to the error ﬂoor after a ﬁxed number of iterations, provided that the
tree-like assumption is valid. It remains to show that the actual fraction of balls that are not in the giant component after iterations is highly concentrated around p . Since the maximum degree of left nodes are again a constant D, the exact procedure used in [21] to get a concentration bound can be also applied here.
Towards this end, ﬁrst we show that a neighborhood of depth of a typical edge is a tree with high probability for a constant in Lemma 3.4.4 Second, in Lemma 3.5, we use the standard Doob’s martingale argument [2],
to show that the number of uncolored balls after iterations of the algorithm is highly concentrated around Kp . We refer the readers to [21] for the proofs.
Consider a directed edge from e = (v, c) from a left-node (ball) v to a right-node (bin) c. Deﬁne the directed neighborhood of depth of (e) as Ne , that is the subgraph of all the edges and nodes on paths having length less than or equal to , that start from v and the ﬁrst edge of the path is not e.

Lemma 3.4. For a ﬁxed ∗, Ne2 ∗ is a tree-like neighborhood with probability at least 1 − O(log(K) ∗/K).

Lemma 3.5. Let Z be the number of uncolored edges5 after iterations of the PhaseCode algorithm. Then, for any 2 > 0, there exists a large enough K and a constant β such that

|E[Z] − Kd¯p | < Kd¯ 2/2

(15)

P(|Z − Kd¯p | > Kd¯ ) < 2e−β 22K1/(4 , +1)

(16)

where p is derived from the density evolution equation (2).

3.1 Trigonometric-Based Modulation

In this section, we will explain the choice of the trig-modulation T , and how T enables us to detect the non-

zero signal components and recover them in magnitude and phase (up to a global phase). We will provide a

brief explanation here, while referring the readers to [21] for thorough analysis.

Deﬁne the length 4 vector yi to be the measurement vector corresponding to the i-th row of matrix H

for

1

≤

i

≤

M.

Then

y

=

[

y

T 1

,

y2T

,

.

.

.

,

y

T M

]T

,

where

yi

=

[yi,1, yi,2, yi,3, yi,4]T .

Let

ω

=

2πn .

Recall

from

Equation (1) that we design the measurement matrix T = [tj ] as follows. For all , 1 ≤ ≤ n,

t1 = eiω , t2 = e−iω , t3 = 2 cos(ω ), t4 = eiω .

4The depth- neighborhood of edge (v, c) is the subgraph of all the edges and nodes of paths having length less than or equal
to , that start from v and the ﬁrst edge of the path is not (v, c). 5An edge is colored if its corresponding ball is colored.

10

This measurement matrix enables the algorithm to detect a left node (bin) that is connected to some colored balls and only one uncolored ball. Furthermore, the measurements enable the algorithm to ﬁnd the index of uncolored ball, and recover the corresponding non-zero signal component in magnitude and phase relative to the known (colored) components.
Consider a bin, let’s say bin i, for which we know that it is connected to some colored balls. We want to check if bin i is connected to exactly one other uncolored ball; i.e. one unknown non-zero component of x, say x , as in Figure 3. We now describe a guess and check strategy to check our guess, and to ﬁnd and x if the guess is correct. If our guess is correct, we have access to measurements of the form:

yi,1 = |a + eiω x |,

(17)

yi,2 = |b + e−iω x |,

(18)

yi,3 = |c + 2 cos(ω )x |,

(19)

yi,4 = |d + eiω x |,

(20)

where complex numbers a, b, c and d are known values that depend on the values and locations of the known colored balls. We want to solve the ﬁrst 3 equations (17)-(19) to ﬁnd and x , and use (20) to check if our guess is correct. We skip the algebra here, and refer the readers to [21] for details of how this can be done. We emphasize that one can solve the ﬁrst 3 equations to ﬁnd (at most) 4 possible solutions for x and in closed-form. Whether one of those possible solutions is admissible or not can be checked using the 4-th equation (20). Since ω is a random phase, the probability that the check equation declares admissible solution while the solution is not valid is 0.
3.2 How to initialize the ball-coloring algorithm?
We have so far assumed that an arbitrarily small fraction δ > 0 of the balls are colored in the initial phase. That is, a positive fraction of non-zero signal components are detected. In this subsection, we propose two methods for initializing the coloring algorithm. The ﬁrst method is based on having an active sensing stage. In active sensing, the measurements can be adaptive and are functions of the previous observations. The second method assumes that the locations6 of a small fraction of non-zero components of the signal are known. Note that this is the case for most practical scenarios. For example, almost all sparse images in the Fourier domain have non-zero low band components. In both methods, we make essential use of the deterministic measurements for non-sparse phase retrieval introduced in [21].
In the ﬁrst method, as mentioned, we ﬁrst try to ﬁnd the location of a positive fraction of non-zero components. Consider the following 3 2K measurements7 for some small 2 > 0:

y˜ = |T1 ⊗ H1x|,

where

1

1 ... 1 

T1 =  eiω

ei2ω . . . einω  ∈ C3×n,

(21)

cos(ω) cos(2ω) . . . cos(nω)

and H1 ∈ {0, 1} 2K×n is a code matrix, and is constructed as follows. Each column of H1 has exactly one entry that is equal to 1, and the location of this entry is random. Equivalently, we consider a random bipartite
graph model in which left nodes (which refer to signal components) are columns of H1 and right nodes (which refer to measurements) are rows of H1. Let y˜ = [y˜1T , y˜2T , . . . , y˜MT 1]T , where y˜i = [y˜i,1, y˜i,2, y˜i,3]T .

6Note that we assume only location knowledge of a tiny fraction of the active signal components, but no knowledge about the
magnitude or phase of these components. 7Without loss of generality suppose that 2K is an integer.

11

Deﬁne a singleton right node to be a right node that is connected to exactly 1 left nodes with non-zero signal component. Now we show that if a right node is a singleton, the location and magnitude of the non-zero component can be found using ratio test. To this end, suppose that
y˜i,1 = |x | y˜i,2 = |ei ωx | y˜i,3 = | cos( ω)x |.
The fact that yy˜˜ii,,21 = 1 reveals that the i-th right node is a singleton. The magnitude of the non-zero component is y˜i,1. Furthermore, the location of the non-zero component can be found using = cos−1(y˜i,3/x ). It is easy to see that the number of active components that can be found in location and magnitude approaches
K Pr(left node is connected to singleton = K(1 − 1 )K = Ke−1/ 2 = Kδ, 2K
where δ = e−1/ 2 > 0 is a constant. In order to recover the phases of these non-zero components, we use deterministic measurements as follows. Let δK = K1. Without loss of generality and for ease of notation assume that the detected non-zero components are x1, x2, . . . , xK1. We use 2K1 − 2 measurements to get |x1 + x | and |x1 + ix | for 2 ≤ ≤ K1 − 1. Then, one can easily ﬁnd the relative angle between x and x1. Therefore, a positive fraction δ of the active signal components can be found in location, phase and magnitude, and their corresponding balls can be colored. This ensures that the ball-coloring algorithm is initialized and it recovers almost all the signal components. Moreover, the number of extra measurements that we use in the active sensing stage is only (3 2 + 2δ)K, and (3 2 + 2δ) > 0 is a constant which can be made arbitrarily small. Thus, the total number of measurements that PhaseCode uses is still 4(1 + )K for arbitrarily small constant > 0.
The second method assumes that the location of a small fraction δ of active signal components is known, e.g. the low band components of an image in Fourier domain. Given this, one can use exactly the same procedure described in the ﬁrst method to recover these components with 3δK − 2 measurements. Again let K1 = δK. Without loss of generality and for ease of notation assume that the known non-zero components are x1, x2, . . . , xK1. Then the following measurements recover all the components using some simple algebra up to a global phase as described in [21]: |x |, 1 ≤ ≤ K1, |x1 + x |, 2 ≤ ≤ K1, and |x1 + ix |, 2 ≤ ≤ K1.
4 Two-Layer PhaseCode based on compressive sensing
and trig-measuremen-based phase-retrieval
In this section, we propose a “separation-principle” based two-layered approach to the compressive phase retrieval problem: a compressive-sensing outer layer and a deterministic trigonometric-measurement-based phase-retrieval inner layer. A block diagram of our layered modular approach is shown in Figure 7. As alluded to earlier, a similar high-level approach has been independently proposed in recent work [20]. Although our works shares similarities in the high-level layering concepts, the proposed algorithms are signiﬁcantly different. Principally, our measurement matrix is designed using sparse-graph codes, making our algorithm distinct from and more efﬁcent than that of [20].
Before we describe the technical details, let us overview the high-level proposed architecture. In our two-layered design, the compressive-sensing layer operates as a linear phase-aware compressive measurement subsystem, while the trig-based phase-retrieval layer provides the desired abstraction between the targeted nonlinear phase-retrieval problem and the induced linear compressive-sensing problem. In our compressive sensing layer, we use the recent sparse-graph code based framework of [22], to design only
12

xC zB

|.| y = |Bz| Phase Retrieval

CS xˆ
Decoder

Figure 7: Block diagram of two-stage compressive phase retrieval. In this modular approach, the measurement matrix is the product of two matrices, C and B. Matrix C is an arbitrary compressive sensing (CS) matrix such that the CS decoder can recover signal x from measurements z = Cx. matrix B is a phase retrieval matrix that enables the algorithm to recover z from the magnitude of linear measurements y = |Bz|.

m1 2K measurements that guarantee perfect recovery for the compressive sensing problem, and in the phase-retrieval layer of the algorithm, we use 3m1 − 2 deterministic measurements proposed in [21] that recover the phase of the m1 measurements in phase and magnitude. Thus, we show that the signal can be reconstructed perfectly using only slightly more than 6K measurements. Details follow.

Proposition 4.1. (Modular approach for compressive phase retrieval) Let C ∈ Cm1×n be a measurement matrix such that one can recover a K-sparse signal, x ∈ Cn, from m1 noiseless linear measurements, z = Cx ∈ Cm1, using a decoding algorithm of a certain computational complexity. Assume that z1 is non-zero. Then, one can recover a K-sparse signal x from (3m1 − 2) magnitude of linear measurements, y = |BCx| = |Bz|, using a modiﬁed decoding algorithm of the same computational complexity, where

B = [B1T , B2T , B3T ] ∈ C(3m1−2)×m1 , B1 = Im1×m1 ,

 1 1 0 ...

0

1 0 1  B2 =  1 0 0   

0 ... 0 



1 . . . 0  ∈ C(m1−1)×m1, and

...

 



1 0 ...

01

 1 i 0 ...

0

1 0 i  B3 =  1 0 0   

0 ... 0 



i . . . 0  ∈ C(m1−1)×m1 .

...

 



1 0 ...

0i

Proof. Since |z1| = 0, one can retrieve the phase of z for all up to a global phase using measurements y1 = |z1|, y = |z |, ym1+ −1 = |z1 + z | and y2m1+ −2 = |z1 + iz | for ≥ 2 as follows. Let z = |z |eiφ.
Then, by the cosine law we have

|z1 + z |2 − |z1|2 − |z |2

cos(φ) =

2|z z |

= α.

1

Assuming that cos−1(α) for −1 ≤ α ≤ 1 returns values between 0 and π, we have φ = ± cos−1(α). Thus, we need to resolve the ambiguity of the sign. This ambiguity can be resolved using the other measurement: |z1 + iz |.
Thus, z is recovered up to a global phase, and one can decode x up to a global phase from it using the decoding algorithm for linear measurements.

13

Note that the proposed approach is highly ﬂexible due to its modularity: one can choose any compressive measurement matrix C that possesses suitable properties that are speciﬁc to applications.
Recently in [22], it is shown that a K-sparse signal, x ∈ Cn, can be perfectly recovered with high probability using only m1 = 2K(1+ ) noiseless linear measurements. The measurement matrix is designed based on irregular left-degree sparse-graph codes. Using this compressive measurement scheme alongside Proposition 4.1, we provide an efﬁcient compressive phase retrieval scheme.
Corollary 4.2. For arbitrarily small > 0, with high probability, one can perfectly recover a K-sparse signal with magnitude of 6K(1 + ) − 2 linear measurements and optimal complexity O(K).
5 Conclusion

Average fraction of non-detected support

1 K=100 K=500 K=1000
0.8 KK==510000000
0.6

0.4

0.2

0

1

1.2

1.4

1.6

1.8

2

M/K, Ratio of bins to balls

Figure 8: Performance of irregular PhaseCode without initialization phase: We simulate the ball-coloring algorithm without any initialization phase and varying the ratio of the number of right nodes in the graph (bins) to the number of non-zero signal components (balls), M/K. We consider several values of K from 100 to 10000, and ﬁx the length of the signal as n = 20000. The plotted simulation results show a clear trend: as K increases, the sample complexity required to decode successfully decreases and it approaches the capacity that is M/K = 1. For instance, when K = 10000, the coloring algorithm successfully decodes all symbols but a small fraction ( ≤ 0.005) when M/K = 1.3.
In this paper, we have considered the problem of recovering a K-sparse complex signal x ∈ Cn from m intensity measurements of the form |aix|, 1 ≤ i ≤ m, where ai is a measurement row vector. It is well-known that the minimum number of measurements to perfectly recover the signal is 4K − o(K) for compressive phase retrieval. We have proposed an irregular-left-degree PhaseCode algorithm that can recover the signal almost perfectly using only 4K(1 + ) measurements for arbitrarily small with high probability as K gets large under some mild assumptions. In order to initialize our algorithm, we rely on either an active sensing phase with K measurements, or we assume that the locations of an arbitrarily small fraction of the non-zero components are known, which is very reasonable in many applications of interest, e.g. in the case of natural objects like images, we know that low-frequency bands are active.

14

We have also proposed another variant of PhaseCode algorithm that is based on a separation architecture involving compressive sensing using sparse-graph codes. The measurement matrix of this algorithm is a concatenation of deterministic measurements that are used to recover the phase of the measurements required for compressive sensing, and measurements based on sparse-graph codes for compressive sensing which are now phase-aware. We have shown that the signal can be reconstructed perfectly using only slightly more than 6K measurements.
We conclude the paper by emphasizing an empirical observation that is useful for practical applications. In Section 3.2, we explained how one can initialize the coloring algorithm by means of feedback or prior knowledge about a few non-zero components of the signal. In our previous work [21], we showed that a linear-size component of colored balls can be formed with around 14K measurements (which is far from the fundamental limit 4K) in the regular construction without using feedback or any prior knowledge about the signal. However, via simulations, we empirically observe that our coloring algorithm can be used even without the initialization stage for irregular PhaseCode. We simulate irregular PhaseCode without any initialization stage with the following parameters. We vary K from 100 to 10000, and ﬁx the length of signal as n = 20000. We observe that even without the initialization stage, the coloring algorithm successfully recovers the signal with a sample complexity that is close to the fundamental limit. For example, when K = 10000, the coloring algorithm successfully decodes the signal with only 4 × 1.3K = 5.2K measurements. An interesting future direction is to theoretically investigate whether irregular PhaseCode without initializing is also capacity-approaching. Finally, in this work, we have focused on the noiseless compressive phase-retrieval problem, predominantly to elucidate our sparse-graph based capacity-approaching construction. Of course, in most practical settings, one needs to consider noisy observations. Our proposed framework can indeed be extended to be robust to noise, and this will be part of our future dissemination.
References
[1] S. Cai, M. Bakshi, S. Jaggi, and M. Chen, “SUPER: Sparse signals with Unknown Phases Efﬁciently Recovered,” arXiv preprint arXiv:1401.4451, 2014.
[2] T. Richardson and R. Urbanke, “The Capacity of Low-Density Parity-Check Codes Under MessagePassing Decoding” IEEE Transactions on Information Theory, vol. 47, pp. 599–618, Feb. 2001.
[3] R. P. Milane, “Phase retrieval in crystallography and optics,” J. Opt. Soc. Am. A, vol. 7, pp. 394–411, 1990.
[4] R. W. Harrison “Phase problem in crystallography,” JOSA A, vol. 10, pp. 1046–1055, 1993.
[5] J. C. Dainty and J. R. Fienup, “Phase retrieval and image reconstruction for astronomy,” Image Recovery: Theory and Application, Academic Press, pp. 231–275, 1987.
[6] T. Heinosaari, L. Mazzarella, and M. M. Wolf, “Quantum tomography under prior information,” Communication in Mathematical Physics, vol. 318, no. 2, pp. 355–374, 2013.
[7] M. L. Moravec, J. K. Romberg, and R. Baraniuk, “Compressive phase retrieval,” in SPIE Conf. Series, vol. 6701, 2007.
[8] E. J. Candes, T. Strohmer, and V. Voroninski, “Phaselift: Exact and stable signal recovery from magnitude measurements via convex programming,” Communications on Pure and Applied Mathematics, vol. 66, no. 8, pp. 1241–1274, 2013.
[9] P. Schniter and S. Rangan, “Compressive phase retrieval via generalized approximate message passing,” Proceedings of Allerton Conference on Communication, Control, and Computing, 2012.
15

[10] J. M. Rodenburg, “Ptychography and related diffractive imaging methods,” Advances in Imaging and Electron Physics, vol. 150, pp. 87–184, 2008.
[11] K. Jaganathan, S. Oymak, and B. Hassibi, “Sparse phase retrieval: Convex algorithms and limitations,” Proceedings of IEEE International Symposium on Information Theory (ISIT), pp. 1022–1026, 2013.
[12] K. Jaganathan, S. Oymak, and B. Hassibi, “Phase retrieval for sparse signals using rank minimization,” Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 3449– 3452, 2012.
[13] H. Ohlsson, A. Yang, R. Dong, and S. Sastry, “Compressive phase retrieval from squared output measurements via semideﬁnite programming,” arXiv preprint, arXiv:1111.6323, 2011.
[14] X. Li and V. Voroninski, “Sparse signal recovery from quadratic measurements via convex programming,” arXiv preprints arXiv:1209.4785, 2012.
[15] P. Netrapalli, P. Jain, and S. Sanghavi, “Phase retrieval using alternating minimization,” arXiv preprints arXiv:1306.0160, 2013.
[16] A. Walther, “The question of phase retrieval in optics,” Optica Acta, vol. 10, no. 1, pp. 41–49, 1963. [17] M. Mirhosseini, O. S. Magana-Loaiza, S. M. Hashemi Rafsanjani, R. W. Boyd, “Compressive direct
measurement of the quantum wavefunction,” arXiv preprint arXiv:1404.2680, 2014. [18] M. Akcakaya and V. Tarokh, “New conditions for sparse phase retrieval,” arXiv preprint
arXiv:1310.1351, 2013. [19] M. Luby, M. Mitzenmacher, M. A. Shokrollahi, and D. Spielman, “Improved low-density parity check
codes using irregular graphs,” IEEE Trans. Info. Theory, vol. 47, pp. 585–598, 2001. [20] C. Yapar, V. Pohl, and H. Boche, “Fast compressive phase retrieval from Fourier measurements,” arXiv
preprint arXiv:1410.7351, 2014. [21] R. Pedarsani, K. Lee, and K. Ramchandran, “PhaseCode: Fast and Efﬁcient Compressive Phase Re-
trieval based on Sparse-Graph-Codes,” arXiv preprint arXiv:1408.0034, 2014. [22] X. Li, S. Pawar and K. Ramchandran, “Sub-linear Time Support Recovery for Compressed Sensing
using Sparse-Graph Codes,” arXiv preprint arXiv:1412.7646, 2014.
16

