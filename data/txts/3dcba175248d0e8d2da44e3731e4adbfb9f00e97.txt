Integrating Local Context and Global Cohesiveness for Open Information Extraction

arXiv:1804.09931v4 [cs.CL] 1 Dec 2018

Qi Zhu1, Xiang Ren2, Jingbo Shang1, Yu Zhang1, Ahmed El-Kishky1, Jiawei Han1

1University of Illinois at Urbana-Champaign, IL, USA 2University of Southern California, CA, USA
1{qiz3, shang7, yuz9, elkishk2, hanj}@illinois.edu 2xiangren@usc.edu

ABSTRACT
Extracting entities and their relations from text is an important task for understanding massive text corpora. Open information extraction (IE) systems mine relation tuples (i.e., entity arguments and a predicate string to describe their relation) from sentences.
ese relation tuples are not con ned to a prede ned schema for the relations of interests. However, current Open IE systems focus on modeling local context information in a sentence to extract relation tuples, while ignoring the fact that global statistics in a large corpus can be collectively leveraged to identify high-quality sentence-level extractions. In this paper, we propose a novel Open IE system, called ReMine, which integrates local context signals and global structural signals in a uni ed, distant-supervision framework. Leveraging facts from external knowledge bases as supervision, the new system can be applied to many di erent domains to facilitate sentence-level tuple extractions using corpus-level statistics. Our system operates by solving a joint optimization problem to unify (1) segmenting entity/relation phrases in individual sentences based on local context; and (2) measuring the quality of tuples extracted from individual sentences with a translating-based objective. Learning the two subtasks jointly helps correct errors produced in each subtask so that they can mutually enhance each other. Experiments on two real-world corpora from di erent domains demonstrate the e ectiveness, generality, and robustness of ReMine when compared to state-of-the-art open IE systems.
1 INTRODUCTION
With the emergence of massive text corpora in many domains and languages, the sheer size and rapid growth of this new data poses many challenges understanding and extracting insights from these massive corpora. Information extraction (IE) [31] – extraction of relation tuples in the form of head entity, relation, tail entity – is a key step towards automating knowledge acquisition from text. In Fig. 1, for example, the relation tuple Louvre-Lens, build, new satellites can be extracted from unstructured text s2 to represent a piece of factual knowledge in structured form. ese relation tuples have a variety of downstream applications, such as serving as building blocks for knowledge base construction [11] and facilitating
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. WSDM ’19, Melbourne, VIC, Australia © 2019 ACM. 978-1-4503-5940-5/19/02. . . $15.00 DOI: 10.1145/3289600.3291030

ID Document

S1 [London] is the most populous [city] and capital of [England] and the [United Kingdom].

S2 [Louvre-Lens], [a museum] approximately 200 kilometers northwest of [Paris], is building striking [new satellites] to display parts of [their collection].

S3 By the end of the [12th century], [Paris] had become the political, economic, religious, and cultural capital of [France].

…

…

Phrase Detection

Local Consistent Extraction

Iterative Update

Global Cohesiveness Error Pruning

Corpus-level Extracted Entities & Relation

Head Entity

Predicate

Tail Entity Cohesiveness Sentence ID

London

is, capital of

England

✔

S1

Text

Paris

become, capital of France

✔

S3

Corpus city capital of England ✘ S1

Louvre-Lens

build

new satellites

✔

S2

…

…

…

…

…

construct

Negative Pool of Corrupt Tuples

Head Entity

Predicate

Tail Entity Cohesiveness Sentence ID

city

become, capital of

France

✘

∅

Louvre-Lens

build

Burger King

✘

∅

…

…

…

✘

∅

Figure 1: Example of incorporating global cohesiveness view for er-
ror pruning. One can infer “London” and “Paris” are similar because
they co-occur a lot with the same relation in corpus. By construct-
ing false tuples from extractions, “city” occurs with relation “capi-
tal of” in the negative pool more o en, then it is unlikely for tuples
with “city” and “capital of” to be correct. question answering systems [13, 35]. While traditional IE systems require people to pre-specify the set of relations of interest, recent studies on open-domain information extraction (Open IE) [3, 8, 32] rely on relation phrases extracted from text to represent the entity relationship, making it possible to adapt to various domains (i.e., open-domain) and di erent languages (i.e., language-independent).
Current Open IE systems focus on analyzing the local context within individual sentences to extract entities and their relationships, while ignoring the redundant information that can be collectively referenced across di erent sentences and documents in the corpus. For example, in Fig. 1, seeing entity phrases “London” and “Paris” frequently co-occur with similar predicate strings and tail entities in the corpus, one gets to know that they have close semantics (same for “England” and “France”). is not only helps con rm that London, is capital of, England is a quality tuple as we know Paris, become capital of, France is extracted with high con dence, but this also rules out the tuple city, capital of, England as “city” is semantically distant from “capital of”. erefore, the information redundancy in the massive corpus provides clues on whether a candidate relation tuple is consistently used in the corpus, and motivates us to design a principled way of measuring tuple quality (i.e., global cohesiveness).
Furthermore, most existing Open IE systems assume that they have access to entity detection tools (e.g., named entity recognizer (NER), noun phrase (NP) chunker) to extract entity phrases from

ID Document

S1 [London] is the most populous city and capital of [England] and the [United Kingdom].
S2 [Louvre-Lens], a museum approximately 200 kilometers northwest of

Tuple Generation Module

Paris, is building striking [new satellites] to display parts of [their

collection].

S3 By the end of the 12th century, [Paris] had become the political, economic, Positive

religious, and cultural capital of [France].

Seeds

S4 [Your dry cleaner] set out from [eastern Queens] on [foot] [Tuesday

Generation

Measure with
Cohesiveness

morning] and now somewhere near [Maspeth].

distant supervision
Text corpus from different domains

Phrase Extraction Module

London England United Kingdom Louvre-Lens new satellites
Pairs France Entity phrase

capital of in, on, build set out from had become north west of graduate from
Relation phrase

London

Global Cohesiveness Module

France

New York

✔
England

Paris

new satellites

foot

✘

Positive Extractions from Corpus

Head Entity eh
London Paris
Louvre-Lens Paris
eastern Queens your dry cleaner your dry cleaner

Predicate ph,t
is, capital of become, capital of
build build on set out from, on set out from

Tail Entity et
England France new satellites new satellites
foot foot eastern Queens

Cohesiveness

1st round 2nd round

✔

✔

✔

✔

✔

✔

✔

✘

✔

✘

✔

✔

✔

✔

Negative Pool of Corrupt Tuples

Head Entity London New York …

Predicate build on …

Tail Entity new satellites
foot …

Cohesiveness ✘ ✘ ✘

Figure 2: Overview of the ReMine Framework.

sentences, which are then used to form entity pairs for relation tuple extraction [3, 8, 32]. Some systems further rely on dependency parsers to generate syntax parse trees to guide the relation tuple extraction [2, 10, 32]. However, these systems su er from error propagation as the errors in prior parts of the pipeline(e.g., entity recognition) could accumulate by cascading down the pipeline(e.g., to relation tuple extraction), yielding more signi cant errors. In addition, the NERs and NP chunkers are o en pre-trained for general domain and may not work well on a domain-speci c corpus (e.g., scienti c papers, social media posts).
In this paper, we propose a novel framework, called ReMine, to unify two important yet complementary signals for the Open IE problem, i.e., the local context information and global cohesiveness (see also Fig. 2). While most existing Open IE systems focus on analyzing local context and sentence structures for tuple extraction, ReMine further makes use of all the candidate tuples extracted from the entire corpus, to collectively measure whether these candidate tuples are re ecting cohesive semantics. is is done by mapping both entity and relation phrases into the same low-dimensional embedding space, where two entity phrases are similar if they share similar relation phrases and head/tail entity phrases. e entity and relation embeddings so learned can be used to measure the cohesiveness score of a candidate relation tuple. To overcome the error propagation issue, ReMine jointly optimizes both the extraction of entity and relation phrases and the global cohesiveness across the corpus, each being formalized as an objective function so as to quantify the quality scores, respectively.
e major contributions of this paper are as follows.
(1) We propose a novel open IE framework, ReMine, that can extract relation tuples with local context and global cohesiveness.
(2) We develop a context-dependent phrasal segmentation algorithm that can identify high quality phrases of multiple types.
(3) We design a uni ed objective to measure both tuple quality in a local context and global cohesiveness of candidate tuples.
(4) Extensive experiments on three public datasets demonstrate that ReMine achieves state-of-the-art performance on both entity phrase extraction task as well as Open IE task.
2 PROBLEM DEFINITION
Notations. For any sentence s in a corpus D, a phrase, p, is de ned as single-word or multi-word phrase in s. We further group phrases into three di erent types, i.e. entity phrase e, relation phrase r and background text b. In Open IE, an entity phrase occurs as subject

or object in extractions. In practice, entity phrase can be either a named entity of pre-de ned types(e.g., time, location, person, organization) or other noun phrases. In sentence s4 of Fig. 2, “Your dry cleaner” is not a named entity, although it is the subject of this sentence and cannot be omi ed in relation tuples extraction. erefore, previous work [12, 32] use pre-trained NP chunkers to identify entity phrases. Positive entity phrase pairs Ep+ is a set of entity pairs that may have textual relations between them. Relation phrase r describes relation between an entity phrase pair (eh , et ) ∈ Ep+. Unlike relation extraction tasks, one relation instance can correspond to multiple relation phrases, e.g. location/country/capital can correspond to (’s capital, capital of, the capital, …). Lastly, background text is not a component of relation tuple.
Problem. Let T denote the extracted relation tuples. Each relation tuple t is de ned as {eh , ph,t , et }, where eh and et correspond to head and tail entity arguments and predicate p = (r1, r2, ...rn ) may contain multiple relation phrases(e.g., we have two relation phrases: “had become” and “capital of” between Paris, France in sentence s3). Formally, we de ne the task of Open IE as follows.
De nition 2.1. Given corpus D, the task of Open IE aims to: (1) segment sentence s ∈ D to extract entity phrases e, relation phrases r ; and (2) output relation tuples {eh, ph,t , et }kN=t 1,.
3 THE REMINE FRAMEWORK
ReMine aims to jointly address two problems: extracting entity and relation phrases from sentences and generating quality relation tuples. To accomplish this, we must rst address three challenges. First, as the phrase boundary and category are unknown, one needs to design a segmentation algorithm to score the quality of segmented phrases and label their categories. Second, as multiple entity phrases may be extracted from a sentence, one needs to identify positive entity phrase pairs and obtain proper relation phrase between them. ird, as tuple extraction based solely on local sentence context may be error-prone, one needs to incorporate corpus-level statistics to help correct errors.
Framework Overview. We propose a framework, called ReMine, that integrates both local context and global structure cohesiveness (see also Fig. 2) to address above challenges. ReMine has three major modules, each focusing on address one challenge mentioned above: (1) phrase extraction module; (2) tuple generation module; and (3) global cohesiveness module. First, to extract quality phrases with di erent categories, the phrase extraction module trains a robust

phrase classi er using existing entity phrases from external knowledge base as “distant supervision” and adjust quality iteratively. Second, the tuple extraction module generates candidate tuples based on sentence’s language structure—it adopts widely used local structure pa erns [10, 27, 32], including syntactic and lexical pa erns over pos tags and dependency parsing tree. Di erent from previous studies, the module incorporates corpus-level information redundancy. Last, the global cohesiveness module learns entity and relation phrase representation and uses the representation in a score function to rank tuples. By collaborating with each other, the relation tuple generation module and the global cohesiveness module mutually enhance each other’s results. Particularly, the relation tuple generation module produces candidate relation tuples(as positive tuples) and feeds them into the global cohesiveness module. By distinguishing positive tuples with constructed negative samples, the global cohesiveness module provides a cohesiveness measure for candidate tuples. e tuple generator further incorporates global cohesiveness into local generation and outputs more precise extractions. ReMine integrates tuple generation and global cohesiveness learning into a joint objective. Upon convergence, the training process results in distinctive and accurate tuples. Overall, ReMine extracts relation tuples as follows, see also Fig. 2:
(1) Phrase extraction module conducts context-dependent phrasal segmentation on a target corpus (using distant supervision) , to generate entity phrases, relation phrases and sentence segmentation probability W.
(2) Tuple generation module generates positive entity pairs and identi es predicates p between each entity phrase pair (eh , et ).
(3) Global cohesiveness module learns entity and relation representations V via a translating objective to capture global structure cohesiveness σ .
(4) Iteratively update extractions T based on both local context information and global structure cohesiveness.

3.1 Phrase Extraction Module
Example 3.1 (Multi-type phrasal segmentation). [London] is the most populous [city] and captital of [England] and the [United
Kingdom]. entity phrases in [], relation phrases in italic and all the others are background text.

We address entity and relation phrase extraction as a multi-type

phrasal segmentation task. Given word sequence C and corre-

sponding linguistic features F in Table 2, a phrasal segmentation

S = s1, s2, ..., sn is separated by boundary index B = b1, b2, ..., bn+1. For each segment si , there is a type indicator ti ∈ {e, r , b}1, indi-

cating the most possible type of si . In above example 3.1, s0 = London, t0 = e. We factorize the phrasal segmentation probability as: n

P(C|F ) = P(bi+1, si |bi , F )

(1)

i =1

ReMine generates each segment as follows,

1. Given the start index bi , generate the end index bi+1 according to context-free prior P (bi+1 − bi ) = δ |bi+1−bi |, i.e. length penalty [21]. 2. Given the start and end index (bi , bi+1) of segment si , generate a word sequence si according to a multinomial distribution over all

segments of the same length.

P (si |bi , bi+1) = P (si |bi+1 − bi )

(2)

1e:entity phrase, r:relation phrase, b:background text

Table 1: Entity and relation phrase candidates generation with regular expression patterns on part-of-speech tag

Pattern Entity Phrase Pa erns <DT|PP$>?<JJ>*<NN>+ <NNP>+<IN>?<NNP>+ Relation Phrase Pa erns {V=<VB|VB*>+} {V}{P=<NN|JJ|RP|PRP|DT>} {V}{W=<IN|RP>?*}{P}

Examples
the state health department Gov. Tim Pawlenty of Minnesota
furnish, work, leave provided by, retire from die peacefully at home in

3. Finally, we generate a phrase type ti indicating the type of si and a quality score showing how likely it is to be a good phrase s .

P ( si |si ) = max ti P (ti |si ) = Qti (si )

(3)

Phrase type t and quality Q are determined by a random forest classi er with robust positive-only distant training [33], which uses phrases in external knowledge base as positive samples and draws a number of phrases from unknown candidates as negative samples. Among all word sequence si , we denote unique phrase as u and P(si |bi+1 − bi ) as θu . Similar with [21], we use Viterbi Training [1] to nd best segmentation boundary B and parameters θ, δ iteratively. In the E-step, given θ and δ , dynamic programming is used to nd the optimized segmentation. In the M-step, we rst
x parameter θ , and update context-dependent prior δ . Next when δ is xed, optimized solution of θu is:

m i =1

1

·

(si

= u)

θu =

m i =1

1

·

(bi +1

− bi

=

|u |)

(4)

Phrase Mining [20, 33] makes an assumption that quality phrases can only be frequent n-grams within a corpus. To overcome the phrasal sparsity of this assumption, several NP-chunking rules [12] in Table 1, are adopted to discover infrequent but informative phrase candidates. In experiment 4.2, ReMine has be er performance than AutoPhrase [33] as we consider more phrase candidates and multitype segmentation helps exclude relation phrases and background text be er in entity phrase extraction task.

3.2 Tuple Generation Module
Generating Candidate Entity Pairs. For a given sentence s, a er phrase segmentation, we have entity phrases e1, e2, ..., en and relation phrases r1, r2, ..., rn . However, it’s computationally intractable to explore possible relationships between every entity pair and a large portion of tuples are incorrect among n(n − 1) pairs. Ep+ are candidate entity phrase pairs. Here we heuristically initialize Ep+0 by a aching the nearest subject ei (within the sentence) to the object ej and make an approximation that each entity argument phrase can only be an object once; this also guarantees entity pairs to be distinctive. e nearest subject of ej is de ned as the entity ei that has the shortest dependency path length to ej among all other entities. Considering Fig. 3b, we would like to nd the subject of entity e4 : United Kingdom, the lengths of the shortest paths between e4 and e1, e2, e3 are 2,3,1. For those entity candidates with the same distance, see Fig. 3b, both e1: London and e4: United Kingdom is one hop away from e2: city. In this situation, we will prefer the subject with “nsubj” type i.e. e1. If there are still multiple entities, we will choose the closest entity in the original sentence.

become

[city] e2

capital had [Paris]e2
[France]the political e1 …
of

[London] capital is e1 the [England] [Kingdom]e4 e3

case

the [United]

of

e4

(a) Finding semantic path

(b) Positive Entity Pairs Initialization

Figure 3: Dependency parsing tree of example sentences s1 and s3
in Fig. 2, Segmented entities are marked as “[entity token]ei ” Semantic Path Generation. Once (eh , et ) ∈ Ep+ is determined, the semantic path is de ned as the shortest dependency path between
two arguments. Compared with using word sequence between (eh , et ) directly, the semantic path helps cloud irrelevant information. For example, in Fig. 3a, the semantic path between “Paris” and
“France” of sentence s3 is marked in red, where word sequence“the political, economic…” is correctly excluded. To preserve integrity of
potential relation phrases, we further include particles and prepo-
sition along the shortest dependency path as part of the semantic
path, which is shown as red do ed line in Fig. 3a.

De nition 3.2. (Semantic Path) For an entity phrase pair (eh , et ) in the same sentence, the semantic path is de ned as word sequence SPh,t along expanded dependency path.
Example 3.3 (Generating Relation Tuples). Extracting relation phrases on the semantic path
[Paris] + had become + capital of + [France]

We now present how we generate valuable relation tuples according to semantic path, i.e.

n

P(r , eh, et ) = P(ri |si , eh, et )P(si |bi , bi+1)

i =1

(5)

max
p

P(r

,

eh

,

et

)

⇒

log σ (ri , eh, et ) + log wi

h, t

ri ∈ph,t

where b1, b2, ..., bn+1 are boundary index along semantic path SPh,t of entity phrase pair(eh, et ). P(si |bi , bi + 1) is inherited from phrase extraction module as sentence segmentation probability wi , then ReMine judges whether it is a good relation between entity eh and entity et . Notice that the relation phrase boundary i ∈ ph,t in equation 5 can be derived via dynamic programming since wi and σ is known for every possible segmentation. In example 3.3, within
entity pair Paris, France , the semantic path is “had become capital
of”. Tuple Paris, had become|capital of, France will be generated
as both relation phrases had become and capital of are coherent
with global cohesiveness measure σ and wi .

3.3 Global Cohesiveness Module
Inevitably, false tuple like city, is capital of, England will be generated by relation tuple generation module as introduced in Sec 3.2, since the nearest subject of England in Fig. 3b is city. To get rid of such false tuples, current methods use textual pa erns [10, 32] to identify it as a false extraction. In contrast, we design global cohesiveness measure using corpus-level statistics, and integrate the measure with the relation tuple generation. To capture the global cohesiveness of relation tuples, we adopt translation-based multi-relational data representation [5].
σ (p, h, t) = −d(h + p, t); d(h + p, t) = h + p − t (6)

where h, t are embeddings for head and tail entities, p is the

predicate. Such a measure imposes reliable relation tuples on small

translating distance between h +p and t. We use L1 norm in ReMine. Based on initial positive entity pairs constructed Ep+0 and relation

tuples T , we construct a pseudo knowledge graph. Particularly,

predicate ph,t may contain several relation phrases. Motivated by

process of knowledge traverse [15], we average multiple relation

phrases embeddings to represent the predicate i.e. p =

n i =1

ri /n.

Example 3.4 (Generating False Tuples). Paris, become capital of, France → city, become capital of, France , Paris, become capital of, Burger King

In order to learn a global cohesiveness representation V, we construct correlated negative tuples from positive seeds. For instance, as seen for example 3.4, we see that for a positive tuple, we can generate many incorrect or “negative” tuples.
e cohesiveness measure σ is optimized by maximizing the cohesiveness margin between positive and negative tuples,

T T−

max

[σ (p, h, t) − σ (p, h , t ) − γ ]−

(7)

V p,h,t p,h ,t

where [x]− denotes the negative part of x, T denotes positive relation tuples generated by local relational extraction, γ is the hyper margin, (p, h , t ) ∈ T − is composed of training tuples with either h or t replaced.

3.4 e Joint Optimization Problem
Relation tuple generation in Section 3.2 incorporates cohesiveness similarity σ . Additionally global cohesiveness measure learning depends on extracted tuples T . We now show how local context and global cohesiveness introduced above can be integrated.

Overall Updating Schema. e nal objective for update is formulated as the sum of both sub-objectives,

maxV, T O = Olocal + O lobal

(8)

Olocal = log P(ph,t , eh , et )

(9)

Ep+

T T−

O lobal =

[σ (p, h, t) − σ (p, h , t ) − γ ]− (10)

p,h,t p,h ,t

To maximize the above uni ed open IE objective, see Alg. 1, we rst initialize positive entity pairs Ep+0. Given entity phrase pairs, we perform local optimization, which leads to positive relation tuples T . Note that, at the rst round, there is no global representation, so we initialize all σ = 1 as identical. en we update global phrase semantic representation via stochastic gradient descent. With both global cohesiveness information and local segmentation results, ReMine updates relation tuples as described in Alg. 1. Overall ReMine solves the integrated problem greedil and it iteratively updates local and global objectives until a stable Ep+ is reached.

Example 3.5 (Updating Relation Tuples). In sentence s1, city, is capital of, England → London, is capital of, England

Update Positive Entity Pairs and Relation Tuples. Given a se-
mantic representation for each entity e and relation r and local
segmentation between entity pairs, we can update the Positive En-
tity Pairs by nding the most semantically consistent subject eh for each object et among Msp -nearest neighbors on the dependency

Algorithm 1: e ReMine Algorithm for Joint Optimization

Input: corpus D, sentence S, text features F, convergence threshold t Output: relation tuples T, semantic representation V, similarity measure σ
1 generate entity and relation seeds via distant corpus linking ;

2 phrase extraction module outputs entity phrases, relation phrases, sentence segmentation

probability W ;
3 initialize positive Ep+0, cohesiveness measure σ = 1 ; 4 generate relation tuples T among Ep+0 ;

5 do 6 7
8 9 10 11 12

update V, σ in Eq. (10) via global cohesiveness module ; Ep+n ← ∅, ∆E ← 0 ;
for each tuple eh, pht , et ∈ T do construct candidate subject sets s of et with at most Msp entities;
σ∗ ← σ (eh, ph,t , et ) ; for i = 1 to Msp do
generate si , pi,t , et in Eq. (9) via relation tuple generation module
given W and V;

13

if σ (si , pi,t , et ) > σ∗ then

14

σ∗ ← σ (si , pi,t , et ), e∗ ← si ;

15

end

16

end

17

Ep+n ← Ep+n e∗, et ;

18

if e∗ eh then

19

∆E ← ∆E + 1, e∗, p∗t , et ← eh, pht , et update T ;

20

end

21

end

22 while

∆E +n

> t;

|Ep |

Table 2: Features used in the phrase extraction module (Sec. 3.1).

Feature
popularity completeness concordance punctuation stopwords word shape POS tags

Descriptions
raw frequency, occurrence probability whether can be interpreted as a complete semantic unit tokens in quality phrases should co-occurs frequently phrase in parenthesis, quote or has dash a er
rst/last token is stopword and stopword ratio rst capitalized or all capitalized unigram and bigram POS tags

parsing tree. By optimizing P(r , eh, et ) in Eq. 5, we also obtain the relation tuples for updated positive pairs Ep+n+1.

Ep+ = argmax P(ph,t , eh, et )

(11)

eh

In example 3.5 and Fig. 3b, false tuple city, is capital of, England will be updated as London, is capital of, England . Seeing London and Paris share lots of predicate and tail entities, the updated tuple is more cohesive with others e.g. Paris, become capital of, France .

4 EXPERIMENTS
For thorough evaluation of the proposed approach, we test the performance of ReMine system from two aspects, i.e., quality of the extracted entity phrases (i.e., entity phrase extraction with distant training), and quality of the extracted relation tuples (i.e., output of the Open IE system). In particular, we compare ReMine with state-of-the-art Open IE systems to validate our three claims: (1) the domain-independent framework performs consistently well on di erent domains, (2) global structure cohesiveness improves performance of Open IE, and (3) the proposed iterative updating algorithm is e ective and scalable.

4.1 Experimental Setup
Datasets. We use three public datasets2 from di erent domains in our experiments: (1) NYT [29]: a corpus consisting of 23.6k sentences from ∼294k 1987-2007 New York Times news articles.
2Codes and datasets can be downloaded at h ps://github.com/GentleZhu/ReMine

395 sentences are manually annotated with entities and their relationships. (2) Wiki-KBP [19]: e training corpus contains 2.4k sentences sampled from ∼780k Wikipedia articles [19] as the training corpus and 290 manually annotated sentences as test data. (3) Twi er [38]: consists of 1.4 million tweets from Los Angeles with entities and/or noun phrases collected from 2014.08.01 to 2014.11.30.
Distant Supervision for Generating Training Data. For each corpus, we apply the entity linking tool DBpedia Spotlight 3 [9] to recognize DBpedia entities in sentences and use them as “seed” entity phrases. With seed entity phrases, we generate relation phrases between each pair of entity mentions via pa ern matching (see Sec. 3.2), forming the seed relation tuples. ese seed tuples are used as distant supervision for training segmentation algorithm (thus “distant training”). We then follow the procedure introduced in Sec. 3.1 to segment sentences into entity and relation phrases.
Phrase Features Generation. In order to estimate quality and catgeory of phrases, we use features F in Table 2. ese features can be grouped into several di erent categories, i.e. statistic features, token-wise features and POS features. ReMine treats phrases with multiple POS tag sequences as di erent pa erns. For example, “work NN” and “work VBP” are two di erent semantic pa erns. We applied the Stanford CoreNLP [25] tool to get POS tags and dependency parsing trees.
Compared Methods. For the entity phrase extraction task, NYT and Wiki-KBP are used for evaluation, since both datasets contain annotated entity mentions in test set. We adopt the sequence labeling evaluation setup [24], and compare ReMine’s entity phrase extraction module with two state-of-the-art sequence labeling methods and one distantly-supervised phrase mining method on the test sets: (1) Ma & Hovy [24]: adopts a Bi-directional LSTM-CNN structure to encode character embeddings and pre-trained word embeddings; (2) Liu. et al. [22]: incorporates a neural language model and conducts multi-task learning to guide sequence labeling; and (3) AutoPhrase [33]: the state-of-the-art quality phrase mining method with POS-guided phrasal segmentation.
For the relation tuple extraction task, we consider following Open IE baselines for comparison: (1) OLLIE [32] utilizes open pa ern learning and extracts pa erns over the dependency path and part-of-speech tags. (2) ClausIE [10] adopts clause pa erns to handle long-distance relationships. (3) Stanford OpenIE [2] learns a clause spli er via distant training data. (4) MinIE [14] re nes tuple extracted by ClausIE by identifying and removing parts that are considered overly speci c. (5) ReMine-L is a base model of our approach with only local context. We only plot precision@300 in Fig. 4 as no ranking measure is deployed. (6) ReMine-G extend ReMine-L by ranking tuples via global cohesiveness without updating entity phrase pairs and any further iterations. (7) ReMine is our proposed approach, in which relation tuple generation module collaborates with global cohesiveness module.
Parameters Settings. For baselines of entity phrase extraction task, we tune all the models using the same validation set. In the testing of ReMine and its variants, we set hypermargin γ = 1, maximal phrase length ϵ = 6, number of candidate subject entity phrase for each tail entity Msp = 6 and learning rate of the global cohesiveness module α = 10−3. e dimension of global cohesiveness
3h ps://github.com/dbpedia-spotlight/dbpedia-spotlight

representation k is 100. We stop further joint optimization if the ratio t of updated tuples is smaller than 10−3. Table 3: Performance comparison with state-of-the-art entity phrase extraction algorithms for the weakly-supervised entity phrase extraction task.

Methods
AutoPhrase [33] Ma & Hovy [24]
Liu. et al. [22] ReMine

F1 0.531 0.664 0.676 0.648

NYT [29] Prec 0.543 0.704
0.704 0.524

Rec 0.519 0.629 0.650 0.849

Wiki-KBP [19] F1 Prec Rec 0.416 0.529 0.343 0.324 0.629 0.218 0.337 0.629 0.230
0.515 0.636 0.432

Cut-o reshold for Extraction Output. e number of tuple extractions from di erent systems can vary a lot. For example, for the rst 100 sentences in the NYT test set, both ReMine and OLLIE get about 300 tuples. In contrast, Stanford OpenIE returns more than 1,000 tuples. However, many paraphrased extractions can be found within them. Since each extracted tuple is also assigned with a con dence score, we select 300 tuples for both datasets with the highest scores for each open IE system to report the performance. By selecting 100 sentences from NYT test set and 300 tweets from Twi er test set, we believe ∼3 tuples per sentence in News domain and ∼1 tuple per sentence in Twi er are reasonable for a fair comparison. A more detailed study can be found in Sec. 5.
Annotation of Ground-truth Data. We manually labeled the top300 tuple extraction results obtained from all compared methods via pooling method (i.e., high-con dence tuples by each system are pooled together as the candidate set). Each extracted tuple in the candidate set was labeled by two independent annotators. A tuple is labeled as positive only if both labelers agree on its correctness. All tuples with con icting labels results were ltered. Similar to [10], we ignored the context of the extracted tuples during labeling. For example, both (“we”, “hate”, “it”) and (“he”, “has”, “father”) will be treated as correct as long as they meet the fact described in the sentence. However, tuples cannot be read smoothly will be labeled as incorrect propositions. For example, (“he”, “is”, “is the professor”) and (“he”, “is”, “the professor and”) will not be counted since they have mistakes at the word segmentation level. e Cohen’s Kappa value between the two labelers are 0.79 and 0.73 for the NYT dataset and the Twi er dataset respectively.
Evaluation Metrics. We use Precision (i.e. how many entities we get are correct), Recall (i.e. how many correct entities do we get), and F1-score to evaluate the performances on entity phrase extraction task, same as other sequence labeling studies [24]. For the Open IE task, since each tuple obtained by ReMine and other benchmark methods will also be assigned a con dence score. We rank all the tuples according to their con dence scores. Based on the ranking list, we use the following four measures: P@k is the precision at rank k. MAP is mean average precision of the whole ranking list. N DCG@k is the normalized discounted cumulative gain at rank k. MRR is the mean reciprocal rank of the whole ranking list. Note that we do not use recall in this task because it is impossible to collect all the “true” tuples.

4.2 Experiments and Performance Study
1. Performance on Entity Phrase Extraction. e training data is generated through distant supervision described above without type information. Regarding open domain extractions, we train

Precision

0.85 0.8
0.75 0.7
0.65 0.6
0.55 0.5 0
0.8 0.7 0.6

ReMine OLLIE Stanford ClausIE MinIE ReMine-G ReMine-L

50

100

150

200

250

300

Yield(K)

(a) NYT

ReMine OLLIE Stanford ClausIE MinIE ReMine-G ReMine-L

Precision

0.5

0.4

0.3

0.2

0

50

100

150

200

250

300

Yield(K)

(b) Twitter

Figure 4: e Precision@K curves of di erent open IE systems on NYT and Twitter datasets.
baseline models using the same distant supervision as ReMine, to push them towards a fair comparison. Table 3 demonstrates the comparison result over all datasets. In the Wiki-KBP dataset, ReMine evidently outperforms all the other baselines. In the NYT dataset, ReMine has a rather high recall and is on par with the two neural network models on F1-score.
2. Performance on Relation Tuple Extraction. On NYT and twi er test set, we compare ReMine with its variants ReMine-L and ReMine-G as well as four baseline open IE systems mentioned above. e results are shown in Figure 4 and Table 4.
“Does ReMine perform consistently well on di erent domains?”
According to the curves in Figure 4a and 4b, ReMine achieves the best performance among all open IE systems. All methods experience performance drop in Twi er, while ReMine declines less than any other methods on the rank-based measures. In the NYT dataset, all the systems except OLLIE have similar overall precision (i.e. P@300). But ReMine has a “higher” curve since most tuples obtained by Stanford OpenIE and ClausIE will be assigned score 1. erefore we may not rank them in a very rational way. In contrast, the scores of di erent tuples obtained by ReMine-G and ReMine are usually distinct from each other. In Table 4, ReMine also consistently performs the best . In the Twi er dataset, ReMine shows its power in dealing with short and noisy text. Both ClausIE and MinIE have a rather low score since there are lots of nonstandard language usages and grammatical errors in tweets. In twi er, dependency parsing a aches more wrong arguments and labels than usual. All methods investigated depend on dependency parsing to varying degrees, while clause-based methods rely heavily on it and may not achieve a satisfying performance.
“Does global cohesiveness improve quality of open IE?”
Model-wise, we believe global cohesiveness helps open IE from two aspects: (1) ranking tuples (2) updating entity phrase pairs.

Table 4: Performance comparison with state-of-the-art Open IE systems on two datasets from di erent domains, using Precision@K, Mean Average Precision (MAP), Normalized Discounted Cumulative Gain (NDCG) and Mean Reciprocal Rank (MRR).

Methods
ClausIE Stanford
OLLIE MinIE ReMine-G ReMine

P@100 0.580 0.680 0.670 0.680 0.730
0.780

P@200 0.625 0.625 0.640 0.645 0.695
0.720

MAP 0.623 0.665 0.683 0.687 0.734
0.760

NYT [29] NDCG@100
0.575 0.689 0.684 0.724 0.751
0.787

NDCG@200 0.667 0.654 0.775 0.723 0.783
0.791

MRR 0.019 0.023
0.028 0.027 0.027 0.027

P@100 0.300 0.390 0.580 0.350 0.510
0.610

P@200 0.305 0.410 0.510 0.340 0.580
0.610

Twitter [38]

MAP NDCG@100

0.308

0.332

0.415

0.413

0.525

0.519

0.361

0.362

0.561

0.522

0.627

0.615

NDCG@200 0.545 0.557 0.626 0.541 0.610
0.651

MRR 0.021 0.023 0.017
0.025 0.021 0.022

Figure 5: e number of updated tuples and global cohesiveness against the number of epochs for the proposed ReMine.
From Figure 4 and Table 4, we nd ReMine outperforms ReMine-G and ReMine-L on each evaluation metric on both datasets. In particular, ReMine-G di ers from ReMine-L only on extraction scores, since global cohesiveness σ provides be er ranking performance (P@300) over random (ReMine-L). e gain between ReMine and ReMine-G clearly shows the updated extractions have be er quality in general.
“Is the joint optimization e ective and scalable?”
In Fig. 5, We plot out the number of updated tuples and global cohesiveness objective on NYT dataset. e number of updated tuples re ects how global cohesiveness in uences the tuple genration module. e convergence of global cohesiveness indicates the joint optimization leads to cleaner and more coherent extractions. Suppose that corpus D has Nd words. e time cost of phrase extraction module is O(ϵNd ) with the assumption that maximal length of a phrase is a constant ϵ. e tuple generation module examines Msp candidate head entities for each entity phrase and takes ϵMsp time to perform tuple generation as maximal semantic path is bounded by Msp . In total, it takes O(ϵMs2p Nd ) time. e global cohesiveness module requires O(Nr k + Nek), where Nr ,Ne are number of entity and relation phrases and k is the embedding dimension. Nr and Ne is bounded by Nd . By omi ing constants, the computational complexity of joint optimization is O(Nd ). Furthermore, each component of ReMine is paralleled as the independence between each document.
5 CASE STUDY
Clearness and correctness on extractions. In Table. 5, we show the extraction samples of the NYT sentence “Gov. Tim Pawlenty of Minnesota ordered the state health department this month to monitor day-to-day operations at the Minneapolis Veterans Home a er state inspectors found that three men had died there in the previous month because of neglect or medical errors.”. We can see that

Table 5: Extraction samples of one sentence in the NYT dataset us-
ing di erent methods. “T” means correct tuples and “F” means incorrect ones. ∗ e tuple is too complicated to clearly explain one proposition. # e tuple cannot read smoothly. † e tuple is logi-
cally wrong.

ClausIE R1 (”Gov. Tim Pawlenty of Minnesota”, ”ordered”, ”the state health F∗

department this month to monitor day-to-day operations a er

state inspectors found that three men had died there in the previous

month because of neglect or medical errors”)

R2 (”Gov. Tim Pawlenty of Minnesota”, ”ordered”, ”the state health T

department this month to monitor day-to-day operations”)

Stanford OpenIE

R3 (”Gov. Tim Pawlenty”, ”ordered”, ”state health department”)

T

R4 (”Gov. Tim Pawlenty”, ”monitor”, ”operations”)

F†

R5 (”three men”, ”died there because of”, ”neglect”)

T

R6 (”men”, ”died in”, ”month”)

F#

OLLIE

R7 (”Gov. Tim Pawlenty of Minnesota”, ”ordered the state health T

department in”, ”this month”)

R8 (”three men”, ”had died there in”, ”the previous month”)

T

R9 (”Gov. Tim Pawlenty of Minnesota”, ”had died because of”, ”ne- F†

glect errors”)

MinIE

R10 (”Tim Pawlenty”, ”is”, ”Gov.”)

T

R11 (”Tim Pawlenty of Minnesota”, ”ordered state health department”, T

”this month”)

R12 (”QUANT S 1 men”, ”had died because of”, ”neglect errors”)

F†

ReMine

R13 (”Gov. Tim Pawlenty of Minnesota”, ”order”, ”the state health T

department”)

R14 (”Gov. Tim Pawlenty of Minnesota”, ”order to monitor”, ”day-to- T

day operation”)

R15 (”Gov. Tim Pawlenty of Minnesota”, ”order to monitor at”, ”Min- T

neapolis Veterans Home”)

R16 (”three man”, ”have die there”, ”medical error”)

F#

all the extractors share consensus on that “Gov. Tim Pawlenty of
Minnesota ordered the state health department” (R2, R3, R7, R11 and R13). But some other actions do not belong to “Tim Pawlenty”. Both Stanford OpenIE and OLLIE make mistakes on that (R4 and R9). In contrast, ClausIE has no logical mistakes in the samples. However, the objective component of R1 is too complicated to illustrate one proposition clearly. As we mentioned above, these
kinds of tuples will be labeled as incorrect ones. R15 is the only correct tuple to identify the location “Minneapolis Veterans Home”,
and ReMine also carefully selects the words to form the predicate
“order to monitor at” to prevent excessively long relation phrase.

Distinctiveness of tuple generation. In our formulation, we try to cover every entity detected in the target sentence while avoiding extracting duplicate tuples. In Fig. 6a, we show the distribution

(a) Number of tuples

(b) Jaccard similarity

Figure 6: Distribution over number of extractions and distinctive-
ness of extractions for di erent Open IE systems. of the number of extractions obtained by each Open IE system on the rst 100 sentences in NYT dataset. We can see that OLLIE’s and ReMine’s distributions are relatively balanced. In contrast, Stanford OpenIE returns extractions with a large variance. Among 1054 tuples it extracted, there are 228 tuples belonging to a single sentence and 157 belonging to another. is is despite the la er sentence only containing 39 words. is reminds us that the number of extractions may not be a good alternative to “recall”. A more direct way to examine distinctiveness is calculating average Jaccard similarity between extractions from same sentence. We present the Jaccard similarity distribution of di erent systems at Fig. 6b, we can clearly see MinIE and ReMine extract the most distinctive facts.

E ectiveness of global evidence. Corpus-level cohesiveness can help reduce local error while generating relation tuples. Especially on the twi er dataset, local linguistic structure fails to a ach correct argument initially whereby global cohesiveness module corrects those extractions. In table 6, ReMine rejects entity pair (Liberador, Hollywood) which is not compatible with the predicate “@”. is is because in the twi er corpus, it is more common to see Person @ Place. erefore ReMine a aches Hollywood to Dudamel. Table 6: Di erent entity pairs discovered by ReMine and ReMine-G,
where blue ones are incorrect extractions.

Dudamel conduct his score from Liberador#BeastMode @Hollywood Bowl

ReMine-G

ReMine

(Dudamel; “conduct”; Liberador) (Dudamel; “conduct”; Liberador)

(Dudamel; “conduct…from”;

(Dudamel; “conduct… @”;

#BeastMode)

Hollywood Bowl)

(Liberador, “@”, Hollywood Bowl)

6 RELATED WORK
Open Information Extraction. Open domain information extraction has been extensively studied in literature. Most of the existing work follow two lines of work, that is, pa ern based methods or clause based methods. Pa ern based information extraction can be as early as Hearst pa erns like “N P0 such as {N P1, N P2, ...}” for hyponymy relation extraction [16]. Carlson and Mitchell et al. introduced Never-Ending Language Learning (NELL) based on freetext predicate pa erns [7, 26]. ReVerb [12] identi ed relational phrases via part-of-speech-based regular expressions. Besides partof-speech tags, recent works have started to use more linguistic features, such as dependency parsing, to induce long distance relationships [27, 32]. Similarly, ClausIE [10] inducted short but coherent pieces of information along dependency paths, which is typically subject, predicate and optional object with complement. Angeli et al. adopts a clause spli er using distant training and statistically maps predicate to known relation schemas [2]. MinIE [14] removes overly-speci c constituents and captures implicit relations in ClausIE by introducing several statistical measures like polarity, modality, a ribution, and quantities. Compared with these works,

this paper di ers in several aspects: (1) previous work relies on external tools for phrase extraction, which may su er from domainshi and sparsity problem, while we provide an End-to-End solution towards Open IE. (2) Although previous e orts achieve comparable high precision and reasonable coverage on extraction results, they all focus on local linguistic context. e correctness of extracted facts are evaluated purely on local context, however, large corpus can exclude false extractions from inferred inconsistencies.
Knowledge Base Embedding and Completion. Knowledge bases (KBs), such as DBpedia [4] and Freebase [17], extract tuples from World Wide Web. Knowledge base population or completion aims at predicting whether tuples not in knowledge base are likely to be true or not. Previous works a empted to construct web-scale knowledge base using statistical learning and pre-de ned rules and predicates [28]. Recently, embedding models [5, 18, 30, 34] have been widely used to learn semantic representation for both entities and relations. By observing each relation may have di erent semantic meaning, Wang et al. [37] projected entity vectors to relation-speci c hyperplane. Further research [15, 23] shows that embedding techniques can support composite query(i.e. asking about multiple relations) on knowledge graph. All previouos knowledge graph embedding methods start with existing knowledge base tuples, while our proposed global cohesiveness representation starts from noisy extractions. ere is another line of work trying to combining KB relations and textual relations [36] or model unstructured and structured data by universal schema [29]. However, they are all built upon on existing and speci c relation types. Although we shared similar semantic measures as these work, ReMine uses KB embeddings to measure quality of extracted relation tuples and improve Open IE in a multi-tasking way.
7 CONCLUSION
is paper studies the task of open information extraction and proposes a principled framework, ReMine, to unify local contextual information and global structural cohesiveness for e ective extraction of relation tuples. e local objective is jointly learned together with a translating-based objective to enforce structural cohesiveness, such that corpus-level statistics are incorporated for boosting high-quality tuples extracted from individual sentences. Experiments on two real-world corpora of di erent domains demonstrate that ReMine system achieves superior precision when outpu ing same number of extractions, compared with several state-of-the-art open IE systems. Interesting future work can be (1) On- e-Fly knowledge graph construction from relation tuples; (2) applying ReMine to downstream applications e.g. open domain estion Answering.
8 ACKNOWLEDGEMENTS
Research was sponsored in part by the U.S. Army Research Lab. under Cooperative Agreement No. W911NF-09-2-0053 (NSCTA), National Science Foundation IIS 16-18481, IIS 17-04532, and IIS-1741317, and grant 1U54GM114838 awarded by NIGMS through funds provided by the trans-NIH Big Data to Knowledge (BD2K) initiative (www.bd2k.nih.gov). Xiang Ren’s research has been supported in part by National Science Foundation SMA 18-29268. We thank Frank F. Xu and Ellen Wu for valuable feedback and discussions.

REFERENCES
[1] A. Allahverdyan and A. Galstyan. Comparative analysis of viterbi training and maximum likelihood estimation for hmms. In NIPS, 2011.
[2] G. Angeli, M. J. Premkumar, and C. D. Manning. Leveraging linguistic structure for open domain information extraction. In ACL, 2015.
[3] M. Banko, M. J. Cafarella, S. Soderland, M. Broadhead, and O. Etzioni. Open information extraction from the web. In IJCAI, 2007.
[4] K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In SIGMOD, 2008.
[5] A. Bordes, N. Usunier, A. Garcia-Duran, J. Weston, and O. Yakhnenko. Translating embeddings for modeling multi-relational data. In NIPS, 2013.
[6] R. C. Bunescu and R. J. Mooney. Learning to extract relations from the web using minimal supervision. In ACL, 2007.
[7] A. Carlson, J. Be eridge, B. Kisiel, B. Se les, E. R. Hruschka Jr, and T. M. Mitchell. Toward an architecture for never-ending language learning. In AAAI, 2010.
[8] A. Carlson, J. Be eridge, R. C. Wang, E. R. Hruschka Jr, and T. M. Mitchell. Coupled semi-supervised learning for information extraction. In WSDM, 2010.
[9] J. Daiber, M. Jakob, C. Hokamp, and P. N. Mendes. Improving e ciency and accuracy in multilingual entity extraction. In I-Semantics, 2013.
[10] L. Del Corro and R. Gemulla. Clausie: clause-based open information extraction. In WWW, 2013.
[11] X. L. Dong, T. Strohmann, S. Sun, and W. Zhang. Knowledge vault: A web-scale approach to probabilistic knowledge fusion. In KDD, 2014.
[12] A. Fader, S. Soderland, and O. Etzioni. Identifying relations for open information extraction. In EMNLP, 2011.
[13] A. Fader, L. Ze lemoyer, and O. Etzioni. Open question answering over curated and extracted knowledge bases. KDD, 2014.
[14] K. Gashteovski, R. Gemulla, and L. Del Corro. Minie: minimizing facts in open information extraction. In EMNLP, 2017.
[15] K. Guu, J. Miller, and P. Liang. Traversing knowledge graphs in vector space. In EMNLP, 2015.
[16] M. A. Hearst. Automatic acquisition of hyponyms from large text corpora. In ACL, 1992.
[17] J. Lehmann, R. Isele, M. Jakob, A. Jentzsch, D. Kontokostas, P. N. Mendes, S. Hellmann, M. Morsey, P. Van Kleef, S. Auer, et al. Dbpedia–a large-scale, multilingual knowledge base extracted from wikipedia. Semantic Web, 6(2):167–195, 2015.
[18] Y. Lin, Z. Liu, M. Sun, Y. Liu, and X. Zhu. Learning entity and relation embeddings for knowledge graph completion. In AAAI, volume 15, pages 2181–2187, 2015.
[19] X. Ling and D. S. Weld. Fine-grained entity recognition. In AAAI, 2012. [20] J. Liu, J. Shang, and J. Han. Phrase mining from massive text and its applications.
volume 9. [21] J. Liu, J. Shang, C. Wang, X. Ren, and J. Han. Mining quality phrases from massive
text corpora. In SIGMOD, 2015. [22] L. Liu, J. Shang, F. F. Xu, X. Ren, H. Gui, J. Peng, and J. Han. Empower sequence
labeling with task-aware neural language model. arXiv preprint arXiv:1709.04109, 2017. [23] Y. Luo, Q. Wang, B. Wang, and L. Guo. Context-dependent knowledge graph embedding. In EMNLP, 2015. [24] X. Ma and E. Hovy. End-to-end sequence labeling via bi-directional lstm-cnns-crf. In ACL, 2016. [25] C. D. Manning, M. Surdeanu, J. Bauer, J. R. Finkel, S. Bethard, and D. McClosky.
e stanford corenlp natural language processing toolkit. In ACL (System Demonstrations), 2014. [26] T. M. Mitchell, W. W. Cohen, E. R. Hruschka Jr, P. P. Talukdar, J. Be eridge, A. Carlson, B. D. Mishra, M. Gardner, B. Kisiel, J. Krishnamurthy, et al. Never ending learning. In AAAI, 2015. [27] N. Nakashole, G. Weikum, and F. Suchanek. Pa y: A taxonomy of relational pa erns with semantic types. In EMNLP-CoNLL, 2012. [28] F. Niu, C. Zhang, C. Re´, and J. W. Shavlik. Deepdive: Web-scale knowledge-base construction using statistical learning and inference. In VLDS, 2012. [29] S. Riedel, L. Yao, A. McCallum, and B. M. Marlin. Relation extraction with matrix factorization and universal schemas. In NAACL, 2013. [30] T. Rockta¨schel, S. Singh, and S. Riedel. Injecting logical background knowledge into embeddings for relation extraction. In Proceedings of the 2015 Conference
of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1119–1129, 2015. [31] S. Sarawagi. Information extraction. Foundations and trends in databases, 1(3):261– 377, 2008. [32] M. Schmitz, R. Bart, S. Soderland, O. Etzioni, et al. Open language learning for information extraction. In EMNLP-CoNLL, 2012. [33] J. Shang, J. Liu, M. Jiang, X. Ren, C. R. Voss, and J. Han. Automated phrase mining from massive text corpora. arXiv preprint arXiv:1702.04457, 2017. [34] R. Socher, D. Chen, C. D. Manning, and A. Ng. Reasoning with neural tensor networks for knowledge base completion. In Advances in neural information processing systems, pages 926–934, 2013. [35] H. Sun, H. Ma, W.-t. Yih, C.-T. Tsai, J. Liu, and M.-W. Chang. Open domain question answering via semantic enrichment. In WWW, 2015. [36] K. Toutanova, D. Chen, P. Pantel, H. Poon, P. Choudhury, and M. Gamon. Representing text for joint embedding of text and knowledge bases. In Proceedings of

the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1499–1509, 2015. [37] Z. Wang, J. Zhang, J. Feng, and Z. Chen. Knowledge graph embedding by translating on hyperplanes. In AAAI, 2014. [38] C. Zhang, G. Zhou, Q. Yuan, H. Zhuang, Y. Zheng, L. Kaplan, S. Wang, and J. Han. Geoburst: Real-time local event detection in geo-tagged tweet streams. In SIGIR, 2016.

