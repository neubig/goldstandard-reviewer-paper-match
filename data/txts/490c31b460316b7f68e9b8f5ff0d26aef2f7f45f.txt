Sensitivity Analysis for Markov Decision Process Congestion Games
Sarah H. Q. Li1, Daniel Calderone2, Lillian Ratliff2, Behc¸et Ac¸ıkmes¸e1

arXiv:1909.04167v2 [cs.GT] 12 Sep 2019

Abstract— We consider a non-atomic congestion game where each decision maker performs selﬁsh optimization over states of a common MDP. The decision makers optimize for their own expected cost, and inﬂuence each other through congestion effects on the state-action costs. We analyze the sensitivity of MDP congestion game equilibria to uncertainty and perturbations in the state-action costs by applying an implicit function type analysis. The occurrence of a stochastic Braess paradox is deﬁned and analyzed based on sensitivity of game equilibria and demonstrated in simulation. We further analyze how the introduction of stochastic dynamics affects the magnitude of Braess paradox in comparison to deterministic dynamics.
I. INTRODUCTION
Markov decision process (MDP) congestion games have been successfully used to model distributions of selﬁsh decision makers when competing for ﬁnite resources [1]. In particular, MDP congestion games introduce stochastic dynamics in congestion games by mapping user inputs to probabilistic outcomes. An equilibrium concept similar to Wardrop equilibrium of routing games [2], MDP Wardrop equilibrium describes steady-state population behaviour at which no players can optimize their expected state-action costs through further changes in their decision strategies.
In modelling a physical process as a game, the game equilibrium approximates the true steady-state of the physical process; this is because models inherently cannot predict the physical process to full accuracy. The underlying assumption is that the modelling errors cause negligible deviations of prediction from physical equilibrium. However, this is false if the steady-state distribution is sensitive to changes in the modelling parameters. This motivates our study of sensitivity of MDP congestion game to state-action costs.
In this paper, we quantify sensitivity for the occurrence of stochastic Braess paradox, and relate the paradox to its deterministic counterpart. We also deﬁne and derive conditions for MDP dynamics and state-action costs under which our sensitivity analysis is valid. Finally we bound the sensitivity of a stochastic MDP congestion game in terms of the sensitivity of its deterministic counterpart.
Here we’d also like to emphasize why we consider the sensitivity of Wardrop equilibrium to the state-action cost parameters. In utilizing MDP congestion game models to forecast steady-state behaviour of a physical system, stateaction costs are often parameterized by experimental data,
*This work was is supported by NSF award CNS-1736582. 1Authors are with the William E. Boeing Department of Aeronautics and Astronautics, University of Washington, Seattle. sarahli@uw.edu behcet@uw.edu 2Authors are with the Department of Electrical Engineering, University of Washington, Seattle. djcal@uw.edu ratliffl@uw.edu

which has uncertainty. When this uncertainty is bounded, it is natural to consider bounding the resulting deviation of true equilibrium from the predicted equilibrium. Secondly, the sensitivity of game equilibrium is highly relevant to Stackelberg games for the leader, who may utilize the sensitivity information to derive an optimal action sequence for its own objective [3]. Finally, when a game designer with a certain ‘budget’ for changing the cost function attempts to alter an existing game equilibrium to maximize an external objective, it’s important to know the optimal change with respect to designer’s alternative objective.
We review existing literature on sensitivity and MDP congestion games in section II. In section III, MDP congestion game and related concepts are deﬁned. Sensitivity results and stochastic Braess paradox characterizations are given in section IV. We analyze stochasticity’s effect on paradox sensitivity in section V. Finally, simulations demonstrating stochastic Braess paradox and the sensitivity analysis is shown in section VI.
II. RELATED WORK
MDP congestion games [1], [2] combine features of nonatomic routing games [4]–[6], i.e. where decision makers inﬂuence each other’s edge costs through congestion effects over a network—and stochastic games [7], [8]—i.e. where each decision maker solves an MDP.
Our analysis resembles sensitivity work on Wardrop equilibria in trafﬁc assignment literature [9]–[11], where extensive research exist on both the sensitivity of Wardrop equilibria and a related problem of network design with respect to optimal user equilibrium [12], [13]. Efﬁciency of Wardrop equilibria leads to a paradoxical phenomenon known as Braess paradox [14], whose occurrence is linked to the underlying network of system dynamics [15].
To incorporate randomness in the trafﬁc assignment model, a variety of probabilistic models were analyzed. Approximation algorithms have been derived for networks where uncertainty exists in user demand [16], in user dynamics as logit model [17], and in perceived cost function as normal error distribution [18]. Sensitivity of other network games to modelling parameters have also been studied in [19]. Our work is fundamentally different from previous work due to our assumption: we consider exclusively on uncertain dynamics, and instead of modelling uncertainty with explicit probability distributions, we describe dynamics with MDPs, which can be interpreted as a discretization of an arbitrary probability distribution. The addition of MDP dynamics then requires additional treatment as described in later sections.

III. PRELIMINARIES
We introduce MDP congestion game framework from an individual decision maker’s perspective and deﬁne a variational inequality-style game equilibria. From a system-level perspective, MDP congestion game is formulated as a potential game with a hypergraph structure. The set {1, . . . , N } is denoted by [N ] and the vector [1, . . . 1] ∈ RN by 1N .

A. MDP Congestion game
In an archetypal ﬁnite MDP problem, each decision maker solves a ﬁnite-horizon MDP [20] with horizon length T , state space [S], and action space [A] given by

min

xsacsa

xsa

s∈[S]a∈[A]

s.t.

xsa = 1,

sa

(1)

xsa =

Pss a, ∀ s ∈ [S],

a

s ∈[S]a∈[A]

xsa ≥ 0, ∀ s ∈ [S], a ∈ [A],

where the objective is to minimize the expected average cost

over an inﬁnite time horizon with a ﬁnite set of actions

[A] and a ﬁnite set of states [S]. The optimization variable

x ∈ RS+A deﬁnes a state-action distribution of an individ-

ual decision maker, such that xsa/ a ∈[A] xsa denotes a

decision maker’s probability of taking action a at state s.

The

probability

kernel

P

∈

S×SA
R+

has

form

Ps1s1a1 Ps1s1a2 . . . Ps1s2a1 . . . Ps1sS aA 

Ps2s1a1 Ps2s1a2 . . . Ps2s2a1 . . . Ps2sS aA 

P = 

..

, 

.



Psns1a1 Psns1a2 . . . Psns2a1 . . . PsnsS aA

where Pss a denotes the transition probability from state s to s when taking action a. P is column stochastic and deﬁnes the transition dynamics.
In a non-atomic MDP congestion game, an inﬁnite number of decision makers each solves an MDP on the same stateaction space. The total population distribution is described by y ∈ RS+A.

Assumption 1 (Mean Field Assumption). In the limit where
the number of decision makers approaches to inﬁnity, the total population becomes a continuous distribution y ∈ RS+A with total mass M > 0, where ysa denotes the portion of population who chooses action a at state s.

The population distribution y relates to individual stateaction distribution by y = k αkx(k), k∈K αk = M, αk > 0, ∀ k ∈ K, where K is the index set of feasible distributions with respect to MDP (1), and αk corresponds to the portion of population that chooses distribution x(k).
Assumption 1 results in a non-atomic nature of MDP
congestion games: each decision maker’s state-action distri-
bution is inﬁnitesimal with respect to the population distribution, and changes in an individual x does not affect y.
In an MDP congestion game, the state-action costs csa are population dependent functions, i.e., csa = sa(ysa),

where sa : R+ → R. We denote : RS+A → RSA as the vector of state-action costs. The population dependency of reﬂects congestion effects: the greater the population in a given state-action pair, the greater the cost of taking that state-action for all decision makers. This assumption is consistent with practical networked interactions in trafﬁc and telecommunications [21] where, e.g., the cost of traversing a road increases for each driver when the number of cars on the road increases.
Assumption 2. The state-action costs : RS+A → RSA are continuously differentiable and ∇y is positive deﬁnite.
In an MDP congestion game, all decision makers achieve their optimal expected cost when the population distribution is at MDP Wardrop equilibrium.
Deﬁnition 1 (MDP Wardrop Equilibrium [2]). A population distribution y which satisﬁes Assumption 1 is a Wardrop equilibrium when each decision maker’s probability x (k) satisﬁes
sa(ysa)(x (k)sa − xsa) ≤ 0, ∀k ∈ K.
s∈[S] a∈[A]
Deﬁnition 1 deﬁnes optimality in terms of expected cost: an individual decision maker deviating from its current strategy will not achieve a more optimal expected cost.
B. Directed Hypergraphs
Similar to stochastic shortest path problems [22], MDP congestion game is inherently related to hypergraphs [23]. We consider a weighted directed hypergraph G = ([S], E), where [S] is the set of states considered in MDP congestion game and E is the set of hyperarcs. A hyperarc (s, a) is deﬁned for each state-action pair, such that the tail is always at s, and the head, H(s, a), is the set of states that can be reached from state s taking action a—i.e., H(s, a) = {s ∈ [S] | Ps sa > 0}.

B

A

D

C

Fig. 1. A directed hypergraph with 4 states. The hyperarcs in red have one tail but multiple heads, denoting possible states s that taking state-action (s, a) may result in next.

A hypergraph incidence matrix E ∈ RS×|E| has elements deﬁned as

1

s = s,

(E)s ,(s,a) =

(2)

−Ps sa s = s.

Alternatively the incidence matrix can be written as E = (IS ⊗ 1TA − P ). In this form, we can see that the difference

in probability density per state (i.e., (IS ⊗ 1TA)x) before and after a stochastic transition (i.e., P x) can be written as Ex. Therefore a stationary distribution xˆ always satisﬁes Exˆ = 0.
A directed hypergraph is strongly connected if every nonempty subset R ⊂ [S] has at least one incoming hyperarc from the set [S]/R. In the following consider hypergraphs whose incidence matrix has rank S − 1.

Assumption 3 (Incidence Rank). The hypergraph that corresponds to probability transition kernel P is strongly connected, and its incidence matrix E has row rank S − 1.

An MDP congestion game can be stated as an optimization problem over population distribution y [2], formulated as

ysa

min

sa(u)du

(3a)

y s∈[S] a∈[A] 0

s.t. Ey = 0,

(3b)

1T y = M,

(3c)

y ≥ 0,

(3d)

where constraints on y is derived from feasibility conditions of individual decision makers.
Let ν, λ, µ be Lagrange multipliers corresponding to (3b), (3c), (3d), respectively. When satisﬁes Assumption 2, uniqueness of the tuple (y , λ , µ ) is guaranteed [2]. However due to the rank deﬁciency of ET , ν must be nonunique. We show next that the constraint Ey = 0 can be reduced to a full ranked condition, such that the corresponding optimal Lagrange multiplier ν is unique.

Lemma 1 (Full Row Rank Incidence Matrix). An MDP

congestion game (3) that satisﬁes Assumption 3 is equivalent

to

ysa

min
y

s∈[S] a∈[A] 0

sa(x)dx

s.t. E˜y = 0,

(4)

1T y = M,

y ≥ 0,

where E = E˜ and E˜ has full row rank. eT
Proof. Consider removing arbitrary row vector eT from the incidence matrix E. By Assumption 3, eT is not identically 0. Clearly, Ey = 0 implies E˜y = 0. To see that the opposite implication, note that ET 1 = 0 from deﬁnition leads to 1T E˜ = −eT . Therefore E˜y = 0 implies −eT y = 0.

The Karush-Kuhn-Tucker (KKT) conditions of (4) are

 (y ) − E˜T ν − λ 1 − µ

 H(y , ν , λ , µ ) = 


E˜y 1T y − M

(µ )T y

 0  = 0 ,  0
0

µ ≥ 0, y ≥ 0. (5)
where ν ∈ RS−1, λ ∈ R, µ ∈ RS+A are uniquely determined for a given population distribution y.

IV. SENSITIVITY ANALYSIS
In this section, we derive a sensitivity characterization of stochastic Braess paradox. To facilitate the analysis, we introduce perturbation dependent cost functions : RSA × RSA → RSA that is continuously differentiable in both inputs, where the additional input represents perturbation to the cost function. The game itself is played with respect to a given perturbation and a corresponding cost (·, ).
The KKT conditions (5) can also be viewed as an implicit characterization of optimal population y as parameterized by . We deﬁne a point-to-set mapping given by
Q : → {(y, ν, λ, µ)| H( , λ, ν, y, µ) = 0, µ ≥ 0, y ≥ 0} . (6)
The point-to-set mapping, Q( ), generalizes local differentiability of y as a function of [24]. For an , if the optimal distribution y and corresponding optimal Lagrange multipliers are unique, Q( ) is a single valued set mapping; in this case we denote the optimal population distribution by y ( ). Unless otherwise stated, Assumption 2 holds from now on.
Consider an MDP congestion game played with costs (y, 0) and its optimal solution y (0). When Q( ) is a single valued set mapping for in an open set containing zero, the Jacobian ∇ y (0) exists. We call ∇ y (0) the sensitivity of MDP Wardrop equilibria—i.e.,how y (0) changes when cost is perturbed by .
We restrict our attention to MDP congestion games whose unique equilibrium satisﬁes y (0) > 0.
Assumption 4 (Positivity Condition). The optimal population distribution of the unperturbed MDP congestion game satisﬁes y > 0.
Assumption 4 is not restrictive in the following sense: when state-action costs satisfy Assumption 2, Assumption 4 will always be satisﬁed for some total mass M > 0. Consider cost functions that satisfy sa(0) = bsa ∈ R. If a hyperarc is not optimal, i.e. has no mass, then bsa must be at least maxa ∈[A] sa (ysa , 0). However, all other state action costs must increase as total mass M increases, therefore a total mass threshold exists for which maxa ∈[A] sa (ysa , 0) ≥ bsa, past which (s, a) will become optimal.
Proposition 1 (Perturbation Map). If an MDP congestion game (3) satisﬁes Assumptions 2 and 3 with costs (·, ), and y ( ) satisﬁes Assumption 4, then the mapping Q( ) (6) is a single valued mapping at .
Proof. From Assumptions 2 and 4, there exists a unique y ( ) > 0 solving the KKT conditions (5) for costs (·, ). Lagrange multiplier µ = 0 from complementary slackness. The other optimal solutions can be determined by solving (y )T ( (y ) − E˜T ν − λ 1) = 0, which implies λ = (y )T (y )/M . Furthermore, unique y and λ implies E˜ν is unique. Since E˜T has full rank, ν is unique.
Proposition 1 implies that when is continuously differentiable at y and = 0, there exists a continuously differentiable and invertible function of the optimal distribution y in

terms of . We note that similar sensitivity results which do not consider stochastic congestion effects exist for routing games [9]. However, our results for MDP congestion games are less restrictive due to the lack of the dual route/link space.
Theorem 1 (MDP Congestion Game Flow Sensitivity). Consider an MDP congestion game with costs (y, ), such that is a continuously differentiable function of (y, ) and satisﬁes Assumption 2, and the associated hypergraph satisﬁes Assumption 3. If the optimal population distribution y ( ) > 0, the sensitivity of the MDP Wardrop equilibrium is given by
∇ y = G−1N (N T G−1N )−1N T G−1J − G−1J.

Moreover, the sensitivity of optimal state-action costs is

∇ (y , ) = N (N T G−1N )−1N T G−1J,

where N = E˜T 1 , E˜ as given by Lemma 1, G = ∇y (y ( ), ), and J = ∇ (y ( ), ).

Proof. From Proposition 1, the game with costs (·, ) has

associated single valued mapping Q( ) in a neighborhood

of , then H(Q( ), ) = 0 implies the total derivative

dH(Q( ), )/d = 0 for − ≤ δ. Let w = y ν λ  (y, ) − E˜T ν − λ1 

and f (y, ν, λ, ) = 

E˜y

. Like H, f is

1T y − M

continuously differentiable in w, and is equal to 0 at y ( )

and corresponding optimal Lagrange multipliers. From the

implicit function theorem [24, Sec.1B], when ∇wf (w, ) is invertible, ∇ w = ∇wf (w , ) −1∇ f (w , ). We wish

G −N to show that ∇wf (w , ) = N T 0 is non-singular.

The Schur complement of ∇vf (Q ( ), ) with respect to the lower block diagonal component 0 is N T G−1N . From

Assumptions 3 and 2, N T has full row rank and G 0.

Therefore N T G−1N is positive deﬁnite and non-singular

and equivalently, ∇wf (w , ) 0 and non-singular.

The partial gradient of f (w , ) with respect to is

∇ f (w , ) = J 0 . 00

We use Gaussian elimination to invert ∇wf (w , ) and get (∇Q( )f (Q ( ), ))−1 = CA DB .

where A = G−1 − G−1N (N T G−1N )−1N T G−1, B = −G−1N (N T G−1N )−1, C = BT , D = (N T G−1N )−1.
We decompose w to its components and solve for ∇ y ,

y 

G−1(J − N (N T G−1N )−1N T G−1J ) 0

∇ ν  = −

−(N T G−1N )−1N T G−1J

0,

λ

where the ﬁrst row corresponds to ∇ y ( ) and the second row corresponds to ∇ ν λ T . The ﬁrst block corre-
sponds to ∇ y ( ). Note that because y ( ) > 0, we can

express the optimal cost as

= E˜T 1 ν = N ν .

λ

λ

The sensitivity of the costs with respect to perturbation is

∇ = N ∇ ν = N (N T G−1N )−1N T G−1J. λ

A. Stochastic Braess Paradox
In the routing game literature, a well-known phenomenon that is related to the sensitivity of optimal routes is Braess paradox [14]. The phenomenon refers to the paradoxical effect that occurs when costs of traversing edges are decreased, resulting in an increase in player’s average cost. We show that a similar behaviour exists in MDP congestion games, and its occurrence can be linked to the underlying hypergraph structure through sensitivity analysis. Consider the social cost of an MDP congestion game, J(y, ) = yT (y).
Stochastic Braess paradox can be deﬁned by the sensitivity of the social cost of MDP congestion games.

Deﬁnition 2 (Stochastic Braess Paradox). For two MDP congestion games (3) satisfying Assumption 2 deﬁned on the same hypergraph, their respective costs and ¯ satisﬁes
(y) − ¯(y) ≥ 0, ∀{y | Ey = 0, 1T y = M, y ≥ 0}.

Let the optimal population distribution be y and y¯ , respec-
tively. A stochastic Braess paradox occurs when the social cost satisﬁes J(y , ) < J(y¯ , ¯).
When and ¯ are instantiated by different values of the same continuously differentiable function (·, ), the exis-
tence of Braess paradox suggests that there is a perturbation which increases the state-action costs from ¯ to such that J(y , ) < J(y¯ , ¯).

Corollary 1 (Sufﬁcient Conditions for stochastic BP). Consider a feasible MDP congestion game (3) which satisﬁes Assumptions 2 and 3 with an optimal population distribution y > 0. Its social cost sensitivity can be deﬁned as

∇ J =(G−1N (N T G−1N )−1)−1N T G−1 − G−1) (y )

+ N (N T G−1N )−1N T G−1y .

(7)

Then, ∇ J

∈/

|S ||A|
R+

is

a

sufﬁcient

condition

for

the

occurrence of stochastic Braess paradox.

Proof. J is bilinear and therefore continuously differentiable in and y . From Theorem 1, there exists a neighbourhood
≤ δ within which J is continuously differentiable in , and the Jacobian is given as

∇ J( , y ) = ∇y J∇ y + ∇ J∇ .

For any ∇ J ∈/ R|+S||A|, there exists

∈

|S ||A|
R+

such

that

≤ δ and T ∇ J < 0. We then consider the MDP

congestion game with costs ¯ and equilibrium y¯ , where ¯

is deﬁned by

¯= + .

By the mean value theorem, there exists k ∈ (0, 1] where J(y¯ , ¯ ) = J(y , ) + (k )T ∇ J.
Since k T ∇ J(δ) < 0, J(y¯ , ¯) < J(y , ) holds.

V. ROLE OF STOCHASTICITY
In this section, we consider the deterministic counterpart of MDP congestion games to evaluate how the introduction of stochasticity inﬂuences social cost sensitivity.

A. Cycle Game
A directed primal graph [25] Gd = ([S], Ed) can be derived from a hypergraph G = ([S], E), by considering the same set of states and deﬁne edge set Ed deﬁned by

e = (s1, s2) ∈ Ed if ∃ (s1, a) s.t. Ps2s1a > 0.

Its incidence matrix D ∈ RS×Ed is given by

  1, 
[D]ie = −1,

if edge e starts at state i, if edge e ends at state i,

 

0,

otherwise.

An MDP congestion game (3) can be played on Gd for a

given cost . The constraint Dy = 0 implies that any feasible

population distribution must be a combination of cycles of

Gd [26]. Therefore, we call a deterministic MDP congestion

game where all state-action pairs lead to deterministic out-

comes, a cycle game [2].

The edge set of a primal graph dictates allowable transi-

tions over state space [S], where as a hyperarc corresponds

to a discrete set of particular probability distributions as-

signments to these allowable transitions as given by Ed.

We

consider

a

transformation

T

∈

|Ed |×|E |
R+

between

the

incidence matrix of a hypergraph E and its host graph D,

such that E = DT . Columns of T denote how an action a

distributes mass over edges adjacent to s of the primal graph,

T(s1,s2),(s,a) = P0,s2as, os1th=erws,ise. (8)

In addition to being element-wise non-negative, T is also column stochastic—i.e.,

Te,(s,a) = Ps as = 1.

e∈Ed

s ∈S

An example is given in Fig. 2 in which labeled edges are deﬁned between states {A, B, C}. The incidence and transformation matrices corresponding to Fig. 2 is given by

 0 −1 0 1 

0.4 0 0 0

D =  1 1 −1 0  , T = 0.6 1 0 0 .

−1 0 1 −1

 0 0 1 0

0 001

The eigenvalues of T characterize the amount of stochasticity introduced by the MDP dynamics. When T = I, the MDP congestion game is itself a cycle game with no stochasticity. When each state-action pair uniformly distributes the probability over available edges, T has a block diagonal structure with eigenvalues less than 1 if a state has two or more actions available. Fig. 2 also provides an example of a feasible transformation T that is invertible.

Fig. 2. Example graph structure of a cycle game.

B. Effects of Stochasticity
When the incidence matrix of a hypergraph is related to the incidence matrix of the corresponding primal graph by an invertible transformation T , there is a direct relationship between the equilibria of the MDP congestion game and cycle game played on these graphs.

Assumption 5 (Invertible Transformation T ). A directed hypergraph G = ([S], E) can be induced from its directed primal graph Gd = ([S], Ed), such that |E| = |Ed|, and the incidence matrices, E and D, of the two graphs, respectively, are related by an invertible transformation T .

E = DT,

T ∈ R+|Ed|×|E|, 1T T = 1T .

Proposition 2 (Equilibria Relationship). If the graph G of an MDP congestion game satisﬁes Assumption 5, y > 0 is an MDP Wardrop equilibrium if and only if T y is an equilibrium of the cycle game deﬁned on Gd with costs e on its edges where

e(·) = T −T sa ◦ T −1(·).

Proof. Consider an MDP Wardrop equilibrium y that satisﬁes Assumption 4, then there exists primal variable solution y and dual variables ν , λ that satisfy the KKT conditions (5) with µ = 0. We can re-write H(y, ν, λ, µ) = 0 from (5) with transformations DT = E and z = T y , and µ = 0,

T −T (T −1z ) − DT ν − λ T −T 1 = 0,

Dz = 0,

(9)

1T T −1z − M = 0.

Since T is element-wise non-negative, and y > 0, T y = z > 0. By construction, T −1 is column stochastic, therefore T −T 1 = 1. Therefore (9) is equivalent to the KKT conditions of a game with cost T −T ◦ ◦ T −1, deterministic
incidence matrix D, and optimal population distribution z . We note that T −T (∇ )T −1 is positive deﬁnite, and while
an individual state-action cost (T −T ◦ ◦ T −1)sa requires multiple hyperarcs’ population distribution to deﬁne the
congestion cost at (s, a), it deﬁnes a potential game [1]
consistent with Assumption 2. This implies that (9) coincides
with the KKT conditions of a cycle game formulation with costs T −T ◦ ◦T −1, incidence matrix D, and mass M . Since
z > 0 satisﬁes the KKT conditions of this cycle game, z is
the cycle game’s unique optimal population distribution.

The relationship between the equilibria of the deterministic game and the equilibria of the game allows for a direct

comparison between the sensitivity of the social cost in the two games. We show next that the social cost sensitivity of a MDP congestion game can be directly bounded by the eigenvalues of T , ie the amount of stochasticity introduced.

Theorem 2 (Effects of Stochasticity). We consider an MDP congestion game (3) and a cycle game (Section V-A) whose graphs satisfy Assumption 3. Let the social cost of the cycle game be Jc, and the social cost of the MDP congestion game be J, the sensitivity of the cycle game can be bounded by

∇ Jc 2 ≤ T 2 ∇ J 2 .

Proof. Let Nc = D¯ T 1 , where D¯ is D with any one row removed. From Assumption 3, the removed row cannot be
identically zero as that would ensure rank(D) ≤ S −2, then Nc is related to N = E¯T 1 by T T Nc = N where E¯ has the same row removed.
Since z = T y , the sensitivity of the cycle game social cost Jc = (z )T T −T (T −1z ) can be evaluated at (y , ),

∇ Jc

y = T −T AT T T 0

(y )

0

TB

y. (y )

where A = N (N T G−1N )−1N T G−1 and B = G−1 − G−1N (N T G−1N )−1)−1N T G−1. In comparison, the sen-
sitivity of the MDP congestion game’s social cost is

∇J y = A 0

(y )

0B

y. (y )

We can compare the social cost sensitivity Jacobian for the cycle game and the MDP congestion game, denoted by Mc and M respectively.
Mc 2 = σmax{T −T AT T T, T B} (10) ≤ T 2 M 2.

Theorem 2 states that given equivalent Wardrop equilibria, the sensitivity of the social cost in the deterministic cycle game is always bounded by the sensitivity of the MDP congestion game and the amount of stochasticity introduced. Since T 2 ≤ 1, Theorem 2 states that introducing stochasticity increases effects of Braess paradox.
VI. SIMULATIONS
In this section, we use the results of sensitivity analysis on a hypergraph derived from a directed Wheatstone graph. Wheatstone structure is known to induce Braess paradox for non-atomic routing games [15], we analyze its behaviour under stochastic transitions and show that not only does stochastic Braess paradox also occur, but we can avoid the paradox by our sensitivity analysis. We demonstrate Theorem 1 by cost perturbations in both the negative and positive directions of the social cost sensitivity, and validating the predictions with simulated results.
Consider an MDP congestion game deﬁned on hypergraph shown in Figure 3. We play the MDP congestion game deﬁned by (3), with a scaled mass M = 1. The cost functions are deﬁned as sa(ysa) = Asaysa + bsa.

6

B

1

32

A

D

5

4

C

Fig. 3. Hypergraph structure of MDP congestion game

Asa bsa

19

1

2 0.1 1

3 0.1 0

49

1

5 0.1 0.1

6 0.1 0

TABLE I DISTRIBUTION DEPENDENT HYPERARC COSTS

All state-action pairs correspond to hyperarcs, but all state-action pairs except for hyperarc 3 deﬁne deterministic actions. The stochastic incidence matrix is deﬁned by
 1 0 0 0 1 −1 E = −1 1 1 0 0 0  .
 0 0 −0.9 1 −1 0  0 −1 −0.1 −1 0 1
Note that when a hyperarc has one head state, its corresponding column of incidence matrix E is identical to that of the cycle game incidence matrix D (Section V-A). Stochastic hyperarcs are convex combinations of the deterministic edges that correspond to allowable state transitions originating from the same tail state.
We simulate each MDP congestion game by solving the convex optimization formulation given by (3) with cvxpy. First, we verify in Figure 4 that at given costs , the optimal population distribution y is strictly positive.

Population Distribution

0.2

0.1

0.0

2

4

6

State Action Pairs

Fig. 4. Optimal population distribution at with link costs from table I

We consider perturbing the hyperarc costs modelled by ¯(·, ) = (·)+ . Sensitivity of social cost can be analytically
derived from Theorem 1 based on the hypergraph structure as ∇ J = 0.023 0.501 −0.478 0.023 0.454 0.477 T .
The sensitivity vector ∇ J implies that increasing the third
hyperarc cost would result in the most decrease in social cost,
while increasing the second hyperarc cost would result in the

1

0

0.00

0.25

0.2

0.0

0.00

0.25

Fig. 5. Braess Paradox: Perturbing game costs with [0, 0, 1, 0, 0, 0], where ∈ R+ increases along x-axis. Right shows the game optimal population distribution on each hyperarc. Left shows the social cost at optimal population distribution (blue) and the sensitivity for hyperarc 3 varying with (orange).

most increasing in social cost. We verify both scenarios by successively increasing and re-evaluating the social cost at the optimal population distribution y ( ), as solved by cvxpy. The results are shown in Figures 5 and 6.

1.0

0.8

0.6

0.00

0.05

0.2

0.1

0.0

0.00

0.05

Fig. 6.

No Braess Paradox: Perturbing the game costs with

[0, 1, 0, 0, 0, 0], where ∈ R+ increases along x-axis. Right shows

the game optimal population distribution on each hyperarc. Left shows the

social cost at optimal population distribution (blue) and the sensitivity value

for hyperarc 2 at given (orange).

A couple conclusions can be drawn from Figures 5 and 6. First, we see that there exists a continuous region around
where y ( ) > 0, and therefore renders this sensitivity analysis valid. Figure 5 shows a negative sensitivity value for the third hyperarc as we increase , which implies stochastic Braess paradox. Then as predicted, the social cost decreases as is increased. In contrast, Figure 6 shows a positive sensitivity value for the second hyperarc as we increase , therefore the social cost should not decrease as increases. This is also conﬁrmed as the social cost obtained from the output of cvxpy increases with . Both Braess paradox and the absence of Braess paradox is correctly predicted for the regions where positive mass exists on every hyperarc.
VII. CONCLUSIONS
We derived sensitivity analysis for MDP congestion games when the optimal population distribution is strictly positive. From the sensitivity of optimal cost and population distribution to changes in state-action cost, we derived sufﬁcient conditions for the occurrence of stochastic Braess paradox deﬁned in terms of network and cost structure. Finally, we considered effects of stochasticity on the magnitude of Braess paradox. Our simulations explicitly show the occurrence of stochastic Braess paradox on MDP congestion games. Future work include generalizing the analysis to MDP

congestion games whose optimal population distribution is
not strictly positive.
REFERENCES
[1] D. Calderone and S. S. Sastry, “Markov decision process routing games,” in Proc. Int. Conf. Cyber-Physical Syst. ACM, 2017, pp. 273–279.
[2] D. Calderone and S. Shankar, “Inﬁnite-horizon average-cost markov decision process routing games,” in Proc. Intell. Transp. Syst. IEEE, 2017, pp. 1–6.
[3] C.-S. N. Shiau and J. J. Michalek, “Optimal product design under price competition,” J. Mech. Design, vol. 131, no. 7, p. 071003, 2009.
[4] J. G. Wardrop, “Some theoretical aspects of road trafﬁc research,” in Inst. Civil Engineers Proc. London/UK/, 1952.
[5] M. Beckmann, “A continuous model of transportation,” Econometrica, pp. 643–660, 1952.
[6] M. Patriksson, The trafﬁc assignment problem: models and methods. Courier Dover Publications, 2015.
[7] L. S. Shapley, “Stochastic games,” Proc. Nat. Acad. Sci., vol. 39, no. 10, pp. 1095–1100, 1953.
[8] J.-F. Mertens and A. Neyman, “Stochastic games,” Int. J. Game Theory, vol. 10, no. 2, pp. 53–66, 1981.
[9] R. Tobin and T. Friesz, “Sensitivity analysis for equilibrium network ﬂow,” Transp. Sci., vol. 22, no. 4, pp. 242–250, 1988.
[10] Y. Qiu and T. L. Magnanti, “Sensitivity analysis for variational inequalities,” Math. Op. Res., vol. 17, no. 1, pp. 61–76, 1992.
[11] M. Patriksson, “Sensitivity analysis of trafﬁc equilibria,” Transp. Sci., vol. 38, no. 3, pp. 258–281, 2004.
[12] T. Yamada and Z. Febri, “Freight transport network design using particle swarm optimisation in supply chain–transport supernetwork equilibrium,” Transp. Res., vol. 75, pp. 164–187, 2015.
[13] H. Bar-Gera, F. Hellman, and M. Patriksson, “Computational precision of trafﬁc equilibria sensitivities in automatic network design and road pricing,” Procedia-Social and Behav. Sci., vol. 80, pp. 41–60, 2013.
[14] D. Braess, “ U about a paradox of trafﬁc planning,” Op. Res., vol. 12, no. 1, pp. 258–268, 1968.
[15] I. Milchtaich, “Network topology and the efﬁciency of equilibrium,” Games and Econ. Behav., vol. 57, no. 2, pp. 321–346, 2006.
[16] S. V. Ukkusuri, T. V. Mathew, and S. T. Waller, “Robust transportation network design under demand uncertainty,” Comput.-Aided Civil and Infrastructure Eng., vol. 22, no. 1, pp. 6–18, 2007.
[17] H. Liu and D. Z. Wang, “Global optimization method for network design problem with stochastic user equilibrium,” Transp. Res., vol. 72, pp. 20–39, 2015.
[18] S. D. Clark and D. P. Watling, “Sensitivity analysis of the probit-based stochastic user equilibrium assignment model,” Transp. Res., vol. 36, no. 7, pp. 617–635, 2002.
[19] F. Parise and A. Ozdaglar, “A variational inequality framework for network games: Existence, uniqueness, convergence and sensitivity analysis,” Games and Econ. Behav., 2019.
[20] E. Altman, Constrained Markov decision processes. CRC Press, 1999, vol. 7.
[21] B. of Public Roads, “Trafﬁc assignment manual,” US Dept. of Commerce, 1964.
[22] A. Epstein, M. Feldman, and Y. Mansour, “Efﬁcient graph topologies in network routing games,” Games and Econ. Behav., vol. 66, no. 1, pp. 115–125, 2009.
[23] G. Gallo, G. Longo, S. Pallottino, and S. Nguyen, “Directed hypergraphs and applications,” Discrete Applied Math., vol. 42, no. 2-3, pp. 177–201, 1993.
[24] A. L. Dontchev and R. T. Rockafellar, “Implicit functions and solution mappings,” Springer Monographs in Math., vol. 208, 2009.
[25] I. Adler, G. Gottlob, and M. Grohe, “Hypertree width and related hypergraph invariants,” Eur. J. of Combinatorics, vol. 28, no. 8, pp. 2167–2181, 2007.
[26] C. Godsil and G. Royle, “Cuts and ﬂows,” in Algebraic Graph Theory. Springer, 2001, pp. 307–339.

