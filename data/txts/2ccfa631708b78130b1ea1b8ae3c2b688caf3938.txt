Proceedings of Machine Learning for Healthcare 2017

JMLR W&C Track Volume 68

arXiv:1702.05386v3 [stat.ML] 13 Jul 2017

Predicting Surgery Duration with Neural Heteroscedastic Regression
Nathan H Ng1, Rodney A Gabriel2,3, Julian McAuley1, Charles Elkan1, Zachary C Lipton1,2 ∗ Department of Computer Science1 Division of Biomedical Informatics2 Department of Anesthesiology3 University of California, San Diego 9500 Gilman Drive La Jolla, CA 92093, USA {nhng, ragabriel, jmcauley, elkan, zlipton}@ucsd.edu
Abstract
Scheduling surgeries is a challenging task due to the fundamental uncertainty of the clinical environment, as well as the risks and costs associated with under- and over-booking. We investigate neural regression algorithms to estimate the parameters of surgery case durations, focusing on the issue of heteroscedasticity. We seek to simultaneously estimate the duration of each surgery, as well as a surgery-speciﬁc notion of our uncertainty about its duration. Estimating this uncertainty can lead to more nuanced and effective scheduling strategies, as we are able to schedule surgeries more efﬁciently while allowing an informed and case-speciﬁc margin of error. Using surgery records from a large United States health system we demonstrate potential improvements on the order of 20% (in terms of minutes overbooked) compared to current scheduling techniques. Moreover, we demonstrate that surgery durations are indeed heteroscedastic. We show that models that estimate case-speciﬁc uncertainty better ﬁt the data (log likelihood). Additionally, we show that the heteroscedastic predictions can more optimally trade off between over and under-booking minutes, especially when idle minutes and scheduling collisions confer disparate costs.
1. Introduction
In the United States, healthcare is expensive and hospital resources are scarce. Healthcare expenditure now exceeds 17% of US GDP (World Bank, 2014), even as surgery wait times appear to have increased over the last decade (Bilimoria et al., 2011). One source of inefﬁciency (among many) is the inability to fully utilize hospital resources. Because doctors cannot accurately predict the duration of surgeries, operating rooms can become congested (when surgeries run long) or lie vacant (when they run short). Over-booking can lead to long wait times and higher costs of labor (due to over-time pay), while under-booking decreases throughput, increasing the marginal cost per surgery.
At present, doctors book rooms according to a simple formula. The default time reserved is simply the mean duration of that speciﬁc procedure. The procedure code does in fact explain a signiﬁcant amount of the variance in surgery durations. But by ignoring other signals, we hypothesize that the medical system leaves important signals untapped.
We address this issue by developing better and more nuanced strategies for surgery case prediction. Our work focuses on a collection of surgery logs recorded in Electronic Health Records (EHRs) at a large United States health system. For each patient, we consider a collection of pre-operative features, including patient attributes (age, weight, height, sex, co-morbidities, etc.), as well as attributes of the clinical environment, such as the surgeon, surgery location, and time. For each procedure, we also know how much time was originally scheduled, in addition to the actual ‘ground-truth’ surgery duration, recorded after each procedure is performed.
∗. Corresponding author, website: http://zacklipton.com
c 2017.

We are particularly interested in developing methods that allow us to better estimate the uncertainty associated with the duration of each surgery. Typically, neural network regression objectives assume homoscedasticity, i.e., constant levels of target variability for all instances. While mathematically convenient, this assumption is clearly violated in data such as ours: as one might surmise intuitively that operations that typically take a long time tend to exhibit greater variance than shorter ones. For example, among the 30 most common procedures, epidural injections are both the shortest procedures and the ones with the least variance (Figure 1). Among the same 30 procedures, exploratory laparotomy and major burn surgery exihibit the greatest variance. All procedures exhibit long (and one-sided) tails.
To model this data, we revisit the idea of heteroscedastic neural regression, combining it with expressive, dropout-regularized neural networks. In our approach, we jointly learn all parameters of a predictive distribution. In particular, we consider Gaussian and Laplace distributions, each of which is parameterized by a mean and standard deviation. We also consider Gamma distributions, which are especially suited to survival analysis. Unlike the Gaussian and Laplace which are long tailed on both ends, the gamma has a long right tail and has only positive support (i.e., it assigns zero probability density to any value less than zero). The restriction to positive values suits the modeling of durations or other survival-type data. While the gamma distribution (and the related Weibull distribution) has been applied to medical data with classical approaches Bennett (1983); Sahu et al. (1997), this is, to our knowledge, the ﬁrst to approximate the a parameters of a gamma distribution using modern neural network approaches.
Our heteroscedastic models better ﬁt the data (as determined by log likelihood) compared to both current practice and neural network baselines that fail to account for heteroscedasticity. Furthermore, our models produce reliable estimates of the variance, which can be used to schedule intelligently, especially when over-booking and under-booking confer disparate costs. These uncertainty estimates come at no cost in performance by traditional measures. The best-performing Gamma MLP model achieves a lower mean squared error than a vanilla least squares (Gaussian) MLP, despite optimizing a different objective.
2. Dataset
Our dataset consists of patient records extracted from the EHR system at a large United States hospital. Speciﬁcally, we selected 107,755 records corresponding to surgeries that took place between 2014 and 2016. These surgeries span 995 distinct procedures, and were performed by 368 distinct surgeons. Histograms of both are long-tailed, with over 796 procedures performed fewer than 100 times and 213 doctors performing fewer than 100 surgeries each. Moreover the data contains several clerical mistakes in logging the durations. For example, a number of surgeries in the record were reported as running less than 5 minutes. Discussions with the hospital experts suggest that this may indicate either clerical errors or an inconsistently applied convention for logging canceled surgeries. Additionally, several surgeries were reported to run over 24 hours, suggesting (rare) clerical errors in logging the end times of procedures. We remove all surgeries reported to take less than 5 minutes or more than 24 hours from the dataset. This preprocessing left us with roughly 80% of our original data (86,796 examples). For our experiments, we split this remaining data 80%/8%/12% for training/validation/testing.
2.1 Inputs
For each surgery, we extracted a number of pre-operative features from the corresponding EHRs. We restrict attention to features that are available for a majority of patients and (to avoid target leaks) exclude any information that is charted during or following the procedure. Our features fall into several categories: patient, doctor, procedure, and context.
Patient features: For each of our patients, we include the following features:
• Size: Patient height and weight are real-valued features. We normalize each to mean 0, variance 1.
• Age: A categorical variable, binned according to ten-year wide intervals that are open on the left side (0 − 10], (10 − 20], . . . None of the patients in our cohort are zero years old.
2

Figure 1: Distributions of durations for the 30 most common procedures.
• ASA score: an ordinal score that represents the severity of a patient’s illness. For example, ASA I denotes a healthy patient, ASA III denotes severe systemic disease, and ASA V denotes that the patient is moribund without surgery. ASA VI refers to a brain-dead patient in preparation for organ transplantation.
• Anesthesia Type: This categorical feature represents the type of anesthesia applied to sedate the patient. The values assigned to this variable include General, Monitored anesthesia care (MAC)—in which a patient undergoes local anesthesia together with sedation, Neuraxial, No Anesthesiologist, and other/unknown.
• Patient Class: This categorical feature indicates the patient’s current status. The values assigned to this variable include Emergency Department Encounter, Hospital Outpatient Procedure, Hospital Outpatient Surgery, Hospital Inpatient Surgery, Trauma Inpatient Admission, Inpatient Admission, Trauma Outpatient.
• Comorbidities: We model the following co-morbidities as binary variables: smoker status, atrial ﬁbrillation, chronic kidney disease, chronic obstructive pulmonary disease, congestive heart failure, coronary artery disease, diabetes, hypertension, cirrhosis, obstructive sleep apnea, cardiac device, dialysis, asthma, and dementia.
Doctor: We represent the doctor performing the procedure (categorical) using a one-hot vector. The doctor feature exhibits considerable class imbalance, with the most proliﬁc doctor performing 3770 surgeries and the least proliﬁc doctor (in the pruned dataset) performing 100.
3

Feature
Age Sex Weight Height Time of Day Day of Week Month Location Patient Class ASA Rating Anesthesia Type Surgeon Procedure Smoker Heart Arrhytmia Chronic Kidney Disease Congestive Heart Failure Coronoary Artery Disease Type II Diabetes Hypertension Liver Cirrhosis Sleep Apena Cardiac Device Dialysis Asthma Dementia Cognitive Impairment

Abbreviation
age sex weight height hour day month location class asa anesthesia surgeon procedure smoker aﬁb ckd chf cad diabetes htn cirrhosis osa cardiac_device dialysis asthma dementia cognitive

Type
Categorical Binary Numerical Numerical Categorical Categorical Categorical Categorical Categorical Categorical Categorical Categorical Categorical Binary Binary Binary Binary Binary Binary Binary Binary Binary Binary Binary Binary Binary Binary

#Categories
9 2 8 7 12 10 7 6 5 155 199 2 2 2 2 2 2 2 2 2 2 2 2 2 2

Table 1: Summary of features.

Mode
50-60 Female 9:00-12:00 Friday March Hospital Outpatient None General Colonoscopy No No No No No No No No No No No No No No

Procedure: We represent the procedure performed as a one-hot vector. The most common operations tend to be minor GI procedures: the four most frequent procedures are colonoscopy, upper GI endoscopy, cataract removal, and abdominal paracentesis. This distribution is also long-tailed with 11,173 colonoscopies.
Context: We represent the context of the procedure with several categorical variables. First, we represent the hour of the day as a categorical variable with values binned into 8 non-overlapping 3-hour width buckets. Second, we represent the day of the week and month of the year each as one-hot vectors. Finally, we similarly represent the location of the operations as a one-hot vector.
We summarize the number and kind of features in our dataset in Table 1. We handle variables with missing values, including height, weight, and hour of the day, by incorporating missing value indicators, following previous work on clinical datasets (Lipton et al., 2016).

3. Methods
This paper addresses the familiar task of regression. We start off by refreshing some basic preliminaries. Given a set of examples {xi}, and corresponding labels {yi}, we desire a model f that outputs a prediction yˆ = f (x). The task of the machine learning algorithm is to produce the function f given a dataset D consisting of examples X and labels y. Generally, we seek predictions that are somehow close to y, as

4

determined by some computable loss function L. Most often we minimize the squared loss L = for all instances (xi, yi).

i(yi − yˆi)2

One popular method for producing such a function is to choose a class of functions f parameterized by

some values θ. Linear models are the simplest examples of this approach. To train a linear regression model,

we deﬁne f (x) = θT x. Then we solve the following optimization problem:

θ∗ = argminθL(y, yˆ)

over some training data and evaluate the model by its performance on previously unseen data. For linear models, the error-minimizing parameters (on the training data) can be calculated analytically. For all modern deep learning models, no analytic solution exists, so optimization typically proceeds by stochastic gradient descent.
For neural network models, we change only the function f . In multilayer perceptrons (MLP) for example, we transform our input through a series of matrix multiplications, each followed by a nonlinear activation function. Formally, an L-layer MLP for regression has the simple form

yˆ = WL · φ(WL−1 · . . . · φ(W1 · x + b1) + . . . + bL−1) + bL ,

where φ is an activation function such as sigmoid, tanh, or rectiﬁed linear unit (ReLU) and θ consists of the full set of parameters Wl and bl.
We might view the loss function (squared loss) as simply an intuitive measure of distance. Alternatively, it’s possible to derive the choice of squared loss by viewing regression from a probabilistic perspective. In the probabilistic view, a parametric model outputs a distribution P (y|x).
In the simplest case, we can assume that the prediction yˆ is the mean of a Gaussian predictive distribution with some variance σ. In this view, we can calculate the probability density of any y given x, and thus can choose our parameters according to the maximum likelihood principle:

MLE

n1

−(yi − yˆi)2

n

(yi − yˆi)2

θ = max √ exp

θ

2πσˆ2

2σˆ2

= min
θ

log(σˆi) + 2σˆ2

.

(1)

i=1

i=1

Assuming constant σˆ, this yields a familiar least-squares objective. In this work, we relax the assumption of constant variance (homoscedasticity), predicting both yˆ(θ, x)
and σˆ(θ, x) simultaneously. While we apply the idea to MLPs, it is easily applied to networks of arbitrary architecture. To predict the standard deviation σˆ of the predictive distribution, we modify our MLP to have two outputs: The ﬁrst output has linear activation and we interpret its output as the conditional mean yˆ. The second output models the conditional variance σˆ. To enforce positivity of σˆ, we run this output through the softplus activation function softplus(z) = log(1 + exp(z)).
We extend the same idea to Laplace distributions, which turn out to better describe the target variability for surgery duration, and are also maximum likelihood estimators when optimizing the Mean Absolute Error (MAE). Mean Absolute Error corresponds to the average number of minutes over or underbooked, and is typically√the quantity of interest for this type of scheduling task. The Laplace distribution is parameterized by b = 2σ:

θMLE = max n 1 exp −|yi − yˆi| = min n log b + |yi − yˆi| . (2)

2b

b

θ

b

i=1

i=1

Finally, we apply the same technique to perform neural regression with gamma predictive distributions. The gamma distribution has strictly positive support and is long-tailed on the right. Since surgeries and other survival-type data have nonnegative lengths, probability distributions with similarly nonnegative support such as the gamma distribution (compared to the real-valued support of the Gaussian and Laplace distributions), might better describe surgery duration. Formally, the expected time between surgeries (or their associated durations) follows a gamma distribution when surgery start times are modeled as a Poisson process.

5

The gamma distribution is parametrized by a shape parameter k and a scale parameter Φ:

MLE

n

1

k−1

−yi

n

yi

θ

= max

Γ(k)Φk yi

exp

Φ

= min
θ

log(Γ(k)) + k log Φ − (k − 1) log yi + Φ . (3)

i=1

i=1

In this case, the model now needs to predict two values: kˆ(θ, x) and Φˆ (θ, x). As before, our MLP has two outputs, with both passed through a softplus activation to enforce positivity.

4. Experiments
We now present the basic experimental setup. For all experiments we use the same 80%/8%/12% training/validation/test set split. Model weights are updated on the training set and we choose all non-differentiable hyper-parameters and architecture details based on validation set performance. In the ﬁnal tally, we have 441 features, the majority of which are sparse and accounted for by the one-hot representations over procedures and doctors. We express our labels (the surgery durations) as the number of hours that each procedure takes.
Baselines We consider three sensible baselines for comparison. The ﬁrst is to follow the current heuristic of predicting the average time per procedure. Note that this is equivalent to training an unregularized linear regression model with a single feature per procedure and no others. Although the main technical contribution of this paper is concerned with modeling heteroscedasticity, we are also generally interested to know how much performance the current approach leaves untapped. This baseline helps us to address this question. We also compare against linear regression. While we tried applying 2 regularization, choosing the strength of regularization λ on holdout data, this did not lead to improved performance. Finally, we compare against traditional multilayer perceptrons. To calculate NLL for models that assume homoscedasticity, we choose the constant variance that minimizes NLL on the validation set.
Training Details For all neural network experiments, we use MLPs with ReLU activations. We optimize each network’s parameters by stochastic gradient descent, halving the learning rate every 50 epochs. For each experiment, we used an initial learning rate of .1. To determine the architecture, we performed a grid search over the number of hidden layers (in the range 1-3) and over the number of hidden nodes, choosing between 128, 256, 384, 512. As determined by our hyper-parameter optimization, for homoscedastic models, all MLPs use 1 hidden layer with 128 nodes. All heteroscedastic models use 1 hidden layer with 256 nodes. All models use dropout regularization.
For our basic quantitative evaluation, we report the root mean squared error (RMSE), mean absolute error (MAE), and negative log-likelihood (NLL). For heteroscedastic models, we evaluate NLL using the predicted parameters of the distribution. For the Gamma distribution, we calculate its mean as k · Φ. We use its mean as the prediction yˆ for calculating RMSE. To calculate MAE, we use the median of the Gamma distribution as yˆ. Although the median of a Gamma distribution has no closed form, it can be efﬁciently approximated.
We summarize the results in Table 2. The heteroscedastic Gamma MLP performs best as measured by both RMSE and NLL, while the Laplace MLP performs best as measured by MAE. All heteroscedastic models outperform all homoscedastic models (as determined by NLL) with the heteroscedastic Gamma MLP achieving an NLL of .4668 as compared to 1.062 by the best performing homoscedastic model (Laplace MLP). The signiﬁcant quantity when evaluating log likelihood is the difference between NLL values, corresponding to the (log of the) likelihood ratio between two models.
Plots in Figure 2 demonstrate that the predicted deviation reliably estimates the observed error, and QQ plots (Figure 3) demonstrate that the Laplace distribution appears to ﬁt our targets better than a Gaussian predictive distribution. This gives some (limited) insight into why the Laplace predictive distribution might better ﬁt our data than the Gaussian.

6

Models
Current Method Procedure Means Linear Regression MLP Gaussian MLP Gaussian HS MLP Laplace MLP Laplace HS MLP Gamma HS

RMSE
49.80 49.06 45.23 43.51 44.03 44.24 45.07 43.38

MAE
28.87 27.70 25.07 23.90 24.23 23.14 23.41 23.23

NLL
1.2385 1.2222 1.1446 1.1102 0.7325 1.0621 0.5034 0.4668

Change in NLL vs. Current Method
0.0000 0.0164 0.0939 0.1283 0.5060 0.1765 0.7351 0.7717

Table 2: Performance on test-set data (lower is better). MLP models outperform alternatives at the 1% signiﬁcance level or better.

(a) Gaussian

(b) Laplacian

(c) Gamma

(d) Gaussian

(e) Laplacian

(f) Gamma

Figure 2: Plots of predicted σˆ against absolute error with heteroscedastic Gaussian (a), Laplacian (b), and Gamma (c) models. Averaging over bins of width 0.05 (d) (e) (f), shows that σˆi is a reliable estimator of the observed error.

5. Related Work
Previous work in in the medical literature addresses the prediction of surgery duration (Eijkemans et al., 2010; Kayıs¸ et al., 2015; Devi et al., 2012), accounting for both patient and surgical team characteristics. To our knowledge ours is the ﬁrst paper to address the problem with modern deep learning techniques and the ﬁrst to model its heteroscedasticity. The idea of neural heteroscedastic regression was ﬁrst proposed by Nix and Weigend (1994), though they do not share hidden layers between the two outputs, and are only concerned with Gaussian predictive distributions. Williams (1996) use a shared hidden layer and consider the case of multivariate Gaussian distributions, for which they predict the full covariance matrix via its Cholesky factorization. Heteroscedastic regression has a long history outside of neural networks. Le et al. (2005)

7

(a) Gaussian QQ Plot

(b) Laplace QQ Plot

Figure 3: QQ plots of observed error for Gaussian and Laplace noise models. The Laplace distribution better describes observed error, with shorter tails at both ends.

address a formulation for Gaussian processes. Most related is Lakshminarayanan et al. (2016) which also revisits heteroscedastic neural regression, also using a softplus activation to enforce non-negativity. We show some successful modiﬁcations to the above work, such as the use of the Laplace distribution, but our more signiﬁcant contribution is the application of the idea to clinical medical data.
6. Discussion
Our results demonstrate both the efﬁcacy of machine learning (over current approaches) and the heteroscedasticity of surgery duration data. In this section, we explore both results in greater detail. Speciﬁcally, we analyze the models to see which features are most predictive and examine the uncertainty estimates to see how they might be used in decision theory to lower costs.
6.1 Feature Importance
First, we consider the importance of the various features. Perhaps the most common way to do this is to see which features corresponded to the largest weights in our linear model. These results are summarized in Figure 4. Not surprisingly, the top features are dominated by procedures. In particular pulmonary thromboendarterectomy receives the highest positive weight. This procedure involves a high risk of mortality, a full cardiopulmonary bypass, hypothermia and full cardiac arrest. Interestingly, even after accounting for procedures, two doctors receive high weight. One (Doctor 266) receives signiﬁcant negative weight, indicating unusual efﬁciency and another (Doctor 296) appears to be unusually slow. For ethical reasons, we maintain the anonymity of both the doctors and their specialties.
For neural network models, we evaluate the importance of each feature group by performing an ablation analysis (Figure 5). As a group, procedure codes are again the most important features. However, location, patient class, surgeon, anesthesia, and patient sex all contribute signiﬁcantly. The hour of day appears to inﬂuence the performance of our models but the day of the week does not and the month appears to merely introduce noise, leading to a reduction in test set performance. Interestingly, comorbidities also made little difference in performance. However, it is possible that these features only apply to a small subset of patients but are highly predictive for that subset.
6.2 Economic Analysis
Our aim in predicting the variance of the error is to provide uncertainty information that could be used to make better scheduling decisions. To compare the various approaches from an economic/decision-theoretic

8

Figure 4: Top 30 linear regression features sorted by coefﬁcient magnitude.
perspective, we might consider the plausible case where the cost to over-reserve the room by one minute (procedure ﬁnishes early) differs from the cost to under-reserve the room (procedure runs over). We demonstrate how the two quantities can be traded off in Figure 6.
For models that don’t output variance, we consider scheduled durations of the form yˆ + k and yˆ · k where k is a data-independent constant. In either case, by modulating k, one books more or less aggressively. The multiplicative approach performed better, likely because long procedures have higher variance than short ones. This approach is equivalent to selecting a certain percentile of each predicted distribution given a constant sigma.
For heteroscedastic models we make the trade-off by selecting a constant percentile of each predicted distribution. When the cost of over-reserving by one minute and under-reserving by one minute are equal, the problem reduces to minimizing absolute error. Around this point on the curve the homoscedastic Laplacian outperforms all other models. However, given cost sensitivity, the heteroscedastic Gamma strictly outperforms all other models.
6.3 Future Work
We are encouraged by the efﬁcacy of simple machine learning methods both to predict the durations of surgeries and to estimate our uncertainty. We see several promising avenues for future work. Most concretely, we are currently engaged in discussions with the medical institution whose data we used about introducing a trial in which surgeries would be scheduled according to decision theory based on our estimates. Regarding methodology, we look forward to expanding this research in several directions. First, we might extend the approach to modeling covariances and more complex interactions among multiple real-valued predictions. We might also consider problems like bounding box detection, requiring more complex neural architectures.
References
Steve Bennett. Log-logistic regression models for survival data. Applied Statistics, pages 165–171, 1983.
Karl Y Bilimoria, Clifford Y Ko, James S Tomlinson, Andrew K Stewart, Mark S Talamonti, Denise L Hynes, David P Winchester, and David J Bentrem. Wait times for cancer surgery in the united states: trends and predictors of delays. Annals of surgery, 253(4):779–785, 2011.
9

Figure 5: Ablation analysis of feature importance for neural models.
S Prasanna Devi, K Suryaprakasa Rao, and S Sai Sangeetha. Prediction of surgery times and scheduling of operation theaters in optholmology department. Journal of medical systems, 2012.
Marinus JC Eijkemans, Mark van Houdenhoven, Tien Nguyen, Eric Boersma, Ewout W Steyerberg, and Geert Kazemier. Predicting the unpredictable: A new prediction model for operating room times using individual characteristics and the surgeon’s estimate. The Journal of the American Society of Anesthesiologists, 2010.
Enis Kayıs¸, Taghi T Khaniyev, Jaap Suermondt, and Karl Sylvester. A robust estimation model for surgery durations with temporal, operational, and surgery team effects. Health care management science, 2015.
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncertainty estimation using deep ensembles. arXiv preprint arXiv:1612.01474, 2016.
Quoc V Le, Alex J Smola, and Stéphane Canu. Heteroscedastic gaussian process regression. In ICML, 2005. Zachary C Lipton, David C Kale, and Randall Wetzel. Modeling missing data in clinical time series with
rnns. In Machine Learning for Healthcare, 2016. David A Nix and Andreas S Weigend. Estimating the mean and variance of the target probability distribution.
In International Conference on Neural Networks. IEEE, 1994.
10

Figure 6: Total over-booking and under-booking errors for different models as we adjust predicted values. Predictions were selected by considering different percentiles of the distribution predicted for each case. For homoscedastic models, this was equivalent to multiplying each prediction by a constant value. Sujit K Sahu, Dipak K Dey, Helen Aslanidou, and Debajyoti Sinha. A weibull regression model with gamma
frailties for multivariate survival data. Lifetime data analysis, 3(2):123–137, 1997. Peter M Williams. Using neural networks to model conditional multivariate densities. Neural Computation,
1996. World Bank. Health expenditure, total (% of gdp), 2014. URL http://data.worldbank.org/
indicator/SH.XPD.TOTL.ZS.
11

