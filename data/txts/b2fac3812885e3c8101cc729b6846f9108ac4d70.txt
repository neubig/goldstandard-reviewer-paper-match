arXiv:1906.04066v1 [cs.LG] 10 Jun 2019

Stretching the Eﬀectiveness of MLE from Accuracy to Bias for Pairwise Comparisons
Jingyan Wang†, Nihar B. Shah† and R. Ravi∗
School of Computer Science† and Tepper School of Business∗ Carnegie Mellon University
{jingyanw, nihars}@cs.cmu.edu, ravi@cmu.edu
Abstract A number of applications (e.g., AI bot tournaments, sports, peer grading, crowdsourcing) use pairwise comparison data and the Bradley-Terry-Luce (BTL) model to evaluate a given collection of items (e.g., bots, teams, students, search results). Past work has shown that under the BTL model, the widely-used maximum-likelihood estimator (MLE) is minimax-optimal in estimating the item parameters, in terms of the mean squared error. However, another important desideratum for designing estimators is fairness. In this work, we consider fairness modeled by the notion of bias in statistics. We show that the MLE incurs a suboptimal rate in terms of bias. We then propose a simple modiﬁcation to the MLE, which “stretches” the bounding box of the maximum-likelihood optimizer by a small constant factor from the underlying ground truth domain. We show that this simple modiﬁcation leads to an improved rate in bias, while maintaining minimax-optimality in the mean squared error. In this manner, our proposed class of estimators provably improves fairness represented by bias without loss in accuracy.
1 Introduction
A number of applications involve data in the form of pairwise comparisons among a collection of items, and entail an evaluation of the individual items from this data. An application gaining increasing popularity is competition between pairs of AI bots (e.g., [26]). Here a number of AI bots compete with each other in pairwise matchups for a certain task, where each bot plays every other bot a certain number of times in a round robin fashion, with the goal of evaluating the quality of each bot. A second example is the evaluation of self-play of AI algorithms in their training phase [34], where again, diﬀerent copies of an AI bot play against each other a number of times. Applications involving humans include sports and online games such as the English Premier League of football [22, 2] (unoﬃcial ratings) and oﬃcial world rankings for chess (e.g., FIDE [1] and USCF [14] ratings). The inﬂuence of scientiﬁc journals has also been analyzed in this manner, where citations from one journal to another are modeled by pairwise comparisons [35].
A common method of evaluating the items based on pairwise comparisons is to assume that the probability of an item beating another equals the logistic function of the diﬀerence in the true quality of the two items, and then infer the true quality from the observed outcomes of the comparisons (e.g., the Elo rating system). Various applications employ such an approach to rating from pairwise comparisons, with some modiﬁcations tailored to that speciﬁc application. Our goal is not to study the application-speciﬁc versions, but the foundational underpinnings of such rating systems.
In this paper, we study the pairwise-comparison model that underlies [15, 4] these rating systems, namely the Bradley-Terry-Luce (BTL) model [6, 24]. The BTL model assumes that each item is associated to an unknown real-valued parameter representing the quality of that item, and assumes that the probability of an item beating another is the logistic function applied to the diﬀerence of the parameters of these two items. The BTL model is also employed in the applications of peer grading [32, 23] (where the grades of the students
1

are set as the BTL parameters to be estimated), crowdsourcing [7, 27], and understanding consumer choice in marketing [16].

1.1 BTL model and maximum likelihood estimation
Now we present a formal deﬁnition of the BTL model. Let d ≥ 2 denote the number of items. The d items are associated to an unknown parameter vector θ∗ ∈ Rd whose ith entry represents the underlying quality of item i ∈ [d]. When any item i ∈ [d] is compared with any item j ∈ [d] in the BTL model, the item i beats item j with probability

1 1 + e−(θi∗−θj∗) , (1)
independent of all other comparisons. The probability of item j beating i is one minus the expression (1) above. We consider the “league format” [4] of comparisons where every pair of items is compared k times.
We follow the usual assumption [17, 31] under the BTL model that the true parameter vector θ∗ lies in the set ΘB parameterized by a constant B > 0 and satisfy:

d

ΘB = {θ ∈ Rd | θ ∞ ≤ B and θi = 0}.

(2)

i=1

The ﬁrst constraint requires that the magnitude of the parameters is bounded by some constant B. We call this constraint the “box constraint”. A box constraint is necessary, because otherwise the estimation error can diverge to inﬁnity [31, Appendix G]. The second constraint requires the parameters to sum to 0. This is without loss of generality due to the shift-invariance property of the BTL model.
A large amount of both theoretical [19, 17, 38, 25, 31] and applied [35, 33, 7, 27] literature focuses on the goal of estimating the parameter vector θ∗ of the BTL model. A standard and widely-studied estimator is the maximum-likelihood estimator (MLE):

θ(B) = argmin (θ),

(3)

θ∈ΘB

where is the negative log-likelihood function. Letting Wij denote a random variable representing the number of times that item i ∈ [d] beats item j ∈ [d], the log-likelihood function is given by:

(θ) := ({Wij}; θ) = −

1

1

Wij log

+ Wji log

.

1 + e−(θi−θj )

1 + e−(θj −θi)

1≤i<j≤d

1.2 Metrics
Accuracy. A common metric used in the literature on estimating the BTL model is the accuracy of the estimate, measured in terms of the mean squared error. Formally, the accuracy of any estimator θ is deﬁned as:
α(θ) := sup E[ θ − θ∗ 22].
θ∗ ∈ΘB
Importantly, past work [17, 31] has shown that the MLE (3) has the appealing property of being minimaxoptimal in terms of the accuracy.

Bias. Another important desideratum for designing and evaluating estimators is fairness. For example, in sports or online games, we do not want to assign scores in such a way that it systematically gives certain players higher scores than their true quality, but at the same time gives certain other players lower scores than their true quality. In this paper, we use the standard deﬁnition of bias in statistics as the notion of

2

Bias (E[θi] − θi∗)

0.05 0.00 −0.05

MLE stretched-MLE

Estimator
Standard MLE θ(B)
Unconstrained MLE θ(∞)
Stretched MLE θ(A)

Bias
Ω( √1 )
dk
(Thm. 2.1(a))
Undeﬁned
O( d1k ) (Thm. 2.1(b))

Mean squared error O( k1 )
minimax-optimal [17, 31]
∞
O( k1 ) minimax-optimal
(Thm. 2.2(b))

−1.0 −0.5 0.0

0.5

1.0

Parameter of item (θi∗)

Figure 1: Biases on items of diﬀerent parameters, induced by the MLE and our stretched-MLE (with A = 2). Our estimator signiﬁcantly reduces the maximum magnitude of the bias across the items. Note that this ﬁgure plots the bias including its sign: A positive bias means over-estimation of the parameter, and a negative bias means under-estimation of the parameter. Each bar is a mean over 5000 iterations.

Table 1: Theoretical guarantees for the MLE θ(B), unconstrained MLE θ(∞) and the proposed stretched-MLE θ(A) (with a constant A such that A > B). The proposed stretched-MLE achieves a better rate on bias, while retaining minimax optimality in terms of accuracy. Recall that d denotes the number of items and k denotes the number of comparisons per pair.

fairness. For any estimator, the bias incurred by this estimator on a parameter is deﬁned as the diﬀerence between the expected value of the estimator and the true value of the parameter. Since our parameters are a vector, we consider the worst-case bias, that is, the maximum magnitude of the bias across all items. Formally, the bias of any estimator θ is deﬁned as:
β(θ) := sup E[θ] − θ∗ ∞.
θ∗ ∈ΘB
With this background, we now provide an overview of the contributions of this paper.
1.3 Contribution I: Performance of MLE
Our ﬁrst contribution is to analyze the widely-used MLE (3) in terms of its bias. Let us begin with a visual illustration through simulation. Consider d = 25 items with parameter values equally spaced in the interval [−1, 1], where k = 5 pairwise comparisons are observed between each pair of items under the BTL model. We estimate the parameters using the MLE, and plot the bias on each item across 5000 iterations of the simulation in Figure 1 (striped red). The MLE shows a systematic bias: it induces a negative bias (under-estimation) on the large positive parameters, and a positive bias (over-estimation) on the large negative parameters. In the applications of interest, the MLE thus systematically underestimates the abilities of the top players/students/items and overestimates the abilities of those at the bottom.
In this paper, we theoretically quantify the bias incurred by the MLE.
Theorem 1.1 (MLE bias lower bound; Informal). The MLE (3) incurs a bias β(θ(B)) lower bounded as Ω( √1 ).
dk
As shown by our results to follow, this bias is suboptimal. Our proof for this result indicates that the bias is incurred because the MLE operates under the accurately speciﬁed model with the box constraint at B. That is, the MLE “clips” the estimate to lie within the set ΘB. This issue is visible in the simulation of Figure 1 where the bias is the largest when the true values of the parameters are near the boundaries ±B.
3

For example, consider a true parameter whose value equals B. The estimate of this parameter sometimes equals the largest allowed value B (due to the box constraint), and sometimes is smaller than B (due to the randomness of the data). Therefore, in expectation, the estimate of this parameter incurs a negative bias. An analogous argument explains the positive bias when the true parameter equals or is close to −B.

1.4 Contribution II: Proposed stretched estimator and its theoretical guarantees
Our goal is to design an estimator with a lower bias while maintaining high accuracy. Since the MLE (3) is already widely studied and used, it is also desirable from a practical and computational standpoint that the new estimator is a simple modiﬁcation of the MLE (3). With this motivation in mind, an intuitive approach is to consider the MLE but without the box constraint “ θ ∞ ≤ B”. We call the estimator without the box constraint as the “unconstrained MLE”, and denote it by θ(∞), because removing the box constraint is equivalent to setting the box constraint to ∞:

θ(∞) = argmin (θ),

(4)

θ∈Θ∞

where Θ∞ := {θ ∈ Rd |

d i=1

θi

=

0}.

The

unconstrained

MLE

θ(∞)

incurs

an

unbounded

error

in

terms

of

accuracy. This is because with non-zero probability an item beats all others, in which case the unconstrained

MLE estimates the parameter of this item as ∞, thereby inducing an unbounded mean squared error.

Consequently, in this work, we propose the following simple modiﬁcation to the MLE which is a middle

ground between the standard MLE (3) and the unconstrained MLE. Speciﬁcally, we consider a “stretched-

MLE”, which is associated to a parameter A such that A > B. Given the parameter A, the stretched-MLE is

identical to (3) but “stretches” the box constraint to A:

θ(A) = argmin (θ),

(5)

θ∈ΘA

where ΘA := {θ ∈ Rd | θ ∞ ≤ A and

d i=1

θi

=

0}.

That is, ΘA simply replaces the box constraint

θ ∞ ≤ B in (2) by the “stretched” box constraint θ ∞ ≤ A.

The bias induced by the stretched-MLE (with A = 2) in the previous experiment is also shown in

Figure 1 (solid blue). Observe that the maximum bias (incurred at the leftmost item with the largest negative

parameter, or the rightmost item with the largest positive parameter) is signiﬁcantly reduced compared to the

MLE. Moreover, the bias induced by the stretched-MLE looks qualitatively more evened out across the items.

Our second main theoretical result proves that the stretched-MLE indeed incurs a signiﬁcantly lower bias.

Theorem 1.2 (Stretched-MLE bias upper bound; Informal). The stretched-MLE (5) with A = 2 incurs a bias β(θ(A)) upper bounded as O( d1k ).
Given the signiﬁcant bias reduction by our estimator, a natural question is about the accuracy of the stretched-MLE, particularly given the unbounded error incurred by the unconstrained MLE. We prove that our stretched-MLE is able to maintain the same minimax-optimal rate on the mean squared error as the standard MLE.

Theorem 1.3 (Stretched-MLE accuracy upper bound; Informal). The stretched-MLE (5) with A = 2 incurs a mean squared error α(θ(A)) upper bounded as O( k1 ), which is minimax-optimal.
This result shows a win-win by our stretched-MLE: reducing the bias while retaining the accuracy guarantee. The comparison of the MLE and the stretched-MLE in terms of accuracy and bias is summarized in Table 1. Another attractive feature of our result is that the proposed stretched-MLE is a simple modiﬁcation of the standard MLE, which can easily be incorporated in any existing implementation. It is important to note that while our modiﬁcation to the estimator is simple to implement, our theoretical analyses and the proofs are non-trivial.

4

1.5 Related work

The logistic nature (1) of the BTL model relates our work to studies of logistic regression (e.g., [28, 18, 37, 11]),

among which the paper [37] is the most closely related to ours. The paper [37] considers an unconstrained

MLE in logistic regression, and shows its bias in the opposite direction as compared to our results on the

standard MLE (constrained) in the BTL model. Speciﬁcally, the paper [37] shows that the large positive

coeﬃcients are overestimated, and the large negative coeﬃcients are underestimated. There are several

additional key diﬀerences between the results in [37] as compared to the present paper. The paper [37] studies

the asymptotic bias of the unconstrained MLE, showing that the unconstrained MLE is not consistent. On

the other hand, we operate in a regime where the MLE is still consistent, and study ﬁnite-sample bounds.

Moreover, the paper [37] assumes that the predictor variables are i.i.d. Gaussian. On the other hand, in

the BTL model the probability that item i beats item j can be written as

1
T

∗ , where each predictor

1+e−xij θ

variable xij ∈ Rd has entry i equal to 1, entry j equal to −1, and the remaining entries equal to 0.

A common way to achieve bias reduction is to employ ﬁnite-sample correction, such as Jackknife [29] and

other methods [10, 5, 12] to the MLE (or other estimators). These methods operate in a low-dimensional

regime (small d) where the MLE is asymptotically unbiased. Informally, these methods use a Taylor expansion and write the expression for the bias as an inﬁnite sum f1(nθ∗) + f2n(θ2∗) + . . ., where n is the number samples, for some functions f1, f2, . . .. These works then modify the estimator in a variety of ways to eliminate the

lower-order terms in this bias expression. However, since the expression is an inﬁnite sum, eliminating the

ﬁrst term does not guarantee a low rate of the bias. Moreover, since the functions fi are implicit functions of θ∗, eliminating lower-order terms does not directly translate to explicit worst-case guarantees.

Returning to the pairwise-comparison setting, in addition to the mean squared error, some past work has

also considered accuracy in terms of the 1 norm error [3] and the ∞ norm error [9, 8, 20]. The ∞ bound for

a regularized MLE is analyzed in [8]. Our proof for bounding the bias of the standard MLE (unregularized)

relies on a high-probability ∞ bound for the unconstrained MLE (unregularized). It is important to note

that the bound for regularized MLE from [8] does not carry to unregularized MLE, because the proof from [8]

relies on the strong convexity of the regularizer. On the other hand, our intermediate result provides a

partial answer to the open question in [8] about the ∞ norm for the unregularized MLE (Lemma A.5 in

Appendix A): We establish an ∞ bound for unregularized MLE when pobs = 1, which has the same rate as

that of the regularized MLE in [8].

Another common occurrence of bias is the phenomenon of regression towards the mean [36]. Regression

towards the mean refers to the phenomenon that random variables taking large (or small) values in one

measurement are likely to take more moderate (closer to average) values in subsequent measurements. On

the contrary, we consider items whose indices are ﬁxed (and are not order statistics). For ﬁxed indices, our

results suggest that under the BTL model, the bias (under-estimation of large true values) is in the opposite

direction as that in regression towards the mean (over-estimation of large observed values).

Finally, the paper [22] models the notion of fairness in Elo ratings in terms of the “variance”, where

an estimator is considered fair if the estimator is not much aﬀected by the underlying randomness of the

pairwise-comparison outcomes. The paper [22] empirically evaluates this notion of fairness on the English

Premier League data, but presents no theoretical results.

2 Main results
In this section, we formally provide our main theoretical results on bias and on the mean squared error.
2.1 Bias
Recall that d denotes the number of items and k denotes the number of comparisons per pair of items. The true parameter vector is θ∗ ∈ ΘB for some pre-speciﬁed constant B > 0. The following theorem provides bounds on the bias of the standard MLE θ(B) and that of our stretched-MLE θ(A) with parameter A. In
5

particular, it shows that if A is a ﬁnite constant strictly greater than B, then our stretched-MLE has a much smaller bias than the MLE when d and k are suﬃciently large.

Theorem 2.1. (a) There exists a constant c > 0 that depends only on the constant B, such that

β(θ(B)) ≥ √c ,

(6a)

dk

for all d ≥ d0 and all k ≥ k0, where d0 and k0 are constants that depend only on the constant B.

(b) Let A be any ﬁnite constant such that A > B. There exists a constant c > 0 that depends only on the constants A and B, such that

β(θ(A)) ≤ c log d + log k ,

(6b)

dk

for all d ≥ d0 and all k ≥ k0, where d0 and k0 are constants that depend only on the constants A and B.

We note that in Theorem 2.1(b), we allow A to be any positive constant as long as A > B. Therefore, the

diﬀerence between A and B can be any arbitrarily small constant. It is perhaps surprising that stretching

the box constraint only by a small constant yields such a signiﬁcant improvement in the bias. We provide

intuition behind this result in Section 2.1.1.

We devote the remainder of this section to providing a sketch of the proof of Theorem 2.1. We ﬁrst prove

Theorem 2.1(b) and then Theorem 2.1(a), because the proof of Theorem 2.1(a) depends on the proof of

Theorem 2.1(b). The complete proof is provided in Appendix A.

For Theorem 2.1(b), we ﬁrst analyze the unconstrained MLE θ(∞). By plugging θ(∞) into the ﬁrst-order

optimality condition of the negative log-likelihood function and using concentration on the comparison

outcomes, we prove an

∞ bound of the form

θ(∞) − θ∗

∞

=

O( √1 )
dk

with

suﬃciently

high

probability

(which partially resolves the open problem from [8], in the regime where pobs = 1). Next, using a second-order

mean value theorem on the ﬁrst-order optimality condition and taking an expectation, we show a result

of the form

E[θ(∞) | E] − θ∗ ∞ ≈

θ(∞) − θ∗

2 ∞

= O( d1k ),

where E

is some high-probability event (recall

from Table 1 that for unconstrained MLE, the bias E[θ(∞)] − θ∗ ∞ without conditioning on E is undeﬁned).

Finally, we show that the unconstrained MLE θ(∞) and the stretched-MLE θ(A) are identical with high

probability for suﬃciently large d and k, and perform some algebraic manipulations to ﬁnally arrive at the

claim (6b).

For Theorem 2.1(a), we ﬁrst prove a bound on the order of √1 when there are d = 2 items. Then for
d

general

d,

we

consider

the

bias

on

item

1

under

the

true

parameter

vector

θ∗

=

[B

,

−

B d−

1

,

.

.

.

,

−

B d−

1

]

.

We

construct an “oracle” MLE, such that analyzing the bias of the “oracle” MLE can be reduced to the proof of

the 2-item case, and thereby prove a bias on the order of √1 for the oracle MLE. Finally, we show that the
dk

diﬀerence between the oracle MLE and the standard MLE is small, by repeating arguments from the proof of

Theorem 2.1(b).

2.1.1 Intuition for Theorem 2.1

In this section, we provide intuition why stretching the box constraint from B to A signiﬁcantly reduces the

bias. Speciﬁcally, we consider a simpliﬁed setting with d = 2 items. Due to the centering constraint, we have

θ2∗ = −θ1∗ for the true parameters, and we have θ2 = −θ1 for any estimator θ that satisﬁes the centering

constraint. Therefore, it suﬃces to focus only on item 1. Denote µ as the random variable representing

the fraction of times that item 1 beats item 2, and denote the true probability that item 1 beats item 2 as

µ∗ :=

. 1
−(θ∗ −θ∗ )

We

consider

the

true

parameter

of

item

1

as

θ1∗

∈

[−B, B].

Then

we

have

µ∗

∈

[µ−, µ+],

1+e 1 2

where µ−

=

1 1+e2B

and µ+

=

1 1+e−2B

.

The standard MLE θ(B),

the stretched-MLE θ(A)

and the unconstrained

6

θ1

θ1(B)

θ1(∞)

θ1(A)

B
0 µ− −B

0.5
(a)

B µ+ 1 µ

θ1(B)

θ1(A)

θ1(∞)

0

B

µ+

µ0

A B

µ+

µ0

µ+

µ

(b)

(c)

(d)

Figure 2: Intuition on the sources of bias. (a) The estimators standard MLE θ(B), stretched-MLE θ(A)
and unconstrained MLE θ(∞) (on item 1), as a function of µ when there are d = 2 items. We consider θ∗ = [B, −B], under which the true probability that item 1 beats item 2 is µ+. We zoom in to the region around µ = µ+ indicated by the grey box. (b) The standard MLE θ(B) incurs a negative bias, because the estimate is required to be at most B. (c) The unconstrained MLE θ(∞) incurs a positive bias by Jensen’s inequality, because the estimator function is convex on µ ∈ (0.5, 1). (d) Our estimator balances out the negative bias and the positive bias.

MLE θ(∞) can be solved in closed form:



−B

θ1(B)(µ)

=

−

1 2

log

B



−A

θ1(A)(µ)

=

−

1 2

log

A

1 µ

−

1

1 µ

−

1

θ1(∞)(µ) = − 21 log µ1 − 1 .

if µ ∈ [0, µ−] if µ ∈ (µ−, µ+) if µ ∈ [µ+, 1].

if µ ∈ if µ ∈ if µ ∈

0,

1 1+e2A

1 1+e2A

,

1 1+e−2A

1 1+e−2A

,

1

.

See Fig. 2a for a comparison of these three estimators.
Now we consider the bias incurred by these three estimators. For intuition, let us consider the case θ1∗ = B, which incurs the largest bias in our simulation of Fig. 1. If the observation µ were noiseless (and thus equals the true probability µ+), then all three estimators would output the true parameter B. However, the observation µ is noisy, and only concentrates around µ+. To investigate how these three estimators behave diﬀerently under this noise, we zoom in to the region around µ = µ+ indicated by the grey box in Fig. 2a. (Note that the observation µ can lie outside the grey box, but for intuition we ignore this low-probability
event due to concentration.)
The behaviors of the three estimators in the grey box are shown in Fig. 2b, Fig. 2c and Fig. 2d, respectively.
For each of these estimators, the blue dots on the x-axis denotes the noisy observation of µ across diﬀerent
iterations, and the blue dots on the estimator function denotes the corresponding noisy estimates. The
expected value of the estimator is a mean over the blue dots on the estimator function. For the standard MLE θ(B) (Fig. 2b), the box constraint requires that the estimate shall never exceed B. We call this phenomenon the “clipping” eﬀect, which introduces a negative bias. For the unconstrained MLE θ(∞) (Fig. 2c), since the estimator function is convex, by Jensen’s inequality, the unconstrained MLE θ(∞) introduces a positive bias. Our proposed stretched-MLE θ(A) (Fig. 2d) lies in the middle between the standard MLE and the

7

unconstrained MLE. Therefore, the stretched-MLE balances out the negative bias from the “clipping” eﬀect and the positive bias from the convexity of the estimator function, thereby yielding a smaller bias on the item parameter. In practice, one can numerically tune the parameter A to minimize the bias across all possible parameter vector θ∗ ∈ ΘB. Simulation results on diﬀerent values of A are included in Section 3.

2.2 Accuracy
Given the result of Theorem 2.1 on the bias reduction of the estimator θ(A), we revisit the mean squared error. Past work [17, 31] has shown that the standard MLE θ(B) is minimax-optimal in terms of the mean squared error. The following theorem shows that this minimax-optimality also holds for our proposed stretched-MLE θ(A), where A is any constant such that A > B. The theorem statement and its proof follows Theorem 2 from [31], after some modiﬁcation to accommodate the bounding box parameter A.

Theorem 2.2. (a) [Theorem 2(a) from [31]] There exists a constant c > 0 that depends only on the constant B, such that any estimator θ has a mean squared error lower bounded as

α(θ)

≥

c ,

(7a)

k

for all k ≥ k0, where k0 is a constant that depends only on the constant B.

(b) Let A be any ﬁnite constant such that A > B. There exists a constant c > 0 that depends only on the constants A and B, such that

α(θ(A))

≤

c .

(7b)

k

Theorem 2.2 shows that using the estimator θ(A) retains the minimax-optimality achieved by θ(B) in terms of the mean squared error. Combining Theorem 2.1 and Theorem 2.2 shows the Pareto improvement of our estimator θ(A): the estimator θ(A) decreases the rate of the bias, while still performing optimally on the mean squared error.
The proof of Theorem 2.2 closely mimics the proof of Theorem 2(b) from [31], replacing the steps involving the domain ΘB by the stretched domain ΘA. The details are provided in Appendix B.

3 Simulations

In this section, we explore our problem space and compare the standard MLE and our proposed stretched-

MLE by simulations. In what follows, we set B = 1, and unless speciﬁed otherwise we set A = 2 and

θ∗

=

[1,

−

d

1 −1

,

−

1 d−

1

,

.

.

.

,

−

d

1 −1

].

We

also

evaluate

the

performance

of

other

values

of

θ∗

subsequently.

Error

bars in all the plots represent the standard error of the mean.

(i) Dependence on d: We vary the number of items d, while ﬁxing k = 5. The results are shown in Fig. 3. Observe that the stretched-MLE has a signiﬁcantly smaller bias, and performs on par with the MLE in terms of the mean squared error when d is large. Moreover, the simulations also suggest the rate of bias as of order √1d for the MLE and d1 for the stretched-MLE, as predicted by our theoretical results.
(ii) Dependence on k: We vary the number of comparisons k per pair of items, while ﬁxing d = 10. The results are shown in Fig. 4. As in the simulation (i) with varying d, we observe that the stretched-MLE has a signiﬁcantly smaller bias, and performs on par with the MLE in terms of the mean squared error. Moreover, the simulations also suggest the rate of bias as of order √1k for the MLE and k1 for the stretched-MLE, as predicted by our theoretical results.
(iii) Diﬀerent values of A: In our theoretical analysis, we proved bounds that hold for all constant A such that A > B. In this simulation, we empirically compare the performance of the stretched-MLE for

8

Mean squared error

9 × 10−1

10−1

MLE

stretched-MLE

8 × 10−1

Bias

10−2

MLE stretched-MLE

101

102

d

(a) Bias

7 × 10−1

101

102

d

(b) Mean squared error

Figure 3: Performance of estimators for various values of d, with k = 5 and A = 2. Each point is a mean over 10000 iterations.

Mean squared error

10−1

MLE

100

stretched-MLE

10−2

10−1

Bias

10−3

MLE

10−4

stretched-MLE

100

101

102

103

104

k

(a) Bias

10−2

10−3

100

101

102

103

104

k

(b) Mean squared error

Figure 4: Performance of estimators for various values of k, with d = 10 and A = 2. Each point is a mean over 10000 iterations.

diﬀerent values of A (note that setting A = 1 is equivalent to the standard MLE). We ﬁx d = 10, varying A ∈ [0.5, 3] and k from 1 to 100. The results are shown in Fig. 5. For the bias, we observe that the bias keeps decreasing in the range of A ∈ [0.5, 1]. This is because as we increase A to 1, the negative bias introduced by the “clipping” eﬀect is reduced. The optimal value of A for all settings of k is always greater than 1. Moreover, the optimal A seems to be closer to 1 when we increase k. This agrees with the intuition in Section 2.1.1. When k is larger, the estimate becomes more concentrated around the true parameter. Then the “clipping” eﬀect becomes smaller and can be accommodated by a smaller A. The mean squared error is insensitive to the choice of A as long as A ≥ 1.

(iv) Diﬀerent settings of the true parameter θ∗: Our theoretical result considers the worst-case
bias and accuracy. In this simulation, we empirically compare the performance of the stretched-MLE under diﬀerent settings of the true parameter vector θ∗ (again, recall that setting A = 1 is equivalent to the standard MLE). Speciﬁcally, we consider the following values of θ∗:

•

Worst

case:

θ∗

=

[1,

−

1 d−1

,

.

.

.

,

−

1 d−1

].

• Worst case (0.5): θ∗ = [0.5, − d0−.51 , . . . , − d0−.51 ]. • Bipolar: half of the values are 1, and the other half are −1.

• Linear: the values are equally spaced in the interval [−1, 1].

9

k=1 k=5

k = 25 k = 100

Mean squared error

Bias

10−1 10−2 10−3

100 10−1

1

2

3

A

(a) Bias

1

2

3

A

(b) Mean squared error

Figure 5: Performance of estimators for various values of A and k, with d = 10. Setting A = 1 is equivalent to the standard MLE. Each point is a mean over 5000 iterations.

Mean squared error

0.5

Worst case

2.5

Worst case

Worst-case (0.5)

Worst-case (0.5)

0.4

Bipolar

2.0

Bipolar

Linear

Linear

0.3

All zeros

1.5

All zeros

Bias

0.2

1.0

0.1

0.5

0.0 1 2
A
(a) Bias

3 0.0 1 2 3
A
(b) Mean squared error

Figure 6: Performance of estimators for various values of A and various settings of θ∗, with d = 10 and k = 5. Setting A = 1 is equivalent to the standard MLE. Each point is a mean over 5000 iterations.

• All zeros: all parameters are 0.
We ﬁx d = 10 and k = 5, varying A ∈ [0.5, 3] under diﬀerent settings of the true parameter vector θ∗. The results are shown in Fig. 6. Two high-level takeaways from the empirical evaluations are that the bias generally reduces with an increase in A till past B, and that the mean squared error remains relatively constant beyond A = 1 in the plotted range. In more detail, for the bias, we observe that the performance primarily depends on the largest magnitude of the items (that is, θ∗ ∞). For the settings worst case, bipolar and linear (where θ∗ ∞ = 1), the bias keeps decreasing when A is past B = 1. For the setting worst-case (0.5) (where θ∗ ∞ = 0.5), the bias keeps decreasing when A is past 0.5. This makes sense since in this case we eﬀectively have B = 0.5 (although the algorithm would not know this in practice). The bias for the setting all zeros stays small across values of A. For the mean squared error, the increase when A is past 1 is relatively small under most of the settings of the true parameter vector θ∗. The bipoloar setting has the largest increase in the mean squared error. Under this setting, all parameters θi∗ take values at the boundaries ±B, and therefore the estimates of all parameters are aﬀected by the box constraint.
(v) Sparse observations: So far we have considered a league format where k comparisons are observed
10

Bias Mean squared error

10−1

6 × 10−2

4 × 10−2 3 × 10−2
2.5 × 101

MLE stretched-MLE

5 × 101
d
(a) Bias

1 × 102

2 × 102

MLE stretched-MLE
101

6 × 100

2.5 × 101

5 × 101

1 × 102

d

(b) Mean squared error

2 × 102

Figure 7: Performance of estimators for various values of d under sparse observations, with A = 2. A number
of k = 5 comparisons are observed between any pair independently with probability pobs = √1 and none
d
otherwise. Each point is a mean over 10000 iterations.

between any pair of items. Now we consider a random-design setup, where k comparisons are observed between any pair of items independently with probability pobs ∈ (0, 1), and none otherwise [25, 8]. In our simulations, we set pobs = √1 and k = 5. We discard an iteration if the graph is not connected, since the
d
problem is not identiﬁable under such a graph. The results are shown in Figure 7. We observe that the
stretched-MLE continues to outperform MLE in terms of bias, and perform on par in terms of the mean
squared error.

4 Conclusions and discussions
In this work, we show that the widely-used MLE is suboptimal in terms of bias, and propose a class of estimators called the “stretched-MLE”, which provably reduces the bias while maintaining the minimaxoptimality in terms of accuracy. These results on the performance of the MLE and the stretched-MLE are of both theoretical and practical interest. From the theoretical point of view, our analysis and proofs provide insights on the cause of the bias, explain why stretching the box alleviates this cause, and prove theoretical guarantees in bias reduction by stretching the box. Our results on the beneﬁts of the stretched-MLE thus suggest theoreticians to consider the stretched-MLE for analysis instead of the standard MLE.
From the practical point of view, the constant B is often unknown, and practitioners oten estimate the value of B by ﬁtting the data or from past experience. Our results thus suggest that one should estimate B leniently, as an estimation smaller than or equal to the true B causes signiﬁcant bias. Moreover, our proposed estimator is a simple modiﬁcation to the MLE, which can be incorporated into any existing implementation at ease.
Our results lead to several open problems. First, it is of interest to extend our theoretical analysis to settings where the observations are sparse. For example, one may consider a random-design setup, where k comparisons are observed between any pair independently with probability pobs and none otherwise [25, 8] (also see simulation (v) in Section 3). In terms of the bias under this random-design setup, we think that the lower-bound for MLE and the upper-bound for our stretched-MLE also depend on d and k as Ω( √1 )
dk
and O( d1k ) respectively; we also think that the dependence of the stretched-MLE on pobs is no worse than that of the standard MLE. Second, it is of interest to extend our results to other parametric models such as the Thurstone model [39], and we envisage similar results to hold across a variety of such models. Finally, the ideas and techniques developed in this paper may also help in improving the Pareto eﬃciency on other learning and estimation problems, in terms of the bias-accuracy tradeoﬀ.
11

Acknowledgements
The work of JW and NBS was supported in part by NSF grants 1755656 and 1763734. The work of RR was supported in part by NSF grant 1527032.
References
[1] FIDE rating regulations eﬀective from 1 July 2017, 2017. https://www.ﬁde.com/ﬁde/handbook.html?id=197& view=article [Online; accessed May 21, 2019].
[2] Elo ratings - English Premier League, 2019. https://sinceawin.com/data/elo/league/div/e0 [Online; accessed May 21, 2019].
[3] Arpit Agarwal, Prathamesh Patil, and Shivani Agarwal. Accelerated spectral ranking. In International Conference on Machine Learning, 2018.
[4] David Aldous. Elo ratings and the sports model: A neglected topic in applied probability? Statistical Science, 32(4):616–629, 2017.
[5] J. A. Anderson and S. C. Richardson. Logistic discrimination and bias correction in maximum likelihood estimation. Technometrics, 21(1):71–78, 1979.
[6] Ralph A. Bradley and Milton E. Terry. Rank analysis of incomplete block designs: I. the method of paired comparisons. Biometrika, 39(3/4):324–345, 1952.
[7] Baiyu Chen, Sergio Escalera, Isabelle Guyon, Víctor Ponce-López, Nihar Shah, and Marc Oliu Simón. Overcoming calibration problems in pattern labeling with pairwise ratings: application to personality traits. In European Conference on Computer Vision, 2016.
[8] Yuxin Chen, Jianqing Fan, Cong Ma, and Kaizheng Wang. Spectral method and regularized MLE are both optimal for top-K ranking. Ann. Statist., 47(4):2204–2235, 08 2019.
[9] Yuxin Chen and Changho Suh. Spectral MLE: top-K rank aggregation from pairwise comparisons. In International Conference on Machine Learning, 2015.
[10] D. R. Cox and E. J. Snell. A general deﬁnition of residuals. Journal of the Royal Statistical Society. Series B (Methodological), 30(2):248–275, 1968.
[11] Yingying Fan, Emre Demirkaya, and Jinchi Lv. Nonuniformity of p-values can occur early in diverging dimensions. Journal of Machine Learning Research, 20(77):1–33, 2019.
[12] David Firth. Bias reduction of maximum likelihood estimates. Biometrika, 80(1):27–38, 1993. [13] E. N. Gilbert. Random graphs. The Annals of Mathematical Statistics, 30(4):1141–1144, 1959. [14] Mark E. Glickman and Thomas Doan. The US chess rating system, 2017. http://www.glicko.net/ratings/rating.
system.pdf [Online; accessed May 21, 2019]. [15] Mark E Glickman and Albyn C Jones. Rating the chess rating system. Chance, 12:21–28, 1999. [16] Paul E. Green, J. Douglas Carroll, and Wayne S. DeSarbo. Estimating choice probabilities in multiattribute
decision making. Journal of Consumer Research, 8(1):76–84, 1981. [17] Bruce Hajek, Sewoong Oh, and Jiaming Xu. Minimax-optimal inference from partial rankings. In Advances in
Neural Information Processing Systems, 2014. [18] Xuming He and Qi-Man Shao. On parameters of increasing dimensions. Journal of Multivariate Analysis,
73(1):120 – 135, 2000. [19] David R. Hunter. MM algorithms for generalized Bradley-Terry models. Ann. Statist., 32(1):384–406, 02 2004. [20] Minje Jang, Sunghyun Kim, Changho Suh, and Sewoong Oh. Optimal sample complexity of m-wise data for
top-K ranking. In Advances in Neural Information Processing Systems, 2017. [21] L. R. Ford Jr. Solution of a ranking problem from binary comparisons. The American Mathematical Monthly,
64(8P2):28–33, 1957. [22] Franz J. Király and Zhaozhi Qian. Modelling competitive sports: Bradley-Terry-Élő models for supervised and
on-line learning of paired competition outcomes. preprint arXiv:1701.08055, 2017.
12

[23] Alec Lamon, Dave Comroe, Peter Fader, Daniel McCarthy, Rob Ditto, and Don Huesman. Making WHOOPPEE: A collaborative approach to creating the modern student peer assessment ecosystem. In EDUCAUSE, 2016.
[24] R. Duncan Luce. Individual Choice Behavior: A Theoretical analysis. Wiley, New York, NY, USA, 1959.
[25] Sahand Negahban, Sewoong Oh, and Devavrat Shah. RankCentrality: Ranking from pair-wise comparisons. Operations Research, 65:266–287, 2016.
[26] S. Ontañón, G. Synnaeve, A. Uriarte, F. Richoux, D. Churchill, and M. Preuss. A survey of real-time strategy game AI research and competition in StarCraft. IEEE Transactions on Computational Intelligence and AI in Games, 5(4):293–311, 2013.
[27] Víctor Ponce-López, Baiyu Chen, Marc Oliu, Ciprian Corneanu, Albert Clapés, Isabelle Guyon, Xavier Baró, Hugo Jair Escalante, and Sergio Escalera. ChaLearn LAP 2016: First round challenge on ﬁrst impressions-dataset and results. In European Conference on Computer Vision, 2016.
[28] Stephen Portnoy. Asymptotic behavior of likelihood methods for exponential families when the number of parameters tends to inﬁnity. Ann. Statist., 16(1):356–366, 03 1988.
[29] M. H. Quenouille. Approximate tests of correlation in time-series. Journal of the Royal Statistical Society. Series B (Methodological), 11(1):68–84, 1949.
[30] Walter Rudin. Principles of Mathematical Analysis. McGraw-Hill, 1976.
[31] Nihar B. Shah, Sivaraman Balakrishnan, Joseph Bradley, Abhay Parekh, Kannan Ramchandran, and Martin J. Wainwright. Estimation from pairwise comparisons: Sharp minimax bounds with topology dependence. Journal of Machine Learning Research, 17(58):1–47, 2016.
[32] Nihar B. Shah, Joseph K Bradley, Abhay Parekh, Martin Wainwright, and Kannan Ramchandran. A case for ordinal peer-evaluation in MOOCs. In NIPS Workshop on Data Driven Education, 2013.
[33] P. C. Sham and D. Curtis. An extended transmission/disequilibrium test (TDT) for multi-allele marker loci. Annals of Human Genetics, 59(3):323–336, 1995.
[34] David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, L Robert Baker, Matthew Lai, Adrian Bolton, Yutian Chen, Timothy P. Lillicrap, Fan Fong Celine Hui, Laurent Sifre, George van den Driessche, Thore Graepel, and Demis Hassabis. Mastering the game of Go without human knowledge. Nature, 550:354–359, 2017.
[35] Stephen M. Stigler. Citation patterns in the journals of statistics and probability. Statistical Science, 9(1):94–108, 1994.
[36] Stephen M. Stigler. Regression towards the mean, historically considered. Statistical methods in medical research, 6(2):103–14, 02 1997.
[37] Pragya Sur and Emmanuel J. Candès. A modern maximum-likelihood theory for high-dimensional logistic regression. preprint arXiv:1803.06964, 2018.
[38] Balázs Szörényi, Róbert Busa-Fekete, Adil Paul, and Eyke Hüllermeier. Online rank elicitation for Plackett-Luce: A dueling bandits approach. In Advances in Neural Information Processing Systems, 2015.
[39] L. L. Thurstone. A law of comparative judgement. Psychological Review, 34:278–286, 1927.
A Proof of Theorem 2.1
In this appendix, we present the proof of Theorem 2.1. We ﬁrst introduce notation and preliminaries in Appendix A.1, to be used subsequently in proving both parts of Theorem 2.1. The proof of Theorem 2.1(b) is presented in Appendix A.2. The proof of Theorem 2.1(a) is presented in Appendix A.3. We ﬁrst present the proof of Theorem 2.1(b) followed by Theorem 2.1(a), because the proof of Theorem 2.1(a) depends on the proof of Theorem 2.1(b).
In the proof of Theorem 2.1(a), the constants are allowed to depend only on the constant B. In the proof of Theorem 2.1(b), the constants are allowed to depend only on the constants A and B. The proofs for all the lemmas are presented in Appendix A.4.
13

A.1 Notation and preliminaries
In this appendix, we introduce notation and preliminaries that are used subsequently in the proofs of both Theorem 2.1(b) and Theorem 2.1(a).

(i) Notation

Recall that d denotes the number of items, and k denotes the number of comparisons per pair of items.

The d items are associated to a true parameter vector θ∗ = [θ1∗, . . . , θd∗]. We have the set ΘB = {θ ∈ Rd |

θ ∞ ≤ B,

d i=1

θi

=

0}

and

the

set

ΘA

=

{θ

∈

Rd

|

θ ∞ ≤ A,

d i=1

θi

=

0},

where

A

and

B

are

ﬁnite

constants such that A > B > 0. The true parameter vector satisﬁes θ∗ ∈ ΘB.

Denote µ∗ij as the probability that item i ∈ [d] beats item j ∈ [d]. Under the BTL model, we have

µ∗ =

1 .

(8)

ij 1 + e−(θi∗−θj∗)

For every r ∈ [k], denote the outcome of the rth comparison between item i ∈ [d] and item j ∈ [d] as

Xi(jr) := 1{item i beats item j in their rth comparison}.

We have Xi(jr) ∼ Bernoulli(µ∗ij), independent across all r ∈ [k] and all i < j. Recall that Wij denotes the

number of times that item i beats j. We have Wij =

k r=1

Xi(jr)

and

therefore

Wij

∼

Binom

(

k

,

µ

∗ ij

)

.

Denote

µij as the fraction of times that item i beats item j. That is,

1

1 k (r)

µij := k Wij = k Xij .

(9)

r=1

We

have

µij

∼

1 k

Binom

(k

,

µ

∗ ij

),

independent

across

all

i

<

j.

Finally, we use c, c , c1, c2, etc. to denote ﬁnite constants whose values may change from line to line. We write f (n) g(n) if there exists a constant c such that f (n) ≤ c · g(n) for all n ≥ 1. The notation f (n) g(n)
is deﬁned analogously.

(ii) Notion of conditioning Let E be any event. The conditional bias of any estimator θ conditioned on the event E is deﬁned as:

β(θ | E) := sup E[θ | E] − θ∗ ∞.
θ∗ ∈ΘB

We use “w.h.p.( d1k )” to denote that an event E happens with probability at least

P(E) > 1 −

c ,

dk

for all d ≥ d0 and k ≥ k0, where d0, k0 and c are positive constants.
Similarly, we use “w.h.p.( d1k | E)” to denote that conditioned on some event E, some other event E happens with probability at least

P(E

| E) ≥ 1 −

c ,

dk

for all d ≥ d0 and k ≥ k0, where d0, k0 and c are positive constants.

14

(iii) The negative log-likelihood function and its derivative Recall that denotes the negative log-likelihood function. Under the BTL model, we have

(θ) :=

({Wij}; θ) = −

Wij log

1≤i<j≤d

1 1 + e−(θi−θj )

+ Wji log

= −k

µij log

1≤i<j≤d

1 1 + e−(θi−θj )

+ µji log

=k

log(eθi + eθj ) − µij θi − µjiθj .

1≤i<j≤d

1 1 + e−(θj −θi)
1 1 + e−(θj −θi)

(10)

Since {µij} is simply a normalized version of {Wij}, we equivalently denote the negative log-likelihood function as ({µij}; θ).
From the expression of in (10), we compute the gradient ∂∂θm for every m ∈ [d] as

∂ =k

1

− µmi .

∂θm

1 + e−(θm−θi)

i=m

(11)

Finally, the following lemma from [19] shows the strict convexity of the negative log-likelihood function . Lemma A.1 (Lemma 2(a) from [19]). The negative log-likelihood function (θ) is strictly convex in θ ∈ Rd.

(iv) The sigmoid function and its derivatives

Denote

the

function

f

:

(−∞, ∞)

→

(0, 1)

as

the

sigmoid

function

f (x)

=

1 1+e−x

.

It

is

straightforward

to

verify that the function f has the following two properties.

• The ﬁrst derivative f is positive on (−∞, ∞). Moreover, on any bounded interval, the ﬁrst derivative f is bounded above and below. That is, for any constants c1 < c2, there exist constants c3, c4 > 0 such that

0 < c3 < f (x) < c4, for all x ∈ (c1, c2).

(12a)

• The second derivative f is bounded on any bounded interval. That is, for any constants c1 < c2, there exists a constant c5 such that

|f (x)| < c5, for all x ∈ (c1, c2).

(12b)

(v) Existence and uniqueness of MLE
Recall that the MLE (3), the unconstrained MLE (4), and the stretched-MLE (5) are respectively deﬁned as:

θ(B)({µij}) = argmin ({µij}; θ),

(13)

θ∈ΘB

θ(∞)({µij}) = argmin ({µij}; θ),

(14)

θ∈Θ∞

θ(A)({µij}) = argmin ({µij}; θ).

(15)

θ∈ΘA

The following lemma shows the existence and uniqueness of the stretched-MLE θ(A) (15) for any constant A > 0, which incorporates the standard MLE θ(B) by setting A = B.
Lemma A.2. For any ﬁnite constant A > 0, there always exists a unique solution θ(A) to the stretchedMLE (15).

15

See Appendix A.4.1 for the proof of Lemma A.2. For the unconstrained MLE, due to the removal of the box constraint in (14), a ﬁnite solution θ(∞) may not exist. However, the following lemma shows that a unique ﬁnite solution exists with high probability.
Lemma A.3. There exists a unique ﬁnite solution θ(∞) to the unconstrained MLE (14) w.h.p.( d1k ).
See Appendix A.4.2 for the proof of Lemma A.3. In the subsequent proofs of Theorem 2.1(b) and Theorem 2.1(a), we heavily use the unconstrained MLE as an intermediate quantity to analyze the MLE and the stretched-MLE.

A.2 Proof of Theorem 2.1(b)
In this appendix, we present the proof of Theorem 2.1(b). To describe the main steps involved, we ﬁrst present a proof sketch of a simple case of d = 2 items (Appendix A.2.1), followed by the complete proof of the general case (Appendix A.2.2). The reader may pass to the complete proof in Appendix A.2.2 without loss of continuity.

A.2.1 Simple case: 2 items
We ﬁrst present an informal proof sketch for a simple case where there are d = 2 items. The proof for the general case in Appendix A.2.2 follows the same outline. In the case of d = 2 items, due to the centering constraint on the true parameter vector θ∗, we have θ2∗ = −θ1∗. Similarly, we have θ2 = −θ1 for any estimator that satisﬁes the centering constraint (in particular, for the stretched-MLE θ(A) and the unconstrained MLE θ(∞)). Therefore, it suﬃces to focus only on item 1. Since there are only two items, for ease of notation, we denote µ = µ12 and µ∗ = µ∗12. We now present the main steps of the proof sketch.

Proof sketch of the 2-item case (informal): In the proof sketch, we ﬁx any θ∗ ∈ ΘB, and any ﬁnite constants A and B such that A > B > 0.

Step 1: Establish concentration of µ By Hoeﬀding’s inequality, we have

|µ − µ∗|

log k ,

w.h.p.

(16)

k

Since |θ∗| ≤ B, we have that µ∗ is bounded away from 0 and 1 by a constant. Hence, for suﬃciently large k, there exist constants cL, cU where 0 < cL < cU < 1, such that

µ, µ∗ ∈ (cL, cU ).

(17)

Step 2: Write the ﬁrst-order optimality condition for θ(∞)
The unconstrained MLE θ(∞) minimizes the negative log-likelihood . If a ﬁnite unconstrained MLE θ(∞) exists1, we have ∇θ=θ(∞) (θ) = 0. Setting m = 1 in the gradient expression (11) and plugging in θ(∞), we have

∂ =k
∂θ1 θ=θ(∞) =k

1

− µ12

1 + e−(θ1(∞)−θ2(∞))

1

−µ .

1 + e−2θ1(∞)

(18)

1 For the proof sketch, we ignore the high-probability nature of Lemma A.3, and assume that a ﬁnite θ(∞) always exists. It is made precise in the complete proof in Appendix A.2.2.

16

Setting the derivative (18) to 0, we have

θ1(∞) = − 21 log µ1 − 1 . (19)

By the deﬁnition of {µ∗ij} in (8), we have µ∗ =

= 1
−(θ∗ −θ∗ )

1−2θ∗ , which can be written as

1+e 1 2

1+e 1

θ1∗ = − 12 log µ1∗ − 1 . (20)

Deﬁne a function h : [0, 1] → R ∪ {±∞} as

h(t) = − 1 log 1 − 1 .

(21)

2

t

Subtracting (20) from (19) and using the deﬁnition of h from (21), we have

θ1(∞) − θ1∗ = h(µ) − h(µ∗).

(22)

Step 3: Bound the diﬀerence between θ(∞) and θ∗, by the ﬁrst-order mean value theorem

It can be veriﬁed that h has positive ﬁrst-order derivative on (0, 1). Moreover, there exists some constant c1 such that 0 < h (t) < c1 for all t ∈ (cL, cU ). Applying the ﬁrst-order mean value theorem on (22), we have the deterministic relation

θ1(∞) − θ1∗ = h (λ) · (µ − µ∗),

(23)

where λ is a random variable that depends on µ and µ∗, and takes values between µ and µ∗. By (17), we have λ ∈ (cL, cU ). From (23) we have

|θ1(∞) − θ1∗| ≤ c1|µ − µ∗|.

(24)

Combining (24) with (16), we have

|θ1(∞) − θ1∗| lokg k , w.h.p. (25)

Step 4: Bound the expected diﬀerence between θ(∞) and θ∗, by the second-order mean value theorem

By the second-order mean value theorem on (22), we have the deterministic relation

θ1(∞) − θ1∗ = h(µ) − h(µ∗) = h (µ∗) · (µ − µ∗) + h (λ) · (µ − µ∗)2,

(26)

where λ is a random variable that depends on µ and µ∗, and takes values between µ and µ∗. By (17), we have λ ∈ (cL, cU ).
It can be veriﬁed that h has bounded second-order derivative. That is, |h (t)| < c2 for all t ∈ (cL, cU ). Taking an expectation over (26), we have

E[θ1(∞)] − θ1∗ = h (µ∗) · (E[µ] − µ∗) + E[h (λ) · (µ − µ∗)2]

(27)

(i)
≤ c2E[(µ − µ∗)2]

(ii) log k

,

(28)

k

where (i) is true because E[µ] = µ∗ combined with the fact that |h | < c2 on (cL, cU ), and (ii) is true2 by (16).

2 For the proof sketch, we ignore the high-probability nature of (16) and treat it as a deterministic relation. It is made precise in the complete proof in Appendix A.2.2.

17

Step 5: Connect θ(∞) back to θ(A) From (25), we have |θ1(∞) − θ1∗| ≤ A − B w.h.p. for suﬃciently large k. Hence,
|θ1(∞)| ≤ |θ1∗| + |θ1(∞) − θ1∗| ≤ B + (A − B) = A, w.h.p.

Moreover, we have θ2(∞) = θ1(∞) ≤ A. Therefore, with high probability, the unconstrained MLE θ(∞)
does not violate the box constraint at A, and therefore θ(∞) is identical to the stretched-MLE θ(A). Hence, the bound (28) holds3 for the stretched-MLE, completing the proof sketch.

A.2.2 Complete Proof
In this appendix, we present the proof of Theorem 2.1(b), by formally extending the 5 steps outlined for the simple case in Appendix A.2.1. In the general case, one notable challenge is that one can no longer write a closed-form solution of the MLE as we did in (19) of Step 2. The ﬁrst-order optimality condition now becomes a system of equations that describe an implicit relation between θ and µ, requiring more involved analysis.
In the proof, we ﬁx any θ∗ ∈ ΘB, and ﬁx any ﬁnite constants A and B such that A > B > 0.
Step 1: Establish concentration of {µij} We ﬁrst use standard concentration inequalities to establish the following lemma, to be used in the subsequent steps of the proof.
Lemma A.4. There exists a constant c > 0, such that

µmi − µ∗mi ≤ c

i=m

i=m

d(log d + log k) ,
k

simultaneously for all m ∈ [d] w.h.p.( d1k ).

See Appendix A.4.3 for the proof of Lemma A.4.
Recall that Lemma A.3 states that a ﬁnite unconstrained MLE θ(∞) exists w.h.p.( d1k ). We denote E0 as the event that Lemma A.3 and Lemma A.4 both hold. For the rest of the proof, we condition on E0. Since both Lemma A.3 and Lemma A.4 hold w.h.p.( d1k ), taking a union bound, we have that E0 holds w.h.p.( d1k ). That is,

P(E0) ≥ 1 −

c ,

for some constant c > 0.

(29)

dk

Step 2: Write the ﬁrst-order optimality condition for the unconstrained MLE θ(∞)
Recall from Lemma A.1 that the negative log-likelihood function is convex in θ. In this step, we ﬁrst justify that the whenever a ﬁnite unconstrained MLE θ(∞) exists, it satisﬁes the ﬁrst-order optimality condition ∇θ=θ(∞) (θ) = 0. (Note that for any optimization problem with constraints, it is in general not true that the derivative of the convex objective equals 0 at the optimal solution.) Then we derive a speciﬁc form of the ﬁrst-order optimality condition, to be used in subsequent steps of the proof.
Given that we have conditioned on E0 (and therefore on Lemma A.3), a ﬁnite solution θ(∞) to the unconstrained MLE exists. To show that θ(∞) satisﬁes the ﬁrst-order optimality condition, we show that
3 For the proof sketch, we ignore the high-probability nature of the fact that θ(∞) = θ(A), and treat it as a deterministic relation. It is made precise in the complete proof in Appendix A.2.2.

18

θ(∞) is also a solution to the following MLE without any constraint at all (that is, we remove the centering constraint too):

argmin (θ).

(30)

θ∈Rd

If the unconstrained MLE θ(∞) is a solution to (30), then it satisﬁes the ﬁrst-order condition ∇θ (θ(∞)) = 0.

Now we prove that θ(∞) is a solution to (30). Note that the solutions to (30) are shift-invariant. That is, if θ

is a solution to (30), then θ + c1 is also a solution, where 1 is the d-dimensional all-one vector, and c is any

constant. Now suppose by contradiction that θ(∞) is not a solution to (30). Then there exists some ﬁnite

θ ∈ Rd such that

(θ) <

(θ(∞)). Now consider θ

:=

θ

−

(

1 d

d i=1

θi

)1.

We have θ

∈ Θ∞ because it satisﬁes

the centering constraint, and we have (θ ) = (θ) < (θ(∞)) because the solutions to (30) are shift-invariant.

The construction of θ thus contradicts the assumption that θ(∞) is optimal for the unconstrained MLE.

Hence, θ(∞) is a solution to (30), and θ(∞) satisﬁes the ﬁrst-order optimality condition.

Now we derive a speciﬁc form of the ﬁrst-order optimality condition. Plugging θ(∞) into the gradient expression (11) and setting the gradient to 0, we have the deterministic equality

1

(∞) = (∞)

µmi,

i=m 1 + e−(θm −θi ) i=m

for every m ∈ [d].

(31)

In words, the ﬁrst-order optimality condition (31) means that for any item m ∈ [d], the probability that item m wins (among all comparisons in which item m is involved) as predicted by the unconstrained MLE θ(∞) equals the fraction of wins by item m from the observed comparisons. We now subtract (8) from both sides of (31):

i=m d
i=1

1

−

1

1 + e−(θm (∞)−θi(∞)) 1 + e−(θm ∗ −θi∗)

1

−

1

1 + e−(θm (∞)−θi(∞)) 1 + e−(θm ∗ −θi∗)

= (µmi − µ∗mi)
i=m
= (µmi − µ∗mi).
i=m

(32)

For ease of notation, we denote the random vector δ := θ(∞) − θ∗. Equivalently, we have θ(∞) = θ∗ + δ. Using the deﬁnition of δ, we rewrite (32) as:

d

1

1

1 + e−(θm ∗ −θi∗+δm−δi) − 1 + e−(θm ∗ −θi∗) =

(µmi − µ∗mi).

i=1

i=m

(33)

Using

the

deﬁnition

of

the

sigmoid

function

f (x)

=

1 1+e−x

,

we

rewrite

(33)

as:

d

[f (θm∗ − θi∗ + δm − δi) − f (θm∗ − θi∗)] = (µmi − µ∗mi).

i=1

i=m

(34)

In the rest of the proof, we primarily work with the ﬁrst-order optimality condition in the form of (34).

Step 3: Bound the diﬀerence between the unconstrained MLE θ(∞) and the true parameter vector θ∗
The ﬁrst-order optimality condition (34) can be thought of as a system of equations that describes some implicit relation between the unconstrained MLE θ(∞) and the observations {µmi}. Intuitively, the concentration of {µmi} on the RHS of (34) (by Lemma A.4) should imply the concentration of the unconstrained MLE θ(∞) on the LHS. The following lemma formalizes this intuition about the concentration of θ(∞).

19

Lemma A.5. Conditioned on E0, we have the deterministic relation

|δm| = |θm(∞) − θm∗ |

log d + log k ,
dk

for all d ≥ d0 and k ≥ k0, where d0 and k0 are constants.

for every m ∈ [d],

See Appendix A.4.4 for the proof of Lemma A.5.
This lemma provides a deterministic bound on the diﬀerence between θ(∞) and θ∗. Now we move to analyze the diﬀerence between θ(∞) and θ∗ in expectation.
Step 4: Bound the expected diﬀerence between the unconstrained MLE θ(∞) and the true parameter vector θ∗, using the second-order mean value theorem
In Step 1 we bound the diﬀerence between {µmi} and {µ∗mi} with high-probability. However, if we consider the diﬀerence in expectation, we have E[µmi] = µ∗mi. The expected diﬀerence between {µmi} and {µ∗mi} is 0, signiﬁcantly smaller than the high-probability bound in Step 1. Intuitively, we may also expect that the expected diﬀerence between θ(∞) and θ∗ is smaller than the deterministic bound in Lemma A.5. In this step, we formalize this intuition.
By the second-order mean value theorem on the LHS of the ﬁrst-order optimality condition (34), we have the deterministic relation that for every m ∈ [d],

d

1

f (θm∗ − θi∗) · (δm − δi) + f (λmi) · (δm − δi)2 =

(µmi − µ∗mi)

2

i=1

i=m

d
f (θm∗ − θi∗) · (δm − δi) =

1d

(µmi − µ∗mi) −

f (λmi) · (δm − δi)2, (35)

2

i=1

i=m

i=1

where each λmi is a random variable that takes values between θm∗ − θi∗ and θm∗ − θi∗ + (δm − δi). Taking an expectation over (35) conditional on E0, we have that for every m ∈ [d]:

d
f (θm∗ − θi∗) · E [δm − δi | E0] =

1d

(E[µmi | E0] − µ∗mi) −

E[f (λmi)(δm − δi)2 | E0].

2

i=1

i=m

i=1

(36)

Denote the vector ∆ := E[δ | E0] = E[θ(∞) | E0] − θ∗. Plugging this deﬁnition of ∆ into (36) yields

d
f (θm∗ − θi∗) · (∆m − ∆i) =

1d

(E[µmi | E0] − µ∗mi) −

E[f (λmi)(δm − δi)2 | E0].

2

i=1

i=m

i=1

(37)

We ﬁrst bound the RHS of (37), and then derive a bound regarding ∆i on the LHS accordingly.
To bound the RHS of (37), we ﬁrst consider the term E[µmi | E0] − µ∗mi. In what follows, we state a lemma that is slightly more general than what is needed here. The more general version is used in the subsequent proof of Theorem 2.1(a). To state the lemma, recall the deﬁnition that an event E happens w.h.p.( d1k | E), if the conditional probability P(E | E) ≥ 1 − dck , for some constant c > 0.
Lemma A.6. Let E be any event, and let E be any event that happens w.h.p.( d1k | E). Then for any m = i, we have

|E[µmi | E , E] − E[µmi | E]|

1 .

(38)

dk

20

See Appendix A.4.5 for the proof of Lemma A.6. To apply Lemma A.6, we set E to be the (trivial) event of the entire probability space, and set E E0 in (38). We have
|E[µmi | E0] − E[µmi]| = |E[µmi | E0] − µ∗mi| d1k .

to be (39)

The remaining terms in (37) are handled in the following lemma. This lemma bounds the expected diﬀerence between θ(∞) and θ∗ conditioned on E0, that is, the quantity |∆m| = |E[θm(∞) | E0] − θm∗ |.

Lemma A.7. Conditioned on E0, we have

|∆m|

log d + log k ,
dk

for every m ∈ [d],

for all d ≥ d0 and all k ≥ k0, where d0 and k0 are constants. Equivalently,

β(θ(∞) | E0) = E[θ(∞) | E0] − θ∗ ∞ = ∆ ∞ log dd+klog k , (40) for all d ≥ d0 and all k ≥ k0, where d0 and k0 are constants.

See Appendix A.4.6 for the proof of Lemma A.7.
Note that (40) yields the desired rate on the quantity β(θ(∞) | E0). It remains to show that β(θ(∞) | E0) is suﬃciently close to β(θ(A)).

Step 5: Show that the box constraint at A is vacuous for the unconstrained MLE θ(∞) and hence θ(∞) is the same as the stretched-MLE θ(A) with high probability, using the deterministic
bound in Step 3

To show that β(θ(∞) | E0) is suﬃciently close to β(θ(A)), we divide the argument into two parts. First, we show that β(θ(∞) | E0) = β(θ(A) | E0). Second, we show that β(θ(A) | E0) is close to β(θ(A)).

We ﬁrst show that β(θ(∞) | E0) = β(θ(A) | E0). Recall that A and B are constants such that A > B.

Recall from Lemma A.5 that θ(∞) − θ∗ ∞

log d+log k dk

conditioned

on

E0.

Hence,

there

exist

constants

d0

and k0, such that for any d ≥ d0 and k ≥ k0, we have θ(∞) − θ∗ ∞ < A − B conditioned on E0. In this

case, we have

θ(∞) ∞ ≤ θ∗ ∞ + θ(∞) − θ∗ ∞ < B + (A − B) = A, conditioned on E0.

Conditioned on E0, the unconstrained MLE θ(∞) obeys the box constraint θ(∞) ∞ ≤ A. Therefore, θ(∞) is also a solution to the stretched-MLE θ(A). By the uniqueness of θ(A) from Lemma A.2, we have

θ(A) = θ(∞), conditioned on E0.

Hence, we have the relation

β(θ(∞) | E0) = β(θ(A) | E0),

(41)

completing the ﬁrst part of the argument.

It remains to show that β(θ(A) | E0) is suﬃciently close to β(θ(A)). We have

β(θ(A)) = E[θ(A)] − θ∗ ∞

(=i) E[θ(A) | E0] · P(E0) + E[θ(A) | E0] · P(E0) − θ∗ ∞

(ii)
≤ E[θ(A) | E0] − θ∗ ∞ · P(E0) + E[θ(A) | E0] − θ∗ ∞ · P(E0)

= β(θ(A) | E0) · P(E0) + E[θ(A) | E0] − θ∗ ∞ · P(E0) .

(42)

R1

R2

21

where step (i) is true by the law of iterated expectation, and step (ii) is true by the triangle inequality. Consider the two terms in (42). For R1, combining (40) and (41) yields

Therefore,

β(θ(A) | E0) = β(θ(∞) | E0)

log d + log k .
dk

log d + log k R1 dk . (43)

Now consider R2. By the box constraint θ(A) ∞ ≤ A, we have

(i)
E[θ(A) | E0] − θ∗ ∞ ≤ E[θ(A) | E0] ∞ + θ∗ ∞ ≤ A + B,

(44)

where step (i) is true by the triangle inequality. Recall from (29), the event E0 happens w.h.p.( d1k ). Therefore,

1 P(E0) dk . (45)

Combining (44) and (45) yields

1 R2 dk . (46)

Plugging the term R1 from (43) and the term R2 from (46) back into (42), we have

β(θ(A))

log d + log k ,
dk

completing the proof of Theorem 2.1(b).

A.3 Proof of Theorem 2.1(a)
Similar to the proof of Theorem 2.1(b), we ﬁrst present a proof of the simple case of d = 2 items. It is important to note that although we present proofs of the 2-item case for both Theorem 2.1(b) and Theorem 2.1(a), their purposes are diﬀerent. In Theorem 2.1(b) presented in Appendix A.2, the proof sketch of the 2-item case is informal. It serves as a guideline for the general case. Then the main work involved in the general case is to generalize the arguments in the 2-item case step-by-step. On the other hand, in Theorem 2.1(a), the proof of the 2-item case to be presented is formal. It serves as a core sub-problem of the general case. Then the main work involved in the general case is to reduce the problem to the 2-item case, and then the results from the 2-item case directly.

A.3.1 Simple case: 2 items

As in Appendix A.2.1, we ﬁrst consider the simple case where there are d = 2 items. Again, due to the centering constraint, we have θ2∗ = −θ1∗ for the true parameter vector θ∗, and we have θ2 = −θ1 for any estimator θ that satisﬁes the centering constraint (in particular, for the standard MLE θ(B) and the unconstrained MLE
θ(∞)). Therefore, it suﬃces to focus only on item 1. Since there are only two items, for ease of notation, we denote µ = µ12 and µ∗ = µ∗12.
We consider the true parameter vector θ∗ = [B, −B]. By the deﬁnition of {µ∗ij} in (8), we have

µ∗ =

1

1

=

.

1 + e−(θ1∗−θ2∗) 1 + e−2B

The following proposition now lower bounds the bias of the standard MLE θ(B).

22

Proposition A.8. Under θ∗ = [B, −B], the bias of the MLE θ(B) is bounded as β(θ(B)) = E[θ(B)] − θ∗ ∞ = |E[θ1(B)] − B| √1k .
Speciﬁcally, the bias is negative, that is, E[θ1(B)] − B ≤ − √ck , (47)
for some constant c > 0. The rest of this appendix is devoted to proving (47) in Proposition A.8.

For ease of notation, denote µ+ = µ∗ =

1 1+e−2B

,

and

µ−

=

1 − µ∗

=

1 1+e2B

.

In the proof sketch of

Theorem 2.1(b) of the case of d = 2 items (Appendix A.2.1), we derived the following expression (19) for the

unconstrained MLE:

θ1(∞)(µ) = − 12 log µ1 − 1 .

Now consider the standard MLE θ(B). By straightforward analysis, one can derive the following closed-form

expression for the standard MLE:



−B

if µ ∈ [0, µ−]

θ1(B)(µ)

=

−

1 2

log

1 µ

−

1

if µ ∈ (µ−, µ+)

(48)

B

if µ ∈ [µ+, 1].

For ease of notation, we denote a function h : [0, 1] → [−B, B] as

 −B

if t ∈ [0, µ−]

h(t)

=

−

1 2

log

1 t

−

1

if t ∈ (µ−, µ+)

(49)

B

if t ∈ [µ+, 1],

where h(t) = θ1(B)(µ = t) for any t ∈ [0, 1]. Then the standard MLE (48) can be equivalently written as h(µ). To make the computation of the bias incurred by θ(B) more tractable, we also deﬁne the following auxiliary function h+ : [0, 1] → [−B, B] as:

h+(t) := µ2B+ (t − µ+) + B if t ∈ [0, µ+)

(50)

B

if t ∈ [µ+, 1].

In words, the function h+ is piecewise linear. On the interval [0, µ+], it is a line passing through the points
(0, −B) and (µ+, B). On the interval [µ+, 1], its value equals the constant B. The following lemma now states a relation between h+(µ) and h(µ) in expectation with respect to µ.

Lemma A.9. Under θ∗ = [B, −B], we have

E[h(µ)] ≤ E[h+(µ)].

(51)

See Appendix A.4.7 for the proof of Lemma A.9. Now subtracting B from both sides of (51), we have

E[θ1(B)] − θ1∗ = E[h(µ)] − B ≤ E[h+(µ)] − B.

(52)

The following lemma states that the bias introduced by h+(µ) satisﬁes the desired rate from Proposition A.8.

23

Lemma A.10. Under θ∗ = [B, −B], we have

E[h+(µ)] − B ≤ − √c ,

(53)

k

for some constant c > 0.

See Appendix A.4.8 for the proof of Lemma A.10. Combining (52) and (53), we have
E[θ1(B)] − θ1∗ ≤ − √ck ,

completing the proof of (47) in Proposition A.8.

A.3.2 Complete Proof

In this appendix, we present the proof of Theorem 2.1(a). The proof reduces the general case to the 2-item

case presented in Appendix A.3.1. In the reduction, we construct an “oracle” MLE, such that the oracle MLE

yields identical estimates for item 2 through item d. Speciﬁcally, we consider an unconstrained oracle denoted

by θ(∞) (without the box constraint), and a constrained oracle denoted by θ(B) (with the box constraint

at B), to be deﬁned precisely in the proof shortly. Then we derive the closed-form expressions for θ(∞)

and θ(B), which bear resemblance to the expressions of the the unconstrained MLE and the standard MLE

in the 2-item case. Using the proof of the 2-item case, we prove that the constrained oracle θ(B) incurs a

negative bias of Ω( √1 ). Given this result, it remains to show that θ(B) and θ(B) diﬀer by o( √1 ) in terms of

dk

dk

bias. We decompose the diﬀerence between θ(B) and θ(B) into three terms: from θ(B) to θ(∞), from θ(∞) to

θ(∞), and from θ(∞) to θ(B), The second term is bounded by O( d1k ) by modifying the upper-bound proof of Theorem 2.1(b). The ﬁrst and the third terms are bounded by carefully analyzing the eﬀect of the box

constraint on the oracle MLE and the standard MLE, respectively.

In the proof, we ﬁx any constant B > 0, and consider the true parameter vector:

θ∗ = B, − B , − B , . . . , − B .

(54)

d−1 d−1

d−1

It can be veriﬁed that θ∗ satisﬁes both the box constraint at B and the centering constraint, so we have θ∗ ∈ ΘB. We prove that the bias on item 1 is negative, and its magnitude is Ω( √1 ). That is, we prove that
dk
E[θ1(B)] − θ1∗ = E[θ1(B)] − B ≤ − √cdk ,

for some constant c > 0. The proof consists of the following 5 steps.

Step 1: Construct oracle estimators θ(∞) (unconstrained) and θ(B) (constrained)

Recall

that

µij

∼

1 k

Binom

(

k

,

µ

∗ ij

)

is

a

random

variable

representing

the

fraction

of

times

that

item

i

beats

item j. We deﬁne µ1 as fraction of wins by item 1, among all comparisons in which item 1 is involved:

1d

µ1 := d − 1 µ1m.

(55)

m=2

We

similarly

deﬁne

the

true

probability

µ∗1

=

1 d−1

d m=2

µ∗1m.

With

the

construction

(54) of θ∗,

we

have

µ∗1 = 1+e−1d−d 1 B . Now we construct the following random quantities {µij}i=j as a function of {µij}i=j:



µ1

if i = 1, j ∈ {2, . . . , d}

µij = 11 − µ1 oifthj e=rw1i,sei. ∈ {2, . . . , d} (56)
2

24

Recall that θ(∞)({µij}) denotes the unconstrained MLE (14). Now deﬁne an “unconstrained oracle” MLE θ(∞) as:

θ(∞)({µij }) := θ(∞)({µij })
= argmin ({µij}; θ).
θ∈Θ∞

(57a)

Similarly, deﬁne a “constrained oracle” MLE θ(B) as:

θ(B)({µij }) := θ(B)({µij })
= argmin ({µij}; θ).
θ∈ΘB

(57b)

In the subsequent steps, these oracle estimators are used to reduce the general case to the 2-item case.
Step 2: Formalize the oracle information contained in the unconstrained oracle θ(∞) and the constrained oracle θ(B)
Note that the construction of {µij} in (56) is symmetric with respect to item 2 through item d, that is, for any two items i and i where i, i ∈ {2, . . . , d}, we have µij = µi j and µji = µji for every i ∈ [d] \ {j, j }. Therefore, the construction of {µij} intuitively encodes the “oracle” that item 2 through item d have identical parameters. Formally, deﬁne the set Θoracle := {θ ∈ Rd | θ2 = · · · = θd}. The following lemma states that the unconstrained oracle and the constrained oracle incorporate the set Θoracle into the domain of optimization without altering their solutions.
Lemma A.11. The unconstrained oracle θ(∞) can be equivalently written as

θ(∞) = argmin ({µij}; θ).
Θ∞ ∩Θoracle

(58a)

That is, a solution to (57a) exists if and only if a solution to (58a) exists. Moreover, when the solutions to (57a) and (58a) exist, they are identical.
Similarly, the constrained oracle θ(B) can be equivalently written as

θ(B) = argmin ({µij}; θ).
θ∈ΘB ∩Θoracle

(58b)

See Appendix A.4.9 for the proof of Lemma A.11.
Given Lemma A.11 combined with the centering constraint, we parameterize the unconstrained oracle θ(∞) and the constrained oracle θ(B) as:

θ(∞) = θ(B) =

θ1(∞), − d −1 1 θ1(∞), . . . , − d −1 1 θ1(∞) , θ1(B), − d −1 1 θ1(B), . . . , − d −1 1 θ1(B) .

(59a) (59b)

Step 3: Show that the bias of the constrained oracle θ(B) on item 1 is bounded by E[θ1(B)]−θ1∗ ≤ − √c , by making a reduction to the 2-item case
dk

In this step, we modify the proof of Proposition A.8 in the 2-item case to lower bound the bias of the

constrained oracle θ(B). Speciﬁcally, we show that given θ∗ =

B

,

−

B d−1

,

.

.

.

,

−

B d−1

, the bias on item 1 is

bounded as (cf. (47)):

E[θ1(B)] − θ∗ ≤ − √cdk ,

25

for some constant c > 0.
First, we solve for the unconstrained oracle θ(∞) and the constrained oracle θ(B) in closed form. Set m = 1 in the gradient expression (11). Plugging in the expressions for the unconstrained oracle θ(∞) (59a) and the manipulated observations {µij} (56), we have

∂

= k(d − 1)

∂θ1 θ=θ(∞)

1

− µ1

1

+

e−

d d−1

θ1(∞)

Setting the derivative (60) to 0, we have

1 1 + e− d−d 1 θ1(∞) = µ1

θ(∞) = − d − 1 log 1 − 1 .

1

d

µ1

(60) (61)

Denote µd,+ = µ∗1 = 1+e−1d−d 1 B , and µd,− = 1 − µd,+ = 1+e d1−d 1 B . In the notations µd,+ and µd,−, the

dependency on d is made explicit. When the dependency on d does not need to be emphasized, we also use

the shorthand notations µ+ and µ−. Now consider the constrained oracle θ(B). By straightforward analysis,

one can derive the following closed-form expression for the constrained oracle:



−B

θ1(B)(µ1)

=

−

d−1 d

log

B

µ11 − 1

if 0 ≤ µ1 < µd,− if µd,− < µ1 < µd,+ if µd,+ ≤ µ1 ≤ 1.

(62)

Note the similarity between θ(B) in (62) and the 2-item case θ1(B) in (48) from Appendix A.3.1. Similar to

the function h deﬁned in (49) of the 2-item case, we denote a function hd : [0, 1] → [−B, B] as:

 −B

if 0 ≤ t < µd,−

hd(t)

=

−

d−1 d

log

1 t

−

1

B

if µd,− < t < µd,+ if µd,+ ≤ t ≤ 1,

where hd(t) = θ1(B)(µ1 = t) for any t ∈ [0, 1]. Then the estimator θ1(B)(µ) can be equivalently written as hd(µ). Similar to the function h+ deﬁned in (50) of the 2-item case, we deﬁne an auxiliary function h+d : [0, 1] → [−B, B] as:

h+d (t) =

µ2dB,+ (t − µd,+) + B B

if 0 ≤ t < µd,+ if µd,+ ≤ t ≤ 1.

Note that in the proofs of Lemma A.9 and Lemma A.10, we have only relied on the following two facts:

• There exists a constant c such that

1 2 < µ+ < c < 1.

•

The

random

variable

µ

is

sampled

as

µ∼

1 k

Binom

(k

,

µ

+

).

In the general case, it can be veriﬁed that

• There exists a constant c such that 1 2 < µd,+ < c < 1,

for all d ≥ 2.

26

•

The random variable µ1 as deﬁned in (56) is sampled as µ1 ∼

1 k

Binom(k

,

µ+),

where

k

:= (d − 1)k

denotes the total number of comparisons in which item 1 is involved.

To extend the arguments in the 2-item case to the general case, we replace µ by µ1, replace µ+ by µd,+, replace h+ by h+d , and replace k by k in the proof of Proposition A.8. It can be veriﬁed that the arguments
in Lemma A.9 and Lemma A.10 still hold after these replacements. Therefore, extending the arguments in

Proposition A.8, we have that at θ∗ =

B

,

−

B d−

1

,

.

.

.

,

−

B d−

1

,

E[θ1(B)] − θ1∗ ≤ − √ck = − (d c− 1)k ≤ − √cdk , (63)

for some constants c, c > 0.

Step 4: Bound the diﬀerence between the unconstrained oracle θ(∞) and the unconstrained MLE θ(∞), by modifying the proof of Theorem 2.1(b)

Recall that the random variable µ1 denotes the fraction of wins by item 1. In this step, we ﬁx any real

number

v

∈

[

1 2

,

µ+

],

and

denote

Ev

as

the

event

that

we

observe

µ1

=

v.

Then

we

prove

that

conditioned

on

the event Ev, the diﬀerence between the unconstrained oracle θ(∞) and the unconstrained MLE θ(∞) is small

in expectation, by modifying Step 1 to Step 4 in the upper-bound proof of Theorem 2.1(b) in Appendix A.2.2.

We ﬁrst conceptually explain how to modify the proof of Theorem 2.1(b). Our goal is to bound the

diﬀerence between θ(∞) and θ(∞) in expectation conditioned on the event Ev. By the deﬁnition of {µij} in (56), the quantities {µij} are ﬁxed (not random) conditioned on Ev, and hence the unconstrained oracle
θ(∞) is ﬁxed conditioned on Ev. We therefore replace the role of the true parameter vector θ∗ in the proof of Theorem 2.1(b) by the unconstrained oracle θ(∞). Then we think of the actual observations {µij} as a noisy
version of {µij}, and think of θ(∞) as the estimate for θ(∞). Now we modify the proof of Theorem 2.1(b) to
bound the expected diﬀerence between θ(∞) and θ(∞) conditioned on Ev. At the end of this step, we provide more intuition why we need to condition on the event Ev.

Formally, we denote {µvij} as the values of {µij} conditional on Ev. We denote θv as the unconstrained

oracle

θ(∞)

conditional

on

Ev .

It

can

be

veriﬁed

that

{µvij }

and

θv

are

ﬁxed

(not

random)

given

any

v

∈

[

1 2

,

µ+

].

Conditioned on Ev, we think of θv as if it is the “true” parameter vector to be estimated (replacing the role

of θ∗), and think of {µvij} as if it is the “true” underlying probabilities (replacing the role of {µ∗ij}).

Given the deﬁnition of {µij} in (56), we have that conditioned on event Ev,



v

if i = 1, j ∈ {2, . . . , d}

µvij = 11 − v iofthj e=rw1i,sei. ∈ {2, . . . , d} (64)
2

From the expression (61) of the unconstrained oracle θ(∞), it can be veriﬁed that θ(∞) satisﬁes the deterministic equality

1 1 + e− θi(∞)−θj(∞)

= µij ,

for all i = j.

(65)

Now we start to replicate Step 1 to Step 4 in the proof of Theorem 2.1(b) presented in Appendix A.2.2.
To replicate Step 1 of Theorem 2.1(b), recall that in the proof of Theorem 2.1(b), we condition on Lemma A.3 and Lemma A.4. We ﬁrst establish the modiﬁed versions of these two lemmas, when conditioned on Ev.

Lemma A.12 (Conditional version of Lemma A.3). Conditioned on the event Ev, there exists a ﬁnite solution θ(∞) to the unconstrained MLE (14) w.h.p.( d1k | Ev).

27

See Appendix A.4.10 for the proof of Lemma A.12.
Lemma A.13 (Conditional version of Lemma A.4). Conditioned on the event Ev, there exists a constant c > 0, such that

µmi − µvmi ≤ c d(log dk+ log k) , (66)

i=m

i=m

simultaneously for all m ∈ [d] w.h.p.( d1k | Ev).

See Appendix A.4.11 for the proof of Lemma A.13.
Recall that we have conditioned on the event Ev. Denote E0 as the event that Lemma A.12 and Lemma A.13 both hold. (Note that the event E0 is deﬁned for some ﬁxed v, so to be precise, the event E0 should be denoted as E0,v. For ease of notation, we drop the subscript v.) Taking a union bound of Lemma A.12 and Lemma A.13, we have that E0 happens w.h.p.( d1k | Ev). For the rest of the proof, we condition on the events (E0, Ev).
To replicate Step 2 of Theorem 2.1(b), we subtract equality (65) from both sides of (31). We obtain the (unconditional) deterministic equality:

d

1

1

(∞) − (∞)

= (∞) (∞)

(µmi − µmi),

i=1 1 + e−(θm −θi ) 1 + e−(θm −θi )

i=m

for every m ∈ [d].

(67)

Conditioning (67) on (E0, Ev), we have the following deterministic equality, as a modiﬁed version of (32):

d

1

1

−

= (µmi − µvmi),

i=1 1 + e−(θm (∞)−θi(∞)) 1 + e−(θm v −θiv)

i=m

conditioned on (E0, Ev). (68)

To

replicate

Step

3

of

Theorem

2.1(b),

note

that

v

is

bounded

as

v

∈

[

1 2

,

µ+

]

.

By

the

expression

(61)

of θ(∞) (and hence of θv), it can be veriﬁed that θv is bounded as |θv| ≤ c for some constant c. Denote

δ = θ(∞) − θv. Using the same arguments as in Lemma A.5, we have the deterministic relation that

θ(∞) − θv ∞ = δ ∞ log dd+klog k , conditioned on (E0, Ev). (69)

To replicate Step 4 of Theorem 2.1(b), we ﬁrst apply the second-order mean value theorem on (68), and then take an expectation conditional on (E0, Ev). The following equation establishes a modiﬁed version of (36):

d
f (θmv − θiv) · E
i=1

δi − δm | E0, Ev =

1d

(E[µmi |E0, Ev] − µvmi) −

E[f

2

i=m

i=1

(λmi)(δm − δi)2 | E0, Ev],

(70)

where each λmi is a random variable that takes values between θmv − θiv and θmv − θiv + δm − δi. To apply Lemma A.6, we set E as Ev, and set E as E0 in (38):

|E[µij | E0, Ev] − E[µij | Ev]|

1 .

(71)

dk

28

It can be veriﬁed that

E[µij | Ev] = µvij .

(72)

Plugging (72) into (71), we have

|E[µij | E0, Ev] − µvij| d1k .
Using the same arguments as in Lemma A.7 to handle the remaining terms in (70), we have the following upper bound as a modiﬁed version of (40):

E[θ(∞) − θv | E0, Ev] ∞ = E[θ(∞) − θ(∞) | E0, Ev] ∞ log dd+klog k . (73)

Now that we have established the desired result (73) of this step, we conclude this step with some intuition why we need to condition on Ev. Without conditioning on Ev, we could still have utilized the proof of Theorem 2.1(b), and could have established a result of the form (cf. (73)):

E[θ(∞) − θv | E0] ∞ = E[θ(∞) − θ(∞) | E0] ∞ log dd+klog k . (74)

Our goal here is to bound the constrained oracle θ(B) and the constrained MLE θ(B) in expectation. However,

the fact that two unconstrained estimators are close in expectation does not imply that their constrained

counterparts are close in expectation4. Therefore, a bound of the form (74) is not suﬃcient for our goal,

and instead we need to establish some “pointwise” control between θ(∞) and θ(∞). That is, whenever the

box constraint has little eﬀect on θ(∞), we want to show that the box constraint also has little eﬀect on

θ(∞).

Thus,

we

condition

on

the

event

Ev

for

any

v

∈

[

1 2

,

µ+

]

,

and

bound

the

diﬀerence

between

θ(∞)

and

θ(∞) in expectation conditioned on Ev (that is, the bound in (73)). Given this pointwise result, we then

integrate over v to establish the desired result that θ(B) and θ(B) are close in expectation, to be presented in

the subsequent step of the proof.

Step 5: Bound the expected diﬀerence between θ(B) and θ(B), by making a connection between θ(B) − θ(B) and θ(∞) − θ(∞)
We decompose the bias of the standard MLE θ(B) as

E[θ1(B)] − θ1∗ = (E[θ1(B)] − θ1∗) + E[θ1(B) − θ1(B)].

(75)

Recall from (63) that E[θ1(B)] − θ1∗ ≤ − √cdk . (76)

In what follows, we prove that

E[θ1(B) − θ1(B)] ≤ c log dd+klog k . (77)
4 For example, consider the following two univariate estimators. The ﬁrst estimator always outputs a value within [−B, B]. The second estimator sometimes outputs a value within [−B, B], and sometimes outputs a value greater than B. The two estimators could be constructed such that they are close (or equal) in expectation. However, now consider their constrained counterparts. The ﬁrst estimator is not aﬀected by a box constraint at B, whereas the expected value of second estimator can become signiﬁcantly smaller due to the box constraint. Therefore, the constrained counterparts of these two estimators may not be close in expectation.

29

Then plugging (76) and (77) back into (75) yields E[θ1(B)] − θ1∗ ≤ − √cdk + c log dd+klog k ≤ − √cdk ,
for all d ≥ d0 and k ≥ k0 where d0 and k0 are constants, completing the proof of Theorem 2.1(a).

The rest of this step is devoted to proving (77). To bound E[θ1(B) − θ1(B)], we make a connection between θ1(B) − θ1(B) and θ1(∞) − θ1(∞), and then we evoke the bound on θ1(∞) − θ1(∞) from (73) in Step 4.
Recall that µ1 is a discrete random variable representing the fraction of wins by item 1. By the law of iterated expectation, we have

E[θ1(B) − θ1(B)] = E θ1(B) − θ1(B) | 12 < µ1 < µ∗1 · P 12 < µ1 < µ∗1
R1
+ E[θ1(B) − θ1(B) | µ1 ≥ µ∗1] · P (µ1 ≥ µ∗1) + E θ1(B) − θ1(B) | µ1 < 12 · P µ1 < 12 .
R2 R3

(78)

In what follows, we bound the terms R1, R2 and R3 separately. Consider the term R2. From the expression of θ(B) in (62), we have θ1(B) = B when µ1 ≥ µ∗1. Therefore,

E[θ1(B) − θ1(B) | µ1 ≥ µ∗1] = E[θ1(B) | µ1 ≥ µ∗1] − B (≤i) 0,

where (i) is true due to the box constraint |θ1(B)| ≤ B. Hence,

R2 ≤ 0.

(79)

Consider the term R3, we have E[µ1] = µ∗1 = 1+e−1d−d 1 B , and therefore it can be veriﬁed that there exists

a

constant

τ

>

0,

such

that

µ∗1

>

1 2

+τ

for

all

d

≥

2.

By

Hoeﬀding’s

inequality,

we

have

P µ1 < 12 < P (|µ1 − µ∗1| > τ )

≤ 2 exp −2(d − 1)kτ 2

1 .

(80)

dk

Therefore, we have

R3 = E θ1(B) − θ1(B) | µ1 < 12 · P µ1 < 21

(i)

1

≤ 2B · P µ1 <

2

(ii) 1

,

(81)

dk

where

(i)

is

true

because

|θ1(B)

−

θ

(B 1

)

|

≤

|θ1(B

)

|

+

|

θ

(B 1

)

|

≤

2B

by

the

box

constraint,

and

(ii)

is

true

due

to

(80).

30

Now consider the term R1. Denote E0 as the complement of the event E0. Using the law of iterated expectation again, we have

R1 = E θ1(B) − θ1(B) | 12 < µ1 < µ∗1 · P 12 < µ1 < µ∗1 = E θ1(B) − θ1(B) | E0, 12 < µ1 < µ∗1 · P E0, 21 < µ1 < µ∗1
R11
+ E θ1(B) − θ1(B) | E0, 12 < µ1 < µ∗1 · P E0, 12 < µ1 < µ∗1
R12

(82)

Consider the term R12. We have

P E0, 12 < µ1 < µ∗1 =

P(E0 | Ev) · P(Ev)

v

∈

(

1 2

,µ∗1

)

(≤i) c

P(Ev )

dk

v

∈

(

1 2

,µ∗1

)

1 ,
dk

(83)

where (i) is true because E0 happens w.h.p.( d1k | Ev). Combining (83) with the fact that |θ1(B) − θ1(B)| ≤ 2B due to the box constraint, we have

1 R12 dk . (84)

Now consider the term R11. We ﬁrst analyze the constrained oracle θ(B). By the expression of θ(B) in (62) and the expression of θ(∞) in (61), we have

θ(B) = θ(∞), conditioned on 21 < µ1 < µ∗1. (85)

Moreover,

given

1 2

<

µ1

<

µ∗1 ,

by

the

expression

of

θ(B)

in

(62),

we

have

0 < θ1(B) < B

and therefore by the parameterization of θ(B) in (59b),

|θi(B)| ≤ d −1 1 B Hence, there exists a constant τ > 0 such that

for every i ∈ {2, . . . , d}.

θ1(B) > −B + τ

(87a)

and

−B + τ < θi(B) < B − τ for every i ∈ {2, . . . , d}.

(87b)

31

Now we analyze the standard MLE θ(B). Recall that Ev denotes the event that µ1 = v. We have that for

every v ∈

1 2

,

µ∗1

,

θ1(∞) − θ1(B) ∞ (=i) θ1(∞) − θ(∞) ∞ (ii)

log d + log k ,
dk

conditioned on (E0, Ev),

(88)

where (i) is true by (85), and (ii) is true by (69) from Step 4. By (88), we have that for every v ∈

1 2

,

µ∗1

,

θ1(∞) − θ1(B) ∞ ≤ τ , conditioned on (E0, Ev),

(89)

for all d ≥ d0 and all k ≥ k0, where d0 and k0 are constants. Combining (89) with (87), if the unconstrained
MLE θ(∞) violates the box constraint, then only possible case is θ1(∞) > B. Then either θ1(∞) = θ1(B) (when θ(∞) does not violate the box constraint) or θ1(∞) > B ≥ θ1(B) (when θ(∞) violates the box constraint). Hence, for every v ∈ ( 12 , µ∗1),

θ1(∞) ≥ θ1(B), conditioned on (E0, Ev).

(90)

Combining (85) and (90), we have that for every v ∈ ( 21 , µ∗1),

θ(B) − θ(B) ≤ θ(∞) − θ(∞), conditioned on (E0, Ev).

(91)

By the law of iterated expectation again, we have

R11 =

E[θ1(B) − θ1(B) | E0, µ1 = v] · P(E0, µ1 = v)

v

∈(

1 2

,µ∗1

)

=

E[θ1(B) − θ1(B) | E0, Ev] · P(E0, Ev)

v

∈(

1 2

,µ∗1

)

(≤i) E[θ1(∞) − θ1(∞) | E0, Ev] · P(E0, Ev)

v

∈

(

1 2

,µ∗1

)

(ii) log d + log k

dk P(E0, Ev)

v

∈

(

1 2

,µ

∗ 1

)

log d + log k ,
dk

(92)

where (i) is true due to (91), and (ii) is true due to the bound (73) from Step 4. Plugging the term R11 from (92) and R12 from (84) back to (82), we have

log d + log k R1 = R11 + R12 dk . (93) Finally, plugging the terms R1 from (93), R2 from (79), and R3 from (81) back into (78) yields

completing the proof of (77).

E[θ1(B) − θ1(B)]

log d + log k ,
dk

A.4 Proofs of Lemmas
In this appendix, we present the proofs of all the lemmas used for proving Theorem 2.1.

32

A.4.1 Proof of Lemma A.2
We ﬁx any constant A > 0. The stretched-MLE (15) is an optimization over the compact set ΘA, and the negative log-likelihood
function is continuous. By the Extreme Value Theorem [30, Theorem 4.16], a solution θ(A) is guaranteed to exist.
It remains to prove the uniqueness of θ(A). Assume for contradiction that there exist two solutions θ, θ ∈ ΘA to the stretched-MLE (15) and θ = θ . By Lemma A.1, the negative log-likelihood function is strictly convex. Therefore,

1

θ+θ

(θ) + (θ ) >

.

(94)

2

2

It can be veriﬁed that θ+2θ ∈ ΘA. Moreover, (94) along with the fact that (θ) = (θ ) implies that θ+2θ attains a strictly smaller function value than both θ and θ . This contradicts the assumption that θ and θ are both optimal solutions to the stretched-MLE (15).

A.4.2 Proof of Lemma A.3
We ﬁrst deﬁne a “comparison graph” G({Wij}) as a function of the pairwise-comparison outcomes {Wij}. Let each item i ∈ [d] be a node of the graph. Let there be a directed edge (i → j) ∈ G, if and only if there exists a comparison where item i beats item j. A directed graph is called strongly-connected if and only if there exists a path from every node i to every other node j.
The following lemma from [21] relates the existence and uniqueness of a ﬁnite unconstrained MLE θ(∞) to the strong connectivity of the comparison graph G. This lemma is based on a diﬀerent parameterization of the BTL model. In this parameterization, each item has a weight wi∗ > 0, and the probability that item i beats item j equals wi∗ .
wi∗ +wj∗
Lemma A.14 (Section 2 from [21]). If the comparison graph G({Wij}) is strongly-connected, then there exists a unique solution to the following MLE:

wMLE = argmin w({Wij}; w),

w∈Rd

wi >0,

d i=1

wi =1

where the negative log-likelihood function w is deﬁned as

w(w) = −

Wij log wi + Wji log wj .

1≤i<j≤d

wi + wj

wi + wj

It can be seen that θ and w are simply diﬀerent parameterizations of the same problem. There is a
one-to-one mapping between θ and w, by taking θi = log(wi) and re-centering accordingly (or in the inverse direction, by taking wi = eθi and normalizing accordingly). Therefore, the existence and the uniqueness of the MLE wMLE in Lemma A.3 carries over to our unconstrained MLE θ(∞) in (14). That is, if the comparison graph G is strongly-connected, then there exists a unique solution θ(∞) to the unconstrained MLE. It remains to show that the comparison graph G is strongly-connected w.h.p.( d1k ).

We ﬁrst construct an undirected graph G ({Wij}) as follows. Let each item i ∈ [d] be a node of the graph G . Let there be an undirected edge (i, j) ∈ G , if and only if in the directed graph G we have both (i → j) ∈ G and (j → i) ∈ G. Equivalently, there exists an undirected edge (i, j) ∈ G , if and only if
0 < µij < 1. It can be veriﬁed that the connectivity of the undirected graph G implies the strong connectivity of the directed graph G. Therefore,

P(G strongly-connected) ≥ P(G connected).

(95)

33

The probability that (i, j) ∈ G is P(0 < µij < 1). By Hoeﬀding’s inequality, we have that for any t > 0,

P(|µij − µ∗ij| > t) < 2e−kt2 , for all 1 ≤ i < j ≤ d.

We

have

0<

1 1+e2B

≤ µ∗ij

≤

1 1+e−2B

< 1,

for

any

i < j.

Since

B

is

a

constant,

we

have

that

µ∗ij

is

bounded

away

from

0

and

1

by

a

constant.

Set

t

=

τ

where

τ

is

any

constant

such

that

0

<

τ

<

1 1+e2B

.

Then

for

all

1 ≤ i < j ≤ d, we have

P(0 < µij < 1) > P(µ∗ij − τ < µij < µ∗ij + τ ) ≥ 1 − P(|µij − µ∗ij| > τ ) > 1 − 2e−ck,

for some constant c > 0 . Recall that the random variables {µij} are independent across all 1 ≤ i < j ≤ d. Hence, the probability
of the undirected graph G being connected is at least the probability of an (undirected) Erdős-Rényi random graph being connected, where each edge independently exists with probability 1 − 2e−ck.
The following lemma from [13] provides an upper bound on the probability of an (undirected) Erdős-Rényi
random graph being disconnected (and hence a lower bound on the probability of the graph being connected).

Lemma A.15 (Theorem 1 from [13]). For an (undirected) Erdős-Rényi graph of d nodes, where each edge independently exists with probability p. Let q := 1 − p. Then the probability of the graph being disconnected is at most
1 − d − 1 qd−1 dqd−1. 2

To apply Lemma A.15, we set p = 1 − 2e−ck and therefore q = 2e−ck. Then we have

P[G disconnected] ≤ 1 − d − 1 qd−1 dqd−1 2

≤ dqd−1

= de−ck(d−1)

≤ c , for some constant c > 0.

(96)

dk

Combining (95) and (96) completes the proof of the lemma.

A.4.3 Proof of Lemma A.4 We ﬁrst consider any ﬁxed m ∈ [d]. By the deﬁnition of {µij} in (9), we have

1

k (r)

µmi = k

Xmi .

i=m

i=m r=1

(97)

There are (d − 1)k terms of the form Xm(ri) in (97). It can be veriﬁed that the terms Xm(ri) involved in (97) are independent. Moreover, since Xm(ri) ∈ {0, 1}, changing the value of a single term Xm(ri) changes the value of (97) by k1 . By McDiarmid’s inequality, we have that for any t > 0,





P  µmi − µ∗mi > t ≤ 2 exp − (d − 12)tk2· ( 1 )2 = 2 exp − (d2k−t21) . (98)

i=m

i=m

k

34

Setting t = c d(log dk+log k) in (98), we have





P  µmi − µ∗mi ≤ c

i=m

i=m

d(log d + log k)  ≥ 1 − 2 exp k

−c

d (log d + log k)

d−1

≥1− c ,

(99)

d2k

for some constants c , c > 0, provided that the constant c > 0 is suﬃciently large. Taking a union bound over m ∈ [d] on (99) completes the proof.

A.4.4 Proof of Lemma A.5
Denote the random variables m+ := argmaxi∈[d] δi and m− := argmini∈[d] δi. When there are multiple maximizers or minimizers, we arbitrarily choose one.
Setting m = m+ in the ﬁrst-order optimality condition (34), we have

d

[

f

(θ

∗ m+

−

θi∗

+

δm+

−

δi)

−

f

(θ

∗ m

+

−

θi∗)]

=

(i)
(µmi − µ∗mi)

i=1

i=m+

R+

d(log d + log k) ,
k

(100)

where (i) is true by Lemma A.4 (recall that the lemma statement is conditioned on the event E0 that both

Lemma A.3 and Lemma A.4 hold).

Denote

the

function

g(x, t) := f (x + t) − f (x) =

1 1+e−(x+t)

−

1 1+e−x

.

The

following

lemma

states

three

properties for the function g, which are used in later parts of the proof.

Lemma A.16. We have the following properties for the function g.

g(x, t) = −g(−x, −t), g(x, t) ≥ g(τ, t) > 0, g(τ, t1) + g(τ, t2) ≥ g(τ, t1 + t2),

for all x, t ∈ R for all τ > 0, t > 0, and all x such that − τ ≤ x ≤ τ
for all τ > 0, and all t1, t2 ≥ 0.

(101a) (101b) (101c)

Lemma A.16 can be veriﬁed by straightforward algebra. For completeness, we include the proof of
Lemma A.16 at the end of this appendix. By the deﬁnition of m+, we have δm+ = maxi∈[d] δi, and therefore δm+ − δi ≥ 0 for all i ∈ [d]. Hence, we
have

d

R+ =

f

(θ

∗ m

+

−

θi∗

+

δm+

−

δi)

−

f

(θ

∗ m

+

−

θi∗)

i=1

d
= g(θm∗ + − θi∗, δm+ − δi)
i=1

(i) d
≥ g(2B, δm+ − δi),

i=1

(102)

where (i) is true by (101b) combined with the fact that |θi∗ − θj∗| ≤ |θi∗| + |θj∗| ≤ 2B for all i, j ∈ [d]. Similarly, setting m = m− in the ﬁrst-order optimality condition (34), we have

d

[

f

(θ

∗ m

−

−

θi∗

+

δm−

−

δi)

−

f

(

θ

∗ m−

−

θi∗)]

i=1

R−

d(log d + log k) .
k

(103)

35

By the deﬁnition of m−, we have δm− = mini∈[d] δi, and therefore δi − δm− ≥ 0 for all i ∈ [d]. Hence, we have

d

R− =

f

(θ

∗ m

−

−

θi∗

+

δm−

−

δi)

−

f

(

θ

∗ m−

−

θi∗)

i=1

d
= g(θm∗ − − θi∗, δm− − δi)
i=1

d

(i)
=

−g(θi∗

−

θ

∗ m−

,

δi

−

δm− )

i=1

(ii) d
≤ −g(2B, δi − δm− ),

i=1

(104)

where (i) is true by (101a), and (ii) is true by (101b) combined with the fact that |θi∗ − θj∗| ≤ 2B for all i, j ∈ [d].
Combining (102) and (104), we have

d

d

R+ − R− ≥ g(2B, δm+ − δi) + g(2B, δi − δm− )

i=1

i=1

(i) d
≥ g(2B, δm+ − δm− )

i=1

(ii)
= d · g(2B, δm+ − δm− ) ≥ 0,

(105)

where (i) is true due to (101c) since δm+ − δi ≥ 0 and δi − δm− ≥ 0 for all i ∈ [d], and (ii) is true since δm+ − δm− ≥ 0. On the other hand, combining (100) and (103), we have

R+ − R− Combining (105) and (106), we have

d(log d + log k) .
k

(106)

0 ≤ d · g(2B, δm+ − δm− ) ≤ R+ − R+ g(2B, δm+ − δm− )
f (2B + δm+ − δm− ) − f (2B)

d(log d + log k) k
log d + log k dk
log d + log k .
dk

By the ﬁrst-order mean value theorem on the LHS of (107), we have

(107)

f (2B + δm+ − δm− ) − f (2B) = f (λ) · (δm+ − δm− ) ≤ c

log d + log k ,

dk

(108)

where λ is a random variable that takes values in the interval [2B, 2B + δm+ − δm− ]. Let be any constant such that 0 < < 1 − f (2B). Then there exists a constant τ > 0 such that
f (2B + τ ) − f (2B) = . On the other hand, there exist constants d0 > 0 and k0 > 0 such that

log d + log k

c

<,

dk

for any d ≥ d0 and k ≥ k0.

(109)

36

Combining (108) and (109), we have

f (2B + δm+ − δm− ) − f (2B) ≤ c

log d + log k <

dk

f (2B + δm+ − δm− ) ≤ f (2B + τ ).

= f (2B + τ ) − f (2B)

(110)

By (12a), we have f > 0 on (−∞, ∞), and hence the function f is monotonically increasing. Hence, from (110), we have δm+ − δm− ≤ τ , and therefore the interval [2B, 2B + δm+ − δm− ] is bounded. By the property (12a) of the sigmoid function f , we have f > c3 > 0 for some constant c3 > 0 in the bounded interval [2B, 2B + δm+ − δm− ]. Recall that λ takes values in the interval [2B, 2B + δm+ − δm− ]. Therefore, we have

c3(δm+ − δm− ) < f (λ) · (δm+ − δm− ).

(111)

Combining (108) and (111), we have

c3(δm+ − δm− ) < f (λ) · (δm+ − δm− ) ≤ c

δm+ − δm−

log d + log k .
dk

log d + log k dk

(112)

By the assumption that θ∗ ∈ ΘB, we have

d i=1

θi∗

= 0.

Similarly,

by

the

centering

constraint

on

the

unconstrained MLE θ(∞) in (14), we have

d i=1

θi(∞)

=

0.

Hence,

we

have

the

deterministic

relation

d

d

d

θi(∞) − θi∗ = δi = 0.

i=1

i=1

i=1

(113)

Hence, δm+ ≥ 0 and δm− ≤ 0. By (112), we have

δm+ − δm− = |δm+ | + |δm− |

log d + log k .
dk

Hence, |δm+ |

log d+log k dk

and

|δm− |

log dd+klog k . Therefore,

|δm| completing the proof of the lemma.

log d + log k ,
dk

for all m ∈ [d],

Proof of Lemma A.16: We prove the three parts of the lemma separately. (a) It can be veriﬁed that f (x) = 1 − f (−x). Hence, g(x, t) = f (x + t) − f (x) = [1 − f (−x − t)] − [1 − f (−x)] = −[f (−x − t) − f (−x)] = −g(−x, −t).
(b) We prove the two parts of the inequality separately. We ﬁrst prove that g(τ, t) > 0. By (12a), the function f is strictly increasing. Therefore, for any t > 0, we have
g(τ, t) = f (τ + t) − f (τ ) > 0.
37

Now we prove that g(x, t) ≥ g(τ, t). We have

g(x, t) − g(τ, t) = f (x + t) − f (x) − [f (τ + t) − f (τ )]

x+t

τ +t

=

f (u) du −

f (u) du

x

τ

t

t

= f (x + u) du − f (τ + u) du

0

0

t

= [f (x + u) − f (τ + u)] du.

0

By (114), it remains to prove that

(114)

f (x + u) ≥ f (τ + u), for any u ∈ [0, t].

(115)

Fix any u ∈ [0, t]. By assumption we have τ > 0. Hence, τ + u > 0. Now we consider the sign of (x + u).
If x + u ≥ 0, then by the assumption that x ≤ τ , we have 0 ≤ x + u ≤ τ + u. It can be veriﬁed that f is decreasing on [0, ∞). Therefore,

f (x + u) ≥ f (τ + u).

(116)

If x + u < 0, we have

(i)

(ii)

0 < −x − u ≤ τ − u ≤ τ + u,

(117)

where (i) is true by the assumption that x ≥ −τ , and (ii) is true because u ∈ [0, t] and therefore u ≥ 0. We have

(i)

(ii)

f (x + u) = f (−x − u) ≥ f (τ + u),

(118)

where (i) holds because it can be veriﬁed that f (x) = f (−x) for any x ∈ R, and (ii) is true by combining (117) with the fact that f is decreasing on [0, ∞).
Combining the two cases of (116) and (118) completes the proof of (115).

(c) We have

g(τ, t1) + g(τ, t2) = f (τ + t1) − f (τ ) + f (τ + t2) − f (τ )

τ +t1

τ +t2

=

f (u) du +

f (u) du

τ

τ

(i) τ +t1

τ +t1+t2

≥

f (u) du +

f (u) du

τ

τ +t1

τ +t1+t2

=

f (u) du

τ

= f (τ + t1 + t2) − f (τ ) = g(τ, t1 + t2),

where (i) is true because f is decreasing on (0, ∞), and because τ > 0 and t1, t2 ≥ 0 by assumption.

A.4.5 Proof of Lemma A.6 We ﬁx any i, j ∈ [d] where i = j. By the law of iterated expectation, we have
E[µij | E] = E[µij | E , E] · P(E | E) + E[µij | E , E] · P(E | E).

(119)

38

Subtracting E[µij | E , E] from both sides of (119), we have

E[µij | E] − E[µij | E , E] = E[µij | E , E] · [P(E | E) − 1] + E[µij | E , E] · P(E | E) = (−E[µij | E , E] + E[µij | E , E]) · P(E | E).
Taking an absolute value on (120), we have

(120)

|E[µij | E] − E[µij | E , E]| = −E[µij | E , E] + E[µij | E , E] · P(E | E)
(i) 1 ,
dk
where (i) is true due to the deterministic inequality 0 ≤ µij ≤ 1 and the fact that event E happens w.h.p.( d1k | E).

A.4.6 Proof of Lemma A.7
Denote m+ := argmaxi∈[d] ∆i and m− := argmini∈[d] ∆i. When there are multiple maximizers or minimizers, we arbitrarily choose one. The proof works similarly in spirit to the proof of Lemma A.5. We ﬁrst show that ∆m+ − ∆m− satisﬁes the desired upper bound. Then we show that ∆m+ and ∆m− have diﬀerent signs, and therefore the desired upper bound holds on |∆m| uniformly across all m ∈ [d].
Recall from (37) that for every m ∈ [d],

d
f (θm∗ − θi∗) · (∆m − ∆i) =

1d

(E[µmi | E0] − µ∗mi) −

E[f (λmi)(δm − δi)2 | E0],

2

i=1

i=m

i=1

(121)

R1

R2

where λmi is a random variable that takes values between θm∗ − θi∗ and θm∗ − θi∗ + (δm − δi). We consider the two terms on the RHS of (37) separately. For the term R1, recall from (39) that

Therefore,

|E[µmi | E0] − µ∗mi| d1k .

|R1| (d − 1) · 1

1 .

dk k

(122)

Now consider the term R2. Recall that θ∗ ∈ ΘB. Therefore, for every m ∈ [d], we have |θm∗ | ≤ B. Recall from Lemma A.5 that for every m ∈ [d], we have

|δm|

log d + log k ,

conditioned on E0.

dk

(123)

Let c > 0 be any constant. By (123), we have |δm| ≤ c, for all d ≥ d0 and k ≥ k0, where d0 and k0 are constants which may only depend on c. Hence, conditioned on E0, the interval between θm∗ − θi∗ and θm∗ − θi∗ + (δm − δi) is contained in the interval [−2B − 2c, 2B + 2c]. By the property (12b) of the sigmoid function f , we have

|f | < c5, on the bounded interval [−2B − 2c, 2B + 2c].

Therefore,

E f (λmi) · (δm − δi)2 | E0

≤

c5

·

E[(δm

−

δi)2

|

E0]

(i)

log d

+

log k ,

dk

for all i, m ∈ [d],

39

where (i) is again by (123). Therefore,

|R2|

d·

log d + log k

=

log d + log k .

dk

k

Taking an absolute value on (121) and using the triangle inequality, we have

(124)

d

(i) log d + log k

f (θm∗ − θi∗) · (∆m − ∆i) ≤ |R1| + |R2|

,

k

i=1

(125)

where (i) is true by combining the term R1 from (122) and the term R2 from (124). Taking m = m+ in (125), we have

d

log d + log k

f (θm∗ + − θi∗) · (∆m+ − ∆i) ≤ c

.

k

i=1

(126)

Taking m = m− in (125), we have

and hence

d

log d + log k

f (θm∗ − − θi∗) · (∆m− − ∆i) ≥ −c

k

i=1

d

log d + log k

f (θm∗ − − θi∗) · (∆i − ∆m− ) ≤ c

.

k

i=1

(127)

Adding (126) and (127), we have

d

d

log d + log k

f (θm∗ + − θi∗) · (∆m+ − ∆i) + f (θm∗ − − θi∗) · (∆i − ∆m− ) ≤ c

.

k

i=1

i=1

R

(128)

Consider the term R. We have |θm∗ − θi∗| ≤ 2B for all i, m ∈ [d]. By the property (12a) of the sigmoid function, there exists some constant c3, such that

f (θm∗ − θi∗) > c3 > 0, for all i, m ∈ [d].

(129)

By the deﬁnition of m+ and m−, we have ∆m+ − ∆i ≥ 0 and ∆i − ∆m− ≥ 0 for every i ∈ [d]. Plugging (129) into (128), combined with the fact that ∆m+ − ∆i ≥ 0 and ∆i − ∆m− ≥ 0, we have

d

d

log d + log k

c3 (∆m+ − ∆i) + (∆i − ∆m− ) ≤ R ≤ c k

i=1

i=1

c3d

·

(∆m+

−

∆m− )

≤

log c

d

+

log

k

k

∆m+ − ∆m−

log d + log k .
dk

By (113) in the proof of Lemma A.5, we have the deterministic relation

(130)

d
δi = 0.
i=1

(131)

40

B

0 µ− −B

0.5

µ+ 1

h h+ h0

Figure 8: The functions h, h+ and h0.

Taking an expectation over (131) conditional on E0, we have

d
∆i = 0.
i=1

Hence, ∆m+ ≥ 0 and ∆m− ≤ 0. By (130), we have

∆m+ − ∆m− = |∆m+ | + |∆m− |

log d + log k .
dk

Hence, |∆m+ |

log d+log k dk

and

|∆m− |

log dd+klog k . Therefore,

|∆m|

log d + log k ,
dk

for all m ∈ [d].

A.4.7 Proof of Lemma A.9

To compare the functions h and h+, we introduce an auxiliary function h0 : [0, 1] → [−B, B]:



−B

h0(t)

=

B



µ+

−

1 2

(t

−

21 )

B

if 0 ≤ t ≤ µ− if µ− < t < µ+ if µ+ ≤ t ≤ 1.

In words, the function h0 is piecewise linear. On the interval [0, µ−], its value equals the constant −B. On
the interval [µ−, µ+], it is a line passing through the points (µ−, −B) and (µ+, B). On the interval [µ+, 1], its value equals the constant B. See Fig. 8 for a comparison of the three functions h, h+ and h0.
It can be veriﬁed that h+(t) ≥ h0(t) for any t ∈ [0, 1]. Hence,

E[h+(µ)] ≥ E[h0(µ)].

(132)

Recall that our goal is to prove (51):

E[h(µ)] ≤ E[h+(µ)].

Given (132), it suﬃces to prove that

E[h(µ)] ≤ E[h0(µ)].

(133)

41

The rest of the proof is devoted to proving (133).

It can be veriﬁed that h and h0 are anti-symmetric around 12 . That is, for any t ∈ [0, 1], we have

h(t) = −h(1 − t) h0(t) = −h0(1 − t).

(134a) (134b)

In particular, we have

1

1

h 2 = h0 2 = 0.

(135)

It can also be veriﬁed that

h(t) ≥ h0(t),

for all t ∈

1 0,

.

2

(136)

Recall the notation of W = kµ representing the number of times that item 1 beats item 2 among the k comparisons between them. We have W ∼ Binom(k, µ+). Therefore,

E[h(µ)] − E [h0(µ)] = EW h W k

− EW h0 W k

k

w

= h k − h0

w=0



k

(i)  2

k

= +



w=0 w= k2

w · P(W = w) k

(h − h0) w k

· P(W

= w)

k

2
(ii)

w

w

=

(h − h0)

· P(W = w) + (h − h0) 1 −

k

k

w=0

k

2
(iii)

w

= (h − h0)

· [P(W = w) − P(W = k − w)],

k

w=0

· P(W = k − w)

(137)

where (i) is true by (135). Speciﬁcally, when k is even, we double-count the term of w = k2 . This term equals

(h

−

h0

)(

1 2

)

=

0,

so

double-counting

this

term

does

not

aﬀect

the

equality.

Moreover,

step

(ii)

is

true

by

a

change of variable w ← k − w in the second summation, and step (iii) is true by the anti-symmetry (134) of

the functions h and h+.

Now consider the terms in the summation (137). By (136), we have

(h − h0) w ≥ 0, k

for all 0 ≤ w ≤

k .

2

Using the binomial probabilities of W ∼ Binom(k, µ+), we also have

P(W = w) − P(W = k − w) = k w
k =
w
(i)
≤ 0,

[(µ+)w(1 − µ+)k−w − (µ+)k−w(1 − µ+)w]

(µ+)w(1 − µ+)w · [(1 − µ+)k−2w − (µ+)k−2w]

for all 0 ≤ w ≤

k ,

2

(138) (139)

42

where

(i)

is

true

because

µ+

=

1 1+e−2B

>

12 ,

combined

with

the

fact

that

k − 2w

≥ 0,

for

all

0≤w

≤

k2 .

Plugging (138) and (139) back into (137), we have

E[h(µ)] − E[h0(µ)] ≥ 0,

completing the proof of (133).

A.4.8 Proof of Lemma A.10

We have

E[h+(µ)] − θ1∗ = EW h+ Wk − B

k

w

= h+

· P(W = w) − B

k

w=0

kµ+

(i)
=

2B w − µ+ · P(W = w)

w=0 µ+ k 

 kµ+ w

kµ+



= c  

k · P(W = w) −µ+

P(W = w) , 

w=0

w=0

R1

R2

(140)

where (i) is true by plugging in the deﬁnition of the function h+ from (50). Now we consider the two terms R1 and R2 separately. For any integer n ≥ 1, any integer s such that
0 ≤ s ≤ n, and any real number p ∈ [0, 1], we deﬁne Ple(n, p, s) (resp. Peq(n, p, s)) as the probability that the value of the random variable Binom(n, p) is at most (resp. equal to) s. That is,

Ple(n, p, s) = P[Binom(n, p) ≤ s], Peq(n, p, s) = P[Binom(n, p) = s].

Then the term R2 can be written as

R2 = Ple(k, µ+, kµ+ ).

(141)

For the term R1, we have

kµ+

kµ+

w · P(W = w) =

w·

R1 = k k

w=0

w=0

wk µw+(1 − µ+)(k−w)

kµ+
= wk · w!(kk−! w)! µw+(1 − µ+)(k−w)
w=1

kµ+

(k − 1)!

w−1

(k−w)

= µ+

(w − 1)!(k − w)! µ+ (1 − µ+)

w=1

(i)

kµ+ −1

(k − 1)!

w

(k−1−w)

= µ+

(w)!(k − w − 1)! µ+(1 − µ+)

w=0

= µ+

kµ+ −1 w=0

k w− 1 µw+(1 − µ+)(k−1−w)

= µ+ · Ple(k − 1, µ+, kµ+ − 1),

(142)

43

where (i) is true by a change of variable w ← w − 1. Plugging (141) and (142) back into (140), we have

E[h+(µ)] − θ1∗ = cµ+ · [Ple(k − 1, µ+, kµ+ − 1) − Ple(k, µ+, kµ+ )].

(143)

For any integer n ≥ 1, any integer s such that 0 ≤ s ≤ n, and any p ∈ [0, 1], we claim the combinatorial equality

Ple(n, p, s) = Ple(n − 1, p, s − 1) + (1 − p) · Peq(n − 1, p, s).

(144)

To prove (144), we use a standard combinatorial argument. Consider n balls, and we select each ball independently with probability p. Then the LHS of (144) equals the probability that at most s balls are selected. This event can be decomposed into two cases. Either there are at most (s − 1) balls selected from the ﬁrst (n − 1) balls; or there are exactly s balls selected from the ﬁrst (n − 1) balls, and the last ball is not selected. These two cases correspond to the two terms on the RHS of (144).
Now setting n = k, p = µ+, and s = kµ+ in (144), we have

Ple(k, µ+, kµ+ ) = Ple(k − 1, µ+, kµ+ − 1) + (1 − µ+) · Peq(k − 1, µ+, kµ+ ]).

(145)

Combining (143) and (145), we have

E[h+(µ)] − θ1∗ = −c(1 − µ+) · Peq(k − 1, µ+, kµ+ ).

(146)

It remains to bound the term Peq(k − 1, µ+, kµ+ ) on the RHS of (146). Writing out the binomial probability, we have

Peq(k − 1, µ+, kµ+ ) =

k−1 kµ+

µ+kµ+ (1 − µ+)k−1− kµ+ .

(147)

By the Stirling’s approximation, we have √2π · kk+ 12 e−k ≤ k! ≤ e · kk+ 21 e−k,

for any integer k ≥ 0.

Then for any integer n ≥ 1, and any integer k such that 0 ≤ k ≤ n, we have

n

n!

n

n+

1 2

k = k!(n − k)! ≥ c kk+ 12 (n − k)n−k+ 21 .

(148)

Plugging (148) into (147), we have

Peq(k − 1, µ+,

kµ+

)≥c

(k

−

1)k−

1 2

· µ kµ+ (1 − µ )k−1− kµ+

(k − 1 −

kµ+

)k

−

1 2

−

kµ+

· ( kµ+ ) kµ+ + 21

+

+

≥ c (k − 1)k− 21

· µ kµ+ (1 − µ )k−1− kµ+

(k

−

k

µ

+

)

k

−

1 2

−

kµ+

· (kµ+) kµ+ + 21

+

+

≥ c (k − 1)k− 21

· µ kµ+ (1 − µ )k−1− kµ+

kk

·

(1

−

µ+

)

k

−

1 2

−

kµ+

· (µ+) kµ+ + 21

+

+

= c (k −k1k)k− 21 · µ−+ 12 (1 − µ+)− 12

(i)

(k

−

1)k−

1 2

1

=c

≥ c√

(1 − 1 )k

√1 ,

kk

k−1 k

k

(149)

where (i) is true because µ+ =

1 1+e−2B

is bounded away from 0 and 1 by a constant.

Combining (146) and (149), we have

E[h+(µ)] − θ1∗ ≤ − √ck , for some constant c > 0.

44

A.4.9 Proof of Lemma A.11
First consider the unconstrained oracle θ(∞). We prove that for any θ ∈ Θoracle, there exists some θ ∈ Θoracle such that (θ ) < (θ), where both θ and θ satisfy the centering constraint.
Consider any θ ∈ Θoracle. By the deﬁnition of Θoracle, there exist some integers i and j where 2 ≤ i < j ≤ d, such that θi = θj. By the symmetry of the manipulated observations {µij} deﬁned in (56) with respect to item 2 through item d, we have that for any θ ∈ Rd,

({µi,j; θ}) = ({µi,j; θπ}),

(150)

where π : {2, . . . , d} → {2, . . . , d} is any permutation of item 2 through item d, and θπ = [θ1, θπ(2), . . . , θπ(d)]. For every s ∈ {0, 1, . . . , d − 2}, deﬁne πs as the permutation where item 2 through item d are shifted s positions to the left in a circle. That is, for every i ∈ {2, . . . , d}, we have

πs(i) = 2 + [(i − 2 + s) mod (d − 1)].

Now deﬁne θ = d−1 1

d−2 s=0

θπs

.

It

can

be

veriﬁed

that

θ=

1d

1d

θ1, d − 1 θi, . . . , d − 1 θi

i=2

i=2

∈ Θoracle.

(151)

Moreover, we have

(θ ) =

1 d−2 d − 1 θπs
s=0

(i) 1 d−2

(ii)

< d − 1 (θπs ) = (θ),

s=0

where (i) is due to the strict convexity of the negative log-likelihood function in Lemma A.1, and (ii) is due to (150).
Now we argue the equivalence of the unconstrained oracle θ(∞) deﬁned in (57a) and (58a). If a solution θ(∞) to (57a) exists, then we have θ(∞) ∈ Θoracle and it is trivially also the solution to (58a). On the other hand, if a solution θ(∞) to (58a) exists, assume for contradiction that θ(∞) is not a solution to (57a). Then either there exists no solution to (57a), or the solution to (57a) is not θ(∞). In either case, there exists some θ such that (θ) < (θ(∞)). By (151), we construct some θ ∈ Θoracle such that (θ ) < (θ) < (θ(∞)). This contradicts the assumption that θ(∞) is the optimal solution to (58a). Hence, Eq. (57a) and (58a) are equivalent deﬁnitions of the unconstrained oracle θ(∞).

The same argument can be extended to the constrained oracle θ(B), by noting that if θ ∈ ΘB, then in the construction (151) we have θ ∈ ΘB.

A.4.10 Proof of Lemma A.12

Note that the lemma statement is conditioned on the event Ev. That is, we observe µ1 = v for some

1 2

≤

v

≤

µ+

<

1.

In

particular,

we

have

0

<

µ1

<

1.

Then

there

exists

at

least

one

directed

edge

from

node

1

to nodes {2, . . . , d}, and at least one directed edge from nodes {2, . . . , d} to node 1. Then it suﬃces to prove

that the subgraph consisting of nodes {2, . . . , d} is strongly-connected w.h.p.( d1k ). Note that the observations {µij} for any 2 ≤ i < j ≤ d are all independent of µ1, and therefore independent

of the event Ev. Using the arguments in Lemma A.3, we have that the subgraph consisting of nodes {2, . . . , d}

is strongly-connected w.h.p.( d1k ).

A.4.11 Proof of Lemma A.13

Note that the lemma statement is conditioned on the event Ev. That is, we observe µ1 = v for some

1 2

≤

v

≤

µ+

<

1.

45

When m = 1, the desired inequality (66) holds trivially, because conditioned on Ev, we have

µ1i − µv1i = (d − 1)v − (d − 1)v = 0.

i=1

i=1

Now consider every m ∈ {2 . . . , d}. Consider the (unconditional) McDiarmid’s inequality of (99) in the proof of Lemma A.4. Replacing the summation sign i=m on the LHS of (99) by the summation sign i≥2
i=m
(that is, we further exclude i = 1 from the summation) yields the unconditional inequality:





P 

µmi −

µ∗mi ≤ c

2≤i≤d

2≤i≤d

i=m

i=m

d(log dk+ log k)  ≥ 1 − dc2k ,

(152)

where c, c > 0 are constants. Now we condition (152) on the event Ev. Note that for all i, m ∈ {2, . . . , d}

with i = m, the terms {µmi} are independent of Ev. Moreover, by the expression of µvmi in (64), we have

µ∗mi

=

1 2

=

µvmi

conditioned

on

Ev .

Hence,

we

have





P 

µmi −

µvmi ≤ c

2≤i≤d

2≤i≤d

i=m

i=m

d(log d + log k) k

Ev  ≥ 1 − dc2k .

(153)

Now we bound the quantity |µm1 − µvm1| conditioned on Ev. By the deﬁnition of µ1, we have that among the (d − 1)k comparisons {X1(rj)}j∈{2,...,d},r∈[k] in which item 1 is involved, there are (d − 1)kµ1 terms that
have value 1, and the rest have value 0. Hence, each µ1j can be thought of as the mean of k comparisons
sampled without replacement from the (d − 1)k comparisons {X1(rj)}j∈{2,...,d},r∈[k]. By Hoeﬀding’s inequality (sampling without replacement), we have that for every j ∈ {2, . . . , d},

P µ1j − µv1j ≤ c log d +k log k Ev ≥ 1 − 2 exp (−c (log d + log k)) ≥1− c , d2k
where c, c , c > 0 are constants. Equivalently, by a change of variables, we have that for every j ∈ {2, . . . , d},

P |µm1 − µvm1| ≤ c

log d + log k k

Ev ≥ 1 − c . d2k

(154)

Combining (153) and (154) by the triangle inequality, and taking a union bound over m ∈ {2, . . . , d} completes the proof.

B Proof of Theorem 2.2
In this appendix, we present the proof of Theorem 2.2. Both Theorem 2.2(a) and Theorem 2.2(b) are closely related to Theorem 2 from [31]. Under our setting, the quantity σ deﬁned in [31] is a universal constant, and the quantities ζ and γ deﬁned in [31] are constants that depend only on the constant B.
46

B.1 Proof of Theorem 2.2(a)
Theorem 2.2(a) is a direct consequence of Theorem 2(a) from [31]. We now provide some details on how to apply Theorem 2(a) from [31]. Under our setting, each pair of items is compared k times. Therefore, the sample size n is

n = d k = Θ(d2k). 2

(155)

Moreover, under our setting the underlying topology is a complete graph. Let L denote the scaled Laplacian as deﬁned in Eq. (4) from [31], and let L† denote the Moore-Penrose pseudoinverse of L. From [31], the spectrum of L for a complete graph is 0, d−2 1 , . . . , d−2 1 . Therefore, we have

2

λ2(L)

=

d

−

, 1

tr(L†)

=

(d

−

1)

·

d

−

1

=

(d

−

1)2 .

2

2

(156a) (156b)

Plugging (155) and (156) into Theorem 2(a) from [31] shows that the Theorem 2.2(a) holds for all k ≥ k0, where k0 is a constant.

B.2 Proof of Theorem 2.2(b)

The proof of Theorem 2.2(b) closely mimics the proof of Theorem 2(b) from [31] (which is in turn based on Theorem 1(b) from [31]). In what follows, we state a minor modiﬁcation to be made in order to extend the proof from [31] to Theorem 2.2(b).
In the proof from [31], the box constraint for the MLE θ(B) is only used to obtain the following bound (see Appendix A.2 from [31]):

vT ∇2 (w)v ≥ nγσ2 Xv 22, for all v, w ∈ ΘB.

(157)

Now we ﬁx any constant A such that A > B. It can be veriﬁed that (157) still holds when replacing ΘB by ΘA, where we now allow γ to depend on both A and B. Since A is assumed to be a constant, we have that γ is still a constant. Then the rest of the arguments from [31] carry to the proof of Theorem 2.2(b).

47

