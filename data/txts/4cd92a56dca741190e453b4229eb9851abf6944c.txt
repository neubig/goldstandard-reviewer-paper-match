Stochastic Optimization with Heavy-Tailed Noise via Accelerated Gradient Clipping

arXiv:2005.10785v2 [math.OC] 23 Oct 2020

Eduard Gorbunov∗ MIPT and HSE, Russia

Marina Danilova† ICS RAS and MIPT, Russia

Alexander Gasnikov‡ MIPT and HSE, Russia

Abstract
In this paper, we propose a new accelerated stochastic ﬁrst-order method called clipped-SSTM for smooth convex stochastic optimization with heavy-tailed distributed noise in stochastic gradients and derive the ﬁrst high-probability complexity bounds for this method closing the gap in the theory of stochastic optimization with heavy-tailed noise. Our method is based on a special variant of accelerated Stochastic Gradient Descent (SGD) and clipping of stochastic gradients. We extend our method to the strongly convex case and prove new complexity bounds that outperform state-of-the-art results in this case. Finally, we extend our proof technique and derive the ﬁrst non-trivial high-probability complexity bounds for SGD with clipping without light-tails assumption on the noise.

1 Introduction

In this paper we focus on the following problem

min f (x), f (x) = Eξ [f (x, ξ)] ,

(1)

x∈Rn

where f (x) is a smooth convex function and the mathematical expectation in (1) is taken with respect to the random variable ξ deﬁned on the probability space (X , F, P) with some σ-algebra F and probability measure P. Such problems appear in various applications of machine learning [21, 61, 64] and mathematical statistics [66]. Perhaps, the most popular method to solve problems like (1) is Stochastic Gradient Descent (SGD) [26, 50, 51, 59, 63]. There is a lot of literature on the convergence in expectation of SGD for (strongly) convex [20, 24, 25, 46, 48, 49, 55] and non-convex [6, 20, 34] problems under different assumptions on stochastic gradient. When the problem is good enough, i.e. when the distributions of stochastic gradients are light-tailed, this theory correlates well with the real behavior of trajectories of SGD in practice. Moreover, the existing high-probability bounds for SGD [9, 11, 49] coincide with its counterpart from the theory of convergence in expectation up to logarithmical factors depending on the conﬁdence level.

However, there are a lot of important applications where the noise distribution in the stochastic gradient is signiﬁcantly heavy-tailed [65, 71]. For such problems SGD is often less robust and shows poor performance in practice. Furthermore, existing results for the convergence with high-probability for SGD are also much worse in the presence of heavy-tailed noise than its “light-tailed counterparts”. In this case, rates of the convergence in expectation can be insufﬁcient to describe the behavior of the method.

To illustrate this phenomenon we consider a simple example of stochastic optimization problem and apply SGD with constant stepsize to solve it. After that, we present a natural and simple way to resolve the issue of SGD based on the clipping of stochastic gradients. However, we need to introduce some important notations and deﬁnitions before we start to discuss this example.

∗eduard.gorbunov@phystech.edu, eduardgorbunov.github.io †danilovamarina15@gmail.com, marinadanya.github.io ‡gasnikov@yandex.ru

34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.

1.1 Preliminaries

In this section we introduce the main part of notations, assumption and deﬁnitions. The rest is
classical for optimization literature and stated in the appendix (see Section A). Throughout the paper we assume that at each point x ∈ Rn function f is accessible only via stochastic gradients ∇f (x, ξ)
such that

Eξ[∇f (x, ξ)] = ∇f (x), Eξ ∇f (x, ξ) − ∇f (x) 22 ≤ σ2,

(2)

i.e. we have an access to the unbiased estimator of ∇f (x) with uniformly bounded by σ2 variance where σ is some non-negative number. These assumptions on the stochastic gradient are standard in the stochastic optimization literature [18, 20, 31, 38, 49]. Below we introduce one of the most important deﬁnitions in this paper.
Deﬁnition 1.1 (light-tailed random vector). We say that random vector η has a light-tailed distribution, i.e. satisﬁes “light-tails” assumption, if there exist E[η] and P { η − E[η] 2 > b} ≤ 2 exp − 2bσ22 for all b > 0

Such distributions are often called sub-Gaussian ones (see [30] and references therein). One can show (see Lemma 2 from [30]) that this deﬁnition is equivalent to

E exp

η−E[η]

/2
2

σ2

≤ exp(1)

(3)

up to absolute constant difference in σ. Due to Jensen’s inequality and convexity of exp(·) one can easily show that inequality (3) implies E[ η − E[η] 22] ≤ σ2. However, the reverse implication does not hold in general. Therefore, in the rest of the paper by stochastic gradient with heavy-tailed
distribution, we mean such a stochastic gradient that satisﬁes (2) but not necessarily (3).

1.2 Simple Motivational Example: Convergence in Expectation and Clipping
In this section we consider SGD xk+1 = xk − γ∇f (xk, ξk) applied to solve the problem (1) with f (x, ξ) = x 22/2 + ξ, x , where ξ is a random vector with zero mean and the variance by σ2 (see the details in Section H.1). The state-of-the-art theory (e.g. [24, 25]) says that convergence properties in expectation of SGD in this case depend only on the stepsize γ, condition number of f , initial suboptimality f (x0) − f (x∗) and the variance σ, but does not depend on distribution of ξ. However, the trajectory of SGD signiﬁcantly depends on the distribution of ξ. To illustrate this we consider 3 different distributions of ξ with the same σ, i.e., Gaussian distribution, Weibull distribution [69] and Burr Type XII distribution [3, 42] with proper shifts and scales to get needed mean and variance for ξ (see the details in Section H.1). For each distribution, we run SGD several times from the same starting point, the same stepsize γ, and the same batchsize, see typical runs in Figure 1. This simple

f(xk) − f(x * ) f(x0) − f(x * ) f(xk) − f(x * ) f(x0) − f(x * ) f(xk) − f(x * ) f(x0) − f(x * )

100 10−1

Gaussian tails, f(x0) − f(x * ) = 2.87
SGD clipped-SGD

10−2

10−3 0

20000 40000 60000 80000 100000 Number of iterations

100 10−1

Weibull tails, f(x0) − f(x * ) = 2.87
SGD clipped-SGD

10−2

10−3 0

20000 40000 60000 80000 100000 Number of iterations

100 10−1

Burr Type XII tails, f(x0) − f(x * ) = 2.87
SGD clipped-SGD

10−2

10−3 0

20000 40000 60000 80000 100000 Number of iterations

Figure 1: Typical trajectories of SGD and clipped-SGD applied to solve (130) with ξ having Gaussian, Weibull, and Burr Type XII tails.

example shows that SGD in all 3 cases rapidly reaches a neighborhood of the solution and then starts to oscillate there. However, these oscillations are signiﬁcantly larger for the second and the third cases where stochastic gradients are heavy-tailed. Unfortunately, guarantees for the convergence in expectation cannot express this phenomenon, since in expectation the convergence guarantees for all 3 cases are identical.
Moreover, in practice, e.g., in training big machine learning models, it is often used only a couple runs of SGD or another stochastic method. The training process can take hours or even days, so, it is extremely important to obtain good accuracy of the solution with high probability. However,

2

as our simple example shows, SGD fails to converge robustly if the noise in stochastic gradients is heavy-tailed which was also noticed for several real-world problems like training AlexNet [37] on CIFAR10 [36] (see [65]) and training an attention model [68] via BERT [8] (see [71]).
Clearly, since the distributions of stochastic gradients in the second and the third cases are heavy tailed the probability of sampling too large ξ (in terms of the norm) and, as a consequence, too large ∇f (x, ξ) is high even if we are close to the solution. Once the current point xk is not too far from the solution and SGD gets a stochastic gradient with too large norm the method jumps far from the solution. Therefore, we see large oscillations. Since the reason of such oscillations is large norm of stochastic gradient it is natural to clip it, i.e., update xk+1 according to xk+1 = xk − γ min{1, λ/ ∇f(xk,ξk) 2}∇f (xk, ξk). The obtained method is known in literature as clipped-SGD (see [17, 21, 43, 44, 57, 70, 71] and references therein). Among the good properties of clipped-SGD we emphasize its robustness to the heavy-tailed noise in stochastic gradients (see also [71]). In our tests, trajectories of clipped-SGD oscillate not signiﬁcantly even for heavy-tailed distributions, and clipping does not spoil the rate of convergence. These two factors make clipped-SGD preferable than SGD when we deal with heavy-tailed distributed stochastic gradients (see further discussion in Section B.2).
1.3 Related Work
1.3.1 Smooth Stochastic Optimization: Light-Tailed Noise
In the light-tailed case high-probability complexity bounds and complexity bounds in expectation for SGD and AC-SA differ only in logarithmical factors of 1/β, see the details in Table 1. Such bounds were obtained in [9] for SGD in the convex case and then were extended to the µ-strongly convex case in [11] for modiﬁcation of SGD called Stochastic Intermediate Gradient Method (SIGM). Finally, optimal complexities were derived in [18, 19, 38] for the method called AC-SA in the convex case and for Multi-Staged AC-SA (MS-AC-SA) in the strongly convex case.
1.3.2 Smooth Stochastic Optimization: Heavy-Tailed Noise
Without light tails assumption the most straightforward results lead to O(1/β2) and O(1/β) dependency on β in the complexity bounds. Such bounds can be obtained from the complexity bounds for the convergence in expectation via Markov’s inequality. However, for small β these bounds become unacceptably poor. Classical results [13, 53, 62] reduce these dependence to O(ln(β−1)) but they have worse dependence on ε than corresponding results relying on light tails assumption.
For a long time the following question was open: is it possible to design stochastic methods having the same or comparable complexity bounds as in the light-tailed case but without light tails assumption on stochastic gradients? In [47] and [7] the authors give a positive answer to this question but only partially. Let us discuss the results from these papers in detail.
In [47] Nazin et al. develop a new algorithm called Robust Stochastic Mirror Descent (RSMD) which is based on a special truncation of stochastic gradients and derive complexity guarantees similar to SGD in the convex case but without light assumption, see Table 1. This technique is very similar to gradient clipping. Moreover, in [47] authors consider also composite problems with non-smooth composite term. However, in [47] the optimization problem is deﬁned on some compact convex set X with diameter Θ = max{ x − y 2 | x, y ∈ X} < ∞ and the analysis depends substantially on the boundedness of X. Using special restarts technique together with iterative squeezing of the set X Nazin et al. extend their method to the µ-strongly convex case, see Table 2. Finally, in the discussion section of [47] authors formulate the following question: is it possible to develop such accelerated stochastic methods that have the same or comparable complexity bounds as in the light-tailed case but do not require stochastic gradients to be light-tailed?
In the strongly convex case the positive answer to this question was given by Davis et al. [7] where authors propose a new method called proxBoost that is based on robust distance estimation [29, 51] and proximal point method [40, 41, 60], see Table 2. However, this approach requires solving an auxiliary optimization problem at each iteration that can lead to poor performance in practice.
In our paper we close the gap in theory, i.e., we provide a positive answer to the following question: Is it possible to develop such an accelerated stochastic method that have the same or comparable
3

complexity bound as for AC-SA in the convex case but do not require stochastic gradients to be light-tailed?

1.4 Our Contributions
• One of the main contributions of our paper is a new method called Clipped Stochastic Similar Triangles Method (clipped-SSTM). For the case when the objective function f is convex and L-smooth we derive the following complexity bound without light tails assumption on the stochastic gradients: O(max{ LR02/ε, σ2R02/ε2} ln(LR02/εβ)). This bound outperforms all known bounds for this setting (see Table 1) and up to the difference in logarithmical factors recovers the complexity bound of AC-SA derived under light tails assumption. That is, in this paper we close the gap in theory theory of smooth convex stochastic optimization with heavy-tailed noise. Moreover, unlike in [47], we do not assume boundedness of the set where the optimization problem is deﬁned, which makes our analysis more complicated. We also study different batchsize policies for clipped-SSTM.
• Using restarts technique we extend clipped-SSTM to the µ-strongly convex objectives and obtain a new method called Restarted clipped-SSTM (R-clipped-SSTM). For this method we prove the following complexity bound (again, without light tails assumption on the stochastic gradients): O(max{ L/µ ln(µR2/ε), σ2/µε} ln(L/µβ ln(µR2/ε))). Our bound outperforms the state-of-the-art result from [7] in terms of the dependence on ln Lµ , see Table 2 for the details.
• We prove the ﬁrst high-probability complexity guarantees for clipped-SGD in convex and strongly convex cases without light tails assumption on the stochastic gradients, see Tables 1 and 2. The complexity we prove for clipped-SGD in the convex case is comparable with corresponding bound for SGD derived under light tails assumption. In the µ-strongly convex case we derive a new complexity bound for the restarted version of clipped-SGD (R-clipped-SGD) which is comparable with its “light-tailed counterpart”.
• We conduct several numerical experiments with the proposed methods in order to justify the theory we develop. In particular, we show that clipped-SSTM can outperform SGD and clipped-SGD in practice even without using large batchsizes. Moreover, in our experiments we illustrate how clipping makes the convergence of SGD and SSTM more robust and reduces their oscillations.

Table 1: Comparison of existing high-probability convergence results for stochastic optimization under assumptions (2) for convex and L-smooth objectives. The second column contains an overall number of stochastic ﬁrst-order oracle calls needed to achieve ε-solution with probability at least 1 − β. In the third column “light” means that ∇f (x, ξ) satisﬁes (3) and “heavy” means that the result holds even in the case when (3) does not hold. Column “Domain” describes the set where the optimization problem is deﬁned. For RSMD Θ is a diameter of the set where the optimization problem is deﬁned. We use red color to emphasize the restrictions we eliminate.

Method SGD [9] AC-SA [18, 38] RSMD [47] clipped-SGD [This work] clipped-SSTM [This work]

Complexity O max LRε02 , σ2εR202 ln2(β−1)

O max

LRε 02 , σ2εR2 02 ln(β−1)

O max O max

, LΘ2 σ2Θ2

ε

ε2

, LR0 2
ε

σ 2 R0 2 ε2

ln(β−1) ln(β−1)

O max

, LR02
ε

σ 2 R02 ε2

ln LR02+σR0
εβ

Tails Domain light bounded

light arbitrary

heavy heavy heavy

bounded Rn Rn

1.4.1 Relation to [71] While Zhang et al. [71] consider different setup, [71] is highly relevant to our paper, and, in some sense, it complements our ﬁndings. In particular, it contains the analysis of several versions of
4

Table 2: Comparison of existing high-probability convergence results for stochastic optimization under assumptions (2) for µ-strongly convex and L-smooth objectives. The second column contains an overall number of stochastic ﬁrst-order oracle calls needed to achieve ε-solution with probability at least 1 − β. In the third column “light” means that ∇f (x, ξ) satisﬁes (3) and “heavy” means that the result holds even in the case when (3) does not hold. Column “Domain” describes the set where the optimization problem is deﬁned. For RSMD Θ is a diameter of the set where the optimization problem is deﬁned and R = 2(f(x0)−f(x∗))/µ, r0 = f (x0) − f (x∗). We use red color to emphasize the restrictions we eliminate.

Method SIGM [11] MS-AC-SA [19] restarted-RSMD
[47]
proxBoost [7]

O max O max

Complexity

L ln µR02 , σ2 ln β−1 ln µR02

µ

ε µε

ε

L ln LR02 , σ2 ln β−1 ln LR02

µ

ε µε

ε

O max Lµ ln µΘε 2 , σµ2ε ln β−1 ln µΘε 2

O max

Lµ ln

LR02 ln

L µ

ε

, σ2ln Lµ
µε

·C ,

where C = ln L ln ln Lµ

µ

β

Tails light light heavy

Domain arbitrary arbitrary bounded

heavy arbitrary

clipped-SGD
[This work]
R-clipped-SGD
[This work]
R-clipped-SSTM
[This work]

O max Lµ , σµ2ε · Lµ ln rε0 ln µLβ ln rε0 O max Lµ ln µRε 2 , σµ2ε ln µLβ ln µRε 2 O max Lµ ln µRε 2 , σµ2ε ln µLβ ln µRε 2

heavy Rn heavy Rn heavy Rn

clipped-SGD establishing the rates of convergence in expectation while we focus on the high-

probability complexity guarantees. Secondly, we consider convex and strongly convex cases while

[71] provides an analysis for non-convex and strongly convex problems. Finally, [71] relies on the

following assumption: there exist such G > 0 and α ∈ (1, 2] that the stochastic gradient g(x) satisﬁes

E

g(x)

α 2

≤ Gα.

This assumption implies the boundedness of the gradient of the objective function

f (x) which is quite restrictive and does not hold on the whole space for strongly convex functions. In

our paper, we assume only boundedness of the variance. Moreover, we consider smooth problems that

allows us to accelerate clipped-SGD and obtain clipped-SSTM, while Zhang et al. [71] provide

non-accelerated rates.

1.5 Paper Organization
The remaining part of the paper is organized as follows. In Section 2 we present clipped-SSTM together with the main complexity result in the convex case that we prove for this method. Then, we present the ﬁrst high-probability complexity bounds for clipped-SGD for for the convex problems. In Section 4 we provide our numerical experiments justifying our theoretical results. Finally, in Section 5 we provide some concluding remarks and discuss the limitations and possible extensions of the results developed in the paper. Due to the space limitations, we put the exact formulations of all theorems, results for the strongly convex problems and the full proofs in the Appendix (see Sections F and G), together with auxiliary and technical results and additional experiments (see Section H). Moreover, in Section F.1.2 we present a sketch of the proof of the main convergence result for clipped-SSTM and explain the intuition behind it.

2 Accelerated SGD with Clipping
In this section we consider the situation when f (x) is convex and L-smooth on Rn. For this problem we present a new method called Clipped Stochastic Similar Triangles Method (clipped-SSTM, see Algorithm 1). In our method we use a clipped stochastic gradient that is deﬁned in the following way:

clip(∇f (x, ξ), λ) = min {1, λ/ ∇f(x,ξ) 2} ∇f (x, ξ)

(4)

5

Algorithm 1 Clipped Stochastic Similar Triangles Method (clipped-SSTM)

Input: starting point x0, number of iterations N , batchsizes {mk}Nk=1, stepsize parameter a, clipping parameter B

1: Set A0 = α0 = 0, y0 = z0 = x0

2: for k = 0, . . . , N − 1 do 3: Set αk+1 = k2a+L2 , Ak+1 = Ak + αk+1, λk+1 = αkB+1

4:

xk+1 = / (Akyk+αk+1zk) Ak+1

5: Draw fresh i.i.d. samples ξ1k, . . . , ξmk k and compute ∇f (xk+1, ξk) = m1k m i=k1 ∇f (xk+1, ξik)

6: Compute ∇f (xk+1, ξk) = clip(∇f (xk+1, ξk), λk+1) using (4)

7: zk+1 = zk − αk+1∇f (xk+1, ξk)

8:

yk+1 = / (Akyk+αk+1zk+1) Ak+1

9: end for

Output: yN

where ∇f (x, ξ) = m1

m i=1

∇f (x,

ξi)

is

a

mini-batched

version

of

∇f (x).

That is, in order to

compute clip(∇f (x, ξ), λ) one needs to get m i.i.d. samples ∇f (x, ξ1), . . . , ∇f (x, ξm), compute its

average and then project the result ∇f (x, ξ) on the Euclidean ball with radius λ and center at the

origin. Next theorem summarizes the main convergence result for clipped-SSTM.

Theorem 2.1. Assume that function f is convex and L-smooth. Then for all β ∈ (0, 1) and N ≥ 1 such that ln(4N/β) ≥ 2 we have that after N iterations of clipped-SSTM with mk = Θ max 1, / σ2α2k+1N ln(N/β) R02 , B = Θ(R0/ln(N/β)) and a = Θ(ln2(N/β)) that f (yN ) − f (x∗) = O(aLR02/N2) holds with probability at least 1 − β where R0 = x0 − x∗ 2. In other words, if we choose a to be equal to the maximum from (27), then the method achieves
f (yN ) − f (x∗) ≤ ε with probability at least 1 − β after O( LR02/ε ln(LR02/εβ)) iterations and
requires O(max{ LR02/ε, σ2R02/ε2} ln(LR02/εβ)) oracle calls.

The theorem says that for any β ∈ (0, 1) clipped-SSTM converges to ε-solution with probability at least 1 − β and requires exactly the same number of stochastic ﬁrst-order oracle calls (up to the difference in constant and logarithmical factors) as optimal stochastic methods like AC-SA [18, 38] or Stochastic Similar Triangles Method [16, 22]. However, our method achieves this rate under less restrictive assumption. Indeed, Theorem 2.1 holds even in the case when the stochastic gradient ∇f (x, ξ) satisﬁes only (2) and can have heavy-tailed distribution. In contrast, all existing results that establish (30) and that are known in the literature hold only in the light-tails case, see Section 1.3.1.
Finally, when σ2 is big then Theorem 2.1 says that at iteration k clipped-SGD requires large batchsizes mk ∼ k2N (see (26)) which is proportional to ε−3/2 for last iterates. It can make the cost of one iteration extremely high, therefore, we also consider different stepsize policies that remove this drawback in Section F.1.1. In particular, the following result shows that clipped-SSTM achieves the same oracle complexity even with constant batchsizes mk when stepsize parameter a is chosen properly.

Corollary 2.2. Let√ the assumptions

Θ max{1, ln2(N/β),

ln

N/β

σ

N

/ 3/2
LR0

}

.

of Theorem F.1 hold and a = Then mk = O(1) and clipped-SSTM

achieves f (yN ) − f (x∗) ≤ ε with probability at O(max{ LR02/ε, σ2R02/ε2} ln((LR02+σR0)/εβ)) iterations/oracle calls.

least

1−β

after

3 SGD with Clipping
In this section we present our complexity results for clipped-SGD (see Algorithm 2) in the convex case. Next theorem summarizes the main convergence result for clipped-SGD in this case.

6

Algorithm 2 Clipped Stochastic Gradient Descent (clipped-SGD)

Input: starting point x0, number of iterations N , batchsizes {mk}Nk=−01, stepsize γ > 0, clipping level λ > 0

1: for k = 0, . . . , N − 1 do

2: Draw fresh i.i.d. samples ξ1k, . . . , ξmk k and compute ∇f (xk, ξk) = m1k m i=k1 ∇f (xk, ξik)

3: Compute ∇f (xk, ξk) = clip(∇f (xk, ξk), λ) using (4)

4: xk+1 = xk − γ∇f (xk, ξk)

5: end for Output: x¯N = N1

Nk=−01 xk

Theorem 3.1. Assume that function f is convex and L-smooth. Then for all β ∈ (0, 1) and N ≥ 1
such that ln(4N/β) ≥ 2 we have that after N iterations of clipped-SGD with λ = Θ(LR0) and mk = m = Θ(max{1, Nσ2/R02L2 ln(N/β)}) where R0 = x0 − x∗ 2 and stepsize γ = 1/80L ln(4N/β) that f (x¯N ) − f (x∗) = O(LR02 ln(4N/β)/N) with probability at least 1 − β where x¯N = N1 kN=−01 xk. In other words, the method achieves f (x¯N ) − f (x∗) ≤ ε with probability at least 1 − β after O LR02/ε ln(LR02/εβ) iterations and requires O(max{LR02/ε, σ2R02/ε2} ln(LR02/εβ)) oracle calls.

To the best of our knowledge, it is the ﬁrst result for clipped-SGD establishing non-trivial complexity guarantees for the convergence with high probability. Up to the difference in logarithmical factors our bound recovers the complexity bound for SGD which was obtained under light tails assumption and the complexity bound for RSMD. However, unlike in [47], we do not assume that the optimization problem is deﬁned on the bounded set. The proof technique is similar to one we use to prove Theorem F.1. One can ﬁnd the full proof in Section G.3.1.

4 Numerical Experiments

We have tested4 clipped-SSTM and clipped-SGD on the logistic regression problem, the datasets were taken from LIBSVM library [4]. To implement methods we use Python 3.7 and standard libraries. One can ﬁnd additional experiments and details in Section H.2.
First of all, using standard solvers from scipy library we ﬁnd good enough approximation of the solution of the problem for each dataset. For simplicity, we denote this approximation by x∗. Then, we numerically study the distribution of ∇fi(x∗) 2 and plot corresponding histograms for each dataset, see Figure 2. These histograms hint that near the solution for heart dataset tails of stochastic

Density Density Density

10−2

heart, real samples

10−3

10−4 0 50 100 150 200 250 300 350 400
Noise norm

10−2

diabetes, real samples

10−4

10−6

10−8

10−10

0 100 200 300 400 500 600 700
Noise norm

10−4 10−12 10−20 10−28 10−36 10−44 10−52 10−60
0

australian, real samples
500 1000 1500 2000 2500 3000 3500 4000
Noise norm

Figure 2: Histograms of ∇fi(x∗) 2 for different datasets. Red lines correspond to probability density functions of normal distributions with empirically estimated means and variances.

gradients are not heavy and the norm of the noise can be well-approximated by Gaussian distribution, whereas for diabetes and australian we see the presense of outliers that makes the distribution heavy-tailed.
Next, let us consider numerical results for SGD and SSTM with and without clipping applied to solve logistic regression problem on these 3 datasets, see Figures 3- 5. For all methods we used constant batchsizes m, stepsizes and clipping levels were tuned, see Section H.2 for the details. In our experiments we also consider clipped-SGD with periodically decreasing clipping level λ
4One can ﬁnd the code here: https://github.com/eduardgorbunov/accelerated_clipping.

7

f(xk) − f(x * ) f(x0) − f(x * ) f(xk) − f(x * ) f(x0) − f(x * ) f(xk) − f(x * ) f(x0) − f(x * )

100 10−1

heart

SGD clipped-SGD d-clipped-SGD

10−2

10−3

10−4
0 2500 5000 7500 10000 12500 15000 17500 20000
Number of passes through the data

100 10−1

heart

SGD SSTM

10−2

10−3

10−4

10−5
0 2500 5000 7500 10000 12500 15000 17500 20000
Number of passes through the data

100 10−1 10−2

heart

SGD clipped-SGD d-clipped-SGD clipped-SSTM

10−3

10−4
0 2500 5000 7500 10000 12500 15000 17500 20000
Number of passes through the data

Figure 3: Trajectories of SGD, clipped-SGD, SSTM and clipped-SSTM applied to solve logistic regression problem on heart dataset.

(d-clipped-SGD in Figures), i.e. the method starts with some initial clipping level λ0 and after every l epochs or, equivalently, after every rl/m iterations the clipping level is multiplied by some constant α ∈ (0, 1).

f(xk) − f(x * ) f(x0) − f(x * )

100 10−1

diabetes

SGD clipped-SGD d-clipped-SGD

10−2

10−3

10−4

0

2000

4000

6000

8000

10000

Number of passes through the data

f(xk) − f(x * ) f(x0) − f(x * )

100 10−1

diabetes

SGD SSTM

10−2

10−3

10−4

10−5

0

2000

4000

6000

8000

10000

Number of passes through the data

f(xk) − f(x * ) f(x0) − f(x * )

100 10−1 10−2

diabetes

SGD clipped-SGD d-clipped-SGD clipped-SSTM

10−3

10−4

10−5

0

2000

4000

6000

8000

10000

Number of passes through the data

Figure 4: Trajectories of SGD, clipped-SGD, SSTM and clipped-SSTM applied to solve logistic regression problem on diabetes dataset.

f(xk) − f(x * ) f(x0) − f(x * )

100 10−1 10−2

australian

SGD clipped-SGD d-clipped-SGD

0

5000 10000 15000 20000 25000 30000

Number of passes through the data

f(xk) − f(x * ) f(x0) − f(x * )

100 10−1

australian

SGD SSTM

10−2

10−3

10−4

0

5000 10000 15000 20000 25000 30000

Number of passes through the data

f(xk) − f(x * ) f(x0) − f(x * )

100 10−1 10−2

australian

SGD clipped-SGD d-clipped-SGD clipped-SSTM

10−3

10−4

0

5000 10000 15000 20000 25000 30000

Number of passes through the data

Figure 5: Trajectories of SGD, clipped-SGD, SSTM and clipped-SSTM applied to solve logistic regression problem on australian dataset.

Let us discuss the obtained numerical results. First of all, d-clipped-SGD stabilizes the oscillations of SGD even if the initial clipping level was high. In contrast, clipped-SGD with too large clipping level λ behaves similarly to SGD. Secondly, we emphasize that due to the fact that we used small bathcsizes SSTM has very large oscillations in comparison to SGD. Actually, fast error/noise accumulation is a typical drawback of accelerated SGD with small batchsizes [35]. Moreover, deterministic accelerated and momentum-based methods often have non-monotone behavior (see [5] and references therein). However, to some extent clipped-SSTM suffers from the ﬁrst drawback less than SSTM and has comparable convergence rate with SSTM. Finally, in our experiments on heart and australian datasets clipped-SSTM converges faster than SGD and clipped-SGD and oscillates little, while on diabetes dataset it also converges faster than SGD, but oscillates more if parameter B is not ﬁne-tuned.
We also want to mention that the behavior of SGD on heart and diabetes datasets correlates with the insights from Section 1.2 and our numerical study of the distribution of ∇fi(x∗) 2. Indeed, for heart dataset SGD has little oscillations since the distribution of ∇fi(xk) − ∇f (xk) 2, where xk is the last iterate, is well concentrated near its mean and can be approximated by Gaussian distribution (see the details in Section H.2). In contrast, Figure 4 shows that SGD oscillates more than in the previous example. One can explain such behavior using Figure 2 showing that the distribution of
∇f (x∗) 2 has heavier tails than for heart dataset.

8

However, we do not see any oscillations of SGD for australian dataset despite the fact that according to Figure 2 the distribution of ∇fi(x∗) 2 in this case has heavier tails than in previous examples. Actually, there is no contradiction and in this case it simply means that SGD does not get close to the solution in terms of functional value, despite the fact that we used γ = 1/L. In Section H.2 we present the results of different tests where we tried to use bigger stepsize γ in order to reach oscillation region faster and show that in fact in that region SGD oscillates signiﬁcantly more, but clipping ﬁxes this issue without spoiling the convergence rate.
5 Discussion
In this paper we close the gap in the theory of high-probability complexity bounds for stochastic optimization with heavy-tailed noise. In particular, we propose a new accelerated stochastic method — clipped-SSTM — and prove the ﬁrst accelerated high-probability complexity bounds for smooth convex stochastic optimization without light-tails assumption. Moreover, we extend our results to the strongly convex case and prove new complexity bounds outperforming the state-of-the-art results. Finally, we derive ﬁrst high-probability complexity bounds for the popular method called clipped-SGD in convex and strongly convex cases and conduct a numerical study of the considered methods.
However, our approach has several limitations. In particular, it signiﬁcantly relies on the assumption that the optimization problem is deﬁned on Rn. Moreover, we do not consider regularized or composite problems like in [47] and [7]. However, in [47] it is signiﬁcant in the analysis that the set where the problem is deﬁned is bounded and in [7] the analysis works only for the strongly convex problems. It would also be interesting to generalize our approach to generally non-smooth problems using the trick from [52].
Broader Impact
Our contribution is primarily theoretical. Therefore, a broader impact discussion is not applicable.
Acknowledgments and Disclosure of Funding
The research of E. Gorbunov and A. Gasnikov was partially supported by the Ministry of Science and Higher Education of the Russian Federation (Goszadaniye) 075-00337-20-03. The research of Marina Danilova was funded by RFBR, project number 20-31-90073.
References
[1] George Bennett. Probability inequalities for the sum of independent random variables. Journal of the American Statistical Association, 57(297):33–45, 1962.
[2] Aleksandr Alekseevich Borovkov and Konstantin Aleksandrovich Borovkov. On probabilities of large deviations for random walks. i. regularly varying distribution tails. Theory of Probability & Its Applications, 46(2):193–213, 2002.
[3] Irving W Burr. Cumulative frequency functions. The Annals of mathematical statistics, 13(2):215–232, 1942.
[4] Chih-Chung Chang and Chih-Jen Lin. Libsvm: A library for support vector machines. ACM transactions on intelligent systems and technology (TIST), 2(3):1–27, 2011.
[5] Marina Danilova, Anastasiia Kulakova, and Boris Polyak. Non-monotone behavior of the heavy ball method. In Martin Bohner, Stefan Siegmund, Roman Šimon Hilscher, and Petr Stehlík, editors, Difference Equations and Discrete Dynamical Systems with Applications, pages 213–230, Cham, 2020. Springer International Publishing.
[6] Damek Davis and Dmitriy Drusvyatskiy. Stochastic model-based minimization of weakly convex functions. SIAM Journal on Optimization, 29(1):207–239, 2019.
[7] Damek Davis, Dmitriy Drusvyatskiy, Lin Xiao, and Junyu Zhang. From low probability to high conﬁdence in stochastic convex optimization. arXiv preprint arXiv:1907.13307, 2019.
9

[8] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.
[9] Olivier Devolder et al. Stochastic ﬁrst order methods in smooth convex optimization. Technical report, CORE, 2011.
[10] Pavel Dvurechenskii, Darina Dvinskikh, Alexander Gasnikov, Cesar Uribe, and Angelia Nedich. Decentralize and randomize: Faster algorithm for wasserstein barycenters. In Advances in Neural Information Processing Systems, pages 10760–10770, 2018.
[11] Pavel Dvurechensky and Alexander Gasnikov. Stochastic intermediate gradient method for convex problems with stochastic inexact oracle. Journal of Optimization Theory and Applications, 171(1):121–145, 2016.
[12] Kacha Dzhaparidze and JH Van Zanten. On bernstein-type inequalities for martingales. Stochastic processes and their applications, 93(1):109–117, 2001.
[13] O Bousquet A Elisseeff and Olivier Bousquet. Stability and generalization. Journal of Machine Learning Research, 2:499–526, 2002.
[14] David A Freedman et al. On tail probabilities for martingales. the Annals of Probability, 3(1):100–118, 1975.
[15] Alexander Gasnikov, Pavel Dvurechensky, and Yurii Nesterov. Stochastic gradient methods with inexact oracle. arXiv preprint arXiv:1411.4218, 2014.
[16] Alexander Gasnikov and Yurii Nesterov. Universal fast gradient method for stochastic composit optimization problems. arXiv:1604.05275, 2016.
[17] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N Dauphin. Convolutional sequence to sequence learning. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 1243–1252. JMLR. org, 2017.
[18] Saeed Ghadimi and Guanghui Lan. Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization i: A generic algorithmic framework. SIAM Journal on Optimization, 22(4):1469–1492, 2012.
[19] Saeed Ghadimi and Guanghui Lan. Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization, ii: shrinking procedures and optimal algorithms. SIAM Journal on Optimization, 23(4):2061–2089, 2013.
[20] Saeed Ghadimi and Guanghui Lan. Stochastic ﬁrst-and zeroth-order methods for nonconvex stochastic programming. SIAM Journal on Optimization, 23(4):2341–2368, 2013.
[21] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. MIT Press, 2016. http://www.deeplearningbook.org.
[22] Eduard Gorbunov, Darina Dvinskikh, and Alexander Gasnikov. Optimal decentralized distributed algorithms for stochastic convex optimization. arXiv preprint arXiv:1911.07363, 2019.
[23] Eduard Gorbunov, Pavel Dvurechensky, and Alexander Gasnikov. An accelerated method for derivative-free smooth stochastic convex optimization. arXiv preprint arXiv:1802.09022, 2018.
[24] Eduard Gorbunov, Filip Hanzely, and Peter Richtárik. A uniﬁed theory of sgd: Variance reduction, sampling, quantization and coordinate descent. arXiv preprint arXiv:1905.11261, 2019.
[25] Robert Mansel Gower, Nicolas Loizou, Xun Qian, Alibek Sailanbayev, Egor Shulgin, and Peter Richtárik. Sgd: General analysis and improved rates. In International Conference on Machine Learning, pages 5200–5209, 2019.
[26] Moritz Hardt, Benjamin Recht, and Yoram Singer. Train faster, generalize better: Stability of stochastic gradient descent. arXiv preprint arXiv:1509.01240, 2015.
[27] Elad Hazan and Satyen Kale. Beyond the regret minimization barrier: optimal algorithms for stochastic strongly-convex optimization. The Journal of Machine Learning Research, 15(1):2489–2512, 2014.
[28] Elad Hazan, Kﬁr Levy, and Shai Shalev-Shwartz. Beyond convexity: Stochastic quasi-convex optimization. In Advances in Neural Information Processing Systems, pages 1594–1602, 2015.
10

[29] Daniel Hsu and Sivan Sabato. Loss minimization and parameter estimation with heavy tails. The Journal of Machine Learning Research, 17(1):543–582, 2016.
[30] Chi Jin, Praneeth Netrapalli, Rong Ge, Sham M Kakade, and Michael I Jordan. A short note on concentration inequalities for random vectors with subgaussian norm. arXiv preprint arXiv:1902.03736, 2019.
[31] Anatoli Juditsky, Arkadi Nemirovski, et al. First order methods for nonsmooth convex largescale optimization, i: general purpose methods. Optimization for Machine Learning, pages 121–148, 2011.
[32] Anatoli Juditsky and Yuri Nesterov. Deterministic and stochastic primal-dual subgradient algorithms for uniformly convex minimization. Stochastic Systems, 4(1):44–80, 2014.
[33] Sham M Kakade and Ambuj Tewari. On the generalization ability of online strongly convex programming algorithms. In Advances in Neural Information Processing Systems, pages 801–808, 2009.
[34] Ahmed Khaled and Peter Richtárik. Better theory for sgd in the nonconvex world. arXiv preprint arXiv:2002.03329, 2020.
[35] Rahul Kidambi, Praneeth Netrapalli, Prateek Jain, and Sham Kakade. On the insufﬁciency of existing momentum schemes for stochastic optimization. In 2018 Information Theory and Applications Workshop (ITA), pages 1–9. IEEE, 2018.
[36] Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. Cifar-10 and cifar-100 datasets. URl: https://www. cs. toronto. edu/kriz/cifar. html, 6, 2009.
[37] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classiﬁcation with deep convolutional neural networks. In Advances in neural information processing systems, pages 1097–1105, 2012.
[38] Guanghui Lan. An optimal method for stochastic composite optimization. Mathematical Programming, 133(1-2):365–397, 2012.
[39] Kﬁr Y Levy. The power of normalization: Faster evasion of saddle points. arXiv preprint arXiv:1611.04831, 2016.
[40] Bernard Martinet. Régularisation d’inéquations variationnelles par approximations successives. rev. française informat. Recherche Opérationnelle, 4:154–158, 1970.
[41] Bernard Martinet. Détermination approchée d’un point ﬁxe d’une application pseudocontractante. CR Acad. Sci. Paris, 274(2):163–165, 1972.
[42] Michael P McLaughlin. A compendium of common probability distributions. Michael P. McLaughlin, 2001.
[43] Aditya Krishna Menon, Ankit Singh Rawat, Sashank J Reddi, and Sanjiv Kumar. Can gradient clipping mitigate label noise? In International Conference on Learning Representations, 2020.
[44] Stephen Merity, Nitish Shirish Keskar, and Richard Socher. Regularizing and optimizing lstm language models. arXiv preprint arXiv:1708.02182, 2017.
[45] Tomáš Mikolov. Statistical language models based on neural networks. Presentation at Google, Mountain View, 2nd April, 80, 2012.
[46] Eric Moulines and Francis R Bach. Non-asymptotic analysis of stochastic approximation algorithms for machine learning. In Advances in Neural Information Processing Systems, pages 451–459, 2011.
[47] Aleksandr Viktorovich Nazin, AS Nemirovsky, Aleksandr Borisovich Tsybakov, and AB Juditsky. Algorithms of robust stochastic optimization based on mirror descent method. Automation and Remote Control, 80(9):1607–1627, 2019.
[48] Deanna Needell, Nathan Srebro, and Rachel Ward. Stochastic gradient descent, weighted sampling, and the randomized kaczmarz algorithm. Mathematical Programming, 155(1-2):549– 573, 2016.
[49] Arkadi Nemirovski, Anatoli Juditsky, Guanghui Lan, and Alexander Shapiro. Robust stochastic approximation approach to stochastic programming. SIAM Journal on optimization, 19(4):1574– 1609, 2009.
11

[50] Arkadi S Nemirovski and David Berkovich Yudin. Cesari convergence of the gradient method of approximating saddle points of convex-concave functions. In Doklady Akademii Nauk, volume 239, pages 1056–1059. Russian Academy of Sciences, 1978.
[51] Arkadi Semenovich Nemirovsky and David Borisovich Yudin. Problem complexity and method efﬁciency in optimization. 1983.
[52] Yu Nesterov. Universal gradient methods for convex optimization problems. Mathematical Programming, 152(1-2):381–404, 2015.
[53] Yu Nesterov and J-Ph Vial. Conﬁdence level solutions for stochastic programming. Automatica, 44(6):1559–1568, 2008.
[54] Yurii Nesterov. Lectures on convex optimization, volume 137. Springer, 2018.
[55] Lam Nguyen, Phuong Ha Nguyen, Marten Dijk, Peter Richtarik, Katya Scheinberg, and Martin Takac. Sgd and hogwild! convergence without the bounded gradients assumption. In International Conference on Machine Learning, pages 3750–3758, 2018.
[56] Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio. On the difﬁculty of training recurrent neural networks. In International conference on machine learning, pages 1310–1318, 2013.
[57] Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. Deep contextualized word representations. arXiv preprint arXiv:1802.05365, 2018.
[58] Alexander Rakhlin, Ohad Shamir, and Karthik Sridharan. Making gradient descent optimal for strongly convex stochastic optimization. arXiv preprint arXiv:1109.5647, 2011.
[59] Herbert Robbins and Sutton Monro. A stochastic approximation method. The annals of mathematical statistics, pages 400–407, 1951.
[60] R Tyrrell Rockafellar. Monotone operators and the proximal point algorithm. SIAM journal on control and optimization, 14(5):877–898, 1976.
[61] Shai Shalev-Shwartz and Shai Ben-David. Understanding machine learning: From theory to algorithms. Cambridge university press, 2014.
[62] Shai Shalev-Shwartz, Ohad Shamir, Nathan Srebro, and Karthik Sridharan. Stochastic convex optimization. In COLT, 2009.
[63] Shai Shalev-Shwartz, Yoram Singer, Nathan Srebro, and Andrew Cotter. Pegasos: Primal estimated sub-gradient solver for svm. Mathematical programming, 127(1):3–30, 2011.
[64] Alexander Shapiro, Darinka Dentcheva, and Andrzej Ruszczyn´ski. Lectures on stochastic programming: modeling and theory. SIAM, 2014.
[65] Umut Simsekli, Levent Sagun, and Mert Gurbuzbalaban. A tail-index analysis of stochastic gradient noise in deep neural networks. arXiv preprint arXiv:1901.06053, 2019.
[66] Vladimir Spokoiny et al. Parametric estimation. ﬁnite sample theory. The Annals of Statistics, 40(6):2877–2909, 2012.
[67] Ilnura Usmanova. Robust solutions to stochastic optimization problems. Master Thesis (MSIAM); Institut Polytechnique de Grenoble ENSIMAG, Laboratoire Jean Kuntzmann, 2017.
[68] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information processing systems, pages 5998–6008, 2017.
[69] Waloddi Weibull. A statistical distribution function of wide applicability. Journal of Applied Mechanics, 18:293–297, 1951.
[70] Jingzhao Zhang, Tianxing He, Suvrit Sra, and Ali Jadbabaie. Why gradient clipping accelerates training: A theoretical justiﬁcation for adaptivity. In International Conference on Learning Representations, 2020.
[71] Jingzhao Zhang, Sai Praneeth Karimireddy, Andreas Veit, Seungyeon Kim, Sashank J Reddi, Sanjiv Kumar, and Suvrit Sra. Why adam beats sgd for attention models. arXiv preprint arXiv:1912.03194, 2019.
12

Appendix
Stochastic Optimization with Heavy-Tailed Noise via
Accelerated Gradient Clipping

Contents

1 Introduction

1

1.1 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2

1.2 Simple Motivational Example: Convergence in Expectation and Clipping . . . . . . . . . . . 2

1.3 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3

1.3.1 Smooth Stochastic Optimization: Light-Tailed Noise . . . . . . . . . . . . . . . . . . 3

1.3.2 Smooth Stochastic Optimization: Heavy-Tailed Noise . . . . . . . . . . . . . . . . . 3

1.4 Our Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4

1.4.1 Relation to [71] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4

1.5 Paper Organization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5

2 Accelerated SGD with Clipping

5

3 SGD with Clipping

6

4 Numerical Experiments

7

5 Discussion

9

A Notations and Deﬁnitions

14

B Related Work: Additional Details

16

B.1 Related Work on Non-Smooth Stochastic Optimization . . . . . . . . . . . . . . . . . . . . . 16

B.2 Related Work on Gradient Clipping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

C Basic Facts

17

D Auxiliary Results

17

D.1 Bernstein Inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

D.2 About the Sum of i.i.d. Random Variables with Heavy Tails . . . . . . . . . . . . . . . . . . 17

E Technical Results

18

F Accelerated SGD with Clipping: Exact Formulations and Missing Proofs

19

F.1 Convex Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

F.1.1 Convergence Guarantees for clipped-SSTM . . . . . . . . . . . . . . . . . . . . . . 19

F.1.2 Sketch of the Proof of Theorem F.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . 21

F.2 Strongly Convex Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22

F.3 Proofs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24

F.3.1 Proof of Lemma F.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24

F.3.2 Proof of Lemma F.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26

13

F.3.3 Proof of Theorem F.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 F.3.4 Proof of Corollary F.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 F.3.5 Proof of Corollary F.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 F.3.6 Proof of Theorem F.6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 F.3.7 Proof of Corollary F.7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38

G SGD with Clipping: Exact Formulations and Missing Proofs

39

G.1 Convex Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39

G.2 Strongly Convex Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39

G.3 Proofs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41

G.3.1 Proof of Theorem G.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41

G.3.2 Proof of Theorem G.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46

G.3.3 Proof of Theorem G.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47

H Extra Experiments

53

H.1 Detailed Description of Experiments from Section 1.2 . . . . . . . . . . . . . . . . . . . . . 53

H.2 Additional Details and Experiments with Logistic Regression . . . . . . . . . . . . . . . . . 54

A Notations and Deﬁnitions

We use x, y to deﬁne standard inner product between two vectors x, y ∈ Rn, i.e. x, y d=ef

n i=1

xiyi,

where

xi

is

i-th

coordinate

of

vector

x,

i

=

1,

.

.

.

,

n.

Standard

Euclidean

norm

of

vector

x ∈ Rn is deﬁned as x 2 d=ef x, x .

We use P{·} to deﬁne probability measure which is always known from the context, E[·] denotes

mathematical expectation, Eξ[·] is used to deﬁne conditional mathematical expectation with respect to

the randomness coming from ξ only and E [ξ | η] denotes mathematical expectation of ξ conditional

on η. In our proofs, we also use Ek[·] to denote conditional mathematical expectation with respect to
all randomness coming from k-th iteration. For P-measurable set X we use 1X to denote indicator

of event X, i.e.

1X = 1, if event X holds,

(5)

0, otherwise.

Next, we introduce some standard deﬁnitions.

Deﬁnition A.1 (L-smoothness). Function f is called L-smooth on Rn with L > 0 when it is differentiable and its gradient is L-Lipschitz continuous on Rn, i.e.

∇f (x) − ∇f (y) 2 ≤ L x − y 2, ∀x, y ∈ Rn.

(6)

It is well-known that L-smoothness implies (see [54])

f (y) ≤ f (x) + ∇f (x), y − x + L2 y − x 22 ∀x, y ∈ Rn, (7)

and if f is additionally convex, then

∇f (x) − ∇f (y)

2 2

≤

2L (f (x) − f (y) − ∇f (y), x − y )

∀x, y ∈ Rn.

(8)

Since in this paper we focus only on smooth optimization problems we introduce strong convexity in the following way.

14

Deﬁnition A.2 (µ-strong convexity). Differentiable function f is called µ-strongly convex on Rn with µ ≥ 0 if for all x, y ∈ Rn
f (x) ≥ f (y) + ∇f (y), x − y + µ2 x − y 22. (9) In particular, µ-strong convexity implies that for all x ∈ Rn
f (x) − f (x∗) ≥ µ2 x − x∗ 22. (10) Throughout the paper, we use x∗ to denote any solution of problem (1) assuming its existence. By the complexity of stochastic ﬁrst-order method we always mean the total number of stochastic ﬁrst-order oracle calls that the method needs in order to produce such a point xˆ that f (xˆ) − f (x∗) ≤ ε with probability at least 1 − β for some ε > 0 and β ∈ (0, 1). Finally, in the complexity bounds we often use R0 to denote x0 − x∗ 2 where x0 is the starting point of the method.
15

B Related Work: Additional Details

B.1 Related Work on Non-Smooth Stochastic Optimization

Here we present an overview of existing results in the convex non-smooth case, i.e. when f is
still convex but not necessarily L-smooth and the stochastic gradients have a bounded second moment: Eξ[ ∇f (x, ξ) 22] ≤ M 2 for all x ∈ Rn. Under additional assumption that the stochastic gradients have light-tailed distribution it was shown that SGD [49] has O M2R02 ln(β−1)/ε2 complexity
and if additionally f is µ-strongly convex it was shown in [31, 32] that the restarted version of SGD has O M2 ln(β−1 ln(M )/ 2µ−1ε−1) µε complexity (see also [27, 33, 58]). Moreover, removing
logarithmical factors from these bounds we get the complexity bounds of these methods for the convergence in expectation, i.e. needed number of oracle calls to ﬁnd such xˆ that E[f (xˆ)]−f (x∗) ≤ ε.
That is, under light tails assumption high-probability complexity bounds and complexity bounds in
expectation for SGD and restarted-SGD differ only in logarithmical factors of 1/β.

Unfortunately, for these methods the situation changes dramatically when the stochastic gradients
are heavy-tailed. To the best of our knowledge, the best know bounds in the literature with the same dependency on ε are O / M2R02 β2ε2 and O M2/µβε . One can obtain these bounds using complexity
results for the convergence in expectation and Markov’s inequality. However, it leads to signiﬁcantly worse dependence on β: instead of O(ln(β−1)) we get O(β−2) and O(β−1) dependence on the
conﬁdence level β. Furthermore, based on the well-known results on the distribution of sum of
i.i.d. random variables (see Section D.2) in [15] authors consider the case when the tails of the distribution of stochastic gradient satisfy P{ ∇f (x, ξ) − ∇f (x) 2 > s} = O(s−α) for α > 2 and give the following complexity bounds without formal proofs that SGD for convex problems and
restarted-SGD for µ-strongly convex problems have following complexities:

O M 2R2 max ln β−1 , 1 3α2−2 ,

ε2

βεα

  M 2 ln β−1 ln Mµε2

M2

α 3α−2

M2

2  3α−2 

O max

,

β−1 ln

.

 µε µε

µε 

The ﬁrst terms in maximums above correspond to the Central Limit Theorem regime, while the second terms correspond to the heavy-tailed regime, see Section D.2. These bounds show that heavy tailed distributions of the stochastic gradients signiﬁcantly spoil complexity bounds of SGD and restarted-SGD when the conﬁdence level β is small enough.

B.2 Related Work on Gradient Clipping
As we mentioned Section 1.2 clipped-SGD [21, 45, 56, 67] is known to be robust to the noise in stochastic gradients and performs better than SGD in the vicinity of extremely steep cliffs. Zhang et al. [71] analyse the convergence of clipped-SGD in expectation for strongly convex and non-convex objectives under assumption that E[ ∇f (x, ξ) α2 ] is bounded for some α ∈ (1, 2]. For α < 2 this assumption covers some heavy-tailed distributions of stochastic gradients appearing in practice. Moreover, in [71] authors conduct several numerical tests showing that in some real-world problems where the noise in stochastic gradients is heavy-tailed clipped-SGD converges faster than SGD. In [70] Zhang et al. found that clipped-GD is able to converge in non-convex case to the stationary point under the relaxed smoothness assumption with O(ε−2) rate while Gradient Descent (GD) can fail to converge with the same rate in this setting. A very similar approach based on the normalization of GD is studied in [28, 39].

16

C Basic Facts

In this section we enumerate for convenience basic facts that we use many times in our proofs.

Fenchel-Young inequality. For all a, b ∈ Rn and λ > 0

| a, b | ≤ a 22 + λ b 22 . (11)

2λ

2

Squared norm of the sum. For all a, b ∈ Rn

a+b

2 2

≤2

a

2 2

+

2

b

22.

(12)

Inner product representation. For all a, b ∈ Rn a, b = 21 a + b 22 − a 22 − b 22 (13)

Variance decomposition. If ξ is a random vector in Rn with bounded second moment, then

E

ξ+a

2 2

=E

ξ − E[ξ]

2 2

+

E[ξ] + a

2 2

(14)

for any deterministic vector a ∈ Rn. In particular, this implies

E

ξ − E[ξ]

2 2

≤E

ξ+a

2 2

(15)

for any deterministic vector a ∈ Rn.

D Auxiliary Results

D.1 Bernstein Inequality
Lemma D.1 (Bernstein inequality for martingale differences [1, 12, 14]). Let the sequence of random variables {Xi}i≥1 form a martingale difference sequence, i.e. E [Xi | Xi−1, . . . , X1] = 0 for all i ≥ 1. Assume that conditional variances σi2 d=ef E Xi2 | Xi−1, . . . , X1 exist and are bounded and assume also that there exists deterministic constant c > 0 such that Xi 2 ≤ c almost surely for all i ≥ 1. Then for all b > 0, F > 0 and n ≥ 1

n

n

b2

Xi > b and σi2 ≤ F ≤ 2 exp −

.

(16)

P

2F + 2cb/3

i=1

i=1

D.2 About the Sum of i.i.d. Random Variables with Heavy Tails

In this section we present some classical results about the distribution of sum of i.i.d. random variables

N k=1

ξk

with

heavy

tails

[2].

As

one

can

see

from

our

proofs

of

main

results

for

clipped-SSTM

and clipped-SGD such sums play a central role in the analysis of convergence with high probability.

Assume that {ξk} is i.i.d. with E[ξk] = 0 and Var[ξk] d=ef E[(ξk − E[ξk])2] = σ2. Assume also that V (s) = P {ξk ≥ s} = Θ (s−α), where α > 2. In this case

where N

N

P

ξk ≥ s

k=1

1 − Φ √ s + N · V (s), σ2N

1 and Φ(x) = 21π −x∞ exp −y2/2 dy. Since

2x2

x2

0.2 exp −

≤ 1 − Φ(x) ≤ exp − ,

π

2

we have5

N

s

P

ξk ≥ s 1 − Φ √

, s ≤ (α − 2)σ2N ln N (CLT regime) (17)

k=1 σ2N

5CLT = Central Limit Theorem.

17

and

N

P

ξk ≥ s

k=1

N · V (s), s > (α − 2)σ2N ln N (heavy-tailed regime). (18)

This simple observation can play a signiﬁcant role in deriving complexity results for non-smooth convex optimization under the assumption that stochastic gradients are heavy-tailed, see [15] for the details.

E Technical Results
Lemma E.1. Consider two sequences of non-negative numbers {αk}k≥0 and {Ak}k≥0 such that

k+2 α0 = A0 = 0, Ak+1 = Ak + αk+1, αk+1 = 2aL ∀k ≥ 0, (19) where a, L > 0. Then for all k ≥ 0

(k + 1)(k + 4) Ak+1 = 4aL , (20)

Ak+1 ≥ aLαk2+1.

(21)

Proof. By deﬁnition of Ak+1 we have that

k+1

1 k+1

(k + 1)(k + 4)

Ak+1 =

αl = 2aL (l + 1) =

. 4aL

l=1

l=1

Using (k + 1)(k + 4) ≥ (k + 2)2 together with the inequality above we derive (21).

18

F Accelerated SGD with Clipping: Exact Formulations and Missing Proofs

In this section we provide exact formulations of all the results that we have for clipped-SSTM and R-clipped-SSTM together with the full proofs.

F.1 Convex Case

Recall that in order to compute clip(∇f (x, ξ), λ) one needs to get m i.i.d. samples ∇f (x, ξ1), . . . , ∇f (x, ξm), compute its average
1m ∇f (x, ξ) = m ∇f (x, ξi), (22)
i=1

and then project the result ∇f (x, ξ) on the Euclidean ball with radius λ and center at the origin. We also notice that

Eξ[∇f (x, ξ)] = ∇f (x),

(23)

2

σ2

Eξ ∇f (x, ξ) − ∇f (x) 2

≤. m

(24)

F.1.1 Convergence Guarantees for clipped-SSTM

Next theorem summarizes the main convergence result for clipped-SSTM.

Theorem F.1. Assume that function f is convex and L-smooth. Then for all β ∈ (0, 1) and N ≥ 1

such that

4N

ln ≥ 2

(25)

β

we have that after N iterations of clipped-SSTM with

6000σ2αk2+1N

ln

4N β

10368σ2αk2+1N

mk = max 1,

C 2 R2

,

C 2 R2

,

(26)

0

0

B = CR0 , a ≥ max 1, 16 ln 4βN , 36 2 ln 4N + 4 ln2 4N + 2 ln 4N 2 , (27)

8 ln 4βN

C

β β β

that with probability at least 1 − β

f (yN ) − f (x∗) ≤ 2aLC2R02 , (28) N (N + 3)

where R0 = x0 − x∗ 2 and

√

C = 5.

(29)

In other words, if we choose a to be equal to the maximum from (27), then the method achieves f (yN ) − f (x∗) ≤ ε with probability at least 1 − β after O LRε 02 ln LεRβ02 iterations and requires

LR02 σ2R02

LR02

O max

ε , ε2

ln εβ

oracle calls.

(30)

One can easily notice that multiplicative constant factors in formulas for mk and a are too big and seem to be impractical, but in practice one can tune these constants to get good enough performance. That is, big constants in (26) and (27) are needed only in our analysis in order to get bound (30).
Finally, when σ2 is big then Theorem F.1 says that at iteration k clipped-SGD requires large batchsizes mk ∼ k2N (see (26)) which is proportional to ε−3/2 for last iterates. It can make the cost of one iteration extremely high, therefore, we consider different stepsize policies that remove this drawback.

19

Corollary F.2. Let the assumptions of Theorem F.1 hold.

1. (Medium batchsize). If N and β are such that N ln 4βN is bigger than the maximum from (27), then for a = N ln 4βN we have

6000σ2(k + 2)2 10368σ2(k + 2)2

mk = max 1, 4L2N C2R2 ln 4N , 4L2C2R2N ln2 4N

(31)

0β

0

β

and the method achieves f (yN ) − f (x∗) ≤ ε with probability at least 1 − β after O LRε 02 ln LεRβ02 iterations and requires

LR02 σ2R02

LR02

O max

ε , ε2

ln εβ

oracle calls.

(32)

2. (Constant batchsize). If N and β are such that a0N 3/2 ln 4βN is bigger than the maximum from (27) for some positive constant a0, then for a = a0N 3/2 ln 4βN we have

6000σ2(k + 2)2 10368σ2(k + 2)2

mk = max 1, 4a2L2N 2C2R2 , 4a2L2C2R2N 2 ln 4N

(33)

0

0

0

0

β

and the method achieves f (yN ) − f (x∗) ≤ ε with probability at least 1 − β after O a20Lε22R04 ln a0εLβR02 iterations and requires

a20L2R04 σ2R02

a0LR02

O max

ε2 , ε2

ln εβ

oracle calls.

(34)

Finally, if a0 = LσR0 , then mk = O(1) for k = 0, 1, . . . , N and clipped-SSTM ﬁnds ε-solution with probability at least 1 − β after O σ2εR2 02 ln σεRβ0 iterations and requires
O(1) oracle calls per iteration.

In the ﬁrst case batchsizes increase from O(1) for k = 1 to O(ε−1) for k = N and the overall complexity recovers the complexity of Robust Stochastic Mirror Descent (RSMD) from [47]. However, analysis from [47] works only for the optimization problems on compact convex sets, whereas our analysis handles an unconstrained optimization on Rn. Despite the similarities of our approach and [47], it seems that the technique from [47] cannot be generalized to obtain the complexity like in (30) due to the fast bias accumulation that appears because of the special truncation of stochastic gradients that is used in RSMD.
In the second case the corollary establishes ε−2 ln(ε−1β−1) rate for clipped-SSTM with constant batchsizes, i.e. mk = O(1) for all k. The ability of clipped-SSTM to converge with constant batchsizes makes it more practical and applicable for wider class of problems where it can be very expensive to compute large batchsizes, e.g. training deep neural networks. Moreover, when σ is not too small, i.e. σ2 ≥ Lε, this rate is optimal (up to logarithmical factors) and also recovers the rate of RSMD.
Finally, setting

a = max 1, 16 ln 4βN , 36 2 ln 4N + 4 ln2 4N + 2 ln 4N 2 ,

C

β β β

σN 3/2

4N

a = max a ,

ln

(35)

LR0

β

and mk as in (26), we get mk = O(1) for k = 0, 1, . . . , N and derive the following result.

20

Corollary F.3. Let the assumptions of Theorem F.1 hold, a is chosen as in (35) and mk is computed via (26). Then clipped-SSTM achieves f (yN ) − f (x∗) ≤ ε with probability at least 1 − β after

O max

LR02 , σ2R02 ε ε2

ln LR02 + σR0 εβ

iterations/oracle calls.

F.1.2 Sketch of the Proof of Theorem F.1

We start with the following lemma that is pretty standard in the analysis of Stochastic Similar Triangles Method, e.g. see the proof of Theorem 1 from [10].
Lemma F.4. Let f be a convex L-smooth function and let stepsize parameter a satisfy a ≥ 1. Then after N ≥ 0 iterations of clipped-SSTM for all z ∈ Rn we have

AN f (yN ) − f (z)

1

1

N −1

≤

z0 − z

2 2

−

zN − z

2 2

+

αk+1 θk+1, z − zk

2

2

k=0

N −1

N −1

+

αk2+1 θk+1 22 +

αk2+1 θk+1, ∇f (xk+1) , (36)

k=0

k=0

θk+1 d=ef ∇f (xk+1, ξk) − ∇f (xk+1).

(37)

That is, if z = x∗, then the result above gives a preliminary upper bound for AN (f (yN ) − f (x∗)).

The ﬁrst and the second terms in the r.h.s. of (36) come from the analysis of Similar Triangles Method

[16] and three last terms have a stochastic nature. In particular, they explicitly depend on differences

θk+1 = ∇f (xk+1, ξk) − ∇f (xk+1) between clipped mini-batched stochastic gradients and full

gradients at xk+1, so, if ∇f (xk+1, ξk) = ∇f (xk+1) with probability 1, then we easily get needed

convergence rate. However, we are interested in the more general case and, as a consequence, to

continue the proof, we need to ﬁnd a good enough upper bound for the last three terms from (36). In

other words, we need to show that choosing parameters a, mk and λk+1 properly we can upper bound

these terms by something that coincides with

z0 − x∗

2 2

up

to

numerical

multiplicative

constant.

The proof of convergence result for RSMD from [47] where authors provide upper bound for similar

sums hints that Bernstein’s inequality (see Lemma D.1) applied to estimate these terms can help us

to reach our goal. In order to apply Bernstein’s inequality one should derive tight bounds for such

characteristics of ∇f (xk+1, ξk) as upper bounds for the magnitude, bias, variance and distortion and

the next lemma provides us with this.

Lemma F.5. For all k ≥ 0 the following inequality holds:

∇f (xk+1, ξk) − Eξk ∇f (xk+1, ξk) ≤ 2λk+1.

(38)

2

Moreover, if

∇f (xk+1)

2

≤

λk+1 2

for some k ≥ 0, then for this k we have:

k+1 k

k+1

4σ2

Eξk ∇f (x

, ξ ) − ∇f (x

)≤

,

2

mk λk+1

(39)

k+1 k

2 k+1

18σ2

Eξk ∇f (x

, ξ ) − ∇f (x

)
2

≤

, mk

(40)

k+1 k

k+1 k 2

18σ2

Eξk ∇f (x

, ξ ) − Eξk ∇f (x

,ξ )
2

≤

. mk

(41)

Clearly, clipping introduces a bias in ∇f (xk+1, ξk) which inﬂuences the convergence of the method. Hence, the clipping level λk+1 should be chosen in a very accurate way. Below we informally describe what does it mean and present the sketch of the remaining part of the proof.
Imagine the ideal situation: ∇f (xk+1, ξk) = ∇f (xk+1) with probability 1 for all k, i.e. we have an access to the full gradients at points xk+1. Then it is natural to choose λk+1 in such a way that clip(∇f (xk+1), λk+1) = ∇f (xk+1) in order to recover Similar Triangles Method (STM) that

21

converges with optimal rate in the deterministic case. In other words, one can pick λk+1 such that ∇f (xk+1) 2 ≤ λk+1 and get an optimal method. Since we know that in this case the method
should converge with O(1/k2) rate in terms of f (xk) − f (x∗) one can expect that the gradient’s norm
decays with O(1/k) rate, so, one can choose λk+1 to be proportional to 1/k. It is exactly what we do when we deﬁne λk+1 as B/αk+1.

The ideal case described above gives a good insight on how to choose λk+1 in the general case and can be described as follows: if we want to prevent our gradient estimator ∇f (xk+1, ξk) from large deviations from ∇f (xk+1) with high probability, then it is needed to choose λk+1 such that
∇f (xk) 2 ≤ cλk+1 with high probability where c < 1 is some positive number. This choice guarantees that with high probability clipped mini-batched gradient ∇f (xk+1, ξk) cannot deviates from ∇f (xk+1) signiﬁcantly and, as a consequence, the convergence rate of clipped-SSTM in terms
of the number of iterations needed to achieve the desired accuracy of the solution with high probability
becomes similar to the convergence rate of STM up to some logarithmical factors depending on the
conﬁdence level.

In particular, we choose λk+1 such that ∇f (xk+1) 2 ≤ / λk+1 2 with high probability. Moreover, we

derive this relation by induction via reﬁned estimation of the three last terms from the r.h.s. of (36)

that is based on the new variant of advanced recurrences technique from [22, 23]. The main trick

there is in showing by induction that sequence zk − x∗ 2 is bounded by some constant multiplied

by x0 − x∗ 2 and in deriving ∇f (xk+1) 2 ≤ / λk+1 2 simultaneously for all k = 0, 1, . . . , N . With

such bounds and Lemma F.5 in hand, it is possible to apply Bernstein’s inequality to three sums from

the r.h.s. of (36) since all summands are bounded with high probability. After applying Bernstein’s

inequality we adjust parameters αk+1 and mk in such a way that after rearranging the terms in the

obtained upper bounds we get that r.h.s. in (36) (with z = x∗) is smaller than

x0 − x∗

2 2

up

to

some

multiplicative numerical constant. This ﬁnishes the proof.

To conclude, the key tools in our analysis are Bernstein’s inequality (see Lemma D.1) and advanced recurrences technique [22, 23] that helps us to show boundedness of zN −x∗ 2 and ∇f (xk+1) 2 ≤ / λk+1 2 with high probability. We provide detailed proofs of presented result in the Appendix (see
Section F.3).

F.2 Strongly Convex Case
In this section we assume additionally that f (x) is µ-strongly convex. For this case we modify Algorithm 1 and propose a new method called Restarted Clipped Similar Triangles Method (R-clipped-SSTM), see Algorithm 3. At each iteration R-clipped-SSTM runs clipped-SSTM for

Algorithm 3 Restarted Clipped Stochastic Similar Triangles Method (R-clipped-SSTM)
Input: starting point x0, number of iterations N0 of clipped-SSTM, number of clipped-SSTM runs, batchsizes {m0k}Nk=0−0 1, {m1k}Nk=0−0 1, . . . , {mτk}Nk=0−0 1, stepsize parameter a, clipping parameters {Bt}t=0
1: Set xˆ0 = x0 2: for t = 0, 1, . . . , τ − 1 do 3: Run clipped-SSTM (Algorithm 1) for N0 iterations with batchsizes {mtk}Nk=01, stepsize
parameter a, clipping parameter Bt and starting point xˆt. Deﬁne the output of clipped-SSTM by xˆt+1. 4: end for Output: xˆτ

N0 iterations from the current point xˆk and use its output as next iterate xˆk+1. In literature this approach is known as the restarts technique [11, 31, 32, 51]. Choosing N0 and parameters mk, a and B in a proper way one can get an accelerated method for strongly convex objectives. Theorem below
states the main convergence result for R-clipped-SSTM.

22

Theorem F.6. Assume that f is µ-strongly convex and L-smooth. If we choose β ∈ (0, 1), τ and N0 ≥ 1 such that

ln 4N0τ ≥ 2, N0 ≥ C 8aL , (42)

β

µ

and

t

6000

·

2tσ2αk2+1N0

ln

4N0 τ β

10368 · 2tσ2αk2+1N0

mk = max 1,

C 2 R2

, C2R2

,

(43)

CR

Bt = 8 · 2t ln 4N0τ ,

(44)

β

a ≥ max 1, 16 ln 4Nβ0τ , 36 2 ln 4N0τ + 4 ln2 4N0τ + 2 ln 4N0τ 2 , (45)

C

β β β

where R = 2(f(x0)µ−f(x∗)) and C = √5, then we have that after τ runs of clipped-SSTM in R-clipped-SSTM the inequality

f (xˆτ ) − f (x∗) ≤ 2−τ f (x0) − f (x∗)

(46)

holds with probability at least 1 − β. That is, if we choose a to be equal to the maximum from

(45) and N0 ≤ C1

8aL µ

with

some

numerical

constant

C1

≥

C,

then

the

method

achieves

f (xˆτ ) − f (x∗) ≤ ε with probability at least 1 − β after

L µR2

L µR2

O

ln

ln

ln

iterations (in total)

(47)

µ

ε

µβ ε

of clipped-SSTM and requires

L µR2 σ2

L µR2

O max

ln ,

ln

ln

oracle calls.

(48)

µ ε µε

µβ ε

In other words, R-clipped-SSTM has the same convergence rate as optimal stochastic methods for strongly convex problems like Multi-Staged AC-SA (MS-AC-SA) [19] or Stochastic Similar Triangles Method for strongly convex problems (SSTM_sc) [16, 22]. Moreover, in Theorem F.6 we do not assume that stochastic gradients are sampled from sub-Gaussian distribution while corresponding results for MS-AC-SA and SSTM_sc are substantially based on the light tails assumption. Our bound outperforms the state-of-the-art result from [7] in terms of the dependence on ln Lµ . It is worth to mention here that using special restarts technique Nazin et al. [47] generalize their method (RSMD) for the strongly convex case, but since RSMD is not accelerated their approach gives only non-accelerated convergence rate.
We also emphasize that big numerical factors in formulas for mtk and a are needed only in our analysis and in practice they can be tuned. However, when σ2 is big bathsizes mtk become of the order k2ε−1. It can make the cost of one iteration extremely high, therefore, as for clipped-SSTM we consider a different stepsize policy removing this drawback.

Corollary F.7. Let the assumptions of Theorem F.6 hold. Assume that conditions (42), (43), (44) and (45) are satisﬁed for

σ4 ln2 Nβ0τ

aL

a = Θ Lµε2

, N0 = Θ

. µ

(49)

Then after τ = ln(µR2/2ε) runs of clipped-SSTM in R-clipped-SSTM the method achieves f (xˆτ ) − f (x∗) ≤ ε with probability at least 1 − β. Moreover, the total number of iterations of

23

clipped-SSTM equals

σ2 µR2

σ2 µR2

O ln

ln

ln

(50)

µε

ε

µεβ ε

with mtk = O(1) for all k = 0, 1, . . . , N0 − 1, t = 0, 1, . . . , τ − 1.

When σ2 is big the obtained bound is comparable with bounds for restarted-RSMD and proxBoost, see Table 2.

F.3 Proofs

F.3.1 Proof of Lemma F.4 Using zk+1 = zk − αk+1∇f (xk+1, ξk) we get that for all z ∈ Rn

αk+1 ∇f (xk+1, ξk), zk − z = αk+1 ∇f (xk+1, ξk), zk − zk+1

+αk+1 ∇f (xk+1, ξk), zk+1 − z

= αk+1 ∇f (xk+1, ξk), zk − zk+1 + zk+1 − zk, z − zk+1

(≤13) αk+1 ∇f (xk+1, ξk), zk − zk+1 − 12 zk − zk+1 22 + 21 zk − z 22 − 21 zk+1 − z 22. (51)

Next, we notice that

yk+1 = Akyk + αk+1zk+1 = Akyk + αk+1zk + αk+1

Ak+1

Ak+1

Ak+1

which implies:

zk+1 − zk

= xk+1+ αk+1 Ak+1

zk+1 − zk (52)

αk+1 ∇f (xk+1, ξk), zk − z

(37),(51)
≤
(=52)
(7)
≤
(=52)

αk+1 ∇f (xk+1), zk − zk+1 − 21 zk − zk+1 22 +αk+1 θk+1, zk − zk+1 + 21 zk − z 22 − 21 zk+1 − z 22
Ak+1 ∇f (xk+1), xk+1 − yk+1 − 21 zk − zk+1 22 +αk+1 θk+1, zk − zk+1 + 21 zk − z 22 − 21 zk+1 − z 22

Ak+1 f (xk+1) − f (yk+1) + Ak+2 1L xk+1 − yk+1 22 − 12 zk − zk+1 22 + αk+1 θk+1, zk − zk+1 + 21 zk − z 22 − 21 zk+1 − z 22

Ak+1

f (xk+1) − f (yk+1)

1 +

2

αk2+1L − 1 Ak+1

zk − zk+1

2 2

+αk+1 θk+1, zk − zk+1 + 21 zk − z 22 − 21 zk+1 − z 22.

Since Ak+1 ≥ aLαk2+1 (see Lemma E.1) and a ≥ 1 we can continue our derivations:

αk+1 ∇f (xk+1, ξk), zk − z

≤ Ak+1 f (xk+1) − f (yk+1) + αk+1 θk+1, zk − zk+1 + 12 zk − z 22 − 21 zk+1 − z 22. (53)

24

Next, due to convexity of f we have

∇f (xk+1, ξk), yk − xk+1 (=37) ∇f (xk+1), yk − xk+1 + θk+1, yk − xk+1

≤ f (yk) − f (xk+1) + θk+1, yk − xk+1 .

(54)

By deﬁnition of xk+1 we have xk+1 = AkykA+kα+k1+1zk which implies

αk+1 xk+1 − zk = Ak yk − xk+1

(55)

since Ak+1 = Ak + αk+1. Putting all together we derive that

αk+1 ∇f (xk+1, ξk), xk+1 − z

= (=55)
(54),(53)
≤
(=55)
≤

αk+1 ∇f (xk+1, ξk), xk+1 − zk
+αk+1 ∇f (xk+1, ξk), zk − z
Ak ∇f (xk+1, ξk), yk − xk+1
+αk+1 ∇f (xk+1, ξk), zk − z
Ak f (yk) − f (xk+1) + Ak θk+1, yk − xk+1 +Ak+1 f (xk+1) − f (yk+1) + αk+1 θk+1, zk − zk+1 + 21 zk − z 22 − 21 zk+1 − z 22
Akf (yk) − Ak+1f (yk+1) + αk+1 θk+1, xk+1 − zk +αk+1f (xk+1) + αk+1 θk+1, zk − zk+1 + 21 zk − z 22 − 21 zk+1 − z 22
Akf (yk) − Ak+1f (yk+1) + αk+1f (xk+1) +αk+1 θk+1, xk+1 − zk+1 + 21 zk − z 22 − 21 zk+1 − z 22.

Rearranging the terms we get

Ak+1f (yk+1) − Akf (yk) ≤ αk+1 f (xk+1) + ∇f (xk+1, ξk), z − xk+1 + 21 zk − z 22 − 21 zk+1 − z 22 + αk+1 θk+1, xk+1 − zk+1
(=37) αk+1 f (xk+1) + ∇f (xk+1), z − xk+1 +αk+1 θk+1, z − xk+1 + 21 zk − z 22 − 21 zk+1 − z 22 +αk+1 θk+1, xk+1 − zk+1
≤ αk+1f (z) + 21 zk − z 22 − 21 zk+1 − z 22 + αk+1 θk+1, z − zk+1
25

where in the last inequality we use the convexity of f . Taking into account A0 = α0 = 0 and

AN =

N −1 k=0

αk+1

we

sum

up

these

inequalities

for

k

=

0,

.

.

.

,

N

−

1

and

get

1

1

N −1

AN f (yN ) ≤ AN f (z) +

z0 − z

2 2

−

zN − z

2 2

+

αk+1 θk+1, z − zk+1

2

2

k=0

1

1

N −1

= AN f (z) +

z0 − z

2 2

−

zN − z

2 2

+

αk+1 θk+1, z − zk

2

2

k=0

N −1
+ αk2+1 θk+1, ∇f (xk+1, ξk)

k=0

(37)

10

2 1N

N −1 2

k

= AN f (z) + 2 z − z 2 − 2 z − z 2 + αk+1 θk+1, z − z

k=0

N −1

+

αk2+1

k=0

N −1

θk+1 22 +

αk2+1

k=0

θk+1, ∇f (xk+1)

which concludes the proof.

F.3.2 Proof of Lemma F.5
Proof of (38). By deﬁnition of ∇f (xk+1, ξk) we have that ∇f (xk+1, ξk) 2 ≤ λk+1 and, as a consequence, Eξk [∇f (xk+1, ξk)] ≤ λk+1. Using this we get
2

∇f (xk+1, ξk) − Eξk ∇f (xk+1, ξk) ≤ ∇f (xk+1, ξk) + Eξk ∇f (xk+1, ξk) ≤ 2λk+1.

2

2

2

Proof of (39). In order to prove this bound we introduce following indicator random variables:

1 χk d=ef ∇f (xk+1,ξk) 2>λk+1 ,

1 ηk d=ef

. ∇f (xk+1,ξk)−∇f (xk+1)

2

>

1 2

λk+1

From the assumptions of the lemma, we have that

∇f (xk+1)

2

≤

λk+1 2

which implies

(56)

∇f (xk+1, ξk) ≤
2
≤

∇f (xk+1, ξk) − ∇f (xk+1) + ∇f (xk+1)

2

2

∇f (xk+1, ξk) − ∇f (xk+1) + λk+1 ,

2

2

hence

χk ≤ ηk.

(57)

The introduced notation helps us to rewrite ∇f (xk+1, ξk) in the following way:

∇f (xk+1, ξk) = ∇f (xk+1, ξk)(1 − χk) +

λk+1

∇f (xk+1, ξk)χk (58)

∇f (xk+1, ξ) 2





= ∇f (xk+1, ξk) + 

λk+1

− 1 ∇f (xk+1, ξk)χk. (59)

∇f (xk+1, ξk)

2

26

We use this representation to obtain the following inequality:

Eξk ∇f (xk+1, ξk) − ∇f (xk+1)
2

(23=),(59)
≤
(=56)
(56)
≤
(57)
≤ ≤
≤
(24)
≤







λk+1 Eξk  ∇f (xk+1, ξk)

− 1 ∇f (xk+1, ξk)χk

2

2





Eξk  ∇f (xk+1, ξk) ·
2

λk+1 ∇f (xk+1, ξk)

− 1 χk

2







Eξk  ∇f (xk+1, ξk) · 1 −
2

λk+1 ∇f (xk+1, ξk)

 χk

2

Eξk ∇f (xk+1, ξk) χk
2

Eξk ∇f (xk+1, ξk) ηk
2
Eξk ∇f (xk+1, ξk) − ∇f (xk+1) ηk
2
+ ∇f (xk+1) 2 Eξk [ηk]

2

Eξk ∇f (xk+1, ξk) − ∇f (xk+1)

Eξ

k

[

η

2 k

]

2

+ ∇f (xk+1) 2 Eξk [ηk]

σ √

E

k

[η2] +

λk+1 E

k

[ηk] .

(60)

mk ξ k

2ξ

Next, we derive an upper bound for the expectation of ηk using Markov’s inequality:

Eξk [ηk] = Eξk ηk2 = Pξk {ηk = 1}

(=56) Pξk

∇f (xk+1, ξk) − ∇f (xk+1) > λk+1

2

2

2

4Eξk

∇f (xk+1, ξk) − ∇f (xk+1)
2 (24)

4σ2

≤ λ2k+1 ≤ mkλ2k+1 . (61)

Putting all together we derive (39):

Eξk ∇f (xk+1, ξk) − ∇f (xk+1)
2

(60),(61)
≤

2σ2

λk+1 4σ2

4σ2

mkλk+1 + 2 · mkλ2k+1 = mkλk+1 .

Proof of (40). Recall that in the space of random variables with ﬁnite second moment, i.e. in L2, one can introduce a norm as E|X|2 for an arbitrary random variable X from this space. Using triangle
27

inequality for this norm we get

2
Eξk ∇f (xk+1, ξk) − ∇f (xk+1)
2



2

(58)
≤

E  λk+1∇f (xk+1, ξk) − ∇f (xk+1) χ2 

ξk  ∇f (xk+1, ξk)

k

2

2

+ Eξk

2
∇f (xk+1, ξk) − ∇f (xk+1) (1 − χk)2
2



2



(12)
≤

λk+1∇f (xk+1, ξk) E 2

+ 2 ∇f (xk+1) 2 χ2 

ξk  ∇f (xk+1, ξk)

2 k

22

+ Eξk

2
∇f (xk+1, ξk) − ∇f (xk+1)
2

(24)
≤
(57),(61)
≤
≤

5 2 λk+1

E

k

[χ2] +

σ √

ξk

mk

5

2σ

σ

2 λk+1 · √mkλk+1 + √mk =

√

18σ

√.

mk

√ 10 + 1

σ √
mk

Proof of (41). To derive (41) we use (40):
2
Eξk ∇f (xk+1, ξk) − Eξk ∇f (xk+1, ξk)
2

(15)
≤ Eξk

2
∇f (xk+1, ξk) − ∇f (xk+1)
2

(40) 18σ2

≤

.

mk

F.3.3 Proof of Theorem F.1

Lemma F.4 implies that the inequality

AN f (yN ) − f (x∗)

1

1

N −1

≤

z0 − x∗

2 2

−

zN − x∗

2 2

+

αk+1 θk+1, x∗ − zk

2

2

k=0

N −1

N −1

+

αk2+1 θk+1 22 +

αk2+1 θk+1, ∇f (xk+1) ,

k=0

k=0

(62)

θk+1 d=ef ∇f (xk+1, ξk) − ∇f (xk+1)

(63)

holds for all N ≥ 0. Taking into account that f (yN ) − f (x∗) ≥ 0 for all yN and using new notation Rk d=ef zk − x∗ 2, R0 = R0, Rk+1 = max{Rk, Rk+1} we derive that for all k ≥ 0

k−1
Rk2 ≤ R02 + 2 αl+1
l=0

θl+1, x∗ − zl

k−1
+ 2 αl2+1
l=0

θl+1, ∇f (xl+1)

k−1
+ 2 αl2+1
l=0

θl+1

22. (64)

First of all, we notice that for each k ≥ 0 iterates xk+1, zk, yk lie in the ball BRk (x∗). We prove it using induction. Since y0 = z0 = x0, R0 = R0 = z0 − x∗ 2 and x1 = A0y0A+1α1z0 = z0 we have that x1, z0, y0 ∈ BR0 (x∗). Next, assume that xl, zl−1, yl−1 ∈ BRl−1 (x∗) for some l ≥ 1. By
deﬁnitions of Rl and Rl we have that zl ∈ BRl (x∗) ⊆ BRl (x∗). Since yl is a convex combination of yl−1 ∈ BRl−1 (x∗) ⊆ BRl (x∗), zl ∈ BRl (x∗) and BRl (x∗) is a convex set we conclude that

28

yl ∈ BRl (x∗). Finally, since xl+1 is a convex combination of yl and zl we have that xl+1 lies in BRl (x∗) as well.
The rest of the proof is based on the reﬁned analysis of inequality (64). In particular, via induction we prove that for all k = 0, 1, . . . , N with probability at least 1 − kNβ the following statement holds: inequalities

(64)

t−1

t−1

t−1

Rt2 ≤ R02 + 2

αl+1 θl+1, x∗ − zl + 2

αl2+1 θl+1, ∇f (xl+1) + 2

αk2+1

θl+1

2 2

l=0

l=0

l=0

≤ C2R02

(65)

hold for t = 0, 1, . . . , k simultaneously where C is deﬁned in (29). Let us deﬁne the probability

event

when

this

statement

holds

as

Ek .

Then,

our

goal

is

to

show

that

P{Ek }

≥

1−

kβ N

for

all

k = 0, 1, . . . , N . For t = 0 inequality (65) holds with probability 1 since C ≥ 1, hence P{E0} = 1.

Next, assume that for some k = T − 1 ≤ N − 1 we have P{Ek} = P{ET −1} ≥ 1 − (T −N1)β . Let

us

prove

that

P{ET

}

≥

1

−

Tβ N

.

First

of

all,

probability

event

ET −1

implies

that

(62) 1 1

t−1

f (yt) − f (x∗) ≤

R02 + αl+1 θl+1, x∗ − zl + αl+1∇f (xl+1)

At 2 l=0

(≤65) C2R02 2At

hold for t = 0, 1, . . . , T − 1. Then, inequalities

t−1
+ αk2+1
l=0

θl+1

2 2

(66)

∇f (x1) 2 ∇f (xt+1) 2

=
≤
(6),(8)
≤

∇f (z0)

(6)
≤L

z0 − x∗

2=

1 · R0 ,

2

a α1

∇f (xt+1) − ∇f (yt) 2 + ∇f (yt) 2

L xt+1 − yt 2 + 2L(f (yt) − f (x∗))

(55),(66)
≤
(20)
≤
≤

αt+1L xt+1 − zk + LC2R02

At

2

At

√

2L(t + 2) xk+1 − x∗ 2 + x∗ − zk 2 + 2LCR0 a

t(t + 3)

t(t + 3)

√

4L(t + 2)Rk + 2LCR0 a

t(t + 3)

t(t + 3)

(≤65) 2aLCR0 2(t + 2)2 + t + 2 t + 2 at(t + 3) at(t + 3)

≤

C R0

93 +√

αt+1 2a 2 a

hold for t = 1, . . . , T − 1 where the last inequality follows from (tt(+t+23)2) ≤ 1(1(1++23)2) = 94 . Taking a

such that

a ≥ 2R0 and

93 +√ ≤

B

B

2a 2 a 2CR0

we obtain that probability event ET −1 implies

∇f (xt+1) ≤ B = λt+1

(67)

2

2αt+1

2

for t = 0, . . . , T − 1. Since B =

C R0
4N

we have to choose such a that

8 ln β

a ≥ 16 ln 4βN C

93

1

and

a

+

√ a

≤

8 ln

4N

.

β

29

Solving quadratic inequality

√ 4N

4N

a − 24 a ln − 72 ln ≥ 0

β

β

√ w.r.t. a we get that a should satisfy

 a ≥ max  16 ln 4βN , 36
C

4N 2 ln +
β

2

4 ln2 4N + 2 ln 4N

 .

β β

Having inequalities (67) in hand we show in the rest of the proof that (65) holds for t = T with big enough probability. First of all, we introduce new random variables:

x∗ − zl, if x∗ − zl 2 ≤ CR0, ηl =

0,

otherwise,

and ζl = 0∇,f (xl+1), oifthe∇rwf i(sxel,+1) 2 ≤ 2αBl+1 ,

(68) for l = 0, 1, . . . T − 1. Note that these random variables are bounded with probability 1, i.e. with probability 1 we have

B ηl 2 ≤ CR0 and ζl 2 ≤ 2αl+1 . (69)

Secondly, we use the introduced notation and get that ET −1 implies

(64),(65),(67),(68)

T −1

T −1

T −1

RT2

≤

R02 + 2

αl+1 θl+1, ηl + 2

αl2+1

θl+1

2 2

+

2

αl2+1 θl+1, ζl

l=0

l=0

l=0

T −1

T −1

=

R02 + αl+1 θl+1, 2ηl + 2αl+1ζl + 2 αl2+1 θl+1 22.

l=0

l=0

Finally, we do some preliminaries in order to apply Bernstein’s inequality (see Lemma D.1) and obtain that ET −1 implies

(12)

T −1

T −1

RT2 ≤ R02 + αl+1 θlu+1, 2ηl + 2αl+1ζl + αl+1 θlb+1, 2ηl + 2αl+1ζl

l=0

l=0

T −1
+ 4αl2+1
l=0

x

θlu+1

2 2

−

Eξl

θlu+1

2 2

y
T −1
+ 4αl2+1Eξl
l=0

θlu+1

2 2

z

{

T −1

+

4αl2+1

θlb+1

2 2

l=0

|

where we introduce new notations:

θlu+1 d=ef ∇f (xl+1, ξl) − Eξl ∇f (xl+1, ξl) , θlb+1 d=ef Eξl ∇f (xl+1, ξl) − ∇f (xl+1),

(70) (71)

θl+1 (=37) θlu+1 + θlb+1.

It remains to provide tight upper bounds for x, y, z, { and |, i.e. in the remaining part of the proof we show that x + y + z + { + | ≤ δC2R02 for some δ < 1.

Upper

bound

for

x.

First

of

all,

since

Eξ

l

[θ

u l+1

]

=

0

summands

in

x

are

conditionally

unbiased:

Eξl αl+1 θlu+1, 2ηl + 2αl+1ζl = 0.

30

Secondly, these summands are bounded with probability 1:

αl+1 θlu+1, 2ηl + 2αl+1ζl

≤
(38),(69)
≤
=
(25)
≤

αl+1 θlu+1 2 2ηl + 2αl+1ζl 2

2αl+1λl+1 (2CR0 + B) = 2B(2CR0 + B)

C 2 R02

C 2 R02

2 ln 4N + 32 ln2 4N

β

β

C 2 R02

C 2 R02

33C 2 R02

2 ln 4N + 64 ln 4N ≤ 64 ln 4N .

β

β

β

Finally, one can bound conditional variances σl2 d=ef Eξl αl2+1 θlu+1, 2ηl + 2αl+1ζl 2 in the following way:

σl2

≤

Eξl

αl2+1

θlu+1 22

2ηl + 2αl+1ζl

2 2

(69)
≤ αl2+1Eξl

θlu+1 22 (2CR0 + B)2.

(72)

In other words, sequence αl+1 θlu+1, 2ηl + 2αl+1ζl l≥0 is bounded martingale difference sequence with bounded conditional variances {σl2}l≥0. Therefore, we can apply Bernstein’s inequality, i.e. we apply Lemma D.1 with Xl = αl+1 θlu+1, 2ηl + 2αl+1ζl , c = 6343Cln24RN02 and F = c2 l1n84βN and
β
get that for all b > 0

T −1

T −1

b2

Xl > b and σl2 ≤ F ≤ 2 exp −

P

2F + 2cb/3

l=0

l=0

or, equivalently, with probability at least 1 − 2 exp − 2F +b22cb/3

T −1
either σl2 > F or
l=0

T −1
Xl
l=0

≤ b.

|x|

The choice of F will be clariﬁed further, let us now choose b in such a way that 2 exp − 2F +b22cb/3 = 2βN . This implies that b is the positive root of the quadratic equation

b2 − 2c ln 4βN b − 2F ln 4N = 0,

3

β

hence

c ln 4βN

c2 ln2 4βN

4N c ln 4βN

b=

+

+ 2F ln ≤

+

3

9

β

3

√

= 1 + 2 c ln 4N ≤ 33C2R02 .

3

β

64

That is, with probability at least 1 − 2βN

T −1 2

33C 2 R02

either σl > F or |x| ≤ 64 .

l=0

probability event Ex

2c2 ln2 4βN 9

31

Next, we notice that probability event ET −1 implies that

T −1
σl2
l=0

(72)
≤
(41),(67)
≤
(25),(26)
≤
T ≤N
≤

T −1
(2CR0 + B)2 αl2+1Eξl
l=0

θlu+1 22

18σ 2 C 2 R02

1 2 + 8 ln 4N
β

2 T −1 αl2+1 l=0 ml

18σ 2 C 2 R02

1 2+
16

2 T −1

αl2+1 C 2 R02

l=0

6000σ2αl2+1N

ln

4N β

18 2 + 116 2 4 4 N−1 1 c2 ln 4βN

6000 ln 4N C R0

≤

= F,

N

18

β

l=0

where the last inequality follows from c = 6343Cln24RN02 and simple arithmetic. β

Upper bound for y. First of all, we notice that probability event ET −1 implies

αl+1 θlb+1, 2ηl + 2αl+1ζl This implies that

≤
(39),(69)
≤
=
(25),(26)
≤
=

αl+1 θlb+1 2 2ηl + 2αl+1ζl 2

4σ2 αl+1 · mlλl+1 (2CR0 + B)

32αl2+1σ2

ln

4N β

ml C R0

C R0 2CR0 + 8 ln 4N
β

32αl2+1 σ 2 C 2 R02

ln

4N β

6000αl2+1N σ2

ln

4N β

1 2+
16

11C2R02 . 1000N

T −1 b

T ≤N 11C2R02

y=

αl+1 θl+1, 2ηl + 2αl+1ζl ≤

. 1000

l=0

Upper bound for z. We derive the upper bound for z using the same technique as for x. First of all, we notice that the summands in z are conditionally independent:

Eξl 4αl2+1

θlu+1

2 2

−

Eξl

θlu+1

2 2

= 0.

Secondly, the summands are bounded with probability 1:

4αl2+1

θlu+1

2 2

−

Eξl

θlu+1

2 2

≤

4αl2+1

θlu+1

2 2

+

Eξl

θlu+1

2 2

(38)
≤ 4αl2+1 4λ2l+1 + 4λ2l+1

2

C2R02 (25) C2R02 def

= 32B = 2 ln2 4N ≤ 4 ln 4N = c1. (73)

β

β

Finally, one can bound conditional variances σˆl2 d=ef Eξl the following way:

4αl2+1

θlu+1

2 2

−

Eξl

θlu+1

2 2

2 in

(73)

σˆl2

≤

c1Eξl 4αl2+1

θlu+1

2 2

−

Eξl

θlu+1

2 2

≤

4c1αl2+1Eξl

θlu+1

2 2

+

Eξl

θlu+1

2 2

= 8c1αl2+1Eξl

θlu+1

2 2

.

(74)

In other words, sequence 4αl2+1

θlu+1

2 2

−

Eξl

θlu+1

2 2

l≥0 is bounded martingale difference

sequence with bounded conditional variances {σˆl2}l≥0. Therefore, we can apply Bernstein’s inequal-

ity, i.e. we apply Lemma D.1 with Xl = Xˆl = 4αl2+1

θlu+1

2 2

−

Eξl

θlu+1

2 2

, c = c1 = 4Cln2R4N02 β

32

and F = F1 = c21 l1n84βN and get that for all b > 0

T −1

T −1

P

Xˆl > b and σˆl2 ≤ F1

l=0

l=0

b2 ≤ 2 exp −
2F1 + 2c1b/3

or, equivalently, with probability at least 1 − 2 exp − 2F1+b22c1b/3

T −1
either σˆl2 > F1 or
l=0

T −1
Xˆl ≤ b.
l=0

|z|

As in our derivations of the upper bound for x we choose such b that 2 exp − 2F1+b22c1b/3

i.e.

c1

ln

4N β

b=

+

3

c21 ln2 4N

√ 4N 1 + 2

4N C2R2

β + 2F1 ln ≤

c1 ln ≤

0.

9

β

3

β

4

That is, with probability at least 1 − 2βN

T −1 2

C 2 R02

either σˆl > F1 or |z| ≤ 4 .

l=0

probability event Ez
Next, we notice that probability event ET −1 implies that

T −1
σˆl2
l=0

(74)
≤
(41),(67)
≤
(26)
≤
T ≤N
≤

T −1

8c1

αl2+1Eξl

l=0

θlu+1 22

T −1 144σ2αl2+1 c1 ml
l=0

T −1 144σ2αl2+1C2R02

c1

10368σ2α2 N

l=0

l+1

C2R02 ln 4βN c1 · 4 ln 4N · 18 = F1.
β

c1

= 2βN ,

Upper bound for {. The probability event ET −1 implies

{=
T ≤N
≤

T −1
4αl2+1Eξl
l=0
C2R02 . 144

θlu+1

2 2

(41),(67) T −1 72αl2+1σ2 (26) T −1 72αl2+1σ2C2R02

≤ l=0 ml

≤

10368α2 σ2N

l=0

l+1

Upper bound for |. Again, we use corollaries of probability event ET −1:

T −1 2

b 2 (39),(67) T −1 64αl2+1σ4

1 T −1 64αl4+1σ4

|=

4αl+1 θl+1 2 ≤

m2λ2 = B2

m2

l=0

l=0 l l+1

l=0

l

(26) 64 ln2 4βN T −1 64αl4+1σ4C4R04

≤

C 2 R2

60002σ4α4 N 2 ln2 4N

0 l=0

l+1

β

T ≤N
≤

16C2R02 . 140625

33

Now we summarize all bound that we have: probability event ET −1 implies

(64)

T −1

k−1

T −1

RT2 ≤ R02 + 2

αl+1 θl+1, x∗ − zl + 2

αl2+1 θl+1, ∇f (xl+1) + 2

αl2+1

θl+1

2 2

l=0

l=0

l=0

(70)
≤ R02 + x + y + z + { + |,

y ≤ 11C2R02 , { ≤ C2R02 , | ≤ 16C2R02 ,

1000

144

140625

T −1

T −1

σl2 ≤ F,

σˆl2 ≤ F1

l=0

l=0

and where

(T − 1)β

β

β

P{ET −1} ≥ 1 − N , P{Ex} ≥ 1 − 2N , P{Ez} ≥ 1 − 2N ,

Ex = Ez =

T −1 2

33C 2 R02

either σl > F or |x| ≤ 64 ,

l=0

T −1 2

C 2 R02

either σˆl > F1 or |z| ≤ 4 .

l=0

Taking into account these inequalities we get that probability event ET −1 ∩ Ex ∩ Ez implies

(64)

T −1

k−1

T −1

RT2 ≤ R02 + 2

αl+1 θl+1, x∗ − zl + 2

αl2+1 θl+1, ∇f (xl+1) + 2

αl2+1

θl+1

2 2

l=0

l=0

l=0

≤ R02 + 6343 + 110100 + 14 + 1144 + 14016625 C2R02

≤ 1 + 54 C2 R02 (≤29) C2R02. (75)

Moreover, using union bound we derive

Tβ P {ET −1 ∩ Ex ∩ Ez} = 1 − P ET −1 ∪ Ex ∪ Ez ≥ 1 − N . (76) That is, by deﬁnition of ET and ET −1 we have proved that

(75)

(76)

Tβ

P{ET } ≥ P {ET −1 ∩ Ex ∩ Ez} ≥ 1 − N ,

which implies that for all k = 0, 1, . . . , N we have P{Ek} ≥ 1 − kNβ . Then, for k = N we have that with probability at least 1 − β

AN f (yN ) − f (x∗)

(62) 1

1

N −1

≤

z0 − z

2 2

−

zN − z

2 2

+

αk+1 θk+1, z − zk

2

2

k=0

N −1

+

αk2+1

k=0

N −1

θk+1 22 +

αk2+1

k=0

θk+1, ∇f (xk+1)

(≤65) C2R02 . 2

Since

AN

=

N (N +3) 4aL

(see

Lemma

E.1)

we

get

that

with

probability

at

least

1

−

β

f (yN ) − f (x∗) ≤ 2aLC2R02 . N (N + 3)

34

In other words, clipped-SSTM with a = max 1, 16 ln 4βN , 36 2 ln 4N +

2
4 ln2 4N + 2 ln 4N

=

C

β

β

β

2
36 2 ln 4βN + 4 ln2 4βN + 2 ln 4βN achieves f (yN ) − f (x∗) ≤ ε with probability at least 1 − β

after O LRε 02 ln LεRβ02 iterations and requires

oracle calls.

N −1

N −1 (26)

σ2αk2+1N

ln

N β

mk =

O max 1,

R2

k=0

k=0

0

= O max N, N−1 σ2(k + 2)2N ln Nβ k=0 a2L2R02

(27)

σ2N 4

= O max N, ln3 N L2R2

β

0

= O max

LR02 , σ2R02 ln LR02 .

ε ε2

εβ

F.3.4 Proof of Corollary F.2

Theorem F.1 implies that with probability at least 1 − β

f (yN ) − f (x∗) (≤28) 2aLC2R02 , (77) N (N + 3)

where a satisﬁes



(27)  16 ln 4βN

4N

2

4N

4N  def

a ≥ max 1,

, 36 2 ln + 4 ln2 + 2 ln

= aˆ,

(78)

C

β β β

αk+1

=

k+2 2aL

and

batchsizes

mk

are

chosen

according

to

(26):

(26)

1185σ2αk2+1N

ln

4N β

10368σ2αk2+1N

mk = max 1,

C 2 R2

,

C 2 R2

0

0

1185σ2(k + 2)2N ln 4βN 10368σ2(k + 2)2N

= max 1,

4a2 L2 C 2 R2

, 4a2L2C2R2

.

(79)

0

0

We consider two different options for a.

1. If N ln 4βN is bigger than aˆ, then we take a = N ln 4βN which implies that

mk = max

1185σ2(k + 2)2 10368σ2(k + 2)2

1, 4L2N C2R2 ln 4N , 4L2C2R2N ln2 4N

0β

0

β

=O

max

σ2(k + 2)2

1, L2R2N ln 4N

0

β

and with probability at least 1 − β

f (yN ) − f (x∗) ≤ 2LC2R02 ln 4βN . (80) N +3

That is, if ε is small enough to satisfy LRε 02 ln LεRβ02 ≥ C1 ln2 LεRβ02 for some constant C1, then due to (80) we have that after

N = O LR02 ln LR02

ε

εβ

iterations

35

of clipped-SSTM we obtain such point yN that with probability at least 1 − β inequality f (yN ) − f (x∗) ≤ ε holds and the method requires

N −1

N −1

σ2(k + 2)2

mk =

O max 1, L2R2N ln 4N

k=0

k=0

0

β

σ2N 2 = O max N, L2R2 ln 4N
0β

=O

max

LR02 , σ2R02 ε ε2

ln LR02 εβ

stochastic ﬁrst-order oracle calls.

2. If a0N 3/2 ln 4βN is bigger than aˆ for some a0 > 0, then we take a = a0N 3/2 which implies that

ln 4βN





 1185σ2(k + 2)2 10368σ2(k + 2)2 

mk

=

max 1, 

4a20L2N 2C2R02

,

4a2L2C2R2N 2

=O ln 4N 

0

0

β

max

σ2(k + 2)2

1, a2L2R2N 2

0

0

and with probability at least 1 − β

2a0LC2R02 N ln 4βN

f (yN ) − f (x∗) ≤

.

(81)

N +3

That is, if ε is small enough to satisfy a30Lε33R06 ln LεRβ02 3/2 ≥ C2 ln2 LεRβ02 for some constant

C2, then due to (81) we have that after

N =O

a20L2R04 ln a20L2R04

ε2

ε2β

=O

a20L2R04 ln a0LR02

ε2

εβ

iterations

of clipped-SSTM we obtain such point yN that with probability at least 1 − β inequality f (yN ) − f (x∗) ≤ ε holds and the method requires

N −1

N −1

σ2(k + 2)2

mk =

O max 1, a2L2R2N 2

k=0

k=0

0

0

σ2N

= O max N, a2L2R2

0

0

=O

max

a20L2R04 , σ2R02

ε2

ε2

ln a0LR02 εβ

stochastic ﬁrst-order oracle calls. Finally, if all assumptions on N , β and ε hold for a0 = LσR0 , then for all k = 0, 1, . . . , N − 1

σ2(k + 2)2

mk = O max 1, a2L2R2N 2

0

0

(k + 2)2 = O max 1, N 2

= O(1),

i.e. one iteration of clipped-SSTM requires O(1) oracle calls, and f (yN ) − f (x∗) ≤ ε with probability at least 1 − β after

N =O

σ2R02 ln σR0

ε2

εβ

iterations.

F.3.5 Proof of Corollary F.3

Recall that a



 16 ln 4βN

4N

= max 1,

, 36 2 ln +

C β

2

4 ln2 4N + 2 ln 4N

 ,

β β

σN 3/2

4N

k+2

a = max a , LR0 ln β , αk+1 = 2aL ,

6000σ2αk2+1N

ln

4N β

10368σ2αk2+1N

mk = max 1,

C 2 R2

,

C 2 R2

.

0

0

Since a ≥ σLNR3/02 we have that mk = O(1). Next, there are two possible situations.

36

1. If a = a , then we are in the settings of Theorem F.1. This means that clipped-SSTM achieves f (yN ) − f (x∗) ≤ ε with probability at least 1 − β after

O max

LR02 , σ2R02 ε ε2

ln LR02 εβ

oracle calls.

2. If a = σLNR3/02 ln 4βN , then we are in the settings of Corollary F.2 which implies that clipped-SSTM achieves f (yN ) − f (x∗) ≤ ε with probability at least 1 − β after

O σ2R02 ln σR0

ε2

εβ

oracle calls.

Finally, we combine these two cases and obtain that with a = max a , σLNR3/02 clipped-SSTM guarantees f (yN ) − f (x∗) ≤ ε with probability at least 1 − β after

ln 4βN

O max max

LR02 , σ2R02 ε ε2

ln LR02 , σ2R02 ln σR0

εβ ε2

εβ

= O max

, LR02
ε

σ 2 R02 ε2

ln LR02+σR0
εβ

iterations/oracle calls.

F.3.6 Proof of Theorem F.6

First of all, consider behavior of clipped-SSTM during the ﬁrst run in R-clipped-SSTM. We notice that the proof of Theorem F.1 will be valid if we substitute R0 everywhere by its upper bound R. From µ-strong convexity of f we have
R02 = x0 − x∗ 22 (≤10) µ2 f (x0) − f (x∗) ,

therefore, one can choose R = clipped-SSTM we have

µ2 (f (x0) − f (x∗)). It implies that after N0 iterations of

N

∗

2aC2LR2 4aC2L 0

∗

f (y 0 ) − f (x ) ≤

=

N0(N0 + 3)

N 2µ (f (x ) − f (x )).

0

with probability at least 1 − βτ , hence with the same probability f (yN0 ) − f (x∗) ≤ 12 (f (x0) − f (x∗)) since N0 ≥ C 8aµL . In other words, with probability at least 1 − βτ

f (xˆ1) − f (x∗) ≤ 1 f (x0) − f (x∗) = 1 µR2.

2

4

Then, by induction one can show that for arbitrary k ∈ {0, 1, . . . , τ − 1} the inequality

f (xˆk+1) − f (x∗) ≤ 1 f (xˆk) − f (x∗) 2

holds with probability at least 1− βτ . Therefore, these inequalities hold simultaneously with probability at least 1 − β. Using this we derive that inequality

f (xˆτ )−f (x∗) ≤ 1 f (xˆτ−1) − f (x∗) ≤ 1 f (xˆτ−2) − f (x∗) ≤ . . . ≤ 1 f (x0) − f (x∗) = µR2

2

22

2τ

2τ +1

holds with probability ≥ 1 − β. That is, after τ =

log2

µR2 2ε

restarts R-clipped-SSTM generates

such a point xˆτ that f (xˆτ ) − f (x∗) ≤ ε with probability at least 1 − β. Moreover, if a equals

37

the maximum from (45) and N0 ≤ C1

8aL µ

with

some

numerical

constant

C1

≥

C,

then

a

∼

2
ln Nβ0τ , the total number of iterations of clipped-SSTM equals

N0τ = O

L µR2

L µR2

ln

ln

ln

µ

ε

µβ ε

and the overall number of stochastic ﬁrst-order oracle calls is

τ −1 N0−1 t

τ −1 N0−1

2tσ2αk2+1N0

ln

4N0 τ β

mk =

O max 1, R2

t=0 k=0

t=0 k=0

τ −1 N0−1

2tσ2(k + 2)2N0

=

O max 1, ln3 4N0τ L2R2

t=0 k=0

β

σ22τ N04 = O max N0τ, ln3 4N0τ L2R2
β

= O max

L µR2 σ2

L µR2

ln

,

ln

ln

.

µ

ε µε

µβ ε

F.3.7 Proof of Corollary F.7

Similarly to the proof of Theorem F.6 (see the previous subsection) we derive that under assumptions

of the corollary after τ =

log2

µR2 2ε

restarts R-clipped-SSTM generates such a point xˆτ that

f (xˆτ ) − f (x∗) ≤ ε with probability at least 1 − β. Moreover, a and N0 satisfy the following system

of inequalities

σ4 ln2 Nβ0τ

aL

a = Θ Lµε2 , N0 = Θ µ

(82)

which is consistent and implies that

a = Θ σ4 ln2 σ2 ln µR2 , N0 = Θ σ2 ln σ2 ln µR2 . (83)

Lµε

µεβ ε

µε µεβ ε

Then, for all k = 0, 1, . . . , N0 − 1 and t = 0, 1, . . . , τ − 1 batchsizes satisfy

t

τ −1

2τ σ2αN2 0 N0 ln Nβ0τ

mk ≤ mN0−1 = O max 1,

R2

µR2σ2N03

ln

N0 τ β

= O max 1, a2L2εR2

(82=),(83) O(1),

i.e. the algorithm requires O(1) oracle calls per iteration. Finally, the total number of iterations is

σ2 µR2

σ2 µR2

N0τ = O µε ln ε ln µεβ ln ε .

38

G SGD with Clipping: Exact Formulations and Missing Proofs

In this section we provide exact formulations of all the results that we have for clipped-SGD and R-clipped-SGD together with the full proofs.

G.1 Convex Case

We start with the case when f (x) is convex and L-smooth and, as before, we assume that at each point x ∈ Rn function f is accessible only via stochastic gradients ∇f (x, ξ) such that (2) holds.
Next theorem summarizes the main convergence result for clipped-SGD in this case.

Theorem G.1. Assume that function f is convex and L-smooth. Then for all β ∈ (0, 1) and N ≥ 1

such that

4N

ln ≥ 2

(84)

β

we have that after N iterations of clipped-SGD with

27N σ2 λ = 2LCR0, mk = m = max 1, 2(CR0)2L2 ln 4βN , (85)

where R0 = x0 − x∗ 2 and stepsize

1

γ = 80L ln 4N ,

(86)

β

that with probability at least 1 − β

f (x¯N ) − f (x∗) ≤ 80LC2R02 ln 4βN , (87) N

where x¯N = N1 Nk=−01 xk and √

C = 2.

(88)

In other words, the method achieves f (x¯N ) − f (x∗) ≤ ε with probability at least 1 − β after O LRε 02 ln LεRβ02 iterations and requires

LR02 σ2R02

LR02

O max

ε , ε2

ln εβ

oracle calls.

(89)

To the best of our knowledge, it is the ﬁrst result for clipped-SGD establishing non-trivial complexity guarantees for the convergence with high probability. One can ﬁnd the full proof in Section G.3.1.

G.2 Strongly Convex Case
Next, we consider the situation when f is additionally µ-strongly convex and propose a restarted version of clipped-SGD (R-clipped-SGD), see Algorithm 4. For this method we prove the following

Algorithm 4 Restarted Clipped Stochastic Gradient Descent (R-clipped-SGD)
Input: starting point x0, number of iterations N0 of clipped-SGD, number τ of clipped-SGD runs, batchsizes m0, m1, . . . , mτ
1: Set xˆ0 = x0, stepsize γ > 0 2: for t = 0, 1, . . . , τ − 1 do 3: Run clipped-SGD (Algorithm 2) for N0 iterations with constant batchsizes mt, stepsize γ
and starting point xˆt. Deﬁne the output of clipped-SGD by xˆt+1. 4: end for Output: xˆτ

result.

39

Theorem G.2. Assume that f is µ-strongly convex and L-smooth. If we choose β ∈ (0, 1), τ and

N0 ≥ 1 such that

4N0τ

N0

320C 2 L

ln β ≥ 2, ln 4N0τ ≥

, µ

(90)

β

and

t

27 · 2tN0σ2

m = max 1, 2(CR)2L2 ln 4N0τ ,

(91)

β

where R = 2(f(x0)µ−f(x∗)) and C = √2, then we have that after τ runs of clipped-SGD in

R-clipped-SGD the inequality

f (xˆτ ) − f (x∗) ≤ 2−τ f (x0) − f (x∗)

(92)

holds with probability at least 1 − β. That is, if we choose ln N4N0β0τ ≤ Cµ1L with some numerical

constant C1 ≥ 320C2, then the method achieves f (xˆτ ) − f (x∗) ≤ ε with probability at least 1 − β

after

L µR2

L µR2

O ln

ln

ln

iterations (in total)

(93)

µ

ε

µβ ε

of clipped-SGD and requires

L µR2 σ2

L µR2

O max ln ,

ln

ln

oracle calls.

(94)

µ ε µε

µβ ε

This theorem implies that R-clipped-SGD has the same complexity as the restarted version of RSMD from [47] up to the difference in logarithmical factors. We notice that the main difference between our result and one from [47] is that we do not need to assume that the optimization problem is considered on the bounded set.
However, in order to get (94) R-clipped-SGD requires to know strong convexity parameter µ. In order to remove this drawback we analyse clipped-SGD for the strongly convex case and get the following result.

Theorem G.3. Assume that function f is µ-strongly convex and L-smooth. Then for all β ∈ (0, 1)

and N ≥ 1 such that

4N

ln ≥ 2

(95)

β

we have that after N iterations of clipped-SGD with

27N σ2 λl = 4 L(1 − γµ)lr0, mk = max 1, 16Lr0(1 − γµ)k ln 4βN , (96)

where r0 = f (x0) − f (x∗) and stepsize

1

γ = 81L ln 4N ,

(97)

β

that with probability at least 1 − β

f (xN ) − f (x∗) ≤ 2(1 − γµ)N (f (x0) − f (x∗)).

(98)

In other words, the method achieves f (xN ) − f (x∗) ≤ ε with probability at least 1 − β after O Lµ ln rε0 ln µLβ ln rε0 iterations and requires

O max L , σ2 · L ln r0 ln L ln r0 oracle calls. (99)

µ µε µ

ε

µβ ε

Unfortunately, our approach leads to worse complexity bound than we have for R-clipped-SGD: in the second term of the maximum in (99) we get an extra factor L/µ that can be large. Nevertheless, to

40

the best of our knowledge it is the ﬁrst non-trivial complexity result for clipped-SGD that guarantees convergence with high probability. One can ﬁnd the full proof of Theorem G.3 in Section G.3.3.

G.3 Proofs

G.3.1 Proof of Theorem G.1

Since f (x) is convex and L-smooth, we get the following inequality:

xk+1 − x∗

2 2

=

=

(12)
≤

(8)
≤

≤

xk − γ∇f (xk, ξk) − x∗

2 2

=

xk − x∗

2 2

+

γ2

∇f (xk, ξk)

2 2

−

2γ

xk − x∗, gk

xk − x∗

2 2

+

γ2

∇f (xk) + θk

2 2

−

2γ

xk − x∗, ∇f (xk) + θk

xk − x∗

2 2

+

2γ2

∇f (xk)

2 2

+

2γ2

θk

2 2

−

2γ

xk − x∗, ∇f (xk) + θk

xk − x∗

2 2

+

4γ2L

f (xk) − f (x∗)

+ 2γ2

θk

2 2

−

2γ

xk − x∗, ∇f (xk) + θk

xk − x∗

2 2

+

(4γ2L

−

2γ)

f (xk) − f (x∗)

+ 2γ2

θk

2 2

−

2γ

xk − x∗, θk

,

where θk = ∇f (xk, ξk) − ∇f (xk) and the last inequality follows from the convexity of f . Using notation Rk d=ef xk − x∗ 2 we derive that for all k ≥ 0

Rk2+1 ≤ Rk2 + (4γ2L − 2γ)

f (xk) − f (x∗)

+ 2γ2

θk

2 2

−

2γ

xk − x∗, θk

.

Let us deﬁne A = 2γ − 4γ2L , then

A

f (xk) − f (x∗)

≤ Rk2 − Rk2+1 + 2γ2 θk

2 2

−

2γ

xk − x∗, θk

.

Summing up these inequalities for k = 0, . . . , N − 1 we obtain

A N−1 f (xk) − f (x∗) N
k=0

1 N−1

2γ2 N−1

2γ2 N−1

≤

Rk2 − Rk2+1 +

θk

2 2

−

xk − x∗, θk

N

N

N

k=0

k=0

k=0

1

2γ2 N−1

2γ2 N−1

=

R02 − RN2 +

θk

2 2

−

xk − x∗, θk .

N

N

N

k=0

k=0

N −1

N −1

Noticing that for x¯N = N1 xk Jensen’s inequality gives f (x¯N ) = f N1 xk ≤

k=0

k=0

N −1
N1 f (xk) we have
k=0

N −1

N −1

AN f (x¯N ) − f (x∗) ≤ R02 − RN2 + 2γ2

θk

2 2

−

2γ

xk − x∗, θk .

k=0

k=0

(100)

Taking into account that f (x¯N ) − f (x∗) ≥ 0 and changing the indices we get that for all k ≥ 0

k−1

k−1

Rk2 ≤ R02 + 2γ2

θl

2 2

−

2γ

xl − x∗, θk .

l=0

l=0

(101)

The remaining part of the proof is based on the analysis of inequality (101). In particular, via induction we prove that for all k = 0, 1, . . . , N with probability at least 1 − kNβ the following statement holds: inequalities

(101)

t−1

Rt2 ≤ R02 + 2γ2

l=0

t−1

θk

2 2

−

2γ

l=0

xk − x∗, θk

≤ C2R02

(102)

hold for t = 0, 1, . . . , k simultaneously where C is deﬁned in (88). Let us deﬁne the probability

event

when

this

statement

holds

as

Ek .

Then,

our

goal

is

to

show

that

P{Ek }

≥

1−

kβ N

for

all

k = 0, 1, . . . , N . For t = 0 inequality (102) holds with probability 1 since C ≥ 1. Next, assume

41

that for some k = T − 1 ≤ N − 1 we have P{Ek} = P{ET −1} ≥ 1 − (T −N1)β . Let us prove that

P{ET

}

≥

1

−

Tβ N

.

First

of

all,

probability

event

ET −1

implies

that

(100)
f (x¯N ) − f (x∗) ≤

1

AN

N −1

N −1

R02 + 2γ2

θk

2 2

−

2γ

xk − x∗, θk

k=0

k=0

(1≤02) C2R02 AN

hold for t = 0, 1, . . . , T − 1. Since f is L-smooth, we have that probability event ET −1 implies

∇f (xt) ≤ L xt − x∗ 2 ≤ LCR0 = λ

2

2

(103)

for t = 0, . . . , T − 1, where the clipping level is deﬁned as

λ = 2LCR0.

(104)

Having inequalities (103) in hand we show in the rest of the proof that (102) holds for t = T with big enough probability. First of all, we introduce new random variables:

x∗ − zl, if x∗ − zl 2 ≤ CR0, ηl =

0,

otherwise,

(105)

for l = 0, 1, . . . T − 1. Note that these random variables are bounded with probability 1, i.e. with

probability 1 we have

ηl 2 ≤ CR0.

(106)

Secondly, we use the introduced notation and get that ET −1 implies

(101),(102),(103),(105)

T −1

T −1

RT2

≤

R02 + 2γ

θl, ηl + 2γ2

θl+1 22.

l=0

l=0

Finally, we do some preliminaries in order to apply Bernstein’s inequality (see Lemma D.1) and obtain that ET −1 implies

(12)

T −1

T −1

T −1

RT2 ≤ R02 + 2γ

θ

u l

,

ηl

+ 2γ

θ

b l

,

ηl

+ 4γ2

θlu

2 2

−

Eξl

θlu

2 2

l=0

l=0

l=0

x

y

z

T −1
+ 4γ2 Eξl

T −1

θlu

2 2

+ 4γ2

θlb

2 2

l=0

l=0

{

|

where we introduce new notations:

θlu d=ef ∇f (xl, ξl) − Eξl ∇f (xl, ξl) , θlb d=ef Eξl ∇f (xl, ξl) − ∇f (xl),

(107) (108)

θl = θlu + θlb.
It remains to provide tight upper bounds for x, y, z, { and |, i.e. in the remaining part of the proof we show that x + y + z + { + | ≤ δC2R02 for some δ < 1.

Upper

bound

for

x.

First

of

all,

since

Eξ

l

[θ

u l

]

=

0

summands

in

x

are

conditionally

unbiased:

Eξl [2γ

θ

u l

,

ηl

] = 0.

Secondly, these summands are bounded with probability 1:

|2γ θlu, ηl | ≤ 2γ θlu 2 ηl 2 (38)≤,(106) 4γλCR0 (1=04) 8γ(CR0)2L.

Finally, one can bound conditional variances σl2 d=ef Eξl

4γ2

θ

u l

,

ηl

2

in the following way:

σl2 ≤ Eξl 4γ2 θlu 22 ηl 22 (1≤06) 4γ2(CR0)2Eξl

θlu

2 2

.

42

In other words, sequence {2γ

θ

u l

,

ηl

}l≥0 is a bounded martingale difference sequence with bounded

conditional variances {σl2}l≥0. Therefore, we can apply Bernstein’s inequality, i.e. we apply Lemma D.1 with Xl = 2γ θlu, ηl , c = 8γ(CR0)2L and F = c2 ln6 4βN and get that for all b > 0

T −1

T −1

b2

Xl > b and σl2 ≤ F ≤ 2 exp −

P

2F + 2cb/3

l=0

l=0

or, equivalently, with probability at least 1 − 2 exp − 2F +b22cb/3

T −1
either σl2 > F or
l=0

T −1
Xl
l=0

≤ b.

|x|

The choice of F will be clariﬁed further, let us now choose b in such a way that 2 exp − 2F +b22cb/3 = 2βN . This implies that b is the positive root of the quadratic equation

b2 − 2c ln 4βN b − 2F ln 4N = 0,

3

β

hence

b = c ln 4βN + 3

c2 ln2 4βN

4N c ln 4βN

+ 2F ln =

+

9

β

3

4c2 ln2 4βN 9

=

4N c ln

= 8γ(CR0)2L ln 4N .

β

β

That is, with probability at least 1 − 2βN

T −1

4N

either σl2 > F or |x| ≤ 8γ(CR0)2L ln .

β

l=0

probability event Ex

Next, we notice that probability event ET −1 implies that

T −1
σl2
l=0

≤
(85)
≤
T ≤N
≤

T −1
4γ2(CR0)2 Eξl
l=0

θlu 22 (≤41) 72γ2(CR0)2σ2 mT

2

2

2

2T

(C R0 )2 L2

ln

4N β

72γ (CR0) σ

27N σ2

16 γ2(CR0)4L2 ln 4N ≤ c2 ln 4βN = F,

3

β

6

where the last inequality follows from c = 8γ(CR0)2L and simple arithmetic.

Upper bound for y. First of all, we notice that probability event ET −1 implies

2γ

θ

b l

,

ηl

This implies that

b

(39),(106) 4σ2

(104) 4γσ2

≤ 2γ θl 2 ηl 2 ≤ 2γ mλ CR0 = Lm .

T −1

T ≤N 4γN σ2

y = 2γ

θ

b l

,

ηl

≤

.

mL

l=0

Upper bound for z. We derive the upper bound for z using the same technique as for x. First of all, we notice that the summands in z are conditionally independent:

Eξl 4γ2

θlu

2 2

−

Eξl

θlu

2 2

= 0.

43

Secondly, the summands are bounded with probability 1:

4γ2

θlu

2 2

−

Eξl

θlu

2 2

≤

4γ2

θlu

2 2

+

Eξl

θlu

2 2

(1=04) 128γ2(CR0)2L2 d=ef c1.

(38)
≤ 4γ2 4λ2 + 4λ2 (109)

Finally, one can bound conditional variances σˆl2 d=ef Eξl 4γ2 following way:

θlu

2 2

−

Eξl

θlu

2 2

2 in the

(109)

σˆl2

≤

c1Eξl 4γ2

θlu

2 2

−

Eξl

θlu

2 2

≤

4γ2c1Eξl

θlu

2 2

+

Eξl

θlu

2 2

= 8γ2c1Eξl

θlu

2 2

.

(110)

In other words, sequence 4γ2

θlu

2 2

−

Eξl

θlu

2 2

l≥0 is a bounded martingale difference se-

quence with bounded conditional variances {σˆl2}l≥0. Therefore, we can apply Bernstein’s inequality,

i.e. we apply Lemma D.1 with Xl = Xˆl = 4γ2

θlu

2 2

−

Eξl

θlu

2 2

, c = c1 = 128γ2(CR0)2L2

and F = F1 = c21 ln6 4βN and get that for all b > 0

T −1

T −1

P

Xˆ > b and σˆ2 ≤ F

≤ 2 exp −

b2

l

l

1

2F1 + 2c1b/3

l=0

l=0

or, equivalently, with probability at least 1 − 2 exp − 2F1+b22c1b/3

T −1
either σˆl2 > F1 or
l=0

T −1
Xˆl ≤ b.
l=0
|z|

As in our derivations of the upper bound for x we choose such b that 2 exp − 2F1+b22c1b/3 i.e.

= 2βN ,

c1

ln

4N β

b=

+

3

c21 ln2 4βN + 2F1 ln 4N = c1 ln 4N = 128γ2(CR0)2L2 ln 4N .

9

β

β

β

That is, with probability at least 1 − 2βN

T −1
either σˆl2 > F1
l=0

or |z| ≤ 128γ2(CR0)2L2 ln 4N . β
probability event Ez

Next, we notice that probability event ET −1 implies that

T −1
σˆl2
l=0

(110)
≤
(85)
≤
T ≤N
≤

T −1
8γ2c1 Eξl
l=0

θlu 22 (≤41) 144γ2c1σ2 mT

32 γ2c1(CR0)2L2 T

4N ln

3

Nβ

c21

ln

4N β

6 ≤ F1.

Upper bound for {. The probability event ET −1 implies

T −1
{ = 4γ2 Eξl
l=0

θlu

2 2

(≤41) 72γ2σ2 T −1 1 T ≤≤N 72γ2N σ2 .

m

m

l=0

44

Upper bound for |. Again, we use corollaries of probability event ET −1:

T −1 2

b 2 (39)

2 4 T (104) 64γ2σ4

T T ≤N 16γ2N σ4

| = 4γ l=0 θl 2 ≤ 64γ σ m2λ2 = 4(CR0)2L2 · m2 ≤ (CR0)2L2m2 .

Now we summarize all bound that we have: probability event ET −1 implies

(101)

T −1

T −1

RT2 ≤ R02 + 2γ2

θl

2 2

−

2γ

xl − x∗, θl

l=0

l=0

(107)
≤ R02 + x + y + z + { + |,

4γN σ2

72γ2N σ2

16γ2N σ4

y ≤ mL , { ≤ m , | ≤ (CR0)2L2m2 ,

T −1

T −1

σl2 ≤ F,

σˆl2 ≤ F1

l=0

l=0

and where

(T − 1)β

β

β

P{ET −1} ≥ 1 − N , P{Ex} ≥ 1 − 2N , P{Ez} ≥ 1 − 2N ,

Ex = Ez =

T −1

4N

either σl2 > F or |x| ≤ 8γ(CR0)2L ln

,

β

l=0

T −1

4N

either σˆl2 > F1 or |z| ≤ 128γ2(CR0)2L2 ln

.

β

l=0

Taking into account these inequalities and our assumptions on m and γ (see (85) and (86)) we get that probability event ET −1 ∩ Ex ∩ Ez implies

(101)

T −1

T −1

RT2 ≤ R02 + 2γ2

θl

2 2

−

2γ

xl − x∗, θl

l=0

l=0

≤ R02 + 110 + 110 + 110 + 110 + 110 C2R02 ≤ 1 + 21 C2 R02 (≤88) C2R02. (111)

Moreover, using union bound we derive

P {ET −1 ∩ Ex ∩ Ez} = 1 − P ET −1 ∪ Ex ∪ Ez That is, by deﬁnition of ET and ET −1 we have proved that

Tβ ≥1− .
N

(112)

(111)

(112)

Tβ

P{ET } ≥ P {ET −1 ∩ Ex ∩ Ez} ≥ 1 − N ,

which implies that for all k = 0, 1, . . . , N we have P{Ek} ≥ 1 − kNβ . Then, for k = N we have that with probability at least 1 − β

(100)

N −1

AN f (x¯N ) − f (x∗) ≤ R02 + 2γ2

k=0

N −1

θk

2 2

−

2γ

xk − x∗, θk

k=0

(102)
≤ C2R02.

Since A = 2γ (1 − 2γL) and 1 − γL ≥ 21 we get that with probability at least 1 − β

f (x¯N ) − f (x∗) ≤ C2R02 ≤ C2R02 (≤86) 80C2R02L ln 4βN .

AN

γN

N

45

In other words, clipped-SGD achieves f (x¯N ) − f (x∗) ≤ ε with probability at least 1 − β after O LRε 02 ln LεRβ02 iterations and requires

N −1

N −1 (85)

N σ2

mk =

O max 1, C2R2L2 ln N

k=0

k=0

0

β

= O max LR02 , σ2R02 ln LR02

ε ε2

εβ

=O

max

N 2σ2

N, C2R2L2 ln N

0

β

oracle calls.

G.3.2 Proof of Theorem G.2

First of all, consider behavior of clipped-SGD during the ﬁrst run in R-clipped-SGD. We notice that the proof of Theorem G.1 will be valid if we substitute R0 everywhere by its upper bound R. From µ-strong convexity of f we have
R02 = x0 − x∗ 22 (≤10) µ2 f (x0) − f (x∗) ,

therefore, one can choose R = clipped-SGD we have

µ2 (f (x0) − f (x∗)). It implies that after N0 iterations of

80LC2R2 ln 4N0τ 160LC2R2 ln 4N0τ

f (x¯N0 ) − f (x∗) ≤

β=

β (f (x0) − f (x∗)).

N0

N0µ

with probability at least 1 − βτ , hence with the same probability f (x¯N0 ) − f (x∗) ≤ 12 (f (x0) − f (x∗)) since ln N4N00τ ≥ 320µC2L . In other words, with probability at least 1 − βτ
β

f (xˆ1) − f (x∗) ≤ 1 f (x0) − f (x∗) = 1 µR2.

2

4

Then, by induction one can show that for arbitrary k ∈ {0, 1, . . . , τ − 1} the inequality

f (xˆk+1) − f (x∗) ≤ 1 f (xˆk) − f (x∗) 2

holds with probability at least 1− βτ . Therefore, these inequalities hold simultaneously with probability at least 1 − β. Using this we derive that inequality

f (xˆτ ) − f (x∗) ≤ 1 f (xˆτ−1) − f (x∗) ≤ 1 f (xˆτ−2) − f (x∗) ≤ . . . ≤ 1 f (x0) − f (x∗)

2

22

2τ

µR2 = 2τ+1

holds with probability ≥ 1 − β. That is, after τ =

log2

µR2 2ε

restarts R-clipped-SGD generates

such point xˆτ that f (xˆτ ) − f (x∗) ≤ ε with probability at least 1 − β. Moreover, if ln N4N0β0τ ≤ Cµ1L with some numerical constant C1 ≥ 320C2, then the total number of iterations of clipped-SGD

equals

L µR2

L µR2

N0τ = O µ ln ε ln µβ ln ε

and the overall number of stochastic ﬁrst-order oracle calls is

τ −1 t

τ −1

2tN02σ2

N0m =

O max N0, R2L2 ln 4N0τ

t=0

t=0

β

τ −1 2tN02σ2

= O max N0τ, R2L2 ln 4N0τ

t=0

β

L µR2 σ2

L µR2

= O max ln

,

ln

ln

.

µ

ε µε

µβ ε

46

G.3.3 Proof of Theorem G.3

Since f is L-smooth we have

k+1

k

k

kk

Lγ2

k k2

f (x

)

≤

f (x ) − γ ∇f (x ), ∇f (x , ξ ) + 2

∇f (x , ξ ) 2

(12)

≤

f (xk) − γ

∇f (xk)

2 2

−

γ

∇f (xk), θk

+ Lγ2

∇f (xk)

2 2

+

Lγ2

θk

2 2

=

f (xk) − γ(1 − Lγ)

∇f (xk)

2 2

−

γ

∇f (xk), θk

+ Lγ2

θk

2 2

≤ f (xk) − γ2 ∇f (xk) 22 − γ ∇f (xk), θk + Lγ2 θk 22,

θk d=ef ∇f (xk, ξk) − ∇f (xk)

(113)

where in the last inequality we use 1 − γL ≥ 21 . Next, µ-strong convexity of f implies

∇f (xk)

2 2

≥

2µ(f (xk) − f (x∗)) and

f (xk+1) − f (x∗))

≤

f (xk) − f (x∗) − γµ(f (xk) − f (x∗)) − γ

∇f (xk), θk

+ Lγ2

θk

2 2

= (1 − γµ)(f (xk) − f (x∗)) − γ ∇f (xk), θk + Lγ2 θk 22.

Unrolling the recurrence we obtain

N −1
f (xN ) − f (x∗)) ≤ (1 − γµ)N (f (x0) − f (x∗)) + γ (1 − γµ)N−1−l −∇f (xl), θl

l=0

N −1
+Lγ2 (1 − γµ)N−1−l θl 22,

(114)

l=0

for all N ≥ 0. Using notation rk d=ef f (xk) − f (x∗) we rewrite this inequality in the following form:

k−1
rk ≤ (1 − γµ)kr0 + γ (1 − γµ)k−1−l
l=0

−∇f (xl), θl

k−1
+ Lγ2 (1 − γµ)k−1−l θl 22.
l=0

(115)

The rest of the proof is based on the reﬁned analysis of inequality (115). In particular, via induction we prove that for all k = 0, 1, . . . , N with probability at least 1 − kNβ the following statement holds: inequalities

(115)

t−1

t−1

rt ≤ (1 − γµ)tr0 + γ

(1 − γµ)t−1−l −∇f (xl), θl + Lγ2

(1 − γµ)t−1−l

θl

2 2

l=0

l=0

≤ 2(1 − γµ)tr0

(116)

hold for t = 0, 1, . . . , k simultaneously. Let us deﬁne the probability event when this statement

holds

as

Ek .

Then,

our

goal

is

to

show

that

P{Ek }

≥

1

−

kβ N

for

all

k

=

0, 1, . . . , N .

For

t

=

0

inequality (116) holds with probability 1 since 2(1 − γµ)0 ≥ 1, hence P{E0} = 1. Next, assume

that for some k = T − 1 ≤ N − 1 we have P{Ek} = P{ET −1} ≥ 1 − (T −N1)β . Let us prove that

P{ET

}

≥

1

−

Tβ N

.

First

of

all,

probability

event

ET −1

implies

that

(116)
f (xt) − f (x∗) ≤ 2(1 − γµ)tr0

(117)

hold for t = 0, 1, . . . , T − 1. Since f is L-smooth, we have that probability event ET −1 implies

∇f (xl) 2 ≤ for t = 0, . . . , T − 1 and

2L(f (xl) − f (x∗)) ≤

4L(1 − γµ)lr0 = λl 2

(118)

λl = 4 L(1 − γµ)lr0.

(119)

47

Having inequalities (118) in hand we show in the rest of the proof that (116) holds for t = T with big enough probability. First of all, we introduce new random variables:

ζl = −0,∇f (xl+1), iofthe∇rwf i(sxel,+1) 2 ≤ λ2l ,

(120)

for l = 0, 1, . . . T − 1. Note that these random variables are bounded with probability 1, i.e. with

probability 1 we have

ζl 2 ≤ λl . 2

(121)

Secondly, we use the introduced notation and get that ET −1 implies

(115),(116),(118),(120)

T −1

rT

≤

(1 − γµ)T r0 + γ (1 − γµ)T −1−l ζl, θl

l=0

T −1
+Lγ2 (1 − γµ)T −1−l θl 22.

l=0

Finally, we do some preliminaries in order to apply Bernstein’s inequality (see Lemma D.1) and obtain that ET −1 implies

(12)

T −1

T −1

rT ≤ (1 − γµ)T r0 + γ

(1 − γµ)T −1−l

θ

u l

,

ζl

+γ

(1 − γµ)T −1−l

θ

b l

,

ζl

l=0

l=0

x

y

T −1
+ 2Lγ2 (1 − γµ)T −1−l

θlu

2 2

−

Eξl

θlu

2 2

l=0

z

T −1

+ 2Lγ2

(1

−

γ

µ)T

−1−l
Eξl

l=0

T −1

θlu

2 2

+ 2Lγ2

(1 − γµ)T −1−l

θlb

2 2

l=0

(122)

{

|

where we introduce new notations:

θlu d=ef ∇f (xl, ξl) − Eξl ∇f (xl, ξl) , θlb d=ef Eξl ∇f (xl, ξl) − ∇f (xl),

(123)

θl = θlu + θlb.

It remains to provide tight upper bounds for x, y, z, { and |, i.e. in the remaining part of the proof we show that x + y + z + { + | ≤ (1 − γµ)T r0.

Upper

bound

for

x.

First

of

all,

since

Eξ

l

[θ

u l

]

=

0

summands

in

x

are

conditionally

unbiased:

Eξl

γ(1 − γµ)T −1−l

θ

u l

,

ζl

= 0.

Secondly, these summands are bounded with probability 1:

γ(1 − γµ)T −1−l

θ

u l

,

ζl

≤
(38),(121)
≤

γ(1 − γµ)T −1−l θlu 2 ζl 2 γ(1 − γµ)T −1−lλ2l (1=19) 16γLr0(1 − γµ)T −1.

Finally, one can bound conditional variances σl2 d=ef Eξl

γ2(1 − γµ)2(T −1−l)

θ

u l

,

ζl

2

in the fol-

lowing way:

2

2

2(T −1−l) u 2

2 (121) 2

2(T −1−l) λ2

σl ≤ Eξl γ (1 − γµ)

θl 2, ζl 2 ≤ γ (1 − γµ)

4 Eξl

(119)

≤

4γ

2Lr0(1

−

γ

µ)2(T

−1)−l
Eξl

θlu

2 2

.

θlu

2 2

(124)

48

In other words, sequence

γ(1 − γµ)T −1−l

θ

u l

,

ζl

l≥0 is a bounded martingale difference sequence

with bounded conditional variances {σl2}l≥0. Therefore, we can apply Bernstein’s inequality, i.e. we apply Lemma D.1 with Xl = γ(1 − γµ)T −1−l θlu, ζl , c = 16γLr0(1 − γµ)T −1 and F = c2 ln6 4βN and get that for all b > 0

T −1

T −1

P

Xl > b and σl2 ≤ F ≤ 2 exp

l=0

l=0

or, equivalently, with probability at least 1 − 2 exp − 2F +b22cb/3

b2 −
2F + 2cb/3

T −1
either σl2 > F or
l=0

T −1
Xl
l=0

≤ b.

|x|

The choice of F will be clariﬁed further, let us now choose b in such a way that 2 exp − 2F +b22cb/3 = 2βN . This implies that b is the positive root of the quadratic equation

b2 − 2c ln 4βN b − 2F ln 4N = 0,

3

β

hence

b = c ln 4βN + 3

c2 ln2 4βN

4N c ln 4βN

+ 2F ln =

+

9

β

3

=

4N c ln

= 16γLr0(1 − γµ)T −1 ln 4N .

β

β

4c2 ln2 4βN 9

That is, with probability at least 1 − 2βN

T −1

4N

either σl2 > F or |x| ≤ 16γLr0(1 − γµ)T −1 ln .

β

l=0

probability event Ex

Next, we notice that probability event ET −1 implies that

T −1

(124)

T −1

σl2 ≤ 4γ2Lr0σ2(1 − γµ)2(T −1) Eξl

l=0

l=0

θlu

2 2

(41)

T −1

1

≤ 72γ2Lr0σ2(1 − γµ)2(T −1)

ml(1 − γµ)l

l=0

(96) 128 2 2 2

2(T −1) 4N c2 ln 4βN

≤ 3 γ L r0(1 − γµ)

ln =

= F,

β

6

where the last inequality follows from c = 16γLr0(1 − γµ)T −1 and simple arithmetic.

Upper bound for y. First of all, we notice that probability event ET −1 implies

γ(1 − γµ)T −1−l

θ

b l

,

ζl

≤
(39),(121)
≤
=
(=96)

γ(1 − γµ)T −1−l θlb 2 ζl 2 γ(1 − γµ)T −1−l 4σ2 λl
mlλl 2 2σ2γ(1 − γµ)T −1−lσ2

ml

64

γLr0(1

−

γµ)T −1

ln

4N β

.

27

N

49

This implies that y=

T −1
γ(1 − γµ)T −1−l
l=0

θ

b l

,

ζl

T ≤N
≤

64 γLr0(1 − γµ)T −1 ln 4N .

27

β

Upper bound for z. We derive the upper bound for z using the same technique as for x. First of all, we notice that the summands in z are conditionally independent:

Eξl 2Lγ2(1 − γµ)T −1−l

θlu

2 2

−

Eξl

θlu

2 2

= 0.

Secondly, the summands are bounded with probability 1:

2Lγ2(1 − γµ)T −1−l

θlu

2 2

−

Eξl

θlu

2 2

≤

2Lγ2(1 − γµ)T −1−l

θlu

2 2

+

Eξl

θlu

2 2

(38)
≤ 2Lγ2(1 − γµ)T −1−l 4λ2l + 4λ2l (1=19) 256γ2L2r0(1 − γµ)T −1 d=ef c1.

(125)

Finally, one can bound conditional variances σˆl2 d=ef Eξl 2Lγ2(1 − γµ)T −1−l

θlu

2 2

−

Eξl

θlu

2 2

2

in the following way:

(125)

σˆl2

≤

c1Eξl 2Lγ2(1 − γµ)T −1−l

θlu

2 2

−

Eξl

θlu

2 2

≤

2Lγ2(1 − γµ)T −1−lc1Eξl

θlu

2 2

+

Eξl

θlu

2 2

=

4Lγ2(1 − γµ)T −1−lc1Eξl

θlu

2 2

.

(126)

In other words, sequence 2Lγ2(1 − γµ)T −1−l

θlu

2 2

−

Eξl

θlu

2 2

l≥0 is a bounded mar-

tingale difference sequence with bounded conditional variances {σˆl2}l≥0. Therefore, we can apply Bernstein’s inequality, i.e. we apply Lemma D.1 with Xl = Xˆl = 2Lγ2(1 −

γµ)T −1−l

θlu

2 2

−

Eξl

and get that for all b > 0

θlu

2 2

, c = c1 = 256γ2L2r0(1 − γµ)T −1 and F = F1 = c21 ln6 4βN

T −1

T −1

P

Xˆ > b and σˆ2 ≤ F

≤ 2 exp −

b2

l

l

1

2F1 + 2c1b/3

l=0

l=0

or, equivalently, with probability at least 1 − 2 exp − 2F1+b22c1b/3

T −1
either σˆl2 > F1 or
l=0

T −1
Xˆl ≤ b.
l=0

|z|

As in our derivations of the upper bound for x we choose such b that 2 exp − 2F1+b22c1b/3 i.e.

= 2βN ,

c1

ln

4N β

b=

+

3

c21 ln2 4βN + 2F1 ln 4N = c1 ln 4N = 256γ2L2r0(1 − γµ)T −1 ln 4N .

9

β

β

β

That is, with probability at least 1 − 2βN

T −1

4N

either σˆl2 > F1 or |z| ≤ 256γ2L2r0(1 − γµ)T −1 ln .

β

l=0

probability event Ez

Next, we notice that probability event ET −1 implies that

T −1

(126)

T −1

1

σˆl2 ≤ 4Lγ2(1 − γµ)T −1c1 (1 − γµ)l Eξl

l=0

l=0

θlu

2 2

(41)

T −1

1

≤ 72Lγ2(1 − γµ)T −1c1σ2

1 (96),T ≤N ≤

(1 − γµ)l ml

l=0

c21

ln

4N β

6

= F1.

50

Upper bound for {. The probability event ET −1 implies

T −1

(41)

T −1 1 18σ2

{ = 2Lγ2 l=0 (1 − γµ)T −1−lEξl θlu 22 ≤ 2Lγ2(1 − γµ)T −1 l=0 (1 − γµ)l ml

(96),T ≤N
≤

64 γ2L2r0(1 − γµ)T −1 ln 4N .

3

β

Upper bound for |. Again, we use corollaries of probability event ET −1:

T −1

(39)

T −1

1

16σ4

|

=

2Lγ2

(1 − γµ)T −1−l

θlb

2 2

≤

2Lγ2(1 − γµ)T −1

(1 − γµ)l m2λ2

l=0

l=0

ll

(119=),(96)
T ≤N
≤

512 2 2

T −1 2 4N T −1 1

729 γ L r0(1 − γµ) ln β

N2

l=0

512

γ2L2r0(1

−

γµ)T −1

ln2

4N β

.

729

N

Now we summarize all bounds that we have: probability event ET −1 implies

(115)

T −1

T −1

rT ≤ (1 − γµ)T r0 + γ

(1 − γµ)T −1−l −∇f (xl), θl + Lγ2

(1 − γµ)T −1−l

θl

2 2

l=0

l=0

(122)
≤ (1 − γµ)T r0 + x + y + z + { + |,

y ≤ 32 γLr0(1 − γµ)T −1 ln 4N , { ≤ 64 γ2L2r0(1 − γµ)T −1 ln 4N ,

27

β

3

β

512

γ2L2r0(1

−

γµ)T −1

ln2

4N β

T −1 2

T −1 2

| ≤ 729

N

,

σl ≤ F,

σˆl ≤ F1

l=0

l=0

and where

(T − 1)β

β

β

P{ET −1} ≥ 1 − N , P{Ex} ≥ 1 − 2N , P{Ez} ≥ 1 − 2N ,

Ex = Ez =

T −1

4N

either σl2 > F or |x| ≤ 16γLr0(1 − γµ)T −1 ln

,

β

l=0

T −1

4N

either σˆl2 > F1 or |z| ≤ 256γ2L2r0(1 − γµ)T −1 ln

.

β

l=0

Taking into account these inequalities and our assumptions on mk and γ (see (96) and (97)) we get that probability event ET −1 ∩ Ex ∩ Ez implies

(115)

T −1

T −1

rT ≤ (1 − γµ)T r0 + γ

(1 − γµ)T −1−l −∇f (xl), θl + Lγ2

(1 − γµ)T −1−l

θl

2 2

l=0

l=0

≤

(1 − γµ)T r0 +

11111 ++++

(1 − γµ)T r0 = 2(1 − γµ)T r0.

55555

(127)

Moreover, using union bound we derive

P {ET −1 ∩ Ex ∩ Ez} = 1 − P ET −1 ∪ Ex ∪ Ez That is, by deﬁnition of ET and ET −1 we have proved that

Tβ ≥1− .
N

(128)

(127)

(128)

Tβ

P{ET } ≥ P {ET −1 ∩ Ex ∩ Ez} ≥ 1 − N ,

51

which implies that for all k = 0, 1, . . . , N we have P{Ek} ≥ 1 − kNβ . Then, for k = N we have that with probability at least 1 − β

(114)

N −1

f (xN ) − f (x∗)) ≤ (1 − γµ)N (f (x0) − f (x∗)) + γ (1 − γµ)N−1−l −∇f (xl), θl

l=0

N −1

(116)

+Lγ2

(1 − γµ)N−1−l

θl

2 2

≤

2(1 − γµ)N (f (x0) − f (x∗))(1. 29)

l=0

As a result, we get that with probability at least 1 − β

f (xN ) − f (x∗) ≤ 2(1 − γµ)N (f (x0) − f (x∗)) ≤ 2 exp (−γµN ) (f (x0) − f (x∗))

(97)

µN

≤ 2 exp − 80L ln 4N

β

(f (x0) − f (x∗)).

In other words, clipped-SGD achieves f (xN ) − f (x∗) ≤ ε with probability at least 1 − β after

O L ln r0 ln L ln r0

µε

µβ ε

iterations, where r0 = f (x0) − f (x∗) and requires

N −1

N −1 (96)

N σ2

k=0 mk = k=0 O max 1, Lr0(1 − γµ)k ln 4βN

(97)

N σ2

= O max N, µr0(1 − γµ)N−1

N σ2 = O max N,
µε

= O max L , σ2 · L ln r0 ln L ln r0 .

µ µε µ

ε

µβ ε

oracle calls.

52

H Extra Experiments

H.1 Detailed Description of Experiments from Section 1.2

In this section we provide a detailed description of experiments from Section 1.2 together with additional experiments. In these experiments we consider the following problem:

min f (x), f (x) = x 22/2 = Eξ [f (x, ξ)] , f (x, ξ) = x 22/2 + ξ, x
x∈Rn

(130)

where ξ is a random vector with zero mean and bounded variance. Clearly, f (x) is µ-strongly convex

and L-smooth with µ = L = 1. We assume that E

ξ

2 2

≤ σ2 for some non-negative number

σ. Then, the stochastic gradient ∇f (x, ξ) = x + ξ satisﬁes conditions (2) and the state-of-the-art

theory (e.g. [24, 25]) says that after k iterations of SGD with constant stepsize γ ≤ 1/L = 1 we have

E

xk − x∗

2 2

≤ (1 − γµ)k

x0 − x∗

2 2

+

γσ2/µ.

Taking

into

account

that

for

our

problem

x∗

=

0,

f (x) = 12 x 22, f (x∗) = 0 and µ = 1 we derive

E f (xk) − f (x∗) ≤ (1 − γ)k f (x0) − f (x∗) + γσ2/2.

(131)

That is, for given k the r.h.s. of the formula above depends only on the stepsize γ, initial suboptimality f (x0) − f (x∗) and the variance σ.

We emphasize that the obtained bound and the convergence in expectation itself does not imply non-trivial upper bound for f (xk) − f (x∗) with high-probability without additional assumptions
on the distribution of random vector ξ. In fact, the trajectory of SGD signiﬁcantly depends on the
distribution of ξ. To illustrate this we consider 3 different distributions of ξ with the same σ.

1. In the ﬁrst case we consider ξ from standard normal distribution, i.e. ξ is a Gaussian random vector with zero mean and covariance matrix I. Clearly, in this situation σ2 = n.

2. Next, we consider a random vector ξ with i.i.d. components having Weibull distribution [69]. The cumulative distribution function (CDF) for Weibull distribution with parameters c > 0 and α > 0 is

1 − exp − x c , if x ≥ 0,

CDFW (x) =

α

0,

if x < 0.

(132)

There are explicit formulas for mean and variance for Weibull distribution:

mean = αΓ 1 + 1 , variance = α2 Γ 1 + 2 − Γ 1 + 1 2 ,

c

c

c

where Γ denotes the gamma function. Having these formulas one can easily shift and scale the distribution in order to get a random variable with zero mean and the variance equal 1.
In our experiments, we take c = 0.2,

1

α=

,

Γ 1 + 2c − Γ 1 + 1c 2

shift the distribution by −αΓ 1 + 1c and sample from the obtained distribution n i.i.d. random variables to form ξ. Such a choice of parameters implies that E[ξ] = 0 and E[ ξ 22] = n.
3. Finally, we consider a random vector ξ with i.i.d. components having Burr Type XII
distribution [3] having the following cumulative distribution function

1 − (1 + xc)−d , if x > 0,

CDFB(x) = 0,

if x ≤ 0,

(133)

where c > 0 and d > 0 are the positive parameters. There are explicit formulas for mean and variance for Burr distribution:
mean = µ1, variance = −µ21 + µ2,

53

where the r-th moment (if exists) is deﬁned as follows [42]:

cd − r c + r

µr = dB

,

,

c

c

where B denotes the beta function.
In our experiments, we take c = 1 and d = 2.3 and then apply shifts and scales similarly to the case with Weibull distribution. Again, such a choice of parameters implies that E[ξ] = 0 and E[ ξ 22] = n.

For all experiments we considered the dimension n = 100, the stepsize γ = 0.001 and for clipped-SGD we set λ = 100. The result of 10 independent runs of SGD and clipped-SGD are presented in Figures 6-10. These numerical tests show that for Weibull and Burr Type XII distributions SGD have signiﬁcantly larger oscillations than for Gaussian distribution in all 10 tests. In contrast, clipped-SGD behaves much more robust in all 3 cases during all 10 runs without signiﬁcant oscillations.

100 10−1

Gaussian tails, f(x0) − f(x * ) = 2.87 SGD

100 10−1

Weibull tails, f(x0) − f(x * ) = 2.87 SGD

Burr Type XII tails, f(x0) − f(x * ) = 2.87

100

SGD

10−1

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Gaussian tails, f(x0) − f(x * ) = 2.87 clipped-SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Gaussian tails, f(x0) − f(x * ) = 2.87 SGD

10−1

10−2

10−3

0

20000 40000 60000 80000 100000

Number of iterations

Gaussian tails, f(x0) − f(x * ) = 2.87

100

clipped-SGD

10−1

10−2

10−3 0

20000 40000 60000 80000 100000 Number of iterations

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Weibull tails, f(x0) − f(x * ) = 2.87 clipped-SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Weibull tails, f(x0) − f(x * ) = 2.87 SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 Number of iterations
Weibull tails, f(x0) − f(x * ) = 2.87

100000

clipped-SGD

10−1

10−2

10−3 0

20000 40000 60000 80000 100000 Number of iterations

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Burr XII tails, f(x0) − f(x * ) = 2.87 clipped-SGD

10−1

10−2

10−3

0

20000 40000 60000 80000 100000

Number of iterations

Burr Type XII tails, f(x0) − f(x * ) = 2.87

100

SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 Number of iterations
Burr XII tails, f(x0) − f(x * ) = 2.87

100000

clipped-SGD

10−1

10−2

10−3 0

20000 40000 60000 80000 100000 Number of iterations

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

Figure 6: 2 independent runs of SGD (blue) and clipped-SGD (red) applied to solve (130) with ξ having Gaussian (left column), Weibull (central column) and Burr Type XII (right column) tails.

H.2 Additional Details and Experiments with Logistic Regression

In this section, we provide additional details of the experiments presented in Section 4 together with extra numerical results. In particular, we consider the logistic regression problem:

1r

min f (x) =

log (1 + exp (−yi · (Ax)i))

x∈Rn

r

i=1

fi (x)

(134)

54

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

100 10−1

Gaussian tails, f(x0) − f(x * ) = 2.87 SGD

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Gaussian tails, f(x0) − f(x * ) = 2.87 clipped-SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Gaussian tails, f(x0) − f(x * ) = 2.87 SGD

10−1

10−2

10−3

0

20000 40000 60000 80000 100000

Number of iterations

Gaussian tails, f(x0) − f(x * ) = 2.87

100

clipped-SGD

10−1

10−2

10−3 0

20000 40000 60000 80000 100000 Number of iterations

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

100 10−1

Weibull tails, f(x0) − f(x * ) = 2.87 SGD

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Weibull tails, f(x0) − f(x * ) = 2.87 clipped-SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Weibull tails, f(x0) − f(x * ) = 2.87 SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 Number of iterations
Weibull tails, f(x0) − f(x * ) = 2.87

100000

clipped-SGD

10−1

10−2

10−3 0

20000 40000 60000 80000 100000 Number of iterations

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

Burr Type XII tails, f(x0) − f(x * ) = 2.87

100

SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Burr XII tails, f(x0) − f(x * ) = 2.87 clipped-SGD

10−1

10−2

10−3

0

20000 40000 60000 80000 100000

Number of iterations

Burr Type XII tails, f(x0) − f(x * ) = 2.87

100

SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 Number of iterations
Burr XII tails, f(x0) − f(x * ) = 2.87

100000

clipped-SGD

10−1

10−2

10−3 0

20000 40000 60000 80000 100000 Number of iterations

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

Figure 7: 2 independent runs of SGD (blue) and clipped-SGD (red) applied to solve (130) with ξ having Gaussian (left column), Weibull (central column) and Burr Type XII (right column) tails.

where A ∈ Rr×n is matrix of instances and y ∈ {0, 1}r is vector of labels. It is well-known that
f (x) from (134) is convex and L-smooth with L = λmax(A A)/4r where λmax(A A) denotes the maximal eigenvalue of A A. One can consider problem (134) as a special case of (1) where ξ is a random index uniformly distributed on {1, . . . , r} and f (x, ξ) = fξ(x). We take the datasets from LIBSVM library [4]: see Table 3 with the summary of the datasets we used.

Size Dimension

Table 3: Summary of used datasets.

heart 270 13

diabetes 768 8

australian 690 13

a9a 32561
123

w8a 49749 300

We notice that in all experiments that we did with logistic regression the initial suboptimality f (x0) − f (x∗) was of order 10. Moreover, as it was mentioned in the main part of the paper the parameters for the methods were tuned. One can ﬁnd parameters that we used in the experiments from Section 4 in Table 4.
Next, we provide our numerical study of the distribution of ∇fi(xk) − ∇f (xk) 2, where xk is the last iterate produced by SGD in experiments presented in Section 4, see Figure 11. As we mentioned in the main part of the paper these histograms are very similar to ones presented in Figure 2, so, the insights that we got from Figure 2 are right. However, in our experiments with australian dataset SGD with the stepsize γ = 1/L did not reach needed suboptimality in order to oscillate.
Therefore, we run SGD along with its clipped variants with the same batchsize m = 50 for bigger number of epochs and also tuned their parameters. One can ﬁnd the results of these runs in Figure 12.

55

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

100 10−1

Gaussian tails, f(x0) − f(x * ) = 2.87 SGD

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Gaussian tails, f(x0) − f(x * ) = 2.87 clipped-SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Gaussian tails, f(x0) − f(x * ) = 2.87 SGD

10−1

10−2

10−3

0

20000 40000 60000 80000 100000

Number of iterations

Gaussian tails, f(x0) − f(x * ) = 2.87

100

clipped-SGD

10−1

10−2

10−3 0

20000 40000 60000 80000 100000 Number of iterations

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

100 10−1

Weibull tails, f(x0) − f(x * ) = 2.87 SGD

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Weibull tails, f(x0) − f(x * ) = 2.87 clipped-SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Weibull tails, f(x0) − f(x * ) = 2.87 SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 Number of iterations
Weibull tails, f(x0) − f(x * ) = 2.87

100000

clipped-SGD

10−1

10−2

10−3 0

20000 40000 60000 80000 100000 Number of iterations

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

Burr Type XII tails, f(x0) − f(x * ) = 2.87

100

SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Burr XII tails, f(x0) − f(x * ) = 2.87 clipped-SGD

10−1

10−2

10−3

0

20000 40000 60000 80000 100000

Number of iterations

Burr Type XII tails, f(x0) − f(x * ) = 2.87

100

SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 Number of iterations
Burr XII tails, f(x0) − f(x * ) = 2.87

100000

clipped-SGD

10−1

10−2

10−3 0

20000 40000 60000 80000 100000 Number of iterations

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

Figure 8: 2 independent runs of SGD (blue) and clipped-SGD (red) applied to solve (130) with ξ having Gaussian (left column), Weibull (central column) and Burr Type XII (right column) tails.

Table 4: Parameters that are used to produce plots presented in Figures 3-5. In the ﬁrst contains the name of the dataset and the batchsize m that was used for all methods tested on the dataset. For d-clipped-SGD λ0 is an initial clipping level, l is a period (in terms of epochs) of decreasing the clipping level and α is a coefﬁcient of decrease, i.e. every l epochs the clipping level is multiplied by α. For SSTM parameter a was picked the same as for clipped-SSTM in order to emphasize the effect of clipping.

heart m = 20
diabetes m = 100
australian m = 50
a9a m = 100
w8a m = 1000

SGD γ = 21L γ = 101L γ = L1 γ = 21L γ = L1

clipped-SGD

γ

=

1 2L

,

λ

=

2.72

γ

=

1 10L

,

λ

=

68.86

γ

=

1 L

,

λ

=

74.47

γ

=

1 2L

,

λ

=

0.025

γ

=

1 L

,

λ

=

1.3

d-clipped-SGD

γ

=

1 2L

,

λ0

=

2.72,

l = 103, α = 0.9

γ

=

1 10L

,

λ0

=

68.86,

l = 103, α = 0.7

γ

=

1 L

,

λ0

=

74.47,

l = 1000, α = 0.9

γ

=

1 L

,

λ0

=

4.9,

l = 5, α = 0.5

γ

=

1 L

,

λ0

=

64.78,

l = 50, α = 0.9

SSTM a = 104 a = 5 · 103 a = 103
a=1 a=1

clipped-SSTM a = 104,
B = 2 · 10−4 a = 5 · 103, B = 7 · 10−4 a = 5 · 103, B = 2 · 10−4
a = 1, B = 3 · 10−2
a = 1, B = 19 · 10−2

We see that SGD with this stepsize achieves better suboptimality but it also oscillates signiﬁcantly more. In contrast, clipped-SGD and d-clipped-SGD do not have signiﬁcant oscillations and converge with the same rate as SGD. Moreover, clipped-SSTM shows slightly better performance in this case. Finally, we numerically studied the distribution of ∇fi(xk) − ∇f (xk) 2, where xk is the last iterate produced by SGD, see Figure 13. These histograms imply that the noise in stochastic gradients is heavy-tailed and explain an unstable behavior of SGD in this case.
56

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

100 10−1

Gaussian tails, f(x0) − f(x * ) = 2.87 SGD

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Gaussian tails, f(x0) − f(x * ) = 2.87 clipped-SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Gaussian tails, f(x0) − f(x * ) = 2.87 SGD

10−1

10−2

10−3

0

20000 40000 60000 80000 100000

Number of iterations

Gaussian tails, f(x0) − f(x * ) = 2.87

100

clipped-SGD

10−1

10−2

10−3 0

20000 40000 60000 80000 100000 Number of iterations

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

100 10−1

Weibull tails, f(x0) − f(x * ) = 2.87 SGD

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Weibull tails, f(x0) − f(x * ) = 2.87 clipped-SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Weibull tails, f(x0) − f(x * ) = 2.87 SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 Number of iterations
Weibull tails, f(x0) − f(x * ) = 2.87

100000

clipped-SGD

10−1

10−2

10−3 0

20000 40000 60000 80000 100000 Number of iterations

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

Burr Type XII tails, f(x0) − f(x * ) = 2.87

100

SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Burr XII tails, f(x0) − f(x * ) = 2.87 clipped-SGD

10−1

10−2

10−3

0

20000 40000 60000 80000 100000

Number of iterations

Burr Type XII tails, f(x0) − f(x * ) = 2.87

100

SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 Number of iterations
Burr XII tails, f(x0) − f(x * ) = 2.87

100000

clipped-SGD

10−1

10−2

10−3 0

20000 40000 60000 80000 100000 Number of iterations

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

Figure 9: 2 independent runs of SGD (blue) and clipped-SGD (red) applied to solve (130) with ξ having Gaussian (left column), Weibull (central column) and Burr Type XII (right column) tails.

Finally, we conducted experiments on larger datasets: a9a and w8a. The results of our numerical test are reported on Figures 14 and 15. We notice that SSTM with given stepsize and batchsize suffers from noise accumulation, while clipped-SSTM does not have this drawback and shows comparable performance with SGD on a9a and much better performance on w8a.
Figure 15 shows the gradient’s noise distributions for both datasets. While the distribution of stochastic gradients at the optimum for a9a have sub-Gaussian-like distribution, for w8a they have heavy-tailed distribution.

57

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

100 10−1

Gaussian tails, f(x0) − f(x * ) = 2.87 SGD

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Gaussian tails, f(x0) − f(x * ) = 2.87 clipped-SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Gaussian tails, f(x0) − f(x * ) = 2.87 SGD

10−1

10−2

10−3

0

20000 40000 60000 80000 100000

Number of iterations

Gaussian tails, f(x0) − f(x * ) = 2.87

100

clipped-SGD

10−1

10−2

10−3 0

20000 40000 60000 80000 100000 Number of iterations

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

100 10−1

Weibull tails, f(x0) − f(x * ) = 2.87 SGD

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Weibull tails, f(x0) − f(x * ) = 2.87 clipped-SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Weibull tails, f(x0) − f(x * ) = 2.87 SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 Number of iterations
Weibull tails, f(x0) − f(x * ) = 2.87

100000

clipped-SGD

10−1

10−2

10−3 0

20000 40000 60000 80000 100000 Number of iterations

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

Burr Type XII tails, f(x0) − f(x * ) = 2.87

100

SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 100000 Number of iterations
Burr XII tails, f(x0) − f(x * ) = 2.87 clipped-SGD

10−1

10−2

10−3

0

20000 40000 60000 80000 100000

Number of iterations

Burr Type XII tails, f(x0) − f(x * ) = 2.87

100

SGD

10−1

10−2

10−3 0
100

20000 40000 60000 80000 Number of iterations
Burr XII tails, f(x0) − f(x * ) = 2.87

100000

clipped-SGD

10−1

10−2

10−3 0

20000 40000 60000 80000 100000 Number of iterations

f(xk) − f(x * ) f(x0) − f(x * )

f(xk) − f(x * ) f(x0) − f(x * )

Figure 10: 2 independent runs of SGD (blue) and clipped-SGD (red) applied to solve (130) with ξ having Gaussian (left column), Weibull (central column) and Burr Type XII (right column) tails.

Density

10−2

heart, real samples

10−3

10−4

10−2

0 50 100 150 200 250 300 350 400
Noise norm heart, synthetic Gaussian samples

10−3

10−4 0 50 100 150 200 250 300 350 400
Noise norm

Density

Density

10−2

diabetes, real samples

10−4

10−6

10−8

10−10
0 100 200 300 400 500 600 700
Noise norm 10−2 diabetes, synthetic Gaussian samples

10−4

10−6

10−8

10−10

0 100 200 300 400 500 600 700
Noise norm

Density

Density

10−6 10−16 10−26 10−36 10−46 10−56 10−66 10−76

australian, real samples

0 1000 2000 3000 4000 5000
Noise norm

australian, synthetic Gaussian samples
10−6 10−16 10−26 10−36 10−46 10−56 10−66 10−76

0 1000 2000 3000 4000 5000
Noise norm

Density

Figure 11: Histograms of ∇fi(xk) − ∇f (xk) 2 for different datasets (the ﬁrst row) and synthetic Gaussian samples with mean and variance estimated via empirical mean and variance of real samples
∇f1(xk) − ∇f (xk) 2, . . . , ∇fr(xk) − ∇f (xk) 2 (the second row) where xk is the last point produced by SGD. Red lines correspond to probability density functions of normal distributions with
empirically estimated means and variances.

58

100 10−1 10−2

australian

SGD clipped-SGD d-clipped-SGD clipped-SSTM

f(xk) − f(x * ) f(x0) − f(x * )

10−3

10−4

0

10000

20000

30000

40000

50000

Number of passes through the data

Figure 12: Trajectories of SGD, clipped-SGD, d-clipped-SGD and clipped-SSTM applied to solve logistic regression problem on australian dataset. For SGD and its clipped variants stepsize γ = 2L0 was used. For clipped-SGD we used λ = 18.62 and for d-clipped-SGD the parameters are as
follows: λ0 = 74.47, l = 1500, α = 0.9. Parameters for clipped-SSTM are the same as in the
corresponding cell in Table 4.

Density Density

10−5 10−14 10−23 10−32 10−41 10−50 10−59 10−68
0

australian, real samples

1000 2000 3000
Noise norm

4000

australian, synthetic Gaussian samples
10−5 10−14 10−23 10−32 10−41 10−50 10−59 10−68

0

1000 2000 3000 4000

Noise norm

Figure 13: Histograms of ∇fi(xk) − ∇f (xk) 2 for australian dataset and synthetic Gaus-
sian samples with mean and variance estimated via empirical mean and variance of real samples ∇f1(xk) − ∇f (xk) 2, . . . , ∇fr(xk) − ∇f (xk) 2 where xk is the last point produced by SGD
with γ = 2L0 . Red lines correspond to probability density functions of normal distributions with empirically estimated means and variances.

f(xk) − f(x * ) f(x0) − f(x * ) f(xk) − f(x * ) f(x0) − f(x * )

100 10−1 10−2

a9a

SGD clipped-SGD d-clipped-SGD clipped-SSTM SSTM

10−3

10−4

0

20

40

60

80 100

Number of passes through the data

100 10−1 10−2 10−3 10−4

w8a

SGD clipped-SGD d-clipped-SGD clipped-SSTM SSTM

0

100 200 300 400 500

Number of passes through the data

Figure 14: Trajectories of SGD, clipped-SGD, d-clipped-SGD and clipped-SSTM applied to solve logistic regression problem on a9a and w8a datasets. Parameters of the methods used in experiments are presneted in Table 4.

59

a9a, real samples
101

100 a9a, synthetic Gaussian samples

Density

100 10−1 10−2

Density

10−1 10−2

Density

10−3
0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0
Noise norm
w8a, real samples
10−4 10−26 10−48 10−70 10−92 10−114 10−136 10−158

0

2

4

6

8

Noise norm

Density

10−3

0

1

2

3

4

Noise norm

w8a, synthetic Gaussian samples

10−11 10−32 10−53 10−74 10−95 10−116 10−137 10−158

0

2

4

6

8

Noise norm

Figure 15: Histograms of ∇fi(x∗) 2 for a9a and w8a dataset and synthetic Gaussian sam-
ples with mean and variance estimated via empirical mean and variance of real samples ∇f1(x∗) 2, . . . , ∇fr(x∗) 2. Red lines correspond to probability density functions of normal
distributions with empirically estimated means and variances.

60

