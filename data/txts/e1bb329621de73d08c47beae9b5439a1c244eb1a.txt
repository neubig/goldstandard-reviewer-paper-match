arXiv:2007.08176v2 [cs.LG] 21 Oct 2020

CSI: Novelty Detection via Contrastive Learning on Distributionally Shifted Instances
Jihoon Tack∗†, Sangwoo Mo∗‡, Jongheon Jeong‡, Jinwoo Shin†‡ †Graduate School of AI, KAIST
‡School of Electrical Engineering, KAIST {jihoontack,swmo,jongheonj,jinwoos}@kaist.ac.kr
Abstract
Novelty detection, i.e., identifying whether a given sample is drawn from outside the training distribution, is essential for reliable machine learning. To this end, there have been many attempts at learning a representation well-suited for novelty detection and designing a score based on such representation. In this paper, we propose a simple, yet effective method named contrasting shifted instances (CSI), inspired by the recent success on contrastive learning of visual representations. Speciﬁcally, in addition to contrasting a given sample with other instances as in conventional contrastive learning methods, our training scheme contrasts the sample with distributionally-shifted augmentations of itself. Based on this, we propose a new detection score that is speciﬁc to the proposed training scheme. Our experiments demonstrate the superiority of our method under various novelty detection scenarios, including unlabeled one-class, unlabeled multi-class and labeled multi-class settings, with various image benchmark datasets. Code and pre-trained models are available at https://github.com/alinlab/CSI.
1 Introduction
Out-of-distribution (OOD) detection [26], also referred to as a novelty- or anomaly detection is a task of identifying whether a test input is drawn far from the training distribution (in-distribution) or not. In general, the OOD detection problem aims to detect OOD samples where a detector is allowed to access only to training data. The space of OOD samples is typically huge, i.e., an OOD sample can vary signiﬁcantly and arbitrarily from the given training distribution. Hence, assuming speciﬁc prior knowledge, e.g., external data representing some speciﬁc OODs, may introduce a bias to the detector. The OOD detection is a classic yet essential problem in machine learning, with a broad range of applications, including medical diagnosis [4], fraud detection [53], and autonomous driving [12].
A long line of literature has thus been proposed, including density-based [74, 46, 6, 47, 11, 55, 61, 17], reconstruction-based [58, 76, 9, 54, 52, 7], one-class classiﬁer [59, 56], and self-supervised [15, 25, 2] approaches. Overall, a majority of recent literature is concerned with (a) modeling the representation to better encode normality [23, 25], and (b) deﬁning a new detection score [56, 2]. In particular, recent studies have shown that inductive biases from self-supervised learning signiﬁcantly help to learn discriminative features for OOD detection [15, 25, 2]. Meanwhile, recent progress on self-supervised learning has proven the effectiveness of contrastive learning in various domains, e.g., computer vision [21, 5], audio processing [50], and reinforcement learning [63]. Contrastive learning extracts a strong inductive bias from multiple (similar) views of a sample by let them attract each other, yet repelling them to other samples. Instance discrimination [69]
∗Equal contribution
34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.

is a special type of contrastive learning where the views are restricted up to different augmentations, which have achieved state-of-the-art results on visual representation learning [21, 5].
Inspired by the recent success of instance discrimination, we aim to utilize its power of representation learning for OOD detection. To this end, we investigate the following questions: (a) how to learn a (more) discriminative representation for detecting OODs and (b) how to design a score function utilizing the representation from (a). We remark that the desired representation for OOD detection may differ from that for standard representation learning [23, 25], as the former aims to discriminate in-distribution and OOD samples, while the latter aims to discriminate within in-distribution samples.
We ﬁrst found that existing contrastive learning scheme is already reasonably effective for detecting OOD samples with a proper detection score. We further observe that one can improve its performance by utilizing “hard” augmentations, e.g., rotation, that were known to be harmful and unused for the standard contrastive learning [5]. In particular, while the existing contrastive learning schemes act by pulling all augmented samples toward the original sample, we suggest to additionally push the samples with hard or distribution-shifting augmentations away from the original. We observe that contrasting shifted samples help OOD detection, as the model now learns a new task of discriminating between in- and out-of-distribution, in addition to the original task of discriminating within in-distribution.
Contribution. We propose a simple yet effective method for OOD detection, coined contrasting shifted instances (CSI). Built upon the existing contrastive learning scheme [5], we propose two novel additional components: (a) a new training method which contrasts distributionally-shifted augmentations (of the given sample) in addition to other instances, and (b) a score function which utilizes both the contrastively learned representation and our new training scheme in (a). Finally, we show that CSI enjoys broader usage by applying it to improve the conﬁdence-calibration of the classiﬁers: it relaxes the overconﬁdence issue in their predictions for both in- and out-of-distribution samples while maintaining the classiﬁcation accuracy.
We verify the effectiveness of CSI under various environments of detecting OOD, including unlabeled one-class, unlabeled multi-class, and labeled multi-class settings. To our best knowledge, we are the ﬁrst to demonstrate all three settings under a single framework. Overall, CSI outperforms the baseline methods for all tested datasets. In particular, CSI achieves new state-of-the-art results2 on one-class classiﬁcation, e.g., it improves the mean area under the receiver operating characteristics (AUROC) from 90.1% to 94.3% (+4.2%) for CIFAR-10 [33], 79.8% to 89.6% (+9.8%) for CIFAR-100 [33], and 85.7% to 91.6% (+5.9%) for ImageNet-30 [25] one-class datasets, respectively. We remark that CSI gives a larger improvement in harder (or near-distribution) OOD samples. To verify this, we also release new benchmark datasets: ﬁxed version of the resized LSUN and ImageNet [39].
We remark that learning representation to discriminate in- vs. out-of-distributions is an important but under-explored problem. We believe that our work would guide new interesting directions in the future, for both representation learning and OOD detection.

2 CSI: Contrasting shifted instances
For a given dataset {xm}M m=1 sampled from a data distribution pdata(x) on the data space X , the goal of out-of-distribution (OOD) detection is to model a detector from {xm} that identiﬁes whether x is sampled from the data generating distribution (or in-distribution) pdata(x) or not. As modeling pdata(x) directly is prohibitive in most cases, many existing methods for OOD detection deﬁne a score function s(x) that a high value heuristically represents that x is from in-distribution.

2.1 Contrastive learning

The idea of contrastive learning is to learn an encoder fθ to extract the necessary information to distinguish similar samples from the others. Let x be a query, {x+}, and {x−} be a set of positive and negative samples, respectively, and sim(z, z ) := z · z / z z be the cosine similarity. Then,
the primitive form of the contrastive loss is deﬁned as follows:

1

Lcon(x, {x+}, {x−}) := −

log

x ∈{x+} exp(sim(z(x), z(x ))/τ ) , (1)

|{x+}|

x ∈{x+}∪{x−} exp(sim(z(x), z(x ))/τ )

where |{x+}| denotes the cardinality of the set {x+}, z(x) denotes the output feature of the contrastive layer, and τ denotes a temperature hyper-parameter. One can deﬁne the contrastive feature z(x)

2We do not compare with methods using external OOD samples [24, 57].

2

directly from the encoder fθ, i.e., z(x) = fθ(x) [21], or apply an additional projection layer gφ, i.e., z(x) = gφ(fθ(x)) [5]. We use the projection layer following the recent studies [5, 30].

In this paper, we speciﬁcally consider the simple contrastive learning (SimCLR) [5], a simple and
effective objective based on the task of instance discrimination [69]. Let x˜(i1) and x˜(i2) be two independent augmentations of xi from a pre-deﬁned family T , namely, x˜(1) := T1(xi) and x˜(2) :=
T2(xi), where T1, T2 ∼ T . Then the SimCLR objective can be deﬁned by the contrastive loss (1) where each (x˜(i1), x˜(i2)) and (x˜(i2), x˜(i1)) are considered as query-key pairs while others being negatives. Namely, for a given batch B := {xi}Bi=1, the SimCLR objective is deﬁned as follows:

L

1 (B; T ) :=

B
L

(x˜(1), x˜(2), B˜ ) + L

(x˜(2), x˜(1), B˜ ),

(2)

SimCLR

2B

con i

i

−i

con i

i

−i

i=1

where B˜ := {x˜(i1)}Bi=1 ∪ {x˜(i2)}Bi=1 and B˜−i := {x˜(j1)}j=i ∪ {x˜(j2)}j=i.

2.2 Contrastive learning for distribution-shifting transformations
Chen et al. [5] has performed an extensive study on which family of augmentations T leads to a better representation when used in SimCLR, i.e., which transformations should fθ consider as positives. Overall, the authors report that some of the examined augmentations (e.g., rotation), sometimes degrades the discriminative performance of SimCLR. One of our key ﬁndings is that such augmentations can be useful for OOD detection by considering them as negatives - contrast from the original sample. In this paper, we explore which family of augmentations S, which we call distribution-shifting transformations, or simply shifting transformations, would lead to better representation in terms of OOD detection when used as negatives in SimCLR.
Contrasting shifted instances. We consider a set S consisting of K different (random or deterministic) transformations, including the identity I: namely, we denote S := {S0 = I, S1, . . . , SK−1}. In contrast to the vanilla SimCLR that considers augmented samples as positive to each other, we attempt to consider them as negative if the augmentation is from S. For a given batch of samples B = {xi}Bi=1, this can be done simply by augmenting B via S before putting it into the SimCLR loss deﬁned in (2): namely, we deﬁne contrasting shifted instances (con-SI) loss as follows:

Lcon-SI := LSimCLR

BS; T , where BS := {S(xi)}Bi=1.

(3)

S∈S

Here, our intuition is to regard each distributionally-shifted sample (i.e., S = I) as an OOD with respect to the original. In this respect, con-SI attempts to discriminate an in-distribution (i.e., S = I) sample from other OOD (i.e., S ∈ {S1, . . . , SK−1}) samples. We further verify the effectiveness of con-SI in our experimental results: although con-SI does not improve representation for standard

classiﬁcation, it does improve OOD detection signiﬁcantly (see linear evaluation in Section 3.2).

Classifying shifted instances. In addition to contrasting shifted instances, we consider an auxiliary task that predicts which shifting transformation yS ∈ S is applied for a given input x, in order to

facilitate fθ to discriminate each shifted instance. Speciﬁcally, we add a linear layer to fθ for modeling an auxiliary softmax classiﬁer pcls-SI(yS |x), as in [15, 25, 2]. Let B˜S be the batch augmented from

BS via SimCLR; then, we deﬁne classifying shifted instances (cls-SI) loss as follows:

11 Lcls-SI :=

− log pcls-SI(yS = S | x˜S).

(4)

2B K

S∈S x˜S ∈B˜S

The ﬁnal loss of our proposed method, CSI, is deﬁned by combining the two objectives:

LCSI = Lcon-SI + λ · Lcls-SI

(5)

where λ > 0 is a balancing hyper-parameter. We simply set λ = 1 for all our experiments.

OOD-ness: How to choose the shifting transformation? In principle, we choose the shifting transformation that generates the most OOD-like yet semantically meaningful samples. Intuitively, such samples can be most effective (‘nearby’ but ‘not-too-nearby’) OOD samples, as also discussed in Section 3.2. More speciﬁcally, we measure the OOD-ness of a transformation by the area under the receiver operating characteristics (AUROC) between in-distribution vs. transformed samples under vanilla SimCLR, using the detection score (6) deﬁned in Section 2.3. The transformation with high OOD-ness values (i.e., OOD-like) indeed performs better (see Table 4 and Table 5 in Section 3.2).

3

2.3 Score functions for detecting out-of-distribution

Upon the representation z(·) learned by our proposed training objective, we deﬁne several score functions for detecting out-of-distribution; whether a given x is OOD or not. We ﬁrst propose a detection score that is applicable to any contrastive representation. We then introduce how one could incorporate additional information learned by contrasting (and classifying) shifted instances as in (5).

Detection score for contrastive representation. Overall, we ﬁnd that two features from SimCLR representations are surprisingly effective for detecting OOD samples: (a) the cosine similarity to the nearest training sample in {xm}, i.e., maxm sim(z(xm), z(x)), and (b) the norm of the representation, i.e., z(x) . Intuitively, the contrastive loss increases the norm of in-distribution samples, as it is an easy way to minimize the cosine similarity of identical samples by increasing the denominator of (1). We discuss further detailed analysis of both features in Appendix H. We simply combine these features to deﬁne a detection score scon for contrastive representation:

scon(x; {xm}) := max sim(z(xm), z(x)) · z(x) .

(6)

m

We also discuss how one can reduce the computation and memory cost by choosing a proper subset (i.e., coreset) of training samples in Appendix E.

Utilizing shifting transformations. Given that our proposed LCSI is used for training, one can further improve the detection score scon signiﬁcantly by incorporating shifting transformations S. Here, we propose two additional scores, scon-SI and scls-SI, where are corresponded to Lcon-SI (3) and Lcls-SI (4), respectively.

Firstly, we deﬁne scon-SI by taking an expectation of scon over S ∈ S:

scon-SI(x; {xm}) := λcSon scon(S(x); {S(xm)}),

(7)

S∈S

where λcSon := M/ m scon(S(xm); {S(xm)}) = M/ m z(S(xm)) for M training samples is a balancing term to scale the scores of each shifting transformation (See Appendix F for details).

Secondly, we deﬁne scls-SI utilizing the auxiliary classiﬁer p(yS |x) upon fθ as follows:

scls-SI(x) := λcSls WS fθ(S(x)),

(8)

S∈S

where λcSls := M/ m[WSfθ(S(xm))] are again balancing terms similarly to above, and WS is the weight vector in the linear layer of p(yS |x) per S ∈ S.

Finally, the combined score for CSI representation is deﬁned as follows:

sCSI(x; {xm}) := scon-SI(x; {xm}) + scls-SI(x).

(9)

Ensembling over random augmentations. In addition, we ﬁnd one can further improve each of the proposed scores by ensembling it over random augmentations T (x) where T ∼ T . Namely, for instance, the ensembled CSI score is deﬁned by sCSI-ens(x) := ET ∼T [sCSI(T (x))]. Unless otherwise noted, we use these ensembled versions of (6) to (9) in our experiments. See Appendix D for details.

2.4 Extension for training conﬁdence-calibrated classiﬁers

Furthermore, we propose an extension of CSI for training conﬁdence-calibrated classiﬁers [22, 37]
from a given labeled dataset {(xm, ym)}m ⊆ X × Y by adapting it to supervised contrastive learning (SupCLR) [30]. Here, the goal is to model a classiﬁer p(y|x) that is (a) accurate on predicting y
when x is in-distribution, and (b) the conﬁdence ssup(x) := maxy p(y|x) [22] of the classiﬁer is well-calibrated, i.e., ssup(x) should be low if x is an OOD sample or arg maxy p(y|x) = true label.

Supervised contrastive learning (SupCLR). SupCLR is a supervised extension of SimCLR that
contrasts samples in class-wise, instead of in instance-wise: every samples of the same classes are considered as positives. Let C = {(xi, yi)}Bi=1 be a training batch with class labels yi ∈ Y, and C˜ be an augmented batch by random transformation T , i.e., C˜ := {(x˜j, yj) | x˜j ∈ B˜}. For a given label y, we divide C˜ into two subsets C˜ = C˜y ∪ C˜−y where C˜y contains the samples of label y and C˜−y contains the remaining. Then, the SupCLR objective is deﬁned by:

L

1 2B

(C; T ) :=

L

(x˜ , C˜ \ {x˜ }, C˜

).

(10)

SupCLR

2B

con j yj

j −yj

j=1

4

Table 1: AUROC (%) of various OOD detection methods trained on one-class dataset of (a) CIFAR-10, (b) CIFAR-100 (super-class), and (c) ImageNet-30. For CIFAR-10, we report the means and standard deviations of per-class AUROC averaged over ﬁve trials, and the ﬁnal column indicates the mean AUROC across all the classes. For CIFAR-100 and ImaegeNet-30, we only report the mean AUROC over a single trial. Bold denotes the best results, and ∗ denotes the values from the reference. See Appendix C for additional results, e.g., per-class AUROC on CIFAR-100 and ImageNet-30.

(a) One-class CIFAR-10

Method

Network

OC-SVM∗ [59] DeepSVDD∗ [56] AnoGAN∗ [58] OCGAN∗ [52] Geom∗ [15] Rot∗ [25] Rot+Trans∗ [25] GOAD∗ [2]
Rot [25]
Rot+Trans [25]
GOAD [2]

LeNet DCGAN OCGAN WRN-16-8 WRN-16-4 WRN-16-4 WRN-10-4 ResNet-18 ResNet-18 ResNet-18

CSI (ours)

ResNet-18

Plane Car Bird Cat Deer Dog Frog Horse Ship Truck

65.6 61.7 67.1 75.7 74.7 71.9 77.5 77.2 78.3±0.2 80.4±0.3 75.5±0.3

40.9 65.9 54.7 53.1 95.7 94.5 96.9 96.7 94.3±0.3 96.4±0.2 94.1±0.3

65.3 50.8 52.9 64.0 78.1 78.4 87.3 83.3 86.2±0.4 85.9±0.3 81.8±0.5

50.1 59.1 54.5 62.0 72.4 70.0 80.9 77.7 80.8±0.6 81.1±0.5 72.0±0.3

75.2 60.9 65.1 72.3 87.8 77.2 92.7 87.8 89.4±0.5 91.3±0.3 83.7±0.9

51.2 65.7 60.3 62.0 87.8 86.6 90.2 87.8 89.0±0.4 89.6±0.3 84.4±0.3

71.8 67.7 58.5 72.3 83.4 81.6 90.9 90.0 88.9±0.4 89.9±0.3 82.9±0.8

51.2 67.3 62.5 57.5 95.5 93.7 96.5 96.1 95.1±0.2 95.9±0.1 93.9±0.3

67.9 75.9 75.8 82.0 93.3 90.7 95.2 93.8 92.3±0.3 95.0±0.1 92.9±0.3

48.5 73.1 66.5 55.4 91.3 88.8 93.3 92.0 89.7±0.3 92.6±0.2 89.5±0.2

89.9±0.1 99.1±0.0 93.1±0.2 86.4±0.2 93.9±0.1 93.2±0.2 95.1±0.1 98.7±0.0 97.9±0.0 95.5±0.1

Mean
58.8 64.8 61.8 65.7 86.0 83.3 90.1 88.2 88.4 89.8 85.1
94.3

(b) One-class CIFAR-100 (super-class)

(c) One-class ImageNet-30

Method
OC-SVM∗ [59] Geom∗ [15] Rot [25] Rot+Trans [25] GOAD [2] CSI (ours)

Network
WRN-16-8 ResNet-18 ResNet-18 ResNet-18 ResNet-18

AUROC
63.1 78.7 77.7 79.8 74.5 89.6

Method
Rot∗ [25] Rot+Trans∗ [25] Rot+Attn∗ [25] Rot+Trans+Attn∗ [25] Rot+Trans+Attn+Resize∗ [25]
CSI (ours)

Network
ResNet-18 ResNet-18 ResNet-18 ResNet-18 ResNet-18 ResNet-18

AUROC
65.3 77.9 81.6 84.8 85.7 91.6

After training the embedding network fθ(x) with the SupCLR objective (10), we train a linear classiﬁer upon fθ(x) to model pSupCLR(y|x).
Supervised extension of CSI. We extend CSI by incorporating the shifting transformations S into the SupCLR objective: here, we consider a joint label (y, yS ) ∈ Y × S of class label y and shifting transformation yS . Then, the supervised contrasting shifted instances (sup-CSI) loss is given by:

Lsup-CSI := LSupCLR

CS; T , where CS := {(S(xi), (yi, S))}Bi=1.

(11)

S∈S

Note that we do not use the auxiliary classiﬁcation loss Lcls-SI (4), since the objective already classiﬁes the shifted instances under a self-label augmented [35] space Y × S.

Upon the learned representation via (11), we additionally train two linear classiﬁers: pCSI(y|x) and pCSI-joint(y, yS |x) that predicts the class labels and joint labels, respectively. We directly apply
ssup(x) for the former pCSI(y|x). For the latter, on the other hand, we marginalize the joint prediction
over the shifting transformation in a similar manner of Section 2.3. Precisely, let l(x) ∈ RC×K be logit values of pCSI-joint(y, yS |x) for |Y| = C and |S| = K, and l(x)k ∈ RC be logit values
correspond to pCSI-joint(y, yS = Sk|x). Then, the ensembled probability is:

1 pCSI-ens(y|x) := σ K l(Sk(x))k , (12)
k
where σ denotes the softmax activation. Here, we use pCSI-ens to compute the conﬁdence ssup(x). We denote the conﬁdence computed by pCSI and pCSI-ens and “CSI” and “CSI-ens”, respectively.

3 Experiments
In Section 3.1, we report OOD detection results on unlabeled one-class, unlabeled multi-class, and labeled multi-class datasets. In Section 3.2, we analyze the effects on various shifting transformations in the context of OOD detection, as well as an ablation study on each component we propose.

5

Table 2: AUROC (%) of various OOD detection methods trained on unlabeled (a) CIFAR-10 and (b)
ImageNet-30. The reported results are averaged over ﬁve trials, subscripts denote standard deviation, and bold denote the best results. ∗ denotes the values from the reference.

(a) Unlabeled CIFAR-10

CIFAR10 →

Method
Likelihood∗ Likelihood∗ Likelihood∗ Likelihood Ratio∗ [55] Input Complexity∗ [61] Input Complexity∗ [61]

Network
PixelCNN++ Glow EBM PixelCNN++ PixelCNN++ Glow

SVHN
8.3 8.3 63.0 91.2 92.9 95.0

LSUN
-

ImageNet LSUN (FIX) ImageNet (FIX) CIFAR-100 Interp.

64.2

-

-

66.3

-

-

-

-

-

-

-

-

58.9

-

-

71.6

-

-

52.6

52.6

58.2

58.2

-

70.0

-

-

53.5

-

73.6

-

Rot [25] Rot+Trans [25] GOAD [2] CSI (ours)

ResNet-18 ResNet-18 ResNet-18 ResNet-18

97.6±0.2 97.8±0.2 96.3±0.2 99.8±0.0

89.2±0.7 92.8±0.9 89.3±1.5 97.5±0.3

90.5±0.3 94.2±0.7 91.8±1.2 97.6±0.3

77.7±0.3 81.6±0.4 78.8±0.3 90.3±0.3

83.2±0.1 86.7±0.1 83.3±0.1 93.3±0.1

79.0±0.1 82.3±0.2 77.2±0.3 89.2±0.1

64.0±0.3 68.1±0.8 59.4±1.1 79.3±0.2

Method
Rot [25] Rot+Trans [25] GOAD [2] CSI (ours)

Network
ResNet-18 ResNet-18 ResNet-18 ResNet-18

CUB-200
76.5±0.7 74.5±0.5 71.5±1.4 90.5±0.1

(b) Unlabeled ImageNet-30

ImageNet-30 →

Dogs Pets Flowers Food-101 Places-365

77.2±0.5 77.8±1.1 74.3±1.6 97.1±0.1

70.0±0.5 70.0±0.8 65.5±1.3 85.2±0.2

87.2±0.2 86.3±0.3 82.8±1.4 94.7±0.4

72.7±1.5 71.6±1.4 68.7±0.7 89.2±0.3

52.6±1.4 53.1±1.7 51.0±1.1 78.3±0.3

Caltech-256
70.9±0.1 70.0±0.2 67.4±0.8 87.1±0.1

DTD
89.9±0.5 89.4±0.6 87.5±0.8 96.9±0.1

Setup. We use ResNet-18 [20] architecture for all the experiments. For data augmentations T , we adopt those used by Chen et al. [5]: namely, we use the combination of Inception crop [64], horizontal ﬂip, color jitter, and grayscale. For shifting transformations S, we use the random rotation 0°, 90°, 180°, 270° unless speciﬁed otherwise, as rotation has the highest OOD-ness (see Section 2.2) values for natural images, e.g., CIFAR-10 [33]. However, we remark that the best shifting transformation can be different for other datasets, e.g., Gaussian noise performs better than rotation for texture datasets (see Table 6 in Section 3.2). By default, we train our models from scratch with the training objective in (5) and detect OOD samples with the ensembled version of the score in (9).
We mainly report the area under the receiver operating characteristic curve (AUROC) as a thresholdfree evaluation metric for a detection score. In addition, we report the test accuracy and the expected calibration error (ECE) [45, 19] for the experiments on labeled multi-class datasets. Here, ECE estimates whether a classiﬁer can indicate when they are likely to be incorrect for test samples (from in-distribution) by measuring the difference between prediction conﬁdence and accuracy. The formal description of the metrics and detailed experimental setups are in Appendix A.
3.1 Main results
Unlabeled one-class datasets. We start by considering the one-class setup: here, for a given multiclass dataset of C classes, we conduct C one-class classiﬁcation tasks, where each task chooses one of the classes as in-distribution while the remaining classes being out-of-distribution. We run our experiments on three datasets, following the prior work [15, 25, 2]: CIFAR-10 [33], CIFAR-100 labeled into 20 super-classes [33], and ImageNet-30 [25] datasets. We compare CSI with various prior methods including one-class classiﬁer [59, 56], reconstruction-based [58, 52], and self-supervised [15, 25, 2] approaches. Table 1 summarizes the results, showing that CSI signiﬁcantly outperforms the prior methods in all the tested cases. We provide the full, additional results, e.g., class-wise AUROC on CIFAR-100 (super-class) and ImageNet-30, in Appendix C.
Unlabeled multi-class datasets. In this setup, we assume that in-distribution samples are from a speciﬁc multi-class dataset without labels, testing on various external datasets as out-of-distribution. We compare CSI on two in-distribution datasets: CIFAR-10 [33] and ImageNet-30 [25]. We consider the following datasets as out-of-distribution: SVHN [48], resized LSUN and ImageNet [39], CIFAR100 [33], and linearly-interpolated samples of CIFAR-10 (Interp.) [11] for CIFAR-10 experiments, and CUB-200 [67], Dogs [29], Pets [51], Flowers [49], Food-101 [3], Places-365 [75], Caltech256 [18], and DTD [8] for ImageNet-30. We compare CSI with various prior methods, including density-based [11, 55, 61] and self-supervised [15, 2] approaches.

6

Table 3: Test accuracy (%), ECE (%), and AUROC (%) of conﬁdence-calibrated classiﬁers trained on labeled (a) CIFAR-10 and (b) ImageNet-30. The reported results are averaged over ﬁve trials for CIFAR-10 and one trial for ImageNet-30. Subscripts denote standard deviation, and bold denote the best results. CSI-ens denotes the ensembled prediction, i.e., 4 times slower (as we use rotation).

(a) Labeled CIFAR-10

CIFAR10 →

Train method Test acc. ECE SVHN LSUN ImageNet LSUN (FIX) ImageNet (FIX) CIFAR100 Interp.

Cross Entropy SupCLR [30] CSI (ours) CSI-ens (ours)

93.0±0.2 93.8±0.1 94.8±0.1 96.1±0.1

6.44±0.2 5.56±0.1 4.40±0.1 3.50±0.1

88.6±0.9 97.3±0.1 96.5±0.2 97.9±0.1

90.7±0.5 92.8±0.5 96.3±0.5 97.7±0.4

88.3±0.6 91.4±1.2 96.2±0.4 97.6±0.3

87.5±0.3 91.6±1.5 92.1±0.5 93.5±0.4

87.4±0.3 90.5±0.5 92.4±0.0 94.0±0.1

85.8±0.3 88.6±0.2 90.5±0.1 92.2±0.1

75.4±0.7 75.7±0.1 78.5±0.2 80.1±0.3

(b) Labeled ImageNet-30

ImageNet-30 →

Train method Test acc. ECE CUB-200 Dogs Pets Flowers Food-101 Places-365 Caltech-256 DTD

Cross Entropy 94.3 5.08 88.0 96.7 95.0 89.7

79.8

90.5

SupCLR [30]

96.9 3.12

86.3

95.6 94.2 92.2

81.2

89.7

CSI (ours)

97.0 2.61 93.4 97.7 96.9 96.0

87.0

92.5

CSI-ens (ours) 97.8 2.19 94.6 98.3 97.4 96.2

88.9

94.0

90.6

90.1

90.2

92.1

91.9

93.7

93.2

97.4

Table 2 shows the results. Overall, CSI signiﬁcantly outperforms the prior methods in all benchmarks tested. We remark that CSI is particularly effective for detecting hard (i.e., near-distribution) OOD samples, e.g., CIFAR-100 and Interp. in Table 2a. Also, CSI still shows a notable performance in the cases when prior methods often fail, e.g., AUROC of 50% (i.e., random guess) for Places-365 dataset in Table 2b. Finally, we notice that the resized LSUN and ImageNet datasets ofﬁcially released by Liang et al. [39] might be misleading to evaluate detection performance for hard OODs: we ﬁnd that those datasets contain some unintended artifacts, due to incorrect resizing procedure. Such an artifact makes those datasets easily-detectable, e.g., via input statistics. In this respect, we produce and test on their ﬁxed versions, coined LSUN (FIX), and ImageNet (FIX). See Appendix I for details.
Labeled multi-class datasets. We also consider the labeled version of the above setting: namely, we now assume that every in-distribution sample also contains discriminative label information. We use the same datasets considered in the unlabeled multi-class setup for in- and out-of-distribution datasets. We train our model as proposed in Section 2.4, and compare it with those trained by other methods, the cross-entropy and supervised contrastive learning (SupCLR) [30]. Since our goal is to calibrate the conﬁdence, the maximum softmax probability is used to detect OOD samples (see [22]).
Table 3 shows the results. Overall, CSI consistently improves AUROC and ECE for all benchmarks tested. Interestingly, CSI also improves test accuracy; even our original purpose of CSI is to learn a representation for OOD detection. CSI can further improve the performance by ensembling over the transformations. We also remark that our results on unlabeled datasets (in Table 2) already show comparable performance to the supervised baselines (in Table 3).
3.2 Ablation study
We perform an ablation study on various shifting transformations, training objectives, and detection scores. Throughout this section, we report the mean AUROC values on one-class CIFAR-10.
Shifting transformation. We measure the OOD-ness (see Section 2.2) of transformations, i.e., the AUROC between in-distribution vs. transformed samples under vanilla SimCLR, and the effects of those transformations when used as a shifting transformation. In particular, we consider Cutout [10], Sobel ﬁltering [28], Gaussian noise, Gaussian blur, and rotation [14]. We remark that these transformations are reported to be ineffective in improving the class discriminative power of SimCLR [5]. We also consider the transformation coined “Perm”, which randomly permutes each part of the evenly partitioned image. Intuitively, such transformations commonly shift the input distribution, hence forcing them to be aligned can be harmful. Figure 1 visualizes the considered transformations.
Table 4 shows AUROC values of the vanilla SimCLR, where the in-distribution samples shifted by the chosen transformation are given as OOD samples. The shifted samples are easily detected: it validates our intuition that the considered transformations shift the input distribution. In particular, “Perm” and “Rotate” are the most distinguishable, which implies they shift the distribution the most.

7

(a) Original (b) Cutout (c) Sobel (d) Noise

(e) Blur

(f) Perm (g) Rotate

Figure 1: Visualization of the original image and the considered shifting transformations.

Table 4: OOD-ness (%), i.e., the AUROC between in-distribution vs. transformed samples under the vanilla SimCLR (see Section 2.2), of various transformations. The vanilla SimCLR is trained on one-class CIFAR-10 under ResNet-18. Each column denotes the applied transformation.
Cutout Sobel Noise Blur Perm Rotate

OOD-ness 79.5 69.2 74.4 76.0 83.8 85.2

Table 5: Ablation study on various transformations, added or removed from the vanilla SimCLR.

“Align” and “Shift” indicates that the transformation is used as T and S, respectively. (a) We add a

new transformation as an aligned (up) or shifting (down) transformations. (b) We remove (up) or

convert-to-shift (down) the transformation from the vanilla SimCLR. All reported values are the

mean AUROC (%) over one-class CIFAR-10, and “Base” denotes the vanilla SimCLR.

(a) Add transformations

(b) Remove transformations

Base

Cutout Sobel Noise Blur Perm Rotate

87.9 +Align 84.3 85.0 85.5 88.0 73.1 76.5 +Shift 88.5 88.3 89.3 89.2 90.7 94.3

Crop Jitter Gray

-Align 55.7 78.8 78.4

+Shift -

- 88.3

Note that “Perm” and “Rotate” turns out to be the most effective shifting transformations; it implies that the transformations shift the distribution most indeed performs best for CSI.3

Besides, we apply the transformation upon the vanilla SimCLR: align the transformed samples to the original samples (i.e., use as T ) or consider them as the shifted samples (i.e., use as S). Table 5a shows that aligning the transformations degrade (or on par) the detection performance, while shifting the transformations gives consistent improvements. We also remove or convert-to-shift the transformation from the vanilla SimCLR in Table 5b, and see similar results. We remark that one can further improve the performance by combining multiple shifting transformations (see Appendix G).

Data-dependence of shifting transformations. We re- Table 6: OOD-ness (%) and AUROC (%)

mark that the best shifting transformation depends on on DTD, where Textile is used for OOD.

the dataset. For example, consider the rotation-invariant

datasets: Describable Textures Dataset (DTD) [8] and

Textile [60] are in- vs. out-of-distribution, respectively

(see Appendix J for more visual examples). For such

datasets, rotation (Rot.) does not shift the distribution, and Gaussian noise (Noise) is more suitable transfor- (a) OOD-ness

(b) AUROC

mation (see Table 6a). Table 6b shows that CSI using Rot. Noise Base CSI(R) CSI(N)

Gaussian noise (“CSI(N)”) indeed improves the vanilla 50.6 75.7 70.3 65.9 80.1 SimCLR (“Base”) while CSI using rotation (“CSI(R)”)

degrades instead. This results support our principles on selecting shifting transformations.

Linear evaluation. We also measure the linear evaluation [32], the accuracy of a linear classiﬁer to discriminate classes of in-distribution samples. It is widely used for evaluating the quality of (unsupervised) learned representation. We report the linear evaluation of vanilla SimCLR and CSI (with shifting rotation), trained under unlabeled CIFAR-10. They show comparable results, 90.48% for SimCLR and 90.19% for CSI; CSI is more specialized to learn a representation for OOD detection.

Training objective. In Table 7a, we assess the individual effects of each component that consists of our ﬁnal training objective (5): namely, we compare the vanilla SimCLR (2), contrasting shifted

3We also have tried contrasting external OOD samples similarly to [24]; however, we ﬁnd that naïvely using them in our framework degrade the performance. This is because the contrastive loss also discriminates within external OOD samples, which is unnecessary and an additional learning burden for our purpose.

8

Table 7: Ablation study on each component of our proposed (a) training objective and (b) detection score. For (a), we use the corresponding detection score for each training loss; namely, (6) to (9) for (2) to (5), respectively. For (b), we use the model trained by the ﬁnal training loss (5). We measure the mean AUROC (%) values, trained under CIFAR-10 with ResNet-18. Each row indicates the corresponding equation of the given checkmarks, and bold denotes the best results. “Con.”, “Cls.”, and “Ensem.” denotes contrast, classify, and ensemble, respectively.

(a) Training objective

(b) Detection score

SimCLR Con. Cls. AUROC

Con. Cls. Ensem. AUROC

LSimCLR (2)

Lcon-SI (3)

Lcls-SI (4)

-

LCSI (5)

-

-

87.9

scon (6)

-

-

91.3

-

91.6

scon-SI (7)

-

93.3

-

88.6

scls-SI (8)

-

93.8

94.3

sCSI (9)

94.3

instances (3), and classifying shifted instances (4) losses. For the evaluation of the models of different training objectives (2) to (5), we use the detection scores deﬁned in (6) to (9), respectively. We remark that both contrasting and classifying shows better results than the vanilla SimCLR; and combining them (i.e., the ﬁnal CSI objective (5)) gives further improvements, i.e., two losses are complementary.
Detection score. Finally, Table 7b shows the effect of each component in our detection score: the vanilla contrastive (6), contrasting shifted instances (7), and classifying shifted instances (8) scores. We ensemble the scores over both T and S for (7) to (9), and use a single sample for (6). All the reported values are evaluated from the model trained by the ﬁnal objective 5. Similar to above, both contrasting and classifying scores show better results than the vanilla contrastive score; and combining them (i.e., the ﬁnal CSI score (9)) gives further improvements.
4 Related work
OOD detection. Recent works on unsupervised OOD detection (i.e., no external OOD samples) [26] can be categorized as: (a) density-based [74, 46, 6, 47, 11, 55, 61, 17], (b) reconstruction-based [58, 76, 9, 54, 52, 7], (c) one-class classiﬁer [59, 56], and (d) self-supervised [15, 25, 2] approaches. Our work falls into (c) the self-supervised approach, as it utilizes the representation learned from self-supervision [14]. However, unlike prior works [15, 25, 2] focusing on the self-label classiﬁcation tasks (e.g., predict the angle of the rotated image), we ﬁrst incorporate contrastive learning [5] for OOD detection. Concurrently, Winkens et al. [68] and Liu and Abbeel [40] report that contrastive learning also improves the OOD detection performance of classiﬁers [39, 38, 25].
Conﬁdence-calibrated classiﬁers. Conﬁdence-calibrated classiﬁers aim to calibrate the prediction conﬁdence (maximum softmax probability), which can be directly used as an uncertainty estimator for both within in-distribution [45, 19] and in- vs. out-of-distribution [22, 37]. Prior works improved calibration through inference [19] or training [37] schemes, which are can be jointed applied to our method. Some works design a speciﬁc detection score upon the pre-trained classiﬁers [39, 38], but they only target OOD detection, while ours also consider the in-distribution calibration.
Self-supervised learning. Self-supervised learning [14, 32], particularly contrastive learning [13] via instance discrimination [69], has shown remarkable success on visual representation learning [21, 5]. However, most prior works focus on the downstream tasks (e.g., classiﬁcation), and other advantages (e.g., uncertainty or robustness) are rarely investigated [25, 31]. Our work, concurrent with [40, 68], ﬁrst veriﬁes that contrastive learning is also effective for OOD detection. In particular, we ﬁnd that the shifting transformations, which were known to be harmful and unused for the standard contrastive learning [5], can help OOD detection. This observation provides new considerations for selecting transformations, i.e., which transformation should be used for positive or negative [66, 71].
We further provide a more comprehensive survey and discussions with prior works in Appendix B.
5 Conclusion
We propose a simple yet effective method named contrasting shifted instances (CSI), which extends the power of contrastive learning for out-of-distribution (OOD) detection problems. CSI demonstrates outstanding performance under various OOD detection scenarios. We believe our work would guide various future directions in OOD detection and self-supervised learning as an important baseline.

9

Acknowledgements
This work was supported by Institute of Information & Communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (No.2019-0-00075, Artiﬁcial Intelligence Graduate School Program (KAIST) and No.2017-0-01779, A machine learning and statistical inference framework for explainable artiﬁcial intelligence). We thank Sihyun Yu, Chaewon Kim, Hyuntak Cha, Hyunwoo Kang, and Seunghyun Lee for helpful feedback and suggestions.
Broader Impact
This paper is focused on the subject of out-of-distribution (OOD) (or novelty, anomaly) detection, which is an essential ingredient for building safe and reliable intelligent systems [1]. We expect our results to have two consequences for academia and broader society.
Rethinking representation for OOD detection. In this paper, we demonstrate that the representation for classiﬁcation (or other related tasks, measured by linear evaluation [32]) can be different from the representation for OOD detection. In particular, we verify that the “hard” augmentations, thought to be harmful for contrastive representation learning [5], can be helpful for OOD detection. Our observation raises new questions for both representation learning and OOD detection: (a) representation learning researches should also report the OOD detection results as an evaluation metric, (b) OOD detection researches should more investigate the specialized representation.
Towards reliable intelligent system. The intelligent system should be robust to the potential dangers of uncertain environments (e.g., ﬁnancial crisis [65]) or malicious adversaries (e.g., cybersecurity [34]). Detecting outliers is also related to human safety (e.g., medical diagnosis [4] or autonomous driving [12]), and has a broad range of industrial applications (e.g., manufacturing inspection [42]). However, the system can be stuck into conﬁrmation bias, i.e., ignore new information with a myopic perspective. We hope the system to balance the exploration and exploitation of the knowledge.
References
[1] D. Amodei, C. Olah, J. Steinhardt, P. Christiano, J. Schulman, and D. Mané. Concrete problems in ai safety. arXiv preprint arXiv:1606.06565, 2016.
[2] L. Bergman and Y. Hoshen. Classiﬁcation-based anomaly detection for general data. In International Conference on Learning Representations, 2020.
[3] L. Bossard, M. Guillaumin, and L. Van Gool. Food-101–mining discriminative components with random forests. In European Conference on Computer Vision, 2014.
[4] R. Caruana, Y. Lou, J. Gehrke, P. Koch, M. Sturm, and N. Elhadad. Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission. In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2015.
[5] T. Chen, S. Kornblith, M. Norouzi, and G. Hinton. A simple framework for contrastive learning of visual representations. In International Conference on Machine Learning, 2020.
[6] H. Choi, E. Jang, and A. A. Alemi. Waic, but why? generative ensembles for robust anomaly detection. arXiv preprint arXiv:1810.01392, 2018.
[7] S. Choi and S.-Y. Chung. Novelty detection via blurring. In International Conference on Learning Representations, 2020.
[8] M. Cimpoi, S. Maji, I. Kokkinos, S. Mohamed, and A. Vedaldi. Describing textures in the wild. In IEEE Conference on Computer Vision and Pattern Recognition, 2014.
[9] L. Deecke, R. Vandermeulen, L. Ruff, S. Mandt, and M. Kloft. Image anomaly detection with generative adversarial networks. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, 2018.
[10] T. DeVries and G. W. Taylor. Improved regularization of convolutional neural networks with cutout. arXiv preprint arXiv:1708.04552, 2017.
10

[11] Y. Du and I. Mordatch. Implicit generation and modeling with energy based models. In Advances in Neural Information Processing Systems, 2019.
[12] K. Eykholt, I. Evtimov, E. Fernandes, B. Li, A. Rahmati, C. Xiao, A. Prakash, T. Kohno, and D. Song. Robust physical-world attacks on deep learning visual classiﬁcation. In IEEE Conference on Computer Vision and Pattern Recognition, 2018.
[13] W. Falcon and K. Cho. A framework for contrastive self-supervised learning and designing a new approach. arXiv preprint arXiv:2009.00104, 2020.
[14] S. Gidaris, P. Singh, and N. Komodakis. Unsupervised representation learning by predicting image rotations. In International Conference on Learning Representations, 2018.
[15] I. Golan and R. El-Yaniv. Deep anomaly detection using geometric transformations. In Advances in Neural Information Processing Systems, 2018.
[16] P. Goyal, P. Dollár, R. Girshick, P. Noordhuis, L. Wesolowski, A. Kyrola, A. Tulloch, Y. Jia, and K. He. Accurate, large minibatch sgd: Training imagenet in 1 hour. arXiv preprint arXiv:1706.02677, 2017.
[17] W. Grathwohl, K.-C. Wang, J.-H. Jacobsen, D. Duvenaud, M. Norouzi, and K. Swersky. Your classiﬁer is secretly an energy based model and you should treat it like one. In International Conference on Learning Representations, 2020.
[18] G. Grifﬁn, A. Holub, and P. Perona. Caltech-256 object category dataset, 2007.
[19] C. Guo, G. Pleiss, Y. Sun, and K. Q. Weinberger. On calibration of modern neural networks. In International Conference on Machine Learning, 2017.
[20] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In IEEE Conference on Computer Vision and Pattern Recognition, 2016.
[21] K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick. Momentum contrast for unsupervised visual representation learning. In IEEE Conference on Computer Vision and Pattern Recognition, 2020.
[22] D. Hendrycks and K. Gimpel. A baseline for detecting misclassiﬁed and out-of-distribution examples in neural networks. In International Conference on Learning Representations, 2017.
[23] D. Hendrycks, K. Lee, and M. Mazeika. Using pre-training can improve model robustness and uncertainty. In International Conference on Machine Learning, 2019.
[24] D. Hendrycks, M. Mazeika, and T. Dietterich. Deep anomaly detection with outlier exposure. In International Conference on Learning Representations, 2019.
[25] D. Hendrycks, M. Mazeika, S. Kadavath, and D. Song. Using self-supervised learning can improve model robustness and uncertainty. In Advances in Neural Information Processing Systems, 2019.
[26] V. Hodge and J. Austin. A survey of outlier detection methodologies. Artiﬁcial intelligence review, 2004.
[27] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. International Conference on Machine Learning, 2015.
[28] N. Kanopoulos, N. Vasanthavada, and R. L. Baker. Design of an image edge detection ﬁlter using the sobel operator. IEEE Journal of solid-state circuits, 1988.
[29] A. Khosla, N. Jayadevaprakash, B. Yao, and L. Fei-Fei. Novel dataset for ﬁne-grained image categorization. In IEEE Conference on Computer Vision and Pattern Recognition, Colorado Springs, CO, June 2011.
[30] P. Khosla, P. Teterwak, C. Wang, A. Sarna, Y. Tian, P. Isola, A. Maschinot, C. Liu, and D. Krishnan. Supervised contrastive learning. In Advances in Neural Information Processing Systems, 2020.
11

[31] M. Kim, J. Tack, and S. J. Hwang. Adversarial self-supervised contrastive learning. In Advances in Neural Information Processing Systems, 2020.
[32] A. Kolesnikov, X. Zhai, and L. Beyer. Revisiting self-supervised visual representation learning. In IEEE Conference on Computer Vision and Pattern Recognition, 2019.
[33] A. Krizhevsky et al. Learning multiple layers of features from tiny images, 2009.
[34] C. Kruegel and G. Vigna. Anomaly detection of web-based attacks. In Proceedings of the 10th ACM conference on Computer and communications security, 2003.
[35] H. Lee, S. J. Hwang, and J. Shin. Self-supervised label augmentation via input transformations. In International Conference on Machine Learning, 2020.
[36] K. Lee, C. Hwang, K. S. Park, and J. Shin. Conﬁdent multiple choice learning. In International Conference on Machine Learning, 2017.
[37] K. Lee, H. Lee, K. Lee, and J. Shin. Training conﬁdence-calibrated classiﬁers for detecting out-of-distribution samples. In International Conference on Learning Representations, 2018.
[38] K. Lee, K. Lee, H. Lee, and J. Shin. A simple uniﬁed framework for detecting out-of-distribution samples and adversarial attacks. In Advances in Neural Information Processing Systems, 2018.
[39] S. Liang, Y. Li, and R. Srikant. Enhancing the reliability of out-of-distribution image detection in neural networks. In International Conference on Learning Representations, 2018.
[40] H. Liu and P. Abbeel. Hybrid discriminative-generative training via contrastive learning. arXiv preprint arXiv:2007.09070, 2020.
[41] I. Loshchilov and F. Hutter. Sgdr: Stochastic gradient descent with warm restarts. arXiv preprint arXiv:1608.03983, 2016.
[42] D. Lucke, C. Constantinescu, and E. Westkämper. Smart factory-a step towards the next generation of manufacturing. Manufacturing Systems and Technologies for the New Frontier, page 115, 2008.
[43] L. v. d. Maaten and G. Hinton. Visualizing data using t-sne. Journal of machine learning research, 2008.
[44] J. MacQueen et al. Some methods for classiﬁcation and analysis of multivariate observations, 1967.
[45] M. P. Naeini, G. Cooper, and M. Hauskrecht. Obtaining well calibrated probabilities using bayesian binning. In AAAI Conference on Artiﬁcial Intelligence, 2015.
[46] E. Nalisnick, A. Matsukawa, Y. W. Teh, D. Gorur, and B. Lakshminarayanan. Do deep generative models know what they don’t know? In International Conference on Learning Representations, 2019.
[47] E. Nalisnick, A. Matsukawa, Y. W. Teh, and B. Lakshminarayanan. Detecting out-of-distribution inputs to deep generative models using a test for typicality. arXiv preprint arXiv:1906.02994, 2019.
[48] Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, and A. Y. Ng. Reading digits in natural images with unsupervised feature learning. In Advances in Neural Information Processing Systems Workshop on Deep Learning and Unsupervised Feature Learning, 2011.
[49] M.-E. Nilsback and A. Zisserman. A visual vocabulary for ﬂower classiﬁcation. In IEEE Conference on Computer Vision and Pattern Recognition, 2006.
[50] A. v. d. Oord, Y. Li, and O. Vinyals. Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748, 2018.
[51] O. M. Parkhi, A. Vedaldi, A. Zisserman, and C. Jawahar. Cats and dogs. In IEEE Conference on Computer Vision and Pattern Recognition, 2012.
12

[52] P. Perera, R. Nallapati, and B. Xiang. Ocgan: One-class novelty detection using gans with constrained latent representations. In IEEE Conference on Computer Vision and Pattern Recognition, 2019.
[53] C. Phua, V. Lee, K. Smith, and R. Gayler. A comprehensive survey of data mining-based fraud detection research. arXiv preprint arXiv:1009.6119, 2010.
[54] S. Pidhorskyi, R. Almohsen, and G. Doretto. Generative probabilistic novelty detection with adversarial autoencoders. In Advances in Neural Information Processing Systems, 2018.
[55] J. Ren, P. J. Liu, E. Fertig, J. Snoek, R. Poplin, M. Depristo, J. Dillon, and B. Lakshminarayanan. Likelihood ratios for out-of-distribution detection. In Advances in Neural Information Processing Systems, 2019.
[56] L. Ruff, R. Vandermeulen, N. Goernitz, L. Deecke, S. A. Siddiqui, A. Binder, E. Müller, and M. Kloft. Deep one-class classiﬁcation. In International Conference on Machine Learning, 2018.
[57] L. Ruff, R. A. Vandermeulen, N. Görnitz, A. Binder, E. Müller, K.-R. Müller, and M. Kloft. Deep semi-supervised anomaly detection. In International Conference on Learning Representations, 2020.
[58] T. Schlegl, P. Seeböck, S. M. Waldstein, U. Schmidt-Erfurth, and G. Langs. Unsupervised anomaly detection with generative adversarial networks to guide marker discovery. In International conference on information processing in medical imaging, 2017.
[59] B. Schölkopf, R. C. Williamson, A. J. Smola, J. Shawe-Taylor, and J. C. Platt. Support vector method for novelty detection. In Advances in Neural Information Processing Systems, 2000.
[60] H. Schulz-Mirbach. Tilda-ein referenzdatensatz zur evaluierung von sichtprüfungsverfahren für textiloberﬂächen. Interner Bericht, 1996. URL https://lmb.informatik.uni-freiburg. de/resources/datasets/tilda.en.html.
[61] J. Serrà, D. Álvarez, V. Gómez, O. Slizovskaia, J. F. Núñez, and J. Luque. Input complexity and out-of-distribution detection with likelihood-based generative models. In International Conference on Learning Representations, 2020.
[62] Severstal. Severstal: Steel defect detection, 2019. URL https://www.kaggle.com/c/ severstal-steel-defect-detection.
[63] A. Srinivas, M. Laskin, and P. Abbeel. Curl: Contrastive unsupervised representations for reinforcement learning. In International Conference on Machine Learning, 2020.
[64] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. In IEEE Conference on Computer Vision and Pattern Recognition, pages 1–9, 2015.
[65] J. B. Taylor and J. C. Williams. A black swan in the money market. American Economic Journal: Macroeconomics, 2009.
[66] Y. Tian, C. Sun, B. Poole, D. Krishnan, C. Schmid, and P. Isola. What makes for good views for contrastive learning. In Advances in Neural Information Processing Systems, 2020.
[67] C. Wah, S. Branson, P. Welinder, P. Perona, and S. Belongie. The Caltech-UCSD Birds-200-2011 Dataset. Technical Report CNS-TR-2011-001, California Institute of Technology, 2011.
[68] J. Winkens, R. Bunel, A. G. Roy, R. Stanforth, V. Natarajan, J. R. Ledsam, P. MacWilliams, P. Kohli, A. Karthikesalingam, and S. Kohl. Contrastive training for improved out-of-distribution detection. arXiv preprint arXiv:2007.05566, 2020.
[69] Z. Wu, Y. Xiong, S. X. Yu, and D. Lin. Unsupervised feature learning via non-parametric instance discrimination. In IEEE Conference on Computer Vision and Pattern Recognition, 2018.
13

[70] G.-S. Xia, X. Bai, J. Ding, Z. Zhu, S. Belongie, J. Luo, M. Datcu, M. Pelillo, and L. Zhang. Dota: A large-scale dataset for object detection in aerial images. In IEEE Conference on Computer Vision and Pattern Recognition, 2018.
[71] T. Xiao, X. Wang, A. A. Efros, and T. Darrell. What should not be contrastive in contrastive learning. arXiv preprint arXiv:2008.05659, 2020.
[72] Y. You, I. Gitman, and B. Ginsburg. Large batch training of convolutional networks. arXiv preprint arXiv:1708.03888, 2017.
[73] S. Yun, J. Park, K. Lee, and J. Shin. Regularizing class-wise predictions via self-knowledge distillation. In IEEE Conference on Computer Vision and Pattern Recognition, 2020.
[74] S. Zhai, Y. Cheng, W. Lu, and Z. Zhang. Deep structured energy based models for anomaly detection. In International Conference on Machine Learning, 2016.
[75] B. Zhou, A. Lapedriza, A. Khosla, A. Oliva, and A. Torralba. Places: A 10 million image database for scene recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017.
[76] B. Zong, Q. Song, M. R. Min, W. Cheng, C. Lumezanu, D. Cho, and H. Chen. Deep autoencoding gaussian mixture model for unsupervised anomaly detection. In International Conference on Learning Representations, 2018.
14

Appendix
CSI: Novelty Detection via Contrastive Learning on Distributionally Shifted Instances
A Experimental details
Training details. We use ResNet-18 [20] as the base encoder network fθ and 2-layer multi-layer perceptron with 128 embedding dimension as the projection head gφ. All models are trained by minimizing the ﬁnal loss LCSI (5) with a temperature of τ = 0.5. We follow the same optimization step of SimCLR [5]. For optimization, we train CSI with 1,000 epoch under LARS optimizer [72] with weight decay of 1e−6 and momentum with 0.9. For the learning rate scheduling, we use linear warmup [16] for early 10 epochs until learning rate of 1.0 and decay with cosine decay schedule without a restart [41]. We use batch size of 512 for both vanilla SimCLR and ours: where the batch is given by B for vanilla SimCLR and the aggregated one S∈S BS for ours. Furthermore, we use global batch normalization (BN) [27], which shares the BN parameters (mean and variance) over the GPUs in distributed training.
For supervised contrastive learning (SupCLR) [30] and supervised CSI, we select the best temperature from {0.07, 0.5}: SupCLR recommend 0.07 but 0.5 was better in our experiments. For training the encoder fθ, we use the same optimization scheme as above, except using 700 for the epoch. For training the linear classiﬁer, we train the model for 100 epochs with batch size 128, using stochastic gradient descent with momentum 0.9. The learning rate starts at 0.1 and is dropped by a factor of 10 at 60%, 75%, and 90% of the training progress.
Data augmentation details. We use SimCLR augmentations: Inception crop [64], horizontal ﬂip, color jitter, and grayscale for random augmentations T , and rotation as shifting transformation S. The detailed description of the augmentations are as follows:
• Inception crop. Randomly crops the area of the original image with uniform distribution 0.08 to 1.0. After the crop, cropped image are resized to the original image size.
• Horizontal ﬂip. Flips the image horizontally with 50% of probability.
• Color jitter. Change the hue, brightness, and saturation of the image. We transform the RGB (red, green, blue) image into an HSV (hue, saturation, value) image format and add noise to the HSV channels. We apply color jitter with 80% of probability.
• Grayscale. Convert into a gray image. Randomly apply a grayscale with 20% of probability.
• Rotation. We use rotation as S, the shifting transformation, {0°, 90°, 180°, 270°}. For a given batch B, we apply each rotation degree to obtain the new batch for CSI: S∈S BS.

(a) Original

(b) Inception crop (c) Horizontal ﬂip (d) Color jitter

(e) Grayscale

Figure 2: Visualization of original image and SimCLR augmentations.

15

Dataset details. For one-class datasets, we train one class of CIFAR-10 [33], CIFAR-100 (superclass) [33], and ImageNet-30 [25]. CIFAR-10 and CIFAR-100 consist of 50,000 training and 10,000 test images with 10 and 20 (super-class) image classes, respectively. ImageNet-30 contains 39,000 training and 3,000 test images with 30 image classes.
For unlabeled and labeled multi-class datasets, we train ResNet with CIFAR-10 and ImageNet-30. For CIFAR-10, out-of-distribution (OOD) samples are as follows: SVHN [48] consists of 26,032 test images with 10 digits, resized LSUN [39] consists of 10,000 test images of 10 different scenes, resized ImageNet [39] consists of 10,000 test images with 200 images classes from a subset of full ImageNet dataset, Interp. consists of 10,000 test images of linear interpolation of CIFAR-10 test images, and LSUN (FIX), ImageNet (FIX) consists of 10,000 test images, respectively with following details in Appendix I. For multi-class ImageNet-30, OOD samples are as follows: CUB-200 [67], Stanford Dogs [29], Oxford Pets [51], Oxford Flowers [49], Food-101 [3] without the “hotdog” class to avoid overlap, Places-365 [75] with small images (256 * 256) validation set, Caltech-256 [18], and Describable Textures Dataset (DTD) [8]. Here, we randomly sample 3,000 images to balance with the in-distribution test set.
Evaluation metrics. For evaluation, we measure the two metrics that each measures (a) the effectiveness of the proposed score in distinguishing in- and out-of-distribution images, (b) the conﬁdence calibration of softmax classiﬁer.

• Area under the receiver operating characteristic curve (AUROC). Let TP, TN, FP, and FN denote true positive, true negative, false positive and false negative, respectively. The ROC curve is a graph plotting true positive rate = TP / (TP+FN) against the false positive rate = FP / (FP+TN) by varying a threshold.

•

Expected

calibration

error

(ECE).

For

a

given

test

data

{(

x

n

,

yn

)}

N n=1

,

we

group

the

predictions into M interval bins (each of size 1/M ). Let Bm be the set of indices of samples whose prediction conﬁdence falls into the interval ( mM−1 , Mm ]. Then, the expected calibration error (ECE) [45, 19] is follows:

M |Bm| ECE = N |acc(Bm) − conf(Bm)|, (13)
m=1

where acc(Bm) is accuracy of Bm: acc(Bm) = |B1m| i∈Bm 1{yi=arg maxy p(y|xi)} where 1 is indicator function and conf(Bm) is conﬁdence of Bm: conf(Bm) = |B1m| i∈Bm q(xi)
where q(xi) is the conﬁdence of data xi.

16

B Detailed review on related work
B.1 OOD detection
Out-of-distribution (OOD) detection is a classic and essential problem in machine learning, studied under different names, e.g., novelty or anomaly detection [26]. In this paper, we primarily focus on unsupervised OOD detection, which is arguably the most traditional and popular setup in the ﬁeld [59]. In this setting, the detector can only access in-distribution samples while required to identify unseen OOD samples. There are other settings, e.g., semi-supervised setting - the detector can access a small subset of out-of-distribution samples [24, 57], or supervised setting - the detector knows the target out-of-distribution, but we do not consider those settings in this paper. We remark that the unsupervised setting is the most practical and challenging scenario since there are inﬁnitely many cases for out-of-distribution, and it is often not possible to have such external data.
Most recent works can be categorized as: (a) density-based [74, 46, 6, 47, 11, 55, 61, 17], (b) reconstruction-based [58, 76, 9, 54, 52, 7], (c) one-class classiﬁer [59, 56, 57], and (d) self-supervised [15, 25, 2] approaches. We note that there are more extensive literature on this topic, but we mainly focus on the recent work based on deep learning. Brief description for each method are as follows:
• Density-based methods. Density-based methods are one of the most classic and principled approaches for OOD detection. Intuitively, they directly use the likelihood of the sample as the detection score. However, recent studies reveal that the likelihood is often not the best metric - especially for deep neural networks with complex datasets [46]. Several work thus proposed modiﬁed scores, e.g., typicality [47], WAIC [6], likelihood ratio [55], input complexity [61], or unnormalized likelihood (i.e., energy) [11, 17].
• Reconstruction-based methods. Reconstruction-based approach is another popular line of research for OOD detection. It trains an encoder-decoder network that reconstructs the training data in an unsupervised manner. Since the network would less generalize for unseen OOD samples, they use the reconstruction loss as a detection score. Some works utilize auto-encoders [76, 54] or generative adversarial networks [58, 9, 52].
• One-class classiﬁers. One-class classiﬁers are also a classic and principled approach for OOD detection. They learn a decision boundary of in- vs. out-of-distribution samples by giving some margin covering the in-distribution samples [59]. Recent works have shown that the one-class classiﬁer is effective upon the deep representation [56].
• Self-supervised methods. Self-supervised approaches are a relatively new technique based on the rich representation learned from self-supervision [14]. They train a network with a pre-deﬁned task (e.g., predict the angle of the rotated image) on the training set, and use the generalization error to detect OOD samples. Recent self-supervised approaches show outstanding results on various OOD detection benchmark datasets [15, 25, 2].
Our work falls into (c) the self-supervised approach [15, 25, 2]. However, unlike prior work focusing on the self-label classiﬁcation tasks (e.g., rotation [14]) which trains an auxiliary classiﬁer to predict the transformation applied to the sample, we ﬁrst incorporate contrastive learning [5] for OOD detection. To that end, we design a novel detection score utilizing the unique characteristic of contrastive learning, e.g., the features in the projection layer learned by cosine similarity. We also propose a novel self-supervised training scheme that further improves the representation for OOD detection. Nevertheless, we acknowledge that the prior work largely inspired our work. For instance, the classifying shifted instances loss (4) follows the form of auxiliary classiﬁers [25], which gives further improvement upon our novel contrasting shifted instances loss (3).
Concurrently, Winkens et al. [68] and Liu and Abbeel [40] report the similar observations that contrastive learning also improves the OOD detection performance of classiﬁers [39, 38, 25]. Winkens et al. [68] jointly train a classiﬁer with the SimCLR [5] objective and use the Mahalanobis distance [38] as a detection score. Liu and Abbeel [40] approximates JEM [17] (a joint model of classiﬁer and energy-based model [11]) by a combination of classiﬁcation and contrastive loss and use densitybased detection scores [17]. In contrast to both work, we mainly focus on the unlabeled OOD setting (although we also discuss the conﬁdent-calibrated classiﬁers). Here, we design a novel detection score, since how to utilize the contrastive representation (which is learned in an unsupervised manner) for OOD detection have not been explored before.
17

B.2 Conﬁdence-calibrated classiﬁers Another line of research is on conﬁdence-calibrated classiﬁers [22], which relaxes the overconﬁdence issue of the classiﬁers. There are two types of calibration: (a) in-distribution calibration [45, 19], that aligns the uncertainty and the actual accuracy, measured by ECE, and (b) out-of-distribution detection [22, 37], that reduces the uncertainty of OOD samples, measured by AUROC. Note that the goal of conﬁdence-calibrated classiﬁers is to regularize the prediction. Hence, the softmax probability is used for all three tasks: classiﬁcation, in-distribution calibration, and out-of-distribution detection. Namely, the detection score is given by the prediction conﬁdence (or maximum softmax probability) [22]. Prior works improved calibration through inference (temperature scaling) [19] or training (regularize predictions of OOD samples) [37] schemes, which can be jointly applied to our method. Some works design a speciﬁc detection score upon the pre-trained classiﬁers [39, 38], but they only target OOD detection, while ours also consider the in-distribution calibration. B.3 Self-supervised learning Self-supervised learning [14, 32] has shown remarkable success in learning representations. In particular, contrastive learning [13] via instance discrimination [69] show the state-of-the-art results on visual representation learning [21, 5]. However, most prior works focus on improving the downstream task performance (e.g., classiﬁcation), and other advantages of self-supervised learning (e.g., uncertainty or robustness) are rarely investigated [25, 31]. Our work, concurrent with [40, 68], ﬁrst veriﬁes that contrastive learning is also effective for OOD detection. Furthermore, we ﬁnd that the shifting transformations, which were known to be harmful and unused for the standard contrastive learning [5], can help OOD detection. This observation provides new considerations for selecting transformations, i.e., which transformation should be used for positive or negative [66, 71]. Speciﬁcally, Tian et al. [66] claims the optimal views (or transformations) of the positive pairs should minimize the mutual information while keeping the task-relevant information. It suggests that the shifting transformation may not contain the information for classiﬁcation, but may contain OOD detection information when used for the negative pairs. Xiao et al. [71] suggests a framework that automatically learns whether the transformation should be positive or negative. One could consider incorporating our principle on shifting transformation (i.e., OOD-ness); OOD detection could be another evaluation metric for the learned representations.
18

C Additional one-class OOD detection results
Table 8 presents the confusion matrix of AUROC values of our method on one-class CIFAR-10 datasets, where bold denotes the hard pairs. The results align with the human intuition that ‘car’ is confused to ‘ship’ and ‘truck’, and ‘cat’ is confused to ‘dog’.
Table 9 presents the OOD detection results of various methods on one-class CIFAR-100 (super-class) datasets, for all 20 super-classes. Our method outperforms the prior methods for all classes.
Table 10 presents the OOD detection results of our method on one-class ImageNet-30 dataset, for all 30 classes. Our method consistently performs well for all classes.

Table 8: Confusion matrix of AUROC (%) values of our method on one-class CIFAR-10. The row and column indicates the in-distribution and OOD class, respectively, and the ﬁnal column indicates the mean value. Bold denotes the values under 80%, which implies the hard pair.

Plane Car Bird Cat Deer Dog Frog Horse Ship Truck Mean

Plane - 74.1 95.8 98.4 94.9 98.0 96.2 90.1 79.6 82.8 90.0

Car

99.3 - 99.9 99.9 99.8 99.9 99.8 99.7 98.7 95.0 99.1

Bird 91.1 97.5 - 97.3 87.0 92.5 96.1 83.2 96.4 98.0 93.2

Cat

91.9 91.5 90.3 - 83.3 67.0 89.6 79.0 92.8 91.9 86.4

Deer 95.7 98.4 94.9 96.6 - 94.7 98.7 69.0 97.4 98.8 93.8

Dog 97.9 98.5 95.5 90.3 88.1 - 96.8 76.6 98.6 98.3 93.4

Frog 93.6 92.3 94.6 96.1 96.8 96.3 - 95.2 94.4 97.3 95.2

Horse 99.3 99.5 99.0 99.3 94.2 97.4 99.8 - 99.7 99.4 98.6

Ship 96.6 91.2 99.5 99.7 99.4 99.7 99.5 99.3 - 96.6 97.9

Truck 96.2 72.3 99.4 99.5 99.1 99.4 98.7 98.3 96.2 -

95.5

Table 9: AUROC (%) values of various OOD detection methods trained on one-class CIFAR-100 (super-class). Each row indicates the results of the selected super-class, and the ﬁnal row indicates the mean value. ∗ denotes the values from the reference, and bold denotes the best results.
OC-SVM∗ DAGMM∗ DSEBM∗ ADGAN∗ Geom∗ Rot Rot+Trans GOAD CSI (ours)

0

68.4

1

63.6

2

52.0

3

64.7

4

58.2

5

54.9

6

57.2

7

62.9

8

65.6

9

74.1

10

84.1

11

58.0

12

68.5

13

64.6

14

51.2

15

62.8

16

66.6

17

73.7

18

52.8

19

58.4

43.4

64.0

63.1

74.7 78.6

79.6

73.9

86.3

49.5

47.9

64.9

68.5 73.4

73.3

69.2

84.8

66.1

53.7

41.3

74.0 70.1

71.3

67.6

88.9

52.6

48.4

50.0

81.0 68.6

73.9

71.8

85.7

56.9

59.7

40.6

78.4 78.7

79.7

72.7

93.7

52.4

46.6

42.8

59.1 69.7

72.6

67.0

81.9

55.0

51.7

51.1

81.8 78.8

85.1

80.0

91.8

52.8

54.8

55.4

65.0 62.5

66.8

59.1

83.9

53.2

66.7

59.2

85.5 84.2

86.0

79.5

91.6

42.5

71.2

62.7

90.6 86.3

87.3

83.7

95.0

52.7

78.3

79.8

87.6 87.1

88.6

84.0

94.0

46.4

62.7

53.7

83.9 76.2

77.1

68.7

90.1

42.7

66.8

58.9

83.2 83.3

84.6

75.1

90.3

45.4

52.6

57.4

58.0 60.7

62.1

56.6

81.5

57.2

44.0

39.4

92.1 87.1

88.0

83.8

94.4

48.8

56.8

55.6

68.3 69.0

71.9

66.9

85.6

54.4

63.1

63.3

73.5 71.7

75.6

67.5

83.0

36.4

73.0

66.7

93.8 92.2

93.5

91.6

97.5

52.4

57.7

44.3

90.7 90.4

91.5

88.0

95.9

50.3

55.5

53.0

85.0 86.5

88.1

82.6

95.2

Mean

63.1

50.6

58.8

55.2

78.7 77.7

79.8

74.5

89.6

Table 10: AUROC (%) values of our method trained on one-class ImageNet-30. The ﬁrst and third row indicates the selected class, and the second and ﬁrth row indicates the corresponding results.

0

1

2

3

4

5

6

7

8

9 10 11 12 13 14

85.9 99.0 99.8 90.5 95.8 99.2 96.6 83.5 92.2 84.3 99.0 94.5 97.1 87.7 96.4

15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 84.7 99.7 75.6 95.2 73.8 94.7 95.2 99.2 98.5 82.5 89.7 82.1 97.2 82.1 97.6

19

D Ablation study on random augmentation
We verify that ensembling the scores over the random augmentations T improves OOD detection. However, naïve random sampling from the entire T is often sample inefﬁcient. We ﬁnd that choosing a proper subset Tcontrol ⊂ T improves the performance for given number of samples. Speciﬁcally, we choose Tcontrol as the set of the most common samples. For example, the size of the cropping area is sampled from U[0.08, 1] for uniform distribution U during training. Since the rare samples, e.g., area near 0.08 increases the noise, we only use the samples with size (0.08 + 1)/2 = 0.54 during inference. Table 11 shows random sampling from the controlled set often gives improvements.

Table 11: AUROC (%) values of our method for different number of random augmentations, under one-class (OC-) CIFAR-10 and CIFAR-100 (super-class). The values are averaged over classes. Random augmentations over the controlled set show the best performance.

# of samples Controlled OC-CIFAR-10 OC-CIFAR-100

4

-

92.22

87.36

40

-

94.13

89.51

40

94.31

89.55

E Efﬁcient computation of (6) via coreset
One can reduce the computation and memory cost of the contrastive score (6) by selecting a proper subset, i.e., coreset, of the training samples. To this end, we run K-means clustering [44] on the normalized features Wm := z(xm)/ z(xm) using cosine similarity as a metric. Then, we use the center of each cluster as the coreset. For contrasting shifted instances (4), we choose the coreset for each shifting transformation S. Table 12 shows the results for various coreset sizes, given by a ratio from the full training samples. Keeping only a few (e.g., 1%) samples is sufﬁcient.

Table 12: AUROC (%) values of our method for various corset sizes (% of training samples), under one-class (OC-) CIFAR-10, CIFAR-100 (super-class), and ImageNet-30. The values are averaged over classes. Keeping only a few (e.g., 1%) samples shows sufﬁciently good results.

Coreset (%) OC-CIFAR-10 OC-CIFAR-100 OC-ImageNet-30

1% 10% 100%

94.22 94.30 94.31

89.27 89.46 89.55

91.06 91.51 91.63

20

F Ablation study on the balancing terms
We study the effects of the balancing terms λcSon, λcSls in Section 2.3. To this end, we compare of our ﬁnal loss (5), without (w/o) and with (w/) the balancing terms λcSon and λcSls. When not using the balancing terms, we set λcSon = λcSls = 1 for all S. We follow the experimental setup of Table 1, e.g., use rotation for the shifting transformation. We run our experiments on CIFAR-10, CIFAR-100 (super-class), and ImageNet-30 datasets. Table 13 shows that the balancing terms gives a consistent improvement. CIFAR-10 do not show much gain since all λcSon and λcSls show similar values; in contrast, CIFAR-100 (super-class) and ImageNet-30 show large gain since they varies much.

Table 13: AUROC (%) values of our method without (w/o) and with (w/) balancing terms, under one-class (OC-) CIFAR-10, CIFAR-100 (super-class), and ImageNet-30. The values are averaged over classes, and bold denotes the best results. Balancing terms give consistent improvements.

OC-CIFAR-10 OC-CIFAR-100 OC-ImageNet-30

CSI (w/o balancing) CSI (w/ balancing)

94.28 94.31

89.00 89.55

91.04 91.63

G Combining multiple shifting transformations
We ﬁnd that combining multiple shifting transformations: given two transformations S1 and S2, use S1 × S2 as the combined shifting transformation, can give further improvements. Table 14 shows that combining “Noise”, “Blur”, and “Perm” to “Rotate” gives additional gain. We remark that one can investigate the better combination; we choose rotation for our experiments due to its simplicity.

Table 14: AUROC (%) values of our method under various shifting transformations. Combining “Noise”, “Blur”, and “Perm” to “Rotate” gives additional gain.

Base Noise Blur Perm Rotate Rotate+Noise Rotate+Blur Rotate+Perm

AUROC 87.89 89.29 89.15 90.68 94.31

94.65

94.66

94.60

21

H Discussion on the features of the contrastive score (6)
We ﬁnd that the two features: a) the cosine similarity to the nearest training sample in {xm}, i.e., maxm sim(z(xm), z(x)), and (b) the feature norm of the representation, i.e., z(x) , are important features for detecting OOD samples under the SimCLR representation.
In this section, we ﬁrst demonstrate the properties of the two features under vanilla SimCLR. While we use the vanilla SimCLR to validate they are general properties of SimCLR, we remark that our training scheme (see Section 2.2) further improves the discrimination power of the features. Next, we verify that cosine similarity and feature norm are complementary, that combining both features (i.e., scon (6)) give additional gain. For the latter one, we use our ﬁnal training loss to match the reported values in prior experiments, but we note that the trend is consistent among the models.
First, we demonstrate the effect of cosine similarity for OOD detection. To this end, we train vanilla SimCLR using CIFAR-10 and CIFAR-100 and in- and out-of-distribution datasets. Since SimCLR attracts the same image with different augmentations, it learns to cluster similar images; hence, it shows good discrimination performance measured by linear evaluation [5]. Figure 3a presents the t-SNE [43] plot of the normalized features that each color denote different class. Even though SimCLR is trained in an unsupervised manner, the samples of the same classes are gathered.
Figure 3b and Figure 3c presents the histogram of the cosine similarities from the nearest training sample (i.e., maxm sim(z(xm), z(x))), for training and test datasets, respectively. For the training set, we choose the second nearest sample since the nearest one is itself. One can see that training samples are concentrated, even though contrastive learning pushes the different samples. It complements the results of Figure 3a. For test sets, the in-distribution samples show a similar trend with the training samples. However, the OOD samples are farther from the training samples, which implies that the cosine similarity is an effective feature to detect OOD samples.

(a) t-SNE visualization

(b) Similarities (train) Figure 3: Plots for cosine similarity.

(c) Similarities (test)

22

Second, we demonstrate that the feature norm is a discriminative feature for OOD detection. Following the prior setting, we use CIFAR-10 and CIFAR-100 for in- and out-of-distribution datasets, respectively. Figure 4a shows that the discriminative power of feature norm improves as the training epoch increases. We observe that this phenomenon consistently happens over models and settings; the contrastive loss makes the norm of in-distribution samples relatively larger than OOD samples. Figure 4b shows the norm of CIFAR-10 is indeed larger than CIFAR-100, under the ﬁnal model.
This is somewhat unintuitive since the SimCLR uses the normalized features to compute the loss (1). To understand this phenomenon, we visualize the t-SNE [43] plot of the feature space in Figure 4c, randomly choosing 100 images from both datasets. We randomly augment each image for 100 times for better visualization. One can see that in-distribution samples tend to be spread out over the large sphere, while OOD samples are gathered near center.4 Also, note that the same image with different augmentations are highly clustered, while in-distribution samples are slightly more assembled.5
We suspect that increasing the norm may be an easier way to maximize cosine similarity between two vectors: instead of directly reducing the feature distance of two augmented samples, one can also increase the overall norm of the features to reduce the relative distance of two samples.

(a) Trend of AUROC

(b) Histogram of norms Figure 4: Plots for feature norm.

(c) t-SNE visualization

Finally, we verify that cosine similarity (sim-only) and feature norm (norm-only) are complementary: combining them (sim+norm) gives additional improvements. Here, we use the model trained by our ﬁnal objective (5), and follow the inference scheme of the main experiments (see Table 7). Table 15 shows AUROC values under sim-only, norm-only, and sim+norm scores. Using only sim or norm already shows good results, but combining them shows the best results.

Table 15: AUROC (%) values for sim-only, norm-only, and sim+norm (i.e., contrastive (6)) scores, under one-class (OC-) CIFAR-10, CIFAR-100 (super-class), and ImageNet-30. The values are averaged over classes. Using both sim and norm features shows the best results.

OC-CIFAR-10 OC-CIFAR-100 OC-ImageNet-30

Sim-only Norm-only Sim+Norm

90.12 92.70 93.32

86.57 87.71 88.79

83.18 88.56 89.32

4t-SNE plot does not tell the true behavior of the original feature space, but it may give some intuition. 5We also try the local variance of the norm as a detection score. It also works well, but the norm is better.
23

I Rethinking OOD detection benchmarks

We ﬁnd that resized LSUN and ImageNet [39], one of the most popular benchmark datasets for OOD detection, are visually far from in-distribution datasets (commonly, CIFAR [33]). Figure 5 shows that resized LSUN and ImageNet contain artiﬁcial noises, produced by broken image operations.6 It is problematic since one can detect such datasets with simple data statistics, without understanding semantics from neural networks. To progress OOD detection research one step further, one needs more hard or semantic OOD samples that cannot be easily detected by data statistics.
To verify this, we propose a simple detection score that measures the input smoothness of an image. Intuitively, noisy images would have a higher variation in input space than natural images. Formally, let x(i,j) be the i-th value of the vectorized image x ∈ RHW K . Here, we deﬁne the neighborhood N as the set of spatially connected pairs of pixel indices. Then, the total variation distance is given by

TV(x) =

x(i) − x(j) 22.

(14)

i,j∈N

Then, we deﬁne the smoothness score as the difference of total variation from the training samples:

1 ssmooth(x) := |TV(x) − M TV(xm)|. (15)
m

Table 16 shows that this simple score detects current benchmark datasets surprisingly well.
To address this issue, we construct new benchmark datasets, using a ﬁxed resize operation7, hence coined LSUN (FIX) and ImageNet (FIX). For LSUN (FIX), we randomly sample 1,000 images from every ten classes of the training set of LSUN. For ImageNet (FIX), we randomly sample 10,000 images from the entire training set of ImageNet-30, excluding “airliner”, “ambulance”, “parkingmeter”, and “schooner” classes to avoid overlapping with CIFAR-10.8 Figure 6 shows that the new datasets are more visually realistic than the former ones (Figure 5). Also, Table 16 shows that the ﬁxed datasets are not detected by the simple data statistics (15). We believe our newly produced datasets would be a stronger benchmark for hard or semantic OOD detection for future researches.

Figure 5: Current benchmark datasets: resized LSUN (left two) and ImageNet (right two).
Figure 6: Proposed datasets: LSUN (FIX) (left two) and ImageNet (FIX) (right two). 6It is also reported in https://twitter.com/jaakkolehtinen/status/1258102168176951299. 7We use PyTorch torchvision.transforms.Resize() operation. 8We provide the datasets and data generation code in https://github.com/alinlab/CSI.
24

Table 16: AUROC (%) values using the smoothness score (15), under unlabeled CIFAR-10. Bold denotes the values over 80%, which implies the dataset is easily detected.

CIFAR10 →

SVHN LSUN ImageNet LSUN (FIX) ImageNet (FIX) CIFAR-100 Interp.

85.88 95.70 90.53

44.13

52.76

52.14

66.17

J Additional examples of rotation-invariant images
We provide additional examples of rotation-invariant images (see Table 6 in Section 3.2). Those image commonly appear in real-world scenarios since many practical applications deal with non-natural images, e.g., manufacturing - steel [62] or textile [60] for instance, or aerial [70] images. Figure 7 and Figure 8 visualizes the samples of manufacturing and aerial images, respectively.

Figure 7: Examples of steel (left two) and textile (right two) images.

Figure 8: Examples of aerial images.

25

