arXiv:1806.05085v2 [stat.ML] 13 Sep 2018

Your 2 is My 1, Your 3 is My 9: Handling Arbitrary Miscalibrations in Ratings
Jingyan Wang and Nihar B. Shah
School of Computer Science Carnegie Mellon University {jingyanw,nihars}@cs.cmu.edu
Abstract
Cardinal scores (numeric ratings) collected from people are well known to suﬀer from miscalibrations. A popular approach to address this issue is to assume simplistic models of miscalibration (such as linear biases) to de-bias the scores. This approach, however, often fares poorly because people’s miscalibrations are typically far more complex and not well understood. In the absence of simplifying assumptions on the miscalibration, it is widely believed by the crowdsourcing community that the only useful information in the cardinal scores is the induced ranking. In this paper, inspired by the framework of Stein’s shrinkage, empirical Bayes, and the classic two-envelope problem, we contest this widespread belief. Speciﬁcally, we consider cardinal scores with arbitrary (or even adversarially chosen) miscalibrations which are only required to be consistent with the induced ranking. We design estimators which despite making no assumptions on the miscalibration, strictly and uniformly outperform all possible estimators that rely on only the ranking. Our estimators are ﬂexible in that they can be used as a plug-in for a variety of applications, and we provide a proof-of-concept for A/B testing and ranking. Our results thus provide novel insights in the eternal debate between cardinal and ordinal data.
1 Introduction
“A raw rating of 7 out of 10 in the absence of any other information is potentially useless.” [MGCV11] “The rating scale as well as the individual ratings are often arbitrary and may not be consistent from one user to another.” [AS12]
Consider two items that need to be evaluated (for example, papers submitted to a conference) and two reviewers. Suppose each reviewer is assigned one distinct item for evaluation, and this assignment is done uniformly at random. The two reviewers provide their evaluations (say, in the range [0, 1]) for the respective item they evaluate, from which the better item must be chosen. However, the reviewers’ rating scales may be miscalibrated. It might be the case that the ﬁrst reviewer is lenient and always provides scores in [0.6, 1] whereas the second reviewer is more stringent and provides scores in the range [0, 0.4]. Or it might be the case that one reviewer is moderate whereas the other is extreme – the ﬁrst reviewer’s 0.2 is equivalent to the second reviewer’s 0.1 whereas the ﬁrst reviewer’s 0.3 is equivalent to the second reviewer’s 0.9. More generally, the miscalibration of the reviewers may be arbitrary and unknown. Then is there any hope of identifying the better of the two items with any non-trivial degree of certainty?
A variety of applications involve collection of human preferences or judgments in terms of cardinal scores (numeric ratings). A perennial problem with eliciting cardinal scores is that of miscalibration – the systematic errors introduced due to incomparability of cardinal scores provided by diﬀerent people (see [GB08] and references therein).
1

This issue of miscalibration is sometimes addressed by making simplifying assumptions about the form of miscalibration, and post-hoc corrections under these assumptions. Such models include one-parameterper-reviewer additive biases [Pau81, BK13, GWG13, MKLP17], two-parameters-per-reviewer scale-and-shift biases [Pau81, RRS11] and others [FSG+10]. The calibration issues with human-provided scores are often signiﬁcantly more complex causing signiﬁcant violations to these simpliﬁed assumptions (see [GB08] and references therein). Moreover, the algorithms for post-hoc correction often try to estimate the individual parameters which may not be feasible due to low sample sizes. For instance, John Langford notes from his experience as the program chair of the ICML 2012 conference [Lan12]:
“We experimented with reviewer normalization and generally found it signiﬁcantly harmful.”
This problem of low sample size is exacerbated in a number of applications such as A/B testing where every reviewer evaluates only one item, thereby making the problem underdetermined even under highly restrictive models.
It is commonly believed that when unable or unwilling to make any simplifying assumptions on the bias in cardinal scores, the only useful information is the ranking of the scores [Rok68, FISS03, HBBR+09, MGCV11, AS12, NOS12]. This perception gives rise to a second approach towards handling miscalibrations – that of using only the induced ranking or otherwise directly eliciting a ranking and not scores from the use. As noted by Freund et al. [FISS03]:
“[Using rankings instead of ratings] becomes very important when we combine the rankings of many viewers who often use completely diﬀerent ranges of scores to express identical preferences.”
These motivations have spurred a long line of literature on analyzing data that takes the form of partial or total rankings of items [CGPR07, BK09, AS12, NOS12, RGLA15, SBB+16, SW18].
In this paper, we contest this widely held belief with the following two fundamental questions:
• In the absence of simplifying modeling assumptions on the miscalibration, is there any estimator (based on the scores) that can outperform estimators based on the induced rankings?
• If only one evaluation per reviewer is available, and if each reviewer may have an arbitrary (possibly adversarially chosen) miscalibration, is there hope of estimation better than random guessing?
We show that the answer to both questions is “Yes”. One need not make simplifying assumptions about the miscalibration and yet guarantee a performance superior to that of any estimator that uses only the induced rankings.
In more detail, we consider settings where a number of people provide cardinal scores for one or more from a collection of items. The calibration of each reviewer is represented by an unknown monotonic function that maps the space of true values to the scores given by this reviewer. These functions are arbitrary and may even be chosen adversarially. We present a class of estimators based on cardinal scores given by the reviewers which uniformly outperforms any estimator that uses only the induced rankings. A compelling feature of our estimators is that they can be used as a plug-in to improve ranking-based algorithms in a variety of applications, and we provide a proof-of-concept for two applications: A/B testing and ranking.
The techniques used in our analyses draw inspiration from the framework of Stein’s shrinkage [Ste56, JS61] and empirical Bayes [Rob56]. Moreover, our setting with 2 reviewers and 2 papers presented subsequently in the paper carries a close connection to the classic two-envelope problem (for a survey of the two-envelope problem, see [Gne16]), and our estimator in this setting is similar in spirit to the randomized strategy [Cov87] proposed by Thomas Cover. We discuss connections with the literature in more detail in Section 3.1.1.
Our work provides a new perspective on the eternal debate between cardinal scores and ordinal rankings. It is often believed that ordinal rankings are a panacea for the miscalibration issues with cardinal scores. Here we show that ordinal estimators are not only inadmissible, they are also strictly and uniformly beaten by our cardinal estimators. Our results thus uncover a new point on the bias-variance tradeoﬀ for this class of problems: Estimators that rely on simpliﬁed assumptions about the miscalibration incur biases due to model mismatch, whereas the absence of such assumptions in our work eliminates the modeling bias. Moreover, in
2

this minimal-bias regime, our cardinal estimators incur a strictly smaller variance as compared to estimators based on ordinal data alone.
Finally, a note qualifying the scope of the problem setting considered here. In applications such as crowdsourced microtasks where workers often spend very little time answering every question, the cardinal scores elicited may not necessarily be consistent with the ordinal rankings, and moreover, ordinal rankings are often easier and faster to provide. These diﬀerences cease to exist in a variety of applications such as peer-review or in-person laboratory A/B tests which require the reviewers to spend a non-trivial amount of time and eﬀort in the review process, and these applications form the motivation of this work.

2 Preliminaries

Consider a set of n items denoted as {1, . . . , n} or [n] in short.1 Each item i ∈ [n] has an unknown value xi ∈ R. For ease of exposition, we assume that all items have distinct values. There are m reviewers {1, . . . , m} and each reviewer evaluates a subset of the items. The calibration of any reviewer j ∈ [m] is given by an unknown, strictly-increasing function fj : R → R. (More generally, our results hold for any non-singleton intervals on the real line as the domain and range of the calibration functions). When reviewer j evaluates item i, the reported score is fj(xi). We make no other assumptions on the calibration functions f1, . . . , fm. We use the notation to represent a relative order of any items, for instance, we use “1 2” to say that item 1 has a larger value (ranked higher) than item 2. We assume that m and n are ﬁnite.
Every reviewer is assigned one or more items to evaluate. We denote the assignment of items to reviewers as A = (S1, . . . , Sm), where Sj ⊆ [n] is the set of items assigned to reviewer j ∈ [m]. We use the notation Π to represent the set of all permutations of n items. We let π∗ ∈ Π denote the ranking of the n items induced by their respective values (x1, . . . , xn), such that xπ∗(1) > xπ∗(2) > · · · > xπ∗(n). The goal is to estimate this ranking π∗ from the evaluations of the reviewers. We consider two types of settings: an ordinal setting where estimation is performed using the rankings induced by each reviewer’s reported scores, and a cardinal setting where the estimation is performed using the reviewers’ scores (which can have an arbitrary miscalibration and only need to be consistent with the rankings). Formally:

• Ordinal: Each reviewer j reports a total ranking among the items in Sj, that is, the ranking of the items induced by the values {fj(xi)}i∈Sj . An ordinal estimator observes the assignment A and the rankings reported by all reviewers.

• Cardinal: Each reviewer j reports the scores for the items in Sj, that is, the values of {fj(xi)}i∈Sj . A cardinal estimator observes the assignment A and the scores reported by all reviewers.

Observe that the setting described above considers “noiseless” data, where each reviewer reports either

the scores {fj(xi)} or the induced rankings. We provide an extension to the noisy setting in Appendix A.

In order to compare the performance of diﬀerent estimators, we use the notion of strict uniform dominance.

Informally, we say that one estimator strictly uniformly dominates another if it incurs a strictly lower risk for

all possible choices of the miscalibration functions and the item values.

In more detail, suppose that you wish to show that an estimator π1 is superior to estimator π2 with respect to some metric for estimating π∗. However, there is a clever adversary who intends to thwart your

attempts. The adversary can choose the miscalibration functions of all reviewers and the values of all items,

and moreover, can tailor these choices for diﬀerent realizations of π∗. Formally, the adversary speciﬁes a set of

values

{f

π 1

,

.

.

.

,

f

π m

,

xπ1

,

.

.

.

,

x

π n

}

π

∈

Π

.

The

only

constraints

in

this

choice

are

that

the

miscalibration

functions

f

π 1

,

.

.

.

,

f

π m

must

be

strictly

monotonic

and

that

the

item

values

x

π 1

,

.

.

.

,

x

π n

should

induce

the

ranking

π.

In the sequel, we consider two ways of choosing the true ranking π∗: In one setting, π∗ can be chosen by

the adversary, and in the second setting π∗ is drawn uniformly at random from Π. Once this ranking π∗

is chosen, the actual values of the miscalibration functions and the item values are set as f1π∗ , . . . , fmπ∗ and

x

π 1

∗

,

.

.

.

,

x

π∗ n

.

The

items

are

then

assigned

to

reviewers

according

to

the

(possibly

random)

assignment

A.

The reviewers now provide their ordinal or cardinal evaluations as described earlier, and these evaluations are

1We use the standard notation of [κ] to denote the set {1, . . . , κ} for any positive integer κ.

3

used to compute and evaluate the two estimators π1 and π2. We say that estimator π1 strictly uniformly dominates π2, if π1 is always guaranteed to incur a strictly smaller (expected) error than π2. Formally:

Deﬁnition 1 (Strict uniform dominance) Let π1 and π2 be two estimators for the true ranking π∗. Estimator π1 is said to strictly uniformly dominate estimator π2 with respect to a given loss L : Π × Π → R if

E[L(π∗, π1)] < E[L(π∗, π2)]

for all permissible

{

f1π

,

.

.

.

,

f

π m

,

xπ1

,

.

.

.

,

x

π n

}π

∈

Π

.

(1)

The expectation is taken over any randomness in the assignment A and the estimators. If the true ranking π∗ is drawn at random from a ﬁxed distribution, then the expectation is also taken over this distribution; otherwise, inequality (1) must hold for all values of π∗.

Note that strict uniform dominance is a stronger notion than comparing estimators in terms of their minimax (worst-case) or average-case risks. Moreover, if an estimator π2 is strictly uniformly dominated by some estimator π1, then the estimator π2 is inadmissible.
Finally, for ease of exposition, we focus on the 0-1 loss in the main text:

L(π∗, π) = 1{π∗ = π},

where we use the standard notation 1{A} to denote the indicator function of an event A, where 1{A} = 1 if
the event A is true, and 0 otherwise. Extensions to other metrics of Kendall-tau distance and Spearman’s footrule distance are provided in Appendix B.

3 Main results
In this section we present our main theoretical results. All proofs are provided in Section 5.

3.1 A canonical setting
We begin with a canonical setting that involves two items and two reviewers (that is, n = 2, m = 2), where each reviewer evaluates one of the two items. Our analysis for this setting conveys the key ideas underlying our general results. These ideas are directly applicable towards designing uniformly superior estimators for a variety of applications, and we subsequently demonstrate this general utility with two applications.
In this canonical setting, each of the two reviewers evaluates one of the two items chosen uniformly at random without replacement, that is, the assignment A is chosen uniformly at random from the two possibilities (S1 = 1, S2 = 2) and (S1 = 2, S2 = 1). Since each reviewer is assigned only one item, the ordinal data is vacuous. Then the natural ordinal baseline is an estimator which makes a guess uniformly at random:

1 πcan(A, {}) =
2

2 with probability 0.5 1 with probability 0.5.

In the cardinal setting, let y1 denote the score reported for item 1 by its respective reviewer, and let y2 denote the score for item 2 reported by its respective reviewer. Since the calibration functions are arbitrary (and may be adversarial), it appears hopeless to obtain information about the relative values of x1 and x2 from just this data. Indeed, as we show below, standard estimators such as the sign test — ranking the items in terms of their reviewer-provided scores — provably fail to achieve this goal. More generally, the following theorem holds for the class of all deterministic estimators, that is, estimators given by deterministic mappings from {A, y1, y2} to the set {1 2, 2 1}.
Theorem 1 No deterministic (cardinal or ordinal) estimator can strictly uniformly dominate the randomguessing estimator πcan.

4

This theorem demonstrates the diﬃculty of this problem by ruling out all deterministic estimators. Our original question then still remains: is there any estimator that can strictly uniformly outperform the random-guessing ordinal baseline?
We show that the answer is yes, with the construction of a randomized estimator for this canonical setting, denoted as πcoaunr. This estimator is based on a function w : [0, ∞) → [0, 1) which may be chosen as any arbitrary strictly-increasing function. For instance, one could choose w(x) = 1+xx or w as the sigmoid function. Given the scores y1, y2 reported for the two items, let i(1) ∈ argmaxi∈{1,2} yi denote the item which receives the higher score, and let i(2) denote the remaining item (with ties broken uniformly). Then our randomized estimator outputs:
πcoaunr(A, y1, y2) = ii((12)) ii((21)) wotihtherpwrioseb.ability 1+w(|y21−y2|) (2)
Note that the the output of this estimator is independent of the assignment A, so in the remainder of this paper we also denote this estimator as πcoaunr(y1, y2).
The following theorem now proves that our proposed estimator indeed achieves the stated goal.
Theorem 2 The randomized estimator πcoaunr strictly uniformly dominates the random-guessing baseline πcan.
While this result considers a setting with “noiseless” observations (that is, where y = f (x)), in Appendix A we show that the guarantee for πcoaunr continues to hold when the observations are noisy.
Having established the positive result for this canonical setting, we now discuss some connections and inspirations in the literature.
3.1.1 Connections to the literature
The canonical setting has a close connection to the randomized version of the two-envelope problem [Cov87]. In the two-envelope problem, there are two arbitrary numbers. One of the two numbers is observed uniformly at random, and the other remains unknown. The goal is to estimate which number is larger. This problem can also be viewed from a game-theoretic perspective [Gne16] as ours, where one player picks an estimator and the other player picks the two values. Cover [Cov87] proposed a randomized estimator whose probability of success is strictly larger than 0.5 uniformly across all arbitrary pairs of numbers. The proposed estimator samples a new random variable Z whose distribution has a probability density function p with p(z) > 0 for all z ∈ R. Then if the observed number is smaller than Z, the estimator decides that the observed number is the smaller number; if the observed number is larger than Z, the estimator decides that the observed number is the larger number.
Our canonical setting can be reduced to the two-envelope problem as follows. Consider the two values f1(x1)−f2(x2) and f1(x2)−f2(x1). Since the two items are assigned to the two reviewers uniformly at random, we observe one of these two values uniformly at random. By the assumption that f1 and f2 are monotonically increasing, we know that these two values are distinct, and furthermore, f1(x1) − f2(x2) > f1(x2) − f2(x1) if and only if x1 > x2. Hence, the relative ordering of these two values is identical to the relative ordering of x1 and x2, reducing our canonical setting to the two-envelope problem. Our estimator πcoaunr also carries a close connection to Cover’s estimator to the two-envelope problem. Speciﬁcally, Cover’s estimator can be equivalently viewed as being designated by a “switching function” [MA09]. This switching function speciﬁes the probability to “switch” (that is, to guess that the unobserved value is larger), and is a monotonically-decreasing function in the observed value. The use of the monotonic function w in our estimator in (2) is similar in spirit.
The two-envelope problem can also be alternatively viewed as a secretary problem with two candidates. Negative results have been shown regarding the eﬀect of cardinal vs. ordinal data when there are more than two candidates [SN92, Gne94], and positive result has been shown on extensions of the secretary problem to diﬀerent losses [GK96].
Our original inspiration for our proposed estimator arose from Stein’s phenomenon [Ste56] and empirical Bayes [Rob56]. This inspiration stems for the fact that the two items are not to be estimated in isolation, but in
5

a joint manner. That said, a signiﬁcant fraction of the work (e.g., [Rob56, Ste56, JS61, Bar70, Boc75, TKV17]) in these areas is based on deterministic estimators. In comparison, our negative result for all deterministic estimators (Theorem 1) and the positive result for our randomized estimator (Theorem 2) provide interesting insights in this space.

3.2 A/B testing
We now demonstrate how to use the result in the canonical setting as a plug-in for more general scenarios. Speciﬁcally, we construct simple extensions to our canonical estimator, as a proof-of-concept for the superiority of cardinal data over ordinal data in A/B testing (this section) and ranking (Section 3.3). A/B testing is concerned with the problem of choosing the better of two given items, based on multiple evaluations of each item, and is used widely for the web and e-commerce (e.g. [KLSH09]). In many applications of A/B testing, the two items are rated by disjoint sets of individuals (for example, when comparing two web designs, each user sees one and only one design). It is therefore important to take into account the diﬀerent calibrations of diﬀerent individuals, and this problem ﬁts in our setting with n = 2 items and m reviewers. For simplicity, we assume that m is even. We consider the assignment obtained by assigning item 1 to some m/2 reviewers chosen uniformly at random (without replacement) from the set of m reviewers, and assigning item 2 to the remaining m/2 reviewers.2
As in the canonical setting we studied earlier, in the absence of any direct comparison between the two items, a natural ordinal estimator in the A/B testing setting is a random guess:

1 πab(A, {}) =
2

2 with probability 0.5 1 with probability 0.5.

For concreteness, we consider the following method of performing the random assignment of the two items

to the m reviewers. We ﬁrst perform a uniformly random permutation of the m reviewers, and then assign

the ﬁrst m/2 reviewers in this permutation to item 1; we assign the last m/2 reviewers in this permutation to

item 2. We let y1(1), . . . , y1(m/2) denote the scores given by the m/2 reviewers to item 1, and let y2(1), . . . , y2(m/2) denote the scores given by the m/2 reviewers assigned to item 2. Namely, the reviewers (in the permuted order)

provide

the

scores

[

y

(1) 1

,

.

.

.

,

y

(m/ 1

2)

,

y2(1)

,

.

.

.

,

y

(m/2) 2

]

.

Now consider the following standard (deterministic)

estimators:

• Sign estimator: The sign estimator outputs the item which has more pairwise wins:

1 m/2

(j)

(j) 1 2

j=1 {y1 > y2 } ≷

21

m/2 j=1

1{y2(j)

>

y1(j)}.

• Mean estimator: The mean estimator outputs the item with the higher mean score:

(1)

(m/2) 1 2

(1)

(m/2)

mean(y1 , . . . , y1 ) ≷ mean(y2 , . . . , y2 ).

21

• Median estimator: The median estimator outputs the item with the higher median score (upper median if there are multiple medians)3: median(y1(1), . . . , y1(m/2)) 1≷2 median(y2(1), . . . , y2(m/2)).
21
In each estimator, ties are assumed to be broken uniformly at random. We now show that despite using the scores given by all m reviewers, where m can be arbitrarily large,
these natural estimators fail to uniformly dominate the naïve random-guessing ordinal estimator.
2Our results also hold in the following settings: (a) Each reviewer is assigned one of the two items independently and uniformly at random. (b) Reviewers are grouped (in any arbitrary manner) into m/2 pairs, and within each pair, the two reviewers are assigned one distinct item each uniformly at random.
3For values a1 ≥ · · · ≥ an, we deﬁne the median function as the upper median, median(a1, . . . , an) = a (n+1)/2 . Theorem 3 also holds instead for the lower median a (n+2)/2 , and the median deﬁned as the mean of the two middle values, (a (n+1)/2 + a (n+2)/2 )/2.

6

Theorem 3 For any (even) number of reviewers, none of the sign, mean, and median estimators can strictly uniformly dominate the random-guessing estimator πab.
The negative result of Theorem 3 demonstrates the challenges even when one is allowed to collect an arbitrarily large number of scores for each item. Intuitively, the more reviewers there are, the more miscalibration functions they introduce. Even if the statistics used by these estimators converge as the number of the reviewers m grows large, these values are not guaranteed to be informative towards comparing the values of the items due to the miscalibrations.
The failure of these standard estimators suggests the need of a novel approach towards this problem of A/B testing under arbitrary miscalibrations. To this end, we build on top of our canonical estimator πcoaunr from Section 3.1, and present a simple randomized estimator πaobur as follows:
(1) For every j ∈ [m/2], use the canonical estimator πcoaunr on the jth pair of scores (y1(j), y2(j)) and obtain the estimate rj := πcoaunr(y1(j), y2(j)) ∈ {1 2, 2 1}.
(2) Set the output πaobur as the outcome of the majority vote among the estimates {rj}j∈[m/2] with ties broken uniformly at random.
The following theorem now shows that the results for the canonical setting from Section 3.1 translate to this A/B testing application.
Theorem 4 For any (even) number of reviewers, the estimator πaobur strictly uniformly dominates the random guessing estimator πab.
This result thus illustrates the use of our canonical estimator πcoaunr as a plug-in for A/B testing. So far we have considered settings where there are only two items and where each reviewer is assigned only one item, thereby making the ordinal information vacuous. We now turn to an application that is free of these restrictions.

3.3 Ranking

It is common in practice to estimate the partial or total ranking for a list of items by soliciting ordinal

or cardinal responses from individuals. In conference reviews or peer-grading, each reviewer is asked to

rank [Dou09, SBP+13, STM+17] or rate [GWG13, PHC+13, STM+17] a small subset of the papers, and this

information is subsequently used to estimate a partial or total ranking of the papers (or student homework).

Other applications for aggregating rankings include voting [You88, PSZ16], crowdsourcing [SBB+16, SW18],

recommendation systems [FISS03] and meta-search [DKNS01].

Formally, we let n > 2 denote the number of items and m denote the number of reviewers. For simplicity,

we focus on a setting where each reviewer reports noiseless evaluations of some pair of items, and the goal is

to estimate the total ranking of all items. We consider a random design setup where the pairs compared

are randomly chosen and randomly assigned to reviewers. We assume 1 < m < n2 so that the problem

does not degenerate. Each reviewer evaluates a pair of items, and these pairs are drawn uniformly without

replacement from the

n 2

possible pairs of items. We let A = (S1, . . . , Sm) denote these m pairs of items

to be evaluated by the m respective reviewers, where Sj ∈ [n] × [n] denotes the pair of items evaluated by

reviewer j ∈ [m]. For each pair Sj = (i, i ), denote the cardinal evaluation as y(Sj) = (fj(xi), fj(xi )), and

the ordinal evaluation as the induced ranking b(Sj) ∈ {i i , i i}. Denote the set of ordinal observations as B = {b(Sj)}m j=1, and the set of cardinal observations as Y = {y(Sj)}m j=1. The input to an ordinal estimator is the ordinal information B. The input to a cardinal estimator is the reviewer assignment A and the set of

cardinal observations Y. Finally, let G(B) denote a directed acyclic graph (DAG) with nodes comprising the

n items and with an edge from any node i to any other node i if and only if {i i } ∈ B. A topological

ordering on G is any total ranking of its vertices which does not violate any pairwise comparisons indicated

by B.

We

now

present

our

(randomized)

cardinal

estimator

π

our rank

(

A,

Y

)

in

Algorithm

1.

In

words,

this

algorithm

start from any topological ordering of the items as the initial estimate of the true ranking. Then the algorithm

7

Algorithm 1: Our cardinal ranking estimator πroaunrk(A, Y).

1 Deduce the ordinal observations B from the cardinal observations Y.

2 Compute a topological ordering π on the graph G(B), with ties broken in order of the indices of the

items.

3 t ← 1.

4 while t < n do

5 Let πﬂip be the ranking obtained by ﬂipping the positions of the tth and the (t + 1)th items in π.

6 if πﬂip is a topological ordering on G(B), and both the tth and (t + 1)th items are evaluated by at

least one reviewer each in Y then

7

From all of the scores of the tth item in Y, sample one uniformly at random and denote it as

yπ(t). Likewise denote yπ(t+1) as a randomly chosen score of the (t + 1)th item from Y.

8

Consider the two reviewers reporting the scores yπ(t) and yπ(t+1). Remove from Y all scores

provided by these two reviewers.

9

if πcoaunr(yπ(t), yπ(t+1)) outputs π(t + 1) π(t) then

10

π ← πﬂip.

11

end

12

t ← t + 2.

13 else

14

t ← t + 1.

15 end

16 end 17 Output πroaunrk(A, Y) = π.

scans one-by-one over the pairs with adjacent items in the initial estimated ranking. If a pair can be ﬂipped (that is, if the ranking after ﬂipping this pair is also a topological ordering), we uniformly sample a pair of scores for these two items from the cardinal observations Y, and use the randomized estimator πcoaunr to determine the relative order of the pair. After πcoaunr is called, the positions of this pair are ﬁnalized. We remove all scores of these two reviewers from future use, and jump to the next pair that does not contain these two items.
The following theorem now presents the main result of this section.
Theorem 5 Suppose that the true ranking π∗ is drawn uniformly at random from the collection of all possible rankings, and consider any ordinal estimator πrank for π∗. Then the cardinal estimator πroaunrk strictly uniformly dominates the ordinal estimator πrank.
We note that Algorithm 1 runs in polynomial time (in the number of items n) because the two major operations of this estimator – ﬁnding a topological ordering, and checking if a ranking is a topological ordering on the DAG – can be implemented in polynomial time [DPV08]. Theorem 5 thus demonstrates again the power of the canonical estimator πcoaunr as a plug-in component to be used in a variety of applications. An extension of our results to the setting where π∗ can be arbitrary (adversarially chosen) is presented in Appendix C.
4 Simulations
We now experimentally evaluate our proposed estimators for A/B testing and ranking. Since the performance of the ordinal estimators vary signiﬁcantly in diﬀerent problem instances, we use the notion of “relative improvement”. The relative improvement ρπ(π) of an estimator π as compared to a baseline estimator π is deﬁned as: ρπ(π) = E[L(π∗E,[πL)(]π−∗E,[πL)(]π∗,π)] × 100%. A positive value of the relative improvement ρπ(π) indicates the superiority of estimator π over the estimator π. A relative improvement of zero indicates an identical performance of the two estimators. In our proposed estimators, the function w is set as w(x) = 1+xx .
8

Relative improvement
in exact recovery (%)

100

20

20

mean sign

75

15

15

median ours

50

10

10

25

5

5

0

0

25

50

Number of reviewers

(a) one biased reviewer

0

0

0

25

50 0

25

50

Number of reviewers

Number of reviewers

(b) incremental biases

(c) incremental biases with one bi-

ased reviewer

Figure 1: Relative improvement in exact recovery of various estimators as compared to the random-guessing ordinal estimator πab for A/B testing. Each point is an average over 10, 000 trials. The error bars are too small to display.

4.1 A/B testing
We now present simulations to evaluate various points on the bias-variance tradeoﬀ. For A/B testing, we compare our estimator πaobur with other standard estimators — the sign, mean and median estimators introduced in Section 3.2. The item values x1 and x2 are chosen independently and uniformly at random from the interval [0, 1]. The calibration functions are linear and given by:
(a) One biased reviewer: One reviewer gives an abnormally (high or low) score. Formally, fj(x) = x for j ∈ [m − 1], and fm(x) = x + m.
(b) Incremental biases: Calibration functions of reviewers are shifted from each other. Formally, fj(x) = x + j for j ∈ [m].
(c) Incremental biases with one biased reviewer: A combination of setting (a) and setting (b). Formally, fj(x) = x + (j − 1) for j ∈ [m − 1], and fm(x) = x + m(m2−1) .
We simulate and compute the relative improvement of the diﬀerent estimators as compared to the random-guessing estimator πab. The results are shown in Figure 1. While the performance of the estimators vary with respect to each other, our estimator consistently beats the baseline whereas every other estimator fails. Our estimator thus indeed operates at a unique point on the bias-variance tradeoﬀ with a low (zero) bias and a variance strictly smaller than the ordinal estimators, whereas all other estimators incur a non-zero error due to bias.

4.2 Ranking

Next, we evaluate the performance of our ranking estimator πroaunrk when the true ranking π∗ is drawn from a uniform prior. We compare this estimator with an optimal ordinal estimator πrank which outputs a topological

ordering with ties broken in order of the indices of the items (this ordinal estimator is optimal regardless of

the tie-breaking strategy).

For any number of items n, we generate the values x1, . . . , xn of the items i.i.d. uniformly from the interval

[0, n]. We set m =

1n 22

. We assume that the jth reviewer has a linear calibration function fj(x) = kjx + bj,

where we sample kj and bj i.i.d. uniformly from the interval [0, 1].

We have previously proved that our estimator πroaunrk based on cardinal data can strictly uniformly

outperform the optimal ordinal estimator for the 0-1 loss. We use these simulations to evaluate the eﬃcacy of

our approach for a diﬀerent loss function – Kendall-tau distance. Speciﬁcally, Figure 2 compares these two

estimators in terms of Kendall-tau distance (Appendix B provides a formal deﬁnition of this distance and

9

Relative improvement in
Kendall-tau distance (%)

10

5

0

0

25

50

75

100

Number of items

Figure 2: Relative improvement in Kendall-tau distance of our ranking estimator πroaunrk as compared to an optimal ordinal estimator πrank for ranking. Each point is an average over 100 trials, where in each trial the quantities E[L(π∗, πroaunrk)] and E[L(π∗, πrank)] are approximated by an empirical average over 1000 samples.

associated theoretical results). We observe that our estimator πroaunrk is able to consistently yield improvements even for this loss. The reason that the improvement becomes smaller when the number of items is large is that by ﬂipping pairs, our estimator only modiﬁes the ranking in the neighborhood of the initial estimate. We strongly believe that it should be possible to design better estimators for the large n regime using the tools developed in this paper. Having met our stated goal of outperforming ordinal estimators to handle arbitrary miscalibrations, we leave this interesting problem for future work.

4.3 Tradeoﬀ between estimation under perfect calibration vs. miscalibration
In this section, we present a preliminary experiment showing the tradeoﬀ between estimation under perfect calibration (all reviewers reporting the true values of the papers) and estimation under miscalibration. For simplicity, we consider the canonical setting from Section 3.1. We evaluate the performance of our estimator under two scenarios: (1) perfect calibration, where fj(x) = x for each j ∈ {1, 2}; (2) miscalibration with one biased reviewer, where f1(x) = x and f2(x) = x + 1. We consider the function w in our estimator as w(x) = 1+γxγx , where γ ∈ {2k | −10 ≤ k ≤ 10, k ∈ Z}. We sample x1 and x2 uniformly at random from the interval [0, 1].
Figure 3 shows the relative improvement of our estimator over the random-guessing baseline under perfect calibration and under miscalibration, where γ increases from left to right. Let us focus on a few regimes in this plot. First, on the left end of the curve, when γ is close to 0, we have w(x) close to 0. The estimator is close to random-guessing. At the other extreme, on the right end of the curve, when γ goes to inﬁnity,

10

Relative improvement under one biased reviewer (%)

5

0

0

25

50

75

100

Relative improvement

under perfect calibration (%)

Figure 3: Relative improvement of our canonical estimator πcoaunr under perfect calibration and under miscalibration of one biased reviewer, with w(x) = 1+γxγx and γ ∈ {2k | −10 ≤ k ≤ 10, k ∈ Z}, where γ increases from left to right in the plot. Each point is an average over 5 × 105 trials. The error bars are too
small to display.

10

we have w(x) close to 1. The estimator always outputs the item with the higher score, and hence gives perfect estimation under perfect calibration. Under miscalibration, this estimator always chooses the biased reviewer giving the higher score and hence performs the same as random guess. Past the maximum point of the function at approximately (25%, 9%) when γ = 1, the value of the curve starts decreasing, suggesting a tradeoﬀ of estimation accuracy under perfect calibration and under miscalibration. It is clear that points to the left of the maximum point are not Pareto-eﬃcient, since there exist other points with the same accuracy under miscalibration but improved accuracy under perfect calibration.
We thus see that robustness under arbitrary miscalibration comes at a cost of lower accuracy under perfect calibration. Establishing a formal understanding of this tradeoﬀ and designing estimators that are provably Pareto-eﬃcient are important open problems.
5 Proofs
In this section, we present the proofs of our theoretical results. For notational simplicity, we use “1 ≺ 2” to denote that item 1 has a smaller value than item 2. Since the
items have distinct values, we have 1 ≺ 2 if and only if 2 1. For the 0-1 loss L(π∗, π) = 1{π = π∗}, we call
the expected loss E[L(π∗, π)] = P(π = π∗) as the “probability of error” of any estimator π, and P(π = π∗) as the “probability of success”. For the canonical setting and A/B testing, the probability of success of random guessing is 0.5. To show that some estimator π strictly uniformly dominates random guessing for the canonical setting or A/B testing, we only need to show that the probability of success of this estimator is strictly higher than 0.5, or equivalently, the probability of error of of this estimator is strictly lower than 0.5.
5.1 Proof of Theorem 1
We prove that no deterministic cardinal estimator can strictly uniformly dominate the random-guessing estimator πcan, which implies the negative result for any deterministic ordinal estimator.
Recall the notation i(1) = argmaxi∈{1,2} yi as the item receiving the higher score (with ties broken uniformly at random), and the notation i(2) as the remaining item. First, we consider a deterministic estimator that always outputs i(1) as the item whose value is greater. We call this estimator the “sign estimator”, denoted πsign:
πsign(A, y1, y2) = (i(1) i(2)).
The proof consists of two steps. (1) We show that the sign estimator does not strictly uniformly dominate random guess. (2) Building on top of (1), we show that more generally, no deterministic estimator strictly uniformly dominates random guess. Step 1: The sign estimator does not strictly uniformly dominate random guess.
We construct the following counterexample such that the probability of error of the sign estimator is 0.5. We construct reviewer calibration functions such that their ranges are disjoint, that is, one reviewer always gives a higher score than the other reviewer, regardless of the items they are assigned. Then the relative ordering of the two scores does not convey any information about the relative ordering of the two items, and we show that in this case, the sign estimator has a probability of error of 0.5. Concretely, let the item values be bounded as x1, x2 ∈ (0, 1), and let the calibration functions be f1(x) = x and f2(x) = x + 1. Then the score given by reviewer 2 is higher than the score given by reviewer 1 regardless of the item values they are assigned. The sign estimator always observes y1 < y2, and outputs the item assigned to reviewer 2 as the larger item. The assignment is either A = (S1 = 1, S2 = 2) or (S1 = 2, S2 = 1) with probability 0.5 each. Under assignment (S1 = 1, S2 = 2), the sign estimator outputs 1 ≺ 2. Under assignment (S1 = 2, S2 = 1), the sign estimator outputs 1 2. Under one (and exactly one) of the two assignments, the output of the sign estimator is correct. Hence, the probability of error of the sign estimator is 0.5. Step 2: No deterministic estimator strictly uniformly dominates random guess.
11

Let A be the set of the two assignments, A = {(S1 = 1, S2 = 2), (S1 = 2, S2 = 1)}. A deterministic estimator πdet : A × R × R → {1 2, 1 ≺ 2} is a deterministic function that takes as input the assignment and the scores for the two items, and outputs the relative ordering between the two items. Step 1 has shown that the sign estimator does not strictly uniformly dominate random guess. Hence, we only need to prove that any deterministic estimator πdet that is diﬀerent from the sign estimator does not strictly uniformly dominate random guess. For this deterministic estimator πdet, there exist some input values (a, y1, y2) such that the output of this deterministic estimator diﬀers from the sign estimator. If the two estimators πsign and πdet only diﬀer at points where y1 = y2, then we can use the same counterexample in Step 1 to show that the probability of error of this deterministic estimator is 0.5. It remains to consider the case when y1 = y2. Without loss of generality, assume y1 > y2. Then consider the following counterexample. Let x1 > x2. Let f1, f2 be strictly-increasing functions such that f1(x1) = f2(x1) = y1, f1(x2) = f2(x2) = y2. Regardless of the reviewer assignment, the score y1 for item 1 is y1, and the score y2 for item 2 is y2. The item receiving a higher score is always i(1) = argmaxi∈{1,2} yi = 1, so the sign estimator πsign always outputs 1 2. Under assignment a, the deterministic estimator diﬀers from the sign estimator, so the deterministic estimator gives the incorrect output (1 ≺ 2). The assignment a happens with probability 0.5, so the probability of error of this deterministic estimator is at least 0.5.
The two steps above complete the proof that there exists no deterministic estimator that strictly uniformly dominates random guess.
5.2 Proof of Theorem 2
In what follows, we prove that the probability of success of our estimator is strictly greater than 0.5 under arbitrary item values x1, x2 and arbitrary calibration functions f1, f2. We start with re-writing our estimator in (2) into an alternative and equivalent expression, and then prove the result on this new expression of our estimator.
Recall that i(1) = argmaxi∈{1,2} yi denotes the item receiving the higher score, and i(2) denotes the remaining item (with ties broken uniformly). Depending on the relative ordering of y1 and y2, we can split (2) into the following three cases:

πcoaunr(A, y1, y2 | y1 > y2) = 12 πcoaunr(A, y1, y2 | y1 < y2) = 12 πcoaunr(A, y1, y2 | y1 = y2) = 12

2 with probability 1+w(y21−y2) 1 otherwise,
2 with probability 1−w(y22−y1) 1 otherwise,
2 with probability 12 1 otherwise.

(3a) (3b) (3c)

Recall that the function w is from [0, ∞) to [0, 1). Now we deﬁne the following auxiliary function w : R → (0, 1):

 1+w(x)

 

2

if x > 0

w(x) = 12 if x = 0 (4)  1−w2(−x) otherwise.

Combining (3) and (4), we have

πcoaunr(A, y1, y2) = 12 21 wotihtherpwrioseb.ability w(y1 − y2) (5)

12

Without loss of generality, assume x1 > x2. The assignment is either a := (S1 = 1, S2 = 2) or
a := (S1 = 2, S2 = 1) with probability 0.5 each. Thus, the estimator observes {y1 = f1(x1), y2 = f2(x2)}
under assignment a, or {y1 = f2(x1), y2 = f1(x2)} under assignment a . The probability of success of our estimator πcoaunr is:

P(πcoaunr = π∗) =

P(πcoaunr = π∗ | A = a)P(A = a)

a∈{a,a }

(i) 1

1

= 2 w(f1(x1) − f2(x2)) + 2 w(f2(x1) − f1(x2))

1 = 2 [w(f1(x1) − f2(x2)) + w(f2(x1) − f1(x2))]

(ii) 1 = 2 [1 + w(f1(x1) − f2(x2)) − w(f1(x2) − f2(x1))] , (6)

where step (i) is true by plugging in (5), and step (ii) is true because w(x) + w(−x) = 1 by the deﬁnition of the function w in (4).
By the monotonicity of the functions f1 and f2, and by the assumption that x1 > x2, we have f1(x1) + f2(x1) > f1(x2) + f2(x2), and therefore f1(x1) − f2(x2) > f1(x2) − f2(x1). Since w(0) ≥ 0 and w is monotonically increasing on [0, ∞), it is straightforward to verify that w is monotonically increasing on R. Hence, we have

w(f1(x1) − f2(x2)) > w(f1(x2) − f2(x1)).

(7)

Combining (6) and (7), we have

P(πcoaunr = π∗) > 12 .

5.3 Proof of Theorem 3
We construct a counterexample on which the mean, median and sign estimators have a probability of error of 0.5. In this counterexample, let the item values be bounded as x1, x2 ∈ (0, 1), and let the m reviewer calibration functions be as follows:

x + (j − 1) 

if 1 ≤ j ≤ m − 1

fj(x) =

m(m − 1)

(8)

x +

if j = m.

2

In these calibration functions, the score provided by each reviewer is the sum of the true value of the item

assigned to this reviewer, and a bias term speciﬁc to this reviewer. The analysis is performed separately for

the three estimators. At a high level, the analysis for the mean estimator uses the fact that one reviewer

(speciﬁcally, reviewer m) has a signiﬁcantly greater bias than the rest of the reviewers. The analysis for the

median and the sign estimators uses the fact that the ranges of these calibration functions are disjoint.

Mean estimator: Recall that each reviewer is assigned one of the two items. Given any assignment, consider

the item assigned to reviewer m. Trivially, the sum of the scores for this item must be strictly greater than

fm(0) = m(m2−1) . Now consider the remaining item (not assigned to reviewer m). The sum of the scores for

the remaining item can be at most

m−1 j=1

fj (1)

=

m j=−11 j = m(m2−1) .

From these two bounds on the sum of the scores, an item has a greater sum of scores if and only if

reviewer m is assigned to this item. By symmetry of the assignment, reviewer m is assigned to either item

with probability 0.5. With the true ranking being either 1 2 or 1 ≺ 2, the mean estimator makes an error

in one of the two assignments, and this assignment happens with probability 0.5. Hence, the mean estimator

13

makes an error with probability 0.5.

Median estimator and sign estimator: For the median estimator and the sign estimator, we ﬁrst present
an alternative view on the assignment, which is used for the analysis of both estimators. Recall that the
assignment speciﬁes m/2 reviewers to evaluate item 1, drawn uniformly at random without replacement,
and the remaining m/2 reviewers to item 2. Equivalently, we can view this assignment as comprising the
following two steps. (1) We sample uniformly at random a permutation of the m reviewers, denoted as a list
(j1, . . . , jm). Deﬁne R and R as the ﬁrst half and second half of the reviewers in the list, R = (j1, . . . , j m ) 2
and R = (j m +1, . . . , jm). (2) We draw uniformly at random one of the two items, and assign the list R of 2
reviewers to this item. Then assign the list R of reviewers to the remaining item. For each k ∈ [m/2] , call reviewers {jk, j m +k} as the kth pair of reviewers.
2
For the median estimator and the sign estimator, we prove that given any arbitrary lists of reviewers R
and R in Step (1) of the assignment, the randomness in Step (2) yields the probability of error of the two
estimators as 0.5.
Recall that the item values are bounded as x1, x2 ∈ (0, 1). Since the biases of any two reviewers diﬀer by at least 1 in Eq. (8), any reviewer j gives a higher score than any other reviewer j if and only if j < j ,
independent of the item values and the assignment. Formally, for any x, x ∈ (0, 1), and any j, j ∈ [m], we
have

fj(x) < fj (x ) if and only if j < j .

(9)

The remaining analysis is performed separately for the median estimator and the sign estimator. Median estimator: Denote j1med and j2med as the indices of the reviewers providing the (upper) median scores in the set R1 and R2, respectively. From (9), we have

j1med = median(j1, . . . , j m2 ) (10) j2med = median(j m2 +1, . . . , jm).

Also from (9), the higher score in the two scores given by reviewer j1med and j2med is the reviewer with the

larger

index,

max

{j

med 1

,

j2med

}.

In

Step

(2)

of

the

assignment,

reviewer

j1med

is

assigned

to

item

1

or

item

2

with equal probability. Hence, the probability of error of the median estimator is 0.5. This proves the claim

that the (upper) median estimator does not strictly uniformly dominates random guess.

We now comment on using the median function deﬁned as the lower median, or as the mean of the two middle values. For the lower median, the same argument as above applies. Now consider the median deﬁned as the mean of the two middle values. When m/2 is odd, Eq. (10) still holds, and the argument as above still applies. When m/2 is even, the median value may not be equal to any scores from the reviewers. We construct a counterexample where the item values are still bounded as x1, x2 ∈ (0, 1), and the calibration functions as follows:
fj(x) = x + 2j for every j ∈ [m].
With these calibration functions, for any x, x , x , x ∈ (0, 1), and any j, j , j , j ∈ [m], we have
fj(x) + fj (x ) < fj (x ) + fj (x ) if and only if max{j, j } < max{j , j }.
Using this fact, we can show that the output of this median estimator only depends on reviewer indices and the realization of Step (2), independent of the item values. The probability of error of this median estimator is also 0.5.

Sign estimator: Denote a as the assignment that reviewers in R are assigned to item 1, and denote a as
the assignment that reviewers in R are assigned to item 2. For each k ∈ [m/2], deﬁne vk ∈ {0, 1} as the binary value of whether the higher score in the kth pair of scores comes from item 1, under assignment a.

14

Set vk = 1 if the higher score comes from item 1 and vk = 0 otherwise. Deﬁne vk ∈ {0, 1} similarly under

assignment a . Set vk = 1 if the higher score comes from item 1, and vk = 0 otherwise. Inequality (9) implies

that vk + vk = 1 for any k ∈ [m/2]. Deﬁne v =

m/2 k=1

vk

as

the

count

of

pairwise

wins

for

item

1

under

assignment a, and deﬁne v similarly. Then we have

m

v+v = .

(11)

2

The sign estimator outputs the item with more pairwise wins. That is, the sign estimator outputs item 1 under assignment a if v > m/4, outputs item 1 under assignment a if v > m/4, and outputs one of the two items uniformly at random if v = m/4 or v = m/4. When v = v = m/4, then under either assignment, the sign estimator has a tie, and hence outputs one of the two items uniformly at random. The probability of error of the sign estimator is 0.5. Otherwise, we have v = m/4. By (11), we have either v > m/4 > v or v > m/4 > v. The sign estimator gives diﬀerent outputs under the two assignments, out of which one and only one output is correct. The probability of error of the sign estimator is 0.5.

5.4 Proof of Theorem 4
Recall that a subset of m/2 reviewers, drawn uniformly at random without replacement, are assigned to item 1, and the remaining m/2 reviewers are assigned to item 2. We provide an alternative and equivalent view of the assignment as the following two steps:
(1) We sample two reviewers, uniformly at random without replacement, as the ﬁrst pair of reviewers for the two items, and call them {j1, j1}. Then sample two reviewers, uniformly at random without replacement, from the remaining (m − 2) reviewers as the second pair of reviewers for the two items, and call them {j2, j2}. Continue until all m reviewers are exhausted, and call the subsequent pairs of reviewers {j3, j3}, . . . , {jm/2, jm/2}.
(2) Within each pair, assign the pair of reviewers to the two items uniformly at random. That is, for each k ∈ [m/2], assign reviewer jk to one of the two items uniformly at random, and assign reviewer jk to the remaining item. The assignments are independent across pairs.
Consider any arbitrary values of items x1, x2 ∈ R. Given any arbitrary realization of Step (1) of the assignment procedure described above, we apply Theorem 2 and show that on each pair of reviewers, the canonical estimator gives the correct output with probability strictly greater than 0.5. Then we show that combining the m/2 pairs by majority-voting yields probability of success strictly greater than 0.5.
Denote λ(x1, x2, {f, f }) as the probability that our canonical estimator in Eq. (2) gives the correct output comparing items of values x1, x2 under reviewer calibration functions f, f . In Step (2) of the assignment procedure described above, for any k ∈ [m/2], consider the kth pair of reviewers, {jk, jk}. Suppose that the calibration functions of these two reviewers are denoted as {f, f }. By Theorem 2, since the two reviewers are assigned to the two items uniformly at random, we have
1 λ (x1, x2, {f, f }) > 2 for all permissible f, f . (12)
Let λmin denote the probability of success of our canonical estimator when run on the worst pair of calibration functions among all pairs of reviewers
(i) 1 λmin = f,f ∈{mf1i,n...,fm} λ(x1, x2, {f, f }) > 2 ,
where inequality (i) is true because of Eq. (12), and because the number of reviewers m is ﬁnite. Now assume that we are given any arbitrary realization of Step (1) of the assignment. For each k ∈ [m/2],
deﬁne Vk ∈ {0, 1} as the indicator variable of the correctness of our canonical estimator on the kth pair of scores. We set Vk = 1 if the canonical estimator gives the correct output on the kth pair, and 0 otherwise.

15

Then Vk is a Bernoulli random variable with mean λ(x1, x2, {fjk , fjk }) ≥ λmin. Moreover, since Step (2) of the assignment is performed independently across all pairs, the variables {Vj}kj=1 are independent given the
item values and Step (1) of the assignment.

Let V =

m/2 j=1

Vj

be

the

number

of

pairs

for

which

the

canonical

estimator

πcoaunr

gives

the

correct

output.

Deﬁne a binomial random variable B with k trials and the success probability parameter λmin. Then the

random variable V stochastically dominates the random variable B. Recall that our estimator breaks ties

uniformly at random. The probability of success of our estimator with the majority-voting procedure is then

bounded as

k1

k1

k

k

P[V > 2 ] + 2 P[V = 2 ] = 2 P[V > 2 ] + P[V ≥ 2 ]

1

k

k

≥ 2 P[B > 2 ] + P[B ≥ 2 ]

k1

k

=P[B > 2 ] + 2 P[B = 2 ]

(i) 1 >,
2

where inequality (i) is true because the success probability parameter λmin of the binomial variable is strictly greater than 21 .
We complete the proof that the probability of success of our estimator is strictly greater than 0.5 uniformly
on any item values x1, x2 and any permissible calibration functions {fj}m j=1.

5.5 Proof of Theorem 5
We ﬁrst provide a high-level description of the proof. We call a pair of items “ﬂippable”, if Algorithm 1 uses the canonical estimator to decide the relative ordering of this pair (that is, the if-condition in Line 6 in Algorithm 1 is true). Note that a “ﬂippable” pair may or may not be ﬂipped by the algorithm, as the outcome depends on the output of the canonical estimator. In Theorem 2, we show that our canonical estimator πcoaunr predicts the relative ordering of a pair of items correctly with probability strictly greater than 0.5. The main idea of the proof is to apply Theorem 2 to each ﬂippable pair. Then we show that an improvement on the probability of correctness on these ﬂippable pairs translates to an improvement on the probability of success of exact recovery.
Theorem 2 requires that within each pair, the two reviewers are assigned the two items uniformly at random. To be able to apply this theorem, we separate the diﬀerent sources of randomness in the joint procedure of the assignment and the algorithm. We derive an equivalent algorithm by re-ordering the steps of Algorithm 1, so that in this equivalent algorithm, given any ﬂippable pair of items and two reviewers evaluating this pair, the last sources of randomness comes from the random assignment of the two reviewers to the two items within this pair.
We introduce some additional notation for our re-ordered algorithm. Recall the notation of A = (S1, . . . , Sm) for the reviewer assignment, where Sj is a pair of items assigned to reviewer j for each j ∈ [m]. Denote Q = {Sj}m j=1 as the same m pairs of items, but the reviewer assigned to each pair Sj is unspeciﬁed. Now we present an equivalent joint procedure of the assignment and the cardinal estimator πroaunrk in Algorithm 2. In what follows, we provide a high-level summary of Algorithm 2:
(1) Line 1-2: We sample m pairwise comparisons of the items, drawn uniformly at random without replacement from the n2 pairs. Obtain an initial estimate π of the ranking, by computing a topological ordering on the graph G(B).
(2) Line 3-18: Store the positions of all ﬂippable pairs (if any) determined by Algorithm 1. If an item is included in some ﬂippable pair, then this item is matched to a distinct pairwise comparison in Q. Store the matching between the items in ﬂippable pairs and the pairwise comparisons.

16

Algorithm 2: An equivalent joint procedure of the assignment A, the evaluation Y, and the execution of our cardinal ranking estimator πroaunrk(A, Y) in Algorithm 1.

1 Sample pairwise comparisons Q = {Sj}m j=1 uniformly at random from all

n 2

pairs. Obtain the ordinal

comparisons B.

2 Compute a topological ordering π on the graph G(B), with ties broken in order of the indices of the

items.

3 t ← 1.

4 Qavail ← Q.

5 flippable_positions ← [ ].

6 reviewer_indices ← [ ].

7 while t < n do

8 Let πﬂip be the ranking obtained by ﬂipping the positions of the tth and the (t + 1)th items in π.

9 if πﬂip is a topological ordering on G(B), and both the tth and (t + 1)th items are each included in

at least one pairwise comparison in Qavail then

10

From all of the pairwise comparisons in Qavail including the tth item, sample one uniformly at

random and denote it as St. Likewise denote St+1 as a randomly chosen pairwise comparison

including the (t + 1)th item from Qavail.

11

Append t to flippable_positions.

12

Append the pair [St, St+1] to reviewer_indices.

13

Remove St and St+1 from Qavail.

14

t ← t + 2.

15 else

16

t ← t + 1.

17 end

18 end

19 For each pair [St, St+1] in reviewer_indices, sample uniformly at random without replacement a pair of reviewers {jt, jt+1}.
20 foreach t ∈flippable_positions do

21 Assign reviewer jt to one of the two pairs St or St+1, uniformly at random. Assign reviewer jt+1 to the remaining pair. Obtain the scores from these two reviewers for their corresponding pair.

22 Denote yπ(t) as the score for the tth item in St. Likewise denote yπ(t+1) as the score for the (t + 1)th

item in St+1.

23 if πcoaunr(yπ(t), yπ(t+1)) outputs π(t + 1) π(t) then

24

Let πﬂip be the ranking obtained by ﬂipping the positions of the tth and the (t + 1)th items in π.

25

π ← πﬂip.

26 end

27 end 28 Output π.

(3) Line 19: For the two pairwise comparisons associated with each pair of ﬂippable items, sample two reviewers uniformly at random without replacement to evaluate the two comparisons.
(4a) Line 20-21: Within each ﬂippable pair, assign the two reviewers to the two items uniformly at random. (4b) Line 22-28: Run the canonical estimator on each ﬂippable pair, and ﬂip the pair if the canonical
estimator decides to do so (Line 23-26). After all ﬂippable pairs are examined, output the ﬁnal ranking π.
We now brieﬂy discuss the equivalence of Algorithm 2 to Algorithm 1. We ﬁrst discuss the equivalence of
17

the assignment procedures in the two algorithms, and then the estimation aspect in the next paragraph. The assignment consists of Steps (1), (3) and (4a). Recall that the assignment in Algorithm 1 samples m pairwise comparisons, uniformly at random without replacement, to assign to the m reviewers. In Algorithm 2, this assignment is decomposed into the choice of pairwise comparisons, the choice of a pair of reviewers to two pairwise comparisons in each ﬂippable pair, and the assignment within each ﬂippable pair, corresponding to Steps (1), (3) and (4a), respectively. Note that only the selected pairwise comparison for each item within some ﬂippable pair is used for Algorithm 2, so we do not need to specify the assignment of the reviewers for the rest of the comparisons. This re-ordering of the assignment is equivalent to Algorithm 1.
The cardinal ranking estimator consists of the rest of the steps, namely Steps (2) and (4b). In the original presentation of the estimator in Algorithm 1, the estimator scans through the items, identiﬁes ﬂippable pairs, calls the canonical estimator on each ﬂippable pair, and ﬂips the pairs accordingly. Note that the identiﬁcation of ﬂippable pairs does not need the assignment of reviewers or the scores from the reviewers, so Algorithm 2 ﬁrst scans through the items and identiﬁes all ﬂippable pairs, without using the choice of the reviewers in the assignment or using the scores from the reviewers. Then Algorithm 2 calls the canonical estimator on each ﬂippable pair once the choice of the reviewers and the scores are determined, and ﬂips each pair based on the corresponding output from the canonical estimator. Note that when checking for a ﬂippable pair (the if-condition in Line 6 in Algorithm 1 and Line 9 in Algorithm 2), Algorithm 1 checks whether the ﬂipped ranking πﬂip is a topological ordering, where the previous ﬂippable pairs in πﬂip may have already been ﬂipped. In Algorithm 2, the previous ﬂippable pairs are identiﬁed but are not ﬂipped. However, whether the ﬂipped ranking πﬂip is a topological ordering is independent of whether the previous ﬂippable pairs in πﬂip are ﬂipped. Hence, the identiﬁcation of the ﬂippalbe pairs is equivalent in the two algorithms. The re-ordering of the steps of the cardinal estimator πroaunrk is valid.
Having now established the equivalence of Algorithm 2 to Algorithm 1, we now prove Theorem 5 with respect to Algorithm 2. Let us denote πreaqnk as the cardinal estimator in Algorithm 2. Denote topo(B) as the set of all topological orderings on the directed graph G(B) induced by the set of ordinal observations B. We denote a random variable T (B) := |topo(B)| as the number of such topological orderings. Note that the deﬁnition of ﬂippable pairs carries over from Algorithm 1 to Algorithm 2. We denote a random variable L as the number of ﬂippable pairs in Algorithm 2.
Let us ﬁrst consider the probability of success of the ordinal estimator. The following lemma describes the posterior distribution of the true ranking conditioned on the set of ordinal observations B. Using this posterior distribution, the optimal ordinal estimators and their probability of success are derived.

Lemma 1 (a) Given any possible set of ordinal observations β, the posterior distribution of the true ranking π∗ is uniformly distributed over the T (β) topological orderings:
P(π∗ = π | B = β) = T (1β) if π ∈ topo(β) (13) 0 otherwise.

(b) Any ordinal estimator πroapntk is optimal for the 0-1 loss, if and only if given any set of ordinal observations β, the output of this ordinal estimator belongs to the T (β) topological orderings with probability
1, that is, if and only if

P(πroapntk(β) ∈ topo(β) | B = β) = 1 for all possible set of ordinal observations β.

(14)

Moreover, conditioned on the set of ordinal observations β, the probability of success of any optimal ordinal estimator πroapntk is
P(πroapntk = π∗ | B = β) = T (1β) . (15)

See Section 5.5.1 for the proof of the lemma.

18

Now consider the probability of success of our cardinal estimator πreaqnk from Algorithm 2. We write the probability of success of our cardinal estimator as

P(πreaqnk = π∗) =

P(πroaunrk = π∗ | B = β, L = )P(B = β, L = ),

(16)

β

where β is summed over all possible sets of ordinal observations, and is summed from 0 to n/2 . We consider each term P(πreaqnk = π∗ | B = β, L = ) separately for each β and . We prove that for any β
and any , the probability of success of our cardinal estimator is greater than or equal to the probability of success of any optimal ordinal estimator πroapntk. We also show that the probability of success is strictly greater for some β and . We discuss the following two cases separately, depending on the number of ﬂippable pairs.
Case 1: = 0.
We have the number of ﬂippable pairs L = 0 either if there is a unique topological ordering on the graph
G(B), or if in each pair of adjacent items that can be ﬂipped without violating pairwise comparisons, at least
one item in this pair does not have any score. Note that these two conditions are fully determined by the set
of ordinal observations. Hence, conditioned on the set of ordinal observations B = β, the event of L = 0 is
fully determined, and is independent of everything else given B.
The initial estimated ranking of the cardinal estimator is a topological ordering (Line 2 of Algorithm 2).
Since there is no ﬂippable pair, the cardinal estimator simply outputs this topological ordering. For any set
of ordinal observations β such that P(B = β, L = 0) > 0, we have

P(πreaqnk = π∗ | B = β, L = 0) (=i)P(πreaqnk = π∗ | B = β) (=ii)P(πroapntk = π∗ | B = β),

(17)

where πroapntk denotes any optimal ordinal estimator. Here in (17), equality (i) is true because the event L = 0 is fully determined by B, and equality (ii) is true because this cardinal estimator that simply outputs a topological ordering is equivalent to an ordinal estimator that outputs the same topological ordering. From (14), this ordinal estimator is one optimal ordinal estimator. Case 2: > 0.
In this case, Algorithm 2 identiﬁes at least one ﬂippable pair. The probability of success of our cardinal estimator is

P(πreaqnk = π∗ | B = β, L = ) = P(πreaqnk = π | π∗ = π, B = β, L = )P(π∗ = π | B = β, L = )
π∈Π

(=i) P(πreaqnk = π | π∗ = π, B = β, L = )P(π∗ = π | B = β)

π∈Π

(ii) 1 =
T (β)

P(πreaqnk = π | π∗ = π, B = β, L = ),

π∈topo(β)

(18)

where equality (i) is true because L is independent of π∗ conditioned on B. Equality (ii) is true by plugging in (13).
In Algorithm 2, Lines 1-19 fully determine the number of the ﬂippable pairs, their positions, and the two reviewers evaluating each ﬂippable pair. In Lines 20-28, within each ﬂippable pair, the algorithm ﬁrst assigns uniformly at random one reviewer to one item and the remaining reviewer to the remaining item, and then calls the canonical estimator to output the relative ordering of this pair. Conditioned on the randomness in Lines 1-19 of Algorithm 2, we now apply Theorem 2 to each ﬂippable pair. Since the reviewer assignment within each ﬂippable pair (Line 21) is uniformly at random, by Thoerem 2, the probability that the canonical estimator outputs the correct relative ordering of each ﬂippable pair is strictly greater than 12 . Since the assignment within each ﬂippable pair is independent across pairs, the probability that the canonical estimator outputs the correct relative ordering of all ﬂippable pairs is strictly greater than 21 .

19

Recall that the initial estimated ranking of our cardinal estimator is a topological ordering. Consider
all total rankings that are identical to this initial ranking, except for (possibly) the relative ordering of the
ﬂippable pairs. Since the items in the ﬂippable pairs are disjoint, there are 2 such total rankings. By
deﬁnition, a pair is ﬂippable only if the total ranking after this pair is ﬂipped is still a topological ordering.
Hence, all these 2 total rankings are topological orderings on the graph G(B). In (18), the summation of
π is over all topological orderings. In particular, this summation includes these 2 total rankings. On each of these 2 total rankings, the output of our ranking estimator πreaqnk is correct if and only if the canonical estimator outputs the correct relative orderings for the ﬂippable pairs, which happens with probability strictly greater than 21 . Hence, we bound (18) as

P(πreaqnk = π∗ | B = β, L = ) > T (1β) · 2 · 21 = T (1β)

(=i)P(πroapntk = π∗ | B = β),

(19)

where πroapntk denotes any optimal ordinal estimator. Equality (i) is true because of (15) in Lemma 1. Plugging (17) and (19) into (16), we have

P(πreaqnk = π∗) ≥ P(πroapntk = π∗) for any optimal ordinal estimator πroapntk,

(20)

and a strict inequality holds in (20) if there exists some β and some > 0, such that

P(B = β, L = ) > 0.

(21)

It remains to ﬁnd some β and some > 0 such that (21) is true. We construct such β and > 0 as follows. Consider the true ranking 1 2 · · · n, which happens with a strictly positive probability as the prior distribution of the true ranking is uniform. Conditioned on this true ranking, consider the event that the sampled pairwise comparisons in Q do not include a direct comparison between items 1 and 2, but both item 1 and item 2 have at least one score each (from comparisons with at least one of the remaining (n − 2) items). Recall that the number of pairs satisﬁes 1 < m < n2 , so such a set Q of pairwise comparisons arises with a strictly positive probability. Let β be the set of ordinal observations derived from the true ranking and the set Q of pairwise comparisons described as above. With this β, item 1 and item 2 are the ﬁrst two items in the initial ranking of the topological ordering, they can be ﬂipped, and they both have some scores. Hence, item 1 and item 2 form a ﬂippable pair, and we have L > 0. Hence, with this construction of β, we have

n/2
P(B = β, L = ) > 0.
=1

Thus there exists some > 0 such that P(B = β, L = ) > 0. Hence, Equation (21) is true, implying the strictly inequality in (20). Consequently, the probability of success of our cardinal ranking estimator πreaqnk is strictly uniformly greater than the probability of success of any optimal ordinal estimator. By the equivalence
of Algorithm 2 and Algorithm 1, this result also holds for the original cardinal estimator πroaunrk, completing the proof.

5.5.1 Proof of Lemma 1

We ﬁrst prove part (a) of the lemma. By Bayes rule, for any ranking π ∈ Π and any possible set of ordinal observations β, we have

P(π∗ = π | B = β) = P(B = β | π∗ = π)P(π∗ = π) .

(22)

P(B = β)

Given the set of ordinal observations β, the denominator in (22) is independent of π. Since the prior of the true ranking is uniform, in the numerator we have P(π∗ = π) = n1! , independent of π. Now it remains to

20

consider the term P(B = β | π∗ = π) in the numerator. Recall the notation of the random variable Q as the set of pairwise comparisons in the ordinal observations (but Q does not include the results of the relative orderings of these pairs). We write the term P(B = β | π∗ = π) as

P(B = β | π∗ = π) = P(B = β | Q = q, π∗ = π)P(Q = q | π∗ = π)
q

(i)
=

P(B = β | Q = q, π∗ = π)P(Q = q),

(23)

q

where q is summed over all possible sets of m pairwise comparisons. Equality (i) is true because the sampling of the set of pairwise comparisons Q is independent of the true ranking π∗.
Recall that the set of ordinal observations β includes the pairwise comparisons and results of the relative orderings of these pairwise comparisons, whereas q only includes the pairwise comparisons themselves, so β fully determines q. For this term to be non-zero, the set of pairwise comparisons indicated by β and the set of pairwise comparisons indicated by q need to be identical. Hence, there is only one q in the summation of (23) consistent with β, and we denote q as the set of pairs consistent with β. Then (23) reduces to

P(B = β | π∗ = π) =P(B = β | Q = q, π∗ = π)P(Q = q),

(24)

In (24), the second term P(Q = q) is independent of π. Now consider the ﬁrst term P(B = β | Q = q, π∗ = π). If π is a topological ordering on G(β), then by deﬁnition, the relative orderings on the pairs q induced by the ranking π is the set of ordinal observations β. If π is not a topological ordering, then by deﬁnition, the relative orderings induced by the ranking π violates at least one relative ordering in β. Hence,

P(B = β | Q = q, π∗ = π) = 1 if π ∈ topo(β)

(25)

0 otherwise.

Combining the law of total probability with (22), (24) and (25), the posterior distribution of the true ranking is
P(π∗ = π | B = β) = T (1β) if π ∈ topo(β) (26) 0 otherwise.
Conditioned on the set of ordinal observations β, the posterior distribution of the true ranking is uniform over all topological ordering on the graph G(β). This completes the proof for part (a) of the lemma.

For part (b) of the lemma, we condition on any possible set of ordinal observations β. On the input β, the probability of success of any (possibly-randomized) ordinal estimator πrank is:

P(πrank(β) = π∗ | B = β) = P(πrank(β) = π | π∗ = π, B = β)P(π∗ = π | B = β)

π∈Π

(i) 1 =

P(πrank(β) = π | π∗ = π, B = β)

T (β)

π∈topo(β)

(ii) 1

= T (β)

P(πrank(β) = π)

π∈topo(β)

(iii) 1

≤

,

(27)

T (β)

where equality (i) is true by plugging in (26). Equality (ii) is true because the output of the ordinal estimator πrank(β) on the input β only depends on its internal randomness, and hence independent of the π∗ and B.

21

Inequality (iii) is true by the law of total probability. In particular, the equality sign in (iii) holds if and only if the output of the ordinal estimator is always a topological ordering consistent with β, that is, if and only if

P(πrank(β) ∈ topo(β) | B = β) = 1.

(28)

Taking an expectation over all possible ordinal observations β, we have

P(πrank(B) = π∗) = P(πrank(β) = π∗ | B = β)P(B = β).

(29)

β

Combining (29) with the condition (28) for the equality sign in (27), an ordinal estimator is optimal if and only if Eq. (28) holds on all possible ordinal observations β where P(B = β) > 0. This completes the proof for part (b) of the lemma.

6 Discussion
Breaking the barrier of using only ranking data in the presence of arbitrary (and potentially adversarial) miscalibrations, we show that cardinal scores can yield strict and uniform improvements over rankings. This result uncovers a novel, strictly-superior point on the tradeoﬀ between cardinal scores and ordinal rankings, and provides a new perspective on this eternally-debated tradeoﬀ. Our estimator allows for easily plugging into a variety of algorithms, thereby yielding it a wide applicability.
The results of this paper lead to several useful open problems. First, while our estimators indeed uniformly outperform ordinal estimators, in the future, a more careful design in our estimators (e.g. how to choose the function w in the canonical estimator, and how to design better estimators for A/B testing and ranking) may yield even better results. Second, it is of interest to obtain statistical bounds on the relative errors of the cardinal and ordinal estimators in terms of the unknown miscalibration functions. Third, a promising direction of future research is to design estimators that achieve the guarantees of our proposed estimator under arbitrary/adversarial miscalibrations while simultaneously being able to adapt and yield stronger guarantees when the calibration functions follow one of the popular simpler models of miscalibration (à la “win-win” models and estimators in prior work [Sha17, Part I] [HSRW16, SBW16, SBGW17, SBW18, SW18]). Fourth, although we consider the rating scales as continuous intervals, it is not hard to see that our results extend to discrete scales (but with the strict inequality in Equation (1) sometimes replaced by a non-strict inequality to account for ties). Using our results to guide the choice of the scale used for elicitation is an open problem of interest. And ﬁnally, practical applications such as peer-review do not suﬀer from the problem of miscalibration in isolation. It is a useful and challenging open problem to address miscalibration simultaneously with other issues such as noise [SSS18], subjectivity [NSP18], strategic behavior [XZSS18] and others.

Acknowledgments
This work was supported in parts by NSF grants CRII: CIF: 1755656 and CCF: 1763734. The authors thank Bryan Parno for very useful discussions on biases in conference peer review. The authors thank Pieter Abbeel for pointing out the related work on the two-envelope problem.

References

[AS12] [Bar70]

Ammar Ammar and Devavrat Shah. Eﬃcient rank aggregation using partial data. In SIGMETRICS/PERFORMANCE Joint International Conference on Measurement and Modeling of Computer Systems, 2012.
A. J. Baranchik. A family of minimax estimators of the mean of a multivariate normal distribution. Ann. Math. Statist., 41(2):642–645, 1970.

22

[BK09]

Jacob P. Baskin and Shriram Krishnamurthi. Preference aggregation in group recommender systems for committee decision-making. In ACM Conference on Recommender Systems, RecSys, 2009.

[BK13]

Yukino Baba and Hisashi Kashima. Statistical quality estimation for general crowdsourcing tasks. In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2013.

[Boc75]

M. E. Bock. Minimax estimators of the mean of a multivariate normal distribution. Ann. Statist., 3(1):209–218, 1975.

[CGPR07] Wade D. Cook, Boaz Golany, Michal Penn, and Tal Raviv. Creating a consensus ranking of proposals from reviewers’ partial ordinal rankings. Computers & Operations Research, 34(4):954–965, 2007.

[Cov87] Thomas M. Cover. Pick the Largest Number, pages 152–152. Springer New York, New York, NY, 1987.

[DKNS01] Cynthia Dwork, Ravi Kumar, Moni Naor, and D. Sivakumar. Rank aggregation methods for the web. In International Conference on World Wide Web, 2001.

[Dou09]

John R Douceur. Paper rating vs. paper ranking. ACM SIGOPS Operating Systems Review, 43(2):117–121, 2009.

[DPV08]

Sanjoy Dasgupta, Christos H. Papadimitriou, and Umesh Vazirani. Algorithms. McGraw-Hill, Inc., 1 edition, 2008.

[FISS03]

Yoav Freund, Raj D. Iyer, Robert E. Schapire, and Yoram Singer. An eﬃcient boosting algorithm for combining preferences. Journal of Machine Learning Research, 4:933–969, 2003.

[FSG+10]

Peter A. Flach, Sebastian Spiegler, Bruno Golénia, Simon Price, John Guiver, Ralf Herbrich, Thore Graepel, and Mohammed J. Zaki. Novel tools to streamline the conference review process: Experiences from SIGKDD’09. SIGKDD Explor. Newsl., 11(2):63–67, 2010.

[GB08]

Dale Griﬃn and Lyle Brenner. Perspectives on Probability Judgment Calibration, chapter 9, pages 177–199. Wiley-Blackwell, 2008.

[GK96]

Alexander V. Gnedin and Ulrich Krengel. Optimal selection problems based on exchangeable trials. Ann. Appl. Probab., 6(3):862–882, 08 1996.

[Gne94] Alexander V. Gnedin. A solution to the game of googol. Ann. Probab., 22(3):1588–1595, 07 1994.

[Gne16] Alexander Gnedin. Guess the larger number. preprint arXiv:1608.01899, 2016.

[GWG13] Hong Ge, Max Welling, and Zoubin Ghahramani. A Bayesian model for calibrating conference review scores, 2013. http://mlg.eng.cam.ac.uk/hong/nipsrevcal.pdf [Online; accessed 14-May-2018].
[HBBR+09] Anne-Wil Harzing, Joyce Baldueza, Wilhelm Barner-Rasmussen, Cordula Barzantny, Anne Canabal, Anabella Davila, Alvaro Espejo, Rita Ferreira, Axele Giroud, Kathrin Koester, et al. Rating versus ranking: What is the best way to reduce response and language bias in cross-national research? International Business Review, 18(4):417–432, 2009.

[HSRW16] Reinhard Heckel, Nihar B. Shah, Kannan Ramchandran, and Martin J. Wainwright. Active ranking from pairwise comparisons and when parametric assumptions don’t help. preprint arXiv:1606.08842, 2016.

[JS61]

William James and Charles Stein. Estimation with quadratic loss. In Proceedings of the fourth Berkeley symposium on mathematical statistics and probability, volume 1, pages 361–379, 1961.

[KLSH09]

Ron Kohavi, Roger Longbotham, Dan Sommerﬁeld, and Randal M. Henne. Controlled experiments on the web: survey and practical guide. Data Mining and Knowledge Discovery, 18(1):140–181, 2009.

[Lan12]

John Langford. ICML acceptance statistics, 2012. http://hunch.net/?p=2517 [Online; accessed 14-May2018].

[MA09]

Mark D. McDonnell and Derek Abbott. Randomized switching in the two-envelope problem. Proceedings of the Royal Society of London A: Mathematical, Physical and Engineering Sciences, 2009.

[MGCV11] Ioannis Mitliagkas, Aditya Gopalan, Constantine Caramanis, and Sriram Vishwanath. User rankings from comparisons: Learning permutations in high dimensions. In Allerton Conference on Communication, Control, and Computing, 2011.

[MKLP17] R. S. MacKay, R. Kenna, R. J. Low, and S. Parker. Calibration with conﬁdence: a principled method for panel assessment. Royal Society Open Science, 4(2), 2017.

[NOS12]

Sahand Negahban, Sewoong Oh, and Devavrat Shah. Iterative ranking from pair-wise comparisons. In Advances in Neural Information Processing Systems, 2012.

23

[NSP18] [Pau81] [PHC+13] [PSZ16] [RGLA15]
[Rob56] [Rok68] [RRS11] [SBB+16]
[SBGW17]
[SBP+13] [SBW16] [SBW18] [Sha17] [SN92] [SSS18] [Ste56]
[STM+17] [SW18] [TKV17] [XZSS18] [You88]

Ritesh Noothigattu, Nihar Shah, and Ariel Procaccia. Choosing how to choose papers. arXiv preprint arxiv:1808.09057, 2018.
S. R. Paul. Bayesian methods for calibration of examiners. British Journal of Mathematical and Statistical Psychology, 34(2):213–223, 1981.
Chris Piech, Jonathan Huang, Zhenghao Chen, Chuong Do, Andrew Ng, and Daphne Koller. Tuned models of peer assessment in MOOCs. preprint arXiv:1307.2579, 2013.
Ariel D. Procaccia, Nisarg Shah, and Yair Zick. Voting rules as error-correcting codes. Artif. Intell., 231:1–16, 2016.
Arun Rajkumar, Suprovat Ghoshal, Lek-Heng Lim, and Shivani Agarwal. Ranking from stochastic pairwise preferences: Recovering Condorcet winners and tournament solution sets at the top. In International Conference on Machine Learning, pages 665–673, 2015.
Herbert Robbins. An empirical Bayes approach to statistics. In Proceedings of the Third Berkeley Symposium on Mathematical Statistics and Probability, volume 1, pages 157–163, 1956.
Milton Rokeach. The role of values in public opinion research. Public Opinion Quarterly, 32(4):547–559, 1968.
Magnus Roos, Jörg Rothe, and Björn Scheuermann. How to calibrate the scores of biased reviewers by quadratic programming. In AAAI Conference on Artiﬁcial Intelligence, 2011.
Nihar B. Shah, Sivaraman Balakrishnan, Joseph Bradley, Abhay Parekh, Kannan Ramchandran, and Martin J. Wainwright. Estimation from pairwise comparisons: Sharp minimax bounds with topology dependence. Journal of Machine Learning Research, 17(1):2049–2095, 2016.
Nihar B. Shah, Sivaraman Balakrishnan, Adityanand Guntuboyina, and Martin J. Wainwright. Stochastically transitive models for pairwise comparisons: Statistical and computational issues. IEEE Transactions on Information Theory, 63(2):934–959, 2017.
Nihar B. Shah, Joseph K Bradley, Abhay Parekh, Martin Wainwright, and Kannan Ramchandran. A case for ordinal peer-evaluation in MOOCs. In NIPS Workshop on Data Driven Education, 2013.
Nihar B. Shah, Sivaraman Balakrishnan, and Martin J. Wainwright. A permutation-based model for crowd labeling: Optimal estimation and robustness. preprint arXiv:1606.09632, 2016.
Nihar B. Shah, Sivaraman Balakrishnan, and Martin J. Wainwright. Low permutation-rank matrices: Structural properties and noisy completion. In International Symposium on Information Theory, 2018.
Nihar Shah. Learning From People. PhD thesis, EECS Department, University of California, Berkeley, 2017.
Stephen Silverman and Arthur Nádas. On the game of googol as the secretary problem. Contemporary Mathematics, 125:77–83, 1992.
Ivan Stelmakh, Nihar Shah, and Aarti Singh. PeerReview4All: Fair and accurate reviewer assignment in peer review. arXiv preprint arxiv:1806.06237, 2018.
Charles Stein. Inadmissibility of the usual estimator for the mean of a multivariate normal distribution. In Proceedings of the Third Berkeley Symposium on Mathematical Statistics and Probability, volume 1, pages 197–206, 1956.
Nihar B. Shah, Behzad Tabibian, Krikamol Muandet, Isabelle Guyon, and Ulrike Von Luxburg. Design and analysis of the NIPS 2016 review process. preprint arXiv:1708.09794, 2017.
Nihar B. Shah and Martin J. Wainwright. Simple, robust and optimal ranking from pairwise comparisons. Journal of Machine Learning Research, 2018.
Kevin Tian, Weihao Kong, and Gregory Valiant. Learning populations of parameters. In Advances in Neural Information Processing Systems, 2017.
Yichong Xu, Han Zhao, Xiaofei Shi, and Nihar Shah. On strategyproof conference review. arXiv preprint arxiv:1806.06266, 2018.
H. P. Young. Condorcet’s theory of voting. American Political Science Review, 82(4):1231––1244, 1988.

24

Appendix: Extensions
We now present three extensions of our problem setting and results from the main text.

A Noisy data
In this section, we show that even when the scores given by the reviewers are noisy, our estimator in (2) continues to strictly uniformly dominate random guessing in the canonical setting (Section 3.1). We focus on the canonical estimator.
In the noisy setting, when reviewer j ∈ [m] evaluates item i ∈ [n], the reported score is
fj (xi) + ij ,
where ij is a noise term. We assume that the noise terms { ij}i∈[n],j∈[m] are drawn i.i.d. from an unknown distribution. In this setting of noisy reported scores, we modify Deﬁnition 1 of strict uniform dominance, and let the expectation include the randomness in the noise.
The following theorem establishes the strict uniform dominance in the noisy setting for the cardinal estimator πcoaunr in (2) (cf. Theorem 2 for the noiseless setting).
Theorem 6 The canonical estimator πcoaunr strictly uniformly dominates the random-guessing estimator πcan in the presence of noise.
Observe that this result is quite general, since the noise distribution can be arbitrary and unknown. The remainder of this section is devoted to the proof of Theorem 6.

A.1 Proof of Theorem 6

The proof is a slight modiﬁcation to the proof of Theorem 2, so we only highlight the diﬀerence. Recall that ij denotes the noise in the reported score of reviewer j ∈ {1, 2} for item i ∈ {1, 2}. In Eq. (6)
from the proof of Theorem 2, we replace all the noiseless terms fj(xi) by the noisy terms fj(xi) + ij for each i ∈ {1, 2} and j ∈ {1, 2}. Using the fact that the noise terms are independent of everything else, and taking an expectation over all the noise terms, we have

P(πcoaunr = π∗) = 12 E 11, 12, 21, 22 [1 + w((f1(x1) + 11) − (f2(x2) + 22)) − w((f1(x2) + 21) − (f2(x1) + 1
= 2 E 11, 12, 21, 22 [1 + w(f1(x1) − f2(x2) + 11 − 22) − w(f1(x2) − f2(x1) + 21 − 12)] (i) 1 = 2 E 1, 2 [1 + w(f1(x1) − f2(x2) + 1 − 2) − w(f1(x2) − f2(x1) + 1 − 2)] ,

12))] (30)

where step (i) uses linearity of expectation with a change of variable names, as the noise terms ij are i.i.d. Without loss of generality, assume x1 > x2. Recall from the proof of Theorem 2 that f1(x1) − f2(x2) >
f1(x2) − f2(x1), and therefore we have the deterministic inequality

f1(x1) − f2(x2) + 1 − 2 > f1(x2) − f2(x1) + 1 − 2, for any 1, 2 ∈ R.

Using the monotonicity of w, we have

w(f1(x1) − f2(x2) + 1 − 2)) > w(f1(x2) − f2(x1) + 1 − 2).

(31)

Taking an expectation over 1 and 2 in (31) and combining with (30) gives P(πcoaunr = π∗) > 21 .

25

B Ranking under Kendall-tau and Spearman’s footrule distance

In addition to the 0-1 exact recovery loss considered in Theorem 5, Kendall-tau distance and Spearman’s footrule distance are also common metrics for ranking. Recall that a ranking of n items is deﬁned by a function π : [n] → [n], such that π(t) is the index of the tth ranked item for each t ∈ [n]. Equivalently, we can deﬁne a ranking by the function σ : [n] → [n], such that σ(i) is the rank of each item i ∈ [n]. With this notation, we have the relation σ = π−1.
The Kendall-tau distance and the Spearman’s footrule distance are usually deﬁned in terms of the ranking σ. Hence for consistency with these deﬁnitions, throughout this section we focus on the rankings as deﬁned by σ (instead of π as done throughout the remainder of the paper). Kendall-tau distance and Spearman’s footrule distance between any two rankings σ1 and σ2 of n items are deﬁned as:

Kendall-tau distance:

LKT(σ1, σ2) =

1{σ2(i) > σ2(i )}

i∈[n],i ∈[n]: σ1(i)<σ1(i )

Spearman’s footrule distance:

LSF(σ1, σ2) = |σ1(i) − σ2(i)|.
i∈[n]

The following theorem states that given any arbitrary ordinal estimator, there exists a cardinal estimator that performs strictly uniformly better than this ordinal estimator, simultaneously on Kendall-tau distance and Spearman’s footrule distance (cf. Theorem 5 for 0-1 loss).

Theorem 7 Suppose that the true ranking σ∗ is drawn uniformly at random from the collection of all possible rankings. For any arbitrary ordinal estimator σrank, there exists a cardinal estimator with access to one call to the ordinal estimator σrank that strictly uniformly dominates the ordinal estimator σrank with respect to Kendall-tau distance and Spearman’s footrule distance. The computatinal complexity of this cardinal estimator is polynomial in the number of items n, in addition to the time taken by one call to the ordinal estimator σrank.

This result demonstrates the generality of our results in the main text with respect to various (not only 0-1) loss functions. The remainder of this section is devoted to the proof of Theorem 7.

B.1 Proof of Theorem 7
We ﬁrst present the construction of a cardinal estimator σroaunrk-metric, which has access to one call to any arbitrary ordinal estimator σrank. For any i, i ∈ [n] with i = i , we call the pair of items (i, i ) “topologicallyidentical” under the set of ordinal observations B, if the following conditions are met. There is no direct comparison between item i and item i in B. For any item ∈ {i, i }, the set B includes a comparison between item i and item , if and only if the set B includes a comparison between item i and item . Moreover, if two comparisons (i, ) and (i , ) are in the set B, their comparison results are the same, that is,
1{i } = 1{i }. Note that it is possible that item i is compared to no item in B (and hence item i is
also compared to no item). For any item i ∈ [n] and any possible set of ordinal observations B, we deﬁne the following sets:
V +(i, B) ={ ∈ [n], = i | there exists a directed path from item to item i in the graph G(B)}
V −(i, B) ={ ∈ [n], = i | there exists a directed path from item i to item in the graph G(B)}.
In words, V +(i, B) is the set of items that are ranked higher than item i according to the set of ordinal observations B, and V −(i, B) is the set of items that are ranked lower than item i. For any topologicallyidentical pair (i, i ), we have V +(i, B) = V +(i , B) and V −(i, B) = V −(i , B), so we denote V +(i, i , B) := V +(i, B) and V −(i, i , B) := V −(i, B). Now we present a cardinal estimator σroaunrk-metric in Algorithm 3.
In words, Algorithm 3 obtains an initial estimated ranking σinit by making one call to the given ordinal estimator σrank. Then Algorithm 3 identiﬁes two items that are topologically-identical. If such a topologicallyidentical pair (i, i ) exists, we perform the following two steps on this topologically-identical pair:

26

Algorithm 3: Our cardinal ranking estimator σroaunrk-metric(A, Y) concerning Kendall-tau distance and Spearman’s footrule distance.

1 Deduce the ordinal observations B from the cardinal observations Y. Compute an initial estimated

ranking σinit = σrank(B). 2 for i = 1, . . . , n do

3 for i = (i + 1), . . . , n do

4

if the pair (i, i ) is topologically-identical, and both items i and i have at least one score each

from Y then

5

Compute V + := V +(i, i , B). Denote the items in V + as i+1 · · · i+|V +| under the ranking

πinit.

6

Compute V − := V −(i, i , B). Denote the items in V − as i−1 · · · i−|V −| under the ranking

πinit.

7

positions = { ∈ V + ∪ V − ∪ {i, i } | σinit( )}.

8

σ ← σinit.

9

if i i under σinit then

10

Re-arrange items in V + ∪ V − ∪ {i, i } in σ, such that they still occupy positions, and

i+1 · · · i+|V +| i i i−1 · · · i−|V −|.

11

else

12

Re-arrange items in V + ∪ V − ∪ {i, i } in σ, such that they still occupy positions, and

i+1 · · · i+|V +| i i i−1 · · · i−|V −|.

13

end

14

From all of the scores of item i in Y, sample one uniformly at random and denote it as yi.

Likewise denote yi as a randomly chosen score of item i from Y.

15

if πcoaunr(yi, yi ) indicates a relative ordering of the pair (i, i ) diﬀerent from σ then

16

Let σﬂip be the ranking obtained by ﬂipping items i and i in σ.

17

σ ← σﬂip.

18

end

19

break from both for-loops and go to Line 23.

20

end

21 end

22 end 23 Output σroaunrk-metric(A, Y) = σ.

(1) Line 5-13: Using the set of ordinal observations B, we obtain a new ranking σ by re-arranging the items in the initial estimated ranking σinit. In this new ranking σ, we keep all items outside V + ∪ V − ∪ {i, i } in the same positions as they are in σinit. We re-arrange the items in V + ∪ V − ∪ {i, i }, so that they occupy the remaining positions; the set V + is ranked higher than items {i, i }, and the set V − is ranked lower than items {i, i }. Moreover, the relative ranking of items within each set (V +, V − or {i, i }) is preserved. That is, if , ∈ V with some V ∈ {V +, V −, {i, i }}, we have σ( ) < σ( ) if and only if σinit( ) < σinit( ).
(2) Line 14-18: We sample uniformly at random a score for each item in the topologically-identical pair (i, i ). Based on this pair of scores, we call the canonical estimator to decide the relative ordering of these two items. Depending on the outcome of the canonical estimator, we keep the relative ordering of these two items unchanged, or ﬂip the two items accordingly.
This completes the description of the cardinal estimator σroaunrk-metric. We now show that the cardinal estimator σroaunrk-metric takes polynomial time in the number of items n, in addition to the time taken by one call to the given ordinal estimator σrank. To check if a pair of items (i, i )
27

is topologically-identical, it takes polynomial time to go through the pairwise comparisons in B. Hence, it takes polynomial time to identify a topologically-identical pair (or determine that such a pair does not exist). For any topologically-identical pair, in the re-arranging step, the set V −(i, i , B) can be found by a graph traversal from node i. The set V +(i, i , B) can be found by a graph traversal from node i on the graph G(B) but with all edges reversed. Both traversals take polynomial time. Hence, Algorithm 3 takes polynomial time, in addition to one call to the ordinal estimator σrank.

We now present the proof for the uniform strict dominance of the cardinal estimator σroaunrk-metric over the given ordinal estimator σrank. Given any two rankings σ1, σ2 and any two items (i, i ), we denote
α(σ1, σ2, i, i ) := 1{1{σ1(i) > σ1(i )} = 1{σ2(i) > σ2(i )}} as Kendall-tau distance between σ1 and σ2 con-
tributed by the pair of items (i, i ). Then we can write Kendall-tau distance between σ1, σ2 as

LKT(σ1, σ2) =

1{σ2(i) > σ2(i )}

i∈[n],i ∈[n]: σ1(i)<σ2(i )

=

1{1{σ1(i) > σ1(i )} = 1{σ2(i) > σ2(i )}}

1≤i<i ≤n

=

α(σ1, σ2, i, i ).

1≤i<i ≤n

(32)

For Spearman’s footrule dsitance, for each item i ∈ [n], we call the term |σ1(i) − σ2(i)| as Spearman’s footrule distance between σ1 and σ2 contributed by item i.
We analyze Step (1) of re-arranging the items and Step (2) of evoking the canonical estimator separately. The following rearrangement inequality is used for analyzing both steps. For any a1, a2, b1, b2 ∈ R where a1 < a2 and b1 < b2, it is straightforward to verify that

|a1 − b2| + |a2 − b1| ≥ |a1 − b1| + |a2 − b2|.

(33)

We ﬁrst analyze the re-arranging step in Line 5-13 of Algorithm 3. We denote the random variable σre as the estimated ranking after the re-arranging step (that is, the value of the quantity σ after Line 13 of Algorithm 3). The re-arranged ranking σre is a deterministic function of the initial ranking σinit. The following lemma proves a deterministic result about this re-arranging step.

Lemma 2 For any true ranking σ∗, any set of ordinal observations B consistent with the true ranking, and any initial estimated ranking σinit, the re-arranged ranking σre yields smaller or equal loss compared to the initial ranking σinit, regarding Kendall-tau distance and Spearman’s footrule distance. That is,

LKT(σre, σ∗) ≤ LKT(σinit, σ∗) LSF(σre, σ∗) ≤ LSF(σinit, σ∗).

(34a) (34b)

The lemma is proved at the end of this section.

Now we turn to analyze the second step of calling the canonical estimator on the topologically-identical
pair. This step starts from the re-arranged ranking σre. Denote E as the event that Algorithm 3 identiﬁes some topologically-identical pair (that is, Line 5-19 of Algorithm 3 is executed). Then Ec denotes the event
that no topologically-identical pair is found. If there exists no topologically-identical pairs, then the second step in Line 14-18 of Algorithm 3 is never executed. Trivially, the ﬁnal output σroaunrk-metric is identical to the re-arranged ranking σre. We have

E[LKT(σroaunrk-metric, σ∗) | Ec] = E[LKT(σre, σ∗) | Ec] E[LSF(σroaunrk-metric, σ∗) | Ec] = E[LSF(σre, σ∗) | Ec].

(35a) (35b)

28

It remains to consider the case when the event E is true. We start by showing that the event E happens with non-zero probability. Consider any arbitrary true ranking σ∗. Under this true ranking, denote the top item as i(1), and denote the second-ranked item as i(2). Conditioned on this true ranking, consider the set of pairwise comparisons Q such that the set Q includes comparisons between item i(1) and a subset of min{ m/2 , n − 2} items from [n] \ {i(1), i(2)}. Assume that Q also includes comparisons between item i(2) and the identical subset of items from [n] \ {i(1), i(2)}. The rest of the comparisons can be arbitrary between the (n − 2) items in [n] \ {i(1), i(2)}. Recall that 1 < m < n2 , so such a set Q arises with non-zero probability. Hence, the event E happens with non-zero probability.
Note that the set of ordinal observations B fully determines the topologically-identical pair (if any)
selected by Algorithm 3. Since the event E happens with non-zero probability, there exists β such that
P(B = β, E) > 0. We condition on the event E and any set of ordinal observations β such that P(B = β, E) > 0. We denote the two items in the topologically-identical pair selected by the algorithm as items (i(β), i (β))
(or items (i, i ) in short). In what follows, we consider Kendall-tau distance and Spearman’s footrule separately.

Kendall-tau distance: For each , ∈ [n] with = , we consider Kendall-tau distance contributed by the pair ( , ) . Recall that conditioned on the event event E and the set of ordinal observations β, the only pair that can be ﬂipped by Algorithm 3 is (i(β), i (β)). We only need to consider the pairs ( , ) such that the relative ordering of ( , ) can be potentially changed by ﬂipping the pair (i, i ). We consider the following two cases separately.
Case 1: We consider Kendall-tau distance contributed by the pair (i, i ) itself. That is, { , } = {i, i }.
Consider the ranking σre from the re-arranging step. We have

E[α(σre, σ∗, i, i ) | B = β, E] = E[α(σre, σ∗, i, i ) | σ∗ = σ, B = β, E] · P(σ∗ = σ | B = β, E)

σ

(i)
=

E[α(σre, σ, i, i ) | σ∗ = σ, B = β, E] · P(σ∗ = σ | B = β)

σ

(ii) 1 =

E[α(σre, σ, i, i ) | σ∗ = σ, B = β, E].

(36)

T (β)

σ∈topo(β)

where equality (i) is true because σ∗ is independent of E conditioned on B. Equality (ii) is true because of (13) in Lemma 1.
Recall that the initial ranking σinit is obtained by calling the (possibly randomized) ordinal estimator σrank taking input B, and the re-arranged ranking σre is fully determined by σinit. Hence, we further write (36) as

E[α(σre, σ∗,i, i ) | B = β, E]

1 =

E[α(σ, σ, i, i ) | σre = σ, σ∗ = σ, B = β, E] · P(σre = σ | σ∗ = σ, B = β, E)

T (β)

σ σ∈topo(β)

(i) 1 =

E[α(σ, σ, i, i ) | σre = σ, σ∗ = σ, B = β, E] · P(σre = σ | B = β),

(37)

T (β)

σ σ∈topo(β)

where equality (i) is true, because σrank is independent of the true ranking σ∗ and the event E conditioned on B. Hence, σre is independent of the true ranking π∗ and the event E conditioned on B.
Deﬁne the set Ωi i ⊆ topo(β) as the collection of topological orderings where i is ranked higher than i . Deﬁne the set Ωi≺i ⊆ topo(β) as the collection of topological orderings where i is ranked lower than i. Then {Ωi i , Ωi≺i } is a partition of the collection of all topological orderings, topo(β). Given that the pair (i, i ) is topologically-identical, for any ranking σ ∈ topo(β), we can ﬂip items (i, i ), and the ﬂipped ranking is still a
topological ordering. Flipping the items (i, i ) deﬁnes a bijection between the set Ωi i , Ωi≺i , so we have |Ωi≺i | = |Ωi≺i |. Any ranking σre is correct on one and only one of the sets Ωi i and Ωi≺i , and hence the

29

re-arranged ranking σre is correct on exactly half of the topological orderings. For any σ, we have

E[α(σ, π, i, i

)

|

σre

=

σ, σ∗

=

σ, B

=

β, E]

=

1 .

(38)

2

σ∈topo(β)

Combining (38) with (37) yields

E[α(σre, σ∗, i, i

)

|

B

=

β, E]

=

1 .

2

Now consider the cardinal estimator. Similar to the proof of Theorem 5, we have

E[α(σroaunrk-metric, σ∗, i, i ) | B = β, E] < 12 .

Consequently, in Case 1, we have

E[α(σroaunrk-metric, σ∗, i, i ) | B = β, E] < E[α(σre, σ∗, i, i ) | B = β, E].

(39)

Case 2: Consider any pair ( , ) that is not identical to the pair (i, i ). Since the relative ordering of the pair
( , ) is changed by ﬂipping the pair (i, i ), then one item has to be either i or i . Without loss of generality,
assume ∈ {i, i } and ∈ {i, i }. We consider pairs in the form of ( , i) and ( , i ).
If the position of is not in between item i and item i in the ranking σre (that is, if σre( ) < min{σre(i), σre(i )} or σre( ) > max{σre(i), σre(i )}), then ﬂipping the pair (i, i ) does not change the relative ordering of the pair ( , i) or ( , i ). Now we restrict our attention to item ranked in between item i and item
i in the ranking σre. Moreover, if the position of is not in between the positions of item i and item i in the true ranking (that is, if σ∗( ) < min{σ∗(i), σ∗(i )} or σ∗( ) > max{σ∗(i), σ∗(i )}), then whether ﬂipping the
pair (i, i ) or not, one and only one of the two comparisons ( , i) and ( , i) is correct. Hence, we only need to
consider each item ranked between the two items i and i , in both the re-arranged ranking σre and the true ranking σ∗. For each such item , for any re-arranged ranking σre, we have the determinisitc equality

α(σre, σ∗, , i) + α(σre, σ∗, , i ) = 2α(σre, σ∗, i, i ) α(σroaunrk-metric, σ∗, , i) + α(σroaunrk-metric, σ∗, , i ) = 2α(σroaunrk-metric, σ∗, i, i )

(40)

Combining (40) and (39), for each item ranked in between item i and item i in both the re-arranged ranking σre and the true ranking σ∗, we have
E[α(σroaunrk-metric, σ∗, , i) + α(σroaunrk-metric, σ∗, , i ) | B = β, E] < E[α(σre, σ∗, , i) + α(σre, σ∗, , i ) | B = β, E]. (41)

Combining the expression of Kendall-tau distance in (32) with the two cases in (39) and (41) of which the relative ordering of some pair ( , ) is changed, we have

E[LKT(σroaunrk-metric, σ∗) | B = β, E] < E[LKT(σre, σ∗) | B = β, E].

Recall that P(B = β, E) > 0 for some β. Taking an expectation over B yields

E[LKT(σroaunrk-metric, σ∗) | E] < E[LKT(σre, σ∗) | E].

(42)

Combining (42) and (35a) yields

E[LKT(σroaunrk-metric, σ∗)] < E[LKT(σre, σ∗)].

(43)

Finally, combining (43) with inequality (34a) for the re-arranging step completes the proof for Kendall-tau distance.

30

Spearman’s footrule distance: We condition on the event E and any set of ordinal observations β such that P(B = β, E) > 0. Since only one pair (i(β), i (β)) can be ﬂipped by Algorithm 3, we only need to consider Spearman’s footrule distance contributed by these two items. Consider any ranking σi i ∈ Ωi i . Let σi≺i be the ranking obtained by ﬂipping items (i, i ) in σi i . Then we have σi≺i ∈ Ωi≺i . For any such pair {σi i , σi≺i }, we have

P(σ∗ ∈ {σi i , σi≺i }, B = β, E) =P(σ∗ ∈ {σi i , σi≺i } | B = β, E) · P(B = β, E)

=P(σ∗ ∈ {σi i , σi≺i } | B = β, E) · P(B = β, E)

=P(σ∗ ∈ {σi i , σi≺i } | B = β) · P(B = β, E)

(44)

(i)

>0,

(45)

where inequality (i) is true, because the two terms in (44) are both non-zero. The ﬁrst term in (44) is non-zero by the fact that σi i , σi≺i are topological orderings, and by (13) in Lemma 1. The second term in (44) is non-zero, because by construction we ﬁnd β such that the second term P(B = β, E) > 0.
Now we analyze the Spearman’s footrule distance conditioned on the event σ∗ ∈ {σi i , σi≺i }. Using the argument deriving (39), we can further derive
E[α(σroaunrk-metric, σ∗, i, i ) | σ∗ ∈ {σi i , σi≺i }, B = β, E] <E[α(σre, σ∗, i, i ) | σ∗ ∈ {σi i , σi≺i }, B = β, E]. (46)

By the rearrangement inequality (33), if the relative ordering of the pair (i, i ) is correct, then Spearman’s footrule distance does not increase compared to the ranking with the relative ordering of (i, i ) incorrect. Eq. (46) implies that conditioned on β, the event E and the event of σ∗ ∈ {σi i , σi≺i }, the probability that the cardinal estimator σroaunrk-metric gives the correct relative ordering of the pair (i, i ) is higher than the probability that σre gives the correct relative ordering. Hence, for any set of ordinal observations β and any pair {σi i , σi≺i } of the true rankings, we have
E[LSF(σroaunrk-metric, σ∗) | σ∗ ∈ {σi i , σi≺i }, B = β, E] ≤ E[LSF(σre, σ∗) | σ∗ ∈ {σi i , σi≺i }, B = β, E]. (47)

Note that directly applying the re-arrangement inequality does not translate the strict inequality from (39) to (47). The reason is that correctly ordering a topologically-identical pair does not guarantee strictly smaller Spearman’s footrule distance. For example, if item i and item i are the top-2 items in the true ranking, but are the bottom-2 items in σre. Then the relative ordering of the pair (i, i ) does not change the Spearman’s footrule distance. In the rearrangement inequality (33), strictly inequality holds if a1 ≤ {b1, b2} ≤ a2. Hence, we ﬁnd one pair of true rankings {σi∗ i , σi∗≺i } such that one of the following is true:
σi∗ i (i) ≤ {σre(i), σre(i )} ≤ σi∗ i (i ) or σi∗ i (i ) ≤ {σre(i), σre(i )} ≤ σi∗ i (i). (48)
Then strictly inequality in (46) holds on the pair {σi∗ i , σi∗≺i }. Now we provide the construction of this pair {σi∗ i , σi∗≺i }.
We start by constructing a topological ordering σ(i, i , β) (or σ in short) as follows. We topologically sort the items in V + := V (i, i , β) and place them as the top |V +| items in σ. We topologically sort the items in V − := V −(i, i, β) and place them as the bottom |V −| items. Arbitrarily choose one item from {i, i } and place it at the position (|V +| + 1), and place the remaining item from the pair {i, i } at the position (n − |V −|). Topologically sort the rest of the items, and place them in the remaining positions in σ.
We now prove that the ranking σ is a valid topological ordering. Assume for contradiction that σ is not a valid topological ordering. Then there exists a pair ( , ) that violates some pairwise comparison in B. Denote V c = [n] \ (V + ∪ V − ∪ {i, i }). Within each set V +, V − or V c, the items are ordered by a topological ordering. Moreover, there is no direct comparison between item i and item i , so items {i, i } can be ranked

31

with either i i or i ≺ i . Hence, and cannot belong to the same set of V +, V, V c or {i, i }. By the

deﬁnition of the sets V + and V −, in the true ranking V + should be ranked higher than {i, i }, and V −

should be ranked lower than {i, i }. In our ranking σ, we also rank V + higher than {i, i }, and V − lower than

{i, i }. Hence, if both item and item are in V + ∪ V − ∪ {i, i }, the relative ordering between ( , ) must

be consistent with B. Then at least one item from the pair ( , ) must be in V c. Without loss of generality,

assume ∈ V c. Since and cannot belong to the same set, we have ∈ V c. If ∈ {i, i }, since the pair

( , ) violates some pairwise comparison, the items ( , ) are compared in B, that is, is compared to either

i or i . By the deﬁnition of the sets V + and V −, it must be true that ∈ V + or ∈ V −, contradicting the

assumption that ∈ V c. If ∈ V +, by construction the ranking σ ranks higher than . Since the pair ( , )

violates some pairwise comparison, the set B must include the pairwise comparison

. By the deﬁnition

of V +, since ∈ V +, there exists a path from to i. Concatenating the pairwise comparison

with the

path from to i, we have a path from to i. Hence, ∈ V +, contradicting the assumption that ∈ V c.

Similarly, ∈ V − gives a contradiction. Hence, in the ranking σ there exists no pair of items violating

pairwise comparisons in B. By deﬁnition, the ranking σ is a topological ordering. The ranking σ places

items {i, i } at positions {|V +| + 1, n − |V −|}. In Algorithm 3, the re-arranged ranking σre places the set V + before items {i, i }, and the set V − after items {i, i }. Hence, we have either σ(i) ≤ {σre(i), σre(i )} ≤ σ(i )

or σ(i ) ≤ {σre(i), σre(i )} ≤ σ(i). Recall that when constructing σ, we arbitrarily place an item from the set {i, i } at position (|V +| + 1),

and the remaining item from {i, i } at position (n − |V −|). Denote σi∗ i as the topological ordering with item i in position (|V +| + 1). Denote σi∗≺i as the topological ordering with item i in position (|V +| + 1). For any possible σre, one of the conditions in (48) holds on the pair {σi∗ i , σi∗≺i }, and hence strict inequality in (47) holds for the pair {σi∗ i , σi∗≺i }.
Eq. (45) implies that the event σ∗ ∈ {σi∗ i , σi∗≺i } arises with non-zero probability. Taking an expectation over all possible pairs {σi i , σi≺i } in (47), and using the strict inequality for the pair {σi∗ i , σi∗≺i } yields

E[LSF(σroaunrk-metric, σ∗) | B = β, E] < E[LSF(σre, σ∗) | B = β, E].

Taking an expectation over the set of ordinal observations B yields

E[LSF(σroaunrk-metric, σ∗) | E] < E[LSF(σre, σ∗) | E].

(49)

Combining (49) with inequality (35b) for the re-arranging step yields

E[LSF(σroaunrk-metric, σ∗)] < E[LSF(σre, σ∗)].

(50)

Finally, combining (50) with inequality (34b) for the re-arranging step completes the proof for Spearman’s footrule.

We make a comment about having multiple topologically-identical pairs. Notice that in Algorithm 3, we only ﬁnd one topologically-identical pair, and then break out of the for-loops. Alternatively, we can identify and ﬂip multiple disjoint topologically-identical pairs in a similar fashion as in Algorithm 1. This is still a valid algorithm, because each step of processing one topologically-identical pair does not increase Kendall-tau distance or Spearman’s footrule distance.
It remains to prove Lemma 2.

B.2 Proof of Lemma 2

Consider any two items , ∈ [n], such that

in the true ranking σ∗. Let σ1 be an arbitrary ranking.

Let σ2 be a ranking where all items are ranked the same as in σ1, except that the positions of items and

are ﬂipped as compared to σ1. The remainder of the proof is broken into two parts.

Part 1: If the relative ordering of a pair is inconsistent with the relative ordering indicated by the true ranking, then ﬂipping this pair does not increase Kendall-tau distance or Spearman’s footrule distance.

32

Speciﬁcally, we claim that if ≺ in π1, then σ2 has a smaller or equal loss than σ1, with respect to Kendall-tau distance and Spearman’s footrule distance. We discuss the two distance metrics separately.

Kendall-tau distance: First, consider Kendall-tau distance contributed by the pair ( , ). We have ≺

in σ1 and

in σ2. Since we have

in the true ranking, the relative ordering of this pair is correct in

σ2, and incorrect in σ1. Hence,

0 = α(σ2, σ∗, , ) < α(σ1, σ∗, , ) = 1.

(51)

Denote mid as any item ranked in between and in σ1 (or equivalently, in σ2). In the rest of the pairs that are not ( , ), the ﬂip only changes the relative ordering of each pair of the form ( , mid) or ( , mid). If in the true ranking σ∗, item mid is ranked higher than both ( , ), or ranked lower than both ( , ), then the sum of the contributions to Kendall-tau distance by the pair ( , mid) and the pair ( , mid) is the same in σ1 and σ2:

α(σ2, σ∗, , mid) + α(σ2, σ∗, , mid) = 1 = α(σ1, σ∗, , mid) + α(σ1, σ∗, , mid).

(52)

Otherwise mid is ranked in between and in the true ranking σ∗, then we have

0 = α(σ2, σ∗, , mid) + α(σ2, σ∗, , mid) < α(σ1, σ∗, , mid) + α(σ1, σ∗, , mid) = 2.

(53)

Combining the expression (32) of Kendall-tau distance with (51), (52) and (53) yields

LKT(σ2, σ∗) < LKT(σ1, σ∗).

Spearman’s footrule distance: By ﬂipping the positions of the items ( , ), only Spearman’s footrule

distance contributed by these two items has changed. Recall that the condition for ﬂipping the pair ( , )

requires ≺ in π1 and

in σ∗. Applying the rearrangement inequality (33) with a1 = σ1( ), a2 =

σ1( ), b1 = σ∗( ), b2 = σ∗( ), we have

|σ1( ) − σ∗( )| + |σ1( ) − σ∗( )| ≥|σ1( ) − σ∗( )| + |σ1( ) − σ∗( )|

=|σ2( ) − σ∗( )| + |σ2( ) − σ∗( )|.

(54)

Combining (54) with the deﬁnition of Spearman’s footrule distance yields

LSF(σ2, σ∗) ≤ LSF(σ1, σ∗).

This completes Part 1 of the proof.

Part 2: The re-arranging step in Algorithm 3 is equivalent to a sequence of pair ﬂips.
With Part 1 in place, we now explain the rest of the proof. For any arbitrary topologically-identical pair of items (i, i ) and any arbitrary set of ordinal observations B, denote the sets V1 := V +(i, i , B), V2 := {i, i }, V3 := V −(i, i , B). We consider the following procedure. We start by setting σ1 as the initial estimated ranking σinit. We identify one pair ( , ) (if any) such that the following three conditions are met. First, we have ∈ Vj, ∈ Vj with j < j . Second, we have ≺ in σ1. Third, there is no item in V1 ∪ V2 ∪ V3, whose position is in between and in the ranking σ1. If such a pair is found, we ﬂip the positions of and , and update σ1 to be this new ranking. Repeat this procedure until no such pair can be found.
Now we show that this procedure is equivalent to the re-arranging step in Line 5-13 of Algorithm 3. This
procedure properly terminates, because each pair of items ( , ) can be swapped at most once, and there is a
ﬁnite number of pairs. When the procedure terminates, the ranking is identical to the re-arranged ranking
σ after Line 13 of Algorithm 3. To see this claim, we ﬁrst note that this procedure has never moved items
outside V1 ∪ V2 ∪ V3, so we only need to concern about the items in V1 ∪ V2 ∪ V3 and their positions. For each pair ( , ) to be ﬂipped, the procedure speciﬁes that and belong to two diﬀerent sets from V1, V2 and V3. Moreover, by the condition on the pair ( , ), there cannot be any item in V1 ∪ V2 ∪ V3 that is ranked

33

in between and . Hence, the relative ordering of the items within each set of V1, V2 or V3 is unchanged, consistent with the ranking speciﬁed in Line 10 and Line 12 of Algorithm 3. Moreover, the re-arranging step in Algorithm 3 ranks all items in V1 before all items in V2, and all items in V2 before all items in V3. Assume that the ﬁnal output of the procedure is a diﬀerent ranking from the re-arranging step in Algorithm 3, then we can ﬁnd a pair ( , ) that can be ﬂipped, contradicting the fact that no such pairs can be found at the termination of the procedure. Hence, the procedure and the re-arranging step in Algorithm 3 are equivalent. Applying Part 1 to each ﬂip in this procedure completes the proof of the lemma.

C Ranking under arbitrary true ranking
Theorem 5 in Section 3.3 compared our cardinal estimator with arbitrary ordinal estimators under a uniform prior over the true ranking. In this section, we present a result for ranking under any arbitrary true ranking. This setting is more similar to our results on the canonical setting (Theorem 2) and A/B testing (Theorem 4) in the main text. When the true ranking is arbitrary, a minimax-optimal ordinal estimator outputs uniformly at random a topoglocial ordering consistent with the pairwise comparisons. We denote this optimal ordinal estimator as πrank-unif.
Given this ordinal estimator, we then construct a cardinal estimator πroaunrk-unif by simply setting the initial estimate π = πrank-unif(B) in Line 2 of Algorithm 1 (instead of executing the current Line 2). The following theorem states the desired result for strict uniform dominance of this cardinal estimator over the optimal ordinal estimator πrank-unif.
Theorem 8 When the true ranking is arbitrary, the cardinal estimator πroaunrk-unif strictly uniformly dominates the minimax-optimal ordinal estimator πrank-unif.
Importantly, we can think of this cardinal estimator as a post-processing step which builds on the output of the optimal ordinal estimator. This cardinal estimator takes polynomial time in the number of items n, in addition to the time taken by one call to the ordinal estimator πrank-unif.
We prove Theorem 8 in the remainder of this section.
C.1 Proof of Theorem 8
The proof is a slight modiﬁcation to the proof of Theorem 5, so we only highlight the diﬀerence. First, we consider the probability of success of the optimal ordinal estimator πrank-unif that outputs one of the topological orderings uniformly at random:

P(πrank-unif(β) = π∗ | B = β) =

P(π = π∗ | πrank-unif = π, B = β)P(πrank-unif = π | B = β)

π∈topo(β)

(i) 1 =

P(π = π∗ | πrank-unif = π, B = β),

T (β)

π∈topo(β)

(55)

where equality (i) is true because the ordinal estimator πrank-unif uniformly at random outputs one of the topological orderings consistent with β.
Now we consider each term P(π = π∗ | πrank-unif = π, B = β) in (55). The quantities π∗ and π are both deterministic. Trivially, we have

P(π = π∗ | πrank = π, B = β) = 01 oifthπe=rwπis∗e. (56)

Combining (55) and (56) with the fact that the true ranking π∗ must be a topological ordering consistent with β, we have

P(πrank-unif(β) = π∗ | B = β) = 1 .

(57)

T (β)

34

Now consider the cardinal estimator πroaunrk-unif. When the number of ﬂippable pairs is zero, the cardinal estimator behaves equivalently as the ordinal estimator πrank-unif. Following a similar argument as Case 1 in the proof of Theorem 5, for any set of ordinal observations β, we have (cf. Equation (17) in the proof of
Theorem 5):

P(πroaunrk-unif | B = β, L = 0) = P(πrank-unif = π∗ | B = β).

(58)

Denote πinit as the initial estimated ranking obtained by calling the ordinal estimator πrank-unif. When the number of ﬂippable pairs is L = > 0, the probability of success of the cardinal estimator is

P(πroaunrk-unif = π∗ | B = b, L = )

=

P(πroaunrk-unif = π∗ | B = β, L = , πinit = π)P(πinit = π | B = β, L = )

π∈topo(β)

(i) 1 =
T (β)

P(πroaunrk-unif = π∗ | B = β, L = , πinit = π),

π∈topo(β)

(59)

where equality (i) is true because the ordinal estimator πrank-unif outputs a topological ordering uniformly at random.
The remaining argument is similar to Case 2 in the proof of Theorem 5, so we only outline the main steps. Consider all total rankings that are identical to the true ranking π∗, except for (possibly) the relative
ordering of the ﬂippable pairs. There are 2 such total rankings, and all these 2 total rankings are
topological orderings on the graph G(B). In (59), the summation of π is over all topological orderings. In particular, this summation includes these 2 total rankings. Recall that the cardinal estimator πroaunrk-unif is obtained by replacing Line 2 of Algorithm 1 by calling the ordinal estimator πrank-unif. To be able to apply Theorem 2, we obtain a cardinal estimator πreaqnk-unif by replacing Line 2 of Algorithm 2 by calling the ordinal estimator πrank-unif. This estimator πreaqnk-unif is equivalent to the original estimator πroaunrk-unif. When the initial estimated ranking πinit is any of the 2 total rankings, the probability that the cardinal estimator πreaqnk-unif gives the correct output is strictly greater than 21 . Hence, we bound (59) as (cf. Equation (19) in the proof of Theorem 5):

P(πreaqnk-unif = π∗ | B = b, L = ) > T (1β) · 2 · 21 = T (1β) (=i) P(πrank-unif = π∗ | B = β). (60)

where equality (i) is true from (57). Having established (58) and (60), the rest of the argument follows the proof of Theorem 5.

35

