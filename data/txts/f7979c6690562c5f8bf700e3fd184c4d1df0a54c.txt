Zero-shot Neural Transfer for Cross-lingual Entity Linking
Shruti Rijhwani Jiateng Xie Graham Neubig Jaime Carbonell
Language Technologies Institute Carnegie Mellon University
{srijhwan, jiatengx, gneubig, jgc}@cs.cmu.edu

arXiv:1811.04154v1 [cs.CL] 9 Nov 2018

Abstract
Cross-lingual entity linking maps an entity mention in a source language to its corresponding entry in a structured knowledge base that is in a different (target) language. While previous work relies heavily on bilingual lexical resources to bridge the gap between the source and the target languages, these resources are scarce or unavailable for many low-resource languages. To address this problem, we investigate zero-shot cross-lingual entity linking, in which we assume no bilingual lexical resources are available in the source low-resource language. Speciﬁcally, we propose pivot-based entity linking, which leverages information from a highresource “pivot” language to train character-level neural entity linking models that are transferred to the source lowresource language in a zero-shot manner. With experiments on 9 low-resource languages and transfer through a total of 54 languages, we show that our proposed pivot-based framework improves entity linking accuracy 17% (absolute) on average over the baseline systems, for the zero-shot scenario.1 Further, we also investigate the use of language-universal phonological representations which improves average accuracy (absolute) by 36% when transferring between languages that use different scripts.
Introduction
Entity linking (EL) is the task of associating an entity mention with its corresponding entry in a structured knowledge base (such as Wikipedia or Freebase), with several downstream applications including document understanding, entity and event coreference, text mining and information retrieval (Mihalcea and Csomai 2007; Han and Sun 2012). In this work, we focus on cross-lingual EL (McNamee et al. 2011), where the given entity mention is in a (source) language different from the (target) language of the knowledge base. In Figure 1, for example, the input entity in Marathi (‘Poland’) is linked to the appropriate entry in an English knowledge base (KB).
In monolingual EL, simple methods like string similarity and Wikipedia anchor-text can be used effectively to identify candidate KB entries for each entity mention (Ji and Grishman 2011; Sil et al. 2017). However, such methods often fail in the case of cross-lingual EL, because entity mentions in
1All data, resources and code will be made available as a new benchmark for zero-shot cross-lingual entity linking.

Marathi [पोलंड] हा मध्य युरोपातील एक देश आहे
Gloss: [Poland] is a country in Central Europe.

Cross-lingual Entity Linking पोलंड Marathi

Grapheme Pivoting
पोलंड
Marathi

पोलंैड
Hindi

Poland Poland

Phoneme Pivoting polənɖə Marathi IPA

polæːnɖə
Hindi IPA

powlənd
English IPA

Figure 1: Cross-lingual EL of an entity mention in a Marathi sentence to an English KB: (1) direct Marathi–English linking. (2) Pivoting Marathi through Hindi for linking. (3) Using IPA for pivoting. The arrows represent entity linking and the solid blue lines represent parallel data from bilingual lexicons, used for pivoting.

the source language and KB entries in the target language are frequently dissimilar. Existing work uses bilingual resources to bridge this gap, including lexicons and Wikipedia inter-language links (Tsai and Roth 2016; Pan et al. 2017; Tsai and Roth 2018). However, the vast majority of the world’s ≈ 7, 000 living languages are low-resourced, and have extremely limited or zero bilingual resources. Even within the 300 languages available on Wikipedia, some have an extremely small number of articles (for example, Oromo and Tigrinya have only 773 and 168 Wikipedia pages respectively, while English has over 5 million). In order to enable cross-lingual EL for such low-resource languages (LRLs), it is imperative to design methods that do not rely heavily on lexicons or other resources in the LRLs.
In this work, we take this to the extreme: we perform the ﬁrst study on zero-shot cross-lingual entity linking, de-

vising methods that require no bilingual resources in the source language (i.e., the language that the input entity mention is sourced from). We propose pivot-based entity linking, or PBEL, which is based on the intuition that despite the fact that many languages have very few resources, it is common that these languages have closely-related higherresource languages (HRLs) that we can leverage. For example, the relatively low-resourced languages of Marathi and Lao are from the same language family as the highresourced Hindi and Thai respectively. We exploit bilingual lexicons and structured information available in these HRLs to improve EL for languages where no such resources are available. The speciﬁc contributions of this paper are
• PBEL, a novel method for cross-lingual EL, that uses no bilingual resources in the source language. This consists of two components:
Zero-shot transfer of neural entity linking models: Using a bilingual lexicon between an HRL and English, we train a character-level neural model for linking entities in the HRL to an English KB. The model can be transferred to perform EL for a source LRL, without any languagespeciﬁc ﬁne-tuning. For example, we train a model to link Hindi (HRL) to English and transfer the model to link Marathi (LRL) to English. Such transfer learning schemes have been successful for other tasks, such as morphological tagging and machine translation, when used between closely-related languages (Zoph et al. 2016; Cotterell and Heigold 2017).
Pivoting: Rather than attempting to directly link an LRL entity to English, we link the entity to a closely-related HRL. We then use bilingual lexicons, readily available in the HRL, to obtain the corresponding English entity link. We are, therefore, using the HRL as an intermediate pivot between the source LRL and English. Our experiments demonstrate that this signiﬁcantly improves EL accuracy over directly linking to English, as named entities are likely similar in related languages (Tsvetkov and Dyer 2016). In Figure 1, the orthographic pivoting example shows that ‘Poland’ in Marathi and Hindi are written similarly and can be linked with our neural EL model. Since we have extensive Hindi-English lexicons, we can obtain the English KB entry quite simply from the Hindi name (shown with a solid blue line in the ﬁgure).
• The use of phonological representations for cross-lingual EL. Transfer of character-level models is bound to fail when the HRL and LRL do not use the same writing system. We propose using International Phonetic Alphabet (IPA) to bridge the gap between different scripts. Figure 1 shows an example of pivoting in the phonological space. We see that the pronunciation (IPA representation) of ‘Poland’ is highly similar in Marathi and Hindi because they are closely-related languages.
• Experiments with 9 test languages from various language families and 54 transfer languages that analyze the performance of current state-of-the-art cross-lingual entity linking methods in truly zero-shot settings, in order to demonstrate the effectiveness of the proposed PBEL method.

Problem Setting
Cross-lingual EL is the task of linking an entity mention m in a source language to a structured KB K in a target language. In our work, we study the case when the source language is some low-resource language (LRL), and follow most previous work by using an English KB as the target (Pan et al. 2017; Tsai and Roth 2018). The task involves identifying the appropriate entry een ∈ K that corresponds to the entity mention m. Our EL model predicts an entity link by maximizing a score function between m and een.
eˆen = argmax score(m, een)
een ∈K
In addition, consider an HRL that is closely-related (via language family, script, similar phonology etc.) to the source LRL, for which bilingual resources with links to the English KB are available. These are easily obtainable from inter-language links in massive multilingual resources like Wikipedia, DBPedia (Auer et al. 2007) and BabelNet (Navigli and Ponzetto 2012). For each entry een ∈ K, let the parallel entity in the HRL be eHRL. Note that it is possible that eHRL = ∅ for some een, as not all English entities are language-linked to the HRL. These HRL parallel entities are the only cross-lingual resources we have access to in this work. They are used for training the EL model as well as for pivoting, as described in the following section. We do not use any parallel entities in the LRL.
Model
The basic component of our entity linking system consists of two neural encoders, one for the HRL and one for English, which convert named entities (character sequences) into vector representations. The two encoders are trained such that the vector representations of two parallel entities eHRL and een are similar. We use the two encoders to calculate two sets of scores between an LRL entity mention m and a KB entry een through the following methods, leveraging the fact that the LRL and HRL are closely-related:
• Zero-shot Transfer We apply the HRL encoder directly on m and the English encoder on een, and calculate a score based on the similarity of the vector representations.
• Pivoting We apply the HRL encoder on both the LRL entity mention m and the parallel entry eHRL, and calculate a score based on the similarity of the vector representations.
Then, we take the maximum out of these two scores as the score between m and een.
In the following sections, we describe each part of the model in more detail, and discuss using phonological representations. For simplicity, we introduce the system with a single HRL, and discuss transfer from multiple HRLs later.
We should note that, in most existing work, the EL process is a two-step pipeline – candidate retrieval and contextbased disambiguation (Hachey et al. 2013). Candidate retrieval reduces the search space for EL by selecting a small number of candidates for more precise linking. This is required because precise linking algorithms are often prohibitively expensive to use on the entire KB. Our proposed

Cosine Similarity

vHRL
HRL Bi-LSTM
…

ven
English Bi-LSTM
…

Character embedding

Character embedding

पोलैंड
Hindi

Poland
English

Figure 2: Entity similarity model trained on parallel entities between an HRL and English. An example entity (‘Poland’) with Hindi as the HRL is shown here.

method is context-insensitive, much like traditional candidate retrieval models. Although we present our method as an end-to-end EL system by simply picking the top-scoring KB entry as the entity link, we also discuss how it can be used to retrieve a larger number of candidates in next section.
Entity Similarity Encoder
The entity similarity model is shown in Figure 2. We use character-level Bidirectional-LSTMs (Bi-LSTM) to encode entities into a continuous vector space. The model is trained to maximize the cosine similarity between the vector representations of an entity in an HRL and its equivalent (i.e., parallel) entity in English, much like recent work in neural information retrieval (Mitra and Craswell 2017).
Consider an entity eHRL and its parallel entity in English een. Each entity is a sequence of characters; eHRL = c1, c2 . . . cM and een = k1, k2 . . . kN . For each character, we obtain a ﬁxed-size character embedding. The embeddings are used as input to the Bi-LSTM and the ﬁnal states (concatenation of the last states from the forward and backward LSTMs) form the encoded entity vectors vHRL and ven.
vHRL = HRL-Bi-LSTM( c1, c2 . . . cM )
ven = English-Bi-LSTM( k1, k2 . . . kN )
The similarity score is computed as,
sim(eHRL, een) = cosine(vHRL, ven)
Since we want to efﬁciently train a model that can rank KB entries for a given mention, we follow existing work and use negative sampling with a max-margin loss for training the encoder (Collobert et al. 2011). The loss function is
L = max(0, sim(eHRL, een) − sim(eHRL, e∗en) + λ)

पोलैंड
Hindi

eHRL

पोलंड m
Marathi

Poland een
English

HRL Bi-LSTM
HRL Bi-LSTM
English Bi-LSTM

vHRL vm vm ven

sim(eHRL, m) max
sim(een, m)

Figure 3: Architecture to compute score(m, een) with pivoting through a high-resource language entity eHRL. An example entity (‘Poland’) is shown here, with Marathi as the source LRL and Hindi as the pivot HRL.

where λ is the margin and e∗en is a negative KB example such that e = e∗.2
Zero-shot Transfer to LRL If we train the model using an HRL that is sufﬁciently similar to the source LRL, the entity encoder can effectively predict similarity between an entity mention m and the English KB entries. We use the learned HRL-Bi-LSTM to encode m and the English-Bi-LSTM to encode an English KB entry een ∈ K. The score for een is the cosine similarity between these encodings:
sim(m, een) = cosine(vm, ven)
where vm = HRL-Bi-LSTM(m), and m is a sequence of characters.
Pivoting By transferring the entity encoder (as discussed above), we can compute similarity between an LRL mention and the English KB entries. In addition, we propose pivoting, which uses an HRL as an intermediate pivot between the LRL and English. Speciﬁcally, instead of considering the English entity een, we consider its parallel entity eHRL in the HRL. We use the learned HRL-Bi-LSTM to encode both m and eHRL, and calculate a similarity score between the encodings:
sim(m, eHRL) = cosine(vm, vHRL)
Note that this score is used for een, as een and eHRL refer to the same entity (in English and the pivot HRL respectively).
Calculate EL score Using the two methods described above, we have two sets of scores between m and een, and we take the maximum out of the two as our ﬁnal score (Figure 3):
score(m, een) = max(sim(m, een), sim(m, eHRL)) (1)
2For each mini-batch of training data consisting of paired HRLEnglish entities, we use the correct KB entry as the positive sample, and all other KB entries in the mini-batch as negative samples.

The score function for EL is modiﬁed to consider both the similarity between m and een and the similarity between m and eHRL. The ﬁnal score for een ∈ K takes the maximum of the two scores because our objective is to maximize the similarity. Since not all the entries in K have a parallel entity in HRL, it is non-trivial to use another combination of the scores (instead of max). If there is no parallel entity, we consider sim(m, eHRL) = −∞.
Phonological Representation
Since the entity similarity model is a character-level neural network, cross-lingual transfer is bound to fail if the LRL uses a different script than the HRL used for training the encoder. To overcome this problem, we propose training the encoder in the language-universal phonological space. We experiment with two representations:
Phoneme embeddings: We convert all parallel training data between the HRL and English into IPA using Epitran, a grapheme-to-phoneme system that supports over 55 languages (Mortensen, Dalmia, and Littell 2018). The encoder model itself is agnostic to the characters used to represent the entities and can be trained with the IPA parallel data in the same manner as described above.
Articulatory feature embeddings: We transform our parallel IPA training data into articulatory feature sets using PanPhon (Mortensen et al. 2016). Articulatory features can potentially capture important characteristics of the pronunciation that may not be apparent from the IPA, as indicated by improved low-resource Named Entity Recognition by (Mortensen et al. 2016). PanPhon converts each IPA segment into 21 features, which represent phonological aspects of the input (including voice, nasal, strident etc.) Since each word is a sequence of IPA segments, we obtain a sequence of feature vectors from PanPhon. These features are linearly transformed into an embedding (which replaces the character embedding in Figure 2) using a weight matrix and bias vector, both of which are trained with the encoder model.
Phylogenetic Weighting
So far, we have discussed transferring to the LRL from a single HRL. However, we can easily train multiple encoders on different HRLs. In order to leverage these models, we use a simple weighting mechanism, whereby the similarity scores from each HRL model is weighted by the phylogenetic distance between the HRL and the source LRL. The KB entry with the maximum score after weighting is selected as the predicted entity link. Phylogenetic distance, obtained from the URIEL Database (Littell et al. 2017), represents the relative distance between two languages in the Glottolog hypothesized tree of language (Hammarstro¨m et al. 2018). This essentially implies languages that have similar origin will be closer in distance, which is intuitively useful for identifying appropriate pivot HRLs for a speciﬁc LRL.
Experiments
In this section, we discuss our experimental setting, baselines and results on several low-resource languages. We attempt to answer the following research questions: (1) “Does

the proposed PBEL method outperform methods that do not perform pivoting?” (2) “What is the interplay of the orthographic or phonological input representation with the features of the high-resource transfer language and the lowresource test language?” (3) “What is the potential of using pivoting for candidate retrieval in 2-step EL systems?” (4) “How much does a small amount of lexical data in the LRL improve PBEL?”
Experimental Settings
In order to comprehensively, yet realistically, examine performance on a wide variety of low-resource language pairs, we perform experimental validation on two varieties of the task. For both, we measure the performance of the baselines and our system with linking accuracy – i.e. the fraction of instances when the system-predicted link was the “true” KB entry for the given input.
Cross-lingual KB Title Linking Our test set is constructed from Wikipedia parallel titles between the LRL and English. That is, the ‘gold-standard’ link for an article title in the LRL is the corresponding English Wikipedia entry. Note that these parallel titles are used only for testing.
In contrast to the traditional EL task of linking textual entity mentions to KB entries, this experimental setting is similar to “Cross-lingual Article Linking” (Wang, Wu, and Tsai 2014), where we link Wikipedia article titles in the LRL to English KB entries. We focus on articles about named entities (locations, persons and organizations). Most work (Sorg and Cimiano 2008; Wang et al. 2012; Wang, Wu, and Tsai 2014) in cross-lingual article linking assumes the availability of a KB in the source LRL. This is unrealistic for our zero-shot scenario and hence, we compare with existing methods that do not rely on this assumption.
We test on nine relatively low-resource languages from various language families: Tigrinya (ti), Lao (lo), Uyghur (ug), Telugu (te), Punjabi (pa), Javanese (jv), Marathi (mr), Bengali (bn) and Ukrainian (uk). We have 2000 titles in the test set for each language, apart from ti, lo and ug, for which we have 90, 579 and 1297 instances respectively3. The target KB is English Wikipedia, which contains 2.1 million titles. We use a total of 54 HRLs as potential transfer languages, details of which are in the supplementary material.
We primarily use Wikipedia links as a test bed because of the availability of data in many LRLs, not found in traditional EL datasets. We note that although the title linking task is not identical to entity mention linking, it maintains much of the difﬁculty associated with cross-lingual EL, particularly with respect to how state-of-the-art translationbased techniques perform poorly in the zero-resource setting. However, the challenge of linking ambiguous mentions is eliminated in this task, which is why we also test our method on a full cross-lingual EL dataset, described below.
Full Cross-lingual Entity Linking We also test our proposed PBEL method on the standard cross-lingual EL setting of linking textual mentions to KB entries. For the test set, we use annotated documents from the DARPA
3Due to the small size of Wikipedia in these languages.

Model

bn

jv

lo

mr

pa

te

ti

uk

ug Avg.

EXACT TRANS

.00

.63

.02

.00

.00

.00

.00

.63

.02

.17

.00

.00

.02

.02

.03 .08

.46

.02

.03 .15

ENCODE MANUAL .36 (hi) .70 (id) .07 (th) .46 (hi) .31 (hi) .20 (ta) .44 (am) .25 (ru) .16 (tr) .33 BEST-53 .38 (ms) .70 (id) .07 (th) .46 (hi) .36 (te) .36 (pa) .44 (am) .41 (kk) .16 (tr) .37

PBEL

MANUAL .48 (hi) .86 (id) .28 (th) .62 (hi) .49 (hi) .33 (ta) .69 (am) .50 (ru) .32 (tr) .51

BEST-53 .48 (hi) .86 (id) .28 (th) .62 (hi) .49 (hi) .47 (hi) .69 (am) .54 (kk) .32 (tr) .53

MULTI

.53

.87

.28

.62

.48

.46

.69

.56

.40 .54

Table 1: Accuracy for cross-lingual Wikipedia title linking, with the transfer HRL shown in parentheses. The best accuracy among input representations with graphemes, phonemes or articulatory features for ENCODE and PBEL is presented here. Complete results for each representation are in the supplementary material.

LORELEI program4, in two extremely low-resource languages – Tigrinya and Oromo. These are news articles, blogs and social media posts about disasters and humanitarian crises (ﬂoods, famine, political unrest etc.). The data contains named entity mentions extracted from the texts, annotated with their respective KB links. The English KB provided with the dataset contains over 11M entries. This KB is much larger than English Wikipedia and includes entities from, among other sources, GeoNames and the CIA World Factbook.
Entity Similarity Scoring Models
We consider three models for scoring KB entries for crosslingual EL. Two are based on existing literature on stateof-the-art monolingual or cross-lingual EL methods (Ji and Grishman 2011; Pan et al. 2017; Sil et al. 2017), which have been shown to work in the supervised setting where an entity lexicon for the LRL is available, but are intuitively less suited for our zero-shot setting. The third is the characterlevel neural decoder described in the previous section, which we posit is more appropriate for zero-shot transfer, and for use with our proposed pivoting method.
• EXACT: Exact match to the KB is used in state-of-the-art monolingual EL systems (Sil et al. 2017).5 The predicted entity link, if found, is the KB entry that is an exact string match with the mention m.
• TRANS: This baseline is a candidate retrieval technique used in the state-of-the-art low-resource EL system by Pan et al. (2017), which attempts to translate the mention m into English in order to predict the entity link. We generate a bilingual lexicon with word alignments on parallel Wikipedia titles using fast align (Dyer, Chahuneau, and Smith 2013). Each word in the input entity m is translated to English using the lexicon. The pre-
4https://www.darpa.mil/program/ low-resource-languages-for-emergent-incidents
5Monolingual EL also often uses Wikipedia anchor text for matching, which is infeasible in the LRL scenario.

dicted entity link is the exact match of the obtained translation, if found, in K. We experiment with two varieties of lexicon creation with different resource requirements:
Supervised. The lexicon is created from a small number of parallel entities between the LRL and English.
Zero-shot. The lexicon is created from parallel entities between a closely-related HRL and English.
• ENCODE: We train a similarity encoder, as seen in Figure 2, using parallel Wikipedia titles between English and an HRL. We transfer the trained HRL-Bi-LSTM, without ﬁne-tuning, to encode the mention m. The ENCODE model does not make use of “pivoting” and directly compare m with the English KB entries. These models are trained in either orthographic or phonological space.
The entity similarity encoder model is implemented in DyNet (Neubig et al. 2017), with a character embedding size of 64 and LSTM hidden layer size of 512.
Results: Cross-lingual KB Title Linking
As described above, we test on nine LRLs. We experiment with variants of the models that differ in terms of selecting an appropriate HRL for transfer:
• MANUAL: We manually choose an HRL a priori, which is closely related (from the same language family) to the source LRL. The HRLs we select are (for the respective LRLs) – Amharic (Tigrinya), Thai (Lao), Turkish (Uyghur), Tamil (Telugu), Hindi (Punjabi, Marathi, Bengali), Indonesian (Javenese) and Russian (Ukrainian). The HRLs selected are of different script than the LRL for some languages (Lao-Thai, Bengali-Hindi etc.), in order to test the utility of phonological transfer.
• BEST-53: We attempt to transfer similarity encoders trained on 53 potential HRLs and present the HRL that obtained the highest accuracy for each of the nine test languages. The 53 are all the languages supported by Epitran (Mortensen, Dalmia, and Littell 2018), apart from the source LRL itself.

• MULTI: In this setting, we use multiple pivot languages for a single source LRL. We use all 53 languages together, and experiment with both unweighted and phylogeneticdistance-weighted combination, as described in the previous section.
We use the above methods with the ENCODE model as well as our proposed PBEL method. For ENCODE, we use the HRL only for training the encoder. For PBEL, we additionally use the HRL for pivoting, i.e., to score KB entries as described in Equation 1. We also compare with EXACT and TRANS (Zero-shot). The supervised TRANS uses a lexicon built from Wikipedia parallel titles in the LRL, which we also use to construct the test set, leading to an unfair comparison for the cross-lingual title linking task.
The entity linking accuracy on the Wikipedia test set are summarized in Table 1. On average, our proposed PBEL method performs signiﬁcantly better than the baselines, with signiﬁcant accuracy gains in all nine test languages.
The EXACT baseline, which is most often used for monolingual EL (Sil et al. 2017), performs reasonably only when the test language is in the same script as English (i.e., Javanese). Similarly TRANS, the current state-of-the-art retrieval method in cross-lingual EL (Pan et al. 2017), fails when zero data is available in the test language, unless the HRL is very closely-related to the LRL (as with jv, mr and am). On the other hand, ENCODE presents relatively strong zero-shot transfer results.
PBEL offers stronger performance than ENCODE because it considers similarity of the LRL mention with both the HRL and English. As seen in the BEST-53 results, the HRL that performs best is closely-related to the respective test LRL (language family, shared writing system or geographic proximity). Since PBEL leverages this similarity, it becomes easier to predict the correct link. We also observe that using multiple pivot HRLs leads to better average accuracy, with considerable improvement for some languages.
In most cases, the MANUAL HRL is also the best performing in BEST-53. However, we see that the Dravidian Telugu (te) seems to obtain higher accuracy with Indo-Aryan HRLs – Punjabi (pa) or Hindi (hi). This could be because Tamil (ta) uses a different script and is relatively distant from Telugu in the Dravidian family (Rama and Kolachina 2013). We also see that the Ukrainian (uk) test set has better performance with another Cyrillic script language, Kazakh (kk), rather than Russian (ru). We attribute this to the fact that, on Wikipedia, person names in Russian are written last-name,ﬁrst-name, but ﬁrst-name,last-name in Ukrainian, which reduces the success of zero-shot transfer.
Results: Full Cross-lingual Entity Linking
We select appropriate HRLs a priori for training ENCODE and PBEL – Amharic for Tigrinya and Somali for Oromo. We compare with the EXACT, supervised and unsupervised TRANS and ENCODE scoring models. The training data for the encoders is Wikipedia parallel entities between the HRL and English, as in the previous section.
Entity linking accuracies on the LORELEI dataset are shown in Table 2. PBEL has considerably higher accu-

Lang.
EXACT TRANS Supervised TRANS Unsupervised ENCODE PBEL

Tigrinya
0.00 0.21 0.21 0.16 0.33

Oromo
0.01 0.05 0.01 0.10 0.11

Table 2: Entity linking accuracy on non-Wikipedia data

racy than the other methods. However, we see relatively lower improvement in accuracy with Somali-Oromo than Amharic-Tigrinya. This is because Somali and Oromo, despite both being Afro-Asiatic languages, are from different sub-language-family branches and are not similar enough for strong transfer performance6 (Banti 1988). The availability of a closely-related HRL is essential to the success of PBEL.
Surprisingly, the supervised TRANS model, which uses Wikipedia parallel data in the LRL itself as a lexicon, does not perform better than the zero-shot PBEL. We primarily attribute this to the extremely small size of Wikipedia in these languages (90 Tigrinya and 295 Oromo parallel links with English). We also note that TRANS relies solely on lexicon string lookup. This is particularly disadvantageous for Oromo, where there are several accepted spelling variants of the same word and the Wikipedia lexicon contains just one of these (for example ‘Ethiopia’ can be written as ‘Itiyoophiyaa’, ‘Itoophiyaa’, ‘Itoopiyaa’, ‘Toophiyaa’ or ‘Itophiyaa’). The character-level LSTM we use is likely able to normalize across some of these variations (Lample et al. 2016; Luong and Manning 2016). Overall, our proposed PBEL method counters several of the limitations of using bilingual lexicons, which strongly affects the performance on such extremely low-resource EL datasets.
Analysis
Character Representation We look at the use of different character representations: orthographic (graphemes), IPA (phonemes) and articulatory features. The PBEL model results for our test set with each input representation are presented in Table 3. The HRLs used are the same as MANUAL.
We see that using phonological representations (phonemes and articulatory features) offers the ability to map between languages that use different orthographies, explaining the convincing improvement over graphemes for HRL-LRL pairs that are written in different scripts (Table 3). With graphemes, the experiments on these languages achieve ≈ 0 accuracy because the character vocabulary of the HRL encoder simply does not contain the low-resource test language characters. This is the case with Lao-Thai (lo-th), Telugu-Tamil (te-ta) and Bengali-Hindi (bn-hi). In contrast, we observe that the grapheme representation offers strong transfer performance when the LRL and HRL share orthography, notably Javanese-Indonesian (jv-id), Marathi-Hindi (mr-hi) and Ukrainian-Russian (uk-ru).
6We used Somali because it is the closest language to Oromo that is available on both Wikipedia and Epitran.

Input
Grapheme Phoneme Articulatory

*bn (hi)
.00 .48 .45

jv (id)
.86 .84 .82

*lo (th)
.02 .20 .28

mr (hi)
.62 .58 .56

*pa (hi)
.00 .18 .49

*te (ta)
.00 .10 .33

ti (am)
.61 .69 .63

*uk (ru)
.50 .23 .42

*ug (tr)
.08 .21 .32

Table 3: Entity linking accuracy with PBEL, using Graphemes, Phonemes or Articulatory features as input. The HRL used for training and pivoting is shown in parentheses in the ﬁrst row. The pairs with the different scripts are marked with a “*”.

Recall @100

Recall @20

Recall @10

1.0

Recall @5

Recall @1

0.5

bn-hi jv-id lo-th mr-hi pa-hi te-ta ti-am uk-ru ug-tr

0.0
Figure 4: Recall @k for nine test languages
Pivoting for Candidate Generation Up to this point, we have demonstrated that our pivoting method can be used for end-to-end EL. However, as mentioned in the previous section, it is common in standard EL systems to use candidate retrieval methods that feed into a more sophisticated downstream disambiguation model. In this case, it is of interest how good the entity linking algorithm is at generating lists of k-best candidates. Figure 4 examines this by showing the ‘Recall @k’ – the fraction of instances when the correct entity link is present in the top-k entities as scored by our system (Tsai and Roth 2018). We observe that for systems with high entity linking accuracy (recall @1) like JavaneseIndonesian (jv-id) and Tigrinya-Amharic (ti-am), recall at higher k values offer diminishing returns. However, other languages show considerable gain in recall even at k = 5 and up to k = 100.
Joint Training with the Source Language Although our main focus is an entity linking method that uses zero resources in the source language, we also analyze how the performance of our model improves when jointly trained with a small amount of data in the source LRL. Figure 5 shows the variation of EL accuracy with different amounts, ranging from 10 to 2,500, of LRL samples added to the HRL (MANUAL setting) data for training the entity similarity encoder. For language pairs that are very closely-related and share the same scripts, such as jv-id and mr-hi, there is only a small increase in accuracy even with thousands of source language training samples. In contrast, there is considerable performance improvement for bn-hi and te-ta, both of which

Figure 5: Entity linking accuracy on joint training with different amounts of LRL data (x-axis is not to scale).
use phonological transfer since the writing systems are different. We also note that several of our test languages (ti, lo, ug) are so poorly resourced, even on Wikipedia, that there was not enough data for this joint training experiment (shown in Figure 5).
Related Work
We brieﬂy discuss previous work related to various facets of our proposed method. Cross-lingual EL. The TAC-KBP shared task on entity linking has featured Chinese/Spanish to English EL since 2011 (Ji, Grishman, and Dang 2011; Ji, Nothman, and Hachey 2014; Ji et al. 2017). Around the same time, McNamee et al. (2011) introduced cross-lingual EL as a new task and designed a candidate retrieval technique based on Wikipedia language-links. More recently, Tsai and Roth (2016) used word embeddings for EL in 12 languages, Pan et al. (2017) use word-for-word translation for in a massive multilingual effort for EL in 282 language pairs and Tsai and Roth (2018) develop better name translation for improving the performance of existing translation-based EL techniques. The neural model proposed by Sil et al. (2017) based on multilingual word embeddings and Wikipedia links achieves state-of-the-art results on the TAC2015 dataset.
Cross-lingual transfer learning. Zeman and Resnik (2008) perform transfer to adapt parsers to low-resource languages and Hwa et al. (2005) project parsers from English to other languages that have no

syntactic annotation, using parallel texts. Neural models for transfer from high-resource to low-resource are used for several tasks including POS tagging, machine translation, and morphological analysis (Zoph et al. 2016; Fang and Cohn 2017; Cotterell and Heigold 2017). Unlike our work, these methods jointly train with a small amount of data in the low-resource language.
Phonological representation. IPA representations of language have been used to identify borrowed words across unrelated languages (Tsvetkov, Ammar, and Dyer 2015; Tsvetkov and Dyer 2016). Perhaps most similar to our work is Bharadwaj et al. (2016), which uses IPA in transferring learned models for named entity recognition to low-resource languages.
Conclusion
We present PBEL, a method for cross-lingual entity linking that uses zero parallel resources in the language of the input mention. With extensive experiments on nine test languages, we demonstrate its potential for low-resource entity linking across several language families. Our model uses zero-shot transfer from closely-related high-resource languages and improves accuracy by 17% on average over baseline systems. We also show its ability to transfer across orthographies through phonological representations.
An immediate future focus for our work could be training a model that predicts the ‘best’ pivot language for a given named entity mention, which can replace the languagespeciﬁc phylogenetic-distance-based weights used in this work. Further, we currently train individual encoders for each language. Universal multilingual encoders have had success in tasks like translation (Johnson et al. 2016; Ha, Niehues, and Waibel 2016) and can potentially ease the scaling up of our model to a large number of languages.
Acknowledgements
This work is sponsored by Defense Advanced Research Projects Agency Information Innovation Ofﬁce (I2O), Program: Low Resource Languages for Emergent Incidents (LORELEI), issued by DARPA/I2O under Contract No. HR0011-15-C-0114. Shruti Rijhwani is supported by a Bloomberg Data Science Ph.D. Fellowship. The authors would also like to thank Abhilasha Ravichander, Aditi Chaudhary, Xinyi Wang, Danish, Deepak Gopinath, Gayatri Bhat, Maria Ryskina, Paul Michel, Shivani Poddar, and Siddharth Dalmia for their reviews while drafting this paper.
References
[Auer et al. 2007] Auer, S.; Bizer, C.; Kobilarov, G.; Lehmann, J.; Cyganiak, R.; and Ives, Z. 2007. Dbpedia: A nucleus for a web of open data. In Proceedings of the 6th International The Semantic Web and 2nd Conference on Asian Semantic Web.
[Banti 1988] Banti, G. 1988. Two cushitic systems: Somali and oromo nouns. Autosegmental studies on pitch accent 11–50.

[Bharadwaj et al. 2016] Bharadwaj, A.; Mortensen, D.; Dyer, C.; and Carbonell, J. 2016. Phonologically aware neural model for named entity recognition in low resource transfer settings. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, 1462–1472. Austin, Texas: Association for Computational Linguistics.
[Collobert et al. 2011] Collobert, R.; Weston, J.; Bottou, L.; Karlen, M.; Kavukcuoglu, K.; and Kuksa, P. 2011. Natural language processing (almost) from scratch. Journal of Machine Learning Research 12(Aug):2493–2537.
[Cotterell and Heigold 2017] Cotterell, R., and Heigold, G. 2017. Cross-lingual character-level neural morphological tagging. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, 748–759. Copenhagen, Denmark: Association for Computational Linguistics.
[Dyer, Chahuneau, and Smith 2013] Dyer, C.; Chahuneau, V.; and Smith, N. A. 2013. A simple, fast, and effective reparameterization of ibm model 2. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 644–648. Atlanta, Georgia: Association for Computational Linguistics.
[Fang and Cohn 2017] Fang, M., and Cohn, T. 2017. Model transfer for tagging low-resource languages using a bilingual dictionary. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers).
[Ha, Niehues, and Waibel 2016] Ha, T.; Niehues, J.; and Waibel, A. H. 2016. Toward multilingual neural machine translation with universal encoder and decoder. CoRR abs/1611.04798.
[Hachey et al. 2013] Hachey, B.; Radford, W.; Nothman, J.; Honnibal, M.; and Curran, J. R. 2013. Evaluating entity linking with wikipedia. Artif. Intell. 194:130–150.
[Hammarstro¨m et al. 2018] Hammarstro¨m, H.; Bank, S.; Forkel, R.; and Haspelmath, M. 2018. Glottolog 3.2. Max Planck Institute for the Science of Human History.
[Han and Sun 2012] Han, X., and Sun, L. 2012. An entitytopic model for entity linking. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, 105–115. Jeju Island, Korea: Association for Computational Linguistics.
[Hwa et al. 2005] Hwa, R.; Resnik, P.; Weinberg, A.; Cabezas, C.; and Kolak, O. 2005. Bootstrapping parsers via syntactic projection across parallel texts. Natural language engineering.
[Ji and Grishman 2011] Ji, H., and Grishman, R. 2011. Knowledge base population: Successful approaches and challenges. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics.
[Ji et al. 2017] Ji, H.; Pan, X.; Zhang, B.; Nothman, J.; May-

ﬁeld, J.; and McNamee, P. 2017. Overview of tac-kbp2017 13 languages entity discovery and linking. In Text Analysis Conference 2017.
[Ji, Grishman, and Dang 2011] Ji, H.; Grishman, R.; and Dang, T. 2011. Overview of the tac2011 knowledge base population track. In Text Analysis Conference 2011.
[Ji, Nothman, and Hachey 2014] Ji, H.; Nothman, J.; and Hachey, B. 2014. Overview of tac-kbp2014 entity discovery and linking tasks. In Text Analysis Conference 2014.
[Johnson et al. 2016] Johnson, M.; Schuster, M.; Le, Q. V.; Krikun, M.; Wu, Y.; Chen, Z.; Thorat, N.; Vie´gas, F. B.; Wattenberg, M.; Corrado, G.; Hughes, M.; and Dean, J. 2016. Google’s multilingual neural machine translation system: Enabling zero-shot translation. CoRR abs/1611.04558.
[Lample et al. 2016] Lample, G.; Ballesteros, M.; Subramanian, S.; Kawakami, K.; and Dyer, C. 2016. Neural architectures for named entity recognition. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 260–270. Association for Computational Linguistics.
[Littell et al. 2017] Littell, P.; Mortensen, D. R.; Lin, K.; Kairis, K.; Turner, C.; and Levin, L. 2017. Uriel and lang2vec: Representing languages as typological, geographical, and phylogenetic vectors. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, volume 2, 8–14.
[Luong and Manning 2016] Luong, M.-T., and Manning, C. D. 2016. Achieving open vocabulary neural machine translation with hybrid word-character models. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics.
[McNamee et al. 2011] McNamee, P.; Mayﬁeld, J.; Lawrie, D.; Oard, D.; and Doermann, D. 2011. Cross-language entity linking. In Proceedings of 5th International Joint Conference on Natural Language Processing, 255–263. Chiang Mai, Thailand: Asian Federation of Natural Language Processing.
[Mihalcea and Csomai 2007] Mihalcea, R., and Csomai, A. 2007. Wikify!: Linking documents to encyclopedic knowledge. In Proceedings of the Sixteenth ACM Conference on Conference on Information and Knowledge Management, CIKM ’07.
[Mitra and Craswell 2017] Mitra, B., and Craswell, N. 2017. Neural models for information retrieval. arXiv preprint arXiv:1705.01509.
[Mortensen et al. 2016] Mortensen, D. R.; Littell, P.; Bharadwaj, A.; Goyal, K.; Dyer, C.; and Levin, L. 2016. Panphon: A resource for mapping ipa segments to articulatory feature vectors. In Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, 3475–3484. The COLING 2016 Organizing Committee.
[Mortensen, Dalmia, and Littell 2018] Mortensen, D. R.; Dalmia, S.; and Littell, P. 2018. Epitran: Precision g2p for

many languages. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018).
[Navigli and Ponzetto 2012] Navigli, R., and Ponzetto, S. P. 2012. BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network. Artiﬁcial Intelligence 193:217–250.
[Neubig et al. 2017] Neubig, G.; Dyer, C.; Goldberg, Y.; Matthews, A.; Ammar, W.; Anastasopoulos, A.; Ballesteros, M.; Chiang, D.; Clothiaux, D.; Cohn, T.; Duh, K.; Faruqui, M.; Gan, C.; Garrette, D.; Ji, Y.; Kong, L.; Kuncoro, A.; Kumar, G.; Malaviya, C.; Michel, P.; Oda, Y.; Richardson, M.; Saphra, N.; Swayamdipta, S.; and Yin, P. 2017. Dynet: The dynamic neural network toolkit. arXiv preprint arXiv:1701.03980.
[Pan et al. 2017] Pan, X.; Zhang, B.; May, J.; Nothman, J.; Knight, K.; and Ji, H. 2017. Cross-lingual name tagging and linking for 282 languages. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers).
[Rama and Kolachina 2013] Rama, T., and Kolachina, S. 2013. Distance-based phylogenetic inference algorithms in the subgrouping of dravidian languages. Approaches to Measuring Linguistic Differences.
[Sil et al. 2017] Sil, A.; Kundu, G.; Florian, R.; and Hamza, W. 2017. Neural cross-lingual entity linking. AAAI.
[Sorg and Cimiano 2008] Sorg, P., and Cimiano, P. 2008. Enriching the crosslingual link structure of wikipedia-a classiﬁcation-based approach. In Proceedings of the AAAI 2008 workshop on wikipedia and artiﬁcal intelligence.
[Tsai and Roth 2016] Tsai, C.-T., and Roth, D. 2016. Crosslingual wikiﬁcation using multilingual embeddings. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 589–598. San Diego, California: Association for Computational Linguistics.
[Tsai and Roth 2018] Tsai, C.-T., and Roth, D. 2018. Learning better name translation for cross-lingual wikiﬁcation. In AAAI.
[Tsvetkov, Ammar, and Dyer 2015] Tsvetkov, Y.; Ammar, W.; and Dyer, C. 2015. Constraint-based models of lexical borrowing. In Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.
[Tsvetkov and Dyer 2016] Tsvetkov, Y., and Dyer, C. 2016. Cross-lingual bridges with models of lexical borrowing. J. Artif. Intell. Res. 55:63–93.
[Wang et al. 2012] Wang, Z.; Li, J.; Wang, Z.; and Tang, J. 2012. Cross-lingual knowledge linking across wiki knowledge bases. In Proceedings of the 21st international conference on World Wide Web, 459–468. ACM.
[Wang, Wu, and Tsai 2014] Wang, Y.-C.; Wu, C.-K.; and Tsai, R. T.-H. 2014. Cross-language and cross-encyclopedia article linking using mixed-language topic model and hypernym translation. In Proceedings of the 52nd Annual Meeting

of the Association for Computational Linguistics (Volume 2: Short Papers).
[Zeman and Resnik 2008] Zeman, D., and Resnik, P. 2008. Cross-language parser adaptation between related languages. In IJCNLP-08 Workshop on NLP for Less Privileged Languages.
[Zoph et al. 2016] Zoph, B.; Yuret, D.; May, J.; and Knight, K. 2016. Transfer learning for low-resource neural machine translation. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing.

