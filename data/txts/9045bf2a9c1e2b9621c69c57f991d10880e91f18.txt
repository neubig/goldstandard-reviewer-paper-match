arXiv:2107.11886v1 [cs.CC] 25 Jul 2021

Logspace Reducibility From Secret Leakage Planted Clique
Jay Mardia∗
July 27, 2021
Abstract
The planted clique problem is well-studied in the context of observing, explaining, and predicting interesting computational phenomena associated with statistical problems. When equating computational eﬃciency with the existence of polynomial time algorithms, the computational hardness of (some variant of) the planted clique problem can be used to infer the computational hardness of a host of other statistical problems.
Is this ability to transfer computational hardness from (some variant of ) the planted clique problem to other statistical problems robust to changing our notion of computational eﬃciency to space eﬃciency? We answer this question aﬃrmatively for three diﬀerent statistical problems, namely Sparse PCA [BR13a], submatrix detection [MW15], and testing almost k-wise independence [AAK+07]. The key challenge is that space eﬃcient randomized reductions need to repeatedly access the randomness they use. Known reductions to these problems are all randomized and need polynomially many random bits to implement. Since we can not store polynomially many random bits in memory, it is unclear how to implement these existing reductions space eﬃciently. There are two ideas involved in circumventing this issue and implementing known reductions to these problems space eﬃciently. 1. When solving statistical problems, we can use parts of the input itself as randomness. This idea was pioneered by [GW02] in the context of derandomizing ‘typically correct’ algorithms. Our observation is that this is useful even if we do not care about derandomization, and instead care about repeatedly accessing randomness that can not be stored in working memory. 2. Secret leakage variants of the planted clique problem with appropriate secret leakage can be more useful than the standard planted clique problem when we want to use parts of the input as randomness. The idea that secret leakage is helpful in the context of polynomial time reducibility to statistical problems was introduced by [BB20]. They demonstrated the polynomial time hardness of a wide variety of statistical problems by assuming polynomial time hardness of secret leakage variants of the planted clique problem. Our observation is that leakage is useful even for the seemingly unrelated task of ﬁnding randomness in the input.
1 Introduction
Over the past century, the ﬁeld of statistics has developed a rich theory to explain the ease or diﬃculty of various inference problems. In parallel, computational complexity theorists have also developed a diﬀerent rich theory to explain the ease or diﬃculty of various computational problems. It has long been observed [Val84, DGR00, Ser99] that these notions governing statistical and computational tractability of a problem do not always coincide. In recent decades this misalignment between the two notions of tractability (called a statistical-computational gap) has emerged as a widespread conjectural phenomenon in high-dimensional statistics and learning theory. Even well-studied problems where no such gap exists might display such a gap with minor tweaks. For example, this happens when the statistician is simply given additional information that they are unable to eﬃciently exploit [BR13a,
∗Department of Electrical Engineering, Stanford University. jmardia@stanford.edu
1

BR13b, WBS16], or is required to handle small amounts of data contamination [Li17, Robust sparse mean estimation]. Hence, there has been much interest and success in developing tools to understand and predict the occurrence of such gaps. The introduction of [BB20] has an excellent survey on the current landscape of statistical-computational phenomena.
Most research on the computational complexity of statistical inference has used the existence of polynomial time algorithms as a benchmark for computational tractability. This is an excellent model for computational eﬃciency whose use in the statistical context has been validated by it enabling the discovery and study of statistical-computational gaps. That being said, traditional complexity theory has identiﬁed a host of resources such as memory, communication, and randomness that capture the eﬀect of some fundamental resource other than time. Studying the complexity theories of these resources is not only interesting in their own right, but has produced insights in seemingly unrelated areas. For example, space complexity (one way of formalizing limited memory) turns out to have fundamental connections to the complexity of 2-player games [AB09, The essence of PSPACE] as well as that of interactive proofs [Sha92]. Communication complexity turns out to be very useful in studying streaming complexity (another way of formalizing limited memory).
Even in the context of statistical problems, studying alternate notions of resource has proved fruitful. Evidence for the computational hardness of several problems has been built up by showing that various restricted algorithmic classes can not solve these problems (see Section 3 for details). While these classes all correspond to some non-standard notion of resource, to the best of our knowledge, they are usually viewed as proxies for the class of “polynomial time algorithms”. That is, these results are usually used to draw heuristic conclusions about the entire class of polynomial time algorithms. One way to interpret this state of aﬀairs is that in the context of statistical problems, studying alternate notions of complexity is not merely interesting; it is also a promising avenue towards results that are actually within reach of our current mathematical technology.
The preceding discussion recommends, in the statistical context, an explicit study of resource-driven notions of eﬃcient computation other than “polynomial time”1. A natural question that arises is-
Are the conjectured statistical-computational phenomena we know robust to changes in our notion of computational eﬃciency?
While this is a very broad question, in this work we will be concerned with one speciﬁc alternate notion of eﬃciency (space eﬃciency) and the statistical-computational phenomena centered around the planted clique problem2. Space is one of the most well-studied computational resources other than time while the planted clique problem has emerged as a testbed for the study of statisticalcomputational gaps. When equating computational eﬃciency with the existence of polynomial time algorithms, this problem displays the following interesting statistical-computational phenomena. 1. There is a conjectured threshold phenomenon at signal strength k = Θ(√n), irrespective of whether the problem is formalized using its detection or recovery variant. 2. The computational hardness of (some variant of) the planted clique problem below the Θ(√n) signal strength threshold can be used to infer the computational hardness of a host of other statistical problems. Recently, [Mar20] provided some evidence that the planted clique threshold phenomena at k = Θ(√n) also occurs at the same threshold when we use space eﬃciency as our notion of computational eﬃciency.
1In this spirit, [MMS20] studied connections between small depth circuit classes and phase transitions in the broadcast tree model and [RWYZ21] studied the communication complexity of statistical problems.
2This problem concerns an n-vertex graph with a statistical signal whose strength is denoted by an integer 1 ≤ k ≤ n.
2

In this work, we investigate whether the ability to transfer computational hardness from (some variant of ) the planted clique problem to other statistical problems is also robust to changing our notion of computational eﬃciency to space eﬃciency.
The conjectured non-existence√of polynomial time algorithms3 for the planted clique problem and its variants below the k = Θ( n) signal strength threshold has been used to show non-existence of polynomial time algorithms for various other statistical problems. Our goal is to replace the phrase ‘polynomial time algorithms’ in the sentence above with ‘randomized logspace algorithms’, which is the correct notion of space eﬃcent algorithms. Section 2.1 provides details about this class of algorithms, but for now we just need to recall that any randomized logspace algorithm is also a polynomial time algorithm. As a result, this work will not provide any new hardness beliefs. That is, we already believe these other statistical problems do not have polynomial time algorithms, so we also already believe they do not have randomized logspace algorithms. Our motivation is, instead, the following.
1. As discussed, our main motivation is to examine the robustness of statistical-computational phenomena (particularly, the ability to transfer hardness from one statistical problem to another) to changing our notion of computational eﬃciency from time bounded to space bounded.
2. The most natural route towards proving unconditional computational hardness results against the class of polynomial time algorithms is by showing hardness against larger and larger restricted classes of algorithms. It is plausible that technology showing unconditional impossibility results for the planted clique problem and its variants for randomized logspace algorithms will appear long before corresponding technology for the entire class of polynomial time algorithms. In such a scenario, our results will imply unconditional randomized logspace hardness for various other statistical problems while existing randomized polynomial time reductions would not.
3. In worst-case complexity, many complexity classes are known to have natural complete problems that are complete under reductions far more eﬃcient than “polynomial time” [Imm12, ABI97]. For example, NP has many natural complete problems under “ﬁrst-order projections” (fops), a type of reduction even more restrictive than logspace computation [Dah83, MI94]. Similarly L, NL, and P also have problems complete under fops reductions [Imm12, Chapter 3], and PSPACE has problems complete under logspace reductions [AS03].
The planted clique problem, with its variants, is emerging as a useful central problem for the complexity of statistical problems, analogous to central problems in worst-case complexity. Showing that it shares other characteristics of important problems in worst-case complexity, such as reducibility using reductions much more eﬃcient than polynomial time, would strengthen this correspondence.
4. In the quest to show polynomial time hardness of more and more statistical problems, [BB20] made the nice discovery that assuming hardness of various secret leakage variants of the planted clique problem allows reducibility to a wider array of problems. Unfortunately, it is not known if the planted clique problem or any of its variants is complete for any reasonable complexity class of statistical problems. This makes it non-trivial to choose a single central problem from amongst the many planted clique variants on which to base a clean theory of reducibility for statistical problems. The results in [BB20] suggest a trade-oﬀ between the utility of the variant and the conservativeness of the hardness assumption. Variants that are reducible to more problems also have more structure that an algorithm might exploit to solve it.
In this work we too end up needing secret leakage variants of the planted clique problem to
3We do not discuss the exact model of polynomial time algorithms used by previous works. However, a crucial aspect is that the model allows the use of randomness.
3

achieve our desired randomized logspace reductions. In light of the worst-case reducibility with very eﬃcient reductions, this suggests a heuristic principle to help choose a central planted clique variant. “Choose a variant from which reductions can be implemented in randomized logspace”.

2 Our Results and Techniques

Our results suggest that the ability to transfer computational hardness from (some variant of)4 the planted clique problem to other statistical problems is indeed robust to changing our notion of computational eﬃciency to space eﬃciency. Informally, these results are as follows.

The non-existence of randomized logspace algorithms solving (some variant of) the planted clique
problem implies the non-existence of randomized logspace algorithms solving Sparse PCA hypothesis testing [BR13a], submatrix detection [MW15], and testing almost k-wise independence [AAK+07].

We spend the rest of Section 2 explaining the statement above5. The planted clique detection problem

PCD(n; k) (Deﬁnition 4.7) is a hypothesis testing problem where the input is either an Erd˝os-R´enyi

graph G(n; 1=2) (a uniformly random n-vertex graph) or a planted clique graph G(n; 1=2; k) (G(n; 1=2)

with

an

additional

clique

on

a

uniformly

random

k -vertex

subset).

We

focus

on

k

=

O

(n

1 2

−

‹

)

for

any

constant ‹ > 0, where eﬃcient algorithms for the planted clique problem are believed not to exist.

Let P denote any hypothesis testing problem (Deﬁnition 4.3) such that there exist distributions P0 and P1 on poly(n) sized bit strings with the following properties.
1. There is a polynomial time algorithm using poly(n) independent uniform random bits that maps a sample drawn according to G(n; 1=2) (respectively G(n; 1=2; k)) to a sample drawn according to P0 (respectively P1).
2. P0 (respectively P1) is close in total variation distance to some distribution in the null (respectively alternate) hypothesis of P.
[BR13a], [MW15], and [AAK+07] respectively showed that the hypothesis testing problems Sparse PCA, submatrix detection, and testing almost k-wise independence all satisfy such conditions. The non-existence of polynomial time algorithms solving the planted clique problem then immediately implies the non-existence of polynomial time algorithms solving such a hypothesis testing problem P.

2.1 An obstacle to space eﬃcient randomized reductions: access to randomness
The class of logarithmic space bounded computation is widely agreed to be the benchmark of ‘space efﬁcient’ computation. A deterministic or randomized logspace algorithm6 (see [AB09] or Deﬁnition 4.1) has read-only multiple access to an poly(n)-bit input, along with read-and-write multiple access to a working tape consisting of O(log n) bits. Its output must be written on a write-only tape and the algorithm must terminate within poly(n) time7. Further, if the algorithm is randomized, it is allowed access to a read-once bit string of independent uniform random bits of size poly(n).
4Some of our results will use variants that have not been studied before. We provide evidence for the hardness of these variants in Section 2.7.
5We do not describe these other statistical problems here, since their details are not needed for our current discussion. We refer the reader to Section 7 for formal deﬁnitions or, in the case of Sparse PCA, a further pointer to the formal deﬁnition in [BR13a].
6Our algorithms are deﬁned using any ﬁxed reasonable Random-Access Turing Machine model. 7The section on BPHSP ACE in [Sak96] and the section on Finite Automata and Counting in [Wig19] discuss why a reasonable model for randomized space bounded computation should also have an associated time bound.

4

One aspect of randomized logspace algorithms worth keeping in mind (because it is the central nuisance we deal with in this work) is that the algorithm can access its random bits only in a read-once fashion. That is, if the algorithm wants to look at a random bit it has already used, it must have stored that bit for the future using its O(log n) bits of working space. See [Nis93] for why this is the appropriate deﬁnition of randomized logspace algorithms.
That being said, it will be convenient to talk about “multiple access randomized logspace algorithms” (Deﬁnition 4.2). These are randomized logspace algorithms given the extra ability to access not only their input and work tapes, but also polynomially many auxiliary random bits as many times as desired without having to explicitly store them in memory. Of course, while this is a useful deﬁnition, this class of algorithms does not correspond to eﬃcient space bounded computation [Nis93], since it lets us store polynomially many random bits ‘for free’.
The reductions in [BR13a, MW15, AAK+07] as well as the transference of computational hardness from the planted clique problem are still valid if we replace ‘polynomial time algorithms’ with ‘multiple access randomized logspace algorithms’ in the discussion above. This follows by examining the reductions implemented by these works and verifying that all the steps can be performed space eﬃciently when given multiple access randomness8. For completeness, we provide the straightforward formal proofs of these facts in Section 7.
Unfortunately, such a reduction does not let us transfer randomized logspace hardness from the planted clique problem (or its variants) to other statistical problems. The existence of a randomized logspace algorithm that solves the various other statistical problems would only imply the existence of a multiple access randomized logspace algorithm that solves some variant of the planted clique problem. This would not contradict the conjectured non-existence of a randomized logspace algorithm solving some variant of the planted clique problem9.
The reason we need to resort to multiple access randomized logspace reductions when trying to implement a randomized reduction space eﬃciently is as follows. A sample drawn from the distribution we are reducing to (P0 or P1) has size poly(n), so unlike polynomial time algorithms, a logspace algorithm of any variety can not compute and simultaneously store every bit of this sample in its memory. What is feasible, however, is that any individual bit of such a sample can be computed space eﬃciently given the planted clique input and randomness. A space eﬃcient algorithm A that solves the hypothesis testing problem P can be used to space eﬃciently solve the planted clique problem by recomputing bits of the sample we have reduced to whenever the algorithm A needs them. As a logspace algorithm, A can inspect any bit of its input sample many times. The reduction from the planted clique problem thus needs to be able to recompute its output bits multiple times. This is not possible if the randomness it uses is only accessible once.
The discussion above constitutes a barrier towards implementing randomized reductions space eﬃciently. In fact, such a barrier has been encountered even in worst-case complexity, necessitating the use of multiple access randomized logspace reductions [CNS96, VM98]. [VM98] even states it as an open problem to implement such reductions in the more natural read-once model of randomized
8The only additional primitive we need is the ability to approximately implement a uniformly random permutation using a multiple access randomized logspace algorithm. This is not hard, and we provide an algorithm in Lemma 8.1.
9If we assume that no multiple access randomized logspace algorithm (or the even stronger non-uniform model of computation concerning polynomial sized branching programs) can solve the planted clique problem or its variants, we would, of course, be done. This strong assumption (just like the strong assumption about non-existence of polynomial time algorithms) would imply the randomized logspace hardness of our other statistical problems of interest. However, our aim in this work, as motivated in Section 1, is to show that such a result also follows from the much weaker assumption concerning only eﬃcient space bounded computation. We want to show that randomized logspace hardness can indeed be transferred from the planted clique problem or its variants to other statistical problems.
5

logspace algorithms.

2.2 Harvesting multiple access randomness from the input: hardness of Sparse PCA for a restricted range of parameters

The ﬁrst of the two themes in this work is the following.

There is an algorithmic technique available in the context of statistical problems (but not for worst-case problems) which might enable space eﬃcient randomized reductions using randomized logspace algorithms that do not have their own supply of auxiliary multiple access randomness. We can harvest multiple access randomness from the input itself.

[GW02] pioneered the idea that randomized algorithms which are “typically correct” can be derandomized by harvesting randomness from the input itself. This idea has often been used for various kinds of derandomization tasks (see the surveys [Sha10, HW12] or the related work section in [Hoz17]). Our observation is that harvesting randomness from average case / statistical inputs has a use beyond derandomization. Namely, to simulate multiple access to randomness in situations where we otherwise only have read-once randomness.

We show that when solving statistical problems with nice structure such as the planted clique problem and its variants, one can simulate a multiple access randomized logspace algorithm using a randomized logspace algorithm. The non-existence of the latter then implies the non-existence of the former, which, as discussed earlier, implies the non-existence of randomized logspace algorithms for other statistical problems such as Sparse PCA, submatrix detection, and testing almost k-wise independence.

(Lemma 5.2, Informal) If no randomized logspace algorithm can solve the planted c`liq´ue

`probl´em PCD(n; k), no multiple access randomized logspace algorithm using at most

n 2

−

n−m 2

= o(n2=k) multiple access random bits can solve PCD(n − m; k) for ‘nice enough’10

values of m = o(n=k).

We sketch the the proof of Lemma 5.2. Given an instance of the planted clique detection problem

PCD(n; k), we can harvest Θ(n · m) independent mu`lti´ple `acces´s random bits to use as long as m =

o(n=k). To do this, use the edge indicators for the

n 2

−

n−m 2

= Θ(n · m) possible edges involving

at least one of the last m vertices as multiple access randomness. Then view the subgraph induced

on the ﬁrst n − m vertices as an instance of PCD(n − m; k). With high probability there will be no

planted clique vertex in the last m = o(n=k) vertices, so both our ‘multiple access randomness’ and our

‘planted clique instance’ on the ﬁrst n − m vertices will behave as desired. The claims of Lemma 5.2

then follow from a simple contradiction argument. See Figure 1 for a pictorial representation.

Use as problem instance Use as randomness

Figure 1: Adjacency matrix of the input graph above the diagonal as used in Lemma 5.2.
One drawback of the scheme from Lemma 5.2 is that it can only rule out multiple access randomized logspace algorithms solving PCD(n − m; k) if they use o(n2=k) independent multiple access random
10This niceness involves a very mild technical assumption.
6

bits. In principle, however, a multiple access randomized logspace algorithm solving PCD(n − m; k) can use any arbitrarily large poly(n) number of independent multiple access random bits. The Sparse PCA problem [BR13a] has an input consisting of n¯ vectors in d¯ dimensions. The reduction in Lemma 7.1 shows that when d¯ is not much larger than n¯, a randomized logspace algorithm solving Sparse PCA implies a multiple access randomized logspace algorithm solving PCD(n − m; k) whose multiple access randomness usage contradicts the logspace planted clique conjecture by Lemma 5.2. For this reasonable but restricted parameter range, this lets us deduce non-existence of randomized logspace algorithms solving Sparse PCA from the conjectured non-existence of randomized logspace algorithms for the planted clique problem (Conjecture 5.1). See Theorem 1 in Section 7.1 for a formal statement and details about the parameters involved. The remaining challenge: Reductions to Sparse PCA for more general values of d¯, to submatrix detection, and to testing almost k-wise independence can not be carried out with the amount of multiple access randomness provided by Lemma 5.2. For example, when reducing from PCD(n − m; k) to submatrix detection, we need Θe (n2) multiple access random bits [MW15]. We need some further ideas to make progress.
2.3 Self-reducibility and k-partite planted clique: hardness of submatrix detection for a restricted range of parameters
In Section 2.2 we saw that within a planted clique instance we can ﬁnd two things; another slightly smaller planted clique instance as well as independent random bits that are disjoint from this smaller instance. These multiple access random bits can be used to simulate a multiple access randomized logspace algorithm that is run on the smaller planted clique instance. Unfortunately, the number of multiple access random bits we get from this scheme is not as large as we might want.
Our next observation is that to reduce to other statistical problems, we do not care solely about the number of multiple access random bits we can harvest from the original planted clique instance. Instead, we care about this number in comparison to the size of the smaller planted clique instance, since this smaller instance is what we reduce from. We can thus make progress not just by harvesting more multiple access randomness from the input, but also by locating a smaller instance of the planted clique problem in the input!
The planted clique problem almost has a useful ‘self-reducibility’ property. Given an instance of PCD(n; k), the subgraph induced on the ﬁrst ns vertices is morally like an instance of PCD(ns ; k ·(ns =n)). We can use the same randomness harvesting technique from Section 2.2 to get multiple access to slightly less than n2=k random bits. See Figure 2 for a pictorial representation.
Use as problem instance Use as randomness
Figure 2: Adjacency matrix of the input graph above the diagonal as used in Lemma 5.6.
Unfortunately, the subgraph induced on the ﬁrst ns vertices is not actually an instance of PCD(ns ; k · (ns =n)). This is because the size of the planted clique in this subgraph is a binomial random variable with mean k · (ns=n). With probability tending to 1, this size will in fact not be k · (ns=n). However,
7

several close variants of the planted clique problem do have an exact self-reducibility property. One such variant is where every vertex of the graph is included in the planted clique independently with probability k=n. It is easy to see that the subgraph induced on any subset of vertices of such a graph will also exactly be distributed like such a graph ensemble with a diﬀerent signal strength11.

Another variant called the k-partite planted clique problem kPCD(‘ · k; k) (Deﬁnition 5.4) studied in [BB20] also has such an exact self-reducibility property. In this variant, the number of vertices in the
graph is an integer multiple of the number of the planted clique vertices. This is why we prefer to parametrize the problem as kPCD(‘ · k; k), denoting a graph with ‘ · k vertices and a planted clique of size k. The diﬀerence between this formulation and the vanilla planted clique problem PCD(‘ · k; k) is that in the planted graph, every set of ‘ vertices of the form {(i − 1) · ‘ + 1; :::; i · ‘} (for i ∈ {1; 2; :::; k})
has exactly one planted clique vertex, which is distributed uniformly over this set. Given an instance of kPCD(‘·k; k), the subgraph induced on the ﬁrst ‘·ks vertices is exactly an instance of kPCD(‘·ks ; ks ).

This problem kPCD(‘ · k; k) is similar enough to the planted clique problem that it is still believed to be unsolvable by polynomial time (and hence randomized logspace) algorithms when k = O(‘1−‹) for some constant ‹ > 0. [BB20] provide evidence for this belief through impossibility results for low degree algorithms. This means the scheme depicted in Figure 2 can be implemented for the k-partite planted clique problem.

(Lemma 5.6, Informal) If no randomized logspace algorithm can solve the k-partite planted

clique`pro´blem` kPC´D(‘ · k; k), no multiple access randomized logspace algorithm using at

most

‘·k 2

−

‘·k−m 2

= o(‘2 · k) multiple access random bits can solve kPCD(‘ · ks ; ks ) for

‘nice enough’ values of m = o(‘) and ks ≤ k − 1.

The [MW15] reduction from a k-partite planted clique instance on ‘·ks vertices to submatrix detection requires Θe ((‘ · ks )2) multiple access random bits (Lemma 7.4). Hence, the existence of a randomized logspace algorithm solving submatrix detection yields a multiple access randomized logspace solving kPCD(‘ · ks ; ks ) with Θe ((‘ · ks )2) multiple access random bits. This only contradicts Lemma 5.6 if ks is small en√ough. Even if we take k in Lemma 5.6 as only slightly smaller than ‘, we need ks to be smaller than o( ‘) for a contradiction to occur. As a result, we can only use this idea to infer randomized
logspace hardness of the submatrix detection problem for a restricted set of parameters. Those which
can be reduced to from k-partite planted clique instances with signal strength ks much much smaller than the threshold at which we believe the problem becomes infeasible.

Luckily, this still allows us to show randomized logspace hardness for a non-trivial parameter range of
submatrix detection problems from the randomized logspace hardness of the k-partite planted clique kPCD(‘ · k; k) problem when k = O(‘1−‹) (Conjecture 5.5). See Theorem 3 for a formal statement and discussion about the parameter ranges involved.

The remaining challenge: The restriction on ks described above means we can not show randomized logspace hardness of the submatrix detection problem for all settings of parameters in which we believe the problem to be hard. To do that, we need to reduce from a k-partite pla√nted clique instance kPCD(‘ · ks ; ks ) with ks only slightly smaller than ‘, rather than smaller than o( ‘).

2.4 Trying to get more multiple access randomness from the k-partite planted clique problem
A natural attempt to circumvent the restrictions of Lemma 5.6 is as follows.
11The self-reducibility property of this variant was crucially used in [MAC20] to study the sublinear time complexity of the planted clique problem.

8

Consider a k-partite planted clique problem instance kPCD(‘ · 2k; 2k) with k = O(‘1−‹). We do not

believe any randomized logspace algorithm can solve this problem (Conjecture 5.5). For some ks ≤ k,

we could again view the subgraph on the ﬁrst ‘ · ks vertices of the input as kPCD(‘ · ks ; ks ). Unlike

the scheme in Lemma 5.6 and Figure 2, we might hope that we can use the edge indicators of the

subgraph induced on the last ‘ · k vertices as a source of multiple access randomness. The intuition for

this is that even though these edge indicators are not independent random bits, eﬃcient algorithms

should not be able to distinguish them from independent random bits. This is, after a`ll, w´ hat k-partite

planted clique hardness entails. The advantage now is that we can use as many as

‘·k 2

(rather than

o(‘2 · k)) multiple access random bits to reduce to other statistical problems from the smaller k-partite

planted clique instance kPCD(‘ · ks ; ks ). This could potentially allow us to implement the reduction to

submatrix detection with larger ks than in Theorem 3. See Figure 3 for a pictorial representation.

Use as problem instance Use as randomness

Figure 3: Adjacency matrix of the input graph above the diagonal as used in Lemma 5.7.

Showing that this idea works involves a slight subtlety. For our harvested randomness to behave as
desired, we need to show that no randomized logspace algorithm can distinguish between the following. An Erd˝os-R´enyi graph G(‘ · k; 1=2) (which represents what we wish our multiple access randomness was) and a k-partite planted clique graph kG(‘ · k; 1=2; k) (Deﬁnition 5.3) (which represents what
we use as our multiple access randomness) even if the algorithm has multiple access to another independent k-partite planted clique graph kG(‘ · ks ; 1=2; ks ) (which is the problem instance we reduce from). Unfortunately, the only way we know of doing this is by showing that this auxiliary graph can be simulated by Θ((‘ · ks )2) multiple access random bits and using Lemma 5.6. However, we can only invoke Lemma 5.6 if the amount of auxiliary randomness needed, Θ((‘ · ks)2), is appropriately small. This is, after all, the drawback to Lemma 5.6 we are trying to circumvent in the ﬁrst place.

The upshot is that this idea does actually work, but once again with a restriction on ks .

(Lemma 5.7, Informal) If no randomized logspace algorithm can solve the k-partite planted

clique pr`obl´em kPCD(‘ · 2k; 2k), no multiple access randomized logspace algorithm using

at most

‘·k 2

multiple access random bits can solve kPCD(‘ · ks ; ks ) for ‘nice enough’ values

of ks ≤ √k‘ .

We need k = O(‘1−‹) for the conjectured non-existence of randomized logspace algorithms solving kPCD(‘ · 2k; 2k). This implies a restriction on ks once again. We can not infer randomized logspace hardness of other statistical p√roblems that we reduce to from a k-partite planted clique instance kPCD(‘ · ks ; ks ) with ks = Ω( ‘). More ideas are needed to make progress on the reduction to submatrix detection for all relevant parameter ranges.

While the scheme of Lemma 5.7 does not help us in our goal of reducing to submatrix detection, it is a non-trivial improvement on Lemma 5.6 in the regime where ks is small. There could be applications involving hardness of other statistical problems we have not considered where Lemma 5.7 is useful even though Lemma 5.6 is not. Most known reductions between statistical problems are statistical. That is, the reduction maps the input problem to something that is statistically indistinguishable from the output problem. Interestingly, Lemma 5.7 is a reduction that itself has a computational aspect.

9

2.5 Clique leakage k-partite planted clique: hardness of submatrix detection

Examining the utility of k-partite planted clique hardness over planted clique hardness in harvesting multiple access randomness suggests the second theme in this work.

Randomized logspace hardness of more structured variants of the planted clique problem (i.e. where the algorithm solving the problem has more information) allows us to harvest larger amounts of multiple access randomness from the input.

[BB20] pioneered the idea that more structured “secret leakage”12 variants of the planted clique problem seem to allow polynomial time reducibility to a wider array of statistical problems than from the vanilla planted clique problem. This is why they studied the k-partite planted clique problem and its hardness. Our observation is that even the seemingly unrelated task of harvesting larger amounts of multiple access randomness from the input is made easier by assuming hardness of the planted clique problem despite secret leakage.

Our goal, then, is to discover structure or secret leakage that balances two competing requirements. First, the planted clique problem should still be computationally hard despite the secret leakage. Second, the secret leakage should be informative enough to help in randomness harvesting.

We propose the clique leakage k-partite planted clique problem clkPCD(‘ · k; k) (Deﬁnition 5.9). As its name suggests, this is the k-partite planted clique problem with the additional constraint that the ﬁrst vertex is always in the planted clique. The algorithm knows that if the input is a planted instance rather than a null instance, the ﬁrst vertex is in the planted clique. We discuss evidence for the randomized logspace hardness of this problem in Section 2.7. For now, we focus on using this conjectured hardness to show randomized logspace hardness of the submatrix detection problem in full generality.

Consider a clique leakage k-partite planted clique problem clkPCD(‘ · 4k; 4k). Our belief is that no randomized logspace algorithm can solve this problem when k = O(‘1−‹) for some constant ‹ > 0 (Conjecture 5.10). For some ks ≤ k, consider the subgraph on the ﬁrst ‘ · ks vertices and note that it is an instance of clkPCD(‘ · ks ; ks ). Now consider the subgraph induced on the subset of the last 3k vertices which do not have an edge to the ﬁrst vertex. We interpret the edge indicator bits of trhanisdsoemcoiznedd sluobggspraapceh aalsgmoruitlhtimpleonactcheses srmanadlloerminnesstsa.nWceecclkaPnCuDs(e‘t·hkiss ;tkos )sitmhualtatreeqauniyrems uatltimploestac`c‘e2·ks´s multiple access random bits. Because the ﬁrst vertex is guaranteed to be a planted clique vertex if the original large graph is a planted instance, the edge indicator bits we use are always independent random bits. Further, with high probability, the subgraph we use as our source of multiple access randomness will have at least ‘ · k vertices, which means we have access to enough multiple access random bits. See Figure 4 for a pictorial representation of this scheme.

(Lemma 5.11, Informal) If no randomized logspace algorithm can solve the clique leakage

k-partite planted clique pr`ob´lem clkPCD(‘ · 4k; 4k), no multiple access randomized logspace

algorithm using at most

‘·k 2

multiple access random bits can solve clkPCD(‘ · ks ; ks ) for

‘nice enough’ values of ks ≤ k.

This lets us rule out multiple access randomized logspace algorithms for clkPCD(‘ · ks ; ks ), and hence also PCD(‘ · ks ; ks ) (see Lemma 8.2) that use much larger amounts of multiple access randomness than Lemma 5.6, without the restriction on ks needed for Lemma 5.7. This improvement is enough to let us show randomized logspace hardness of the submatrix detection problem for all scalings of parameters

12[BB20] introduced the terminology secret leakage because the more structured variants can all be seen as instances of the planted clique problem with additional side information about the location of the planted clique vertices.

10

Vertices outside ‘problem instance’ that are unconnected to the ﬁrst vertex (drawn reordered)

Use as problem instance Use as randomness

Figure 4: Adjacency matrix of the input graph above the diagonal as used in Lemma 5.11. The vertices outside the ‘problem instance’ have been drawn reordered, so that the vertices unconnected to the ﬁrst vertex of the graph are all at the end.

in which we believe this problem to be hard. See Theorem 4 for a formal statement and proof.
The remaining challenge: Lemma 5.11 does not let us rule out multiple access randomized algorithms that use arbitrarily large polynomial amounts of multiple access randomness from solving the planted clique problem. Consider the reduction to testing almost k-wise independence [AAK+07] and the reduction to Sparse PCA without the restrictions of Theorem 1. These only yield multiple access randomized logspace algorithms solving the planted clique problem that use arbitrarily large polynomial amounts of multiple access randomness. To show randomized logspace hardness of these problems, we introduce even more structure in our hardness assumption.

2.6 Clique leakage hypergraph planted clique: hardness of testing almost k-wise independence and Sparse PCA

[BB20] studied a (k-partite version of a) hypergraph planted clique problem. They showed that its polynomial time hardness implied the polynomial time hardness of all the other secret leakage planted clique problems they used. Further, it allowed them to reduce to a wider array of statistical problems. To provide evidence for the computational hardness of this problem, they showed that low-degree algorithms can not solve it. We show that adding a little more structure to this problem also makes it useful for our randomness harvesting task. Taking inspiration from our previous success with clique leakage, this additional structure too will involve leaking some clique vertex locations to the algorithm.

The hypergraph planted clique problem HPCsD(n; k) (Deﬁnition 6.1) concerns an s-uniform hypergraph on n vertices. Here s ≥ 3 can be any constant positive integer. In the null instance HGs(n; 1=2), every
possible s-uniform hyperedge is included in this hypergraph independently with probability 1=2. The alternate instance HGs(n; 1=2; k), is an instance of HGs(n; 1=2) with an additional s-uniform clique
planted on a uniformly random subset of k vertices.

We propose the clique leakage hypergraph planted clique problem clHPCsD(n; k) (Deﬁnition 5.15), which

is the same problem as above with an additional constraint. In the planted instance of the problem,

the ﬁrst s − 2 (which is a constant) vertices are guaranteed to be in the planted clique. Our belief is

that

no

randomized

logspace

algorithm

can

solve

this

problem

if

k

=

O

(n

1 2

−

‹

)

for

some

constant

‹

>

0

(Conjecture 5.16). We provide evidence for this belief in Section 2.7 and focus on using this belief to

achieve our desired randomness harvesting goals.

Consider an instance of clHPCsD(n + s − 1; k + s − 2). It is easy to observe that the subgraph induced

by this hypergraph on the n vertices {s − 1; s; :::; n + s − 2} is an instance of PCD(n; k). Further,

with high probability, the las`t verte´x in the hypergraph is not in the planted clique. We can use the

hyperedge indicators for all

n+s −2 s −1

possible hyperedges involving this last vertex as multiple access

randomness to solve the aforementioned instance of PCD(n; k). Since s can be any constant we desire,

11

Conjecture
Logspace planted clique conjecture (Conjecture 5.1)
Logspace k-partite planted clique conjecture (Conjecture 5.5)
Clique leakage logspace k-partite planted clique conjecture (Conjecture 5.10)
Clique leakage logspace hypergraph planted clique conjecture (Conjecture 5.16)

Statistical problem Theorem 1: Sparse PCA (re-
stricted parameter range) Theorem 3: Submatrix detection (restricted parameter range) Theorem 4: Submatrix detection
Theorem 5: Testing almost k-wise independence and Theorem 2: Sparse PCA

Table 1: A summary of our results. The conjecture in the ﬁrst column implies the randomized logspace hardness of the statistical problem shown in the second column.

this lets us rule out multiple access randomized logspace algorithms solving the planted clique problem irrespective of the amount of multiple access randomness needed.
(Lemma 5.17, Informal) If no randomized logspace algorithm can solve the clique leakage hypergraph planted clique problem clHPCsD(n + s − 1; k + s − 2) for any constant integer s ≥ 3, no multiple access randomized logspace algorithm can solve PCD(n; k).
We know that randomized logspace algorithms for testing almost k-wise independence (Lemma 7.7) and Sparse PCA (Lemma 7.1) imply a multiple access randomized logspace that solves the planted clique problem. Lemma 5.17 implies that the aforementioned statistical problems can not be solved by a randomized logspace algorithm. See Theorems 5 and 2 for formal statements.
We have now shown that the randomized logspace hardness of Sparse PCA [BR13a], submatrix detection [MW15], and testing almost k-wise independence [AAK+07] follows from the randomized logspace hardness (rather than polynomial time hardness) of the planted clique problem or its variants. Table 1 contains a summary of our results.
2.7 Are the k-partite and hypegraph planted clique problems computationally hard even with clique leakage?
Assuming randomized logspace hardness of the clique leakage k-partite and clique leakage hypergraph versions of the planted clique problem is useful in showing randomized logspace hardness of other statistical problems. But is this hardness assumption true?
First, [BB20] provided evidence (by studying low-degree algorithms) that if there is no clique leakage, the k-partite and hypergraph versions of the planted clique problem are indeed computationally hard13. Clique leakage, which tells the algorithm the location of only a constant number of planted clique vertices, should not make the problem much easier.
We show that a deterministic logspace algorithm solving the recovery14 problem for clique leakage
13Technically, [BB20] studied the hardness of the k-partite version of the hypergraph planted clique problem. However, the hardness of this problem can easily be transferred to the hypergraph planted clique problem with a small amount of multiple access randomness, similar to Lemma 8.2.
14In the recovery task, the input is a (hyper)graph that is guaranteed to have a planted clique. The logspace algorithm must decide, for every vertex, if that vertex is in the planted clique or not. Any reasonable notion of ‘solving’ the recovery task seems to require some form of determinism in the algorithm. Using such an algorithm even to simply verify its correctness (i.e. checking if the vertices it says are in the clique indeed form a clique) requires running it multiple times on the same input and vertex combination. We would want it to output the same answer every time.
12

k-partite or clique leakage hypergraph planted clique implies a deterministic logspace algorithm for

the

detection

version

of

these

problems

with

no

clique

leakage.

Suppose

1
!((log n) s−1 ) = k

=

O

(n

1 2

−

‹

)

for some constants s ≥ 3 and ‹ > 0. If we had a deterministic algorithm to solve clique leakage

hypergraph planted recovery (Deﬁnition 6.3), we could solve hypergraph planted clique detection

HPC

s D

(n

;

k

)

(Deﬁnition

6.1)

as

follows.

Iterate over all vertex sets of size s − 2 (we can do this

in logspace because s is a constant), and run the deterministic clique leakage hypergraph recovery

algorithm in each of these iterations by pretending this vertex set is actually in the planted clique.

Check if the output of this algorithm is indeed a planted clique of size k. If this is true for any of the

iterations of our algorithm, say that the input graph is a planted clique instance. Otherwise, say it is

a null instance.

This algorithm works because of two reasons. First, a null instance (an s-uniform Erd˝os-R´enyi hypergraph HGs (n; 1=2)) does not have a clique of size k with high probability. Second, in the planted instance, at least one of the vertex sets of size s − 2 we run the clique leakage recovery algorithm with will indeed be a part of the planted clique, so the recovery algorithm will output a planted clique of size k in this iteration. A formal proof that this reduction works can be found in Lemma 6.4. A similar reduction also holds for the k-partite planted clique problem and its clique leakage variant (Lemma 6.5).

Combined with the hardness beliefs from [BB20], this implies that the recovery problem for k-partite and hypergraph planted clique is hard despite clique leakage. For the vanilla planted clique problem PCD(n; k), polynomial time algorithms for detection are known if an only if polynomial time algorithms for recovery are known. [Mar20] showed that this tight connection between the complexity of the detection and recovery variants also holds for space complexity (except possibly for a minuscule range of parameters).

It is then reasonable to believe that even for the secret leakage variants of the planted clique problem, space eﬃcient algorithms for detection exist if and only if deterministic space eﬃcient algorithms exist for recovery. It would be an interesting surprise if this were not true for some secret leakage variant of the planted clique problem. If we believe in this tight connection between the recovery and detection problems, we have evidence for the computational hardness of the detection version of the clique leakage k-partite and hypergraph planted clique problems.

2.8 Why didn’t we use pseudorandom generators that fool space bounded computation?
Having sketched the ideas involved in this paper, we brieﬂy discuss an alternate approach to the problem of multiple access randomness that might seem useful at ﬁrst, but does not work.
A natural idea, after harvesting a small amount of multiple access randomness from the planted clique input in Lemma 5.2 in Section 2.2, would have been to increase our multiple access randomness by using a pseudorandom generator that fools space bounded computation [BNS92, Nis92, INW94]. Seemingly, this would let us implement all our desired reductions using just the scheme of Lemma 5.2.
This natural idea fails for the simple reason that in our applications, we must use these pseudorandom bits to simulate the randomness of a multiple access randomized logspace algorithm rather than a randomized logspace algorithm. All the known unconditional pseudorandom generators which can be implemented in logspace and which fool space bounded computation [BNS92, Nis92, INW94] need the algorithms they fool to only access their random bits in a read-once fashion. They do not fool multiple access randomized logspace algorithms and are not useful for us.
[KVM02] provides a pseudorandom generator that can be implemented in logspace and fools poly-

13

nomial sized circuit families, and hence multiple access randomized logspace algorithms. However, this is based on unproven assumptions. This construction would let us conditionally transfer randomized logspace hardness from the planted clique problem to Sparse PCA [BR13a], submatrix detection [MW15], and testing almost k-wise independence [AAK+07]15.
Our results, on the other hand, let us transfer randomized logspace hardness to various statistical problems without making any computational assumptions beyond the randomized logspace hardness of the planted clique problem and its variants. This is why pseudorandom generators are not as helpful in our context as they might initially seem.
2.9 Future outlook and further discussion
There are two bottlenecks to implementing randomized reductions in logspace. First, we need the reduction to only involve ‘simple’ computations, which do not require large memory. Second, we need multiple access to the random bits the reduction uses. In this work, we have focused on the latter issue. We demonstrated our ideas using three examples, namely Sparse PCA [BR13a], submatrix detection [MW15], and testing k-wise independence [AAK+07]. One reason for choosing these examples was that the ﬁrst requirement, the reduction being ‘simple’, is satisﬁed by already existing reductions to these three problems. Hence we could focus on our ideas to tackle the second issue.
1. That being said, we have not carefully handpicked the only known examples of reductions from the planted clique problem where this simplicity condition holds [ABW10, HK11, HWX15, GMZ17]. Hence our randomness harvesting ideas should be applicable beyond the examples we have provided.
However, the latest generation of reductions from the planted clique problem and its variants [BBH18, BB19, BB20] do not seem to satisfy this simplicity condition. A glance at the reductions implemented in these works reveals some obstacles to obtaining logspace versions of their results16. Some of the primitives require taking the ‘square-root’ of matrices (after checking their positive semideﬁniteness), or sampling a Haar random matrix from the orthogonal group. Standard implementations of either of these tasks use linear algebraic techniques that require large amounts of memory. It is an intriguing open problem to see if the hardness results in these works can be made robust to changing the notion of computational eﬃciency to space eﬃciency. This might be either by implementing known reductions more eﬃciently17, or designing alternate
15This conditionality would be disappointing for the following reasons.
1. We can already show the impossibility of space eﬃcient algorithms solving the statistical problems from [BR13a, MW15, AAK+07] by assuming the impossibility of time eﬃcient algorithms solving some other problem (like the planted clique problem or its variants). Our goal is to derive such conclusions while only assuming randomized logspace hardness of some initial problem. Using the [KVM02] pseudorandom generator does not achieve this goal since it assumes impossibility results against the resource ‘circuit size’ (and hence time).
2. One beneﬁt of the eﬃcient reductions we implement arises when technology to prove impossibility results has progressed to showing unconditional impossibility results for randomized logspace algorithms solving the planted clique problem or its variants. Our results will then imply unconditional randomized logspace hardness of the statistical problems in [BR13a, MW15, AAK+07]. If we used the conditional pseudorandom generator of [KVM02], this would not be true.
16One not so serious obstacle is that these works use a ‘real-valued’ model of computation rather than a more standard model of computation where inputs are represented using bits. To port these results to logspace, one would either have to use an appropriate ‘real-valued’ model of computation that meaningfully captures space bounds, or use ideas like in [MW15] to relate the real-valued problems to asymptotically equivalent discretized problems.
17To demonstrate that their is indeed hope of doing this, we sketch a heuristic idea to bypass the diﬃculty in taking square roots of matrices. Carefully inspecting the reduction CLIQUE-TO-WISHART in [BB19], we see that the matrix we want a square root of is a small perturbation of the identity matrix. It is plausible, though not certain, that the
14

reductions that are space eﬃcient.
2. Like [BB20], we too see a tradeoﬀ between the conservativeness of our hardness assumption and the utility of that assumption. In our context, we could harvest more multiple access randomness if we assumed computational hardness of more structured variants of the planted clique problem. This suggests two directions of study. The ﬁrst is to provide more evidence that the secret leakage variants whose hardness we have assumed are indeed computationally hard, particularly the clique leakage variants. The second is to try and devise cleverer techniques to harvest more multiple access randomness from less structured versions of the planted clique problem. That is, versions in which there is less secret leakage. Lemma 5.7 is an attempt of this sort.
Harvesting multiple access randomness from (all variants of) the planted clique problem turned out to be particularly easy. In all our schemes, we simply used bits from the input as multiple access randomness without any post-processing. This is unlike works that use randomness harvesting for derandomization, where the the input is often passed through sophisticated randomness processing tools [GW02, KvMS12, Hoz17, CT21]. If we believe that the ability to transfer computational hardness for statistical problems should be robust to changing our notion of reducibility from polynomial time to logarithmic space, this is further evidence for the utility of the planted clique problem and its variants. Not all problems would be so amenable to harvesting randomness from the input.
3 Related Work
The planted clique problem is believed to be hard, and this hardness is useful: It is widely believed that polyn√omial time algorithms can only detect or recover the planted clique for clique sizes above k = Ω( n). One piece of evidence for this belief is the long line of algorithmic progress using a variety of techniques that has been unable to break this barrier [Kuˇc95, AKS98, FK00, FR10, AV11, DGGP14, CX14, DM15a, HWX15, MAC20]. The other piece of evidence comes from studying restricted but powerful classes of algorithms. [Jer92] showed that a natural Markov chain based technique requires more than polynomial time below this threshold. Similar hardness results for the planted clique problem or its variants have been shown for statistical query algorithms [FGR+17], circuit classes [Ros08, Ros10], the Lov´asz–Schrijver hierarchy [FK03], and the sum-of-squares hierarchy [MPW15, DM15b, HKP+18, BHK+19].
Further evidence comes from the low-degree-likelihood method [HS17, HKP+17, Hop18, KWB19] and through concepts from statistical physics [GZ19]. This conjectured polynomial time hardness of the planted clique problem has also been widely used to show the polynomial time hardness of other problems, and we refer the reader to [BB20] for a comprehensive list of examples. In the spirit of studying the utility of diﬀerent notions of ‘eﬃcient computation’, in this work we show interesting reductions from weaker computational assumptions (space rather than time). In the same spirit but in the opposite direction, [MRS21] demonstrated the utility of stronger computational assumptions for the planted clique problem.
Sparse PCA, submatrix detection, and testing almost k-wise independence: The Sparse PCA problem has been well-studied from a computational lower bound perspective [BR13a, BR13b, WBS16, BB19]. See [DKWB19] for a discussion about the extensive algorithmic progress on the Sparse PCA problem. Submatrix detection [BI13, MRZ15, KBRS11, BKR+11, CX16, CLR17, MW15, BBH19] and testing almost k-wise independence [AAK+07, OZ18] have also been widely studied.
reduction goes through even if we replac√e the square root function by a truncated taylor series of the square root function about the identity matrix (for example, 1 + x ≈ 1 + x2 ). It would be easy to implement such a function space eﬃciently.
15

The hypergraph planted clique problem: Computational problems involving the Erd˝os-R´enyi or planted clique hypergraphs have also been studied before [BB20], though less comprehensively than the corresponding graph problems. [BABB19] studied the average-case complexity of counting cliques in Erd˝os-R´enyi hypergraphs. [ZX18, LZ20] used the conjectured hardness of the hypergraph planted clique problem to show hardness of other statistical problems, and the latter also provided evidence for this conjecture by studying Markov chain based algorithms like in [Jer92].

4 Technical Preliminaries
Unless stated otherwise, all logarithms are taken base 2. [n] := {1; 2; :::; n}.

Deﬁnition 4.1 (Randomized logspace algorithm). A randomized logspace algorithm A is a probabilistic random-access Turing Machine. Given multiple
access to a binary input x of length n and read-once access to a uniformly random bit string rro of length at most poly(n), it can compute the output bit A(x; rro ) using at most O(log n) bits of multiple access working space and poly(n) time.

Deﬁnition 4.2 (Multiple access randomized logspace algorithm). A multiple access randomized logspace algorithm A is a probabilistic random-access Turing Machine.
Given multiple access to a binary input x of length n, read-once access to a uniformly random bit string rro, and multiple access to a uniformly random bit string rma (each of length at most poly(n)) it can compute the output bit A(x; rro ; rma) using at most O(log n) bits of multiple access working space and poly(n) time.

Deﬁnition 4.3 (Hypothesis testing problem).
A hypothesis testing problem P consists of non-decreasing positive integer sequences ‘ = !(1) and
sizeP (‘) along with two sequences of hypotheses H0(‘) and H1(‘). For i ∈ {0; 1}, Hi (‘) is a set of distributions over binary strings of length sizeP (‘). For a problem indexed by ‘, the input x ∈ {0; 1}sizeP (‘) is distributed with probability 1=2 according to some distribution P0 ∈ H0(‘) or with probability 1=2 according to some distribution P1 ∈ H1(‘).

Deﬁnition 4.4 (Solving a hypothesis testing problem).

A randomized algorithm A with access to a uniformly random bit string r solves a hypothesis testing

problem P if

inf P (A(x; r ) = 0) + inf P (A(x; r ) = 1) = 1 + Ω(1):

P0∈H0(‘)x ∼P0;r

P1∈H1(‘)x ∼P1;r

Deﬁnition 4.5 (Erd˝os-R´enyi graph distribution: G(n; 1=2)).
Let G = ([n]; E) be a graph with vertex set of size n. The edge set E is created by including each possible edge independently with probability 21 . The distribution on graphs (represented by their n2-bit adjacency matrix) thus formed is denoted G(n; 1=2).

Deﬁnition 4.6 (Planted Clique graph distribution: G(n; 1=2; k)).

Let G = ([n]; E) b`e ´a graph with vertex set of size n. Let K ⊂ [n] be a set of size k chosen uniformly at

random from all

n k

subsets of size k. For all distinct pairs of vertices u; v ∈ K, we add the edge (u; v )

to E. For all remaining distinct pairs of vertices u; v , we add the edge (u; v ) to E independently with

16

probability 12 . The distribution on graphs (represented by their n2-bit adjacency matrix) thus formed is denoted G(n; 1=2; k).
Deﬁnition 4.7 (Planted Clique Detection Problem: PCD(n; k)). Given non-decreasing positive integer sequences n = !(1) and k ≤ n, this is the hypothesis testing problem induced by
H0(n) = {G(n; 1=2)} and H1(n) = {G(n; 1=2; k)}
where the input to problem is the triple given by the number of vertices n, the size of the planted clique k, and the adjacency matrix of the random graph.

5 Harvesting Multiple Access Randomness from the Input

5.1 Planted Clique

Conjecture 5.1 (Logspace Planted Clique Conjecture: PC-Conj-Space).

Let A be any randomized logspace algorithm whose read-once uniformly random bit string is denoted

rro .

Let

n = !(1)

and

k

be

any

sequences

of

non-decreasing

positive

integers

such

that

k

=

O

(n

1 2

−

‹

)

for some constant ‹ > 0. Then

P (A({n; k; AG }; rro ) = 0) + P (A({n; k; AG }; rro ) = 1) = 1 + o(1):

AG ∼G(n;1=2); rro

AG ∼G(n;1=2;k); rro

Lemma 5.2 (Small amounts of multiple access randomness from the Planted Clique input).

Let n = !(1), k, and m = o(n=k) be any non-decreasing positive integer sequences such that k =

O

(n

1 2

−

‹

)

for

some

positive

constant

‹

> 0.

Given

n

and

k,

assume

we

can

deterministically

compute

and store m using an additional O(log n) bits of space.

If PC-`C´onj-S`pace´ (Conjecture 5.1) is true, no multiple access randomized logspace algorithm using at

most

n 2

−

n−m 2

= o(n2=k) multiple access random bits18 can solve PCD(n − m; k).

Proof. Let S be any multiple access randomized logspace algorithm that uses at most `n´ − `n−m´

2

2

multiple access random bits when run on an instance of PCD(n − m; k). We will show that S fails to

solve PCD(n − m; k).

The key idea is to use randomness from the input itself, since we have multiple access to the input.

Let S′

be

an

algorithm

which

takes

an

input

{n

;

k

;

A

′ G

}

corresponding

to

PCD(n; k).

Let AG

denote

the adjacency matrix of the subgraph induced by A′G (th`e a´dja`cency´ matrix input to S′) on its ﬁrst

n − m vertices. Let rG be a binary string containing the

n 2

−

n−m 2

edge indicator bits for possible

edges with at least one endpoint in the last m vertices. Let S′ run S on AG using rG as its source of

multiple access random bits and output the answer given by S.

• S′ is a randomized logspace algorithm: We ﬁrst make a technical remark. The number of the bits in the input triple {number of vertices, number of planted vertices, adjacency matrix} for both problems PCD(n−m; k) and PCD(n; k) are within polynomial factors of each other, since m = o(n=k) =

18This upper bound is required only on the multiple access randomness used. We do not assume any upper bounds on the read-once randomness other than those implied by the space constraints on the algorithm.

17

o(n). Thus a logspace algorithm for one is also a logspace algorithm for the other. Hence we can ignore the distinction about which of the two problems we are running the algorithm on when determining its space complexity.

By assumption, S′ can deterministically compute and store m (and hence n − m) using O(log n) bits

of working space. This lets S′ deterministically simulate multiple access to n − m, k, AG, and rG from

multiple access to n, k, and A′G using O(log n) bits of working space. Finally, S (and hence S′) can

be implemented` a´s a`rand´omized logspace algorithm given multiple access to n − m, k, AG, and rG

because rG has

n 2

−

n−m 2

bits.

Because

k

=

O

(n

1 2

−

‹

),

PC-Conj-Space

(Conjecture

5.1)

combines

with

the

fact

above

to

imply

that

S′

fails to solve PCD(n; k). Formally,

P `S′({n; k; A′

}; rro )

=

´ 0

+

P `S′({n; k; A′

}; rro )

=

´ 1

=

1

+

o(1):

A′G ∼G(n;1=2);rro G

A′G ∼G(n;1=2;k);rrGo

• S fails to solve PCD(n − m; k): Let LastVerticesNotInClique denote the event that under the random choice of clique vertices in PCD(n; k), all k planted clique vertices are in the ﬁrst n − m vertices. Conditioned on LastVerticesNotInClique, it is clear that S (when invoked by S′) is being run on an
instance of PCD(n − m; k). This is because

1. Irrespective of whether the input graph is G(n; 1=2) or G(n; 1=2; k), rG consists of iid uniform random bits that are independent of AG.

2. If A′G ∼ G(n; 1=2), then AG ∼ G(n − m; 1=2). On the other hand, if A′G ∼ G(n; 1=2; k), then AG ∼ G(n − m; 1=2; k).

Conditioned on LastVerticesNotInClique, the probability that S′ outputs the correct answer is equal to

the probability that S outputs the correct answer when run on a instance of PCD(n − m; k). Because

m

=

o (n=k ),

a

union

bound

gives

Pr(LastVerticesNotInCliquec )

≤

m·

k n

=

o(1).

Hence

we

must

have

P (S({n − m; k; AG}; rro ; rma) = 0) + P (S({n − m; k; AG}; rro ; rma) = 1) = 1 + o(1):

AG ∼G(n−m;1=2);rro ;rma

AG ∼G(n−m;1=2;k);rro ;rma

5.2 k-Partite Planted Clique
Deﬁnition 5.3 (k-Partite Planted Clique graph distribution: kG(‘ · k; 1=2; k)). This is the planted clique graph distribution G(‘ · k; 1=2; k) conditioned on the event that for all i ∈ {1; 2; :::; k}, there is exactly one planted clique vertex in [i · ‘] \ [(i − 1) · ‘].

Deﬁnition 5.4 (k-Partite Planted Clique Detection Problem: kPCD(‘ · k; k)). Given non-decreasing positive integer sequences ‘ = !(1) and k, this is the hypothesis testing problem induced by
H0(‘) = {G(‘ · k; 1=2)} and H1(‘) = {kG(‘ · k; 1=2; k)}
where the input to problem is the triple given by the number of vertices ‘ · k, the size of the planted clique k, and the adjacency matrix of the random graph.

Conjecture 5.5 (Logspace k-Partite Planted Clique Conjecture: kPC-Conj-Space). Let A be any randomized logspace algorithm whose read-once uniformly random bit string is denoted
18

rro. Let ‘ = !(1) and k be any sequence of non-decreasing positive integers such that k = O(‘1−‹) for some constant ‹ > 0. Then

P (A({‘ · k; k; AG }; rro ) = 0) + P (A({‘ · k; k; AG }; rro ) = 1) = 1 + o(1):

AG ∼G(‘·k;1=2); rro

AG ∼kG(‘·k;1=2;k); rro

Lemma 5.6 (Multiple access randomness from the k-Partite Planted Clique input). Let ‘ = !(1), k, ks ≤ k − 1, and m = o(‘) be any non-decreasing positive integer sequences such that k = O(‘1−‹) for some positive constant ‹ > 0. Given ‘ · k and k, assume we can deterministically compute and store ks and m using an additional O(log ‘) bits of space.

If kPC`-Co´nj-S`pace (´Conjecture 5.5) is true, no multiple access randomized logspace algorithm using at

most

‘·k 2

−

‘·k−m 2

= o(‘2 · k) multiple access random bits can solve kPCD(‘ · ks ; ks ).

Proof. The proof is analogous to that of Lemma 5.2, so we note the slight change required and omit the details. The only diﬀerence from Lemma 5.2 is that the reduction uses the subgraph induced on the ﬁrst ‘ · ks vertices (instead of the ﬁrst n − m vertices) as the instance of kPCD(‘ · ks ; ks ) to solve. The auxiliary multiple access random bits harvested from the input are still the edge indicators for possible edges with at least one endpoint in the last m vertices. The key reason this works is that the k-Partite planted clique problem has a nice ‘self-reducibility’ structure so that the subgraph induced on the ﬁrst ‘ · ks vertices is an instance of kPCD(‘ · ks ; ks ).

Lemma 5.7 (More multiple access randomness from the k-Partite Planted Clique input). Let ‘ = !(1), k and ks be any non-decreasing positive integer sequences such that k = O(‘1−‹) for some constant ‹ > 0 and ks ≤ √k‘ . Given ‘ · k and k, assume we can deterministically compute and store ks using an additional O(log ‘) bits of space.
aIft tmheosktP`C‘-2·kC´onmj-uSltpiapclee a(Cccoenssjecratunrdeo5m.5b)itiss tcraune,sonlovemkuPltCipDl(e‘a·ckcse;skss )ra. ndomized logspace algorithm using

Proof. Let S be any multiple access randomized logspace algorithm that uses at most `‘·k´ multiple
2
access random bits when run on an instance of kPCD(‘ · ks ; ks ). We will show that S must fail to solve kPCD(‘ · ks ; ks ).

Let S′ be an algorithm which takes as input {‘ · 2k; 2k; AG } corresponding to kPCD(‘ · 2k; 2k). Let As

(respectively Ar ) denote the adjacency matrix of the subgraph induced by AG (the adjacency matrix

`inpu´t to S′) on its ﬁrst ‘ · ks (respectively last ‘ · k) vertices. Let rG be a binary string containing the

‘·k 2

edge indicator bits for`pos´sible edges in the graph corresponding to Ar . Let S′ run S on As using

rG as its source of at most

‘·k 2

multiple access random bits and output the answer given by S.

• S′ is a randomized logspace algorithm: The space complexity analysis of S′ is like in the proof of Lemma 5.2. We omit the details.

Combined with the kPC-Conj-Space (Conjecture 5.5) and the fact that 2k = O(‘1−‹), this means S′ fails to solve kPCD(‘ · 2k; 2k). Formally,

P

`S′({‘

·

2k ;

2k ;

AG

};

rr o

)

=

´ 0

+

P

`S′({‘

·

2k ;

2k ;

AG

};

rr o

)

=

´ 1

=

1

+

o(1):

AG ∼G(‘·2k;1=2);rro

AG ∼kG(‘·2k;1=2;2k);rro

19

• S fails to solve kPCD(‘ · ks ; ks ): Letting rma denote a set of `‘2·k´ independent uniformly random multiple access bits, we want to show that

P (S({‘ · ks ; ks ; As }; rro ; rma) = 0) + P (S({‘ · ks ; ks ; As }; rro ; rma) = 1) = 1 + o(1):

As ∼G(‘·ks ;1=2);rro ;rma

As ∼kG(‘·ks ;1=2;ks );rro ;rma

1. If the input graph AG is drawn from G(‘ · 2k; 1=2), then As ∼ G(‘ · ks ; 1=2) and rG is a set of independent uniformly random bits. Hence we can relate the performance of S′ to the performance of S to obtain

P

(S({‘

·

ks

;

ks

;

As

};

rr o

;

rma)

=

0)

=

P

`S′({‘

·

2k ;

2k ;

AG

};

rr o

)

=

´ 0

:

As ∼G(‘·ks ;1=2);rro ;rma

AG ∼G(‘·2k ;1=2);rr o

2. If the input graph AG is drawn from kG(‘ · 2k; 1=2; 2k), then we do have As ∼ kG(‘ · ks ; 1=2; ks ) as we might hope. However, rG is not a collection of independent uniformly random bits. This is because Ar ∼ kG(‘ · k; 1=2; k). Hence S′ is actually using a source of multiple access random bits that is not truly independent and uniform.

Luckily, eﬃcient algorithms should not be able to distinguish between kG(‘ · k; 1=2; k) and a source of truly random bits. This allows us to relate the performance of S′ when using Ar as its source of multiple access randomness to its performance when using a truly random source of multiple access
bits. If

|P

(S({‘

·

ks

;

ks

;

As

};

rr o

;

rma)

=

1)

−P

`S′({‘

·

2k ;

2k ;

AG

};

rr o

)

=

´ 1|

=

o(1);

(1)

As ∼kG(‘·ks ;1=2;ks );rro ;rma

AG ∼kG(‘·2k;1=2;2k);rro

|

{z

}

:=1−S0

then clearly we have the desired conclusion that S fails to`so´lve kPCD(‘ · ks ; ks ). We now show that

(1) must hold. Let rG denote the dependent collection of

‘·k 2

multiple access random bits obtained

from Ar ∼ kG(‘ · k; 1=2; k). By construction, the output of S′ is identical to the output of S when run

with rG as its source of multiple access randomness, which means

P

(S({‘

·

ks

;

ks

;

As

};

rr o

;

rG )

=

1)

=

P

`S′({‘

·

2k ;

2k ;

AG

};

rr o

)

=

´ 1

:

As ∼kG(‘·ks ;1=2;ks );rro ;rG

AG ∼kG(‘·2k ;1=2;2k );rr o

|

{z

}

:=S1

Hence, showing (1) is equivalent to showing S0 + S1 = 1 + o(1). We will reason about S0 and S1 using a hypothetical algorithm H whose input {‘ · k; k; AhG } is an instance of the problem kPCD(‘ · k; k). H outputs the answer obtained by running S using its input AhG as the multiple access randomness S needs and {‘ · ks ; ks ; Ahr } as the ‘input’ to S. Here Ahr is an adjacency matrix on ‘ · ks vertices we will
deﬁne later.

We s`how´that H can be implemented as a multiple access randomized logspace algorithm that uses

r :=

‘·ks 2

+ ks · (10‘(⌈log ‘⌉)2) multiple access random bits. By assumption, H can compute ‘ · ks ; ks

from its input using O(log ‘) bits of space. It can also clearly provide S with multiple access to its

input adjacency matrix AhG for use as randomness. Since S is a multiple access randomized logspace

machine and the inputs to all problems we consider are of size poly(‘), we only need to show that

multiple access to the (yet to be deﬁned) matrix Ahr takes O(log ‘) bits of space. Of the r multiple access random bits, let the ﬁrst `‘·ks´ be the edge indicators of an Erd˝os-R´enyi
2
G(‘ · ks ; 1=2) graph. Partition the rest into ks sets of (10‘(⌈log ‘⌉)2) independent uniform random
bits. For all j ∈ [ks ], use the jth such set to sample an eﬃciently computable random function

(which is approximately a uniformly random permutation) ıj : [‘] → [‘] using Lemma 8.1. Because

20

these functions are all sampled independently, the ‘sub-additivity’ or ‘tensorization’ property of total
variation distance [BB19, Fact 3.1] implies that the total variation distance between the set of functions ıj obtained from Lemma 8.1 and a set of independent uniformly random permutations is O(ks =‘4) = o(1).

We now deﬁne Ahr so that it is ‘approximately’ distributed as kPCD(‘ · ks ; 1=2; ks ). Let it be the

adjacency matrix of the ‘ · ks vertex graph whose edge set is as follows. Given two vertices (j1 − 1) ·

‘ + i1; (j2 − 1) · ‘ + i2 with j1; j2 ∈ [ks ] and i1; i2 ∈ [‘], if ıj1(i1) = ıj2(i2) = 1, there is an edge between

the two vertices. Otherwise, there is an edge between the two vertices if and only if there is an edge

betw`een ´the corresponding two vertices in the Erd˝os-R´enyi G(‘ · ks ; 1=2) graph sampled using the the

ﬁrst

‘·ks 2

multiple access random bits available to H.

It is straightforward to observe that because the functions ıj can all be implemented using an additional

O(log ‘) bits of space (Lemma 8.1), the algorithm H can provide the algorithm S with multiple access

to the adjacency matrix Ahr using O(log ‘) bits of working space. This completes the proof that H

can be implemented as a multiple access randomized logspace algorithm that uses r multiple access

random bits. Because

„«

„

«„

«

r ≤ 2 ‘ · ks ≤ (‘ · ks )2 ≤ ‘ · k · (2k) ≤ ‘ · (k + 1) − ‘ · (k + 1) − 2k ;

2

2

2

2

Lemma 5.6 implies that our hypothetical algorithm H must fail to solve kPCD(‘ · k; k). Formally, this

means

P (H({‘ · k; k; AG}; rro ; rma) = 0) + P (H({‘ · k; k; AG }; rro ; rma) = 1) = 1 + o(1):

AG ∼G(‘·k;1=2); rro ;rma

AG ∼kG(‘·k;1=2;k); rro ;rma

|

{z

}|

{z

}

:=H0

:=H1

Recall that that the total variation distance between the set of functions ıj used by H and a set of independent uniformly random permutations is o(1). Further, if H used independent uniformly
random permutations instead of the ıj ’s from Lemma 8.1, Ahr would be distributed exactly as kPCD(‘· ks ; 1=2; ks ). Because of how H was constructed, the data processing inequality for total variation distance [BB19, Fact 3.1] thus implies |Si − Hi | = o(1) for i ∈ {0; 1}. This completes our proof.

5.3 Clique Leakage k-Partite Planted Clique
Deﬁnition 5.8 (Clique Leakage k-Partite PC graph distribution: clkG(‘ · k; 1=2; k)). This is the k-partite planted clique graph distribution kG(‘ · k; 1=2; k) conditioned on the event that the ﬁrst vertex in the graph (i.e the vertex named 1) is in the set of planted clique vertices.

Deﬁnition 5.9 (Clique Leakage k-Partite PC Detection Problem: clkPCD(‘ · k; k)). This is the hypothesis testing problem deﬁned analogous to kPCD(‘·k; k) using clkG(‘·k; 1=2; k) instead of kG(‘ · k; 1=2; k).

Conjecture 5.10 (Clique Leakage Logspace k-Partite PC Conjecture: clkPC-Conj-Space). This is the conjecture analogous to kPC-Conj-Space involving clkPCD(‘ · k; k) instead of kPCD(‘ · k; k).

Lemma 5.11 (Multiple access randomness from the Clique Leakage k-Partite PC input). Let ‘ = !(1), k and ks be any non-decreasing positive integer sequences such that k = O(‘1−‹) for some constant ‹ > 0 and ks ≤ k. Given ‘ · k and k, assume we can deterministically compute and store ks using an additional O(log ‘) bits of space.
21

If the clkPC-Co`nj-´Space (Conjecture 5.10) is true, no multiple access randomized logspace algorithm

using at most

‘·k 2

multiple access random bits can solve clkPCD(‘ · ks ; ks ).

Proof. Let S be any multiple access randomized logspace algorithm that uses at most `‘·k´ multiple
2
access random bits when run on an instance of clkPCD(‘ · ks ; ks ). We will show that S fails to solve clkPCD(‘ · ks ; ks ).

Let S′ be an algorithm which takes as input {‘ · 4k; 4k; AG } corresponding to an instance of clkPCD(‘ ·

4k; 4k). Let As denote the adjacency matrix of the subgraph induced by AG (the adjacency matrix input to S′) on its ﬁrst ‘ · ks vertices. Let Ar denote the adjacency matrix of the subgraph induced by

AG on the following vertex subset. This vertex subset consists of those of the last ‘ · 3k vertices of AG

which do not have an edge to its ﬁrst vertex. Because ks ≤ k, there are no common vertices shared

by As and Ar . Let rG be the binary string containing the edge indicator bits for p`oss´ible edges in the

graph corresponding to Ar . Let S′ run S on As using rG as its source of at most

‘·k 2

multiple access

random bits19 and output the answer given by S.

1. If the input graph to S′ has the null distribution AG ∼ G(‘ · 4k; 1=2), the input graph to S is an instance of As ∼ G(‘ · ks; 1=2) with rG a string of independent uniform random bits.

2. If the input graph to S′ has the planted distribution AG ∼ clkG(‘ · 4k; 1=2; 4k), the input graph to S is an instance of As ∼ clkG(‘ · ks ; 1=2; ks ) with rG a string of independent uniform random bits that are independent of all other randomness. The former is because the ﬁrst vertex of AG is also the ﬁrst vertex of As. The latter is by construction since none of the vertices in Ar can be in the planted clique vertex set of AG.

• S′ is a randomized logspace algorithm: Using O(log ‘) space, S′ can count how many vertices
there are in Ar as well as provide multiple access to Ar by using its ability to check if any given vertex has an edge to the ﬁrst vertex in AG. The space complexity analysis of S′ now proceeds like in the proof of Lemma 5.2. We omit the details. Combined with the clkPC-Conj-Space (Conjecture 5.10) and the fact that 4k = O(‘1−‹), this means S′ fails to solve clkPCD(‘ · 4k; 4k).

• S fails to solve clkPCD(‘ · ks ; ks ): Let EnoughVertices denote the event that there are at least ‘ · k vertices in the subgraph corresponding to the adjacency matrix Ar . Standard tail bounds for binomial random variables imply that Pr(EnoughVertices) = 1 − o(1) irrespective of whether AG ∼ G(‘ · 4k; 1=2) or AG ∼ clkG(‘ · 4k; 1=2; 4k). Conditioned on EnoughVertices, the random string rG has enough random bits for S’s multiple access needs, and the probability that S′ outputs the correct answer is equal to the probability that S outputs the correct answer20. Since S′ fails and Pr(EnoughVertices) = 1 − o(1),
S must fail to solve clkPCD(‘ · ks ; ks ).

5.4 Clique Leakage Hypergraph Planted Clique
Deﬁnition 5.12 (Erd˝os-R´enyi hypergraph distribution: HGs(n; 1=2)). Let G = ([n]; E) be a s-uniform hypergraph with vertex set of size n. The hyperedge set E is created by including each possible hyperedge independently with probability 21 . The distribution on s-uniform hypergraphs thus formed is denoted HGs(n; 1=2).

Deﬁnition 5.13 (Hypergraph Planted Clique distribution: HGs(n; 1=2; k)). Let G = ([n]; E) be a s-uniform hypergraph with vertex set of size n. Let K ⊂ [n] be a set of size k chosen
19If Ar has fewer than ‘ · k vertices, S′ can output any arbitrary ﬁxed answer. 20Crucially, the randomness that determines whether EnoughVertices occurs is independent of the randomness in As and only aﬀects the size of rG, not its independence and uniformity.

22

uniformly at random from all `kn´ subsets of size k. For all sets of s distinct vertices u1; u2; :::; us ∈ K, we add the hyperedge (u1; u2; :::; us ) to E. For all other possible hyperedges, we add the hyperedge to E independently with probability 12 . The distribution on s-uniform hypergraphs thus formed is denoted HGs (n; 1=2; k).

Deﬁnition 5.14 (Clique Leakage Hypergraph Planted Clique distribution: clHGs(n; 1=2; k)). This is the hypergraph planted clique distribution HGs(n; 1=2; k) conditioned on the event that the ﬁrst
s − 2 vertices are in the planted clique vertex set K.

Deﬁnition

5.15

(Clique

Leakage

Hypergraph

PC

Detection

Problem:

cl

HPC

s D

(n

;

k

)).

Given non-decreasing positive integer sequences n = !(1) and k ≤ n, this is the hypothesis testing

problem induced by

H0(n) = {HGs (n; 1=2)} and H1(n) = {clHGs (n; 1=2; k)}

where the input to problem is the quadruple given by the number of vertices n, the size of the planted clique k, the hyperedge set of the random hypergraph, and s.

Conjecture 5.16 (Clique Leakage Logspace Hypergraph PC Conjecture: clHPC-Conj-Space).

Let A be any randomized logspace algorithm whose read-once uniformly random bit string is denoted

rro. Let s ≥ 3 be any constant integer and n = !(1), k ≤ n be any sequences of non-decreasing positive

integers

such

that

k

=

O

(n

1 2

−

‹

)

for

some

constant

‹

>

0.

Then

P (A({n; k; AG; s}; rro ) = 0) + P (A({n; k; AG ; s}; rro ) = 1) = 1 + o(1):

AG∼HGs (n;1=2); rro

AG ∼clHGs (n;1=2;k); rro

Lemma 5.17 (Arbitrarily large polynomial amounts of multiple access randomness from the Clique

Leakage Hypergraph Planted Clique input).

Let

n

=

!(1)

and

k

be

any

non-decreasing

positive

integer

sequences

such

that

k

=

O

(n

1 2

−

‹

)

for

some

positive constant ‹ > 0.

If clHPC-Conj-Space (Conjecture 5.16) is true, no multiple access randomized logspace algorithm can solve the planted clique detection problem PCD(n; k).

Proof. Our proof will strongly mirror that of Lemma 5.2. Let S be any multiple access randomized

logspace algorithm. Since such algorithms can only use poly(n) amounts of randomness, there must

exist a constant positive integer s ≥ 3 such that for all large enough n, the number o`f mult´iple access

random bits S uses when run on the input corresponding to PCD(n; k) is at most

n+s −2 s −1

.

We will

show that S fails to solve PCD(n; k).

Let S′ be an algorithm which takes as input the quadruple {n + s − 1; k + s − 2; AG; s} corresponding to an instance of clHPCsD(n + s − 1; k + s − 2). Here AG encodes the hyperedge set of the s-uniform

hypergraph on n + s − 1 vertices. Let APC denote the adjacency matrix of an n-vertex graph whose n

vertices correspond to the vertex subset VPC = {s − 1; s; :::; n + s − 2} of the hypergraph AG. The edge

set of APC depends on the hyperedge set of AG as follows. For any two distinct vertices i < j ∈ VPC,

there is an edge in APC `if and´only if the size s hyperedge (1; 2; :::; s − 2; i ; j) exists in AG. Let rG

denote the string of size

n+s −2 s −1

containing the hyperedge indicators for all possible hyperedges in AG

23

involving the last vertex (i.e the vertex named n + s − 1) in AG. Let S′ run S on APC using rG as its source of multiple access random bits21 and output the answer given by S.

• S′ is a randomized logspace algorithm: The space complexity analysis of S′ is essentially like in

the proof of Lemma 5.2. We omit the details. Combined with the clHPC-Conj-Space (Conjecture 5.16)

and

the

fact

that

k

+s

−2

=

O((n

+s

−

1)

1 2

−

‹

),

this

means

S′

fails

to

solve

clHPCsD(n

+s

− 1;

k

+s

− 2).

• S fails to solve PCD(n; k): Let LastVertexNotInClique denote the event that the (n + s − 1)th vertex in AG is not in the planted clique set when AG ∼ clHGs(n + s − 1; 1=2; k + s − 2). Observe that Pr(LastVertexNotInClique) = 1 − o(1). Conditioned on LastVertexNotInClique, it is clear that S (when invoked by S′) is being run on an instance of PCD(n; k). This is because

1. Irrespective of whether the input hypergraph is HGs (n + s − 1; 1=2) or clHGs(n + s − 1; 1=2; k + s − 2), rG consists of iid uniform random bits that are independent of APC.

2. If AG ∼ HGs (n + s − 1; 1=2), then APC ∼ G(n; 1=2). On the other hand, if AG ∼ clHGs (n + s − 1; 1=2; k + s − 2), then APC ∼ G(n; 1=2; k).

Conditioned on LastVerticesNotInClique, the probability that S′ outputs the correct answer is equal to the probability that S outputs the correct answer when run on a instance of PCD(n; k). Since S′ fails and Pr(LastVerticesNotInClique) = 1 − o(1), S must fail to solve PCD(n; k).

6 Evidence for Planted Clique Hardness despite Clique Leakage

Deﬁnition

6.1

(Hypergraph

PC

Detection

Problem:

HPC

s D

(n

;

k

)).

This is the hypothesis testing problem analogous to clHPCsD(n; k) that uses HGs(n; 1=2; k) instead of

clHGs (n; 1=2; k).

Conjecture 6.2 (Logspace Hypergraph PC Conjecture: HPC-Conj-Space).

This

is

the

conjecture

analogous

to

clHPC-Conj-Space

involving

HPCsD(n; k)

instead

of

cl

HPC

s D

(n

;

k

).

Deﬁnition 6.3 (Deterministic Logspace Algorithm for Planted Clique Recovery).
Given a ‘planted clique input’ (i.e a random object distributed as any of the variants of the planted clique distribution G(n; 1=2; k) / kG(‘·k; 1=2; k) / clkG(‘·k; 1=2; k) / HGs(n; 1=2; k) / clHGs(n; 1=2; k)), a deterministic logspace algorithm A solves the planted clique recovery task if it outputs the true planted
clique K with at least constant probability over the randomness in the input. That is, if G denotes the planted clique input22, the following happens with at least constant probability. For any vertex ∈ [n] (or vertex ∈ [‘ · k]), A({G; vertex}) is 1 if vertex ∈ K and 0 if vertex ∈= K.

Lemma 6.4 (Hardness of Clique Leakage Hypergraph PC Recovery from HPC-Conj-Space).

Let

n

=

!(1)

and

k

be

non-decreasing

positive

integer

sequences

such

that

1
!((log n) s−1 )

=

k

=

O

(n

1 2

−

‹

)

for some constants s ≥ 3 and ‹ > 0.

If HPC-Conj-Space is true, no deterministic logspace algorithm can solve the clique leakage hypergraph planted clique recovery problem (Deﬁnition 6.3 with clHGs(n; 1=2; k)).

21If S needs more multiple access random bits than the size of rG (as is possible if n is not large enough) S′ can output
any arbitrary ﬁxed answer. 22Recall that this input also contains problem parameters such as n (or ‘ · k), k, and s.

24

Proof. Suppose a deterministic logspace algorithm A can solve the planted clique recovery problem

with clHGs (n; 1=2; k).

We

construct

a

deterministic

logspace

algorithm

that

solves

the

HPC

s D

(n

;

k

),

yielding a contradiction.

Let S

be

an

algorithm

that

gets

as

input

{n; k; AG; s}

corresponding

to

the

input

of

HPC

s D

(n

;

k

).

S

iterates over all ns−2 tuples (v1; v2; :::; vs−2) where each vi ∈ [n]. It can do this eﬃciently in lexicographic

order by maintaining and incrementing s − 2 counters named v1; v2; :::; vs−2 that use O(log n) bits each.

For a given tuple, it checks if v1 < v2 < ::: < vs−2. This can be done using O(log n) bits of space. If

this condition is not met, S moves on to the next tuple23. If this condition is met, however, S does

the following.

Letting t denote the current tuple (v1; :::; vs−2), we deﬁne a s-uniform hypergraph At that is essentially AG but with the vertices renamed. Let renamet : [n] → [n] be a permutation we will deﬁne soon. At has a hyperedge (i1; i2; :::; is ) if an only if AG has a hyperedge (renamet(i1); renamet (i2); :::; renamet(is )). For i ∈ [s − 2], we deﬁne renamet(i ) := vi . For i ∈ [n] \ [s − 2] we deﬁne renamet(i ) to be the (i − (s − 2))th smallest positive integer not in {v1; v2; :::; vs−2}. Observe that renamet is a permutation and can be computed using O(log n) bits of space for any input i ∈ [n]. Hence we can check the existence
of any given s-uniform hyperedge in At using O(log n) bits of space. Crucially, if the {v1; :::; vs−2} corresponding to t are all planted clique vertices in AG, the ﬁrst s − 2 vertices are planted clique vertices in At.

S now uses the deterministic logspace algorithm A on the renamed hypergraph At and counts the number of vertices in At for which A outputs a 1 (i.e the number of vertices in At that A believes are in a planted clique). If this number is less than k, S moves on to the next tuple. If this number is at least k, S does the following. If the vertices in At for which A outputs 1 form a clique24, S terminates and outputs 1 (indicating its belief that the input hypergraph has a planted clique). If not, S moves
on to the next tuple. If S iterates over all tuples without terminating as described above, it terminates
and outputs a 0 (indicating its belief that the input hypergraph does not have a planted clique).

First, it is clear by construction that S is a deterministic logspace algorithm. We now argue that

S

solves

HPC

s D

(n

;

k

).

It is impossible for S to output 1 if there is no clique of size k in AG.

If

AG ∼ HGs (n; 1=2), it is folklore (Lemma 8.3) that AG can not have a clique of size k except with

probability o(1). Hence the probability that S outputs the correct answer is at least 1 − o(1).

If, on the other hand, AG ∼ HGs (n; 1=2; k), there must be at least one tuple t = (v1; v2; :::; vs−2) such that At ∼ clHGs(n; 1=2; k). By assumption, with at least constant probability, A will correctly identify the planted clique vertices in At and S will output the correct answer 1. This gives

P (S({n; k; AG; s}) = 0) + P (S({n; k; AG; s}) = 1) = 1 + Ω(1)

AG ∼HGs (n;1=2)

AG∼HGs (n;1=2;k)

and completes the proof.

Lemma 6.5 (Hardness of Clique Leakage k-Partite PC Recovery from kPC-Conj-Space). Let ‘ = !(1) and k be non-decreasing positive integer sequences such that !(log(‘ · k)) = k = O(‘1−‹) for some constant ‹ > 0.
If kPC-Conj-Space is true, no deterministic logspace algorithm can solve the clique leakage k-Partite planted clique recovery problem (Deﬁnition 6.3 with clkG(‘ · k; 1=2; k)).
23Essentially, this is a space eﬃcient way to iterate over all vertex sets (rather than tuples) of size s − 2. 24This can be checked with O(log n) bits of working space by iterating over all size s subsets of [n] (using the scheme described earlier in the proof). For every set of s vertices {i1; :::; is } such that A outputs 1 on all of them, we check for a hyperedge (i1; :::; is ) in At .

25

Proof. The proof is analogous to that of Lemma 6.4 so we omit the details. The only diﬀerence is that we now iterate over all vertices i ∈ [‘] rather than tuples of size s − 2 as in Lemma 6.4. For any vertex i ∈ [‘], the renamed graph simply swaps vertices 1 and i and leaves the names of all other vertices unchanged.

7 Logspace Reductions using auxiliary Multiple Access Randomness

7.1 Sparse Principal Component Analysis [BR13a]



q

ﬀ

Setting up some notation from [BR13a], deﬁne R0 := (d¯; n¯; k¯) ∈ N3 : 15 k¯ log(1n¯20ed¯) ≤ 1; k¯ ≤ d¯0:49 25

and

R—

:=

R0

∩

˘n¯—

≤

k¯¯

∩

˘ n¯

<

d¯¯

for

any

—

∈

(0;

1).

The Sparse PCA Hypothesis Testing Problem (SPCA(d¯; n¯; k¯; „¯)) [BR13a] is a problem where the input consists of the parameters d¯, n¯, k¯, „¯ (which must lie in R—) as well as n¯ independent samples X1; :::; Xn¯ ∈ Rd¯ of a d¯-dimensional random vector X. The null hypothesis is the set of all distributions
(D0) whose empirical variance along any direction is ‘small’. The alternate hypothesis is the set of all distributions (D1k¯(„¯)) for which there is a k¯-sparse direction along which the empirical variance is ‘large’, as quantiﬁed by „¯. Since we will not need the detailed deﬁnitions of D0 and D1k¯(„¯), we do not provide them here and point the interested reader to [BR13a].

Lemma 7.1 ([BR13a]’s reduction to Sparse PCA can be implemented in mutiple access randomized

logspace)`. ´

ˆ

´

1

Let ‹ ∈

0;

1 6

and — ∈

13 ;

1 2

−

‹

be constants. Let n = !(1), k = Θ(n 2 −‹), and m = o(n=k) be

non-decreasing positive integer sequences with the following properties. Given n and k, the value m

can

be

computed

and

stored

u‰s“ing

O(log ”

n)
1

ıadditional

bits

of

space

and l

n

−m m

is

always

a

multiple

of

2.

Let

n−m 2

<

d¯ ≤

poly(n),

n¯ =

4(n−m) 1−— k

= o(n), and n¯— ≤ k¯ =

n¯k 4(n−m)

≤ d¯0:49 be non-decreasing

r!

positive

integer

sequences.

In

particular,

(d¯; n¯; k¯) ∈ R—.

Deﬁne

„¯ :=

(k¯−1)k n−m

=Θ

k¯

4−

1 —

n¯

. Assume

that given n − m and k, we can deterministically compute and store d¯ using O(log n) additional bits of space.

If there is a randomized logspace algorithm that solves SPCA(d¯; n¯; k¯`; „¯), t`here ´is´ a multiple access ran-

domized logspace algorithm that solves PCD(n − m; k) using at most

d¯ −

n−m 2

·n¯+ 2·10d¯(⌈log d¯⌉)2 +

n¯ ≤ poly(n − m) multiple access random bits.

Proof. The proof follows easily from observing that the reduction of [BR13a] can be (approximately)

implemented space eﬃciently. Let S be a randomized logspace` algo`rithm´´that solves SPCA(d¯; n¯; k¯; „¯).

Let S′ be a multiple access randomized algorithm that has

d¯ −

n−m 2

· n¯ + 2 · 10d¯(⌈log d¯⌉)2 + n¯

multiple access random bits and {n − m; k; AG} as input corresponding to PCD(n − m; k). Clearly,

S′ can compute and store d¯, n¯, k¯, and „¯ (the latter can be represented by storing its numerator and

denominator) using O(log n) bits of space.

Let

A¯

denote

a

d¯ × n¯

matrix

whose

ﬁrst

n−m 2

rows

are `

simply ´

the

‘bottom-left’

submatrix

of

AG .

That is, for i ∈ [ n−2m ], the i th row of A¯ is simply the

n−m 2

+

i

th

row

of

AG

restricted

to

its

ﬁrst

n¯

25The 120 is arbitrary and can be any constant greater than 18. Similarly the 0:49 can be any constant less than 0:5.

26

columns26. The rest of the d¯ − ` n−m ´ rows of A¯ are populated by independent uniform random bits.

Let

ıd¯

:

[d¯]

→

[d¯]

and

ın¯

:

[n¯]

→

2
[n¯]

be

independent

random

eﬃciently

computable

functions

(which

are approximately uniform random permutations) sampled by invoking Lemma 8.1 with 10d¯(⌈log d¯⌉)2

and 10n¯(⌈log n¯⌉)2 independent uniform multiple access random bits respectively.

Let B¯ denote the d¯ × n¯ matrix whose (i ; j)th entry is the (ıd¯(i ); ın¯(j))th entry of A¯ and B¯j denote

the jth column of B¯. For j ∈ [n¯], deﬁne Xj = ”j (2B¯j − 1) ∈ {−1; 1}d¯ where ”j is an independent

unif`orm `rando´m´ bit. Because the ı’s can be computed space eﬃciently (see Lemma 8.1), S′ can use

its

d¯ −

n−m 2

· n¯ + 2 · 10d¯(⌈log d¯⌉)2 + n¯ multiple access random bits to provide multiple access to

the vectors X1; :::; Xn¯. Since d¯n¯ ≤ poly(n), as a multiple access randomized logspace algorithm, S′ can

invoke S on X1; :::; Xn¯ and output the corresponding answer.

We know from Lemma 8.1 and the tensorization inequality for total variation distance [BB19, fact 3.1]
that the pair (ıd¯; ın¯) we use has vanishing o(1) total variation distance from a pair of independent uniformly random permutations. The data processing inequality then implies that our space eﬃcient algorithm S′ solves PCD(n − m; k) if and only if an analogous algorithm S′′ solves PCD(n − m; k). S′′ uses a pair of independent uniformly random permutations instead of (ıd¯; ın¯). Crucially, we do not care about the space complexity of S′′ and can invoke results from [BR13a], where it was studied. For
the rest of the proof, assume the ı’s are independent uniformly random permutations.

As noted in the proof of [BR13a, Theorem 7], if AG ∼ G(n − m; 1=2), then the vectors X1; :::; Xn¯ are

drawn from a distribution in the null hypothesis of SPCA(d¯; n¯; k¯; „¯). On the other hand, if AG ∼

G(n − m; 1=2; k),

the

collection

of

vectors

X1; :::; Xn¯

has

total

variation

distance

at

most

16n¯ n−m

=

o(1)

from a collection of n¯ independent samples from some distribution in the alternate hypothesis of

SPCA(d¯; n¯; k¯; „¯).

This last fact follows from [BR13a, Lemma 8] because

2n¯k n−m

≥ max{16 log n; 8k¯}27.

By the data processing inequality, the probability that S′′ outputs the correct answer on an instance

of PCD(n − m; k) is within o(1) of the probability that S outputs the correct answer on an instance of SPCA(d¯; n¯; k¯; „¯). This complete the proof.

Theorem 1 (Logspace hardness of Sparse PCA (Restricted parameter range)).

Let d¯`, n¯, k¯´, and „¯ be as deﬁned in Lemma 7.1 with the additional constraints that m = !(l og 2n) and

d¯ =

n−m 2

+

o

(

nm n¯

).

If

the

logspace

planted

clique

conjecture

PC-Conj-Space

(Conjecture

5.1)

is

true,

no randomized logspace algorithm can solve SPCA(d¯; n¯; k¯; „¯).

Proof. We have `d¯ − ` n−m ´´ · n¯ + 2 · 10d¯(⌈log d¯⌉)2 + n¯ = o(mn) ≤ `n´ − `n−m´ for large enough n.

2

2

2

Since m can be computed and stored using O(log n) bits of space given n and k, we can obtain the

desired conclusion by combining Lemma 7.1 with Lemma 5.2.

Theorem 1 shows that we can use Conjecture 5.1 to deduce the randomized logspace hardness of the Sparse PCA problem as long as d¯ is not too small and not too large compared to n¯. However, we believe the Sparse PCA problem is hard even for much larger values of d¯. Theorem 2, which follows immediately by combining Lemma 7.1 with Lemma 5.17, can show randomized logspace hardness for Sparse PCA instances with such parameters.

26In [BR13a], a uniformly random permutation is applied to the matrix AG before extracting this ‘bottom-left’ submatrix. However, in our formulation of the planted clique problem, all sets of size k are equally likely to be the planted vertex set, so AG’s distribution (in both the null and planted cases) is invariant to permutations. Hence we can skip this step.
27[BR13a, Lemma 8] actually states a worse upper bound on the total variation distance. However, a close look at their proof shows that the better total variation distance upper bound we state also holds.
27

Theorem 2 (Logspace hardness of Sparse PCA). Let d¯, n¯, k¯, and „¯ be as deﬁned in Lemma 7.1. If the clique leakage logspace hypergraph planted clique conjecture clHPC-Conj-Space (Conjecture 5.16) is true, no randomized logspace algorithm can solve SPCA(d¯; n¯; k¯; „¯).
The formulation for the Sparse PCA problem used by [BR13a] (and hence by us) is just one of many formulations considered in the literature. We refer the reader to [BB19] for a comprehensive discussion of issues surrounding these various formulations.
7.2 Planted Submatrix Detection [MW15]
Following [MW15], for any real number x and integer t, denote the t-bit truncation of x as [x]t := 2−t ⌊2t x⌋. We extend this notation to matrices of real numbers by applying the truncation entrywise.

Deﬁnition 7.2 (Planted Gaussian Matrix: PGM(p¯; „¯; t¯)). This is the distribution on p¯×p¯ matrices X = (Xij ) whose entries are independent truncated Gaussians [N („¯ij ; 1)]t¯. Here „¯ = („¯ij ) is any p¯ × p¯ matrix with real entries.

Deﬁnition 7.3 (Planted Submatrix Detection: Submat(p¯; k¯; –¯; t¯) [MW15]). Let p¯ = !(1), k¯ ≤ p¯, and t¯ be non-decreasing positive integer sequences. Let –¯ be a sequence of positive numbers. This is the hypothesis testing problem (with p¯, k¯, [–¯]t¯, and t¯ part of the input.) induced by H0(p¯) = PGM(p¯; 0p¯; t¯)28 and

H1(p¯)

=

˘ PGM(p¯;

„¯;

t¯)

:

∃U;

V

⊂ [p¯]

such

that

|U|; |V | ≥ k¯; „¯ij

≥ –¯

if

(i ; j) ∈ U × V; „¯ij

=0

¯ otherwise :

Lemma 7.4 ([MW15]’s reduction from planted clique to Submat(p¯; k¯; –¯; t¯) can be implemented in multiple access randomized logspace). Let ‘ = !(1), ks , p¯, !(1) = k¯ ≤ p¯, and t¯ = ⌈4 log p¯⌉ be non-decreasing sequences of positive integers. Let –¯ be a sequence of positive numbers. Suppose 20k¯ = ks = O(‘1−‹) for some constant ‹ > 0. Further, p¯ is a factor of ‘·2ks such that 2ks ≤ p¯ ≤ ‘·2ks and –¯ ≤ (‘·ks )√6p¯log(‘·ks ) . Assume that ks , p¯, and [–¯]t¯ can be computed and stored given ‘ using O(log ‘) bits of space.
If there is a randomized logspace algorithm that solves Submat(p¯; k¯; –¯; t¯), there is a multiple access randomized logspace algorithm that solves kPCD(‘ · ks ; ks ) (or clkPCD(‘ · ks ; ks )) using at most O((‘ · ks )2 log ‘) multiple access random bits.

Proof. Because of the reduction in Lemma 8.2, it suﬃces to demonstrate a multiple access randomized logspace algorithm that solves PCD(‘·ks ; ks ) using at most O((‘·ks )2 log ‘) multiple access random bits. We show that the reduction from [MW15, Theorem 4] can yield such an algorithm since k¯ = !(1).
Our parameters are slightly more constrained than the corresponding parameters in [MW15]. However, since we have only introduced (rather than removed) constraints, the reduction’s proof of correctness from [MW15] carries over unchanged, and we only need to reason about its space complexity. These extra constraints are extremely mild and technical, and do not aﬀect the scaling of any parameters involved. They ensure that the number of vertices (‘·ks ) is an integral multiple of the number of planted clique vertices (ks ) because we want to reduce from k-partite versions of the clique problem. Further, they ensure ks, p¯, and [–¯]t¯ can be stored and computed given ‘ using O(log ‘) bits of space. The ﬁrst of these is useful in downstream applications when we need to invoke our randomness harvesting lemmas
280p¯ denotes the p¯ × p¯ all zeros matrix.

28

from Sections 5.2 and 5.3. The latter are useful in our current proof to ensure our algorithm ‘knows’ the size of the Submat instance it should reduce to29.

Let S be a randomized logspace algorithm that solves Submat(p¯; k¯; –¯; t¯). Let S′ be a multiple access

randomized algorithm that has Θ((‘ · ks )2 log ‘) multiple access random bits and {‘ · ks ; ks ; AG} as

input corresponding to PCD(‘ · ks ; ks ). Sp′ can compute and store p¯ and k¯ (and hence t¯ and [–¯]t¯)

using O(log ‘) bits of space. Let M¯ :=

6 log(‘ · ks ),

—¯

:=

1 2M¯

,

w¯

:=

t¯ + 6⌈log(‘ · ks )⌉,

and

T¯

:=

⌈log M¯ ⌉ + w¯ + 3⌈log(‘ · ks )⌉. Let Q0 and Q1 be two distributions (to be deﬁned later) on the support of

[−M¯ ; M¯ ]w¯ . Any sample from either distribution can be described using ⌈log M¯ +⌉ + w¯ = O(log ‘) bits.

Further assume (an assumption we will justify in the ﬁnal paragraph of this proof) that sampling an independent sample from either of them can be done using O(log ‘) bits of space and T¯ independent

uniform random bits.

Deﬁne the integer

N2 :=

‘·ks 2

and let B0

(respectively

B1) be a N2 × N2

matrix ﬁlled with independent

sample from Q0 (respectively Q1). S′ can provide multiple access to entries of B0 and B1 since it has

multiple access to 2·N22·T¯ = O((‘·ks )2 log ‘) independent uniform random bits. Letting A ∈ {0; 1}N2×N2

be the lower left quarter of the input adjacency matrix AG, deﬁne B as the N2 × N2 matrix whose

(i ; j)th entry is B0ij (1 − A0ij ) + B1ij (A0ij ). Noting that p¯ divides N2 by assumption, partition B into

(

N2 p¯

)2

consecutive

blocks

of

size

p¯ ×

p¯

and

let

X

denote

the

p¯ ×

p¯

matrix

that

is

the

sum

of

all

blocks

divided by

N2 p¯

.

Clearly S′ can provide multiple access to entries of X.

S′ now outputs the answer

given by S when invoked on a [X]t¯ along with the corresponding parameters. Since p¯ ≤ poly(‘), S′

can simulate this call to S.

To complete the proof, we justify that the distributions Q0 and Q1 used by [MW15] can indeed be sampled from using T¯ independent uniform random bits and O(log ‘) bits of space. Remark 5 in [MW15] describes how the ‘inverse CDF’ technique can be used to do this if we can compute any desired entry in the CDF (equivalently pmf) of either distribution. This technique can easily be implemented space eﬃciently using linear search because the support of each distribution has at most M¯ 2w¯+1 ≤ poly(‘) elements. Hence we only need that the probability of any sample of either distribution can be computed using O(log ‘) bits of space. These values are all, by construction, representable using T¯ bits of space. Further, they are T¯ bit truncations of real numbers deﬁned using simple univariate operations such as addition, subtraction, multiplication, division, and integration of smooth functions, which can all be computed up to s bits of accuracy using O(s) bits of space. Computing all these operations using some large enough constant multiple of T¯ bits of precision (which is still O(log ‘)) will give us a number whose ﬁrst T¯ bits are indeed the correct pmf value. Hence each of these values can be computed using O(log ‘) bits of space.

Theorem 3 (Logspace hardness of planted submatrix detection (Restricted parameter range)).

Let

p¯,

k¯,

–¯

and

t¯

be

as

described

in

Lemma

7.4

with

the

additional

constraint

that

k¯

=

O

(‘

1 2

−

‹

)

for

some

constant ‹ > 0. If the logspace k-partite planted clique conjecture kPC-Conj-Space (Conjecture 5.5) is true, no randomized logspace algorithm can solve Submat(p¯; k¯; –¯; t¯).

Proof.

Let

k

=

m

=

⌈‘1−

‹ 2

⌉

be

non-de`cre´asin`g

posi´tive

integer

sequences.

ks

= 20k¯

= O(‘ 21 −‹),

which

gives O((‘ · ks )2 log ‘) = o(‘ · k · m) ≤

‘·k 2

−

‘·k−m 2

for large enough ‘. Combining Lemma 5.6 (using

ks , k, and m as deﬁned) with Lemma 7.4 and using the fact that ks and m are computable from ‘

using O(log ‘) bits of space completes the proof.

29[MW15] does not need these technical conditions because they use a (very weakly) non-uniform hardness assumption.

29

An

example

illustrates

the

impact

of

the

restriction

k¯

=

O

(‘

1 2

−

‹

)

required

in

Theorem

3.

Consider

parameter

sequences

such

that

–¯

=

Θ(1=√log p¯)

and

k¯

=

Θ

(p¯

1 3

).

Even

though

we

believe

that

a

sub-

matrix detection instance with such parameters can not be solved by randomized logspace algorithms,

we can not use Theorem 3 to show this. We can, however, use Theorem 4 to circumvent this restriction.

Theorem 4 (Logspace hardness of planted submatrix detection). Let p¯, k¯, –¯ and t¯ be as described in Lemma 7.4. If the clique leakage logspace k-partite planted clique
conjecture clkPC-Conj-Space (Conjecture 5.10) is true, no randomized logspace algorithm can solve Submat(p¯; k¯; –¯; t¯).

Proof.

Let k

=

⌈‘1`−

‹ 2

⌉´

be

a

non-decreasing

positive

integer

sequence.

Since ks

= O(‘1−‹), we have

O((‘ · ks )2 log ‘) ≤

‘·k 2

for large enough ‘. Combining Lemma 5.11 (using ks and k as deﬁned) with

Lemma 7.4 and using the fact that ks is computable from ‘ using O(log ‘) bits of space completes the

proof.

7.3 Testing Almost k-wise Independence [AAK+07]

Deﬁnition 7.5 ((›¯; k¯)-wise Independence: Deﬁnition 2.1 in [AAK+07]).

A distribution D supported on {0`; 1}n¯ is (›¯; k¯)´-wise independent if for any k¯ indices i1 < i2 < ::: < ik¯

and any vector v ∈ {0; 1}k¯ , | P xi1:::xi¯ = v − 2−k¯| ≤ ›¯. Let D(›¯;k¯) denote the set of all (›¯; k¯)-wise

x ∼D

k

independent distributions.

Deﬁnition 7.6 (Testing (›¯; k¯)-wise vs (›¯′; k¯)-wise Independence: Indep(n¯; k¯; ›¯; ›¯′; s¯)). Let n¯ = !(1), k¯ ≤ n¯, and s¯ ≤ poly(n¯) be non-decreasing positive integer sequences. Let 0 < ›¯ < ›¯′ < 1
be sequences. The input consists of all the aforementioned parameters and s¯ independent samples from a distribution D supported on {0; 1}n¯. This is the hypothesis testing problem induced by

n

o

n

o

H0(n¯) = D : D ∈ D(›¯;k¯) and H1(n¯) = D : D ∈= D(›¯′;k¯) :

Lemma 7.7 ([AAK+07]’s reduction from PCD(n; k) to Indep(n¯; k¯; ›¯; ›¯′; s¯) can be implemented in mul-

tiple access randomized logspace).

Let

0

<

¸

≤

1

and

‹

>

0

be

any

constants

and

let

‘

=

!(1),

n

=

2‘,

!(log2

n)

=

k

=

O

(n

1 2

−

‹

),

k¯

=

1 + ‘,

n¯ =

k¯
2¸,

and

s¯ ≤

poly(n¯)

be

non-decreasing

positive

integer

sequences.

Deﬁne

sequences

0

<

›¯ <

›¯′

<

1

as ›¯ := 2¸ lon¯g¸2(n¯) and ›¯′ := kn¯−¸2 . Assume that s¯ can be computed and stored using O(log n) bits of space given n and k.

If there is a randomized logspace algorithm that solves Indep(n¯; k¯; ›¯; ›¯′; s¯), there is a multiple access randomized logspace algorithm that solves PCD(n; k).

Proof. The proof is a straightforward observation that the reduction of [AAK+07] can be implented using a multiple access randomized logspace algorithm. We only reason about the space complexity of this reduction. Its correctness follows immediately from the analysis in [AAK+07]. Let S be any randomized logspace algorithm that solves Indep(n¯; k¯; ›¯; ›¯′; s¯).
Let S′ be a multiple access randomized logspace algorithm that receives as input an instance {n; k; AG} of PCD(n; k). It can store and compute all the parameters n¯; k¯; ›¯; ›¯′; s¯ using O(log n) bits of space. Consider a matrix B ∈ {0; 1}n×n¯ whose ﬁrst n columns are the adjacency matrix AG augmented with

30

independent uniform random bits on the diagonal. The last n¯ − n columns of B consists entirely of more independent uniform random bits. Because S′ has multiple access to poly(n) independent uniform random bits (and n¯ ≤ poly(n)), it can simulate multiple access to B. Consider a further ‘ · s¯ multiple access random bits. S′ can use them to simulate multiple access to s¯ independent uniformly random rows of B. S′ interprets these rows as s¯ samples from a distribution on {0; 1}n¯, invokes S on them, and outputs S’s answer. S′ can do this because s¯· n¯ ≤ poly(n), so invoking S takes O(log n) bits of space. [AAK+07] shows that S′ solves PCD(n; k).
Combining Lemma 7.7 with Lemma 5.17 immediately yields the following.
Theorem 5 (Logspace hardness of testing almost k-wise independence). Let n¯, k¯, ›¯, ›¯′, and s¯ be as deﬁned in Lemma 7.7. If the clique leakage logspace hypergraph planted clique conjecture clHPC-Conj-Space (Conjecture 5.16) is true, no randomized logspace algorithm can solve Indep(n¯; k¯; ›¯; ›¯′; s¯).
[AAK+07] also consider a diﬀerent formalization of the testing problem. However, they show that this other problem is equivalent to Indep(n¯; k¯; ›¯; ›¯′; s¯). That is, the two problems are related by the identity reduction. This is why we have only focused on Indep(n¯; k¯; ›¯; ›¯′; s¯).

8 Auxiliary Lemmas

Lemma 8.1 (Space eﬃcient uniformly random permutation from uniform random bits). Let n = !(1) and r be non-decreasing positive integer sequences. Suppose 10n(⌈log n⌉)2 ≤ r ≤ poly(n). Given r independent uniform random bits, there is a random function ı : [n] → [n] with the following
properties.

• Given multiple access to the r random bits, ı(i ) can be computed using a further O(log n) bits of space when given any i ∈ [n].

• Th“e total v“ariation”d”istance between ı and a uniformly random permutation from [n] → [n] decays as

O

n · exp

−r 2n⌈log n⌉

.

Proof. Divide the r random bits into contiguous chunks of size ⌈log n⌉30. Each chunk represents an integer in [2⌈log n⌉]. Deﬁne ı : [n] → [n] as follows. Enumerating over chunks in the natural ordering, let ı(i ) be the i th distinct integer in [n] that we see represented by the random bits in a chunk. If
there are fewer than i distinct integers in [n] represented in all the chunks combined, let ı(i ) be any
ﬁxed integer in [n].

To compute ı(i ), we maintain three O(log n) bit counters. Using the ﬁrst counter, we enumerate over chunks in the natural ordering. We increment the second counter every time we see a chunk whose random bits represent an integer in [n] we have not seen so far. We can do this as follows. Every time the ﬁrst counter sees an integer in [n], we use the third counter to enumerate over all previous chunks to check if we have already seen that integer. Once the second counter reaches i , we output the integer represented in the corresponding chunk as ı(i ). If the ﬁrst counter has enumerated over all chunks and the second counter does not reach i , output any ﬁxed value. This shows the space complexity of computing ı is as claimed.

St“andard “tail boun”d”s for the coupon collector problem imply that except with probability at most

O

n · exp

−r 2n⌈log n⌉

, each integer i ∈ [2⌈log n⌉] (and hence in [n]) is represented in at least one chunk.

30Formally, the jth chunk consists of the bits [j · ⌈log n⌉] \ [(j − 1) · ⌈log n⌉].

31

Conditioned on every integer in [n] being represented in at least one chunk, ı clearly deﬁnes a uniform random permutation. This proves the total variation bound using the well-known “conditioning on an event” property of total variation distance [BB19, Fact 3.1].

Lemma 8.2 (Reduction from k-Partite versions of Planted Clique to PCD). Let ‘ = !(1), r , and k be non-decreasing positive integer sequences such that r ≥ 10‘ · k(⌈log(‘ · k)⌉)2. Assume there is a multiple access randomized logspace algorithm that solves PCD(‘ · k; k) using at most r −10‘·k(⌈log(‘·k)⌉)2 multiple access random bits. Then there is a multiple access randomized logspace algorithm that solves kPCD(‘ · k; k) or clkPCD(‘ · k; k) using r multiple access random bits.
Proof. Use the ﬁrst 10‘·k(⌈log(‘·k)⌉)2 multiple access random bits to sample an eﬃciently computable random function ı : [‘·k] → [‘·k] using Lemma 8.1. Given an instance of kPCD(‘·k; k) or clkPCD(‘·k; k), invoke the algorithm for PCD(‘ · k; k) on the following graph and output the answer it gives. Given two vertices i ; j, there is an edge between them if and only if there is an edge between the vertices ı(i ) and ı(j) in the input graph. Clearly this construction gives a randomized logspace algorithm using r multiple access random bits. If ı were a uniformly random permutation, this new graph would be distributed as PCD(‘ · k; k). Since the total variation distance between ı and a uniformly random permutation is o(1), the data processing inequality for total variation distance [BB19, Fact 3.1] implies that the constructed algorithm solves our problem.

The following fact is folklore.

Lemma 8.3 (Maximum clique size in an Erd˝os-R´enyi hypergraph HGs (n; 1=2)).

For n = !(1), with probability at least 1 − o(1), the size of the largest clique in an Erdo˝s-R´enyi

hypergraph

HGs (n; 1=2)

is

1
O((log n) s−1 ).

Pofrosoizf.e Tt h≥is sfolbloewinsgfraomcliqauseimispl2e−u(nst)i.onSbinocuendthaerrgeumareen`t.n´Tvheertperxobsaubbisliettys ooff asnizyeﬁtx,eda vuenritoenx bsuobusnedt

implies

that

the

probability

of

there

existing

a

clique

t
of size

t

is

upper

bounded

by

`n´ · 2−(st).

If

t

1

t = !((log n) s−1 ), this upper bound is o(1).

Acknowledgments
We would like to thank Yanjun Han, Ray Li, and Greg Valiant for helpful discussions and feedback that improved the presentation of these results.

References

[AAK+07]

Noga Alon, Alexandr Andoni, Tali Kaufman, Kevin Matulef, Ronitt Rubinfeld, and Ning Xie. Testing k-wise and almost k-wise independence. In Proceedings of the thirty-ninth annual ACM symposium on Theory of computing, pages 496–505, 2007. 1, 4, 5, 11, 12, 14, 15, 30, 31

[AB09]

Sanjeev Arora and Boaz Barak. Computational complexity: a modern approach. Cambridge University Press, 2009. 2, 4

[ABI97]

Eric Allender, Jos´e Balc´azar, and Neil Immerman. A ﬁrst-order isomorphism theorem. SIAM Journal on Computing, 26(2):557–567, 1997. 3

32

[ABW10]

Benny Applebaum, Boaz Barak, and Avi Wigderson. Public-key cryptography from different assumptions. In Proceedings of the forty-second ACM symposium on Theory of computing, pages 171–180, 2010. 14

[AKS98]

Noga Alon, Michael Krivelevich, and Benny Sudakov. Finding a large hidden clique in a random graph. Random Structures & Algorithms, 13(3-4):457–466, 1998. 15

[AS03]

Argimiro A Arratia and Iain A Stewart. A note on ﬁrst-order projections and games. Theoretical computer science, 290(3):2085–2093, 2003. 3

[AV11]

Brendan PW Ames and Stephen A Vavasis. Nuclear norm minimization for the planted clique and biclique problems. Mathematical programming, 129(1):69–89, 2011. 15

[BABB19]

Enric Boix-Adser`a, Matthew Brennan, and Guy Bresler. The average-case complexity of counting cliques in erdo˝s-r´enyi hypergraphs. In 2019 IEEE 60th Annual Symposium on Foundations of Computer Science (FOCS), pages 1256–1280. IEEE, 2019. 16

[BB19]

Matthew Brennan and Guy Bresler. Optimal average-case reductions to sparse pca: From weak assumptions to strong hardness. arXiv preprint arXiv:1902.07380, 2019. 14, 15, 21, 27, 28, 32

[BB20]

Matthew Brennan and Guy Bresler. Reducibility and statistical-computational gaps from secret leakage. In Jacob Abernethy and Shivani Agarwal, editors, Proceedings of Thirty Third Conference on Learning Theory, volume 125 of Proceedings of Machine Learning Research, pages 648–847. PMLR, 09–12 Jul 2020. 1, 2, 3, 8, 10, 11, 12, 13, 14, 15, 16

[BBH18]

Matthew Brennan, Guy Bresler, and Wasim Huleihel. Reducibility and computational lower bounds for problems with planted sparse structure. In S´ebastien Bubeck, Vianney Perchet, and Philippe Rigollet, editors, Proceedings of the 31st Conference On Learning Theory, volume 75 of Proceedings of Machine Learning Research, pages 48–166. PMLR, 06–09 Jul 2018. 14

[BBH19]

Matthew Brennan, Guy Bresler, and Wasim Huleihel. Universality of computational lower bounds for submatrix detection. In Conference on Learning Theory, pages 417–468. PMLR, 2019. 15

[BHK+19]

Boaz Barak, Samuel Hopkins, Jonathan Kelner, Pravesh K Kothari, Ankur Moitra, and Aaron Potechin. A nearly tight sum-of-squares lower bound for the planted clique problem. SIAM Journal on Computing, 48(2):687–735, 2019. 15

[BI13]

Cristina Butucea and Yuri I Ingster. Detection of a sparse submatrix of a high-dimensional noisy matrix. Bernoulli, 19(5B):2652–2688, 2013. 15

[BKR+11]

Sivaraman Balakrishnan, Mladen Kolar, Alessandro Rinaldo, Aarti Singh, and Larry Wasserman. Statistical and computational tradeoﬀs in biclustering. In NIPS 2011 workshop on computational trade-oﬀs in statistical learning, volume 4, 2011. 15

[BNS92]

La´szlo´ Babai, Noam Nisan, and M´ario´ Szegedy. Multiparty protocols, pseudorandom generators for logspace, and time-space trade-oﬀs. Journal of Computer and System Sciences, 45(2):204–232, 1992. 13

[BR13a]

Quentin Berthet and Philippe Rigollet. Complexity theoretic lower bounds for sparse principal component detection. In Conference on Learning Theory, pages 1046–1066. PMLR, 2013. 1, 2, 4, 5, 7, 12, 14, 15, 26, 27, 28

33

[BR13b]

Quentin Berthet and Philippe Rigollet. Optimal detection of sparse principal components in high dimension. The Annals of Statistics, 41(4):1780–1815, 2013. 2, 15

[CLR17]

T Tony Cai, Tengyuan Liang, and Alexander Rakhlin. Computational and statistical boundaries for submatrix localization in a large noisy matrix. The Annals of Statistics, 45(4):1403–1430, 2017. 15

[CNS96]

Jin-yi Cai, Ashish V Naik, and D Sivakumar. On the existence of hard sparse sets under weak reductions. In Annual Symposium on Theoretical Aspects of Computer Science, pages 307–318. Springer, 1996. 5

[CT21]

Lijie Chen and R. Tell. Hardness vs randomness, revised: Uniform, non-black-box, and instance-wise. Electron. Colloquium Comput. Complex., 28:80, 2021. 15

[CX14]

Yudong Chen and Jiaming Xu. Statistical-computational tradeoﬀs in planted problems and submatrix localization with a growing number of clusters and submatrices. arXiv preprint arXiv:1402.1267, 2014. 15

[CX16]

Yudong Chen and Jiaming Xu. Statistical-computational tradeoﬀs in planted problems and submatrix localization with a growing number of clusters and submatrices. The Journal of Machine Learning Research, 17(1):882–938, 2016. 15

[Dah83]

Elias Dahlhaus. Reduction to np-complete problems by interpretations. In Symposium on Recursive Combinatorics, pages 357–365. Springer, 1983. 3

[DGGP14] Yael Dekel, Ori Gurel-Gurevich, and Yuval Peres. Finding hidden cliques in linear time with high probability. Combinatorics, Probability and Computing, 23(1):29–49, 2014. 15

[DGR00]

Scott E Decatur, Oded Goldreich, and Dana Ron. Computational sample complexity. SIAM Journal on Computing, 29(3):854–879, 2000. 1

[DKWB19] Yunzi Ding, Dmitriy Kunisky, Alexander S Wein, and Afonso S Bandeira. Subexponentialtime algorithms for sparse pca. arXiv preprint arXiv:1907.11635, 2019. 15 p
[DM15a] Yash Deshpande and Andrea Montanari. Finding hidden cliques of size N=e in nearly linear time. Foundations of Computational Mathematics, 15(4):1069–1128, 2015. 15

[DM15b]

Yash Deshpande and Andrea Montanari. Improved sum-of-squares lower bounds for hidden clique and hidden submatrix problems. In Conference on Learning Theory, pages 523–562, 2015. 15

[FGR+17]

Vitaly Feldman, Elena Grigorescu, Lev Reyzin, Santosh S Vempala, and Ying Xiao. Statistical algorithms and a lower bound for detecting planted cliques. Journal of the ACM (JACM), 64(2):1–37, 2017. 15

[FK00]

Uriel Feige and Robert Krauthgamer. Finding and certifying a large hidden clique in a semirandom graph. Random Structures & Algorithms, 16(2):195–208, 2000. 15

[FK03]

Uriel Feige and Robert Krauthgamer. The probable value of the lov´asz–schrijver relaxations for maximum independent set. SIAM Journal on Computing, 32(2):345–370, 2003. 15

[FR10] Uriel Feige and Dorit Ron. Finding hidden cliques in linear time. 2010. 15

[GMZ17]

Chao Gao, Zongming Ma, and Harrison H Zhou. Sparse cca: Adaptive estimation and computational barriers. The Annals of Statistics, 45(5):2074–2101, 2017. 14

34

[GW02]

Oded Goldreich and Avi Wigderson. Derandomization that is rarely wrong from short advice that is typically good. In International Workshop on Randomization and Approximation Techniques in Computer Science, pages 209–223. Springer, 2002. 1, 6, 15

[GZ19]

David Gamarnik and Ilias Zadik. The landscape of the planted clique problem: Dense subgraphs and the overlap gap property. arXiv preprint arXiv:1904.07174, 2019. 15

[HK11]

Elad Hazan and Robert Krauthgamer. How hard is it to approximate the best nash equilibrium? SIAM Journal on Computing, 40(1):79–91, 2011. 14

[HKP+17]

Samuel B Hopkins, Pravesh K Kothari, Aaron Potechin, Prasad Raghavendra, Tselil Schramm, and David Steurer. The power of sum-of-squares for detecting hidden structures. In 2017 IEEE 58th Annual Symposium on Foundations of Computer Science (FOCS), pages 720–731. IEEE, 2017. 15

[HKP+18]

Samuel B Hopkins, Pravesh Kothari, Aaron Henry Potechin, Prasad Raghavendra, and Tselil Schramm. On the integrality gap of degree-4 sum of squares for planted clique. ACM Transactions on Algorithms (TALG), 14(3):1–31, 2018. 15

[Hop18]

Samuel Hopkins. Statistical inference and the sum of squares method. PhD thesis, Cornell University, 2018. 15

[Hoz17]

William M Hoza. Typically-correct derandomization for small time and space. arXiv preprint arXiv:1711.00565, 2017. 6, 15

[HS17]

Samuel B Hopkins and David Steurer. Bayesian estimation from few samples: community detection and related problems. arXiv preprint arXiv:1710.00264, 2017. 15

[HW12]

Lane A Hemaspaandra and Ryan Williams. Sigact news complexity theory column 76: an atypical survey of typical-case heuristic algorithms. ACM SIGACT News, 43(4):70–89, 2012. 6

[HWX15]

Bruce Hajek, Yihong Wu, and Jiaming Xu. Computational lower bounds for community detection on random graphs. In Conference on Learning Theory, pages 899–928. PMLR, 2015. 14, 15

[Imm12] Neil Immerman. Descriptive complexity. Springer Science & Business Media, 2012. 3

[INW94]

Russell Impagliazzo, Noam Nisan, and Avi Wigderson. Pseudorandomness for network algorithms. In Proceedings of the twenty-sixth annual ACM symposium on Theory of computing, pages 356–364, 1994. 13

[Jer92]

Mark Jerrum. Large cliques elude the metropolis process. Random Structures & Algorithms, 3(4):347–359, 1992. 15, 16

[KBRS11]

Mladen Kolar, Sivaraman Balakrishnan, Alessandro Rinaldo, and Aarti Singh. Minimax localization of structural information in large noisy matrices. In Advances in Neural Information Processing Systems, pages 909–917, 2011. 15

[Kuˇc95]

Ludˇek Kuˇcera. Expected complexity of graph partitioning problems. Discrete Applied Mathematics, 57(2-3):193–212, 1995. 15

[KVM02]

Adam R Klivans and Dieter Van Melkebeek. Graph nonisomorphism has subexponential size proofs unless the polynomial-time hierarchy collapses. SIAM Journal on Computing, 31(5):1501–1526, 2002. 13, 14

35

[KvMS12]

Jeﬀ Kinne, Dieter van Melkebeek, and Ronen Shaltiel. Pseudorandom generators, typically-correct derandomization, and circuit lower bounds. Computational Complexity, 21(1):3–61, 2012. 15

[KWB19]

Dmitriy Kunisky, Alexander S Wein, and Afonso S Bandeira. Notes on computational hardness of hypothesis testing: Predictions using the low-degree likelihood ratio. arXiv preprint arXiv:1907.11636, 2019. 15

[Li17]

Jerry Li. Robust sparse estimation tasks in high dimensions. arXiv:1702.05860, 2017. 2

arXiv preprint

[LZ20]

Yuetian Luo and Anru R Zhang. Tensor clustering with planted structures: Statistical optimality and computational limits. arXiv preprint arXiv:2005.10743, 2020. 16

[MAC20]

Jay Mardia, Hilal Asi, and Kabir Aladin Chandrasekher. Finding planted cliques in sublinear time. arXiv preprint arXiv:2004.12002, 2020. 8, 15

[Mar20]

Jay Mardia. Is the space complexity of planted clique recovery the same as that of detection? arXiv preprint arXiv:2008.12825, 2020. 2, 13

[MI94]

J Antonio Medina and Neil Immerman. A syntactic characterization of np-completeness. In Proceedings Ninth Annual IEEE Symposium on Logic in Computer Science, pages 241– 250. IEEE, 1994. 3

[MMS20]

Ankur Moitra, Elchanan Mossel, and Colin Sandon. Parallels between phase transitions and circuit complexity? In Conference on Learning Theory, pages 2910–2946. PMLR, 2020. 2

[MPW15]

Raghu Meka, Aaron Potechin, and Avi Wigderson. Sum-of-squares lower bounds for planted clique. In Proceedings of the forty-seventh annual ACM symposium on Theory of computing, pages 87–96, 2015. 15

[MRS21]

Pasin Manurangsi, Aviad Rubinstein, and Tselil Schramm. The strongish planted clique hypothesis and its consequences. In 12th Innovations in Theoretical Computer Science Conference (ITCS 2021). Schloss Dagstuhl-Leibniz-Zentrum fu¨r Informatik, 2021. 15

[MRZ15]

Andrea Montanari, Daniel Reichman, and Ofer Zeitouni. On the limitation of spectral methods: From the gaussian hidden clique problem to rank-one perturbations of gaussian tensors. Advances in Neural Information Processing Systems, 28:217–225, 2015. 15

[MW15]

Zongming Ma and Yihong Wu. Computational barriers in minimax submatrix detection. The Annals of Statistics, 43(3):1089, 2015. 1, 4, 5, 7, 8, 12, 14, 15, 28, 29

[Nis92]

Noam Nisan. Pseudorandom generators for space-bounded computation. Combinatorica, 12(4):449–461, 1992. 13

[Nis93]

Noam Nisan. On read once vs. multiple access to randomness in logspace. Theoretical Computer Science, 107(1):135–144, 1993. 5

[OZ18]

Ryan O’Donnell and Yu Zhao. On closeness to k-wise uniformity. arXiv preprint arXiv:1806.03569, 2018. 15

[Ros08]

Benjamin Rossman. On the constant-depth complexity of k-clique. In Proceedings of the fortieth annual ACM symposium on Theory of computing, pages 721–730, 2008. 15

36

[Ros10]

Benjamin Rossman. The monotone complexity of k-clique on random graphs. In 2010 IEEE 51st Annual Symposium on Foundations of Computer Science, pages 193–201. IEEE, 2010. 15

[RWYZ21] Cyrus Rashtchian, David P Woodruﬀ, Peng Ye, and Hanlin Zhu. Average-case communication complexity of statistical problems. arXiv preprint arXiv:2107.01335, 2021. 2

[Sak96]

Michael Saks. Randomization and derandomization in space-bounded computation. In Proceedings of Computational Complexity (Formerly Structure in Complexity Theory), pages 128–149. IEEE, 1996. 4

[Ser99]

Rocco A Servedio. Computational sample complexity and attribute-eﬃcient learning. In Proceedings of the thirty-ﬁrst annual ACM symposium on Theory of Computing, pages 701–710, 1999. 1

[Sha92] Adi Shamir. Ip= pspace. Journal of the ACM (JACM), 39(4):869–877, 1992. 2

[Sha10]

Ronen Shaltiel. Typically-correct derandomization. ACM SIGACT News, 41(2):57–72, 2010. 6

[Val84]

Leslie G Valiant. A theory of the learnable. Communications of the ACM, 27(11):1134– 1142, 1984. 1

[VM98]

Dieter Van Melkebeek. Deterministic and randomized bounded truth-table reductions of p, nl, and l to sparse sets. Journal of Computer and System Sciences, 57(2):213–232, 1998. 5

[WBS16]

Tengyao Wang, Quentin Berthet, and Richard J Samworth. Statistical and computational trade-oﬀs in estimation of sparse principal components. The Annals of Statistics, 44(5):1896–1930, 2016. 2, 15

[Wig19] Avi Wigderson. Mathematics and computation. Princeton University Press, 2019. 4

[ZX18]

Anru Zhang and Dong Xia. Tensor svd: Statistical and computational limits. IEEE Transactions on Information Theory, 64(11):7311–7338, 2018. 16

37

