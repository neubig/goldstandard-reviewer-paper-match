Whose Language Counts as High Quality? Measuring Language Ideologies in Text Data Selection
Suchin Gururangan† Dallas Card♦ Sarah K. Dreier♥ Emily K. Gade♣ Leroy Z. Wang† Zeyu Wang† Luke Zettlemoyer† Noah A. Smith†♠
†University of Washington ♦ University of Michigan ♥University of New Mexico ♣Emory University ♠Allen Institute for AI
{sg01, zwan4, lsz, nasmith}@cs.washington.edu dalc@umich.edu
skdreier@unm.edu emily.gade@emory.edu lryw@uw.edu

arXiv:2201.10474v2 [cs.CL] 26 Jan 2022

Abstract
Language models increasingly rely on massive web dumps for diverse text data. However, these sources are rife with undesirable content. As such, resources like Wikipedia, books, and newswire often serve as anchors for automatically selecting web text most suitable for language modeling, a process typically referred to as quality ﬁltering. Using a new dataset of U.S. high school newspaper articles—written by students from across the country—we investigate whose language is preferred by the quality ﬁlter used for GPT-3. We ﬁnd that newspapers from larger schools, located in wealthier, educated, and urban ZIP codes are more likely to be classiﬁed as high quality. We then demonstrate that the ﬁlter’s measurement of quality is unaligned with other sensible metrics, such as factuality or literary acclaim. We argue that privileging any corpus as high quality entails a language ideology, and more care is needed to construct training corpora for language models, with better transparency and justiﬁcation for the inclusion or exclusion of various texts.
1 Introduction
The language models central to modern NLP are trained on large Internet corpora, typically gathered from community resources (e.g., Wikipedia; Liu et al. 2019) or web dumps (e.g., WebText, Common Crawl; Radford et al. 2019, Brown et al. 2020). The selection of texts impacts every research or deployed NLP system that builds on these models. Yet there is rarely any explicit justiﬁcation for why various texts were included.
Web dumps like Common Crawl offer the promise of more diverse text than what is available in curated resources. However, much of the web consists of frequently replicated boilerplate (e.g., privacy policies), code (e.g., HTML and Javascript), pornography, hate speech, and more. Automated approaches, typically referred to as

quality ﬁlters,1 are often applied in an effort to remove this undesirable content from training data. These ﬁlters include code removers (Gao et al., 2020), heuristics (Rae et al., 2021), stopwords (Raffel et al., 2020), and classiﬁers (Brown et al., 2020; Wenzek et al., 2020).
Although quality ﬁltering is often treated as a relatively neutral preprocessing step, it necessarily implies a value judgment: which data is assumed to be of sufﬁciently high quality to be included in the training corpus? More concretely, when a quality ﬁlter is a classiﬁer trained on instances assumed to be of high (and low) quality, the selection of those examples will impact the language model and any downstream technology that uses it. Many ﬁlters use Wikipedia, books, and newswire to represent high quality text. But what texts are excluded as a result? Because natural language varies with social and demographic variables (Rickford, 1985; Eckert, 1989; Labov, 2006; Blodgett et al., 2016; Hovy and Yang, 2021; Lucy and Bamman, 2021, inter alia), we can also ask whose language will be excluded.
We begin with a summary of the handful of data sources used to construct training corpora for many language models and assumed to be of high quality (§2). The systematic authorship biases in these datasets motivate the study that follows, in which we replicate the quality ﬁlter from Brown et al. (2020). We apply this ﬁlter to a new dataset of U.S. high school newspapers, augmented (via ZIP codes and counties) with demographic data from the U.S. Census and the National Center for Education Statistics (§3). We demonstrate that the ﬁlter has strong topical and stylistic preferences, and favors text from authors who originate from regions with better educational attainment, urban centers, larger schools, and higher valued homes.
1We note that the term quality is often ill-deﬁned in the NLP literature. For example, Brown et al. (2020) and Wenzek et al. (2020) refer to “high-quality text” or “high-quality sources”—both citing Wikipedia as an example—but without explaining precisely what is meant.

In sociolinguistics, the term language ideology refers to common (but often unspoken) presuppositions, beliefs, or reﬂections about language that justify its social use and structure (Craft et al., 2020). Our analysis begins to characterize the language ideology encoded in the quality ﬁlter used by Brown et al. (2020), a representative of a wider set of ﬁltering methods. We also observe in §4 that the ﬁlter is unaligned with other notions of quality familiar from human endeavors: factuality ratings for news sources, standardized test scores, and literary awards. Of course, these institutions hold their own language ideologies. We argue that when constructing a corpus, one cannot avoid adopting some language ideology; the language ideology which is appropriate depends on the goals of the work, and one language ideology may conﬂict with another. In short, there is no truly general-purpose corpus.
Our code and analysis is publicly available.2
2 Motivation: Data Sources
Across the many language models recently reported in the literature, the same small group of datasets have been routinely used as training corpora— Wikipedia, collections of books, and popular online articles (§A.1). These data are often treated as exemplars of high quality text (Devlin et al., 2019; Liu et al., 2019; Radford et al., 2019; Raffel et al., 2020; Brown et al., 2020). Although these datasets include text from many sources, extensive research suggests that the voices they represent are drawn from a relatively small, biased sample of the population, over-representing authors from hegemonic social positions.
Wikipedia Wikipedia serves as a backbone for language models because of its scale, ease of use, permissive license, and goal of providing comprehensive coverage of human knowledge. However, although anyone can edit Wikipedia content, not everyone does. In practice, there are signiﬁcant biases in Wikipedia authorship, content, and perspectives. For instance, despite efforts by Wikimedia, the site has been unable to resolve a persistent gender imbalance among its editors (Huang, 2013; Meta-wiki, 2018). This imbalance is reﬂected in who gets written about, and how (Bamman and Smith, 2014; Graells-Garrido et al., 2015; Wagner et al., 2015). There is also a pervasive urban bias; editors are less likely to come from rural areas, and
2https://github.com/kernelmachine/ quality-filter

coverage of these areas in Wikipedia tends to be more limited (Mandiberg, 2020). Although coverage in English Wikipedia is not limited to those places where English is a majority language, an Anglo-American perspective dominates coverage.3 Lastly, a relatively small number of people are responsible for most of the content (Panciera et al., 2009; Matei and Britt, 2017). Wikipedia is thus less representative of language of the population than one might expect given its size and design.
Books Language models are also frequently trained on book corpora. BERT (Devlin et al., 2019) used the Toronto BookCorpus (Zhu et al., 2015), which consists of 7,185 self-published novels, a dataset criticized for copyright violation, poor quality control, imbalanced representation, and lack of documentation (Bandy and Vincent, 2021).
GPT-3 (Brown et al., 2020) and The Pile (Gao et al., 2020) both use much larger corpora of books (although the former do not identify the source of this data). However, the Pile’s books (also called Books3) are not a random selection. Rather, they appear to be drawn from a torrent ﬁle containing hundreds of thousands of copyrighted eBooks.
Books3 is deserving of a more thorough investigation, but preliminary analyses reveal that the most prevalent authors in the corpus are American and British writers, especially of romance, mystery, and children’s books (e.g., L. Ron Hubbard, Danielle Steel, etc.). This pattern should be considered against the background of the American book publishing industry, which has been widely criticized as homogeneous (Lee & Low Books, 2020).4
News and Other Popular Internet Content Radford et al. (2019) scrape text from the websites featured in popular Reddit submissions (i.e., those that received at least three upvotes) to construct the training data for GPT-2. As the original corpus is unavailable, we analyze its open-source replica, OpenWebText (Gokaslan and Cohen, 2019).
We do not expect the corpus to represent a wide range of language variation. Reddit users are mostly male, younger, and lean liberal, which inﬂuences the types of content shared on the platform.5
3For example, of the ten most frequently mentioned people in English Wikipedia, seven are U.S. Presidents, two are prominent ﬁgures in Christianity, and the only woman is the British monarch, Queen Victoria.
4This 2020 study found that Black people comprise only 5% of the industry, and books by men tend to generate disproportionately more attention than those by women.
5As of 2016, 71% of Reddit users are male, 59% are be-

URL Domain
bbc.co.uk theguardian.com washingtonpost.com nytimes.com reuters.com hufﬁngtonpost.com cnn.com cbc.ca dailymail.co.uk go.com

# Docs
116K 115K 89K 88K 79K 72K 70K 67K 58K 48K

% of Total Docs
1.50% 1.50% 1.20% 1.10% 1.10% 0.96% 0.93% 0.89% 0.77% 0.63%

Table 1: The most popular top-level URL domains in OpenWebText. Mainstream news forms the overwhelming majority of content in the dataset. Overall, just 1% of the top-level URL domains in OpenWebText contribute 75% of the total documents in the corpus.

Viral media on the Internet assume similar characteristics; they tend to elicit awe, anger, or anxiety (Berger and Milkman, 2012), validate group identities (Gaudette et al., 2021), and disseminate from users with authority (Weismueller et al., 2022).
Indeed, we ﬁnd that 1% of the 311K unique top-level domains in OpenWebText contribute 75% of documents in the corpus (Table 1). The most common websites in OpenWebText are internationally circulating British and American news outlets (e.g., BBC, The New York Times, The Washington Post, The Guardian), blogging platforms (e.g., Tumblr, Blogspot, or Medium), sports content (e.g., ESPN, SBNation), and tech news (e.g., TechCrunch, Wired). As expected, these links tend to appear on the most highly trafﬁcked subreddits (e.g., /r/politics, /r/worldnews, /r/news).
These data are likely dominated by formal writing styles. Among news organizations, the adherence to slowly evolving style guides expresses speciﬁc linguistic standards (Froke et al., 2020) and even geopolitical interests (Vultee, 2012), which encourage rules about language use that can reinforce gender norms and racial hierarchies (DiNicola, 1994; Bien-Aimé, 2016).
In general, a relatively homogeneous set of authors writes the majority of newswire (Grieco, 2018). Researchers ﬁnd a striking lack of diversity in newsrooms and newspaper leadership.6 This may be compounded by the economic hardships aspiring journalists must incur,7 which act as a ﬁlter
tween ages 18–29, and 43% identify as liberal (vs. 19% conservative): https://pewrsr.ch/3FLbNL7
6As of 2018, racial minorities make up 37% of the U.S. population, but only 17% of staff and 13% of leadership in U.S. newsrooms (Arana, 2018).
7In 2020, median salary for U.S. news analysis, reporters,

for who can afford to be employed in newsrooms.
Summary Authors from speciﬁc, relatively powerful social positions produce a disproportionate amount of text in the core data sources of existing language models. These text sources favor privileged segments of the English-speaking population, including men, white populations, communities of higher socio-economic status, and those harboring American and Western European historical, geopolitical, and cultural perspectives. By contrast, these corpora tend to be less inclusive of the voices of women and members of marginalized groups. Alternative perspectives, including those of people from rural areas, non-dominant gender, sexual, or racial identities, and counter-hegemonic vantage points, are less likely to be included, and thus less likely to inﬂuence models trained on this data.
Although formal, streamlined content like news or Wikipedia articles may seem like desirable sources for high quality content, not all writing styles or substantive topics that might be relevant to language technologies and their user communities are represented in the resulting corpora. When deployed, many of the technologies using language models trained on these data will face language that—despite being less formal, professional, or carefully edited—is no less high quality and is essential to the communicative lives of the people who use it.
3 Measuring the Language Ideology of the GPT-3 Quality Filter
Empirically evaluating the full distribution of authors in the data sources from §2 is difﬁcult, due to their size, as well as their lack of metadata about each document’s authors. We instead curate a new dataset of U.S. high school newspaper articles that varies both topically and along demographic variables that can be resolved using ZIP codes. Although we do not directly consider individual authors of these articles, this dataset is useful, in that it can be associated with extensive metadata at the level of individual newspapers. We then analyze the behavior of a (replicated) quality ﬁlter on text from this dataset and discuss its implications.
3.1 U.S. SCHOOL NEWS
Background Many U.S. schools produce a newspaper to give students journalism experience, to
and journalists was $35,950, a slight decrease from 2012 after adjusting for inﬂation: https://pewrsr.ch/3qCO75v

report on local news, to comment on national or global events, and to publish school-related material (e.g., announcements, campus life, student interviews, sports or honor rolls; Gibson, 1961). The substantive content of school newspapers varies considerably, possibly due to their local audiences. Because a school’s access to resources is shaped by local income levels (Betts et al., 2000) and tied to student achievement (Greenwald et al., 1996), we expect schools in wealthier areas (relative to poorer areas) to produce newspaper content that is more similar to the formal, professional texts that a quality ﬁlter is likely to classify as high quality.
Collection We collect articles from Englishlanguage U.S. school newspapers that used a common Wordpress template.8 After retrieving 2483 schools who use this template, we scrape 1.95M articles from their respective newspaper sites (more details in §A.2). We retrieve article categories by extracting them from the article URL slugs. We then resolve each school to its ZIP code using the Google Maps Place API.9 We restrict our dataset to articles from U.S. high schools. We only consider articles from 2010–2019, remove pages under the video, photo, or multimedia categories, and remove schools that have less than 100 articles (which tend to contain scraping errors). The ﬁnal corpus includes 910K articles, from 1410 schools, located in 1329 ZIP codes (552 counties) dispersed across all U.S. states (plus D.C.).
Limitations Our corpus is neither a random nor a representative sample of U.S. school newspapers. Instead, it represents schools that had sufﬁcient Internet access, that elected to use a particular website template, and that maintain websites with retrievable archived content. The lack of representation in school newspaper leadership positions may inﬂuence which students contribute content to school newspapers (Chen et al., 2021). Educators also likely shape some articles, at least in part (though we expect them to be similarly affected by resource constraints). Finally, much of the content in these articles is speciﬁc to student concerns (e.g., sports, school events, campus culture, etc.), and the writing is, by deﬁnition, amateur. Nevertheless, because the corpus captures a wide range of content and geographical areas, it allows us to evaluate
8SNOsites.com 9https://developers.google.com/maps/ documentation/places/web-service/ search-find-place?hl=en

how a quality ﬁlter handles real-world language variation, within a particular domain.
Using text from school newspapers introduces privacy concerns, especially since authors and subjects are minors. We therefore use this data only for evaluation purposes, and do not train (or release) any models on this data, or any raw text from the corpus. We do, however, release a Datasheet (Gebru et al., 2021) which documents the dataset’s general characteristics and curation procedure (§A.2).
3.2 The GPT-3 Quality Filter
To investigate how quality correlates with various attributes of a newspaper, we re-implement the Brown et al., 2020 quality ﬁlter based on the description provided in the paper. The ﬁlter is a binary logistic regression classiﬁer trained (using n-gram features) to distinguish between reference corpora (Books3, Wikipedia, and OpenWebText) and a random sample of Common Crawl.
We replicate the ﬁlter as closely as possible using scikit-learn (Pedregosa et al., 2011). To create the training data for the classiﬁer, we sample 80M whitespace-separated tokens of OpenWebText, Wikipedia, and Books3 each for the positive class, and 240M whitespace-separated tokens of a September 2019 Common Crawl snapshot for the negative class. We download the Common Crawl snapshot using code provided by Wenzek et al. (2020). We perform a 100-trial random hyperparameter search, ﬁxing only the hashing vectorizer and basic whitespace tokenization, following the implementation in Brown et al. (2020). See the search space and ﬁnal hyperparameters of our replicated ﬁlter in §A.3. Our ﬁnal classiﬁer gets 90.4% F1 (91.7% accuracy) on a set of 60M test tokens (30M held-out tokens from each class, or 72K documents from the negative class, and 33K from the positive class). We release code for training the quality ﬁlter and a demo of the trained ﬁlter.10,11 We apply the quality ﬁlter to the U.S. SCHOOL NEWS data, computing a quality score per document, which we denote P (high quality).
3.3 Document-Level Analysis
We ﬁrst explore document-level preferences of the ﬁlter. The GPT-3 quality ﬁlter is more likely to classify high school newspaper articles as low qual-
10https://github.com/kernelmachine/ quality-filter
11https://huggingface.co/spaces/ssgrn/ gpt3-quality-filter

Density

4 3 2 1 0 0.0
announcements campus-life clubs sports op-ed politics 0.0

Newswire High School 0.2 0.4 0.6 0.8 1.0 P(high quality) 0.2 0.4 0.6 0.8 1.0 P(high quality)

Article Category

Figure 1: Scraped school articles tend to be considered lower quality by the GPT-3 quality ﬁlter than general newswire (histogram built from 10K random documents from each domain). This ﬁnding is consistent across a variety of categories, and more signiﬁcant for certain ones (e.g., school announcements).

ity, compared to general newswire (Figure 1).12 This is unsurprising, since the training data for the GPT-3 quality ﬁlter included texts by professional journalists. §A.4 shows a random sample of text from the dataset with high and low quality scores, illustrating differences in style and formality.
More notably, controlling for article category (e.g., opinion pieces), we ﬁnd that the GPT-3 quality ﬁlter has topical and stylistic preferences (discovered through exploratory data analysis). For topical features, we train an topic model (via Latent Dirichlet Allocation; Blei et al. 2003) over opinion pieces with 10 topics using scikit-learn. We also consider whether documents contain ﬁrst, second, or third person pronouns, and the length of the document. We then combine these features in a regression model to assess the effect of particular attributes on the quality score of a document, while controlling for others.
The results of our regression are displayed in Table 2. We ﬁnd that certain topics have quite large effect sizes (see §A.5 for the distribution of quality scores per topic). For example, documents
12Here, the general newswire are articles from popular online news sources; see §4 for data details.

Dependent variable: P (high quality) Number of observations: 10K opinion articles

Feature

Coefﬁcient

Intercept Topic 5 (christmas, dress, holiday) Topic 2 (school, college, year) Topic 6 (student, school, class) Topic 1 (people, just, like) Topic 7 (movie, ﬁlm, movies) Topic 3 (music, album, song) Topic 4 (people, women, media) Topic 9 (game, team, players) Topic 8 (Trump, president, election) Presence of ﬁrst/second person pronoun Presence of third person pronoun log2(Number of tokens)

0.471∗∗∗ −0.056∗∗∗ −0.037∗∗∗
−0.004
0.003 0.062∗∗∗ 0.113∗∗∗ 0.197∗∗∗ 0.246∗∗∗ 0.346∗∗∗ −0.054∗∗∗
0.024 0.088∗∗∗

R2 adj. R2

0.336 0.336

Table 2: Regression of the quality score of an opinion piece in the U.S. SCHOOL NEWS dataset, on document features. We observe that political and sports-related topics, the lack of ﬁrst and second person pronouns, and longer document lengths are associated with higher quality scores. We omit Topic 0 (food, restaurant, eat) to avoid a saturated model. See §A.5 for the distribution of quality scores per topic. ∗p < 0.05, ∗∗p < 0.01, ∗∗∗p < 0.001.

entirely about Trump and the presidential election have quality scores 35 percentage points higher, on average, whereas documents about sports are 25 percentage points higher (relative to the omitted topic about food). Stylistically, the presence of ﬁrst or second pronouns in a document decreases quality score by 5 percentage points, while a doubling of the number of tokens in a document increases the quality score by 9 percentage points.
3.4 Demographic Analysis
Next, we examine whether the GPT-3 quality ﬁlter prefers language from certain demographic groups over others. We ﬁrst check raw correlations between average quality scores (per newspaper) and features of interest. As in §3.3, we then combine the features in a regression model.
Demographic Features As we note in §3.1, we expect a priori that content from schools located in wealthier, more educated, and urban areas of the U.S. will tend to have higher quality scores, relative to poorer, less educated, rural areas. Therefore, we consider demographic features that correspond to class, rural/urban divides, and school resources.
For each school, we retrieve 2017–2018 schoollevel demographic data from the National Center

for Education Statistics (NCES).13 These include the number of students, student:teacher ratio, and indicators for charter, private, and magnet schools. We also retrieve the latest ZIP code- and countylevel demographic data from the 2020 U.S. Census.14 To measure the wealth of the corresponding ZIP code, we use median home values, and for educational attainment we use the percentage of college-educated adults. We also use Census data on the percent of rural population by county. Finally, we consider local political leanings, operationalized by GOP vote share in the 2016 Presidential election, using county-level data from the MIT election lab.15 We display full descriptions of features in our demographic analysis in §A.6.
Correlation Analysis To inform the variables we include in our regressions, we explore correlations between variables of interest and the average quality score of a school newspaper. Our analyses in Figure 2 suggest that our initial hypotheses hold: schools in wealthier, urban, and more educated ZIP codes, as well as those in Democrat-leaning counties, tend to have higher quality scores.
Data Preprocessing Here, we use schools as the unit of analysis, and consider average quality score assigned to the school’s articles as the dependent variable. We only include those schools that could be matched to the NCES database, dropping schools which are missing school size, as well as those located in ZIP codes with $1M or greater median home value, due to a census artifact.16 Missing values for other features are imputed with the median value of that feature for the corresponding ZIP code, or (if necessary) county or state. For regressions, we log-transform school size, student:teacher ratio, and home values, using raw values for other features, to preserve interpretability. Our regression dataset includes 968 high schools, in 926 ZIP codes across 354 counties. All linear regressions are implemented with the statsmodels API.17 We release this anonymous dataset to support reproducibility.18
13https://nces.ed.gov/ccd/elsi/ tablegenerator.aspx
14https://data.census.gov/cedsci/ 15https://electionlab.mit.edu/data 16The census data we use imposes an artiﬁcial upper bound on housing prices over $1M. 17https://www.statsmodels.org/stable/ index.html 18https://github.com/kernelmachine/ quality-filter

P(high quality)

P(high quality)

r: 0.27 0.7 0.6 0.5 0.4 0.3 0.2 0.1
50K 100K 250K 500K 1M Median Home Value r: -0.33
0.7 0.6 0.5 0.4 0.3 0.2 0.1
0 20 40 60 80 % 2016 GOP Vote

P(high quality)

P(high quality)

r: 0.30 0.7 0.6 0.5 0.4 0.3 0.2 0.1
20 40 60 80 % Adults Bachelor Degrees
r: -0.30 0.7 0.6 0.5 0.4 0.3 0.2 0.1
0 20 40 60 80 100 % Rural

Figure 2: Scatter plots displaying correlations of select demographic features of a school’s ZIP code or county with its average P (high quality).

Regression Analysis Because the variables identiﬁed above are correlated with each other, we use regression to estimate the effect of certain factors while controlling for others, with results shown in Table 3. Overall, home values, parental education, school size, public school status, and urban locations all show signiﬁcant positive associations with quality scores. Thus, even controlling for ﬁnancial resources, parental education, and other factors, articles from rural schools are still scored as signiﬁcantly lower quality than those from urban schools.
Nevertheless, the effects, considered individually, are relatively modest. A 14 percentage point increase in percent urban population or a 17 percentage point increase in parental education (percent of adults with college degrees) correspond to a 1 percentage point increase in average quality score, as does a doubling of home values, or a quadrupling of school size. Average quality scores associated with public schools are 1.5 percentage points higher than private schools, controlling for other factors. Coefﬁcients for charter schools, magnet schools, and student:teacher ratio are all sensible, though none are signiﬁcant. Altogether, the combined effects of all these factors account for large differences in quality scores between wealthy, urban, educated locations, and poorer, rural, and less educated parts of the country.

Dependent variable: P (high quality) Observations: 968 schools

Feature

Coefﬁcient

Intercept % Rural % Adults ≥ Bachelor Deg. log2(Median Home Value) log2(Number of students) log2(Student:Teacher ratio) Is Public Is Magnet Is Charter

0.076 −0.069∗∗∗
0.059∗∗ 0.010∗ 0.006∗
−0.007 0.015∗
0.013
0.033

R2 adj. R2

0.140 0.133

Table 3: Regression of the average P (high quality) of a school in the U.S. SCHOOL NEWS dataset, on demographic variables. We observe that larger schools in educated, urban, and wealthy areas of the U.S tend to be scored higher by the GPT-3 quality ﬁlter. See §A.6 for more information on these features. ∗p < 0.05, ∗∗p < 0.01, ∗∗∗p < 0.001.

Summary and Limitations This analysis reveals an unintended consequence of the GPT-3 quality ﬁlter: by attempting to exclude text that is less like mainstream news and Wikipedia, the ﬁlter reinforces a language ideology that text from authors of wealthy, urban, and educated backgrounds are more valuable for inclusion in language model training data. These implicit preferences align with the attributes of authors that dominate the corpora from §2, which the ﬁlter considers to be high quality.
Although most of the above ﬁndings are robust to alternate model speciﬁcations, the model ultimately only accounts for a relatively small amount of variance in quality scores. In addition, most of our features are taken from a single a point in time, and do not account for changing demographics over the period 2010–2019. Data errors could also arise due to how datasets were aligned (based on school name and ZIP code). These ﬁndings may not generalize to other domains (e.g., social media), and inclusion of additional features could affect these ﬁndings. For additional models which include vote share and racial demographics taken from NCES data, see §A.7.
4 Alignment with Other Notions of Quality
The GPT-3 quality ﬁlter purports to judge the quality of text. Humans, on the other hand, frequently judge the quality of text without the use of auto-

mated systems. In this section, we consider three forms of human evaluations: institutional awards to select books, fact-checkers’ designated factuality of news outlets, and standardized test essays evaluated by human graders. How well does the behavior of the GPT-3 quality ﬁlter map onto these other notions of quality?
4.1 Data
Factually (Un)reliable News To analyze the correspondence between the GPT-3 quality ﬁlter and news factuality, we use the list provided by Baly et al. (2018) to identify a set of popular news sources from a broad range of factuality ratings and political leanings.19 Using Newspaper3k,20 we scrape and score 9.9K and 7.7K articles from high and low factuality news outlets, respectively.
Essay Exams Next, to analyze the correspondence between the GPT-3 quality ﬁlter and essay scores, we collect and score 12.1K participant essays from the Test Of English as a Foreign Language (TOEFL) exam, a widely used English language proﬁciency test (Blanchard et al., 2013). The TOEFL exam responses include ofﬁcial scores from exam readers, as well as each essay’s prompt.
Award-Winning Literature Finally, to analyze the correspondence between the GPT-3 quality ﬁlter and literary awards, we select and score books from Books3 and the Gutenberg corpus (Brooke et al., 2015) that have won a Pulitzer Prize in various categories. We collected these data by scraping the publicly available list of recipients.21
4.2 Results
If the ﬁlter aligns with news factuality, we would expect that articles from factually reliable sources would be rated as higher quality than those from factually unreliable ones. However, we ﬁnd no difference in the quality distribution between articles from high and low factuality news sources (p = 0.085, two-way Kolmogorov-Smirnov test; Figure 3). Many factually unreliable news articles are considered high quality by the ﬁlter (§A.8).
Turning to the TOEFL exam responses, we would expect that if the ﬁlter agrees with essay
19Baly et al. (2018) release a dataset of factual reliability and political leanings across news sources by scraping NewsMediaBiasFactCheck.org.
20https://newspaper.readthedocs.io/en/ latest/
21https://www.pulitzer.org/ prize-winners-categories

Density

P(high quality)

1.4

High Factuality News Low Factuality News

1.2

1.0

0.8

0.6

0.4

0.2

0.0 0.0

0.2

0.4

0.6

0.8

1.0

P(high quality)

Figure 3: There is no difference in quality scores between articles written by news sources of high and low factual reliability.

0.8

0.7

0.6

0.5 median quality 0.4 of BooksCorpus

0.3

0.2

0.1

nonfiction

fiction

poetry

drama

Pulitzer Prize Category

Figure 4: Among works that have won a Pulitzer Prize, the quality ﬁlter tends to favor nonﬁction and longer ﬁctional forms, disfavoring poetry and dramatic plays.

scores, higher scoring essays would receive higher quality scores. While essay scores are weakly correlated with quality scores (Pearson r = 0.12, p < 0.001), Table 4 demonstrates that the essay’s prompt is far more predictive of the essay’s quality designation. For example, essays responding to a prompt (P4) which asks participants to describe "...whether advertisements make products seem much better than they really are" are much less likely to be ﬁltered than all other prompts, including P6, which asks participants to describe "...whether it is best to travel in a group" (see §A.9 for more details). The latter prompt tends to invoke personal experiences in the responses.
Finally, if the ﬁlter aligns with literary awards, we would expect that most Pulitzer-Prize winning books would achieve high quality scores. On the contrary, quality scores vary heavily based on the genre (Figure 4). Poetry and drama are less favored by the ﬁlter relative to non-ﬁction, ﬁction, and even fan ﬁction (from the BookCorpus; Zhu et al. 2015).

Dependent variable: P (high quality) Observations: 12.1K TOEFL exams

Feature

Coefﬁcient

Intercept Low score High score Prompt 7 Prompt 6 Prompt 2 Prompt 8 Prompt 3 Prompt 5 Prompt 4

0.0631∗∗∗
−0.0414
0.0339 −0.0283∗∗∗ −0.0204∗∗∗
0.0068∗∗∗ 0.0346∗∗∗ 0.0880∗∗∗ 0.1470∗∗∗ 0.6745∗∗∗

R2 adj. R2

0.712 0.711

Table 4: Regression of the quality of a TOEFL exam essay on its assigned score and prompt. While we observe some relationship between the score an essay receives and its quality score, the essay prompts themselves have signiﬁcantly higher effect sizes. The highest quality essays come from Prompt 4, which asks participants to discuss products and advertisements. See §A.9 for visualizations of distributions of quality across prompts and scores. ∗p < 0.05, ∗∗p < 0.01, ∗∗∗p < 0.001.

Summary Our analysis demonstrates that the GPT-3 quality ﬁlter conﬂicts with other standards of text quality. Of course, even the alternative standards we compare here are subject to their own language ideologies. Readers are more likely to trust news as factual if its political position aligns with their own (Mitchell et al., 2018). English-language teaching pedagogies are rooted in ideologies about well-spokenness (Vanegas et al., 2016). Literary awards favor white and male authors.22 In general, any designation of text as high quality is subjective and inﬂuenced by sociopolitical context.
5 Discussion
The above sections have demonstrated that automated ﬁltering of text to build language modeling corpora may lead to counterintuitive or undesirable exclusion of sources. Because of the variety of use cases for language models and the broad range of text that could be appropriate for certain tasks, we suggest that there is no simple, universal standard for what should be considered high quality text. Indeed, there is a long history of privileging some people’s spoken language as better or more “cor-
22A 2016 study by the Columbia Journalism Review found that since 1918, 84% of Pulitzer Prizes had been awarded to white authors, and 84% to male authors: https://www. cjr.org/analysis/100_years_of_data.php.

rect” than others. Researchers and practitioners of NLP who are aware of this history have the option to be intentional in their design of systems that, however implicitly, risk excluding the language of underprivileged identities or communities.
Some amount of selection in building corpora is inevitable. It is not possible to collect a uniform random sample of all written utterances. However, our ﬁndings suggest that current selection methods are, for many purposes, ﬂawed. Future work into alternative ﬁltering criteria could be paired with investigations into the unintended consequences of their assumptions.
We do not believe that there is likely to be a single solution to this challenge. Indeed, the text that is best suited for training a model may depend on the application of that model. At a minimum, however, the NLP community could more carefully consider and clearly document the criteria by which text is being selected for inclusion. NLP practitioners could also be explicit about the reasons for using certain sources, even if those reasons are related to availability or empirical performance. A collection of tests could also be deployed (and improved over time), to give a clear understanding of the implications of different choices of ﬁlters.
More generally, we echo calls in the literature for more thoughtful and inclusive data collection (Jo and Gebru, 2020; Bender et al., 2021; Tanweer et al., 2021). This could include, but is not limited to a) intentionally curating data from people and viewpoints that are not otherwise well represented; b) including a greater diversity of genres; c) more nuanced or intentional exclusion criteria; d) more thorough interrogation of what text is being excluded; e) developing standard checks for prominent biases in inclusion; f) abandoning the notion of a general-purpose corpus.
6 Ethical Considerations & Limitations
Our U.S. SCHOOL NEWS dataset comes with many limitations, as described in §3.1. For example, the dataset contains sampling biases (e.g., it depends on use of a speciﬁc publication template), and the ZIP codes and counties are not uniformly spread across U.S. states. In general, our dataset likely captures neither the least resourced schools (which may not have access to online resources) in the United States, nor the wealthiest ones (who may have their own publication platforms). However, we speculate that an expanded corpus, which in-

cluded writings from these schools, would demonstrate a continuation of trends we report in this paper.
While the text in our dataset varies considerably along topical, stylistic, and demographic variables, it is a niche domain; the text is a speciﬁc genre meant for local student consumption, its authors are U.S. students, and it thus primarily represents U.S.-centric cultural and political perspectives. We acknowledge that we also perpetuate some of the biases we identify, especially by working with English language text from the United States. We hope future work will extend this study of language ideologies to multilingual settings, other textual domains, and different sets of authors.
With respect to demographic variables, we merge census demographics with school-level data via ZIP codes or counties, which are imperfect identiﬁers of a school, since ZIP codes (and counties) may include multiple schools of varying resource levels. Moreover, tracking demographic variables and other author metadata, if deployed at scale, implies a certain level of invasive surveillance (Brayne, 2017). Future work may explore how to maintain the rights of authors as data subjects and producers while mapping demographic representation in large corpora.
Finally, we did not seek consent from authors to scrape their articles. The ethical and legal norms around scraping public-facing web data, especially those produced by minors, are still in ﬂux (Fiesler et al., 2020), and may not align with user perceptions of what constitutes fair use of online communications (Williams et al., 2017). For these reasons, we do not release the corpus of school newspaper articles, and only use it for analysis and evaluation. We only make available a dataset of demographic variables and quality scores per school, to support reproducibility.
7 Related Work
Language Ideologies Language ideologies have been widely explored in the sociolinguistics literature (Gal and Irvine, 1995; Rosa and Flores, 2017; Craft et al., 2020, inter alia). An ideology that promotes the inherent correctness, clarity, and objectivity of certain language varieties over others is a mechanism for linguistic discrimination (Craft et al., 2020; Gal, 2016; MacSwan, 2020; Rickford and King, 2016). A salient example of such discrimination is the stigmatization of second-

language speakers of English (Lindemann, 2005). Language ideologies have an important, but of-
ten unacknowledged, inﬂuence on the development of NLP technologies (Blodgett et al., 2020). For example, an ideology that distinguishes between standard and non-standard language variations surfaces in text normalization tasks (van der Goot et al., 2021), which tend to strip documents of pragmatic nuance (Baldwin and Chai, 2011) and social signals (Nguyen et al., 2021). Language on the Internet has been historically treated as a noisy variant of English, even though lexical variation on the Internet is highly communicative of social signals (Eisenstein, 2013), and varies considerably along demographic variables (Eisenstein et al., 2014) and community membership (Lucy and Bamman, 2021). Language ideologies also surface in tools for toxicity detection; for example, the classiﬁcation behavior of the PERSPECTIVE API (a popular hate speech detector) aligns with the attitudes of conservative, white, female annotators, who tend to perceive African-American dialects as more toxic (Sap et al., 2021). In this work, we examine the language ideology encoded in a widely used quality ﬁlter for text data selection.
Critiques of Laissez-Faire Data Collection We provide empirical evidence that laissez-faire data collection (i.e., ﬁltering large web data sources) leads to data homogeneity (Bender et al., 2021). As an alternative to laissez-faire collection, Jo and Gebru (2020) recommend drawing on institutional archival practices. However, we note that language ideologies are also prevalent (and may not be explicit) in institutional archives, which, for example, have preferred colonial voices over colonized ones when documenting historical events (Trouillot, 1995; Decker, 2013).
Other Quality Filters Other deﬁnitions of text quality are used to create pretraining datasets, some of which do not rely on the datasets from §2. However, all techniques adopt language ideologies of what constitutes high quality text. Bad-word ﬁltering, which removes documents that contain certain stop-words, disproportionately excludes language about and by minority groups (Dodge et al., 2021). Filtering Internet content for popularity (Radford et al., 2019) leads to data homogeneity based on the characteristics of viral media and the composition of userbases in online forums (§2). Even lightweight ﬁlters (Aghajanyan et al., 2021; Rae

et al., 2021) put more emphasis on features like document length over factuality when determining what makes a document high quality. Any ﬁltering method requires transparent justiﬁcation and recognition of tradeoffs.
Downstream Behavior The behavior of language systems aligns with what we would expect from a language ideology that favors training data written by a narrow, powerful sector of society. For example, dialogue agents perform signiﬁcantly worse when engaging in conversations about race (Schlesinger et al., 2018) and with minority dialects of English (Mengesha et al., 2021). GPT-3 frequently resorts to use of stereotypes when minority groups are mentioned in its prompt (Abid et al., 2021; Blodgett, 2021). GPT-3 is also prone to producing hate speech (Gehman et al., 2020) and misinformation (McGufﬁe and Newhouse, 2020), which we would expect if its quality ﬁlter fails to distinguish the factual reliability of news sources in its training data (§4). Concurrent to this work, Gao (2021) show that aggressive data ﬁltering with the GPT-3 quality ﬁlter degrades downstream task performance. A closer analysis of how the language ideologies in data selection lead to certain model behaviors is a rich area for future work.
8 Conclusion
Using a new dataset of U.S. school newspapers, we ﬁnd that the conventional, automated valuation of Wikipedia, newswire, books, and popular Internet content as reference for high quality text implicitly favors content written by authors from larger schools in wealthier, educated, urban areas of the United States. Adopting this language ideology for text data selection leads to implicit, yet systematic and as-yet undocumented inequalities in terms of whose language is more likely to be included in training corpora. Although no single action will solve this complicated issue, data curators and researchers could be more intentional about curating text from underrepresented authors and groups, gathering sources from multiple genres and writing styles, and documenting their curation procedures and possible sources of exclusion.

Acknowledgments
This paper beneﬁted from thoughtful feedback from a number of people: Emily M. Bender, Amber Boydstun, Timnit Gebru, Eun Seo Jo, Kelvin Luu, Lucy Li, Julian Michael, Amandalynne Paullada, Katharina Reinecke, Swabha Swayamdipta, Kelly Wright, and Kaitlyn Zhou.
References
Abubakar Abid, Maheen Farooqi, and James Zou. 2021. Persistent anti-Muslim bias in large language models. In Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society.
Armen Aghajanyan, Dmytro Okhonko, Mike Lewis, Mandar Joshi, Hu Xu, Gargi Ghosh, and Luke Zettlemoyer. 2021. Htlm: Hyper-text pre-training and prompting of language models. arXiv, abs/2107.06955.
Gabriel Arana. 2018. Decades of failure. Columbia Journalism Review.
Tyler Baldwin and Joyce Chai. 2011. Beyond normalization: Pragmatics of word form in text messages. In Proceedings of 5th International Joint Conference on Natural Language Processing.
Ramy Baly, Georgi Karadzhov, Dimitar Alexandrov, James Glass, and Preslav Nakov. 2018. Predicting factuality of reporting and bias of news media sources. In Proceedings of EMNLP.
David Bamman and Noah A Smith. 2014. Unsupervised discovery of biographical structure from text. Transactions of the Association for Computational Linguistics, 2:363–376.
Jack Bandy and Nicholas Vincent. 2021. Addressing “documentation debt” in machine learning: A retrospective datasheet for BookCorpus. In NeurIPS.
Emily M. Bender, Timnit Gebru, Angelina McMillanMajor, and Shmargaret Shmitchell. 2021. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of FAccT.
Jonah Berger and Katherine L. Milkman. 2012. What makes online content viral? Journal of Marketing Research, 49(2):192–205.
Julian R. Betts, Kim S. Reuben, and Anne Danenberg. 2000. Equal Resources, Equal Outcomes? The Distribution of School Resources and Student Achievement in California. Public Policy Institute of California.
Steve Bien-Aimé. 2016. AP stylebook normalizes sports as a male space. Newspaper Research Journal, 37(1):44–57.

Daniel Blanchard, Joel R. Tetreault, Derrick Higgins, A. Cahill, and Martin Chodorow. 2013. TOEFL11: A corpus of non-native English. ETS Research Report Series, 2013:15.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent Dirichlet allocation. J. Mach. Learn. Res., 3:993–1022.
Su Lin Blodgett. 2021. Sociolinguistically Driven Approaches for Just Natural Language Processing. Ph.D. thesis, University of Massachusetts Amherst.
Su Lin Blodgett, Solon Barocas, Hal Daumé III, and Hanna Wallach. 2020. Language (technology) is power: A critical survey of “bias” in NLP. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5454– 5476, Online. Association for Computational Linguistics.
Su Lin Blodgett, Lisa Green, and Brendan O’Connor. 2016. Demographic dialectal variation in social media: A case study of African-American English. In Proceedings of EMNLP.
Sarah Brayne. 2017. Big data surveillance: The case of policing. American Sociological Review, 82(5):977– 1008.
Julian Brooke, Adam Hammond, and Graeme Hirst. 2015. GutenTag: an NLP-driven tool for digital humanities research in the Project Gutenberg corpus. In Proceedings of the Fourth Workshop on Computational Linguistics for Literature.
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. arXiv, abs/2005.14165.
Janice Kai Chen, Ilena Peng, Jasen Lo, Trisha Ahmed, Simon J. Levien, and Devan Karp. 2021. Voices investigation: Few black, latinx students are editors of top college newspapers. AAJA Voices.
Kevin Clark, Minh-Thang Luong, Quoc V. Le, and Christopher D. Manning. 2020. ELECTRA: Pretraining text encoders as discriminators rather than generators. In ICLR.
Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. 2020. Unsupervised cross-lingual representation learning at scale.

Justin T. Craft, Kelly E. Wright, Rachel Elizabeth Weissler, and Robin M. Queen. 2020. Language and discrimination: Generating meaning, perceiving identities, and discriminating outcomes. Annual Review of Linguistics, 6(1):389–407.
Stephanie Decker. 2013. The silence of the archives: business history, post-colonialism and archival ethnography. Management & Organizational History, 8(2):155–173.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of NAACL.
Robert DiNicola. 1994. Teaching journalistic style with the AP stylebook: Beyond fussy rules and dogma of ‘correctness’. The Journalism Educator, 49(2):64–70.
Jesse Dodge, Maarten Sap, Ana Marasovic, William Agnew, Gabriel Ilharco, Dirk Groeneveld, and Matt Gardner. 2021. Documenting the english colossal clean crawled corpus. arXiv, abs/2104.08758.
Penelope Eckert. 1989. Jocks and burnouts: Social categories and identity in the high school. Teachers college press.
Jacob Eisenstein. 2013. What to do about bad language on the internet. In Proceedings of NAACL, pages 359–369.
Jacob Eisenstein, Brendan O’Connor, Noah A. Smith, and Eric P. Xing. 2014. Diffusion of lexical change in social media. PLoS ONE, 9.
William Fedus, Barret Zoph, and Noam Shazeer. 2021. Switch transformers: Scaling to trillion parameter models with simple and efﬁcient sparsity.
Casey Fiesler, Nathan Beard, and Brian Keegan. 2020. No robots, spiders, or scrapers: Legal and ethical regulation of data collection methods in social media terms of service. In Proceedings of ICWSM.
Paula Froke, Anna Jo Bratton, Jeff McMillan, Pia Sarkar, Jerry Schwartz, and Raghuram Vadarevu. 2020. The Associated Press stylebook 2020-2022. The Associated Press.
Susan Gal. 2016. Sociolinguistic differentiation, page 113–136. Cambridge University Press.
Susan Gal and Judith T. Irvine. 1995. The boundaries of languages and disciplines: How ideologies construct difference. Social Research, 62(4):967–1001.
Leo Gao. 2021. An empirical exploration in quality ﬁltering of text data. arXiv, abs/2109.00698.
Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. 2020. The Pile: An 800Gb dataset of diverse text for language modeling. arXiv, abs/2101.00027.

Tiana Gaudette, Ryan Scrivens, Garth Davies, and Richard Frank. 2021. Upvoting extremism: Collective identity formation and the extreme right on reddit. New Media & Society, 23(12):3491–3508.
Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daumé III, and Kate Crawford. 2021. Datasheets for datasets. Communications of the ACM, 64(12):86–92.
Samuel Gehman, Suchin Gururangan, Maarten Sap, Yejin Choi, and Noah A. Smith. 2020. RealToxicityPrompts: Evaluating neural toxic degeneration in language models. In Findings of the Association for Computational Linguistics: EMNLP 2020.
Joyce Still Gibson. 1961. A study of the status of high school newspapers in the virginia public schools. Master’s thesis, University of Richmond.
Aaron Gokaslan and Vanya Cohen. 2019. Openwebtext corpus.
Eduardo Graells-Garrido, Mounia Lalmas, and Filippo Menczer. 2015. First women, second sex: Gender bias in Wikipedia. In Proceedings of the 26th ACM conference on hypertext & social media.
Rob Greenwald, Larry V. Hedges, and Richard D. Laine. 1996. The effect of school resources on student achievement. Review of Educational Research, 66(3):361–396.
Elizabeth Grieco. 2018. Newsroom employees are less diverse than U.S. workers overall. Pew Research Center. [online; accessed 2022-01-22].
Dirk Hovy and Diyi Yang. 2021. The importance of modeling social factors of language: Theory and practice. In Proceedings of NAACL.
Keira Huang. 2013. Wikipedia fails to bridge gender gap. South China Morning Post. [online; accessed 2022-01-11].
Eun Seo Jo and Timnit Gebru. 2020. Lessons from archives: Strategies for collecting sociocultural data in machine learning. Proceedings of FAccT.
Paresh Kharya and Ali Alvi. 2021. Using deepspeed and megatron to train megatron-turing nlg 530b, the world’s largest and most powerful generative language model. [online; accessed 2022-01-20].
William Labov. 2006. The Social Stratiﬁcation of English in New York City, 2 edition. Cambridge University Press.
Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut. 2020. ALBERT: A lite BERT for self-supervised learning of language representations. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.

Lee & Low Books. 2020. Where is the diversity in publishing? The 2019 diversity baseline survey results. [online; accessed 2021-11-24].
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7871–7880, Online. Association for Computational Linguistics.
Stephanie Lindemann. 2005. Who speaks “broken English”? US undergraduates’ perceptions of nonnative English. International Journal of Applied Linguistics, 15(2):187–212.
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. RoBERTa: A robustly optimized bert pretraining approach. arXiv, abs/1907.11692.
Li Lucy and David Bamman. 2021. Characterizing English Variation across Social Media Communities with BERT. Transactions of the Association for Computational Linguistics, 9:538–556.
Jeff MacSwan. 2020. Academic English as standard language ideology: A renewed research agenda for asset-based language education. Language Teaching Research, 24(1):28–36.
Michael Mandiberg. 2020. Mapping wikipedia. The Atlantic. [online; accessed 2021-11-24].
Sorin Adam Matei and Brian C. Britt. 2017. Structural Differentiation in Social Media. Springer International Publishing.
Kris McGufﬁe and Alex Newhouse. 2020. The radicalization risks of GPT-3 and advanced neural language models. arXiv, abs/2009.06807.
Zion Mengesha, Courtney Heldreth, Michal Lahav, Juliana Sublewski, and Elyse Tuennerman. 2021. “I don’t think these devices are very culturally sensitive.”—Impact of automated speech recognition errors on African Americans. Frontiers in Artiﬁcial Intelligence, 4:169.
Meta-wiki. 2018. Community insights/2018 report/contributors. [online; accessed 2012-11-24].
Amy Mitchell, Jeffrey Gottfried, Michael Barthel, and Nami Sumida. 2018. Can Americans tell factual from opinion statements in the news? Pew Research Center’s Journalism Project. [online; accessed 2022-01-22].
Dong Nguyen, Laura Rosseel, and Jack Grieve. 2021. On learning and representing social meaning in NLP: A sociolinguistic perspective. In Proceedings of NAACL.

Katherine Panciera, Aaron Halfaker, and Loren Terveen. 2009. Wikipedians are born, not made: A study of power editors on wikipedia. In Proceedings of the ACM 2009 International Conference on Supporting Group Work.
Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Jake Vanderplas, Alexandre Passos, David Cournapeau, Matthieu Brucher, Matthieu Perrot, and Édouard Duchesnay. 2011. Scikit-learn: Machine learning in python. Journal of Machine Learning Research, 12(85):2825–2830.
Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep contextualized word representations. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 2227–2237, New Orleans, Louisiana. Association for Computational Linguistics.
Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018. Improving language understanding with unsupervised learning. [online; accessed 2022-01-22].
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners. [online; accessed 2022-01-22].
Jack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, Eliza Rutherford, Tom Hennigan, Jacob Menick, Albin Cassirer, Richard Powell, George van den Driessche, Lisa Anne Hendricks, Maribeth Rauh, Po-Sen Huang, Amelia Glaese, Johannes Welbl, Sumanth Dathathri, Saffron Huang, Jonathan Uesato, John Mellor, Irina Higgins, Antonia Creswell, Nat McAleese, Amy Wu, Erich Elsen, Siddhant Jayakumar, Elena Buchatskaya, David Budden, Esme Sutherland, Karen Simonyan, Michela Paganini, Laurent Sifre, Lena Martens, Xiang Lorraine Li, Adhiguna Kuncoro, Aida Nematzadeh, Elena Gribovskaya, Domenic Donato, Angeliki Lazaridou, Arthur Mensch, Jean-Baptiste Lespiau, Maria Tsimpoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sottiaux, Mantas Pajarskas, Toby Pohlen, Zhitao Gong, Daniel Toyama, Cyprien de Masson d’Autume, Yujia Li, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin, Aidan Clark, Diego de Las Casas, Aurelia Guy, Chris Jones, James Bradbury, Matthew Johnson, Blake Hechtman, Laura Weidinger, Iason Gabriel, William Isaac, Ed Lockhart, Simon Osindero, Laura Rimell, Chris Dyer, Oriol Vinyals, Kareem Ayoub, Jeff Stanway, Lorrayne Bennett, Demis Hassabis, Koray Kavukcuoglu, and Geoffrey Irving. 2021. Scaling language models: Methods, analysis & insights from training gopher. arXiv, abs/2112.11446.

Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a uniﬁed text-totext transformer. Journal of Machine Learning Research, 21(140):1–67.
Sean F Reardon and Ann Owens. 2014. 60 years after Brown: Trends and consequences of school segregation. Annual Review of Sociology, 40:199–218.
John R. Rickford. 1985. Ethnicity as a sociolinguistic boundary. American Speech, 60(2):99–125.
John R. Rickford and Sharese King. 2016. Language and linguistics on trial: Hearing rachel jeantel (and other vernacular speakers) in the courtroom and beyond. Language, 92(4):948–988.
Jonathan Rosa and Nelson Flores. 2017. Unsettling race and language: Toward a raciolinguistic perspective. Language in Society, 46(5):621–647.
Maarten Sap, Swabha Swayamdipta, Laura Vianna, Xuhui Zhou, Yejin Choi, and Noah A. Smith. 2021. Annotators with attitudes: How annotator beliefs and identities bias toxic language detection. arXiv, abs/2111.07997.
Dante J. Scala and Kenneth M. Johnson. 2017. Political polarization along the rural-urban continuum? the geography of the presidential vote, 2000–2016. The ANNALS of the American Academy of Political and Social Science, 672(1):162–184.
Ari Schlesinger, Kenton P. O’Hara, and Alex S. Taylor. 2018. Let’s talk about race: Identity, chatbots, and AI. In Proceedings of CHI.
Anissa Tanweer, Emily Kalah Gade, PM Krafft, and Sarah K Dreier. 2021. Why the data revolution needs qualitative thinking. Harvard Data Science Review.
Michel-Rolph Trouillot. 1995. Silencing the past: Power and the production of history. Beacon Press.
Rob van der Goot, Alan Ramponi, Arkaitz Zubiaga, Barbara Plank, Benjamin Muller, Iñaki San Vicente Roncal, Nikola Ljubešic´, Özlem Çetinog˘lu, Rahmad Mahendra, Talha Çolakog˘lu, Timothy Baldwin, Tommaso Caselli, and Wladimir Sidorenko. 2021. MultiLexNorm: A shared task on multilingual lexical normalization. In Proceedings of the Seventh Workshop on Noisy User-generated Text.
Marlon Vanegas, Juan Restrepo, Yurley Zapata, Giovany Rodríguez, Luis Cardona, and Cristian Muñoz. 2016. Linguistic discrimination in an English language teaching program: Voices of the invisible others. Íkala, Revista de Lenguaje y Cultura, 21.
Fred Vultee. 2012. A paleontology of style. Journalism Practice, 6(4):450–464.

Claudia Wagner, David Garcia, Mohsen Jadidi, and Markus Strohmaier. 2015. It’s a man’s Wikipedia? Assessing gender inequality in an online encyclopedia. In Proceedings of the AAAI conference on web and social media.
Jason Weismueller, Paul Harrigan, Kristof Coussement, and Tina Tessitore. 2022. What makes people share political content on social media? The role of emotion, authority and ideology. Computers in Human Behavior, 129:107150.
Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary, Francisco Guzmán, Armand Joulin, and Edouard Grave. 2020. CCNet: Extracting high quality monolingual datasets from web crawl data. In Proceedings of LREC.
Matthew L Williams, Pete Burnap, and Luke Sloan. 2017. Towards an ethical framework for publishing Twitter data in social research: Taking into account users’ views, online context and algorithmic estimation. Sociology, 51(6):1149–1168.
Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le. 2019. Xlnet: Generalized autoregressive pretraining for language understanding. In Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc.
Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, and Sanja Fidler. 2015. Aligning books and movies: Towards story-like visual explanations by watching movies and reading books. In Proceedings of ICCV.

A Appendix
A.1 Language Model Training Corpora
We display a list of popular language modeling corpora in Table 5.
A.2 Datasheet
Our datasheet for the U.S. SCHOOL NEWS dataset can be found here: https://bit.ly/3rLrmwV.
A.3 Quality Filter Hyperparameters
We display the hyperparameters of our logistic regression classiﬁer (reproduction of the ﬁlter developed by Brown et al. 2020) in Table 6.
A.4 Example Articles
We display example articles and their quality scores in the U.S. SCHOOL NEWS dataset in Table 11.
A.5 Topic Modeling
See the quality distribution among topics for 10K opinion pieces in Figure 5.
A.6 Demographic Features
We display a table of features we use in our demographic regression model in Table 7.
A.7 Additional Regressions
Here we include regressions results from two models with additional covariates.
We ﬁrst consider race as a possible omitted variable, given the extent of school segregation in the U.S. (Reardon and Owens, 2014). NCES data provides the distribution of students by race for each school, using a particular set of racial categories, which comes with obvious limitations. Nevertheless, we use the raw percentage scores provided as additional covariates in this model as a validity check. We exclude the Native and Paciﬁc Islander categories, due to imbalanced data and geographic concentration, as well as the white category, to avoid a saturated model.
As shown in Table 8, the ﬁndings are nearly identical to the results in the main paper, with the exception that home values are no longer signiﬁcant. The only racial category that shows a signiﬁcant effect is Asian. However, we note a positive correlation between percentage of Asian students and median home values (Pearson r =0.32, p < 0.001), suggesting that the variable for percentage of Asian students may be partially absorbing the effect of our measure of wealth.

Table 9 shows the results for an alternate model which includes % GOP vote share in the 2016 election. Once again, the results are very similar to the results in the main paper, although there is a strong (and signiﬁcant) negative association between GOP vote share and quality scores, whereas the measures of home values and percent rural are no longer signiﬁcant.
The results for this model exemplify the difﬁculty of working with highly correlated variables. Given the strong association between GOP voters and rural areas, GOP vote share serves as an effective proxy for other variables of interest. However, because the results of the 2016 Presidential election were likely somewhat idiosyncratic, and because we ﬁnd wealth and geography to be a more plausible explanation for differences in student writing than political preferences among their parents, we opt for the model without GOP vote share in the main paper.
A.8 Low Factuality News Considered High Quality
We display example low factuality news articles that are assigned high quality scores by the GPT-3 quality ﬁlter in Table 12.
A.9 TOEFL Exam Responses
We display the distribution of quality scores against prompts and essay scores in the TOEFL exam dataset in Figure 6. We display the prompts of this dataset in Table 10.

Model

ELMo GPT-1 GPT-2 BERT RoBERTa XL-Net ALBERT T5 XLM-R BART GPT-3 ELECTRA Megatron-Turing Switch-C Gopher

NLG

Pretraining Data Sources
1B Word benchmark BookCorpus WebText BookCorpus + Wikipedia BookCorpus + Wikipedia + CC-news + OpenWebText + Stories BookCorpus + Wikipedia + Giga5 + ClueWeb 2012-B + Common Crawl BERT, RoBERTa, and XL-net’s data sources Common Crawl (ﬁltered) Common Crawl (ﬁltered) BookCorpus + Wikipedia Wikipedia + Books + WebText (expanded) + Common Crawl (ﬁltered) BookCorpus + Wikipedia + Giga5 + ClueWeb 2012-B + Common Crawl The Pile + Common Crawl (ﬁltered) + RealNews + Stories Common Crawl (ﬁltered) MassiveWeb + Books + Common Crawl (ﬁltered) + News + GitHub + Wikipedia

Citation

(Peters (Radford (Radford
(Devlin (Liu
(Yang (Lan
(Raffel (Conneau
(Lewis (Brown (Clark (Kharya and (Fedus
(Rae

et al., et al., et al., et al., et al., et al., et al., et al., et al., et al., et al., et al., Alvi, et al., et al.,

2018) 2018) 2019) 2019) 2019) 2019) 2020) 2020) 2020) 2020) 2020) 2020) 2021) 2021) 2021)

Table 5: Overview of recent language models and their training corpora. All studies tend to draw from the same core data sources: Wikipedia, Books, News, or ﬁltered web dumps.

Computing Infrastructure Number of search trials Search strategy Best validation F1

56 Intel Xeon CPU Cores 100
uniform sampling 90.4

Hyperparameter regularization C solver tol ngram range random state tokenization vectorization
remove stopwords

Search space choice[L1, L2] uniform-ﬂoat[0, 1]
64 loguniform-ﬂoat[10e-5, 10e-3]
choice["1 2", "1 3", "2 3"] uniform-int[0, 100000] whitespace hashing choice[Yes, No]

Best assignment L1
0.977778 liblinear 0.000816
"1 2" 44555 whitespace hashing
No

Table 6: Hyperparameter search space and best assignments for our re-implementation of the GPT-3 quality ﬁlter.

5:christmas dress holiday day thanksgiving dance prom halloween year wear 2:school college year high senior seniors students class time classes 0:food restaurant eat pizza menu chicken coffee meal foods cheese
6:students school student teachers class high classes time schools teacher 1:people just like life time don know day things ve
7:movie film movies characters story character plot films marvel book 3:album music song songs band lyrics sound listen like artists
4:people women media world new social states gun country like 9:game team players games season sports football teams play athletes 8:trump president election vote political clinton country obama people donald

P(high quality)

0.0 0.2 0.4 0.6 0.8 1.0

Figure 5: Considering 10K opinion pieces in U.S. SCHOOL NEWS, we observe that the GPT-3 quality ﬁlter prefers topics that are more prevalent in Wikipedia or newswire.

Feature
Is Charter Is Private Is Magnet % Black Students % Asian Students % Mixed Students % Hispanic Students Student:Teacher School Size Median Home Value % Adults ≥ Bachelor Deg. % Rural % 2016 GOP Vote

Description
Is the school a charter school? Is the school a private school? Is the school a magnet school? % students who identify as Black % students who identify as Asian % students who identify as Mixed race % students who identify as Hispanic Student-teacher ratio Total number of students Median home value % adults (≥ 25 years old) with at least a bachelor’s degree Percent of a county population living in a rural area Republican vote share in the 2016 presidential election

Level
School School School School School School School School School ZIP code ZIP code County County

Source
NCES database NCES database NCES database NCES database NCES database NCES database NCES database NCES database NCES database
Census Census Census MIT Election Lab

Table 7: Description of features we include in our demographic analyses.

Dependent variable: P (high quality) Observations: 968 schools

Feature

Coefﬁcient

Intercept % Rural % Adults ≥ Bachelor Deg. log2(Median Home Value) log2(Number of students) log2(Student:Teacher ratio) Is Public Is Magnet Is Charter % Asian Students % Mixed Students % Black Students % Hispanic Students

0.134 −0.073∗∗∗
0.049∗
0.007 0.005∗
−0.008 0.020∗
0.013 0.035∗ 0.081∗∗
0.051
−0.009
−0.020

R2 adj. R2

0.152 0.142

Table 8: Regression of the average P (high quality) of a school in the U.S. SCHOOL NEWS dataset, on demographic variables. As in the main paper, larger schools in educated and urban areas of the U.S tend to be scored higher by the GPT-3 quality ﬁlter. Asian is the only categorical race variable which shows a signiﬁcant association (using data and categories taken directly from NCES). The association with home values is no longer signiﬁcant, plausibly explained by a correlation between a higher proportion of Asian students and higher median home values. See §A.6 for more information on these features. ∗p < 0.05, ∗∗p < 0.01, ∗∗∗p < 0.001.

Dependent variable: P (high quality) Observations: 968 schools

Feature

Coefﬁcient

Intercept % Rural % Adults ≥ Bachelor Deg. log2(Median Home Value) log2(Number of students) log2(Student:Teacher ratio) Is Public Is Magnet Is Charter % GOP vote share

0.248∗∗
−0.021 0.067∗∗
0.003 0.006∗∗
−0.007 0.017∗
0.009
0.027 −0.114∗∗∗

R2 adj. R2

0.164 0.157

P(high quality)

P(high quality)

0.8 0.6 0.4 0.2 0.0
low EsmsaeydiSucmore high
1.0 0.8 0.6 0.4 0.2 0.0 P7 P6 P1 P2 P8 P3 P5 P4
Essay Prompt
Figure 6: TOEFL exam score is weakly correlated with quality score across prompts (Pearson correlation; r=0.12 ± 0.05, p ≈ 0; top), but the essay prompt seems to be a much stronger indicator of quality scores than the exam scores are (bottom).

Table 9: Regression of the average P (high quality) of a school in the U.S. SCHOOL NEWS dataset, on demographic variables, including % 2016 GOP Vote. We observe that including the political leaning of the county tends to wash out other variables, likely because partisan voting correlates heavily with other effects, like the urban/rural divide (Scala and Johnson, 2017). The only other covariates that stay signiﬁcant are school size, parental education, and public (as opposed to private) schools. ∗p < 0.05, ∗∗p < 0.01, ∗∗∗p < 0.001.

ID Text

P (high quality)

P7 It is more important for students to understand ideas and concepts than it is for them to learn facts.

0.04

P6 The best way to travel is in a group led by a tour guide.

0.05

P1 It is better to have broad knowledge of many academic subjects than to specialize in one speciﬁc subject.

0.07

P2 Young people enjoy life more than older people do.

0.08

P8 Successful people try new things and take risks rather than only doing what they already know how to do well.

0.10

P3 Young people nowadays do not give enough time to helping their communities.

0.16

P5 In twenty years, there will be fewer cars in use than there are today.

0.22

P4 Most advertisements make products seem much better than they really are.

0.74

Table 10: TOEFL prompt IDs and their text, ordered by their quality score by GPT-3 quality ﬁlter.

Category: Student-Life P (high quality) = 0.001
As our seniors count down their ﬁnal days until graduation, we will be featuring them each day. [REDACTED], what are your plans after graduation? To attend [REDACTED] in the fall and get my basics. Then attend the [REDACTED] program. What is your favorite high school memory? My crazy, obnoxious and silly 5th hour English with [REDACTED]. What advice do you have for underclassmen? Pay attention, stay awake (I suggest lots of coffee), and turn in your dang work! You can do it, keep your head up because you are almost there!
Category: News P (high quality) = 0.99
On Monday, September 3rd, Colin Kaepernick, the American football star who started the “take a knee” national anthem protest against police brutality and racial inequality, was named the new face of Nike’s “Just Do It” 30th-anniversary campaign. Shortly after, social media exploded with both positive and negative feedback from people all over the United States. As football season ramps back up, this advertisement and the message behind it keeps the NFL Anthem kneeling protest in the spotlight.
Table 11: Examples of high school news paper articles from U.S. SCHOOL NEWS. Many of the articles in studentlife category, and similar, rated lower quality have very different styles from documents rated high quality.

Article from http://en-volve.com P (high quality) = 0.93
The German government has effectively began the process of eliminating the unvaccinated by starving them to death by pushing grocery stories to ban unvaccinated residents from buying essential food items...The pressure on the unvaccinated grows and grows!...
Article from http://www.censored.news P (high quality) = 0.98
The provisional number of births in the U.S. was 3,605,201 in 2020. That is the lowest number of births in the United States since 1979, according to the Centers for Disease Control. 2020 also had the lowest fertility rate since the government started tracking births in 1902. And don’t blame the so-called “pandemic.”...we’re learning in 2021 that intelligent people succumb to government psy-ops. But critical thinkers understood immediately that something was very wrong with all the COVID-19 stuff. Plus many among the global elite continually and openly gloat about their desire to cull the masses. Bill Gates isn’t even coy about his desires...
Table 12: Examples of news from low factuality sources (as identiﬁed by MediaBiasFactCheck.com) rated high quality by GPT-3 quality ﬁlter, but contain COVID disinformation.

