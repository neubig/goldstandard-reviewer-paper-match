arXiv:1005.1634v3 [cs.IT] 13 Sep 2010

Interference Alignment in Regenerating Codes for
Distributed Storage: Necessity and Code
Constructions
Nihar B. Shah, K. V. Rashmi, P. Vijay Kumar, Fellow, IEEE, and Kannan Ramchandran, Fellow, IEEE
Abstract
Regenerating codes are a class of recently developed codes for distributed storage that, like Reed-Solomon codes, permit data recovery from any arbitrary k of n nodes. However regenerating codes possess in addition, the ability to repair a failed node by connecting to any arbitrary d nodes and downloading an amount of data that is typically far less than the size of the data ﬁle. This amount of download is termed the repair bandwidth. Minimum storage regenerating (MSR) codes are a subclass of regenerating codes that require the least amount of network storage; every such code is a maximum distance separable (MDS) code. Further, when a replacement node stores data identical to that in the failed node, the repair is termed as exact.
The four principal results of the paper are (a) the explicit construction of a class of MDS codes for d = n − 1 ≥ 2k − 1 termed the MISER code, that achieves the cut-set bound on the repair bandwidth for the exactrepair of systematic nodes, (b) proof of the necessity of interference alignment in exact-repair MSR codes, (c) a proof showing the impossibility of constructing linear, exact-repair MSR codes for d < 2k − 3 in the absence of symbol extension, and (d) the construction, also explicit, of MSR codes for d = k + 1. Interference alignment (IA) is a theme that runs throughout the paper: the MISER code is built on the principles of IA and IA is also a crucial component to the non-existence proof for d < 2k − 3. To the best of our knowledge, the constructions presented in this paper are the ﬁrst, explicit constructions of regenerating codes that achieve the cut-set bound.
I. INTRODUCTION
In a distributed storage system, information pertaining to a data ﬁle is dispersed across nodes in a network in such a manner that an end-user (whom we term as a data-collector, or a DC) can retrieve the data stored by tapping into neighboring nodes. A popular option that reduces network congestion and that leads to increased resiliency in the face of node failures, is to employ erasure coding, for example by calling upon maximum-distance-separable (MDS) codes such as Reed-Solomon (RS) codes.
Let B be the total number of message symbols, over a ﬁnite ﬁeld Fq of size q. With RS codes, data is stored across n nodes in the network in such a way that the entire data can be recovered by a data-collector by connecting to any arbitrary k nodes, a process of data recovery that we will refer to as reconstruction. Several distributed storage systems such as RAID-6, OceanStore [1] and Total Recall [2] employ such an erasure-coding option.
Upon failure of an individual node, a self-sustaining data storage network must necessarily possess the ability to repair the failed node. An obvious means to accomplish this, is to permit the replacement node to connect to any k nodes, download the entire data, and extract the data that was stored in the failed node. For example, RS codes treat the data stored in each node as a single symbol belonging to the ﬁnite ﬁeld Fq. When this is coupled with the restriction that individual nodes perform linear operations over
The material in this paper was presented in part at the ITA Workshop at UCSD, 2010, in part at the IEEE Information Theory Workshop, Cairo, Egypt, January 2010 and in part at Allerton 2009.
Nihar B. Shah, K. V. Rashmi and P. Vijay Kumar are with the Department of Electrical Communication Engineering, Indian Institute of Science, Bangalore, 560 012 India (email: {nihar,rashmikv,vijay}@ece.iisc.ernet.in). P. Vijay Kumar is also an adjunct faculty member of the Electrical Engineering Systems Department at the University of Southern California, Los Angeles, CA 90089-2565.
Kannan Ramchandran is with the Department of Electrical Engineering and Computer Science, University of California at Berkeley, Berkeley, CA 94720 USA (e-mail: kannanr@eecs.berkeley.edu).

2

node 1

node 2

α

α node 3
α α

node k

node k+1

DC
data collector

node 1 node 2 node 3
node k node k+1

β

rep. node 1

β

α capacity

node

β

β β

node d+1

node d+1

node n

node n

α capacity
nodes (a)

α capacity
nodes (b)

Fig. 1: The regenerating codes setup: (a) data reconstruction, and (b) repair of a failed node.

Fq, it follows that the smallest unit of data that can be downloaded from a node to assist in the repair of a failed node (namely, an Fq symbol), equals the amount of information stored in the node itself. As a consequence of the MDS property of an RS code, when carrying out repair of a failed node, the replacement node must necessarily collect data from at least k other nodes. As a result, it follows that the total amount of data download needed to repair a failed node can be no smaller than B, the size of the entire ﬁle. But clearly, downloading the entire B units of data in order to recover the data stored in a single node that stores only a fraction of the entire data ﬁle is wasteful, and raises the question as to whether there is a better option. Such an option is provided by the concept of a regenerating code introduced by Dimakis et al. [3].
Regenerating codes overcome the difﬁculty encountered when working with an RS code by working with codes whose symbol alphabet is a vector over Fq, i.e., an element of Fαq for some parameter α > 1. Each node stores a vector symbol, or equivalently stores α symbols over Fq. In this setup, it is clear that while maintaining linearity over Fq, it is possible for an individual node to transfer a fraction of the data stored within the node.
Apart from this new parameter α, two other parameters (d, β) are associated with regenerating codes. Thus we have
{q, [n, k, d], (β, α, B)}
as the parameter set of a regenerating code. Under the deﬁnition of regenerating codes introduced in [3], a failed node is permitted to connect to an arbitrary subset of d nodes out of the remaining (n − 1) nodes while downloading β ≤ α symbols from each node. The total amount dβ of data downloaded for repair purposes is termed the repair bandwidth. Typically, with a regenerating code, the average repair bandwidth dβ is small compared to the size of the ﬁle B. Fig. 1a and Fig. 1b illustrate reconstruction and node repair respectively, also depicting the relevant parameters.
The cut-set bound of network coding can be invoked to show that the parameters of a regenerating

3

code must necessarily satisfy [4]:

k−1

B ≤ min{α, (d − i)β}.

(1)

i=0

It is desirable to minimize both α as well as β since minimizing α results in a minimum storage solution while minimizing β (for a ﬁxed d) results in a solution that minimizes the repair bandwidth. It turns out that there is a tradeoff between α and β. The two extreme points in this tradeoff are termed the minimum storage regenerating (MSR) and minimum bandwidth regenerating (MBR) points respectively. The parameters α and β for the MSR point on the tradeoff can be obtained by ﬁrst minimizing α and then minimizing β to obtain

B αMSR = k ,
B βMSR = k(d − k + 1) . (2)

Reversing the order, leads to the MBR point which thus corresponds to

2B βMBR = k(2d − k + 1) ,
2dB αMBR = k(2d − k + 1) . (3)

The focus of the present paper is on the MSR point. Note that regenerating codes with (α = αMSR) and (β = βMSR) are necessarily MDS codes over the vector alphabet Fαq . This follows since the ability to
reconstruct the data from any arbitrary k nodes necessarily implies a minimum distance dmin = n − k + 1. Since the code size equals (qα)k, this meets the Singleton bound causing the code to be an MDS code.

A. Choice of the Parameter β Let us next rewrite (2) in the form

αMSR = βMSR(d − k + 1)

B = βMSR(d − k + 1)(k).

(4)

Thus if one is able to construct an [n, k, d] MSR code with repair bandwidth achieving the cut-set bound for a given value of β, then both αMSR = (d − k + 1)βMSR and the size B = k αMSR of the ﬁle are necessarily ﬁxed. It thus makes sense to speak of an achievable triple

(β, α = (d − k + 1)β, B = kα).

However if a triple (β, α, B) is achievable, then so is the triple ( β, α, B) simply through a process of

divide and conquer, i.e., we divide up the message ﬁle into sub-ﬁles and apply the code for (β, α, B) to

each of the sub-ﬁles. Hence, codes that are applicable for the case β = 1, are of particular importance

as they permit codes to be constructed for every larger integral value of β. In addition, a code with small

β will involve manipulating a smaller number of message symbols and hence will in general, be of lesser

complexity. For these reasons, in the present paper, codes are constructed for the case β = 1. Setting

β = 1 at the MSR point yields

αMSR = d − k + 1.

(5)

Note that when α = 1, we have B = k and meeting the cut-set bound would imply d = k. In this case, any [n, k]-MDS code will achieve the bound. Hence, we will consider α > 1 throughout.

4

B. Additional Terminology
1) Exact versus Functional Repair: In general, the cut-set bound (as derived in [3]) applies to functionalrepair, that is, it applies to networks which replace a failed node with a replacement node which can carry out all the functions of the earlier failed node, but which does not necessarily store the same data. Thus, under functional-repair, there is need for the network to inform all nodes in the network of the replacement. This requirement is obviated under exact-repair, where a replacement node stores exactly the same data as was stored in the failed node. We will use the term exact-repair MSR code to denote a regenerating code operating at the minimum storage point, that is capable of exact-repair.
2) Systematic Codes: A systematic regenerating code can be deﬁned as a regenerating code designed in such a way that the B message symbols are explicitly present amongst the kα code symbols stored in a select set of k nodes, termed as the systematic nodes. Clearly, in the case of systematic regenerating codes, exact-repair of the systematic nodes is mandated. A data-collector connecting to the k systematic nodes obtains the B message symbols in an uncoded form, making systematic nodes a preferred choice for data recovery. This makes the fast repair of systematic nodes a priority, motivating the interest in minimizing the repair bandwidth for the exact-repair of systematic nodes.
The immediate question that this raises, is as to whether or not the combination of (a) restriction to repair of systematic nodes and (b) requirement for exact-repair of the systematic nodes leads to a bound on the parameters (α, β) different from the cut-set bound. It turns out that the same bound on the parameters (α, β) appearing in (2) still applies and this is established in Section III.

C. Exact-repair MSR Codes as Network Codes
The existence of regenerating codes for the case of functional-repair was proved ( [3], [4]) after casting the reconstruction and repair problems as a multicast network coding problem, and using random network codes to achieve the cut-set bound. As shown in our previous work [12], construction of exact-repair MSR codes for the repair of systematic nodes is most naturally mapped to a non-multicast problem in network coding, for which very few results are available.

DC

DC

DC

Node 1 Rate α
Node 2 Rate α

node 3in

node 3out

node 4in

node 4out

DC DC

1 1

1'

1

1

1 1

2'

DC

Fig. 2: The MSR code design problem for the exact-repair of just the systematic nodes, as a non-multicast network coding
problem. Here, [n = 4, k = 2 d = 3] with β = 1 giving (α = 2, B = 4). Unmarked edges have capacity α. Nodes labelled DC are data-collector sinks, and those labelled l are replacement node sinks.

The non-multicast network for the parameter set [n = 4, k = 2, d = 3] with β = 1 is shown in Fig. 2. In general, the network can be viewed as having k source nodes, corresponding to the k systematic nodes, generating α symbols each per channel use. The parity nodes correspond to downlink nodes in the graph.

5
To capture the fact that a parity node can store only α symbols, it is split (as in [4]) into two parts connected by a link of capacity α : parity node m is split into min and mout with all incoming edges arriving at min and all outgoing edges emanating from mout.
The sinks in the network are of two types. The ﬁrst type correspond to data-collectors which connect to an arbitrary collection of k nodes in the network for the purposes of data reconstruction. Hence there are nk sinks of this type. The second type of sinks represent a replacement node that is attempting to duplicate a failed systematic node, with the node replacing systematic node denoted by . Sinks of this type connect to an arbitrary set of d out of the remaining (n − 1) nodes, and hence they are k n−d 1 in number. It is the presence of these sinks that gives the problem a non-multicast nature.
Thus, the present paper provides an instance where explicit code constructions achieve the cut-set bound for a non-multicast network, by exploiting the speciﬁc structure of the network.
Relation Between β and Scalar/Vector Network Coding: The choice of β as unity (as in Fig. 2) may be viewed as an instance of scalar network coding. Upon increase in the value of β, the capacity of each data pipe is increased by a factor of β, thereby transforming the problem into a vector network coding problem. Thus, β = 1 implies the absence of symbol extension, which in general, reduces the complexity of system implementation and is thus of greater practical interest.
D. Results of the Present Paper
The primary results of the present paper are: • The construction of a family of MDS codes for d = n − 1 ≥ 2k − 1 that enable exact-repair of
systematic nodes while achieving the cut-set bound on repair bandwidth. We have termed this code the MISER 1 code. • Proof that interference alignment is necessary for every exact-repair MSR code. • The proof of non-existence of linear exact-repair MSR codes for d < 2k −3 in the absence of symbol extension (i.e., β = 1). This result is clearly of interest in the light of on-going efforts to construct exact-repair codes with β = 1 meeting the cut-set bound [7]–[11], [13], [14], [17], [18]. • The construction, also explicit, of an MSR code for d = k + 1. For most values of the parameters, d = k + 1 falls under the d < 2k − 3 regime, and in light of the non-existence result above, exactrepair is not possible. The construction does the next best thing, namely, it carries out repair that is approximately exact 2.
Note that the only explicit codes of the MDS type to previously have been constructed are for small values of parameters, [n = 4, k = 2, d = 3] and [n = 5, k = 3, d = 4]. Prior work is described in greater detail in Section II.
The remainder of the paper is organized as follows. A brief overview of the prior literature in this ﬁeld is given in the next section, Section II. The setting and notation are explained in Section III. The appearance of interference alignment in the context of distributed storage for construction of regenerating codes is detailed in Section IV along with an illustrative example. Section V describes the MISER code. The non-existence of linear exact-repair MSR codes for d < 2k − 3 in the absence of symbol extension can be found in Section VI, along with the proof establishing the necessity of interference alignment. Section VII describes the explicit construction of an MSR code for d = k + 1. The ﬁnal section, Section VIII, draws conclusions.
1Short for an MDS, Interference-aligning, Systematic, Exact-Regenerating code, that is miserly in terms of bandwidth expended to repair a systematic node.
2The code consists of an exact-repair part along with an auxiliary part whose repair is not guaranteed to be exact. This is explained in greater detail in Section VII.

6

II. PRIOR WORK
The concept of regenerating codes, introduced in [3], [4], permit storage nodes to store more than the minimal B/k units of data in order to reduce the repair bandwidth. Several distributed systems are analyzed, and estimates of the mean node availability in such systems are obtained. Using these values, the substantial performance gains offered by regenerating codes in terms of bandwidth savings are demonstrated.
The problem of minimizing repair bandwidth for the functional repair of nodes is considered in [3], [4] where it is formulated as a multicast network-coding problem in a network having an inﬁnite number of nodes. A cut-set lower bound on the repair bandwidth is derived. Coding schemes achieving this bound are presented in [4], [6] which however, are non-explicit. These schemes require large ﬁeld size and the repair and reconstruction algorithms are also of high complexity.
Computational complexity is identiﬁed as a principal concern in the practical implementation of distributed storage codes in [5] and a treatment of the use of random, linear, regenerating codes for achieving functional-repair can be found there.
The authors in [7] and [8] independently introduce the notion of exact-repair. The idea of using interference alignment in the context of exact-repair codes for distributed storage appears ﬁrst in [7]. Code constructions of the MDS type are provided, which meet the cut-set lower bound when k = 2. Even here, the constructions are not explicit, and have large complexity and ﬁeld-size requirement.
The ﬁrst explicit construction of regenerating codes for the MBR point appears in [8], for the case d = n − 1. These codes carry out uncoded exact-repair and hence have zero repair complexity. The required ﬁeld size is of the order of n2, and in terms of minimizing bandwidth, the codes achieve the cut-set bound.
A computer search for exact-repair MSR codes for the parameter set [n = 5, k = 3, d = 4], β = 1, is carried out in [9], and for this set of parameters, codes for several values of ﬁeld size are obtained.
A slightly different setting, from the exact-repair situation is considered in [11], where optimal MDS codes are given for the parameters d = k + 1 and n > 2k. Again, the schemes given here are non-explicit, and have high complexity and large ﬁeld-size requirement.
We next describe the setting and notation to be used in the current paper.

III. SETTING AND NOTATION

The distributed storage system considered in this paper consists of n storage nodes, each having the

capacity to store α symbols. Let u be the message vector of length B comprising of the B message

symbols. Each message symbol can independently take values from Fq, a ﬁnite ﬁeld of size q.

In this paper, we consider only linear storage codes. As in traditional coding theory, by a linear storage

code, we mean that every stored symbol is a linear combination of the message symbols, and only linear

operations are permitted on the stored symbols. Thus all symbols considered belong to Fq. For m = 1, . . . , n, let the (B × α) matrix G(m) denote the generator matrix of node m. Node m stores

the following α symbols

utG(m).

(6)

In the terminology of network coding, each column of the nodal generator matrix G(m) corresponds to the global kernel (linear combination vector) associated to a symbol stored in the node. The (B × nα) generator matrix for the entire distributed-storage code, is given by

G = G(1) G(2) · · · G(n) .

(7)

Note that under exact-repair, the generator matrix of the code remains unchanged.
We will interchangeably speak of a node as either storing α symbols, by which we will mean the symbols utG(m) or else as storing α vectors, by which we will mean the corresponding set of α global kernels that form the columns of nodal generator matrix G(m).

7

We partition the B(= kα)-length vector u into k components, ui for i = 1, . . . , k, each comprising of

α distinct message symbols:

u1

u =  ...  .

(8)

uk

We also partition the nodal generator matrices analogously into k sub-matrices as

G(1m)

 G(m) = 

...

 ,

(9)



G(km)

where each G(im) is an (α × α) matrix. We will refer to G(im) as the ith component of G(m). Thus, node m stores the α symbols
k

utG(m) = utiG(im).

(10)

i=1

Out of the n nodes, the ﬁrst k nodes (i.e., nodes 1, . . . , k) are systematic. Thus, for systematic node

G( ) = Iα if i = ∀i ∈ {1, . . . , k},

(11)

i

0α if i =

where 0α and Iα denote the (α × α) zero matrix and identity matrix respectively; systematic node thus stores the α message symbols that u is comprised of.
Upon failure of a node, the replacement node connects to an arbitrary set of d remaining nodes, termed as helper nodes, downloading β symbols from each. Thus, each helper node passes a collection of β linear combinations of the symbols stored within the node. As described in Section I-A, an MSR code with β = 1 can be used to construct an MSR code for every higher integral value of β. Thus it sufﬁces to provide constructions for β = 1 and that is what we do here. When β = 1, each helper node passes just a single symbol. Again, we will often describe the symbol passed by a helper node in terms of its associated global kernel, and hence will often speak of a helper node passing a vector 3.

Throughout the paper, we use superscripts to refer to node indices, and subscripts to index the elements
of a matrix. The letters m and are reserved for node indices; in particular, the letter is used to index
systematic nodes. All vectors are assumed to be column vectors. The vector ei represents the standard basis vector of length α, i.e., ei is an α-length unit vector with 1 in the ith position and 0s elsewhere. For a positive integer p, we denote the (p × p) zero matrix and the (p × p) identity matrix by 0p and Ip respectively. We say that a set of vectors is aligned if the vector-space spanned by them has dimension
at most one.

We next turn our attention to the question as to whether or not the combination of (a) restriction to systematic-node repair and (b) requirement of exact-repair of the systematic nodes leads to a bound on the parameters (α, β) different from the cut-set bound appearing in (1).
The theorem below shows that the cut-set bound comes into play even if functional repair of a single node is required.
Theorem 1: Any [n, k, d]-MDS regenerating code (i.e., a regenerating code satisfying B = kα) that guarantees the functional-repair of even a single node, must satisfy the cut-set lower bound of (1) on
3A simple extension to the case of β > 1 lets us treat the global kernels of the β symbols passed by a helper node as a subspace of dimension at most β. This ‘subspace’ viewpoint has been found useful in proving certain general results at the MBR point in [8], and for the interior points of the tradeoff in [13].

8

repair bandwidth, i.e., must satisfy

B

β≥

.

(12)

k(d − k + 1)

Proof: First, consider the case when β = 1. Let denote the node that needs to be repaired, and let

{mi | i = 1, . . . , d} denote the d helper nodes assisting in the repair of node . Further, let {γ(mi, ) | i =

1, . . . , d} denote the vectors passed by these helper nodes. At the end of the repair process, let the (B ×α)

matrix G( ) denote the generator matrix of the replacement node (since we consider only functional-repair

in this theorem, G( ) need not be identical to the generator matrix of the failed node).

Looking back at the repair process, the replacement node obtains G( ) by operating linearly on the

collection of d vectors {γ(mi, ) | i = 1, . . . , d} of length B. This, in turn, implies that the dimension of

the nullspace of the matrix

G( ) γ(m1, ) · · · γ(md, )

(13)

should be greater than or equal to the dimension of G(l), which is α. However, the MDS property requires that at the end of the repair process, the global kernels associated to any k nodes be linearly independent, and in particular, that the matrix

G( ) γ(m1, ) · · · γ(mk−1, )

(14)

have full-rank. It follows that we must have

d ≥ k − 1 + α.

The proof for the case β > 1, when every helper node passes a set of β vectors, is a straightforward

extension that leads to:

dβ ≥ (k − 1)β + α.

(15)

Rearranging the terms in the equation above, and substituting α = Bk leads to the desired result.

Thus, we recover equation (2), and in an optimal code with β = 1, we will continue to have d = k − 1 + α.

In this way, we have shown that even in the setting that we address here, namely that of the exact-repair of the systematic nodes leads us to the same cut-set bound on repair bandwidth as in (1). The next section explains how the concept of interference alignment arises in the distributed-storage context.

IV. INTERFERENCE ALIGNMENT IN REGENERATING CODES
The idea of interference alignment has recently been proposed in [19], [20] in the context of wireless communication. The idea here is to design the signals of multiple users in such a way that at every receiver, signals from all the unintended users occupy a subspace of the given space, leaving the remainder of the space free for the signal of the intended user.
In the distributed-storage context, the concept of ‘interference’ comes into play during the exact-repair of a failed node in an MSR code. We present the example of a systematic MSR code with [n = 4, k = 2, d = 3] and β = 1, which gives (α = d − k + 1 = 2, B = kα = 4). Let {u1, u2, u3, u4} denote the four message symbols. Since k = 2 here, we may assume that nodes 1 and 2 are systematic and that node 1 stores {u1, u2} and node 2 stores {u3, u4}. Nodes 3 and 4 are then the parity nodes, each storing two linear functions of the message symbols.
Consider repair of systematic node 1 wherein the d = 3 nodes, nodes 2, 3 and 4, serve as helper nodes. The second systematic node, node 2, can only pass a linear combination of message symbols u3 and u4. The two symbols passed by the parity nodes are in general, functions of all four message symbols: (a1u1 + a2u2 + a3u3 + a4u4) and (b1u1 + b2u2 + b3u3 + b4u4) respectively.

9

Node 1 Node 2 Node 3 Node 4

u1 u3 3u1 + 2u2 + u3 3u1 + 4u2 + 2u3

u2 u4 u2 + 2u3 + 3u4 u2 + 2u3 + u4

u3
3u1 + 2u2 + u3
3u1 + 4u2 + 2u3
Desired Interference components: components: independent aligned

Replacement Node 1

Fig. 3: Illustration of interference alignment during exact-repair of systematic node 1.

Using the symbols passed by the three helper nodes, the replacement of node 1 needs to be able to recover message symbols {u1, u2}. For obvious reasons, we will term (a1u1 + a2u2) and (b1u1 + b2u2) as the desired components of the messages passed by parity nodes 3 and 4 and the terms (a3u3 + a4u4) and (b3u3 + b4u4) as interference components.
Since node 2 cannot provide any information pertaining to the desired symbols {u1, u2}, the replacement node must be able to recover the desired symbols from the desired components (a1u1 + a2u2) and (b1u1 + b2u2) of the messages passed to it by the parity nodes 3 and 4. To access the desired components, the replacement node must be in a position to subtract out the interference components (a3u3 + a4u4) and (b3u3 + b4u4) from the received linear combinations (a1u1 + a2u2 + a3u3 + a4u4) and (b1u1 + b2u2 + b3u3 + b4u4); the only way to subtract out the interference component is by making use of the linear combination of {u3, u4} passed by node 2. It follows that this can only happen if the interference components (a3u3 + a4u4) and (b3u3 + b4u4) are aligned, meaning that they are scalar multiples of each other.
An explicit code over F5 for the parameters chosen in the example is shown in Fig. 3. The exact-repair of systematic node 1 is shown, for which the remaining nodes pass the ﬁrst of the two symbols stored in them. Observe that under this code, the interference component in the two symbols passed by the parity nodes are aligned in the direction of u3, i.e., are scalar multiples of u3. Hence node 2 can simply pass u3 and the replacement node can then make use of u3 to cancel (i.e., subtract out) the interference.
In the context of regenerating codes, interference alignment was ﬁrst used by Wu et al. [7] to provide a scheme (although, not explicit) for the exact-repair at the MSR point. However, interference alignment is employed only to a limited extent as only a portion of the interference components is aligned and as a result, the scheme is optimal only for the case k = 2.
In the next section, we describe the construction of the MISER code which aligns interference and achieves the cut-set bound on the repair bandwidth for repair of systematic nodes. This is the ﬁrst interference-alignment-based explicit code construction that meets the cut-set bound.
V. CONSTRUCTION OF THE MISER CODE
In this section we provide an explicit construction for a systematic, MDS code that achieves the lower bound on repair bandwidth for the exact-repair of systematic nodes and which we term as the MISER code. We begin with an illustrative example that explains the key ideas behind the construction. The general code construction for parameter sets of the form n = 2k, d = n − 1 closely follows the construction in the example. A simple, code-shortening technique is then employed to extend this code construction to the more general parameter set n ≥ 2k, d = n − 1.
The construction technique can also be extended to the even more general case of arbitrary n, d ≥ 2k−1, under the added requirement however, that the replacement node connect to all of the remaining systematic nodes.

10

A. An Example
The example deals with the parameter set, [n = 6, k = 3, d = 5], β = 1, so that (α = d − k + 1 = 3, B = kα = 9). We select F7 as the underlying ﬁnite ﬁeld so that all message and code symbols are drawn from F7. Note that we have α = k = 3 here. This is true in general: whenever n = 2k and d = n − 1, we have α = d − k + 1 = k which simpliﬁes the task of code construction.

1) Design of Nodal Generator Matrices: As k = 3, the ﬁrst three nodes are systematic and store data

in uncoded form. Hence

I3 

03

03

G(1) = 03 , G(2) = I3 , G(3) = 03 .

(16)

03

03

I3

A key ingredient of the code construction presented here is the use of a Cauchy matrix [21]. Let

 ψ1(4) Ψ3 =  ψ2(4)
ψ3(4)

ψ1(5) ψ2(5) ψ3(5)

ψ1(6)  ψ2(6)  ψ3(6)

(17)

be a (3 × 3) matrix such that each of its sub-matrices is full rank. Cauchy matrices have this property and in our construction, we will assume Ψ3 to be a Cauchy matrix.

We choose the generator matrix of parity node m (m = 4, 5, 6) to be

 2ψ1(m)  2ψ2(m)

0 ψ1(m)

 0
0 

 

2ψ3(m)

0



ψ1(m)

 



 

ψ2(m)

2ψ1(m)

 0





G(m) =  0 2ψ2(m) 0  , (18)

 

0



2ψ3(m)

ψ2(m)

 



 

ψ3(m)



0 

0 ψ3(m)

2ψ1(m)

 



2ψ2(m) 

0

0 2ψ3(m)

where the location of the non-zero entries of the ith sub-matrix are restricted to lie either along the diagonal or else within the ith column. The generator matrix is designed keeping in mind the need for interference alignment and this will be made clear in the discussion below concerning the exact-repair of systematic nodes. The choice of scalar ‘2’ plays an important role in the data reconstruction property; the precise role of this scalar will become clear when this property is discussed. An example of the [6, 3, 5] MISER code over F7 is provided in Fig. 4, where the Cauchy matrix Ψ is chosen as

5 4 1

Ψ =  2 5 4 .

(19)

325

Also depicted in the ﬁgure is the exact-repair of node 1, for which each of the remaining nodes pass the ﬁrst symbol that they store. It can be seen that the ﬁrst symbols stored in the three parity nodes 4, 5 and 6 have their interference components (components 2 and 3) aligned and their desired components (component 1) linearly independent.

11

Systematic nodes

Node 1
u1 u2 u3

Node 2
u4 u5 u6

Node 3
u7 u8 u9
Interference aligned
Interference aligned

Node 4

3u1 0 0

+

+

+

4u2 5u2 0

+

+

+

6u3 0 5u3

+

+

+

2u4 3u4 0

+

+

+

0 4u5 0

+

+

+

0 6u6 2u6

+

+

+

3u7 0 3u7

+

+

+

0 3u8 4u8

+

+

+

0 0 6u9

Parity nodes

Node 5

u1 0 0

+

+

+

3u2 4u2 0

+

+

+

4u3 0 4u3

+

+

+

5u4 u4 0

+

+

+

0 3u5 0

+

+

+

0 4u6 5u6

+

+

+

2u7 0 u7

+

+

+

0 2u8 3u8

+

+

+

0 0 4u9

Node 6

2u1 0 0

+

+

+

u2 u2 0

+

+

+

3u3 0 u3

+

+

+

4u4 2u4 0

+

+

+

0 u5 0

+

+

+

0 3u6 4u6

+

+

+

5u7 0 2u7

+

+

+

0 5u8 u8

+

+

+

0 0 3u9

Fig. 4: An example of the [6, 3, 5] MISER code over F7. Here, {u1, . . . , u9} denote the message symbols and the code
symbols stored in each of the nodes are shown. Exact-repair of node 1 is also depicted.

The key properties of the MISER code will be established in the next section, namely: • that the code is an MDS code over alphabet Fαq and this property enables data reconstruction and • that the code has the ability to carry out exact-repair of the systematic nodes while achieving the
cut-set bound on repair bandwidth.
We begin by establishing the exact-repair property.

2) Exact-repair of Systematic Nodes: Our algorithm for systematic node repair is simple. As noted above, each node stores α = k symbols. These k symbols are assumed to be ordered so that we may speak of the ﬁrst symbol stored by a node, etc. To repair systematic node , 1 ≤ ≤ k, each of the remaining nodes passes their respective th symbol.
Suppose that in our example construction here, node 1 fails. Each of the parity nodes then pass on their ﬁrst symbol, or equivalently, in terms of global kernels, the ﬁrst column of their generator matrices for the repair of node 1. Thus, from nodes 4, 5, and 6, the replacement node obtains

 2ψ1(4)   2ψ2(4)   2ψ3(4) 





 ψ2(4) 

 

0

, 

0 









 ψ3(4) 

0

0

 2ψ1(5)   2ψ2(5)   2ψ3(5) 





 ψ2(5) 

 

0

, 

0 









 ψ3(5) 

0

0

 2ψ1(6)   2ψ2(6)   2ψ3(6) 





 ψ2(6) 

 

0

. 

0 









 ψ3(6) 

0

0

(20)

Note that in each of these vectors, the desired (ﬁrst) components are a scaled version of the respective
columns of the Cauchy matrix Ψ3. The interference (second and third) components are aligned along the vector [1 0 0]t. Thus, each interference component is aligned along a single dimension. Systematic nodes
2 and 3 then pass a single vector each that is designed to cancel out this interference. Speciﬁcally, nodes

12

2 and 3 respectively pass the vectors

0 0

0 0

 

0

 

 

0

 

 1   0 

 0 ,  0  .

(21)

 

0  0  0

0  1  0

0

0

The net result is that after interference cancellation has taken place, replacement node 1 is left with

access to the columns of the matrix

 2Ψ3 

 03  .

03

Thus the desired component is a scaled Cauchy matrix Ψ3. By multiplying this matrix on the right by

21 Ψ−3 1, one recovers

 I3 

 03 

03

as desired. Along similar lines, when nodes 2 or 3 fail, the parity nodes pass the second or third columns of
their generator matrices respectively. The design of generator matrices for the parity nodes is such that interference alignment holds during the repair of either systematic node, hence enabling the exact-repair of all the systematic nodes.

3) Data Reconstruction (MDS property): For the reconstruction property to be satisﬁed, a data-collector downloading symbols stored in any three nodes should be able to recover all the nine message symbols. That is, the (9 × 9) matrix formed by columnwise concatenation of any three nodal generator matrices, should be non-singular. We consider the different possible sets of three nodes that the data-collector can connect to, and provide appropriate decoding algorithms to handle each case.
(a) Three systematic nodes: When a data-collector connects to all three systematic nodes, it obtains all the message symbols in uncoded form and hence reconstruction is trivially satisﬁed.
(b) Two systematic nodes and one parity node: Suppose the data-collector connects to systematic nodes 2 and 3, and parity node 4. It obtains all the symbols stored in nodes 2 and 3 in uncoded form and proceeds to subtract their effect from the symbols in node 4. It is thus left to decode the message symbols u1, that are encoded using matrix G(14) given by

 2ψ1(4) 0

 0

G(14) =  2ψ2(4) ψ2(4) 0  . (22)

2ψ3(4) 0 ψ3(4)

This lower-triangular matrix is non-singular since by deﬁnition, all the entries in a Cauchy matrix are non-zero. The message symbols u1 can hence be recovered by inverting G(14).
(c) All three parity nodes: We consider next the case when a data-collector connects to all three parity
nodes. Let C1 be the (9 × 9) matrix formed by the columnwise concatenation of the generator matrices
of these three nodes.

Claim 1: The data-collector can recover all the message symbols encoded using the matrix C1, formed

13

by the columnwise concatenation of the generator matrices of the three parity nodes:

C1 = G(4) G(5) G(6) .

(23)

Proof: We permute the columns of C1 to obtain a second matrix C2 in which the ith (i = 1, 2, 3) columns of all the three nodes are adjacent to each other as shown below:

 2ψ1(4)

 2ψ2(4)

 

2ψ3(4)

  ψ2(4) 

C2 =  0 0



 

ψ3(4)

0 

0

2ψ1(5) 2ψ2(5) 2ψ3(5)
ψ2(5) 0
0
ψ3(5) 0
0

2ψ1(6) 2ψ2(6) 2ψ3(6)
ψ2(6) 0
0
ψ3(6) 0
0

0 ψ1(4)
0
2ψ1(4) 2ψ2(4) 2ψ3(4)
0 ψ3(4)
0

0 ψ1(5)
0
2ψ1(5) 2ψ2(5) 2ψ3(5)
0 ψ3(5)
0

0 ψ1(6)
0
2ψ1(6) 2ψ2(6) 2ψ3(6)
0 ψ3(6)
0

0
0 ψ1(4)
0
0 ψ2(4)
2ψ1(4) 2ψ2(4) 2ψ3(4)

0
0 ψ1(5)
0
0 ψ2(5)
2ψ1(5) 2ψ2(5) 2ψ3(5)


0

0

ψ1(6)

 



0 

0 . ψ2(6) 


2ψ1(6)

 

2ψ2(6)  
2ψ3(6)

group 1

group 2

group 3

Note that a permutation of the columns does not alter the information available to the data-collector
and hence is a permissible operation. This rearrangement of coded symbols, while not essential, simpliﬁes the proof. We then post-multiply by a block-diagonal matrix Ψ−3 1 to obtain the matrix C3 given by

 Ψ−3 1 03 03 

C3 = C2  03 Ψ−3 1 03 

(24)

03 03 Ψ−3 1

2 0 0 0 0 0 0 0 0

0 2 0 1 0 0 0 0 0

0 0 2 0 0 0 1 0 0





0 1 0 2 0 0 0 0 0





=  0 0 0 0 2 0 0 0 0 .

(25)





0 0 0 0 0 2 0 1 0





0 0 1 0 0 0 2 0 0





0 0 0 0 0 1 0 2 0

000000002

To put things back in perspective, the data collector at this point, has access to the coded symbols

utC3

associated with the three parity nodes. From the nature of the matrix it is evident that message symbols u1, u5 and u9 are now available to the data-collector, and their effect can be subtracted from the remaining symbols to obtain the matrix

2 0 1 0 0 0

0 2 0 0 1 0

1 0 2 0 0 0

[u2 u3 u4 u6 u7 u8]  0

0

0

2

0

1

. 

(26)





0 1 0 0 2 0

000102

C4

14

As 22 = 1 in F7, the matrix C4 above can be veriﬁed to be non-singular and thus the remaining message

symbols can also be recovered by inverting C4.

(d) One systematic node and two parity nodes: Suppose the data-collector connects to systematic node

1 and parity nodes 4 and 5. All symbols of node 1, i.e., u1 are available to the data-collector. Thus, it

needs to decode the message-vector components u2 and u3 which are encoded using a matrix B1 given

by

B1 =

G(24) G(34)

G(25) G(35)

(27)

Claim 2: The block-matrix B1 above is non-singular and in this way, the message-vector components
u2 and u3 can be recovered. Proof: Once again, we begin by permuting the columns of B1. For i = 2, 3, 1 (in this order), we
group the ith columns of the two parity nodes together to give the matrix

 2ψ1(4) 2ψ1(5) 0

0 ψ2(4) ψ2(5) 

 2ψ2(4) 2ψ2(5) 0 

0 0 0 

 

2ψ3(4)

2ψ3(5)

ψ2(4)

ψ2(5)

0

0

 

B2 =  0

(4)

(5) (4) (5)  .

0 2ψ1 2ψ1 ψ3 ψ3 





 

ψ3(4)

ψ3(5) 2ψ2(4) 2ψ2(5)

0

0 

0

0 2ψ3(4) 2ψ3(5) 0

0

(28)

Let Ψ2 be the (2 × 2) sub-matrix of the Cauchy matrix Ψ3, given by

Ψ2 = ψψ2((44)) ψψ2((55)) .

3

3

(29)

Since every sub-matrix of Ψ3 is non-singular, so is Ψ2. Keeping in mind the fact that the data collector
can perform any linear operation on the columns of B2, we next multiply the last two columns of B2 by Ψ−2 1 (while leaving the other 4 columns unchanged) to obtain the matrix

 2ψ1(4) 2ψ1(5) 0

0 1 0

 2ψ2(4) 2ψ2(5) 0

0 0 0





B3 =  2ψ03(4) 2ψ03(5) 2ψψ2((44)) 2ψψ2((55)) 00 01  . (30)



1

1



 

ψ3(4)

ψ3(5)

2ψ2(4)

2ψ2(5)

0

 0

0

0 2ψ3(4) 2ψ3(5) 0 0

The message symbols associated to the last last two columns of B2 are now available to the data-collector and their effect on the rest of the encoded symbols can be subtracted out to get


 B4 = 


2ψ2(4) 2ψ3(4) ψ3(4)
0

2ψ2(5) 2ψ3(5) ψ3(5)
0

0
ψ2(4) 2ψ2(4) 2ψ3(4)

 0

ψ2(5)  .

2ψ2(5)

 

2ψ3(5)

(31)

Along the lines of the previous case, the matrix B4 above can be shown to be non-singular. We note that this condition is equivalent to the reconstruction in a MISER code with k = 2 and a data-collector that attempts to recover the data by connecting to the two parity nodes.

15

B. The General MISER Code for n = 2k, d = n − 1

In this section, the construction of MISER code for the general parameter set n = 2k, d = n − 1 is

provided. Since the MISER code is built to satisfy the cut-set bound, we have that d = α + k − 1 which

implies that

k=α .

(32)

This relation will play a key role in the design of generator matrices for the parity nodes as this will permit each parity node to reserve α = k symbols associated to linearly independent global kernels for the repair of the k systematic nodes. In the example just examined, we had α = k = 3. The construction of the MISER code for the general parameter set n = 2k, d = n − 1 is very much along the lines of the construction of the example code.
1) Design of Nodal Generator Matrices: The ﬁrst k nodes are systematic and store the message symbols in uncoded form. Thus the component generator matrices G(i ), 1 ≤ i ≤ k of the th systematic node, 1 ≤ ≤ k, are given by

G( ) = Iα if i = .

(33)

i

0α if i =

Let Ψ be an (α × (n − k)) matrix with entries drawn from Fq such that every sub-matrix of Ψ is of full rank. Since n − k = α = k, we have that Ψ is a square matrix 4. Let the columns of Ψ be given by

Ψ = ψ(k+1) ψ(k+2) · · · ψ(n)

(34)

where the mth column is given by

ψ1(m)

ψ(m) =  ...  .

(35)



ψα(m)

A Cauchy matrix is an example of such a matrix, and in our construction, we will assume Ψ to be a Cauchy matrix.

Deﬁnition 1 (Cauchy matrix): An (s × t) Cauchy matrix Ψ over a ﬁnite ﬁeld Fq is a matrix whose (i, j)th element (1 ≤ i ≤ s, 1 ≤ j ≤ t) equals (xi−1yj) where {xi} ∪ {yj} is an injective sequence, i.e., a sequence with no repeated elements.

Thus the minimum ﬁeld size required for the construction of a (s × t) Cauchy matrix is s + t. Hence

if we choose Ψ to be a Cauchy matrix,

q ≥ α + n − k.

(36)

Any ﬁnite ﬁeld satisfying this condition will sufﬁce for our construction. Note that since n − k ≥ α ≥ 2, we have q ≥ 4.

We introduce some additional notation at this point. Denote the jth column of the (α × α) matrix G(im) as g(m), i.e.,
i,j

G(im) = g(i,m1 ) · · · g(i,mα) .

(37)

The code is designed assuming a regeneration algorithm under which each of the α parity nodes passes its th column for repair of the th systematic node. With this in mind, for k + 1 ≤ m ≤ n, 1 ≤ i, j ≤ α,

4In Section V-D, we extend the construction to the even more general case of arbitrary n, d ≥ 2k − 1, under the added requirement however, that the replacement node connect to all of the remaining systematic nodes. In that section, we will be dealing with a rectangular (α × (n − k)) matrix Ψ.

16

we choose

(m)

ψ(m) if i = j

gi,j = ψi(m)ej if i = j (38)

where is an element from Fq such that = 0 and 2 = 1 (in the example provided in the previous section, ∈ F7 was set equal to 2). The latter condition 2 = 1 is needed during the reconstruction process, as was seen in the example. Note that there always exists such a value as long as q ≥ 4.
As in the example, the generator matrix is also designed keeping in mind the need for interference
alignment. This property is utilized in the exact-repair of systematic nodes, as described in the next section.

2) Exact-Repair of Systematic Nodes: The repair process we associate with the MISER code is simple.

The repair of a failed systematic node, say node , involves each of the remaining d = n − 1 nodes

passing their th symbols (or equivalently, associated global kernels) respectively. In the set of α vectors

passed by the parity nodes, the th (desired) component is independent, and the remaining (interference)

components are aligned. The interference components are cancelled using the vectors passed by the

remaining systematic nodes. Independence in the desired component then allows for recovery of the

desired message symbols.

The next theorem describes the repair algorithm in greater detail.

Theorem 2: In the MISER code, a failed systematic node can be exactly repaired by downloading one

symbol from each of the remaining d = n − 1 nodes.

Proof: Consider repair of the systematic node . Each of the remaining (n − 1) nodes passes its th

column, so that the replacement node has access to the global kernels represented by the columns shown

below:





e · · · 0 0 · · · 0 ψ1(k+1)e · · · ψ1(n)e

 

...

...

...

...

...

...

...

...

...

 





 0 · · · e 0 · · · 0 ψ(−k+11)e · · · ψ(−n)1e 

  0 ··· 0 0 ··· 0 

ψ(k+1) · · ·

ψ(n)

 ,



 0 · · · 0 e · · · 0 ψ(+k+11)e · · · ψ(+n)1e   ... . . . ... ... . . . ... ... . . . ... 





0 · · · 0 0 · · · e ψk(k+1)e · · · ψk(n)e

From systematic nodes From parity nodes

where e denotes the th unit vector of length α and 0 denotes a zero vector of length α.

Observe that apart from the desired th component, every other component is aligned along the vector

e . The goal is to show that some α linear combinations of the columns above will give us a matrix whose

th component equals the (α × α) identity matrix, and has zeros everywhere else. But this is clear from

the interference alignment structure just noted in conjunction with linear independence of the α vectors

in the desired component:

{ψ(k+1), · · · , ψ(n)}.

(39)

Next, we discuss the data reconstruction property.
3) Data Reconstruction (MDS Property): For reconstruction to be satisﬁed, a data-collector downloading all symbols stored in any arbitrary k nodes should be able to recover the B message symbols. For this, we need the (B × B) matrix formed by the columnwise concatenation of any arbitrary collection of

17

k nodal generator matrices to be non-singular. The proof of this property is along the lines of the proof in the example. For completeness, a proof is presented in the appendix.
Theorem 3: A data-collector connecting to any k nodes in the MISER code can recover all the B message symbols.
Proof: Please see the Appendix.

Remark 1: It is easily veriﬁed that both reconstruction and repair properties continue to hold even when we choose the generator matrices of the parity nodes g(m), k + 1 ≤ m ≤ n, 1 ≤ i, j ≤ α to be given by:
i,j

(m)

Σiψ(m) if i = j

gi,j = ψi(m)ej if i = j (40)

where Σi = diag{ i,1 , . . . ,

1) i,j = 0,

∀ i, j

2) i,j j,i = 1, ∀ i = j.

i,α} is an (α × α) diagonal matrix satisfying

The ﬁrst condition sufﬁces to ensure exact-repair of systematic nodes. The two conditions together ensure that the (MDS) reconstruction property holds as well.

C. The MISER Code for n ≥ 2k, d = n − 1
In this section we show how the MISER code construction for n = 2k, d = n − 1 can be extended to the more general case n ≥ 2k, d = n − 1. From the cut-set bound (5), for this parameter regime, we get

k≤α .

(41)

We begin by ﬁrst showing how an incremental change in parameters is possible.

Theorem 4: An [n, k, d], linear, systematic, exact-repair MSR code C can be derived from an [n = n + 1, k = k + 1, d = d + 1] linear, systematic, exact-repair MSR code C . Furthermore if d = ak + b in code C , d = ak + b + (a − 1) in code C.
Proof: We begin by noting that

n−k = n −k

(42)

α = α=d−k+1

(43)

B = k (d − k + 1) = B + α.

(44)

In essence, we use code shortening [22] to derive code C from code C . Speciﬁcation of code C requires that given a collection of B = kα message symbols, we identify the α code symbols stored in each of the n nodes. We assume without loss of generality, that in code C, the nodes are numbered 1 through n, with nodes 1 through k representing the systematic nodes. We next create an additional node numbered 0.
The encoding algorithm for code C is based on the encoding algorithm for code C . Given a collection of B message symbols to be encoded by code C, we augment this collection by an additional α message symbols all of which are set equal to zero. The ﬁrst set of B message symbols will be stored in systematic nodes 1 through k and the string of α zeros will be stored in node 0. Nodes 0 through k are then regarded as constituting a set of k = (k + 1) systematic nodes for code C . The remaining (n − k) parity nodes are ﬁlled using the encoding process associated with code C using the message symbols stored in the k nodes numbered 0 through k. Note that both codes C and C share the same number (n − k) of parity nodes.
To prove the data reconstruction property of C, it sufﬁces to prove that all the B message symbols can be recovered by connecting to an arbitrary set of k nodes. Given a data-collector connecting to a particular

Node 0
u1 u2 u3

Node 1
u4 u5 u6

Set equal to zero

18

Node 2
u7 u8 u9
zero

Node 3

3u1 0 0

+

+

+

4u2 5u2 0

+

+

+

6u3 0 5u3

+

+

+

2u4 3u4 0

+

+

+

0 4u5 0

+

+

+

0 6u6 2u6

+

+

+

3u7 0 3u7

+

+

+

0 3u8 4u8

+

+

+

0 0 6u9

Node 4

u1 0 0

+

+

+

3u2 4u2 0

+

+

+

4u3 0 4u3

+

+

+

5u4 u4 0

+

+

+

0 3u5 0

+

+

+

0 4u6 5u6

+

+

+

2u7 0 u7

+

+

+

0 2u8 3u8

+

+

+

0 0 4u9

Node 5

2u1 0 0

+

+

+

u2 u2 0

+

+

+

3u3 0 u3

+

+

+

4u4 2u4 0

+

+

+

0 u5 0

+

+

+

0 3u6 4u6

+

+

+

5u7 0 2u7

+

+

+

0 5u8 u8

+

+

+

0 0 3u9

Fig. 5: Construction of a [n = 5, k = 2, d = 4] MISER code from a [n = 6, k = 3, d = 5] MISER code. Shortening
the code with respect to node zero is equivalent to removing systematic node 0 as well as the top component of every nodal generator matrix. The resulting [n = 5, k = 2, d = 4] MISER code has {u4, . . . , u9} as its B = kα = 6 message symbols.

set of k nodes, we examine the corresponding scenario in code C in which the data-collector connects to node 0 in addition to these k nodes. By the assumed MDS property of code C , all the B message symbols along with the α message symbols stored in node 0 can be decoded using the data stored these (k + 1) nodes. However, since the α symbols stored in node 0 are all set equal to zero, they clearly play no part in the data-reconstruction process. It follows that the B message symbols can be recovered using the data from the k nodes (leaving aside node 0), thereby establishing that code C possesses the required MDS data-reconstruction property.
A similar argument can be used to establish the repair property of code C as well. Finally, we have
d = ak + b
⇒ d + 1 = a(k + 1) + b
⇒ d = ak + b + (a − 1).

By iterating the procedure in the proof of Theorem 4 above i times we obtain:
Corollary 5: An [n, k, d] linear, systematic, exact-repair MSR code C can be constructed by shortening a [n = n+i, k = k+i, d = d+i] linear, systematic, exact-repair MSR code C . Furthermore if d = ak +b in code C , d = ak + b + i(a − 1) in code C.
Remark 2: It is shown in the sequel (Section VI-B) that every linear, exact-repair MSR code can be made systematic. Thus, Theorem 4 and Corollary 5 apply to any linear, exact-repair MSR code (not just systematic). In addition, note that the theorem and the associated corollary hold for general values of [n, k, d] and are not restricted to the case of d = n − 1. Furthermore, a little thought will show that they apply to linear codes C that perform functional repair as well.
The next corollary follows from Corollary 5, and the code-shortening method employed in the Theorem 4.
Corollary 6: The MISER code for n ≥ 2k, d = n − 1 can be obtained by shortening the MISER code for n = n + (n − 2k), k = k + (n − 2k), d = d + (n − 2k) = n − 1 .
Example: The code-shortening procedure represented by Theorem 4 is illustrated by the example shown

19
in Fig. 5. Here it is shown how a MISER code having code parameters [n = 6, k = 3, d = 5], β = 1 and (α = d −k +1 = 3, B = α k = 9) yields upon shortening with respect to the message symbols in node 0, a MISER code having code parameters [n = 5, k = 2, d = 4], β = 1 and (α = d−k+1 = 3, B = αk = 6).
D. Extension to 2k − 1 ≤ d ≤ n − 1 When The Set of Helper Nodes Includes All Remaining Systematic Nodes
In this section, we present a simple extension of the MISER code to the case when 2k − 1 ≤ d ≤ n − 1, under the additional constraint however, that the set of d helper nodes assisting a failed systematic node includes the remaining k − 1 systematic nodes. The theorem below, shows that the code provided in Section V-B for n = 2k, d = n − 1 supports the case d = 2k − 1, d ≤ n − 1 as well as long as this additional requirement is met. From here on, extension to the general case d ≥ 2k − 1, d ≤ n − 1 is straightforward via the code-shortening result in Theorem 4. Note that unlike in the previous instance, the (α × (n − k)) Cauchy matrix used in the construction for d < n − 1 is a rectangular matrix.
Theorem 7: For d = 2k − 1, d ≤ n − 1, the code deﬁned by the nodal generator matrices in equations (33) and (38), achieves reconstruction and optimal, exact-repair of systematic nodes, provided the replacement node connects to all the remaining systematic nodes.
Proof: Reconstruction: The reconstruction property follows directly from the reconstruction property in the case of the original code.
Exact-repair of systematic nodes: The replacement node connects to the (k − 1) remaining systematic nodes and an arbitrary α parity nodes (since, meeting the cut-set bound requires d = k − 1 + α). Consider a distributed storage system having only these (k − 1 + α) nodes along with the failed node as its n nodes. Such a system has d = n − 1, d = 2k − 1 and is identical to the system described in Section V-B. Hence exact-repair of systematic nodes meeting the cut-set bound is guaranteed.
E. Analysis of the MISER Code
a) Field Size Required: The constraint on the ﬁeld size comes due to construction of the (α × (n − k)) matrix Ψ having all sub-matrices of full rank. For our constructions, since Ψ is chosen to be a Cauchy matrix, any ﬁeld of size (n + d − 2k + 1) or higher sufﬁces. For speciﬁc parameters, the matrix Ψ can be handcrafted to yield smaller ﬁeld sizes.
b) Complexity of Exact-Repair of Systematic Nodes: Each node participating in the exact-repair of systematic node i, simply passes its ith symbol, without any processing. The replacement node has to multiply the inverse of an (α × α) Cauchy matrix with an α length vector and then perform (k − 1) subtractions for interference cancellation.
c) Complexity of Reconstruction: The complexity analysis is provided for the case n = 2k, d = n−1, other cases follow on the similar lines. A data-collector connecting to the k systematic nodes can recover all the data without any additional processing. A data-collector connecting to some k arbitrary nodes has to (in the worst case) multiply the inverse of a (k × k) Cauchy matrix with k vectors, along with operations having a lower order of complexity.
F. Relation to Subsequent Work [14]
Two regenerating codes are equivalent if one code can be transformed into the other via a non-singular symbol remapping (this deﬁnition is formalized in Section VI-B). The capabilities and properties of equivalent codes are thus identical in every way.
The initial presentation of the MISER code in [10] (the name ‘MISER’ was coined only subsequently) provided the construction of the code along with two (of three) parts of what may be termed as a complete decoding algorithm, namely: (a) reconstruction by a data collector, and (b) exact-repair of failed systematic nodes. It was not known whether the third part of decoding, i.e., repair of a failed parity node could be carried out by the MISER code. Following the initial presentation of the MISER code, the authors of [14]

20

show how a common eigenvector approach can be used to establish that exact repair of the parity nodes is also possible under the MISER code construction 5.

VI. NECESSITY OF INTERFERENCE ALIGNMENT AND NON-EXISTENCE OF SCALAR, LINEAR, EXACT-REPAIR MSR CODES FOR d < 2k − 3
In Section V, explicit, exact-repair MSR codes are constructed for the parameter regimes (d ≥ 2k − 1, d = n − 1) performing reconstruction and exact-repair of systematic nodes. These constructions are based on the concept of interference alignment. Furthermore, these codes have a desirable property of having the smallest possible value for the parameter β, i.e., β = 1.
As previously discussed in Section I-C, the problem of constructing exact-repair MSR codes is (in part) a non-multicast network coding problem. In particular, for the case of β = 1, it reduces to a scalar network coding problem. Upon increase in the value of β, the capacity of every data pipe is increased by a factor of β, thereby transforming it into a vector network coding problem. Thus, β = 1 corresponds to the absence of symbol extension, which in general, reduces the complexity of system implementation. Furthermore, as noted in Section I-A, an MSR code for every larger integer value of β, can be obtained by concatenating multiple copies of a β = 1 code. For this reason, the case of β = 1 is of special interest and a large section of the literature in the ﬁeld of regenerating codes ( [7]–[11], [13], [14], [17], [18]) is devoted to this case.
In the present section, we show that for d < 2k − 3, there exist no linear, exact-repair MSR codes achieving the cut-set bound on the repair bandwidth in the absence of symbol extension. In fact, we show that the cut-set bound cannot be achieved even if exact-repair of only the systematic nodes is desired. We ﬁrst assume the existence of such a linear, exact-repair MSR code C satisfying:

(β = 1, B = kα, α = d − k + 1)

(45)

and

(d < 2k − 3 ⇒ α < k − 2).

(46)

Subsequently, we derive properties that this code must necessarily satisfy. Many of these properties hold for a larger regime of parameters and are therefore of independent interest. In particular, we prove that interference alignment, in the form described in Section IV, is necessary. We will show that when d < 2k − 3 the system becomes over-constrained, leading to a contradiction.
We begin with some some additional notation.

Remark 3: In recent work, subsequent to the original submission of this paper, it is shown in [15],

[16] that the MSR point under exact-repair can be achieved asymptotically for all [n, k, d] via an inﬁnite

symbol extension, i.e., in the limit as β → ∞. This is established by presenting a scheme under which

limβ→∞

γ dβ

=

1.

Note

that

in

the

asymptotic

setup,

since

both

α, B

are

multiples

of

β,

these

two

parameters

tend to inﬁnity as well.

A. Additional Notation
We introduce some additional notation for the vectors passed by the helper nodes to the replacement node. For , m ∈ {1, . . . , n}, = m, let γ(m, ), denote the vector passed by node m for repair of node . In keeping with our component notation, we will use γ(m, ) to denote the ith component, 1 ≤ i ≤ k, of
i
this vector. Recall that a set of vectors are aligned when the vector-space spanned by them has a dimension no
more than one. Given a matrix A, we denote its column-space by colspace[A] and its (right) null space by nullspace[A]. Clearly, γ(m, ) ∈ colspace G(m) .
5In [14] a class of regenerating codes is presented that have the same parameters as does the MISER code. This class of codes can however, be shown to be equivalent to the MISER code (and hence to each other) under the equivalence notion presented in Section VI-B.

21

B. Equivalent Codes
Two codes C and C are equivalent if C can be represented in terms of C by i) a change of basis of the vector space generated by the message symbols (i.e., a remapping of the
message symbols), and ii) a change of basis of the column-spaces of the nodal generator matrices (i.e., a remapping of the
symbols stored within a node). A more rigorous deﬁnition is as follows.

Deﬁnition 2 (Equivalent Codes): Two codes C and C are equivalent if

G (m) = W G(m) U (m)

(47)

γ (m, ) = W γ(m, )

(48)

∀ , m ∈ {1, . . . , n}, = m, for some (B × B) non-singular matrix W , and some (α × α) non-singular matrix U (m).

Since the only operator required to transform a code to its equivalent is a symbol remapping, the capabilities and properties of equivalent codes are identical in every respect. Hence, in the sequel, we will not distinguish between two equivalent codes and the notion of code equivalence will play an important role in the present section. Here, properties of a code that is equivalent to a given code are ﬁrst derived and the equivalence then guarantees that these properties hold for the given code as well. The next theorem uses the notion of equivalent codes to show that every linear exact-repair MSR code can be made systematic.

Theorem 8: Every linear, exact-repair MSR code can be made systematic via a non-singular linear

transformation of the rows of the generator matrix, which simply corresponds to a re-mapping of the

message symbols. Furthermore, the choice of the k nodes that are to be made systematic can be arbitrary.

Proof:

Let the generator matrix of the given linear, exact-repair MSR code C be G. We will derive an equivalent

code C that has its ﬁrst k nodes in systematic form. The reconstruction (MDS property) of code C implies

that the (B × B) sub-matrix of G,

G(1) G(2) · · · G(k)

is non-singular. Deﬁne an equivalent code C having its generator matrix G as:

G = G(1) G(2) · · · G(k) −1 G.

(49)

Clearly, the B left-most columns of G form a B × B identity matrix, thus making the equivalent code C systematic. As the repair is exact, the code will retain the systematic form following any number of failures and repairs.
The transformation in equation (49) can involve any arbitrary set of k nodes in C, thus proving the second part of the theorem.

The theorem above permits us to restrict our attention to the class of systematic codes, and assume the ﬁrst k nodes (i.e., nodes 1, . . . , k) to be systematic. Recall that, for systematic node (∈ {1, . . . , k}),

G( ) = Iα if i = ∀i ∈ {1, . . . , k}.

(50)

i

0α if i =

Thus, systematic node stores the α symbols in u .

22
C. Approach
An exact-repair MSR code should be capable of performing exact-repair of any failed node by connecting to any arbitrary subset of d of the remaining (n − 1) nodes, while meeting the cut-set bound on repair bandwidth. This requires a number of repair scenarios to be satisﬁed. Our proof of non-existence considers a less restrictive setting, in which exact-repair of only the systematic nodes is to be satisﬁed. Further, we consider only the situation where a failed systematic node is to be repaired by downloading data from a speciﬁc set of d nodes, comprised of the (k − 1) remaining systematic nodes, and some collection of α parity nodes. Thus, for the remainder of this section, we will restrict our attention to a subset of the n nodes in the distributed storage network, of size (k + α) nodes, namely, the set of k systematic nodes and the ﬁrst α parity nodes. Without loss of generality, within this subset, we will assume that nodes 1 through k are the systematic nodes and that nodes (k + 1) through (k + α) are the α parity nodes. Then with this notation, upon failure of systematic node , 1 ≤ ≤ k, the replacement node is assumed to connect to nodes {1, . . . , k + α}\{ }.
The generator matrix G of the entire code can be written in a block-matrix form as shown in Fig. 6. In the ﬁgure, each (block) column represents a node and each (block) row, a component. The ﬁrst k and the remaining α columns contain respectively, the generator matrices of the k systematic nodes and the α parity nodes.

Systematic nodes

Parity nodes

Fig. 6: The generator matrix G of the entire code. First k (block) columns are associated with the systematic nodes 1 to k
and the next α (block) columns to the parity nodes (k + 1) to (k + α). Empty blocks denote zero matrices.

We now outline the steps involved in proving the non-existence result. Along the way, we will uncover some interesting and insightful properties possessed by linear, exact-repair MSR codes.
1) We begin by establishing that in order to satisfy the data reconstruction property, each sub-matrix in the parity-node section of the generator matrix (see Fig. 6) must be non-singular.
2) Next, we show that the vectors passed by the α parity nodes for the repair of any systematic node must necessarily satisfy two properties:
• alignment of the interference components, and • linear independence of the desired component.
3) We then prove that in the collection of k vectors passed by a parity node for the respective repair of the k systematic nodes, every α-sized subset must be linearly independent. This is a key step that links the vectors stored in a node to those passed by it, and enables us to replace the α columns of the generator matrix of a parity node with the vectors it passes to aid in the repair of some subset of α systematic nodes. We will assume that these α systematic nodes are in fact, nodes 1 through α.
4) Finally, we will show that the necessity of satisfying multiple interference-alignment conditions simultaneously, turns out to be over-constraining, forcing alignment in the desired components as well. This leads to a contradiction, thereby proving the non-existence result.

23
D. Deduced Properties Property 1 (Non-singularity of the Component Submatrices): Each of the component submatrices {G(im) |
k + 1 ≤ m ≤ k + α, 1 ≤ i ≤ k} is non-singular. Proof: Consider a data-collector connecting to systematic nodes 2 to k and parity node (k + 1). The
data-collector has thus access to the block matrix shown in Fig. 7.

Fig. 7: The block matrix accessed by a data-collector connecting to systematic nodes 2 through k and parity node (k + 1).

For the data-collector to recover all the data, this block matrix must be non-singular, forcing G(1k+1) to be non-singular. A similar argument shows that the same must hold in the case of each of the other
component submatrices.

Corollary 9: Let H = [H1t H2t, · · · , Hkt]t be a (kα × ) matrix each of whose ≥ 1 columns is a linear combination of the columns of G(m) for some m ∈ {k + 1, . . . , k + α}, and having k components {Hi}
of size (α × ). Thus colspace[H] ⊆ colspace[G(m)].

Then for every i ∈ {1, . . . , k}, we have

nullspace[Hi] = nullspace[H].

(51)

Proof: Clearly,

nullspace[H] ⊆ nullspace[Hi].

(52)

Let H = G(m)A, for some (α × ) matrix A. Then

Hi = G(im)A.

(53)

For a vector v ∈ nullspace[Hi],

Hi v = G(im)A v = 0.

(54)

However, since G(im) is of full rank (Property 1) it follows that

Av = 0

(55)

⇒ G(m)A v = Hv = 0

(56)

⇒ nullspace[Hi] ⊆ nullspace[H].

(57)

The corollary says, in essence, that any linear dependence relation that holds amongst the columns of any of the components Hi, also extends to the columns of the entire matrix H itself.

24
We next establish properties that are mandated by the repair capabilities of exact regenerating codes. Consider the situation where a failed systematic node, say node , 1 ≤ ≤ k, is repaired using one vector (as β = 1) from each of the remaining k − 1 + α nodes.
Deﬁnition 3: When considering repair of systematic node , 1 ≤ ≤ k, the th component {γ(m, )} of each of the α vectors {γ(m, ) | k + 1 ≤ m ≤ k + α} passed by the α parity nodes will be termed as the desired component. The remaining components {γ(m, ) | i = } will be termed as interference
i
components.
The next property highlights the necessity of interference alignment in any exact-repair MSR code. Clearly, the vectors passed by the remaining (k − 1) systematic nodes have th component equal to 0, and thus the onus of recovering the ‘desired’ th component of replacement node falls on the α parity nodes. However, the vectors passed by the parity nodes have non-zero ‘interference’ components that can be nulled out only by the vectors passed by the systematic nodes. This forces an alignment in these interference components, and this is shown more formally below.
Property 2 (Necessity of Interference Alignment): In the vectors {γ(m, ) | k + 1 ≤ m ≤ k + α} passed by the α parity nodes for the repair of any systematic node (say, node ), the set of α interference components {γ(m, )}, 1 ≤ i ≤ k, i = must necessarily be aligned, and the desired components {γ(m, )}
i
must necessarily be linearly independent. Proof: We assume without loss of generality that = 1, i.e., we consider repair of systematic node
1. The matrix depicted in Fig. 8 consists of the α vectors needed to be recovered in the replacement node , alongside the d vectors passed by the d helper nodes 2, . . . , k + α. This matrix may be decomposed into three sub-matrices, namely: a (B × α) matrix Γ1, comprising of the α columns to be recovered at the replacement node; a (B × (k − 1)) matrix Γ2, comprising of the (k − 1) vectors passed by the remaining systematic nodes; and a (B × α) matrix Γ3, comprising of the α vectors passed by the parity nodes.

To be recovered

From systematic nodes

From parity nodes

Fig. 8: Matrix depicting the α (global-kernel) vectors to be recovered by replacement node 1 (represented by the matrix Γ1),
alongside the d vectors passed by the helper nodes 2, . . . , k + α (represented by [Γ2 | Γ3]).

The vectors {γ(k+1,1), . . . , γ(k+α,1)} appearing in the ﬁrst row of the matrix constitute the desired

1

1

component; for every i ∈ {2, . . . , k}, the set of vectors {γ(k+1,1), . . . , γ(k+α,1)}, constitute interference

i

i

components. An exact-repair of node 1 is equivalent to the recovery of Γ1 from the columns of Γ2 and

Γ3 through a linear transformation, and hence it must be that

colspace[Γ1] ⊆ colspace [Γ2|Γ3] ,

(58)

25
TO (systematic node)

FROM (parity node)

Fig. 9: Table indicating the vectors passed by the α parity nodes to repair the ﬁrst α systematic nodes.

where ‘|’ operator denotes concatenation. When we restrict attention to the ﬁrst components of the matrices, we see that we must have

colspace[Iα] ⊆ colspace γ1(k+1,1) . . . γ(1k+α,1) , (59)

thereby forcing the desired components {γ(k+1,1), . . . , γ(k+α,1)} to be linearly independent.

1

1

Further, from (58) it follows that

colspace [Γ1|Γ2] ⊆ colspace [Γ2|Γ3] .

(60)

Clearly, rank[Γ1] = α, and from Fig. 8 it can be inferred that

rank[Γ1|Γ2] = α + rank[Γ2] .

(61)

Moreover, as the ﬁrst component in Γ3 is of rank α,

rank[Γ2|Γ3] ≤ rank[Γ2] + α

(62)

= rank[Γ1|Γ2].

(63)

It follows from equation (60) and (63), that

colspace [Γ1|Γ2] = colspace [Γ2|Γ3] ,

(64)

and this forces the interference components in Γ3 to be aligned. Thus, for i ∈ {2, . . . , k},

colspace γ(k+1,1) · · · γ(k+α,1) ⊆ colspace γ(i,1) .

(65)

i

i

i

Remark 4: Properties 1 and 2 also hold for all β ≥ 1, in which case, each of the α helper parity nodes pass a β-dimensional subspace, and each interference component needs to be conﬁned to a β-dimensional subspace. Furthermore, the two properties also hold for all [n, k, d] exact-repair MSR codes, when (k −1) of the d helper nodes along with the replacement node are viewed as systematic.

26

The next property links the vectors stored in a parity node to the vectors it passes to aid in the repair of any set of α systematic nodes.

Property 3: For d < 2k − 1, the vectors passed by a parity node to repair any arbitrary set of α systematic nodes are linearly independent, i.e., for m ∈ {k + 1, . . . , k + α}, it must be that every subset of size α drawn from the set of vectors
γ(m,1), . . . , γ(m,k)

is linearly independent. (Thus the matrix [γ(m,1) . . . γ(m,k)] may be viewed as the generator matrix of a [k, α]-MDS code.)
Proof: Consider Fig. 9 which depicts the vectors passed by parity nodes {k + 1, . . . , k + α} to repair systematic nodes {1, . . . , α}. From Property 2 one can infer that in column i ∈ {1, . . . , α}, the ith (desired) components of the α vectors are independent, and the jth (interference) components for all j ∈ {1, . . . , k}\{i} are aligned. In particular, for all j ∈ {α + 1, . . . , k}, the jth components of each column are aligned. Note that as d < 2k − 1 we have k > α, which guarantees that the set {α + 1, . . . , k} is non-empty and hence, the presence of an (α + 1)th component.
We will prove Property 3 by contradiction. Suppose, for example, we were to have

γ(k+1,1) ⊆ colspace γ(k+1,2) · · · γ(k+1,α) ,

(66)

which is an example situation under which the α vectors passed by parity node (k + 1) for the respective repair of the ﬁrst α systematic nodes would fail to be linearly independent. Restricting our attention to component (α + 1), we get

γ(k+1,1) ⊆ colspace γ(k+1,2) · · · γ(k+1,α) .

α+1

α+1

α+1

(67)

Now, alignment of component (α + 1) along each column forces the same dependence in all other parity

nodes, i.e.,

γ(m,1) ⊆ colspace γ(m,2) · · · γ(m,α) ∀m ∈ {k + 2, . . . , k + α}.

(68)

α+1

α+1

α+1

Noting that a vector passed by a helper node lies in the column-space of its generator matrix, we now invoke Corollary 9:

nullspace γ(m,1) · · · γ(m,α) = nullspace γ(m,1) · · · γ(m,α) ∀m ∈ {k + 1, . . . , k + α}

(69)

α+1

α+1

This, along with equations (67) and (68), implies

γ(m,1) ⊆ colspace γ(m,2) · · · γ(m,α) ∀m ∈ {k + 1, . . . , k + α}.

(70)

Thus the dependence in the vectors passed by one parity node carries over to every other parity node. In particular, we have

γ(m,1) ⊆ colspace γ(m,2) · · · γ(m,α) ∀m ∈ {k + 1, . . . , k + α}.

(71)

1

1

1

However, from Property 2, we know that the vectors passed to systematic nodes 2 to α have their ﬁrst components aligned, i.e.,

rank γ(k+1, ) . . . γ(k+α, ) ≤ 1 ∀ ∈ {2, . . . , α}.

(72)

1

1

27

Aggregating all instantiations (w.r.t. m) of equation (71), the desired component is conﬁned to:

colspace ⇒ rank

γ (m,1) 1
γ (m,1) 1

k+α m=k+1 k+α m=k+1

⊆ colspace

γ(m, ) 1

(k+α, α) (m, )=(k+1, 2)

≤ rank

γ(m, ) 1

(k+α, α) (m, )=(k+1, 2)

α

k+α

≤

rank γ(m, )

1

m=k+1

=2

≤ α − 1,

(73) (74) (75) (76)

where the last inequality follows from equation (72). This contradicts the assertion of Property 2 with respect to the desired component:

rank

γ (m,1) 1

k+α m=k+1

= α.

(77)

Remark 5: It turns out that an attempted proof of the analogue of this theorem for the case β > 1, fails to hold.

The connection between the vectors passed by a parity node and those stored by it, resulting out of Property 3, is presented in the following corollary.

Corollary 10: If there exists a linear, exact-repair MSR code for d < 2k − 1, then there exists an

equivalent linear, exact-repair MSR code, where, for each parity node, the α columns of the generator

matrix are respectively the vectors passed for the repair of the ﬁrst α systematic nodes.

Proof: Since a node can pass only a function of what it stores, the vectors passed by a parity node

m ∈ {k + 1, . . . , k + α}, for repair of the systematic nodes must belong to the column-space of its

generator matrix, i.e.,

γ(m,1) · · · γ(m,α) ⊆ colspace G(m) .

(78)

Further, Property 3 asserts that the vectors it passes for repair of the ﬁrst α systematic nodes are linearly independent, i.e.,

rank γ(m,1) · · · γ(m,α) = α = rank G(m) .

(79)

It follows that the generator matrix G(m) is a non-singular transformation of the vectors γ(m,1) · · · γ(m,α) that are passed for the repair of the ﬁrst α systematic nodes, and the two codes with generator matrices given by the two representations are hence equivalent.

In the equivalent code, each row of Fig. 9 corresponds to the generator matrix G(m) of the associated

parity node, i.e.,

G(m) = γ(m,1) · · · γ(m,α)

∀ m ∈ {k + 1, . . . , k + α}.

(80)

Since the capabilities of a code are identical to an equivalent code, we will restrict our attention to this generator matrix for the remainder of this section. The two properties that follow highlight some additional structure in this code.

Property 4 (Code structure - what is stored): For d < 2k − 1, any component ranging from (α + 1) to k across the generator matrices of the parity nodes differ only by the presence of a multiplicative diagonal

28

matrix on the right, i.e.,

G(αk++11) = Hα+1 Λ(αk++11), ...
G(kk+1) = Hk Λ(kk+1),

G(αk++12) = Hα+1 Λ(αk++12), ...
G(kk+2) = Hk Λk(k+2),

· · · G(αk++1α) = Hα+1 Λ(αk++1α)

...

...

· · · G(kk+α) = Hk Λ(kk+α)

(81)

where the matrices of the form Λ(∗∗) are α × α diagonal matrices (and where, for instance, we can choose Hα+1 = Gα(k++11), in which case Λ(αk++11) = Iα).
Proof: Consider the ﬁrst column in Fig. 9, comprising of the vectors passed by the α parity nodes
to repair node 1. Property 2 tells us that in these α vectors, the components ranging from (α + 1) to
k constitute interference, and are hence aligned. Clearly, the same statement holds for every column in
Fig. 9. Thus, the respective components across these columns are aligned. Since the generator matrices
of the parity nodes are as in (80), the result follows.

For the repair of a systematic node, a parity node passes a vector from the column-space of its generator

matrix, i.e., the vector γ(m, ) passed by parity node m for repair of failed systematic node can be written

in the form:

γ(m, ) = G(m) θ(m, )

(82)

for some α-length vector θ(m, ). In the equivalent code obtained in (80), a parity node simply stores the α vectors it passes to repair
the ﬁrst α systematic nodes. On the other hand, the vector passed to systematic node , α + 1 ≤ ≤ k, is a linear combination of these α vectors. The next property employs Property 3 to show that every coefﬁcient in this linear combination is non-zero.

Property 5 (Code structure - what is passed): For d < 2k − 1, and a helper parity node m assisting a
failed systematic node (a) For ∈ {1, . . . , α}, θ(m, ) = e , and (b) For ∈ {α + 1, . . . , k}, every element of θ(m, ) is non-zero.
Proof: Part (a) is a simple consequence of the structure of the code. We will prove part (b) by contradiction. Suppose θα(m, ) = 0, for some ∈ {α + 1, . . . , k}. Then γ(m, ) is a linear combination of
only the ﬁrst (α − 1) columns of G(m). This implies,

γ(m, ) ⊆ colspace γ(m,1) · · · γ(m,α−1) .

(83)

This clearly violates Property 3, thus leading to a contradiction.

E. Proof of Non-existence
We now present the main theorem of this section, namely, the non-achievability proof. The proof, in essence, shows that the conditions of Interference Alignment necessary for exact-repair of systematic nodes, coupled with the MDS property of the code, over-constrain the system, leading to alignment in the desired components as well.
We begin with a toy example that will serve to illustrate the proof technique. Consider the case when [n = 7, k = 5, d = 6]. Then it follows from (5) that (α = d − k + 1 = 2, B = kα = 10). In this case, as depicted in Figure 10, in the vectors passed by parity nodes 6 and 7, (a) when repairing systematic node 3, there is alignment in components 4 and 5, and (b) when repairing systematic node 4, there is alignment in component 5. It is shown that this, in turn, forces alignment in component 4 (desired component) during repair of node 4 which is in contradiction to the assertion of Property 2 with respect to the desired component being linearly independent.

29

Component 4

From To 3

4

6

Component 5

3

4

Component 4

3

4

aligned aligned aligned aligned

7
(Required to be
independent)
Fig. 10: A toy-example, with parameters [n = 7, k = 5, d = 6], to illustrate the proof of non-existence.

Theorem 11: Linear, exact-repair MSR codes achieving the cut-set bound on the repair-bandwidth do not exist for d < 2k − 3 in the absence of symbol extension (i.e., when β = 1).
Proof: Recall that achieving the cut-set bound on the repair bandwidth in the absence of symbol extension gives d = k − 1 + α. For the parameter regime d < 2k − 3 under consideration, we get k ≥ α + 3. Furthermore, since α > 1 6, we have n ≥ k + 2 (as n ≥ d + 1 = k + α). Hence the system contains at least (α + 3) systematic nodes and at least two parity nodes.
We use Property 4 to express the generator matrix of any parity node, say node m, in the form:

 G(1m) 



...









G(m)

=

 

G(αm)

 

(m)  .

 Hα+1Λα+1 

 ... 

Hk Λ(km)

In this proof, we will use the notation A ≺ B to indicate that the matrices A and B are scalar multiples of each other, i.e., A = κB for some non-zero scalar κ and write A ⊀ B to indicate that matrices A and B are not scalar multiples of each other.
We will restrict our attention to components (α + 2) and (α + 3). First, consider repair of systematic node (α + 1). By the interference alignment property, Property 2,

γ(k+1,α+1) ≺ γ(k+2,α+1)

α+2

α+2

i.e.,

G(αk++21) θ(k+1,α+1) ≺ Gα(k++22) θ(k+2,α+1)

⇒ Hα+2 Λ(αk++21) θ(k+1,α+1) ≺ Hα+2 Λ(αk++22) θ(k+2,α+1)

⇒

Λ(αk++21) θ(k+1,α+1) ≺ Λ(αk++22) θ(k+2,α+1),

(84) (85) (86) (87)

where, equation (87) uses the non-singularity of Hα+2 (which is a consequence of Property 1). We will use the notation Θ(∗,∗) to denote an (α × α) diagonal matrix, with the elements on its diagonal

as the respective elements in θ(∗,∗). Observing that the matrices Λ(∗∗) are diagonal matrices, we rewrite

equation (87) as

Λ(αk++21)Θ(k+1,α+1) ≺ Λ(αk++22)Θ(k+2,α+1).

(88)

Similarly, alignment conditions on the (α+3)th component in the vectors passed for repair of systematic

node (α + 1) give

Λ(αk++32)Θ(k+2,α+1) ≺ Λ(αk++31)Θ(k+1,α+1),

(89)

6As discussed previously in Section I, α = 1 corresponds to a trivial scalar MDS code; hence, we omit this case from consideration.

30

and those on the (α + 3)th component in the vectors passed for repair of systematic node (α + 2) give

Λ(αk++31)Θ(k+1,α+2) ≺ Λ(αk++32)Θ(k+2,α+2).

(90)

Observe that in equations (88), (89) and (90), matrices Λ(∗∗) and Θ(∗,∗) are non-singular, diagonal matrices. As a consequence, a product (of the terms respective in the left and right sides) of equations (88), (89) and (90), followed by a cancellation of common terms leads to:

Λ(αk++21)Θ(k+1,α+2) ≺ Λ(αk++22)Θ(k+2,α+2).

(91)

This is clearly in contradiction to Property 2, which mandates linear independence of the desired components in vectors passed for repair of systematic node (α + 2):

Hα+2Λ(αk++21)θ(k+1,α+2) ⊀ Hα+2Λ(αk++22)θ(k+2,α+2),

i.e.,

Λ(αk++21)Θ(k+1,α+2) ⊀ Λ(αk++22)Θ(k+2,α+2).

(92) (93)

VII. EXPLICIT CODES FOR d = k + 1
In this section, we give an explicit MSR code construction for the parameter set [n, k, d = k + 1], capable of repairing any failed node with a repair bandwidth equal to that given by the cut-set bound. This parameter set is relevant since
a) the total number of nodes n in the system can be arbitrary (and is not constrained to be equal to d + 1), making the code pertinent for real-world distributed storage systems where it is natural for the system to expand/shrink,
b) k + 1 is the smallest value of the parameter d that offers a reduction in repair bandwidth, making the code suitable for networks with low connectivity.
The code is constructed for β = 1, i.e., the code does not employ any symbol extension. All subsequent discussion in this section will implicitly assume β = 1.
For most values of the parameters [n, k, d], d = k + 1 falls under d < 2k − 3 regime, where we have shown (Section VI) that exact-repair is not possible. When repair is not exact, a nodal generator matrix is liable to change after a repair process. Thus, for the code construction presented in this section, we drop the global kernel viewpoint and refer directly to the symbols stored or passed.

As a build up to the code construction, we ﬁrst inspect the trivial case of d = k. In this case, the cut-set lower bound on repair bandwidth is given by

d ≥ k = B.

(94)

Thus the parameter regime d = k mandates the repair bandwidth to be no less than the ﬁle size B, and has the remaining parameters satisfying

(α = 1, B = k) .

(95)

An MSR code for these parameters is necessarily an [n, k] scalar MDS code. Thus, in this code, node i

stores the symbol

pt u ,

(96)

i

where u is a k-length vector containing all the message symbols, and {ri}ni=1 is a set of k-length vectors such that any arbitrary k of the n vectors are linearly independent. Upon failure of a node, the replacement node can connect to any arbitrary d = k nodes and download one symbol each, thereby recovering the
entire message from which the desired symbol can be extracted.

31

Node i

Node i

Node i

M E

Exact

Exact

S S A

Auxiliary

Auxiliary

G

Exact

Exact

E

Initialization

Repair

Repair

time →

Fig. 11: Evolution of a node through multiple repairs in the MSR d = k + 1 code.

When d = k + 1, the cut-set bound (5) gives

(α = d − k + 1 = 2, B = αk = 2k) .

(97)

Let the 2k message symbols be the elements of the 2k-dimensional column vector

u1 , u2
where u1 and u2 are k-length column vectors. In the case of d = k + 1, a code analogous to the d = k code would have node i storing the two symbols:

pti u1, pti u2 . (98)

Maintaining the code as in (98), after one or more node repairs, necessitates exact repair of any failed node. Since in this regime, exact-repair is not possible for most values of the parameters, we allow an auxiliary component in our code, as described below.
In our construction, the symbols stored in the nodes are initialized as in (98). On repair of a failed node, the code allows for an auxiliary component in the second symbol. Thus, under this code, the two symbols stored in node i, 1 ≤ i ≤ n, are

( pti u1, pti u2
Exact component

+ rti u1 ),
Auxiliary component

(99)

where ri is a k-length vector corresponding to the auxiliary component. Further, the value of ri may alter when node i undergoes repair. Hence we term this repair process as approximately-exact-repair.
For a better understanding, the system can be viewed as analogous to a Z-channel; this is depicted in
Fig. 11, where the evolution of a node through successive repair operations is shown. In the latter half of this section, we will see that the set of vectors {ri}ni=1 do not, at any point in time, inﬂuence either the reconstruction or the repair process.
We now proceed to a formal description of the code construction.

A. Code Construction: Let {pi}ni=1 be a set of k-length vectors such that any arbitrary k of the n vectors are linearly independent.
Further, let {ri}ni=1 be a set of k-length vectors initialized to arbitrary values. Unlike {pi}, the vectors {ri} do not play a role either in reconstruction or in repair. In our code, node i stores the two symbols:

pti u1, pti u2 + rti u1 .

(100)

Node 1 Node 2 Node 3 Node 4 Node 5 Node 6 Node 7 Node 8

u1 u2 u3 u4 u5 4u1 + 5u2 + 3u3 + u4 + u5 3u1 + 6u2 + u3 + u4 + 7u5 3u1 + 7u2 + 8u3 + 3u4 + 4u5

u6 + u3 + 2u4 + 2u5 u7 + 2u1 + u3 + u4 + u5
u8 + 10u4 u9 + u1 + 2u2 + u3 + u5
u10 + u1 + u4 4u6 + 5u7 + 3u8 + u9 + u10 3u6 + 6u7 + u8 + u9 + 7u10 + u4 3u6 + 7u7 + 8u8 + 3u9 + 4u10 + u1 + 4u3

32

<•, [6 1]> <•, [1 1]> <•, [3 1]> <•, [3 1]> <•, [1 1]> <•, [0 1]>

Approx. Exact Repair

Replacement Node 8

3u1 + 7u2 + 8u3 + 3u4 + 4u5

3u6 + 7u7 + 8u8 + 3u9 + 4u10 + 6u1 + 2u2 + 4u3 + 7u4 + 9u5

Exact

Auxiliary

Fig. 12: A sample MSR d = k + 1 code for the parameters [n = 8, k = 5, d = 6], (β = 1, α = 2, B = 10), over F11.
Also depicted is the repair of node 8, assisted by helper nodes 1 to 6.

Upon failure of a node, the exact component, as the name suggests, is exactly repaired. However, the
auxiliary component may undergo a change. The net effect is what we term as approximately-exact-repair.
The code is deﬁned over the ﬁnite ﬁeld Fq of size q. The sole restriction on q comes from the construction of the set of vectors {ri}ni=1 such that every subset of k vectors are linearly independent. For instance, these vectors can be chosen from the rows of an (n × k) Vandermonde matrix or an (n × k) Cauchy
matrix, in which case any ﬁnite ﬁeld of size q ≥ n or q ≥ n + k respectively will sufﬁce.
Example: Fig. 12 depicts a sample code construction over F11 for the parameters [n = 8, k = 5, d = 6] with β = 1 giving (α = 2, B = 10). Here,

1 0 0 0 0

0 0 1 2 2

0 1 0 0 0

2 0 1 1 1

 pt   0 0 1 0 0   rt   0 0 0 10 0 

 ...1  =  00 00 00 10 01  ,  ...1  =  11 20 10 01 10  .

pt 8





4 5 3 1 1

rt8





0 0 0 0 0









3 6 1 1 7

0 0 0 1 0

37834

104 0 0

The two theorems below show that the code described above is an [n, k, d = k + 1] MSR code by establishing respectively, the reconstruction and the repair properties of the code.

Theorem 12 (Reconstruction, i.e., MDS property): In the code presented, all the B message symbols can be recovered by a data-collector connecting to any arbitrary k nodes.
Proof: Due to symmetry we assume (without loss of generality) that the data-collector connects to the ﬁrst k nodes. Then the data-collector obtains access to the 2k symbols stored in the ﬁrst k nodes:

pti u1,

k
pti u2 + rti u1 i=1 .

(101)

By construction, the vectors {pi}ki=1 are linearly independent, allowing the data-collector to recover the ﬁrst message vector u1. Next, the data-collector subtracts the effect of u1 from the second term. Finally, in a manner analogous to the decoding of u1, the data-collector recovers the second message vector u2.

33

Theorem 13 (Node repair): In the code presented, approximately exact-repair of any failed node can be achieved by connecting to an arbitrary subset of d (= k + 1) of the remaining (n − 1) nodes.
Proof: Due to symmetry, it sufﬁces to consider the case where helper nodes {1, . . . , k + 1} assist in the repair of another failed node f . The two symbols stored in node f prior to failure are

ptf u1, ptf u2 + rtf u1 .

However, since repair is guaranteed to be only approximately exact, it sufﬁces for the replacement node

to obtain

ptf u1, ptf u2 + r˜tf u1 ,

where r˜f is an arbitrary vector that need not be identical to rf .

The helper nodes {1, . . . , k + 1} pass one symbol each, formed by a linear combination of the symbols

stored in them. More speciﬁcally, helper node i, 1 ≤ i ≤ k + 1, under our repair algorithm, passes the

symbol

λi pti u1 + pti u2 + rti u1 .

(102)

We introduce some notation at this point. For ∈ {k, k + 1}, let P be a ( × k) matrix comprising

of the vectors p1, . . . , p as its rows respectively. Let R be a second ( × k) matrix comprising of the vectors r1, . . . , r as its rows respectively. Further, let Λ = diag{λ1, . . . , λ } be an ( × ) diagonal

matrix. In terms of these matrices, the k + 1 symbols obtained by the replacement node can be written

as the (k + 1)-length vector

(Λk+1Pk+1 + Rk+1) u1 + (Pk+1) u2 .

(103)

The precise values of the scalars {λi}ki=+11 are derived below.

Recovery of the First Symbol: Let ρ be the linear combination of the received symbols that the replacement node takes to recover the ﬁrst symbol that was stored in the failed node, i.e., we need

ρt ((Λk+1Pk+1 + Rk+1) u1 + (Pk+1) u2) = ptf u1. This requires elimination of u2, i.e., we need
ρtPk+1 = 0t.

(104) (105)

To accomplish this, we ﬁrst choose

ρ = ρ1 , −1

(106)

and in order to satisfy equation (105), we set

ρt 1

=

ptk+1Pk−1.

Note that the (k × k) matrix Pk is non-singular by construction. Now as u2 is eliminated, to obtain ptf u1, we need

ρt (Λk+1Pk+1 + Rk+1) = ptf

⇒ ρt1 (ΛkPk + Rk) = ptf + λk+1 ptk+1 + rtk+1 .

(107)
(108) (109)

Choosing λk+1 = 0 and substituting the value of ρt1 from equation (107), a few straightforward manipu-

34

lations yield that choosing

Λk =

diag

pt k+1

Pk−1

−1
diag

pt f

−

pt k+1

Pk−1

Rk

+

rtk+1

Pk−1

,

(110)

satisﬁes equation (109), thereby enabling the replacement node to exactly recover the ﬁrst symbol. The

non-singularity of the matrix diag

pt k+1

Pk−1

used here is justiﬁed as follows. Consider

pt k+1

Pk−1

Pk = ptk+1 .

(111)

Now, if any element of

pt k+1

Pk−1

is zero, it would imply that a linear combination of (k − 1) rows

of Pk can yield ptk+1. However, this contradicts the linear independence of every subset of k vectors in {pi}ni=1.

Recovery of the Second Symbol: Since the scalars {λi}ki=+11 have already been utilized in the exact recovery of the ﬁrst symbol, we are left with fewer degrees of freedom. This, in turn, gives rise to the
presence of an auxiliary term in the second symbol. Let δ be the linear combination of the received symbols, that the replacement node takes, to obtain its
second symbol (ptf u2 + r˜tf u1), i.e., we need

δt ((Λk+1Pk+1 + Rk+1) u1 + (Pk+1) u2) = ptf u2 + r˜tf u1.

(112)

Since the vector r˜f is allowed to take any arbitrary value, the condition in (112) is reduced to the

requirement

δtPk+1 = ptf .

(113)

To accomplish this, we ﬁrst choose

δ = δ1 , 0

(114)

where, in order to satisfy equation (113), we choose δt1 = ptf Pk−1 .

(115)

In the example provided in Fig. 12, node 8 is repaired by downloading one symbol each from nodes 1 to 6. The linear combination coefﬁcients used by the helper nodes are:
[λ1 · · · λ6] = [6 1 3 3 1 0] .
The replacement node retains the exact part, and obtains a different auxiliary part, with ˜r8 = [6 2 4 7 9] .
VIII. CONCLUSIONS
This paper considers the problem of constructing MDS regenerating codes achieving the cut-set bound on repair bandwidth, and presents four major results. First, the construction of an explicit code, termed the MISER code, that is capable of performing data reconstruction as well as optimal exact-repair of the systematic nodes, is presented. The construction is based on the concept of interference alignment. Second, we show that interference alignment is, in fact, necessary to enable exact-repair in an MSR code. Thirdly, using the necessity of interference alignment as a stepping stone, several properties that every exact-repair MSR code must possess, are derived. It is then shown that these properties over-constrain the system in the absence of symbol extension for d < 2k − 3, leading to the non-existence of any linear, exact-repair MSR code in this regime. Finally, an explicit MSR code for d = k + 1, suited for networks with low connectivity, is presented. This is the ﬁrst explicit code in the regenerating codes literature that does not impose any restriction on the total number of nodes n in the system.

35
REFERENCES
[1] S. Rhea, P. Eaton, D. Geels, H. Weatherspoon, B. Zhao, and J. Kubiatowicz, “Pond:the OceanStore Prototype,” in Proc. USENIX File and Storage Technologies (FAST), 2003.
[2] R. Bhagwan, K. Tati, Y. C. Cheng, S. Savage, and G. M. Voelker, “Total Recall: System Support for Automated Availability Management,” in NSDI, 2004.
[3] A. G. Dimakis, P. B. Godfrey, M. Wainwright, and K. Ramchandran, “Network Coding for Distributed Storage Systems,” Proc. IEEE INFOCOM, Anchorage, May 2007.
[4] Y. Wu, A. G. Dimakis, and K. Ramchandran, “Deterministic Regenerating Codes for Distributed Storage,” in Proc. Allerton Conf., Urbana-Champaign, Sep. 2007.
[5] A. Duminuco and E. Biersack, “A Practical Study of Regenerating Codes for Peer-to-Peer Backup Systems,” in Proc. 29th IEEE International Conference on Distributed Computing Systems, Montreal, Jun. 2009.
[6] Y. Wu, “Existence and Construction of Capacity-Achieving Network Codes for Distributed Storage,” in Proc. IEEE ISIT, Seoul, Jul. 2009.
[7] Y. Wu and A. G. Dimakis, “Reducing Repair Trafﬁc for Erasure Coding-Based Storage via Interference Alignment,” in Proc. IEEE ISIT, Seoul, Jul. 2009.
[8] K. V. Rashmi, N. B. Shah, P. V. Kumar, and K. Ramchandran, “Explicit Construction of Optimal Exact Regenerating Codes for Distributed Storage,” in Proc. Allerton Conf., Urbana-Champaign, Sep. 2009.
[9] D. Cullina, A. G. Dimakis and T. Ho, “Searching for Minimum Storage Regenerating Codes,” in Proc. Allerton Conf., UrbanaChampaign, Sep. 2009.
[10] N. B. Shah, K. V. Rashmi, P. V. Kumar, and K. Ramchandran,“Explicit Codes Minimizing Repair Bandwidth for Distributed Storage,” in Proc. IEEE Information Theory Workshop, Cairo, Jan. 2010.
[11] Y. Wu, “A Construction of Systematic MDS Codes with Minimum Repair Bandwidth,” submitted to IEEE Transactions on Information Theory. Available online : arXiv:0910.2486v1 [cs.IT].
[12] N. B. Shah, K. V. Rashmi, P. V. Kumar, and K. Ramchandran, “Interference Alignment as a Tool in Network Coding as Applied to Distributed Storage,” in National Conference on Communications, Chennai, Jan. 2010.
[13] K. V. Rashmi, N. B. Shah, P. V. Kumar, and K. Ramchandran “Explicit and Optimal Exact-Regenerating Codes for the MinimumBandwidth Point in Distributed Storage,” in Proc. IEEE ISIT, Austin, Jun. 2010.
[14] C. Suh and K. Ramchandran, “Interference Alignment Based Exact Regeneration Codes for Distributed Storage,” in Proc. IEEE ISIT, Austin, Jun. 2010.
[15] V. R. Cadambe, S. A. Jafar and H. Maleki, “Distributed Data Storage with Minimum Storage Regenerating Codes - Exact and Functional Repair are Asymptotically Equally Efﬁcient,” available online at arXiv:1004.4299v1 [cs.IT].
[16] C. Suh and K. Ramchandran, “On the Existence of Optimal Exact-Repair MDS Codes for Distributed Storage,” available online at arXiv:1004.4663v1 [cs.IT].
[17] K. V. Rashmi, N. B. Shah and P. V. Kumar, “Optimal Exact-Regenerating Codes for the MSR and MBR Points via a Product-Matrix Construction,” submitted to IEEE Transactions on Information Theory. Available online at arXiv:1005.4178 [cs.IT].
[18] B. Gaston and J. Pujol, “Double Circulant Minimum Storage Regenerating Codes,” submitted to Allerton Conf., Urbana-Champaign, Sep. 2010. Available online at arXiv:1007.2401 [cs.IT].
[19] V. R. Cadambe and S. A. Jafar, “Interference Alignment and the Degrees of Freedom for the K User Interference Channel,” IEEE Transactions on Information Theory, vol. 54, no. 8, pp. 3425-3441, Aug. 2008.
[20] M. A. Maddah-Ali, S. A. Motahari and A. K. Khandani, “Communication over MIMO X Channels: Interference Alignment, Decomposition, and Performance Analysis,” IEEE Transactions on Information Theory, vol. 54, no. 8, pp. 3457-3470, Aug. 2008.
[21] D. S. Bernstein, Matrix mathematics: Theory, facts, and formulas with application to linear systems theory, Princeton University Press, Princeton, NJ, p.119, 2005.
[22] F.J. MacWilliams and N.J.A. Sloane, The Theory of Error-Correcting Codes, Part I, North-Holland Publishing Company, Amsterdam, New York, Oxford, 1977.
APPENDIX PROOF OF THEOREM 3: RECONSTRUCTION IN THE MISER CODE
Proof: The reconstruction property is equivalent to showing that the (B × B) matrix, obtained by columnwise concatenation of the generator matrices of the k nodes to which the data-collector connects, is non-singular. We denote this (B × B) matrix by D1. The proof proceeds via a series of linear, elementary row and column transformations of D1, obtaining new (B × B) matrices at each intermediate step, and the non-singularity of the matrix obtained at the end of this process will establish the non-singularity of D1.
Since we need to employ a substantial amount of notation here, we will make the connection between any notation that we introduce here with the notation employed in example presented in Section V-A. This example provided the MISER code construction for the case k = α = 3, with the scalar selection
= 2; we will track the case of reconstruction (Section V-A3, case (d)) when the data-collector connects to the ﬁrst systematic node (node 1), and the ﬁrst two parity nodes (nodes 4 and 5).

36

Let δ1, . . . , δp be the p parity nodes to which the data-collector connects. Let ω1, . . . , ωk−p (ω1 < · · · < ωk−p) be the k − p systematic nodes to which the data-collector connects, and Ω1, . . . , Ωp (Ω1 < · · · < Ωp) be the p systematic nodes to which it does not connect. In terms of this notation, the matrix D1 is

D1 = G(ω1) · · · G(ωk−p) G(δ1) · · · G(δp) .

(116)

Clearly, the sets {ω1, . . . , ωk−p} and {Ω1, . . . , Ωp} are disjoint. In the example, the notation corresponds to p = 2, δ1 = 4, δ2 = 5, ω1 = 1, Ω1 = 2 and Ω2 = 3.

Since the data-collector can directly obtain the (k − p)α symbols stored in the k − p systematic nodes it connects to, the corresponding components, i.e., components ω1, . . . , ωk−p, are eliminated from D1. Now, reconstruction is possible if the (pα × pα) matrix D2 is non-singular, where D2 is given by

D2 = G (δ1) G (δ2) · · · G (δp)

G(Ωδ11) G(Ωδ12) · · · G(Ωδ1p)

=  ...

... . . . ...  .





G(Ωδp1) G(Ωδp2) · · · G(Ωδpp)

(117)

The (6 × 6) matrix B1 in the example corresponds to the matrix D2 here. The remaining proof uses certain matrices having speciﬁc structure. These matrices are deﬁned in
Table I, along with their values in the case of the example.

Matrix S S˜ Ta,b T˜a,b Ea,b E˜a,b

TABLE I: Notation: Matrices used in the Proof of Theorem 3

Dimension α×p p×p α×p p×p α×p p×p

Value

[S]i,j = ψi(δj)

∀i, j

[S˜]i,j = ψΩ(δij)

∀i, j

ath row as [ψΩ(δb1) . . . ψΩ(δbp)], all other elements 0 ath row as [ψΩ(δb1) . . . ψΩ(δbp)], all other elements 0

Element at position (a, b) as 1, all other elements 0

Element at position (a, b) as 1, all other elements 0

In the Example
 ψ1(4) ψ1(5)  S =  ψ2(4) ψ2(5) 
ψ3(4) ψ3(5)

S˜ =

ψ2(4) ψ3(4)

ψ2(5) ψ3(5)

= Ψ2

 ψ3(4) ψ3(5) 

T1,2 =  0 0 

00

T˜1,2 =

ψ3(4) 0

ψ3(5) 0

0 1

E1,2 =  0 0  00

E˜1,2 =

01 00

Note ﬁrst that S˜, being a sub-matrix of the Cauchy matrix Ψ, is non-singular. Further, note the following

relations between the matrices:

Ta,b S˜−1 = Ea,b

(118)

and

T˜a,b S˜−1 = E˜a,b .

(119)

We begin by permuting the columns of D2. Group the Ω1th columns of {G (δm) | m = 1, . . . , p} as the

37

ﬁrst p columns of D3, followed by Ω2th columns of {G (δm) | m = 1, . . . , p} as the next p columns, and so on. Thus, column number Ωi of G (δm) moves to the position p × (i − 1) + m. Next, group the ω1th columns of {G (δm) | m = 1, . . . , p} and append this group to the already permuted columns, followed by

the ω2th columns, and so on. Thus, column number ωi of G (δm) moves to the position p2 +p×(i−1)+m.

Let D3 be the (pα × pα) matrix obtained after these permutations. The (6 × 6) matrix B2 in the example,

corresponds to the matrix D3 here.

Next, we note that there are α groups with p columns each in D3. The component-wise grouping of the

rows in the parent matrix D2 induces a natural grouping in D3, with its rows grouped into p groups of α

rows each. Thus D3 can be viewed as a block matrix, with each block of size α × p, and the dimension

of D3 being p × α blocks. Now, in terms of the matrices deﬁned in Table I, the matrix D3 can be written

as  S TΩ2,1 · · · TΩp,1 Tω1,1 · · · Tωk−p,1 

 TΩ1,2

D3 =  

...

S · · · TΩp,2 ... . . . ...

Tω1,2 · · · Tωk−p,2 

... . . .

...

. 

(120)

TΩ1,p TΩ2,p · · · S Tω1,p · · · Tωk−p,p

Next, as the data collector can perform any linear operation on the columns of D3, we multiply the last (k−p) block-columns (i.e., blocks of p columns each) in D3 by S˜−1 (while leaving the other block-columns unchanged). Using equation (118), the resulting pα × pα matrix is


 D4 = 


S TΩ1,2
... TΩ1,p

TΩ2,1 · · · S ··· ... . . .
TΩ2,p · · ·

TΩp,1 TΩp,2
... S

Eω1,1 · · · Eωk−p,1 

Eω1,2 · · · Eωk−p,2 

... . . .

...

. 

Eω1,p · · · Eωk−p,p

(121)

The (6 × 6) matrix B3 in the example, corresponds to the matrix D4 here. Observe that in the block-columns ranging from p + 1 to α of the matrix D4, every individual column
has exactly one non-zero element. The message symbols associated to these columns of D4 are now available to the data-collector and their effect on the rest of the encoded symbols can be subtracted out to get the following (p2 × p2) matrix


 D5 = 


S˜ T˜2,1 · · · T˜p,1 

T˜1,2 S˜ · · · T˜p,2 

...

...

...

...

. 



T˜1,p T˜2,p · · · S˜

(122)

The matrix D5 here, is the (4 × 4) matrix B4 in the example. This is equivalent to reconstruction in the MISER code with the parameter k equal to p when a data-collector is attempting data recovery from the p parity nodes. Hence, general decoding algorithms for data collection from the parity nodes alone can also be applied, as in the present case, where data collection is done partially from systematic nodes and partially from parity nodes. The decoding procedure for this case is provided below.

In the example detailed in case (c) of Section V-A3, where the data-collector connects to all three parity nodes, is related to this general case with p = 3, S˜ = Ψ3 and D5 = C2. We will track this case in the
sequel. The data-collector multiplies each of the p block-columns in D5 by S˜−1. From equation (119), the

38

resultant (p2 × p2) matrix is

 Ip E˜2,1 E˜3,1 · · · E˜p,1 

 E˜1,2 D6 =  ...


Ip E˜3,2 · · · E˜p,2 

...

...

...

...

. 



E˜1,p E˜2,p E˜3,p · · · Ip

The (9 × 9) matrix C3 in the example, corresponds to the matrix D6 here.

(123)

For i = 1, . . . , p, the ith column in the ith block-column contains exactly one non-zero element (which is in the ith row of the ith block-row). It is evident that message symbols corresponding to these columns
are now available to the data-collector, and their effect can be subtracted from the remaining symbols. This intermediate matrix corresponds to the (6 × 6) matrix C4 in the example. Next we rearrange the resulting matrix by ﬁrst placing the ith column of the jth block-column adjacent to the jth column of the ith block-column and repeating the same procedure for rows to get a ((p2 − p) × (p2 − p)) matrix D7 as

 1 0 0 ··· 0 0 

 1 0 0 ··· 0 0 

 0 0 1 · · · 0 0 

D7

=

 

0

0

1

···

0

0

 .

 

...

...

...

...

...

...

 





 0 0 0 0 ··· 1 

0 0 0 0 ··· 1

(124)

This is a block diagonal matrix which is non-singular since 2 = 1. Thus the remaining message symbols can be recovered by decoding them in pairs.

