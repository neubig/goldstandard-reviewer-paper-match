arXiv:1606.08842v2 [cs.LG] 23 Sep 2016

Active Ranking from Pairwise Comparisons and when Parametric Assumptions Don’t Help
Reinhard Heckel Nihar B. Shah Kannan Ramchandran Martin J. Wainwright†,
Department of Statistics†, and Department of Electrical Engineering and Computer Sciences
UC Berkeley, Berkeley, CA 94720
September 26, 2016
Abstract We consider sequential or active ranking of a set of n items based on noisy pairwise comparisons. Items are ranked according to the probability that a given item beats a randomly chosen item, and ranking refers to partitioning the items into sets of pre-speciﬁed sizes according to their scores. This notion of ranking includes as special cases the identiﬁcation of the top-k items and the total ordering of the items. We ﬁrst analyze a sequential ranking algorithm that counts the number of comparisons won, and uses these counts to decide whether to stop, or to compare another pair of items, chosen based on conﬁdence intervals speciﬁed by the data collected up to that point. We prove that this algorithm succeeds in recovering the ranking using a number of comparisons that is optimal up to logarithmic factors. This guarantee does not require any structural properties of the underlying pairwise probability matrix, unlike a signiﬁcant body of past work on pairwise ranking based on parametric models such as the Thurstone or Bradley-Terry-Luce models. It has been a long-standing open question as to whether or not imposing these parametric assumptions allows for improved ranking algorithms. For stochastic comparison models, in which the pairwise probabilities are bounded away from zero, our second contribution is to resolve this issue by proving a lower bound for parametric models. This shows, perhaps surprisingly, that these popular parametric modeling choices oﬀer at most logarithmic gains for stochastic comparisons.
1 Introduction
Given a collection of n items, it is frequently of interest to estimate a ranking based on noisy comparisons between pairs of items. Such rank aggregation problems arise across a wide range of applications. Some traditional examples in sports include identifying the best player in a tournament, selecting the top k teams for playoﬀs, and ﬁnding the full ranking of players. More recently, the internet era has led to a variety of applications involving pairwise comparison data, including recommender systems [Pie+13; Agg16] for rating movies, books, or other consumer items; peer grading [Sha+13] for ranking students in massive open online courses; and online sequential survey sampling [SL15] for assessing the popularity of proposals in a population of voters. In many of these and other such applications, it is possible to make comparisons in an active or adaptive manner—that is, based on the outcomes of comparisons of previously chosen pairs. Motivated by those applications, the focus of this paper is the problem of obtaining statistically sound rankings based on a sequence of actively chosen pairwise comparisons.
We consider a collection of n items, and our data consists of outcomes of comparisons between pairs of items in this collection collected actively. We assume that the outcomes of comparisons are
1

stochastic—that is, item i beats item j with an unknown probability Mij ∈ (0, 1). The outcomes of pairwise comparisons are furthermore assumed to be statistically mutually independent. We deﬁne
the ordering of the items in terms of their (unknown) scores, where the score τi of item i is deﬁned as the probability that item i beats an item chosen uniformly at random from all other items:

τi := 1

Mij .

(1)

n − 1 j=i

In the context of social choice theory [DB81], these sums are also known as the Borda scores or counts of the items. Apart from their intuitive appeal, the Borda counts are of particular interest because they provide a natural uniﬁcation of the assumed orderings in several popular comparison models. Speciﬁcally, the parametric Bradley-Terry-Luce (BTL) [BT52; Luc59] and Thurstone [Thu27] models, as well as the non-parametric Strong Stochastic Transitivity (SST) model [TER69], are all based on an assumed ordering of the items; in all of these models, this ordering coincides with that given by the scores {τi}ni=1. In this paper, we consider the problem of partitioning the items into sets of pre-speciﬁed sizes according to their respective scores. This notion of ranking includes as special cases identiﬁcation of the top-k items and the total ordering of the items.
We make two primary contributions. We begin by presenting and analyzing a simple active ranking algorithm for estimating a partial or total ranking of the items. At each round, this algorithm ﬁrst counts the number of comparisons won, then computes conﬁdence bounds from those counts, which it ﬁnally uses to select a subset of pairs to be compared at the next time step. We provide performance guarantees showing that with high probability, the algorithm recovers the desired partial or total ranking from a certain number of comparisons, which we refer to as the sample complexity. We show that the sample complexity is a function of the (unknown) scores {τi}ni=1, and therefore distribution-dependent. Conversely, we prove distribution-dependent lower bounds that are matching up to logarithmic factors, thereby showing that the algorithm is nearoptimal in the number of comparisons. Our analysis leverages the fact that ranking in terms of the scores {τi}ni=1 is related to a particular class of multi-armed bandit problems [ED+06; Bub+13; Urv+13]. This connection has been observed in past work [Yue+12; Jam+15; Urv+13] in the context of ﬁnding the top item.
Our second main contribution relates to the popular parametric modeling choices made in the literature. On one hand, the algorithmic analysis of this paper does not impose any assumptions on the pairwise comparison probabilities. On the other hand, much past work (including some of our own) is based on speciﬁc parametric assumptions on the pairwise comparisons; for instance, see the papers [Sz15; Hun04; Neg+12; Haj+14; CS15; Sou+14; Sha+16a; MG15] as well as references therein. Concrete examples of parametric assumptions include the Bradley-Terry-Luce (BTL) and Thurstone parametric models. There is a long standing debate on whether such parametric assumptions are reasonable—that is, in which situations they (approximately) hold, and in which they fail [BW97]. When such parametric models are suitable, the natural hope is that their structure allows some reduction of the sample complexity. In fact, for essentially deterministic comparison models (meaning that pairwise comparison probabilities may be arbitrarily close to zero or one), there can indeed be signiﬁcant gains; see the discussion following Theorem 2 for further details. However, as we show in the paper, if one considers stochastic comparison models (in which the pairwise probabilities are bounded away from zero and one), then there is at most a logarithmic gain in the sample complexity in assuming a parametric comparison model over not making any

2

structural assumption. This logarithmic gain needs to be weighed against the potential lack of robustness incurred by using a parametric model (note that parametric modeling assumptions often hold only approximately [BW97], if at all), which can be signiﬁcant, as shown in our numerical results section.
Related work: There is a vast literature on ranking and estimation from pairwise comparison data. Most works assume probabilistic comparison outcomes; we refer to the paper [JN11] and references therein for ranking problems assuming deterministic comparison outcomes. Several prior works [Hun04; Neg+12; Haj+14; Sou+14; Sha+16a; SW15; Che+16] consider settings where pairs to be compared are chosen a priori. In contrast, we consider settings where the pairs may be chosen in an active manner. The recent work [Sz15] assumes the Bradley-Terry-Luce (BTL) parametric model, and considers the problem of ﬁnding the top item and the full ranking in an active setup. In the stochastic regime, for certain underlying distributions, the corresponding results [Sz15, Theorem 3 and Theorem 4] are close to what our more general result implies. On the other hand, for several other problem instances the performance guarantees of Theorem 3 and Theorem 4 in the work [Sz15] lead to a signiﬁcantly larger sample complexity. Our work thus oﬀers better guarantees for the BTL model in the stochastic regime, despite the additional generality of our setting in that we do not restrict ourselves to the BTL model. However outside the stochastic regime, speciﬁcally for models with pairwise comparison probabilities very close to zero and one, [Sz15, Theorem 3 and Theorem 4] oﬀer gains over the results aﬀorded by our more general model; we discuss this regime in more detail later. The paper [MG15] considers the problem of ﬁnding a full ranking of items for a BTL pairwise comparison model, and provides a performance analysis for a probabilistic model on the BTL parameter vector. Finally, Eriksson [Eri13] considers the problem of ﬁnding the very top items using graph based techniques, Busa-Fekete et al. [BF+13] consider the problem of ﬁnding the top-k items, and Ailon [Ail11] considers the problem of linearly ordering the items so as to disagree in as few pairwise preference labels as possible. Our work is also related to the literature on multi-armed bandits, and we revisit these relations later in the paper.
Organization: The remainder of this paper is organized as follows. We begin with background and problem formulation in Section 2. We then present a description and a sharp analysis of our ranking algorithm in Section 3. In Section 4, we show that parametric assumptions do not reduce the sample complexity in the stochastic regime. In Section 5 we study numerically whether algorithms designed for parametric models can yield some improvement outside the stochastic regime, and study some additional aspects of our proposed algorithm. We provide proofs of all our results in Section 6, and conclude with a discussion in Section 7.
2 Problem formulation and background
In this section, we formally state the ranking problem considered in this paper and formalize the notion of an active ranking algorithm. We also formally introduce the class of parametric models in this section.
2.1 Pairwise probabilities, scores, and rankings
Given a collection of items [n] := {1, . . . , n}, let us denote by Mij ∈ (0, 1) the (unknown) probability that item i wins a comparison with item j. For all items i and j, we require that each comparison results in a winner (meaning that Mij + Mji = 1), and we set Mii = 1/2 for concreteness. For
3

each

item

i

∈

[n],

consider

the

score

(1)

given

as

τi

:=

1 n−1

j∈[n]\{i} Mij. Note that the (unknown)

score τi ∈ (0, 1) corresponds to the probability that item i wins a comparison with an item j chosen

uniformly at random from [n] \ {i}.

Assuming that the scores are all distinct, they deﬁne a unique ranking of the n items; this

(unknown) ranking corresponds to the permutation π : [n] → [n] such that

τπ(1) > τπ(2) > . . . > τπ(n).

In words, π(i) denotes the ith ranked item according to the scores. A number of ranking problems
can be deﬁned in terms of π: at one extreme, ﬁnding the best item corresponds to determining the
item π(1), whereas at the other extreme, ﬁnding a complete ranking is equivalent to estimating
π(j) for all j ∈ [n]. We introduce a general formalism that allows us to handle these and many other ranking problems. In particular, given an integer L ≥ 2, we let {k }L=1 be a collection of positive integers such that 1 ≤ k1 < k2 < . . . < kL−1 < kL = n. Any such collection of positive integers deﬁnes a partition of [n] into L disjoint sets of the form

S1 := {π(1), . . . , π(k1)}, S2 := {π(k1 + 1), . . . , π(k2)}, . . . , SL := {π(kL−1 + 1), . . . , π(n)}. (2)

For instance, if we set L = 2 and k1 = k, then the set partition (S1, S2) corresponds to split-
ting [n] into the top k items and its complement. At the other extreme, if we set L = n and (k1, k2, . . . , kn) = (1, 2, . . . , n), then the partition {S }L=1 allows us to recover the full ranking of the items, as speciﬁed by the permutation π.
For future reference, we deﬁne

CMmin := M ∈ (0, 1)n×n | Mij = 1 − Mji, Mij ≥ Mmin, and τi = τj for all (i, j) ,

(3)

corresponding to the set of pairwise comparison matrices with pairwise comparison probabilities lower bounded by Mmin, and for which a unique ranking exists.1

2.2 The active ranking problem

An active ranking algorithm acts on a pairwise comparison model M ∈ C0. Consider any speciﬁed values of L and {k }L=1 deﬁning a partition of the form (2) in terms of their latent scores (1). The goal is to obtain a partition of the items [n] into L disjoints sets of the form (2) from active comparisons. At each time instant, the algorithm can compare two arbitrary items, and the choice of which items to compare may be based on the outcomes of previous comparisons. As a result of comparing two items i and j, the algorithm receives an independent draw of a binary random variable with success probability Mij in response. After termination dictated by an associated
stopping rule, the algorithm returns a ranking S1, . . . , SL. For a given tolerance parameter δ ∈ (0, 1), we say that a ranking algorithm A is δ-accurate for
a comparison matrix M if the ranking it outputs obeys

PM S = S , for all = 1, . . . , L ≥ 1 − δ.

(4)

For any set of comparison matrices C, we say that the algorithm A is uniformly δ-accurate over C if it is δ-accurate for each matrix M ∈ C. The performance of any algorithm is measured by means of its sample complexity, by which we mean the number of comparisons required to obtain the desired partition.
1We note that our results actually do not require the entire underlying ordering of the scores to be strict; rather, we require strict inequalities only at the boundaries of the sets S1, . . . , SL.

4

2.3 Active ranking and multi-armed bandits

It is worthwhile noting that the ranking problem studied here is related to multi-armed ban-

dits [Kau+16; BCB12]. More precisely, a multi-armed bandit model consists of a collection of

n “arms”, each associated with an unknown and stochastic reward function, and the goal is to

maximize the reward obtained via a sequential choice of arms. In past work, various researchers

(e.g., [YJ11; Yue+12; Urv+13; Jam+15]) have drawn links between pairwise comparison ranking

and such bandit problems. In particular, by deﬁnition of the score τi, comparing item i to a distinct

item chosen from the n−1 alternatives can be modeled as drawing a Bernoulli random variable with

mean τi. Our subsequent analysis in Section 3 relies on this relation. When cast in the multi-armed

bandit setting, the setting of pairwise comparisons is often referred to as that of “dueling bandits”.

Prior works in this setting [YJ11; Yue+12; Urv+13; Jam+15] address the problem of ﬁnding the

single “best arm”— meaning the item with the highest score—based on noisy comparisons. By

contrast, this paper treats the more general problem of ﬁnding a partial or total ordering of the

items.

Despite these similarities, there is an important distinction between the two settings. If we view

our problem as a multi-armed bandit problem with Bernoulli random variables with means {τi}ni=1, these means are actually coupled together, in the sense that information about any particular

mean imposes constraints on all the other means. In particular, any set of scores {τi}ni=1 must be realized by some valid set of pairwise comparison probabilities {Mij}i,j∈[n]. Since these pairwise

comparison probabilities must obey the constraint Mij = 1 − Mji, the induced scores must satisfy

certain constraints, not all of which are obvious. One obvious constraint, which follows immediately

from the deﬁnition (1), is that

n i=1

τi

=

n/2,

another

constraint

is

that

j i=1

τπ(i)

≥

1 j(j−1) n−1 2

[Lan53; Joe88]. Those condition, while necessary, are certainly not suﬃcient, as can be seen by

studying some simple cases.2 Our algorithm, presented in the next section, does not take the

coupling of the scores explicitly into account. Nevertheless, our algorithm is shown to be optimal

up to a logarithmic factor in the stochastic regime.

2.4 Parametric models

In this section, we introduce a family of parametric models that form a basis of several prior works [Sz15; Hun04; Neg+12; Haj+14; Sha+16a]. To be clear, we make no modeling assumptions for our algorithm and its analysis in Section 3. Rather, we focus on these parametric models in Section 4, where we show that, perhaps surprisingly, outside of the deterministic regime, none of these parametric assumptions provide more than a logarithmic gain in sample complexity.
Any member of this family is deﬁned by a strictly increasing and continuous function Φ : R → [0, 1] obeying Φ(t) = 1 − Φ(−t), for all t ∈ R. The function Φ is assumed to be known. A pairwise comparison matrix in this family is associated to an unknown vector w ∈ Rn, where each entry of w represents some quality or strength of the corresponding item. The parametric model CPAR(Φ) associated with the function Φ is deﬁned as:

CPAR(Φ) = {Mij = Φ(wi − wj) for all i, j ∈ [n], for some w ∈ Rn}.

(5)

2For instance, there is no set of pairwise comparison probabilities with scores [1, 1, 0, 0], even though those scores satisfy the aforementioned constraints. In order to verify this fact, note that τ1 = 1 implies M12 = M13 = M14 = 1. Thus, we have M21 = 0, which implies τ2 ≤ 2/3 and therefore contradicts τ2 = 1.

5

Popular examples of models in this family are the Bradley-Terry-Luce (BTL) model, ob-

tained

by

setting

Φ

equal

to

the

sigmoid

function

(Φ(t)

=

1 1+e−t

),

and

the

Thurstone

model,

obtained by setting Φ equal to the Gaussian CDF. Note that τ1 > τ2 > . . . > τn is equivalent to

w1 > w2 > . . . > wn, meaning that the ranking induced by the scores {τi}ni=1 is equivalent to that

induced by w.

It is worthwhile noting that a common assumption in the setting of parametric models [Neg+12;

Sha+16a; CS15] is that w ∞ ≤ B for some ﬁnite constant B. This boundedness assumption implies that the pairwise comparison probabilities {Mij}ni,j=1 are all uniformly bounded away from 0 and 1, thereby guaranteeing a stochastic comparison model.

3 Active ranking from pairwise comparisons
In this section, we present our algorithm for obtaining the desired partition of the items as described earlier in Section 2, and a sharp analysis of this algorithm proving its optimality up to logarithmic factors.

3.1 Active ranking (AR) algorithm

Our active ranking algorithm is based two ingredients:
• Successive estimation of the scores {τi}ni=1, where score τi is estimated by comparing item i with items chosen uniformly at random from [n] \ {i}.

• Assigning an item i to an estimate S of the set S once a certain conﬁdence level of i belonging to S is attained.

This strategy is essentially an adaption of the successive elimination approach from the bandit literature, proposed in the classical paper [Pau64], and studied in a long line of subsequent work (see, for example, [ED+06; Bub+13; Urv+13; Jam+15]).
The ﬁrst input to the algorithm is a collection of positive integers {k }L=0 such that
k0 = 0 < k1 < k2 < . . . < kL−1 < kL = n,

which deﬁne a desired ranking. The second input is a tolerance parameter δ ∈ (0, 1), which deﬁnes the probability with which the algorithm is allowed to fail.

Algorithm 1 (Active Ranking (AR)). At time t = 0, deﬁne and initialize the following quantities:

• S = [n] • S = ∅ for all ∈ [L] • k = k for all ∈ {0, . . . , L} • τi(0) = 0 for all i ∈ [n]
At any time t ≥ 1:

(set of items not ranked yet); (estimates of the partition); (borders of the sets); (estimates of the scores).

1. For every i ∈ S: Compare item i to an item chosen uniformly at random from [n] \ {i}, and set

τi(t) =

t−t 1 τi(t

−

1)

+

1 t

if i wins

(6)

t−1 t

τi(t

−

1)

otherwise.

6

t=5

t = 10

t = 15

latent scores τ1

τ(1)

τ(1)

of items in S1 τ2

τ(2)

τ(1)

τ(2)

latent scores τ3 τ(3) τ(3) τ(2)

of items in S2 τ4

τ(4)

τ(4)

Figure 1. Illustration of the AR algorithm applied to the problem of ﬁnding the top 2 items out of n = 4 items total, corresponding to S1 = {1, 2}, S2 = {3, 4}. The ﬁgure depicts the estimates τi(t), along with the corresponding conﬁdence intervals [τi(t) − 4αt, τi(t) + 4αt], at diﬀerent time steps t. At time t = 5, the algorithm is not conﬁdent about the position of any of the items, and hence it continues to sample further. At time t = 10, the conﬁdence interval of item (1) indicates that (1) is
either the best or the second best item, therefore the AR algorithm assigns (1) to S1. Likewise, it
assigns item (4) to S2. At time step t = 15, the AR algorithm assigns items (1) and (2) to S1 and
S2, respectively, and terminates.

2. Sort the items in set S by their current estimates of the scores: For any k ∈ [|S|], let (k) denote the item with the k-th largest estimate of the score.

3. With αt := log(125n lotg(1.12t)/δ) , do the following for every j ∈ S: If the following pair of conditions (7a) and (7b) hold simultaneously for some

∈ [L],

k −1 = 0 or k = |S| or

τj(t) < τ(k −1)(t) − 4αt τj(t) > τ(k +1)(t) + 4αt

(j likely is one of the lower n − k −1 − 1 items) (7a)

(j likely is one of the top k items),

(7b)

then add j to S , remove j from S, and set k ← k − 1 for all ≤ .

4. If S = ∅, terminate. See Figure 1 for an illustration of the progress of this algorithm on a particular instance.

3.2 Guarantees and optimality of the AR algorithm
In this section, we establish guarantees on the number of samples for the AR algorithm to succeed. As we show below, the sample complexity is a function of the gaps between the scores, deﬁned as
∆¯ ,i := τπ(k −1) − τi, and ∆ ,i := τi − τπ(k +1). (8) The dependence on these gaps is controlled via the functions
f0(x) := x12 , and fAR(x) := log(2 loxg2(2/x)) . (9)

7

∆1,1 ∆1,2, ∆¯ 2,3

∆2,4, ∆¯ 3,5 ∆¯ 3,6

τ1

τ2 τ3

τ4

τ5

τ6

Figure 2. Illustration of the gaps ∆¯ ,i and ∆ ,i relevant for ﬁnding a partitioning of the items {1, 2, . . . , 6} into the sets S1 = {1, 2}, S2 = {3, 4}, and S3 = {5, 6}.

In part (a) of the theorem to follow, we prove an upper bound involving fAR on the AR algorithm, and in part (b), we prove a lower bound involving f0 that applies to any uniformly δ-accurate algorithm. As one might intuitively expect, the number of comparisons required is lower when the gaps between the underlying scores are larger. See Figure 2 for an illustration of the gaps for the particular problem of ﬁnding a partitioning of the items {1, 2, . . . , 6} into three sets of cardinality two each.

Theorem 1. There are positive universal constants (cup, clow) such that:

(a) For any M ∈ C0, and any δ ∈ (0, 0.14] the AR algorithm is δ-accurate for M using a query size upper bounded by

n cup log δ

L−1

fAR(∆1,i) +

max

i∈S1

=2 i∈S

fAR(∆ ,i), fAR(∆¯ ,i)

+

fAR(∆¯ L,i) .

i∈SL

(10a)

(b) For any δ ∈ (0, 0.14], consider a ranking algorithm that is uniformly δ-accurate over C1/8. Then when applied to a given pairwise comparison model M ∈ C3/8, it must make at least

1 clow log 2δ

L−1

f0(∆1,i)+

max

i∈S1

=2 i∈S

f0(∆ ,i), f0(∆¯ ,i)

+ f0(∆¯ L,i)
i∈SL

(10b)

comparisons on average.

Part (a) of Theorem 1 proves that the AR algorithm is δ-accurate, and characterizes the number of comparisons required to ﬁnd a ranking as a function of the gaps between scores. In contrast, part (b) shows that, up to logarithmic factors, the AR algorithm is optimal, not only in a minimax sense, but in fact when acting on any given problem instance. The proof of part (b) involves constructing pairs of comparison matrices that are especially hard to distinguish, and makes use of a change of measure lemma [Kau+16, Lem. 1] from the bandit literature. For the special case of top-1 identiﬁcation (corresponding to L = 2 and k1 = 1), Jamieson et al. [Jam+15] and Urvoy et al. [Urv+13] observe that by using the relation to multi-armed bandits discussed in Section 2.3, a standard multi-armed bandit algorithm can be applied which in turn is known to achieve the sample complexity (10a). Again for the special case of top-1 identiﬁcation, part (b) of Theorem 1 recovers Theorem 1 in [Jam+15]. Note that our negative result in part (b) pertains to the stochastic regime,

8

where the pairwise comparison probabilities are bounded away from zero, and does therefore not

rule out the possibility that in the regime where the pairwise comparison probabilities are very

close to one, improvements in sample complexity are possible.

In order to gain intuition on this result, in particular the dependence on the squared gaps, it is

useful to specialize to the toy case n = 2. In this special case with n = 2, we have τ1 = M12 and

τ2 = M21 = 1 − M12. Thus, the ranking problem reduces to testing the hypothesis {τ1 > τ2}. One

can verify that the hypothesis {τ1 > τ2} is equivalent to {M12 > 21 }. Let Xi, i = 1, . . . , Q be the

outcomes of Q independent comparisons of items 1 and 2, that is, P [Xi = 1] = M12 and P [Xi = 0] =

1 − M12.

A

natural

test

for

{M12

>

21 }

is

to

test

whether

X¯

>

1/2,

where

X¯

:=

1 Q

Q i=1

Xi.

Supposing without loss of generality that M12 > 12 , by Hoeﬀding’s inequality, we can upper bound

the corresponding error probability as

P X¯ ≤ 1/2 = P X¯ − M12 ≤ 1/2 − M12 ≤ e−2Q(1/2−M12)2 = e−2Q(τ1−τ2)2 .

Thus, for Q ≥ 2l(oτg1(−1τ/2δ))2 the error probability is less than δ. The bound (10a) in Theorem 1(a) yields an identical result up to a logarithmic factor.
More generally, testing for the inclusion i ∈ S amounts to testing for ∆¯ ,i > 0 and ∆ ,i > 0, where ∆¯ ,i = τπ(k −1) − τi and ∆ ,i = τi − τπ(k +1). These requirements provide some intuition
regarding the dependence of our bounds on the inverses of the squared gaps.

3.3 Gains due to active estimation

In order to understood the beneﬁts of an active strategy, it is worthwhile to compare the performance of our active method to the (minimax optimal) guarantees obtainable by passive comparison strategies. We hasten to add that these gains should not be seen as surprising in of themselves, since it is well-known that active estimators can often yield signiﬁcant improvements over passive schemes.
Recent work by a subset of the current authors [SW15] considers the problem of ranking items from pairwise comparisons in a passive random design setup. On one hand, it is shown (Theorem 1) that a simple passive scheme—namely, one that ranks items according to the total number of comparisons won—recovers the top k items with high probability using (τkn−lτokg+n1)2 comparisons in total; the same paper also establishes a matching lower bound, meaning that no passive scheme can do better up to constant factors. In contrast, Theorem 1 of the present paper shows that in the active setting, the number of comparisons necessary and suﬃcient for ﬁnding the top k items is of the order

k

1

n

1

(τi − τk+1)2 +

(τk − τi)2 ,

i=1

i=k+1

up to a logarithmic factor. By comparing this guarantee to the passive sample complexity (τkn−lτokg+n1)2 , we can understand when active strategies do or do not lead to substantial gains. First, note that
the complexity of the non-active estimator is always lower, except for scores satisfying the linear
constraints τ1 = . . . = τk and τk+1 = . . . = τn, in which case the two estimators would have similar performance. Second, the diﬀerence in sample complexity can be as large as a factor of n, up to
logarithmic factors. In particular, suppose that the score diﬀerence τi − τi+1 is on the order of 1/n:

9

estimated score

1 0.8 0.6 0.4 0.2
00

100 200 index
(a) PlaNYC

0

100 200 300

index

(b) OECD

Figure 3. Estimated scores from comparisons of the proposals in the PlaNYC (a) and OECD (b) surveys, as reported in the paper [SL15] (only scores of items (proposals) that were rated at least 50 times are depicted). Estimation of the top k proposals or another ranking with an active scheme would require a signiﬁcantly smaller number of queries compared to a non-active estimator.

in this case, up to logarithmic factors, the sample complexity of the active and passive schemes scale as n2 and n3 respectively. A similar conclusion holds if we compare the results of the paper [SW15] with those of the present paper for the problem of recovering the full ranking.
Having seen that the gains from active estimation depend on the distribution of the scores {τi}ni=1, it is natural to wonder how these scores behave in real-world settings. As one illustration, Figure 3 shows some real-world examples of this distribution for data collected by Salganik and Levy [SL15]; the left panel shows the scores estimated in the paper [SL15] of a collection of environmental proposals for New York City, whereas the right panel shows a collection of educational proposals for the Organisation for Economic Co-operation and Development (OECD). These data were collected by asking interviewees in corresponding online surveys for preferences between two options. The goal of such online surveys is, for example, to identify the top proposals or a total ranking of the proposals. Our results show that estimation of the top k proposals or another ranking with an active scheme would require a signiﬁcantly smaller number of queries compared to an non-active estimator.

4 When parametric assumptions don’t help
The active ranking algorithm described and analyzed in the previous section applies to any comparison matrix M —that is, it neither assumes nor exploits any particular structure in M , such as that imposed by the parametric models described in Section 2.4. Given that the AR algorithm imposes no conditions on the model, one might suspect that when ranking data is actually drawn from a parametric model—for example, of BTL or Thurstone type—it could be possible to come up with another algorithm with a lower sample complexity. Surprisingly, as we show in this section, this intuition turns out to be false in the following sense: for stochastic comparison models—in which the comparison probabilities are bounded strictly away from zero and one—imposing parametric assumptions can lead to at most a logarithmic reduction in sample complexity.

10

Recall that a parametric model is described by a continuous and strictly increasing CDF Φ; in this section, we prove a lower bound that applies even to algorithms that are given a priori knowledge of the function Φ. For any pair of constants 0 < φmin ≤ φmax < ∞, we say that a CDF Φ is (φmin, φmax, Mmin)-bounded, if it is diﬀerentiable, and if its derivative Φ satisﬁes the bounds

φmin ≤ Φ (t) ≤ φmax, for all t ∈ [Φ−1(Mmin), Φ−1(1 − Mmin)].

(11)

Note that these conditions hold for standard parametric models, such as the BTL and Thurstone models.
The following result applies to any parametric model CPAR(Φ) described by a CDF of this type. It also involves the complexity parameter

L−1

F (τ (M )) := f0(∆1,i) +

max

i∈S1

=2 i∈S

f0(∆ ,i), f0(∆¯ ,i)

+ f0(∆¯ L,i),
i∈SL

(12)

which appeared previously in the lower bound from Theorem 1(b).

Theorem 2.

(a) Given a tolerance δ ∈ (0, 0.15], and a continuous and strictly increasing CDF Φ whose derivative is (φmin, φmax, Mmin)-bounded, consider any algorithm that is uniformly δ-accurate over CPAR(Φ)∩CMmin. Then, when applied to a given pairwise comparison matrix M ∈ CPAR(Φ) ∩ CMmin, it must make at least

1 cpar log 2δ F (τ (M )),

where

cpar

:=

, Mmin φ2min
2.004φ2

max

(13)

comparisons on average.
(b) Let τ ∈ (0, 1)n be any set of scores that is realizable by some pairwise comparison matrix M ∈ CMmin, Mmin > 0. Then for any continuous and strictly increasing Φ, there exists a pairwise comparison matrix in M ∈ CPAR(Φ) ∩ CMmin with scores τ , and in particular with F (τ (M )) = F (τ (M )).
First, let us provide some concrete settings of the constant cpar: for Mmin = 83 , we have cpar = 0.164 and cpar = 0.169 for the BTL and Thurstone models, respectively; whereas for Mmin = 14 , we have cpar = 0.07 and cpar = 0.079 for the BTL and Thurstone models, respectively.
Second, let us turn to the implications of Theorem 2. To start, it should be noted that the lower bound (13) is, at least in a certain sense, stronger than the lower bound from Theorem 1, because it applies to a broader class of algorithms—namely, those that are δ-accurate only over the smaller class of parametric models. On the ﬂip side, it is possible that the lower bound (13) could be weaker in some sense: more precisely, could there be some “diﬃcult” matrix M ∈ CMmin such that the supremum of F (τ (M )) over M ∈ CPAR(Φ) ∩ CMmin is much smaller than F (τ (M ))? Part (b) of the theorem rules out this possibility: it guarantees that for any pairwise comparison matrix M —which need not be generated by a parametric model—there exists a parametric model M for which the ranking problem is equally hard. This result is surprising because one might think that imposing parametric assumptions might simplify the ranking problem. In fact, the full set CMmin is substantially larger than the parametric subclass CPAR(Φ) ∩ CMmin; in particular, one can

11

demonstrate matrices in CMmin that cannot be well-approximated by any parametric model; for

example, see the paper [Sha+16b] for inapproximability results of this type.

A consequence of Theorem 2 is that up to logarithmic factors, the AR algorithm is again optimal,

even if we restrict ourselves to algorithms that are uniformly δ-accurate only over a parametric

subclass. Thus, for stochastic comparison models, imposing parametric assumptions only limits

the ﬂexibility while failing to provide any signiﬁcant reductions in sample complexity for ranking.

It is worth commenting that for deterministic or near-deterministic comparison models—in which

the pairwise probabilities can be arbitrarily close to zero or one— the constant cpar in the lower

bound (13) can become small. For this reason, our lower bound does not contradict the fact that

parametric assumptions might help for (near)-deterministic comparison models. As one example,

recalling that the BTL model described in Section 2.4 is based on a parameter vector w ∈ Rn,

suppose

that

we

set

wi

=

ξ(n − i)

for

all

i

∈

[n],

and

then

let

ξ

tend

to

inﬁnity.

Since

Mij

=

ewi ewi +ewj

under the model, taking the limit ξ → ∞ leads to a fully deterministic comparison model in

which items i beats j with probability one if and only if wi > wj. In this limit, pairwise ranking

reduces to a deterministic sorting problem, and sorting-based algorithms (e.g., [Sz15]) can be used

to achieve top item identiﬁcation with O(n log n) comparisons. In contrast, in this deterministic

setting, the AR algorithm requires3 O(n2 log n) comparisons, which can be guaranteed by applying

Theorem 1(a) with the associated score vector τi = 1 − ni−−11 .

5 Numerical results
We now turn to some numerical comparisons of our active ranking (AR) algorithm with algorithms designed for parametric models. One ﬁnding—consistent with our theory—is that the AR algorithm is on par or outperforms these algorithms, unless the pairwise comparison probabilities are close to zero or one. Moreover, we ﬁnd that algorithms designed for parametric models start to break down even if the parametric modeling assumption is only slightly violated. Finally, we experiment with the choice of constants setting conﬁdence intervals αt for the AR algorithm, and ﬁnd that the choice given by our theory is conservative.

5.1 Comparison to algorithms tailored to parametric models
Our results in Section 4 show that for stochastic comparison models, algorithms that exploit parametric structure can have sample complexities lower by at most a logarithmic factor. On the other hand, for (near)-deterministic comparison models, we gave an example showing that parametric structure can allow for signiﬁcant gains. In this section, we perform some numerical experiments to quantify and understand these two diﬀerent regimes.
To this end, we consider the problem of top item recovery, known as the dueling bandit problem, simply because algorithms are available for this special case of the more general ranking problem considered in our paper. We compare the AR algorithm to the Plackett-Luce PAC (PLPAC) [Sz15] and Beat the Mean Bandit (BTMB) [YJ11] algorithms. Both algorithms yield an δ-accurate ranking provided the BTL modeling assumptions hold. We choose the PLPAC algorithm for comparison as it is based on sorting: a BTL problem with pairwise comparison probabilities close to one and zero
3To be very clear, this example does not violate any of our claimed results since the lower bound of Theorem 1(b), and hence the associated claim of optimality, applies only to the case when the pairwise comparison probabilities are bounded away from 0 and 1 by some constant Mmin.

12

sample complexity

105 104.5

AR PBLTPMABC 105 F (τ (M (η)))
104

AR PLPAC BTMB F (τ (M (ξ)))

0.65 0.7

0.8

0.9

Mmax

(a)

103 0.99 0.65 0.7

0.8

0.9 0.99

Mmax

(b)

Figure 4. (a) Empirical sample complexity of the AR, PLPAC, and BTMB algorithms applied to the BTL model M (η) with parameters wi = log(η + n − i), i = 1, . . . , 10, and (b) applied to the BTL model M (ξ) with parameters wi = ξ(n − i), i = 1, . . . , 10, as a function of Mmax := maxi,j Mij. For panel (a) and (b) we varied η and ξ such that Mmax ∈ [0.65, 0.99]. The error bars correspond to one standard deviation from the mean. While the AR algorithm has even lower sample complexity than
the PLPAC and BTMB algorithms in the regime where Mmax is not to close to 1; the PLPAC and BTMB perform better when Mmax is close to one.

is in essence a noisy sorting problem, thus we expect sorting based procedures to work well here.

The BTMB algorithm is guaranteed to succeed if Strong Stochastic Transitivity (SST) (or a relaxed

version thereof) and a certain stochastic transitivity triangle inequality hold4; both assumptions

are satisﬁed for the BTL model. Regarding the algorithms parameters; for the AR algorithm we

set

αt

=

1 4

log(3n log(1.12t)/δ) (see Section 5.2 for a discussion for the choice of αt), and for all

algorithms we choose δ = 0.1.

We set n = 10 and consider two diﬀerent BTL models parameterized by η > 0 and ξ > 0,

respectively, and denoted by M (η) and M (ξ). The parameters η and ξ determine how close the

minimal and maximal pairwise comparison probabilities are to 0 and 1; the larger, the closer.

Speciﬁcally, the parameters of the BTL model M (η) are given by wi = log(1/η + n − i), i = 1, . . . , n.

This

results

in

pairwise

comparison

probabilities

Mi(jη)

=

1/η+n−i 2(1/η+n)−i−j

.

The parameters of the

second BTL model, M (ξ), are wi = ξ(n − i) which implies that the probability that item i beats the

next

best

item

i+1

is

Mi(,ξi+) 1

=

1 1+e−ξ

.

Thus,

each

item

beats

all

lower

ranked

ones

with

probability

at

least

1 1+e−ξ

,

which

results

in

all

the

pairwise

comparison

probabilities

being

skewed

away

from

1/2; the larger ξ the “closer” those probabilities are to 0 and 1.

In Figure 4 we depict the empirical sample complexity for both models as a function of

Mmax := maxi,j Mij, along with the corresponding complexity parameters F (τ (M (η))) and F (τ (M (ξ))).

Here, we choose the model parameters η and ξ such that Mmax varies between 0.65 and 0.99. The

4A necessary and suﬃcient condition for a matrix to satisfy the SST condition is the existence of a permutation of the items, such that the permuted pairwise comparison matrix M is non-decreasing across rows and non-increasing across columns. The stochastic transitivity inequality demands that for each triplet with τ1 > τj > τk, we have that M1j − 1/2 + Mjk − 1/2 ≥ M1k − 1/2.

13

relative sample complexity failure probability

AR

AR

PLPAC

0.6

PLPAC

10

BTMB

BTMB

0.4

5 0.2

00

0.1

0.2

0.3

λ

(a)

00

0.1

0.2

0.3

λ

(b)

Figure 5. (a) Relative sample complexity deﬁned as the number of comparisons until termination, Q, divided by the complexity parameter F (τ (M )), and (b) failure probability on a BTL model M with n = 10 and with a fraction of λ of the oﬀ-diagonals of M substituted by a random pairwise comparison probability. The model transitions from a BTL model to a random pairwise comparison matrix in λ; the closer λ to zero the closer M to the original BTL model. The results show that, while the AR algorithm yields an δ-accurate ranking after O(F (τ (M ))) comparisons, irrespectively of λ, the sample complexity and more importantly the failure probability of the PLPAC and BTMB algorithms become very large in λ.

results show, as predicted by our theory, that the sample complexity of the AR algorithm is essentially a constant times the complexity parameter F . In contrast, the sample complexity of the PLPAC and the BTMB algorithms improves in Mmax relative to the complexity parameter F . Note that the AR algorithm performs better than PLPAC and BTMB if Mmax is not too large, while both PLPAC and BTMB have lower sample complexity than the AR algorithm in the regime where Mmax is very close to one. We remark that the relative improvement is not determined solely by Mmax, as shown by the curves for the two diﬀerently parameterized BTL models diﬀering.
Our next simulation shows that, however, even if the pairwise comparison matrix only deviates slightly from the BTL model, both the sample complexity and more pertinently the failure proba-
bility (that is, PM S = S , for one or more = 1, . . . , L ) can become very large. Speciﬁcally, as
before, we generate a BTL model M with n = 10 and parameters wi = log(1 + n − i), i = 1, . . . , n. We then substitute a fraction of λ of the oﬀ-diagonal elements of M with a number drawn uniformly from [0, 1]. Thus, the model M transitions from a BTL model to a random pairwise comparison matrix in λ; for small λ, the model M is close to the original BTL model. The results, depicted in Figure 5, show that, while the AR algorithm succeeds for all values of λ as expected, the sample complexity and more importantly the failure probability of the PLPAC and BTMB algorithms become very large. We hasten to add that both the PLPAC and BTMB algorithm are not designed for this scenario; therefore it might not be surprising that they fail. The results show that these algorithms are, however, not robust to violations of their assumed models.

14

number of comparisons error probability

400
300
200
10−2 10−3 10−4 10−5 10−6 error probability (a)

10−2 10−3 10−4 10−5 10−6

10−1

10−2

δ

(b)

Figure 6. (a) Number of comparisons required to ﬁnd the top-2 items out of 5 items, for αt =

1 4

log(n/3(log(t) + 1)/δ)/t. (b) Empirical error probability required to ﬁnd the top-2 items out of

5 items. The particular choice of the constants in αt = log(125n log(1.12t)/δ)/t in our theoretical

results is very conservative, in the sense that for obtaining a δ-accurate ranking, the constants in αt

can be chosen smaller, which in turn results in fewer comparisons.

5.2 Selection of conﬁdence interval

Recall that the AR algorithm eliminates an item if the conﬁdence that it belongs to one of the

sets S1, . . . , SL, is suﬃciently large. Our main results show that the AR algorithm succeeds at

recovering the ranking with probability at least 1 − δ, provided that the length of the conﬁdence

interval is chosen as αt = log(125n lotg(1.12t)/δ) . While this result is optimal up to log-factors, the particular choice of the constants might be overly conservative, and improvements in the (empirical)

sample complexity might be obtained by choosing the constants in αt smaller, as we show next. To

investigate

this

claim,

we

set

αt

=

1 4

log(n/3(lotg(t)+1)/δ) . We generate a pairwise comparison model

with n = 5, scores τ = (0.9, 0.7, 0.5, 0.3, 0.1), and use the AR algorithm to ﬁnd the top 2 items, for

diﬀerent values of the desired accuracy δ. The results, depicted in Figure 6, show that, even with

those signiﬁcantly smaller constants, the AR algorithm is δ-accurate.

6 Proofs
In this section, we provide the proofs of our two main theorems. In order to simplify notation, we take the underlying permutation π equal to the identity, so that τ1 > τ2 > . . . > τn. This assumption entails no loss of generality, since it can also be satisﬁed by re-indexing the items if necessary.
6.1 Proof of Theorem 1(a)
In this section, we provide a proof of the achievable result stated in part (a) of Theorem 1. Our proof consists of three main steps. We begin by showing that the estimate τi(t) is guaranteed to

15

be αt-close to τi, for all i ∈ S, with high probability. We then use this result to show that the AR algorithm never misclassiﬁes any item, and that it stops with the number of comparisons satisfying the claimed upper bound.
Throughout the paper, we use S to denote the set of items that have not been ranked yet; to be clear, since items are eliminated from S at certain time steps t, the set S changes with t, but we suppress this dependence for notational simplicity.

Lemma 1. Under the theorem’s assumptions, the event

Eα := {|τi(t) − τi| ≤ αt, for all i ∈ S and for all t ≥ 1}

(14)

occurs with probability at least 1 − δ.
Our next step is to show that provided that the event Eα occurs, the AR algorithm never misclassiﬁes any item, that is, S ⊆ S for all and for all t ≥ 1. First suppose that, at a given time step t, the AR algorithm did not misclassify any item at a previous time step. We show that, at time t, conditioned on the event Eα, any item j ∈ S is added to S only if j ∈ S , which implies that the AR algorithm does not misclassify any item at time t. This fact is a consequence of our second auxiliary result.
In order to state this second lemma, we require some additional notation. Let τ{k} denote the k-th largest score among the latent scores τi, i ∈ S. Note that we use the notation {·} to emphasize that the index {k} is not necessarily equal to the index (k), since the latter corresponds to the k-th largest score amongst the estimated scores τi(t), i ∈ S.
Lemma 2. Suppose that the event Eα occurs. Then both of the implications

• for any j ∈ S, τj(t) < τ(k −1)(t) − 4αt • for any j ∈ S, τj(t) > τ(k +1)(t) + 4αt

implies implies

τj < τ{k −1}, and τj > τ{k +1},

(15a) (15b)

hold for all t ≥ 1.

Provided that the AR algorithm did not misclassify any item at a previous time step, some consequences of implications (15a) and (15b) are the following:

• ﬁrst, for any index , an item is added to S at time t only if j ∈ S .

• therefore, we are guaranteed that S ⊆ S at time t + 1.

These consequences allow us to apply an inductive argument to conclude that the AR algorithm never misclassiﬁes any item.

Our next step is to show that, conditioned on the event Eα on which the AR algorithm does not misclassify any item, all items are eliminated after the number of comparisons given in equation (10a) have been carried out. Since, by Lemma 1, the event Eα holds with probability at least 1 − δ, this concludes the proof of Theorem 1(a).
In order to establish the former claim, we use the following lemma, in which we made the dependence of the set of candidates S on t explicit by writing S(t).

16

Lemma 3. Suppose that the event Eα occurs. For any index S ∩ S(ti), we have, with c1 := 654,

∈ {2, . . . , L} and any item i ∈

τi(ti) < τ(k −1)(ti) − 4αti , where ti := ∆¯c21,i log nδ log ∆¯2,i , ∆¯ ,i = τk −1 − τi, (16a)

and for ∈ {1, . . . , L − 1} and any item i ∈ S ∩ S(ti), with probability at least 1 − 4δn , we have

τi(ti) > τ(k +1)(ti) − 4αti ,

where ti := ∆¯c21 log

n log δ

2 ∆

,i

,i

, ∆ ,i = τi − τk +1.

(16b)

Consequently, the index i ∈ S is eliminated from the set of candidates S after no more than the following number of many time steps (and hence comparisons):



ti,

if = 1



max(ti, ti), if ∈ {2, . . . , L − 1} .

ti,

if = L

Using the relations

log(2 log(2/∆¯ ,i))

log(2 log(2/∆ ,i))

ti ≤ cup

∆¯ 2

log(n/δ), and ti ≤ cup

∆2

log(n/δ),

,i

,i

where the inequalities hold for some constant cup, it follows that the AR algorithm terminates after the number of comparisons stated in equation (10a) has been carried out.

It remains to prove Lemmas 1, 2, and 3, and we do so in the following subsections.

6.1.1 Proof of Lemma 1

In order to show that the event Eα occurs with probability at least 1 − δ, ﬁrst recall that comparing item i to an item chosen uniformly at random from [n]\{i} is equivalent to taking an independent draw from a Bernoulli random variable with mean τi. One can verify from the recursion (6) that τi(t) is a sum of t independent Bernoulli random variables, each of which has mean τi/t. In order to control the ﬂuctuations of τi(t), we make use of a non-asymptotic version of the law of the iterated logarithm from Jamieson et al. [Jam+14].
Lemma 4 ([Jam+14, Lem. 1, with = 0.1151]). Given an i.i.d. sequence {Xs}∞ s=1 of Bernoulli variables with mean µ, then for any ∈ (0, 1) and δ ∈ (0, 1), we have

1t t (Xs − µ) ≤
s=1
with probability at least 1 − δ.

log(125 log(1.12t)/δ ) , t

for all t ≥ 1

In the current context, applying Lemma 4 with δ = n/δ and αt =

log(125n log(1.12t)/δ) t

yields

δ P |τi(t) − τi| ≥ αt for some t ≥ 1 ≤ n .

Taking the union bound over all indices i ∈ S ⊆ [n] yields that P[Eα] ≥ 1 − δ, as claimed.

17

6.1.2 Proof of Lemma 2
We show that implications (15a) and (15b) follow from the inequality in event Eα. In order to do so, consider any index k such that τk (t) = τ(k)(t). Here we have allowed for the possibility that (k) may not be unique. We start by showing that the inequality in event Eα implies that

|τ{k} − τk | ≤ 2αt.

(17)

We claim that τ{k} − τk ≥ −2αt. By deﬁnition of k , there are k indices {i1, . . . , ik} such that τi (t) ≥ τk (t) for every ∈ [k]. In conjunction with the inequality in event Eα, we obtain

τi + αt ≥ τk − αt.

Since this inequality holds for k many indices {i1, . . . , ik}, one of those indices must be {k}, due
to τ{1} ≥ τ{2} ≥ . . . ≥ τ{|S|}. It follows that τ{k} − τk ≥ −2αt. It remains to establish that τ{k} − τk ≤ 2αt. By deﬁnition of k , there are |S| − k + 1 many indices k˜ obeying

τk˜(t) ≤ τk (t).
By the inequality in event Eα, this yields τk˜ −αt ≤ τk +αt. Since this inequality holds for |S|−k +1 indices k˜, it must hold for k˜ = {k}, which implies τ{k} ≤ τk + 2αt. Thus, we have established that inequality (17) must hold under event Eα.
We are now ready to establish the claim (15a). Let k be any index such that τk = τ(k −1). As long as τj(t) < τ(k −1) − 4αt, we have

(i)
4αt < τk (t) − τj(t) ≤ τk + αt − τj + αt ≤ τ{k −1} − τj + 2αt + 2αt. (18)

Here step (i) follows by the inequality in event Eα, whereas inequality (18) follows by inequality (17).
Noting that inequality (18) is equivalent to τj < τ{k −1}, we have established the claim (15a). The proof of claim (15b) is analogous, so we omit the details.

6.1.3 Proof of Lemma 3
We ﬁrst prove that, if the event Eα occurs, then for any given index i ∈ S , and for all > 1, inequality (16a) holds. Let k be any index satisfying the equality τk (t) = τ(k −1)(t), and recall that τ{k} is the k-th largest score out of the latent scores τi, i ∈ S. On the event Eα, we have

(i)
τk (ti) ≥ τk − αti − τi(ti) ≥ τ{k −1} − 3αti

(ii)
≥ τk −1 − 3αti = ∆¯ ,i − 3αti + τi

(iii)
≥

∆¯

,i

−

4αt

+ τi(ti).

i

(19)

18

Here step (i) follows by inequality (17), which holds on the event Eα, and inequality (ii) follows from τ{k −1} ≥ τk −1, which is seen as follows. As shown above, on the event Eα, the AR algorithm never misclassiﬁes any item, therefore the k −1-th largest score among the items in the set S must be larger or equal to the k −1-th largest score among all scores. Finally, inequality (iii) follows from τi(ti) − τi ≤ αti, which holds on the event Eα.
From the deﬁnition of αti, some algebra leads to the lower bound
∆¯ ,i > 8αti . (20)
See the end of this subsection for details of this calculation. Application of inequality (20) on the RHS of inequality (19) yields
τk (ti) > 4αti + τi(ti),
which concludes the proof of inequality (16a). Analogously, it follows that inequality (16b) holds for a given item i if the event Eα occurs.

Proof of the lower bound (20): By deﬁnition of αt and ti, we have that

α2 = log 12δ5n log 1.12 ∆¯c21,i log nδ log ∆¯2,i

ti

c1 ∆¯ 2

log

n δ

log

2 ∆¯

,i

,i

∆¯ 2 log ≤ ,i
c1

125n δ

log

1.12c1 n 23 4 δ ∆¯ 3

,i

log nδ log ∆¯2,i

≤ ∆¯ 2,i log 12δ5n 1.142c1 nδ 1/3 3 log ∆¯2,i c1 log nδ log ∆¯2,i

∆¯ 2,i

4 3

log

≤

c1

∆¯ 2,i < 82 ,

375

1.142c1 1/3 nδ log

2 ∆¯

,i

log nδ log ∆¯2,i ,

where the last inequality holds for c1 = 654.

6.2 Proof of Theorem 1(b)
We now turn to the proof of the lower bound from Theorem 1. We ﬁrst introduce some notation required to state a useful lemma [Kau+16, Lem. 1] from the bandit literature. Let ν = {νj}mj=1 be a collection of m probability distributions, each supported on the real line R. Consider an algorithm A, that, at times t = 1, 2, . . ., selects the index it ∈ [m] and receives an independent draw Xt from the distribution νit in response. Algorithm A may select it only based on past observations, that is, it is Ft−1 measurable, where Ft is the σ-algebra generated by i1, Xi1, . . . , it, Xit. Algorithm A

19

has a stopping rule χ that determines the termination of A. We assume that χ is a stopping time

measurable with respect to Ft and obeying P [χ < ∞] = 1.

Let Qi(χ) denote the total number of times index i has been selected by the algorithm A (until

termination). For any pair of distributions ν and ν , we let KL(ν, ν ) denote their Kullback-Leibler

divergence,

and

for

any

p, q

∈

[0, 1],

let

d(p, q)

:=

p log

p q

+(1−p) log

1−p 1−q

denote

the

Kullback-Leiber

divergence between two binary random variables with success probabilities p, q.

With this notation, the following lemma relates the cumulative number of comparisons to the

uncertainty between the actual distribution ν and an alternative distribution ν .

Lemma 5 ([Kau+16, Lem. 1]). Let ν, ν be two collections of m probability distributions on R. Then for any event E ∈ Fχ with Pν [E] ∈ (0, 1), we have

m

Eν [Qi(χ)] KL(νi, νi) ≥ d(Pν [E] , Pν [E]).

(21)

i=1

Let us now use Lemma 5 to prove Theorem 1(b). In particular, we apply it using the event

E := S = S , for all = 1, . . . , L ,

(22)

which corresponds to success of the algorithm A. Recalling that χ is the stopping rule of algorithm A, we are guaranteed that E ∈ Fχ. Given the linear relations Mij = 1 − Mji, the pairwise comparison matrix M is determined by the entries {Mij, i = 1, . . . , n, j = i + 1, . . . , n}. Let Qij(χ) be the total number of comparisons between items i and j made by A. For any other pairwise comparison matrix M ∈ C0, Lemma 5 ensures that

nn

EM [Qij] d(Mij, Mij) ≥ d(PM [E] , PM [E]).

(23)

i=1 j=i+1

For some > 1 and item5 m ∈ S (M ), our next step is to construct a matrix M ∈ C1/8 such that m ∈/ S (M ) under the distribution M . Since the algorithm A is uniformly δ-accurate over C1/8 by assumption, we are guaranteed that

PM [E] ≥ 1 − δ and PM [E] ≤ δ,

from which it follows that

1−δ

1

d(PM [E] , PM [E]) ≥ d(δ, 1 − δ) = (1 − 2δ) log δ ≥ log 2δ ,

(24)

where the last inequality holds for δ ≤ 0.15. It remains to specify the alternative matrix M ∈ C0 for use in inequality (24): it is deﬁned with
entries

 Mmj + (τk −1 − τm), if i = m, j ∈ [n] \ {m} 

Mij := Mim − (τk −1 − τm), if j = m, i ∈ [n] \ {m}

(25)

Mij

otherwise.

5It is helpful here to make explicit the dependence of S = {π(k −1 + 1), . . . , π(k )} on the distribution M . Note that π is a function of M .

20





M14









 

M24

 









 

M34

 









 M41 M42 M43 M44 M45 M46 











M54













M64



scores τj, τj

0.8

τj

τj

0.6

0.4

0.2

2

4

6

index j

Figure 7. Illustration of the distributions M, M and the corresponding scores τj, τj: Suppose that m = 4 and k −1 = 2. The probabilities Mij are obtained from the probabilities Mij by increasing the probabilities surrounded by a rectangle, and decreasing the probabilities surrounded by a circle,
all others remain unchanged.

From this deﬁnition, it follows that

1

1

τm = n − 1

Mmj = n − 1

Mmj + (τk −1 − τm)

j∈[n]\{m}

j∈[n]\{m}

= τk −1 .

Similarly, all other scores τi are smaller than τi by a common constant, that is, for i ∈ [n] \ {m} 1
τi = τi − n − 1 (τk −1 − τm).
See Figure 7 for an illustration. It follows that, under the distribution M , the score of item m is among the k −1 highest scoring items, which ensures m ∈/ S (M ). Moreover, we claim that M ∈ C1/8. This inclusion follows from the assumption M ∈ C3/8, which implies that
5 53 7 Mmj ≤ 8 + 8 − 8 ≤ 8 .
An analogous argument shows that Mmj ≥ 18 . Next consider the total number of comparisons of item m with all others items,
that is, Qm = j∈[n]\{m} Qmj. By the linearity of expectation, we have

max d(Mmj, Mmj)EM [Qm] = max d(Mmj, Mmj)

EM Qmj

j∈[n]\{m}

j∈[n]\{m}

j ∈[n]\{m}

≥

EM [Qmj] d(Mmj, Mmj).

j∈[n]\{m}

Now observe that by the deﬁnition of M in equation (25), we have d(Mij, Mij) = 0 for all (i, j) outside of the sets {(m, j) | j ∈ [n] \ {m}} and {(i, m) | i ∈ [n] \ {m}}. Removing these terms from

21

the sum yields

nn

max d(Mmj, Mmj)EM [Qm] ≥

EM [Qij] d(Mij, Mij)

j∈[n]\{m}

i=1 j=i+1

(i)
≥ d(PM [E] , PM [E])

(≥ii) log 1 , 2δ

(26)

where step (i) follows inequality (23) in Lemma 5; and step (ii) follows from inequality (24). We next upper bound the KL divergence on the left hand side of inequality (26). Using the
inequality log x ≤ x − 1 valid for x > 0, we have

d(M , M ) ≤ (Mmj − Mmj)2 ≤ 16(τ − τ )2,

(27)

mj mj Mmj (1 − Mmj )

k −1

m

where the last step uses the deﬁnition of M

in

equation

(25),

as

well

as

the

inclusion

1 8

≤

Mmj

≤

78 ,

which implies that M

1 (1−M

) ≤ 16.

mj

mj

Applying inequality (27) to the left hand side of inequality (26) yields

log(1/(2δ))

EM [Qm] ≥ 16(τk − τm)2 , valid for each m ∈ S (M ) and > 1.

(28)

−1

Now consider an index m ∈ S (M ) for some < L. In this case, again construct an alternative pairwise comparison matrix M under which m ∈/ S (M ). Speciﬁcally, for notational convenience, we set

 Mmj − (τm − τk +1),  Mij = Mim + (τm − τk +1), Mij

i = m, j ∈ [n] \ {m} j = m, i ∈ [n] \ {m} otherwise.

In a similar manner to our earlier argument, we have τi = τi + n−1 1 (τm − τk +1) for i ∈ [n] \ {m} and τm = τk +1 (relative to the scores τi, the score of m is smaller and all others are larger by the same factor). Under M , item m is not amongst the k items with the largest scores, and therefore
m ∈/ S (M ). Carrying out the same computations as above yields:

log(1/(2δ))

EM [Qm] ≥ 16(τm − τk +1)2 .

(29)

Combining inequalities (28) and (29) across all items m yields the bound



n

L−1

EM [Q] = E [Qi] ≥ clow log(1/(2δ))  ∆−1,i2 +

max

i=1

i∈S1

=2 i∈S

∆−,i2, ∆¯ −,i2



+

∆¯

−2 L,i



,

i∈SL

with clow = 1/16, thereby yielding the claimed result.

22

6.3 Proof of Theorem 2(a)

Our goal is to prove that any algorithm A that is uniformly δ-accurate over CPAR(Φ) ∩ CMmin, when applied to a given pairwise comparison model M ∈ CPAR(Φ) ∩ CMmin, must make at least

EM [Q] ≥ Mminφ2min log 1 F (τ (M ))

2.004φ2max

2δ

comparisons on average. Here F (τ (M )) is the complexity parameter deﬁned in equation (12).
The proof is similar to that of Theorem 1(b), with the primary diﬀerence being that the alterna-
tive matrix M must now be constructed such that it lies in the parametric class. In what follows,
we show how to modify the proof of Theorem 1 at appropriate positions in order to accommodate
this diﬀerence.
Consider any parametric pairwise comparison matrix M ∈ CPAR(Φ) ∩ CMmin. Then there exists a parameter vector w ∈ Rn such that Mij = Φ(wi − wj). By the assumption τ1 > . . . > τn, this parameter vector obeys w1 > . . . > wn. Consider an item m ∈ S (M ), > 1, and set k := k −1, for notational convenience. We construct an alternative matrix M ∈ CPAR(Φ) ∩ CMmin as follows. Consider some scalar value ρ that lies in the interval 0 < ρ < wk − wk−1. Deﬁne a set of alternative parameters as

 wk  wi := wk − ρ wi

if i = m, if i = k, otherwise.

Now let M be the matrix with pairwise comparison probabilities Mij = Φ(wi − wj). By deﬁnition, we have w1 ≥ wi ≥ wn for all i ∈ [n], which ensures that M ∈ CPAR(Φ) ∩ CMmin. Moreover, by deﬁnition, item m is among the top k items, so that m ∈/ S (M ). Since (by assumption) algorithm
A is uniformly δ-accurate over CPAR(Φ) ∩ CMmin, we have both PM [E] ≥ 1 − δ and PM [E] ≤ δ, which ensures that inequality (24) holds. Here E denotes the previously deﬁned event (22) that the
algorithm A correctly recovers the set structure.
Next consider the total number of comparisons of item m with all others items, denoted by Qm. As in inequality (26), we are guaranteed that

max d(Mmj, Mmj)EM [Qm] ≥

EM [Qmj] d(Mmj, Mmj)

j∈[n]\{m}

j∈[n]\{m}

n
(=i)

n
EM [Qij] d(Mij, Mij) −

EM [Qjk] d(Mjk, Mjk)

i=1 j=i+1

j∈[n]\{k,m}

(ii)
≥ d(PM [E] , PM [E]) − 0.001d(PM [E] , PM [E])

(iii)
≥ d(PM [E] , PM [E]) −

EM [Qjk] d(Mjk, Mjk)

j∈[n]\{k,m}

≥ 0.999 log 1 . (30) 2δ

Here inequality (i) follows from the fact that d(Mij, Mij) = 0 for all (i, j) with i, j ∈ [n] \ {k, m}, by deﬁnition of M . Inequality (ii) follows from inequality (23) (that is, from Lemma 5). Inequality

23

(iii) is a result of the fact that limρ→0 d(Mik, Mik) = limρ→0 d(Φ(wi − wk), Φ(wi − wk + ρ)) = 0 for every i ∈ [n] \ {k, m}, where we have also employed the continuous mapping theorem: Due to this
relation we can choose ρ suﬃciently close to 0 to obtain the bound of (iii). Finally, inequality (30)
is a consequence of inequality (24).
Our next step is to upper bound the KL divergence d(Mmj, Mmj) For each j ∈ [n] \ {k, m}, we have

(Mmj − Mmj )2 d(Mmj, Mmj) ≤ Mmj(1 − Mmj)
(i) (Mkj − Mmj )2 =
Mkj(1 − Mkj)

(ii)
≤

2 (Φ(wk − wj) − Φ(wm − wj))2

Mmin

(iii)
≤

2 (φmax(wk − wm))2

Mmin

≤ 2φ2max (τk − τm)2. Mminφ2min

(31)

Here step (i) follows by deﬁnition of the parameters Mij; step (ii) follows because Mij belongs to the interval [Mmin, 1 − Mmin]; and step (iii) is a consequence of assumption (11). Finally, the last
inequality (31) follows from the relations





1

τk − τm = n − 1 Φ(wk − wm) − Φ(wm − wk) +

(Φ(wk − wj) − Φ(wm − wj))

j∈[n]\{k,m}





(i) 1

≥ n − 1 φmin(wk − wm − (wm − wk)) +

φmin(wk − wm)

j∈[n]\{k,m}

n = n − 1 φmin(wk − wm) ≥ φmin(wk − wm).

(32)

Here inequality (i) follows from assumption (11); in particular, recall that wk > wm, so the diﬀerence wk − wm above is positive.
Similarly, we have

d(Mmk, Mmk) ≤ M2min (φmax(ρ + wk − wm))2 (≤i) M2.0m0i1n (φmax(wk − wm))2

(ii)
≤

2

.001

φ

2 max

(

τk

−

τm)2,

Mminφ2min

(33)

where inequality (i) follows from choosing ρ suﬃciently close to 0, whereas inequality (ii) follows from the relation (32).
Given an index m in a set S (M ) with > 1, combining inequalities (31) and (33) with inequality (30) yields

EM [Qm] ≥ Mminφ2min log(1/(2δ)) . 2.004φ2max (τk −1 − τm)2

(34a)

24

Similarly, for an index m ∈ S (M ) with < L, we deﬁne an alternative matrix M by deﬁning
corresponding parameters as wm = wk +1, wk +1 = wk +1 + ρ for ρ ∈ (0, wk − wk +1), and wi = wi, for all i ∈/ {m, k + 1}. Under the model speciﬁed by M , item m is not amongst the k items with
the largest scores, and therefore m ∈/ S (M ). The same line of arguments as above yields

EM [Qm] ≥ Mminφ2min log(1/(2δ)) . 2.004φ2max (τm − τk +1)2

(34b)

Combining the lower bounds (34a) and (34b) concludes the proof.

6.4 Proof of Theorem 2(b)
Let τ ∈ (0, 1)n be any set of scores that is realizable by some pairwise comparison matrix in CMmin. Theorem 2(b) is proven by showing that for any continuous and strictly increasing Φ, there exists a pairwise comparison matrix in CPAR(Φ) ∩ CMmin with scores τ . As mentioned before, the proof of Theorem 2(b) relies on results established by Joe [Joe88] on majorization orderings of pairwise probability matrices. For convenience, we deﬁne the set of pairwise probability matrices with scores τ = (τ1, . . . , τn) as







1



C(τ ) = M ∈ C0 | n − 1 Mij = τi, for all i .



j=i



Minimality for pairwise comparison matrices: Our proof requires some background on ma-

jorization and a certain notion of minimality for pairwise comparison matrices. We say that a

vector y ∈ Rm is non-increasing if its entries satisfy y1 ≥ y2 ≥ . . . ≥ ym. Given two non-increasing

vectors y, z ∈ Rm such that

m i=1

yi

=

m i=1

zi,

we

say

y

majorizes

z,

written

y

z, if

k

k

yi ≥ zi, for all k = 1, . . . , m − 1.

i=1

i=1

Given pairwise comparison matrices M, M ∈ C(τ ), we let v(M ), v(M ) ∈ (0, 1)n(n−1) be vectors with entries corresponding to the oﬀ-diagonal elements of M and M , respectively, in non-increasing order. We say that M majorizes M if v(M ) v(M ), and we use the shorthand M M to denote this relation. Finally, a matrix M ∈ C(τ ) is minimal if any other M ∈ C(τ ) obeying M M satisﬁes the relation v(M ) = v(M ).
In order to prove Theorem 2(a), we show that there is a minimal M ∈ C(τ ) ∩ CMmin. We ﬁrst note that Joe [Joe88, Thm. 2.7] observed that the argument minimizing any Schur convex 6 function over the set C(τ ) is a minimal M . Let us now construct a function that is Schur convex. In particular, we ﬁrst deﬁne a scalar function ψ : [0, 1] → [0, ∞] as

ψ(u) =

1 2

u 1/2

Φ−1

(x)dx,

u∈

1 2

,

1

,

(35)

− 12

1/2 u

Φ−1

(x)dx,

u∈

0,

1 2

.

6In our context, a function f : (0, 1)n×n → R is Schur convex (or order-preserving) if for all M, M ∈ C(τ ) such that M is majorized by M , we have f (M ) ≤ f (M ).

25

The function ψ is well deﬁned since the inverse Φ−1 exists due to our assumption that Φ is strictly increasing and continuous. Since Φ is strictly increasing, so is Φ−1. It follows that ψ is strictly
convex. From the property that all symmetric and strictly convex functions are also strictly Schur
convex, it follows that the function i,j=i ψ(Mij) is strictly Schur convex over C(τ ). As a result, we are guaranteed that the argument minimizing the following convex program corresponds to a
minimal matrix:

minimize (ψ(Mij) + ψ(1 − Mij))

(36)

i,j>i

subject to 0 ≤ Mij ≤ 1, for all i = 1, . . . , n, j = i + 1, . . . , n, and

1 i−1

1n

n − 1 (1 − Mji) + n − 1

Mij = τi,

j=1

j=i+1

for all i = 1, . . . , n.

Here the minimization is performed over the variables Mij for i = 1, . . . , n and j = i + 1, . . . , n.

We next show that any optimal solution M ∗ to the problem (36) has entries satisfying the

interval inclusion Mi∗j ∈ [Mmin, 1 − Mmin] for all pairs (i, j), and therefore M ∗ ∈ CMmin, as desired. Indeed, suppose that there were an optimal solution M ∗ that violated this inclusion. By assumption,

there exists a matrix M ∈ C(τ ) ∩ CMmin. Thus, if the inclusion were violated, then there would be some index pair (i, j) such that Mi∗j < Mij. This would imply that M ∗ is strictly larger than M in
the majorization ordering. But since the objective function (36) is Schur convex, this contradicts

the optimality of M ∗.

Since there exists a solution to the convex optimization problem (36) that satisﬁes the inequality

constraints strictly (due to Mmin > 0, by assumption), Slater’s conditions hold, and the Karush-

Kuhn-Tucker (KKT) conditions are necessary and suﬃcient for optimality (see, for instance, [BV04,

Sec.

5.5]).

Thus,

the

primal

and

dual

optimal

solutions

Mi∗j

and

{

λ

∗ ij

,

κ∗ij

,

νi∗

}

must

satisfy

the

KKT

conditions

λ∗ij , κ∗ij ≥ 0, λ∗ij(Mi∗j − 1) = 0, κ∗ijMi∗j = 0, and ψ (Mi∗j) − ψ (1 − Mi∗j) + λ∗ij − κ∗ij + νi∗ − νj∗ = 0.

(37a) (37b) (37c)

Since Mi∗j ∈ (0, 1) for all pairs (i, j), the KKT conditions imply that λ∗ij = 0 and κ∗ij = 0. Consequently, equation (37c) takes the simpler form

ν∗ − ν∗ = ψ (M ∗ ) − ψ (1 − M ∗ ) = 1 Φ−1(M ∗ ) − 1 Φ−1(1 − M ∗ )

j

i

ij

ij 2

ij 2

ij

(=i) Φ−1(Mi∗j ),

(38)

where step (i) follows because Φ(t) = 1 − Φ(−t) for all t ∈ R by assumption. It follows that Mi∗j = Φ(νj∗ − νi∗) for all pairs (i, j), meaning that M ∗ takes a parametric form, as claimed.

7 Discussion
In this paper, we considered the problem of ﬁnding a partial or complete ranking from active pairwise comparisons. We proved that a simple and computationally eﬃcient algorithm succeeds

26

in recovering the ranking with a sample complexity that is optimal up to logarithmic factors. We furthermore proved that this algorithm remains optimal when imposing common parametric assumptions such as the popular BTL or Thurstone models—provided the pairwise comparison probabilities are bounded away from 0 and 1. This show that, perhaps surprisingly, imposing common parametric assumptions cannot reduce the sample complexity of ranking by more than a log-factor in the stochastic regime. That being said, it should be noted that in practice, the possibility of gaining (at most) a log factor from assuming the parametric model may be overshadowed by the signiﬁcant additional robustness aﬀorded by our more general model class. For instance, see Ballinger et al. [BW97] for some empirical evidence that parametric models do not provide good ﬁt in many applications, and, as our numerical results demonstrated, algorithms relying on parametric models can be quite sensitive to violations of those modeling assumptions.
There are a number of open and practically relevant questions suggested by our work. From a theoretical perspective, it would be interesting to provide an algorithm and corresponding guarantees for parametric models that matches our lower bound in the regime where the comparison probabilities are bounded away from zero and one, and at the same time is optimal in the regime where the pairwise comparison probabilities are very close to zero and one. A ﬁnal interesting topic of future work is related to approximate rankings. Speciﬁcally, in practice, one might only be interested in ﬁnding an approximate ranking, or might only be able to ﬁnd an approximate ranking due to a limited budget of queries.
Acknowledgements
The work of RH was supported by the Swiss National Science Foundation under grant P2EZP2 159065. This work was supported by Oﬃce of Naval Research MURI grant DOD-002888, Air Force Oﬃce of Scientiﬁc Research Grant AFOSR-FA9550-14-1-001, Oﬃce of Naval Research grant ONR-N00014, as well as National Science Foundation Grant CIF-31712-23800. The work of NBS was also supported in part by a Microsoft Research PhD fellowship.

References

[Agg16] [Ail11]
[BW97] [BV04] [BT52] [Bub+13] [BCB12]

C. C. Aggarwal. Recommender systems: The textbook. Springer, 2016.
N. Ailon. “Active learning ranking from pairwise preferences with almost optimal query complexity”. In: Advances in Neural Information Processing Systems. 2011, pp. 810– 818.
T. P. Ballinger and N. T. Wilcox. “Decisions, error and heterogeneity”. In: The Economic Journal 107.443 (1997), pp. 1090–1105.
S. Boyd and L. Vandenberghe. Convex optimization. Cambridge University Press, 2004.
R. A. Bradley and M. E. Terry. “Rank analysis of incomplete block designs: I. The method of paired comparisons”. In: Biometrika 39.3/4 (1952), pp. 324–345.
S. Bubeck, T. Wang, and N. Viswanathan. “Multiple identiﬁcations in multi-armed bandits”. In: International Conference on Machine Learning. 2013, pp. 258–265.
S. Bubeck and N. Cesa-Bianchi. “Regret analysis of stochastic and nonstochastic multiarmed bandit problems”. In: Foundations and Trends in Machine Learning 5 (2012).

27

[BF+13]
[Che+16] [CS15] [DB81] [Eri13] [ED+06]
[Haj+14] [Hun04] [JN11] [Jam+14]
[Jam+15] [Joe88] [Kau+16]
[Lan53]
[Luc59] [MG15] [Neg+12]

R. Busa-Fekete, B. Szorenyi, W. Cheng, P. Weng, and E. Hu¨llermeier. “Top-k selection based on adaptive sampling of noisy preferences”. In: International Conference on Machine Learning. 2013, pp. 1094–1102.
X. Chen, S. Gopi, J. Mao, and J. Schneider. “Competitive analysis of the top-k ranking problem”. In: arXiv:1605.03933 (2016).
Y. Chen and C. Suh. “Spectral MLE: Top-k rank aggregation from pairwise comparisons”. In: International Conference on Machine Learning. 2015, 371–380.
J. C. De Borda. “M´emoire sur les ´elections au scrutin”. In: Histoire de l’Acad´emie Royale des Sciences (1781).
B. Eriksson. “Learning to top-k search using pairwise comparisons”. In: International Conference on Machine Learning. 2013, pp. 265–273.
E. Even-Dar, S. Mannor, and Y. Mansour. “Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems”. In: Journal on Machine Learning Research 7 (2006), pp. 1079–1105.
B. Hajek, S. Oh, and J. Xu. “Minimax-optimal inference from partial rankings”. In: Advances in Neural Information Processing Systems. 2014, pp. 1475–1483.
D. Hunter. “MM algorithms for generalized Bradley-Terry models”. In: Annals of Statistics (2004), pp. 384–406.
K. Jamieson and R. Nowak. “Active ranking using pairwise comparisons”. In: Advances in Neural Information Processing Systems. 2011, pp. 2240–2248.
K. Jamieson, M. Malloy, R. Nowak, and S. Bubeck. “lil’ UCB: An optimal exploration algorithm for multi-armed bandits”. In: Conference on Learning Theory. 2014, pp. 423– 439.
K. Jamieson, S. Katariya, A. Deshpande, and R. Nowak. “Sparse dueling bandits”. In: International Conference on Artiﬁcial Intelligence and Statistics. 2015, pp. 416–424.
H. Joe. “Majorization, entropy and paired comparisons”. In: The Annals of Statistics 16.2 (1988), pp. 915–925.
E. Kaufmann, O. Capp´e, and A. Garivier. “On the complexity of best arm identiﬁcation in multi-armed bandit models”. In: Journal on Machine Learning Research 17.1 (2016), pp. 1–42.
H. G. Landau. “On dominance relations and the structure of animal societies: III The condition for a score structure”. In: The Bulletin of Mathematical Biophysics 15.2 (1953), pp. 143–148.
R. D. Luce. Individual choice behavior: A theoretical analysis. Wiley, 1959.
L. Maystre and M. Grossglauser. “Robust active ranking from sparse noisy comparisons”. In: arXiv:1502.05556 (2015).
S. N. Negahban, S. Oh, and D. Shah. “Iterative ranking from pair-wise comparisons”. In: Advances in Neural Information Processing Systems. 2012, pp. 2474–2482.

28

[Pau64]
[Pie+13]
[SL15] [SW15] [Sha+13]
[Sha+16a]
[Sha+16b]
[Sou+14] [Sz15]
[Thu27] [TER69] [Urv+13] [YJ11] [Yue+12]

E. Paulson. “A sequential procedure for selecting the population with the largest mean from k normal populations”. In: The Annals of Mathematical Statistics 35.1 (1964), pp. 174–180.
C. Piech, J. Huang, Z. Chen, C. Do, A. Ng, and D. Koller. “Tuned models of peer assessment in MOOCs”. In: International Conference on Educational Data Mining. 2013.
M. J. Salganik and K. E. C. Levy. “Wiki surveys: Open and quantiﬁable social data collection”. In: PLOS ONE 10.5 (2015), e0123483.
N. B. Shah and M. J. Wainwright. “Simple, robust and optimal ranking from pairwise comparisons”. In: arXiv:1512.08949 (2015).
N. B. Shah, J. K. Bradley, A. Parekh, M. J. Wainwright, and K. Ramchandran. “A case for ordinal peer-evaluation in MOOCs”. In: NIPS Workshop on Data Driven Education. 2013.
N. B. Shah, S. Balakrishnan, J. Bradley, A. Parekh, K. Ramchandran, and M. J. Wainwright. “Estimation from pairwise comparisons: Sharp minimax bounds with topology dependence”. In: Journal on Machine Learning Research (2016).
N. B. Shah, S. Balakrishnan, A. Guntuboyina, and M. J. Wainwright. “Stochastically transitive models for pairwise comparisons: Statistical and computational issues”. In: International Conference on Machine Learning. 2016.
H. Souﬁani, D. Parkes, and L. Xia. “Computing parametric ranking models via rankbreaking”. In: International Conference on Machine Learning. 2014.
B. Sz¨or´enyi, R. Busa-Fekete, A. Paul, and E. Hu¨llermeier. “Online rank elicitation for Plackett-Luce: A dueling bandits approach”. In: Advances in Neural Information Processing Systems. 2015, pp. 604–612.
L. Thurstone. “A law of comparative judgment”. In: Psychological Review 34.4 (1927), pp. 273–286.
A. Tversky and J. Edward Russo. “Substitutability and similarity in binary choices”. In: Journal of Mathematical Psychology 6.1 (1969), pp. 1–12.
T. Urvoy, F. Clerot, R. F´eraud, and S. Naamane. “Generic exploration and K-armed voting bandits”. In: International Conference on Machine Learning. 2013, pp. 91–99.
Y. Yue and T. Joachims. “Beat the mean bandit”. In: International Conference on Machine Learning. 2011, pp. 241–248.
Y. Yue, J. Broder, R. Kleinberg, and T. Joachims. “The K-armed dueling bandits problem”. In: Journal of Computer and System Sciences 78.5 (2012), pp. 1538–1556.

29

