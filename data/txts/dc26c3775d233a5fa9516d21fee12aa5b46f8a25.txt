arXiv:1901.00401v1 [cs.IR] 14 Dec 2018

Information Extraction from Scientiﬁc Literature for Method Recommendation
Yi Luan University of Washington
luanyi@uw.edu
Abstract As a research community grows, more and more papers are published each year. As a result there is increasing demand for improved methods for ﬁnding relevant papers, automatically understanding the key ideas and recommending potential methods for a target problem. Despite advances in search engines, it is still hard to identify new technologies according to a researcher’s need. Due to the large variety of domains and extremely limited annotated resources, there has been relatively little work on leveraging natural language processing in scientiﬁc recommendation. In this proposal, we aim at making scientiﬁc recommendations by extracting scientiﬁc terms from a large collection of scientiﬁc papers and organizing the terms into a knowledge graph. In preliminary work, we trained a scientiﬁc term extractor using a small amount of annotated data and obtained state-of-the-art performance by leveraging large amount of unannotated papers through applying multiple semi-supervised approaches. We propose to construct a knowledge graph in a way that can make minimal use of hand annotated data, using only the extracted terms, unsupervised relational signals such as co-occurrence, and structural external resources such as Wikipedia. Latent relations between scientiﬁc terms can be learned from the graph. Recommendations will be made through graph inference for both observed and unobserved relational pairs.
1 Introduction
New technologies are always built on previous discoveries and a great technological breakthrough can stimulate a chain of developments across different scientiﬁc ﬁelds. As a research community grows, more and more papers are published each year which requires more and more human effort to read and understand. Typical information researchers seek when reading are the task of the paper and the methods to solve the task. On top of that, researchers need to ﬁgure out how the paper is related to their own research. While there are review papers for some areas, it is generally difﬁcult to be comprehensive. It is even harder to get knowledge of publications from all other related ﬁelds and choose the ones that can shed light on the researcher’s problem. Therefore, an intelligant way of recommending useful and relevant scientiﬁc information is in great demand.
Current efforts to make scientiﬁc recommendation are limited to search engines such as Google Scholar,1 or Semantic Scholar.2 Even though the search engines can provide a way of obtaining all publications related to a certain search query, it is still hard to ﬁlter out or organize key information from the massive search engine output.
1https://scholar.google.com/ 2https://www.semanticscholar.org/
1

In order to make scientiﬁc recommendations, we need to extract and organize useful scientiﬁc knowledge in a structural way. One way of representing knowledge in a large text collection is to build a knowledge graph, which models information in the form of entities and relationships between them [1, 2]. A knowledge graph is a representation of knowledge ﬁrst used by Google to enhance its search engine’s search results with rich semantic information gathered from a wide variety of resources.3 The goal is that users would be able to get an answer to their query without having to navigate to the sites and read the text themselves. A knowledge graph is an important step to transform text-based search results into semantically aware question answering services [3, 4]. Knowledge graphs are also used in several specialized domains. For instance, Bio2RDF [5] and Neurocommons [6] are knowledge graphs that integrate multiple sources of biomedical information. These knowledge graphs have been used for drug discovery and treatment recommendation [7, 8], which is very similar to our problem.
Once a scientiﬁc knowledge graph is constructed, the system can learn latent relation patterns from the observed scientiﬁc terms and generalize the patterns to predict unobserved scientiﬁc pairs. The system can retrieve observed information as well as predicting the possible application of a new algorithm (or possible methods to solve a new task), and make recommendations based on the user query. For example, the Generative Adversarial Network (GAN) has been ﬁrst introduced in machine learning communities in 2014, reaches its peaks in 2015, yet is not been applied in NLP ﬁeld until 2017. NLP researchers may want to know the possible NLP applications of GAN, which could be inferred from relational learning of the scientiﬁc knowledge graph.
Since not much research has been done on scientiﬁc knowledge graph construction, annotated data for both scientiﬁc term and relation extraction is very limited, which becomes the main challenge to construct a knowledge graph in scientiﬁc domain. Previous work on low resource knowledge base construction includes open domain relation extraction (e.g. OpenIE [9]), which uses processed text strings between the two entities as relations and results in a completely unconstrained knowledge graph. Since the relations are not speciﬁed, there is no generalization of these relations and thus it is difﬁcult to use in other systems. Another way to construct a knowledge graph is through distant learning, which requires a high precision, high coverage database that can be used for automatic annotation. However, few such database is available in scientiﬁc domain. Therefore we need to explore new approaches to construct the graph. In this thesis, we propose to apply semisupervised approaches to scientiﬁc information extraction and develop unsupervised approaches for knowledge graph construction and scientiﬁc recommendation. We will discover intrinsic relation signals embedded in the text such as co-occurrence and build the knowledge graph by leveraging both large scale unannotated data and structural external resources such as Wikipedia. Experiments will be based on a large collection of papers from a wide coverage of AI communities which includes speech, computer vision and natural language processing.
The remainder of this proposal is structured as follows. In Section 2, previous work on information extraction and knowledge graph construction is reviewed. In Section 3, our work on scientiﬁc term extraction using a semi-supervised neural approach is introduced. Section 4 introduces the dataset we use, and proposes the research plan for scientiﬁc knowledge graph construction and method recommendation. Conclusions are summarized in Section 5.
3https://googleblog.blogspot.com/2010/07/deeper-understanding-with-metaweb. html
2

2 Background
The major task of Information Extraction (IE) is to turn unstructured text into structured information. Usually IE can be regarded as a pipeline of process with several different types of information that can be extracted: keyphrases (or, entity extraction) and relations between the keyphrases.
2.1 Entity Extraction
A representative task in Entity Extraction is Named Entity Recognition (NER). It is usually modeled as a sequence tagging problem. In previous studies of NER, carefully constructed orthographic features and language-speciﬁc knowledge resources such as gazetteers are widely used [10, 11, 12, 13]. However, language-speciﬁc resources and features are costly to develop in new languages and new domains, making the approaches to NER a challenge to adapt. With the introduction of neural networks, the performance of NER systems has improved substantially [14, 15, 16]. Neural approaches can replace hand-engineered features with well-designed structures that can be easily adapted to other domains or languages.
2.1.1 Neural Sequential Tagging
Sequence tagging has been a classic NLP task which includes part-of-speech tagging (POS), chunking, and named entity recognition (NER). Problems like chunking and NER require detecting the exact span of a term, which could include several tokens within a sentence. In order to be able to distinguish spans of two consecutive terms of the same type, sentences are usually represented in the IOB format (Inside, Outside, Beginning) where every token is labeled as B-label if the token is the beginning of a named entity, I-label if it is inside a named entity but not the ﬁrst token, or O otherwise.
Sequence tagging can be treated as a series of independent classiﬁcation tasks, one per item of the sequence. However, accuracy is generally improved by making the optimal label for a given element dependent on the choices of nearby elements. Common models for sequence tagging are linear statistical models which include the Hidden Markov Model (HMM) and the Conditional Random Field (CRF) [17]. With the introduction of neural approaches, the Convolutional Neural Network and Recurrent Neural Network (RNN) have been proposed to tackle the sequence tagging problem [10, 18]. Conventional RNNs with sigmoid units suffer from gradient decay or explosion, making training difﬁcult. Long-Short-Term Memory (LSTM) [19] models combat the vanishing gradient problem by using a series of gates to avoid amplifying or suppressing gradients during backpropagation. LSTMs have proved to outperform other architectures in many NLP applications and have gained a lot of attention recently.
There is also great interest in NNs that use character-based representations [20, 21, 22] to reduce the effect of out-of-vocabulary (OOV) words. Recent work [15] uses a CRF objective function on top of hybrid word-character LSTM structure and get state-of-the-art result in a NER task. The sequence is tagged using a hierarchical multi-stage model that consists of 3 layers (Figure 1):
1. The Token Representation Layer is the representation of each token, which can be a word embedding or a character representation.
2. The Token LSTM Layer uses a bidirectional LSTM to incorporate contextual cues from surrounding tokens to derive intermediate token embeddings.
3

Figure 1: Neural Network Structure

3. The CRF Layer models token-level tagging decisions jointly using a CRF objective function.

CRF Layer For an input sentence x = (x1, x2, x3, . . . , xn), consider M to be the matrix of scores

output by the bidirectional LSTM network. M is of size n × m, where n is the number of tokens in

a sentence, and m is the number of distinct tags. Pi,t corresponds to the score of the i-th tag of the

t-th word in a sentence:

Pt,i = p(yt = i|xt)

(1)

A ﬁrst-order Markov Model is used and a transition matrix T is deﬁned where Ti,j represents the

score from tag i to tag j. y0 and yn are added as the start and end tags of a sentence. Therefore T

becomes a square matrix of dimension m + 2.

Given one possible output y = (y1, y2, y3, . . . , yn), and neural network parameters θ the score is

deﬁned as

n

n

φ(y; x, θ) = Tyt,yt+1 + Pt,yt

(2)

t=0

t=1

The probability of sequence y is obtained by doing a softmax

exp(φ(y; x, θ)) pθ(y|x) = y ∈ym exp(φ(y ; x, θ)) (3)
where ym is the space of all possible tag sequences. The forward algorithm can be used to efﬁciently calculate the denominator.

2.2 Relation Extraction
Relation Extraction is the next step in analyzing information in texts and turning unstructured information into structured information. After the information is structured and added to a database, it can be used by a wide range of NLP applications, including information retrieval, question answering and many others. Therefore, Relation Extraction is a very important step to knowledge base completion. There are two types of methods used for relation extraction: self-supervised methods and supervised methods.
For scenarios with no labeled data but large amounts of unlabeled data and a small set of extraction patterns, self-supervised systems make the process of relation extraction largely unsupervised. The KnowItAll Web IE system [23] is an example of a self-supervised system. In order to make IE

4

systems faster and more scalable, [24, 9] introduces Open IE, which does not presuppose a predeﬁned set of relations and is targeted at all relations that can be extracted. The system makes a single data-driven pass over its corpus and extracts a large set of relational triplets without requiring any human input. The output of this system consists of triplets stating there is some relation between two entities, but since the relations are not speciﬁed, they are difﬁcult to use in some other systems.
Supervised methods rely on a training set where domain-speciﬁc examples have been tagged. A pre-deﬁned relation is in the form of a triplets t = (ex, rxy, ey) where ex, ey are entities in a predeﬁned relation r within document D. For example, “Mike lives in Chicago.”, a relation (SMike, PHYS, Chicago) would be extracted where PHYS indicates located at. Such systems automatically learn extractors for relations by using machine-learning techniques. The main problem of using these methods is that the development of a suitably tagged corpus can take a lot of time and effort.

2.3 Knowledge Base Representation Learning
Knowledge base (KB) store collections of relation triples t = (ex, rxy, ey) from relation extractor. Even the largest of knowledge bases are incomplete which motivate research of predicting missing information in knowledge bases. In order to recover missing triples, a statistical model needs to exploit regularities in the graphs. Consider for example, the triple (RNN, is a method of, Sequential Tagging) and (Named Entity Recognition, is a task of, Sequential Tagging), then we can infer that Named Entity Recognition can be solved by the method of Recurrent Neural Network. The task of predicting missing relations are usually called Link Prediction, which is a subtask of Knowledge Base Completion.
In order to infer unobserved relations, knowledge base embedding approach was ﬁrst proposed as an alternative statistical relational learning method, and has gained a signiﬁcant amount of attention, due to its simple prediction time computation and strong empirical performance. Early models are learned solely from known direct relationships between two entities (RNN, is a method of, Sequential Tagging). In contrast, using multi-step relation paths (e.g. (NER, is a task of, Sequential Tagging) ∧ (RNN, is a method of, Sequential Tagging)) to train embeddings has been proposed and offered signiﬁcant gains in embedding models for KB completion.

2.3.1 Single-step KB learning
In this framework, entities and relations in a knowledge base are represented in a continuous space. Whether two entities have a previously unknown relationship can be predicted by simple functions of their corresponding vectors [25], matrices [26] or tensors [27].

Vector Embedding In [25], ex and ey in relation triple t = (ex, rxy, ey) are represented by em-

beddings vex, vey and each relation type r is represented by a matrix Qr. Different scoring functions

are designed and compared, all which are deﬁned by a functions between entitiy pair embeddings

and relation matrix. The choice of relation representations are reﬂected in the form of the scoring

function for each triplet. Most of the existing scoring functions in the literature [25, 7] uses bilinear

transformation as

S(ex,r,ey) = veTx Qrvey

(4)

In order to encourage the scores of positive relationships (triplets) to be higher than the scores of any negative relationships (triplets), the model is trained by minimizing a margin-based ranking

5

objective. Since only positive triplets are observed in the data, given a set of positive triplets T ,

a set of “negative” triplets T is constructed by corrupting either one of the relation arguments:

T = {(ex, r, ey) ∈ T } ∪ {(ex, r, ey) ∈ T }. The training objective is designed as minimizing the ranking loss:

L=

max{S(ex,r,ey) − S(ex,r,ey) + 1, 0}

(5)

(ex,r,ey)∈T (ex,r,ey)∈T

Link prediction is then formulated as an entity ranking task. For each triplet in the test data, each entity is treated as the target entity to be predicted in turn. Scores are computed for all the entities in the dictionary and are ranked in descending order. The candidates with higher ranks are considered as correct link.

Matrix Factorization Another way of KB learning is to predict relation based on term occurrence and learn latent representation for terms and relations via matrix factorization. Riedel et. al. [27] generalize the surface forms of relations such as OpenIE [9], which serves as auxiliary relations for link prediction.
In [27], the task is to learn latent feature vectors for entity triplets and relations, columns correspond to relations, and rows correspond to entity triplets. An example of relation extraction through matrix factorization is as Fig. 2. The goal is a model that can estimate the probability of whether a missing element in the matrix is true.
A series of exponential family models that estimate this probability is introduced, which includes modeling three aspects: Latent Feature, Neighborhood Model and Entity Model. Latent Feature guarantees the low rank nature of the reconstructed matrix. Neighborhood Model interpolates the conﬁdence for a given triplet and Entity Model models latent entity representation and relation-argument representation. The scoring function for each triplet is to add all scores of all three models. Similar to Eq. 5, the objective function is to maximize a sum terms of all facts such that the score for each observed fact is bigger than unobserved fact.

Tensor based approaches Instead of clustering surface text patterns to relations, [26] focus on

mining unobserved relations through existing ones via tensor. Given a number of entity E1 . . . En

and relations R1 . . . Rm, the goal is to infer missing relations for existing entities. A tensor X

is constructed as in Fig. 3, where each slice is a relation type and each cell in the slice indicates

the relational existence of two entities. A rank-r factorization is employed , and each slice Xk is

factorized as

Xk ≈ ARkAT , for k = 1, . . . , m

(6)

Here, A is a n × r matrix that contains the latent-component representation of the entities in the domain and Rk is an asymmetric r × r matrix that models the interactions of the latent components in the k-th predicate. The model is optimized by a square loss between the reconstructed tensor with the original value.

2.3.2 Multi-step KB learning
Despite the success of single-step KB learning, it is known that there are also substantial multiplestep relation paths between entities indicating their semantic relationships. The relation paths reﬂect complicated inference patterns among relations in KBs. For example, the relation path (e1, BornInCity, e2) ∧ (e2, CityInCountry, e3) indicates the relation N ationality between e1 and

6

Figure 2: Example of relation extraction through matrix factorization, Figure from [27]. Dark circles are observed facts, shaded circles are inferred facts. Relation Extraction maps surface pattern relations (and other features) to structured relations. Surface form clustering models correlations between patterns.

e3. Previous work about using multi-step relation paths for training can be roughly classiﬁed into two methods: (1) creating auxiliary triples and then add the triples to the learning objective of a factorization model [28]; (2) using paths or walks as features when predicting edges [29, 7, 30].
Both approaches take into account embeddings of relation paths between entities, and both of them used vector space compositions to combine the embeddings of individual relation links ri into an embedding of the path π = {r1 . . . rn}. The intermediate nodes ei are neglected. The composition function of a bilinear model is matrix multiplication. The embedding of a length-n path Φπ is deﬁned as the matrix product of the sequence of relation matrices.

φπ = Qr1 . . . Qrn

(7)

In [28], information from relation paths was used to generate additional auxiliary terms in train-
ing, which provides more training triples for graph learning. The method starts from each node in
the knowledge base, samples m random walks of length 2 to a maximum length L, resulting in a list of triples {(e(xi), π(i), e(yi))}. e(xi) and e(yi) are the start and end nodes of the random walk, and π(i) is the relation path between them. The score of each triple is deﬁned as f (ex, π, ey|θ) = veTxΦπvey .
Instead of using relation paths to augment the set of training triples, [29] proposed to used
paths to deﬁne the scoring function f (ex, π, ey|θ, F (ex, ey)). Here F (ex, ey) denotes the sum of the embeddings of a set of path π between the two nodes in the graph, weighted by path-constrained

7

Figure 3: Tensor model for relational data. E1 . . . En denote the entities, while R1 . . . Rm denote the relations in the domain. Figure from [26].

random walk probabilities as follows:

F (ex, ey) = w|π|P (ey|ex, π)φ(π)

(8)

π

w|π| is a shared parameter for path length, so that the model may learn to trust the contribution of different path lengths for different resources. P (ey|ex, π) is the random walk probability for each path.
The score for each triplet is then deﬁned as:

f (ex, π, ey|θ, F (ex, ey)) = veTxQrvey + vec(F (ex, ey))T vec(Qr) (9)

The ﬁrst term of the scoring function is the same as that of the bilinear model, and the second term takes into account the similarity of the weighted path representation and the predicted relation r. Element-wise product of two matrices is selected as the similarity metric. On top of this framework, [7] propose a dynamic programming method that can learn all paths between two nodes without making any approximations like sampling or pruning, which achieved signiﬁcant improvement over previous methods. The learning method is the same as the single-step, which is to minimize a ranking loss objective.

2.4 Research on Scientiﬁc Literature
There has been growing interest in research on automatic methods to help researchers search and extract useful information from scientiﬁc literature. Past research on this ﬁeld mainly focused on the following aspects. Some research investigated on citation function, for example analyzing citation sentiment, and predicting the reason for whether citing a paper is positive or negative [31, 32]. Some research focused on citation network and community [33, 34], where the main research problems are about exploring key authors in a ﬁeld [35, 36], observation of over-time trends in these networks [37, 38], and detecting scientiﬁc breakthroughs using text content [39]. Research on summarizing scientiﬁc papers has also been extensively explored [40]. However, due to scarce

8

hand-annotated data resources, previous work on information extraction (IE) for scientiﬁc literature is very limited. Gupta and Manning [41] ﬁrst proposed a task that deﬁnes scientiﬁc terms into three aspects: domain, technique and focus and apply template-based bootstrapping to tackle the problem. Based on this study, [42] improve the performance by introducing hand-designed features from named entity recognition [43] to the bootstrapping framework.
For relation extraction in scientiﬁc literature, most work has been done in the biomedical domain under a distant learning framework e.g. using Gene Drug Knowledge Database [44, 8, 45]. The main challenge for relation extraction in scientiﬁc domains is the long context window that the relations can embed in. Relations between scientiﬁc terms cross-sentence can be chained with coreference [46, 47] and discourse relations [8, 45]. However the performance of coreference and discourse parsers is not sufﬁciently accurate on scientiﬁc domains and not so much previous work has been researched. There has been various proposed schema in scientiﬁc discourse analysis such as [48, 49], but mostly on limited hand annotated data.
2.5 Leveraging external resources
The bottleneck of the supervised methods in information extraction is usually the lack of training data. Therefore, leveraging large unlabeled text sources is very important. Previous work has mainly focused on transfer learning [50, 51], multi-task learning [52, 16, 53] or initializing the model with pre-trained word embeddings [54, 55, 56, 57]. Here we especially focus on two ways of leveraging external resources: semi-supervised learning and distant learning. Semi-supervised learning (SSL) uses large scale unlabeled data to improve the performance of a supservised system, while distant learning is method to label unannotated data with the help of database.
2.5.1 Semi-supervised Learning
The earliest SSL algorithms use the Expecatation-Maximization (EM) algorithm. It assumes a model p(x, y) = p(y)p(x|y) where p(x|y) is an identiﬁable mixture distribution, for example Gaussian mixture models. With large amount of unlabeled data, the mixture components can be identiﬁed; only small amount of labeled data per component will be needed to fully determine the mixture distribution. EM based semi-supervised methods have been successfully applied to many applications such as text classiﬁcation [58] and face orientation discrimination [59].
Another common SSL algorithm is self-training [60], where one makes use of a previously trained model to annotate unlabeled data which is then used to re-train the model. Self-training has been successfully applied to several natural language processing tasks such as word sense disambiguation [58], parsing and machine translation [61]. The EM approach can be viewed as a special case of soft self-training. One can imagine that a classiﬁcation mistake can reinforce itself. Some algorithms try to avoid this by ignoring unlabeled points if the prediction conﬁdence is below a threshold.
Graph-based SSL algorithms [62, 63, 64] are an important subclass of semi-supervised techniques that have received much attention in the recent past. Graph-based semi-supervised methods deﬁne a graph where the nodes are represented as the labeled and unlabeled samples in the dataset, and the edges are the similarity between the samples. These methods usually assume neighboring nodes on the graph tend to have similar output (smoothness over the graph). Graph-based methods are non-parametric, discriminative, and transductive in nature. Graph-based methods have also been widely used in NLP applications, but mostly focus on unstructured problems such as text classiﬁ-
9

Computer Science: This paper addresses the tasks of [Named Entity Recognition]Task([NER]Task), a subtask of [information extraction]Task, using [conditional random ﬁelds]Process. Our method is evaluated on the [ConLL NER Corpus]Material. Physics: [Local ﬁeld effects] Process on spontaneous emission rates within [nanostructure photonics material]Material for example are familiar, and have been well used. Material Science: The [Kelvin probe force microscopy technique] Process allows [detection of local EWF]Task between an [atomic force micorscopy]Material and [metal surface]Material.
Figure 4: Annotated ScienceIE examples.
cation [65, 66] and machine translation [67]. Structured NLP problems such as POS tagging and NER tend to be hard to construct the graph, since it is hard to use whole sequence similarity to constrain whole tag sequences assigned to linked examples. Subramanya et. al. [68] construct the graph based on trigram similarity together with some hand-designed features and use graph-based semi-supervised on top of CRF structure to improve POS tagging performance. Following [68], similar methods has also been applied to NER [69] and slot ﬁlling tasks [70].
2.5.2 Distant Learning
Mintz et. al. [71] introduce a new term “distant supervision”. The authors use a large semantic database Freebase containing 7,300 relations between 9 million named entities to annotate a large unlabeled corpus by matching the terms. A relation classiﬁer is extracted on the annotated data. There are two main problems of distant learning: (1) some training examples obtained through this heuristic are not valid, and (2) the same pair of entities can have several relations. Many approaches to on handling the noisy annotation have been explored [72, 73, 27, 74, 75, 76]. Some researchers target the heuristics that are used to map the relations in the databases to the texts, for example, [77] argue that improving matching helps to make data less noisy and therefore enhances the quality of relation extraction in general. Despite the existing problems, distant learning has been applied widely in relation extraction, and provide sufﬁcient training data. Many of the neural based systems are developed with the help of distant learning [78, 45].
3 Initial work
In initial work, we address the problem of extracting keyphrases from scientiﬁc articles and categorizing them as corresponding to a task, process, or material. We cast the problem as a sequence tagging problem and introduce semi-supervised methods to a neural tagging model, which builds on recent advances in named entity recognition. Since annotated training data is scarce in this domain, we introduce a graph-based semi-supervised algorithm together with a data selection scheme to leverage unannotated articles. Both inductive and transductive semi-supervised learning strategies outperform state-of-the-art information extraction performance on the 2017 SemEval Task 10 ScienceIE task.
10

3.1 ScienceIE Dataset
Very recently a new challenge on Scientiﬁc Information Extraction (SemEval Task 10 SCIENCEIE) [79] provides a dataset consisting of 500 scientiﬁc paragraphs with keyphrase annotations for three categories: TASK, PROCESS, MATERIAL across three scientiﬁc domains, Computer Science (CS), Material Science (MS), and Physics (Phy), as in Figure 3. This dataset enables the use of more advanced approaches such as neural network (NN) models [79]. Identifying keyphrases is a very challenging subtask, since the dataset contains many long and infrequent keyphrases.
In addition to keyphrase extraction, the ScienceIE also extracts semantic relations between keywords, including two types of relations: HYPONYM-OF and SYNONYM-OF. For example, in the ﬁrst row of Figure 3, Named Engity Recognition is a SYNONYM-OF of NER, while information extraction is HYPONYM-OF of both Named Engity Recognition and NER. The relation extraction task of ScienceIE is not studied in initial work, but will be used for evaluating entity linking performance in Sec. 4.3
The ScienceIE corpus consists of 500 journal articles; one paragraph of each article is randomly selected and annotated. The complete unlabeled articles and their metadata are provided together with the labeled data. The training data consists of 350 documents; 50 are kept for development and 100 for testing. The 500 articles come from 82 different journals evenly distributed in three domains. We manually labeled 82 journal names in the dataset into the three domains and do analysis based on the domain partitions. The 500 full articles contains 2M words and is 30 times the size of the annotated data.
3.2 Neural Model and Semi-supervised Learning
We adopt the 3-layer LSTM-CRF neural model [15] as in Fig. 1 described in Sec. 2.1.1 to tag scientiﬁc terms. We extend the token representation layer to be a concatenation of three components for each token:a bi-directional character-based embedding, a word embedding, and an embedding associated with orthographic and part-of-speech features.
We develop a semi-supervised algorithm that extends self-training by estimating the labels of unlabeled data and then using those labels for re-training. Speciﬁcally, we use a graph-based algorithm to estimate the posterior probabilities of unlabeled data and develop a new CRF training to take the uncertainty of the estimated labels into account while optimizing the objective function.
3.2.1 Graph-based Posterior Estimates
Our semi-supervised algorithm uses the following steps to estimate the posterior. It ﬁrst constructs a graph of tokens based on their semantic similarity, then uses the CRF marginal as a regularization term to do label propagation on the graph. The smoothed posterior is then used to either interpolate with the CRF marginal or as an additional feature to the neural network.
Graph Construction Vertices in the graph correspond to tokens, and edges are distance between token features which capture semantic similarity. The total size of the graph is equal to the number of tokens in both labeled data Vl and unlabeled data Vu. The tokens are modelled with a concatenation of pre-trained word embeddings (with dimension d) of 5-gram centered by the current token, the word embedding of the closest verb, and a set of discrete features including part-of-speech tags
11

and capitalization (43 and 4 dimension one-hot features). The resulting feature vector with dimen-
sion of 5d + d + 43 + 4 is then projected down to 100 dimensions using PCA. We deﬁne the weight
wuv of the edge between nodes u and v as follows: wuv = de(u, v) if v ∈ K(u) or u ∈ K(v), where K(u) is the set of k-nearest neighbors of u and de(u, v) is the Euclidean distance between any two nodes u and v in the graph.
For every node i in the graph, we compute the marginal probabilities {qi} using the forwardbackward algorithm. Let θi represent the estimate of the CRF parameters after the n-th iteration, we compute the marginal probabilities p˜(j,t) = p(ytj|x; θi) over IOB tags for every token position t in sentence j in labeled and unlabeled data.

Label Propagation We use prior-regularized measure propagation [80, 81] to propagate labels from the annotated data to their neighbors in the graph. The algorithm aims for the label distribution between neighboring nodes to be as similar to each other as possible by optimizing an objective function that minimizes the Kullback-Leibler distances between: i) the empirical distribution ru of labeled data and the predicted label distribution qu for all labeled nodes in the graph; ii) the distributions qu and qv for all nodes u in the graph and their neighbors v; iii) the distributions qu and the CRF marginals p˜u for all nodes. The third term regularizes the predicted distribution toward the CRF prediction if the node is not connected to a labeled vertex, ensuring the algorithm performs at least as well as standard self-training.

Posterior Estimates We develop two strategies to estimate the new posteriors pˆ(yt|x; θ), which can then be used in the CRF training.
The ﬁrst strategy (called GRAPHINTERP) is the commonly used approach [68, 82] that interpolates the smoothed posterior {q} with CRF marginals p:

pˆ(yt|x; θ) = αp(yt|x; θ) + (1 − α)q(y)

(10)

where α is a mixing coefﬁcient.
The second strategy (called GRAPHFEAT) uses the smoothed posterior {q} as features and
learns it with other parameters in the neural network. Given a sentence {x1, . . . , xn}, let Q = {q1, . . . , qn} be the predicted label distribution from the graph. We then use Q as a feature input to neural network as P˜ = P + M Q where P is the n × m matrix output by the bidirectional LSTM
network as in Eq. 2, and M is m × m matrix and is learned together with other parameters of neural network. We modify Eq. 2 by replacing Pt,yt with P˜t,yt. Note that GRAPHFEAT can only be done in a transductive way since it requires output Q from the graph at test time.

3.2.2 CRF training with Uncertain Labels
A standard approach to self-training is to make hard decisions for labeling tokens based on the estimated posteriors and retrain the model. However, the estimated posteriors in our task are noisy due to the difﬁculty and variety of the ScienceIE task. Instead, we extend the CRF training to leverage the conﬁdence of the estimated posteriors. The new CRF training (called Uncertain Label Marginalizing (ULM)) treats low conﬁdence tokens as missing labels and computes the sentencelevel score by marginalizing over them. A similar idea has been previously used in treating partially labeled data [83].

12

Figure 5: Lattice representation of ULM. Dashed box is the uncertain token which is going to be marginalized over.

Speciﬁcally, given a sentence x we deﬁne a constrained lattice Y(x), where at each position t the allowed label types Y(xt) are:

Y(xt) = {yt}, if p(yt|x; θ) > η (11) All label types, otherwise

where η is the conﬁdence threshold, yt is the prediction of posterior decoding and p(yt|x; θ) is its CRF token marginal. The new neural network parameters θ are estimated by maximizing the log-likelihood of pθ(Y(xk)|xk) for every input sentence xk, where

pθ(Y(xk)|xk) =

yk∈Y(xk) exp(φ(yk; xk, θ)) y ∈ym exp(φ(y ; x, θ))

where yk is an instance sequence of lattice Y(x), and k is the sentence index in the training set. Extreme cases are when all tokens are uncertain then the likelihood would be equal to 1, when all tokens of a sequence are conﬁdent, it would be equal to Eq. 3 where only one possible sequence, as in Fig. 5.

Inductive and Transductive Learning The semi-supervised training process is summarized as follow: It ﬁrst computes marginals over the unlabeled data given a set of CRF parameters. It then uses the marginals as a regularization term for label propagation. The smoothed posteriors from the graph are then interpolated with the CRF marginal in GRAPHINTERP or used as an additional feature in GRAPHFEAT. It then uses the estimated labels for the unlabeled data combined with the labeled data to retrain the CRF using either the hard decision CRF training objective as Eq. 3 or the ULM data selection objective.
In the inductive setting, we only use the unlabeled data from the development set for the semisupervision, while in the transductive setting we need to use the unlabeled data of the test set to construct graph. In both cases, the parameters are tuned only on the dev set.

3.3 Experimental Results
We evaluate our NN-CRF model in both supervised and semi-supervised settings on ScienceIE dataset. We also perform ablations and try different variants to best understand our model. Results are reported in [84].
Table 1 reports the results of our neural sequence tagging model NN-CRF in both supervised and semi-supervised learning (ULM and graph-based), and compares them with the baselines and the

13

Span Level
Gupta et.al.(unsupervised) Tsai et.al. (unsupervised) Best Non-Neural SemEval+ Best Neural SemEval+ NN-CRF(supervised) NN-CRF(semi) NN-CRF(semi)∗

Identiﬁcation
9.8 11.9 38 44 40.2 45.3 46.6

Classiﬁcation
6.4 8.0 51 56 52.1 56.9 57.6

Table 1: Overall span-level F1 results for keyphrase identiﬁcation (SemEval Subtask A) and classiﬁcation (SemEval Subtask B). ∗ indicates tranductive setting. + indicates not described in [79] whether transductive
or inductive.

Posterior

Training Dev Test

GRAPHINTERP GRAPHINTERP GRAPHINTERP* GRAPHINTERP* GRAPHFEAT* GRAPHFEAT*

ULM ULM ULM ULM

50.2 42.9 51.3 44.4 50.9 43.3 51.9 45.3 50.7 44.0 51.8 45.7 51.4 44.9 52.1 46.6

Table 2: F1 scores of semi-supervised Learning approaches; * shows transductive models.

state-of-the-art (best SemEval System [79]). We report results for both span identiﬁcation (SemEval SubTask A) and span classiﬁcation into TASK, PROCESS and MATERIAL (SemEval Subtask B). The results show that our neural sequence tagging models signiﬁcantly outperforms the state of the art and both baselines. It conﬁrms that our neural tagging model outperforms other non-neural and neural models for the SemEval ScienceIE challenge.4 It further shows that our system achieves signiﬁcant boost from semi-supervised learning using unlabeled data.
Table 2 reports the results of the semi-supervised learning algorithms in different settings. In particular we ablate incorporating the graph-based methods of computing the posterior and CRF training (ULM vs. hard decision). The table shows incorporating graph-based methods for computing posterior and ULM for CRF training outperforms their counterparts.
The transductive approaches consistently outperform inductive approaches on the test set. With around the same performance on dev set, GRAPHINTERP* seems to generalize better on test set with 1.6% relative improvement over GRAPHINTERP. We observe higher improvement with GRAPHFEAT* compared to GRAPHINTERP. This is mainly because automatically learning the weight matrix M between neural network scores and graph outputs adds more ﬂexibility compared to tuning an interpolation weight α.
The performance is further improved by applying data selection through modifying the objective to ULM. The best inductive system is ULM+GRAPHINTERP with 5.6% relative improvement over pure self-training that makes hard decisions, and the best transductive system is ULM+GRAPHFEAT* with 8.6% relative improvement.
4Best SemEval Numbers from https://scienceie.github.io/

14

[Discriminative Word Alignment]FDoocmuasin via [Alignment Matrix]FToecchuns ique modelling. In this paper a new [discriminative Word Alignment]FToecchunsique method is presented. This approach models directly the [alignment matrix]Technique by the [conditional random ﬁeld]Technique ([CRF]Technique) and so no restrictions to the alignments have to be made.
Figure 6: Annotated Focus, Domain, Technique examples from GM-ANN dataset [41].
4 Research Plan
4.1 Overview
We focus on building a structured knowledge graph that can show the relation between scientiﬁc terms and make recommendations based on user’s query. For example, Generative Adversarial Networks (GAN) has been ﬁrst introduced in machine learning communities in 2014, and reaches its peaks in 2015, yet is not applied in the NLP ﬁeld until 2017. NLP researchers may want to know the possible NLP applications of GAN, which could be inferred from relational learning of a scientiﬁc knowledge graph. Therefore, the goal of our research is to make scientiﬁc recommendations using more existing information and minimizing human annotation effort. We utilize semisupervision, co-occurrence and signals from external resources to improve our system performance. The roadmap is as follows:
• Entity Extraction and Linking: Extract scientiﬁc terms from scientiﬁc articles and merge synonymous expressions of scientiﬁc terms.
• Knowledge Graph Construction: Build a relational knowledge graph on a scientiﬁc domain without extensive human annotation effort.
• Scientiﬁc Recommendation: Recommend the applications for a scientiﬁc method or recommend the methods that can solve a scientiﬁc application. This serves as an evaluation of the graph.
4.2 Data and Other Resources
In addition to the ScienceIE data described in Sec. 3.1, we choose AI as a broad area of focus because our expertise can make it easier to analyze the results. We collect papers from several major AI communities to conduct the experiments.
4.2.1 ACL Anthology Network (AAN) Dataset
The ACL Anthology Network (AAN) Dataset [85, 86] provides citation and collaboration networks of the articles included in the ACL Anthology, which consists of 23766 papers from 1965 to 2013. All papers in AAN are parsed by Parscit [87], which parses scientiﬁc documents [88] into the following logical structures: abstract , categories, general terms, keywords, introduction, background, related work, methodology, evaluation, discussion, conclusions, acknowledgments.
Based on AAN, Gupta and Manning [41] ﬁrst proposed a task that deﬁnes scientiﬁc terms into three aspects: domain, technique and focus and hand-labeled 474 titles and abstracts in AAN with the three categories to measure the token-level precision and recall scores. Fig. 6 shows an example of the annotation. We refer to the dataset as GM-ANN dataset.
15

Communities Venues Paper #

Machine Learning NIPS ICML 6987 3078

NLP ANN 23766

Speech

ICASSP Interspeech

16576

8352

CVPR 6615

Vision ICCV 2839

ECCV 2227

General AI AAAI IJCAI 4416 4799

Table 3: Statistics of venues we collect from both AI2 dataset and ACL anthology.

Figure 7: An example of Wikipedia page for term Conditional Random Field
4.2.2 AI2 dataset
In order to have a broader coverage of research communities, we use the AI2 SemanticScholar Open Resource Corpus5 which has over 7 million published research papers in Computer Science and Neuroscience. We search through the corpus and collect conference proceedings from the following communities: (1) Machine Learning: NIPS and ICML (2) Speech: Interspeech and ICASSP, (3) Vision: CVPR, ICCV and ECCV (4) General AI: AAAI and IJCAI. The statistics of the datasets are in Table 3.
The AI2 dataset has the information of paper title, paper abstract, author, inCitations, outCitations, venue and year. Even though the text of the full paper is not provided, the paper abstract and title are useful for our work.
4.2.3 Wikipedia
Wikipedia includes a large collection of structural articles with the introduction of terms, where information about the term is categorized into sections with speciﬁc section titles. Moreover, hyperlinks of the phrases that are used to describe the term are provided, which means the keyphrase
5http://labs.semanticscholar.org/corpus/
16

Figure 8: The description section of Wikipedia page for term Part-of-speech tagging
boundary can be identiﬁed by the hyperlink. If the phrase existed in Wikipedia, a connection can be built through the hyperlink between the two terms. Furthermore, the structural nature of Wikipedia provides a good resource of relations between scientiﬁc terms. Fig. 7 provides an example of the Wikipedia page of term Conditional Random Field, where there are two sections: Variants and Software. The terms under Variants that are highlighted with bold fonts or hyperlinks are mostly the related methods such as structure prediction, support vector machine and latent variable models. The terms under Software are all tools that can implement a CRF. In this way, we can extract relation triplets such as (support vector machine, software, Conditional Random Field) and (RNNSharp, Variant, Conditional Random Field). The scientiﬁc terms can therefore connect to each other through the links and the contexts.
4.3 Entity Extraction and Linking
All unannotated papers will be tagged by the extractor in Sec. 3 trained using the ScienceIE and the GM-AAN dataset. The scientiﬁc terms extracted are classiﬁed into Task and Method.
Once the terms are extracted, since there are different expressions for the same scientiﬁc term, we need to link them to the same node in the knowledge graph. For example, part-of-speech tagging can be called as POS tagging, PoS tagging or POST. If part-of-speech tagging is used as a tool to solve other problems, it is also called as part-of-speech tagger.
Unlike general entity linking problems (such as linking human names) which have greater variation between entity mentions [89, 90], spelling variants and acronyms play the central role in disambiguating the scientiﬁc terms. We will apply knowledge-driven feature extraction with simple classiﬁer and rules and use the ScienceIE synonym relations for evaluation.
4.4 Knowledge Graph Construction
In order to minimize the effort for human annotation, we aim at exploring relational signals embedded in the text such as co-occurrence and dependency relations, as well as relational signals from external resources such as Wikipedia. We ﬁrst construct a knowledge graph using a set of ﬁxed relation types obtained from term co-occurrence, then add auxiliary relations to improve the graph. We also propose possible ways of modeling open relations through latent representations.
4.4.1 Relational Learning through Term Co-occurrence
Two scientiﬁc terms can be assumed to be related if they co-occur in a context window (sentence, paragraph, section or document). For example, as in Figure 6, the term Alignment Matrix is an
17

approach to solve the problem of Discriminative Word Alignment. The two terms appears in the same sentence multiple times which is a strong indicator for them to be related to each other.
A traditional way of getting the relation category is to train a relation extractor which can classify relation of any two terms into predeﬁned type of relations through context. Since we do not have annotation for the relation extractor, we use the entity types together with occurrence to infer relations. The entity extractor outputs the keyword boundary as well as their categories: each keyword is marked as Task and Method. If a term is labeled as Task, and another term in the same context window labeled as Method, we can assume that the two terms are Task-Method relation (the second term is a method used to solve the ﬁrst term), such as Discriminative Word Alignment and Alignment Matrix in Fig. 6.
Based on the keyword categories, we deﬁne three broad relation types: Task-Task which indicates the two scientiﬁc terms are related tasks, Task-Method which indicates that one term is a task that can be solve by the other, Method-Method which indicates the two terms are related methods. We can then extract relation triplets from term co-occurrence, such as {Discriminative Word Alignment, Task-Method, Alignment Matrix} in the example above. Since the output of term extracter is noisy, we can reduce noise by ﬁltering out the low conﬁdent terms.
We follow previous work on knowledge graph inference in [25] as described in Sec. 2.3.1, and use bilinear transformation (Eq. 4) as our scoring function. The model will be trained by minimizing the ranking loss (Eq. 5) of all triplets extracted from co-occurrence. Note that even though the triplets extracted from co-occurrence are noisy, the objective can naturally put more weight on the more frequent triplets and learn parameters accordingly.
4.4.2 Leveraging Auxiliary Relations
In order to reduce the noise from automatic annotation by co-occurrence, we will use auxiliary relations from dependency paths between the scientiﬁc terms as in many previous studies[27, 7]. In addition, we will also introduce structural external resources such as Wikipedia to augment the graph.
Dependency Paths Syntactic structure provides an important clue for modeling relations, and many state-of-the-art systems use dependency relation as an auxiliary information for KB completion [27, 7]. In scientiﬁc literature, related terms are usually embedded across sentences. Take the second and the third sentence in Fig. 6 as an example, discriminative Word Alignment is connected to alignment matrix through the coreference indicator This approach. Therefore it is very important to consider contexts beyond sentence boundaries when using dependency paths to augment the graph. Following [45], we will incorporate both intra-sentential and inter-sentential dependencies, such as sequential, syntactic, coreference and discourse relations as auxiliary relations using the tool of [45].
Wikipedia The internal links between Wikipedia page formulate a graph connecting scientiﬁc terms. Moreover, the section where the link appears in is a strong indicator for the relation between scientiﬁc terms. For example, the term latent variable models appears under Variants section of the Wikipedia page Conditional Random Field in Figure 7, latent variable models and Conditional Random Field are likely to be similar methods that have many common applications. We will use a set of heuristics to deﬁne a set of categories on the major section names of Wikipedia, such as
18

Figure 9: Wikipedia graph: The arrow starts from the Wikipedia page where the relation triplet is extracted. The arrow points to the scientiﬁc term that appears in the page. The section that the term appears in is shown by the arch caption.
Description, Extension, Example, Application, Models and Methods, Tools, Approach, See also and so on. If a term appears on another term’s Wikipedia page under the section of Application, the two terms are likely to be Method-Task relation. The section names can help distinguish the relation, either explicitly (such as Application and Models and Methods), or implicitly (such as See also and Extension). An example of a Wikipedia-derived graph is shown in Fig. 9.
Figure 10 is an example of a graph with auxiliary relations from different resources. As shown in the ﬁgure, some auxiliary relations connects two scientiﬁc terms through multiple nodes (for example the dependency relations). Many previous studies showed that multiple-step relation paths also contain rich inference patterns between entities, and yield signiﬁcant gains in embedding models for knowledge base completion tasks [29, 28, 7]. Therefore, it is necessary to model multiple-step relation paths through compositional methods.
In order to model multiple-step relation paths, we follow the the approach of [7] as described in Sec. 2.3.2. We redeﬁne the relation matrix Qr in Eq. 4 as Q(rk), which means the r-th relation type on the k-th auxiliary resource of knowledge. For each type of resource k, we extract relation triplets between two scientiﬁc terms {ex, π(k), ey}, where π(k) is the path between the two terms which may consists of multiple steps. We take into account embeddings of relation paths between the two terms, and use vector space compositions to combine the embeddings of individual relation links ri into an embedding of the path π(k). The intermediate nodes ei are neglected.
We calculate the scoring function in Eq. 7 for path π(k) from each auxiliary resource k:
φ(π(k)) = Q(rk1) . . . Q(rkn) (12)
19

Figure 10: Graph with auxiliary relations from different resources: Yellow arches are relations from Wikipedia sections; Grey arches are dependency relations extracted from text where the two terms co-occur. Black arches are scientiﬁc aspect relations (the main relation we focus on).
The weighted path representation will be
F (ex, ey, r) = w|(πk|)P (ey|ex, π(k))φ(π(k)), (13)
k π(k)
where w|(πk|) is a shared parameter for paths of each length for each resource type k, so that the model may learn to trust the contribution of different path lengths for different resources. P (ey|ex, π(k)) is the random walk probability for each path. We use the same scoring function as Eq. 9 and objective function as Eq. 5. We hope through multi-path modeling of multiple resources, the auxiliary relations would improve the performance of scientiﬁc recommendation.
4.4.3 Extension to open relation learning
In the proposed method above, we only deﬁne three broad target relations for recommendations, which is not enough to satisfy all users’ query. Some more ﬁne-grained relations that are under the three broad relations may be more useful. For example, two related methods can both be applied to solve one task, and their performance is usually compared, such as Logistic Regression and SVM. On the other hand, one method may be combined with another method to solve a task, such as HMM and Viterbi Decoding. Similarly, two tasks can be hypernyms such as IE and NER, some tasks can be similar problems that can involve the same methods, such as POS tagging and NER.
Even though we do not have any annotation for those relations, we can learn latent representations through clustering the representations, e.g. the weighted path representation in Eq. 13. It can
20

Figure 11: Link Prediction for scientiﬁc terms. The relation between GAN and Response Generation can be inferred from the graph with a ranking score.
also be obtained from matrix or tensor based low rank factorization. For analysis, we can choose some examples around the cluster centroid and use a small amount of human effort to label the relation each cluster represents.
4.5 Scientiﬁc Recommendation
Our system will be applied to recommend related tasks or methods to a new scientiﬁc term. For example, since GAN is a new technique that has not been widely used in NLP ﬁeld until 2017, we can set our task as predicting the possible applications of GAN in NLP ﬁeld as Fig. 11. The problem is similar to link prediction [7] and knowledge base completion, and [91] can be formulated as a ranking problem where the score between GAN and all other scientiﬁc terms with the relation of Method-Task are calculated and ranked in descending order.
For automatic evaluation, we will hold out all publications about a set of new methods such as GAN in ACL anthology as test set, all publication in ACL anthology 2016 as dev set and use all AI publications (NIPs, CVPR, ACL, etc.) prior to 2016 as a training set to build the knowledge graph. The predicted GAN applications are compared with the GAN papers in 2017, where ground truth ranking is calculated by the number of papers the term appears. The system performance can thus be evaluated by Mean Reciprocal Rank (MRR) or Hits at k.
The automatic evaluation has the limitation that there may be some applications that are indeed good applications for GAN, but have not been published yet. Therefore, in addition to automatic evaluation, we introduce human evaluation. Inspired by TREC competitions [92] and [27], we treat the set of new methods (or tasks) as query and receive the top 30 candidate scientiﬁc terms from each system and manually judge their relevance. This gives a set of relevant results that we can use
21

to calculate recall and precision measures.
5 Conclusion
In summary, we propose a framework that can make scientiﬁc recommendations using minimum effort of human annotation. The anticipated contributions of this thesis work can be summarized as follows. First, we obtained state-of-the-art performance on scientiﬁc term extraction by leveraging a large amount of unannotated papers through applying multiple semi-supervised approaches. Secondly, we construct a scientiﬁc knowledge graph by combining relational signals embedded in the text such as co-occurrence with auxiliary relations from dependency relations or Wikipedia. We also explore possible ways of representing open relations through clustering latent relational representations. Finally, we propose downstream scientiﬁc recommendation tasks that will be of interest to many researchers. Evaluation schemes which can minimize annotation efforts are also proposed. Our approaches to minimize annotation efforts can be generalized to other domains and may provide new solutions to problems in machine reading.
References
[1] Yi Luan, Mari Ostendorf, and Hannaneh Hajishirzi, “The UWNLP system at semeval-2018 task 7: Neural relation extraction model with selectively incorporated concept embeddings,” in Proc. Int. Workshop on Semantic Evaluation (SemEval), 2018, pp. 788–792.
[2] Yi Luan, Luheng He, Mari Ostendorf, and Hannaneh Hajishirzi, “Multi-task identiﬁcation of entities, relations, and coreference for scientiﬁc knowledge graph construction,” in Proc. Conf. Empirical Methods Natural Language Process. (EMNLP), 2018.
[3] Ben Hixon, Peter Clark, and Hannaneh Hajishirzi, “Learning knowledge graphs for question answering through conversational dialog.,” in HLT-NAACL, 2015, pp. 851–861.
[4] David L Waltz, “An english language question answering system for a large relational database,” Communications of the ACM, vol. 21, no. 7, pp. 526–539, 1978.
[5] Franc¸ois Belleau, Marc-Alexandre Nolin, Nicole Tourigny, Philippe Rigault, and Jean Morissette, “Bio2rdf: towards a mashup to build bioinformatics knowledge systems,” Journal of biomedical informatics, vol. 41, no. 5, pp. 706–716, 2008.
[6] Alan Ruttenberg, Jonathan A Rees, Matthias Samwald, and M Scott Marshall, “Life sciences on the semantic web: the neurocommons and beyond,” Brieﬁngs in bioinformatics, vol. 10, no. 2, pp. 193–204, 2009.
[7] Kristina Toutanova, Xi Victoria Lin, Wen-tau Yih, Hoifung Poon, and Chris Quirk, “Compositional learning of embeddings for relation paths in knowledge bases and text,” in Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, 2016, vol. 1, pp. 1434–1444.
[8] Chris Quirk and Hoifung Poon, “Distant supervision for relation extraction beyond the sentence boundary,” arXiv preprint arXiv:1609.04873, 2016.
22

[9] Oren Etzioni, Michele Banko, Stephen Soderland, and Daniel S Weld, “Open information extraction from the web,” Communications of the ACM, vol. 51, no. 12, pp. 68–74, 2008.
[10] Ronan Collobert, Jason Weston, Le´on Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa, “Natural language processing (almost) from scratch,” Journal of Machine Learning Research, vol. 12, no. Aug, pp. 2493–2537, 2011.
[11] Sujan Kumar Saha, Sudeshna Sarkar, and Pabitra Mitra, “Gazetteer preparation for named entity recognition in indian languages.,” in IJCNLp, 2008, pp. 9–16.
[12] Burr Settles, “Biomedical named entity recognition using conditional random ﬁelds and rich feature sets,” in Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications. Association for Computational Linguistics, 2004, pp. 104–107.
[13] Yi Luan, Yangfeng Ji, and Mari Ostendorf, “LSTM based conversation models,” in arXiv preprint arXiv:1603.09457, 2016.
[14] Yi Luan, Shinji Watanabe, and Bret Harsham, “Efﬁcient learning for spoken language understanding tasks with word embedding based pre-training,” in Proc. Conf. Int. Speech Communication Assoc. (INTERSPEECH). Citeseer, 2015, pp. 1398–1402.
[15] Guillaume Lample, Miguel Ballesteros, Sandeep Subramanian, Kazuya Kawakami, and Chris Dyer, “Neural architectures for named entity recognition,” arXiv preprint arXiv:1603.01360, 2016.
[16] Nanyun Peng and Mark Dredze, “Named entity recognition for chinese social media with jointly trained embeddings.,” in EMNLP, 2015, pp. 548–554.
[17] John Lafferty, Andrew McCallum, Fernando Pereira, et al., “Conditional random ﬁelds: Probabilistic models for segmenting and labeling sequence data,” in Proceedings of the eighteenth international conference on machine learning, ICML, 2001, vol. 1, pp. 282–289.
[18] Zhiheng Huang, Wei Xu, and Kai Yu, “Bidirectional lstm-crf models for sequence tagging,” arXiv preprint arXiv:1508.01991, 2015.
[19] Sepp Hochreiter and Ju¨rgen Schmidhuber, “Long short-term memory,” Neural computation, vol. 9, no. 8, pp. 1735–1780, 1997.
[20] Jason PC Chiu and Eric Nichols, “Named entity recognition with bidirectional lstm-cnns,” arXiv preprint arXiv:1511.08308, 2015.
[21] Miguel Ballesteros, Chris Dyer, and Noah A Smith, “Improved transition-based parsing by modeling characters instead of words with lstms,” arXiv preprint arXiv:1508.00657, 2015.
[22] Xuezhe Ma and Eduard Hovy, “End-to-end sequence labeling via bi-directional lstm-cnnscrf,” arXiv preprint arXiv:1603.01354, 2016.
[23] Oren Etzioni, Michael Cafarella, Doug Downey, Ana-Maria Popescu, Tal Shaked, Stephen Soderland, Daniel S Weld, and Alexander Yates, “Unsupervised named-entity extraction from the web: An experimental study,” Artiﬁcial intelligence, vol. 165, no. 1, pp. 91–134, 2005.
23

[24] Michele Banko, Michael J Cafarella, Stephen Soderland, Matthew Broadhead, and Oren Etzioni, “Open information extraction from the web.,” in IJCAI, 2007, vol. 7, pp. 2670–2676.
[25] Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng, “Embedding entities and relations for learning and inference in knowledge bases,” arXiv preprint arXiv:1412.6575, 2014.
[26] Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel, “A three-way model for collective learning on multi-relational data,” in Proceedings of the 28th international conference on machine learning (ICML-11), 2011, pp. 809–816.
[27] Sebastian Riedel, Limin Yao, Andrew McCallum, and Benjamin M Marlin, “Relation extraction with matrix factorization and universal schemas,” 2010.
[28] Kelvin Guu, John Miller, and Percy Liang, “Traversing knowledge graphs in vector space,” arXiv preprint arXiv:1506.01094, 2015.
[29] Yankai Lin, Zhiyuan Liu, Huanbo Luan, Maosong Sun, Siwei Rao, and Song Liu, “Modeling relation paths for representation learning of knowledge bases,” arXiv preprint arXiv:1506.00379, 2015.
[30] Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne van den Berg, Ivan Titov, and Max Welling, “Modeling relational data with graph convolutional networks,” arXiv preprint arXiv:1703.06103, 2017.
[31] Awais Athar and Simone Teufel, “Detection of implicit citations for sentiment detection,” in Proceedings of the Workshop on Detecting Structure in Scholarly Discourse. Association for Computational Linguistics, 2012, pp. 18–26.
[32] Awais Athar and Simone Teufel, “Context-enhanced citation sentiment detection,” in Proceedings of the 2012 conference of the North American chapter of the Association for Computational Linguistics: Human language technologies. Association for Computational Linguistics, 2012, pp. 597–601.
[33] Huy Hoang Nhat Do, Muthu Kumar Chandrasekaran, Philip S Cho, and Min Yen Kan, “Extracting and matching authors and afﬁliations in scholarly documents,” in Proceedings of the 13th ACM/IEEE-CS joint conference on Digital libraries. ACM, 2013, pp. 219–228.
[34] Kokil Jaidka, Muthu Kumar Chandrasekaran, Beatriz Fisas Elizalde, Rahul Jha, Christopher Jones, Min-Yen Kan, Ankur Khanna, Diego Molla-Aliod, Dragomir R Radev, Francesco Ronzano, et al., “The computational linguistics summarization pilot task,” Proceedings of TAC, 2014.
[35] Miray Kas, “Structures and statistics of citation networks,” Tech. Rep., DTIC Document, 2011.
[36] Yanchuan Sim, Noah A Smith, and David A Smith, “Discovering factions in the computational linguistics community,” in Proceedings of the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries. Association for Computational Linguistics, 2012, pp. 22–32.
24

[37] Adam Vogel and Dan Jurafsky, “He said, she said: Gender in the acl anthology,” in Proceedings of the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries. Association for Computational Linguistics, 2012, pp. 33–41.
[38] Vinodkumar Prabhakaran, William L Hamilton, Daniel A McFarland, and Dan Jurafsky, “Predicting the rise and fall of scientiﬁc topics from trends in their rhetorical framing.,” in ACL (1), 2016.
[39] Ashton Anderson, Dan McFarland, and Dan Jurafsky, “Towards a computational history of the acl: 1980-2008,” in Proceedings of the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries. Association for Computational Linguistics, 2012, pp. 13–21.
[40] Amjad Abu-Jbara and Dragomir Radev, “Coherent citation-based summarization of scientiﬁc papers,” in Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1. Association for Computational Linguistics, 2011, pp. 500–509.
[41] Sonal Gupta and Christopher D Manning, “Analyzing the dynamics of research by extracting key aspects of scientiﬁc papers.,” in IJCNLP, 2011, pp. 1–9.
[42] Chen-Tse Tsai, Gourab Kundu, and Dan Roth, “Concept-based analysis of scientiﬁc literature,” in Proceedings of the 22nd ACM international conference on Conference on information & knowledge management. ACM, 2013, pp. 1733–1738.
[43] Michael Collins and Yoram Singer, “Unsupervised models for named entity classiﬁcation,” in Proceedings of the joint SIGDAT conference on empirical methods in natural language processing and very large corpora. Citeseer, 1999, pp. 100–110.
[44] Rodrigo Dienstmann, In Sock Jang, Brian Bot, Stephen Friend, and Justin Guinney, “Database of genomic biomarkers for cancer drugs and clinical targetability in solid tumors,” Cancer discovery, vol. 5, no. 2, pp. 118–123, 2015.
[45] Nanyun Peng, Hoifung Poon, Chris Quirk, Kristina Toutanova, and Wen-tau Yih, “Crosssentence n-ary relation extraction with graph lstms,” Transactions of the Association for Computational Linguistics, vol. 5, pp. 101–115, 2017.
[46] Matthew Gerber and Joyce Y Chai, “Beyond nombank: A study of implicit arguments for nominal predicates,” in Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, 2010, pp. 1583–1592.
[47] Katsumasa Yoshikawa, Sebastian Riedel, Tsutomu Hirao, Masayuki Asahara, and Yuji Matsumoto, “Coreference based event-argument relation extraction on biomedical text,” Journal of Biomedical Semantics, vol. 2, no. 5, pp. S6, 2011.
[48] Simone Teufel and Marc Moens, “Summarizing scientiﬁc articles: experiments with relevance and rhetorical status,” Computational linguistics, vol. 28, no. 4, pp. 409–445, 2002.
[49] Anita de Waard and Henk Pander Maat, “Verb form indicates discourse segment type in biological research papers: Experimental evidence,” Journal of English for academic purposes, vol. 11, no. 4, pp. 357–366, 2012.
25

[50] Andrew M Dai and Quoc V Le, “Semi-supervised sequence learning,” in Advances in Neural Information Processing Systems, 2015, pp. 3079–3087.
[51] Yi Luan, Daisuke Saito, Yosuke Kashiwagi, Nobuaki Minematsu, and Keikichi Hirose, “Semisupervised noise dictionary adaptation for exemplar-based noise robust speech recognition,” in Proc. Int. Conf. Acoustic, Speech, and Signal Process. (ICASSP). IEEE, 2014, pp. 1745–1748.
[52] Ronan Collobert and Jason Weston, “A uniﬁed architecture for natural language processing: Deep neural networks with multitask learning,” in Proceedings of the 25th international conference on Machine learning. ACM, 2008, pp. 160–167.
[53] Yi Luan, Chris Brockett, Bill Dolan, Jianfeng Gao, and Michel Galley, “Multi-task learning for speaker-role adaptation in neural conversation models.,” in Proc. Int. Joint Conf. on Natural Language Processing (IJCNLP), 2017.
[54] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean, “Efﬁcient estimation of word representations in vector space,” arXiv preprint arXiv:1301.3781, 2013.
[55] Jeffrey Pennington, Richard Socher, and Christopher D Manning, “Glove: Global vectors for word representation.,” in EMNLP, 2014, vol. 14, pp. 1532–1543.
[56] Omer Levy and Yoav Goldberg, “Dependency-based word embeddings.,” in ACL (2). Citeseer, 2014, pp. 302–308.
[57] Yi Luan, Yangfeng Ji, Hannaneh Hajishirzi, and Boyang Li, “Multiplicative representations for unsupervised semantic role induction,” in Proc. Annu. Meeting Assoc. for Computational Linguistics (ACL), 2016, p. 118.
[58] Kamal Nigam, Andrew Kachites McCallum, Sebastian Thrun, and Tom Mitchell, “Text classiﬁcation from labeled and unlabeled documents using em,” Machine learning, vol. 39, no. 2, pp. 103–134, 2000.
[59] Shumeet Baluja, “Probabilistic modeling for face orientation discrimination: Learning from labeled and unlabeled data,” in NIPS, 1998, pp. 854–860.
[60] H Scudder, “Probability of error of some adaptive pattern-recognition machines,” IEEE Transactions on Information Theory, vol. 11, no. 3, pp. 363–371, 1965.
[61] Ellen Riloff, Janyce Wiebe, and Theresa Wilson, “Learning subjective nouns using extraction pattern bootstrapping,” in Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003-Volume 4. Association for Computational Linguistics, 2003, pp. 25–32.
[62] Xiaojin Zhu, Zoubin Ghahramani, and John D Lafferty, “Semi-supervised learning using gaussian ﬁelds and harmonic functions,” in Proceedings of the 20th International conference on Machine learning (ICML-03), 2003, pp. 912–919.
[63] Adrian Corduneanu and Tommi Jaakkola, “On information regularization,” in Proceedings of the Nineteenth conference on Uncertainty in Artiﬁcial Intelligence. Morgan Kaufmann Publishers Inc., 2002, pp. 151–158.
26

[64] Amarnag Subramanya and Jeff A Bilmes, “Entropic graph regularization in non-parametric semi-supervised classiﬁcation,” in Advances in Neural Information Processing Systems, 2009, pp. 1803–1811.
[65] Amarnag Subramanya and Jeff Bilmes, “Soft-supervised learning for text classiﬁcation,” in Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2008, pp. 1090–1099.
[66] Kohei Ozaki, Masashi Shimbo, Mamoru Komachi, and Yuji Matsumoto, “Using the mutual k-nearest neighbor graphs for semi-supervised classiﬁcation of natural language data,” in Proceedings of the ﬁfteenth conference on computational natural language learning. Association for Computational Linguistics, 2011, pp. 154–162.
[67] Andrei Alexandrescu and Katrin Kirchhoff, “Graph-based learning for statistical machine translation,” in Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics. Association for Computational Linguistics, 2009, pp. 119–127.
[68] Amarnag Subramanya, Slav Petrov, and Fernando Pereira, “Efﬁcient graph-based semisupervised learning of structured tagging models,” in Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2010, pp. 167–176.
[69] Sherzod Hakimov, Salih Atilay Oto, and Erdogan Dogdu, “Named entity recognition and disambiguation using linked data and graph-based centrality scoring,” in Proceedings of the 4th international workshop on semantic web information management. ACM, 2012, p. 4.
[70] Mohammad Aliannejadi, Masoud Kiaeeha, Shahram Khadivi, and Saeed Shiry Ghidary, “Graph-based semi-supervised conditional random ﬁelds for spoken language understanding using unaligned data,” arXiv preprint arXiv:1701.08533, 2017.
[71] Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky, “Distant supervision for relation extraction without labeled data,” in Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2. Association for Computational Linguistics, 2009, pp. 1003–1011.
[72] Limin Yao, Sebastian Riedel, and Andrew McCallum, “Collective cross-document relation extraction without labelled data,” in Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2010, pp. 1013–1023.
[73] Limin Yao, Sebastian Riedel, and Andrew McCallum, “Universal schema for entity type prediction,” in Proceedings of the 2013 workshop on Automated knowledge base construction. ACM, 2013, pp. 79–84.
[74] Yi Luan, Richard Wright, Mari Ostendorf, and Gina-Anne Levow, “Relating automatic vowel space estimates to talker intelligibility,” in Proc. Conf. Int. Speech Communication Assoc. (INTERSPEECH), 2014.
27

[75] Gina-Anne Levow, Valerie Freeman, Alena Hrynkevich, Mari Ostendorf, Richard Wright, Julian Chan, Yi Luan, and Trang Tran, “Recognition of stance strength and polarity in spontaneous speech,” in Proc. IEEE Workshop on Spoken Language Technology (SLT), 2014, pp. 236–241.
[76] Yi Luan, Masayuki Suzuki, Yutaka Yamauchi, Nobuaki Minematsu, Shuhei Kato, and Keikichi Hirose, “Performance improvement of automatic pronunciation assessment in a noisy classroom,” in Proc. IEEE Workshop on Spoken Language Technology (SLT). IEEE, 2012, pp. 428–431.
[77] Shingo Takamatsu, Issei Sato, and Hiroshi Nakagawa, “Reducing wrong labels in distant supervision for relation extraction,” in Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1. Association for Computational Linguistics, 2012, pp. 721–729.
[78] Daojian Zeng, Kang Liu, Yubo Chen, and Jun Zhao, “Distant supervision for relation extraction via piecewise convolutional neural networks.,” in EMNLP, 2015, pp. 1753–1762.
[79] Sebastian Riedel Lakshmi Vikraman Andrew McCallum Isabelle Augenstein, Mrinal Das, “Semeval 2017 task 10: Scienceie - extracting keyphrases and relations from scientiﬁc publications,” arXiv preprint arXiv:1704.02853, 2017.
[80] Yuzong Liu and Katrin Kirchhoff, “Graph-based semi-supervised acoustic modeling in dnnbased speech recognition,” in Spoken Language Technology Workshop (SLT), 2014 IEEE. IEEE, 2014, pp. 177–182.
[81] Amarnag Subramanya and Jeff Bilmes, “Semi-supervised learning with measure propagation,” Journal of Machine Learning Research, vol. 12, no. Nov, pp. 3311–3370, 2011.
[82] Mohammad Aliannejadi, Masoud Kiaeeha, Shahram Khadivi, and Saeed Shiry Ghidary, “Graph-based semi-supervised conditional random ﬁelds for spoken language understanding using unaligned data,” in Australasian Language Technology Association Workshop, 2014, p. 98.
[83] Young-Bum Kim, Minwoo Jeong, Karl Stratos, and Ruhi Sarikaya, “Weakly supervised slot tagging with partially labeled sequences from web search click logs.,” in HLT-NAACL, 2015, pp. 84–92.
[84] Yi Luan, Mari Ostendorf, and Hannaneh Hajishirzi, “Scientiﬁc information extraction with semi-supervised neural tagging,” in Proc. Conf. Empirical Methods Natural Language Process. (EMNLP), 2017.
[85] Dragomir R Radev, Pradeep Muthukrishnan, and Vahed Qazvinian, “The acl anthology network corpus,” in Proceedings of the 2009 Workshop on Text and Citation Analysis for Scholarly Digital Libraries. Association for Computational Linguistics, 2009, pp. 54–61.
[86] Steven Bird, Robert Dale, Bonnie J Dorr, Bryan R Gibson, Mark Thomas Joseph, Min-Yen Kan, Dongwon Lee, Brett Powley, Dragomir R Radev, Yee Fan Tan, et al., “The acl anthology reference corpus: A reference dataset for bibliographic research in computational linguistics.,” in LREC, 2008.
28

[87] Isaac G Councill, C Lee Giles, and Min-Yen Kan, “Parscit: an open-source crf reference string parsing package.,” in LREC, 2008, vol. 2008.
[88] Minh-Thang Luong, Thuy Dung Nguyen, and Min-Yen Kan, “Logical structure recovery in scholarly articles with rich document features,” Multimedia Storage and Retrieval Innovations for Digital Library Systems, vol. 270, 2012.
[89] Xiao Ling, Sameer Singh, and Daniel S Weld, “Design challenges for entity linking,” Transactions of the Association for Computational Linguistics, vol. 3, pp. 315–328, 2015.
[90] Xianpei Han and Le Sun, “A generative entity-mention model for linking entities with knowledge base,” in Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1. Association for Computational Linguistics, 2011, pp. 945–954.
[91] The´o Trouillon, Christopher R Dance, Johannes Welbl, Sebastian Riedel, E´ ric Gaussier, and Guillaume Bouchard, “Knowledge graph completion via complex tensor factorization,” arXiv preprint arXiv:1702.06879, 2017.
[92] Hinrich Schu¨tze, “Introduction to information retrieval,” in Proceedings of the international communication of association for computing machinery conference, 2008.
29

