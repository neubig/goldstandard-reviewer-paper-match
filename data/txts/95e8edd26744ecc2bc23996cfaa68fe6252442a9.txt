Evidence-aware Fake News Detection with Graph Neural
Networks
Weizhi Xu1,2,∗, Junfei Wu3,∗, Qiang Liu1,2, Shu Wu1,2,†, Liang Wang1,2
1CRIPAC, NLPR, Institute of Automation, Chinese Academy of Sciences 2School of Artificial Intelligence, University of Chinese Academy of Sciences 3Beijing Institute of Technology
weizhi.xu@cripac.ia.ac.cn,junfei.wu@bit.edu.cn,{qiang.liu,shu.wu,wangliang}@nlpr.ia.ac.cn

arXiv:2201.06885v2 [cs.CL] 8 Feb 2022

ABSTRACT
The prevalence and perniciousness of fake news has been a critical issue on the Internet, which stimulates the development of automatic fake news detection in turn. In this paper, we focus on the evidence-based fake news detection, where several evidences are utilized to probe the veracity of news (i.e., a claim). Most previous methods first employ sequential models to embed the semantic information and then capture the claim-evidence interaction based on different attention mechanisms. Despite their effectiveness, they still suffer from two main weaknesses. Firstly, due to the inherent drawbacks of sequential models, they fail to integrate the relevant information that is scattered far apart in evidences for veracity checking. Secondly, they neglect much redundant information contained in evidences that may be useless or even harmful. To solve these problems, we propose a unified Graph-based sEmantic sTructure mining framework, namely GET in short. Specifically, different from the existing work that treats claims and evidences as sequences, we model them as graph-structured data and capture the long-distance semantic dependency among dispersed relevant snippets via neighborhood propagation. After obtaining contextual semantic information, our model reduces information redundancy by performing graph structure learning. Finally, the fine-grained semantic representations are fed into the downstream claim-evidence interaction module for predictions. Comprehensive experiments have demonstrated the superiority of GET over the state-of-the-arts.

Claim The Trump administration worked to free 5,000 Taliban prisoners.
Evidence The Trump administration negotiated directly with the Taliban, getting ready to invite them to Camp David, ……, opening up a prison of 5,000 Taliban and probably ISIS-K individuals and letting them free.
The claim-related snippets

Subgraph for claim-related snippets

Trump

administration Taliban negotiated

5000

with

opening

prison up

directly

Figure 1: A toy example where a claim and its relevant evidence are given. Two significant snippets for verifying the claim are highlighted (“.....” represents that we omit several sentences for conciseness). The right graph is constructed according to the highlighted snippets. Such two snippets have a long distance in the plain text while they are pulled close on the constructed semantic graph via the shared keyword “Taliban”. Besides, there is much redundant information (texts except the highlighted parts), which is useless for claim verification.

Lyon, France. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/ 3485447.3512122

CCS CONCEPTS
• Computing methodologies → Natural language processing; • Information systems → Data mining.
KEYWORDS
evidence-based fake news detection, graph neural networks
ACM Reference Format: Weizhi Xu, Junfei Wu, Qiang Liu, Shu Wu, Liang Wang. 2022. Evidenceaware Fake News Detection with Graph Neural Networks. In Proceedings of the ACM Web Conference 2022 (WWW ’22), April 25–29, 2022, Virtual Event,
∗The first two authors contributed equally to this work. †Corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France © 2022 Association for Computing Machinery. ACM ISBN 978-1-4503-9096-5/22/04. . . $15.00 https://doi.org/10.1145/3485447.3512122

1 INTRODUCTION
Fake news, which is always fabricated by making some minor changes to the correct statement, is highly deceptive and indistinguishable. The widespread of fake news in diverse domains, such as politics [2] and public health [27], has posed a huge threat to web security and human society. Therefore, the research on automatic fake news detection is challenging but in demand.
Generally, previous methods could be roughly categorized into two groups, i.e., pattern-based approaches and evidence-based approaches [32]. The former methods regard the fake news detection as a feature recognition task, where language models are employed to verify the veracity of news solely according to the text pattern, e.g., writing styles. However, pattern-based methods usually suffer from the poor generalization and interpretability. The latter approaches model the task as a reasoning process, where external evidences are provided to probe the veracity of a claim. Models are required to discover and integrate useful information in given evidences for claim verification.
In this paper, we concentrate on the evidence-based pipeline. Existing methods usually follow a two-step paradigm: 1) they first capture the semantics of claims and evidences separately. 2) Next,

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France
they model the claim-evidence interaction to explore the semantic coherence or conflict for more accurate and interpretable verdict. To name a few representative models, the pioneering work DeClarE [30] utilizes bidirectional LSTMs to model textual features, followed by a word-level attention mechanism to capture the claimevidence interaction. HAN [26] further considers the sentence-level interaction to explore more general semantic coherence. To obtain multi-level semantic interaction, some recent works [37, 41] employ hierarchical attention networks.
Nevertheless, existing work focuses on the specific design of different interaction models (the second step) while neglecting exploring fine-grained semantics of claims and evidences (the first step). To be specific, we argue that there are two main weaknesses in previous methods.
Firstly, the complex, long-distance semantic dependency is less explored. Taking Figure 1 as an example, two highlighted snippets are separated by plenty of words, which induces a long distance between them. Such snippets both contain important information for verifying the claim, i.e., the subject “The Trump administration” and the action “opening up a prison of 5,000 Taliban”. Therefore, fusing the information is indispensable and beneficial for claim veracity prediction. However, the long-distance semantic dependency between such information is hard to be captured due to the inherent drawbacks of sequential models utilized in previous methods.
Secondly, existing methods neglect the redundant information involved in semantics. Such redundancy is useless or even harmful for fake news detection, e.g., as depicted in Figure 1, a large number of text segments, such as “getting ready to invite them to Camp David”, have no substantial contribution to the news veracity checking. Though previous models employ attention mechanisms to reduce the effect of unrelated words, these irrelevant texts are still preserved, which may introduce noises to the downstream claim-evidence interaction, deteriorating the final performance of veracity checking. An intuitive solution is to discard words with low attentive scores based on previous methods. However, they compute the score for each word independently, ignoring the complex semantic structure among words. We argue that it is significant to modeling the redundancy with rich semantic structural information, as the redundancy is not only related to the self-information, but also induced by its contexts, e.g., if a claim can be verified by a snippet in an evidence, the snippet’s context will be redundant.
To tackle the aforementioned problems, we propose a unified Graph-based sEmantic sTructure mining framework, namely GET for exploring fine-grained semantics. Specifically, modeling sequential data as graphs has benefited many tasks, such as text classification [47, 54] and sequential recommendation [44], owing to its capability of capturing long-distance structural dependency. To this end, we utilize graph structure to model both claims and evidences, where nodes indicate words and edges represent the co-occurence between two words. Thereafter, the dispersed claim-related snippets are pulled close on graphs, thus the useful information could be better fused via neighborhood propagation. For example, in Figure 1, after constructing the graph for two highlighted snippets distant from each other in plain texts, they are pulled close via the shared keyword “Taliban” so that the long-distance semantic dependency can be captured. Moreover, to alleviate the negative impact of redundant information, within our graph-based framework, we treat

the redundancy mitigation as a graph structure learning process, where unimportant nodes are discarded according to complex semantic structures, i.e., both self-features (node attributes) and their contexts (graph topology). To date, our graph-based framework has captured the fine-grained semantics via long-distance dependency modeling and redundancy mitigation. Based on such semantics, we can apply the widely used attention mechanism in previous work to readout node features and form the claim- and evidence-level representations, followed by claim-evidence interactions to integrate information for the final veracity prediction.
Our main contributions can be summarized as follows:
• We model claims and evidences as graph-structured data and design a graph-based framework to explore the complex semantic structure. To the best of our knowledge, this is the first work to propose a unified graph-based method for evidence-based fake news detection.
• We introduce a simple and effective graph structure learning approach for redundancy mitigation. By capturing longdistance semantic dependency and reducing redundancy, we obtain the fine-grained semantics, which can boost the performance of downstream interaction models.
• Comprehensive experiments are conducted to verify the effectiveness of GET, where the results demonstrate its superiority.
2 RELATED WORK
2.1 Graph Neural Networks
Graph neural networks (GNNs) learn the node representation by gathering information from the neighborhood, i.e., neighborhood propagation/aggregation. Current GNNs can be roughly divided into two groups, namely spectral approaches [8, 19] and spatial approaches [14, 33]. Owing to the capability of capturing longdistance structural relationship on graphs, GNNs have been widely utilized and achieved satisfactory performance in several tasks, such as recommender system [5, 44, 51], text classification [47, 54], and sentiment analysis [22, 39]. Recently, researchers have observed that graphs inevitably contain noises that may deteriorate the training of GNNs [17]. To handle this problem, graph structure learning (GSL) is proposed, aiming to jointly learn an optimized graph structure and node embeddings. Existing GSL methods mainly fall into three groups [58]: 1) the metric-learning-based methods where the adjacency matrices are built as metrics coupled with node embeddings. Therefore, the graph topology is updated with node embeddings being optimized. The metrics are mainly defined as the attention-based function [6, 7, 16] or kernel function [23, 45]. 2) the probabilistic methods assume that the adjacency matrix is generated by sampling from a specific probabilistic distribution [10, 11, 53]. 3) the direct-optimized methods treat the graph topology as learnable parameters that are updated together with task-specific parameters simultaneously, without depending on preset priors (node embeddings and distributions in the first two groups, respectively). The topology is optimized with the guidance of task-specific objectives (and some normalization constraints) [17, 46]. It is worth noting that existing graph pooling methods [12, 20, 48] could also be regarded as GSL algorithms, since the pooling target is to keep the

Evidence-aware Fake News Detection with Graph Neural Networks
most valuable nodes that preserve the graph structural information well, where the graph structure is optimized via merging or dropping nodes. Besides, GNNs are widely employed in the domain of fact verification, which have achieved promising performance [25, 56, 57]. Though fact verification is similar to fake news detection on the task setting, the latter requires more fine-grained semantics since the texts consist of more redundancy.
2.2 Fake News Detection
Several fake news detection methods have been proposed in recent years, which can be roughly grouped into two categories.
The first is the pattern-based pipeline where models solely consider the text pattern involved in the news itself. Different work always focus on different kinds of patterns. Popat et al. [28] classify a claim as true or fake in accordance with stylistic features and the article stance. Besides, some researchers attempt to verify the truthiness via the feedback in social media, such as reposts, likes, and comments [3, 4, 18, 24, 36, 38, 49]. Recently, more attention has been paid to the emotional pattern mining, where they hold an assumption that there are probably obvious sentiment biases in fake news [1, 13, 52].
The second is the evidence-based pipeline where researchers propose to explore the semantic similarity (conflict) in claim-evidence pairs to check the news veracity. Evidences are usually retrieved from the knowledge graph [35] or fact-checking websites [34] by giving unverified claims as queries. DeClarE [30] is the first work to utilize evidences in fake news detection. They employ BiLSTMs to embed the semantics of evidences and obtain the claim’s sentencelevel representation via average pooling. Next, they introduce an attention-based interaction to compute the claim-aware score for each word in evidences. Similar to the pioneering work, the following methods utilize the sequential models to obtain the semantic embeddings, followed by attention mechanisms performed on different granularities. HAN [26] compute the sentence-level coherence and entailment scores between claims and evidences. EHIAN [43] employs the self-attention mechanism to obtain word-level interaction scores. Recent work [37, 41, 42] hierarchically integrates both word-level and sentence-level interactions into the final representation for verification. In summary, they all employ sequential models to embed the semantics and apply attention mechanisms to capture the claim-evidence semantic relationship.
Different from the existing work, we propose a unified graphbased model, where the long-distance semantic dependency is captured via constructed graph structures and the redundancy is reduced by performing graph structure learning.
3 METHOD
3.1 Task Formulation
Evidence-based fake news detection is a classification task, where the model is required to output the prediction of news veracity. Specifically, the inputs are a claim 𝑐, several related evidences E = {𝑒1, 𝑒2, . . . , 𝑒𝑛 }, and their corresponding speakers s ∈ R1×𝑏 or publishers p ∈ R𝑛×𝑏 , where 𝑛 is the number of evidences and 𝑏 is the dimension of speaker and publisher embeddings. The output is the predicted probability of veracity 𝑦ˆ = 𝑓 (𝑐, E, s, p, Θ), where 𝑓 is the verification model and Θ is its trainable parameters.

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

3.2 The Proposed Model: GET
In this part, we elaborate our unified graph-based model GET, which can be mainly separated into four modules: 1) Graph Construction, 2) Graph-based Semantics Encoder, 3) Semantic Structure Refinement, and 4) Attentive Graph Readout Layer.

3.2.1 Graph Construction. In order to capture the long-distance

dependency of relevant information, we first convert the original

claims and evidences to graphs. Like previous graph-based methods

in other NLP tasks [47, 50, 54, 55], we use a fix-sized sliding window

to screen out the connectivity for each word on graphs. In detail,

the center words in every window will be connected with the rest

of words in it (if connected, the corresponding entry in adjacency

matrix is 1, otherwise 0), which captures the local context in center

word’s neighborhood. Furthermore, to model the long-distance

dependency, we merge all the same words into one node on graph,

which explicitly gathers their local contexts (e.g., the word 𝑒2 in

evidence text 1 in Figure 2). Therefore, several relevant snippets

that scatter far apart is close on graphs, which can be explored via

the high-order message propagation. In addition, the initial node

representations are the corresponding word embeddings. Note that

we also try to construct a graph in a fully-connected or semantic-

similarity-based manner, but these two ways are all inferior to the

sliding-window-based method, which may due to the redundant

noises induced by the dense connection.

To ensure the numerical stability, we perform Laplacian normal-

ization

on

adjacency

matrices,

denoted

as

A˜

=

D−

1 2

(A

+

I)

D−

1 2

,

where D is the diagonal degree matrix (i.e., D𝑖𝑖 = 𝑗 A𝑖 𝑗 ) and I is

the identical matrix. Finally, we denote the initial normalized adja-

cency matrices and node feature matrices of claim and evidence as

A˜ (0) ∈ R𝑁𝑐 ×𝑁𝑐 , A˜ (0) ∈ R𝑁𝑒 ×𝑁𝑒 and H(0) ∈ R𝑁𝑐 ×𝑑 , H(0) ∈ R𝑁𝑒 ×𝑑 ,

𝑐

𝑒

𝑐

𝑒

respectively. 𝑁𝑐 and 𝑁𝑒 is the number of nodes in initial claim and

evidence graphs, 𝑑 is the dimension of word embeddings.

Taking the established graph structures and node embeddings as

inputs, we design a graph-based model to better capture complex

semantics and obtain refined semantic structures.

3.2.2 Graph-based Semantics Encoder. To mine the long-distance semantic dependency, we propose to utilize GNNs as the semantics encoder. In particular, as we expect to adaptively keep a balance between self-features and the information of neighboring nodes, we employ graph gated neural networks (GGNN) to perform neighborhood propagation on both claim and evidence graphs, enabling nodes to capture their contextual information, which is significant for learning high-level semantics. Formally, it can be written as follows:

∑︁

a𝑖 =

A˜ 𝑖 𝑗 W𝑎H𝑗

(1)

(𝑤𝑖 ,𝑤𝑗 ) ∈ C

z𝑖 = 𝜎 (W𝑧 a𝑖 + U𝑧 H𝑖 + b𝑧 )

(2)

r𝑖 = 𝜎 (W𝑟 a𝑖 + U𝑟 H𝑖 + b𝑟 )

(3)

H˜ 𝑖 = tanh (Wℎa𝑖 + Uℎ (r𝑖 ⊙ H𝑖 ) + bℎ) (4)

Hˆ 𝑖 = H˜ 𝑖 ⊙ z𝑖 + H𝑖 ⊙ (1 − z𝑖 )

(5)

where C denotes the edge set, W∗, U∗, and b∗ are trainable parameters, which control the proportion of the neighborhood information and self-information. 𝜎 is the non-linear activation unit and we

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

Graph-based Semantic Structure Mining

Graph Construction

Semantics Structure Mining

Graph-based Semantics Encoder
Graph-based Semantics Encoder

Claim Text c1 , c2 , c3 , c4 , c5 , c2 , c6 , c7
Evidence Text 1 e1 , e2 , e3 , e4 , e5 , … , e24 , e2 , e3 , e4 , e25 , … , e96 , e97 , e24 , e25 , e98 , e99

c1 c3 c7 c2 c4
c6 c5

e1 e97 e2 e96 e24

e5 e4 e99
e3 e25 e98

……

……

Evidence Text e1 , e2 , e3 , e1 ,

n< l a t e x i t s h a 1 _ b a s e 6 4 = " d b J w O l w w g c h e u A 6 O j 4 z a 7 d E p y U U = " > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E q s e i F 4 8 V 7 Q e 0 o W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s t H M 0 n Q j + h Q 8 p A z a q z 0 I P v Y L 1 f c q j s H W S V e T i q Q o 9 E v f / U G M U s j l I Y J q n X X c x P j Z 1 Q Z z g R O S 7 1 U Y 0 L Z m A 6 x a 6 m k E W o / m 5 8 6 J W d W G Z A w V r a k I X P 1 9 0 R G I 6 0 n U W A 7 I 2 p G e t m b i f 9 5 3 d S E 1 3 7 G Z Z I a l G y x K E w F M T G Z / U 0 G X C E z Y m I J Z Y r b W w k b U U W Z s e m U b A j e 8 s u r p H V R 9 W p V 7 / 6 y U r / J 4 y j C C Z z C O X h w B X W 4 g w Y 0 g c E Q n u E V 3 h z h v D j v z s e i t e D k M 8 f w B 8 7 n D 0 0 8 j d A = < / l a t e x i t > e
e4 ,

e24 , e3 , e25 , e26 , e4 ,

e83 , e25 , e26 , e84 , e85

…, …, , e86

e2

e24

e1

e86

e3 e25

e85 e4

e e26 e83

84

Semantic Structure Refinement
Graph-based Semantics Encoder
……

Node Embeddings

< l a t e x i t s h a 1 _ b a s e 6 4 = " 5 C r f C Y W g 1 d w b 5 5 B x T H g k a I 1 I a c g = " > A A A B + 3 i c b V D L S s N A F L 3 x W e s r 1 q W b Y B H q p i R F 1 G X R T Z c V 7 A P a G C b T S T t 0 M g k z E 7 G E / I o b F 4 q 4 9 U f c + T d O 2 i y 0 9 c D A 4 Z x 7 u W e O H z M q l W 1 / G 2 v r G 5 t b 2 6 W d 8 u 7 e / s G h e V T p y i g R m H R w x C L R 9 5 E k j H L S U V Q x 0 o 8 F Q a H P S M + f 3 u Z + 7 5 E I S S N + r 2 Y x c U M 0 5 j S g G C k t e W Z l G C I 1 8 Y O 0 l T 2 k t c Z 5 5 m H P r N p 1 e w 5 r l T g F q U K B t m d + D U c R T k L C F W Z I y o F j x 8 p N k V A U M 5 K V h 4 k k M c J T N C Y D T T k K i X T T e f b M O t P K y A o i o R 9 X 1 l z 9 v Z G i U M p Z 6 O v J P K l c 9 n L x P 2 + Q q O D a T S m P E 0 U 4 X h w K E m a p y M q L s E Z U E K z Y T B O E B d V Z L T x B A m G l 6 y r r E p z l L 6 + S b q P u X N a d u 4 t q 8 6 a o o w Q n c A o 1 c O A K m t C C N n Q A w x M 8 w y u 8 G Z n x Y r w b H 4 v R N a P Y O Y Y / M D 5 / A H L J l A 4 = < / l a t e x i t >
H(c2)

Refined Structures

e1 e24

e2

e5

e3

e4
< l a t e x i t s h a 1 _ b a s e 6 4 = " w w H n x O I Y D C a Z j I a U Y g c 3 X g 3 J N c M = " > A A A C B n i c b V D L S s N A F J 3 4 r P U V d S l C s A h 1 U x I R d V l 1 4 7 K C f U A T w 2 R y 0 w 6 d P J i Z C C V k 5 c Z f c e N C E b d + g z v / x k m b h b Y e u H A 4 5 1 7 u v c d L G B X S N L + 1 h c W l 5 Z X V y l p 1 f W N z a 1 v f 2 e 2 I O O U E 2 i R m M e 9 5 W A C j E b Q l l Q x 6 C Q c c e g y 6 3 u i 6 8 L s P w A W N o z s 5 T s A J 8 S C i A S V Y K s n V D + w Q y 6 E X Z L a k z I f s M s / v s 7 p 1 n L s Z W L m r 1 8 y G O Y E x T 6 y S 1 F C J l q t / 2 X 5 M 0 h A i S R g W o m + Z i X Q y z C U l D P K q n Q p I M B n h A f Q V j X A I w s k m b + T G k V J 8 I 4 i 5 q k g a E / X 3 R I Z D I c a h p z q L o 8 W s V 4 j / e f 1 U B h d O R q M k l R C R 6 a I g Z Y a M j S I T w 6 c c i G R j R T D h V N 1 q k C H m m E i V X F W F Y M 2 + P E 8 6 J w 3 r r G H d n t a a V 2 U c F b S P D l E d W e g c N d E N a q E 2 I u g R P a N X 9 K Y 9 a S / a u / Y x b V 3 Q y p k 9 9 A f a 5 w 9 S g J k F < / l a t e x i t >
A˜ (e11)

1-layer ESM

e2 e1
e84

e3 e26

e24

e25

A˜< l a t e x i t s h a 1 _ b a s e 6 4 = " I P X b H 3 l C G E 4 z l J a L m 2 H T P y F 1 G A M = " > A A A C B n i c b V B N S 8 N A E N 3 4 W e t X 1 a M I w S L U S 0 l E 1 G P V i 8 c K 9 g P a G D b b S b t 0 s w m 7 G 6 E s O X n x r 3 j x o I h X f 4 M 3 / 4 3 b N g d t f T D w e G + G m X l B w q h U j v N t L S w u L a + s F t a K 6 x u b W 9 u l n d 2 m j F N B o E F i F o t 2 g C U w y q G h q G L Q T g T g K G D Q C o b X Y 7 / 1 A E L S m N + p U Q J e h P u c h p R g Z S S / d N C N s B o E o e 4 q y n q g L 7 P s X l f c 4 8 z X w D O / V H a q z g T 2 P H F z U k Y 5 6 n 7 p q 9 u L S R o B V 4 R h K T u u k y h P Y 6 E o Y Z A V u 6 m E B J M h 7 k P H U I 4 j k J 6 e v J H Z R 0 b p 2 W E s T H F l T 9 T f E x p H U o 6 i w H S O j 5 a z 3 l j 8 z + u k K r z w N O V J q o C T 6 a I w Z b a K 7 X E m d o 8 K I I q N D M F E U H O r T Q Z Y Y K J M c k U T g j v 7 8 j x p n l T d s 6 p 7 e 1 q u X e V x F N A + O k Q V 5 K J z V E M 3 q I 4 a i K B H 9 I x e 0 Z v 1 Z L 1 Y 7 9 b H t H X B y m f 2 0 B 9 Y n z + v M Z l C < / l a t e x i t >

(1) en

Graph-based Semantics Encoder
……

Average Pooling

Speaker Embeddings

Graph Embeddings

s< l a t e x i t s h a 1 _ b a s e 6 4 = " u r O m b 2 1 l r O a k O V 8 5 9 K e f E x Y x f N s = " > A A A B 8 X i c b V B N S 8 N A F H y p X 7 V + V T 1 6 W S y C p 5 K I q M e i F 4 8 V b C 2 2 o W y 2 L + 3 S z S b s b o Q S + i + 8 e F D E q / / G m / / G T Z u D t g 4 s D D P v s f M m S A T X x n W / n d L K 6 t r 6 R n m z s r W 9 s 7 t X 3 T 9 o 6 z h V D F s s F r H q B F S j 4 B J b h h u B n U Q h j Q K B D 8 H 4 J v c f n l B p H s t 7 M 0 n Q j + h Q 8 p A z a q z 0 2 I u o G Q V h p q f 9 a s 2 t u z O Q Z e I V p A Y F m v 3 q V 2 8 Q s z R C a Z i g W n c 9 N z F + R p X h T O C 0 0 k s 1 J p S N 6 R C 7 l k o a o f a z W e I p O b H K g I S x s k 8 a M l N / b 2 Q 0 0 n o S B X Y y T 6 g X v V z 8 z + u m J r z y M y 6 T 1 K B k 8 4 / C V B A T k / x 8 M u A K m R E T S y h T 3 G Y l b E Q V Z c a W V L E l e I s n L 5 P 2 W d 2 7 q H t 3 5 7 X G d V F H G Y 7 g G E 7 B g 0 t o w C 0 0 o Q U M J D z D K 7 w 5 2 n l x 3 p 2 P + W j J K X Y O 4 Q + c z x / 3 m J E d < / l a t e x i t >

h< l a t e x i t s h a 1 _ b a s e 6 4 = " A 4 B f L 5 z R d t d x x I c / I s D d x G y H e W M = " > A A A B + 3 i c b V D L S s N A F L 3 x W e s r 1 q W b w S K 4 K o m I u i y 6 c V n B P q C N Y T K d t E M n k z A z E U v I r 7 h x o Y h b f 8 S d f + O k z U J b D w w c z r m X e + Y E C W d K O 8 6 3 t b K 6 t r 6 x W d m q b u / s 7 u 3 b B 7 W O i l N J a J v E P J a 9 A C v K m a B t z T S n v U R S H A W c d o P J T e F 3 H 6 l U L B b 3 e p p Q L 8 I j w U J G s D a S b 9 c G E d b j I M z G + U M 2 y v 2 M 5 L 5 d d x r O D G i Z u C W p Q 4 m W b 3 8 N h j F J I y o 0 4 V i p v u s k 2 s u w 1 I x w m l c H q a I J J h M 8 o n 1 D B Y 6 o 8 r J Z 9 h y d G G W I w l i a J z S a q b 8 3 M h w p N Y 0 C M 1 k k V Y t e I f 7 n 9 V M d X n k Z E 0 m q q S D z Q 2 H K k Y 5 R U Q Q a M k m J 5 l N D M J H M Z E V k j C U m 2 t R V N S W 4 i 1 9 e J p 2 z h n v R c O / O 6 8 3 r s o 4 K H M E x n I I L l 9 C E W 2 h B G w g 8 w T O 8 w p u V W y / W u / U x H 1 2 x y p 1 D + A P r 8 w f 0 8 Z U K < / l a t e x i t >

g c

< l a t e x i t s h a 1 _ b a s e 6 4 = " u 3 Z U n w W Y 5 P y D k Q 0 V X k 1 W l F E O u Y E = " > A A A B 9 X i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y B F c l R k R d V l 0 4 7 K C f U B f Z N J M G 5 r J D M k d p Q z 9 D z c u F H H r v 7 j z b 8 y 0 s 9 D W A 4 H D O f d y T 4 4 f S 2 H Q d b + d l d W 1 9 Y 3 N w l Z x e 2 d 3 b 7 9 0 c N g w U a I Z r 7 N I R r r l U 8 O l U L y O A i V v x Z r T 0 J e 8 6 Y 9 v M 7 / 5 y L U R k X r A S c y 7 I R 0 q E Q h G 0 U q 9 T k h x 5 A f p a N o L + q x f K r s V d w a y T L y c l C F H r V / 6 6 g w i l o R c I Z P U m L b n x t h N q U b B J J 8 W O 4 n h M W V j O u R t S x U N u e m m s 9 R T c m q V A Q k i b Z 9 C M l N / b 6 Q 0 N G Y S + n Y y S 2 k W v U z 8 z 2 s n G F x 3 U 6 H i B L l i 8 0 N B I g l G J K u A D I T m D O X E E s q 0 s F k J G 1 F N G d q i i r Y E b / H L y 6 R x X v E u K 9 7 9 R b l 6 k 9 d R g G M 4 g T P w 4 A q q c A c 1 q A M D D c / w C m / O k / P i v D s f 8 9 E V J 9 8 5 g j 9 w P n 8 A 3 Q e S w A = = < / l a t e x i t >
h

f c

Attentive Graph Readout Layer

Node Embeddings
< l a t e x i t s h a 1 _ b a s e 6 4 = " c 5 W m d J O K r f H n i d q S U d 6 B L q B V 4 0 M = " > A A A B / n i c b V D L S g M x F M 3 4 r P U 1 K q 7 c B I t Q N 2 W m i L o s u u m y g n 1 A O w 6 Z N N O G Z j J D k h F K G P B X 3 L h Q x K 3 f 4 c 6 / M d P O Q l s P B A 7 n 3 M s 9 O U H C q F S O 8 2 2 t r K 6 t b 2 y W t s r b O 7 t 7 + / b B Y U f G q c C k j W M W i 1 6 A J G G U k 7 a i i p F e I g i K A k a 6 w e Q 2 9 7 u P R E g a 8 3 s 1 T Y g X o R G n I c V I G c m 3 j w c R U u M g 1 M 3 s Q V f r 5 5 m v i Z v 5 d s W p O T P A Z e I W p A I K t H z 7 a z C M c R o R r j B D U v Z d J 1 G e R k J R z E h W H q S S J A h P 0 I j 0 D e U o I t L T s / g Z P D P K E I a x M I 8 r O F N / b 2 g U S T m N A j O Z h 5 W L X i 7 + 5 / V T F V 5 7 m v I k V Y T j + a E w Z V D F M O 8 C D q k g W L G p I Q g L a r J C P E Y C Y W U a K 5 s S 3 M U v L 5 N O v e Z e 1 t y 7 i 0 r j p q i j B E 7 A K a g C F 1 y B B m i C F m g D D D R 4 B q / g z X q y X q x 3 6 2 M + u m I V O 0 f g D 6 z P H 7 z G l V c = < / l a t e x i t >
H(e21)

< l a t e x i t s h a 1 _ b a s e 6 4 = " 1 I 1 5 L K u s z 5 4 A J t I Q J G / w a d o T 2 b 8 = " > A A A B 9 X i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y B F c l R k R d V l 0 4 7 K C f U B f Z N I 7 b W g m M y Q Z p Q z 9 D z c u F H H r v 7 j z b 8 y 0 s 9 D W A 4 H D O f d y T 4 4 f C 6 6 N 6 3 4 7 K 6 t r 6 x u b h a 3 i 9 s 7 u 3 n 7 p 4 L C h o 0 Q x r L N I R K r l U 4 2 C S 6 w b b g S 2 Y o U 0 9 A U 2 / f F t 5 j c f U W k e y Q c z i b E b 0 q H k A W f U W K n X C a k Z + U E 6 m v a C P v Z L Z b f i z k C W i Z e T M u S o 9 U t f n U H E k h C l Y Y J q 3 f b c 2 H R T q g x n A q f F T q I x p m x M h 9 i 2 V N I Q d T e d p Z 6 S U 6 s M S B A p + 6 Q h M / X 3 R k p D r S e h b y e z l H r R y 8 T / v H Z i g u t u y m W c G J R s f i h I B D E R y S o g A 6 6 Q G T G x h D L F b V b C R l R R Z m x R R V u C t / j l Z d I 4 r 3 i X F e / + o l y 9 y e s o w D G c w B l 4 c A V V u I M a 1 I G B g m d 4 h T f n y X l x 3 p 2 P + e i K k + 8 c w R 8 4 n z / g D 5 L C < / l a t e x i t >
h

f e

< l a t e x i t s h a 1 _ b a s e 6 4 = " m 9 z K Q + N 8 F U e r h D U / 5 / w U E V s V h d U = " > A A A B 8 3 i c b V D L S s N A F L 3 x W e u r 6 t L N Y B F c l U R E X R b d u K x g H 9 D U M p n e t E M n k z A z E U r o b 7 h x o Y h b f 8 a d f + O k z U J b D w w c z r m X e + Y E i e D a u O 6 3 s 7 K 6 t r 6 x W d o q b + / s 7 u 1 X D g 5 b O k 4 V w y a L R a w 6 A d U o u M S m 4 U Z g J 1 F I o 0 B g O x j f 5 n 7 7 C Z X m s X w w k w R 7 E R 1 K H n J G j Z V 8 P 6 J m F I T Z a P o Y 9 i t V t + b O Q J a J V 5 A q F G j 0 K 1 / + I G Z p h N I w Q b X u e m 5 i e h l V h j O B 0 7 K f a k w o G 9 M h d i 2 V N E L d y 2 a Z p + T U K g M S x s o + a c h M / b 2 R 0 U j r S R T Y y T y j X v R y 8 T + v m 5 r w u p d x m a Q G J Z s f C l N B T E z y A s i A K 2 R G T C y h T H G b l b A R V Z Q Z W 1 P Z l u A t f n m Z t M 5 r 3 m X N u 7 + o 1 m + K O k p w D C d w B h 5 c Q R 3 u o A F N Y J D A M 7 z C m 5 M 6 L 8 6 7 8 z E f X X G K n S P 4 A + f z B 2 K 3 k e o = < / l a t e x i t >
h

f

……

< l a t e x i t s h a 1 _ b a s e 6 4 = " b d x L W 6 7 K h X k o f v f M 3 + A k + i H X 0 b s = " > A A A B / n i c b V D L S g M x F M 3 4 r P U 1 K q 7 c B I t Q N 2 W m i L o s u u m y g n 1 A O w 6 Z N N O G Z j J D k h F K G P B X 3 L h Q x K 3 f 4 c 6 / M d P O Q l s P B A 7 n 3 M s 9 O U H C q F S O 8 2 2 t r K 6 t b 2 y W t s r b O 7 t 7 + / b B Y U f G q c C k j W M W i 1 6 A J G G U k 7 a i i p F e I g i K A k a 6 w e Q 2 9 7 u P R E g a 8 3 s 1 T Y g X o R G n I c V I G c m 3 j w c R U u M g 1 M 3 s Q V f r 5 5 m v C c 9 8 u + L U n B n g M n E L U g E F W r 7 9 N R j G O I 0 I V 5 g h K f u u k y h P I 6 E o Z i Q r D 1 J J E o Q n a E T 6 h n I U E e n p W f w M n h l l C M N Y m M c V n K m / N z S K p J x G g Z n M w 8 p F L x f / 8 / q p C q 8 9 T X m S K s L x / F C Y M q h i m H c B h 1 Q Q r N j U E I Q F N V k h H i O B s D K N l U 0 J 7 u K X l 0 m n X n M v a + 7 d R a V x U 9 R R A i f g F F S B C 6 5 A A z R B C 7 Q B B h o 8 g 1 f w Z j 1 Z L 9 a 7 9 T E f X b G K n S P w B 9 b n D x m G l Z Q = < / l a t e x i t >
H(e2n)

p< l a t e x i t s h a 1 _ b a s e 6 4 = " D z q n 2 O L 1 l Q y 7 R 5 q 8 d i J j I R r k b c c = " > A A A B 8 X i c b V B N S 8 N A F H y p X 7 V + V T 1 6 W S y C p 5 K I q M e i F 4 8 V b C 2 2 o W y 2 L + 3 S z S b s b o Q S + i + 8 e F D E q / / G m / / G T Z u D t g 4 s D D P v s f M m S A T X x n W / n d L K 6 t r 6 R n m z s r W 9 s 7 t X 3 T 9 o 6 z h V D F s s F r H q B F S j 4 B J b h h u B n U Q h j Q K B D 8 H 4 J v c f n l B p H s t 7 M 0 n Q j + h Q 8 p A z a q z 0 2 I u o G Q V h l k z 7 1 Z p b d 2 c g y 8 Q r S A 0 K N P v V r 9 4 g Z m m E 0 j B B t e 5 6 b m L 8 j C r D m c B p p Z d q T C g b 0 y F 2 L Z U 0 Q u 1 n s 8 R T c m K V A Q l j Z Z 8 0 Z K b + 3 s h o p P U k C u x k n l A v e r n 4 n 9 d N T X j l Z 1 w m q U H J 5 h + F q S A m J v n 5 Z M A V M i M m l l C m u M 1 K 2 I g q y o w t q W J L 8 B Z P X i b t s 7 p 3 U f f u z m u N 6 6 K O M h z B M Z y C B 5 f Q g F t o Q g s Y S H i G V 3 h z t P P i v D s f 8 9 G S U + w c w h 8 4 n z / z C Z E a < / l a t e x i t >
Publisher Embeddings

Multi-layer Perceptron

yˆ< l a t e x i t s h a 1 _ b a s e 6 4 = " e q H I t U B 9 E B 2 y b o c n d 3 l o Z S g 1 0 w Y = " > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 1 G P R i 8 c K 9 g P a U D b b T b t 0 s w m 7 E y G E / g g v H h T x 6 u / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S K Q w 6 L r f T m l t f W N z q 7 x d 2 d n d 2 z + o H h 6 1 T Z x q x l s s l r H u B t R w K R R v o U D J u 4 n m N A o k 7 w S T u 5 n f e e L a i F g 9 Y p Z w P 6 I j J U L B K F q p 0 x 9 T z L P p o F p z 6 + 4 c Z J V 4 B a l B g e a g + t U f x i y N u E I m q T E 9 z 0 3 Q z 6 l G w S S f V v q p 4 Q l l E z r i P U s V j b j x 8 / m 5 U 3 J m l S E J Y 2 1 L I Z m r v y d y G h m T R Y H t j C i O z b I 3 E / / z e i m G N 3 4 u V J I i V 2 y x K E w l w Z j M f i d D o T l D m V l C m R b 2 V s L G V F O G N q G K D c F b f n m V t C / q 3 l X d e 7 i s N W 6 L O M p w A q d w D h 5 c Q w P u o Q k t Y D C B Z 3 i F N y d x X p x 3 5 2 P R W n K K m W P 4 A + f z B 7 O 5 j 9 A = < / l a t e x i t >

Figure 2: The architecture of GET. The plain texts are first transformed into graphs using a sliding window (the window size is 2
in the figure). The same words repeatedly appear in texts are merged into one node. Next, we introduce graph-based semantics
encoder to capture long-distance structural dependencies and generate high-order representations via neighborhood aggregation. Furthermore, the semantic structure refinement layer is proposed to generate optimized structures {A˜ 𝑒(11), . . . , A˜ 𝑒(𝑛1) } for 𝑛 evidences, where redundant nodes are discarded (The 1-layer ESM consists of a graph-based semantics encoder and a semantic
structure refinement layer). Thereafter, the fine-grained semantics is obtained by performing neighborhood propagation on
refined graphs. Finally, claim and evidence embeddings along with their speaker and publisher information are fed into the attentive graph readout layer to output the final prediction 𝑦ˆ.

utilize the Sigmoid function in our model. For brevity, we denote Eq. (1) - (5) as GGNN(A˜ , H)1.
3.2.3 Semantic Structure Refinement. As evidences always contain redundant information that may mislead model to focus on unimportant features, it is beneficial to discover and filter out the redundancy, thus obtaining refined semantic structures. To this end, in our graph-based framework, we treat the redundancy mitigation as a graph structure learning process, whose aim is to learn the optimized graph topology along with better node representations. Previous GSL methods generally optimize the topology in three ways, i.e., dropping nodes, dropping edges, and adjusting edge weights. Since the redundancy information is mainly involved in words denoted as nodes in evidence graphs, we attempt to refine evidence graph structures via discarding redundant nodes, inspired by previous GSL methods [6, 20, 53].
In particular, we propose to compute a redundancy score for each node, based on which we obtain a ranking list and nodes with the top-𝑘 redundancy scores will be discarded. The redundancy is not only related to the self-information contained in each node, but also induced by the contextual information, which is involved in the neighborhood on graphs. For example, if a claim can be verified by a snippet in an evidence, the rest of segments (including the snippet’s context) will be redundant. Therefore, we utilize a 1-layer GGNN to compute the redundancy scores, which takes into account both self-
1When generally describing the module that will be repeatedly utilized in the model, we omit the superscripts indicating layer number for brevity.

and context-information in score computation. Mathematically, it can be formulated as:

s𝑟 = GGNN(A˜ , Hˆ eW𝑠 )

(6)

𝑖𝑑𝑥 = 𝑡𝑜𝑝𝑘_𝑖𝑛𝑑𝑒𝑥 (s𝑟 )

(7)

A˜ 𝑖𝑑𝑥,: = A˜ :,𝑖𝑑𝑥 = 0

(8)

where W𝑠 ∈ R𝑑×1 is the trainable weights that project node representations into the 1-dimension score space. 𝑖𝑑𝑥 denotes the indices of node with top-𝑘 redundancy scores which are discarded by masking their degrees as 0 (c.f., Eq. (8)). Note that GGNN(·) in Eq. (6) does not share parameters with the semantics encoder due to their different targets. Besides, we only perform semantic structure refinement on evidences since claims are usually short (less than 10 words) so that the semantic structures are simple and unnecessary to be refined.
Finally, we stack the semantic structure refinement layer over one semantics encoder to form a unified module, namely evidence semantics miner (ESM in short), where the long-distance semantic dependency is captured and the redundant information is reduced. In general, we can stack 𝑇𝑅 layers of ESM to refine the semantic structures 𝑇𝑅 times, eventually followed by a semantics encoder to perform neighborhood propagation on refined semantic graphs, obtaining the fine-grained representations.

3.2.4 Attentive Graph Readout Layer. So far, we have obtained refined structures A˜ 𝑒(𝑇𝑅) for each evidence and fine-grained node

Evidence-aware Fake News Detection with Graph Neural Networks

embeddings H(𝑇𝐸) , H(𝑇𝑅+1) for claims and evidences separately2,

𝑐

𝑒

where 𝑇𝑅 and 𝑇𝐸 are the numbers of ESM layer and semantics

encoder layer of claim, respectively (𝑇𝑅 = 1 and 𝑇𝐸 = 2 in Figure

2). Next, to perform the claim-evidence interaction, we first need

to integrate all node embeddings (word embeddings) into general

graph embeddings (claim and evidence embeddings). Following

previous work [37], we propose to obtain claim-aware evidence

representations via the attention mechanism. In detail, we compute

the attention score of the 𝑗-th word H𝑒 𝑗 in the refined evidence

graph with the claim representation h𝑔𝑐 . Thereafter, the evidence

representation h𝑔𝑒 is obtained via weighted summation:

𝑔

1

𝑙𝑐
∑︁

h𝑐 =

H𝑐𝑖

(9)

𝑙𝑐 𝑖=1

p𝑗 = tanh H𝑒 𝑗 ; h𝑔𝑐 W𝑐

(10)

exp p𝑗 W𝑝

𝛼𝑗 =

(11)

𝑙𝑒 𝑖 =1

exp

p𝑖 W𝑝

𝑙𝑒
h𝑔𝑒 = ∑︁ 𝛼 𝑗 H𝑒 𝑗 (12)
𝑗 =1

where [·; ·] denotes the concatenation of two vectors and W𝑐 ∈ R2𝑑×𝑑 and W𝑝 ∈ R𝑑×1 are the trainable parameters. 𝑙𝑐 and 𝑙𝑒 are

the length of claim and evidence, respectively. We denote Eq. (10) - (12) as ATTN(He, h𝑔𝑐 ) and the attention modules can be easily

extended to multi-head ones by concatenating outputs of each head.

It is worth noting that based on the fine-grained representations

our graph-based model outputs, the above attention mechanism

can be replaced by any interaction method in previous work, which

we further discuss in Section 4.4.

As Vo and Lee [37] empirically demonstrate that claim speaker

and evidence publisher information is important for verification,

we extend claim and evidence representations by concatenating

them

with

corresponding

information

vectors,

i.e.,

h𝑓
𝑐

=

[h𝑔𝑐 ; s] and

h𝑟𝑒 = [h𝑔𝑒 ; p].

After obtaining the claim and evidence representations, we fur-

ther employ another attentive network, which is of the same struc-

ture as the above, to capture the document-level interaction be-

tween a claim and several evidences:

H𝑟𝑒 = [h𝑟𝑒1; h𝑟𝑒2; . . . ; h𝑟𝑒𝑛]

(13)

h𝑒𝑓 = ATTN(H𝑟𝑒, h𝑐𝑓 ) (14)

where H𝑟𝑒 denotes the concatenation of embeddings of 𝑛 evidences. Eventually, we integrate claim and evidence embeddings into one unified representation via concatenation, followed by a multi-layer perceptron to output the veracity prediction 𝑦ˆ.

h𝑓

=

[h𝑓
𝑐

;

h𝑓
𝑒

]

(15)

𝑦ˆ = Softmax(W𝑓 h𝑓 + b𝑓 )

(16)

2We omit the index subscript of evidences for brevity, as they are all fed into the same networks.

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

Dataset # True # False # Evi. # Spe. # Pub.

Snopes 1164 PolitiFact 1867

3177 29242 N/A 12236 1701 29556 664 4542

Table 1: The statistics of two datasets. The symbol “#” denotes “the number of”. “True” and “False” stand for true claims and false claims, respectively. “Evi.’, ‘Spe.”, and “Pub.” denote evidences, speakers and publishers.

3.2.5 Training Objective. As it is fundamentally a classification task, we utilize the standard cross entropy loss as the objective function, which can be written as:

LΘ (𝑦, 𝑦ˆ) = −(𝑦 log 𝑦ˆ + (1 − 𝑦) log(1 − 𝑦ˆ))

(17)

where 𝑦 ∈ {0, 1} denotes the label of each unverified news.

4 EXPERIMENTS
In this section, we conduct comprehensive experiments to answer the following research questions:
• RQ1: How does GET perform compared to previous fake news detection baselines?
• RQ2: How does the redundant information involved in evidences affect the fake news detection?
• RQ3: How is the performance of different semantic encoders? • RQ4: How does GET perform with different interaction mod-
ules? • RQ5: How does GET perform under different hyperparame-
ter settings?

4.1 Experimental Setup
4.1.1 Datasets. We utilize two widely used datasets to verify our proposed model. The detailed statistics is summarized in Table 1.
• Snopes [29]. Claims and their corresponding labels (𝑡𝑟𝑢𝑒 or 𝑓 𝑎𝑙𝑠𝑒) are collected from the fack-checking website3. Taking each claim as a query, the evidences and their publishers are retrieved via the search engine.
• PolitiFact [34]. Claim-label pairs are collected from another fact-checking website4 about US politics and evidences are obtained in a similar way to that in Snopes. Aside from publisher information, claim promulgators are added into the dataset. Following previous work [30, 31, 37], we merge 𝑡𝑟𝑢𝑒, 𝑚𝑜𝑠𝑡𝑙𝑦 𝑡𝑟𝑢𝑒, ℎ𝑎𝑙 𝑓 𝑡𝑟𝑢𝑒 into the unified class 𝑡𝑟𝑢𝑒 and 𝑓 𝑎𝑙𝑠𝑒, 𝑚𝑜𝑠𝑡𝑙𝑦 𝑓 𝑎𝑙𝑠𝑒, 𝑝𝑎𝑛𝑡𝑠 𝑜𝑛 𝑓 𝑖𝑟𝑒 into 𝑓 𝑎𝑙𝑠𝑒.
4.1.2 Baselines. To demonstrate the effectiveness of our proposed model GET, we compare it with several existing methods, including both pattern- and evidence-based models, the specific description is listed as follows:
Pattern-based methods.
• LSTM [15]. They utilize LSTM to encode the semantics with the news as input and obtain the final representation of claim via the average pooling.
3 https://www.snopes.com/ 4 https://www.politifact.com/

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

Method
LSTM TextCNN
BERT DeClarE
HAN EHIAN MAC CICD
GET

F1-Ma 0.621 0.631 0.621 0.725 0.752 0.784 0.786 0.789 0.800‡

F1-Mi 0.719 0.720 0.716 0.786 0.802 0.828 0.833 0.837 0.846‡

F1-T 0.430 0.450 0.431 0.594 0.636 0.684 0.687 0.691 0.705‡

Snopes P-T R-T 0.484 0.397 0.482 0.430 0.477 0.407 0.610 0.579 0.625 0.647 0.617 0.768 0.700 0.686 0.632 0.775 0.721‡ 0.694

F1-F 0.812 0.812 0.810 0.857 0.868 0.885 0.886 0.893 0.895‡

P-F 0.791 0.799 0.793 0.852 0.876 0.882 0.886 0.890
0.890

R-F 0.837 0.826 0.830 0.863 0.861 0.890 0.887 0.895 0.902‡

F1-Ma 0.606 0.604 0.597 0.653 0.661 0.676 0.672 0.682 0.691‡

F1-Mi 0.609 0.607 0.598 0.652 0.660 0.679 0.673 0.685 0.694‡

F1-T 0.618 0.615 0.608 0.675 0.679 0.689 0.718 0.702 0.723‡

PolitiFact P-T R-T 0.632 0.613 0.630 0.610 0.619 0.599 0.667 0.683 0.676 0.682 0.686 0.693 0.675 0.735 0.689 0.714 0.687 0.764‡

F1-F 0.593 0.592 0.586 0.631 0.643 0.655 0.643 0.657 0.660‡

P-F 0.590 0.591 0.577 0.637 0.650 0.675 0.676 0.691 0.708‡

R-F 0.604 0.604 0.597 0.625
0.637 0.636 0.617 0.629 0.629

Table 2: The model comparison on two datasets Snopes and PolitiFact. “F1-Ma” and “Fi-Mi” denote the metrics F1-Macro and

F1-Micro, respectively. “-T” represents “True News as Positive” and “-F” denotes “Fake news as Positive” in computing the precision and recall values. The best performance is highlighted in boldface. ‡ indicates that the performance improvement is significant with p-value ≤ 0.05.

• TextCNN [40]. They apply a 1D-convolutional network to embed the semantics of claim.
• BERT [9]. They employ BERT to learn the representation of claim. A linear layer is stacked over the special token [CLS] to output the final prediction.
Evidence-based methods.
• DeClarE [30]. They employ BiLSTMs to embed the semantics of evidences and obtain the claim’s representation via average pooling, followed by an attention mechanism performing among claim and each word in evidences to generate the final claim-aware representation.
• HAN [26]. They use GRUs to embed semantics and design two modules named topic coherence and semantic entailment to model the claim-evidence interaction, which are based on sentence-level attention mechanism.
• EHIAN [43]. They utilize self-attention mechanism to learn semantics and concentrate on the important part of evidences for interaction.
• MAC [37]. They introduce a hierarchical attentive framework to model both word- and evidence-level interaction.
• CICD [41]. They introduce individual and collective cognition view-based interaction to explore both local and global opinions towards a claim.
4.1.3 Implementation Details. We introduce the specific settings in our experiments including hyperparameters, training settings, and the experimental environment.
Following previous work [30, 37], we utilize the same data split5 to train and test our model. We also report 5-fold cross validation results, where 4 folds are used for training and the rest one fold is for testing. We utilize Adam optimizer with a learning rate 𝑙𝑟 = 0.0001 and weight decay 𝑑𝑒𝑐𝑎𝑦 = 0.001. The model early stops when F1macro does not increase in 10 epochs and the maximum number of epoch is 100. We set the maximum length of claims and evidences in both datasets as 30 and 100, respectively. The number of evidences 𝑛 = 30 and the batch size is 32. We set the redundancy discarding rate 𝑟 = 0.4, i.e., 𝑘 = 𝑟𝑙𝑒 will be filtered out in a semantic refinement layer, where 𝑙𝑒 is the length of evidence. The number of semantics encoder layer 𝑇𝐸 = 1 and evidence semantics miner layer 𝑇𝑅 = 1.
5 https://github.com/nguyenvo09/EACL2021/tree/main/formatted_data/declare

The number of word-level and document-level attentive readout head as 5 and 2 for Snopes (3 and 1 for PolitiFact), the dimension of publisher and speaker embedding is both 128, following the work [37]. We use the Glove pretrained embedding with the dimension 𝑑 = 300 for all baselines for a fair comparison. We conduct all experiments using PyTorch 1.5.1 on a Linux server equipped with GeForce RTX 3090 GPUs (with 24GB memory each) and AMD EPYC 7742 (256) CPUs.
4.2 Model Comparison (RQ1)
We compare our model GET with eight baselines6, including three pattern-based methods and five evidence-based methods. The overall results are shown in Table 2, from which we have the following observations:
Firstly, our proposed model GET outperforms all existing methods on most of metrics on both two datasets by a significant margin, demonstrating the effectiveness of GET. It is worth noting that GET stands out from the recent three sequential-based baselines (EHIAN, MAC, and CICD) whose performance is close, indicating the positive impact of introducing graph-based models to evidence-based fake news detection. In detail, compared to the strongest baselines CICD on two datasets, GET advances the performance about 1 percent on F1-Macro and F1-Micro, which are the evaluation metrics better reflect the overall detection capability of models. With regard to the more fine-grained evaluation, i.e., ‘True news as Positive’ and ‘Fake news as Positive’, GET also achieve the best results on the F1 score on two datasets, where the F1 score is more representative than Precision and Recall since it takes into account both of them synthetically.
Secondly, compared to the pattern-based methods (i.e., the first three methods in Table 2), evidence-based approaches have a substantial performance improvement. This is probably due to the better generalization of evidence-based methods, where the external information is utilized to probe the claim veracity, avoiding the over-reliance on text patterns. In addition, the performance of BERT is similar to that of other pattern-based approaches. We suspect the reason is probably that claims are short and contain lots of noises (e.g., spelling errors and domain-specific abbreviations),
6As some evidence-based methods do not release codes, we reproduce results carefully following settings reported in their original paper.

Evidence-aware Fake News Detection with Graph Neural Networks

F1-Ma (%) F1-Mi (%) F1-Ma (%) F1-Mi (%)

Glove

81.0 80.0 79.0 78.0 77.0 76.0

Snopes

MAC
85.0 84.0 83.0 82.0 81.0

GET-w/o SSR

70.0 69.0 68.0 67.0 66.0 65.0

PolitiFact

GET
70.0 69.0 68.0 67.0 66.0 65.0

Figure 3: The performance comparison between GET and model variants with different semantic encoders (Glove and MAC) and without structure refinement (GET-w/o SSR).

which are rarely appeared in the pretraining corpus, thus it is hard for BERT to transfer the contextual information learned from the pretrained stage.
Thirdly, among five evidence-based baselines, the performance of DeClarE and HAN is inferior to other three models, which is mainly because they lack exploring the different grain-sized semantics. Specifically, DeClarE only considers word-level semantic interaction and HAN solely relies on document-level representations to model claim-evidence interaction. However, the rest of evidence-based methods all consider multi-level semantics, thus achieving better performance.
4.3 Ablation Study (RQ2, RQ3)
To verify the positive effect of structure refinement for reducing the useless redundancy in evidences, we conduct the ablation study where the structure learning layer is removed and other parts are kept unchanged. We name this model variant as GET-w/o SSR. As shown in Figure 3, we can observe an obvious decline on both datasets regarding the F1-Micro and F1-Macro. This demonstrates the necessity of performing structure refinement on semantic graphs and confirm the effectiveness of our structure learning method. Furthermore, it also indicates that reducing the effect of unimportant information via attention mechanisms will lead to suboptimal results, since they still maintain the noisy semantic structure unchanged [6] (i.e., specifically, all words will participate in the claim-evidence interaction). Therefore, the effect of structure refinement is not overlapped with the attention mechanism, but further goes beyond.
To demonstrate the superiority of the proposed graph-based semantics encoder, we further conduct experiments on two model variants. One is named Glove, where the pretrained word embeddings are directly fed into the attentive readout layer; the other is named MAC, where the semantics encoder is a BiLSTM the same as the baseline [37]. As shown in Figure 3, Glove has the poorest performance since the contextual information is not captured. Moreover, the performance of GET-w/o SSR is superior to that of MAC, indicating that the long-distance structural dependency involved in semantic structure, which is less explored in sequential models, is significant for veracity checking. Note that we choose GET-w/o SSR instead of GET to be compared with MAC fairly, since the only difference between GET-w/o SSR and MAC is the semantics encoder.

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

Dataset Metric DeC GET-DeC EHI GET-EHI

Snopes

F1-Ma F1-Mi F1-T F1-F

0.725 0.786 0.594 0.857

0.761 0.813 0.649 0.873

0.784 0.828 0.684 0.885

0.795 0.841 0.693 0.897

PolitiFact

F1-Ma F1-Mi F1-T F1-F

0.653 0.652 0.675 0.631

0.681 0.685 0.714 0.647

0.676 0.679 0.689 0.655

0.688 0.690 0.713 0.663

Table 3: The performance of GET with different claimevidence interaction modules, compared to their corresponding baselines DeClarE (DeC) and EHIAN (EHI). The superior results are highlighted in boldface.

4.4 GET with Different Claim-evidence
Interaction Modules (RQ4)
The GET mainly consists of two parts, i.e., graph-based semantic structure mining and attentive graph readout, where the refined semantic structure is obtained in the former stage and the claimevidence interactions are captured in the latter. As we have mentioned in Section 3.2.4, the semantic structure mining framework can be adaptively connected with any interaction module. Therefore, to further verify the positive impact of graph-based structure mining, we replace the concatenation attention mechanism in our base model with different interaction modules used in existing work. In detail, we choose two modules in representative work: one is the word-level attention mechanism employed in DeClarE [30], the other is the self-attention mechanism utilized to obtain global claim-evidence interactions in EHIAN [43]. We name such two model variants as GET-DeC and GET-EHI, respectively. Thereafter, we can compare them with DeClarE (DeC) and EHIAN (EHI) to see whether the optimized semantic structure can boost model performance with different downstream interaction modules.
The experimental results are shown in Table 3. It is obvious that GET-DeC and GET-EHI both surpass their corresponding competitors, which indicates the effectiveness of our unified graph-based semantic structure mining framework, with being agnostic to the downstream interaction modules. In other words, we can employ such graph-based framework in any evidence-based fake news detection model in a plug-in-play manner, obtaining the fine-grained representations on optimized semantic structures and advancing the model performance.
4.5 Sensitivity Analysis (RQ5)
In this section, we conduct experiments to analyse the performance fluctuation of GET with respect to different values of key hyperparameters.
4.5.1 The number of semantics encoder layer for claims 𝑇𝐸 . This hyperparameter decides propagation field on graphs, since stacking 𝑇𝐸 -layer encoder (GGNN) makes each node aggregate information within 𝑇𝐸 -hop neighborhood. We report the model performance when 𝑇𝐸 = 0, 1, 2, 3 (See Figure 4) and summarize the observations as follows:

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France

81.0 80.0 79.0 0

F1-Ma (%)

F1-Mi (%)

85.0 71.0

70.0 84.0 69.0

1

2

Snopes

68.0 3 83.0 0

1

2

PolitiFact

70.0 69.0 68.0 67.0 3

Figure 4: The influence of different semantics encoder layers 𝑇𝐸 for claims on model performance.

82.0

F1-Ma (%)

F1-Mi (%)

85.0 72.0

70.0

81.0

84.0 70.0

68.0

80.0

83.0 68.0

66.0

79.0 0.0 0.1 0.2 0.3 0.4 0.5 0.6 82.0 Snopes

0.0 0.1 0.2 0.3 0.4 0.5 0.6 64.0 PolitiFact

Figure 5: The influence of different discarding rates 𝑟 on model performance.

There is no drastic rise and fall when 𝑇𝐸 is changed from 0 to 3. Specifically, the model with 𝑇𝐸 = 1 slightly outperforms its counterparts. We suspect that the close results are due to the short length of claims (the average lengths of claim are about 6 and 8 in Snopes and PolitiFact, respectively), where the semantic structure can be well-explored merely via 1-hop propagation.
Only one obvious decline is observed between 𝑇𝐸 = 2 and 𝑇𝐸 = 3, which is probably caused by the inappropriate propagation field. When the layer number is 3, each node on graphs aggregate information from 3-hop neighborhood, which may cover all nodes since the claims are short, thus failing to model the local semantic structure and leading to the poor performance.
4.5.2 The discarding rate 𝑟 . This rate is also an important hyperparameter in our proposed model GET. It decides the proportion of redundant information in evidences we filter out. We test the model with 𝑟 ranging from 0 to 0.6 (See Figure 5) and have the following observations:
When 𝑟 = 0, the model is the same as GET-w/o SSR in the ablation study, where structure refinement layer is removed and no words are dropped. We can see that the performance is not satisfactory since redundant information is preserved that may mislead the model.
The performance grows with 𝑟 increasing and peaks at the best when 𝑟 = 0.4, which indicates that reducing redundant information plays a positive role in improving the model performance. When 𝑟 is larger than 0.6, a obvious performance decline can be seen.

82.0 81.0 80.0 79.0 0

F1-Ma (%) 85.0 72.0

F1-Mi (%)

1

2

Snopes

84.0 70.0
83.0 68.0
3 82.0 0

1

2

PolitiFact

70.0 68.0 66.0 3

Figure 6: The influence of different evidence semantics miner layers 𝑇𝑅 on model performance.

The probable reason is that some useful information for veracity prediction is mistakenly discarded, so that the model fails to capture the rich semantics in evidences, as the 𝑟 is too large.
4.5.3 The number of ESM layer 𝑇𝑅. It is a key hyperparameter that controls the information propagation field on graphs and the extent of structure refinement. We observe some phenomena when 𝑇𝑅 increases from 0 to 3 (See Figure 6):
The performance is first improved from 𝑇𝑅 = 0 to 𝑇𝑅 = 1. Note that when 𝑇𝑅 = 0, the model downgrades into the one with only a semantics encoder layer. The inferior performance is mainly due to two aspects: 1) It is unable to capture the high-order semantics of long evidences since only features from 1-hop neighborhood are aggregated. 2) Moreover, no redundancy reduction may affect other claim-relevant useful information, since they are fused via neighborhood propagation. Therefore, these drawbacks, in turn, demonstrate the significance of high-order semantics and structure refinement.
A moderate fall of performance can be seen when 𝑇𝑅 ranges from 1 to 3. This is probably because the networks suffer from the over-smoothing problem, which is common in GNNs [21]. Besides, the information is overly discarded so that the evidence semantics is not well modeled, which is also a main reason.
5 CONCLUSION
In this paper, we have proposed a unified graph-based fake news detection model named GET to explore the complex semantic structure. Based on constructed claim and evidence graphs, the longdistance semantic dependency is captured via the information propagation. Moreover, a simple and effective structure learning module is introduced to reduce the redundant information, obtaining fine-grained semantics that are more beneficial for the downstream claim-evidence interaction. We have also validated the performance of GET with different interaction methods, where results demonstrate its ability of acting as a plug-in-play module to boost the performance of other fake news detection models.
ACKNOWLEDGMENTS
This work is supported by National Natural Science Foundation of China (U19B2038, 61772528, 62141608).

Evidence-aware Fake News Detection with Graph Neural Networks
REFERENCES
[1] Oluwaseun Ajao, Deepayan Bhowmik, and Shahrzad Zargari. 2019. Sentiment Aware Fake News Detection on Online Social Networks. In ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). 2507–2511.
[2] Hunt Allcott and Matthew Gentzkow. 2017. Social Media and Fake News in the 2016 Election. CSN: Politics (Topic) (2017).
[3] Adrien Benamira, Benjamin Devillers, Etienne Lesot, Ayush Ray, Manal Saadi, and Fragkiskos D. Malliaros. 2019. Semi-Supervised Learning and Graph Neural Networks for Fake News Detection. 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM) (2019), 568–569.
[4] Shantanu Chandra, Pushkar Mishra, Helen Yannakoudakis, and Ekaterina Shutova. 2020. Graph-based Modeling of Online Communities for Fake News Detection. ArXiv abs/2008.06274 (2020).
[5] Tianwen Chen and Raymond Chi-Wing Wong. 2020. Handling Information Loss of Graph Neural Networks for Session-based Recommendation. Proceedings of
the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (2020). [6] Yu Chen, Lingfei Wu, and Mohammed Zaki. 2020. Iterative Deep Graph Learning for Graph Neural Networks: Better and Robust Node Embeddings. In NIPS. 19314– 19326. [7] Luca Cosmo, Anees Kazi, Seyed-Ahmad Ahmadi, Nassir Navab, and Michael M. Bronstein. 2020. Latent Patient Network Learning for Automatic Diagnosis. (2020). [8] Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering. In NIPS. [9] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In NAACL. [10] Luca Franceschi, Paolo Frasconi, Saverio Salzo, Riccardo Grazzi, and Massimiliano Pontil. 2018. Bilevel Programming for Hyperparameter Optimization and MetaLearning. In Proceedings of the 35th International Conference on Machine Learning. 1568–1577. [11] Luca Franceschi, Mathias Niepert, Massimiliano Pontil, and Xiao He. 2019. Learning Discrete Structures for Graph Neural Networks. In Proceedings of the 36th International Conference on Machine Learning. 1972–1982. [12] Hongyang Gao and Shuiwang Ji. 2019. Graph U-Nets. In Proceedings of the 36th International Conference on Machine Learning. [13] Anastasia Giachanou, Paolo Rosso, and Fabio Crestani. 2019. Leveraging Emotional Signals for Credibility Detection. In Proceedings of the 42nd International
ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’19). 877–880. [14] William L. Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive Representation Learning on Large Graphs. In NIPS. [15] Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long Short-Term Memory. Neural Computation 9 (1997), 1735–1780. [16] Bo Jiang, Ziyan Zhang, Doudou Lin, Jin Tang, and Bin Luo. 2019. Semi-Supervised Learning With Graph Learning-Convolutional Networks. In 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 11305–11312. [17] Wei Jin, Yao Ma, Xiaorui Liu, Xianfeng Tang, Suhang Wang, and Jiliang Tang. 2020. Graph Structure Learning for Robust Graph Neural Networks. Proceedings
of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (2020). [18] Yiqiao Jin, Xiting Wang, Ruichao Yang, Yizhou Sun, Wei Wang, Hao Liao, and Xing Xie. 2021. Towards Fine-Grained Reasoning for Fake News Detection. ArXiv abs/2110.15064 (2021). [19] Thomas Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. ArXiv abs/1609.02907 (2017). [20] Junhyun Lee, Inyeop Lee, and Jaewoo Kang. 2019. Self-attention graph pooling. In 36th International Conference on Machine Learning, ICML 2019. 6661–6670. [21] Qimai Li, Zhichao Han, and Xiao-Ming Wu. 2018. Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning. ArXiv abs/1801.07606 (2018). [22] Ruifan Li, Hao Chen, Fangxiang Feng, Zhanyu Ma, Xiaojie Wang, and Eduard H. Hovy. 2021. Dual Graph Convolutional Networks for Aspect-based Sentiment Analysis. In ACL/IJCNLP. [23] Ruoyu Li, Sheng Wang, Feiyun Zhu, and Junzhou Huang. 2018. Adaptive Graph Convolutional Neural Networks. ArXiv abs/1801.03226 (2018). [24] Qiang Liu, Feng Yu, Shu Wu, and Liang Wang. 2018. Mining significant microblogs for misinformation identification: an attention-based approach. ACM Transactions on Intelligent Systems and Technology (TIST) 9, 5 (2018), 1–20. [25] Zhenghao Liu, Chenyan Xiong, Maosong Sun, and Zhiyuan Liu. 2020. Finegrained Fact Verification with Kernel Graph Attention Network. In ACL. [26] Jing Ma, Wei Gao, Shafiq Joty, and Kam-Fai Wong. 2019. Sentence-Level Evidence Embedding for Claim Verification with Hierarchical Attention Networks. In ACL. 2561–2571.

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France
[27] Salman Bin Naeem and Rubina Bhatti. 2020. The Covid-19 ‘infodemic’: a new front for information professionals. Health Information and Libraries Journal (2020).
[28] Kashyap Popat, Subhabrata Mukherjee, Jannik Strötgen, and Gerhard Weikum. 2016. Credibility Assessment of Textual Claims on the Web. In Proceedings of the
25th ACM International on Conference on Information and Knowledge Management (CIKM ’16). 2173–2178. [29] Kashyap Popat, Subhabrata Mukherjee, Jannik Strötgen, and Gerhard Weikum. 2017. Where the Truth Lies: Explaining the Credibility of Emerging Claims on the Web and Social Media. Proceedings of the 26th International Conference on World Wide Web Companion (2017). [30] Kashyap Popat, Subhabrata Mukherjee, Andrew Yates, and Gerhard Weikum. 2018. DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep Learning. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. 22–32. [31] Hannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana Volkova, and Yejin Choi. 2017. Truth of Varying Shades: Analyzing Language in Fake News and Political Fact-Checking. In EMNLP. [32] Qiang Sheng, Xueyao Zhang, Juan Cao, and Lei Zhong. 2021. Integrating Patternand Fact-based Fake News Detection via Model Preference Learning. ArXiv abs/2109.11333 (2021). [33] Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio’, and Yoshua Bengio. 2018. Graph Attention Networks. ArXiv abs/1710.10903 (2018). [34] Andreas Vlachos and Sebastian Riedel. 2014. Fact Checking: Task definition and dataset construction. In Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science. 18–22. [35] Andreas Vlachos and Sebastian Riedel. 2015. Identification and Verification of Simple Claims about Statistical Properties. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. 2596–2601. [36] Nguyen Vo and Kyumin Lee. 2018. The Rise of Guardians: Fact-Checking URL Recommendation to Combat Fake News. In The 41st International ACM SIGIR Conference on Research Development in Information Retrieval (SIGIR ’18). 275–284. [37] Nguyen Vo and Kyumin Lee. 2021. Hierarchical Multi-head Attentive Network for Evidence-aware Fake News Detection. In Proceedings of the 16th Conference
of the European Chapter of the Association for Computational Linguistics: Main Volume. 965–975. [38] Svitlana Volkova, Kyle Shaffer, Jin Yea Jang, and Nathan Hodas. 2017. Separating Facts from Fiction: Linguistic Models to Classify Suspicious and Trusted News Posts on Twitter. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). 647–653. [39] Kai Wang, Weizhou Shen, Yunyi Yang, Xiaojun Quan, and Rui Wang. 2020. Relational Graph Attention Network for Aspect-based Sentiment Analysis. In ACL. [40] William Yang Wang. 2017. "Liar, Liar Pants on Fire": A New Benchmark Dataset for Fake News Detection. In ACL. [41] Lianwei Wu, Yuan Rao, Yuqian Lan, Ling Sun, and Zhaoyin Qi. 2021. Unified Dual-view Cognitive Model for Interpretable Claim Verification. arXiv preprint arXiv:2105.09567 (2021). [42] Lianwei Wu, Yuan Rao, Ling Sun, and Wangbo He. 2021. Evidence Inference Networks for Interpretable Claim Verification. Proceedings of the AAAI Conference on Artificial Intelligence (2021), 14058–14066. [43] Lianwei Wu, Yuan Rao, Xiong Yang, Wanzhen Wang, and Ambreen Nazir. 2020. Evidence-Aware Hierarchical Interactive Attention Networks for Explainable Claim Verification.. In IJCAI. 1388–1394. [44] Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, and Tieniu Tan. 2019. Session-based Recommendation with Graph Neural Networks. In AAAI. [45] Xuan-Wei Wu, Lingxiao Zhao, and Leman Akoglu. 2018. A Quest for Structure: Jointly Learning the Graph Structure and Semi-Supervised Classification. Pro-
ceedings of the 27th ACM International Conference on Information and Knowledge Management (2018). [46] Liang Yang, Zesheng Kang, Xiaochun Cao, Di Jin, Bo Yang, and Yuanfang Guo. 2019. Topology Optimization based Graph Convolutional Network. In IJCAI. [47] Liang Yao, Chengsheng Mao, and Yuan Luo. 2019. Graph Convolutional Networks for Text Classification. ArXiv abs/1809.05679 (2019). [48] Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and Jure Leskovec. 2018. Hierarchical graph representation learning with differentiable pooling. In NIPS. 4800–4810. [49] Feng Yu, Q. Liu, Shu Wu, Liang Wang, and Tieniu Tan. 2017. A Convolutional Approach for Misinformation Identification. In IJCAI. [50] Xueli Yu, Weizhi Xu, Zeyu Cui, Shu Wu, and Liang Wang. 2021. Graph-based Hierarchical Relevance Matching Signals for Ad-hoc Retrieval. Proceedings of the Web Conference 2021 (2021). [51] Jinghao Zhang, Yanqiao Zhu, Qiang Liu, Shu Wu, Shuhui Wang, and Liang Wang. 2021. Mining Latent Structures for Multimedia Recommendation. Proceedings of the 29th ACM International Conference on Multimedia (2021). [52] Xueyao Zhang, Juan Cao, Xirong Li, Qiang Sheng, Lei Zhong, and Kai Shu. 2021. Mining Dual Emotion for Fake News Detection (WWW ’21). 3465–3476.

WWW ’22, April 25–29, 2022, Virtual Event, Lyon, France
[53] Yingxue Zhang, Soumyasundar Pal, Mark J. Coates, and Deniz Üstebay. 2019. Bayesian graph convolutional neural networks for semi-supervised classification. In AAAI.
[54] Yufeng Zhang, Xueli Yu, Zeyu Cui, Shu Wu, Zhongzhen Wen, and Liang Wang. 2020. Every Document Owns Its Structure: Inductive Text Classification via Graph Neural Networks. ArXiv abs/2004.13826 (2020).
[55] Yufeng Zhang, Jinghao Zhang, Zeyu Cui, Shu Wu, and Liang Wang. 2021. A Graph-based Relevance Matching Model for Ad-hoc Retrieval. In AAAI.
[56] Wanjun Zhong, Jingjing Xu, Duyu Tang, Zenan Xu, Nan Duan, M. Zhou, Jiahai Wang, and Jian Yin. 2020. Reasoning Over Semantic-Level Graph for Fact Checking. In ACL.
[57] Jie Zhou, Xu Han, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li, and Maosong Sun. 2019. GEAR: Graph-based Evidence Aggregating and Reasoning for Fact Verification. In ACL.
[58] Yanqiao Zhu, Weizhi Xu, Jinghao Zhang, Qiang Liu, Shu Wu, and Liang Wang. 2021. Deep Graph Structure Learning for Robust Representations: A Survey. CoRR (2021).
A VISUALIZATION OF REFINEMENT
In order to better understand what redundant information is discarded by semantic structure refinement, we visualize examples in both datasets depicted respectively by Figure 7 and Figure 8, where the discarded words are highlighted in grey. It is indicated that most dropped words are adverbs, conjunctions, and pronouns which have less valuable information or are relatively unrelated to the news. For instance, words like ’it’ and ’by’ occur frequently but contribute little to the semantic of text. And in the first example in PoltiFact, several nouns like ’illoinois state senate’ have weak connection with its topic and may interfere models’ judgement. Therefore, the refinement layer can effectively distill important information and get rid of redundant noises.

Figure 7: Visualization of discarded words in the examples in Snopes Dataset. [True/False] indicates veracity of claims.
Figure 8: Visualization of discarded words in the examples in PolitiFact Dataset. [True/False] indicates veracity of claims.

