Double or Nothing: Multiplicative Incentive Mechanisms for Crowdsourcing

Nihar B. Shah Department of EECS University of California, Berkeley nihar@eecs.berkeley.edu

Dengyong Zhou Machine Learning Department
Microsoft Research dengyong.zhou@microsoft.com

arXiv:1408.1387v3 [cs.GT] 16 Dec 2015

Abstract
Crowdsourcing has gained immense popularity in machine learning applications for obtaining large amounts of labeled data. Crowdsourcing is cheap and fast, but suffers from the problem of low-quality data. To address this fundamental challenge in crowdsourcing, we propose a simple payment mechanism to incentivize workers to answer only the questions that they are sure of and skip the rest. We show that surprisingly, under a mild and natural “no-free-lunch” requirement, this mechanism is the one and only incentive-compatible payment mechanism possible. We also show that among all possible incentivecompatible mechanisms (that may or may not satisfy no-free-lunch), our mechanism makes the smallest possible payment to spammers. We further extend our results to a more general setting in which workers are required to provide a quantized conﬁdence for each question. Interestingly, this unique mechanism takes a “multiplicative” form. The simplicity of the mechanism is an added beneﬁt. In preliminary experiments involving over 900 worker-task pairs, we observe a signiﬁcant drop in the error rates under this unique mechanism for the same or lower monetary expenditure.
1 Introduction
Complex machine learning tools such as deep learning are gaining increasing popularity and are being applied to a wide variety of problems. These tools require large amounts of labeled data [HDY+12, RYZ+10, DDS+09, CBW+10]. These large labeling tasks are being performed by coordinating crowds of semi-skilled workers through the Internet. This is known as crowdsourcing. Generating large labeled data sets through crowdsourcing is inexpensive and fast as compared to employing experts. Furthermore, given the current platforms for crowdsourcing such as Amazon Mechanical Turk and many others, the initial overhead of setting up a crowdsourcing task is minimal. Crowdsourcing as a means of collecting labeled training data has now become indispensable to the engineering of intelligent systems. The crowdsourcing of labels is also often used to supplement automated algorithms, to perform the tasks that are too difﬁcult to accomplish by machines alone [KDC+11, LRR11, BLM+10, VAMM+08, FKK+11].
Most workers in crowdsourcing are not experts. As a consequence, labels obtained from crowdsourcing typically have a signiﬁcant amount of error [KKKMF11, VdVE11, WLC+10]. It is not surprising that there is signiﬁcant emphasis on having higher quality labeled data for machine learning algorithms, since a higher amount of noise implies requirement of more labels for obtaining the same accuracy in practice. Moreover, several algorithms and settings are not very tolerant of data that is noisy [LS10, HY10, MS13, BP09]; for instance, [LS10] conclude that “a range of different types of boosting algorithms that optimize a convex potential function satisfying mild conditions cannot tolerate random classiﬁcation noise.” Recent efforts have focused on developing statistical techniques to post-process the noisy labels in order to improve its quality (e.g., [RYZ+10, ZPBM12, WJ11, CBCTH13, DS79, KOS11, LPI12, ZCZJ14, IPSW14]). However,
1

a Is this the Golden Gate Bridge?
Yes No

b Is this the Golden Gate Bridge?
Yes No I’m not sure

c Is this the Golden Gate Bridge?
Yes Moderately sure No Moderately sure
I’m not sure

Absolutely sure Absolutely sure

Figure 1: Different interfaces for a task that requires the worker to answer the question “Is this the Golden Gate Bridge?”: (a) the conventional interface; (b) with an option to skip; (c) with multiple conﬁdence levels.
when the inputs to these algorithms are very erroneous, it is difﬁcult to guarantee that the processed labels will be reliable enough for subsequent use by machine learning or other applications. In order to avoid “garbage in, garbage out”, we take a complementary approach to this problem: cleaning the data at the time of collection.
We consider crowdsourcing settings where the workers are paid for their services, such as in the popular crowdsourcing platforms of Amazon Mechanical Turk (mturk.com), Crowdﬂower (crowdflower. com) and other commercial platforms, as well as internal crowdsourcing platforms of companies such as Google, Facebook and Microsoft. These commercial platforms have gained substantial popularity due to their support for a diverse range of tasks for machine learning labeling, varying from image annotation and text recognition to speech captioning and machine translation. We consider problems that are objective in nature, that is, have a deﬁnite answer. Figure 1a depicts an example of such a question where the worker is shown a set of images, and for each image, the worker is required to identify if the image depicts the Golden Gate Bridge.
Our approach builds on the simple insight that in typical crowdsourcing setups, workers are simply paid in proportion to the amount of tasks they complete. As a result, workers attempt to answer questions that they are not sure of, thereby increasing the error rate of the labels. For the questions that a worker is not sure of, her answers could be very unreliable [WLC+10, KKKMF11, VdVE11, JSV14]. To ensure acquisition of only high-quality labels, we wish to encourage the worker to skip the questions about which she is unsure, for instance, by providing an explicit “I’m not sure” option for every question (see Figure 1b). Given this additional option, one must also ensure that the worker is indeed incentivized to skip the questions that she is not conﬁdent about. In a more general form, we consider eliciting the conﬁdence of the worker for each question at multiple levels. For instance, in addition to “I’m not sure”, we may also provide options like “absolutely sure”, and “moderately sure” (see Figure 1c). The goal is to design payment mechanisms that incentivize the worker to attempt only those questions for which they are conﬁdent enough, or alternatively, report their conﬁdences truthfully. As we will see later, this signiﬁcantly improves the aggregate quality of the labels that are input to the machine learning algorithms. We will term any payment mechanism that incentivizes the worker to do so as “incentive compatible”.
In addition to incentive compatibility, preventing spammers is another desirable requirement from incentive mechanisms in crowdsourcing. Spammers are workers who answer randomly without regard to the question being asked, in the hope of earning some free money, and are known to exist in large numbers on crowdsourcing platforms [WLC+10, Boh11, KKKMF11, VdVE11]. The presence of spammers can signif-
2

icantly affect the performance of any machine learning algorithm that is trained on this data. It is thus of interest to deter spammers by paying them as low as possible. An intuitive objective, to this end, is to ensure a minimum possible expenditure on spammers who answer randomly. For instance, in a task with binarychoice questions, a spammer is expected to have half of the attempted answers incorrect; one may thus wish to set the payment to its minimum possible value if half or more of the attempted answers are wrong. In this paper, however, we impose strictly and signiﬁcantly weaker requirement, and then show that there is one and only one incentive-compatible mechanism that can satisfy this weak requirement. Our requirement is referred to as the “no-free-lunch” axiom. In the skip-based setting, it says that if all the questions attempted by the worker are answered incorrectly, then the payment must be the minimum possible. The no-free-lunch axiom for the general conﬁdence-based setting is even weaker: if the worker indicates the highest conﬁdence level for all the questions she attempts in the gold standard, and furthermore if all these responses are incorrect, then the payment must be the minimum possible. We term this condition the “no-free-lunch” axiom. In the general conﬁdence-based setting, we want to make the minimum possible payment if the worker indicates the highest conﬁdence level for all the questions she attempts and if all these responses are incorrect.
In order to test whether our mechanism is practically viable, and to assess the quality of the ﬁnal labels obtained, we conducted experiments on the Amazon Mechanical Turk crowdsourcing platform. In our preliminary experiments that involved several hundred workers, we found that the quality of data consistently improved by use of our schemes as compared to the standard settings, often by two-fold or higher, with the total monetary expenditure being the same or lower as compared to the conventional baseline.
Summary of Contributions. We propose a payment mechanism for the aforementioned setting (“incentive compatibility” plus “no-free-lunch”), and show that surprisingly, this is the only possible mechanism. We also show that additionally, our mechanism makes the smallest possible payment to spammers among all possible incentive compatible mechanisms that may or may not satisfy the no-free-lunch axiom. Interestingly, our payment mechanism takes a multiplicative form: the evaluation of the worker’s response to each question is a certain score, and the ﬁnal payment is a product of these scores. This mechanism has additional appealing features in that it is simple to compute, and is also simple to explain to the workers. Our mechanism is applicable to any type of objective questions, including multiple choice annotation questions, transcription tasks, etc. In preliminary experiments on Amazon Mechanical Turk involving over 900 worker-task pairs, the quality of data improved signiﬁcantly under our unique mechanism, with the total monetary expenditure being the same or lower as compared to the conventional baseline.
Related Literature. The framework of “strictly proper scoring rules” [Bri50, Sav71, GR07, LS09] provides a general theory for eliciting information for settings where this information can subsequently be veriﬁed by the mechanism designer, for example, by observing the true value some time in the future. In our work, this veriﬁcation is performed via the presence of some “gold standard” questions in the task. Consequently, our mechanisms can also be called “strictly proper scoring rules”. It is important to note that the framework of strictly proper scoring rules, however, provides a large collection of possible mechanisms and does not guide the choice of a speciﬁc mechanism from this collection [GR07]. In this work, we show that for the crowdsourcing setups considered, under a very mild “no-free-lunch” condition, the mechanism proposed in this paper is the one and only strictly proper scoring rule.
Interestingly, proper scoring rules have another interesting connection with machine learning techniques: to quote [BSS05], “proper scoring rules comprise most loss functions currently in use: log-loss, squared error loss, boosting loss, and as limiting cases cost-weighted misclassiﬁcation losses.” The present paper does not investigate this aspect of proper scoring rules, and we refer the reader to [BH07, MWB07, BSS05] for more details.
3

The design of statistical inference algorithms for denoising the data obtained from workers is an active topic of research [RYZ+10, ZPBM12, WJ11, CBCTH13, KHH12, DS79, KOS11, LPI12, ZCZJ14, VVV14, IPSW14]. In addition, several machine learning algorithms accommodating errors in the data have also been designed [AL88, CDGL01, LLYL04, CWZ04]. These algorithms are typically oblivious to the elicitation procedure. Our work nicely complements this line of research in that these inference algorithms may now additionally employ the higher quality data and the speciﬁc structure of the elicited data for an improved denoising efﬁciency.
Another relevant problem in crowdourcing is that of choosing which workers to hire or efﬁciently matching workers to tasks, and such problems are studied in [YKL11, HJV13, ZCL14, AGN14] under different contexts. Our work assumes that a worker is already matched, and focuses on incentivizing that worker to respond in a certain manner. A recent line of work has focussed on elicitation of data from multiple agents in order to perform certain speciﬁc estimation tasks [FSW07, DFP08, CDP15]. In contrast, our goal is to ensure that workers censor their own low-quality (raw) data, without restricting our attention to any speciﬁc downstream algorithm or task.
Organization. The organization of this paper is as follows. We present the formal problem setting in Section 2. In Section 3 we consider the skip-based setting: We present our proposed mechanism and show that it is the only mechanism which satisﬁes the requirements discussed above. In Section 4, we then consider the more general setting of eliciting a quantized value of the worker’s conﬁdence. We construct a mechanism for this setting, which also takes a multiplicative form, and prove its uniqueness. In Section 5 we prove that imposing a requirement that is only slightly stronger than our proposed no-free-lunch axiom leads to impossibility results. In Section 6 we present synthetic simulations and real-world experiments on Amazon Mechanical Turk to evaluate the potential of our setting and algorithm to work in practice. We conclude the paper with a discussion on the various modeling choices, future work, and concluding remarks in Section 7.
The paper contains three appendices. In Appendix A we prove all theoretical results whose proofs are not presented in the main text. We provide more details of the experiments in Appendix B. In Appendix C we extend our results to a setting where workers aim to maximize the expected value of some “utility” of their payments.
2 Setting and Notation
In the crowdsourcing setting that we consider, one or more workers perform a task, where a task consists of multiple questions. The questions are objective, by which we mean, each question has precisely one correct answer. Examples of objective questions include multiple-choice classiﬁcation questions such as Figure 1, questions on transcribing text from audio or images, etc.
For any possible answer to any question, we deﬁne the worker’s conﬁdence about an answer as the probability, according to her belief, of this answer being correct. In other words, one can assume that the worker has (in her mind) a probability distribution over all possible answers to a question, and the conﬁdence for an answer is the probability of that answer being correct. As a shorthand, we also deﬁne the conﬁdence about a question as the conﬁdence for the answer that the worker is most conﬁdent about for that question. We assume that the worker’s conﬁdences for different questions are independent. Our goal is that for every question, the worker should be incentivized to skip if her conﬁdence for that question is below a certain predeﬁned threshold, otherwise select the answer that she is most conﬁdent about, and if asked, also indicate a correct (quantized) value of her conﬁdence for the answer.
Speciﬁcally, we consider two settings:
4

• Skip-based. For each question, the worker can either choose to ‘skip’ the question or provide an answer (Figure 1b).
• Conﬁdence-based. For each question, the worker can either ‘skip’ the question or provide an answer, and in the latter case, indicate her conﬁdence for this answer as a number in {1, . . . , L} (Figure 1c). We term this indicated conﬁdence as the ‘conﬁdence-level’. Here, L represents the highest conﬁdence-level, and ‘skip’ is considered to be a conﬁdence-level of 0. 1
One can see from the aforementioned deﬁnition that the conﬁdence-based setting is a generalization of the skip-based setting (the skip-based setting corresponds to L = 1). The goal is to ensure that for a given set of intervals that partition [0, 1], for every question the worker is incentivized to indicate ‘skip’ or choose the appropriate conﬁdence-level when her conﬁdence for that question falls in the corresponding interval. The choice of these intervals will be deﬁned subsequently in the skip-based and conﬁdence-based sections (Section 3 and Section 4) respectively.
Let N denote the total number of questions in the task. Among these questions, we assume the existence of some “gold standard” questions, that is, a set of questions whose answers are known to the requester. Let G (1 ≤ G ≤ N ) denote the number of gold standard questions. The G gold standard questions are assumed to be distributed uniformly at random in the pool of N questions (of course, the worker does not know which G of the N questions form the gold standard). The payment to a worker for a task is computed after receiving her responses to all the questions in the task. The payment is based on the worker’s performance on the gold standard questions. Since the payment is based on known answers, the payments to different workers do not depend on each other, thereby allowing us to consider the presence of only one worker without any loss in generality.
We will employ the following standard notation. For any positive integer K, the set {1, . . . , K} is denoted by [K]. The indicator function is denoted by 1, i.e., 1{z} = 1 if z is true, and 0 otherwise.
Let x1, . . . , xG denote the evaluations of the answers that the worker gives to the G gold standard questions, and let f denote the scoring rule, i.e., a function that determines the payment to the worker based on these evaluations x1, . . . , xG.
In the skip-based setting, xi ∈ {−1, 0, +1} for all i ∈ [G]. Here, “0” denotes that the worker skipped the question, “−1” denotes that the worker attempted to answer the question and that answer was incorrect, and “+1” denotes that the worker attempted to answer the question and that answer was correct. The payment function is f : {−1, 0, +1}G → R.
In the conﬁdence-based setting, xi ∈ {−L, . . . , +L} for all i ∈ [G]. Here, we set xi = 0 if the worker skipped the question, and for l ∈ {1, . . . , L}, we set xi = l if the question was answered correctly with conﬁdence l and xi = −l if the question was answered incorrectly with conﬁdence l. The function f : {−L, . . . , +L}G → R speciﬁes the payment to be made to the worker.
The payment is further associated to two parameters, µmax and µmin. The parameter µmax denotes the budget, i.e., the maximum amount that is paid to any individual worker for this task:
max f (x1, . . . , xG) = µmax.
x1,...,xG
The amount µmax is thus the amount of compensation paid to a perfect worker for her work. Further, one may often also have the requirement of paying a certain minimum amount to any worker. The parameter µmin (≤ µmax) denotes this minimum payment: the payment function must also satisfy
min f (x1, . . . , xG) ≥ µmin.
x1,...,xG
1When the task is presented to the workers, the word ‘skip’ or the numbers {1, . . . , L} are replaced by more comprehensible phrases such as “I don’t know”, “moderately sure”, “absolutely sure”, etc.
5

For instance, crowdsourcing platforms today allow payments to workers, but do not allow imposing penal-

ties: this condition gives µmin = 0. We assume that the worker attempts to maximize her overall expected payment. In what follows, the

expression ‘the worker’s expected payment’ will refer to the expected payment from the worker’s point of

view, and the expectation will be taken with respect to the worker’s conﬁdences about her answers and the

uniformly random choice of the G gold standard questions among the N questions in the task. For any

question i ∈ [N ], suppose the worker indicates the conﬁdence-level yi ∈ {0, . . . , L}. Further, for every question i ∈ [N ] such that yi = 0, let pi be the conﬁdence of the worker for the answer she has selected for question i, and for every question i ∈ [N ] such that yi = 0, let pi ∈ (0, 1) be any arbitrary value. Let E = ( 1, . . . , G) ∈ {−1, 1}G. Then from the worker’s perspective, the expected payment for the selected
answers and conﬁdence-levels is

1

G
1+ i

1− i

N

f ( 1yj1 , . . . , GyjG ) (pji ) 2 (1 − pji ) 2 .

G (j1,...,jG) E∈{−1,1}G

i=1

⊆{1,...,N }

In the expression above, the outermost summation corresponds to the expectation with respect to the randomness arising from the unknown positions of the gold standard questions. The inner summation corresponds to the expectation with respect to the worker’s beliefs about the correctness of her responses.
A payment function f is called a incentive compatible if the expected payment of the worker under this payment function is strictly maximized when the worker answers in the manner desired. The speciﬁc requirements of the skip-based and the conﬁdence-based settings are discussed subsequently in their respective sections. We begin with the skip-based setting.

3 Skip-based Setting
In this section, we consider the setting where for every question, the worker can choose to either answer the question or to skip it; no additional information is asked from the worker. See Figure 1b for an illustration.

3.1 Setting

Let T ∈ (0, 1) be a predeﬁned value. The goal is to design payment mechanisms that incentivize the worker to skip the questions for which her conﬁdence is lower than T , and answer those for which her conﬁdence is higher than T . 2 Moreover, for the questions that she attempts to answer, she must be incentivized to select the answer that she believes is most likely to be correct. The value of T is chosen apriori based on factors such as budget constraints or the targeted quality of labels. The value of T may also depend on the choice of the algorithm that will subsequently be employed to aggregate the answers provided by multiple workers. In this paper, we will assume that the value of the threshold T is already speciﬁed to us.
We impose the following simple and natural requirement:

Axiom 1 (No-free-lunch Axiom) If all the answers attempted by the worker in the gold standard are

wrong, then the payment is the minimum possible. More formally, f (x1, . . . , xG) = µmin for every evalua-

tion (x1, . . . , xG) such that 0 <

G i=1

1{xi

=

0}

=

G i=1

1{xi

=

−1}.

One may expect a payment mechanism to impose the restriction of minimum payment to spammers who answer randomly. For instance, in a task with binary-choice questions, a spammer is expected to have 50% of the attempted answers incorrect; one may thus wish to set a the minimum possible payment if 50% or

more of the attempted answers were incorrect. The no-free-lunch axiom which we impose is however a signiﬁcantly weaker condition, mandating minimum payment if all attempted answers are incorrect.

2In the event that the conﬁdence about a question is exactly equal to T , the worker may choose to answer or skip.

6

3.2 Payment Mechanism

We now present our proposed payment mechanism in Algorithm 1. Algorithm 1: Incentive mechanism for skip-based setting • Inputs:

Threshold T
Budget parameters µmax and µmin Evaluations (x1, . . . , xG) ∈ {−1, 0, +1}G of the worker’s answers to the G gold standard questions

•

Set α−1

= 0,

α0

= 1,

α+1

=

1 T

• The payment is where κ = (µmax − µmin)T G.

G
f (x1, . . . , xG) = κ αxi + µmin,
i=1

The proposed mechanism has a multiplicative form: each answer in the gold standard is given a score

based

on

whether

it

was

correct

(score

=

1 T

),

incorrect

(score

=

0)

or

skipped

(score

=

1),

and

the

ﬁnal

payment is simply a product of these scores (scaled and shifted by constants). The mechanism is easy to

describe to workers: For instance, if T = 12 , G = 3, µmax = 80 cents and µmin = 0 cents, then the

description reads:

“The reward starts at 10 cents. For every correct answer in the 3 gold standard questions, the reward will double. However, if any of these questions are answered incorrectly, then the reward will become zero. So please use the ‘I’m not sure’ option wisely.”

Observe how this payment rule is similar to the popular ‘double or nothing’ paradigm [Dou14]. The algorithm makes a minimum payment if one or more attempted answers in the gold standard are
wrong. Note that this property is signiﬁcantly stronger than the property of no-free-lunch which we originally required, where we wanted a minimum payment only when all attempted answers were wrong. Surprisingly, as we prove shortly, Algorithm 1 is the only incentive-compatible mechanism that satisﬁes nofree-lunch.
The following theorem shows that this mechanism indeed incentivizes a worker to skip the questions for which her conﬁdence is below T , while answering those for which her conﬁdence is greater than T . In the latter case, the worker is incentivized to select the answer which she thinks is most likely to be correct.

Theorem 2 The mechanism of Algorithm 1 is incentive-compatible and satisﬁes the no-free-lunch condition.

In the remainder of this subsection, we present the proof of Theorem 2. The reader may go directly to subsection 3.3 without loss in continuity.
Proof of Theorem 2. The proposed payment mechanism satisﬁes the no-free-lunch condition since the payment is µmin when there are one or more wrong answers in the gold standard. It remains to show that the mechanism is incentive compatible. To this end, observe that the property of incentive-compatibility does not change upon any shift of the mechanism by a constant value or any scaling by a positive constant value. As a result, for the purposes of this proof, we can assume without loss of generality that µmin = 0.
7

We will ﬁrst assume that, for every question that the worker does not skip, she selects the answer which she believes is most likely to be correct. Under this assumption we will show that the worker is incentivized to skip the questions for which her conﬁdence is smaller than T and attempt if it is greater than T . Finally, we will show that the mechanism indeed incentivizes the worker to select the answer which she believes is most likely to be correct for the questions that she doesn’t skip. In what follows, we will employ the notation κ = µmaxT G.
Let us ﬁrst consider the case when G = N . Let p1, . . . , pN be the conﬁdences of the worker for to questions 1, . . . , N respectively. Further, let p(1) ≥ · · · ≥ p(m) > T > p(m+1) ≥ · · · ≥ p(N) be the ordered permutation of these conﬁdences (for some number m). Let {(1), . . . , (N )} denote the corresponding permutation of the N questions. If the mechanism is incentive compatible, then the expected payment received by this worker should be maximized when the worker answers questions (1), . . . , (m) and skips the rest. Under the mechanism proposed in Algorithm 1, this action fetches the worker an expected payment of

κ p(1) · · · p(m) .

T

T

Alternatively, if the worker answers the questions {i1, . . . , iz}, with pi1 < · · · < piy < T < piy+1 < · · · piz , then the expected payment is

pi1 · · · piz Tκz = κ pTi1 · · · pTiz (1)

≤ κ pi1 · · · piy

(2)

TT

≤ κ p(1) · · · p(m) (3)

T

T

where inequality (2) holds because pTij ≤ 1 ∀ j > y and holds with equality only when z = y. Inequality (3) is a result of pT(j) ≥ 1 ∀ j ≤ m and holds with equality only when y = m. It follows that the expected payment is (strictly) maximized when i1 = (1), . . . , iz = (m) as required.
The case of G < N is a direct consequence of the result for G = N , as follows. When G < N , from a worker’s point of view, the set of G questions is distributed uniformly at random in the superset of N questions. However, for every set of G questions, the relations (1), (2), (3) and their associated equality/strict-inequality conditions hold. The expected payment is thus (strictly) maximized when the worker answers the questions for which her conﬁdence is greater than T and skips those for which her conﬁdence is smaller than T .
One can see that for every question that the worker chooses to answer, the expected payment increases with an increase in her conﬁdence. Thus, the worker is incentivized to select the answer that she thinks is most probably correct.
Finally, since κ = µmaxT G > 0 and T ∈ (0, 1), the payment is always non-negative and satisﬁes the µmax-budget constraint.

3.3 Uniqueness of this Mechanism
While we started out with a very weak condition of no-free-lunch of that requires a minimum payment when all attempted answers are wrong, the mechanism proposed in Algorithm 1 is signiﬁcantly more strict and pays the minimum amount when any of the attempted answers is wrong. A natural question that arises is: can we design an alternative mechanism satisfying incentive compatibility and no-free-lunch that operates somewhere in between? The following theorem answers this question in the negative.
Theorem 3 The mechanism of Algorithm 1 is the only incentive-compatible mechanism that satisﬁes the no-free-lunch condition.

8

Theorem 3 gives a strong result despite imposing very weak requirements. To see this, recall our earlier discussion on deterring spammers, that is, incurring a low expenditure on workers who answer randomly. For instance, when the task comprises binary-choice questions, one may wish to design mechanisms which make the minimum possible payment when the responses to 50% or more of the questions in the gold standard are incorrect. The no-free-lunch axiom is a much weaker requirement, and the only mechanism that can satisfy this requirement is the mechanism of Algorithm 1.
The proof of Theorem 3 is based on the following key lemma, establishing a condition that any incentivecompatible mechanism must necessarily satisfy. Note that this lemma does not require the no-free-lunch condition.
Lemma 4 Any incentive-compatible mechanism f must satisfy, for every gold standard question i ∈ {1, . . . , G} and every (y1, . . . , yi−1, yi+1, . . . , yG) ∈ {−1, 0, 1}G−1,
T f (y1, . . . , yi−1, 1, yi+1, . . . , yG) + (1 − T )f (y1, . . . , yi−1, −1, yi+1, . . . , yG) = f (y1, . . . , yi−1, 0, yi+1, . . . , yG) .
The proof of Lemma 4 is provided in Appendix A.1. Using this lemma, we will now prove Theorem 3. The reader interested in further results and not the proof may feel free to jump to Subsection 3.4 without any loss in continuity.
Proof of Theorem 3. The property of incentive-compatibility does not change upon any shift of the mechanism by a constant value or any scaling by a positive constant value. As a result, for the purposes of this proof, we can assume without loss of generality that µmin = 0.
We will ﬁrst prove that any incentive-compatible mechanism satisfying the no-free-lunch condition must make a zero payment if one or more answers in the gold standard are incorrect. The proof proceeds by induction on the number of skipped questions S in the gold standard. Let us assume for now that in the G questions in the gold standard, the ﬁrst question is answered incorrectly, the next (G − 1 − S) questions are answered by the worker and have arbitrary evaluations, and the remaining S questions are skipped. The proof proceeds by an induction on S. Suppose S = G − 1. In this case, the only attempted question is the ﬁrst question and the answer provided by the worker to this question is incorrect. The no-free-lunch condition necessitates a zero payment in this case, thus satisfying the base case of our induction hypothesis. Now we prove the hypothesis for some S under the assumption of it being true when the number of questions skipped in the gold standard is (S + 1) or more. From Lemma 4 (with i = G − S − 1) we have
T f (−1, y2, . . . , yG−S−2, 1, 0, . . . , 0) + (1 − T )f (−1, y2, . . . , yG−S−2, −1, 0, . . . , 0) = f (−1, y2, . . . , yG−S−2, 0, 0, . . . , 0) = 0,
where the ﬁnal equation is a consequence of our induction hypothesis: The induction hypothesis is applicable since f (−1, y2, . . . , yG−S−2, 0, 0, . . . , 0) corresponds to the case when the last (S + 1) questions are skipped and the ﬁrst question is answered incorrectly. Now, since the payment f must be non-negative and since T ∈ (0, 1), it must be that
f (−1, y2, . . . , yG−S−2, 1, 0, . . . , 0) = 0,
and
f (−1, y2, . . . , yG−S−2, −1, 0, . . . , 0) = 0.
9

This completes the proof of our induction hypothesis. Furthermore, each of the arguments above hold for any permutation of the G questions, thus proving the necessity of zero payment when any one or more answers are incorrect.
We will now prove that when no answers in the gold standard are incorrect, the payment must be of the form described in Algorithm 1. Let κ be the payment when all G questions in the gold standard are skipped. Let C be the number questions answered correctly in the gold standard. Since there are no incorrect answers, it follows that the remaining (G − C) questions are skipped. Let us assume for now that the ﬁrst C questions are answered correctly and the remaining (G − C) questions are skipped. We repeatedly apply Lemma 4, and the fact that the payment must be zero when one or more answers are wrong, to get

1

1−T

f (1, . . . , 1, 1, 0, . . . , 0) = f (1, . . . , 1, 0, 0, . . . , 0) −

f (1, . . . , 1, −1, 0, . . . , 0)

T

T

C −1

G−C

C −1

G−C

C −1

G−C

1 = f (1, . . . , 1, 0, 0, . . . , 0)
T

C −1

G−C

...

1 = T C f (0, . . . , 0)
G

1 = TCκ .

In order to abide by the budget, we must have the maximum payment as µmax

=

κ

1 TG

.

It follows that

κ = µmaxT G. Finally, the arguments above hold for any permutation of the G questions, thus proving the

uniqueness of the mechanism of Algorithm 1.

3.4 Optimality against Spamming Behavior
As discussed earlier, crowdsouring tasks, especially those with multiple choice questions, often encounter spammers who answer randomly without heed to the question being asked. For instance, under a binarychoice setup, a spammer will choose one of the two options uniformly at random for every question. A highly desirable objective in crowdsourcing settings is to deter spammers. To this end, one may wish to impose a condition of making the minimum possible payment when the responses to 50% or more of the attempted questions in the gold standard are incorrect. A second desirable metric could be to minimize the expenditure on a worker who simply skips all questions. While the aforementioned requirements were deterministic functions of the worker’s responses, one may alternatively wish to impose requirements that depend on the distribution of the worker’s answering process. For instance, a third desirable feature would be to minimize the expected payment to a worker who answers all questions uniformly at random. We now show that interestingly, our unique multiplicative payment mechanism simultaneously satisﬁes all these requirements. The result is stated assuming a multiple-choice setup, but extends trivially to non-multiplechoice settings.
Theorem 5.A (Distributional) Consider any value A ∈ {0, . . . , G}. Among all incentive-compatible mechanisms (that may or may not satisfy no-free-lunch), Algorithm 1 strictly minimizes the expenditure on a worker who skips some A of the questions in the the gold standard, and chooses answers to the remaining (G − A) questions uniformly at random.
Theorem 5.B (Deterministic) Consider any value B ∈ (0, 1]. Among all incentive-compatible mechanisms (that may or may not satisfy no-free-lunch), Algorithm 1 strictly minimizes the expenditure on a worker who gives incorrect answers to a fraction B or more of the questions attempted in the gold standard.

10

We see from this result that the multiplicative payment mechanism of Algorithm 1 thus possesses very useful properties geared to deter spammers, while ensuring that a good worker will be paid a high enough amount. To illustrate this point, let us compare the mechanism of Algorithm 1 with the popular additive class of payment mechanisms.
Example 1 Consider the popular class of “additive” mechanisms, where the payments to a worker are added across the gold standard questions. This additive payment mechanism offers a reward of µmGax for every correct answer in the gold standard, µmGaxT for every question skipped, and 0 for every incorrect answer. Importantly, the ﬁnal payment to the worker is the sum of the rewards across the G gold standard questions. One can verify that this additive mechanism is incentive compatible. One can also see that that as guaranteed by our theory, this additive payment mechanism does not satisfy the no-free-lunch axiom.
Suppose each question involves choosing from two options. Let us compute the expenditure that these two mechanisms make under a spamming behavior of choosing the answer randomly to each question. Given the 50% likelihood of each question being correct, on can compute that the additive mechanism makes a payment of µm2ax in expectation. On the other hand, our mechanism pays an expected amount of only µmax2−G. The payment to spammers thus reduces exponentially with the number of gold standard questions under our mechanism, whereas it does not reduce at all in the additive mechanism.
Now, consider a different means of exploiting the mechanism(s) where the worker simply skips all questions. To this end, observe that if a worker skips all the questions then the additive payment mechanism will incur an expenditure of µmaxT . On the other hand, the proposed payment mechanism of Algorithm 1 pays an exponentially smaller amount of µmaxT G (recall that T < 1).
We prove Theorem 5 in the rest of this subsection. The reader may feel free to jump directly to Section 4 without any loss in continuity.

Proof of Theorem 5. The property of incentive-compatibility does not change upon any shift of the mech-

anism by a constant value or any scaling by a positive constant value. As a result, for the purposes of this

proof, we can assume without loss of generality that µmin = 0.

Part A (Distributional). Let m denote the number of options in each question. One can verify that

under the mechanism of Algorithm 1, a worker who skips A questions and answers the rest uniformly at random will get a payment of µmmGax−TAA in expectation. This expression arises due to the fact that Algorithm 1 makes a zero payment if any of the attempted answers are incorrect, and a payment of µmaxT A if the worker

skips A questions and answers the rest correctly. Under uniformly random answers, the probability of the

latter

event

is

1 mG−A

.

Now consider any other mechanism, and denote it as f . Let us suppose without loss of generality

that the worker attempts the ﬁrst (G − A) questions. Since the payment must be non-negative, a repeated

application of Lemma 4 gives

f (1, . . . , 1, 0, . . . , 0) ≥ T f (1, . . . , 1, 0, . . . , 0)

(4)

G−A

G−A+1

...

≥ T Af (1, . . . , 1)

= T Aµmax,

(5)

where

(5)

is

a

result

of

the

µmax-budget

constraint.

Since

there

is

a

1 mG−A

chance

of

the

(G − A)

attempted

answers being correct, the expected payment under any other mechanism f must be at least µmmGax−TAA .

11

We will now show that if any mechanism f that makes an expected payment of µmmGax−TAA to such a spammer, then the mechanism must be identical to Algorithm 1. We split the proof of this part into two cases, depending on the value of the parameter A.
Case I (A < G): In order to make an expected payment of µmmGax−TAA , the mechanism must achieve the bound (5) with equality, and furthermore, the mechanism must have zero payment if any of the (G − A) attempted questions are answered incorrectly. In other words, the mechanism f under consideration must
satisfy
f (y1, . . . , yG−A, 0, . . . , 0) = 0 ∀(y1, . . . , yG−A) ∈ {−1, 1}G−A\{1}G−A.

A repeated application of Lemma 4 then implies

f (0, 0, . . . , −1) = 0.

(6)

Note that so far we considered the case when the worker attempts the ﬁrst (G−A) questions. The arguments above hold for any choice of the (G − A) attempted questions, and consequently the results shown so far in this proof hold for all permutations of the arguments to f . In particular, the mechanism f must make a zero payment when any (G − 1) questions in the gold standard are skipped and the remaining question is answered incorrectly. Another repeated application of Lemma 4 to this result gives
f (y1, . . . , yG) = 0 ∀(y1, . . . , yG) ∈ {0, −1}G\{0}G.

This condition is precisely the no-free-lunch axiom, and in Theorem 3 we had shown that Algorithm 1 is the only incentive-compatible mechanism that satisﬁes this axiom. It follows that our mechanism, Algorithm 1 strictly minimizes the expected payment in the setting under consideration.
Case II (A = G): In order to achieve the bound (5) with equality, the mechanism f must also achieve the bound (4) with equality. Noting that we have A = G in this case, it follows that the mechanism f must satisfy

f (−1, 0, . . . , 0) = 0.

This condition is identical to (6) established for Case I earlier, and the rest of the argument now proceeds in a manner identical to the subsequent arguments in Case I.
Part B (Deterministic). Given our result of Theorem 3, the proof for the deterministic part is straightforward. Algorithm 1 makes a payment of zero when one or more of the answers to questions in the gold standard are incorrect. Consequently, for every value of parameter B ∈ (0, 1], Algorithm 1 makes a zero payment when a fraction B or more of the attempted answers are incorrect. Any other mechanism doing so must satisfy the no-free-lunch axiom. In Theorem 3 we had shown that Algorithm 1 is the only incentive-compatible mechanism that satisﬁes this axiom. It follows that our mechanism, Algorithm 1, strictly minimizes the payment in the event under consideration.

4 Conﬁdence-based Setting
In this section, we will discuss incentive mechanisms when the worker is asked to select from more than one conﬁdence-level for every question (Figure 1c). In particular, for some L ≥ 1, the worker is asked to indicate a conﬁdence-level in the range {0, . . . , L} for every answer. Level 0 is the ‘skip’ level, and level L denotes the highest conﬁdence. Note that we do not solicit an answer if the worker indicates a conﬁdencelevel of 0 (skip), but the worker must provide an answer if she indicates a conﬁdence-level of 1 or higher. This makes the case of having only a ‘skip’ as considered in Section 3 a special case of this setting, and corresponds to L = 1.
We generalize the requirement of no-free-lunch to the conﬁdence-based setting as follows.

12

Axiom 6 (Generalized-no-free-lunch axiom) If all the answers attempted by the worker in the gold stan-

dard are selected as the highest conﬁdence-level (level L), and all of them turn out to be wrong, then the

payment is µmin. More formally, we require the mechanism f to satisfy f (x1, . . . , xG) = µmin for every

evaluation (x1, . . . , xG) that satisﬁes 0 <

G i=1

1{xi

=

0}

=

G i=1

1{xi

=

−L}.

In the conﬁdence-based setting, we require speciﬁcation of a set of thresholds {Sl, Tl}Ll=1 that determine the conﬁdence-levels that the workers should indicate. In particular, we will require speciﬁcation of two
reference points for each conﬁdence level, and this speciﬁcation generalizes the skip-based setting.

• The ﬁrst set of thresholds speciﬁes a comparison of any conﬁdence level with the skipping option as a ﬁxed reference. To this end, recall that in the skip-based setting, the threshold T speciﬁed when the worker should skip a question and when she should attempt to answer. This is generalized to the conﬁdence-based setting where for every level l ∈ [L], a ﬁxed threshold Sl speciﬁes the ‘strength’ of conﬁdence-level l: If restricted to only the two options of skipping or selecting conﬁdence-level l for any question, the worker should be incentivized to select conﬁdence-level l if her conﬁdence is higher than Sl and skip if her conﬁdence is lower than Sl.

• The second set of thresholds speciﬁes a comparison of any conﬁdence level with its neighbors. If
a worker decides to not skip a question, she must choose one of multiple conﬁdence-levels. A set {Tl}Ll=1 of thresholds specify the boundaries between different conﬁdence-levels. In particular, when the conﬁdence of the worker for a question lies in (Tl−1, Tl+1), then the worker must be incentivized to indicate conﬁdence-level (l − 1) if her conﬁdence is lower than Tl and to indicate conﬁdence-level l if her conﬁdence is higher than Tl. This includes selecting level L if her conﬁdence is higher than TL and selecting level 0 if her conﬁdence is lower than T1.

We will call a payment mechanism as incentive-compatible if it satisﬁes the two requirements listed above, and also incentivizes the worker to select the answer that she believes is most likely to be correct for every question for which her conﬁdence is higher than T1.
The problem setting inherently necessitates certain restrictions in the choice of the thresholds. Since we require the worker to choose a higher level when her conﬁdence is higher, the thresholds must necessarily be monotonic and satisfy 0 < S1 < S2 < · · · < SL < 1 and 0 < T1 < T2 < · · · < TL < 1. Also observe that the deﬁnitions of S1 and T1 coincide, and hence S1 = T1. Additionally, we can show (Proposition 17 in Appendix A.5) that for incentive-compatible mechanisms to exist, it must be that Tl > Sl ∀ l ∈ {2, . . . , L}. As a result, the thresholds must also satisfy T1 = S1, T2 > S2, . . . , TL > SL. These thresholds may be chosen based on various factors of the problem at hand, for example, on the post-processing algorithms, any statistics on the distribution of worker abilities, budget constraints, etc. In this paper, we will assume that these values are given to us.
13

4.1 Payment Mechanism

The proposed payment mechanism is described in Algorithm 2. Algorithm 2: Incentive mechanism for the conﬁdence-based setting
• Inputs:

Thresholds S1, . . . , SL and T1, . . . , TL Budget parameters µmax and µmin Evaluations (x1, . . . , xG) ∈ {−L, . . . , +L}G of the worker’s answers to the G gold standard questions

• Set α−L, . . . , αL as
αL = S1L , α−L = 0 For l ∈ {L − 1, . . . , 1},

αl = (1 − Sl)Tl+1αl+1 + (1 − Sl)(1 − Tl+1)α−(l+1) − (1 − Tl+1) and α−l = 1 − Slαl

Tl+1 − Sl

1 − Sl

α0 = 1

• The payment is

G
f (x1, . . . , xG) = κ αxi + µmin
i=1

G
1. where κ = (µmax − µmin) αL

The following theorem shows that this mechanism indeed incentivizes a worker to select answers and conﬁdence-levels as desired.
Theorem 7 The mechanism of Algorithm 2 is incentive-compatible and satisﬁes the generalized-no-freelunch condition.
The proof of Theorem 7 follows in a manner similar to that of the proof of Theorem 2, and is provided in Appendix A.2.
Remark 1 The mechanism of Algorithm 2 also ensures a condition stronger than the ‘boundary-based’ deﬁnition of the thresholds {Tl}l∈[L] given earlier. Under this mechanism, for every l ∈ [L−1] the worker is incentivized to select conﬁdence-level l (over all else) whenever her conﬁdence lies in the interval (Tl, Tl+1), select conﬁdence-level 0 (over all else) whenever her conﬁdence is lower than T1 and select conﬁdence-level L (over all else) whenever her conﬁdence is higher than TL.

4.2 Uniqueness of this Mechanism
We prove that the mechanism of Algorithm 2 is unique, that is, no other incentive-compatible mechanism can satisfy the generalized-no-free-lunch condition.
Theorem 8 The payment mechanism of Algorithm 2 is the only incentive-compatible mechanism that satisﬁes the generalized-no-free-lunch condition.

14

The proof of Theorem 8 is provided in Appendix A.3. The proof is conceptually similar to that of Theorem 8 but involves resolving several additional complexities that arise due to elicitation from multiple conﬁdence levels.

5 A Stronger No-free-lunch Condition: Impossibility Results

Recall that the no-free-lunch axiom under the skip-based mechanism of Section 3 requires the payment to

be the minimum possible if all attempted answers in the gold standard are incorrect. However, a worker

who skips all the questions may still receive a payment. The generalization under the conﬁdence-based

mechanism of Section 4 requires the payment to be the minimum possible if all attempted answers in the

gold standard were selected with the highest conﬁdence-level and were incorrect. However, a worker who

marked all questions with a lower conﬁdence level may be paid even if her answers to all the questions in the

gold standard turn out to be incorrect. One may thus wish to impose a stronger requirement instead, where

the minimum payment is made to workers who make no useful contribution. This is the primary focus of

this section.

Consider the skip-based setting. Deﬁne the following axiom which is slightly stronger than the no-free-

lunch axiom deﬁned previously.

Strong-no-free-lunch: If none of the answers in the gold standard are correct, then the payment is µmin.

More formally, strong-no-free-lunch imposes the condition f (x1, . . . , xG) = µmin for every evaluation

(x1, . . . , xG) that satisﬁes

G i=1

1{xi

>

0}

=

0.

The strong-no-free-lunch axiom is only slightly stronger than the no-free-lunch axiom proposed in Sec-

tion 3 for the skip-based setting. The strong-no-free-lunch condition can equivalently be written as imposing

requiring the payment to be the minimum possible for every evaluation that satisﬁes

G i=1

1{xi

=

0}

=

G i=1

1{xi

=

−1}.

From this interpretation, one can see that to the set of events necessitating the min-

imum payment under the no-free-lunch axiom, the strong-no-free-lunch axiom adds only one extra event,

the event of the worker skipping all questions. Unfortunately, it turns out that this minimal strengthening of

the requirements is associated to impossibility results.

In this section we show that no mechanism satisfying the strong-no-free-lunch axiom can be incentive

compatible in general. The only exception is the case when (a) all questions are in the gold standard (G =

N ), and (b) it is guaranteed that the worker has a conﬁdence greater than T for at least one of the N

questions. These conditions are, however, impractical for the crowdsourcing setup under consideration in

this paper. We will ﬁrst prove the impossibility results under the strong-no-free-lunch axiom. For the sake of

completeness (and also to satisfy mathematical curiosity), we will then provide a (unique) mechanism that

is incentive-compatible and satisﬁes the strong-no-free-lunch axiom for the skip-based setting under the two

conditions listed above. The proofs of each of the claims made in this section are provided in Appendix A.6.

Let us continue to discuss the skip-based setting. In this section, we will call any worker whose con-

ﬁdences for all of the N questions is lower than T as an unknowledgeable worker, and call the worker a

knowledgeable worker otherwise.

Proposition 9 No payment mechanism satisfying the strong-no-free-lunch condition can incentivize an unknowledgeable worker to skip all questions. As a result, no mechanism satisfying the strong-no-free-lunch axiom can be incentive-compatible.

The proof of this proposition, and that of all other theoretical claims made in this section, are presented in Appendix A.6.
The impossibility result of Proposition 9 relies on trying to incentivize an unknowledgeable worker to act as desired. Since no mechanism can be incentive compatible for unknowledgeable workers, we will now

15

consider only workers who are knowledgeable. The following proposition shows that the strong-no-freelunch condition is too strong even for this relaxed setting.
Proposition 10 When G < N , there exists no mechanism that is incentive-compatible for knowledgeable workers and satisﬁes the strong-no-free-lunch condition.
Given this impossibility result for G < N , we are left with G = N which means that the true answers to all the questions are known apriori. This condition is clearly not applicable to a crowdsourcing setup; nevertheless, it is mathematically interesting and may be applicable to other scenarios such as testing and elicitation of beliefs about future events.
Proposition 11 below presents a mechanism for this case and proves its uniqueness. We previously saw that an unknowledgeable worker cannot be incentivized to skip all the questions (even when G = N ). Thus, in our payment mechanism, we do the next best thing: Incentivize the unknowledgeable worker to answer only one question, that which she is most conﬁdent about, while incentivizing the knowledgeable worker to answer questions for which her conﬁdence is greater than T and skip those for which her conﬁdence is smaller than T .
Proposition 11 Let C be the number of correct answers and W be the number of wrong answers (in the gold standard). Let the payment be µmin if W > 0 or C = 0, and be (µmax − µmin)T G−C + µmin otherwise. Under this mechanism, when G = N , an unknowledgeable worker is incentivized to answer only one question, that for which her conﬁdence is the maximum, and a knowledgeable worker is incentivized to answer the questions for which her conﬁdence is greater than T and skip those for which her conﬁdence is smaller than T . Furthermore, when G = N , this mechanism is the one and only mechanism that obeys the strong-no-free-lunch condition and is incentive-compatible for knowledgeable workers.
The following proposition shows that the strong-no-free-lunch condition leads to negative results in the conﬁdence-based setting (L > 1) as well. The strong-no-free-lunch condition is still deﬁned as in the beginning of Section 5, i.e., the payment is zero if none of the answers are correct.
Proposition 12 When L > 1, for any values of N and G (≤ N ), it is impossible for any mechanism to satisfy the strong-no-free-lunch condition and be incentive-compatible even when the worker is knowledgeable.
6 Simulations and Experiments
In this section, we present synthetic simulations and real-world experiments to evaluate the effects of our setting and our mechanism on the ﬁnal label quality.
6.1 Synthetic Simulations
We employ synthetic simulations to understand the effects of various distributions of the conﬁdences and labeling errors. We consider binary-choice questions in this set of simulations. Whenever a worker answers a question, her conﬁdence for the correct answer is drawn from a distribution P independent of all else. We investigate the effects of the following ﬁve choices of the distribution P:
• The uniform distribution on the support [0.5, 1].
• A triangular distribution with lower end-point 0.2, upper end-point 1 and a mode of 0.6.
• A beta distribution with parameter values α = 5 and β = 1.
16

% wrong

16

(a) Uniform

(b) Triangular

8

32

12

24

6

8

16

4

4

8

2

0

3

5

7

90

3

5

7

90

Number of workers

Number of workers

16 (d) Hammer-spammer

(e) Truncated Gaussian
24

12

18

8

12

4

6

0

3

5

7

90

3

5

7

9

Number of workers

Number of workers

(c) Beta

3

5

7

9

Number of workers

Baseline Skip-Multiplicative

% wrong

Figure 2: Error under different interfaces for synthetic simulations of ﬁve distributions of the workers’ error probabilities.

• The hammer-spammer distribution [KOS11]: uniform on the discrete set {0.5, 1}.
• A truncated Gaussian distribution: a truncation of N (0.75, 0.5) to the interval [0, 1].
We compare (a) the setting where workers attempt every question, with (b) the setting where workers skip questions for which their conﬁdence is below a certain threshold T . In this set of simulations, we set T = 0.75. In either setting, we aggregate the labels obtained from the workers for each question via a majority vote on the two classes. Ties are broken by choosing one of the two options uniformly at random.
Figure 2 depicts the results from these simulations. Each bar represents the fraction of questions that are labeled incorrectly, and is an average across 50,000 trials. (The standard error of the mean is too small to be visible.) We see that the skip-based setting consistently outperforms the conventional setting, and the gains obtained are moderate to high depending on the underlying distribution of the workers’ errors. In particular, the gains are quite striking under the hammer-spammer model: this result is not surprising since the mechanism (ideally) screens the spammers out and leaves only the hammers who answer perfectly.
The setup of the simulations described above assumes that the workers conﬁdences equal the true error probabilities. In practice, however, the workers may have incorrect beliefs. The setup also assumes that ties are broken randomly; however in practice, ties may be broken in a more systematic manner by eliciting additional labels for only these hard questions. We now present a second set of simulations that mitigates these biases. In particular, when a worker has a conﬁdence of p, the actual probability of error is assumed to be drawn from a Gaussian distribution with mean p and standard deviation 0.1, truncated to [0, 1]. In addition, when evaluating the performance of the majority voting procedure, we consider a tie as having an error of 0.4. Figure 3 depicts the results of these simulations. We observe that the results from these simulations are very similar to those obtained in the earlier simulation setup of Figure 2.
6.2 Experiments on Amazon Mechanical Turk
We conducted preliminary experiments on the Amazon Mechanical Turk commercial crowdsourcing platform (mturk.com) to evaluate our proposed scheme in real-world scenarios. The complete data, including the interface presented to the workers in each of the tasks, the results obtained from the workers, and the ground truth solutions, are available on the website of the ﬁrst author.
17

% wrong

16 (a) Uniform 32 (b) Triangular 8

12

24

6

8

16

4

4

8

2

0

3

5

7

90

3

5

7

90

Number of workers

Number of workers

(d) Hammer-spammer

(e) Truncated Gaussian

16

24

12

18

8

12

4

6

0

3

5

7

90

3

5

7

9

Number of workers

Number of workers

(c) Beta

3

5

7

9

Number of workers

Baseline Skip-Multiplicative

% wrong

Figure 3: Errors under a model that is a perturbation of the ﬁrst experiment, where the worker’s conﬁdence is a noisy version of the true error probability and where ties are considered different from random decisions.

6.2.1 Goal
Before delving into details, we ﬁrst note certain caveats relating to such a study of mechanism design on crowdsourcing platforms. When a worker encounters a mechanism for only a small amount of time (a handful of tasks in typical research experiments) and for a small amount of money (at most a few dollars in typical crowdsourcing tasks), we cannot expect the worker to completely understand the mechanism and act precisely as required. For instance, we wouldn’t expect our experimental results to change signiﬁcantly even upon moderate modiﬁcations in the promised amounts, and furthermore, we do expect the outcomes to be noisy. Incentive compatibility kicks in when the worker encounters a mechanism across a longer term, for example, when a proposed mechanism is adopted as a standard for a platform, or when higher amounts are involved. This is when we would expect workers or others (e.g., bloggers or researchers) to design strategies that can game the mechanism. The theoretical guarantee of incentive compatibility then prevents such gaming in the long run.
We thus regard these experiments as preliminary. Our intentions towards this experimental exercise were (a) to evaluate the potential of our algorithms to work in practice, (b) to investigate the effect of the proposed algorithms on the net error in the collected labelled data, and (c) to identify if there is any major issue of dissatisfaction among the workers.
6.2.2 Experimental setup
We conducted our experiments on the “Amazon Mechanical Turk” commercial crowdsourcing platform (mturk.com). On this platform, individuals or businesses (called ‘requesters’) can post tasks, and any individual (called a ‘worker’) may complete the task over the Internet in exchange for a pre-speciﬁed payment. The payment may comprise of two parts: a ﬁxed component which is identical for all workers performing that task, and a ‘bonus’ which may be different for different workers and is paid at the discretion of the requester.
We designed nine experiments (tasks) ranging from image annotation to text and speech recognition. The individual experiments are described in more detail in Appendix B. All experiments involved objective questions, and the responses elicited were multiple choice in ﬁve of the experiments and freeform text in the rest. For each experiment, we tested three settings: (i) the baseline conventional setting (Figure 1a) with a mechanism of paying a ﬁxed amount per correct answer, (ii) our skip-based setting (Figure 1b)
18

with our multiplicative mechanism, and (iii) our conﬁdence-based setting (Figure 1c) with our conﬁdencebased mechanism. For each mechanism in each experiment, we speciﬁed the requirement of 35 workers independently performing the task. This amounts to a total of 945 worker-tasks (315 worker-tasks for each mechanism). We also set the following constraints for a worker to attempt our tasks: the worker must have completed at least 100 tasks previously, and must have a history of having at least 95% of her prior work approved by the respective requesters. In each experiment, we offered a certain small ﬁxed payment (in order to attract the workers in the ﬁrst place) and executed the variable part of our mechanisms via a bonus payment.
6.2.3 Results: Raw data
Figure 4 plots, for the baseline, skip-based and conﬁdence-based mechanisms for all nine experiments, the (i) fraction of questions that were answered incorrectly, (ii) fraction of questions that were answered incorrectly among those that were attempted, (iii) the average payment to a worker (in cents), and (iv) break up of the answers in terms of the fraction of answers in each conﬁdence level. The payment for various tasks plotted in Figure 4 is computed as the average of the payments across 100 (random) selections of the gold standard questions, in order to prevent any distortion of the results due to the randomness in the choice of the gold standard questions.
The ﬁgure shows that the amount of errors among the attempted questions is much lower in the skip and the conﬁdence-based settings than the baseline setting. Also observe that in the conﬁdence-based setting, as expected, the answers selected with higher conﬁdence-levels are more correct. The total expenditure under each of these settings is similar, with the skip and the conﬁdence-based settings faring better in most cases. We also elicited feedback from the workers, in which we received several positive comments (and no negative comments). Examples of comments that we received: “I was wondering if it would possible to increase the maximum number of HITs I may complete for you. As I said before, they were fun to complete. I think I did a good job completing them, and it would be great to complete some more for you.”; “I am eagerly waiting for your bonus.”; “Enjoyable. Thanks.”
6.2.4 Results: Aggregated data
We saw in the previous section that under the skip-based setting, the amount of error among the attempted questions was signiﬁcantly lower than the amount of error in the baseline setting. However, the skip-based setting was also associated, by design, to lesser amount of data by virtue of questions being skipped by the workers. A natural question that arises is how the baseline and the skip-based mechanisms will compare in terms of the ﬁnal data quality, i.e., the amount of error once data from multiple workers is aggregated.
To this end, we considered the ﬁve experiments that consisted of multiple-choice questions. We let a parameter num workers take values in {3, 5, 7, 9, 11}. For each of the ﬁve experiments and for each of the ﬁve values of num workers, we perform the following actions 1,000 times: for each question, we choose num workers workers and perform a majority vote on their responses. If the correct answer for that question does not lie in the set of options given by the majority, we consider it as an accuracy of zero. Otherwise, if there are m options tied in the majority vote, and the correct answer is one of these m, then we consider it as an accuracy of 1m00 % (hence, 100% if the correct answer is the only answer picked by the majority vote). We average the accuracy across all questions and across all iterations.
We choose majority voting as the means of aggregation since (a) it is the simplest and still most popular aggregation method, and (b) to enable an apples-to-apples comparison design since while more advanced aggregation algorithms have been developed for the baseline setting without the skip [RYZ+10, ZPBM12, WJ11, CBCTH13, KHH12, DS79, KOS11, LPI12, VVV14, ZCZJ14, IPSW14], design of analogous algorithms for the new skip-based setting hasn’t been explored yet.
19

The results are presented in Figure 5. We see that in most cases, our skip-based mechanism induces a lower labelling error at the aggregate level than the baseline. Furthermore, in many of the instances, the reduction is two-fold or higher.
All in all, in the experiments, we observe a substantial reduction in the error-rates while expending the same or lower amounts and receiving no negative comments from the workers, suggesting that these mechanisms can work; the fundamental theory underlying the mechanisms ensures that the system cannot be gamed in the long run. Our proposed settings and mechanisms thus have the potential to provide much higher quality labeled data as input to machine learning algorithms.
7 Discussion and Conclusions
In this concluding section, we ﬁrst discuss the modelling assumptions that we made in this paper, followed by a discussion on future work and concluding remarks.
7.1 Modelling Assumptions
When forming the model for our problem, as in any other ﬁeld of theoretical research, we had to make certain assumptions and choices. In what follows, we discuss the reasons for the modelling choices we made.
• Use of gold standard questions. We assume the existence of gold standard questions in the task, i.e., a subset of questions to which the answers are known to the system designer. The existence of gold standard is commonplace in crowdsourcing platforms [LEHB10, CMBN11].
• Workers aiming to maximize their expected payments: We assume that the workers aim to maximize their expected payments. In many other problems in game theory, one often makes the assumption that people are “risk-averse”, and aim to maximize the expected value of some “utility function” of their payments. While we extend our results to general utility functions in Appendix C in order to accommodate such requirements, we also think that the assumption of workers maximizing their expected payments is a perfectly reasonable assumption for the crowdsourcing settings considered here. The reason is that each such task lasts for a handful of minutes and is worth a few tens of cents. Workers typically perform tens to hundreds of tasks per day, and consequently their empirical hourly wages very quickly converge to their expectation.
• Workers knowing their conﬁdences: We understand that in practice the workers will have noisy or granular estimates of their own beliefs. The mathematical assumption of workers knowing their precise conﬁdences is an idealization intended for mathematical tractability. This is one of the reasons why we only elicit a quantized value of the workers’ beliefs (in terms of skipping or choosing one of a ﬁnite number of conﬁdence levels), and not try to ask for a precise value.
• Eliciting a quantized version of the beliefs: We do not directly attempt to elicit the values of the beliefs of the workers, but instead ask them to indicate only a quantization (e.g., “I’m not sure” or “moderately conﬁdent”, etc.). We prefer this quantization to direct assessment to real-valued probability, motivated by the extensive literature in psychology on the coarseness of human perception and processing (e.g., [Mil56, SN94, JL13, SBB+15]) establishing that humans are more comfortable at providing quantized responses. This notion is veriﬁed by experiments on Amazon Mechanical Turk in [SBB+15] where it is observed that people are more consistent when giving ordinal answers (comparing pairs of items) as opposed to when they are asked for numeric evaluations.
20

a

Iden%fy the Golden Gate Bridge

b

Transcribe the license plate number

c

Mark the breed of the dog

d

Iden%fy heads of countries

e

Mark the con%nent to which the ﬂag belongs

f

Iden%fy the texture

g

Transcribe text (playscript)

h

Transcribe text (cer%ﬁcate)

i

Transcribe the audio clip

Legend
B Baseline
mechanism Skip-based
S multiplicative
mechanism Confidence-based
C multiplicative
mechanism
Break up: Confidence-based multiplicative mechanism:
absolutely sure & wrong moderately sure & wrong
skipped
moderately sure & correct absolutely sure & correct
Skip-based multiplicative mechanism:
skipped

Figure 4: The error-rates in the raw data and payments in the nine experiments. Each individual bar in the plots corresponds to one mechanism in one experiment and is generated from 35 distinct workers (this totals to 945 worker-tasks).
21

(a) Identify the Golden Gate Bridge

(b) Identify breed of dogs

(c) Identify heads of countries

% wrong

% wrong

(d) Identify the continent from flags

(e) Identify texture in images

Legend: Conven&onal Skip-­‐based mul&plica&ve Conﬁdence-­‐based mul&plica&ve

Figure 5: Error-rates in the aggregated data in the ﬁve experiments involving multiple-choice tasks.
7.2 Open problems
We discuss two sets of open problems, one from the practical perspective and another on the theoretical front.
First, in the paper, we assumed that the number of total questions N in a task, the number of gold standard questions G, and the threshold T for skipping (or the number and thresholds of the different conﬁdence levels) were provided to the mechanism. While these parameters may be chosen by hand by a system designer based on her own experience, a more principled design of these parameters is an important question. The choices for these parameters may have to be made based on certain tradeoffs. For instance, a higher value of G reduces the variance in the payments but uses more resources in terms of gold standard questions. Or for instance, more number of threshold levels L would increase the amount of information obtained about the workers’ beliefs, but also increase the noise in the workers’ estimates of her own beliefs.
A second open problem is the design of inference algorithms that can exploit the speciﬁc structure of the skip-based setting. There are several algorithms and theoretical analyses in the literature for aggregating data from multiple workers in the baseline setting [RYZ+10, ZPBM12, WJ11, CBCTH13, KHH12, DS79, KOS11, LPI12, VVV14, ZCZJ14, IPSW14]. A useful direction of research in the future is to develop algorithms and theoretical guarantees that incorporate information about the workers’ conﬁdences. For instance, for the skip-based setting, the missing labels are not missing “at random” but are correlated with the difﬁculty of the task; in the conﬁdence-based setting, we elicit information about the workers’ perceived conﬁdence levels. Designing algorithms that can exploit this information judiciously (e.g., via conﬁdenceweighed worker/item constraints in the minimax entropy method of [ZPBM12]) is a useful direction of future research.
7.3 Conclusions
Despite remarkable progress in machine learning and artiﬁcial intelligence, many problems are still not solvable by either humans or machines alone. In recent years, crowdsourcing has emerged as a powerful tool to combine both human and machine intelligence. Crowdsourcing is also a standard means of collecting labeled data for machine learning algorithms. However, crowdsourcing is often plagued with the problem of poor-quality output from workers.
We designed a reward mechanism for crowdsourcing to ensure collection of high-quality data. Under a very natural “no-free-lunch” axiom, we mathematically prove that surprisingly, our mechanism is the only feasible reward mechanism. We further show that among all possible incentive-compatible mechanisms,
22

our “multiplicative” mechanism makes the strictly smallest expenditure on spammers. In preliminary experiments, we observe a signiﬁcant drop in the error rates under this unique mechanism as compared to basic baseline mechanisms, suggesting that our mechanism has the potential to work well in practice. Our mechanisms offer some additional beneﬁts. The pattern of skips or conﬁdence levels of the workers provide a reasonable estimate of the difﬁculty of each question. In practice, the questions that are estimated to be more difﬁcult may now be delegated to an expert or to more non-expert workers. Secondly, the theoretical guarantees of the mechanism may allow for better post-processing of the data, incorporating the conﬁdence information and improving the overall accuracy. The simplicity of the rules of our mechanisms may facilitate an easier adoption among the workers.
In conclusion, given the uniqueness in theory, simplicity, and good performance observed in practice, we envisage our ‘multiplicative’ mechanisms to be of interest to machine learning researchers and practitioners who use crowdsourcing to collect labeled data.

Acknowledgements
The work of Nihar B. Shah was funded in part by a Microsoft Research PhD fellowship. We thank John C. Platt, Christopher J. C. Burges and Christopher Meek for many inspiring discussions. We also thank John C. Platt and Martin J. Wainwright for helping in proof-reading and polishing parts of the manuscript. This work was done when Nihar B. Shah was an intern at Microsoft Research.

References

[AGN14]

Nima Anari, Gagan Goel, and Afshin Nikzad. Mechanism design for crowdsourcing: An optimal 1-1/e competitive budget-feasible mechanism for large markets. In Foundations of Computer Science (FOCS), pages 266–275, 2014.

[AL88]

Dana Angluin and Philip Laird. Learning from noisy examples. Machine Learning, 2(4):343– 370, 1988.

[BH07] [BLM+10]

Peter Bu¨hlmann and Torsten Hothorn. Boosting algorithms: Regularization, prediction and model ﬁtting. Statistical Science, pages 477–505, 2007.
Michael S Bernstein, Greg Little, Robert C Miller, Bjo¨rn Hartmann, Mark S Ackerman, David R Karger, David Crowell, and Katrina Panovich. Soylent: a word processor with a crowd inside. In ACM symposium on User interface software and technology (UIST), pages 313–322, 2010.

[Boh11]

John Bohannon. Social science for pennies. Science, 334(6054):307–307, 2011.

[BP09]

Jason Baldridge and Alexis Palmer. How well does active learning actually work?: Timebased evaluation of cost-reduction strategies for language documentation. In Conference on Empirical Methods in Natural Language Processing, pages 296–305, 2009.

[Bri50]

Glenn W Brier. Veriﬁcation of forecasts expressed in terms of probability. Monthly weather review, 78(1):1–3, 1950.

[BSS05]

Andreas Buja, Werner Stuetzle, and Yi Shen. Loss functions for binary class probability estimation and classiﬁcation: Structure and applications. Working draft, November, 2005.

23

[CBCTH13]

Xi Chen, Paul N Bennett, Kevyn Collins-Thompson, and Eric Horvitz. Pairwise ranking aggregation in a crowdsourced setting. In ACM international conference on Web search and data mining, pages 193–202, 2013.

[CBW+10]

Andrew Carlson, Justin Betteridge, Richard C Wang, Estevam R Hruschka Jr, and Tom M Mitchell. Coupled semi-supervised learning for information extraction. In ACM international conference on Web search and data mining, pages 101–110, 2010.

[CDGL01]

Izquierdo JM Cano, Yannis A Dimitriadis, Sa´nchez E Go´mez, and Coronado J Lo´pez. Learning from noisy information in fasart and fasback neuro-fuzzy systems. Neural networks: the ofﬁcial journal of the International Neural Network Society, 14(4-5):407–425, 2001.

[CDP15]

Yang Cai, Constantinos Daskalakis, and Christos H Papadimitriou. Optimum statistical estimation with strategic data sources. In Conference on Learning Theory (COLT), 2015.

[CMBN11] Jenny J Chen, Natala J Menezes, Adam D Bradley, and TA North. Opportunities for crowdsourcing research on amazon mechanical turk. Interfaces, 5(3), 2011.

[CWZ04] [DDS+09]

Fang Chu, Yizhou Wang, and Carlo Zaniolo. An adaptive learning approach for noisy data streams. In IEEE International Conference on Data Mining (ICDM), pages 351–354, 2004.
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A largescale hierarchical image database. In IEEE Conference on Computer Vision and Pattern Recognition, pages 248–255, 2009.

[DFP08]

Ofer Dekel, Felix Fischer, and Ariel D Procaccia. Incentive compatible regression learning. In ACM-SIAM symposium on Discrete algorithms, pages 884–893, 2008.

[Dou14]

Double or Nothing. http://wikipedia.org/wiki/Double_or_nothing, 2014. Last accessed: July 31, 2014.

[DS79] [FKK+11]

Alexander Philip Dawid and Allan M Skene. Maximum likelihood estimation of observer error-rates using the EM algorithm. Applied statistics, pages 20–28, 1979.
Michael J Franklin, Donald Kossmann, Tim Kraska, Sukriti Ramesh, and Reynold Xin. CrowdDB: answering queries with crowdsourcing. In ACM SIGMOD International Conference on Management of Data, pages 61–72, 2011.

[FSW07]

Fang Fang, Maxwell Stinchcombe, and Andrew Whinston. Putting your money where your mouth is: A betting platform for better prediction. Review of Network Economics, 6(2), 2007.

[GR07] [HDY+12]

Tilmann Gneiting and Adrian E Raftery. Strictly proper scoring rules, prediction, and estimation. Journal of the American Statistical Association, 102(477):359–378, 2007.
Geoffrey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel-rahman Mohamed, Navdeep Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara N Sainath, et al. Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. IEEE Signal Processing Magazine, 29(6):82–97, 2012.

[HJV13]

Chien-Ju Ho, Shahin Jabbari, and Jennifer W Vaughan. Adaptive task assignment for crowdsourced classiﬁcation. In International Conference on Machine Learning (ICML), pages 534–542, 2013.

24

[HY10]

Steve Hanneke and Liu Yang. Negative results for active learning with convex losses. In International Conference on Artiﬁcial Intelligence and Statistics (AISTATS), pages 321–325, 2010.

[IPSW14]

Panagiotis G Ipeirotis, Foster Provost, Victor S Sheng, and Jing Wang. Repeated labeling using multiple noisy labelers. Data Mining and Knowledge Discovery, 28(2):402–441, 2014.

[JL13]

W Paul Jones and Scott A Loe. Optimal number of questionnaire response categories more may not be better. SAGE Open, 3(2):2158244013489691, 2013.

[JSV14] [KDC+11]

Srikanth Jagabathula, Lakshminarayanan Subramanian, and Ashwin Venkataraman. Reputation-based worker ﬁltering in crowdsourcing. In Advances in Neural Information Processing Systems (NIPS), pages 2492–2500, 2014.
Firas Khatib, Frank DiMaio, Seth Cooper, Maciej Kazmierczyk, Miroslaw Gilski, Szymon Krzywda, Helena Zabranska, Iva Pichova, James Thompson, Zoran Popovic´, Mariusz Jaskolski, and David Baker. Crystal structure of a monomeric retroviral protease solved by protein folding game players. Nature structural & molecular biology, 18(10):1175–1177, 2011.

[KHH12]

Ece Kamar, Severin Hacker, and Eric Horvitz. Combining human and machine intelligence in large-scale crowdsourcing. In International Conference on Autonomous Agents and Multiagent Systems, pages 467–474, 2012.

[KJYL11]

Aditya Khosla, Nityananda Jayadevaprakash, Bangpeng Yao, and Fei-fei Li. L.: Novel dataset for ﬁne-grained image categorization. In First Workshop on Fine-Grained Visual Categorization, CVPR, 2011.

[KKKMF11] Gabriella Kazai, Jaap Kamps, Marijn Koolen, and Natasa Milic-Frayling. Crowdsourcing for book search evaluation: impact of HIT design on comparative system ranking. In ACM SIGIR conference on Research and development in Information Retrieval, pages 205–214, 2011.

[KOS11]

David R Karger, Sewoong Oh, and Devavrat Shah. Iterative learning for reliable crowdsourcing systems. In Advances in neural information processing systems (NIPS), 2011.

[LEHB10]

John Le, Andy Edmonds, Vaughn Hester, and Lukas Biewald. Ensuring quality in crowdsourced search relevance evaluation: The effects of training question distribution. In SIGIR 2010 workshop on crowdsourcing for search evaluation, pages 21–26, 2010.

[LLYL04]

Eric WM Lee, Chee Peng Lim, Richard KK Yuen, and SM Lo. A hybrid neural network model for noisy data regression. Systems, Man, and Cybernetics, Part B: Cybernetics, IEEE Transactions on, 34(2):951–960, 2004.

[LPI12]

Qiang Liu, Jian Peng, and Alexander T Ihler. Variational inference for crowdsourcing. In NIPS, pages 701–709, 2012.

[LRR11]

ASID Lang and Joshua Rio-Ross. Using Amazon Mechanical Turk to transcribe historical handwritten documents. The Code4Lib Journal, 2011.

[LS09]

Nicolas Lambert and Yoav Shoham. Eliciting truthful answers to multiple-choice questions. In ACM conference on Electronic commerce, pages 109–118, 2009.

25

[LS10]

Philip M Long and Rocco A Servedio. Random classiﬁcation noise defeats all convex potential boosters. Machine Learning, 78(3):287–304, 2010.

[LSP05]

Svetlana Lazebnik, Cordelia Schmid, and Jean Ponce. A sparse texture representation using local afﬁne regions. IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(8):1265–1278, 2005.

[Mil56]

George A Miller. The magical number seven, plus or minus two: some limits on our capacity for processing information. Psychological review, 63(2):81, 1956.

[MS13]

Naresh Manwani and PS Sastry. Noise tolerance under risk minimization. IEEE Transactions on Cybernetics, 43(3):1146–1151, 2013.

[MWB07] [RYZ+10]

David Mease, Abraham J Wyner, and Andreas Buja. Boosted classiﬁcation trees and class probability/quantile estimation. The Journal of Machine Learning Research, 8:409–439, 2007.
Vikas C Raykar, Shipeng Yu, Linda H Zhao, Gerardo Hermosillo Valadez, Charles Florin, Luca Bogoni, and Linda Moy. Learning from crowds. The Journal of Machine Learning Research, 11:1297–1322, 2010.

[Sav71] [SBB+15]

Leonard J Savage. Elicitation of personal probabilities and expectations. Journal of the American Statistical Association, 66(336):783–801, 1971.
Nihar B Shah, Sivaraman Balakrishnan, Joseph Bradley, Abhay Parekh, Kannan Ramchandran, and Martin J Wainwright. Estimation from pairwise comparisons: Sharp minimax bounds with topology dependence. In International Conference on Artiﬁcial Intelligence and Statistics (AISTATS), 2015.

[SN94]

Richard M Shiffrin and Robert M Nosofsky. Seven plus or minus two: A commentary on capacity limitations. Psychological Review, 101(2):357–61, 1994.

[VAMM+08] Luis Von Ahn, Benjamin Maurer, Colin McMillen, David Abraham, and Manuel Blum. reCAPTCHA: Human-based character recognition via web security measures. Science, 321(5895):1465–1468, 2008.

[VdVE11]

Jeroen Vuurens, Arjen P de Vries, and Carsten Eickhoff. How much spam can you take? An analysis of crowdsourcing results to increase accuracy. In ACM SIGIR Workshop on Crowdsourcing for Information Retrieval, pages 21–26, 2011.

[VVV14]

Aditya Vempaty, Lav R Varshney, and Pramod K Varshney. Reliable crowdsourcing for multiclass labeling using coding theory. IEEE Journal of Selected Topics in Signal Processing, 8(4):667–679, 2014.

[WJ11] [WLC+10]

Fabian L Wauthier and Michael Jordan. Bayesian bias mitigation for crowdsourcing. In Advances in Neural Information Processing Systems (NIPS), 2011.
Paul Wais, Shivaram Lingamneni, Duncan Cook, Jason Fennell, Benjamin Goldenberg, Daniel Lubarov, David Marin, and Hari Simons. Towards building a high-quality workforce with Mechanical Turk. NIPS workshop on computational social science and the wisdom of crowds, 2010.

26

[YKL11] [ZCL14] [ZCZJ14] [ZPBM12]

Man-Ching Yuen, Irwin King, and Kwong-Sak Leung. Task matching in crowdsourcing. In IEEE International Conference on Cyber, Physical and Social Computing, pages 409–412, 2011.
Yuan Zhou, Xi Chen, and Jian Li. Optimal PAC multiple arm identiﬁcation with applications to crowdsourcing. In International Conference on Machine Learning (ICML), pages 217– 225, 2014.
Yuchen Zhang, Xi Chen, Dengyong Zhou, and Michael I Jordan. Spectral methods meet EM: A provably optimal algorithm for crowdsourcing. In Advances in Neural Information Processing Systems (NIPS), 2014.
Dengyong Zhou, John Platt, Sumit Basu, and Yi Mao. Learning from the wisdom of crowds by minimax entropy. In Advances in Neural Information Processing Systems (NIPS), pages 2204–2212, 2012.

A Proofs
In this section, we prove the claimed theoretical results whose proofs are not included in the main text of the paper.
The property of incentive-compatibility does not change upon any shift of the mechanism by a constant value or any scaling by a positive constant value. As a result, for the purposes of these proofs, we can assume without loss of generality that µmin = 0.

A.1 Proof of Lemma 4: The Workhorse Lemma

First we consider the case of G = N . In the set {y1, . . . , yi−1, yi+1, . . . , yG}, for some (η, γ) ∈ {0, . . . , G− 1}2, suppose there are η elements with a value 1, γ elements with a value −1, and (G − 1 − η − γ) elements
with a value 0. Let us assume for now that i = η + γ + 1, y1 = 1, . . . , yη = 1, yη+1 = −1, . . . , yη+γ = −1, yη+γ+2 = 0, . . . , yG = 0.
Suppose the worker has conﬁdences (p1, . . . , pη+γ) ∈ (T, 1]η+γ for the ﬁrst (η + γ) questions, a conﬁdence of q ∈ (0, 1] for the next question, and conﬁdences smaller than T for the remaining (G − η − γ − 1)
questions. The mechanism must incentivize the worker to answer the ﬁrst (η + γ) questions and skip the
last (G − η − γ − 1) questions; for question (η + γ + 1), it must incentivize the worker to answer if q > T
and skip if q < T . Supposing the worker indeed attempts the ﬁrst (η + γ) questions and skips the last (G − η − γ − 1) questions, let x = {x1, . . . , xη+γ} ∈ {−1, 1}η+γ denote the the evaluation of the worker’s answers to the ﬁrst (η + γ) questions. Deﬁne quantities {rj}j∈[η+γ] as rj = 1 − pj for j ∈ {1, . . . , η}, and rj = pj for j ∈ {η + 1, η + γ}. The requirement of incentive compatibility necessitates





1−xj

1+xj

q

f (x1, . . . , xη, −xη+1, . . . , −xη+γ, 1, 0, . . . , 0)

rj 2 (1 − rj ) 2 

x∈{−1,1}η+γ

j∈[η+γ]





+ (1 − q)

f (x1, . . . , xη, −xη+1, . . . , −xη+γ, −1, 0, . . . , 0)

1−xj

1+xj

rj 2 (1 − rj ) 2 

x∈{−1,1}η+γ

j∈[η+γ]





q<T

1−xj

1+xj

≶

f (x1, . . . , xη, −xη+1, . . . , −xη+γ, 0, 0, . . . , 0)

rj 2 (1 − rj) 2  .

q>T

x∈{−1,1}η+γ

j∈[η+γ]

27

The left hand side of this expression is the expected payment if the worker chooses to answer question (η + γ + 1), while the right hand side is the expected payment if she chooses to skip it. For any real-valued variable q, and for any real-valued constants a, b and c,

q<c
aq ≶ b ⇒
q>c

ac = b .

As a result,





1−xj

1+xj

T

f (x1, . . . , xη, −xη+1, . . . , −xη+γ, 1, 0, . . . , 0)

rj 2 (1 − rj ) 2 

x∈{−1,1}η+γ

j∈[η+γ]





+ (1 − T )

f (x1, . . . , xη, −xη+1, . . . , −xη+γ, −1, 0, . . . , 0)

1−xj

1+xj

rj 2 (1 − rj ) 2 

x∈{−1,1}η+γ

j∈[η+γ]





1−xj

1+xj

−

f (x1, . . . , xη, −xη+1, . . . , −xη+γ−1, 0, 0, . . . , 0)

rj 2 (1 − rj) 2  = 0.

x∈{−1,1}η+γ

j∈[η+γ]

(7)

The left hand side of (7) represents a polynomial in (η + γ) variables {rj}ηj=+1γ which evaluates to zero for all values of the variables within a (η + γ)-dimensional solid Euclidean ball. Thus, the coefﬁcients of the
monomials in this polynomial must be zero. In particular, the constant term must be zero. The constant term appears when xj = 1 ∀ j in the summations in (7). Setting the constant term to zero gives

T f (x1 = 1, . . . , xη = 1, −xη+1 = −1, . . . , −xη+γ = −1, 1, 0, . . . , 0) + (1 − T )f (x1 = 1, . . . , xη = 1, −xη+1 = −1, . . . , −xη+γ = −1, −1, 0, . . . , 0) − f (x1 = 1, . . . , xη = 1, −xη+1 = −1, . . . , −xη+γ = −1, 0, 0, . . . , 0) = 0

as desired. Since the arguments above hold for any permutation of the G questions, this completes the proof

for the case of G = N .

Now consider the case G < N . Let g : {−1, 0, 1}N → R+ represent the expected payment given an

evaluation of all the N answers, when the identities of the gold standard questions are unknown. Here,

the expectation is with respect to the (uniformly random) choice of the G gold standard questions. If

(x1, . . . , xN ) ∈ {−1, 0, 1}N are the evaluations of the worker’s answers to the N questions then the ex-

pected payment is

1

g(x1, . . . , xN ) = N

f (xi1 , . . . , xiG ) .

(8)

G (i1,...,iG)⊆{1,...,N }

Notice that when G = N , the functions f and g are identical. In the set {y1, . . . , yi−1, yi+1, . . . , yG}, for some (η, γ) ∈ {0, . . . , G − 1}2 with η + γ < G, suppose
there are η elements with a value 1, γ elements with a value −1, and (G − 1 − η − γ) elements with a value
0. Let us assume for now that i = η + γ + 1, y1 = 1, . . . , yη = 1, yη+1 = −1, . . . , yη+γ = −1, yη+γ+2 = 0, . . . , yG = 0.
Suppose the worker has conﬁdences {p1, . . . , pη+γ} ∈ (T, 1]η+γ for the ﬁrst (η + γ) of the N questions, a conﬁdence of q ∈ (0, 1] for the next question, and conﬁdences smaller than T for the remaining (N − η −
γ − 1) questions. The mechanism must incentivize the worker to answer the ﬁrst (η + γ) questions and skip the last (N −η −γ −1) questions; for the (η +γ +1)th question, the mechanism must incentivize the worker
to answer if q > T and skip if q < T . Supposing the worker indeed attempts the ﬁrst (η + γ) questions and

28

skips the last (N − η − γ − 1) questions, let x = {x1, . . . , xη+γ} ∈ {−1, 1}η+γ denote the the evaluation of the worker’s answers to the ﬁrst (η + γ) questions. Deﬁne quantities {rj}j∈[η+γ] as rj = 1 − pj for j ∈ {1, . . . , η}, and rj = pj for j ∈ {η + 1, η + γ}. The requirement of incentive compatibility necessitates





1−xj

1+xj

q

g(x1, . . . , xη, −xη+1, . . . , −xη+γ, 1, 0, . . . , 0)

rj 2 (1 − rj ) 2 

x∈{−1,1}η+γ

j∈[η+γ]





+ (1 − q)

g(x1, . . . , xη, −xη+1, . . . , −xη+γ, −1, 0, . . . , 0)

1−xj

1+xj

rj 2 (1 − rj ) 2 

x∈{−1,1}η+γ

j∈[η+γ]





q<T

1−xj

1+xj

≶

g(x1, . . . , xη, −xη+1, . . . , −xη+γ, 0, 0, . . . , 0)

rj 2 (1 − rj) 2  . (9)

q>T

x∈{−1,1}η+γ

j∈[η+γ]

Again, applying the fact that for any real-valued variable q and for any real-valued constants a, b and c,
q<c
aq ≶ b ⇒ ac = b, we get that
q>c

T g(x1 = 1, . . . , xη = 1, −xη+1 = −1, . . . , −xη+γ = −1, 1, 0, . . . , 0) + (1 − T )g(x1 = 1, . . . , xη = 1, −xη+1 = −1, . . . , −xη+γ = −1, −1, 0, . . . , 0) − g(x1 = 1, . . . , xη = 1, −xη+1 = −1, . . . , −xη+γ = −1, 0, 0, . . . , 0) = 0 . (10)

The proof now proceeds via induction on the quantity (G − η − γ − 1), i.e., on the number of skipped questions in {y1, . . . , yi−1, yi+1, . . . , yG}. We begin with the case of (G − η − γ − 1) = G − 1 which implies η = γ = 0. In this case (10) simpliﬁes to

T g(1, 0, . . . , 0) + (1 − T )g(−1, 0, . . . , 0) = g(0, 0, . . . , 0) .

Applying the expansion of function g in terms of function f from (8) gives

T (c1f (1, 0, . . . , 0) + c2f (0, 0, . . . , 0)) + (1 − T ) (c1f (−1, 0, . . . , 0) + c2f (0, 0, . . . , 0)) = (c1f (0, 0, . . . , 0) + c2f (0, 0, . . . , 0))

for constants c1 > 0 and c2 > 0 that respectively denote the probabilities that the ﬁrst question is picked and not picked in the set of G gold standard questions. Cancelling out the common terms on both sides of the equation, we get the desired result

T f (1, 0, . . . , 0) + (1 − T )f (−1, 0, . . . , 0) = f (0, 0, . . . , 0) .

Next, we consider the case when (G − η − γ − 1) questions are skipped in the gold standard, and assume that the result is true when more than (G − η − γ − 1) questions are skipped in the gold standard. In (10), the functions g decompose into a sum of the constituent f functions. These constituent functions f are of two types: the ﬁrst where all of the ﬁrst (η + γ + 1) questions are included in the gold standard, and the second where one or more of the ﬁrst (η + γ + 1) questions are not included in the gold standard. The second case corresponds to situations where there are more than (G − η − γ − 1) questions skipped in the gold standard and hence satisﬁes our induction hypothesis. The terms corresponding to these functions thus cancel out in the expansion of (10). The remainder comprises only evaluations of function f for arguments in which the ﬁrst (η + γ + 1) questions are included in the gold standard: since the last (N − η − γ − 1) questions are skipped by the worker, the remainder evaluates to

T c3f (y1, . . . , yη+γ, 1, 0, . . . , 0) + (1 − T )c3f (y1, . . . , yη+γ, −1, 0, . . . , 0) = c3f (y1, . . . , yη+γ, 0, 0, . . . , 0)

29

for some constant c3 > 0. Dividing throughout by c3 gives the desired result. Finally, the arguments above hold for any permutation of the ﬁrst G questions, thus completing the
proof.

A.2 Proof of Theorem 7: Working of Algorithm 2
We ﬁrst state three properties that the constants {αl}Ll=−L deﬁned in Algorithm 2 must satisfy. We will use these properties subsequently in the proof of Theorem 7.

Lemma 13 For every l ∈ {0, . . . , L − 1}

Tl+1αl+1 + (1 − Tl+1)α−(l+1) = Tl+1αl + (1 − Tl+1)α−l ,

(11)

and

Sl+1αl+1 + (1 − Sl+1)α−(l+1) = α0 = 1 .

(12)

Lemma 14 αL > αL−1 > · · · > α−L = 0.

Lemma 15 For any m ∈ {1, . . . , L}, any p > Tm and any z < m,

pαm + (1 − p)α−m > pαz + (1 − p)α−z ,

(13)

and for any m ∈ {0, . . . , L − 1}, any p < Tm+1 and any z > m,

pαm + (1 − p)α−m > pαz + (1 − p)α−z .

(14)

The proof of these results are available at the end of this subsection. Assuming these lemmas hold, we will now complete the proof of Theorem 7.
The choice of α−L = 0 made in Algorithm 2 ensures that the payment is zero whenever any answer in the gold standard evaluates to −L. This choice ensures that the no-free-lunch condition is satisﬁed. One can easily verify that the payment lies in the interval [0, µmax]. It remains to prove that the proposed mechanism is incentive-compatible.
Deﬁne E = ( 1, . . . , G) ∈ {−1, 1}G and E\1 = ( 2, . . . , G). Suppose the worker has conﬁdences p1, . . . , pN for her N answers. For some (s(1), . . . , s(N )) ∈ {0, . . . , L}N suppose pi ∈ (Ts(i), Ts(i)+1) ∀ i ∈ {1, . . . , N }, i.e., s(1), . . . , s(N ) are the correct conﬁdence-levels for her answers. Consider any other set of conﬁdence-levels s (1), . . . , s (N ). When the mechanism of Algorithm 2 is employed, the expected
30

payment (from the point of view of the worker) on selecting conﬁdence-levels s(1), . . . , s(N ) is

1 E[Pay] = N
G
1 =N
G
... 1
=N
G
1 >N
G

G

1+ i

1− i

α is(ji)(pji ) 2 (1 − pji ) 2

(j1,...,jG) E∈{−1,1}G i=1 ⊆{1,...,N }

pj1 αs(j1) + (1 − pj1 )α−s(j1)
(j1,...,jG) E\1∈{−1,1}G−1 ⊆{1,...,N }

G
(j1,...,jG) i=1 ⊆{1,...,N }
G
(j1,...,jG) i=1 ⊆{1,...,N }

pji αs(ji) + (1 − pji )α−s(ji) pji αs (ji) + (1 − pji )α−s (ji)

(15)

G

1+ i

1− i

α is(ji)(pji ) 2 (1 − pji ) 2

i=2

(16)

(17)

(18)

which is the expected payment under any other set of conﬁdence-levels s (1), . . . , s (N ). The last inequality is a consequence of Lemma 15.
An argument similar to the above also proves that for any m ∈ {1, . . . , L}, if allowed to choose between only skipping and conﬁdence-level m, the worker is incentivized to choose conﬁdence-level m over skip if her conﬁdence is greater Sm, and choose skip over level m if if her conﬁdence is smaller than Sm. Finally, from Lemma 14 we have αL > · · · > α−L = 0. It follows that the expected payment (17) is strictly increasing in each of the values p1, . . . , pN . Thus the worker is incentivized to report the answer that she thinks is most likely to be correct.

A.2.1 Proof of Lemma 13
Algorithm 2 states that α−l = 11−−αSlSl l for all l ∈ [L]. A simple rearrangement of the terms in this expression gives (12).
Towards the goal of proving (11), we will ﬁrst prove an intermediate result:

αl > 1 > α−l ∀ l ∈ {L, . . . , 1} .

(19)

The proof proceeds via an induction on l ∈ {L, . . . , 2}. The case of l = 1 will be proved separately. The induction hypothesis involves two claims: αl > 1 > α−l and Tlαl + (1 − Tl)α−l > 1. The base case is l = L for which we know that αL = S1L > 1 > 0 = α−L and Tlαl + (1 − Tl)α−l = STll > 1. Now suppose that the induction hypothesis is true for (l + 1). Rearranging the terms in the expression deﬁning αl in Algorithm 2 and noting that 1 > Tl+1 > Sl, we get

αl = (1 − Sl) Tl+1αl+1 + (1 − Tl+1)α−(l+1) − (1 − Tl+1) (20) (1 − Sl) − (1 − Tl+1)

> (1 − Sl) − (1 − Tl+1) (21) (1 − Sl) − (1 − Tl+1)

=1.

(22)

31

From (12) we see that the value 1 is a convex combination of αl and α−l. Since αl > 1 and Sl ∈ (0, 1), it must be that α−l < 1. Furthermore, since Tl > Sl we get

Tlαl + (1 − Tl)α−l > Slαl + (1 − Sl)α−l

(23)

=1.

(24)

This proves the induction hypothesis. Let us now consider l = 1. If L = 1 then we have αL = S1L > 1 > 0 = α−L and we are done. If L > 1 then we have already proved that α2 > 1 > α−2 and T2α2 + (1 − T2)α−2 > 1. An argument identical to (20) onwards proves that α1 > 1 > α−1.
Now that we have proved αl > α−l∀ l ∈ [L], we can rewrite the expression deﬁning α−l in Algorithm 2 as
Sl = 1 − α−l . (25) αl − α−l
Substituting this expression for Sl in the deﬁnition of αl in Algorithm 2 and making some simple rearrangements gives the desired result (11).

A.2.2 Proof of Lemma 14

We have already shown (19) in the proof of Lemma 13 above that αl > 1 > α−l ∀ l ∈ [L].

Next we will show that αl+1 > αl and α−(l+1) < α−l ∀ l ≥ 0. First consider l = 0, for which

Algorithm 2 sets α0 = 1, and we have already proved that α1 > 1 > α−1.

Now consider some l > 0. Observe that since Slαl + (1 − Sl)α−l = 1 (Lemma 13), Sl+1 > Sl and

αl > α−l, it must be that

Sl+1αl + (1 − Sl+1)α−l > 1 .

(26)

From Lemma 13, we also have

Sl+1αl+1 + (1 − Sl+1)α−(l+1) = 1 .

(27)

Subtracting (26) from (27) we get

Sl+1(αl+1 − αl) + (1 − Sl+1)(α−(l+1) − α−l) < 0 .

(28)

From Lemma 13 we also have

Tl+1αl+1 + (1 − Tl+1)α−(l+1) = Tl+1αl + (1 − Tl+1)α−l

(29)

⇒ Tl+1(αl+1 − αl) + (1 − Tl+1)(α−(l+1) − α−l) = 0 .

(30)

Subtracting (28) from (30) gives

(Tl+1 − Sl+1)[(αl+1 − αl) + (α−l − α−(l+1))] > 0 .

(31)

Since Tl+1 > Sl+1 by deﬁnition, it must be that

αl+1 − αl > α−(l+1) − α−l .

(32)

Now, rearranging the terms in (29) gives

(αl+1 − αl)Tl+1 = −(α−(l+1) − α−l)(1 − Tl+1) .

(33)

Since Tl+1 ∈ (0, 1), it follows that the terms (αl+1−αl) and (α−(l+1)−α−l) have opposite signs. Using (32) we conclude that αl+1 − αl > 0 and α−(l+1) − α−l < 0.

32

A.2.3 Proof of Lemma 15

Let us ﬁrst prove (13). First consider the case z = m − 1. From Lemma 13 we know that

Tmαm−1 + (1 − Tm)α−(m−1) = Tmαm + (1 − Tm)α−m

⇒

0 = Tm(αm − αm−1) + Tm(α−(m−1) − α−m) − (α−(m−1) − α−m)

< p(αm − αm−1) + p(α−(m−1) − α−m) − (α−(m−1) − α−m) , (34)

where (34) is a consequence of p > Tm and Lemma 14. A simple rearrangement of the terms in (34) gives (13). Now, for any z < m, recursively apply this result to get

pαm + (1 − p)α−m > pαm−1 + (1 − p)α−(m−1) > pαm−2 + (1 − p)α−(m−2) ... > pαz + (1 − p)α−z .

Let us now prove (14). We ﬁrst consider the case z = m + 1. From Lemma 13 we know that

Tm+1αm + (1 − Tm+1)α−m = Tm+1αm+1 + (1 − Tm+1)α−(m+1)

⇒

0 = Tm+1(αm+1 − αm) + Tm+1(α−m − α−(m+1)) − (α−m − α−(m+1))

> p(αm+1 − αm) + p(α−m − α−(m+1)) − (α−m − α−(m+1)) , (35)

where (35) is a consequence of p < Tm+1 and Lemma 14. A simple rearrangement of the terms in (35) gives (14). For any z > m, applying this result recursively gives

pαm + (1 − p)α−m > pαm+1 + (1 − p)α−(m+1) > pαm+2 + (1 − p)α−(m+2) ... > pαz + (1 − p)α−z .

A.3 Proof of Theorem 8: Uniqueness of Algorithm 2

We will ﬁrst deﬁne one additional piece of notation. Let g : {−L, . . . , L}N → R+ denote the expected payment given an evaluation of the N answers, where the expectation is with respect to the (uniformly random) choice of the G gold standard questions. If (x1, . . . , xN ) ∈ {−L, . . . , L}N are the evaluations of the worker’s answers to the N questions then the expected payment is

1

g(x1, . . . , xN ) = N

f (xi1 , . . . , xiG ) .

(36)

G (i1,...,iG)⊆{1,...,N }

Notice that when G = N , the functions f and g are identical. The proof of uniqueness is based on a certain condition necessitated by incentive-compatibility stated in
the form of Lemma 16 below. Note that this lemma does not require the generalized-no-free-lunch condition, and may be of independent interest.

Lemma 16 Any incentive-compatible mechanism must satisfy, for every question i ∈ {1, . . . , G}, every (y1, . . . , yi−1, yi+1, . . . , yG) ∈ {−L, . . . , L}G−1, and every m ∈ {1, . . . , L},

Tmf (y1, . . . , yi−1, m, yi+1, . . . , yG) + (1 − Tm)f (y1, . . . , yi−1, −m, yi+1, . . . , yG) = Tmf (y1, . . . , yi−1, m − 1, yi+1, . . . , yG) + (1 − Tm)f (y1, . . . , yi−1, −(m − 1), yi+1, . . . , yG) (37)

33

and

Smf (y1, . . . , yi−1, m, yi+1, . . . , yG) + (1 − Sm)f (y1, . . . , yi−1, −m, yi+1, . . . , yG)

= f (y1, . . . , yi−1, 0, yi+1, . . . , yG) .

(38)

Note that (37) and (38) coincide when m = 1, since T1 = S1 by deﬁnition. We will ﬁrst prove that any incentive compatible mechanism that satisﬁes the no-free-lunch condition
must give a zero payment when one or more questions are selected with a conﬁdence L and turn out to be incorrect. Let us assume for now that in the G questions in the gold standard, the ﬁrst question is answered incorrectly with a conﬁdence of L, the next (G − 1 − S) questions are answered by the worker and have arbitrary evaluations, and the remaining S questions are skipped. The proof proceeds by an induction on S. If S = G − 1, the only attempted question is the ﬁrst question and this is incorrect with conﬁdence L. The no-free-lunch condition necessitates a zero payment in this case, thus satisfying the base case of our induction hypothesis. Now we prove the hypothesis for some S under the assumption that the hypothesis is true for every S > S. From Lemma 4 with m = 1, we have

T1f (−L, y2, . . . , yG−S−1, 1, 0, . . . , 0) + (1 − T1)f (−L, y2, . . . , yG−S−1, −1, 0, . . . , 0)

= T1f (−L, y2, . . . , yG−S−1, 0, 0, . . . , 0) + (1 − T1)f (−L, y2, . . . , yG−S−1, 0, 0, . . . , 0)

= f (−L, y2, . . . , yG−S−1, 0, 0, . . . , 0)

=0,

(39)

where the ﬁnal equation (39) is a consequence of our induction hypothesis given the fact that f (−L, y2, . . . , yG−S−1, 0, 0, . . . ,

corresponds to the case when the last (S + 1) questions are skipped and the ﬁrst question is answered incor-

rectly with conﬁdence L. Now, since the payment f must be non-negative and since T ∈ (0, 1), it must be

that

f (−L, y2, . . . , yG−S−1, 1, 0, . . . , 0) = 0

(40)

and

f (−L, y2, . . . , yG−S−1, −1, 0, . . . , 0) = 0 .

(41)

Repeatedly applying the same argument to m = 2, . . . , L gives that for every value of m, it must be that f (−L, y2, . . . , yG−S−1, m, 0, . . . , 0) = f (−L, y2, . . . , yG−S−1, −m, 0, . . . , 0) = 0. This completes the proof of our induction hypothesis. Observe that each of the aforementioned arguments hold for any permutation of the G questions, thus proving the necessity of zero payment when any one or more answers are incorrect.
We will now prove that when no answers in the gold standard are incorrect with conﬁdence L, the payment must be of the form described in Algorithm 1. Let κ denote the payment when all G questions in the gold standard are skipped, i.e.,
κ = f (0, . . . , 0) .

Now consider any S ∈ {0, . . . , G − 1} and any (y1, . . . , yG−S−1, m) ∈ {−L, . . . , L}G−S. The payments {f (y1, . . . , yG−S−1, m, 0, . . . , 0)}Lm=−L must satisfy the (2L−1) linear constraints arising out of Lemma 16 and must also satisfy f (y1, . . . , yG−S−1, −L, 0, . . . , 0) = 0. This comprises a total of 2L linearly independent constraints on the (2L + 1) values {f (y1, . . . , yG−S−1, m, 0, . . . , 0)}Lm=−L. The only set of solutions
that meet these constraints are

f (y1, . . . , yG−S−1, m, 0, . . . , 0) = αmf (y1, . . . , yG−S−1, 0, 0, . . . , 0) ,

34

where the constants {αm}Lm=−L are as speciﬁed in Algorithm 2. Applying this argument G times, starting from S = 0 to S = G − 1, gives
G
f (y1, . . . , yG) = κ αyj .
j=1
Finally, the budget requirement necessitates µmax = κ (αL)G, which mandates the value of κ to be µmax α1L G. This is precisely the mechanism described in Algorithm 2.

A.4 Proof of Lemma 16: Necessary condition for any incentive-compatible mechanism
First consider the case of G = N . For every j ∈ {1, . . . , i − 1, i + 1, . . . , G}, deﬁne

rj = 1 − pj if yj ≥ 0

pj

if yj < 0 .

Deﬁne E\i = { 1, . . . , i−1, i+1, . . . , G}. For any l ∈ {−L, . . . , L} let Λl ∈ R+ denote the expected payment (from the worker’s point of view) when her answer to the ith question evaluates to l:





Λl =

f (y1 1, . . . , yi−1 i−1, l, yi+1 i+1, . . . , yG G)

1− j

1+ j

rj 2 (1 − rj) 2  .

E\i∈{−1,1}G−1

j∈[G]\{i}

(42)

Consider a worker who has conﬁdences {p1, . . . , pi−1, pi+1, . . . , pG} ∈ (0, 1)G−1 for questions {1, . . . , i− 1, i + 1, . . . , G} respectively, and for question i suppose she has a conﬁdence of q ∈ (Tm−1, Tm+1). For question i, we must incentivize the worker to select conﬁdence-level m if q > Tm, and to select (m − 1) if q < Tm. This necessitates

q<Tm

qΛm + (1 − q)Λ−m ≶ qΛm−1 + (1 − q)Λ−(m−1) .

(43)

q>Tm

Also, for question i, the requirement of level m having a higher incentive as compared to skipping when q > Sm and vice versa when q < Sm necessitates

q<Sm

qΛm + (1 − q)Λ−m ≶ Λ0 .

(44)

q>Sm

Now, note that for any real-valued variable q, and for any real-valued constants a, b and c,

q<c
aq ≶ b ⇒ ac = b .
q>c

Applying this fact to (43) and (44) gives

(TmΛm + (1 − Tm)Λ−m) − (TmΛm−1 + (1 − Tm)Λ−(m−1)) = 0 ,

(45)

(SmΛm + (1 − Sm)Λ−m) − Λ0 = 0 .

(46)

From the deﬁnition of Λl in (42), we see that the left hand sides of (45) and (46) are both polynomials in (G − 1) variables {rj}j∈[G]\{i} and take a value of zero for all values of the variables in a (G − 1)dimensionall solid ball. Thus, each of the coefﬁcients (of the monomials) in both polynomials must be zero,
and in particular, the constant terms must also be zero. Observe that in both these polynomials, the constant

35

term arises only when j = 1 ∀ j ∈ [G]\{i} (which makes the exponent of rj to be 0 and that of (1 − rj) to be 1). Thus, setting the constant term to zero in the two polynomials results in

Tmf (y1, . . . , yi−1, m, yi+1, . . . , yG) + (1 − Tm)f (y1, . . . , yi−1, −m, yi+1, . . . , yG) = Tmf (y1, . . . , yi−1, m − 1, yi+1, . . . , yG) + (1 − Tm)f (y1, . . . , yi−1, −(m − 1), yi+1, . . . , yG) (47)

and

Smf (y1, . . . , yi−1, m, yi+1, . . . , yG) + (1 − Sm)f (y1, . . . , yi−1, −m, yi+1, . . . , yG)

= f (y1, . . . , yi−1, 0, yi+1, . . . , yG)

(48)

thus proving the claim for the case of G = N .
Now consider the case when G < N . In order to simplify notation, let us assume i = 1 without loss of generality (since the arguments presented hold for any permutation of the questions). Suppose a worker’s answers to questions {2, . . . , G} evaluate to (y2, . . . , yG) ∈ {−L, . . . , L}G−1, and further suppose that the worker skips the remaining (N − G) questions. By going through arguments identical to those for G = N , but with f replaced by g, we get the necessity of

Tmg(m, y2, . . . , yG, 0, . . . , 0) + (1 − Tm)g(−m, y2, . . . , yG, 0, . . . , 0) = Tmg(m − 1, y2, . . . , yG, 0, . . . , 0) + (1 − Tm)g(−(m − 1), y2, . . . , yG, 0, . . . , 0) (49)

and

Smg(m, y2, . . . , yG, 0, . . . , 0) + (1 − Sm)g(−m, y2, . . . , yG, 0, . . . , 0) = g(0, y2, . . . , yG, 0, . . . , 0) . (50)

We will now use this result in terms of function g to get an equivalent result in terms of function f . For some S ∈ {0, . . . , G − 1}, suppose yG−S+1 = 0, . . . , yG = 0. The remaining proof proceeds via an induction on S. We begin with S = G − 1. In this case, (49) and (50) simplify to

Tmg(m, 0, . . . , 0) + (1 − Tm)g(−m, 0, 0, . . . , 0)

= Tmg(m − 1, 0, . . . , 0) + (1 − Tm)g(−(m − 1), 0, . . . , 0)

(51)

and

Smg(m, 0, . . . , 0) + (1 − Sm)g(−m, 0, . . . , 0) = g(0, 0, . . . , 0) .

(52)

Applying the deﬁnition of function g from (36) leads to

Tm (c1f (m, 0, . . . , 0) + c2f (0, 0, . . . , 0)) + (1 − Tm) (c1f (−m, 0, . . . , 0) + c2f (0, 0, . . . , 0))

= Tm (c1f (m − 1, 0, . . . , 0) + c2f (0, 0, . . . , 0))

+ (1 − Tm) (c1f (−(m − 1), 0, . . . , 0) + c2f (0, 0, . . . , 0)) ,

(53)

and

Sm (c1f (m, 0, . . . , 0) + c2f (0, 0, . . . , 0)) + (1 − Sm) (c1f (−m, 0, . . . , 0) + c2f (0, 0, . . . , 0))

= (c1f (0, 0, . . . , 0) + c2f (0, 0, . . . , 0))

(54)

36

for constants c1 > 0 and c2 > 0 that respectively denote the probabilities that the ﬁrst question is picked and not picked in the set of G gold standard questions. Cancelling out the common terms on both sides of the equation, we get the desired results

Tmf (m, 0, . . . , 0) + (1 − Tm)f (−m, 0, . . . , 0)

= Tmf (m − 1, 0, . . . , 0) + (1 − Tm)f (−(m − 1), 0, . . . , 0)

(55)

and

Smf (m, 0, . . . , 0) + (1 − Sm)f (−m, 0, . . . , 0) = f (0, 0, . . . , 0) .

(56)

Next, we consider the case of a general S ∈ {0, . . . , G − 2} and assume that the result is true when yG−S = 0, . . . , yG = 0. In (49) and (50), the functions g decompose into a sum of the constituent f functions. These constituent functions f are of two types: the ﬁrst where all of the ﬁrst (G − S) questions are included in the gold standard, and the second where one or more of the ﬁrst (G − S) questions are not included in the gold standard. The second case corresponds to situations where there are more than S questions skipped in the gold standard, i.e., when yG−S = 0, . . . , yG = 0, and hence satisﬁes our induction hypothesis. The terms corresponding to these functions thus cancel out in the expansion of (49) and (50). The remainder comprises only evaluations of function f for arguments in which the ﬁrst (G − S) questions are included in the gold standard: since the last (N − G + S) questions are skipped by the worker, the remainder evaluates to

Tmc3f (y1, . . . , yi−1, m, yi+1, . . . , yG) + (1 − Tm)c3f (y1, . . . , yi−1, −m, yi+1, . . . , yG) = Tmc3f (y1, . . . , yi−1, m − 1, yi+1, . . . , yG) + (1 − Tm)c3f (y1, . . . , yi−1, −(m − 1), yi+1, . . . , yG) ,
Smc3f (y1, . . . , yi−1, m, yi+1, . . . , yG) + (1 − Sm)c3f (y1, . . . , yi−1, −m, yi+1, . . . , yG) = c3f (y1, . . . , yi−1, 0, yi+1, . . . , yG) ,

for some constant c3 > 0. Dividing throughout by c3 gives the desired result. Finally, the arguments above hold for any permutation of the ﬁrst G questions, thus completing the
proof.

A.5 Necessity of Tl > Sl for the Problem to be Well Deﬁned
We now show that the restriction Tl > Sl was necessary when deﬁning the thresholds in Section 4.

Proposition 17 Incentive-compatiblity necessitates Tl > Sl ∀ l ∈ {2, . . . , L}, even in the absence of the generalized-no-free-lunch axiom.

First observe that the proof of Lemma 16 did not employ the generalized-no-free-lunch axiom, neither did it assume Tl > Sl. We will thus use the result of Lemma 16 to prove our claim.
Suppose the conﬁdence of the worker for all but the ﬁrst question is lower than T1 and that the worker decides to skip all these questions. Suppose the worker attempts the ﬁrst question. In order to ensure that the worker selects the answer that she believes is most likely to be true, it must be that

f (l, 0, . . . , 0) > f (−l, 0, . . . , 0) ∀l ∈ [L] .

(57)

37

We now call upon Lemma 16 where we set i = 1, m = l, y2 = . . . , yG = 0. Using the fact that Tl > Tl−1 ∀l ∈ {2, . . . , L}, we get

Tlf (l, 0, . . . , 0) + (1 − Tl)f (−l, 0, . . . , 0)

= Tlf (l − 1, 0, . . . , 0) + (1 − Tl)f (−(l − 1), 0, . . . , 0)

(58)

> Tl−1f (l − 1, 0, . . . , 0) + (1 − Tl−1)f (−(l − 1), 0, . . . , 0)

(59)

= Tl−1f (l − 2, 0, . . . , 0) + (1 − Tl−1)f (−(l − 2), 0, . . . , 0)

(60)

> Tl−2f (l − 2, 0, . . . , 0) + (1 − Tl−2)f (−(l − 2), 0, . . . , 0)

(61)

...

> T1f (1, 0, . . . , 0) + (1 − T1)f (−1, 0, . . . , 0)

(62)

= f (0, . . . , 0)

(63)

= Slf (l, 0, . . . , 0) + (1 − Sl)f (−l, 0, . . . , 0).

(64)

Since f (l, 0, . . . , 0) > f (−l, 0, . . . , 0), we have our desired result.

A.6 A Stronger No-free-lunch Condition: Impossibility Results
In this section, we prove the various claims regarding the strong no-free-lunch condition studied in Section 5.

A.6.1 Proof of Proposition 9
If the worker skips all questions, then the expected payment is zero under the strong-no-free-lunch axiom. On the other hand, in order to incentivize knowledgeable workers to select answers whenever their conﬁdences are greater than T , there must exist some situation in which the payment is strictly larger than zero. Suppose the payment is strictly positive when questions {1, . . . , z} are answered correctly, questions {z + 1, . . . , z } are answered incorrectly, and the remaining questions are skipped. If the conﬁdence of the unknowledgeable worker is in the interval (0, T ) for every question, then attempting to answer questions {1, . . . , z } and skipping the rest fetches her a payment that is strictly positive in expectation. Thus, this unknowledgeable worker is incentivized to answer at least one question.

A.6.2 Proof of Proposition 10
Consider a (knowledgeable) worker who has a conﬁdence of p ∈ (T, 1] for the ﬁrst question, q ∈ (0, 1) for the second question, and conﬁdences in the interval (0, T ) for the remaining questions. Suppose the worker attempts to answer the ﬁrst question (and selects the answer the believes is most likely to be correct) and skips the last (N − 2) questions as desired. Now, in order to incentivize her to answer the second question if q > T and skip the second question if q < T , the payment mechanism must satisfy

pqg(1, 1, 0, . . . , 0) + (1 − p)qg(−1, 1, 0, . . . , 0) + p(1 − q)g(1, −1, 0, . . . , 0)
q<T
+ (1 − p)(1 − q)g(−1, −1, 0, . . . , 0) ≶ pg(1, 0, 0, . . . , 0) + (1 − p)g(−1, 0, 0, . . . , 0) . (65)
q>T

For any real-valued variable q, and for any real-valued constants a, b and c,

q<c
aq ≶ b ⇒
q>c

ac = b .

38

As a result,

pT g(1, 1, 0, . . . , 0) + (1 − p)T g(−1, 1, 0, . . . , 0) + p(1 − T )g(1, −1, 0, . . . , 0) + (1 − p)(1 − T )g(−1, −1, 0, . . . , 0) − pg(1, 0, 0, . . . , 0) − (1 − p)g(−1, 0, 0, . . . , 0) = 0 . (66)

The left hand side of this equation is a polynomial in variable p and takes a value of zero for all values of p in a one-dimensional box (T, 1]. It follows that the monomials of this polynomial must be zero, and in particular the constant term must be zero:

T g(−1, 1, 0, . . . , 0) + (1 − T )g(−1, −1, 0, . . . , 0) − g(−1, 0, 0, . . . , 0) = 0 .

(67)

The strong-no-free-lunch condition implies f (−1, −1, 0, . . . , 0) = f (−1, 0, . . . , 0) = f (0, . . . , 0) = 0, and hence g(−1, −1, 0, . . . , 0) = g(−1, 0, 0, . . . , 0) = 0. Since T ∈ (0, 1), we have

0 = g(−1, 1, 0, . . . , 0)

(68)

= c1f (−1, 1, 0, . . . , 0) + c2f (−1, 0, . . . , 0) + c2f (1, 0, . . . , 0) ,

(69)

for some constants c1 > 0 and c2 > 0 that represent the probability that the ﬁrst two questions are included in the gold standard, and the probability that the ﬁrst (or, second) but not the second (or, ﬁrst) questions are included in the gold standard. Since f is a non-negative function, it must be that

f (1, 0, . . . , 0) = 0 .

(70)

Now suppose a (knowledgeable) worker has a conﬁdence of p ∈ (T, 1] for the ﬁrst question and conﬁdences lower than T for the remaining (N − 1) questions. Suppose the worker chooses to skip the last (N − 1) questions as desired. In order to incentivize the worker to answer the ﬁrst question, the mechanism must satisfy for all p ∈ (T, 1],

0 < pg(1, 0, . . . , 0) + (1 − p)g(−1, 0, . . . , 0) − g(0, 0, . . . , 0)

= pc3f (1, 0, . . . , 0) + pc4f (0, 0, . . . , 0) + (1 − p)c3f (−1, 0, . . . , 0)

+ (1 − p)c4f (0, 0, . . . , 0) − f (0, 0, . . . , 0)

= 0,

(71)

where c3 > 0 and c4 > 0 are some constants. The ﬁnal equation is a result of the strong-no-free-lunch condition and the fact that f (1, 0, . . . , 0) = 0 as proved above. This yields a contradiction, and hence no incentive-compatible mechanism f can satisfy the strong-no-free-lunch condition when G < N even when allowed to address only knowledgeable workers.
Finally, as a sanity check, note that if G = N then c2 = 0 in (69). The proof above thus doesn’t hold when G = N .

A.6.3 Proof of Proposition 11
We will ﬁrst show that the mechanism works as desired. First consider the case when the worker is unknowledgeable and her conﬁdences are of the form T >
p(1) ≥ p(2) ≥ p(3) ≥ · · · ≥ p(G). If she answers only the ﬁrst question, then her expected payment is κ p(1) . T
39

Let us now see her expected payment if she doesn’t follow this answer pattern. The strong-no-free-lunch condition implies that if the worker doesn’t answer any question then her expected payment is zero. Suppose the worker chooses to answer questions {i1, . . . , iz}. In that case, her expected payment is

κ pi1 · · · piz = κ pi1 · · · piz

(72)

Tz

TT

p(1) z

≤κ

(73)

T

≤ κ p(1) , (74)

T

where (74) uses the fact that p(1) < T . The inequality in (74) becomes an equality only when z = 1. Now when z = 1, the inequality in (73) becomes an equality only when i1 = (1). Thus the unknowledgeable

worker is incentivized to answer only one question – the one that she has the highest conﬁdence in.

Now consider a knowledgeable worker and suppose her conﬁdences are of the form p(1) ≥ · · · ≥ p(m) >

T > p(m+1) ≥ · · · ≥ p(G) for some m ≥ 1. If the worker answers questions (1), . . . , (m) as desired, her

expected payment is

κ p(1) · · · p(m) .

T

T

Now let us see what happens if the worker does not follow this answer pattern. The strong-no-free-lunch

condition implies that if the worker doesn’t answer any question then her expected payment is zero. Now, if

she answers some other set of questions, say questions {i1, . . . , iz} with p(1) ≤ pi1 < · · · < piy ≤ p(m) < piy+1 < · · · piz ≤ p(G). The expected payment in that case is

κ pi1 · · · piz = κ pi1 · · · piz

(75)

Tz

TT

≤ κ pi1 · · · piy

(76)

TT

≤ κ p(1) · · · p(m) (77)

T

T

where inequality (76) is a result of pTij ≤ 1 ∀ j > y and holds with equality only when y = z. Inequality (77) is a result of pT(j) ≥ 1 ∀ j ≤ m and holds with equality only when y = m. Thus the expected payment is maximized when i1 = (1), . . . , iz = (m) as desired. Finally, the payment strictly increases with an increase in the conﬁdences, and hence the worker is incentivized to always consider the answer that she believes is
most likely to be correct.
We will now show that this mechanism is unique.
The necessary conditions derived in Lemma 4, when restricted to G = N and (y1, . . . , yi−1, yi+1, . . . , yG) = {0}N−1, is also applicable to the present setting. This is because the strong-no-free-lunch condition as-
sumed here is a stronger condition than the no-free-lunch axiom considered in Lemma 4, and moreover, (y1, . . . , yi−1, yi+1, . . . , yG) = {0}N−1 avoids the use of unknowledgeable workers in the proof of Lemma 4. It follows that for every question i ∈ {1, . . . , G} and every (y1, . . . , yi−1, yi+1, . . . , yG) ∈ {−1, 0, 1}G−1\{0}G−1, it must be that

T f (y1, . . . , yi−1, 1, yi+1, . . . , yG) + (1 − T )f (y1, . . . , yi−1, −1, yi+1, . . . , yG)

= f (y1, . . . , yi−1, 0, yi+1, . . . , yG) .

(78)

We claim that the payment must be zero whenever the number of incorrect answers W > 0. The proof proceeds by induction on the number of correct answers C. First suppose C = 0 (and W > 0). Then all questions are either wrong or skipped, and hence by the strong-no-free-lunch condition, the payment must be zero. Now suppose the payment is necessarily zero whenever W > 0 and the total number of correct

40

answers is (C − 1) or lower, for some C ∈ [G − 1]. Consider any evaluation (y1, . . . , yG) ∈ {−1, 0, 1}G in which the number of incorrect answers is more than zero and the number of correct answers is C. Suppose yi = 1 for some i ∈ [G], and yj = −1 for some j ∈ [G]\{i}. Then from the induction hypothesis, we have f (y1, . . . , yi−1, −1, yi+1, . . . , yG) = f (y1, . . . , yi−1, 0, yi+1, . . . , yG) = 0. Applying (78) and noting that T ∈ (0, 1), we get that f (y1, . . . , yi−1, 1, yi+1, . . . , yG) = 0 as claimed. This result also allows us to simplify (78) to: For every question i ∈ {1, . . . , G} and every (y1, . . . , yi−1, yi+1, . . . , yG) ∈ {−1, 0, 1}G−1\{0}G−1,
1 f (y1, . . . , yi−1, 1, yi+1, . . . , yG) = T f (y1, . . . , yi−1, 0, yi+1, . . . , yG) . (79)
We now show that when C > 0 and W = 0, the payment must necessarily be of the form described in the statement of Proposition 11. The proof again proceeds via an induction on the number of correct answers C (≥ 1). Deﬁne a quantity κ > 0 as

κ = T f (1, 0, . . . , 0) .

(80)

Now consider the payment f (1, y2, . . . , yG) for some (y2, . . . , yG) ∈ {0, 1}G−1\{0}G−1 with C correct answers. Applying (79) repeatedly (once for every i such that yi = 1), we get

κ

f (1, y2, . . . , yG) = T C .

(81)

Unlike other results in this paper, at this point we cannot claim the result to hold for all permutations of the questions. This is because we have deﬁned the quantity κ in an asymmetric manner (80), in terms of the payment function when the ﬁrst question is correct and the rest are skipped. In what follows, we will prove that the result claimed in the statement of Proposition 11 indeed holds for all permutations of the questions.
From (79) we have

f (0, 1, 0, . . . , 0) = T f (1, 1, 0, . . . , 0)

(82)

= f (1, 0, 0, . . . , 0)

(83)

=κ.

(84)

Thus the payment must be κ even if the second answer in the gold standard is correct and the rest are skipped. In fact, the argument holds when any one answer in the gold standard is correct and the rest are skipped. Thus the deﬁnition of κ is not restricted to the ﬁrst question alone as originally deﬁned in (80), but holds for all permutations of the questions. This allows the other arguments above to be applicable to any permutation of the questions. Finally, the budget constraint of µmax ﬁxes the value of κ to that claimed, thereby completing the proof.

A.6.4 Proof of Proposition 12
Proposition 11 proved that under the skip-based setting with the strong-no-free-lunch condition, the payment must be zero when one or more answers are incorrect. This part of the proof of Proposition 11 holds even when L > 1. It follows that for any question, the penalty for an incorrect answer is the same for any conﬁdence-level in {1, . . . , L}. Thus the worker is incentivized to always select that conﬁdence-level for which the payment is the maximum when the answer is correct, irrespective of her own conﬁdence about the question. This contradicts our requirements.
41

B Details of Experiments
In this section, we provide further details about the experiments described earlier in Section 6.2. The experiments were carried out on the Amazon Mechanical Turk (mturk.com) online crowdsourcing platform in the time period June to October 2013. Figure 6 illustrates the interface shown to the workers for each of the experiments described in Section 6.2, while Figure 7 depicts the instructions given to the workers. The following are more details of each individual experiment. In the description, the notation κ is as deﬁned in Algorithm 1 and Algorithm 2, namely, κ = (µmax − µmin)T G for the skip-based setting and
G
1 for the conﬁdence-based setting. κ = (µmax − µmin) αL

B.1 Recognizing the Golden Gate Bridge

A set of 21 photographs of bridges were shown to the workers, and for each photograph, they had to identify

if it depicted the Golden Gate Bridge or not. An example of this task is depicted in Figure 6a, and the

instructions provided to the worker under the three mechanisms are depicted in Figure 7. The ﬁxed amount

offered to workers was µmin = 3 cents for the task, and the bonus was based on 3 gold standard questions.

We compared (a) the baseline mechanism with 5 cents for each correct answer in the gold standard, (b) the

skip-based mechanism with κ

=

5.9 and

1 T

=

1.5, and (c) the conﬁdence-based mechanism with κ

=

5.9

cents, L = 2, α2 = 1.5, α1 = 1.4, α0 = 1, α−1 = 0.5, α−2 = 0. The results of this experiment are

presented in Figure 4a.

B.2 Transcribing Vehicles’ License Plate Numbers from Photographs

This task presented the workers with 18 photographs of cars and asked them to transcribe the license plate

numbers from each of them (source of photographs: http://www.coolpl8z.com). An example of this task is

depicted in Figure 6b. The ﬁxed amount offered to workers was µmin = 4 cents for the task, and the bonus

was based on 4 gold standard questions. We compared (a) the baseline mechanism with 10 cents for each

correct answer in the gold standard, (b) the skip-based mechanism with κ

=

0.62 and

1 T

=

3, and (c) the

conﬁdence-based mechanism with κ = 3.1 cents, L = 2, α2 = 2, α1 = 1.95, α0 = 1, α−1 = 0.5 α−2 = 0.

The results of this experiment are presented in Figure 4b. When evaluating, in the worker’s answers as well

as in the true solutions, we converted all text to upper case, and removed all spaces and punctuations. We

then declared a worker’s answer to be in error if it did not have an exact match with the true solution.

B.3 Classifying Breeds of Dogs

This task required workers to identify the breeds of dogs shown in 85 images (source of images: [KJYL11,

DDS+09]). For each image, the worker was given ten breeds to choose from. An example of this task

is depicted in Figure 6c. The ﬁxed amount offered to workers was µmin = 5 cents for the task, and the

bonus was based on 7 gold standard questions. We compared (a) the baseline mechanism with 8 cents for

each correct answer in the gold standard, (b) the skip-based mechanism with κ

=

0.78 and

1 T

=

2, and

(c) the conﬁdence-based mechanism with κ = 0.78 cents, L = 2, α2 = 2, α1 = 1.66, α0 = 1, α−1 =

0.67, α−2 = 0. The results of this experiment are presented in Figure 4c.

B.4 Identifying Heads of Countries
Names of 20 personalities were provided and had to be classiﬁed as to whether they were ever the (a) President of the USA, (b) President of India, (c) Prime Minister of Canada, or (d) neither of these. An example of this task is depicted in Figure 6d. The ﬁxed amount offered to workers was µmin = 2 cents

42

for the task, and the bonus was based on 4 gold standard questions. While the ground truth in most other

multiple-choice experiments had approximately an equal representation from all classes, this experiment

was heavily biased with one of the classes never being correct and another being correct for just 3 of the

20 questions. We compared (a) the baseline mechanism with 2.5 cents for each correct answer in the gold

standard, (b) the skip-based mechanism with κ

=

0.25 and

1 T

=

3, and (c) the conﬁdence-based mechanism

with κ = 1.3 cents, L = 2, α2 = 2, α1 = 1.95, α0 = 1, α−1 = 0.5, α−2 = 0. The results of this

experiment are presented in Figure 4d.

B.5 Identifying Flags

This was a relatively long task, with 126 questions. Each question required the workers to identify if a

displayed ﬂag belonged to a place in (a) Africa, (b) Asia/Oceania, (c) Europe, or (d) neither of these. An

example of this task is depicted in Figure 6e. The ﬁxed amount offered to workers was µmin = 4 cents for

the task, and the bonus was based on 8 gold standard questions. We compared (a) the baseline mechanism

with 4 cents for each correct answer in the gold standard, (b) the skip-based mechanism with κ = 0.2 and

1 T

=

2, and (c) the conﬁdence-based mechanism with κ

=

0.2 cents, L

=

2, α2

=

2,

α1

=

1.66,

α0

=

1, α−1 = 0.67, α−2 = 0. The results of this experiment are presented in Figure 4e.

B.6 Distinguishing Textures

This task required the workers to identify the textures shown in 24 grayscale images (source of images: [LSP05,

Dataset 1: Textured surfaces]). For each image, the worker had to choose from 8 different options. Such

a task has applications in computer vision, where it aids in recognition of objects or their surroundings.

An example of this task is depicted in Figure 6f. The ﬁxed amount offered to workers was µmin = 3

cents for the task, and the bonus was based on 4 gold standard questions. We compared (a) the base-

line mechanism with 10 cents for each correct answer in the gold standard, (b) the skip-based mecha-

nism with κ

=

3.1

and

1 T

=

2, and (c) the conﬁdence-based mechanism with κ

=

3.1 cents, L

=

2,

α2 = 2, α1 = 1.66, α0 = 1, α−1 = 0.67, α−2 = 0. The results of this experiment are presented in

Figure 4f.

B.7 Transcribing Text from an Image: Film Certiﬁcate

The task showed an image containing 11 (short) lines of blurry text which the workers had to decipher. We

used text from a certain certiﬁcate which movies releasing in India are provided. We slightly modiﬁed its

text in order to prevent workers from searching a part of it online and obtaining the entire text by searching

the ﬁrst few transcribed lines on the internet. An example of this task is depicted in Figure 6g. The ﬁxed

amount offered to workers was µmin = 5 cents for the task, and the bonus was based on 2 gold standard

questions. We compared (a) the baseline mechanism with 20 cents for each correct answer in the gold

standard, (b) the skip-based mechanism with κ

=

5.5 and

1 T

=

3, and (c) the conﬁdence-based mechanism

with κ = 12.5 cents, L = 2, α2 = 2, α1 = 1.95, α0 = 1, α−1 = 0.5, α−2 = 0. The results of this

experiment are presented in Figure 4g. When evaluating, in the worker’s answers as well as in the true

solutions, we converted all text to upper case, and removed all spaces and punctuations. We then declared a

worker’s answer to be in error if it did not have an exact match with the true solution.

B.8 Transcribing Text from an Image: Script of a Play
The task showed an image containing 12 (short) lines of blurry text which the workers had to decipher. We borrowed a paragraph from Shakespeare’s play ‘As You Like It.’ We slightly modiﬁed the text of the play in order to prevent workers from searching a part of it online and obtaining the entire text by searching the ﬁrst

43

few transcribed lines on the internet. An example of this task is depicted in Figure 6h. The ﬁxed amount

offered to workers was 5 cents for the task, and the bonus was based on 2 gold standard questions. We

compared (a) the baseline mechanism with µmin = 20 cents for each correct answer in the gold standard,

(b) the skip-based mechanism with κ

=

5.5

and

1 T

=

3, and (c) the conﬁdence-based mechanism with

κ = 12.5 cents, L = 2, α2 = 2, α1 = 1.95, α0 = 1, α−1 = 0.5, α−2 = 0. The results of this experiment

are presented in Figure 4h. When evaluating, in the worker’s answers as well as in the true solutions, we

converted all text to upper case, and removed all spaces and punctuations. We then declared a worker’s

answer to be in error if it did not have an exact match with the true solution.

B.9 Transcribing Text from Audio Clips

The workers were given 10 audio clips which they had to transcribe to text. Each audio clip was 3 to

6 seconds long, and comprised of a short sentence, e.g., “my favourite topics of conversation are sports,

politics, and movies.” Each of the clips were recorded in different accents using a text-to-speech converter.

An example of this task is depicted in Figure 6i. The ﬁxed amount offered to workers was µmin = 5 cents for

the task, and the bonus was based on 2 gold standard questions. We compared (a) the baseline mechanism

with 20 cents for each correct answer in the gold standard, (b) the skip-based mechanism with κ = 5.5 and

1 T

=

3, and (c) the conﬁdence-based mechanism with κ

=

12.5 cents, L

=

2, α2

=

2,

α1

=

1.95,

α0

=

1, α−1 = 0.5, α−2 = 0. The results of this experiment are presented in Figure 4i.

a

Recognize*the** b Transcribe*the** c Mark*the*breed*of*the*dog*

Golden*Gate*Bridge* license*plate*number*

Afghan Hound

Doberman

Golden Gate

French Bulldog

NOT Golden Gate Answer:

Tibetan Terrier


d Iden2fy*heads*of*countries* Mohandas Gandhi
President of the USA President of India Prime Minister of Canada None of the above
g Transcribe*text*(playscript)*

e Mark*the*con2nent* to*which*the*ﬂag*belongs*
Africa Asia/Oceania Europe None of these
h Transcribe*text*(cer2ﬁcate)*

f Iden2fy*the*texture*
Granite Carpet Fur Glass Corduroy Wood None of these
i Transcribe*the*audio*clip*

Line 1: Line 2:

Line 1: Line 2:

Answer:

Figure 6: Various tasks on which the payment mechanisms were tested. The interfaces shown are that of the baseline mechanism, i.e., without the skipping or conﬁdence choices.

C General Utility Functions
In this section, we consider a setting where the worker, instead of maximizing her expected payment, aims to maximize the expected value of some utility function of her payment. Consider any function U : R+ → I, where I is any interval on the real number line. We will require the function U to be strictly increasing a√nd to have an inverse. Examples of such functions include U (x) = log(1 + x) with I = R+, U (x) = x with I = R+, and U (x) = 1 − e−x with I = [0, 1]. For any payment f made to the worker (based on the
44

a Baseline*Mechanism*
***$Instruc?ons$for$BONUS$(Read$Carefully)$***$
• There$are$three$ques?ons$whose$answers$are$known$to$us,$based$on$which$the$bonus$is$calculated$ • BONUS$(cents)=$5$*$number$of$ques?ons$out$of$these$that$you$correctly$answer$$
b SkipEbased*mul2plica2ve*mechanism*
If$you$are$not$sure$about$any$answer,$then$mark$"I'm$not$sure”$ You$need$to$mark$at$least$something$for$every$ques?on,$otherwise$your$work$will$be$rejected$ $ ***$Instruc?ons$for$BONUS$(Read$Carefully)$***$ • You$start$with$5.9$cents$of$bonus$for$this$HIT$ • There$are$three$ques?ons$whose$answers$are$known$to$us,$based$on$which$the$bonus$is$calculated$ • For$each$of$these$ques?ons$you$answer$CORRECTLY,$your$bonus$will$INCREASE$BY$50%$(every$1$cent$will$become$1.5$cents)$ • If$you$answer$any$of$these$ques?ons$WRONG,$your$bonus$will$become$ZERO$ • So$for$ques?ons$you$are$not$sure$of,$mark$the$"I'm$not$sure"$op?on:$this$does$not$aﬀect$the$bonus$
c ConﬁdenceEbased*mul2plica2ve*mechanism*
For$each$answer,$you$also$need$to$indicate$how$sure$you$are$about$that$answer$ $If$you$are$not$sure$about$any$answer,$then$mark$"I$don't$know”$ $You$need$to$mark$at$least$something$for$every$ques?on,$otherwise$your$work$will$be$rejected$ $ ***$Instruc?ons$for$BONUS$(Read$Carefully)$***$ • If$any$answer$marked$"absolutely$sure"$is$wrong,$your$bonus$will$become$ZERO$for$this$en?re$HIT$(you$do$not$get$any$bonus$for$this$HIT)$ • For$every$answer$marked$"absolutely$sure"$that$is$correct,$your$bonus$will$INCREASE$BY$50%$(every$1$cent$will$become$1.5$cents)$ • For$every$answer$marked$"moderately$sure"$that$is$wrong,$your$bonus$will$be$HALVED$(every$1$cent$will$become$half$a$cent)$ • For$every$answer$marked$"moderately$sure"$that$is$correct,$your$bonus$will$be$INCREASE$BY$40%$(every$1$cent$will$become$1.4$cents)$ • Marking$"I$don't$know"$for$any$answer$does$not$change$your$bonus$
Figure 7: An example of the instructions displayed to the worker under the three mechanisms.
evaluation of her answers to the gold standard questions), her utility for this payment is U (f ). The worker aims to maximize the expected value of U (f ), where the expectation is with respect to her beliefs regarding correctness of her answers and the uniformly random distribution of the G gold standard questions among the set of N questions. The function U is assumed to be known to the worker as well as the system designer.
Consider the conﬁdence-based setting of Section 4 (of which, the skip-based setting of Section 3 is a special case). Recall the notation {xi}Gi=1, {αj}Lj=−L and κ from Algorithm 2. Also recall the (generalized)no-free-lunch axiom which mandates a zero payment if, in the gold standard, (all attempted questions are marked as the highest conﬁdence L and) the answers to all the attempted questions are incorrect. The following proposition extends the results of the main text in the paper to this setting with utility functions.
Proposition 18 For a worker who aims to maximize function U of the payment, the one and only mechanism that is incentive-compatible and satisﬁes the (generalized-)no-free-lunch axiom is
G
Payment(x1, . . . , xG) = U −1 κ αxi + U (µmin) ,
i=1
where the constants {αj}Lj=−L are as deﬁned in Algorithm 2 and κ = (U (µmax) − U (µmin))αL−G.
Note that for the problem to be well deﬁned, the interval [µmin, µmax] should be contained in the interval I. The proof of Proposition 18 follows easily from the results proved earlier in the paper, and is provided below for completeness.
45

Proof of Proposition 18. We will ﬁrst verify that the proposed payment is always non-negative and satis-

ﬁes the (generalized-)no-free-lunch axiom. Recall from Theorem 7 that for every evaluation {x1, . . . , xG}

for which the (generalized-)no-free-lunch axiom mandates a zero payment, the value of κ

G i=1

αxi

is

zero.

It follows that the payment U −1 κ

G i=1

αxi

+

U (µmin)

= U −1(0 + U (µmin)) = µmin, where the ﬁnal

equation is a consequence of the invertibility of U . Further, recall that the value of κ

G i=1

αxi

in

Algo-

rithm 2 is never smaller than zero. Since the function U is increasing, so is U −1, and hence the payment is

always non-negative.

We will now prove that the proposed payment is incentive-compatible. To this end, observe that the

utility of the proposed payment is

G
U (Payment) = U U −1 κ αxi + U (µmin)
i=1 G
= κ αxi + U (µmin) .
i=1

Noting that U (0) is a constant independent of the worker’s answers, the result of Theorem 7 implies that the expectation of U (Payment) behaves exactly as required for incentive-compatibility.
We will now prove uniqueness of this mechanism. Replacing f (·) by U (Payment(·)) in the proof of Theorem 8, we get that the function U (Payment) must be of the form

G
U (Payment(x1, . . . , xG)) = c1 αxi + c2,
i=1

for some constants c1 and c2, where {αxj }Lj=−L are as deﬁned in Algorithm 2. In other words, the payment must be of the form
G
Payment(x1, . . . , xG) = U −1 c1 αxi + c2 .
i=1

One can evaluate that the maximum value of this payment is c1 + c2. From our µmax-budget constraint, we then have c1 + c2 = µmax. Furthermore, When the evaluations x1, . . . , xG are such that the (generalized)no-free-lunch applies, we need Payment = µmin. It follows that c2 = U (µmin), and consequently c1 = U (µmax) − U (µmin), thereby completing the proof.

46

