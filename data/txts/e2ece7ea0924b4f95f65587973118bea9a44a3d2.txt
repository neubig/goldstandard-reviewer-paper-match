Grounded Discovery of Coordinate Term Relationships between Software Entities

Dana Movshovitz-Attias Computer Science Department
Carnegie Mellon University dma@cs.cmu.edu

William W. Cohen Machine Learning Department
Carnegie Mellon University wcohen@cs.cmu.edu

arXiv:1505.00277v1 [cs.CL] 1 May 2015

Abstract
We present an approach for the detection of coordinateterm relationships between entities from the software domain, that refer to Java classes. Usually, relations are found by examining corpus statistics associated with text entities. In some technical domains, however, we have access to additional information about the real-world objects named by the entities, suggesting that coupling information about the ‚Äúgrounded‚Äù entities with corpus statistics might lead to improved methods for relation discovery. To this end, we develop a similarity measure for Java classes using distributional information about how they are used in software, which we combine with corpus statistics on the distribution of contexts in which the classes appear in text. Using our approach, cross-validation accuracy on this dataset can be improved dramatically, from around 60% to 88%. Human labeling results show that our classiÔ¨Åer has an F1 score of 86% over the top 1000 predicted pairs.
1 Introduction
Discovering semantic relations between text entities is a key task in natural language understanding. It is a critical component which enables the success of knowledge representation systems such as TextRunner [43], ReVerb [8], and NELL [4], which in turn are useful for a variety of NLP applications, including, temporal scoping [38], semantic parsing [20] and entity linking [25].
In this work, we examine coordinate relations between words. According to the WordNet glossary, X and Y are deÔ¨Åned as coordinate terms if they share a common hypernym [10, 27]. This is a symmetric relation that indicates a semantic similarity, meaning that X and Y are ‚Äúa type of the same thing‚Äù, since they share at least one common ancestor in some hypernym taxonomy (to paraphrase the deÔ¨Ånition of Snow et al. [37]).
Semantic similarity relations are normally discovered by comparing corpus statistics associated with the

entities: for instance, two entities X and Y that usually appear in similar contexts are likely to be semantically similar [7, 32, 33]. However, in technical domains, we have access to additional information about the realworld objects that are named by the entities: e.g., we might have biographical data about a person entity, or a 3D structural encoding of a protein entity. In such situations, it seems plausible that a ‚Äùgrounded‚Äù NLP method, in which corpus statistics are coupled with data on the real-world referents of X and Y , might lead to improved methods for relation discovery.
Here we explore the idea of grounded relation discovery in the domain of software. In particular, we consider the detection of coordinate-term relationships between entities that (potentially) refer to Java classes. We use a software domain text corpus derived from the Q&A website StackOverÔ¨Çow (SO), in which users ask and answer questions about software development, and we extract posts which have been labeled by users as Java related. From this data, we collected a small set of entity pairs that are labeled as coordinate terms (or not) based on high-precision Hearst patterns and frequency statistics, and we attempt to label these pairs using information available from higher-recall approaches based on distributional similarity.
We describe an entity linking method in order to map a given text entity to an underlying class type implementation from the Java standard libraries. Next, we describe corpus and code based information that we use for the relation discovery task. Corpus based methods include distributional similarity and string matching similarity. Additionally, we use two sources of code based information: (1) we deÔ¨Åne the classcontext of a Java class in a given code repository, and are therefore able to calculate a code-based distributional similarity measure for classes, and (2) we consider the hierarchical organization of classes, described by the Java class type and namespace hierarchies. We demonstrate that using our approach, cross-validation

$WRPLF5HIHUHQFH -D)U)LOH6LOH5WUHLQDJG:HUVLWHUV )LHOG73%DRLEJVO'LHWLH&RFQHLPOO5DHO QGHUH6UW\OH&R&QVK'WHDH 6RUWH+G6DHVWK0DS7UH3HUL6R&HULRWWV\Q4F&XXRHUQUXHFHXQUWU+HDQWV/KLQ(0N[HDHGSF4XWXRHUX6HHUYLFH %R[/D\RXW

5RZ)LOWHU 7H[W$UHD

$UUD\'HTXH
&ODVV3,DQWSKXW6WUHDP88Q5QNNHQQDRRGZZHQUQV+(R[7VFDWHE(SO[HWFL0RHQRSGWLHROQ/LVWHQH7UDEOH5RZ6RUWHU - -/ 7UHH6H/WLQNH$G/ULUVWD\$/UULDV\W%ORFNLQJ4XHXH

+D=LVSK)0L&OHRDQSFVXUUHQW6NLS/LVW6H)WXWXUH%7ODRVFN74DXEHOHX0HRGHO &ODVV/RDGHUV 6RUWHG805D/S&ODVV/$RDUUGDH\U /LV%WVL&W6RHQWFXUUHQW6NLS/LVW0DS 'HIDXOW7DEOH0RGHO

7UHH1RGH7UHH06FRUGRHOOO3DQH

-+77UH0H/(GLWRU.

8,0D7QHDJ[HW')UHLHIDOGXOW6W\OHG'R-)F

/H(LDV[NHWV5FXHWIHRUHQFHV &'ODVHV/IRDDXGHOUW/LVW,,02**,PRUUDDGJSSH6KHKWLULFOFLQV7VJ(D'$EQWHOWHY0UY&LLEULDFHXRWO%KHWQOH(&LJGR6,LQQWLRPWWHHUSJ[OHWH$WWULE'X&WHHRI6DPHXWOEW&RR%PR 7/UHLQHN0HGD+SD+VDKV6KH6WHW&$RESV\WU2DFQW:/LVULWWH$UUD\/LVW

-DU)LOH
&ODVV3DWK+DVK6HWV

7D$EWORH%0PORR7LFFGDH5NEOLO/HHQL&V&IJHWHHH4UOQOOHO5X5H7QUHHHDFQQEX7HGGOHHHKH5UUUHHR6HUUZWD\6GOHR3&UWRRHQRUVOWD-Q7WDVEO-H7V DE-OH(GLWRU3DQ0H XWDEOH7UHH1RGH&K'HHFIDN7%XHOR[W7W[)UHLOHHG6/HLVOHW6F/WHLRLOVHQWF00WLRRRGGQHH/OOLVWHQHU

U /LQNHG+DV+K0DVDSK0DS

7KUHDG3RRO([HFXWRU 3ULRULW\4XHXH

&'ODVHV/IRDDXGHOUW/LVW0RGHO 7-DDEUOH2&XHWOOS(5XG6RWLW6LZRPUW)SULHOOHWDH$UPWWULEXWH6HW

*UDSKLFV'H-7YHLF[HW$UHD

*&ULGR%PD*E)JRUOR/R%XZDRS\/[/RDDX\\WRRXXWW

)LOH'-LD7ORDJEOH+

6RIW5HIHUHQFHV 5PRHZQ)WLOWHU -/LVW 6RUWHG6HW +DVK70&URHDQHSF6V&XHURWUVHQQF&WX6RUQNUHLFSXQ/UWLU+VHWDQ6WVH/)KWLXQ(0WN[XHDHUGSHF%47XODWRXRVFHUNX64HHXUYHLXFHH 1D&YODLJVVD/ERODHG:0HUHDVDSN+/LDQVNKH70GU/HDH=LSV1LWSRV2GHX=7WULSSHHX,Q0W66SFRXWUGURWHH6OOOD3WUDPHQDH7PH[W$UH-D+77UH0H/*(UGD*LWSRUUK.DLLSFW -VK7&LFHRV[WQ(3IQDLJQYXHL0UUR*DHQWUVLPLRGV'Q%HDQHDJ-WJFH62&L)FPSURRRWQDLUOROP3VOQ)WDUD1VQDR3WHLXUQDPPWQVHDEOWHU)RU-P)DRWUPDWWHG-76HFU[RWO)O%LHDOUG -

GSHDF%47XSODWRXRVFHUNX64HHXUYHLXFHH *=&,3*OD2=V,X3VW/S,QRXSDW6XG2WWH6UUHEWVDUMHPFD,W,P*22UX0DWSH6S6XWWDKUWWLU'LQLFQ%JDVJ%RWD&%RXXORLHOIGQIDHHQIUUL$V7JVWUXWH0UULHEDH0XWVLWRRHV'GQDHHJO FHL)P7RHDU[POW)$D1RUWHXU-DP)P+7R7UDFHE0XWHHV//U() 6RUWHG0DS

$UUD\/LV%WVL&W6RHQWFXUUHQW6%NOLRSF/NLVLQW0J4DSXHX7HKUHDG3RRO $WRPLF5HIHUHQFH

0XWDEOH7UHH1-DRGU,HQ&SK'XHHFWI6DN7%XWHUOR[WH7W[8)DUH,LPO0HHG6D/7QHLHDVOHJW[6FHW'W)HLURHLOHHQIDFO)0GWXLLRROOWH6GQ65H/WW\UOLVHLOHQWHDGJQ'G:HRH-U)FUXVLLOWPHH&HUKV-QRW7RHVH[UW))LHLHO-OG6G%S3%XURWLLQJWVRJ'LQW/LHRDFQ\LRPXDW O

%RUGHU/D\RXW -5DGLR%XWWR %R[/D\R&XRWPER%R[0RGHO

+DVK6HWV
L /LQNHG/LVWV

$UUD\'HTXH**UUDDSSKKLLFFVV('QHYYLULFRHQPH:QW HDN5&HRIPHEURH%QRF[HV-)=RLSUP)LDOHWWH,GQ/7LSVHWX0[W)6RWL)OGHWLHU'HHO-LODGD7ORPD88JEQ5OQHNN+H-QQ6DH-RSRD&GZLGZQHRHQQPUQUHV6+(E$UWRRE[U%VLVFQWRWHUJ(D[SF$[WW%FLWRWXH0UQLWSEWDRWXQLW-R%KW&HQ&LRJPR-,Q5QS-WRW/HHRQDJW[H\3HQWHDWUUQHHG3DQ'HHIDXOW&RPER%R[0R.GHH\O/LVWH$QHFWULR

DS 'HIODWHU2XWSX)2W6LOEH6WMUH5HWFUDHLWQP,QDJSG:XHW UV7UHH1R)GRHFXV)/LHL6VOWFGQU3HRUORO3VDLQW:LH 1DYLJDEOH:0HDDSN+DVK0DS LWHUV RLQQGR'ZH)IDRX-FO5XW6VDW/G\LOLVHRWG $UUD\/LVW 7UHH6H/WLQNHG/LVW

$UUD)L\OH%5*OHRDUFDGSNHKULVQLFJV&4RXQIHLJXX0)HUDLHHWVLORGV'Q3DRHJVFHLL)WPLRRQDUPO)D16RW8XURPP5IWDE/5WH&HUO)IDHRVUUVHP/QDRFWDHGVHU
6WULQJ: LWHUV

-6FUR-5OO%DDGULR,%,2X,W,W02RQH,6VPWWDUDL'QJ%JDH-%RWD5RXDOLGHOGLDRH%QUX&$VWWHWRWOUQOL5EHXQWHGH7'UDHHEUIODHX0OWR7GDHEOOH0RGHO

.H\-(7YRHJQJWOH%XWWRQ

4XHX7HKUHDG3RRO ,QSXW6WU$H0FD,WQXLP3RSWDQRX85E0UWW0OQHDHDLE7FDDSDOSUGVHHV5HHW5H1UVHPR$PGRFHRWWHLWRH2Q2E/EMLHV7MHFWHQWF[H%W WU8)LJ,LO0H'GDH7QFHDJL[PHW)UDLHOOG -3DQHO 7/UHLQ:HN0HHDGDN+S5HD+IVHDKUVH6KQHF6HWHVW&$RESV\WU,2QDSFQXW:W/6LWVUULHWWDHP8$8Q5QUNUNHQDQDRRG\ZZH/QUQLV+V(RW[VFWH(S[WFLRHQS%WLLRJQ'HFLPDO 'HIDX*O'W&=HR,-IP3*ODDE&2U=WR)HR,%X3LUPORW2HS,E[Q0XRXS%WWRS6XRGX2[WHW26U0WOH6EWERDUMWHGMUPHHHFDFODWPW2P,QXSWSX6XW-WW&ULKQHJF7%N%DXREI[I)OHHRU&VFHXOVO5/-L'HV-HQW,QQVGWNHHHWURUUQSH6D3UO)WD\-:UQDO/HHPDL&QEHGRHRQOVZVW)D-RQ)7-FWDRV5XEFVDOXH/GVVLLV/RWL%HVQWX-HH(WQWURGHQLUW0RUH,3WQHDXPQ/HLV0WHRQXHVU H/

U5HQHFIHHUHQFHV ,P,PDDJJHH:5UHLWHD8UG8HQQUNNQQRRZZQQ+(R[VVFHWH('VWS,HHF[WWRIFL,DRFQHXRQ,SPOQW7W,DLPURJHDQJH/LVW6HOHFWLRQ/LVWH 'HIDXOW/LVW0RGHO /LQNHG+DVK06RDISW5HIHUHQFHV3ULRULW\4XHX,,72H,,K02UH,6HPWWDDUDL'QGJ%JDH63%RWWDURRXLQOLRHOJGDO$H(QUW$VW[0UWLHWEDUXFLWE%KWXXH&LJWWHRR,QQUWWHHJ[HW U
HV6HOHFWLRQ0RGHO +DVK0DS *=,3,QSX2W6EWUMHFDWP2XWSXW

&&OODDVV)VVR3/FXRDVDWK/GLV.HWHHU \Q-(7HYUR,HJP,Q.JPWDOHHDJ\%/JHXLHWV:WWR5H$QU$QHLFWHF,HDWQWULL3UGRRS7HQQR-X86/UD0U7WWL0QFEVDDDULOWREFEHDSO-ODOO0QS3VHH6HVD&5ORULWQG5GHHHH-HOOHPUO/(O$P/5RDGFL6VRWERLWVHWWLLWZRRHPHHH2UVQWO),2S,PEHH/7FLOOEMHDWUWRLHD,VHJM$FQHFEWUHRQW,FO,-WPHFQHUW&RL5,UEDQRPRXVJP-DZW'HSHJLVR66D-HQORHR3HJUWDQWHWQVHU OV

-7DE$OHFWLRQ(YHQW

*UDSKLF;V'HYL(FHQFR7GKH7,U,GHK2.DUH,HGPD\*6G6DU*WRS&UJX'HHURH6RSDF2PXVPWU0SEL6&RQ6R%KJRXHR$XU[FFUWNFHW)0%UHLOERHD[X&W%KWKH&LDJQR,QQQHWWHOHV/J[LHWVW0)RLOGH,WH'HO'-PLD7H(O 6RUWHG6HW +DV*'K=7H0&,IU3ORDHD2WQHSHXF6UVW2&XSHXXURWUWWVS6HQXWQF2U&WH6WXE6RDWMUUPHQNHU$FHLFDSFW,P,XQWQQ/L3RUSSWLU+QRVXX8H60UWWWDQ0Q6DWDULWVEFDLHS/Q)DOKSVWHJLVXQ(50%WWN5[HXXHDHPIHUI)$GPHSHFRR%FU47XRWVFWHOLWXDRWRXH2RVQVF2HE/U/NX6EMLLHVV4MHHHFWWQQWFXUHHWYHUULXFHH:LQGRZ&)ODR-FV5XVVD//GRLLVRDW%HGQX$HHWWUFURVWQLR0Q,Q;(H3,WSQHY.XPHX&QW/0WL6V(0WDHQRSQ(FXHRQVU7GHFK/RH7UL-GGVHK6W-H.DHUH&GHQHGSRH.DD\*P07UU6G6HDSUUH*\WWHRSQRU6HHXX'HHUUQR%0SSDF2.WDXVHPHRU-0SF\7G6%/6DHRLDEQRO\XEGRXHLUQXFUGJWFH30)V7HDDLH-%OQQH[)HD\&WJUW$DHKUUP%DHV-Q$X-DH+QSI7ISH-H7UO%HHOU0VVWXHW/WR(QGVLWRU,.WHLWP-(7YHH[0QW03RWVRXD-XVQ7HVHHH0[:RW$WKL-RUHH3QHD/UO/RLVLJVWHWUHHQQHV

U -/LVW 6RUWHG0DS $UUD\/LV%WVL&W,6P;,RPHDQDJWFJHXH:(U5QUUHHFLWRHDQ7GUGWK6HH7U%GUHKN.ODULRHSHGFD\/*6GN6LUV*LWRSQUWX'HHU0JRSDF)2X4VPDL0SOSX6VH6HHR1VRWXX,H7XFRUHWFRUK,WFHFQ))UHR,HLPROQHDX,D&PGJQKD3HGDJVRQ(HQR[HOFOVHSWLRQ,WHP(YH0Q0R$WVRXFXVWHV&L0H0R:KQRXDW0KWL-DRUH3VQDEH/HUOOS/RHLWVL7J(V7WHW/UUUHQ/HQHHRQFHVRHHHFUVRF1U1D%GDORRDH9O:9GGUUDHHDLQUULGDLRD&;EZ1E;O0/HDOR6HL077VV/&7FWVH\H-'/UOD12QDS[R(HEHWVHOS8R)OQUFO3WV7HWL,LRFR)'O0DDHQRGRQH3EGDGHXH/7DIOQHU)QQLHDVUHRGJW[6X(HW')QH[UHLGOFHHI--(HDFO:7GSUWXHLUL-WRQO[RLW7RGQW6U$HRQV/WU[Z\HVLWV)ODHWVLHHGOQ'GHVR-U)FXLOPH&HKQRW RV3HURU JUHVV0RQL-WR6UFUR

6RIW5HIHUHQ*FUHD*SVUKDLSFVK$&LFF,RVWQ3LQ(RS.IQQXLJ&Y0W0XL06UDURDDSQS(PQHFQRWGHG.H\16%SRRH&RF %\WH%XIIHUV )LOH1RW)RXQG([FHSWLRQ+DVK6$HF,WQW3&LVRS.KQXD&0W0U6VDDHSSW((Q/$Q/FRFRWRFRRFGDGDPHOH9OG9ULDF.DU5HULD,L\D2&H;E16E;OI0&HD(OSRHH07VH/&6R7U[V\F'/HOD(UF1HDS(QUHEHVHR2FXQFOFV7HWSXRFS)'H)DRGWURWHEL(GLHHRXWIOHU\)GQ[Q%U(RG6F\X(H[WWQH[UFSG%FHHW(HXDLSSRUIPUIWWHQRLLRUUR(VQVQV[:FHHSDWNLR5QHIH3UH3LSQURHFJH,QU&HSVKVX0DW6UR(V(QWUHYLWHYHRWH'DUQQPHW/WF/LR6VLVGWHHW7HHFDQUQXEH&HEUULKH'UW3/\/GHHDU30LFRV\IDDNR[WDQX%X\HQW-O0RWD37[DMJD7UQQHH-HDO3UHHJ[R6H/WS$UHDX-UO0S\HH05HHFDQUH/WRHLXQRLRV,GXWQWWH300P)DRRLQOGGHHHH'OO-LD7ORDJEOH+H6DGZ-HL7UQJH:[WR)'UNHLHHIDUO-GX%OWX7WUWHRHQ&H

)RXQG([FHSWL*RQ=,3*2=,X3WS,QX&SW6KXD2WW6UVHEWHDHUMWHWVL(PRFDV/',QQ/DW,RPF2R2HJFRFFDHX0GDLO)HP9WO9SHR6UD6DUXWUWPDUOLUWWD)LL'D1&QEREW;JODXUHDOHP0%WP7VD7V\XD/OED1DSO(WLHEHOVHRGQODVU7HWFH)'QDRRURHE$GVXUIOH-)PWQWU)RGUDLX(REWQ[UXPGFW(HHDSUUWWRWLRHUQVG-V76HFU[RWO)O%LHDOUG ,2&(6R[(UFHUH26FXSXSR)WUWFL(LHRWN\G[QH(6FWH([WUFS[H1HWFDLSRHDPWQSYLR(WLQJR[:5QFDHHHEISDHOWNHUL:R5H0QQHHFDIHHD3S3U4HNLLSSQX+H/HFH2HLD,XQ&XHVSNWKKXSHDWX0G6UW(V6(W/DUHYWHYLHWUSVH'DHQWQPDHVW/$WPF/LFR6VLVFGWHHWHHHFQVUQXHVHUULLEUW3\/O3UH0LRV2LS[WDEH\QMGDH5MJ6F7HWHHRUD[FG/W$NHDUUH\H5HWD(URHR[GWF3HD6Q*SHWRU(LRDI*Y*5WSQ5H6UHQKUDHZDWLI4SFHISL6QHVKXUKJZU&HHLLF8HLFXQQ6RVWQHVJLFZQ(O'FL8HWIL3LQHQWLHH4JLYWJVLYOSXLL:XH0ULHUFRVHDRH2HQ'XWUVLPNHXHRVHI'WQ0HDDUSXQHJXROWWFH.WX76L)VUHPHWRH\U)HHDU((R&PDOQYY)H$PWD1&HH0OROFW5QQRXHUFHWWPPWPVHVUQLFVEGDEVVRHWH7LU%EHLUPROU)33H[H2RLLUSS7UEHH-DPMMGGV)&HN5D:FRRWWHUPPDLW-EHG3&3DRUHRUUW%ULPWRYHRSEDG[RHW-H%7U-6RW.0H\F[H&HVU[R\QWKO)XOD%LQH(DJOUYGHH66QZWX4LS6QXS-JZHR68-LXUQS&WWHJLLQORL8WQPLWHHLWEV$UOLRHE%VVWRUD[FW%XWWRQ-&)RRP-Q5

6RIW5HIHUHQFH
([FHSWLRQ U;LQ0J/%'XHIFIHRGUV 6$;([FHSWLRQV

,0OOHR.X7JVHUDHH\7OH((6U&YYHWHHHHDQQO&6OW5WWH-VV4H&O(OQ(R/[GGP(HFL3WEUHR[HRLUSSFU%6HHWRMGL&$RS[:RQW;LPURL(WEH3Q33[R3UUXUUR%FULERY2RSHROSDLSH[F)SHXWHU.HUWLWWU\OW.HL2WH6\R&\\H&5&WQKI\UK0KDHVLDQDQDHQJQ,GJPQJH:HH(W6RH/UYVXLUUHWVQ\SHQWHS(DWUQRVOUHU(UW'URUHUURIDUXJO)W/ULOHLHVDOWVG&WV3HHHUORO2U56V27HFLUWK(UQULR(HHGT7QGHHTXXUU&XHODHHDUHOHG7O(O&7OK5[-KHDHH&DFOQ-OQX5(QR&WGRGPPRUHL65WPELUR&HHRPUUERUY%RLLQF&R%H-Q[R)RHQU[FDQPWRH3H&UFV3$UXWRRRUGEPRSUGO&LSHEF-UHUOH0R.LWHUV\%HHWQV-&\QR\0W&X-[K%H50KDQDDQDXURQ,JGGWHJLHHRPH(O%V/YXLHVWWQWRHWQQVH'U HID-X5OWD/GLVLRW&%HXOWOW5R6QHFKQHGGHXUHOH

HRWN\GQ(6[WUFHHD,SQPWSLR(X)Q[W:L6OFH6WHH5UW'HSDUHLDWNQHLDR5PJIGQ:OH5DHIUHHWVLH3DWUHHUGLU2SQHVHFUXH,VQW&SSKXXD2WW6)U6(VE(LWHUHYWMHYUOHHWGHH'DQF3%QPDHWWR/P,FVQLRVLSWGLHRHXQQUWHU3UR[\ )RF/HDXU \V5H/URLHVRGW&3QDRHQPUHER%:R-[LQ50-3GDRGRDGLQZRH ,OOHJDO6WD6WH45(/X[(QFHW[LPSFHWHLRS(QWL[RFQHS2WLRXQW2I0H,PQWRH18UUXQQ\ON(DO3QOU(URRRUZLUQUR,QWOHU2OHJU(EUJOHM[HH:DDFVFWHOVWH$H(SHUWU2D[UL2JRFNUQH(&(XU5(VS,[TPQR1WTHHXLWRQXHFDHIXQHDUXFOQUP7VOWUXX7LKWRHSK'(EUDQQW5UDHRHQ-([H5FQGF&XU[FQHXP()FRQHWPV5[HPRL0WS&FSLHPUEPHWRWQRPLLRLSRQR&WGH%/WQQDLQRRLLR(HV%IWQQ[LFW(X[FQHWIRHFQD[IHUFH,FW$Q;WU'LRHSHRG0SHUGSGWQ&IXL:/UDRW(OHW6LLX6R6HQUV[OWLQWWVRUQW+FHWUFUHDHDNVPQHDS6GWPR:W8,8OLPHFRQU5'NUQSLQWHN18HOHNH')WQIU,QDDDHXQPRRXFIGONDSZOWZH3WRQXO7QUUOQRRD\WV+7(EZLQDOR[HQEWV&FHO2HWHHU(&(OESO[(HWM[FHOLGORF5H0LFWQHRHSW%D(USQWLWLGW[R%KJLHRFQ&'LUJQHH(,RH$P,UVS,Q[QQFUWDHWWULLWHJRHPH\FHJQ[DUX,DHUWFV/WXOLURLRSVQ'QWWHR(-GF$[X'(FSPS[HHOFISHH-DHWW'VQXLSRLWODW/Q&LORLV%R-JQW7XVPHRIQEIRHOR%;U'%DH0HURGI[:/D-060X6UROHWL.WWRUQ+GHHFXHUDDVN\VOPQH/6GWLR:,VOPHFWHU'NUSL$WQHHOH')HFWIU,DDHWUPLXRFIDSWOQWRXO7/UO-D\WL7V&EWDOHKHEHQ&OFHHHN&UO%O(HROGO[5LWRHUQGHUH-,PU'-DH,QVJW-NHH

HO ,OOHJD1O$XUJOO3&XPRR1LQQHXFWQPHXWU(EU(UH[H[UFQF)HWHR0SSUWRP1LWRLGRRDQLQI&WL(FODD[FVWLHVR'SQW(HLR[I)QFRHXSQWLGRQ(UURU
HW([FHSWLR5QHIHU8H8QQQFNNHQ3Q4RLRSZXZHHQQ2X+(XHR[WVSFWHX(SW[6WFLWRUHHQ$SDWF$WLPL,R/JQ6QL'VSHWHXHF8FQXWL0QHPULLUWFD\D/0DLOSVVWDWQ5DHMJ7$HPHUF[RWWL$WRHUQH2D/ELVMHWQFHW U 6 &ODVV&D,OVOHW(J[D&FO$HODFSVFWLVHR(1VQ[VRF(WH)[SRFWXHLRSQQWGL,R(QQ,[QFLHWLDSOWLL]RHQU(UURU

,26(4[F/H(S[W1LFRHQXSVOWOLR35$Q,R6OURVOU'LHO\RQHDDJ/IWWW/HLDD5VL&VJUWOH$(W'UOD,,IDROFQ[HPOHFVYFFUJ6XDVHHHDPOR(1LQVSGOF$H[FV13WNRQULFHH(DJRW*WRWH)V)UX%Q[D&LP=SROXFPWH,OWIHXHD3ILHUHQRSQWV,UWHQ(QHWGVUL(,G([SR'(Q(Q5F'[XQ,S[XHQFHRQ2W'WPXFH6DILFLR)RPSEHWGX6WQLFWUHRPDMS0LHHXRUOXWWHPVQDFLDL,]QQRSW,PH2H2WGQ%Q,,UWX(0X2(%LWOUXSHU,G6UPLUHOXWRRWGDUUWDUH)UL'QUJD%,JDFH62W%RWRWD6(URUXL\Q4O[LHOJGFD/$HHQ(USW$VW[WUWLFLRWEUH7QXLESHWVX[HWLWWR/H5DQ\RVR'OXH-DW/,QWLD-WVH2JWUQ'USDD,W,LROQORPO)HFQYUJ63XDDPDDPORLQGOHF$)HHV3NVRQUHDJFWW)UXX%DLPVOXPW/HIHIHLUVHQ.WWUWHHH(HU\Q-G([(7H(5F'[YURSQFHRH'JWXHDLQFJRRPSGXWOQFWHHP0LXR%UHPVQDXQSWHWR%QQWX%LOXGLHOGUH-)6UDFFUWRROU-O\36DOLQGHH-OU/DE7HH[O,WP/DDJ\HR,XF

6RIW5HIHUH,,Q2F,HPDJ,H6P,WPU0DLQDJRJJ.HX$VHH:WWH\05UL((UEDHLYYXWWHDHH%KWWFHLQ3Q&UGLRFJWWHRQRVHV,QQVU0UWWWVHHDLDJE[EHSOW33HOUVH2LLSS5EHHMMGHG&H5:P'FRWHHPURDLIWDEWHGVH3XRUH2O%UWV&REHR[MWPH,FFEWR%R[(0YHR6QGZWH4LO6QXJZH8LXQWHJL $ULWKPHWLF,Q(V[WFDHQSWLWDLRWLQRQ([FHSWLRQ

&ODV$V2&UXLWWDSK/XVLPQWW6H('HW5UD[WHHWLFDFD,DQHJP(G$UVSHVD[F)UWWPFWDLRLRR*H3'FQQQXSD=WH/VLF7WDL,I/LVN3O\RWLDHV7SLH2QRWWWH\QHHQS(XHQUH(UOW2HHVS0U[PVXXL76FUHWWUUSH\6RQDVUXWS\WW2U,HWFH6LPERR9D7WQM7QULPHDHHUEFDZDO\WH),P,QQ9LO3WSSLHHRXXUZ86$UWWHW0QIDWUIULEQFDLQHDOSHJ7V5%UWD5HXQHPVII)$IPHRRRFUURWPVFWHLWXR2H2VQS2E//2EMLLHVVXMHFWWWQQWSFHHWXUUW6'WUD:HWDDLQJP$GUVDRF)PZWRLR)3FQRXD/-FVFL5X/VNVLWDHV7H/GWW\QLHLVSRHQW%HHUHVQ0XU$HVWLW(FUURUWQQLRRX0UQP(H,W6QHYX7PHHDQW/EWLVO0HWH9RQLXHHVUZHH/UL-V6W-HH&QSRHDP0UUDSHWQRHXUQ%.WDHU \%/LDQ\GRLQXJW0V D-

RQ,PDJH /LQH7H'[WXUH3DLQ,QW SXW6WUHDPV HURW,SFHRUWQ\,&PKDQJJHH.V6HX\S/SLRVWUHW $ (5OOLHSFVWHDQ'JOH'

,P,PDDJJHH:5$UHLFWHDWLUGRHQU0DS7V$HII[LQWHX7UUH*DV3QUHDVDVIWSRL,HQKFU,PLWQWRF,FSQVRX,/P'QWL6,QDPWHJUDH5JDVHHPDGVHU 7KU/HLDQGH*U'RXSV

7\SH(OHP76HU\QDVW\W,HFPR9Q7LHUDZ\)LOWHU $IILQH7UDQVIRUP2-7SDEEHG3DQ ,WHP(YH0QRWVXVH0RWLRQ/LVWHQHU $:IILLQQGHR7ZUD/LQVVWHIRQUHPU

FHV %RROHDQ$7WWUHLEH7X&WKHHUOHO(DGGLW*RUURXSV 3ULYDWH.H\ 6L*PUSHOJHR'UDLDWHQ)&RDUO$PHQWDRGWPD5ULFH,H,Q$Q;Q3WHWSWRU.JDXPH&QWUL0WF$6/(/URDURQFDSQ(NF\JRQGF(RH75GGOKOLHH.SUGHFHV$W.D\HODS6G96H5QK*R\WSHD'JUO16QD&'HHUOGRWHSDFRRL2OHXHPHP&U,0SH'FPSO6GDR6D,RVVPJRLVXWHDHX'UJFUHHFH)IH)L%OHR\&XWQHKG%D*(QXUUQIHUIHHRJOUUVRVVULDQ&DOHQGDU 0RXVH:K-H3HUO/RLJVWUHHQVHVU%DU

*UD-S2KSLFWLVRQ'3DQ

Q=[,F3*2H2=SX,WXW3L2RWS,QIQX0VSW6HX,2PQWW26UWHERHWEDUMUUHMQ\PHFD(D,FW,PW2O2U(,UQRX0USUUWRSH6X6UXWWWDUJWWLU'QULOQHJDH,JDQ;%WV3D%WVSXH.XHLUXO2IUGI2H7HUU(U(VVHTQHXF&DRHO7GOOK5H-7DH&GQ-KQR.&UGPHRHHDPE\UHR6G6EU%*RWSUR%'HHU[RRDF2[XP0S3636UXRRUERRSXOLXSHUFHUFU.WFUH\H)WH&.\\L&HOKH\KD-&(DQ7QYJKRHJHJDQH(JQW/YLHVQWHW QHU %XIIHUHG,PDJH 7L'PDHW=HR)QRHUPDW OHQ%HXOVWWR'Q %XIIHUHG,PD )LO(H21R)W()[RFXHQSGW(LR[QFHSWLRQ

$$WFRWP&LRLKFQ,D0QUWHVDJHSHW(U6/QD/RPFRFRSFDGODHOH9O09UDRDUGULHDLD&O;EE;O0HDOH07V/7V\'/D1S(HEHRQFO7HWRF)DRGREGHXOHUQUG(6[FLPHSSWOLHR'QVDWH)RU$PWDRWP5LFH,HQ3$QWUHWWRRUJDJPHQUUHLWF$/V/UVRUR0FDQN\RJQLWRU

$OS75KDHDEQ&EGRHH/PGUD3HS\DGRQ,VXPHLW-W0DH3JDDHQQDOHJHU-0 9RODWLOH,PDJH -3RSXS

&KDU(VHYHW'QHW/FLRVGWHHQUHU3UR[\

/D\5HURHRGW3DQH

$WRPLF',QHWIHDJXHOWU7UHH&HOO5HQGHUHU

&)W0R6F(DTSXDO7KD5Q P5L&PRLQ&QRHQFQWRH)UF$RWRGFUGX&UVOHL/HVLQVVWW%HQ\HWHU %XIIHUV 6HUY,H2U6&(R6R[F'UFNHUDHH6FXWSXD&SR2WUKWFLLHRDXWN\GQWQHS(Q6XWH([WWOUF[HHFDSHPWSLR(WL;QR[:5QFHHHISD&HWNHULR5HUWQLQHILFFIHDH33WU4HHLLSSQXHHFH2H,XQXHSWXSWX6W6(WUWHYUHDHQPD$WP&/F6RL'VFOH:RWDHHUFW0VUDQXLVW%RHDULXLGEEUWI\H/OOI3HHHO0LV5U2L,SWDQDEHWQVMGWDHH5MJFU7HWHHUD[GW$HUUHD7L'PDHW=H(R)YQHR6HQUZPW4L6DQXWJZH8LXQ6WHJLZOL8WLLQWHLWJVOL:HVRUNHU M&RPER%R[

6DPSOH0RGHO )RQW0HWULFV 7LPHU7DVN

-&R

XHHHFVWQLIHSVRSOGD'SWQWLW(RWL(HHLRRQ[IU[Q)Q2FFRHX,HXPSW,SSPQWDLXWGRDJLWRQ(618QWXQUH$ONOD3QF,PRWRQL3RZLSQQRXQ8W0UHW2W0QUD$D(LEEFDSMF[DOHSVHFWVF&5LHWRW5(SHKQWHP[DL0$RPFRUFQH(VDRW$WVS,H[LHWQSXRUWH2ULWW(VVQR2H\(FE/H/QDUQX/EMLWQUL/HVV/,VWXFRMFLHFWLWRSQRVRQ'FWFRQFWWHQHGDWHR(GDU,UHGOFP[H9OX(G9FDUDP[H.D:FUSHHULHWDLQLLQ\DSR&WEG1/W6QEL;ORRLHDOV%SRZHQ0W7VXH&H7)VI\QF/IROD1HDS(-FE;U'VH5XRHQO0HV7HGDWF)/I':/GDDRLRL6VXHER6UGWXOWL%HIOWWRUH+)HQQXF$UDDHRGWNVWFPQUHR6X(WGWQLR:Q,[OP0HFQGFU'NUS(H,L(HWWHHQOHH'Y)SWUIXUP,HUDDHPWRQLXFI/RDSWUWOLWRQVVXO70WUVOH\R 6RFNHW'&DKWDDQ,QQSHXO W

6RIW5HIHUHQFH
+WWSV85/&RQQHFWLRQ

0R.XVHH\7,((PU6YYHDHHHJQQHU&Y%WWVVHHXOIUOI(6HUGR/3LFL3WU'VRRNWL5SUDSHHHHWUD&VGW\R2K:5XDXUHFUQVWLHSWRQ%H3X3X3H3XUUUXWUFQUROULERHGYRS%OSODLSHHFXHWHU.HQUWU\GW.HW\O&\H\H&&K;\KKDDDQQQJJJH&HH(6H/YXULHVWSLQWIHSLWFQRDHUWWUH

&R'ORDUW0D%RXGIHIHO U,QW -)UDPHV

DW7 ,OOHJDO6WD6WH4(/[(FH[SF6HWL$RSQW;LR(Q[F2HSXWWL2RQI0V H,PQWRHUUQ\(DOU(URUUURU JUOHHDVWVHHU2U27U(UU(HTHTX&XDDHO7,OOP7OK5-KDDH&JDQ-HQ5QR&,G2PPRH5PELU&H5RPERU%HRLQV&R%RQ[RXRHQU[FFQHWRH%UFX$WQRGGUOGH&UOHLHVQVW )ORDW%XIIHU

'HIDXOW/LVW&HOO56HF,PKQ,PHGDGHDJXUJHHOHH%:UG,XF(UIRLI[WHQDHUEFX-OH$WR5SU6DSOVHH-WUWHY'VLUFLDHORJV

JH ,OOHJDO$UJ&XPR1QHXFQPXW(EU5UH[HXUFQ)&QHWR0KWS%LDUPWRP\ULR%WGHDQXL2(IIWIL(U[FHGUFD[HHFWULHSRSWQLRW(LRQ[QFH6SWWULLRQQJ1856XQHWUDONLOQG3QJHRR%UZLXQIQIWHH2UU,(QESM[HXFWF6HWW(SUHW[LDRFPQH($VS,[QUWHULWRH\F6QDUXUVR/WXLLFRSV'NQWWHRH(GFW['&X(FPDK[HFWDSHDHWQQL,SRQQW/WQSHLRLV%XOQWWXHIQIH;U'H0HGI:/D+6X6UWOLWWRU+HSFUVDDNV8PQH6GW5R:,OPHF/U'NUSL&WHHOH')RWIU,DDHQPXFIQDSWOHWRXO7FUOD\WW7LERDOQHE&OHH&OO(HOGO5LWRHUQGHUHU

/3LUVRW5SHHUVW\R5XUHFVHR-%X7XURFQRHGO%OHXD -,QWHUQDO)UDPHV

6RSQ[WQWGUFL,HR(QHQD,[SQPFLWHWLLR(DSQOW[;L:L]RFHQHHU(JHSDUH:U(UWNU5LRRQR5UUHULWQHD,72UGKH6(UUH4[DF/GH(*S[WULFR&RHXQKSSVWDVLRU5(VQVHRVHYWOH,HWF'/QRLHQWV/W,FP'LRV,,RDOQGWOHHFJYHJXHDQUDPVOHLGO$HU33QU;DJWU)UX0%RDLPOX[PW/HIH\I'HUHQWUWHH(HUF,G([WRH5F[PGSFHW/HHD(LRSDUGYQWHH\L0RU5QHVQRWUVRHRGW3DQH &OD1VXVO&O3D,ROVOLHWQ(JWH[D&FUO$(HODF[SVFFWLVHHR(1VSQ[V1WR6LF(RWRWH)UQ[&LSQRFJOWXHDL%RSQVXQWGVLL,OR'(GQHQ,[HQUFIL)HW)+LRDSLWOWWOXWHSLL]UQR85HGQ5HU((/D&GUUUHURR,RUQQUUSQXH,W2F6)W6LR(LORWXFH4[QNUUFF,H/QHHW(S,SQX[SWWLF6XRHWWQ6USHVWDUWHLPRD5QPRV'OHD/WLDVJW'UD,,ROQPOHFY)J6XDODPORRLGOFD$H3NWQU%HDJWW)UXX%DLPIOXIPWHHIHIHUUHQWUWH(HU(G([(Q5F'[SXQFHR'WPXHDLFRRPSGX6QFWHP0LHXRUWHPVQDQSHW%QWX%LOXGLHOGUH)UDFWRU\

,PDJ-H2,2SWLRQ53HDVQRHXVUFH%XQGOH 7H[W/D\RXW

(([[FFHSHWSLRWQL,RQ3QS.X&W06DSFHRGIHH73UGKH.LUSQHHHDF\6G6H,Q*WSUS'HHURXDF2XPW06S6(W6RU'RHYXX'DHDUFUWDQPFDH)WHWJDL/%OUJH6DL\UV&PDHWWHKPHF6%DQX3RQXHUFDQILINUFWHH\H/NOUVW0VHLVWW ((Q'XQR'PXFRPX6FP0HX0WHPDQRSXHWV%QHWX%0LOXGRLHWOGLRUH)QUD/FL $ULWKPHWLF,Q(,QV%[WW%F\DXWHQHIISWH%LWDULX6RWILWQRIUHLQQU(J%[XF6IHIHWSUULQWLJR:QULWH8U5/&RQQH)FLWOLWR3HQULS2HXGWS,QXSW62XWW6UXHWWDUSHPXDWP6'WUDHWDD&JP$KUVD%FD)PW\URL%RW3FHQXXD2/IVF7ILU/HVNG\LWUHV7SHHWWH\QUHS(HQHUOHHV0UPVL7UHUURQDUW\,6FRW7UQLQDEJO5H69HWUDLLHQGZJHH%UUXIIHU,QSXW6WUHDP

$FWL5RQH0IHDUSH(QQFFRH3G4LHSXGH.H2HX\XH16WSRH&XFOWD6VWVU'HHDI$P)FRXF)QHGRV(FVXULUVER/OU3HLVV2LWSDHEHQQHMGDHU5MJVF7HWHHUD[GW$HUUHDXVH:K-H3(HUO/YR ,QSXW6WUHDP ,QSX2W6XWWSUHXDW6PWU5H$DHP/XDGGL:QLHRHUUL,7WQHH'SU[XWWX6UWUHH3DDPLQ,QW SX/WL6QWHUH5DHPDGVHU

6\VWHP97LHUDZ\)LO,WQHSU $XWII6LQRHXF7NUUFHDHWQ,QVSIRXUWP62WUHSDP +WWS85/&RQQHFWLR$QIILQH7U*DQUDVISRKUPLFV'

%XIIHUHG,(Q5SOOXLHSW6FVWWHUDHQD'JP3OHLSH'G2XWSXW6WUHDP*UHJRULD6QWU&LQDJOH%QXGLDOGUHU )LOWHU5HDGHU )LOWHU,QSXW6WUHDP

6RI&W5KDHUIVHHUWH(/QQ/RFFRFRHFDGDOH9O9UDDUULDLD&EE;O20HDOH07VX7RV\W/.DSX1S(EXVHHRQOW7HHW6\F)D((RWRUEGHYXYOHDQHHUPGQQ$(VWWFVV[WFLRHQS/WLLRV3QW7HV\QSHHUMV&0RLUUPRUER%R[ )LOH&KDQQ'HDOWD,%QXSXIIWH6UWHUHGD5PHDGHU3ULQW6WUHDP RQ &KDU(VHYHW'Q7HW/HFL[RVWGWXHHUQHUH3UD3;LUQ0,RQW[/S\'X/HWL6QFWHRU7H5GU/DHHHDPUDGHU 7\SLHS(HOGHP:76HUU\QDLVWW\HW,3U 2EMHFW,QSXW6WUHDP

6,LPQ%WS%\OXHWHI'IH%DUWXH6)IWIURHLQUU$PJW%DRWPX56ILIFHHW,UHQUL$QQWHWJWRUJ:DPHQUULWF$L/W/HUR8URUFDQ5N\J/&RQQH)$FLWOLSWR93H5KQRULHDS2OQD&HXGWRGLWOHHSP,QU,XHPSSWGR6XD,VPWWJ6ULWHHDHWDUJHPHDP

3HFPURU9L7RQY7LDSH3DUEDZHUWOR\HH)UJW.9L\OUWLHH&HVUZKHDUQJ %XIIHUHG,PDJH 5DQGRP$F)F)LHOLHVOH5V,)HQLDOSHGXHWU6WUHDP

7L'PDHW=HR)QRHUPDW

$WRPLF,QWHJHU 6$DXPGSLROH,Q0SRXGWH6O WUHDP

H\V5H&URHRGOWO3(DGQLHWRU 'HI\DV$X0IIOWLRQ7QHUL ,QSXW6WUHDP 3ULQW:2U%LXWHXWUISIHXUWH6GW2UHXDWSPXW6WUHDP %XIIHUHG:ULWHU

2XWSXW6WUHDP:ULWHU ,QSXW6WUHDP5HDG&HRU'ORDUW0D%R3XGLSIHIHHO GU,2QWXWSXW6WUHDP

)LOH2XWSXW6WUHDP
H5SHWLIRH3UQHLVSQHFH,QSXW6/(WULHQYHDHQP' 33UXRUERSOLSHFHU.WU\HW&\\&KKDDQQJJH )LOH:ULWHU

6HUYHU6RF'NDHWD&2KDXQWSQXHWO

;&HUWLILFDWH %XIIHUHG,QSXW6WUHDP

2EMH'FWD2WDX2WSXXWWS6XWUW6HDWUPHDP
2HXQWF2H3I40LSXHHH,2XPQXHWRHWSUUX(Q\5WO6(DOLHSWOUFU(VUHWHRDUDUQ$UWP/R'J6LUVOHWJHFUQX'HHULDUW\/W0HLVUWD2Q7DU(MJU7HHTHUH[X&WD$HOU7HOODK5-DH&Q-QR&GPRHPEUHREU%RR%[R[6ZLQJ:RUNHU %\WH$UUD\2XWSXW6WUHDP

)LOH&KDQQ'HDOWD,%QXSXIIWH6UWHUHGD5PHD,PGDHJUH3%:UXLUQILIWWHD6UEWUOHH5DPDVWHU

UHQFH 0RXVH(YHFQFWVHVOVHLEVO3VH2LHSUEH2MMG&H5UFR(WHPDTE*GXRHUD%HUOJR7R[KULDD5QQ&PD5LOH&(PQYRGHL6Q&DQZQUWR4LH6QQXFJZQHW8LXRHQWHUJFLO$L8WWRLGWHLUWVG&OLHUOHVLHVQVW 6RFNHW'&DKWDDQ,QQSHXO W

+WWSV58D5Q/G&RPRQ$QFH)F)FLHOWLHLVORH5VQ,)HQLDOSHGXHW2U6EWMUHHFDW,PQSXW6WUHDP/3LUVRW55SHHHVUVWR\RX5XUUHFFHVHR%%XXXUQFQGHGO%HOHXQGOH

LRQ 8Q.NHQ\R(ZYHQQ2WVEMHF3W(LS[HFGH:S,UQWLWLWHRH33UQUULRVSHUW\&KDQJH65XHSHSQRWUWDQW/RFN $O &KD)U%ORXDIWI%HUXIIHU

2XWSX,PW6DWJUHHD,2P 3ULQW:U%LWHXUIIHUHG2XWSXW6WUHDP

UYXDSWHW.HHG\([$FWHRSPWLLFR,QQ$WHWRJPH'ULF$/HUURIDDQ\JX6OWR+FDNQHGW,OPH %\WH2UGHU

6WULQJ56H)WUDLQOGHJH2%U XIWISHXU,WQ6SWXUHW6DWPUH%DXPIIHUHG:ULWHU

SQDW(O(LR[UQUFRHU JSUWHLRDQWH1U2X7OUO(U3HT7RHXU&LDHQHOHW7OH&OK5-UHD(H&OQ-OQ([R&GGPFRHLHWPEURHSRUEU%WRLRR%[Q(R$V[[6UHUL3P\F3UXDXSRUE/ORSWHOLLSHLR'FV'HU.QWDWU\RH(W&\H\F&[)KXFKRDPHDUQPQJSHJHDWQLH(WRW/Y/Q$LHVLWV%QWRHWPXHQIHQLIF'UH,QH;UWHIHD0GJX:/HOWU6/ULWVLWUWH&UDHVPO6O56R:F ,QSXW6RXF)NUFHLOHWH,Q:SUXLWH6UWUHDP

'(UHURI)U RXQOHGV(VHUUU2RUU(,T2XD6(O74[KF/DH(5QSP[WLF5LR&HPQRSLVQ&WQLRRH5QQFQWRVRHO7UFH$LW'P/RGDULHG&VWU=HWOHLR)'HVQ,RQVROHOUWHPFJXDDPW O$HQUJW)X%LPOXWHIHIUHQUW(HG[5FSH6WDLDRPGQHSUOHV%HFKQ Figure 1: Visualization of predicted coordinate6WtUeLQrJm%XLOpGHaUir)+sLW,OWWHSwU855hH/De&GrHReUQ%Qe\HaWHF)c$WLLhO2RWUHUQEDUp,M\QH2aS'FXWiXD2rWWW6SDXWXo2WUSHWf6XXDWWWPScU6HXoWDUWo6HPDrWUPdHDinPate classes is connected

by an
(NQ[RFZHQS2WLERMHQFW([FHSWLRQV ,QYDOLG3DUDPHWHU([FHSWLRQ0R, classes

edge. with

siHmiiglharlyfucnocntnioenctaeldityc. oSmopmoeneanrte,Qsa%W%s\aXWHrIcIeH%oUnX6lItaWIUaHLbQUiJne%lienXd6IgIHWUULbaQJy:fueUnLdWHc8gUt5ei/o&cnRoaQllQoHrc)F,lLWOaLWR3HasQULsnS2HdXgGWS,rQXioStWu6XWWpc6UHaWDUhnHPDaPvbee

noted that they contain been magniÔ¨Åed for easier

RQOHU3Q,SQR,2WLLQWL6R(LWDH4Q[OUFL/(]H([HSF[UWHLF(RHSQ6USWUVLHRWRLURQ(YU5$QV,H[QURVHUUW6OH\FHDURX/U/WFXL'LVLRNSV'WDHQWW'HRW(,D&ROGFO[2HFXK(FJXPDX[HDPQWFSHSOHQ$HWQXLSHRQUWW/WQLRLV%QWXHIQ'IH'D;U'HW0DHGDIW:/DJD6XU6UJODWLWWRUU+HPDFUDDNVP6PQH6GW3R:,OPHFFDU'NUNSLFWHHOHH'N)WIU,WHDDHPXFIWDSWOWRXO7UOD\W7EDOHE(&OH(QH'&XOQOR('HPXFOGORP5XL6WF&RHP0HXUQR'WHPGDDQHSHWUWDH%Q ,QSXW6WUHDP readability.

2XWSXW6WUH$DPXG:LRUL,WQHSU XW6WUHDP ,QSXW6WUHDP5HDGHU

3LSHG2XWSXW6WUHDP

%XIIHUHG,QSXW6WUHDP

JOW)X%LPOXWHIHIUHQUW(HG[5FSHWDLRGQHUV ORU0 )LOH&KDQQ'HDOWD,%QXSXIIWH6UWHUHGD5PHDGHU3ULQW6WUHDP

RU ''DWDDWJDUJD,UQPDYP6DO3RLGFD23NFHDNXWUHWDSWPXHW6WH;WU(U(H(Q'[DXQFR'PPXH&F$RPSXHVWF)LURWWRLLQILFFXDWVH/LVWHQHUV accuracy on this dataset is improved from 60.95%DQtGoRP8$8F%)F)LHOLH.VOH5V,)HQLDOSHGXHW2U6EFWMUHHiFgDW,uPQrSeXW61WUHsDhPows a visualization based on coordinate

/LQH5HDG6HFP0HUXWHPDRQSHQW%Q/WX7%LVLO\XGW7LSHHOGHU\QH)S(HUDHUOFHV0WRPUL76\UHUU\RQDVUW\W,,PHFPDR97JQ7DH:E[OWUH/L According to human labeling, our classiÔ¨Åer has an F1- ter3mULQWp:2aU%LiXWHXrWUIsSIHXpUWH6rGWe2UHdXDiWScPXtWe6dWUHuDPsing the proposed method. Java

7LHHU%DZX\)II score of 86% over the highest-ranking 1000 pre)dLOiHc2tXeWdSXW6cWUlHaDsPs%eXsIIHwUHGit:hULWsHiUmilar functionality are highly connected

2XWSX7W6HW[UHWDXPU$HVF)3WRLDRFQLXQ/,VQW/SLVXWHW6QHWUVHDPV pairs.

2E)MLHOH'Fi:nWD2WUDLXtW2HWhSUXXiWsWS6XWgUW6HrDWaUPHpDhP, indicating that our method can be used

6/RLQF/NHLHQWH'&'5DKHWDDDQ,GQQHSHUXO W 7LV\W7SHH\Q+S(HHWUOWHV0SPVL76U8HUU\RQD5VUW\/W,HF&PR9R7QQDQEHOHF9WLLRHQZHU We see this work as a Ô¨Årst step towards bui%ld\WiHn$gUUD\2tXoWScXoW6nWUsHtDrPuct a code taxonomy.

7H[WXUH3D(LQ5,OQW HSXFWW6DWQUHJDOPHV' 7LHUDZ\)LOWHU $IILQH7UDQVIRUP2S a knowledge representation system for the software do-

LQH' OLSVH' $IILQH7UDQVI,RPUPDJH main, in which text entities refer to elements from a 2 Related Work

HFWDQJOH' &KD)U%ORXDIWI%HUXIIHU *UHJRULDQ&DOHQGDU *UDSKLFV software code base, for example classes, methods, apSVH' %\WH2UGHU 5HHQWUDQW/RFN plications and programming languages. Understanding
*UHJRULDQ&DOHQGD56U6HWUHLQPQJWSU56DOHHQWUDWL'/QGRJDHF%UWNHX)IIHRUU,Q$PSWDXRW$P6OSWLU5FKH,HDQQ$&PWGHRWHRPJUPHHSGRUL,F$VP/LUWDHURJDQH\J software entity relations will allow the construction of
$WRPLF,Q$WHWRJPHULF$/UURDQ\J a domain speciÔ¨Åc taxonomy and knowledge base, which
6LPSOH'DWH)RUPDW 7LPH,Q=SRXQW6HRXFNUFHHW,QSXW$96RWWRUODHPWDLOPLHF,P,QDWHJHJHU can enable higher reasoning capabilities in NLP applica-
76LW'PULDQHWJ=H%R)XQRLHUOGPHDUW +WWS$8WR5P/'LF&,DQRWWQHQJ)HHRFUUWLPRQDW %XIIHUHG,P6 tions for the software domain [3,29,41,42] and improve
)LOWHU5HDGHU )6LODWHPU,SQOHS0XWR6GWUHHODP a variety of code assisting applications, including code
YHU6'RDF'NWDDH,WQD&S2K6XDXWHQWSUQ,XQYH%WWHO%\UX6WHI+IRH%WFUW'XS6N;IVDHWIU8HWLQD&5UJ2/K%&&DXX,HQRQW6IUSISWQQHWLIUXXQLU2HLFQHWW6DOXJFWWW:WHSULRHXUQDLWW6HP8WUU55H;$DH/PXD&,GGQR:LHQRUSUQ&L,WQHH)HXSF,UPLUWXOLWWWR33HWDL&66IQUJLLSS2FRWH'UHHDOWX%H:RGGDUWWDUX2SH,W0UHDQIPXLIXW%SHRWDWD6XUXGSE/3WWIXH6OUIPLHHUWVORW65UWDU5,SHWPQDUHDHWVUPVDWW\RHP5XUUHFVHR%XX refactoring and token completion [1,15,17,34].

Semantic Relation Discovery. Previous work on semantic relation discovery, in particular, coordinate term discovery, has used two main approaches. The Ô¨Årst is based on the insight that certain lexical patterns indicate a semantic relationship with high-precision, as initially observed by Hearst [16]. For example, the conjuction pattern ‚ÄúX and Y‚Äù indicates that X and Y are coordinate terms. Other pattern-based classiÔ¨Åer have

been introduced for meronyms [13], synonyms [24], and general analogy relations [40]. The second approach relies on the notion that words that appear in a similar context are likely to be semantically similar. In contrast to pattern based classiÔ¨Åers, context distributional similarity approaches are normally higher in recall. [7, 32, 33, 36]. In this work we attempt to label samples extracted with high-precision Hearst patterns, using information from higher-recall methods.
Grounded Language Learning. The aim of grounded language learning methods is to learn a mapping between natural language (words and sentences) and the observed world [14, 35, 44], where more recent work includes grounding language to the physical world [19], and grounding of entire discourses [28]. Early work in this Ô¨Åeld relied on supervised aligned sentence-tomeaning data [12, 45]. However, in later work the supervision constraint has been gradually relaxed [18, 23]. Relative to prior work on grounded language acquisition, we use a very rich and complex representation of entities and their relationships (through software code). However, we consider a very constrained language task, namely coordinate term discovery.
Statistical Language Models for Software. In recent work by NLP and software engineering researchers, statistical language models have been adapted for modeling software code. NLP models have been used to enhance a variety of software development tasks such as code and comment token completion [15,17,29,34], analysis of code variable names [1,22], and mining software repositories [11]. This has been complemented by work from the programming language research community for structured prediction of code syntax trees [31]. To the best of our knowledge, there is no prior work on discovering semantic relations for software entities.
3 Coordinate Term Discovery
In this section we describe a coordinate term classiÔ¨Åcation pipeline, as depicted at high-level in Figure 2. All the following steps are described in detail in the sections below.
Given a software domain text corpus (StackOverÔ¨Çow) and a code repository (Java Standard Libraries), our goal is to predict a coordinate relation for X, Y , where X and Y are nouns which potentially refer to Java classes.
We Ô¨Årst attempt a baseline approach of labeling the pair X, Y based on corpus distributional similarity. Since closely related classes often exhibit morphological closeness, we use as a second baseline the string similarity of X and Y .
Next, we map noun X to an underlying class imple-

Word%X"

Word%Y"

p(Class%|%Word)%

Class%X‚Äô"

Class%Y‚Äô"

Text% Corpus%
Source% Code%

Text% Features%
Code% Features%

Coordinate% Term%
ClassiÔ¨Åer%

Figure 2: ClassiÔ¨Åcation Pipeline for determining whether nouns X and Y are coordinate terms. Each noun is mapped to an underlying class from the code repository with probability, p(Class|Word). Textual features are extracted based on the input words, code based features are extracted using the mapped classes, and all of these are given to the coordinate term classiÔ¨Åer.

mentation from the code repository, named X , according to an estimated probability for p(Class X |Word X), s.t., X = maxC pÀÜ(C|X), for all other classes C. X is then the code referent of X. Similarly, we map Y to the class Y . Given a code-based grounding for X and Y we extract information using the class implementations: (1) we deÔ¨Åne a code based distributional similarity measure, using code-context to encode the usage pattern of a class, and (2) we use the hierarchical organization of classes, described by the type and namespace hierarchies. Finally, we combine all the above information in a single SVM classiÔ¨Åer.

3.1 Baseline: Corpus Distributional Similarity. As an initial baseline we calculate the corpus distributional similarity of nouns X, Y , following the assumption that words with similar context are likely to be semantically similar. Our implementation follows Pereira et al. [33]. We calculate the empirical context distribution for noun X

(3.1)

pX = f (c, X)/ f (c , X)
c

where f (c, X) is the frequency of occurrence of noun X in context c. We then measure the similarity of nouns X and Y using the relative entropy or Kullback-Leibler divergence

(3.2)

D(pX ||pY ) = pX (z) log pX (z) z pY (z)

As this measure is not symmetric we Ô¨Ånally consider the distributional similarity of X and Y as D(pX ||pY )+ D(pY ||pX ).

3.2 Baseline: String Similarity. Due to naming convention standards, many related classes often exhibit some morphological closeness. For example, classes that

provide Input/Output access to the Ô¨Åle system will often contain the suÔ¨Éx Stream or Buffer. Likewise, many classes extend on the names of their super classes (e.g., JRadioButtonMenuItem extends the class JMenuItem). More examples can be found in Figure 1 and Table 4. We therefore include a second baseline which attempts to label the noun pair X, Y as coordinate terms according to their string matching similarity. We use the SecondString open source Java toolkit1. Each string is tokenized by camel case (such that ArrayList is represented as Array List). We consider the SoftTFIDF distance of the tokenized strings, as deÔ¨Åned by Cohen et al. [6].

3.3 Entity Linking. In order to draw code based information on text entities, we deÔ¨Åne a mapping function between words and class types. Our goal is to Ô¨Ånd p(C|W ), where C is a speciÔ¨Åc class implementation and W is a word. This mapping is ambiguous, for example, since users are less likely to mention the qualiÔ¨Åed class name (e.g., java.lang.String), and usually use the class label, meaning the name of the class not including its package (e.g., String). As an example, the terms java.lang.String and java.util.Vector appears 37 and 1 times respectively in our corpus, versus the terms String and Vector which appear 35K and 1.6K times. Additionally, class names appear with several variations, including, case-insensitive versions, spelling mistakes, or informal names (e.g., array instead of ArrayList).
Therefore, in order to approximate p(C, W ) in

(3.3)

p(C, W ) p(C|W ) =
p(W )

We estimate a word to class-type mapping that is mediated through the class label, L, as

(3.4)

pÀÜ(C, W ) = p(C, L) ¬∑ p(L, W )

Since p(C, L) = p(C|L)p(L), this can be estimated by the corresponding MLEs

(3.5)

pÀÜ(C, L) = pÀÜ(C|L) ¬∑ pÀÜ(L)

f (C)

=

¬∑

C ‚ààL f (C )

f (L) L f (L )

where f () is the frequency function. Note that since C ‚ààL f (C ) = f (L) we get that pÀÜ(C, L) = pÀÜ(C), as
the class label is uniquely determined by the class qualiÔ¨Åed name (the opposite does not hold since multiple class types may correspond to the same label). Finally, the term p(L, W ) is estimated by the symmetric string

1http://secondstring.sourceforge.net/

ARG-Method : Class is being passed as an argument to Method. We count an occurrence of this context once for the method deÔ¨Ånition
Method(Class class, ...) as well as for each method invocation
Method(class, ...) For example, given the statement
str = toString(i); where i is an Integer, we would count an occurrence for this class in the context ARG-toString.
API-Method : Class provides the API method Method. We count an occurrence of this context once for the method deÔ¨Ånition, and for every occurrence of the method invocation, e.g. class.Method(...). For example, given the statement
s = map.size(); where map is a HashMap, we would count an occurrence for this class in the context API-size.
Table 1: DeÔ¨Ånition of two types of code-contexts for a class type, Class, or an instantiation of that type (e.g., class).
distance between the two strings, as described in Section 3.2. We consider the linking probability of X, Y to be pÀÜ(X |X) ¬∑ pÀÜ(Y |Y ), where X is the best matching class for X s.t. X = maxC pÀÜ(C|X) and similarly for Y.
3.4 Code Distributional Similarity. Corpus distributional similarity evaluates the occurrence of words in particular semantic contexts. By deÔ¨Åning the classcontext of a Java class, we can then similarly calculate a code distributional similarity between classes. Our definition of class context is based on the usage of a class as an argument to methods and on the API which the class provides, and it is detailed in Table 1. We observe over 23K unique contexts in our code repository. Based on these deÔ¨Ånitions we can compute the distributional similarity measure between classes X and Y based on their code-context distributions, as previously described for the corpus distributional similarity (Section 3.1, following Pereira et al. [33]). For the code-based case, we calculate the empirical context distribution of X (see Equation 3.1) using f (c, X ), the occurrence frequency of class X in context c, where c is one of the ARGMethod or API-Method contexts (deÔ¨Åned in Table 1) for methods observed in the code repository. The distributional similarity of X , Y is then taken, using the relative entropy, as D(pX ||pY ) + D(pY ||pX ).

3.5 Code Hierarchies and Organization. The words X and Y are deÔ¨Åned as coordinate terms if they have the same hypernym in a given taxonomy, meaning they have at least one common ancestor in this taxonomy [36]. For the purpose of comparing two class types, we therefore deÔ¨Åne an ancestry relation between them using two taxonomies based on the code namespace and type hierarchies.
Package Taxonomy: A package is the standard way for deÔ¨Åning namespaces in the Java language. It is a mechanism for organizing sets of classes which normally share a common functionality. Packages are organized in a hierarchical structure which can be easily inferred from the class name. For example, the class java.lang.String, belongs to the java.lang package, which belongs to the java package.
Type Taxonomy: The inheritance structure of classes and interfaces in the Java language deÔ¨Ånes a type hierarchy, such that class A is the ancestor of class B if B extends or implements A.
We deÔ¨Åne type-ancestry and package-ancestry relations between classes X , Y , based on the above taxonomies. For the type taxonomy,
Antype(X , Y ) = {# of common ancestors X and Y share within n higher up levels in the type taxonomy}
for n from 1 to 6. Anpackage is deÔ¨Åned similarly for the package taxonomy. As an example,
A2package(ArrayList, Vector) = 2

High PMI
JTextField,JComboBox yearsPlayed,totalEarned PostInsertEventListener, PostUpdateEventListener removeListener,addListener MinTreeMap,MaxTreeMap

Low PMI threads,characters server,user code,design
Java,client Eclipse,array

Table 2: Sample set of word pairs with high and low PMI scores. Many of the high PMI pairs refer to software entities such as variable, method and Java class names, whereas the low PMI pairs contain more general software terms.

Mallet statistical NLP package [26]. In this study, we use only the text portions of the SO posts, and exclude all raw code segments, as indicated by the user-labeled <code> markup. Next, the text was POS tagged with the Stanford POS tagger [39] and parsed with the MaltParser [30]. Finally, we extract noun pairs with the conjunction dependencies: conj or inv-conj, a total of 255,150 pairs, which we use as positive training samples.
We use the Java standard libraries code repository as a grounding source for Java classes, as we expect that users will often refer to these classes in the Java tagged SO posts. This data includes: 7072 source code Ô¨Åles, the implementation of 10562 class and interface types, and 477 packages. The code repository is parsed using the Eclipse JDT compiler tools, which provide APIs for accessing and manipulating Abstract Syntax Trees.

as these classes both belong in the package java.util, and therefore their common level 2 ancestors are: java and java.util. Moreover,

4.2 ClassiÔ¨Åcation. We follow the classiÔ¨Åcation pipeline described in Figure 2, using the LibLinear SVM classiÔ¨Åer [5, 9] with the following features:

A1type(ArrayList, Vector) = 5
since both classes extend the AbstractList class, and also implement four joint interfaces: List, RandomAccess, Cloneable, and Serializable.
4 Experimental Settings 4.1 Data Handling. We downloaded a dump of the interactions on the StackOverÔ¨Çow website2 from its launch date in 2008 and until 2012. We use only the 277K questions labeled with the user-assigned Java tag, and their 629K answers.
Text from the SO html posts was extracted with the Apache Tika toolkit3 and then tokenized with the
2http://www.clearbits.net/creators/146-stack-exchange-datadump
3http://tika.apache.org/

Corpus-Based Features
‚Ä¢ Corpus distributional similarity (Corpus Dist. Sim.) - see Section 3.1.
‚Ä¢ String similarity (String Sim.) - see Section 3.2.
Code-Based Features
‚Ä¢ Text to code linking probability (Text-to-code Prob.) - see Section 3.3.
‚Ä¢ Code distributional similarity (Code Dist. Sim.) - see Section 3.4.
‚Ä¢ Package and type ancestry (A1package A6package and A1type - A6type) - see Section 3.5.
Since the validity of the code based features above is directly related to the success of the entity linking phase,

Method

Code & Corpus

Baselines: Corpus Dist. Sim. String Sim. Corpus Only Code Only

Code Features:

Code Dist. Sim.

A1package A2package A3package A4package A5package A6package A1type A2type A3type A4type A5type A6type Text-to-code

Prob.

Coord
85.3
57.8 65.2 64.7 80.1
67 (60.2) 64.2 (63.8) 64.2 (63.8) 65.8 (64.3) 52.5 (52) 52.5 (52) 50.4 (51.6) 51.4 (51.4) 54 (53.9) 56.8 (56.7) 57.1 (56.9) 57.4 (57.6) 57.2 (57.4)
55.7

Coord-PMI
88
58.2 65.8 60.9 81.1
67.2 (59) 64.3 (63.9) 61.2 (64.8) 66 (64.6) 64.7 (58.7) 52.6 (58.7) 52.3 (52) 55.1 (53.7) 55.5 (54.3) 57 (56.9) 57.3 (57.1) 58 (57.9) 57.5 (57.5)
55.8

Table 3: Cross validation accuracy results for the coordinate term SVM classiÔ¨Åer (Code & Corpus), as well as baselines using corpus distributional similarity, string similarity, all corpus based features (Corpus Only), or all code based features (Code Only), and all individual code based features. The weighted version of the code based features (see Section 4.2) is in parenthesis. Results are shown for both the Coord and Coord-PMI datasets.

each of the code based features are used in the classiÔ¨Åer once with the original value and a second time with the value weighted by the text to code linking probability.
Of the noun pairs X, Y in our data, we keep only pairs for which the linking probability pÀÜ(X |X)¬∑pÀÜ(Y |Y ) is greater than 0.1. Note that this guarantees that each noun must be mapped to at least one class with non-zero probability. Next, we evaluate the string morphology and its resemblance to a camel-case format, which is the acceptable formatting for Java class names. We therefore select alphanumeric terms with at least two upper-case and one lower-case characters. We name this set of noun pairs the Coord dataset.
A key assumption underlying statistical distributional similarity approaches is that ‚Äúhigh-interest‚Äù entities are associated with higher corpus frequencies, therefore, given suÔ¨Écient statistical evidence ‚Äúhigh-interest‚Äù relations can be extracted. In the software domain, real

world factors may introduce biases in a software-focused text corpus which may aÔ¨Äect the corpus frequencies of classes: e.g., users may discuss classes based on the clarity of their API, the eÔ¨Éciency of their implementation, or simply if they are fundamental in software introduced to novice users. Another motivation for using grounded data, such as the class implementation, is that it may highlight additional aspects of interest, for example, classes that are commonly inherited from. We therefore deÔ¨Åne a second noun dataset, Coord-PMI, which attempts to address this issue, in which noun pairs are selected based on their pointwise mutual information (PMI ):

(4.6)

p(X, Y ) PMI (X, Y ) = log
p(X)p(Y )

where the frequency of the pair X, Y in the corpus is positive. In this set we include coordinate term pairs with high PMI scores, which appear more rarely in the corpus and are therefore harder to predict using standard NLP techniques. The negative set in this data are noun pairs which appear frequently separately but do not appear as coordinate terms, and are therefore marked by low PMI scores.
To illustrate this point, we provide a sample of noun pairs with low and high PMI scores in Table 2, where pairs highlighted with bold font are labeled as coordinate terms in our data. We can see that the high PMI set contains pairs that are speciÔ¨Åc and interesting in the software domain while not necessarily being frequent words in the general domain. For example, some pairs seem to represent variable names (e.g., yearsPlayed, totalEarned ), others likely refer to method names (e.g., removeListener, addListener ). Some pairs refer to Java classes, such as JTextField, JComboBox whose implementation can be found in the Java code repository. We can also see examples of pairs such as PostInsertEventListener, PostUpdateEventListener which are likely to be user-deÔ¨Åned classes with a relationship to the Java class java.util.EventListener. In contrast, the low PMI set contains more general software terms (e.g., code, design, server, threads).

5 Results
5.1 ClassiÔ¨Åcation and Feature Analysis. In Table 3 we report the cross validation accuracy of the coordinate term classiÔ¨Åer (Code & Corpus) as well as baseline classiÔ¨Åers using corpus distributional similarity (Corpus Dist. Sim.), string similarity (String Sim.), all corpus features (All Corpus), or all code features (All Code). Note that using all code features is signiÔ¨Åcantly more successful on this data than any of the corpus baselines (corpus baselines‚Äô accuracy is between 57%-

Code Dist. Sim
FileOutputStream,OutputStream AÔ¨ÉneTransform,AÔ¨ÉneTransformOp GZIPOutputStream, DeÔ¨ÇaterOutputStream OutputStream,DataOutputStream AtomicInteger,AtomicIntegerArray ResourceBundle,ListResourceBundle
setIconImages,setIconImage ComboBoxModel, DefaultComboBoxModel JTextArea,TextArea ServerSocketChannel,SocketChannel

A3package
KeyEvent,KeyListener StyleConstants,SimpleAttributeSet BlockQueue,ThreadPoolExecutor

A5type
JMenuItem,JMenu JMenuItems,JMenu JMenuItems,JMenus

BuÔ¨ÄeredImage,WritableRaster MouseListener,MouseWheelListener DocumentBuilderFactory, DocumentBuilder ActionListeners,FocusListeners DataInputStream,DataOutputStream

JLabel,DefaultTreeCellRenderer JToggleButton,JRadioButtonMenu JFrame,JDialogs
JTable,JTableHeader JTextArea,JEditorPane

greaterOrEqualThan,lesserOrEqualThan CopyOnWriteArrayList, ConcurrentLinkedQueue

JTextPane,JEditorPane JTextArea,JTable

Table 4: Top ten coordinate terms predicted by classiÔ¨Åers using one of the following features: code distributional
similarity, package hierarchy ancestry (A3package), and type hierarchy ancestry (A5type). All of the displayed predictions are true.

1 0.86
0.8

0.6

0.56

F 1

0.4 0.28
Full 0.2 Code Dist. Sim.
Corpus Dist. Sim. 0 200 400 600 800 1000
Rank
Figure 3: Manual Labeling Results. F1 results of the top 1000 predicted coordinate terms by rank. The Ô¨Ånal data point in each line is labeled with the F1 score at rank 1000.

65% whereas code-based accuracy is over 80%). When using both data sources, performance is improved even further (to over 85% on the Coord dataset and 88% on Coord-PMI ).
We provide an additional feature analysis in Table 3, and report the cross validation accuracy of classiÔ¨Åers using each single code feature. Interestingly, code distributional similarity (Code Dist. Sim.) is the strongest single feature, and it is a signiÔ¨Åcantly better predictor than corpus distributional similarity, achieving around 67% v.s. around 58% for both datasets.

5.2 Evaluation by Manual Labeling. The crossvalidation results above are based on labels extracted using Hearst conjunction patterns. In Figure 3 we provide an additional analysis based on manual human labeling of samples from the Coord-PMI dataset, following a procedure similar to prior researchers exploring semi-supervised methods for relation discovery [4, 21]. After all development was complete, we hand labeled the top 1000 coordinate term pairs according to the ranking by our full classiÔ¨Åer (using all code and corpus features) and the top 1000 pairs predicted by the classiÔ¨Åers based on code and corpus distributional similarities only. We report the F1 results of each classiÔ¨Åer by the rank of the predicted samples. According to our analysis, the F1 score for the text and code distributional similarity classiÔ¨Åers degrades quickly after the Ô¨Årst 100 and 200 top ranked pairs, respectively. At rank 1000, the score of the full classiÔ¨Åer is at 86%, whereas the code and text classiÔ¨Åers are only at 56% and 28%.
To highlight the strength of each of the code based features, we provide in Table 4 the top ten coordinate terms predicted using the most successful code based features. For example, the top prediction using type hierarchy ancestry (A5type) is JMenuItem, JMenu . Since JMenu extends JMenuItem, the two classes indeed share many common interfaces and classes. Alternatively, all of the top predictions using the package hierarchy ancestry (A3package) are labels that have been matched to pairs of classes that share at least 3 higher up package levels. So for example, BlockQueue has been matched to java.util.concurrent.BlockingQueue which was predicted as a coordinate term of ThreadPoolExecutor which belongs in the same package. Using code dis-

tributional similarity, one of the top predictions is the pair GZIPOutputStream, DeÔ¨ÇaterOutputStream , which share many common API methods such as write, flush, and close. Many of the other top predicted pairs by this feature have been mapped to the same class and therefore have the exact same context distribution.
5.3 Taxonomy Construction. We visualize the coordinate term pairs predicted using our method (with all features), by aggregating them into a graph where entities are nodes and edges are determined by a coordinate term relation (Figure 1). Graph edges are colored using the Louvain method [2] for community detection and an entity label‚Äôs size is determined by its betweenness centrality degree. We can see that high-level communities in this graph correspond to class functionality, indicating that our method can be used to create an interesting code taxonomy.
Note that our predictions also highlight connections within functional groups that cannot be found using the package or type taxonomies directly. One example can be highlighted within the GUI functionality group. Listener classes facilitate a response mechanism to GUI Actions, such as pressing a button, or entering text, however, these classes belong in diÔ¨Äerent packages than basic GUI components for historical reasons. In our graph, Action and Listener classes belong to the same communities of the GUI components they are normally used with.
6 Conclusions
We have presented an approach for grounded discovery of coordinate term relationships between text entities representing Java classes. Using a simple entity linking method we map text entities to an underlying class type implementation from the Java standard libraries. With this code-based grounding, we extract information on the usage pattern of the class and its location in the Java class and namespace hierarchies. Our experimental evaluation shows that using only corpus distributional similarity for the coordinate term prediction task is unsuccessful, achieving prediction accuracy of around 58%. However, adding information based on the entities‚Äô software implementation improves accuracy dramatically to 88%. Our classiÔ¨Åer has an F1 score of 86% according to human labeling over the top 1000 predicted pairs. We have shown that our predictions can be used to build an interesting code taxonomy which draws from the functional connections, common usage patterns, and implementation details that are shared between classes.
References

[1] Dave Binkley, Matthew Hearn, and Dawn Lawrie. Improving identiÔ¨Åer informativeness using part of speech information. In Proc. of the Working Conference on Mining Software Repositories. ACM, 2011.
[2] Vincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefebvre. Fast unfolding of communities in large networks. Journal of Statistical Mechanics: Theory and Experiment, 2008.
[3] SRK Branavan, Luke S Zettlemoyer, and Regina Barzilay. Reading between the lines: Learning to map highlevel instructions to commands. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics. ACL, 2010.
[4] Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr Settles, Estevam R Hruschka Jr, and Tom M Mitchell. Toward an architecture for never-ending language learning. In AAAI, 2010.
[5] Chih-Chung Chang and Chih-Jen Lin. Libsvm: a library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2011.
[6] William W Cohen, Pradeep D Ravikumar, Stephen E Fienberg, et al. A comparison of string distance metrics for name-matching tasks. In IIWeb, 2003.
[7] James Richard Curran. From distributional to semantic similarity. PhD thesis, University of Edinburgh. College of Science and Engineering. School of Informatics., 2004.
[8] Anthony Fader, Stephen Soderland, and Oren Etzioni. Identifying relations for open information extraction. In Proceedings of the Conference on Empirical Methods in Natural Language Processing. ACL, 2011.
[9] Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, XiangRui Wang, and Chih-Jen Lin. Liblinear: A library for large linear classiÔ¨Åcation. The Journal of Machine Learning Research, 9, 2008.
[10] Christiane Fellbaum. Wordnet: An electronic lexical database, 1998.
[11] Mark Gabel and Zhendong Su. Javert: fully automatic mining of general temporal properties from dynamic traces. In Proceedings of the 16th ACM SIGSOFT International Symposium on Foundations of software engineering. ACM, 2008.
[12] Ruifang Ge and Raymond J Mooney. A statistical semantic parser that integrates syntax and semantics. In Computational Natural Language Learning. ACL, 2005.
[13] Roxana Girju, Adriana Badulescu, and Dan Moldovan. Learning semantic constraints for the automatic discovery of part-whole relations. In North American Chapter of the Association for Computational Linguistics on Human Language Technology. ACL, 2003.
[14] Peter Gorniak and Deb Roy. Situated language understanding as Ô¨Åltering perceived aÔ¨Äordances. Cognitive Science, 2007.
[15] Sangmok Han, David R Wallace, and Robert C Miller. Code completion from abbreviated input. In Automated Software Engineering. IEEE, 2009.
[16] Marti A Hearst. Automatic acquisition of hyponyms

from large text corpora. In Proceedings of the 14th conference on Computational linguistics. ACL, 1992. [17] Ferosh Jacob and Robert Tairas. Code template inference using language models. In Southeast Regional Conference. ACM, 2010. [18] Rohit J Kate and Raymond J Mooney. Learning language semantics from ambiguous supervision. In AAAI, 2007. [19] Jayant Krishnamurthy and Thomas Kollar. Jointly learning to parse and perceive: Connecting natural language to the physical world. TACL, 2013. [20] Jayant Krishnamurthy and Tom M Mitchell. Weakly supervised training of semantic parsers. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. ACL, 2012. [21] Ni Lao, Tom Mitchell, and William W Cohen. Random walk inference and learning in a large scale knowledge base. In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2011. [22] Dawn Lawrie, Christopher Morrell, Henry Feild, and David Binkley. Whats in a name? a study of identiÔ¨Åers. In ICPC 2006. 14th IEEE International Conference on Program Comprehension. IEEE, 2006. [23] Percy Liang, Michael I Jordan, and Dan Klein. Learning semantic correspondences with less supervision. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, 2009. [24] Dekang Lin, Shaojun Zhao, Lijuan Qin, and Ming Zhou. Identifying synonyms among distributionally similar words. In IJCAI, 2003. [25] Thomas Lin, Oren Etzioni, et al. Entity linking at web scale. In Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Webscale Knowledge Extraction. ACL, 2012. [26] Andrew Kachites McCallum. Mallet: A machine learning for language toolkit. 2002. [27] George A Miller. Wordnet: A lexical database for english. Communications of the ACM, 1995. [28] Thang Luong Minh, Michael C Frank, and Mark Johnson. Parsing entire discourses as very long strings: Capturing topic continuity in grounded language learning. TACL, 2013. [29] Dana Movshovitz-Attias and William W. Cohen. Natural language models for predicting programming comments. In Association for Computational Linguistics, pages 35‚Äì40. ACL, 2013. [30] Joakim Nivre, Johan Hall, and Jens Nilsson. Maltparser: A data-driven parser-generator for dependency parsing. In Proceedings of LREC, 2006. [31] Cyrus Omar. Structured statistical syntax tree prediction. In Proceedings of the 2013 companion publication for conference on Systems, programming, & applications: software for humanity. ACM, 2013. [32] Patrick Andre Pantel. Clustering by committee. PhD

thesis, Department of Computing Science, University of Alberta, 2003. [33] Fernando Pereira, Naftali Tishby, and Lillian Lee. Distributional clustering of english words. In ACL, 1993. [34] Peter Schulam, Roni Rosenfeld, and Premkumar Devanbu. Building statistical language models of code. In Proc. DAPSE. IEEE, 2013. [35] JeÔ¨Ärey Mark Siskind. A computational study of crosssituational techniques for learning word-to-meaning mappings. Cognition, 1996. [36] Rion Snow, Daniel Jurafsky, and Andrew Y Ng. Learning syntactic patterns for automatic hypernym discovery. In NIPS, 2004. [37] Rion Snow, Daniel Jurafsky, and Andrew Y Ng. Semantic taxonomy induction from heterogenous evidence. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics. Association for Computational Linguistics, 2006. [38] Partha Pratim Talukdar, Derry Wijaya, and Tom Mitchell. Coupled temporal scoping of relational facts. In Proceedings of the Ô¨Åfth ACM international conference on Web search and data mining. ACM, 2012. [39] Kristina Toutanova, Dan Klein, Christopher D Manning, and Yoram Singer. Feature-rich part-of-speech tagging with a cyclic dependency network. In Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology. Association for Computational Linguistics, 2003. [40] Peter Turney, Michael L Littman, JeÔ¨Ärey Bigham, and Victor Shnayder. Combining independent modules to solve multiple-choice synonym and analogy problems. 2003. [41] Xiaoyin Wang, David Lo, Jing Jiang, Lu Zhang, and Hong Mei. Extracting paraphrases of technical terms from noisy parallel software corpora. In Proceedings of the ACL-IJCNLP. ACL, 2009. [42] Markus Weimer, Iryna Gurevych, and Max Mu¬®hlha¬®user. Automatically assessing the post quality in online discussions on software. In Proceedings of the 45th Annual Meeting of the ACL. ACL, 2007. [43] Alexander Yates, Michael Cafarella, Michele Banko, Oren Etzioni, Matthew Broadhead, and Stephen Soderland. Textrunner: open information extraction on the web. In Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations. ACL, 2007. [44] Chen Yu and Dana H Ballard. On the integration of grounding language and learning objects. In AAAI, 2004. [45] Luke S Zettlemoyer and Michael Collins. Learning to map sentences to logical form: Structured classiÔ¨Åcation with probabilistic categorial grammars. Uncertainty in ArtiÔ¨Åcial Intelligence, 2005.

