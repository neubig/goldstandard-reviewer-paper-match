arXiv:1907.13119v1 [cs.IT] 30 Jul 2019

1
Convertible Codes: Efﬁcient Conversion of Coded
Data in Distributed Storage
Francisco Maturana and K. V. Rashmi Computer Science Department Carnegie Mellon University
{fmaturan, rvinayak}@cs.cmu.edu
Abstract
Large-scale distributed storage systems typically use erasure codes to provide durability of data in the face of failures. A set of k blocks to be stored is encoded using an [n, k] code to generate n blocks that are then stored on different storage nodes. The redundancy conﬁguration (that is, the parameters n and k) is chosen based on the failure rates of storage devices, and is typically kept constant. However, a recent work by Kadekodi et al. shows that the failure rate of storage devices vary signiﬁcantly over time, and that adapting the redundancy conﬁguration in response to such variations provides signiﬁcant beneﬁts: a 11% to 44% reduction in storage space requirement, which translates to enormous amounts of savings in resources and energy in large-scale storage systems. However, converting the redundancy conﬁguration of already encoded data by simply re-encoding (the default approach) requires signiﬁcant overhead on system resources such as accesses, device IO, network bandwidth, and compute cycles.
In this work, we ﬁrst present a framework to formalize the notion of code conversion—the process of converting data encoded with an [nI , kI ] code into data encoded with an [nF , kF ] code while maintaining desired decodability properties, such as the maximum-distance-separable (MDS) property. We then introduce convertible codes, a new class of codes that allow for code conversions in a resource-efﬁcient manner. For an important parameter regime (which we call the merge regime) along with the widely used linearity and MDS decodability constraint, we prove tight bounds on the number of nodes accessed during code conversion. In particular, our achievability result is an explicit construction of MDS convertible codes that are optimal for all parameter values in the merge regime albeit with a high ﬁeld size. We then present explicit low-ﬁeld-size constructions of optimal MDS convertible codes for a broad range of parameters in the merge regime. Our results thus show that it is indeed possible to achieve code conversions with signiﬁcantly lesser resources as compared to the default approach of re-encoding.
I. INTRODUCTION
Large-scale distributed storage systems form the bedrock of modern data processing systems. Such storage systems comprise hundreds of thousands of storage devices and routinely face failures in their day-to-day operation [1]–[4]. In order to provide resiliency against such failures, storage systems employ redundancy, typically in the form of erasure codes [5]–[8]. Under erasure coding, a set of k data blocks to be stored is encoded using an [n, k] code to generate n coded blocks. A set of n encoded blocks that correspond to the same k original data blocks is called a “stripe”. Each of the n coded blocks in a stripe is stored on a different storage node (typically chosen from different failure domains). The amount of redundancy added using an erasure code is a function of the redundancy conﬁguration, that is, parameters n and k. These parameters are chosen so as to achieve predetermined thresholds on reliability and availability, such as the mean-time-to-data-loss (MTTDL).
The key factor that determines MTTDL for chosen parameters is the failure rate of the storage devices In a recent work [9], Kadekodi et al. show that failure rates of storage devices in large-scle storage systems vary signiﬁcantly over time (for example, by more than 3.5-fold for certain disk families). Thus, it is advantageous to change the redundancy conﬁguration in response to such variations Kadekodi et al. [9] present a case for tailoring erasure code parameters to the observed failure rates and show that an 11% to 44% reduction in storage space can be achieved by adapting the redundancy conﬁguration according to the changing failure rates. Such a reduction in storage space requirement translates to signiﬁcant savings in the cost of resources and energy consumed in large-scale storage systems.
In particular, disk failure rates exhibit a bathtub curve during the lifetime of disks, which is characterized by three phases: infancy, useful life, and wearout, in that order [9]. Disk failure rate during infancy and wearout can

2
be multiple times higher than during useful life. As a consequence, the chosen redundancy setting will likely be too high for some periods, which is a waste of resources, and too low for other periods, which increases the risk of data loss. Kadekodi et al. [9] address this problem by changing the code rate (that is, the parameters of the erasure coding scheme) as the devices go through different phases of life. For example, given a group of nodes with certain failure characteristics, the system may use a [14, 10] code during infancy, then convert to a [24, 20] code during useful life, and ﬁnally convert back to a [14, 10] code during wearout. We refer the reader to [9] for an in-depth study on failure rate variations and the advantages of adapting the erasure-code parameters with these variations.
Adapting the redundancy conﬁguration requires modifying the code rate for all the stripes that have at least one block stored on a certain disk group when the failure rate of that disk group changes by more than a threshold amount [9]. Changing the code rate, that is the parameters of the erasure code, employed on already encoded data can be highly resource intensive, potentially requiring to access multiple storage devices, read large amounts of data, transfer it over the network, and re-encode it. Modifying the code parameters using the default approach requires reading at least k blocks from each stripe, transferring over the network and re-encoding. In large-scale storage systems, disks are deployed in large batches, and hence a large number of disks go through failure-rate transitions concurrently. Thus, adapting redundancy conﬁguration by using the default approach of re-encoding generates highly varying and prohibitively large load spikes, which adversely affect the foreground trafﬁc. This places signiﬁcant burden on precious cluster resources such as accesses, disk IO, network bandwidth, and computation cycles (CPU). Furthermore, in some cases these conversions need be performed urgently, such as the case where there is an unexpected rise in failure rates and conversion is necessary to reduce the risk of data loss. In such cases, it is necessary to be able to perform fast conversions. Motivated by these applications, in this paper, we initiate a formal study of such code conversions by exploring the following questions:
• What are the fundamental limits on resource consumption of code conversions? • How can one design codes that efﬁciently facilitate code conversions? Formally, the goal is to convert data that is already encoded using an [nI , kI ] code (denoted by CI ) into data encoded using an [nF , kF ] code (denoted by CF )1, with desired constraints on decodability such as both initial and ﬁnal codes satisfying the maximum-distance-separable (MDS) property. Clearly, it is always possible to read the original data (and decode if needed) and re-encode according to CF . However, such a re-encoding approach requires accessing several nodes (kI nodes per stripe for MDS codes), reading out all the data, transferring over the network, and re-encoding, which consumes large amounts of access, disk IO, network bandwidth, and CPU resources. The question then is whether one can perform such conversions in a more resource-efﬁcient manner, while satisfying the decodability constraints. We now present an example showing how resource-efﬁcient conversion can be achieved in a simple manner for certain parameters.
Example 1. Consider nI = kI + 1, nF = kF + 1, and kF = 2kI , with the requirement that both CI and CF are MDS. This conversion can be achieved by “merging” two stripes of the initial code into one stripe, for each stripe of the ﬁnal code. Let us focus on the number of blocks accessed during conversion. Using the default approach of re-encoding to achieve the conversion requires accessing kI blocks from two stripes of encoded data under CI (initial stripes) to create one stripe of encoded data under CF (ﬁnal stripe). That is, each stripe of encoded data under the ﬁnal code CF requires accessing 2kI blocks. Alternatively, as depicted in Figure 1, one can choose CI and CF to be systematic, single-parity-check codes, with the parity block holding the XOR of the data blocks in each stripe (shown with a shaded box in the ﬁgure). To convert from CI to CF , one can compute the XOR between the single parity in each stripe, and store the result as the parity block for the stripe under CF . This alternative approach requires accessing only two blocks for each ﬁnal stripe, and thus is signiﬁcantly more efﬁcient in the number of accessed blocks as compared to the default approach.
In this paper, we ﬁrst propose a novel framework that formalizes the concept of code conversion, that is, the process of converting data encoded with an [nI , kI ] code into data encoded with an [nF , kF ] code while maintaining desired decodability properties, such as maximum-distance-separable (MDS) property. We then introduce a new class of code pairs, which we call convertible codes, which allow for resource-efﬁcient conversions. We begin the study of this new class of code pairs, by focusing on an important regime where kF = λkI for any integer λ ≥ 2
1The superscripts I and F stand for initial and ﬁnal respectively, representing the initial and ﬁnal state of the conversion.

3

Initial stripe 1 kI

Initial stripe 2 kI

2kI Final stripe
Fig. 1. Example of code conversion without re-encoding: two stripes of a [kI + 1, kI ] single-parity-check code become one stripe of a [2kI + 1, 2kI ] single-parity-check code. The parity blocks are shown shaded. The data blocks from each stripe are preserved, and the single parity block from the ﬁnal stripe is computed as the XOR of the parities from each of the initial stripes.
with arbitrary values of nI and nF , which we call the merge regime. Furthermore, we focus on the access cost of code conversion, which corresponds to the total number of nodes that participate in the conversion. Keeping the number of nodes accessed small makes conversion less disruptive and allows the unaffected nodes to remain available for serving client requests. In addition, reducing the number of accesses also reduces disk IO, network bandwidth and CPU consumed.
We prove tight bounds on the access cost of conversions for linear MDS codes in the merge regime. In particular, our achievability result is an explicit construction of MDS convertible codes that are access-optimal for all parameters values in the merge regime albeit with a high ﬁeld size. Finally, we present a sequence of practical low-ﬁeldsize constructions of access-optimal MDS convertible codes in the merge regime based on Hankel arrays. These constructions lead to a tradeoff between ﬁeld size and the parameter values they cover with the two extreme points corresponding to (1) nF − kF ≤ (nI − kI )/λ requiring a ﬁeld size q ≥ max{nI − 1, nF − 1}, and (2) nF − kF ≤ nI − kI − λ + 1 requiring a ﬁeld size q ≥ kI rI . Thus, our results show that code conversions can be achieved with a signiﬁcantly lesser resource overhead as compared to the default approach of re-encoding. Furthermore, all the constructions presented have the added beneﬁt that they continue to be optimal for a wide range of parameters, which allows to handle the case where the parameters of the ﬁnal code are unknown a priori.
The rest of the paper is organized as follows. Section II discusses related work. Section III formalizes the notion of code conversions and presents a framework for studying convertible codes. Section IV shows the derivation of lower bounds on the access cost of conversions for linear MDS codes in the merge regime. Section V describes a general explicit construction for MDS codes in the merge regime that meets the access cost lower bounds, albeit with a high ﬁeld size. Section VI describes low-ﬁeld-size constructions for MDS codes in the merge regime, which provide a tradeoff between ﬁeld size and range of parameter values they cover. Finally, Section VII presents our conclusions and discuss future directions.
II. RELATED WORK
There is extensive literature on the use of erasure codes for reliable data storage. In storage systems, failures can be effectively modeled as erasures, and thereby, erasure codes can be used to provide tolerance to failures, at the cost of some storage overhead [10], [11]. Maximum distance separable (MDS) codes are often used for this purpose, since they achieve the optimal tradeoff between failure tolerance and storage overhead. A well-known and often-used family of MDS codes is Reed-Solomon codes [12].
When using erasure codes in storage systems, a host of other overheads and performance metrics, in addition to storage overhead, comes into picture. Encoding/decoding complexity, node repair performance, degraded read performance, ﬁeld size, and other metrics can signiﬁcantly affect real system performance. Several works in the literature have studied these aspects.
The encoding and decoding of data, and the ﬁnite ﬁeld arithmetic that they require, can be compute intensive. Motivated by this, array codes [13]–[16] are designed to use XOR operations exclusively, which are typically faster to execute, and aim to decrease the complexity of encoding and decoding.
The repair of failed nodes can incur a large amount of data read and transfer, burdening device IO and network bandwidth. Several approaches have been proposed to alleviate the impact of repair operations. Dimakis et al. [17] proposed a new class of codes called regenerating codes that minimize the amount of network bandwidth consumed during repair operations. Several explicit constructions of regenerating codes have been proposed (for example, see

4
[18]–[28]) as well as generalizations (for example, see [29]–[31]). It has been shown that meeting the lower bound on the repair bandwidth requirement when MDS property and high rate are desired necessitates a large value for the so called “sub-packetization” [32]–[35], which negatively affects certain key performance metrics in storage systems [3]. To overcome this issue, several works [36]–[38] have proposed code constructions that relax the requirement of meeting lower bounds on IO and bandwidth requirements for repair operations. For example, the Piggybacking framework [37] provides a general framework to construct repair-efﬁcient codes by transforming any existing codes, while allowing a small sub-packetization (even as small as 2). The above discussed works construct vector codes in order to improve the efﬁciency of repair operation. The papers [39]–[41] propose repair algorithms for (scalar) Reed-Solomon codes that reduce the network bandwidth consumed during repair by downloading elements from a subﬁeld rather than the ﬁnite ﬁeld over which the code is constructed. Network bandwidth consumed is another metric to optimize for during conversion. In this paper, we only focus on the access cost.
Another class of codes, called local codes [42]–[51], focuses on the locality of codeword symbols during repair, that is, the number of nodes that need to be accessed when repairing a single failure. Local codes improve repair and degraded read performance, since missing information can be recovered without having to recover the full data. The locality metric for repair that local codes optimize for is similar to the access cost metric for conversion that we optimize for in this work as both these metrics aim to minimize the number of nodes accessed.
There are several classical techniques for creating new codes from existing ones [12]. For example, techniques such as puncturing, extending, shortening, and others which can be used to modify codes. These techniques, however, do not consider the cost of performing such modiﬁcations to data that is already encoded, which is the focus of our work.
Several works [52], [53] study the problem of two stage encoding: ﬁrst generating a certain number of parities during the encoding process and then adding additional parities. As discussed in [52], adding additional parities can be conceptually viewed as a repair process by considering the new parity nodes to be generated as failed nodes. Furthermore, as shown in [19], for MDS codes, the bandwidth requirement for repair of even a single node is lower bounded by the same amount as in regenerating codes that require repair of all nodes. Thus one can always employ a regenerating code to add additional parities with minimum bandwidth overhead. However, when MDS property and high rate are desired, as discussed above, using regenerating codes requires a large sub-packetization. The paper [53] employs the Piggybacking framework [36], [37] to construct codes that overcome the issue of large sub-packetization factor. The scenario of adding a ﬁxed number of additional parities, when viewed under the setting of conversions, corresponds to having kI = kF and nI < nF .
Another related work [54] proposes a storage system that uses two erasure codes. One of the codes prioritizes the network bandwidth required for recovery, while the other prioritizes storage overhead, and data is converted between the two codes according to the workload. This application constitutes another motivation for resourceefﬁcient conversions. To reduce the cost of code conversion, the system [54] uses product codes [12] and locally repairable codes [44], and the local parities are leveraged during conversion. The authors, however, choose codes from these two families ad hoc, and do not focus on the problem of designing these codes to minimize the cost of code conversion.
Several works [55]–[57] study the update operation in erasure coded storage systems, and the problem of maintaining consistency in such mutable storage systems. The cost of updates is another metric to optimize for in convertible codes, which we do not consider in this paper. In the current paper, the focus is on immutable storage systems which comprise a vast majority of large-scale storage systems.
III. A FRAMEWORK FOR STUDYING CODE CONVERSIONS
In this section, we formally deﬁne and study code conversions and introduce convertible codes. Suppose one wants to convert data that is already encoded using an [nI , kI ] initial code CI into data encoded using an [nF , kF ] ﬁnal code CF . Assume, without loss of generality, that each node has a ﬁxed storage capacity α. In the initial and ﬁnal conﬁgurations, the system stores the same information, but encoded differently. In order to capture the changes in the dimension of the code during conversion, we consider M = lcm(kI , kF ) number of “message” symbols (i.e., the data to be stored) over a ﬁnite ﬁeld Fq, denoted by m ∈ FM q . This corresponds to multiple stripes in the initial and ﬁnal conﬁgurations. We note that this need for considering multiple stripes in order to capture the smallest instance of the problem deviates from existing literature on the repair problem in distributed storage codes where a single stripe is sufﬁcient to capture the problem.

5
Since there are multiple stripes, we ﬁrst specify an initial partition PI and a ﬁnal partition PF of the set [M ], which map the message symbols of m to their corresponding initial and ﬁnal stripes. The initial partition PI ⊆ 2[M] is composed of M/kI disjoint subsets of size kI , and the ﬁnal partition PF ⊆ 2[M] is composed of M/kF disjoint subsets of size kF . In the initial (respectively, ﬁnal) conﬁguration, the data indexed by each subset S ∈ PI (respectively, PF ) is encoded using the code CI (respectively, CF ). The codewords {CI (mS), S ∈ PI } are referred to as initial stripes, and the codewords {CF (mS), S ∈ PF } are referred to as ﬁnal stripes, where mS corresponds to the projection of m onto the coordinates in S and C(mS) is the encoding of mS under code C. We now formally deﬁne code conversion and convertible codes.
Deﬁnition 1 (Code conversion). A conversion from an initial code CI to a ﬁnal code CF with initial partition PI and ﬁnal partition PF is a procedure, denoted by TCI→CF , that for any m, takes the set of initial stripes {CI (mS) | S ∈ PI } as input, and outputs the corresponding set of ﬁnal stripes {CF (mS) | S ∈ PF }.
The descriptions of the initial and ﬁnal partitions and codes, along with the conversion procedure, deﬁne a convertible code.
Deﬁnition 2 (Convertible code). A (nI , kI ; nF , kF ) convertible code over Fq is deﬁned by: (1) a pair of codes (CI , CF ) where CI is an [nI , kI ] code over Fq and CF is an [nF , kF ] code over Fq; (2) a pair of partitions PI , PF of [M = lcm(kI , kF )] such that each subset in PI is of size kI and each subset in PF is of size kF ; and (3) a conversion procedure TCI→CF that on input {CI (mS) | S ∈ PI } outputs {CF (mS) | S ∈ PF } for all m ∈ FM q .
In addition, typically additional constraints on the distance (i.e., decodability) of the codes CI and CF would be imposed, such as requiring both codes to be MDS.
Example 2. Suppose we want to transition from a [nI = 3, kI = 2] code CI to a [nF = 5, kF = 3] code CF . We consider data m of length M = lcm(kI = 2, kF = 3) = 6. In the initial conﬁguration, the data is partitioned into three stripes, each one composed of three blocks encoding two message symbols. For example, if PI = {{1, 2}, {3, 4}, {5, 6}} then the initial stripes are CI (m1, m2), CI (m3, m4), and CI (m5, m6). In the ﬁnal conﬁguration, the data is partitioned into two stripes, each one composed of ﬁve blocks encoding three message symbols. For example, if PF = {{1, 2, 3}, {4, 5, 6}} then the ﬁnal stripes are CF (m1, m2, m3), and CF (m4, m5, m6). Note that a different valid ﬁnal partition could have been PF = {{1, 3, 5}, {2, 4, 6}}.
The conversion procedure TCI→CF must take {CI (m1, m2), CI (m3, m4), CI (m5, m6)} as input, and output {CF (m1, m2, m3), CF (m4, m5, m6)}. In this example, the codes CI , CF , the partitions PI , PF , and procedure TCI→CF deﬁne a (nI = 3, kI = 2; nF = 5, kF = 3) convertible code.
Remark 1. Note that the deﬁnition of convertible codes (Deﬁnition 2) assumes that (nI , kI ; nF , kF ) are ﬁxed a priori, and are known at code construction time. This will be helpful in understanding the fundamental limits of the conversion process. In practice, this assumption might not always hold. For example, the parameters nF , kF depend on the node failure rates that are yet to be observed. Interestingly, it is indeed possible for a (nI , kI ; nF , kF ) convertible code to facilitate conversion for multiple values of nF , kF , as is the case for the code constructions presented in this paper.
The overhead of conversion in a convertible code is determined by the cost of the conversion procedure TCI→CF , as a function of the parameters (nI , kI ; nF , kF ). Towards minimizing the overhead of the conversion, our general objective is to design codes (CI , CF ), partitions (PI , PF ) and conversion procedure TCI→CF that satisfy Deﬁnition 2 and minimize the conversion cost for given parameters (nI , kI ; nF , kF ), subject to desired decodability constraints on CI and CF .
Depending on the relative importance of various resources in the cluster, one might be interested in optimizing the conversion with respect to various types of costs such as access, network bandwidth, disk IO, CPU, etc., or a combination of these costs. The general formulation of code conversions above provides a powerful framework to theoretically reason about convertible codes. In what follows, we will focus on a speciﬁc regime and a speciﬁc cost model.
IV. LOWER BOUNDS ON ACCESS COST OF CODE CONVERSION
The focus of this section is on deriving lower bounds on the access cost of code conversion. We consider one of the fundamental regimes of convertible codes, that corresponds to merging several initial stripes of a code into

6

GI =

g1I g2I g3I
101 011

 g˜1I,1 g˜1I,2 g˜1I,3 g˜2I,1 g˜2I,2 g˜2I,3 
1 0 1 0 0 0 G˜ I =  00 01 01 10 00 10 
000011

 g1F g2F g3F g4F g5F 
1 0 0 0 1 GF =  00 10 01 00 11 
00011

Fig. 2. Generator matrices for a speciﬁc (nI = 3, kI = 2; nF = 5, kF = 4) convertible code: GI is the generator matrix of the initial code; G˜ I is the generator matrix of all initial stripes; GF is the generator matrix of the ﬁnal code.

a single, longer ﬁnal stripe. Speciﬁcally, the convertible codes in this regime have kF = λkI , where λ ≥ 2 is the number of initial stripes merged, with arbitrary values of nI and nF . We call this regime as merge regime. We additionally require that both the initial and ﬁnal code are linear and MDS. Since linear MDS codes are widely used in storage systems and are well understood in the Coding Theory literature, they constitute a good starting point.
We focus on the access cost of code conversion, that is, the number of blocks that are affected by the conversion. The access cost of conversion measures the total number of blocks accessed during conversion. Each new block needs to be written, and hence requires accessing a node. Similarly, each block from the initial stripes that is read, requires accessing a node. Therefore, minimizing access cost amounts to minimizing the sum of the number of new blocks written and the number of blocks read from the initial stripes.2 Keeping this number small makes code conversion less disruptive and allows the unaffected nodes to remain available for application-speciﬁc purposes throughout the procedure, for example, to serve client requests in a storage system. Furthermore, reducing the number of accesses also reduces disk IO, network bandwidth and CPU consumed.
In Section V, we will show that the lower bounds on the access cost derived in this section are in fact achievable. Therefore, we refer to MDS convertible codes in the merge regime that achieve these lower bounds as access-optimal.
Deﬁnition 3 (Access-optimal). A linear MDS (nI , kI ; nF , kF = λkI ) convertible code is said to be access-optimal if and only if it attains the minimum access cost over all linear MDS (nI , kI ; nF , kF = λkI ) convertible codes.
We ﬁrst start with a description of the notation in Section IV-A and then derive lower bounds on the access cost in Section IV-B.

A. Notation

Let CI be an [nI , kI ] MDS code over ﬁeld Fq, speciﬁed by generator matrix GI , with columns (that is, encoding

vectors) {g1I , . . . , gnI I } ⊆ FkqI . Let λ ≥ 2 be an integer, and let CF be an [nF , kF = λkI ] MDS code over ﬁeld Fq,

speciﬁed

by

generator

matrix

GF ,

with

columns

(that

is,

encoding

vectors)

{g

F 1

,

.

.

.

,

gnFF

}

⊆

FkqF .

Let

rI

=

nI

−kI

and rF = nF − kF . When CI and CF are systematic, rI and rF correspond to the initial number of parities and

ﬁnal number of parities, respectively. All vectors are assumed to be column vectors. We will use the notation v[l]

to denote the l-th coordinate of a vector v.

We will represent all the code symbols in the initial stripes as being generated by a single λkI × λnI matrix G˜ I , with encoding vectors {g˜iI,j | i ∈ [λ], j ∈ [nI ]} ⊆ FkqF . This representation can be viewed as embedding the column vectors of the generator matrix GI in an λkI -dimensional space, where the index set Ki = {(i − 1)kI +

1, . . . , ikI }, i ∈ [λ] corresponds to the encoding vectors for initial stripe i. Let g˜iI,j denote the j-th encoding vector in the initial stripe i in this (embedded) representation. Thus, g˜iI,j[l] = gjI [l − (i − 1)kI ] for l ∈ Ki, and g˜iI,j[l] = 0

otherwise. As an example, Figure 2 shows the values of the deﬁned terms for the single parity-check code from

Figure 1 with nI = 3, kI = 2, nF = 5, kF = 4.

At times, focus will be only on the coordinates of an encoding vector of a certain initial stripe i. For this purpose,

deﬁne projKi(v) ∈ FkqI to be the projection of v ∈ FkqF to the coordinates in an index set Ki, and for a set V of vectors, projKi(V) = {projKi(v) | v ∈ V}. For example, projKi(g˜iI,j) = gjI for all i ∈ [λ] and j ∈ [nI ].

2Readers who are familiar with the literature on regenerating codes might observe that convertible codes optimizing for the access cost are “scalar” codes as opposed to being “vector” codes.

7
The following sets of vectors are deﬁned: the encoding vectors from initial stripe i, SiI = {g˜iI,j | j ∈ [nI ]}, all the encoding vectors from all the initial stripes, SI = ∪i∈[λ]SiI , and all the encoding vectors from the ﬁnal stripe SF = {gjF | j ∈ [nF ]}.
We use the term unchanged blocks to refer to blocks from the initial stripes that remain as is (that is, unchanged) in the ﬁnal stripe. The blocks in the ﬁnal stripe that were not present in the initial stripes are called new, and the blocks from the initial stripes that do not carry over to the ﬁnal stripe are called retired. For example, in Figure 1, all the data blocks are unchanged blocks (unshaded boxes), the single parity block of the ﬁnal stripe is a new block, and the two parity blocks from the initial stripes are retired blocks. Each unchanged block corresponds to a pair of identical initial and ﬁnal encoding vectors, that is, a tuple of indices (i, j, l) such that g˜iI,j = glF . For instance, the example in Figure 1 has four unchanged blocks, corresponding to the identical encoding vectors g˜iI,j = g2F(i−1)+j for i, j ∈ [2]. The ﬁnal encoding vectors SF can thus be partitioned into the following sets: unchanged encoding vectors from initial stripe i, Ui = SF ∩ SiI for all i ∈ [λ], and new encoding vectors N = SF \ SI .
From the point of view of conversion cost, unchanged blocks are ideal, because they require no extra work. On the other hand, constructing new blocks require accessing blocks from the initial stripes. When a block from the initial stripes is accessed, all of its contents are downloaded to a central location, where they are available for the construction of all new blocks. For example, in Figure 1, one block from each initial stripe is accessed during conversion.
During conversion, new blocks are constructed by reading blocks from the initial stripes. That is, every new encoding vector is simply a linear combination of a speciﬁc subset of SI . Deﬁne the read access set for an MDS (nI , kI ; nF , kF = λkI ) convertible code as the set of tuples D ∈ [λ]×[nI ] such that the set of new encoding vectors N is contained in the span of the set {g˜iI,j | (i, j) ∈ D}. Furthermore, deﬁne the index sets Di = {j | (i, j) ∈ D}, ∀i ∈ [λ] which denote the encoding vectors accessed from each initial stripe.
B. Lower bounds on the access cost of code conversion
In this subsection, we present lower bounds on the access cost of linear MDS convertible codes in the merge regime. This is done in four steps:
1) We show that in the merge regime, all possible pairs of partitions PI and PF partitions are equivalent up to relabeling, and hence do not need to be speciﬁed.
2) An upper bound on the maximum number of unchanged blocks is proved. We call convertible codes that meet this bound as “stable”.
3) Lower bounds on the access cost of linear MDS convertible codes are proved, under the added restriction that the convertible codes are stable.
4) The stability restriction is removed, by showing that non-stable linear MDS convertible codes necessarily incur higher access cost, and hence it sufﬁces to consider only stable MDS convertible codes.
We now start with the ﬁrst step. In the general regime, partition functions need to be speciﬁed since they indicate how message symbols from the initial stripes are mapped into the ﬁnal stripes. In the merge regime, however, there is only one ﬁnal stripe, and hence the choice of the partition functions does not matter.
Proposition 1. For every (nI , kI ; nF , kF = λkI ) convertible code, all possible pairs of initial and ﬁnal partitions (PI , PF ) are equivalent up to relabeling.
Proof. Given that M = lcm(kI , λkI ) = λkI , there is only one possible ﬁnal partition PF = {[λkI ]}. Thus, regardless of PI , all data in the initial stripes will get mapped to the same ﬁnal stripe. By relabeling blocks, any two initial partitions can be made equivalent.
Thus, the analysis of convertible codes in the merge regime in this regime can be simpliﬁed by noting that the choice of partitions PI and PF is inconsequential.
Since one of the terms in access cost is the number of new blocks, a natural way to reduce access cost is to maximize the number of unchanged blocks. However, there is a limit on the number of blocks that can remain unchanged.

8
Proposition 2. In an MDS (nI , kI ; nF , kF = λkI ) convertible code, there can be at most kI unchanged vectors from each initial stripe. Thus, there can be at most λkI unchanged vectors in total, or in other words, there will be at least rF new vectors.
Proof. Every subset V ⊆ SiI of size at least kI + 1 is linearly dependent, and thus if V ⊆ SF then CF cannot be MDS. Hence, for each stripe i ∈ [λ], the amount of unchanged vectors |Ui| is at most kI .
Since new blocks are constructed using only the contents of blocks read, it is clear that both the quantities that make up access cost are going to be related. Intuitively, more new blocks means that more blocks need to be read, resulting in higher access cost. With this intuition in mind, we will ﬁrst focus on the case where the number of new blocks is the minimum: |N | = nF − λkI = nF − kF = rF . We refer to such codes as stable convertible codes.
Deﬁnition 4 (Stability). An MDS (nI , kI ; nF , kF = λkI ) convertible code is stable if and only if it has exactly λkI unchanged blocks, or in other words, exactly rF new blocks.
We ﬁrst prove lower bounds on the access cost of stable linear MDS convertible codes, and then show that the access cost of conversion in MDS codes without this stability property can only be higher.
A natural question now is characterizing the minimum size of the read access set for conversion D for MDS codes. Clearly, accessing kI blocks from each initial stripe will always sufﬁce, since this is sufﬁcient to decode all the original data. Thus, in a minimum size D we can upper bound the size of each Di by |Di| ≤ kI , i ∈ [λ].
The ﬁrst lower bound on the size of Di will be given by the interaction between rF and the MDS property.
Lemma 3. For all linear stable MDS (nI , kI ; nF , kF = λkI ) convertible codes, the read access set Di from each initial stripe i ∈ [λ] satisﬁes |Di| ≥ min{kI , rF }.
Proof. By the MDS property, every subset V ∈ SF of size at most kF = λkI is linearly independent. For any initial stripe i ∈ [λ], consider the set of all unchanged encoding vectors from other stripes, ∪ =iSI , and pick any subset of new encoding vectors W ⊆ N of size |W| = min{kI , rF }. Consider the subset V = (∪ =iSI ∪ W): it is true that V ⊆ SF and |V| = (λ − 1)kI + min{kI , rF } ≤ kF . Therefore, all the encoding vectors in V are linearly independent.
Notice that the encoding vectors in V \ W contain no information about initial stripe i and complete information about every other initial stripe = i. Therefore, the information about initial stripe i in each encoding vector in W has to be linearly independent since, otherwise, V could not be linearly independent. Formally, it must be the case that Wi = projKi(W) has rank equal to min{kI , rF } (recall from Section IV-A that Ki is the set of coordinates belonging to initial stripe i). However, by deﬁnition, the subset Wi must be contained in the span of {gjI | j ∈ Di}. Therefore, the rank of {gjI | j ∈ Di} is at least that of Wi, which implies that |Di| ≥ min{kI , rF }.
Therefore, in general we need to access at least rF vectors from each initial stripe, unless rF ≥ kI , in which case we need to access kI encoding vectors, that is, the full data.
We next show that, in a linear MDS stable convertible code in the merge regime, when the number of new blocks rF is bigger than rI , at least kI blocks need to be accessed from each initial stripe. The intuition behind this result is the following: in an MDS stable convertible code in the merge regime, when the number of new blocks rF is bigger than rI , during a conversion one is forced to read more than rI blocks. Hence there must exist blocks from the initial stripes that are both unchanged and are read during conversion. Since the unchanged blocks that are read are also present in the ﬁnal stripe, the information read from these blocks is not useful in creating a new block that retains the MDS property for the ﬁnal code unless kI blocks (that is, full data) are read.
Lemma 4. For all linear stable MDS (nI , kI ; nF , kF = λkI ) convertible codes, if rI < rF then the read access set Di from each initial stripe i ∈ [λ] satisﬁes |Di| ≥ kI .
Proof. When rF ≥ kI , this lemma is equivalent to Lemma 3, so assume rI < rF < kI . From the proof of Lemma 3, for every initial stripe i ∈ [λ] it holds that |Di| ≥ rF . Since rF > rI , this implies that Di must contain at least one index of an unchanged encoding vector.
Choose a subset of at most kF = λkI encoding vectors from SF , which must be linearly independent by the MDS property. In this subset, include all the unchanged encoding vectors from the other initial stripes, ∪l=iSlI . Then, choose all the unchanged encoding vectors from initial stripe i that are accessed during conversion, W1 =

9

({g˜iI,j | j ∈ Di} ∩ Ui). For the remaining vectors (if any), choose an arbitrary subset of new encoding vectors,

W2 ⊆ N , such that:

|W2| = min{kI − |W1|, rF }.

(1)

It is easy to check that the subset V = ∪l=iSlI ∪ W1 ∪ W2 is of size at most kF = λkI , and therefore it is linearly independent. This choice of V follows from the idea that the information contributed by W1 to the new encoding
vectors is already present in the unchanged encoding vectors, which will be at odds with the linear independence
of V. Since the elements of W1 and W2 are the only encoding vectors in V that contain information from initial stripe
i, it must be the case that W = projKi(W1) ∪ projKi(W2) has rank |W1| + |W2|. Moreover, W is contained in the span of {gjI | j ∈ Di} by deﬁnition, so it holds that:

|Di| ≥ |W1| + |W2|.

(2)

From Equation (1), there are two cases:
Case 1: kI − |W1| ≤ rF . Then |W2| = kI − |W1| and by Equation (2) it holds that |Di| ≥ |W1| + |W2| = kI . Case 2: kI − |W1| > rF . Then |W2| = rF and by Equation (2) it holds that:

|Di| ≥ |W1| + rF .

(3)

Notice that there are only rI retired (i.e. not unchanged) encoding vectors in stripe i. Since every accessed encoding vector is either in W1 or is a retired encoding vector, it holds that:

|Di| ≤ |W1| + rI .

(4)

By combining Equation (3) and Equation (4), we arrive at the contradiction rF ≤ rI , which occurs because there are not enough retired blocks in the initial stripe i to ensure that the ﬁnal code has the MDS property. Therefore, case 1 always holds, and |Di| ≥ k.

Combining the above results leads to the following theorem on the lower bound of read access set size of linear stable MDS convertible codes.
Theorem 5. Let d∗(nI , kI ; nF , kF ) denote the minimum integer d such that there exists a linear stable MDS (nI , kI ; nF , kF = λkI ) convertible code with read access set D of size |D| = d. For all valid parameters, d∗(nI , kI ; nF , kF ) ≥ λ min{kI , rF }. Furthermore, if rI < rF , then d∗(nI , kI ; nF , kF ) ≥ λkI .

Proof. Follows directly from Lemma 3 and Lemma 4.

So far we have focused on deriving lower bounds on the access cost of conversion for stable MDS convertible codes, which have the maximum number of unchanged blocks. That is, convertible codes that have λkI unchanged blocks and rF new blocks. We next show that this lower bound generally applies even for non-stable convertible
codes by proving that increasing the number of new blocks from the minimum possible does not decrease the lower bound on the size of the read access set D.

Lemma 6. The lower bounds on the size of the read access set from Theorem 5 hold for all (including non-stable) linear MDS (nI , kI ; nF , kF = λkI ) convertible codes.
Proof. We show that, even for non-stable convertible codes, that is, when there are more than rF new blocks, the bounds on the read access set D from Theorem 5 still hold. Case 1: rI ≥ rF . Let i ∈ [λ] be an arbitrary initial stripe. We lower bound the size of Di by invoking the MDS property on a subset V ⊆ SF of size |V| = λkI that minimizes the size of the intersection |V ∩Ui|. There are exactly rF encoding vectors in SF \ V, so the minimum size of the intersection |V ∩ Ui| is max{|Ui| − rF , 0}. Clearly, the subset projKi(V) has rank kI due to the MDS property. Therefore, it holds that |Di| + max{|Ui| − rF , 0} ≥ kI . By reordering, the following is obtained:

|Di| ≥ kI − max{|Ui| − rF , 0} ≥ min{rF , kI },

which means that the bound on Di established in Lemma 3 continues to hold for non-stable codes.

10

Case 2: rI < rF . Let i ∈ [λ] be an arbitrary initial stripe, let W1 = ({g˜iI,j | j ∈ Di} ∩ Ui) be the unchanged encoding vectors that are accessed during conversion, and let W2 = Ui \ W1 be the unchanged encoding vectors that are not accessed during conversion. Consider the subset V ⊆ SF of kF = λkI encoding vectors from the ﬁnal
stripe such that W1 ⊆ V and the size of the intersection W3 = (S ∩ W2) is minimized. Since V may exclude at most rF encoding vectors from the ﬁnal stripe, it holds that:

|W3| = max{0, |W2| − rF }.

(5)

By the MDS property, V is a linearly independent set of encoding vectors of size kF , and thus, must contain all the information to recover the contents of every initial stripe, and in particular, initial stripe i. Since all the information in V about stripe i is in either W3 or the accessed encoding vectors, it must hold that:

|Di| + |W3| ≥ kI .

(6)

From Equation (5), there are two cases: Subcase 2.1: |W2| − rF ≤ 0. Then |W3| = 0, and by Equation (6) it holds that |Di| ≥ kI , which matches the
bound of Lemma 4. Subcase 2.2: |W2| − rF > 0. Then |W3| = |W2| − rF , and by Equation (6) it holds that:

|Di| + |W2| − rF ≥ kI .

(7)

The initial stripe i has kI + rI blocks. By the principle of inclusion-exclusion we have that:

|Di| + |Ui| − |W1| ≤ kI + rI .

(8)

By using Equation (7), Equation (8) and the fact that |W2| = |Ui| − |W1|, we conclude that rI ≥ rF , which is a contradiction and means that subcase 2.1 always holds in this case.

The above result, along with the fact that the lower bound in Theorem 5 is achievable (as will be shown in
Section V), implies that all access-optimal linear MDS convertible codes in the merge regime have the minimum possible number of new blocks (which is rF as shown in Proposition 2), that is they are stable.

Lemma 7. All access-optimal MDS (nI , kI ; nF , kF = λkI ) convertible codes are stable.

Proof. Lemma 6 shows that the lower bound on the read access set D for stable linear MDS convertible codes
continues to hold in the non-stable case. Furthermore, this bound is achievable by stable linear MDS convertible
codes in the merge regime (as will be shown in Section V). The number of new blocks written during conversion under stable MDS convertible codes is rF . On the other hand, the number of new blocks under a non-stable convertible code is strictly greater than rF . Thus, the overall access cost of a non-stable MDS (nI , kI ; nF , kF = λkI ) convertible code is strictly greater than the access cost of an access-optimal (nI , kI ; nF , kF = λkI ) convertible
code.

Thus, for MDS convertible codes in the merge regime, it sufﬁces to focus only on stable codes. Combining all the results above, leads to the following key result.

Theorem 8. For all linear MDS (nI , kI ; nF , kF = λkI ) convertible codes, the access cost of conversion is at least rF + λ min{kI , rF }. Furthermore, if rI < rF , the access cost of conversion is at least rF + λkI .

Proof. Follows from Theorem 5, Lemma 6, and the deﬁnition of access cost.

In Section V we show that the lower bound of Theorem 8 is achievable for all parameters. Thus, Theo-
rem 8 implies that it is possible to perform conversion of MDS convertible codes in the merge regime with signiﬁcantly less access cost than the na¨ıve strategy if and only if rF ≤ rI < kI . For example, for an MDS (nI = 14, kI = 10; nF = 24, kF = 20) convertible code the na¨ıve strategy has an access cost of nF = 24, while the optimal access cost is (λ + 1)rF = 12, which corresponds to savings in access cost of 50%.

V. ACHIEVABILITY: EXPLICIT ACCESS-OPTIMAL CONVERTIBLE CODES IN THE MERGE REGIME
In this section, we present an explicit construction of access-optimal MDS convertible codes for all parameters in the merge regime. In Section V-A, we describe the construction of the generator matrices for the initial and ﬁnal code. Then, in Section V-B, we prove that the code described by this construction has optimal access cost during code conversion.

11

A. Explicit construction

Recall that, in the merge regime, kF = λkI , for any integer λ ≥ 2 and arbitrary nI and nF . Also, recall that

rI = nI − kI and rF = nF − kF . Notice that when rI < rF , or kI ≤ rF , constructing an access-optimal convertible

code is trivial. In those cases, one can simply access all the kF = λkI data blocks of the initial stripes, which

meets the bound stated in Theorem 5. Thus, assume rF ≤ min{rI , kI }.

Let GI , GF be the generator matrices of CI , CF respectively. Our construction is systematic, that is, both CI

and CF are systematic MDS codes. Thus GI , GF are of the form GI = [I|PI ] and GF = [I|PF ], where PI is a

kI × rI matrix and PF is a kF × rF matrix. Therefore, to deﬁne the initial and ﬁnal code, only PI and PF need

to be speciﬁed. Let Fq be a ﬁnite ﬁeld of size q = pD, where p is any prime and the degree D depends on the

convertible code parameters and will be speciﬁed later in this section. Let θ be a primitive element of Fq.

Deﬁne

entry

(i, j)

of

PI

∈

Fkq I ×rI

as

θ(i−1)(j−1),

where

(i, j)

ranges

over

[kI ]×[rI ].

Entry

(i, j)

of

PF

∈

F

k q

F

×r

F

is deﬁned in an identical fashion, as θ(i−1)(j−1), where (i, j) ranges over [kF ] × [rI ].

For example, for kI = 3, rI = 3, kF = 6, rF = 3, the matrices PI and PF would be:





11 1





11 1

11 θθ2 θθ42 

PI = 1 θ θ2 1 θ2 θ4

PF = 1 θ3 θ6  1 θ4 θ8 

1 θ5 θ10

Our explicit construction is stable (recall from Lemma 7 that all access-optimal MDS convertible codes in the merge regime are stable), that is, it has exactly kF = λkI unchanged encoding vectors. Given that our construction
is also systematic it follows that these unchanged encoding vectors correspond exactly to the systematic elements of CF .

B. Proof of optimal access cost during conversion
Throughout this section, we use the following notation for submatrices: let M be a n×m matrix, the submatrix of M deﬁned by row indices {i1, . . . , ia} and column indices {j1, . . . , jb} is denoted by M [i1, . . . , ia; j1, . . . , jb]. For conciseness, we use ∗ to denote all row or column indices, e.g., M [∗; j1, . . . , jb] denotes the submatrix composed by columns {j1, . . . , jb}, and M [i1, . . . , ia; ∗] denotes the submatrix composed by rows {i1, . . . , ia}.
We ﬁrst recall an important fact about systematic MDS codes.
Proposition 9 ([12]). Let C be an [n, k] code with generator matrix G = [I|P ]. Then C is MDS if and only if P is superregular, that is, every square submatrix of P is nonsingular3.
Thus, to be MDS, both PI and PF need to be superregular. From the bound in Lemma 3, to be access-optimal during conversion when rF ≤ kI , the columns of PF (that is, the new encoding vectors) have to be such that they can be constructed by only accessing rF columns of GI (that is, the initial encoding vectors) during conversion. Thus, it sufﬁces to show that the columns of PF can be constructed by accessing only rF columns of PI during conversion. To capture this property, we introduce the following deﬁnition.
Deﬁnition 5 (t-column constructible). We will say that an n × m1 matrix M1 is t-column constructible from an n × m2 matrix M2 if and only if there exists a subset S ⊆ cols(M2) of size t, such that the m1 columns of M1 are in the span of S. We say that a λn × m1 matrix M1 is t-column block-constructible from an n × m2 matrix M2 if and only if for every i ∈ [λ], the submatrix M1[(i − 1)n + 1, . . . , in; ∗] is t-column constructible from M2.
Theorem 10. A systematic (nI , kI ; nF , kF = λkI ) convertible code with kI × rI initial parity generator matrix PI and kF × rF ﬁnal parity generator matrix PF is MDS and access-optimal, if the following two conditions hold: (1) if rI ≥ rF then PF is rF -column block-constructible from PI , and (2) PI , PF are superregular.
3This deﬁnition of superregularity is different from the deﬁnition introduced in [58], which is sometimes used in the context of convolutional codes.

12

Proof. Follows from Proposition 9 and Deﬁnition 5.

Thus, we can reduce the problem of proving the optimality of a systematic MDS convertible code in the merge regime to that of showing that matrices PI and PF satisfy the two properties mentioned in Theorem 10.
We ﬁrst show that the construction speciﬁed in Section V-A satisﬁes condition (1) of Theorem 10.

Lemma 11. Let PI , PF be as deﬁned in Section V-A. Then PF is rF -column block-constructible from PI .

Proof. Consider the ﬁrst rF columns of PI , which we denote as PIrF = PI [∗; 1, . . . , rF ]. Notice that PF can be

written as the following block matrix:

 PIrF 



PIrF diag(1, θkI , θ2kI , . . . , θkI(rF −1))



PF = 

PIrF diag(1, θ2kI , θ2·2kI , . . . , θ2kI(rF −1))

 ,



...



PIrF diag(1, θ(λ−1)kI , θ2(λ−1)kI , . . . , θ(λ−1)kI (rF −1))

where diag(a1, a2, . . . , an) is the n × n diagonal matrix with a1, . . . , an as the diagonal elements. From this representation, it is clear that PF can be constructed from the the ﬁrst rF columns of PI .

It only remains to show that the construction speciﬁed in Section V-A satisﬁes condition (2) of Theorem 10, that is, that PI and PF are superregular. To do this, we consider the minors of PI and PF as polynomials on θ. We show that, due to the structure of the the matrices PI and PF as speciﬁed in Section V-A, none of these polynomials can have θ as a root as long as the ﬁeld size is sufﬁciently large. Therefore none of the minors can
be zero.

Lemma 12. Let PI , PF be as deﬁned in Section V-A. Then PI and PF are superregular, for sufﬁciently large ﬁeld size.

Proof. Let R be a t × t submatrix of PI or PF , determined by the row indices i1 < i2 < · · · < it and the column indices j1 < j2 < · · · < jt, and denote entry (i, j) of R as R[i, j]. The determinant of R is deﬁned by the Leibniz
formula:

t

det(R) =

sgn(σ) R[l, σ(l)] =

sgn(σ)θEσ

(9)

σ∈Perm(t)

l=1

σ∈Perm(t)

t

where Eσ = (il − 1)(jσ(l) − 1),

(10)

l=1

Perm(t) is the set of all permutations on t elements, and sgn(σ) ∈ {−1, 1} is the sign of the permutation σ ∈
Perm(t) (the sign of a permutation σ depends on the number of inversions in σ). Clearly, det(R) deﬁnes a univariate polynomial fR ∈ Fp[θ]. We will now show that deg(fR) = tl=1(il − 1)(jl − 1) by showing that there is a unique permutation σ∗ ∈ Perm(t) for which Eσ∗ achieves this value, and that this is the maximum over all permutations
in Perm(t). This means that fR has a leading term of degree Eσ∗. To prove this, we show that any permutation σ ∈ Perm(t)\{σ∗} can be modiﬁed into a permutation σ such that
Eσ > Eσ. Speciﬁcally, we show that σ∗ = σid, the identity permutation. Consider σ ∈ Perm(t)\{σid}: let a be the smallest index such that σ(a) = a, let b = σ−1(a), and let c = σ(a). Let σ be such that σ (a) = a, σ (b) = c,
and σ (d) = σ(d) for d ∈ [t]\{a, b}. In other words, σ is the result of “swapping” the images of a and b in σ.
Notice that a < b and a < c. Then, we have that:

Eσ − Eσ = (ia − 1)(ja − 1) + (ib − 1)(jc − 1) − (ia − 1)(jc − 1) − (ib − 1)(ja − 1)

(11)

= (ib − ia)(jc − ja) > 0

(12)

The last inequality comes from the fact that a < b implies ia < ib and a < c implies ja < jc. Therefore,
deg(fR) = maxσ∈Perm(t) Eσ = Eσid . Let E∗(λ, kI , rI , rF ) be the maximum degree of fR over all submatrices R of PI or PF . Then, E∗(λ, kI , rI , rF )
corresponds to the diagonal with the largest elements in PI or PF . In PF this is the diagonal of the square submatrix

13

formed by the bottom rF rows. In PI it can be either the diagonal of the square submatrix formed by the bottom

rI rows, or by the right kI columns. Thus, we have that:





rF −1

rI −1

kI −1



E∗(λ, kI , rI , rF ) = max  i(λkI − rF + i), i(kI − rI + i), i(rI − kI + i)

i=0 

i=0

 i=0

rF (rF − 1)(3λkI − rF − 1),

= (1/6) · max  rkII((rkII −−11))((33krII −−rkII −−11)),  .

Let D = E∗(λ, kI , rI , rF )+1. Then, if det(R) = 0 for some submatrix R, θ is a root of fR, which is a contradiction since θ is a primitive element and the minimal polynomial of θ over Fq has degree D > deg(fR) [12].
This construction is practical only for small values of these parameters since the required ﬁeld size grows rapidly with the lengths of the initial and ﬁnal codes. In Section VI we present practical low-ﬁeld-size constructions.
Combining the above results leads to the following key result on the achievability of the lower bounds on access cost derived in Section IV.

Theorem 13. The explicit construction provided in Section V-A yields access-optimal linear MDS convertible codes for all parameter values in the merge regime.

Proof. Follows from Theorem 10, Lemma 11, and Lemma 12.

VI. LOW FIELD-SIZE CONSTRUCTIONS BASED ON SUPERREGULAR HANKEL ARRAYS
In this section we present alternative constructions for (nI , kI ; nF , kF = λkI ) convertible codes that require a signiﬁcantly lower (polynomial) ﬁeld size than the general construction presented in Section V.
Key idea. The key idea behind our constructions is to take the matrices PI and PF as submatrices from a specially constructed triangular array of the following form:

b1 b2 b3 · · · bm−1 bm

... ... ...

b2 b3 · · · · · · bm

b3 ...

Tm : .. ..

(13)

..

bm−1 bm

bm

such that every submatrix of Tm is superregular. Here, (1) b1, . . . , bm are (not necessarily distinct) elements from Fq, and (2) m is at most the ﬁeld size q. The array Tm is said to have Hankel form, which means that Tm[i, j] = Tm[i − 1, j + 1], for all i ∈ [2, m], j ∈ [m − 1]. We denote Tm a superregular Hankel array. Such an array
can be constructed by employing the algorithm proposed in [59] (where the algorithm was employed to construct
generalized Cauchy matrices to yield generalized Reed-Solomon codes). We note that the algorithm outlined in
[59] takes the ﬁeld size q as input, and generates Tq as the output. It is easy to see that Tq thus generated can be truncated to generate the triangular array Tm for any m ≤ q.
We construct the initial and ﬁnal codes by taking submatrices PI and PF from superregular Hankel arrays (the submatrices have to be contained in the triangle where the array is deﬁned). This guarantees that PI and PF are superregular. In addition, we exploit the Hankel form of the array by carefully choosing the submatrices that form PI and PF to ensure that PF is rF -column block-constructible from PI . Given the way we construct
these matrices and the properties of Tm, all the initial and ﬁnal codes presented in this subsection are generalized
doubly-extended Reed-Solomon codes [59]. The above idea yields a sequence of constructions with a tradeoff between the ﬁeld size and the range of rF
supported. We ﬁrst present the two constructions at the extreme ends of this tradeoff, which we call Hankel-I and Hankel-II. Construction Hankel-I, described in Section VI-A, can be applied whenever rF ≤ rI /λ , and requires a ﬁeld size of q ≥ max{nI −1, nF −1}. Construction Hankel-II , described in Section VI-B, can be applied whenever rF ≤ rI − λ + 1, and requires a ﬁeld size of q ≥ kI rI . We then discuss the constructions that fall in between these

14

T11 :

1 3 4 3 10 10 5 9 6 5 10 3 4 3 10 10 5 9 6 5 10 4 3 10 10 5 9 6 5 10 3 10 10 5 9 6 5 10 10 10 5 9 6 5 10 10 5 9 6 5 10 5 9 6 5 10 9 6 5 10 6 5 10 5 10 10

P I ∈ F51×1 4 P F ∈ F1101×2

Fig. 3. Hankel-I construction parity generator matrices for systematic (nI = 9, kI = 5; nF = 12, kF = 10) convertible code. Notice how matrix PF corresponds to the vertical concatenation of the ﬁrst two columns and the last two columns of matrix PI .

two constructions in the tradeoff between ﬁeld size and coverage of rF values in Section VI-C. In Section VI-C
we also provide a discussion on the ability of these constructions to be optimal even when parameters of the ﬁnal code are a priori unknown. Throughout this section we will assume that λ ≤ rI ≤ kI . The ideas presented here are still applicable when rI > kI , but the constructions and analysis change in minor ways.

A. Hankel-I construction
Hankel-I construction provides an access-optimal linear MDS (nI , kI ; nF , kF = λkI ) convertible code when rF ≤ rI /λ , and requires a ﬁeld size of q ≥ max{nI − 1, nF − 1}. Notice that this construction has no penalty in terms of ﬁeld size for access-optimal conversion, since it has the same ﬁeld size requirement as the maximum between a pair of [nI , kI ] and [nF , kF ] Reed-Solomon codes [12]. We start by illustrating the construction with an example.

Example 3. Consider the parameters (nI = 9, kI = 5; nF = 12, kF = 10). First, we construct a superregular Hankel array of size nF − 1 = 11, T11, employing the algorithm in [59]. Then choose PI and PF from T11 as shown in Figure 3. Checking that these matrices are superregular follows from the superregularity of T11. Furthermore,

notice that the chosen parity matrices have the following structure:





PI = p1 p2 p3 p4

PF = p1 p2 p3 p4

From this structure, it is clear that PF is 2-column block-constructible from PI . The ﬁeld size required for this construction is nF − 1 = 11.

General construction. Now we describe how to construct PI , PF for all valid parameters λ, kI , rI , rF , where

rF ≤ rI /λ . As seen in Example 3, this construction works by splitting the encoding vectors corresponding to

the rI initial parities into λ groups, which are then combined to obtain the (at most) rI /λ new encoding vectors.

Let Tm be as deﬁned in Equation (13), with m = nF − 1. Choose PF to be the kF × rF submatrix of the top-left

elements of Tm. Denote the kI × ((λ − 1)kI + rF ) submatrix of the top-left elements of Tm as Q:









b1 · · ·

brF

b1 · · · b(λ−1)kI +rF

PF =  ... . . .

...  Q =  ... . . .

... 

bλkI · · · bλkI +rF −1

bIk · · · bλkI +rF −1

We choose PI to be any kI × rI submatrix of Q that includes columns {l, kI + l, . . . , (λ − 1)kI + l}. The Hankel form of array Tm implies that Tm[kI (i − 1) + j, l] = Tm[j, kI (i − 1) + l] for all i ∈ [λ], j ∈ [kI ]. As a consequence, we have that the l-th column of PF is equal to the vertical concatenation of columns (l, kI + l, . . . , (λ − 1)kI + l)
of Q. Since both PI and PF are submatrices of Tm, they are superregular. Furthermore, since every column of PF is
the concatenation of λ columns of PI , it is clear that PF is rF -column block-constructible from PI . Thus PI and

15

T12 :

12 12 1 9 1 5 11 9 10 6 9 2 12 1 9 1 5 11 9 10 6 9 2 1 9 1 5 11 9 10 6 9 2 9 1 5 11 9 10 6 9 2 1 5 11 9 10 6 9 2 5 11 9 10 6 9 2 11 9 10 6 9 2 9 10 6 9 2
...

P I ∈ F41×3 3 P F ∈ F81×3 2

Fig. 4. Hankel-II construction parity generator matrices for systematic (nI = 7, kI = 4; nF = 10, kF = 8) convertible code. Notice how matrix PF corresponds to the vertical concatenation of the ﬁrst and second column of PI , and the second and third column of PI .

PF satisfy both the sufﬁcient properties laid out in Theorem 10, and hence Hankel-I construction is access-optimal
during conversion. (Access-optimal) Conversion process. During conversion, the kI data blocks from each of the λ initial stripes
remain unchanged, and become the kF = λkI data blocks from the ﬁnal stripe as detailed below. The rF new
(parity) blocks from the ﬁnal stripe are constructed by accessing blocks from the initial stripes. To construct the l-th new block (corresponding to the l-th column of PF , l ∈ [rF ]), read parity block (i − 1)kI + l from each initial stripe i ∈ [λ], and then sum the λ blocks read. The encoding vector of the new block will be equal to the sum of
the encoding vectors of the blocks read (recall from Section IV-A that the initial encoding vectors are embedded into a kF dimensional space). This is done for every new encoding vector l ∈ [rF ].

B. Hankel-II construction

Hankel-II construction, in contrast to the Hankel-I construction above, can handle a broader range of parameter
values, at the cost of a slightly larger ﬁeld-size requirement. In particular, we present a construction of accessoptimal MDS (nI , kI ; nF , kF = λkI ) convertible code for all rF ≤ rI − λ + 1, requiring a ﬁeld size of q ≥ kI rI . We start with an example illustrating this construction.

Example 4. Consider parameters (nI = 7, kI = 4; nF = 10, kF = 8). First, we construct a superregular Hankel array of size kI rI = 12, T12, by choosing q = 13 as the ﬁeld size, and employing the algorithm in [59]. Then choose PI and PF from T12 as shown in Figure 4. Both matrices are superregular by the superregularity of T12.

Notice that the chosen parity matrices have the following structure:





PI = p1 p2 p3

PF = p1 p2 p2 p3

It is easy to see that PF is 2-column block-constructible from PI .

General construction. Now we describe how to construct PI and PF for all valid parameters λ, kI , rI , rF such

that rF ≤ rI − λ + 1. As seen in Example 4, this construction works by choosing the rI initial parity encoding

vectors so that any λ consecutive initial parity encoding vectors can be combined into a new encoding vector.

Let Tm be as in Equation (13), with m ≥ kI rI . We take PI and PF as the following submatrices of Tm:









b1 bkI +1 · · · b(rI −1)kI +1

b1 bkI +1 · · · b(rF −1)kI +1

I  b2 bkI +2 · · · b(rI −1)kI +2

F  b2 bkI +2 · · · b(rF −1)kI +2

P =  ... ... . . .

...  P =  ...

...

...

... 

bkI b2kI · · ·

brI kI

bλkI b(λ+1)kI · · · b(λ+rF −1)kI

The Hankel form of array Tm guarantees that the i-th column of PF corresponds to the concatenation of columns (i, i + 1, . . . , i + λ − 1) of PI . Thus, PF is rF -column block-constructible from PI . Furthermore, since PI and PF are submatrices of Tm, they are superregular.
(Access-optimal) Conversion process. During conversion, the kI data blocks from each of the λ initial stripes remain unchanged, and become the kF = λkI data blocks from the ﬁnal stripe. The rF new (parity) blocks from
the ﬁnal stripe are constructed by accessing blocks from the initial stripes as detailed below. To construct the l-th

16

new block (corresponding to the l-th column of PF , l ∈ [rF ]), read parity block l + i − 1 from each initial stripe i ∈ [λ], and then sum the λ blocks read. The encoding vector of the new block will be equal to the sum of the
encoding vectors of the blocks read (recall from Section IV-A that the initial encoding vectors are embedded into a kF dimensional space). This is done for every new encoding vector l ∈ [rF ].

C. Sequence of Hankel-based constructions and Handling a priori unknown parameters

Sequence of Hankel-based constructions. Our idea of Hankel-array-based construction yields a sequence of access-optimal MDS convertible codes with a tradeoff between ﬁeld size and the range of rF supported. The two
constructions presented in Section VI-A and Section VI-B are the two extreme points of this tradeoff. In particular, our construction can support, for all s ∈ {λ, λ + 1, . . . , rI }:

rF ≤ (s − λ + 1) rI + max{(rI mod s) − λ + 1, 0}, s

for q ≥ skI + rI − 1. s

The parameter s corresponds to the number of groups into which the encoding vectors corresponding to the rI initial parities are split. That is, each group of consecutive initial parity encoding vectors has size rI /s or rI /s . The Hankel-I construction corresponds to s = λ and Hankel-II corresponds to s = rI .
Handling a priori unknown parameters. So far, we had assumed that the parameters of the ﬁnal code, nF , kF ,
are known a priori and are ﬁxed. As discussed in Section III, this is useful in developing an understanding of
the fundamental limits of code conversion. When realizing code conversion in practice, however, the parameters nF , kF might not be known at code construction time (as it depends on the empirically observed failure rates).
Thus, it is of interest to be able to convert a code optimally to multiple different parameters. The Hankel-array based
constructions presented above indeed provide such a ﬂexibility. Our constructions continue to enable access-optimal conversion for any kF = λ kI and nF = rF + kF with 0 ≤ rF ≤ rF and 2 ≤ λ ≤ λ.

VII. CONCLUSIONS AND FUTURE DIRECTIONS
In this paper, we propose the “code conversion” problem, that models the problem of converting data encoded with an [nI , kI ] code into data encoded with an [nF , kF ] code in a resource-efﬁcient manner. The proposed problem is motivated by the practical necessity of reducing the overhead of redundancy adaptation in erasure-coded storage systems. This is a new opportunity beckoning coding theorists to enable large-scale real-world storage systems to adapt their redundancy levels to varying failure rates of storage devices, thereby achieving signiﬁcant savings in resources and energy consumption. We present the framework of convertible codes for studying code conversions, and fully characterize the fundamental limits for the access cost of conversions for an important regime of convertible codes. Furthermore, we present practical low-ﬁeld-size constructions for access-optimal convertible codes for a wide range of parameters.
This work leads to a number of challenging an potentially impactful open problems. An important future direction is to go beyond the merge regime considered in this paper and study the fundamental limits on the access cost and construct optimal convertible codes for general parameter regimes. Another important future direction is to analyze the fundamental limits on the overhead of other cluster resources during code conversions, such as network bandwidth, disk IO, and CPU consumption, and construct convertible codes optimizing these resources. Note that while the access-optimal convertible codes, considered in this paper, also reduce the total network bandwidth, disk IO, and CPU overhead during conversion as compared to the default approach, the overhead on these other resources may not be optimal.

ACKNOWLEDGEMENTS We thank Michael Rudow for his valuable feedback and helpful comments during the writing of this paper.

17
REFERENCES
[1] D. Ford, F. Labelle, F. Popovici, M. Stokely, V. Truong, L. Barroso, C. Grimes, and S. Quinlan, “Availability in globally distributed storage systems,” in USENIX Symposium on Operating Systems Design and Implementation, 2010.
[2] K. V. Rashmi, N. B. Shah, D. Gu, H. Kuang, D. Borthakur, and K. Ramchandran, “A solution to the network challenges of data recovery in erasure-coded distributed storage systems: A study on the Facebook warehouse cluster,” in Proceedings of USENIX HotStorage, Jun. 2013.
[3] ——, “A Hitchhiker’s guide to fast and efﬁcient data reconstruction in erasure-coded data centers,” in ACM SIGCOMM, 2014. [4] M. Sathiamoorthy, M. Asteris, D. Papailiopoulos, A. G. Dimakis, R. Vadali, S. Chen, and D. Borthakur, “XORing elephants: Novel
erasure codes for big data,” in VLDB Endowment, 2013. [5] S. Ghemawat, H. Gobioff, and S. Leung, “The Google ﬁle system,” in ACM SIGOPS Operating Systems Review, vol. 37, no. 5. ACM,
2003, pp. 29–43. [6] D. Borthakur, R. Schmidt, R. Vadali, S. Chen, and P. Kling, “HDFS RAID - Facebook.” [Online]. Available: http:
//www.slideshare.net/ydn/hdfs-raid-facebook [7] C. Huang, H. Simitci, Y. Xu, A. Ogus, B. Calder, P. Gopalan, J. Li, and S. Yekhanin, “Erasure coding in Windows Azure storage,” in
Proceedings of USENIX Annual Technical Conference (ATC), 2012. [8] Apache Software Foundation, “Apache hadoop: HDFS erasure coding,” accessed: 2019-07-23. [Online]. Available: https:
//hadoop.apache.org/docs/r3.0.0/hadoop-project-dist/hadoop-hdfs/HDFSErasureCoding.html [9] S. Kadekodi, K. V. Rashmi, and G. R. Ganger, “Cluster storage systems gotta have HeART: improving storage efﬁciency by exploiting
disk-reliability heterogeneity,” USENIX FAST, 2019. [10] J. Plank, “T1: Erasure codes for storage applications,” Proceedings of the 4th USENIX Conference on File and Storage Technologies,
pp. 1–74, 01 2005. [11] D. A. Patterson, G. Gibson, and R. H. Katz, A case for redundant arrays of inexpensive disks (RAID). ACM, 1988, vol. 17, no. 3. [12] F. MacWilliams and N. Sloane, The Theory of Error-Correcting Codes, 2nd ed. North-holland Publishing Company, 1978. [13] M. Blaum, J. Brady, J. Bruck, and Jai Menon, “EVENODD: an efﬁcient scheme for tolerating double disk failures in RAID architectures,”
IEEE Transactions on Computers, vol. 44, no. 2, pp. 192–202, feb 1995. [14] L. Xu and J. Bruck, “X-code: MDS array codes with optimal encoding,” IEEE Transactions on Information Theory, vol. 45, no. 1, pp.
272–276, 1999. [15] C. Huang and L. Xu, “STAR: An efﬁcient coding scheme for correcting triple storage node failures,” IEEE Transactions on Computers,
vol. 57, no. 7, pp. 889–901, 2008. [16] J. L. Hafner, “WEAVER codes: Highly fault tolerant erasure codes for storage systems,” in Proceedings of the 4th Conference on
USENIX Conference on File and Storage Technologies - Volume 4, ser. FAST’05. Berkeley, CA, USA: USENIX Association, 2005, pp. 16–16. [17] A. G. Dimakis, P. B. Godfrey, Y. Wu, M. J. Wainwright, and K. Ramchandran, “Network coding for distributed storage systems,” IEEE Transactions on Information Theory, vol. 56, no. 9, pp. 4539–4551, sep 2010. [18] K. V. Rashmi, N. B. Shah, and P. V. Kumar, “Optimal exact-regenerating codes for distributed storage at the MSR and MBR points via a product-matrix construction,” IEEE Transactions on Information Theory, vol. 57, no. 8, pp. 5227–5239, 2011. [19] N. B. Shah, K. V. Rashmi, P. V. Kumar, and K. Ramchandran, “Interference alignment in regenerating codes for distributed storage: Necessity and code constructions,” IEEE Transactions on Information Theory, vol. 58, no. 4, pp. 2134–2158, 2011. [20] C. Suh and K. Ramchandran, “Exact-repair MDS code construction using interference alignment,” IEEE Transactions on Information Theory, pp. 1425–1442, Mar. 2011. [21] I. Tamo, Z. Wang, and J. Bruck, “Zigzag codes: MDS array codes with optimal rebuilding,” IEEE Transactions on Information Theory, vol. 59, no. 3, pp. 1597–1616, 2013. [22] V. R. Cadambe, S. A. Jafar, H. Maleki, K. Ramchandran, and C. Suh, “Asymptotic interference alignment for optimal repair of MDS codes in distributed storage,” IEEE Transactions on Information Theory, vol. 59, no. 5, pp. 2974–2987, 2013. [23] M. Ye and A. Barg, “Explicit constructions of optimal-access MDS codes with nearly optimal sub-packetization,” IEEE Transactions on Information Theory, vol. 63, no. 10, pp. 6307–6317, oct 2017. [24] D. Papailiopoulos, A. Dimakis, and V. Cadambe, “Repair optimal erasure codes through Hadamard designs,” IEEE Transactions on Information Theory, vol. 59, no. 5, pp. 3021–3037, May 2013. [25] S. Goparaju, A. Fazeli, and A. Vardy, “Minimum storage regenerating codes for all parameters,” IEEE Transactions on Information Theory, vol. 63, no. 10, pp. 6318–6328, 2017. [26] A. Chowdhury and A. Vardy, “New constructions of MDS codes with asymptotically optimal repair,” in 2018 IEEE International Symposium on Information Theory, 2018, pp. 1944–1948. [27] K. Mahdaviani, A. Khisti, and S. Mohajer, “Bandwidth adaptive & error resilient MBR exact repair regenerating codes,” IEEE Transactions on Information Theory, vol. 65, no. 5, pp. 2736–2759, 2018. [28] K. Mahdaviani, S. Mohajer, and A. Khisti, “Product matrix MSR codes with bandwidth adaptive exact repair,” IEEE Transactions on Information Theory, vol. 64, no. 4, pp. 3121–3135, 2018. [29] N. B. Shah, K. Rashmi, and P. V. Kumar, “A ﬂexible class of regenerating codes for distributed storage,” in 2010 IEEE International Symposium on Information Theory. IEEE, 2010, pp. 1943–1947. [30] K. W. Shum, “Cooperative regenerating codes for distributed storage systems,” in 2011 IEEE International Conference on Communications (ICC). IEEE, 2011, pp. 1–5. [31] V. Abdrashitov, N. Prakash, and M. Me´dard, “The storage vs repair bandwidth trade-off for multiple failures in clustered storage networks,” in 2017 IEEE Information Theory Workshop (ITW). IEEE, 2017, pp. 46–50. [32] I. Tamo, Z. Wang, and J. Bruck, “Access versus bandwidth in codes for storage,” IEEE Transactions on Information Theory, vol. 60, no. 4, pp. 2028–2037, 2014.

18
[33] S. Goparaju, I. Tamo, and R. Calderbank, “An improved sub-packetization bound for minimum storage regenerating codes,” IEEE Transactions on Information Theory, vol. 60, no. 5, pp. 2770–2779, 2014.
[34] S. Balaji and P. V. Kumar, “A tight lower bound on the sub-packetization level of optimal-access MSR and MDS codes,” in 2018 IEEE International Symposium on Information Theory (ISIT). IEEE, 2018, pp. 2381–2385.
[35] O. Alrabiah and V. Guruswami, “An exponential lower bound on the sub-packetization of MSR codes,” in Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing, ser. STOC 2019. New York, NY, USA: ACM, 2019, pp. 979–985.
[36] K. V. Rashmi, N. B. Shah, and K. Ramchandran, “A piggybacking design framework for read-and download-efﬁcient distributed storage codes,” in 2013 IEEE International Symposium on Information Theory, 2013.
[37] ——, “A piggybacking design framework for read-and download-efﬁcient distributed storage codes,” IEEE Transactions on Information Theory, vol. 63, no. 9, pp. 5802–5820, 2017.
[38] V. Guruswami and A. S. Rawat, “MDS code constructions with small sub-packetization and near-optimal repair bandwidth,” in ACMSIAM Symposium on Discrete Algorithms, 2017.
[39] K. Shanmugam, D. S. Papailiopoulos, A. G. Dimakis, and G. Caire, “A repair framework for scalar MDS codes,” IEEE Journal on Selected Areas in Communications, vol. 32, no. 5, pp. 998–1007, 2014.
[40] V. Guruswami and M. Wootters, “Repairing Reed-Solomon codes,” in ACM Symposium on Theory of Computing, 2016, pp. 216–226. [41] H. Dau, I. M. Duursma, H. M. Kiah, and O. Milenkovic, “Repairing Reed-Solomon codes with multiple erasures,” IEEE Transactions
on Information Theory, vol. 64, no. 10, pp. 6567–6582, 2018. [42] P. Gopalan, C. Huang, H. Simitci, and S. Yekhanin, “On the locality of codeword symbols,” IEEE Transactions on Information Theory,
vol. 58, no. 11, pp. 6925–6934, 2012. [43] D. S. Papailiopoulos and A. G. Dimakis, “Locally repairable codes,” IEEE Transactions on Information Theory, vol. 60, no. 10, pp.
5843–5855, 2014. [44] I. Tamo and A. Barg, “A family of optimal locally recoverable codes,” IEEE Transactions on Information Theory, vol. 60, no. 8, pp.
4661–4676, 2014. [45] G. M. Kamath, N. Prakash, V. Lalitha, and P. V. Kumar, “Codes with local regeneration and erasure correction,” IEEE Transactions
on Information Theory, vol. 60, no. 8, pp. 4637–4660, 2014. [46] V. R. Cadambe and A. Mazumdar, “Bounds on the size of locally recoverable codes,” IEEE Transactions on Information Theory,
vol. 61, no. 11, pp. 5787–5794, 2015. [47] I. Tamo, D. S. Papailiopoulos, and A. G. Dimakis, “Optimal locally repairable codes and connections to matroid theory,” IEEE
Transactions on Information Theory, vol. 62, no. 12, pp. 6661–6671, 2016. [48] I. Tamo, A. Barg, and A. Frolov, “Bounds on the parameters of locally recoverable codes,” IEEE Transactions on Information Theory,
vol. 62, no. 6, pp. 3070–3083, 2016. [49] A. Barg, K. Haymaker, E. W. Howe, G. L. Matthews, and A. Va´rilly-Alvarado, “Locally recoverable codes from algebraic curves and
surfaces,” in Algebraic Geometry for Coding Theory and Cryptography. Springer, 2017, pp. 95–127. [50] A. Agarwal, A. Barg, S. Hu, A. Mazumdar, and I. Tamo, “Combinatorial alphabet-dependent bounds for locally recoverable codes,”
IEEE Transactions on Information Theory, vol. 64, no. 5, pp. 3481–3492, 2018. [51] A. Mazumdar, “Capacity of locally recoverable codes,” in 2018 IEEE Information Theory Workshop, nov 2018, pp. 1–5. [52] K. V. Rashmi, N. B. Shah, and P. V. Kumar, “Enabling node repair in any erasure code for distributed storage,” in 2011 IEEE
International Symposium on Information Theory Proceedings. IEEE, 2011, pp. 1235–1239. [53] S. Mousavi, T. Zhou, and C. Tian, “Delayed parity generation in MDS storage codes,” in 2018 IEEE International Symposium on
Information Theory (ISIT), Jun. 2018, pp. 1889–1893. [54] M. Xia, M. Saxena, M. Blaum, and D. A. Pease, “A tale of two erasure codes in HDFS,” in Proceedings of the 13th USENIX Conference
on File and Storage Technologies, ser. FAST’15. Berkeley, CA, USA: USENIX Association, 2015, pp. 213–226. [55] K. M. Konwar, N. Prakash, N. Lynch, and M. Me´dard, “A layered architecture for erasure-coded consistent distributed storage,” in
Proceedings of the ACM Symposium on Principles of Distributed Computing. ACM, 2017, pp. 63–72. [56] V. Cadambe, N. Nicolaou, K. M. Konwar, N. Prakash, N. Lynch, and M. Me´dard, “ARES: Adaptive, reconﬁgurable, erasure coded,
atomic storage,” 2018, to appear in 39th IEEE International Conference on Distributed Computing Systems (ICDCS 2019), Dallas, Texas, July 2019. [57] Z. Wang and V. R. Cadambe, “Multi-version coding: An information-theoretic perspective of consistent distributed storage,” IEEE Transactions on Information Theory, vol. 64, no. 6, pp. 4540–4561, 2017. [58] H. Gluesing-Luerssen, J. Rosenthal, and R. Smarandache, “Strongly-MDS convolutional codes,” IEEE Transactions on Information Theory, vol. 52, no. 2, pp. 584–598, feb 2006. [59] R. M. Roth and G. Seroussi, “On generator matrices of MDS codes,” IEEE Transactions on Infortmation Theory, vol. 31, no. 6, pp. 826–830, Nov. 1985.

