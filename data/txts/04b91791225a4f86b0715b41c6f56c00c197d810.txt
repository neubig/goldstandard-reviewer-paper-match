1
Bandwidth Cost of Code Conversions in Distributed Storage: Fundamental Limits and
Optimal Constructions
Francisco Maturana and K. V. Rashmi Computer Science Department Carnegie Mellon University Pittsburgh, PA, USA
Email: fmaturan@cs.cmu.edu, rvinayak@cs.cmu.edu

arXiv:2008.12707v1 [cs.IT] 28 Aug 2020

Abstract
Erasure codes have become an integral part of distributed storage systems as a tool for providing data reliability and durability under the constant threat of device failures. In such systems, an [n, k] code over a ﬁnite ﬁeld Fq encodes k message symbols from Fq into n codeword symbols from Fq which are then stored on n different nodes in the system. Recent work has shown that signiﬁcant savings in storage space can be obtained by tuning n and k to variations in device failure rates. Such a tuning necessitates code conversion: the process of converting already encoded data under an initial [nI , kI ] code to its equivalent under a ﬁnal [nF , kF ] code. The default approach to conversion is to re-encode the data under the new code, which places signiﬁcant burden on system resources. Convertible codes are a recently proposed class of codes for enabling resource-efﬁcient conversions. Existing work on convertible codes has focused on minimizing the access cost, i.e., the number of code symbols accessed during conversion. Bandwidth, which corresponds to the amount of data read and transferred, is another important resource to optimize during conversions.
In this paper, we initiate the study on the fundamental limits on bandwidth used during code conversion and present constructions for bandwidth-optimal convertible codes. First, we model the code conversion problem using network information ﬂow graphs with variable capacity edges. Second, focusing on MDS codes and an important parameter regime called the merge regime, we derive tight lower bounds on the bandwidth cost of conversion. The derived bounds show that the bandwidth cost of conversion can be signiﬁcantly reduced even in regimes where it has been shown that access cost cannot be reduced as compared to the default approach. Third, we present a new construction for MDS convertible codes which matches the proposed lower bound and is thus bandwidth-optimal during conversion.
I. INTRODUCTION
Erasure codes are an essential tool in distributed storage systems used to add redundancy to data in order to avoid data loss when device failures occur [1]–[4]. In particular, Maximum Distance Separable (MDS) codes are widely used for this purpose in practice because they require the minimum amount of storage overhead for a given level of failure tolerance. In this setting, an [n, k] MDS code over a ﬁnite ﬁeld Fq is used to encode a message consisting of k symbols of Fq into a codeword consisting of n symbols of Fq.1 Each of these n codeword symbols are then stored on n distinct nodes of the distributed storage system (typically, nodes correspond to storage devices residing on different servers). Large-scale distributed storage systems usually comprise hundreds to thousands of nodes, while n is much smaller in comparison, meaning that these systems store many such codewords distributed across different subsets of nodes. The MDS property ensures that any subset of k symbols out of the n symbols in the codeword is enough to decode the original data. This provides tolerance for up to (n − k) node failures.
1In the literature, this set of n symbols is sometimes called a stripe instead of a codeword. In this work, we make no distinctions between these two terms.

August 31, 2020

DRAFT

2
The parameters n and k are typically set based on the reliability of storage devices and additional requirements on system performance and storage overhead. Recent work by Kadekodi et al. [5] has shown that the failure rate of disks can vary drastically over time, and that signiﬁcant savings in storage space (and hence operating costs) can be achieved by tuning the code rate to the observed failure rates. Such tuning typically needs to change both n and k of the code, due to other practical system constraints on these parameters [5]. Other reasons for tuning parameters include changing k in response to changes in data popularity, and adapting the code rate to limit the total amount of storage space used. Such tuning of parameters requires converting the already encoded data from one set of parameters to the newly chosen set of parameters. The default approach to achieving this is to re-encode, that is, read the encoded data, decode if necessary, re-encode it under the new code, and then write it back into the relevant nodes. However, such an approach necessitates signiﬁcantly high overhead in terms of network bandwidth, I/O, and CPU resources in the cluster. This disrupts the normal operation of the storage system.
These applications have led to the study of the code conversion problem [6], [7]. Code conversion is the process of transforming a collection of codewords encoding data under an initial code CI into a collection of codewords encoding the same data under a ﬁnal code CF .2 Given certain parameters for CI and CF , the goal is to design the codes CI and CF along with a conversion procedure from CI to CF that is efﬁcient in conversion (according to some notion of conversion cost as will be discussed subsequently). The design is subject to additional decodability constraints on the codes CI and CF , such as both satisfying the MDS property, since both these codes encode data in the storage system at different snapshots in time. A pair of codes designed to efﬁciently convert encoded data from an [nI , kI ] code to an [nF , kF ] code is called an (nI , kI ; nF , kF ) convertible code, and the initial [nI , kI ] code is said to be (nF , kF )-convertible. In practice, the exact value of the ﬁnal parameters nF and kF might not be known at the time of code construction, as it might depend on future failure rates. Instead, one might have some ﬁnite set of possible values for the pair (nF , kF ) that will be chosen from at the time of conversion. For this reason, we will also seek to construct initial codes which are simultaneously (nF , kF )-convertible for all (nF , kF ) in a given ﬁnite set of ﬁnal parameter values. This allows the ﬂexibility to choose the parameters nF and kF at the time conversion is performed.
Existing works on convertible codes have studied efﬁciency in terms of the access cost of conversion, which corresponds to the number of codeword symbols accessed during conversion. In particular, previous works [6], [7] have derived tight lower bounds on the access cost of conversion for linear MDS convertible codes, and presented explicit constructions of MDS convertible codes that meet those lower bounds (i.e. access-optimal MDS convertible codes). Another important resource overhead incurred during conversion is that on the network bandwidth, which we call conversion bandwidth. In the system, this corresponds to the total amount of data read and transferred between nodes during conversion. Access-optimal convertible codes, by virtue of reducing the number of code symbols accessed, also reduce the network bandwidth cost as compared to the default approach. However, it is not known if these codes are also bandwidth optimal.
In this paper, the focus is on MDS convertible codes that incur minimum conversion bandwidth (i.e. bandwidth-optimal convertible codes). We speciﬁcally focus on a parameter regime known as the merge regime, which has been shown to play the most critical role in the analysis and construction of convertible codes [6]. The merge regime corresponds to conversions where multiple initial codewords are merged into a single ﬁnal codeword (i.e. kF = ςkI for some integer ς ≥ 2).
For the access cost of conversion in the merge regime, it is known [7] that one cannot do better than the default approach for a wide range of parameters (speciﬁcally, when (nI − kI ) < (nF − kF ), which we term Regime 1). For the remaining set of parameters (which we term Regime 2), access-optimal convertible codes lead to considerable reduction in access cost compared to the default approach. Yet, it is possible that there is room for a signiﬁcant reduction in bandwidth cost in both of these regimes. This
2The superscripts I and F stand for initial and ﬁnal, respectively.

August 31, 2020

DRAFT

3

is possible by considering codes over ﬁnite extensions of ﬁnite ﬁelds Fqα, where each codeword symbol can be interpreted as an α-length vector over the base ﬁeld Fq. Such codes are called vector codes. Vector codes allow conversion procedures to download elements of the base ﬁeld from nodes, allowing them to download only a fraction of the codeword symbols. This is inspired by the work on regenerating codes by Dimakis et al. [8] who used vector codes to reduce bandwidth cost of reconstructing a subset of the codeword symbols. Contributions of this paper. First, to analyze the bandwidth cost, we model the code conversion problem via a network information ﬂow graph. This is a directed acyclic graph with capacities, where vertices represent nodes and edges represent the communication between nodes. The approach of information ﬂow graphs has been used by Dimakis et al. [8] in the study on regenerating codes. Unlike in the case of regenerating codes, the proposed model involves variable capacities on edges representing data download during conversion. This feature turns out to be be critical; we show that conversion procedures which download a uniform amount of data from each node are necessarily sub-optimal.
Second, by using the information ﬂow model, we derive a tight lower bound on the network bandwidth cost of conversion for MDS convertible codes in the merge regime. Speciﬁcally, we use the information ﬂow graph to derive constraints on edge capacities that we then feed into an optimization problem whose objective is to minimize the bandwidth of conversion. With this we derive a tight lower bound on the total bandwidth cost of conversion for given code parameters (nI , kI ; nF , kF ).
Third, using the above derived (tight) lower bound, we show that (1) in Regime 1, where no reduction in access cost as compared to the default approach is possible, a substantial reduction in bandwidth cost can be achieved, and (2) in Regime 2, the access-optimal convertible codes are indeed bandwidth-optimal.
Fourth, we present an explicit construction of MDS convertible codes in the merge regime which achieves this lower bound and is therefore optimal in terms of bandwidth cost. This construction exploits the Piggybacking framework [9], which is a general framework for constructing vector codes, and uses access-optimal MDS convertible codes [7] as a building block.
Above, only a single value of ﬁnal parameters nF and kF was considered. So ﬁnally, we propose a technique to transform our construction so as to be simultaneously bandwidth-optimal in conversion for any given set of potential ﬁnal parameter values. The proposed transformation exploits piggybacking in a recursive fashion.
Organization. We review the necessary background and discuss related work in Section II. In Section III, we describe our model of the conversion process as an information ﬂow graph. In Section IV, we derive a lower bound on the conversion bandwidth of MDS convertible codes in the merge regime. In Section V, we propose an explicit construction for bandwidth-optimal MDS convertible codes in the merge regime, including the transformation to make the construction simultaneously bandwidth-optimal in conversion for multiple ﬁnal parameter values. In Section VI, we analyze the savings enabled by bandwidth-optimal convertible codes. We conclude the paper in Section VII.
II. BACKGROUND AND RELATED WORK
In this section we start by introducing concepts from the existing literature that are used in this paper. We then do an overview of other related work.
A. Vector codes and puncturing An [n, k, α] vector code C over a ﬁnite ﬁeld Fq is an Fq-linear subspace C ⊆ Fαq n of dimension αk.
For a given codeword c ∈ C and i ∈ [n], deﬁne ci = (cα(i−1)+1, . . . , cαi) as the i-th symbol of c, which is a vector of length α over Fq. In the context of vector codes, we will refer to elements from the base ﬁeld Fq as subsymbols. An encoding function for C is a function f (m) = (f1(m), . . . , fn(m)) mapping messages m to codewords of C. We denote the encoding of a message m under a code C as C(m). An encoding function (or its associated code) is said to be systematic if it always maps m to a codeword

August 31, 2020

DRAFT

4

having m as a preﬁx. For an [n, k, α] vector code C, the encoding of message m ∈ Fkqα is given by the mapping m → mG where G ∈ Fkqα×nα is called the generator matrix of C, and the columns of G are called encoding vectors. An [n, k, α] vector code C is maximum distance separable (MDS) if its minimum distance is the maximum possible:
min-dist(C) = min |{i ∈ [n] : ci = ci}| = n − k + 1.
c=c ∈C
Equivalently, an [n, k, α] vector code C is MDS if and only if for every c ∈ C, any k symbols of c uniquely specify the remaining (n − k) symbols (i.e. every codeword can be decoded from any k symbols). A scalar code is a vector code with α = 1. We will omit the parameter α when it is clear from context or when α = 1. A puncturing of a vector code C is the resulting vector code after removing a ﬁxed subset of symbols from every codeword c ∈ C.

B. Convertible codes [6], [7]

Convertible codes are erasure codes which are designed to enable encoded data to undergo efﬁcient
conversion. Let CI be an [nI , kI ] code over Fq, and CF be an [nF , kF ] code over Fq. Previous works on convertible codes (and also the present paper) focus on the case where both CI and CF are linear codes. In the initial conﬁguration, data will be encoded under the initial code CI , and in the ﬁnal conﬁguration data will be encoded under the ﬁnal code CF . Let rI = (nI − kI ) and rF = (nF − kF ). In order to allow for a change in code dimension from kI to kF , multiple codewords of codes CI and CF are considered.

The reason behind this is that in the initial and ﬁnal conﬁgurations, the system must encode the same

total number of message symbols (though encoded differently). Thus, even the simplest instance of the

problem involves multiple codewords in the initial and ﬁnal conﬁguration. Let m be a message of length

M = lcm(kI , kF ) which in the initial conﬁguration is encoded as λI = (M/kI) codewords of CI and in

the ﬁnal conﬁguration is encoded as λF = (M/kF ) codewords of CF . For a subset I ⊆ [M ], we denote

the restriction of m to the coordinates in I as m|I ∈ F|qI|. The mapping of message symbols from m to

different codewords is speciﬁed by two partitions of [M ]: an initial partition PI and a ﬁnal partition PF .

Each subset PiI ∈ PI must be of size |PiI | = kI , and indicates that the submessage m|P I is encoded by

i

initial

codeword

i,

for

i

∈

[λI ].

Similarly,

each

subset

PjF

∈

PI

must

be

of

size

|P

F j

|

=

kF ,

and

indicates

that the submessage m|P F is encoded by ﬁnal codeword j, for j ∈ [λF ]. A conversion from initial code j
CI to ﬁnal CF is a procedure that takes the initial codewords {CI (m|P I ) : i ∈ [λI ]} and outputs the ﬁnal i
codewords {CF (m|P F ) : i ∈ [λF ]}. Putting all these elements together, a convertible code is formally i

deﬁned as follows.

Deﬁnition 1 (Convertible code [6]). An (nI , kI ; nF , kF ) convertible code over Fq is deﬁned by : (1)
a pair of initial and ﬁnal codes (CI , CF ) over Fq, where CI is an [nI , kI ] code and CF is an [nF , kF ]
code, (2) initial and ﬁnal partitions (PI , PF ) of M such that |PiI | = kI for PiI ∈ PI and |PjF | = kF for PjF ∈ PF , (3) a conversion procedure from CI to CF .

The access cost of a conversion procedure is the sum of the read access cost, i.e. the total number of
code symbols read, and the write access cost, i.e. the total number of code symbols written. An access-
optimal convertible code is a convertible code whose conversion procedure has the minimum access cost over all convertible codes with given parameters (nI , kI ; nF , kF ). Similarly, an [nI , kI ] code is said to be (nF , kF )-access-optimally convertible if it is the initial code of an access-optimal (nI , kI ; nF , kF )
convertible code. Deﬁnition 1 considers single ﬁxed values for parameters nF and kF . In practice, the values of nF and
kF for the conversion might be unknown. Thus, constructing convertible codes which are simultaneously (nF , kF )-access-optimally convertible for several possible values of nF and kF is also important (as will
be discussed in Section V-B).

August 31, 2020

DRAFT

5

Though the deﬁnition of convertible codes allows for any kind of initial and ﬁnal codes, in this work we focus exclusively on erasure codes that are MDS. We call an (nI , kI ; nF , kF ) convertible code MDS when both CI and CF are MDS. The access cost lower bound for linear MDS convertible codes is known.
Theorem 1 ([7]). Let d1 be the read access cost of a linear MDS (nI , kI ; nF , kF ) convertible code, and d2 its write access cost.. When kI = kF , for every access-optimal code:

d1 ≥

λI rF + [λI mod λF ](kI − max{[kF mod kI ], rF }), M,

if rI ≥ rF and rF < min{kI , kF } otherwise

d2 ≥ λF rF .

There are explicit constructions [6], [7] of access-optimal convertible codes for all valid parameters (nI , kI ; nF , kF ). Notice that for Regime 1 (rI < rF ), read access cost is always M , which is the same as the default approach. In Regime 2 (rI ≥ rF ), on the other hand, one can achieve lower access cost than the default approach when rF < min{kI , kF }.
During conversion, code symbols from the initial codewords can play multiple roles: they can become part of different ﬁnal codewords, their contents might be read or written, additional code symbols may be added and existing code symbols may be removed. Based on their role, code symbols can be divided into three groups: (1) unchanged symbols, which are present both in the initial and ﬁnal codewords without any modiﬁcations; (2) retired symbols, which are only present in the initial codewords but not in the ﬁnal codewords; and (3) new symbols, which are present only in the ﬁnal codewords but not in the initial codewords. Clearly, both unchanged and retired symbols may be read during conversion, and then linear combinations of data read are written into the new symbols. Convertible codes which have the maximum number of unchanged symbols (M when kI = kF ) are called stable.
The merge regime is a fundamental regime of convertible codes which corresponds to conversions which merge multiple initial codewords into a single ﬁnal codeword. Thus, convertible codes in the merge regime are such that kF = ςkI for some integer ς ≥ 2. We recall two lemmas from previous work which are useful for analyzing the merge regime.
Proposition 1 ([6]). For every (nI , kI ; nF , ςkI ) convertible code, all possible pairs of initial and ﬁnal partitions (PI , PF ) are equivalent up to relabeling.

In the merge regime, all data gets mapped to the same ﬁnal stripe. Thus, the initial and ﬁnal partition do not play an important role in this case.
Proposition 2 ([6]). In an MDS (nI , kI ; nF , ςkI ) convertible code, there can be at most kI unchanged symbols from each initial codeword.

This is because having more than kI unchanged symbols in an initial codeword would contradict the
MDS property.
Access optimal convertible code for merge regime. In the merge regime, the bound from Theorem 1 in the case where rI ≥ rF and rF < kI reduces to d1 ≥ ςrF and d2 ≥ rF . Thus in access-optimal conversion in the merge regime, only rF code symbols from each initial codeword need to be read. These symbols are then used to compute rF new code symbols.
In [6], a simple construction for access-optimal convertible codes in the merge regime is proposed.
Codes built using this construction are (1) systematic, (2) linear, (3) during conversion only access the ﬁrst rF parities from each initial stripe (assuming rF ≤ rI ), and (4) when constructed with a given value of λI = ς and rF = r, the initial [nI , kI ] code is (nF , kF )-access-optimally convertible for all kF = ς kI and nF = kF + r such that 1 ≤ ς ≤ ς and 1 ≤ r ≤ r. In Section V we use an access-optimal
convertible code in the merge regime as part of our construction of bandwidth-optimal convertible codes
for the merge regime. We will assume, without loss of generality, that the code has these four properties.

August 31, 2020

DRAFT

6

Symbol 1 f1(m1) f1(m2) · · · f1(mα)

...

...

...

...

...

Symbol n fn(m1) fn(m2) · · · fn(mα)

(a) α instances of the base code

f1(m1) f1(m1) + g2,1(m2) · · · f1(mα) + gα,1(m1, . . . , mα)

...

...

...

...

fn(m1) fn(m1) + g2,n(m2) · · · f1(mα) + gα,n(m1, . . . , mα)

(b) Piggybacked code

Fig. 1: Piggybacking framework [9] for constructing vector codes.

C. Network information ﬂow
Network information ﬂow [10] is a class of problems that model the transmission of information from sources to sinks in a point-to-point communication network. Network coding [11]–[15] is a generalization of store-and-forward routing, where each node in the network is allowed to combine its inputs using a code before communicating messages to other nodes. For the purposes of this paper, an information ﬂow graph is a directed acyclic graph with G = (V, E), where E ⊆ V × V × R≥0 is the set of edges with non-negative capacities, and (i, j, c) ∈ E represents that information can be sent noiselessly from node i to node j at rate c. Let X1, X2, . . . , Xm be mutually independent information sources with rates x1, x2, . . . , xm respectively. Each information source Xi is associated with a source si ∈ V , where it is generated, and a sink ti ∈ V , where it is required. In this paper we mainly make use of the information max-ﬂow bound [16] which indicates that it is impossible to transmit Xi at a higher rate than the maximum ﬂow from si to ti. In other words, xi ≤ max-ﬂow(si, ti) for all i ∈ [m] is a necessary condition for a network coding scheme satisfying all constraints to exist. In our analysis, we will consider si-ti-cuts of the information ﬂow graph, which give an upper bound on max-ﬂow(si, ti) and thus an upper bound on xi as well. We will also utilize the fact that two independent information sources with the same source and sink can be considered as a single information source with rate equal to the sum of their rates.
In [8], information ﬂow and network coding is applied to the repair problem in distributed storage systems. The repair problem is the problem of reconstructing a small number of failed code symbols in an erasure code (without having to decode the full codeword). Dimakis et al. [8] use information ﬂow to establish bounds on the storage size and repair network-bandwidth of erasure codes. Similarly, in this work we use information ﬂow to model the process of code conversion and establish lower bounds on the total amount of network bandwidth used during conversion.
D. Piggybacking framework for constructing vector codes
The Piggybacking framework [9], [17] is a framework for constructing new vector codes building on top of existing codes. The main technique behind the Piggybacking framework is to take an existing code as a base code, create a new vector code consisting of multiple instances of the base code (as described below), and then add carefully designed functions of the data (called piggybacks) from one instance to the others. These piggybacks are added in a way such that it retains the decodability properties of the base code (such as the MDS property). The piggyback functions are chosen to confer additional desired properties to the resulting code. In [9], the authors showcase the Piggybacking framework by constructing codes that are efﬁcient in reducing bandwidth consumed in repairing codeword symbols.
More speciﬁcally, the Piggybacking framework works as follows. Consider a length n code deﬁned by encoding function f (m) = (f1(m), f2(m), . . . , fn(m)). Now, consider α instances of this base code, each corresponding to a coordinate of the α-length vector of each symbol in the new vector code. Let m1, m2, · · · , mα denote the independent messages encoded under these α instances, as shown in Figure 1a. For every i such that 2 ≤ i ≤ α, one can add to the data encoded in instance i an arbitrary function of the data encoded by instances {1, . . . , (i − 1)}. Such functions are called piggyback functions,

August 31, 2020

DRAFT

7

and the piggyback function corresponding to code symbol j ∈ [n] of instance i ∈ {2, . . . , α} is denoted as gi,j.
The decoding of the piggybacked code proceeds as follows. Observe that instance 1 does not have any piggybacks. First, instance 1 of the base code is decoded using the base code’s decoding procedure in order to obtain m1. Then, m1 is used to compute and subtract any of the piggybacks {g2,i(m1)}ni=1 from instance 2 and the base code’s decoding can then be used to recover m2. Decoding proceeds like this, using the data decoded from previous instances in order to remove the piggybacks until all instances have been decoded. It is clear that if an [n, k, α] vector code is constructed from an [n, k] MDS code as the base code using the Piggybacking framework, then the resulting vector code is also MDS. This is because any set of k symbols from the vector code contains a set of k subsymbols from each of the α instances.
In this paper, we use the Piggybacking framework to design a code where piggybacks store data which helps in making the conversion process efﬁcient.
E. Other related work
Apart from [6], which presented a general formulation for the code conversion problem, special cases of code conversion have been studied in the literature. In [18], the authors propose two speciﬁc pairs of non-MDS codes for a distributed storage system which support conversion with lower access cost than the default approach. In [19], the authors study two kinds of conversion in the context of distributed matrix multiplication. These works focus on reducing the access cost of conversion, whereas the focus of the current paper is on the bandwidth cost of conversion. Furthermore, the approaches proposed in these works [18], [19] do not come with any theoretical guarantees on optimality, whereas the current paper also presents tight lower bounds on the bandwidth cost of conversion along with bandwidth-optimal constructions.
A related line of research is that of regenerating codes. Regenerating codes are erasure codes which are designed to solve the repair problem (described in Section II-C above) by downloading the least amount of data from the surviving nodes. Regenerating codes were ﬁrst proposed by Dimakis et al. [8]. Several subsequent works (e.g., [9], [20]–[51] and references therein) have provided constructions and generalizations of regenerating codes. The regenerating codes framework measures the cost of repair in a similar way to how we measure the cost of conversion in this work: in terms of the total amount of network bandwidth used, i.e. the total amount of data transferred during repair. Thus, some of the techniques used in this paper are inspired by the existing regenerating codes literature, as further explained in Section II-C. Furthermore, speciﬁc instances of code conversion can be viewed as instances of the repair problem, for example, increasing n while keeping k ﬁxed as studied in [9], [42], [52]. In such a scenario, one can view adding additional nodes as “repairing” them as proposed in [42]. Note that this setting imposes a relaxed requirement of repairing only a speciﬁc subset of nodes as compared to regenerating codes which require optimal repair of all nodes. Yet, the lower bound from regenerating codes still applies for MDS codes, since as shown in [22], the regenerating codes lower bound for MDS codes applies even for repair of only a single speciﬁc node.
Another related line of research is that of locally recoverable codes, also known as local reconstruction codes, or LRCs for short. LRCs are non-MDS codes with the property that any codeword symbol can be recovered by reading a relatively small subset of other symbols (and usually much smaller than the subset of symbols required to decode the full data). Several works (e.g., [51], [53]–[64] and references therein) have studied the properties of LRCs (and variants thereof) and proposed constructions. While the cost metric of LRCs more closely resembles the access cost metric, the constraint that each initial and ﬁnal codeword in a convertible code can be decoded independently may be seen as a form of local decodability.
There have been several works studying the scaling problem [65]–[76]. This problem considers upgrading an erasure-coded storage system with s new empty data nodes. The general goal is to efﬁciently

August 31, 2020

DRAFT

8

and evenly redistribute data across all nodes, while updating parities to reﬂect the new placement of the data. This is a fundamentally different problem from the code conversion problem we study in this paper, due to the scaling problem’s need to redistribute data across nodes.

III. MODELING CONVERSION FOR OPTIMIZING NETWORK BANDWIDTH

In this section, we model the conversion process as an information ﬂow problem. We utilize this model

primarily for deriving lower bounds on the total amount of information that needs to be transferred during

conversion. Since our focus is on modeling the conversion process, we consider a single value for each of the ﬁnal parameters nF and kF . This model continues to be valid for each individual conversion, even

when the ﬁnal parameters might take multiple values.

In Section II-B, we reviewed the deﬁnition of convertible codes from literature [6], [7]. Existing works

on convertible codes [6], [7] have considered only scalar codes, where each code symbol corresponds

to a scalar from a ﬁnite ﬁeld Fq. Considering scalar codes is sufﬁcient when optimizing for access cost,

which was the focus in these prior works, since the access cost is measured at the granularity of code

symbols. However, when optimizing the cost of network bandwidth, vector codes can perform better than

scalar codes since they allow partial download from a node. This allows conversion procedures to only

download a fraction of a code symbol and thus only incur the bandwidth cost associated with the size

of that fraction. This can potentially lead to signiﬁcant reduction in network bandwidth cost. For this reason, we consider the initial code CI as an [nI , kI , α] MDS code and the ﬁnal code CF as an [nF , kF , α]

MDS code, where α ≥ 1 is considered as a free parameter chosen to minimize network bandwidth cost.

This move to vector codes is inspired by the work of Dimakis et al. [8] on regenerating codes, who

showed the beneﬁt of vector codes in reducing network bandwidth in the context of the repair problem. For MDS convertible codes, message size will be B = M α = lcm(kI , kF )α, which we interpret as a vector m ∈ FM q α composed of M symbols made up of α subsymbols each. We will denote the number of symbols downloaded from node s during conversion as β(s) ≤ α and extend this notation to sets of

nodes as β(S) = s∈S β(s).

Consider

an

(nI , kI ; nF , kF )

MDS

convertible

code

with

initial

partition

PI

=

{

P

I 1

,

.

.

.

,

P

I λI

}

and

ﬁnal

partition

PF

=

{

P

F 1

,

.

.

.

,

P

F λF

}

.

We

model

conversion

using

an

information

ﬂow

graph

as

the

one

shown in Figure 2 where message symbols are generated at source nodes, and sinks represent the decoding

constraints of the ﬁnal code. Symbols of message m are modeled as information sources X1, X2, . . . , XM of rate α (over Fq) each. For each initial codeword i ∈ [λI ], we include one source node si, where the information sources corresponding to the message symbols in PiI are generated. Each code symbol of
initial codeword i is modeled as a node with an incoming edge from si. A coordinator node c models

the central location where the contents of new symbols are computed, and it has incoming edges from

all nodes in the initial codewords. During conversion, some of the initial code symbols will remain

unchanged, some will be retired, and some new code symbols will be added. Thus, we also include

the nodes corresponding to unchanged symbols in the ﬁnal codewords (that is, every unchanged node is

shown twice in Figure 2). Note that the unchanged nodes in the initial codewords and the unchanged

nodes in the ﬁnal codewords are identical, and thus do not add any bandwidth cost. For each new symbol

we add a node that connects to the coordinator node. From this point, we will refer to code symbols and their corresponding nodes interchangeably. For each ﬁnal codeword j ∈ [λF ], we add a sink tj

which connects to some subset of nodes from ﬁnal codeword j, and recovers the information sources

corresponding

to

the

message

symbols

in

P

F j

.

Thus, the information ﬂow graph for a convertible code comprises the following nodes:

• unchanged nodes Ui,j = {ui,j,1, . . . , ui,j,|Ui,j|} for all i ∈ [λI ], j ∈ [λF ], which are present both in

the initial and ﬁnal codewords; • retired nodes Ri = {vi,1, . . . , vi,|Ri|} for i ∈ [λI ], which are only present in the initial codewords; • new nodes Nj = {wj,1, . . . , wj,|Nj|} for j ∈ [λF ], which are only present in the ﬁnal codewords;

August 31, 2020

DRAFT

9

U1,∗ Initial codewords
Final codewords
U∗,1

s1
α

R1 UλI ,∗

c
α
α N1 U∗,λF

sλI
α

RλI

β(x) α

α NλF

t1

tλF

Fig. 2: Information ﬂow graph of conversion in the general case. Unchanged, retired, and new nodes are shown in different colors. Notice that each unchanged node in this ﬁgure is drawn twice: once in the initial codewords and once in the ﬁnal codewords. These correspond to exactly the same node, but are drawn twice for clarity. Some representative edges are labeled with their capacities.

• source nodes si for i ∈ [λI ], representing the data to be encoded; • sink nodes tj for j ∈ [λF ], representing the data decoded; and
• a coordinator node c.

In the information ﬂow graph, information source Xl is generated at node si if and only if l ∈ PiI , and

recovered

at

node

tl

if

and

only

if

l

∈

P

F j

.

Throughout this paper, we use the disjoint union symbol when appropriate to emphasize that the

two sets in the union are disjoint. To simplify the notation, when ∗ is used as an index, it denotes the

disjoint union of the indexed set over the range of that index, e.g. U∗,j =

λI i=1

Ui,j

.

The information ﬂow graph must be such that the following conditions hold: (1) the number of nodes

per initial codeword is nI , i.e., |Ui,∗| + |Ri| = nI for all i ∈ [λI ]; and (2) the number of nodes per ﬁnal

codeword is nF , i.e., |U∗,j|+|Nj| = nF for all j ∈ [λF ]. Additionally, the information ﬂow graph contains

the following set of edges E, where a directed edge from node u to v with capacity δ is represented

with the triple (u, v, δ):

• {(si, x, α) : x ∈ Ui,∗ Ri} ⊂ E for each i ∈ [λI ], where the capacity corresponds to the size of the
data stored on each node; • {(x, c, β(x)) : x ∈ Ui,∗ Ri} ⊂ E for each i ∈ [λI ], where the capacity corresponds to the amount
of data downloaded from node x; • {(c, y, α) : y ∈ Nj} ⊂ E for each j ∈ [λF ], where the capacity corresponds to the size of the data
stored on each new node; • {(y, tj, α) : y ∈ Vj} ⊂ E for Vj ⊆ U∗,j Nj such that |Vj| = kF , for all j ∈ [λF ], where the
capacity corresponds to the size of the data stored on each node.

The sinks tj represent the decoding constraints of the ﬁnal code, and each choice of set Vj will represent a different choice k code symbols for decoding the ﬁnal codeword. A necessary condition for a conversion procedure is to satisfy all sinks tj for all possible V1, . . . , VλF . The sets Ui,j, Ri, Nj and the capacities β(x) are determined by the conversion procedure of the convertible code. Figure 2 shows the information

ﬂow graph of an arbitrary convertible code.

Deﬁnition 2 (Conversion bandwidth). The conversion bandwidth γ is the total network bandwidth used during conversion and is equal to the total amount of data that is transferred to the coordinator node c from the initial nodes plus the total amount of data transferred to the new nodes from the coordinator

August 31, 2020

DRAFT

s1

sλI

c

s1 c

10 sλI

t1

t1

(a)

(b)

Fig. 3: Information ﬂow graph of conversion in the merge regime with two different cuts (used in proofs). For clarity, each unchanged node is drawn twice: once in the initial codewords and once in the ﬁnal codeword. These two instances are connected by a dashed arrow. Marked edges denote a graph cut.

node c, that is:

γ = β(U∗,∗ R∗) + |N∗|α.

(1)

Once the structure of the graph is set and ﬁxed, information ﬂow analysis gives lower bounds on the capacities β(x). Therefore, a part of our objective in designing convertible codes is to set Ui,j, Ri, Nj so as to minimize the lower bound on γ.
Remark 1. In practice, conversion bandwidth can sometimes be further reduced by placing the coordinator node along with a new node and/or a retired node in the same server. One can even ﬁrst split the coordinator node into several coordinator nodes, each processing data which is not used in conjunction with data processed by other coordinator nodes, and then place them in the same server as a new node and/or a retired node. Such “optimizations” do not fundamentally alter our result, and hence are left out in order to make the exposition clear.

IV. OPTIMIZING NETWORK BANDWIDTH OF CONVERSION IN THE MERGE REGIME
In this section, we use the information ﬂow model presented in Section III to derive a lower bound on
the conversion bandwidth for MDS codes in the merge regime. Recall from Section II-B, that convertible codes in the merge regime are those where kF = ςkI for some integer ς ≥ 2, i.e., this regime corresponds to conversions were multiple initial codewords are merged into a single ﬁnal codeword. As in the previous section, our analysis focuses on a single conversion, and thus a single value for the ﬁnal parameters nF and kF . The lower bound on conversion bandwidth derived in this section continues to hold even when we consider multiple possible values for the ﬁnal parameters nF and kF .
Consider an (nI , kI ; nF , ςkI ) convertible code in the merge regime, for some integer ς ≥ 2. Note that for all convertible codes in the merge regime, it holds that λI = ς and λF = 1. Since all initial and ﬁnal partitions (PI , PF ) are equivalent up to relabeling in this regime (by Proposition 1 [6]), we can omit them from our analysis. Note also that every information source shares the same sink, as there is only a single sink t1. Thus, we may treat each source si as having a single information source Xi of rate αkI (i ∈ [λI ]). Figure 3a shows the information ﬂow graph for a convertible code in the merge regime.
First, we derive a general lower bound on conversion bandwidth in the merge regime by considering
a simple cut in the information ﬂow graph. Intuitively, this lower bound emerges from the fact that new
nodes need to have a certain amount of information from each initial codeword in order to fulﬁll the
MDS property of the ﬁnal code. This lower bound depends on the number of unchanged nodes and
achieves its minimum when the number of unchanged nodes is maximized. Recall from Section II-B that

August 31, 2020

DRAFT

11

convertible codes with maximum number of unchanged nodes are called stable convertible codes. Thus, the derived lower bound is minimized for stable convertible codes.
Lemma 2. Consider an MDS (nI , kI ; nF , ςkI ) convertible code. Then γ ≥ ςα min{rF , kI }+rF α, where equality is only possible for stable codes.
Proof. We prove this inequality via an information ﬂow argument. Let i ∈ [λI ] and consider the information source generated at source si. Let S ⊆ Ui,1 be a subset of unchanged nodes from initial codeword i of size r˜i = min{rF , |Ui,1|}. Consider a sink t1 that connects to nodes U∗,1 \ S. We choose the graph cut deﬁned by nodes {si} Ui,1 Ri (see Figure 3a, which depicts the cut for i = λI ). This cut yields the following inequality:
kI α ≤ max{|Ui,1| − rF , 0}α + β(Ui,1 Ri)
⇐⇒ β(Ui,1 Ri) ≥ (kI + rF − max{|Ui,1|, rF })α
By summing this inequality over all sources i ∈ [λI ] and using the deﬁnition of γ (Equation (1)), we obtain:
λI
γ ≥ (kI + rF − max{|Ui,1|, rF })α + |N1|α
i=1
By Proposition 2 [6], |Ui,1| ≤ kI . Therefore, it is clear that the right hand side achieves its minimum if and only |Ui,1| = kI for all i ∈ [λI ], proving the result.
Remark 2. Note that the conversion bandwidth lower bound described in Lemma 2 coincides with the access-cost lower bound described in Theorem 1 when rI ≥ rF . This follows by recalling that each node corresponds to an α-length vector, and for scalar codes α = 1.
In particular, this implies that convertible codes in the merge regime which are access-optimal and have rI ≥ rF are also bandwidth-optimal. Observe that this corresponds to Regime 1. However, as we will show next, this property fails to hold when rI < rF (that is, Regime 2).
We next derive a lower bound on conversion bandwidth which is tighter than Lemma 2 when rI < rF . Nevertheless, it allows for less conversion bandwidth usage than the access-optimal codes.
Intuitively, the data downloaded from retired nodes during conversion will be “more useful” than the data downloaded from unchanged nodes, since unchanged nodes already form part of the ﬁnal codeword. At the same time, it is better to have the maximum amount of unchanged nodes per initial codeword (kI ) because this minimizes the number of new nodes that need to be constructed. However, this leads to fewer retired nodes per initial codeword (rI ). If the number of retired nodes per initial codeword is less than the number of new nodes (rI < rF ), then conversion procedures are forced to download data from unchanged nodes. This is because one needs to download at least rF α from each initial codeword (by Lemma 2). Since data from unchanged nodes is “less useful”, more data needs to be downloaded in order to construct the new nodes.
As in the case of Lemma 2, this lower bound depends on the number of unchanged nodes in each initial codeword, and achieves its minimum in the case of stable convertible codes.
Lemma 3. Consider an MDS (nI , kI ; nF , ςkI ) convertible code, with rI < rF ≤ kI . Then γ ≥ ςα rI + kI 1 − rrFI + rF α, where equality is only possible for stable codes.
Proof. We prove this via an information ﬂow argument. Let i ∈ [λI ] and consider the information source generated at source si. Let S ⊆ Ui,1 be a subset of size r˜i = min{rF , |Ui,1|}. Consider a sink t1 that connects to the nodes in U∗,1 \ S. We choose the graph cut deﬁned by nodes {si} S Ri (see Figure 3b, which depicts the cut when i = λI ). This yields the following inequality:
kI α ≤ (|Ui,1| − r˜i)α + β(S) + β(Ri) .

August 31, 2020

DRAFT

12

By rearranging this inequality and summing over all possible choices of subset S, we obtain the following

inequality:

|Ui,1| (kI + r˜i − |Ui,1|)α ≤ r˜i

|Ui,1| − 1 β(Ui,1) + r˜i − 1

|Ui,1| β(Ri) r˜i

⇐⇒ |Ui,1|(kI + r˜i − |Ui,1|)α ≤ r˜iβ(Ui,1) + |Ui,1|β(Ri) .

(2)

Then, our strategy to obtain a lower bound is to ﬁnd the minimum value for conversion bandwidth γ

which satisﬁes inequality 2 for all i ∈ [λI ], which can be formulated as the following optimization

problem:

minimize γ = i∈λI [β(Ui,1) + β(Ri)] + |N1|α

subject to inequality 2, for all i ∈ [λI ]

(3)

0 ≤ β(x) ≤ α, for all x ∈ U∗,1 R∗.

Intuitively, this linear program shows that it is preferable to download more data from retired nodes
(β(Ri)) than unchanged nodes (β(Ui,1)), since both have the same impact on γ but the contribution β(Ri) towards satisfying inequality 2 is greater than or equal than that of β(Ri), because r˜i ≤ |Ui,1| by deﬁnition. Thus to obtain an optimal solution we ﬁrst set β(Ri) = min{kI + r˜i − |Ui,1|, |Ri|}α to the maximum needed for all i ∈ [λI ], and then set:

β(x) = max{r˜i − rI , 0}|Ui,1|α , r˜i
x∈Ui,1

for all i ∈ [λI ]

to satisfy the constraints. It is straightforward to check that this solution satisﬁes the KKT (Karush-KuhnTucker) conditions, and thus is an optimal solution to linear program 3. By replacing these terms back into γ and simplifying we obtain the optimal objective value:

λI
γ∗ =
i=1

kI − min{rI , r˜i}

|Ui,1| − 1 r˜i

α + |N1|α

It is easy to show that the right hand side achieves its minimum if and only if |Ui,1| = kI for all i ∈ [λI ] (i.e., the code is stable). This gives the following lower bound for conversion bandwidth:

γ ≥ λI α rI + kI 1 − rI rF

+ rF α.

By combining Lemmas 2 and 3 we obtain the following general lower bound on conversion bandwidth of MDS convertible codes in the merge regime.
Theorem 4. For any MDS (nI , kI ; nF , ςkI ) convertible code:

ςα min{kI , rF } + rF α,

if rI ≥ rF or kI ≤ rF

γ ≥ ςα rI + kI 1 − rrFI + rF α, otherwise

where equality can only be achieved by stable convertible codes.

Proof. Follows from Lemmas 2 and 3.

In Section V, we show that the lower bound of Theorem 4 is indeed achievable for all parameter values in the merge regime, and thus it is tight. We will refer to convertible codes that meet this bound with equality as bandwidth-optimal.
Remark 3. Observe that the model above allows for nonuniform data download during conversion, that is, it allows the amount of data downloaded from each node during conversion to be different. If instead one

August 31, 2020

DRAFT

13

were to assume uniform download, i.e. β(x) = β(y) for all x, y ∈ U∗,∗ R∗, then a higher lower bound for conversion bandwidth γ is obtained (mainly due to inequality 2 in the proof of Lemma 3). Since the lower bound of Theorem 4 is achievable, this implies that assuming uniform download necessarily leads to a suboptimal solution.

Remark 4. The case where kI = kF can be analyzed using the same techniques used in this section. In this case, λI = ς = 1. There are some differences compared to the case of the merge regime: for example, in this case the number of unchanged nodes can be at most min{nI , nF } (in contrast to the ςkI maximum of the merge regime). So, conversion bandwidth in the case where nI ≥ nF is zero, since we can simply keep nF nodes unchanged. In the case where nI < nF , the same analysis from Lemma 3
is followed, but the larger number of unchanged nodes will lead to a slightly different inequality. Thus, in the case of kI = kF the lower bound on conversion bandwidth is:

0, γ ≥ α kI + rI

1 − rrFI

+ (rF − rI )α,

if nI ≥ nF otherwise.

Readers familiar with regenerating codes might notice that the above lower bound is equivalent to the lower bound on the repair bandwidth [8], [39] when (rF − rI ) symbols of an [kI + rF , kI ] MDS code are to be repaired with the help of the remaining (kI + rI ) symbols. Note that this setting imposes a
relaxed requirement of repairing only a speciﬁc subset of symbols as compared to regenerating codes
which require optimal repair of all nodes. Yet, the lower bound remains the same. This is not surprising
though, since it has been shown [22] that the regenerating codes lower bound for MDS codes applies
even for repair of only a single speciﬁc symbol.

V. EXPLICIT CONSTRUCTION OF BANDWIDTH-OPTIMAL MDS CONVERTIBLE CODES IN
THE MERGE REGIME
In this section, we present an explicit construction for bandwidth-optimal convertible codes in the merge regime. Our construction employs the Piggybacking framework [9]. Recall from Section II-D that the Piggybacking framework is a framework for constructing vector codes using an existing code as a base code and adding specially designed functions called piggybacks which impart additional properties to the resulting code. We use an access-optimal convertible code to construct the base code and design the piggybacks to help achieve minimum conversion bandwidth. First, in Section V-A, we describe our construction of bandwidth-optimal convertible codes in the case where we only consider ﬁxed unique values for the ﬁnal parameters nF and kF = ςkI . Then, in Section V-B, we show that initial codes built with this construction are not only (nF , kF )-bandwidth-optimally convertible, but also simultaneously bandwidth-optimally convertible for multiple other values of the pair (nF , kF ). Additionally, we present a construction which given any ﬁnite set of possible ﬁnal parameter values (nF , kF ), constructs an initial [nI , kI ] code which is simultaneously (nF , kF )-bandwidth-optimally convertible for every (nF , kF ) in that set.

A. Bandwidth-optimal MDS convertible codes for ﬁxed ﬁnal parameters
The case where rF ≥ kI is trivial, since the default approach to conversion is bandwidth-optimal in this case. Therefore, in the rest of this section, we only consider rF < kI . Moreover, in the case where rI ≥ rF (Regime 2), access-optimal convertible codes (for which explicit constructions are known) are also bandwidth-optimal. Therefore, we focus on the case rI < rF (Regime 1).
We start by describing the base code used in our construction, followed by the design of piggybacks,
and then describe the conversion procedure along with the role of piggybacks during conversion.

August 31, 2020

DRAFT

14

initial codeword 1 (CI )

a1

b1

...

...

a4 a(1)pI1

b4 b(1)pI1 + a(1)pI2

initial codeword 2 (CI )

a5

b5

...

...

a8 a(2)pI1

b8 b(2)pI1 + a(2)pI2

ﬁnal codeword (CF )

a1

b1

...

...

a4

b4

a5

b5

...

...

a8

b8

apF1

bpF1

apF2

bpF2

Fig. 4: Example of a bandwidth-optimal (5, 4; 10, 8) convertible code. Each block in this diagram represents a codeword, where each column corresponds to a distinct coordinate of the α-length vector (α = 2 in this case), and each row corresponds to a node. The shaded rows correspond to retired nodes for the ﬁrst two blocks (initial codewords), and new nodes for the third block (ﬁnal codeword). For the initial codewords, text color is used emphasize the piggybacks. In the ﬁnal codeword, text color is used to denote the base code symbol which can be directly computed from the piggybacks.

a) Base code for piggybacking: As the base code for our construction, we use a punctured initial code of an access-optimal (kI + rF , kI ; nF , kF ) convertible code. Any access-optimal convertible code

can be used. However, as mentioned in Section II-B, we assume without loss of generality that this convertible code is: (1) systematic, (2) linear, and (3) only requires accessing the ﬁrst rF parities from each initial codeword during access-optimal conversion. We refer to the [kI + rF , kI ] initial code of this access-optimal convertible code as CI , to its [nF , kF ] ﬁnal code as CF . Let CI be the punctured version of CI where the last (rF − rI ) parity symbols are punctured.
b) Piggyback design: Now, we describe how to construct the [nI , kI , α] initial vector code CI and the [nF , kF , α] ﬁnal vector code CF that make up the bandwidth-optimal (nI , kI ; nF , ςkI ) convertible
code.
The ﬁrst step is to choose the value of α. Let us reexamine the lower bound derived in Theorem 4 for rI < rF < kI , which is rewritten below in a different form.

γ ≥ λI

rIα + kI

rI 1 − rF

α + rF α.

We can see that one way to achieve this lower bound would be to download exactly β1 = α subsymbols from each of the rI retired nodes in the λI initial codewords, and to download β2 = (1 − rI/rF ) α subsymbols from each of the kI unchanged nodes in the λI initial stripes. Thus, we choose α = rF , which is the smallest value that makes β1 and β2 integers, thus making:
β1 = rF and β2 = (rF − rI ).

The next step is to design the piggybacks. We ﬁrst provide the intuition behind the design. Recall from above that we can download β2 = (rF − rI ) subsymbols from each unchanged node and all the α subsymbols from each retired node. Hence, we can utilize up to β2 = (rF − rI ) coordinates from each of the rI parity nodes for piggybacking. Given that there are precisely (rF − rI ) punctured symbols and α instances of CI , we can store piggybacks corresponding to rI instances of each of these punctured
symbols. During conversion, these punctured symbols can be reconstructed and used for constructing the
new nodes.

August 31, 2020

DRAFT

15

Consider

a

message

m

∈

Fλq I kI α

split

into

λI α

submessages

m(js)

∈

F

k q

I

,

representing

the

data

encoded by instance j ∈ [α] of the base code in initial codeword s ∈ [λI ]. Recall that CI is systematic

by construction. Therefore, the submessage m(js) will correspond to the contents of the j-th coordinate

of the kI systematic nodes in initial codeword s. Let cIi,j(s) denote the contents of the j-th coordinate

of parity symbol i in initial codeword s under code CI , and cFi,j let denote the same for the single ﬁnal

codeword encoded under CF . These are constructed as follows:

cIi,j(s) =

m(js)pIi , m(js)pIi + m(is)pIj ,

cFi,j

=

[m(j1)

·

·

·

m

(λ j

I

)

]p

F i

,

for s ∈ [λI ], i ∈ [rI ], 1 ≤ j ≤ rI for s ∈ [λI ], i ∈ [rI ], rI < j ≤ rF
for i ∈ [rF ], j ∈ [rF ],

where pIi corresponds to the encoding vector of the i-th parity of CI and pFi corresponds to the encoding vector of the i-th parity of CF . By using the access-optimal conversion procedure from the base code, we can compute cFi,j = [m(j1) · · · m(jλI)]pFi from {m(js)pIi : s ∈ [λI ]} for all i ∈ [rF ] and j ∈ [rF ]. Notice that each initial codeword is independent and encoded in the same way (as required).
This piggybacking design, that of using parity code symbols of the base code as piggybacks, is inspired
by one of the piggybacking designs proposed in [9], where it is used for efﬁciently reconstructing failed
(parity) code symbols.
c) Conversion procedure: Conversion proceeds as follows: 1) Download D = {m(js) : s ∈ [λI ] and rI < j ≤ rF }, C1 = {cIi,j(s) : s ∈ [λI ], i ∈ [rI ], and 1 ≤
j ≤ rI }, and C2 = {cIi,j(s) : s ∈ [λI ], i ∈ [rI ], and rI < j ≤ rF }. 2) Recover the piggybacks C3 = {m(js)pIi : s ∈ [λI ], rI < i ≤ rF , and 1 ≤ j ≤ rI } by computing
m(is)pIj from D and obtaining m(js)pIi = cIj,i(s) − m(is)pIj using C2. 3) Compute the remaining base code symbols from the punctured symbols C4 = {m(is)pIj : s ∈
[λI ], rI < i ≤ rF , and rI < j ≤ rF } using D. 4) Compute the parity nodes of the ﬁnal codeword speciﬁed by the subsymbols C5 = {cFi,j : i ∈
[rF ], j ∈ [rF ]}. This is done by using the conversion procedure from the access-optimal convertible
code used as base code to compute C5 from C1, C2, C3, and C4.
This procedure requires downloading β1 subsymbols from each retired node and β2 subsymbols from each unchanged node. Additionally, rF α network bandwidth is required to write the new nodes. Thus,
the total network bandwidth of conversion is:

γ = λI = λI

rI β1 + kI β2 + rF α rIα + kI 1 − rI
rF

+ rF α

which matches Theorem 4. Now we show a concrete example of our construction.

Example 1 (Bandwidth-optimal conversion in the merge regime). Suppose we want to construct a

bandwidth-optimal (5, 4; 10, 8) convertible code over a ﬁnite ﬁeld Fq (assume that q is sufﬁciently large).

As a base code, we use a punctured access-optimal (6, 4; 10, 8) convertible code. Thus, CI is a [6, 4]

code, CF is a [10, 8] code, and CI is a [5, 4] code, all derived from the chosen access-optimal convertible

code

as

described

in

the

construction

above.

Let

p

I 1

,

p

I 2

∈

Fq4×1

be

the

encoding

vectors

for

the

parities

of

CI

,

and

p

F 1

,

p

F 2

∈

F8q×1

be

the

encoding

vector

for

the

parities

of

CF

.

Since α = 2, we construct a [5, 4, 2] initial vector code CI and a [10, 8, 2] ﬁnal vector code CF .

Let a = (a1, . . . , a8) and b = (b1, . . . , b8). Figure 4 shows the resulting piggybacked codes encoding submessages a(1) = (a1, . . . , a4), a(2) = (a5, . . . , a8), b(1) = (b1, . . . , b4), b(2) = (b5, . . . , b8) ∈ F1q×4.

August 31, 2020

DRAFT

16

During conversion, only 12 subsymbols need to be downloaded: b(1), b(2) and all the parity symbols from both codewords. From these subsymbols, we can recover the piggyback terms a(1)pI2 and a(2)pI2, and then compute b(1)pI2 and b(2)pI2 in order to reconstruct the second parity symbol of CI . Finally, we use a(i)pI1, b(i)pI1, a(i)pI2, b(i)pI2 for i ∈ {1, 2} with the conversion procedure from the access-optimal convertible code to compute the base code symbols a pF1 , a pF2 , b pF1 and b pF2 of the new nodes.
The default approach would require one to download 16 subsymbols in total from the initial nodes.
Both approaches require downloading 4 subsymbols in total from the coordinator node to the new nodes. Thus, the proposed construction leads to 20% reduction in conversion bandwidth as compared to the
default approach of reencoding.

B. Convertible codes with bandwidth-optimal conversion for multiple ﬁnal parameters

In practice, the ﬁnal parameters nF , kF might depend on observations made after the initial encoding of the data and hence they may be unknown at code construction time. In particular, for a (nI , kI ; nF , ςkI ) convertible code in the merge regime this means that the values of λI = ς and rF = (nF − kF )

are unknown.

To ameliorate this problem, we now present convertible codes which support bandwidth-optimal

conversion simultaneously for multiple possible values of the ﬁnal parameters. Recall property (4) of

the access-optimal base code which we reviewed in Section II-B: when constructed with a given value of λI = ς and rF = r, the initial [nI , kI ] code is (nF , kF )-access-optimally convertible for all kF = ς kI and nF = kF + r such that 1 ≤ ς ≤ ς and 1 ≤ r ≤ r.
1) Supporting multiple values of λI : The construction from Section V for some particular value of λI = ς, natively supports bandwidth-optimal conversion for any λI = ς < ς. This is a consequence

of property (4) above, and can be done easily by considering one or multiple of the initial codewords

as consisting of zeroes only, and ignoring them during conversion. From Theorem 4, it is easy to see

that this modiﬁed conversion procedure achieves optimal network bandwidth cost for the new parameter λI = ς .
2) Supporting multiple values of rF : We break this scenario into two cases: Case 1 (supporting rF ≤ rI ): due to property (4) above, the base code used in the construction from Section V supports access-optimal conversion for any value of rF = r such that r ≤ rI . Using this property, one can achieve bandwidth optimality for any r ≤ rI by simply using the access-optimal

conversion on each of the α instances of the base code independently. The only difference is that some of

the instances might have piggybacks, which can be simply ignored. The ﬁnal code might still have these piggybacks, however they will still satisfy the property that the piggybacks in instance i (2 ≤ i ≤ α) only depend on data from instances {1, . . . , (i − 1)}. Thus, the ﬁnal code will have the MDS property

and the desired parameters.

Case 2 (supporting rF > rI ): for supporting multiple values of rF ∈ {r1, r2, . . . , rs} such that ri > rI

(i ∈ [s]), we start with an access-optimal convertible code having rF = maxi ri. Then we repeat the

piggybacking step of the construction (see Section V-A) for each ri, using the resulting code from step

i (with the punctured symbols from CI added back) as a base code for step (i + 1). Therefore, the

resulting code will have α =

s i=1

ri.

Since

the

piggybacking

step

will

preserve

the

MDS

property

of

its base code, and the initial code used in the ﬁrst piggyback step is MDS, it is clear that the initial

code resulting from the last piggybacking step will also be MDS. Conversion for one of the supported

rF = ri is performed as described in Section V-A on each of the additional instances created by steps

(i + 1), . . . , s (i.e.

s i

=(i+1)

ri

in total). As before, some of these instances after conversion will have

piggybacks, which can be simply ignored, as the resulting code will continue to have the property that

piggybacks from a given instance only depend on data from earlier instances.

Example 2 (bandwidth-optimal conversion for multiple ﬁnal parameters). In this example, we will extend the (5, 4; 10, 8) convertible code from Example 1 (rF = 2) to construct a code which additionally supports

August 31, 2020

DRAFT

17

a1 ...
a4
a(1) pI1

b1 ...
b4
b(1)pI1 + a(1)pI2

initial codeword 1 (CI )

c1 ...
c4
c(1)pI1 + a(1)pI2

d1 ...
d4
d(1)pI1 + c(1)pI2 + b(1)pI2

e1 ...
e4
e(1)pI1 + a(1)pI3

f1 ...
f4
f (1)pI1 + e(1)pI2 + b(1)pI3

a1 ...
a8
apF1 apF2

b1 ...
b8
bpF1 bpF2

ﬁnal codeword (rF = 2)

cpF1

c1 ...
c8
+ a(1)pI2 + a(2)pI2 cpF2

d1 ...
d8
dpF1 dpF2

e1

f1

... ...

e8

f8

epF1 + a(1)pI3 + a(2)pI3 fpF1

epF2

fpF2

a1 ...
a8
apF1 apF2 apF3

ﬁnal codeword (rF = 3)

b1 ...
b8
bpF1 + a(1)pI2 + a(2)pI2 bpF2 bpF3

c1 ...
c8
cpF1 cpF2 cpF3

d1 ...
d8
dpF1 dpF2 dpF3

e1 f1 ... ...
e8 f8
epF1 fpF1 epF2 fpF2 epF3 fpF3

Fig. 5: Example of a [5, 4] MDS code that supports bandwidth-optimal conversion to multiple ﬁnal codes (only one initial stripe is shown). This code supports bandwidth-optimal conversion to a [8 + r, 8] MDS code for r = 1, 2, 3. Text color is used in the initial codeword to denote piggybacks from different piggybacking steps. In the possible ﬁnal codewords, text color is used to denote base code symbols which are directly computed from the corresponding piggybacks, or to denote leftover piggybacks which were not used during conversion.

bandwidth-optimal conversion to an [11, 8] MDS code (rF = 3). Figure 5 shows one initial codeword of the new initial vector code, which has α = 2·3 = 6. Here a(1) = (a1, . . . , a4), a(2) = (a5, . . . , a8) ∈ F1q×4, a = (a1, . . . , a8) ∈ F1q×8, and similarly for b, . . . , f . The vectors pIi ∈ Fq4×1 are the encoding vectors of the initial code CI and pFi ∈ F8q×1 are encoding vectors of the ﬁnal code CF (i ∈ {1, 2, 3}). Since the maximum supported rF is 3, we start with an access-optimal (7, 4; 11, 8) convertible code. Thus, CI is a [7, 4] code, CF is a [11, 8] code, and CI is a [5, 4] code. In the ﬁrst round of piggybacking we consider rF = 2, which yields the code shown in Example 1. In the second round of piggybacking we consider rF = 3 and piggyback the code resulting from the ﬁrst round, which yields the code shown in Figure 5. Conversion for rF = 1 proceeds by simply downloading the contents of the single parity node and using the access-optimal conversion procedure. Conversion for rF = 2 proceeds by treating this code
as three instances of the code from Example 1 and performing conversion for each one independently. Conversion for rF = 3 proceeds by treating this code as a vector code with α = 3 and base ﬁeld Fq2
(i.e. each element is a vector over Fq of length 2).
Remark 5 (Field size requirement). The ﬁeld size requirement for Fq of the constructions presented in
this section is given by the ﬁeld size requirement of the base code used. The currently lowest known ﬁeld
size requirement for an explicit construction of systematic linear access-optimal convertible codes in the merge regime is given by [6]. In general, this requirement is roughly q ≥ 2ς(nI)3. When rF ≤ rI − ς + 1, the requirement can be signiﬁcantly reduced to q ≥ kI rI . And when rF ≤ rI/ς , the requirement can

August 31, 2020

DRAFT

18

co(nrvelerastiiovne sbaavnidngwisditnh)

1.0

r I = 0.1

r I = 0.3

0.8

r I = 0.5 rI 1

0.6

0.4

0.2

0.0 0.0 0.2 0.4 r F 0.6 0.8 1.0

Fig. 6: Achievable savings in conversion bandwidth by bandwidth-optimal convertible codes in comparison to the default approach to conversion. Here rI = rI /kI and rF = rF /kI are the initial and ﬁnal
redundancies, divided by the initial code dimension. Each curve shows the relative savings for a ﬁxed value of rI , as rF varies. Solid lines indicate bandwidth-optimal convertible codes, and dashed lines indicate access-optimal convertible codes. Notice that each curve overlaps with the red curve (rI ≥ 1) in the range rF ∈ (0, rI ].

be further reduced to q ≥ max{nI , nF }.
VI. BANDWIDTH SAVINGS OF BANDWIDTH-OPTIMAL CONVERTIBLE CODES
In this section, we show the amount of savings in bandwidth that can be obtained by using bandwidthoptimal convertible codes in the merge regime, relative to the default approach to conversion. We present the amount of savings in terms of two ratios:
rI = (rI/kI) and rF = (rF/kI),
i.e. the initial and ﬁnal amount of “redundancy” relative to the initial dimension of the code. For simplicity, we only consider the bandwidth cost of communication from nodes to the coordinator node, since the bandwidth cost of communication from the coordinator node to new nodes is ﬁxed for stable convertible codes (speciﬁcally, it is equal to αrF ). Thus, the bandwidth cost of the default approach is always ςkI α. Figure 6 shows the relative savings, i.e. the ratio between the bandwidth cost of optimal conversion and the bandwidth cost of conversion under the default approach, for ﬁxed values of rI ∈ (0, ∞) and varying rF ∈ (0, ∞).
Each curve shown in Figure 6 can be divided into three regions, depending on the value of rF : • Region 0 < rF ≤ rI and rF < 1: this implies that rF ≤ rI , so by Lemma 2 the conversion
bandwidth is ςrF α, and the relative savings are:
ρ = 1 − ςrF α = 1 − rF . ς kI α
This region corresponds to Regime 2, and in this region access-optimal convertible codes are also bandwidth-optimal. This region of the curve is linear, and the amount of savings is not affected by rI .

August 31, 2020

DRAFT

19

• Region rI < rF < 1: this implies that rI ≤ rF ≤ kI , and by Lemma 3 the conversion bandwidth is ςα(rI + kI (1 − rI /rF )), and the relative savings are:

ςα rI + kI 1 − rrFI

ρ=1−

ς kI α

= rI 1 − 1 . rF

This corresponds to Regime 1, where access-optimal convertible codes provide no conversion bandwidth savings. Thus bandwidth-optimal convertible codes provide substantial savings in conversion bandwidth in this regime, compared to access-optimal convertible codes. • Region rF ≥ 1: this implies that rF ≥ kI and by Lemma 2 a bandwidth of ςkI α is required. Thus no savings in bandwidth cost are possible in this region.
Thus, bandwidth-optimal convertible codes allow for savings in network bandwidth on a much broader region relative to access-optimal convertible codes.

VII. CONCLUSIONS AND FUTURE DIRECTIONS
In this paper, we initiated a study on the network bandwidth cost of convertible codes. We showed that the conversion problem can be effectively modeled using network information ﬂow to obtain lower bounds on conversion bandwidth. Using the bounds derived, we showed that for the merge regime accessoptimal convertible codes are also bandwidth-optimal when rI ≥ rF (Regime 1) and that there is room for reducing conversion bandwidth when rI < rF (Regime 2). We proposed an explicit construction which achieves the optimal conversion bandwidth for all parameters in the merge regime. Finally, we showed that bandwidth-optimal convertible codes can achieve substantial savings in conversion bandwidth over the default approach and access-optimal convertible codes.
This work leads to several open questions and challenges. The main challenge is to extend the conversion bandwidth lower bounds and bandwidth-optimal constructions to encompass all possible parameter values (i.e. the general regime). Another important challenge is characterizing the optimal value of α, especially in the case of multiple possible ﬁnal parameter values, where α can become very large when using the construction proposed in this paper. Yet another open challenge is lowering the ﬁeld size requirement of bandwidth-optimal convertible code constructions, as well as deriving lower bounds for their ﬁeld size requirements.

REFERENCES
[1] S. Ghemawat, H. Gobioff, and S. Leung, “The Google ﬁle system,” in Proceedings of the 19th ACM Symposium on Operating Systems Principles 2003, SOSP 2003, Bolton Landing, NY, USA, October 19-22, 2003 (M. L. Scott and L. L. Peterson, eds.), pp. 29–43, ACM, 2003.
[2] D. Borthakur, R. Schmidt, R. Vadali, S. Chen, and P. Kling, “HDFS RAID - Facebook.” Available on: http://www.slideshare. net/ydn/hdfs-raid-facebook. Accessed: 2019-07-23.
[3] C. Huang, H. Simitci, Y. Xu, A. Ogus, B. Calder, P. Gopalan, J. Li, and S. Yekhanin, “Erasure coding in Windows Azure storage,” in 2012 USENIX Annual Technical Conference, Boston, MA, USA, June 13-15, 2012 (G. Heiser and W. C. Hsieh, eds.), pp. 15–26, USENIX Association, 2012.
[4] Apache Software Foundation, “Apache hadoop: HDFS erasure coding.” Available on: https://hadoop.apache.org/docs/r3.0. 0/hadoop-project-dist/hadoop-hdfs/HDFSErasureCoding.html. Accessed: 2019-07-23.
[5] S. Kadekodi, K. V. Rashmi, and G. R. Ganger, “Cluster storage systems gotta have HeART: improving storage efﬁciency by exploiting disk-reliability heterogeneity,” in 17th USENIX Conference on File and Storage Technologies, FAST 2019, Boston, MA, February 25-28, 2019 (A. Merchant and H. Weatherspoon, eds.), pp. 345–358, USENIX Association, 2019.
[6] F. Maturana and K. V. Rashmi, “Convertible codes: new class of codes for efﬁcient conversion of coded data in distributed storage,” in 11th Innovations in Theoretical Computer Science Conference, ITCS 2020, January 12-14, 2020, Seattle, Washington, USA (T. Vidick, ed.), vol. 151 of LIPIcs, pp. 66:1–66:26, Schloss Dagstuhl - Leibniz-Zentrum fu¨r Informatik, 2020.
[7] F. Maturana, V. S. C. Mukka, and K. V. Rashmi, “Access-optimal linear MDS convertible codes for all parameters,” in IEEE International Symposium on Information Theory, ISIT 2020, Los Angeles, California, USA, June 21-26, 2020, 2020.
[8] A. G. Dimakis, B. Godfrey, Y. Wu, M. J. Wainwright, and K. Ramchandran, “Network coding for distributed storage systems,” IEEE Transactions on Information Theory, vol. 56, no. 9, pp. 4539–4551, 2010.

August 31, 2020

DRAFT

20
[9] K. V. Rashmi, N. B. Shah, and K. Ramchandran, “A piggybacking design framework for read-and download-efﬁcient distributed storage codes,” IEEE Transactions on Information Theory, vol. 63, no. 9, pp. 5802–5820, 2017.
[10] R. Ahlswede, N. Cai, S. R. Li, and R. W. Yeung, “Network information ﬂow,” IEEE Transactions on Information Theory, vol. 46, no. 4, pp. 1204–1216, 2000.
[11] S. R. Li, R. W. Yeung, and N. Cai, “Linear network coding,” IEEE Transactions on Information Theory, vol. 49, no. 2, pp. 371–381, 2003.
[12] R. Koetter and M. Me´dard, “An algebraic approach to network coding,” IEEE/ACM Transactions on Networking, vol. 11, no. 5, pp. 782–795, 2003.
[13] T. Ho, M. Me´dard, R. Koetter, D. R. Karger, M. Effros, J. Shi, and B. Leong, “A random linear network coding approach to multicast,” IEEE Transactions on Information Theory, vol. 52, no. 10, pp. 4413–4430, 2006.
[14] P. Sanders, S. Egner, and L. M. G. M. Tolhuizen, “Polynomial time algorithms for network information ﬂow,” in SPAA 2003: Proceedings of the Fifteenth Annual ACM Symposium on Parallelism in Algorithms and Architectures, June 7-9, 2003, San Diego, California, USA (part of FCRC 2003) (A. L. Rosenberg and F. M. auf der Heide, eds.), pp. 286–294, ACM, 2003.
[15] S. Jaggi, P. Sanders, P. A. Chou, M. Effros, S. Egner, K. Jain, and L. M. G. M. Tolhuizen, “Polynomial time algorithms for multicast network code construction,” IEEE Transactions on Information Theory, vol. 51, no. 6, pp. 1973–1982, 2005.
[16] R. W. Yeung, A First Course in Information Theory. Boston, MA: Springer US, 2002. [17] K. V. Rashmi, N. B. Shah, and K. Ramchandran, “A piggybacking design framework for read-and download-efﬁcient
distributed storage codes,” in 2013 IEEE International Symposium on Information Theory, ISIT 2013, Istanbul, Turkey, July 7-12, 2013, pp. 331–335, IEEE, 2013. [18] M. Xia, M. Saxena, M. Blaum, and D. Pease, “A tale of two erasure codes in HDFS,” in Proceedings of the 13th USENIX Conference on File and Storage Technologies, FAST 2015, Santa Clara, CA, USA, February 16-19, 2015 (J. Schindler and E. Zadok, eds.), pp. 213–226, USENIX Association, 2015. [19] X. Su, X. Zhong, X. Fan, and J. Li, “Local re-encoding for coded matrix multiplication,” in IEEE International Symposium on Information Theory, ISIT 2020, Los Angeles, California, USA, June 21-26, 2020, 2020. [20] K. V. Rashmi, N. B. Shah, and P. V. Kumar, “Optimal exact-regenerating codes for distributed storage at the MSR and MBR points via a product-matrix construction,” IEEE Transactions on Information Theory, vol. 57, no. 8, pp. 5227–5239, 2011. [21] N. B. Shah, K. V. Rashmi, P. V. Kumar, and K. Ramchandran, “Distributed storage codes with repair-by-transfer and nonachievability of interior points on the storage-bandwidth tradeoff,” IEEE Transactions on Information Theory, vol. 58, no. 3, pp. 1837–1852, 2011. [22] N. B. Shah, K. V. Rashmi, P. V. Kumar, and K. Ramchandran, “Interference alignment in regenerating codes for distributed storage: necessity and code constructions,” IEEE Transactions on Information Theory, vol. 58, no. 4, pp. 2134–2158, 2012. [23] C. Suh and K. Ramchandran, “Exact-repair MDS code construction using interference alignment,” IEEE Transactions on Information Theory, vol. 57, no. 3, pp. 1425–1442, 2011. [24] V. R. Cadambe, C. Huang, J. Li, and S. Mehrotra, “Polynomial length MDS codes with optimal repair in distributed storage,” in Conference Record of the Forty Fifth Asilomar Conference on Signals, Systems and Computers, ACSCC 2011, Paciﬁc Grove, CA, USA, November 6-9, 2011 (M. B. Matthews, ed.), pp. 1850–1854, IEEE, 2011. [25] Z. Wang, I. Tamo, and J. Bruck, “On codes for optimal rebuilding access,” in 49th Annual Allerton Conference on Communication, Control, and Computing, Allerton 2011, Allerton Park & Retreat Center, Monticello, IL, USA, 28-30 September, 2011, pp. 1374–1381, IEEE, 2011. [26] I. Tamo, Z. Wang, and J. Bruck, “Zigzag codes: MDS array codes with optimal rebuilding,” IEEE Transactions on Information Theory, vol. 59, no. 3, pp. 1597–1616, 2013. [27] D. S. Papailiopoulos, A. G. Dimakis, and V. R. Cadambe, “Repair optimal erasure codes through Hadamard designs,” IEEE Transactions on Information Theory, vol. 59, pp. 3021–3037, May 2013. [28] O. Alrabiah and V. Guruswami, “An exponential lower bound on the sub-packetization of MSR codes,” in Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing, STOC 2019, Phoenix, AZ, USA, June 23-26, 2019 (M. Charikar and E. Cohen, eds.), pp. 979–985, ACM, 2019. [29] S. B. Balaji and P. V. Kumar, “A tight lower bound on the sub-packetization level of optimal-access MSR and MDS codes,” in 2018 IEEE International Symposium on Information Theory, ISIT 2018, Vail, CO, USA, June 17-22, 2018, pp. 2381–2385, IEEE, 2018. [30] A. Chowdhury and A. Vardy, “New constructions of MDS codes with asymptotically optimal repair,” in 2018 IEEE International Symposium on Information Theory, ISIT 2018, Vail, CO, USA, June 17-22, 2018, pp. 1944–1948, IEEE, 2018. [31] K. Mahdaviani, S. Mohajer, and A. Khisti, “Product matrix MSR codes with bandwidth adaptive exact repair,” IEEE Transactions on Information Theory, vol. 64, no. 4, pp. 3121–3135, 2018. [32] B. Sasidharan, M. Vajha, and P. V. Kumar, “An explicit, coupled-layer construction of a high-rate MSR code with low sub-packetization level, small ﬁeld size and d < (n − 1),” in 2017 IEEE International Symposium on Information Theory, ISIT 2017, Aachen, Germany, June 25-30, 2017, pp. 2048–2052, IEEE, 2017. [33] M. Ye and A. Barg, “Explicit constructions of high-rate MDS array codes with optimal repair bandwidth,” IEEE Transactions on Information Theory, vol. 63, no. 4, pp. 2001–2014, 2017.

August 31, 2020

DRAFT

21
[34] A. S. Rawat, I. Tamo, V. Guruswami, and K. Efremenko, “MDS code constructions with small sub-packetization and near-optimal repair bandwidth,” IEEE Transactions on Information Theory, vol. 64, no. 10, pp. 6506–6525, 2018.
[35] S. Goparaju, A. Fazeli, and A. Vardy, “Minimum storage regenerating codes for all parameters,” IEEE Transactions on Information Theory, vol. 63, no. 10, pp. 6318–6328, 2017.
[36] K. V. Rashmi, N. B. Shah, D. Gu, H. Kuang, D. Borthakur, and K. Ramchandran, “A ”hitchhiker’s” guide to fast and efﬁcient data reconstruction in erasure-coded data centers,” in ACM SIGCOMM 2014 Conference, SIGCOMM’14, Chicago, IL, USA, August 17-22, 2014 (F. E. Bustamante, Y. C. Hu, A. Krishnamurthy, and S. Ratnasamy, eds.), pp. 331–342, ACM, 2014.
[37] I. Tamo, Z. Wang, and J. Bruck, “Access versus bandwidth in codes for storage,” IEEE Transactions on Information Theory, vol. 60, no. 4, pp. 2028–2037, 2014.
[38] K. V. Rashmi, N. B. Shah, D. Gu, H. Kuang, D. Borthakur, and K. Ramchandran, “A solution to the network challenges of data recovery in erasure-coded distributed storage systems: A study on the Facebook warehouse cluster,” in 5th USENIX Workshop on Hot Topics in Storage and File Systems, HotStorage’13, San Jose, CA, USA, June 27-28, 2013 (A. Gulati, ed.), USENIX Association, 2013.
[39] V. R. Cadambe, S. A. Jafar, H. Maleki, K. Ramchandran, and C. Suh, “Asymptotic interference alignment for optimal repair of MDS codes in distributed storage,” IEEE Transactions on Information Theory, vol. 59, no. 5, pp. 2974–2987, 2013.
[40] Z. Wang, I. Tamo, and J. Bruck, “Long MDS codes for optimal repair bandwidth,” in 2012 IEEE International Symposium on Information Theory, ISIT 2012, Cambridge, MA, USA, July 1-6, 2012, pp. 1182–1186, IEEE, 2012.
[41] K. W. Shum, “Cooperative regenerating codes for distributed storage systems,” in Proceedings of IEEE International Conference on Communications, ICC 2011, Kyoto, Japan, 5-9 June, 2011, pp. 1–5, IEEE, 2011.
[42] K. V. Rashmi, N. B. Shah, and P. V. Kumar, “Enabling node repair in any erasure code for distributed storage,” in 2011 IEEE International Symposium on Information Theory Proceedings, ISIT 2011, St. Petersburg, Russia, July 31 - August 5, 2011 (A. Kuleshov, V. M. Blinovsky, and A. Ephremides, eds.), pp. 1235–1239, IEEE, 2011.
[43] N. B. Shah, K. V. Rashmi, and P. V. Kumar, “A ﬂexible class of regenerating codes for distributed storage,” in IEEE International Symposium on Information Theory, ISIT 2010, June 13-18, 2010, Austin, Texas, USA, Proceedings, pp. 1943– 1947, IEEE, 2010.
[44] M. Ye and A. Barg, “Explicit constructions of MDS array codes and RS codes with optimal repair bandwidth,” in IEEE International Symposium on Information Theory, ISIT 2016, Barcelona, Spain, July 10-15, 2016, pp. 1202–1206, IEEE, 2016.
[45] H. Dau, I. M. Duursma, H. M. Kiah, and O. Milenkovic, “Repairing Reed-Solomon codes with multiple erasures,” IEEE Transactions on Information Theory, vol. 64, no. 10, pp. 6567–6582, 2018.
[46] V. Guruswami and M. Wootters, “Repairing Reed-Solomon codes,” IEEE Transactions on Information Theory, vol. 63, no. 9, pp. 5684–5698, 2017.
[47] J. Li, X. Tang, and C. Tian, “A generic transformation to enable optimal repair in MDS codes for distributed storage systems,” IEEE Transactions on Information Theory, vol. 64, no. 9, pp. 6257–6267, 2018.
[48] J. Mardia, B. Bartan, and M. Wootters, “Repairing multiple failures for scalar MDS codes,” IEEE Transactions on Information Theory, vol. 65, no. 5, pp. 2661–2672, 2019.
[49] K. Shanmugam, D. S. Papailiopoulos, A. G. Dimakis, and G. Caire, “A repair framework for scalar MDS codes,” IEEE Journal on Selected Areas in Communications, vol. 32, no. 5, pp. 998–1007, 2014.
[50] I. Tamo, M. Ye, and A. Barg, “Optimal repair of Reed-Solomon codes: achieving the cut-set bound,” in 58th IEEE Annual Symposium on Foundations of Computer Science, FOCS 2017, Berkeley, CA, USA, October 15-17, 2017 (C. Umans, ed.), pp. 216–227, IEEE Computer Society, 2017.
[51] G. M. Kamath, N. Prakash, V. Lalitha, and P. V. Kumar, “Codes with local regeneration and erasure correction,” IEEE Transactions on Information Theory, vol. 60, no. 8, pp. 4637–4660, 2014.
[52] S. Mousavi, T. Zhou, and C. Tian, “Delayed parity generation in MDS storage codes,” in 2018 IEEE International Symposium on Information Theory, ISIT 2018, Vail, CO, USA, June 17-22, 2018, pp. 1889–1893, IEEE, 2018.
[53] P. Gopalan, C. Huang, H. Simitci, and S. Yekhanin, “On the locality of codeword symbols,” IEEE Transactions on Information Theory, vol. 58, no. 11, pp. 6925–6934, 2012.
[54] P. Gopalan, C. Huang, B. Jenkins, and S. Yekhanin, “Explicit maximally recoverable codes with locality,” IEEE Transactions on Information Theory, vol. 60, no. 9, pp. 5245–5256, 2014.
[55] D. S. Papailiopoulos and A. G. Dimakis, “Locally repairable codes,” IEEE Transactions on Information Theory, vol. 60, no. 10, pp. 5843–5855, 2014.
[56] I. Tamo and A. Barg, “A family of optimal locally recoverable codes,” IEEE Transactions on Information Theory, vol. 60, no. 8, pp. 4661–4676, 2014.
[57] V. R. Cadambe and A. Mazumdar, “Bounds on the size of locally recoverable codes,” IEEE Transactions on Information Theory, vol. 61, no. 11, pp. 5787–5794, 2015.
[58] I. Tamo, D. S. Papailiopoulos, and A. G. Dimakis, “Optimal locally repairable codes and connections to matroid theory,” IEEE Transactions on Information Theory, vol. 62, no. 12, pp. 6661–6671, 2016.
[59] A. Barg, K. Haymaker, E. W. Howe, G. L. Matthews, and A. Va´rilly-Alvarado, “Locally recoverable codes from algebraic curves and surfaces,” in Algebraic Geometry for Coding Theory and Cryptography (E. W. Howe, K. E. Lauter, and J. L. Walker, eds.), (Cham), pp. 95–127, Springer International Publishing, 2017.

August 31, 2020

DRAFT

22
[60] S. L. Frank-Fischer, V. Guruswami, and M. Wootters, “Locality via partially lifted codes,” in Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques, APPROX/RANDOM 2017, August 16-18, 2017, Berkeley, CA, USA (K. Jansen, J. D. P. Rolim, D. Williamson, and S. S. Vempala, eds.), vol. 81(43) of LIPIcs, pp. 1–17, Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, 2017.
[61] A. Mazumdar, “Capacity of locally recoverable codes,” in IEEE Information Theory Workshop, ITW 2018, Guangzhou, China, November 25-29, 2018, pp. 1–5, IEEE, 2018.
[62] V. Guruswami, C. Xing, and C. Yuan, “How long can optimal locally repairable codes be?,” IEEE Transactions on Information Theory, vol. 65, no. 6, pp. 3662–3670, 2019.
[63] S. Gopi, V. Guruswami, and S. Yekhanin, “Maximally recoverable LRCs: A ﬁeld size lower bound and constructions for few heavy parities,” in Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2019, San Diego, California, USA, January 6-9, 2019 (T. M. Chan, ed.), pp. 2154–2170, SIAM, 2019.
[64] N. Prakash, G. M. Kamath, V. Lalitha, and P. V. Kumar, “Optimal linear codes with a local-error-correction property,” in Proceedings of the 2012 IEEE International Symposium on Information Theory, ISIT 2012, Cambridge, MA, USA, July 1-6, 2012, pp. 2776–2780, IEEE, 2012.
[65] G. Zhang, W. Zheng, and J. Shu, “ALV: A new data redistribution approach to RAID-5 scaling,” IEEE Transactions on Computers, vol. 59, no. 3, pp. 345–357, 2010.
[66] W. Zheng and G. Zhang, “Fastscale: accelerate RAID scaling by minimizing data migration,” in 9th USENIX Conference on File and Storage Technologies, San Jose, CA, USA, February 15-17, 2011 (G. R. Ganger and J. Wilkes, eds.), pp. 149–161, USENIX, 2011.
[67] C. Wu and X. He, “GSR: A global stripe-based redistribution approach to accelerate RAID-5 scaling,” in 41st International Conference on Parallel Processing, ICPP 2012, Pittsburgh, PA, USA, September 10-13, 2012, pp. 460–469, IEEE Computer Society, 2012.
[68] G. Zhang, W. Zheng, and K. Li, “Rethinking RAID-5 data layout for better scalability,” IEEE Transactions on Computers, vol. 63, no. 11, pp. 2816–2828, 2014.
[69] J. Huang, X. Liang, X. Qin, P. Xie, and C. Xie, “Scale-RS: an efﬁcient scaling scheme for RS-coded storage clusters,” IEEE Transactions on Parallel and Distributed Systems, vol. 26, no. 6, pp. 1704–1717, 2015.
[70] S. Wu, Y. Xu, Y. Li, and Z. Yang, “I/O-efﬁcient scaling schemes for distributed storage systems with CRS codes,” IEEE Transactions on Parallel and Distributed Systems, vol. 27, no. 9, pp. 2639–2652, 2016.
[71] X. Zhang, Y. Hu, P. P. C. Lee, and P. Zhou, “Toward optimal storage scaling via network coding: from theory to practice,” in 2018 IEEE Conference on Computer Communications, INFOCOM 2018, Honolulu, HI, USA, April 16-19, 2018, pp. 1808– 1816, IEEE, 2018.
[72] Y. Hu, X. Zhang, P. P. C. Lee, and P. Zhou, “Generalized optimal storage scaling via network coding,” in 2018 IEEE International Symposium on Information Theory, ISIT 2018, Vail, CO, USA, June 17-22, 2018, pp. 956–960, IEEE, 2018.
[73] X. Zhang and Y. Hu, “Efﬁcient storage scaling for MBR and MSR codes,” IEEE Access, vol. 8, pp. 78992–79002, 2020. [74] B. K. Rai, V. Dhoorjati, L. Saini, and A. K. Jha, “On adaptive distributed storage systems,” in IEEE International Symposium
on Information Theory, ISIT 2015, Hong Kong, China, June 14-19, 2015, pp. 1482–1486, IEEE, 2015. [75] B. K. Rai, “On adaptive (functional MSR code based) distributed storage systems,” in 2015 International Symposium on
Network Coding, NetCod 2015, Sydney, Australia, June 22-24, 2015, pp. 46–50, IEEE, 2015. [76] S. Wu, Z. Shen, and P. P. C. Lee, “On the optimal repair-scaling trade-off in locally repairable codes,” in 2020 IEEE
Conference on Computer Communications, INFOCOM 2020, Virtual Conference, July 6-9, 2020, IEEE, 2020.

August 31, 2020

DRAFT

