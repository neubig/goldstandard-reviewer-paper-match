Time Waits for No One! Analysis and Challenges of Temporal Misalignment
Kelvin Luu1 Daniel Khashabi2 Suchin Gururangan1 Karishma Mandyam1 Noah A. Smith1,2
1University of Washington 2Allen Institute for AI {kellu,sg01,krm28,nasmith}@cs.washington.edu,
danielk@allenai.org

arXiv:2111.07408v1 [cs.CL] 14 Nov 2021

Abstract
When an NLP model is trained on text data from one time period and tested or deployed on data from another, the resulting temporal misalignment can degrade end-task performance. In this work, we establish a suite of eight diverse tasks across different domains (social media, science papers, news, and reviews) and periods of time (spanning ﬁve years or more) to quantify the effects of temporal misalignment. Our study is focused on the ubiquitous setting where a pretrained model is optionally adapted through continued domainspeciﬁc pretraining, followed by task-speciﬁc ﬁnetuning. We establish a suite of tasks across multiple domains to study temporal misalignment in modern NLP systems. We ﬁnd stronger effects of temporal misalignment on task performance than have been previously reported. We also ﬁnd that, while temporal adaptation through continued pretraining can help, these gains are small compared to task-speciﬁc ﬁnetuning on data from the target time period. Our ﬁndings motivate continued research to improve temporal robustness of NLP models.1
1 Introduction
Changes in the ways a language is used over time are widely attested (Labov, 1994; Altmann et al., 2009; Eisenstein et al., 2014); how these changes will affect NLP systems built from text corpora, and in particular their long-term performance, is not as well understood.
This paper focuses on temporal misalignment, i.e., where training and evaluation datasets are drawn from different periods of time. In today’s pretraining-ﬁnetuning paradigm, this misalignment can affect a pretrained language model—a situation that has received recent attention (Jaidka et al., 2018; Lazaridou et al., 2021; Peters et al., 2018; Raffel et al., 2020; Röttger and Pierrehumbert,
1https://github.com/Kel-Lu/ time-waits-for-no-one

2021)—or the ﬁnetuned task model, or both. We suspect that the effects of temporal misalignment will vary depending on the genre or domain of the task’s text, the nature of that task or application, and the speciﬁc time periods.
We focus primarily on measuring the extent of temporal misalignment on task performance. We consider eight tasks, each with datasets that span at least ﬁve years (§2.4), ranging from summarization to entity typing, a subproblem of entity recognition (Grishman and Borthwick, 1999). Notably, these task datasets span four different domains: social media, scientiﬁc articles, news, and reviews. We introduce an easily interpretable metric that summarizes the rate at which task performance degrades as function of time.
Our research questions are:
(Q1) how does temporal misalignment affect downstream tasks over time?
(Q2) how does sensitivity to temporal misalignment vary with text domain and task?
(Q3) how does temporal misalignment affect language models across domains and spans of time?
(Q4) how effective is temporal adaptation, or additional pretraining on a target year, in mitigating temporal misalignment?
We ﬁnd that temporal misalignment affects both language model generalization and task performance. We ﬁnd considerable variation in degradation across text domains (§3.2) and tasks (§3.1). Over 5 years, classiﬁers’ F1 score can deteriorate as much as 40 points (political afﬁliation in Twitter) or as little as 1 point (Yelp review ratings). Two distinct tasks deﬁned on the same domain can show different levels of degradation over time.
We explore domain adaptation of a language model, using temporally selected (unannotated) data, as a way to curtail temporal misalignment (Röttger and Pierrehumbert, 2021). We ﬁnd that

this does not offer much beneﬁt, especially relative to performance that can be achieved by ﬁnetuning on temporally suitable data (i.e., from the same time period as the test data). We conclude that temporal adaptation should not be seen as a substitute for ﬁnding temporally aligned labeled data.
The evidence and benchmarks we offer motivate careful attention to temporal misalignment in many applications of NLP models, and further research on solutions to this problem.
Contributions. To facilitate the study of temporal misalignment phenomenon on downstream applications, we compile a suite of eight diverse tasks across four important language domains. We deﬁne an interpretable metric that summarizes temporal misalignment of a model on a task with timestamped data. Our experiments reveal key factors in how temporal misalignment affects NLP model performance.
2 Methodology Overview
We begin by deﬁning the scope of our study.
2.1 Learning Pipeline
We consider a process for building an NLP model that is in widespread use by the research community, illustrated in Fig. 1. First, a (neural network) language model (LM) is pretrained on a large text collection that is not necessarily selected for topical or temporal proximity to the text of the target application (our focus is on GPT-2; Brown et al., 2020). Second, the LM is optionally adapted by continued training on a collection strategically curated for closer proximity to the target (Beltagy et al., 2019); this stage is often referred to as domain-adaptive pretraining (DAPT; Gururangan et al., 2020). Finally, the model is ﬁnetuned to minimize a taskspeciﬁc loss, using labeled data representative of what the model is expected to be exposed to in testing or deployment.

pretraining (PT) from scratch

domain/temporal adaptation (DAPT)

finetuning on task-specific
dataset

Figure 1: A typical modeling pipeline in NLP.

We study two ways in which temporal misalignment might affect the pipeline’s performance as well as straightforward ways to mitigate them.

Task Shift and Temporal Finetuning The relationship between text inputs and target outputs may change over time. To the extent that this occurs, annotated datasets used to train NLP systems in the ﬁnetuning stage will become stale over time. Due to this temporal misalignment, performance will degrade after deployment, or any in evaluations that use test data temporally distant from the training data. We seek to quantify this degradation across a range of text domains and tasks.
Language Shift and Temporal Domain Adaptation Changes in language use can cause a pretrained LM, which commonly serves as the backbone for most modern NLP models, to become stale over time (Lazaridou et al., 2021), regardless of the end task. Lazaridou et al. (2021) explored temporal adaptation, continuing LM training on new text data. This is essentially the same procedure as DAPT, where the data is selected by time period. Their work focused on the LM alone, not downstream tasks; we consider both here.
Röttger and Pierrehumbert (2021), the closest to our work, studied temporal adaptation in conjunction to ﬁnetuning for a classiﬁcation task over Reddit data. They conclude that temporal adaptation does not help any more than normal DAPT. We corroborate this work and extend it by studying a wider variety of tasks over a longer span of time periods and thus are better able to draw generalizations from our results.
We believe that the two kinds of shift—task shift and language shift—are difﬁcult to disentangle, and we do not attempt to do so in this work. Instead, we aim to quantify the effect of temporal misalignment on a range of NLP tasks, as well as the beneﬁts of these two strategies.
2.2 Evaluation Methodology
Our experiments are designed to measure the effect of temporal misalignment on task performance. To do so, for each task, we ﬁx a test set within a given time period, Ttest . We vary the time period of the training data, allowing us to interpret differences in performance as a kind of “regret” relative to the performance of a model trained on data temporally aligned with Ttest .2 We consider multiple different test periods for each task. We also seek
2This setup avoids a confound of varying test set difﬁculty that we would encounter if we ﬁxed the model and compared its performance across test datasets from different time periods.

to control the effect of training dataset size. We partition training data into time periods of roughly the same size and always train on a single partition, keeping the training set size of each time period constant within each task. We expect that performance could be improved by accumulating training data across multiple time periods, but that would make it more difﬁcult to achieve our research goal of quantifying the effect of temporal misalignment on performance.
2.3 Quantifying Temporal Degradation
Understanding temporal misalignment requires evaluating a model’s performance across data with a range of different timestamps, which makes it difﬁcult to compare various models in terms of their misalignment. We deﬁne a metric for temporal degradation (TD) which summarizes the overall amount of temporal misalignment on a task as a single value. In high-level terms, the TD score measures the average rate of performance deterioration (of perplexity, F1, or Rouge-L) for each time period of misalignment between the train and evaluation sets. Higher TD scores imply greater levels of performance deterioration due to misalignment.
Let St t indicate the performance a model trained on timestep t data and evaluated on timestep t. We deﬁne D(t t) as:
D(t t) = − (St t − St t) × sign(t − t).
D(t t) is a modiﬁed difference in performance between two models.3 Fig. 2 illustrates D as a function of consecutive training time periods.
We ﬁnd a line of best ﬁt for D(t t) for all t using least-squares regression. The slope of this line is TD(t), the TD score for evaluation time period t. The ﬁnal TD score is the average of the TD(t) across all evaluation time periods t. Further details can be found in Appendix A.
2.4 Domains, Tasks, and Datasets
We describe the eight tasks and four domains used for this study. Three (out of eight) of the tasks are newly deﬁned in this work, and all tasks required nontrivial postprocessing; we will release the corresponding datasets publicly at publication 4We
3Without the modiﬁcation, a task with degradation would have have positive performance gaps both t > t and t > t; the function would not be monotone and the rate of change would be harder to approximate. The modiﬁcation yields a simpler visual understanding of the deviations over time.
4https://github.com/Kel-Lu/ time-waits-for-no-one

Figure 2: An example calculation of the TD score for a particular timestep t (discussed in Section 2.3). The plotted markers represent D(t → t) (y-axis) as a function of train time period t (x-axis). The annotated numbers on each blue dot are the raw evaluation scores St →t, not to be confused with the y values. The red line is the line of best ﬁt and its slope is the TD score for evaluation timestep t. In this example, we would expect to see, on average, 9.09 points of deterioration for each year of misalignment. The ﬁnal TD score is averaged between all evaluation timesteps.
provide examples and detailed statistics in Table 1. For more details, refer to Appendix C.
Domain 1: Twitter Social media platforms like Twitter have been mined to study aspects of language change over time, such as the introduction or diffusion of new words (Eisenstein et al., 2014; Tamburrini et al., 2015; Wang and Goutte, 2017). We collect unlabeled data for domain adaptation by extracting a random selection of 12M tweets, spread semi-uniformly from 2015 till 2020.5 We experiment with two tasks on Twitter data:
Political afﬁliation classiﬁcation (POLIAFF) We collect English tweets dated between 2015 and 2020 from U.S. politicians with a political afﬁliation (Republican or Democrat). We omit any politician who changed parties over this time period or identiﬁed as independent. We consider the downstream task of detecting political afﬁliations, i.e., given a text of a single tweet we predict the political alignment of its author at the time of the tweet. This task can be useful for studies that involve an understanding of ideologies conveyed in text (Lin et al., 2008; Iyyer et al., 2014).
Named entity type classiﬁcation (TWIERC) We use the Twitter NER dataset from Rijhwani and Preo¸tiuc-Pietro (2020). The dataset contains tweets dated from 2014 to 2019, each annotated with the mentions of named entities and their types (Person, Organization, or Location). We consider the task
5Collected via the Twitter API.

Domain Twitter Science
News Food Reviews

Task
political afﬁliation classiﬁcation entity type classiﬁcation
mention type
classiﬁcation
venue classiﬁcation
media frame classiﬁcation
publisher classiﬁcation
summarization
review rating classiﬁcation

Time Range 2015-2019 2014-2019 1980-2016
2009-2020 2009-2016 2009-2016 2009-2016 2013-2019

Size 120k
8k 8k
16k 20k 67k 330k 126k

Example
Input: History will note that Trump didn’t merely ﬁddle while the planet burned but tried to throw the Arctic National W... Output: Democrat (vs Republican)
Input: entity: Finola, tweet: Two 64-year olds enjoying their ﬁrst birthday together in 40+ years. My twin sister, Finola, and I. Output: Person Input: mention: deep Long Short-Term Memory (LSTM) subnetwork, abstract: In this paper, we study the problem of online action detection from the streaming skeleton data .... by leveraging the merits of the deep Long Short-Term Memory (LSTM) subnetwork, the proposed model ... Output: Method Input: Rank K Binary Matrix Factorization (BMF) approximates a binary matrix by the product of two binary matrices of lower rank, K... Output: AAAI (vs ICML) Input: You think you have heard the worst horror a gun in the wrong hands can do, and then this.You think there could not have been anywhere more tragic for it to happen... Output: Gun Control (15 possible frames) Input: A Muslim woman said Sunday that her viral article explaining why she voted for Donald Trump has angered her liberal pals as well as other Muslims. Output: FoxNews (vs NYTimes or WaPost) Input: The Consumer Financial Protection Bureau is demanding PayPal return $15 million to consumers and pay a $10 million ﬁne for ... Output: The CFPB alleges many customers unwittingly signed up for PayPal Credit Input: What a beautiful store and amazing experience! Not only the atmosphere, but the people... Output: 4 (out of 5)

Table 1: The tasks from four domains studied in this paper, with examples. See Section 2.4 for more details.

of typing a given mention, which is a subproblem of named entity recognition.
Domain 2: Scientiﬁc Articles Scientiﬁc research produces vast amounts of text with great potential for language technologies (Wadden et al., 2020; Lo et al., 2020); it is expected to show a great deal of variation over time as ideas and terminology evolve. For adaptation to this domain, we collect unlabeled data from science documents available in Semantic Scholar’s corpus,6 which yields 650k documents, spread over a 30-year period (Ammar et al., 2018). For this domain, we study two tasks:
Mention type classiﬁcation (SCIERC) We use the SciERC dataset from Luan et al. (2018) which contains entity-relation annotations for computer science paper abstracts for a relatively wide range of years (1980s to 2019). We subdivide the annotated data into time periods with roughly equal-sized numbers of papers (1980–1999, 2000–2004, 2005– 2009, 2010–2016). The task is to map a mention of a scientiﬁc concept to a type (Task, Method, Metric, Material, Other-Scientiﬁc-Term, or Generic).
AI venue classiﬁcation (AIC) We also examine temporal misalignment on the task of identifying whether a paper was published in AAAI or ICML. We group the data into roughly equal-sized time periods (2009–2011, 2012–2014, 2015–2017, and 2018–2020). This task is, loosely, a proxy for topic classiﬁcation and author disambiguation applica-
6https://api.semanticscholar.org/ corpus/

tions (Subramanian et al., 2021).

Domain 3: News Articles News articles make up a signiﬁcant part of the data commonly used to train LMs (Dodge et al., 2021). News articles convey current events, suggesting strong temporal effects on topic. For adaptation, we use 9M articles from the Newsroom dataset (Grusky et al., 2018), ranging from 2009–2016.7 We experiment with three tasks on news articles:

Newsroom summarization (NEWSUM)

The

Newsroom dataset provides a large quantity of

high-quality summaries of news articles (Grusky

et al., 2018). We group articles by years for

this task (2009–2010, 2011–2012, 2013–2014,

2015–2016). Note that this task, unlike the

other tasks considered here, is not a document

classiﬁcation task.

Publisher classiﬁcation (PUBCLS) The Newsroom dataset also provides metadata, such as publication source. We take the documents published by the 3 most proliﬁc publishers (Fox News, New York Times, and Washington Post) and train models to classify documents among them. We bin the years (2009–2010, 2011–2012, 2013–2014, 2015–2016). This task is a proxy for applications that seek to infer fact provenance (Zhang et al., 2020). We note that, unlike in our other tasks, we downsample to ensure that the labels are equally balanced.

Media frames classiﬁcation (MFC) “Framing” of-

7https://lil.nlp.cornell.edu/newsroom

ten refers to the emphasis or deemphasis of different social or cultural issues in the media’s presentation of the news (Entman, 1983). Card et al. (2015) provide a dataset of news articles annotated with framing dimensions. We predict the primary frame of a document, treating the problem as a 15-way classiﬁcation task. We bin by timestamp (2009–2010, 2011–2012, 2013–2014, 2015–2016).
Domain 4: Food Reviews Food and restaurant reviews have been widely studied in NLP research. We considered this domain as a possible contrast to those above, expecting less temporal change. As we will see, that is what we found, using data from the Yelp Open Dataset.8 We consider one task:
Review rating classiﬁcation (YELPCLS) This is a conventional sentiment analysis task, mapping the text of a review to the numerical rating given by its author (Pang et al., 2002; Dave et al., 2003). We partition the data by year (2013 to 2019) and ensure that each timestep has a roughly equal amount of reviews.
3 Empirical Results and Analysis
In this section, we summarize our experimental analysis, resulting from more than 500 experiments. In our experiments, we primarily explore the effect of temporal misalignment on GPT2 (Brown et al., 2020), a PLM often used for generation.9 We report the macro F1 score for classiﬁcation tasks and Rouge-L (Lin, 2004) for NEWSUM.
We ﬁrst focus on quantifying temporal misalignment in end tasks. As a preliminary analysis, we investigate how the marginal distribution over labels changes over time. We then study how temporal misalignment affects performance of GPT2 models in downstream tasks with temporal ﬁnetuning (Q1,Q2). We ﬁnd that the amount of performance degradation can vary by task; in some cases the degradation can be severe.
We then study how temporal misalignment affects PLMs. As a ﬁrst step, we analyze how vocabularies change over time in our datasets. We then experiment with (Q3) how temporal misalignment affects upstream language modeling and (Q4) how effective temporal adaptation, or additional pretraining on a target year, is in mitigating misalignment. We ﬁnd that while PLMs are affected
8https://www.yelp.com/dataset 9In our preliminary results, we found that BERT, RoBERTa, and GPT2 models showed similar patterns.

Figure 3: KL divergence between label distributions over time for a subset of tasks. See Appendix D for full results. For each cell, we compare the distribution of labels to that of the ﬁrst time period; e.g., the 2017 POLIAFF cell contains the KL-divergence between the label distributions of POLIAFF in 2017 and 2015. While most tasks see little change over time, POLIAFF and MFC see a large shift. However, POLIAFF was sensitive to temporal misalignment while MFC was not.
by misalignment, temporal domain adaptation is not enough to mitigate temporal misalignment.
Details on temporal domain adaptation and ﬁnetuning, and an extended version of our results, can be found in Appendices B and D.
3.1 Temporal Misalignment in Tasks
How much does misalignment affect task performance? We ﬁnd that it depends on the task.
Label Distribution Drift We ﬁrst investigate how task datasets undergo changes in the marginal distribution over labels due to time. For each task and each test period, we calculate the KL divergence between the label distributions in that period and the ﬁrst test period. The results are shown in Fig. 8. In three cases, we detected notable label distribution drift: POLIAFF, AIC, and MFC.10 In POLIAFF, Republican tweets outnumbered Democratic ones by over a 2:1 ratio in 2015, but the reverse held by 2020. This observation conﬁrms that, regardless of the properties of NLP models, the nature of many tasks changes over time, if only because the output distribution is changing.
Finetuning As described in §2.4, for each task, we create training and evaluation sets associated with different time periods. We ﬁnetune GPT2 on
10For other tasks, it is possible that the data collection/annotation procedures suppressed label distribution changes that would be visible in data “from the wild.”

Figure 4: Temporal misalignment in ﬁnetuning affects task performance (§3.1). In all cases, higher scores are better. The heatmap is shaded per column, i.e., the darkest shade of orange in a cell means the cell has the highest score in that column. Mismatch between the the training and evaluation data result in massive performance drop. While all suffer from temporal degradation, its degree is a strong function of task deﬁnition. For example, YELPCLS shows minimal degradation. In contrast, POLIAFF shows major deterioration over time. Additional tables of our remaining tasks can be found in Appendix D.

Domain Task (metric)

TD

Twitter POLIAFF (F1)

7.72

TWIERC (F1)

0.96

Science SCIERC (F1)

1.08

AIC (F1)

1.79

News

PUBCLS (F1)

5.46

NEWSUM (Rouge-L) 1.38

MFC (F1)

0.98

Reviews YELPCLS (F1)

0.26

Table 2: Finetuned models’ temporal degradation summary scores (TD; §2.3; details in Figure 4). These scores estimate how fast a model degrades as the time period of training and evaluation data diverge (higher scores imply faster degradation).

each of the task’s training sets and evaluate each on two evaluation sets. Note that there is no domain adaptation here.
Fig. 4 shows our results on downstream tasks (with no domain adaptation). To get more reliable estimates, each number in this heatmap is an average of ﬁve independent experiments with different random seeds. A summary of the ﬁne-tuning results, in terms of TD scores (§2.3) is in Table 2 which indicates the speed of temporal degradation, for every year that the training and evaluation data diverges. Recall that this score (applied to task performance measures) summarizes the strength of the effect of temporal misalignment on the score, using evidence from across experiments.
(Q1) Temporal misalignment degrades task performance substantially. Fig. 4, similar to earlier work (Röttger and Pierrehumbert, 2021), shows that models trained on data from the same time period as the test data perform far better than those from the past. The performance drop is most severe

for POLIAFF (TD=7.72) and PUBCLS (TD=5.45).
(Q1) Temporal misalignment has a measurable effect on most tasks. With the exception of MFC and TWIERC tasks, all tasks see an average loss of at least 1 point for each time period that the training data diverges from the test data. For datasets like SCIERC that make use of data from three decades or more, this effect could add up.
Moreover, 1 point of difference can be meaningful, especially for the summarization task where we measure Rouge-L. According to the leaderboard,11 the best three performing models are within a point of each other in Rouge-L (Shi et al., 2019, 2021; Mendes et al., 2019). The task has a TD score of 1.38. On average, a time period of temporal misalignment results has a larger effect on performance than changing between the three best models.
(Q1) Performance loss from temporal misalignment occurs in both directions. Another observation in Table 4 is that degradation happens in both directions (past and future). While most of the emphasis on temporal misalignment is on how to adapt our stale models/data to the present time (Dhingra et al., 2021; Lazaridou et al., 2021; Röttger and Pierrehumbert, 2021), our experiments also show that models trained on newer data can be misaligned from the past, as well. This can be important in social science applications (Abercrombie and Batista-Navarro, 2019; Soni et al., 2021), for example, where evaluation sets may come from earlier time periods than the training data. Moreover, the deterioration rates are similar in both directions.
11https://lil.nlp.cornell.edu/newsroom/ index.html

(Q2) Tasks, even in the same domain, are affected differently. Consider the two tasks of POLIAFF and TWIERC (both in the Twitter domain), with TD scores of 7.72 and 0.96, respectively. Of our 8 tasks, TWIERC, MFC, and YELPCLS are the most robust to temporal misalignment (TD scores of 0.96, 0.98 and 0.26, respectively). The high levels of variation show that temporal misalignment affects performance through labeled datasets, not just unlabeled pretraining data.
3.2 Temporal Misalignment in LMs
As LMs are widely used in modern NLP systems, it is important to inspect how robust they are to temporal misalignment. We seek to understand how temporal misalignment affects the language modeling task in our four domains and if temporal domain adaptation helps in downstream tasks.
Vocabulary Shift We ﬁrst consider an extremely simple measurement of language shift: how do vocabularies change across time periods?12 We use a similar procedure to the one Gururangan et al. (2020) used for analyzing domain similarity. Fixing a domain, we compare the (unigram) vocabularies of each pair of training sets. The vocabularies are built using the 10K most frequent terms from each time period. We note that vocabulary overlap is higher between two time periods the closer they are. Most domains see a sizeable amount of shift; however, Yelp is relatively stagnant. Fig. 5 visualizes the overlap measurement.
Temporal Domain Adaptation We next apply DAPT to GPT2: for each domain, we continue pretraining and then evaluate perplexity. We consider how the perplexity varies with the (mis)alignment between the DAPT training data and the evaluation data. We measure the TD score, which summarizes how much performance is affected by temporal misalignment (now applied to perplexity). The results of temporal domain adaptation are in Fig. 6.
(Q3) Domains are a major driver of temporal misalignment in LMs. Consistent with Lazaridou et al. (2021), Fig. 6 shows degradation of LM due to temporal misalignment; it further shows considerable variation by text domain. Twitter changes most rapidly, and food reviews are much slower. This observation is consistent with past
12This can be understood as a model-free way to measure covariate shift for NLP tasks that take text as input.

work on language change in social media (Stewart and Eisenstein, 2018; Eisenstein et al., 2014). To the extent that a LM’s practical usefulness is associated with its ﬁt to new data, researchers and practitioners should understand the temporal dynamics of their target text domains and plan LM updates accordingly.
Joint Effects of Temporal Adaptation and Finetuning As discussed in §2, continued pretraining of an LM on in-domain text has been shown to improve task performance. Our prior results show that both downstream tasks and language modeling are affected by temporal misalignment. Can temporal domain adaptation help mitigate the effects of misalignment in downstream tasks?
Here we consider how the time period of the data selected for continued pretraining affects task performance. For each task’s evaluation set, we apply DAPT twice: once with the earliest available time period’s unannotated data and once with the latest’s. We then ﬁnetune and evaluate on data from the same time periods as in the earlier experiment.
(Q4) Temporal adaptation does not overcome degradation from temporally misaligned labeled data. In Table 3, we see small performance gains from temporal domain adaptation on LMs, and in some cases it is harmful. These observations underscore the importance of the labeled data; adjustments to the LM alone do not yet appear sufﬁcient to mitigate the effects of temporal misalignment. In contrast to temporal domain adaptation, which does not mitigate temporal misalignment’s effects, ﬁnetuning on temporally-updated labeled data is more effective.
This can be observed in each task-speciﬁc subtable of in Table 3: the top-left and bottom-right quadrants (ﬁne-tuning on time-stamp that is used for evaluation) generally lead to higher scores.
4 Limitations and Future Work
Our ﬁndings indicate that temporal misalignment’s effects depend heavily on the task. Though not studied here, the same issues may arise in annotation efforts; consider, for example, recent work on controversy (Zhang et al., 2018) and social norms (Xu et al., 2021; Zhou et al., 2021) likely hinges on constructs that may be time sensitive. Annotations that are temporally misaligned with the original data being annotated may be anachronistic.
An opportunity for future exploration is in the

Figure 5: Vocabulary overlap between time periods, over a subset of our tasks’ datasets. Each cell shows the % overlap between the vocabularies of two time periods. We ﬁnd vocabularies using the evaluation sets and compare the most frequent 10K unigrams between training sets.

Domain (Task) ↓
Twitter (PoliAff)
F1
Domain (Task) ↓
News (NewsSum)
Rouge-L

Finetune Year ↓ 2015
2020 Finetune
Year ↓ 2009-2010
2015-2016

Evaluation → Pretrain ↓ Default
Default → 2015 Default → 2020
Default Default → 2015 Default → 2020 Evaluation →
Pretrain ↓ Default
Default → 2009-2010 Default → 2015-2016
Default Default → 2009-2010 Default → 2015-2016

2015
91.4 92.2 90.9 45.8 47.2 44.2
2009-2010
36.4 36.4 36.1 27.8 28.2 27.8

2020
48.4 47.5 50.8 78.0 76.9 78.3
2015-2016
29.0 29.1 28.9 31.8 31.8 31.6

Domain (Task) ↓
Scientific (SciERC)
F1
Domain (Task) ↓
Food Reviews (Yelp)
F1

Finetune Year ↓
1980-1999
2010-2016 Finetune
Year ↓ 2009-2010
2015-2016

Evaluation → Pretrain ↓ Default
Default → 1980-1999 Default → 2010-2016
Default Default → 1980-1999 Default → 2010-2016
Evaluation → Pretrain ↓ Default
Default → 2014 Default → 2019
Default Default → 2014 Default → 2019

1980-1999
67.9 73.2 73.7 60.3 63.4 64.8
2014
58.6 63.3 60.2 58.3 60.2 60.8

2010-2016
57.2 66.4 66.8 72.5 75.0 76.0
2019
58.3 60.1 62.3 58.3 62.3 62.3

Table 3: Combination of temporal adaptation and ﬁnetuning (§3.2) on our tasks. The row labeled “Default” corresponds to a model that has not been adapted (uses the default pretraining). The models with temporal domain adaptation are shown in rows labeled “Default → y” and each is comparable to the “Default” row above it. The color coding is proportional to the magnitude of the performances of each task (darker shade of orange indicate higher scores). From the results, it can be observed that temporal ﬁnetuning has a greater impact than temporal pretraining. Each quadrant of 3 for each task, indicating the same ﬁnetune and evaluation years, but different pretraining conditions, are mostly uniform. In contrast, we notice a sharper difference in performance when varying the ﬁnetuning year (comparing the quadrants vertically).

context of real-world events with sudden changes such as COVID-19 pandemic Cao et al. (2021) or political changes, which inﬂuence tasks such as question answering (Dhingra et al., 2021; Zhang and Choi, 2021).
Continual learning, which allows models to learn from a continuous stream of data, could also be one way to mitigate temporal misalignment. Most prior work in this space has focused on continual learning in PLMs (Gururangan et al., 2021; Jin et al., 2021) or learning disparate tasks (de Masson d'Autume et al., 2019; Huang et al.). Future work may investigate continual learning algorithms for tasks that change over time.
While we found that task-speciﬁc ﬁnetuning is

more effective than temporal adaptation, new labeled data can be expensive. Ways to characterize or detect changes in a task, such as concept drift, could be helpful in efﬁciently updating datasets (Lu et al., 2019; Webb et al., 2018). Future work can also treat dataset maintenance as an optimization problem between the cost and gains of annotating new data (Bai et al., 2021).
5 Conclusion
Changes in language use over time, and how language relates to other quantities of interest in NLP applications, has clear effects on the performance of those applications. We have explored how temporal misalignment between training data—both

Figure 6: Perplexity of GPT2 after adaptive pretraining on temporally-selected data in different domains (lower is better). The TD score (in parentheses) estimates the expected perplexity rise (i.e., degradation) for every time period of misalignment between evaluation and training times. Degradation follows the expected pattern, but the magnitude varies by domain.
data used to train LMs and annotated data used to ﬁnetune them—affects performance across a range of NLP tasks and domains, taking advantage of datasets where timestamps are available. We compile these datasets as a benchmark for future research as well. We also introduced a summary metric, TD score, that makes it easier to compare models in terms of their temporal misalignment.
Our experiments revealed considerable variation in temporal degradation accross tasks, more so than found in previous studies (Röttger and Pierrehumbert, 2021). These ﬁndings motivate continued study of temporal misalignment across applications of NLP, its consideration in benchmark evaluations,13 and vigilance on the part of practitioners able to monitor live system performance over time.
Notably, we observed that continued training of LMs on temporally aligned data does not have much effect, motivating further research to ﬁnd effective temporal adaptation methods that are less costly than ongoing collection of annotated/labeled datasets over time.
References
Gavin Abercrombie and Riza Theresa Batista-Navarro. 2019. Semantic change in the language of uk par-
13Indeed, for benchmarks where training and testing data are aligned, our ﬁndings suggest that measures of performance may be in some cases inﬂated.

liamentary debates. In Proceedings of the 1st International Workshop on Computational Approaches to Historical Language Change.
Eduardo G Altmann, Janet B Pierrehumbert, and Adilson E Motter. 2009. Beyond word frequency: Bursts, lulls, and scaling in the temporal distributions of words. PLOS one, 4(11):e7678.
Waleed Ammar, Dirk Groeneveld, Chandra Bhagavatula, Iz Beltagy, Miles Crawford, Doug Downey, Jason Dunkelberger, Ahmed Elgohary, Sergey Feldman, Vu Ha, et al. 2018. Construction of the literature graph in semantic scholar. In NAACL.
Fan Bai, Alan Ritter, and Wei Xu. 2021. Pre-train or annotate? domain adaptation with a constrained budget. arXiv preprint arXiv:2109.04711.
Iz Beltagy, Kyle Lo, and Arman Cohan. 2019. Scibert: A pretrained language model for scientiﬁc text. In EMNLP.
Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. arXiv preprint arXiv:2005.14165.
Ivy Cao, Zizhou Liu, Giannis Karamanolakis, Daniel Hsu, and Luis Gravano. 2021. Quantifying the effects of COVID-19 on restaurant reviews. In Proceedings of the International Workshop on Natural Language Processing for Social Media, Online. Association for Computational Linguistics.
Dallas Card, Amber E. Boydstun, Justin H. Gross, Philip Resnik, and Noah A. Smith. 2015. The media frames corpus: Annotations of frames across issues. In ACL.
Kushal Dave, Steve Lawrence, and David M. Pennock. 2003. Mining the peanut gallery: opinion extraction and semantic classiﬁcation of product reviews. In WWW ’03.
Cyprien de Masson d'Autume, Sebastian Ruder, Lingpeng Kong, and Dani Yogatama. 2019. Episodic memory in lifelong language learning. In nips.
Bhuwan Dhingra, Jeremy R. Cole, Julian Martin Eisenschlos, Daniel Gillick, Jacob Eisenstein, and William W. Cohen. 2021. Time-aware language models as temporal knowledge bases. CoRR, abs/2106.15110.
Jesse Dodge, Maarten Sap, Ana Marasovic, William Agnew, Gabriel Ilharco, Dirk Groeneveld, and Matt Gardner. 2021. Documenting the english colossal clean crawled corpus. arXiv preprint arXiv:2104.08758.
Jacob Eisenstein, Brendan O’Connor, Noah A Smith, and Eric P Xing. 2014. Diffusion of lexical change in social media. PloS one, 9(11).

Robert M. Entman. 1983. Framing: Toward clariﬁcation of a fractured paradigm. Journal of Communications.
Ralph Grishman and Andrew Borthwick. 1999. A maximum entropy approach to named entity recognition.
Max Grusky, Mor Naaman, and Yoav Artzi. 2018. Newsroom: A dataset of 1.3 million summaries with diverse extractive strategies. In NAACL.
Suchin Gururangan, Mike Lewis, Ari Holtzman, Noah A. Smith, and Luke Zettlemoyer. 2021. Demix layers: Disentangling domains for modular language modeling. CoRR, abs/2108.05036.
Suchin Gururangan, Ana Marasovic´, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, and Noah A Smith. 2020. Don’t stop pretraining: Adapt language models to domains and tasks. In ACL.
Yufan Huang, Yanzhe Zhang, Jiaao Chen, Xuezhi Wang, and Diyi Yang. Continual learning for text classiﬁcation with information disentanglement based regularization. In ACL.
Mohit Iyyer, Peter Enns, Jordan Boyd-Graber, and Philip Resnik. 2014. Political ideology detection using recursive neural networks. In ACL.
Kokil Jaidka, Niyati Chhaya, and Lyle Ungar. 2018. Diachronic degradation of language models: Insights from social media. In ACL.
Xisen Jin, Dejiao Zhang, Henghui Zhu, Wei Xiao, Shang-Wen Li, Xiaokai Wei, Andrew Arnold, and Xiang Ren. 2021. Lifelong pretraining: Continually adapting language models to emerging corpora.
W. Labov. 1994. Principles of linguistic change.
Angeliki Lazaridou, Adhiguna Kuncoro, Elena Gribovskaya, Devang Agrawal, Adam Liska, Tayfun Terzi, Mai Gimenez, Cyprien de Masson d’Autume, Sebastian Ruder, Dani Yogatama, et al. 2021. Pitfalls of static language modelling. arXiv preprint arXiv:2102.01951.
Chin-Yew Lin. 2004. ROUGE: A package for automatic evaluation of summaries. In Proc. of Text Summarization Branches Out.
Wei-Hao Lin, Eric P. Xing, and Alexander Hauptmann. 2008. A joint topic and perspective model for ideological discourse. In ECML/PKDD.
Kyle Lo, Lucy Lu Wang, Mark Neumann, Rodney Kinney, and Daniel S Weld. 2020. S2orc: The semantic scholar open research corpus. In ACL.
Jie Lu, Anjin Liu, Fan Dong, Feng Gu, João Gama, and Guangquan Zhang. 2019. Learning under concept drift: A review. IEEE Transactions on Knowledge and Data Engineering.

Yi Luan, Luheng He, Mari Ostendorf, and Hannaneh Hajishirzi. 2018. Multi-task identiﬁcation of entities, relations, and coreference for scientiﬁc knowledge graph construction. In EMNLP.
Afonso Mendes, Shashi Narayan, Sebastião Miranda, Zita Marinho, André F. T. Martins, and Shay B. Cohen. 2019. Jointly extracting and compressing documents with summary state representations. In NAACL.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? sentiment classiﬁcation using machine learning techniques. In EMNLP.
Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep contextualized word representations. In NAACL.
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a uniﬁed text-to-text transformer. JMLR, 21:1–67.
Shruti Rijhwani and Daniel Preo¸tiuc-Pietro. 2020. Temporally-informed analysis of named entity recognition. In ACL.
Paul Röttger and Janet B Pierrehumbert. 2021. Temporal adaptation of bert and performance on downstream document classiﬁcation: Insights from social media. arXiv preprint arXiv:2104.08116.
Tian Shi, Yaser Keneshloo, Naren Ramakrishnan, and Chandan K. Reddy. 2021. Neural abstractive text summarization with sequence-to-sequence models. ACM Transactions on Data Science.
Tian Shi, Ping Wang, and Chandan K. Reddy. 2019. LeafNATS: An open-source toolkit and live demo system for neural abstractive text summarization. In NAACL.
Sandeep Soni, Lauren Klein, and Jacob Eisenstein. 2021. Abolitionist networks: Modeling language change in nineteenth-century activist newspapers. arXiv preprint arXiv:2103.07538.
Ian Stewart and Jacob Eisenstein. 2018. Making “fetch” happen: The inﬂuence of social and linguistic context on nonstandard word growth and decline. In EMNLP.
Shivashankar Subramanian, Daniel King, Doug Downey, and Sergey Feldman. 2021. S2and: A benchmark and evaluation system for author name disambiguation. arXiv preprint arXiv:2103.07534.
Nadine Tamburrini, Marco Cinnirella, Vincent AA Jansen, and John Bryden. 2015. Twitter users change word usage according to conversationpartner social identity. Social Networks, 40:84–89.

David Wadden, Shanchuan Lin, Kyle Lo, Lucy Lu Wang, Madeleine van Zuylen, Arman Cohan, and Hannaneh Hajishirzi. 2020. Fact or ﬁction: Verifying scientiﬁc claims. In EMNLP.
Yunli Wang and Cyril Goutte. 2017. Detecting changes in twitter streams using temporal clusters of hashtags. In Proceedings of the Events and Stories in the News Workshop.
Geoffrey I. Webb, Loong Kuan Lee, Bart Goethals, and François Petitjean. 2018. Analyzing concept drift and shift from sample data. Data Mining and Knowledge Discovery.
Albert Xu, Eshaan Pathak, Eric Wallace, Suchin Gururangan, Maarten Sap, and Dan Klein. 2021. Detoxifying language models risks marginalizing minority voices. In NAACL.
Justine Zhang, Jonathan Chang, Cristian DanescuNiculescu-Mizil, Lucas Dixon, Yiqing Hua, Dario Taraborelli, and Nithum Thain. 2018. Conversations gone awry: Detecting early signs of conversational failure. In ACL.
Michael J.Q. Zhang and Eunsol Choi. 2021. SituatedQA: Incorporating extra-linguistic contexts into QA. EMNLP.
Yi Zhang, Zachary Ives, and Dan Roth. 2020. “who said it, and why?” provenance for natural language claims. In ACL.
Xuhui Zhou, Maarten Sap, Swabha Swayamdipta, Yejin Choi, and Noah A. Smith. 2021. Challenges in automated debiasing for toxic language detection. In EACL.

Supplementary Material

A A Metric for Temporal Degradation
Let t be the time period of the training data and t the time period of the evaluation data.14 We aim to summarize the general effect of temporal misalignment (the difference between t and t ) on task performance, in an interpretable way that is comparable across tasks.
Let St t indicate the performance a model trained on timestamp t data and evaluated on the timestamp t. Let

D(t t) = − (St t − St t) × sign(t − t),

In other words, D(t t) is a modiﬁed difference in performance between a aligned and misaligned models. The modiﬁcation ensures that, as performance deteriorates, D increases, regardless of the direction of time between t and t .
Our temporal degradation (TD) score for a ﬁxed evaluation timestamp t for models trained on a set of timestamps T is deﬁned as:

TD(T t ) =

t∈T D(t

t) − D¯ (t − t¯) ,

t∈T (t − t¯)2

where t¯ = avgt∈T t and D¯ = avgt∈T D(t t). This metric is the slope of a line ﬁtting the the performance change of models trained on a variety of timestamps, when evaluated on a ﬁxed timestamp. It can be interpreted as the average rate of performance deterioration per time period.
Fig. 7 shows three examples of TD scores from POLIAFF(the ﬁrst) and YELPCLS(the latter two). These illustrate cases with and without temporal sensitivity. In practice, most examples with deterioration showed a linear trend and thus the rate of degradation was suitible to be approximated by a line. The ﬁnal TD score is averaged over all evaluation years T .

TD = t∈T TD(T t) n
B Details of Model Development
Training Details for Temporal Adaptation We train GPT2 over each domain and timestamp for k steps using Huggingface’s implementation of GPT2. Hyperparameter details can be seen in Table 4.
14See examples in Fig. 4.

Hyperparameter Number of steps Batch size Maximum learning rate Adam Epsilon Adam Beta Block size

DAPT Assignment 10k 32 5e-05 1e-08 0.9. 0.999 1024

Table 4: Hyperparameters for temporal adaptation accross the four domains.

Hyperparameter Number of Epochs Batch size Max learning rate Adam Epsilon Adam Beta top p (sampling) top k temperature max length

Cls. Assign 50 32 2e-05 1e-08 0.9. 0.999 -

Summ. Assign 10 8 2e-05 1e-08 0.9. 0.999 0.05 20 1 512

Table 5: Hyperparameters for temporal ﬁnetuning accross the eight tasks.

Training Details for Temporal Finetuning We use Huggingface’s implementation of GPT2 for ﬁnetuning for both the classiﬁcation and summarization tasks. We train on Quadro RTX 800 GPUs. See Table 5 for details.
C Data Collection
We describe the postprocessing and data collection in greater detail.
POLIAFF We acquire a list of U.S. politician names and Twitter handles15. One of the authors manually annotated if the politician was a Republican or Democrat. In addition, one volunteer double checked to ensure correctness. We throw away any politician who changed parties between 2015 and 2020, any independents, and anyone suspended by Twitter (e.g., RealDonaldTrump).
AIC We randomly sample science documents in Semantic Scholar’s corpus.16 Of those, we only
15https://files.pushshift.io/twitter/ US_PoliticalTweets.tar.gz
16https://api.semanticscholar.org/ corpus/

Figure 7: Three example calculations of the TD score (left from POLIAFF and the center and right from YELPCLS). The annotated numbers are the raw evaluation scores St →t and the plotted markers represent the modiﬁed differences D(t → t) discussed in Section 2.3. For a particular plot, the red line is the line of best ﬁt and its slope is the TD(t) score for evaluation timestep t. The ﬁnal TD score is averaged between all evaluation timesteps for the particular task.

keep documents that (1) are published in ICML or AAAI, (2) are classiﬁed as ‘computer science’ documents, and (3) have an abstract of at least 50 tokens.
Newsroom The following applies to the postprocessing and data selection for both supervised temporal ﬁnetuning and unsupervised temporal adaptation of PUBCLS and NEWSUM. We use the Newsroom dataset.17. We only keep articles where (1) the year in the metadata also appears in the main text and (2) no future year is mentioned in the main text.

test period, we calculate the KL divergence between the label distribution of that period andthe ﬁrst test period. Fig. 8 depicts our results.
Finetuning Results We provide the full results from our ﬁentuning experiments in Section 3.1 in Fig. 9. These results are for downstream tasks with no domain adaptation.
Finetuning with Temporal Domain Adaptation We provide the full results from our ﬁnetuning with temporal domain adaptation in Section 3.2 in Fig. 6.

PUBCLS We carry out additional postprocessing and ensure that each of the three labels (Fox News, New York Times, and Washington Post) have an equal distribution across years. We do so by uniform-random downsampling.

D Extended Results
We provide further results from our experiments described in Section 3.

Label Distribution Drift We measure how label distributions in task datasets change over time, as described in Section 3.1. For each task and each
17https://lil.nlp.cornell.edu/newsroom/

Domain (Task)
Twitter (PoliAff)
F1
Domain (Task)
Scienctific (AIC) F1
Domain (Task)
News (MFC)
F1
Domain (Task)
News (NewsSum)
Rouge-L

Finetune Year 2015 2020
Finetune Year 2009-2011 2018-2020
Finetune Year 2009-2010 2015-2016
Finetune Year 2009-2010 2015-2016

Evaluation → Pretrain ↓ Default
Default → 2015 Default → 2020
Default Default → 2015 Default → 2020 Evaluation →
Pretrain ↓ Default
Default → 2009-2011 Default → 2018-2020
Default Default → 2009-2011 Default → 2018-2020
Evaluation → Pretrain ↓ Default
Default → 2009-2010 Default → 2015-2016
Default Default → 2009-2010 Default → 2015-2016
Evaluation → Pretrain ↓ Default
Default → 2009-2010 Default → 2015-2016
Default Default → 2009-2010 Default → 2015-2016

2015
91.4 92.2 90.9 45.8 47.2 44.2
2009-11
79.0 94.5 88.4 72.0 87.2 86.8
2009-2010
27.0 30.6 29.8 23.8 29.7 32.7
2009-2010
36.4 36.4 36.1 27.8 28.2 27.8

2020
48.4 47.5 50.8 78.0 76.9 78.3
2018-20
72.0 68.8 86.0 85.0 65.2 79.4
2015-2016
26.0 31.8 30.0 33.4 41.6 41.9
2015-2016
29.0 29.1 28.9 31.8 31.8 31.6

Domain (Task)
Twitter (TwiERC)
F1
Domain (Task)
Scientific (SciERC)
F1
Domain (Task)
News (PubCls)
F1
Domain (Task) ↓
Food Reviews (Yelp)
F1

Finetune Year 2014
2019 Finetune Year
1980-1999
2010-2016 Finetune Year
2009-2010
2015-2016 Finetune
Year ↓ 2013
2019

Evaluation → Pretrain ↓ Default
Default → 2014 Default → 2019
Default Default → 2014 Default → 2019 Evaluation →
Pretrain ↓ Default
Default → 1980-1999 Default → 2010-2016
Default Default → 1980-1999 Default → 2010-2016
Evaluation → Pretrain ↓ Default
Default → 2009-2010 Default → 2015-2016
Default Default → 2009-2010 Default → 2015-2016
Evaluation → Pretrain ↓ Default
Default → 2013 Default → 2019
Default Default → 2013 Default → 2019

2014
74.3 76.1 74.1 71.0 73.1 73.7
1980-1999
67.9 73.2 73.7 60.3 63.4 64.8
2009-2010
94.1 95.4 95.4 71.3 80.4 78.7
2014
58.6 63.3 60.2 58.3 60.2 60.8

2019
68.9 69.6 68.9 74.6 75.2 75.8
2010-2016
57.2 66.4 66.8 72.5 75.0 76.0
2015-2016
52.4 54.0 53.5 88.2 90.7 91.1
2019
58.3 60.1 62.3 58.3 62.3 62.3

Table 6: Combination of temporal adaptation and ﬁnetuning (§3.2) on our tasks. The row labeled “Default” corresponds to a model that has not been adapted (uses the default pretraining). The color coding is proportional to the magnitude of the performances of each task (darker shade of orange indicates higher scores). We see that models that were ﬁnetuned on similar time periods performed similarly, no matter how their DAPT conditions differed.

Figure 8: KL divergence between label distributions over time for all tasks. For each cell, we compare the distribution of labels to that of the ﬁrst time period; e.g., the 2017 POLIAFF cell contains the KL-divergence between the label distributions of POLIAFF in 2017 and 2015. We note that while most distributions see little change over time, POLIAFF, AIC and MFC see a large shift. However, we note that POLIAFF was sensitive to temporal misalignment while MFC was not.

Figure 9: emporal misalignment in ﬁnetuning affects task performance (§3.1). In all cases, higher scores are better. The heatmap is shaded per column, i.e., the darkest shade of orange in a cell means the cell has the highest score in that column. Mismatch between the the training and evaluation data result in massive performance drop. While all suffer from temporal degradation, its degree is a strong function of task deﬁnition. For example, YELPCLS, MFC, and TWIERC show minimal degradation. In contrast, POLIAFF and NEWSUM major deterioration over time.

