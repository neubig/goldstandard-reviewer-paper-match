HIGITCLASS: Keyword-Driven Hierarchical
Classiﬁcation of GitHub Repositories
Yu Zhang1, Frank F. Xu2, Sha Li1, Yu Meng1, Xuan Wang1, Qi Li3, Jiawei Han1 1Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL, USA
2Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA, USA 3Department of Computer Science, Iowa State University, Ames, IA, USA
{yuz9, shal2, yumeng5, xwang174, hanj}@illinois.edu, frankxu@cmu.edu, qli@iastate.edu

arXiv:1910.07115v2 [cs.LG] 13 Nov 2021

Abstract—GitHub has become an important platform for code sharing and scientiﬁc exchange. With the massive number of repositories available, there is a pressing need for topic-based search. Even though the topic label functionality has been introduced, the majority of GitHub repositories do not have any labels, impeding the utility of search and topic-based analysis. This work targets the automatic repository classiﬁcation problem as keyword-driven hierarchical classiﬁcation. Speciﬁcally, users only need to provide a label hierarchy with keywords to supply as supervision. This setting is ﬂexible, adaptive to the users’ needs, accounts for the different granularity of topic labels and requires minimal human effort. We identify three key challenges of this problem, namely (1) the presence of multi-modal signals; (2) supervision scarcity and bias; (3) supervision format mismatch. In recognition of these challenges, we propose the HIGITCLASS framework, comprising of three modules: heterogeneous information network embedding; keyword enrichment; topic modeling and pseudo document generation. Experimental results on two GitHub repository collections conﬁrm that HIGITCLASS is superior to existing weakly-supervised and dataless hierarchical classiﬁcation methods, especially in its ability to integrate both structured and unstructured data for repository classiﬁcation.
Index Terms—hierarchical classiﬁcation, GitHub, weaklysupervised learning
I. INTRODUCTION
For the computer science ﬁeld, code repositories are an indispensable part of the knowledge dissemination process, containing valuable details for reproduction. For software engineers, sharing code also promotes the adoption of best practices and accelerates code development. The needs of the scientiﬁc community and that of software developers have facilitated the growth of online code collaboration platforms, the most popular of which is GitHub, with over 96 million repositories and 31 million users as of 2018. With the overwhelming number of repositories hosted on GitHub, there is a natural need to enable search functionality so that users can quickly target repositories of interest. To accommodate this need, GitHub introduced topic labels1 which allowed users to declare topics for their own repositories. However, topicbased search on GitHub is still far from ideal. For example, when searching for repositories related to “phylogenetics”, a highly relevant repository opentree2 with many stars and forks does not even show up in the ﬁrst 10 pages of search
1https://help.github.com/en/articles/about-topics 2https://github.com/OpenTreeOfLife/opentree

results as it does not contain the “phylogenetics” tag. Hence, to improve the search and analysis of GitHub repositories, a critical ﬁrst step is automatic repository classiﬁcation.
In the process of examining the automatic repository classiﬁcation task, we identify three different cases of missing labels: (1) Missing annotation: the majority of repositories (73% in our MACHINE-LEARNING dataset and 78% in our BIOINFORMATICS dataset) have no topic labels at all; (2) Incomplete annotation: since topic labels can be arbitrarily general or speciﬁc, some repositories may miss coarse-grained labels while others miss ﬁne-grained ones; (3) Evolving label space: related GitHub topics tags may not have existed at the time of creation, so the label is naturally missing. Missing annotation is the major drive behind automatic classiﬁcation, but this also implies that labeled data is scarce and expensive to obtain. Incomplete annotation reﬂects the hierarchical relationship between labels: repositories should not only be assigned to labels of one level of granularity, but correspond to a path in the class hierarchy. Finally, the evolving label space requires the classiﬁcation algorithm to quickly adapt to a new label space, or take the label space as part of the input. Combining these observations, we deﬁne our task as keyworddriven hierarchical classiﬁcation for GitHub repositories. By keyword-driven, we imply that we are performing classiﬁcation using only a few keywords as supervision.
Compared to the common setting of fully-supervised classiﬁcation of text documents, keyword-driven hierarchical classiﬁcation of GitHub repositories poses unique challenges. First of all, GitHub repositories are complex objects with metadata, user interaction and textual description. As a result, multimodal signals can be utilized for topic classiﬁcation, including user ownership information, existing tags and README text. To jointly model structured and unstructured data, we propose to construct a heterogeneous information network (HIN) centered upon words. By learning node embeddings in this HIN, we obtain word representations that reﬂect the co-occurrence of multi-modal signals that are unique to the GitHub repository dataset. We also face the supervision scarcity and bias problem as users only provide one keyword for each class as guidance. This single keyword may reﬂect user’s partial knowledge of the class and may not achieve good coverage of the class distribution. In face of this challenge, we introduce a keyword enrichment module that expands the single keyword to a

keyword set for each category. The newly selected keywords are required to be close to the target class in the embedding space. Meanwhile, we keep mutual exclusivity among keyword sets so as to create a clear separation boundary. Finally, while users provide a label hierarchy, the classiﬁcation algorithm ultimately operates on repositories, so there is a mismatch in the form of supervision. Since we already encode the structured information through the HIN embeddings, in our ﬁnal classiﬁcation stage we represent each repository as a document. To transform keywords into documents, we ﬁrst model each class as a topic distribution over words and estimate the distribution parameters. Then based on the topic distributions, we follow a two-step procedure to generate pseudo documents for training. This also allows us to employ powerful classiﬁers such as CNNs for classiﬁcation, which would not be possible with the scarce labels.
To summarize, we have the following contributions:
• We present the task of keyword-driven hierarchical classiﬁcation of GitHub repositories. While GitHub has been of widespread interest to the research community, no previous efforts have been devoted to the task of automatically assigning topic labels to repositories, which can greatly facilitate repository search and analysis. To deal with the evolving hierarchical label space and circumvent expensive annotation efforts, we only rely on the user-provided label hierarchy and keywords to train the classiﬁer.
• We design the HIGITCLASS framework, which consists of three modules: HIN construction and embedding; keyword enrichment; topic modeling and pseudo document generation. The three modules are carefully devised to overcome three identiﬁed challenges of our problem: the presence of multi-modal signals; supervision scarcity and bias; supervision format mismatch.
• We collect two datasets of GitHub repositories from the machine learning and bioinformatics research community. On both datasets we show that our proposed framework HIGITCLASS outperforms existing supervised and semisupervised models for hierarchical classiﬁcation.
The remainder of this paper is organized as follows. In Section II, we formally introduce our problem deﬁnition, multi-modal signals in a GitHub repository and heterogeneous information networks. In Section III, we elaborate our framework HIGITCLASS with its three components. Then in Section IV, we present experimental results and discuss our ﬁndings. Section V covers related literature and we conclude in Section VI.
II. PRELIMINARIES
A. Problem Deﬁnition
We study hierarchical classiﬁcation of GitHub repositories where the categories form a tree structure. Traditional hierarchical classiﬁcation approaches [7], [19] rely on a large set of labeled training documents. In contrast, to tackle the evolving label space and alleviate annotation efforts, we formulate our task as keyword-driven classiﬁcation, where users just need to provide the label hierarchy and one keyword for each leaf category. This bears some similarities with the dataless

User
Description Tags

Name

README
Fig. 1. A sample GitHub repository with the user’s name, the repository name, description tags, and README (only the ﬁrst paragraph is shown).
classiﬁcation proposed in [33] that utilizes an user-deﬁned label hierarchy and class descriptions. There is no requirement of any labeled repository. Formally, our task is deﬁned as follows. Problem Deﬁnition. (KEYWORD-DRIVEN HIERARCHICAL CLASSIFICATION.) Given a collection of unlabeled GitHub repositories, a tree-structured label hierarchy T and one keyword wi0 for each leaf class Ci (i = 1, ..., L), our task is to assign appropriate category labels to the repositories, where the labels can be either a leaf or an internal node in T.
B. GitHub Repositories Fig. 1 shows a sample GitHub repository3. With the help
of GitHub API4, we are able to extract comprehensive information of a repository including metadata, source code and team dynamics. In HIGITCLASS, we utilize the following information: User. Users usually have consistent interests and skills. If two repositories share the same user (“Natsu6767” in Fig. 1), they are more likely to have similar topics (e.g., deep learning or image generation). Name. If two repositories share the same name, it is likely that one is forked from the other and they should belong to the same topic category. Besides, indicative keywords can be obtained by segmenting the repository name properly (e.g., “DCGAN” and “PyTorch” in Fig. 1). Description. The description is a concise summary of the repository. It usually contains topic-indicating words (e.g., “DCGAN” and “CelebA” in Fig. 1). Tags. Although a large proportion of GitHub repositories are not tagged, when available, tags are strong indicators of a repository’s topic (e.g., “dcgan” and “generative-model” in Fig. 1).
3https://github.com/Natsu6767/DCGAN-PyTorch 4https://developer.github.com/v3/

User Input
Machine Learning

CV

NLP

Speech

…

keyword dcgan
Image Generation

keyword … densenet
Image Classification

HIN Encoding

word

word 1

doc

word 2

user

user 1

tag

tag 1

name

doc 1

label

…

……

Keyword Enrichment

densenet

… …

cifar10 resnet

seqgan

wgan

celeba dcgan

keyword dcgan wgan celeba

keyword densenet …
resnet cifar10

Topic Modeling and Pseudo Doc Generation
CV
Speech NLP
CV NLP Speech …
Image Gen. Image Class. …

Classification
Image Gen. CV
vs.
Image Class.

Fig. 2. The HIGITCLASS framework. Three key modules (i.e., HIN encoding, keyword enrichment, and pseudo document generation) are used to tackle the aforementioned three challenges, respectively.

README. The README ﬁle is the main source of textual information in a repository. In contrast to the description, it elaborates more on the topic but may also diverge to other issues (e.g., installation processes and code usages). The latter introduces noises to the task of topic inference.
We concatenate the description and README ﬁelds into a single Document ﬁeld, which serves as the textual feature of a repository.
C. Heterogeneous Information Networks
In our proposed framework HIGITCLASS, we model the multi-modal signals of GitHub repositories as a heterogeneous information network (HIN) [34], [35]. HINs are an extension of homogeneous information networks to support multiple node types and edge types. We formally deﬁne a heterogeneous information network as below:
Heterogeneous Information Network (HIN). An HIN is deﬁned as a graph G = (V, E) with a node type mapping φ : V → TV and an edge type mapping ψ : E → TE . Either the number of node types |TV | or the number of relation types |TE | is larger than 1.
As we all know, one advantage of networks is the ability to go beyond direct links and model higher-order relationships which can be captured by paths between nodes. We introduce the notion of meta-paths, which account for different edge types in HINs.
Meta-Path. In an HIN, meta-paths [35] are an abstraction of paths proposed to describe multi-hop relationships. For an HIN G = (V, E), a meta-path is a sequence of edge types M = E1-E2-...-EL (Ei ∈ TE ). Any path that has the same types as the meta-path is an instance of the meta-path. When edge types are a function of the node types, we also represent a meta-path as M = V1-V2-...-VL (Vi ∈ TV and Vi-Vi+1 ∈ TE for any i).
III. METHOD
We lay out our HIGITCLASS framework in Fig. 2. HIGITCLASS consists of three key modules, which are proposed to solve the three challenges mentioned in Introduction, respectively.

To deal with multi-modal signals, we propose an HIN encoding module (Section III-A). Given the label hierarchy and keywords, we ﬁrst construct an HIN to characterize different kinds of connections between words, documents, users, tags, repository names and labels. Then we adopt ESIM [31], a meta-path guided heterogeneous network embedding technique, to obtain good node representations.
To tackle supervision scarcity and bias, we introduce a keyword enrichment module (Section III-B). This module expands the user-speciﬁed keyword to a semantically concentrated keyword set for each category. The enriched keywords are required to share high proximity with the user-given one from the view of embeddings. Meanwhile, we keep mutual exclusivity among keyword sets so as to create a clear separation boundary.
To overcome supervision format mismatch, we present a pseudo-document generation technique (Section III-C). We ﬁrst model each class as a topic distribution over words and estimate the distribution parameters. Then based on the topic distributions, we follow a two-step procedure to generate pseudo documents for training. This step allows us to employ powerful classiﬁers such as convolutional neural network [16]. Intuitively, the neural classiﬁer is ﬁtting the learned word distributions instead of a small set of keywords, which can effectively prevent it from overﬁtting.
A. HIN Construction and Embedding
HIN Construction. The ﬁrst step of our model is to construct an HIN that can capture all the interactions between different types of information regarding GitHub repositories. We include six types of nodes: words (W ), documents (D), users (U ), tags (T ), tokens segmented from repository names (N ) and labels (L). There is a one-to-one mapping between documents (D) and repositories (R), thus document nodes may also serve as a representation of its corresponding repository in the network. Since the goal of this module is to learn accurate word representations for the subsequent classiﬁcation step, we adopt a word-centric star schema [36], [37]. The schema is shown in Fig. 3(a). We use a sample ego network of the word “DCGAN” to help illustrate our schema (Fig. 3(b)). The word

Label

User Word

Name

Computer-Vision (label) Image-Generation (label)

Natsu6767 (user) DCGAN (word)

DCGAN (name) PyTorch (name)

Doc

Tags

(a) Our HIN schema

Repo001 (document)

gan (tag)

deeplearning (tag)

(b) A sample ego network under the schema

Fig. 3. Our HIN schema and a sample network under the schema. The ﬁve edge types characterize different kinds of second-order proximity between words.

vocabulary is the union of words present in the documents, tags, segmented repository names and user-provided keywords.
Following the star schema, we then have 5 types of edges in the HIN that represent 5 types of word co-occurrences:
(1) W –D. The word-document edges describe documentlevel co-occurrences, where the edge weight between word wi and document dj indicates the number of times wi appears in dj (i.e., term frequency, or tf (wi, dj)). From the perspective of second-order proximity [38], W –D edges reﬂect the fact that two words tend to have similar semantics when they appear in the same repository’s document.
(2) W –U . We add an edge between a word and a user node if the user is the owner of a repository that contains the word in its document ﬁeld. The edge weight between word wi and user uj is the sum of the term frequency of the word w in each of the user’s repositories:
tf (wi, dk).
k: document dk belongs to user uj
(3) W –T . The word-tag relations encode tag-level word cooccurrences. The edge weight between word wi and tag tj is
tf (wi, dk).
k: document dk has tag tj
(4) W –N . We segment the repository name using “-”, “ ” and whitespace as separators. For example, we obtain two tokens “DCGAN” and “PyTorch” by segmenting the repository name “DCGAN-PyTorch” in Fig. 1. The edge weight between word wi and name token nj also deﬁned through term frequency:
tf (wi, dk).
k: document dk has name token nj
(5) W –L. The word-label relations describe categorylevel word co-occurrences. Only user-provided keywords will be linked with label nodes and its parents. For example, if we select “DCGAN” as the keyword of a (leaf) category “$IMAGE-GENERATION”, “DCGAN” will have links to “$IMAGE-GENERATION” and all of its parent categories (e.g., “$COMPUTER-VISION”).
HIN Embedding. Once we have an HIN, we proceed to learn representations for nodes in the network. Then the embedding vectors of word nodes can be applied for repository topic classiﬁcation.

There are many popular choices for network representation learning on HINs, such as METAPATH2VEC [6] and HIN2VEC [9]. We adopt ESIM [31] as our HIN embedding algorithm as it achieves the best performance in our task. (We will validate this choice in Section IV-C.) Random walk based methods [11], [27] have enjoyed success in learning node embeddings on homogeneous graphs in a scalable manner. ESIM adapts the idea for use on HINs, and restricts the random walk under guidance of user-speciﬁed meta-paths. In HIGITCLASS, we choose W –D–W , W –U –W , W –T –W , W –N –W and W – L–W as our meta-paths, modeling the ﬁve different types of second-order proximity between words.
Following the selected meta-paths, we can sample a large number of meta-path instances in our HIN (e.g., W –D–W is a valid node sequence, while D–W –D is not). Given a metapath M and its corresponding node sequence P = u1–u2–...– ul, we assume that the probability of observing a path given a meta-path constraint follows that of a ﬁrst-order Markov chain:

l−1
Pr(P|M) = Pr(u1|M) Pr(ui+1|ui, M),
i=1

where

exp(f (u, v, M))

Pr(v|u, M) =

(1)

v ∈V exp(f (u, v , M))

and

f (u, v, M) = µM + pTMeu + qM T ev + eTu ev.

Here, µM is the global bias of meta-path M. pM and qM are d-dimensional local bias of M. eu and ev are d-dimensional embedding vectors of nodes u and v, respectively. eu, ev, pM, qM and µM can be learned through maximizing the likelihood.
However, the denominator in Equation (1) requires summing over all nodes, which is very computationally expensive given the large network size. In our actual computation, we estimate this term through negative sampling [24].

Pr(v|u, M) =

exp(f (u, v, M)) ,
v ∈V − exp(f (u, v , M)) + exp(f (u, v, M))

where V − is the set of nodes that serve as negative samples.

B. Keyword Enrichment
Since we only ask users to provide one keyword for each category, in case of scarcity and bias, we devise a keyword enrichment module to automatically expand the single keyword wi0 the a keyword set Ki = {wi0, wi1, ..., wiKi } so as to better capture the semantics of the category.
From the HIN embedding step, we have obtained the embedding vector ew for each word w. We perform normalization so that all embedding vectors reside on the unit sphere (i.e., ew ← ew/||ew||). Then the inner product of two embedding vectors eTw1 ew2 is adopted to characterize the proximity between two words w1 and w2. For each class Ci, we add words sharing the highest proximity with wi0 into its enriched keyword set. Meanwhile, to create a clear

Algorithm 1 KEYWORDENRICH(w10, ..., wL0)

1: Ki = {wi0}, i = 1, ..., L

2: wi,last = wi0, i = 1, ..., L

3: while Ki ∩ Kj = ∅ (∀i, j) do

4: for i = 1 to L do

5: wi,last = arg maxw∈/Ki eTw0i ew

6:

Ki = Ki ∪ {wi,last}

7: end for

8: end while

9: Ki = Ki/{wi,last}, i = 1, ..., L //Remove the last added

keyword to keep mutual exclusivity

10: output K1, ..., KL

separation boundary between categories, we require K1, ..., KL to be mutually exclusive. Therefore, the expansion process terminates when any two of the keyword sets tend to intersect. Algorithm 1 describes the process.
Note that on a unit sphere, the inner product is a reverse measure of the spherical distance between two points. Therefore, we are essentially expanding the keyword set with the nearest neighbors of the given keyword. The termination condition is that two “neighborhoods” have overlaps.

C. Topic Modeling and Pseudo Document Generation

To leverage keywords for classiﬁcation, we face two problems: (1) a typical classiﬁer needs labeled repositories as input; (2) although the keyword sets have been enriched, a classiﬁer will likely be overﬁtted if it is trained solely on these keywords. To tackle these issues, we assume we can generate a training document d˜ for class Ci given Ki through the following process:
q(d˜|C) = q(d˜|Θi)p(Θi|Ki).

Here q(·|Θi) is the topic distribution of Ci parameterized by Θi, with which we can “smooth” the small set of keywords Ki
to a continuous distribution. For simplicity, we adopt a “bagof-words” model for the generated documents, so q(d˜|Θi) =
|id=˜|0 q(wi|Θi). Then we draw samples of words from q(·|Θi) to form a pseudo document following the technique proposed
in [22].

Spherical Topic Modeling. Given the normalized embeddings, we characterize the word distribution for each category using a mixture of von Mises-Fisher (vMF) distributions [1], [10]. To be speciﬁc, the probability to generate keyword w from category Ci is deﬁned as

m

m

q(w|Ci) = αjf (ew|µj, κj) = αjcp(κj) exp(κjµTj ew),

j=1

j=1

where f (ew|µj, κj), as a vMF distribution, is the j-th component in the mixture with a weight αj. The vMF distribution can be interpreted as a normal distribution conﬁned to a unit sphere. It has two parameters: the mean direction vector µi and the concentration parameter κi. The keyword embeddings

concentrate around µi, and are more concentrated if κi is large. cp(κi) is a normalization constant.
Following [23], we choose the number of vMF components differently for leaf and internal categories: (1) For a leaf category Cj, the number of components m is set to 1 and the mixture model degenerates to a single vMF distribution. (2) For an internal category Cj, we set the number of components to be the number of Cj’s children in the label hierarchy.
Given the enriched keyword set Kj, we can derive µj and κj using Expectation Maximization (EM) [1]. Recall that the keywords of an internal category are aggregated from its children categories. In practice, we use the approximation procedure based on Newton’s method [1] to derive κj.

Pseudo Document Generation. To generate a pseudo document d˜ for Cj, we ﬁrst sample a document vector ed˜ from f (·|Cj). Then we build a local vocabulary Vd˜ that contains top-τ words similar with d˜ in the embedding space. (τ = 50
in our model.) Given Vd˜, we repeatedly generate a number of words from a background distribution with probability β and
from the document-speciﬁc distribution with probability 1−β.
Formally,

 β pB (w), Pr(w|d˜) = βpB(w) + (1 − β) 

, exp(eTw ed˜)

w

∈V

˜

exp(eT
w

ed˜)

d

w ∈/ Vd˜ w ∈ Vd˜

where pB(w) is the background distribution (i.e., word distribution in the entire corpus).
Here we generate the pseudo document in two steps: ﬁrst sampling the document vector and then sampling words from a mixture of the document language model and a background language model. Compared to directly sampling words from f (·|Cj), the two-step process ensures better coverage of the class distribution. In direct sampling, with high probability we will include words that are close to the centroid of the topic Cj. The classiﬁer may learn to ignore all other words and use only these words to determine the predicted class. By ﬁrst sampling the document vector, we would like to lead the classiﬁer to learn that all documents that fall within the topic distribution belong to the same class.
The synthesized pseudo documents are then used as training data for a classiﬁer. In HIGITCLASS, we adopt convolutional neural networks (CNN) [16] for the classiﬁcation task. One can refer to [16], [22] for more details of the network architecture. The embedding vectors of word nodes obtained by ESIM in the previous HIN module are used as pre-trained embeddings.
Recall the process of generating pseudo documents, if we evenly split the fraction of the background distribution into the m children categories of Cj, the “true” label distribution (an m-dimensional vector) of a pseudo document d˜ can be deﬁned as

label(d˜)i = (β1/−m.β) + β/m, do˜thisergweinseerated from child i

Since our label is a distribution instead of a one-hot vector, we compute the loss as the KL divergence between the output

$Computer-Vision

$Image-Generation (dcgan) $Object-Detection (rcnn) $Image-Classification (densenet) $Semantic-Segmentation (segmentation) $Pose-Estimation (pose) $Super-Resolution (srgan)

$Machine-Learning $Natural-Language-Processing
$Speech

$Text-Generation (seqgan) $Text-Classification (vdcnn) $Named-Entity-Recognition (ner) $Question-Answering (squad) $Machine-Translation (translation) $Language-Modeling (lm)
$Speech-Synthesis (wavenet) $Speech-Recognition (deepspeech)

(a) MACHINE-LEARNING

$Bioinformatics

$Computational-Biology

$Sequence-Analysis (fastq) $Genome-Analysis (genomic) $Gene-Expression (expression) $Systems-Biology (network) $Genetics-and-Population-Analysis (genetic) $Structural-Bioinformatics (structure) $Phylogenetics (phylogenetic)

$Data-Analytics

$Biomedical-Text-Mining (bionlp) $Bioimaging (miccai)

$Database-and-Ontologies (database)

(b) BIOINFORMATICS

Fig. 4. Label hierarchy and provided keywords (in blue) on the two datasets.

label distribution and the pseudo label.
IV. EXPERIMENTS
We aim to answer two questions in our experiments. First, does HIGITCLASS achieve supreme performance in comparison with various baselines (Section IV-B)? Second, we propose three key modules in HIGITCLASS. How do they contribute to the overall performance? (The effects of these three modules will be explored one by one in Sections IV-C, IV-D and IV-E).
A. Experimental Setup
Datasets. We collect two datasets of GitHub repositories covering different domains.5 Their statistics are summarized in Table I.

TABLE I DATASET STATISTICS.

Dataset MACHINE-LEARNING
BIOINFORMATICS

#Repos 1,596 876

#Classes (Level 1 + Level 2) 3 + 14 2 + 10

• MACHINE-LEARNING. This dataset is collected by the Paper With Code project6. It contains a list of GitHub repositories implementing state-of-the-art algorithms of various machine learning tasks, where the tasks are organized as a taxonomy.
• BIOINFORMATICS. This dataset is extracted from research articles published on four venues Bioinformatics, BioNLP, MICCAI and Database from 2014 to 2018. In each article, authors may put a code link, and we extract the links pointing to a GitHub repository. Meanwhile, each article has an issue section, which is viewed as the topic label of the associated repository.
Note that more than 73% (resp., 78%) of the repositories in our MACHINE-LEARNING (resp., BIOINFORMATICS) dataset have no tags.
Baselines. We evaluate the performance of HIGITCLASS against the following hierarchical classiﬁcation algorithms:
5Our code and datasets are available at https://github.com/ yuzhimanhua/HiGitClass.
6https://paperswithcode.com/media/about/evaluation-tables.json.gz

• HierSVM [7] decomposes the training tasks according to the label taxonomy, where each local SVM is trained to distinguish sibling categories that share the same parent node.7
• HierDataless [33] embeds both class labels and documents in a semantic space using Explicit Semantic Analysis on Wikipedia articles, and assigns the nearest label to each document in the semantic space.8 Note that HierDataless uses Wikipedia as external knowledge in classiﬁcation, whereas other baselines and HIGITCLASS solely reply on user-provided data.
• WeSTClass [22] ﬁrst generates pseudo documents and then trains a CNN based on the synthesized training data.9
• WeSHClass [23] leverages a language model to generate synthesized data for pre-training and then iteratively reﬁnes the global hierarchical model on labeled documents.10
• PCNB [41] utilizes a path-generated probabilistic framework on the label hierarchy and trains a path-cost sensitive naive Bayes classiﬁer.11
• PCEM [41] makes use of the unlabeled data to ameliorate the path-cost sensitive classiﬁer and applies an EM technique for semi-supervised learning.
Note that HierSVM, PCNB and PCEM can only take document-level supervision (i.e., labeled repositories). To align the experimental settings, we ﬁrst label all the repositories using TFIDF scores by treating the keyword set of each class as a query. Then, we select top-ranked repositories per class as the supervision to train HierSVM, PCNB and PCEM. Since the baselines are all text classiﬁcation approaches, we append the information of user, tags and repository name to the end of the document for each repository so that the baselines can exploit these signals.
7https://github.com/globality-corp/sklearn-hierarchical-classiﬁcation 8https://github.com/yqsong/DatalessClassiﬁcation 9https://github.com/yumeng5/WeSTClass 10https://github.com/yumeng5/WeSHClass 11https://github.com/HKUST-KnowComp/PathPredictionForTextClassiﬁcation

TABLE II PERFORMANCE OF COMPARED ALGORITHMS ON THE MACHINE-LEARNING DATASET. HIERDATALESS DOES NOT HAVE A STANDARD DEVIATION SINCE
IT IS A DETERMINISTIC ALGORITHM.

Method HierSVM [7] HierDataless [33] WeSTClass [22] WeSHClass [23] PCNB [41] PCEM [41] HIGITCLASS W/O HIN HIGITCLASS W/O ENRICH HIGITCLASS W/O HIER HIGITCLASS

Level-1 Micro 54.20 ± 4.53
76.63 61.78 ± 3.90 70.69 ± 2.14 77.79 ± 1.92 77.28 ± 2.00 75.28 ± 6.99 86.48 ± 1.41 57.31 ± 1.63 87.68 ± 2.23

Level-1 Macro 46.58 ± 3.59
33.44 48.00 ± 2.04 52.73 ± 2.18 62.53 ± 2.55 59.27 ± 2.29 60.85 ± 5.51 72.19 ± 2.53 59.30 ± 3.14 72.06 ± 4.39

Level-2 Micro 27.40 ± 3.55
13.72 37.71 ± 2.72 38.08 ± 2.07 26.77 ± 3.89 22.34 ± 4.02 40.21 ± 2.91 36.71 ± 1.13 40.45 ± 2.51 43.93 ± 2.93

Level-2 Macro 31.99 ± 5.34
8.80 34.34 ± 1.70 33.87 ± 2.23 22.85 ± 1.98 19.28 ± 2.25 39.77 ± 2.22 43.75 ± 2.85 44.41 ± 2.66 45.97 ± 2.29

Overall Micro 40.80 ± 1.20
45.18 49.75 ± 3.24 54.39 ± 2.11 52.28 ± 1.92 49.81 ± 2.00 57.74 ± 4.07 61.60 ± 0.25 48.88 ± 2.07 65.81 ± 3.55

Overall Macro 34.57 ± 3.94
13.15 36.75 ± 1.67 37.60 ± 1.67 29.85 ± 1.74 26.34 ± 1.83 43.49 ± 2.10 48.77 ± 1.94 47.04 ± 1.63 50.57 ± 2.98

TABLE III PERFORMANCE OF COMPARED ALGORITHMS ON THE BIOINFORMATICS DATASET. HIERDATALESS DOES NOT HAVE A STANDARD DEVIATION SINCE IT IS
A DETERMINISTIC ALGORITHM.

Method HierSVM [7] HierDataless [33] WeSTClass [22] WeSHClass [23] PCNB [41] PCEM [41] HIGITCLASS W/O HIN HIGITCLASS W/O ENRICH HIGITCLASS W/O HIER HIGITCLASS

Level-1 Micro 80.39 ± 2.72
81.39 61.78 ± 5.75 63.17 ± 3.56 77.03 ± 2.89 78.51 ± 3.06 66.21 ± 8.33 54.55 ± 10.0 78.79 ± 2.57 81.71 ± 3.95

Level-1 Macro 70.16 ± 6.05
78.75 52.73 ± 4.86 59.65 ± 3.51 59.43 ± 3.51 61.99 ± 4.18 64.39 ± 7.00 53.57 ± 9.15 73.71 ± 2.28 77.11 ± 3.89

Level-2 Micro 13.49 ± 10.2
39.27 20.39 ± 3.48 26.44 ± 1.33 31.77 ± 3.80 32.80 ± 2.88 31.87 ± 3.65 22.95 ± 1.46 39.42 ± 4.47 42.44 ± 8.46

Level-2 Macro 10.04 ± 9.07
36.57 17.52 ± 2.59 24.94 ± 0.98 22.90 ± 4.84 18.93 ± 5.28 30.47 ± 3.15 23.18 ± 1.89 41.58 ± 2.63 41.67 ± 8.04

Overall Micro 46.94 ± 4.66
60.33 41.09 ± 4.28 44.80 ± 2.26 54.40 ± 2.89 55.66 ± 3.06 49.04 ± 5.75 38.74 ± 4.30 59.10 ± 3.51 62.08 ± 6.11

Overall Macro 20.06 ± 7.12
43.60 23.91 ± 2.82 30.72 ± 1.30 28.99 ± 4.82 26.11 ± 5.41 36.13 ± 3.52 28.24 ± 0.87 46.94 ± 2.48 47.57 ± 7.34

Besides the baselines, we also include the following three ablation versions of HIGITCLASS into comparison.
• w/o HIN skips the HIN embedding module and relies on word2vec [24] to generate word embeddings for the following steps.
• w/o Enrich skips the keyword enrichment module and directly uses one single keyword in spherical topic modeling.
• w/o Hier directly classiﬁes all repositories to the leaf layer and then assigns internal labels to each repository according to its leaf category.

Evaluation Metrics. We use F1 scores to evaluate the per-

formance of all methods. Denote T Pi, F Pi and, F Ni as

the instance numbers of true-positive, false-positive and false

negative for category Ci. Let T1 (resp., T2) be the set of all

Level-1 (resp., Level-2/leaf) categories. The Level-1 Micro-

F1 is deﬁned as 2P R , where P =

Ci∈T1 T Pi

and

P +R

Ci∈T1 (T Pi+F Pi)

R=

Ci∈T1 T Pi . The Level-1 Macro-F1 is deﬁned

Ci∈T1 (T Pi+F Ni)

as |T11| Ci∈T1 P2Pi+iRRii , where Pi = T PTi+PFi Pi and Ri =

T PiT+PFi Ni . Accordingly, Level-2 Micro/Macro-F1 and Overall

Micro/Macro-F1 can be deﬁned on T2 and T1 ∪ T2.

B. Performance Comparison with Baselines

Tables II and III demonstrate the performance of compared methods on two datasets. We repeat each experiment 5 times (except HierDataless, which is a deterministic algorithm) with the mean and standard deviation reported.
As we can observe from Tables II and III, on both datasets, a signiﬁcant improvement is achieved by HIGITCLASS com-

pared to the baselines. On MACHINE-LEARNING, HIGITCLASS notably outperforms the second best approach by 22.1% on average. On BIOINFORMATICS, the only metric in terms of which HIGITCLASS does not perform the best is Level-1 Macro-F1, and the main opponent of HIGITCLASS is HierDataless. As mentioned above, HierDataless incorporates Wikipedia articles as its external knowledge. When user-provided keywords can be linked to Wikipedia (e.g., “genomic”, “genetic” and “phylogenetic” in BIOINFORMATICS), HierDataless can exploit the external information well. However, when the keywords cannot be wikiﬁed (e.g., names of new deep learning algorithms such as “dcgan”, “rcnn” and “densenet” in MACHINE-LEARNING), the help from Wikipedia is limited. In fact, on MACHINE-LEARNING, HierDataless performs poorly. Note that on GitHub, it is common that names of recent algorithms or frameworks are provided as keywords.
Besides outperforming baseline approaches, HIGITCLASS shows a consistent and evident improvement against three ablation versions. The average boost of the HIN module over the six metrics is 15.0% (resp., 28.6%) on the MACHINELEARNING (resp., BIOINFORMATICS) dataset, indicating the importance of encoding multi-modal signals on GitHub. The Level-1 F1 scores of HIGITCLASS W/O ENRICH is close to the full model on MACHINE-LEARNING, but the keyword enrichment module demonstrates its power when we go deeper. This ﬁnding is aligned with the fact that the topic distributions of coarse-grained categories are naturally distant from each other on the sphere. Therefore, one keyword per category may be enough to estimate the distributions approximately.

Overall Micro-F1

70 metapath2vec as embedding HIN2vec as embedding
65 NNoo WW--DL--WW No W-T-W
60 No W-U-W No W-N-W Full
55
50
45
40
(a) MACHINE-LEARNING, Micro
55 metapath2vec as embedding HIN2vec as embedding
50 No W-D-W No W-L-W No W-T-W
45 No W-U-W No W-N-W
40 Full
35
30
25
(c) MACHINE-LEARNING, Macro

Overall Macro-F1

Overall Micro-F1

65 metapath2vec as embedding HIN2vec as embedding No W-D-W
60 No W-L-W No W-T-W
55 No W-U-W No W-N-W Full
50
45
40
(b) BIOINFORMATICS, Micro
50 metapath2vec as embedding HIN2vec as embedding No W-D-W
45 No W-L-W No W-T-W No W-U-W
40 No W-N-W Full
35
30
25
(d) BIOINFORMATICS, Macro

Fig. 5. Performance of algorithms with different HIN modules.

Overall Macro-F1

However, when we aim at ﬁne-grained classiﬁcation, the topic distributions become closer, and the inference process may be easily interfered by a biased keyword. HIGITCLASS W/O HIER performs poorly on MACHINE-LEARNING, which highlights the importance of utilizing the label hierarchy during the training process. The same phenomenon occurs in the comparison between WeSTClass and WeSHClass.
C. Effect of HIN Construction and Embedding
We have demonstrated the contribution of our HIN module by comparing HIGITCLASS and HIGITCLASS W/O HIN. To explore the effectiveness of HIN construction and embedding in a more detailed way, we perform an ablation study by changing one “factor” in the HIN and ﬁxing all the other modules in HIGITCLASS. To be speciﬁc, our HIN has ﬁve types of edges, each of which corresponds to a meta-path. We consider ﬁve ablation versions (No W-D-W, No W-U-W, No W-T-W, No W-N-W and No W-L-W). Each version ignores one edge type/meta-path. Moreover, given the complete HIN, we consider to use two popular approaches, METAPATH2VEC [6] and HIN2VEC [9], as our embedding technique, which generates two variants metapath2vec as embedding and HIN2vec as embedding. Fig. 5 shows the performance of these variants and our Full model.
We have the following ﬁndings from Fig. 5. First, our FULL model outperforms the ﬁve ablation models ignoring different edge types, indicating that each meta-path (as well as each node type incorporated in the HIN construction step) plays a positive role in classiﬁcation. Second, our FULL model outperforms METAPATH2VEC AS EMBEDDING and HIN2VEC AS EMBEDDING in most cases, which validates our choice of using ESIM as the embedding technique. The possible reason that ESIM is more suitable for our task may be that we have a simple word-centric star schema and a clear goal of embedding word nodes. Therefore, the choices of meta-paths can be explicitly speciﬁed (i.e., W –?–W ) and do not need to be inferred from data (as HIN2VEC does). Third, among

F1 F1

100

80

60

40
20
0 0

Level-1 Micro Level-1 Macro Level-2 Micro Level-2 Macro Overall Micro Overall Macro

500

1000

1500

#pseudo documents per class

(a) MACHINE-LEARNING

2000

100

80

60

40
20
0 0

Level-1 Micro Level-1 Macro Level-2 Micro Level-2 Macro Overall Micro Overall Macro

500

1000

1500

#pseudo documents per class

(b) BIOINFORMATICS

2000

Fig. 6. Performance of HIGITCLASS with different numbers of pseudo documents.

the ﬁve ablation models ignoring edge types, NO W-U-W performs the worst on MACHINE-LEARNING, which means W -U edges (i.e., the user information) contribute the most in repository classiﬁcation. Meanwhile, on BIOINFORMATICS, W -T edges have the largest offering. This can be explained by the following statistics: in the MACHINE-LEARNING dataset, 348 pairs of repositories share the same user, out of which 217 (62%) have the same leaf label; in the BIOINFORMATICS dataset, there are 356 pairs of repositories having at least two overlapping tags, among which 221 (62%) belong to the same leaf category. Fourth, W -D edges also contribute a lot to the performance. This observation is aligned with the results in [37], where document-level word co-occurrences play a crucial role in text classiﬁcation.
D. Effect of Keyword Enrichment
Quantitatively, the keyword enrichment module has a positive contribution to the whole framework according to previous experiments. We now show its effect qualitatively. Table IV lists top-5 words selected by HIGITCLASS during keyword enrichment. Besides topic-indicating words (e.g., “tagger”, “trait”, “trees”, etc.), popular algorithm/tool names (e.g., “bidaf ” and “pymol”), dataset names (e.g., “mpii”, “pdb”) and author names (e.g., “papandreou” and “lample”) are also included in the expanded keyword set. Note that some provided keywords are more or less ambiguous (e.g., “segmentation” and “structure”), and directly using them for topic modeling may introduce noises. In contrast, the expanded set as a whole can better characterize the semantics of each topic category.
E. Effect of Pseudo Documents
In all previous experiments, when we build a classiﬁer for an internal category Ci, we generate 500 pseudo documents for each child of Ci. What if we use less/more synthesized training data? Intuitively, if the amount of generated pseudo documents is too small, signals in previous modules cannot fully propagate to the training process. On the contrary, if we have too many generated data, the training time will be unnecessarily long. To see whether 500 is a good choice, we plot the performance of HIGITCLASS with 10, 50, 100, 500, 1000 and 2000 pseudo documents in Fig. 6.
On the one side, when the number of pseudo documents is too small (e.g., 10, 50 or 100), information carried in the synthesized training data will be insufﬁcient to train a good classiﬁer. On the other side, when we generate too

Class Keyword
Enriched Keywords
Class Keyword
Enriched Keywords

TABLE IV ENTITY ENRICHMENT RESULTS ON THE TWO DATASETS. FOUR LEAF CATEGORIES ARE SHOWN FOR EACH DATASET.

$SEMANTIC-SEGMENTATION segmentation semantic papandreou scene pixel segment
$GENE-EXPRESSION expression gene genes rna cell isoform

$POSE-ESTIMATION pose
estimation person human mpii 3d
$GENETICS-AND-POPULATION genetic traits trait markers
phenotypes associations

$NAMED-ENTITY-RECOGNITION ner
entity tagger lample
-
$STRUCTURAL-BIOINFORMATICS structure protein pdb residues pymol residue

$QUESTION-ANSWERING squad
question answering
bidaf -
$PHYLOGENETICS phylogenetic trees newick phylogenetics phylogenies evolution

many pseudo documents (e.g, 1000 or 2000), putting efﬁciency aside, the performance is not guaranteed to increase. In fact, on both datasets, the F1 scores start to ﬂuctuate when the number of pseudo documents becomes large. In our task, generating 500 to 1000 pseudo documents for each class will strike a good balance.
V. RELATED WORK
GitHub Repository Mining. As a popular code collaboration community, GitHub presents many opportunities for researchers to learn how people write code and design tools to support the process. As a result, GitHub data has received attention from both software engineering and social computing researchers. Analytic studies [5], [15], [21], [29], [39], [40] have investigated how user activities (e.g., collaboration, following and watching) affect development practice. Algorithmic studies [8], [28], [32], [44] exploit README ﬁles and repository metadata to perform data mining tasks such as similarity search [44] and clustering [32]. In this paper, we focus on the task of automatically classifying repositories whereas previous works [15], [29] have relied on human effort to annotate each repository with its topic.
HIN Embeddings. Many node embeddings techniques have been proposed for HIN, including [6], [9], [31], [42]. From the application point of view, typical applications of learned embeddings include node classiﬁcation [6], [9], [31], [42], node clustering [6] and link prediction [9], [42]. Several studies apply HIN node embeddings into downstream classiﬁcation tasks, such as malware detection [13] and medical diagnosis [12]. Different from the fully-supervised settings in [12], [13], our repository classiﬁcation task relies on a very small set of guidance. Moreover, most information used in [12], [13] is structured. In contrast, we combine structured information such as user-repository ownership relation with unstructured text for classiﬁcation.
Dataless Text Classiﬁcation. Although deep neural architectures [14], [16], [43] demonstrate their advantages in fullysupervised text classiﬁcation, their requirement of massive training data prohibits them from being adopted in some practical scenarios. Under weakly-supervised or dataless settings,

there have been solutions following two directions: latent variable models extending topic models (e.g., PLSA and LDA) by incorporating user-provided seed information [4], [17], [18], [20] and embedding-based models deriving vectorized representations for words and documents [3], [22], [37]. There are also some work on semi-supervised text classiﬁcation [25], [30], but they require a set of labeled documents instead of keywords.
Hierarchical Text Classiﬁcation. Under fully-supervised settings, [7] and [19] ﬁrst propose to train SVMs to distinguish the children classes of the same parent node. [2] further deﬁnes hierarchical loss function and applies cost-sensitive learning to generalize SVM learning for hierarchical classiﬁcation. [26] proposes a graph-CNN based model to convert text to graph-of-words, on which the graph convolution operations are applied for feature extraction. Under weakly-supervised or dataless settings, previous approaches include HierDataless [33], WeSHClass [23] and PCNB/PCEM [41], which have been introduced in Section IV-A. All above mentioned studies focus on text data without additional information. In HIGITCLASS, we are able to go beyond plain text classiﬁcation and utilize multi-modal signals.
VI. CONCLUSIONS AND FUTURE WORK
In this paper, we have studied the problem of keyworddriven hierarchical classiﬁcation of GitHub repositories: the end user only needs to provide a label hierarchy and one keyword for each leaf category. Given such scarce supervision, we design HIGITCLASS with three modules: heterogeneous information network embedding; keyword enrichment; pseudo document generation. Speciﬁcally, HIN embeddings take advantage of the multi-modal nature of GitHub repositories; keyword enrichment alleviates the supervision scarcity of each category; pseudo document generation transforms the keywords into documents, enabling the use of powerful neural classiﬁers. Through experiments on two repository collections, we show that HIGITCLASS consistently outperforms all baselines by a large margin, particularly on the lower levels of the hierarchy. Further analysis shows that the HIN module contributes the most to the boost in performance and keyword

enrichment demonstrates its power deeper down the hierarchy where the differences between classes become more subtle.
For future work, we would like to explore the possibility of integrating different forms of supervision (e.g., the combination of keywords and labeled repositories). The HIN embedding module may also be coupled more tightly with the document classiﬁcation process by allowing the document classiﬁer’s prediction results to propagate along the network.
ACKNOWLEDGMENT
We thank Xiaotao Gu for useful discussions. The research was sponsored in part by U.S. Army Research Lab. under Cooperative Agreement No. W911NF-09-20053 (NSCTA), DARPA under Agreement No. W911NF-17C0099, National Science Foundation IIS 16-18481, IIS 1704532, and IIS-17-41317, DTRA HDTRA11810026, and grant 1U54GM114838 awarded by NIGMS through funds provided by the trans-NIH Big Data to Knowledge (BD2K) initiative (www.bd2k.nih.gov). The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agencies. We thank anonymous reviewers for valuable and insightful feedback.
REFERENCES
[1] A. Banerjee, I. S. Dhillon, J. Ghosh, and S. Sra. Clustering on the unit hypersphere using von mises-ﬁsher distributions. Journal of Machine Learning Research, 6(Sep):1345–1382, 2005.
[2] L. Cai and T. Hofmann. Hierarchical document categorization with support vector machines. In CIKM’04, pages 78–87, 2004.
[3] M.-W. Chang, L.-A. Ratinov, D. Roth, and V. Srikumar. Importance of semantic representation: Dataless classiﬁcation. In AAAI’08, pages 830–835, 2008.
[4] X. Chen, Y. Xia, P. Jin, and J. Carroll. Dataless text classiﬁcation with descriptive lda. In AAAI’15, 2015.
[5] L. Dabbish, C. Stuart, J. Tsay, and J. Herbsleb. Social coding in github: transparency and collaboration in an open software repository. In CSCW’12, pages 1277–1286, 2012.
[6] Y. Dong, N. V. Chawla, and A. Swami. metapath2vec: Scalable representation learning for heterogeneous networks. In KDD’17, pages 135–144, 2017.
[7] S. Dumais and H. Chen. Hierarchical classiﬁcation of web content. In SIGIR’00, pages 256–263, 2000.
[8] Y. Fan, Y. Zhang, S. Hou, L. Chen, Y. Ye, C. Shi, L. Zhao, and S. Xu. idev: Enhancing social coding security by cross-platform user identiﬁcation between github and stack overﬂow. In IJCAI’19, pages 2272–2278, 2019.
[9] T.-y. Fu, W.-C. Lee, and Z. Lei. Hin2vec: Explore meta-paths in heterogeneous information networks for representation learning. In CIKM’17, pages 1797–1806, 2017.
[10] S. Gopal and Y. Yang. Von mises-ﬁsher clustering models. In ICML’14, pages 154–162, 2014.
[11] A. Grover and J. Leskovec. node2vec: Scalable feature learning for networks. In KDD’16, pages 855–864, 2016.
[12] A. Hosseini, T. Chen, W. Wu, Y. Sun, and M. Sarrafzadeh. Heteromed: Heterogeneous information network for medical diagnosis. In CIKM’18, pages 763–772, 2018.
[13] S. Hou, Y. Ye, Y. Song, and M. Abdulhayoglu. Hindroid: An intelligent android malware detection system based on structured heterogeneous information network. In KDD’17, pages 1507–1515, 2017.
[14] J. Howard and S. Ruder. Universal language model ﬁne-tuning for text classiﬁcation. In ACL’18, pages 328–339, 2018.
[15] E. Kalliamvakou, G. Gousios, K. Blincoe, L. Singer, D. M. German, and D. Damian. The promises and perils of mining github. In MSR’14, pages 92–101, 2014.
[16] Y. Kim. Convolutional neural networks for sentence classiﬁcation. In EMNLP’14, pages 1746–1751, 2014.

[17] C. Li, J. Xing, A. Sun, and Z. Ma. Effective document labeling with very few seed words: A topic model approach. In CIKM’16, pages 85–94, 2016.
[18] X. Li, C. Li, J. Chi, J. Ouyang, and C. Li. Dataless text classiﬁcation: A topic modeling approach with document manifold. In CIKM’18, pages 973–982, 2018.
[19] T.-Y. Liu, Y. Yang, H. Wan, H.-J. Zeng, Z. Chen, and W.-Y. Ma. Support vector machines classiﬁcation with a very large-scale taxonomy. SIGKDD Explorations, 7(1):36–43, 2005.
[20] Y. Lu and C. Zhai. Opinion integration through semi-supervised topic modeling. In WWW’08, pages 121–130, 2008.
[21] W. Ma, L. Chen, X. Zhang, Y. Zhou, and B. Xu. How do developers ﬁx cross-project correlated bugs? a case study on the github scientiﬁc python ecosystem. In ICSE’17, pages 381–392, 2017.
[22] Y. Meng, J. Shen, C. Zhang, and J. Han. Weakly-supervised neural text classiﬁcation. In CIKM’18, pages 983–992, 2018.
[23] Y. Meng, J. Shen, C. Zhang, and J. Han. Weakly-supervised hierarchical text classiﬁcation. In AAAI’19, pages 6826–6833, 2019.
[24] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed representations of words and phrases and their compositionality. In NIPS’13, pages 3111–3119, 2013.
[25] T. Miyato, A. M. Dai, and I. J. Goodfellow. Adversarial training methods for semi-supervised text classiﬁcation. In ICLR’16, 2016.
[26] H. Peng, J. Li, Y. He, Y. Liu, M. Bao, L. Wang, Y. Song, and Q. Yang. Large-scale hierarchical text classiﬁcation with recursively regularized deep graph-cnn. In WWW’18, pages 1063–1072, 2018.
[27] B. Perozzi, R. Al-Rfou, and S. Skiena. Deepwalk: Online learning of social representations. In KDD’14, pages 701–710, 2014.
[28] G. A. A. Prana, C. Treude, F. Thung, T. Atapattu, and D. Lo. Categorizing the content of github readme ﬁles. Empirical Software Engineering, pages 1–32, 2018.
[29] P. H. Russell, R. L. Johnson, S. Ananthan, B. Harnke, and N. E. Carlson. A large-scale analysis of bioinformatics code on github. PLOS One, 13(10):e0205898, 2018.
[30] D. S. Sachan, M. Zaheer, and R. Salakhutdinov. Revisiting lstm networks for semi-supervised text classiﬁcation via mixed objective function. In AAAI’19, pages 6940–6948, 2019.
[31] J. Shang, M. Qu, J. Liu, L. M. Kaplan, J. Han, and J. Peng. Metapath guided embedding for similarity search in large-scale heterogeneous information networks. arXiv preprint arXiv:1610.09769, 2016.
[32] A. Sharma, F. Thung, P. S. Kochhar, A. Sulistya, and D. Lo. Cataloging github repositories. In EASE’17, pages 314–319, 2017.
[33] Y. Song and D. Roth. On dataless hierarchical text classiﬁcation. In AAAI’14, pages 1579–1585, 2014.
[34] Y. Sun and J. Han. Mining heterogeneous information networks: principles and methodologies. Synthesis Lectures on Data Mining and Knowledge Discovery, 3(2):1–159, 2012.
[35] Y. Sun, J. Han, X. Yan, P. S. Yu, and T. Wu. Pathsim: Meta path-based top-k similarity search in heterogeneous information networks. PVLDB, 4(11):992–1003, 2011.
[36] Y. Sun, Y. Yu, and J. Han. Ranking-based clustering of heterogeneous information networks with star network schema. In KDD’09, pages 797–806. ACM, 2009.
[37] J. Tang, M. Qu, and Q. Mei. Pte: Predictive text embedding through large-scale heterogeneous text networks. In KDD’15, pages 1165–1174, 2015.
[38] J. Tang, M. Qu, M. Wang, M. Zhang, J. Yan, and Q. Mei. Line: Largescale information network embedding. In WWW’15, pages 1067–1077, 2015.
[39] J. Tsay, L. Dabbish, and J. Herbsleb. Inﬂuence of social and technical factors for evaluating contribution in github. In ICSE’14, pages 356–366. ACM, 2014.
[40] J. T. Tsay, L. Dabbish, and J. Herbsleb. Social media and success in open source projects. In CSCW’12, pages 223–226, 2012.
[41] H. Xiao, X. Liu, and Y. Song. Efﬁcient path prediction for semisupervised and weakly supervised hierarchical text classiﬁcation. In WWW’19, pages 3370–3376, 2019.
[42] C. Yang, Y. Feng, P. Li, Y. Shi, and J. Han. Meta-graph based hin spectral embedding: Methods, analyses, and insights. In ICDM’18, pages 657– 666, 2018.
[43] Z. Yang, D. Yang, C. Dyer, X. He, A. Smola, and E. Hovy. Hierarchical attention networks for document classiﬁcation. In NAACL’16, pages 1480–1489, 2016.
[44] Y. Zhang, D. Lo, P. S. Kochhar, X. Xia, Q. Li, and J. Sun. Detecting similar repositories on github. In SANER’17, pages 13–23, 2017.

