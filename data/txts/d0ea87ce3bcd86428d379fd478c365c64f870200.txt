SGD-X: A Benchmark for Robust Generalization in Schema-Guided Dialogue Systems
Harrison Lee*, Raghav Gupta*, Abhinav Rastogi, Yuan Cao, Bin Zhang, Yonghui Wu
Google Research {harrisonlee,raghavgupta,abhirast,yuancao,zbin,yonghui}@google.com

arXiv:2110.06800v2 [cs.CL] 25 Jan 2022

Abstract
Zero/few-shot transfer to unseen services is a critical challenge in task-oriented dialogue research. The Schema-Guided Dialogue (SGD) dataset introduced a paradigm for enabling models to support an unlimited number of services without additional data collection or re-training through the use of schemas. Schemas describe APIs in natural language, which models consume to understand the services they need to support. However, the impact of the choice of language in these schemas on model performance remains unexplored. We address this by releasing SGD-X, a benchmark for measuring the robustness of dialogue systems to linguistic variations in schemas. SGD-X extends the SGD dataset with crowdsourced variants for every schema, where variants are semantically similar yet stylistically diverse. We evaluate two topperforming dialogue state tracking models on SGD-X and observe that neither generalizes well across schema variants, measured by joint goal accuracy and a novel metric for measuring schema sensitivity. Finally, we present a simple modelagnostic data augmentation method to improve schema robustness and zero-shot generalization to unseen services.
1 Introduction
Task-oriented dialogue systems have begun changing how we interact with technology, from personal assistants to customer support. One obstacle preventing their ubiquity is the resources and expertise needed for their development. Traditional approaches operate on a ﬁxed ontology (Henderson, Thomson, and Young 2014; Mrksˇic´ et al. 2017), which is not suited for a dynamic environment. For every new service that arises or modiﬁcation to an existing service, training data must be re-collected and systems re-trained.
The schema-guided dialogue paradigm, introduced in Rastogi et al. (2020b), advocates for the creation of a universal dialogue system which can interface with any service, without service or domain-speciﬁc optimization. Each service is represented by a schema, which enumerates the slots and intents of the service and describes their functionality in natural language (see Figure 1). Schema-guided dialogue systems then interpret conversations, execute API calls, and respond to users based on the schemas provided to it. In theory, this enables a single system to support any service, but
*Equal contribution Copyright © 2022, Association for the Advancement of Artiﬁcial Intelligence (www.aaai.org). All rights reserved.

whether this is feasible in practice hinges on how robustly models can generalize beyond services seen during training.
In the Schema-Guided Dialogue State Tracking challenge at DSTC8 (Rastogi et al. 2020a), participants developed schema-guided models for dialogue state tracking, which were evaluated on both seen and unseen services. While results were promising, with the top team achieving 87% joint goal accuracy (92% on seen, 85% on unseen) on the test set, we observed a major shortcoming in the SGD dataset - the schemas are linguistically uniform when compared to the diverse writing styles encountered “in the wild”, where schemas are written by API developers of various backgrounds.
The uniformity of SGD’s schema element names epitomizes this point. In the 15 test set schemas “unseen” in the train set, 71% of intent names and 65% of slot names exactly match names appearing in the train schemas, meaning most names in “unseen” schemas are actually already seen by the model during training. MultiWOZ (Budzianowski et al. 2018), another popular dialogue state tracking benchmark, faces similar issues in the zero-shot leave-one-domain-out setup (Wu et al. 2019), with 60-100% of slot names in the held-out domain already seen by the model during training. Descriptions face a similar problem; for example, all descriptions for boolean slots either begin with the words “Boolean ﬂag...” or “Whether...”.
We hypothesize that the uniformity of SGD schemas allows models to overﬁt on speciﬁc linguistic styles without penalty in evaluation, leading to an overoptimistic view of the generalizability of models. Additionally, the fact that “seen” schemas in evaluation are identical to the schemas used in training means that SGD cannot evaluate how well models handle changes in seen schemas, however minor.
In this work, we investigate the robustness of schemaguided models to linguistic styles of schemas. Our contributions are as follows:
• We introduce SGD-X, an extension to the SGD dataset that contains crowdsourced stylistic variations for every schema in the original dataset1
1We release SGD-X and an evaluation script for schemaguided dialogue state tracking models on GitHub at https://github.com/google-research-datasets/dstc8-schema-guideddialogue

Figure 1: The original schema for a Payment service (left) alongside its closest (center) and farthest (left) SGD-X variants, as measured by linguistic distance functions. We study the robustness of models to different writing styles used in schemas.

• Based on SGD-X, we propose schema sensitivity as an auxiliary metric to accuracy metrics for evaluating the sensitivity of models to schema variations
• We show that the top open-sourced schema-guided dialogue state tracking (DST) model and a highly performing T5-based DST model are not robust to schema variations, dropping as much as -18% (relative) on joint goal accuracy for the average SGD-X variant
• We demonstrate that back-translation is an effective, model-agnostic technique for improving schema robustness
2 The SGD-X Dataset
We curate SGD-X, short for Schema Guided Dialogue eXtended, to evaluate the robustness of schema-guided dialogue models to the schema input. Following the SGD terminology, we deﬁne a schema as a collection of intents and slots belonging to a service, along with metadata that describe the intended behavior of these intents and slots. A key feature of the SGD dataset was the inclusion of natural language descriptions for each intent and slot as well as the service. For example, an intent “SearchMap” might have the description “Search for a location of interest on the map”.
SGD-X offers variations of the names and descriptions of services, intents, and slots, hereafter referred to as schema elements. Speciﬁcally, SGD-X provides 5 variant schemas for every 1 schema in the original dataset, where each variant replaces the original schema element names and descriptions with semantically similar paraphrases. Figure 1 shows an original schema alongside two variants. We provide more details on the dataset and its collection below.
2.1 “Blind” Paraphrase Collection
Schema element names and descriptions in the original SGD dataset were written by a small set of authors, and achiev-

ing linguistic diversity was not an explicit goal. To diversify SGD-X, we crowdsourced paraphrases across 400+ authors through Amazon Mechanical Turk. We chose crowdsourcing over automatic paraphrasing methods because we found that automatic methods were often semantically inaccurate and provided insufﬁcient linguistic diversity, especially when the text was short. We designed two crowdsourcing tasks:
Paraphrasing names: To paraphrase names, we provided crowdworkers with a schema element’s original long-form description from the SGD dataset and asked them to generate a short name that would capture the description. We deliberately did not share the original names to encourage a diversity of paraphrases - hence “blind” paraphrasing.
Paraphrasing descriptions: To generate descriptions, we reversed the name paraphrasing prompt - i.e. given only the name of a schema element, we asked crowdworkers to come up with a one sentence description. For certain schema elements, we provided additional information:
• If intent and slot names were ambiguous on their own (e.g. the “intent” slot from the Homes service, which indicates whether a user is interested in buying or renting property), the original description was shown
• For categorical slots, their possible values were shown
For a given task, a crowdworker was given a single service and asked to come up with either all names or all descriptions for its schema elements.
After collecting raw responses, we deduplicated then manually vetted responses for quality and correctness. Our primary criterion was whether a variant could reasonably replace the original, and sometimes “paraphrases” did not fully overlap semantically with the original as traditional paraphrasing typically requires. For instance, consider the intent name FindHomeByArea and its variant SearchByLocation. The variant doesn’t reference the

“home” concept in its name, but we considered it a valid variant because it is implied that the search is for homes in the broader context of the Homes service.
We created enough tasks to collect approximately 10 paraphrases per schema element name and description. At the end of the collection and vetting phase, we had at least 5 paraphrases for every name and description. If we had more than 5, we selected 5 at random for the schema composition step.

2.2 Composing Schema Variants

We composed 5 schema variants, where each variant replaces every name and description in the original schema with a crowdsourced paraphrase. One property we desired was for variants to increasingly diverge from the original schemas as the variant number increases. To decide which paraphrases to use for each variant, we sorted each schema element’s name/description paraphrases by their distance from the original name/description using the following metrics:

• For names, we used Levenshtein distance

• For descriptions, we used Jaccard distance, where stopwords were removed and words were lemmatized using spaCy (Honnibal et al. 2020)

After sorting, for every schema element elem, we had a

set

of

unique

name

paraphrases

N elem

=

{n

elem idx

}

,

idx

∈

{1..5}, ordered by increasing Levenshtein distance from the

original name negltem. Similarly for each schema element de-

scription, we had a set of unique description paraphrases

Delem = {deidlexm}, idx ∈ {1..5}, ordered by increasing Jaccard distance from the original description degltem.

Finally to compose the idxth schema variant, for every

elem in the schema, we simply selected neidlexm and deidlexm. This ensured that the 5 variant schemas increasingly diverge

from the original as the variant number increases, which es-

tablishes the SGD-X benchmark as a series of increasingly

challenging evaluation sets. Henceforth in this paper, we re-

fer to these schemas as v1 through v5, where v1 refers to

the variant schema closest to the original and v5 the farthest.

Figure 1 compares an original schema with its ﬁrst and ﬁfth

variant to highlight the increasing divergence property.

2.3 Dataset Statistics
The original SGD dataset contains 45 schemas with a total of 365 slots and 88 intents. Each schema element is associated with 1 name and 1 description (though service names were not paraphrased). After compiling paraphrases into variant schemas, SGD-X presents 5 variants for every schema, totalling 4,755 paraphrases. Each schema variant is composed of paraphrases from multiple crowdworkers. Designing the tasks, collecting data, manually vetting responses, and composing the variants took approximately 1 month.
As mentioned in Section 1, one concern with the original test set is that roughly 70% of the slot and intent names in the 15 “unseen” schemas appear in training schemas. In contrast, that ﬁgure drops to 8% for slot names and 2% for intent names for the average SGD-X variant.

Metric

Schema variant Orig v1 v2 v3 v4 v5 Avg

%seeonf itnesttrasilnot names 65% 13% 14% 5% 6% 2% 8%

%seeonf itnesttrainintent names 71% 0% 0% 4% 0% 4% 2%

Levenshtein Distance (names)

- 0.30 0.42 0.49 0.56 0.61 0.48

BLEU (descriptions) - 18.8 11.3 5.6 2.9 1.0 7.9

Table 1: SGD-X dataset statistics. The metrics show high linguistic variation from the original SGD schemas.

Table 1 presents metrics to measure the divergence between the original and paraphrased elements. For names, the average normalized Levenshtein distance from original to paraphrase is about 0.5, indicating high variation. For descriptions, the average BLEU score between original and paraphrase is 7.9, and the average BLEU score between paraphrased descriptions (i.e. self-BLEU) is 4.5, indicating a large diversity of descriptions.

3 Evaluation Methodology
To evaluate models on SGD-X, we propose averaging standard performance metrics over the 5 variants and additionally evaluating consistency of predictions across variants. Together, these two metrics give a sense of raw model performance as well as how sensitive models are to linguistic variations in schemas. Below, we ﬁrst describe our schema sensitivity metric, followed by our general proposal for training and evaluating dialogue systems on SGD-X, and ﬁnally a detailed proposal for evaluating dialogue state tracking models speciﬁcally.

3.1 Schema Sensitivity Metric
Let M be a turn-level evaluation metric, which takes a prediction and ground truth at turn t as input, and returns a score. Let K denote the number of schema variants, pkt denote turn-level predictions for variant k, and gt denote the ground-truth at turn t. We deﬁne schema sensitivity (SS) for the metric M as the turn-level Coefﬁcient of Variation (CoV ) of the metric value (i.e., the standard deviation normalized by the mean) averaged over all turns in the evaluation set. This is described by the following set of equations:

SSM = 1 CoVt = 1 σt (1)

|T | t∈T

|T | t∈T x¯t

where the standard deviation σt and mean x¯t are deﬁned as follows:

K
(M(pkt , gt) − M(pt, gt))2

st = k=1

(2)

K −1

x¯t = M(pt, gt)

(3)

K

Here, M(pt, gt)

=

1 K

M(pkt , gt) is the average of

k=1

the metric corresponding to predictions over all K variants

in turn t, and T is the set of all turns in the eval set.

Intuitively, schema sensitivity quantiﬁes how much pre-

dictions ﬂuctuate when exposed to schema variants, inde-

pendent of the prediction correctness. Models with lower

SS are more robust to schema changes. SS may be com-

puted for any turn-level or dialogue-level metric across the

schema-guided dialogue modeling pipeline.

Metric design considerations: We chose Coefﬁcient of

Variation (CoV ) over standard deviation to represent vari-

ability since the mean normalization allows for comparison

of variability across dialogue modeling components such as

DST and NLG as well as between two models with differing

absolute performance.

For the standard deviation used in the numerator of CoV ,

we employ the sample standard deviation because we view

the K variants as a sample of the total population of possible

ways a schema could be written. Using the sample standard

deviation instead of the population standard deviation results

in a less biased estimate of the true variability of the model.

Finally, by computing CoV at the turn-level and then av-

eraging instead of averaging M across all turns before com-

puting CoV , we increase the metric’s sensitivity to changes

in prediction stability. Computing SS as the average turn-

level CoV also provides us with a sense of how much a

model’s predictions can be expected to ﬂuctuate for a given

turn depending on how the schema is written.

3.2 General Evaluation on SGD-X
In order to measure model robustness to linguistic styles of schemas, we propose the following evaluation setup:
1. Models are trained on the original SGD schemas in the train set. They are not exposed to any SGD-X variant schemas, as this would let models “peek” at the variants in the evaluation set
2. Models are evaluated on their performance against the 5 SGD-X variant schemas. The original SGD schemas are not used in evaluation, since models have already seen them during training
3. Finally, performance on SGD-X is measured by two types of metrics:
(a) An average of standard performance metrics over the 5 variants
(b) Schema sensitivity metrics corresponding to the standard performance metrics
Using this training and evaluation setup best measures a model’s ability to generalize to schemas written by a diverse set of authors.

3.3 Dialogue State Tracking on SGD-X
Because schema-guided dialogue state tracking (DST) is relatively well-studied, we apply the recommendations from section 3.2 and outline the training and evaluation procedure

Figure 2: Input to one of the four sub-models of SGP-DST responsible for free-form slot value prediction. The last 2 dialogue utterances, a “null” token, and the slot description are concatenated (green), and the context feature takes on a value based on the slot’s role in the dialogue up until the current point in time. After encoding, a slot value is predicted by selecting a span from the user utterance. Figure borrowed from Ruan et al. (2020).
on SGD-X. We propose scoring models on 2 metrics: Average Joint Goal Accuracy (JGAv1−5 ) and Schema Sensitivity of JGA (SSJGA).
We ﬁrst compute model predictions across each of the |T | dialogue turns in the eval set |K| times - once for each of the schema variants - for a total of |T | ∗ |K| predictions.
For our ﬁrst metric, we compute the average turn-level JGA, which can be expressed as follows:
TK
J GA(pkt , gt) J GAv1−5 = t=1 k=|1T | ∗ |K| (4)
Our second metric is simply the schema sensitivity SS of the JGA, calculated following Equation (1).
Note that for J GAv1−5 and SSJGA calculations, we only use predictions on the SGD-X variant evaluation schemas and not the original SGD schemas. This eliminates models beneﬁting from overﬁtting on the original schema writing styles.
Schema-guided DST models should be evaluated along both metrics, where JGAv1−5 will typically be the primary metric and SSJGA as an auxiliary metric. The precise tradeoff between the two metrics when evaluating candidate models will depend on the context in which the model will be be used (e.g. does higher performance matter more or prediction consistency?). In the next section, we apply this evaluation on two DST models.
4 Experiments
Given schema-guided modeling for DST is relatively well studied, we use SGD-X to conduct two classes of robustness experiments:
1. We train models on original SGD and evaluate against SGD-X
2. We experiment with data augmentation techniques to improve performance on SGD-X
We use the following models for our experiments:

Figure 3: Example inputs and outputs for ﬁne-tuning the T5DST model. The model is run once for each slot. The dialogue history (blue), service (green), slot name (orange), and slot description (dark gray) are input to the model, and the predicted value is decoded. Figure borrowed from Lee, Cheng, and Ostendorf (2021).

Model SGPDST
T5DST

Eval subset
all services seen only unseen only all services seen only unseen only

J GAOrig 60.5 80.1 54.0 72.6 89.7 66.9

J GAv1−5 49.9 60.7 46.3
64.0 79.3 58.9

Dif frel -17.6 -24.3 -14.3 -11.9 -11.6 -12.0

S SJ GA 51.9 51.5 52.0 40.4 31.9 43.3

Table 2: Evaluation of two top-performing DST models on the SGD-X test set. Both models experience substantial declines in performance when exposed to variant schemas.

• SGP-DST2 (Ruan et al. 2020) - the highest-performing model with publicly available code. 4 sub-models are trained from independent BERT-Base encoders, each specializing in a sub-task. Each one takes the dialogue and relevant schema element names/descriptions as input and outputs predictions, which are then combined across the 4 models using rules. Figure 2 illustrates one submodel.
• T5DST (Lee, Cheng, and Ostendorf 2021) - a generative model trained by ﬁne-tuning T5-Base (Raffel et al. 2020) to predict slot values given the dialogue context, service, slot name, and slot description, which achieves SOTA results on MultiWOZ 2.2. Figure 3 depicts the model input and output.
4.1 Train on SGD, Evaluate on SGD-X
We trained both models on the original SGD training set with the settings that produce their reported results, and then evaluated them on the SGD and SGD-X test sets. More training details in the Supplementary Material section.
Results: Table 2 shows the top-line results of evaluation on SGD-X, and Figure 4 shows JGA by variant. Both models see signiﬁcant drops in joint goal accuracy, with SGP-DST and T5DST declining -17.6% and -11.9% respectively on average. For both models, the decline in JGA tends to increase in magnitude as the distance from the original schemas (reﬂected by the variant number) increases, with the two models dropping as much as -28% and -19% respectively for their worst variants. These results reveal that evaluating solely on the original SGD dataset overestimates the generalization capability of schema-guided DST models.
2While the authors of SGP-DST report 72.2% JGA on the original SGD test set, we were only able to reproduce 60.5% JGA, even when training with the recommended hyperparameters.

Figure 4: JGA achieved by SGP-DST and T5DST respectively on the test set for the original SGD dataset and the ﬁve SGD-X variants. Both models fail to generalize well to variants of the original schemas.
For SGP-DST, the JGA drop is much greater for seen services than unseen services. Recall that in this evaluation setup, the “seen” schemas are no longer linguistically identical to the schemas the models trained on. The larger decline suggests that SGP-DST likely overﬁt to the exact language used in seen schemas. Performance on unseen schemas also declines for both models, which we hypothesize is due to overﬁtting on the linguistic styles in the original SGD dataset, as mentioned in Section 1.
On schema sensitivity, T5DST scores almost 12 points lower than SGP-DST in addition to achieving higher JGAv1−5 , indicating it is superior to SGP-DST in both dimensions.
We observe that both models face robustness issues despite having powerful pre-trained language models as their base encoders, which have demonstrated immense success when applied to a variety of natural language tasks. We hypothesize that the models lose some of their generalization

Model SGPDST
T5DST

Aug method
None Backtrans Oracle None Backtrans Oracle

J GAv1−5 49.9
54.1 (+8%) 66.2 (+33%)
64.0 70.8 (+11%) 73.3 (+15%)

S SJ GA 51.9
43.1 (-17%) 22.5 (-57%)
40.4 34.0 (-16%) 24.6 (-39%)

Table 3: Results for different schema augmentation methods on SGP-DST and T5DST models. Back-translation improves robustness for both models as measured by both metrics. Oracle augmentation, which involves augmenting SGD-X variant schemas, serves as an approximate upper bound for paraphrasing-based augmentation methods.

capabilities during the ﬁne-tuning stage, a phenomenon also observed in other settings (Jiang et al. 2020).
4.2 Schema Augmentation
The results in Section 4.1 suggest both models overﬁt on the writing styles in the training set, reducing their ability to generalize to new styles. Data augmentation is a technique for improving robustness (Hou et al. 2018; Yoo, Shin, and Lee 2019). To this end, we experiment with a simple back-translation approach (Sennrich, Haddow, and Birch 2016) for augmenting the training schemas and study its impact on model performance and schema sensitivity. In addition, to establish an approximate upper-bound for how much improvement paraphrasing-based schema augmentation can bring, we also evaluate the impact of augmenting the SGDX crowdworker-collected paraphrases during training.
Back-translation: For each schema, we back-translate its schema element names and descriptions three times using Google Translate to create three alternate schemas: one each for Mandarin, Korean, and Japanese - chosen for their relatively high difﬁculty and consequent diversity of backtranslated paraphrases. The average normalized Levenshtein distance for names and BLEU score for descriptions between the originals and their back-translations are 0.14 and 34.1 respectively. Self-BLEU among back-translated variants schemas is 41.8. These metrics indicate a moderate degree of linguistic deviation from original schemas and intra-variant diversity, but still much less than the SGD-X variants, which average 0.48 Levenshtein distance and 7.9 BLEU and, with a self-BLEU of 4.5.
Once these variant schemas were created, new training examples were generated using the same dialogues as the original training set, but with schema inputs drawn from the variant schemas. When training on the augmented dataset, models encounter the same dialogue multiple times in a given epoch, where schema element names and descriptions differ for each version.
SGD-X Crowdsourced Paraphrases (Oracle): During crowdsourcing, we collected paraphrases for all 45 schemas across train, dev, and test sets. Similarly to the backtranslation experiment, for this experiment we use the crowdsourced v1 through v5 training set schemas to augment the training data. Note that this approach should be seen

Figure 5: J GAv1−5 for the SGP-DST and T5DST models with different schema augmentation methods, split by seen and unseen services. Back-translation improves performance on both seen and unseen services.
as an oracle for paraphrasing-based schema augmentation since this involves collecting roughly 5K human paraphrases for schema element names/descriptions. Furthermore, for a given variant vi, the schema element names and descriptions are the same for a service across train and eval sets. This means that models have already been exposed to the exact language used in seen schemas during training, giving them an unrealistic advantage on those services during evaluation.
Results: We train the SGP-DST and T5DST models using the two aforementioned schema augmentation approaches and report the summarized results in Table 3 and Figure 5.
Training with back-translated schemas improves the robustness of both models. Accuracy on SGD-X increases by +8% for SGP-DST and +11% for T5DST (relative), and it decreases schema sensitivity -17% and -16%, respectively. The improvement is considerable for unseen as well as seen schemas, suggesting that training with diverse schemas improves model generalization. This result is consistent with Wei et al. (2021), which hypothesizes that increasing diversity of training data improves performance on unseen tasks. The oracle method further improves joint goal accuracy and schema sensitivity beyond back-translation - a useful reference for how much paraphrasing-based schema augmentation can improve performance.
Although the models do not achieve parity with performance on the original SGD test set (54.1% vs. 60.1% JGA for SGP-DST, 70.8% vs. 72.6% for T5DST), much of the decline is recouped. Not only is this technique effective, but it is easy to implement and requires no changes to modeling code.
Given that back-translating schemas with Mandarin, Korean, and Japanese already produces a relatively high BLEU score of 34.1 despite being tough to translate, we hypoth-

Service Weather (seen)

Dialogue USER: What will the weather in Portland be on the 14th?

Slot Name and Description O: city - Name of the city
v1: city name - Name of place

Predicted Value Portland
None

Payment (unseen)

USER: I need to make a payment from my visa.

O: payment method - The source of
money used for making the payment v5: money withdrawal source - What is being used to pay, either app bal-
ance or debit/credit card

credit card app balance

Table 4: Examples where the T5DST model fails to predict the slot correctly for some SGD-X variant schemas. O represents the original, and vi represents the i-th SGD-X schema.

esize that incorporating additional back-translated schemas from other languages would not greatly increase the diversity of linguistic styles. As a result, we believe that simply scaling to more languages would yield limited improvements in performance. One alternative to further increase diversity would be to introduce sampling into the decoding steps of back-translation to generate more linguistic variants.
Other augmentation methods: Besides backtranslation, we also experimented with augmenting corrupted versions of schemas, where we randomly replaced words and perturbed word order. However, we did not see improvements over the non-augmented models, which we hypothesize is due to a mismatch between the corrupted training schemas and real test schemas.
Besides augmenting schemas, augmenting dialogues has shown promise in other settings and could improve robustness as well (Ma et al. 2019; Noroozi et al. 2020).
5 Analysis
To gain better intuition of model robustness issues, we inspect cases where T5DST predicts incorrectly when given variant schemas. We also analyze T5DST’s performance at the service-level. All analysis is done on T5DST trained only on the original SGD schemas.
5.1 Visually Inspecting Errors
To gain more intuition on robustness errors, we visually inspected examples where T5DST fails to predict slots correctly when provided with variant schemas.
We observe that many errors arise from failing to predict slots as active. For example, in the Weather dialogue in Table 4, the model correctly predicts “city = Portland” when given the original schema but mis-predicts “city name = None” for the v1 variant. In these cases, the model may not understand the slot name and description well, possibly leading it believe the slot is irrelevant for the current dialogue.
We also observe cases where the model correctly predicts a categorical slot as active but predicts the value incorrectly. For example, in the Payment dialogue in Table 4, the model predicts that the slot for “money withdrawal source” is “app balance” instead of “credit card” when given the v5 schema. Since T5DST is a generative model, one hypothesis is that it has a strong prior for decoding certain words inﬂuenced

Figure 6: A plot showing Average Joint Goal Accuracy (J GAv1−5 ) and Schema Sensitivity (SSJGA) on the test set for the T5DST model trained only on original SGD. Each point represents a service. The model tends to be less sensitive to schema variations for services it predicts more accurately.
by the token distribution in the training set. Though the Payment service is not seen in training, the model is taught to decode the word “balance”, which is present in a few places in the Banks schema. On the other hand, the word “credit” doesn’t appear in any training schema. This decoding bias may have led the model to mis-predict “app balance” instead of “credit card”.
While SGD’s original schemas and SGD-X variant schemas are very semantically similar from humans’ perspective, these slight perturbations have an outsized impact on model performance. These errors highlight the degree of model overﬁtting on the writing style of the original SGD dataset.
5.2 Service-level Results
In order to dissect model performance further, we plot the Average JGA (JGAv1−5 ) and the Schema Sensitivity to JGA (SSJGA) by service, shown in Figure 6. We observe that higher J GAv1−5 tends to correspond to lower SSJGA. This suggests that the model makes stable predictions for services it does well on, seen or unseen.
Given how SSJGA is deﬁned, for a given service, a model could predict the dialogue state inaccurately yet also achieve

a desirably low schema sensitivity. However, our results suggest that this is atypical, with Flights 4 being one of the exceptions to this pattern. We hypothesize that Flights 4 deﬁes this pattern because it is exceptionally difﬁcult for the model, leading the model to make uniformly poor predictions regardless of which schema variant it is given.
6 Related Work
Model robustness is an active area of NLP research (Goel et al. 2021) and has many interpretations, such as to noise (Belinkov and Bisk 2018), distribution shift (Hendrycks et al. 2020) and adversarial input (Jia and Liang 2017).
As they are inherently public-facing in nature, the robustness of dialogue systems to harmful inputs (Dinan et al. 2019; Cheng, Wei, and Hsieh 2019) and input noise (Einolghozati et al. 2019; Liu et al. 2020), such as ASR error, misspellings, and user input paraphrasing have been explored. However, robustness to API schemas for schema-guided dialogue systems remains relatively unexplored.
Schema-guided modeling aims to build task-oriented dialogue systems that can generalize easily to new verticals using very little extra information, including for slot ﬁlling (Bapna et al. 2017; Shah et al. 2019; Liu et al. 2020) and dialogue state tracking (Li et al. 2021; Campagna et al. 2020; Kumar et al. 2020) among other tasks. More recent work has adopted the schema-guided paradigm (Ma et al. 2019; Li, Xiong, and Cao 2020; Zhang et al. 2021) and even extended the paradigm in functionality (Mosig, Mehri, and Kober 2020; Mehri and Eskenazi 2021).
Lin et al. (2021) and Cao and Zhang (2021) both investigate natural language description styles for zero/few-shot dialogue state tracking. The former experiments with homogeneously training and evaluating on different description styles, unlike our work. The latter performs heterogeneous evaluation of template-based description styles (e.g. rephrasing slot name as a question). Models are also evaluated against paraphrased descriptions created via backtranslation but only decline slightly in performance.
7 Conclusion
In this work, we present SGD-X, a benchmark dataset for evaluating the robustness of schema-guided models to schema writing styles. To evaluate robustness, we propose training models on SGD, predicting on SGD-X, and ﬁnally measuring standard performance metrics alongside a novel schema sensitivity metric that quantiﬁes the stability of model predictions across variants.
Applying this to two of the highest-performing schemaguided DST models, we discover that both perform substantially worse on SGD-X than SGD, suggesting that evaluating solely on SGD overestimates models’ ability to generalize to real-world schemas. It’s noteworthy that we witness this decline on models based on T5 and BERT - two popular large language models in research and production. We further demonstrate that back-translating schemas for training data augmentation is an effective, model-agnostic technique for recovering some of this decline while simultaneously reducing schema sensitivity.

We note that the weaknesses of evaluating only on the original SGD dataset uncovered in this work also apply to the leave-one-domain-out zero-shot evaluation on the popular MultiWOZ dataset. Also, while dialogue state tracking is the focal point of this work, SGD-X is applicable to evaluating the robustness of other schema-guided dialogue components (e.g. policy, NLG). We hope that releasing this paper and benchmark motivates further research in the area of schema robustness.
8 Ethical Considerations
Crowdsourcing details: We hired 400+ Amazon Mechanical Turk crowdworkers from the U.S. and paid USD $1-2 per task, where each task consisted of paraphrasing either names or descriptions for every element in a single schema. The median submission time was 3 minutes, which equates to US$20-40/hr. In total, we spent ∼$2000 on data collection.
References
Bapna, A.; Tur, G.; Hakkani-Tur, D.; and Heck, L. 2017. Towards zero-shot frame semantic parsing for domain scaling. arXiv preprint arXiv:1707.02363.
Belinkov, Y.; and Bisk, Y. 2018. Synthetic and Natural Noise Both Break Neural Machine Translation. In International Conference on Learning Representations.
Budzianowski, P.; Wen, T.-H.; Tseng, B.-H.; Casanueva, I.; Ultes, S.; Ramadan, O.; and Gasˇic´, M. 2018. MultiWOZ– A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling. arXiv preprint arXiv:1810.00278.
Campagna, G.; Foryciarz, A.; Moradshahi, M.; and Lam, M. 2020. Zero-Shot Transfer Learning with Synthesized Data for Multi-Domain Dialogue State Tracking. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 122–132.
Cao, J.; and Zhang, Y. 2021. A Comparative Study on Schema-Guided Dialogue State Tracking. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 782–796.
Cheng, M.; Wei, W.; and Hsieh, C.-J. 2019. Evaluating and enhancing the robustness of dialogue systems: A case study on a negotiation agent. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 3325–3335.
Dinan, E.; Humeau, S.; Chintagunta, B.; and Weston, J. 2019. Build it Break it Fix it for Dialogue Safety: Robustness from Adversarial Human Attack. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), 4537–4546.
Einolghozati, A.; Gupta, S.; Mohit, M.; and Shah, R. 2019. Improving robustness of task oriented dialog systems. arXiv preprint arXiv:1911.05153.

Goel, K.; Rajani, N.; Vig, J.; Taschdjian, Z.; Bansal, M.; and Re´, C. 2021. Robustness Gym: Unifying the NLP Evaluation Landscape. NAACL-HLT 2021, 42.
Henderson, M.; Thomson, B.; and Young, S. 2014. Wordbased dialog state tracking with recurrent neural networks. In Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), 292– 299.
Hendrycks, D.; Basart, S.; Mu, N.; Kadavath, S.; Wang, F.; Dorundo, E.; Desai, R.; Zhu, T.; Parajuli, S.; Guo, M.; et al. 2020. The many faces of robustness: A critical analysis of out-of-distribution generalization. arXiv preprint arXiv:2006.16241.
Honnibal, M.; Montani, I.; Van Landeghem, S.; and Boyd, A. 2020. spaCy: Industrial-strength Natural Language Processing in Python.
Hou, Y.; Liu, Y.; Che, W.; and Liu, T. 2018. Sequence-toSequence Data Augmentation for Dialogue Language Understanding. In Proceedings of the 27th International Conference on Computational Linguistics, 1234–1245.
Jia, R.; and Liang, P. 2017. Adversarial Examples for Evaluating Reading Comprehension Systems. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, 2021–2031.
Jiang, H.; He, P.; Chen, W.; Liu, X.; Gao, J.; and Zhao, T. 2020. SMART: Robust and Efﬁcient Fine-Tuning for Pretrained Natural Language Models through Principled Regularized Optimization. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics.
Kingma, D. P.; and Ba, J. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980.
Kumar, A.; Ku, P.; Goyal, A.; Metallinou, A.; and HakkaniTur, D. 2020. Ma-dst: Multi-attention-based scalable dialog state tracking. In Proceedings of the AAAI Conference on Artiﬁcial Intelligence, volume 34, 8107–8114.
Lee, C.-H.; Cheng, H.; and Ostendorf, M. 2021. Dialogue State Tracking with a Language Model using SchemaDriven Prompting. arXiv preprint arXiv:2109.07506.
Li, M.; Xiong, H.; and Cao, Y. 2020. The sppd system for schema guided dialogue state tracking challenge. arXiv preprint arXiv:2006.09035.
Li, S.; Cao, J.; Sridhar, M.; Zhu, H.; Li, S.-W.; Hamza, W.; and McAuley, J. 2021. Zero-shot Generalization in Dialog State Tracking through Generative Question Answering. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, 1063–1074.
Lin, Z.; Liu, B.; Moon, S.; Crook, P. A.; Zhou, Z.; Wang, Z.; Yu, Z.; Madotto, A.; Cho, E.; and Subba, R. 2021. Leveraging Slot Descriptions for Zero-Shot Cross-Domain Dialogue StateTracking. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 5640– 5648.
Liu, J.; Takanobu, R.; Wen, J.; Wan, D.; Li, H.; Nie, W.; Li, C.; Peng, W.; and Huang, M. 2020. Robustness Testing

of Language Understanding in Task-Oriented Dialog. arXiv

preprint arXiv:2012.15262.

Ma, Y.; Zeng, Z.; Zhu, D.; Li, X.; Yang, Y.; Yao, X.; Zhou,

K.; and Shen, J. 2019. An end-to-end dialogue state tracking

system with machine reading comprehension and wide &

deep classiﬁcation. arXiv preprint arXiv:1912.09297.

Mehri, S.; and Eskenazi, M. 2021. Schema-Guided

Paradigm for Zero-Shot Dialog.

arXiv preprint

arXiv:2106.07056.

Mosig, J. E.; Mehri, S.; and Kober, T. 2020. Star: A schema-

guided dialog dataset for transfer learning. arXiv preprint

arXiv:2010.11853. Mrksˇic´, N.; Se´aghdha, D. O´ .; Wen, T.-H.; Thomson, B.; and

Young, S. 2017. Neural Belief Tracker: Data-Driven Dia-

logue State Tracking. In Proceedings of the 55th Annual

Meeting of the Association for Computational Linguistics

(Volume 1: Long Papers), 1777–1788.

Noroozi, V.; Zhang, Y.; Bakhturina, E.; and Kornuta,

T. 2020. A Fast and Robust BERT-based Dia-

logue State Tracker for Schema-Guided Dialogue Dataset.

arXiv:2008.12335.

Paszke, A.; Gross, S.; Massa, F.; Lerer, A.; Bradbury, J.;

Chanan, G.; Killeen, T.; Lin, Z.; Gimelshein, N.; Antiga, L.;

et al. 2019. Pytorch: An imperative style, high-performance

deep learning library. Advances in neural information pro-

cessing systems, 32: 8026–8037.

Raffel, C.; Shazeer, N.; Roberts, A.; Lee, K.; Narang, S.;

Matena, M.; Zhou, Y.; Li, W.; and Liu, P. J. 2020. Exploring

the Limits of Transfer Learning with a Uniﬁed Text-to-Text

Transformer. arXiv:1910.10683.

Rastogi, A.; Zang, X.; Sunkara, S.; Gupta, R.; and Khai-

tan, P. 2020a. Schema-guided dialogue state tracking task

at DSTC8. arXiv preprint arXiv:2002.01359.

Rastogi, A.; Zang, X.; Sunkara, S.; Gupta, R.; and Khaitan,

P. 2020b. Towards scalable multi-domain conversational

agents: The schema-guided dialogue dataset. In Proceed-

ings of the AAAI Conference on Artiﬁcial Intelligence, vol-

ume 34, 8689–8696.

Ruan, Y.-P.; Ling, Z.-H.; Gu, J.-C.; and Liu, Q. 2020.

Fine-tuning bert for schema-guided zero-shot dialogue state

tracking. arXiv preprint arXiv:2002.00181.

Sennrich, R.; Haddow, B.; and Birch, A. 2016. Improv-

ing Neural Machine Translation Models with Monolingual

Data. In Proceedings of the 54th Annual Meeting of the

Association for Computational Linguistics (Volume 1: Long

Papers), 86–96.

Shah, D.; Gupta, R.; Fayazi, A.; and Hakkani-Tur, D. 2019.

Robust Zero-Shot Cross-Domain Slot Filling with Example

Values. In Proceedings of the 57th Annual Meeting of the

Association for Computational Linguistics, 5484–5490.

Wei, J.; Bosma, M.; Zhao, V. Y.; Guu, K.; Yu, A. W.; Lester,

B.; Du, N.; Dai, A. M.; and Le, Q. V. 2021. Finetuned Lan-

guage Models Are Zero-Shot Learners. arXiv:2109.01652.

Wu, C.-S.; Madotto, A.; Hosseini-Asl, E.; Xiong, C.;

Socher, R.; and Fung, P. 2019. Transferable Multi-

Domain State Generator for Task-Oriented Dialogue Sys-

tems. arXiv:1905.08743.

Yoo, K. M.; Shin, Y.; and Lee, S.-g. 2019. Data augmentation for spoken language understanding via joint variational generation. In Proceedings of the AAAI conference on artiﬁcial intelligence, volume 33, 7402–7409.
Zhang, Y.; Noroozi, V.; Bakhturina, E.; and Ginsburg, B. 2021. SGD-QA: Fast Schema-Guided Dialogue State Tracking for Unseen Services. arXiv preprint arXiv:2105.08049.
A Training Details
For training the SGP-DST model (Ruan et al. 2020), we used the BertAdam optimizer in PyTorch (Kingma and Ba 2014; Paszke et al. 2019) with learning rate 2e-5, warmup proportion 0.1 (except the copy slot BERT encoder within this model, which had a warmup proportion of 0.7), training batch size 32, and default settings for other parameters of the BertAdam optimizer. Each of the BERT encoders in the model was trained for 1 epoch (generally converging earlier), except the combine BERT encoder, which was trained for 3 epochs for the baseline SGP-DST model, and 1 epoch for all experiments with augmented training data. Depending on the training data size, training took between 24-36 hours on a single NVIDIA Tesla V100-SXM2 GPU core.
The SGD Baseline model (Rastogi et al. 2020b) was trained for 5 epochs with a learning rate of 1e-4 using Adam. Training took roughly 12 hours on a single NVIDIA Tesla V100-SXM2 GPU core using a training batch size of 32.
B Crowdworker Task
Figures 7 and 8 show snippets of the tasks we asked crowdworkers to do for collecting intent name paraphrases and slot description paraphrases respectively. Note that the original values for both were omitted, to encourage diversity in the crowdworker responses.
C Example Schemas
Figure 9 shows an example of an service schema from the dataset for a digital wallet service along with its ﬁve humanparaphrased variant schemas. The names and descriptions are increasingly distant from the original, and there exists sufﬁcient variation between the variant schemas themselves. Figure 10 shows, in comparison, the same schema along with its three back-translated variant schemas. It is evident that these back-translated schemas present far less diversity in the paraphrases compared to the human-paraphrased variant schemas, and introduce errors as well (e.g., ”amount” → ”sheep” in the Korean back-translated schema).

Figure 7: An example of the task shown to the crowdworker to obtain an intent name paraphrase. Figure 8: An example of the task shown to the crowdworker to obtain a slot desctription paraphrase.

Figure 9: An original schema from the SGD dataset and its ﬁve variant schemas generated from crowdworker paraphrases, in order (original, v1, v2 . . . v5 from left-to-right, top-to-bottom).

Figure 10: An original schema (left) from the SGD dataset and its three variant schemas generated through backtranslation (via Mandarin Chinese, Japanese, and Korean, left to right).

