Local SGD: Uniﬁed Theory and New Eﬃcient Methods

arXiv:2011.02828v1 [cs.LG] 3 Nov 2020

Eduard Gorbunov MIPT, Yandex, Sirius, Russia
KAUST, Saudi Arabia

Filip Hanzely KAUST, Saudi Arabia

Peter Richt´arik KAUST, Saudi Arabia

Abstract
We present a uniﬁed framework for analyzing local SGD methods in the convex and strongly convex regimes for distributed/federated training of supervised machine learning models. We recover several known methods as a special case of our general framework, including Local-SGD/FedAvg, SCAFFOLD, and several variants of SGD not originally designed for federated learning. Our framework covers both the identical and heterogeneous data settings, supports both random and deterministic number of local steps, and can work with a wide array of local stochastic gradient estimators, including shifted estimators which are able to adjust the ﬁxed points of local iterations for faster convergence. As an application of our framework, we develop multiple novel FL optimizers which are superior to existing methods. In particular, we develop the ﬁrst linearly converging local SGD method which does not require any data homogeneity or other strong assumptions.

1 Introduction

In this paper we are interested in a centralized distributed optimization problem of the form

n

min f (x) = n1 fi(x),

(1)

x∈Rd

i=1

where n is the number of devices/clients/nodes/workers. We assume that fi can be represented either as a) an expectation, i.e.,

fi(x) = Eξi∼Di [fξi (x)] ,

(2)

where Di describes the distribution of data on device i, or b) as a ﬁnite sum, i.e.,

m

fi(x)

=

1 m

fij (x).

(3)

j=1

While our theory allows the number of functions m to vary across the devices, for simplicity of exposition, we restrict the narrative to this simpler case.
Federated learning (FL)—an emerging subﬁeld of machine learning [29, 22, 28]—is traditionally cast as an instance of problem (1) with several idiosyncrasies. First, the number of devices n is very large: tens of thousands to millions. Second, the devices (e.g., mobile phones) are often very heterogeneous in their compute, connectivity, and storage capabilities. The data deﬁning each function fi reﬂects the usage patterns of the device owner, and as such, it is either unrelated or at best related only weakly. Moreover, device owners desire to protect their local private data, and for that reason, training needs to take place with the data remaining on the devices. Finally, and this is of key importance for the development in this work, communication among the workers, typically conducted via a trusted aggregation server, is very expensive.
Communication bottleneck. There are two main directions in the literature for tackling the communication cost issue in FL. The ﬁrst approach consists of algorithms that aim to reduce the number of transmitted bits by applying a carefully chosen gradient compression scheme, such as quantization [2, 5, 31, 16, 38, 40], sparsiﬁcation [1, 27, 3, 49, 48, 32], or other more sophisticated strategies [19, 46, 52, 47, 6, 10]. The second approach—one that we investigate in this paper— instead focuses on increasing the total amount of local computation in between the communication rounds in the hope that this will reduce the total number of communication rounds needed to build a model of suﬃcient quality [43, 55, 39, 24, 37]. These two approaches, communication compression and local computation, can be combined for a better practical performance [4].
Local ﬁrst-order algorithms. Motivated by recent development in the ﬁeld [56, 29, 44, 26, 25, 53, 18, 20, 51], in this paper we perform an in-depth and general study of local ﬁrst-order algorithms. Contrasted with zero or higher order local methods, local ﬁrst order methods perform several gradient-type steps in between

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

the communication rounds. In particular, we consider the following family of methods:

xki − γgik,

if ck+1 = 0,

xki +1 =  n1 n xki − γgik , if ck+1 = 1, (4)

i=1

where xki represents the local variable maintained by the i-th device, gik represents local ﬁrst order direction1 and (possibly random) sequence {ck}k≥1 with ck ∈ {0, 1} encoding the times when communication takes place.
Both the classical Local-SGD/FedAvg [29, 44, 20, 51] and shifted local SGD [25, 18] methods fall into this category of algorithms. However, most of the existing methods have been analyzed with limited ﬂexibility only, leaving many potentially fruitful directions unexplored. The most important unexplored questions include i) better understanding of the local shift that aims to correct the ﬁxed point of local methods, ii) support for more sophisticated local gradient estimators that allow for importance sampling, variance reduction, or coordinate descent, iii) variable number of local steps, and iv) general theory supporting multiple data similarity types, including identical, heterogeneous and partially heterogeneous (ζ-heterogeneous - deﬁned later).
Consequently, there is a need for a single framework unifying the theory of local stochastic ﬁrst order methods, ideally one capable of pointing to new and more eﬃcient variants. This is what we do in this work.

Uniﬁcation of stochastic algorithms. There have been multiple recent papers aiming to unify the theory of ﬁrst-order optimization algorithms. The closest to our work is the uniﬁcation of (non-local) stochastic algorithms in [9] that proposes a relatively simple yet powerful framework for analyzing variants of SGD that allow for minibatching, arbitrary sampling,2 variance reduction, subspace gradient oracle, and quantization. We recover this framework as a special case in a nonlocal regime. Next, a framework for analyzing error compensated or delayed SGD methods was recently proposed in [10]. Another relevant approach covers the uniﬁcation of decentralized SGD algorithms [21], which is able to recover the basic variant of Local-SGD as well. While our framework matches their rate for basic Local-SGD, we cover a broader range of local methods in this work as we focus on the centralized setting.

1Vector gik can be a simple unbiased estimator of ∇fi(xki ), but can also involve a local “shift” designed to correct the (inherently wrong) ﬁxed point of local methods.
We elaborate on this point later. 2A tight convergence rate given any sampling strategy
and any smoothness structure of the objective.

1.1 Our Contributions
In this paper, we propose a general framework for analyzing a broad family of local stochastic gradient methods of the form (4). Given that a particular local algorithm satisﬁes a speciﬁc parametric assumption (Assumption 2.3) in a certain scenario, we provide a tight convergence rate of such a method.
Let us give a glimpse of our results and their generality. A local algorithm of the form (4) is allowed to consist of an arbitrary local stochastic gradient estimator (see Section 4 for details), a possible drift/shift to correct for the non-stationarity of local methods3 and a ﬁxed or random local loop size. Further, we provide a tight convergence rate in both the identical and heterogeneous data regimes for strongly (quasi) convex and convex objectives. Consequently, our framework is capable of:
• Recovering known optimizers along with their tight rates. We recover multiple known local optimizers as a special case of our general framework, along with their convergence rates (up to small constant factors). This includes FedAvg/Local-SGD [29, 44] with currently the best-known convergence rate [20, 51, 21, 50] and SCAFFOLD [18]. Moreover, in a special case we recover a general framework for analyzing non-local SGD method developed in [9], and consequently we recover multiple variants of SGD with and without variance reduction, including SAGA [8], L-SVRG [23], SEGA [14], gradient compression methods [31, 16] and many more.
• Filling missing gaps for known methods. Many of the recovered optimizers have only been analyzed under speciﬁc and often limiting circumstances and regimes. Our framework allows us to extend known methods into multiple hitherto unexplored settings. For instance, for each (local) method our framework encodes, we allow for a random/ﬁxed local loop size, identical/heterogeneous/ζ-heterogeneous data (introduced soon), and convex/strongly convex objective.
• Extending the established optimizers. To the best of our knowledge, none of the known local methods have been analyzed under arbitrary smoothness structure of the local objectives4 and consequently, our framework is the ﬁrst to allow for the local stochastic gradient to be constructed via importance (possibly minibatch) sampling. Next, we allow for a local loop
3Basic local algorithms such as FedAvg/Local-SGD or FedProx [24] have incorrect ﬁxed points [37]. To eliminate this issue, a strategy of adding an extra “drift” or “shift” to the local gradient has been proposed recently [25, 18].
4By this we mean that function fi,j from (3) is Mi,jsmooth with Mi,j ∈ Rd×d, Mi,j 0, i.e., for all x, y ∈ Rd we have fi,j (x) ≤ fi,j (y) + ∇fi,j (y), x − y + 12 (x − y) Mi,j(x−y). As an example, logistic regression possesses naturally such a structure with matrices Mi,j of rank 1.

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

with a random length, which is a new development contrasting with the classical ﬁxed-length regime. We discuss advantages of of the random loop in Section 3.
• New eﬃcient algorithms. Perhaps most importantly, our framework is powerful enough to point to a range of novel methods. A notable example is S-Local-SVRG, which is a local variance reduced SGD method able to learn the optimal drift. This is the ﬁrst time that local variance reduction is successfully combined with an on-the-ﬂy learning of the local drift. Consequently, this is the ﬁrst method which enjoys a linear convergence rate to the exact optimum (as opposed to a neighborhood of the solution only) without any restrictive assumptions and is thus superior in theory to the convergence of all existing local ﬁrst order methods. We also develop another linearly converging method: S*-Local-SGD*. Albeit not of practical signiﬁcance as it depends on the a-priori knowledge of the optimal solution x∗, it is of theoretical interest as it enabled us to discover S-Local-SVRG. See Table 2 which summarizes all our complexity results.
Notation. Due to its generality, our paper is heavy in notation. For the reader’s convenience, we present a notation table in Sec. A of the appendix.

2 Our Framework
In this section we present the main result of the paper. Let us ﬁrst introduce the key assumptions that we impose on our objective (1). We start with a relaxation of µ-strong convexity. Assumption 2.1 ((µ, x∗)-strong quasi-convexity). Let x∗ be a minimizer of f . We assume that fi is (µ, x∗)strongly quasi-convex for all i ∈ [n] with µ ≥ 0, i.e. for all x ∈ Rd:
fi(x∗) ≥ fi(x) + ∇fi(x), x∗ − x + µ2 x − x∗ 2. (5)
Next, we require classical L-smoothness5 of local objectives, or equivalently, L-Lipschitzness of their gradients.

Assumption 2.2 (L-smoothness). Functions fi are L-smooth for all i ∈ [n] with L ≥ 0, i.e.,
∇fi(x) − ∇fi(y) ≤ L x − y , ∀x, y ∈ Rd. (6)

In order to simplify our notation, it will be convenient

to introduce the notion of virtual iterates xk deﬁned

as a mean of the local iterates [46]: xk d=ef n1

n i=1

xki

.

5While we require L-smoothness of fi to establish the main convergence theorem, some of the parameters of As. 2.3 can be tightened considering a more complex smoothness structure of the local objective.

Despite the fact that xk is being physically computed

only for k for which ck = 1, virtual iterates are a

very useful tool facilitating the convergence analysis.

Next, we shall measure the discrepancy between the

local and virtual iterates via the quantity Vk deﬁned

as Vk d=ef n1

n i=1

xki − xk

2.

We are now ready to introduce the parametric assumption on both stochastic gradients gik and function f . This is a non-trivial generalization of the assumption
from [9] to the class of local stochastic methods of the form (4), and forms the heart of this work.6

Assumption 2.3 (Key parametric assumption). As-
sume that for all k ≥ 0 and i ∈ [n], local stochastic directions gik satisfy

n

n

1 n

Ek gik = n1

∇fi(xki ),

(7)

i=1

i=1

where Ek[·] deﬁnes the expectation w.r.t. randomness coming from the k-th iteration only. Fur-
ther, assume that there exist non-negative constants
A, A , B, B , C, C , F, F , G, H, D1, D1, D2, D3 ≥ 0, ρ ∈ (0, 1] and a sequence of (possibly random) variables {σk2}k≥0 such that

n
n1 E
i=1

gik 2

n

2

E n1 gik

i=1

≤2AE f (xk) − f (x∗) + BE σk2

+ F E [Vk] + D1,

(8)

≤2A E f (xk) − f (x∗) + B E σk2

+ F E [Vk] + D1,

(9)

E σk2+1 ≤(1 − ρ)E σk2 + 2CE f (xk) − f (x∗)

+ GE [Vk] + D2,

(10)

K

K

2L

wk E[Vk ]

≤

1 2

wkE f (xk) − f (x∗)

k=0

k=0

(11)

+ 2LHEσ02 + 2LD3γ2WK ,

where sequences {WK }K≥0, {wk}k≥0 are deﬁned as

def K
WK = wk,
k=0

wk d=ef

1

k+1 ,

(

1−

min{γ

µ,

ρ 4

})

(12)

Admittedly, with its many parameters (whose meaning will become clear from the rest of the paper), As. 2.3 is not easy to parse on ﬁrst reading. Several comments are due at this point. First, while the complexity of this assumption may be misunderstood as being problematic, the opposite is true. This assumption enables us to prove a single theorem (Thm. 2.1) capturing the
6Recently, the assumption from [9] was generalized in a diﬀerent way to cover the class of the methods with error compensation and delayed updates [10].

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

convergence behavior, in a tight manner, of all local ﬁrst-order methods described by our framework (4). So, the parametric and structural complexity of this assumption is paid for by the uniﬁcation aspect it provides. Second, for each speciﬁc method we consider in this work, we prove that As. 2.3 is satisﬁed, and each such proof is based on much simpler and generally accepted assumptions. So, As. 2.3 should be seen as a “meta-assumption” forming an intermediary and abstract step in the analysis, one revealing the structure of the inequalities needed to obtain a general and tight convergence result for local ﬁrst-order methods. We dedicate the rest of the paper to explaining these parameters and to describing the algorithms and the associate rates their combination encodes. We are now ready to present our main convergence result.

Theorem 2.1. Let As. 2.1, 2.2 and 2.3 be

satisﬁed and assume the stepsize satisﬁes 0 <

γ ≤ min

1

,L

. Deﬁne xK d=ef

2(A + 4C3ρB ) F + 4G3ρB

W1K Kk=0 wkxk, Φ0 d=ef 2 x0−x∗ 2+ 83Bρ γγ2Eσ02+4LHγEσ02

and Ψ0 d=ef 2

D1

+

4B 3ρ

D2

+

2LγD3

.

Let θ d=ef 1 −

min γµ, ρ4 . Then if µ > 0, we have

E f (xK ) − f (x∗) ≤θK Φ0 + γΨ0,

(13)

and in the case when µ = 0, we have E f (xK ) − f (x∗) ≤ ΦK0 + γΨ0. (14)

As already mentioned, Thm. 2.1 serves as a general, uniﬁed theory for local stochastic gradient algorithms. The strongly convex case provides a linear convergence rate up to a speciﬁc neighborhood of the optimum. On the other hand, the weakly convex case yields an O(K−1) convergence rate up to a particular neighborhood. One might easily derive O(K−1) and O(K−2) convergence rates to the exact optimum in the strongly and weakly convex case, respectively, by using a particular decreasing stepsize rule. The next corollary gives an example of such a result in the strongly convex scenario, where the estimate of D3 does not depend on the stepsize γ. A detailed result that covers all cases is provided in Section D.2 of the appendix.
Corollary 2.1. Consider the setup from Thm. 2.1 and by ν1 denote the resulting upper bound on γ.7 Suppose that µ > 0 and D3 does not depend on γ. Let





 ln max 2,min Υ1µ2K2 , Υ1µ3K3



γ = min ν1 ,

, Υ2

Υ3

µK





7In order to get tight estimate of D3 and H, we will impose further bounds on γ (see Tbl. 1). Assume that these extra bounds are included in parameter h.

where Υ1 = 2 x0 − x∗ 2 + 8B3νE2ρσ02 + 4LHνEσ02 , Υ2 = 2D1 + 4B3ρD2 , Υ3 = 4LD3. Then, the procedure (4) achieves
E f (xK ) − f (x∗) ≤ ε
as long as

K ≥O

ρ1 + µν log νΥε 1 + Υµε2 +

Υ3 µ2 ε

.

Remark 2.1. Admittedly, Thm. 2.1 does not yield the tightest known convergence rate in the heterogeneous setup under As. 2.1. Speciﬁcally, the neighborhood to which Local-SGD converges can be slightly smaller [21]. While we provide a tighter theory that matches the bestknown results, we have deferred it to the appendix for the sake of clarity. In particular, to get the tightest rate, one shall replace the bound on the second moment of the stochastic direction (8) with two analogous bounds – ﬁrst one for the variance and the second one for the squared expectation. See As. E.1 for details. Fortunately, Thm. 2.1 does not need to change as it does not require parameters from (8); these are only used later to derive D3, H, γ based on the data type. Therefore, only a few extra parameters should be determined in the speciﬁc scenario to get the tightest rate.
The parameters that drive both the convergence speed and the neighborhood size are determined by As. 2.3. In order to see through the provided rates, we shall discuss the value of these parameters in various scenarios. In general, we would like to have ρ ∈ (0, 1] as large as possible, while all other parameters are desired to be small so as to make the inequalities as tight as possible.
Let us start with studying data similarity and inner loop type as these can be decoupled from the type of the local direction that the method (4) takes.

3 Data Similarity and Local Loop
We now explain how our framework supports ﬁxed and random local loop, and several data similarity regimes.
Local loop. Our framework supports local loop of a ﬁxed length τ ≥ 1 (i.e., we support local methods performing τ local iterations in between communications). This option, which is the de facto standard for local methods in theory and practice [29], is recovered by setting caτ = 1 for all non-negative integers a and ck = 0 for k that are not divisible by τ in (4). However, our framework also captures the very rarely considered local loop with a random length. We recover this when ck are random samples from the Bernoulli distribution Be(p) with parameter p ∈ (0, 1].

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

Data similarity. We look at various possible data similarity regimes. The ﬁrst option we consider is the fully heterogeneous setting where we do not assume any similarity between the local objectives whatsoever. Secondly, we consider the identical data regime with f1 = . . . = fn. Lastly, we consider the ζ-heterogeneous data setting, which bounds the dissimilarity between the full and the local gradients [50] (see Def. 3.1).
Deﬁnition 3.1 (ζ-heterogeneous functions). We say that functions f1, . . . , fn are ζ-heterogeneous for some ζ ≥ 0 if the following inequality holds for all x ∈ Rd:

n

1 n

∇fi(x) − ∇f (x) 2 ≤ ζ2.

(15)

i=1

The ζ-heterogeneous data regime recovers the heterogeneous data for ζ = ∞ and identical data for ζ = 0.
In Sec. E of the appendix, we show that the local loop type and the data similarity type aﬀect parameters H and D3 from As. 2.3 only. However, in order to obtain an eﬃcient bound on these parameters, we impose additional constraints on the stepsize γ. While we do not have space to formally state our results in the main body, we provide a comprehensive summary in Tbl. 1.
Methods with a random loop communicate once per p−1 iterations on average, while the ﬁxed loop variant communicates once every τ iterations. Consequently, we shall compare the two loop types for τ = p−1. In such a case, parameters D3 and H and the extra conditions on stepsize γ match exactly, meaning that the loop type does not inﬂuence the convergence rate. Having said that, random loop choice provides more ﬂexibility compared to the ﬁxed loop. Indeed, one might want the local direction gik to be synchronized with the communication time-stamps in some special cases. However, our framework does not allow such synchronization for a ﬁxed loop since we assume that the local direction gik follows some stationary distribution over stochastic gradients. The random local loop comes in handy here; the random variable that determines the communication follows a stationary distribution, thus possibly synchronized with the local computations.

4 Local Stochastic Direction
This section discusses how the choice of gik allows us to obtain the remaining parameters from As. 2.3 that were not covered in the previous section. To cover the most practical scenarios, we set gik to be a diﬀerence of two components aki , bki ∈ Rd, which we explain next. We stress that the construction of gik is very general: we recover various state-of-the-art methods along with their rates while covering many new interesting algorithms. We will discuss this in more detail in Sec. 5.

4.1 Unbiased local gradient estimator aki

The ﬁrst component of the local direction that the method (4) takes is aki – an unbiased, possibly variance reduced, estimator of the local gradient, i.e., Ek[aki ] = ∇fi(xki ). Besides the unbiasedness, aki is allowed to be anything that satisﬁes the parametric recursive relation from [9], which tightly covers many variants of SGD including non-uniform, minibatch, and variance reduced stochastic gradient. The parameters of such a relation are capable of encoding both the general smoothness structure of the objective and the gradient estimator’s properties that include a diminishing variance, for example. We state the adapted version of this recursive relation as As. 4.1.
Assumption 4.1. Let the unbiased local gradient estimator aki be such that

Ek aki − ∇fi(x∗) 2 ≤ 2AiDfi (xki , x∗) + Biσi2,k + D1,i,

Ek

σi2,k+1

≤

(1

−

ρi)σi2k

+

2

C

i

D

fi

(x

k i

,

x∗)

+

D2,i

for Ai ≥ 0, Bi ≥ 0, D1,i ≥ 0, 0 ≤ ρi ≤ 1, Ci ≥ 0, D2,i ≥ 0 and a non-negative sequence {σi2,k}∞ k=0.8

Note that the parameters of As. 4.1 can be taken directly from [9] and oﬀer a broad range of unbiased local gradient estimators aki in diﬀerent scenarios. The most interesting setups covered include minibatching, importance sampling, variance reduction, all either under the classical smoothness assumption or under a uniform bound on the stochastic gradient variance.
Our next goal is to derive the parameters of As. 2.3 from the parameters of As. 4.1. However, let us ﬁrst discuss the second component of the local direction – the local shift bki .

4.2 Local shift bki

The local update rule (4) can include the local

shift/drift bki allowing us to eliminate the infamous non-stationarity of the local methods. The general

requirement for the choice of bki is so that it sums up

to zero (

n i=1

bki

=

0)

to

avoid

unnecessary

extra

bias.

For the sake of simplicity (while maintaining general-

ity), we will consider three choices of bki – zero, ideal shift (= ∇fi(x∗)) and on-the-ﬂy shift via a possibly

outdated local stochastic non-variance reduced gradient

estimator that satisﬁes a similar bound as As. 4.1.

Assumption 4.2. Consider the following choices: Case I: bki = 0, Case II: bki = ∇fi(x∗),

8By Dfi (xki , xk) we mean Bregman distance between

xki , xk deﬁned as Dfi (xki , xk) d=ef fi(xki ) − fi(xk) −

∇f

i

(

xk

)

,

x

k i

− xk

.

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

Table 1: The eﬀect of data similarity and local loop on As. 2.3. Constant factors are ignored. Homogeneous data are recovered as a special case of ζ-heterogeneous data with ζ = 0. Heterogeneous case is slightly loose in light of Remark 2.1. If one replaces the bound on the second moments (8) with a analogous bound on variance squared expectation (see As. E.1), the bounds on γ, D3 and H will have (τ − 1) times better dependence on the variance parameters (or 1−p p times for the random loop). See Sec. E.1.1 and E.2.1 of appendix for more details.

Data het
ζ -het

Loop ﬁxed
ﬁxed

het random ζ-het radnom

Extra upper bounds on γ

τ1µ , τ

1

,

1

F + ρ(B1−Gρ) τ 2L A+ ρ(B1−Cρ)

τ1µ ,

1

,

√ τ F + ρ(B1−Gρ)

p , √ p , √p ρ(1−ρ) ,

µ

(1−p)F

BG(1−p)

1 Lτ A+ ρ(B1−Cρ)
p L(1−p) A+ ρ(B1−Cρ)

µp , F (1p−p) , BpρG((11−−ρp)) , L(1−p) Ap+ BC ρ(1−ρ)

D3 (τ − 1)2 D1 + BDρ 2

(τ − 1) D1 + γζµ2 + BDρ 2

(1−p)

D1

+

B

D2 ρ

p2

(1−p p) D1 + γζµ2 + BDρ 2

H
B(τ −1)2γ2 ρ
B(τ −1)γ2 ρ
B(1−p)γ2 p2 ρ
B(1−p)γ2 pρ

Case

III:

bki

=

hki

−

1 n

n i=1

hki

where

hki

∈

Rd

is

a

delayed local gradient estimator deﬁned recursively as

k+1 hki with probability 1 − ρi hi = lik with probability ρi ,

where 0 ≤ ρi ≤ 1 and lik ∈ Rd is an unbiased nonvariance reduced possibly stochastic gradient estimator of ∇fi(xk) such that for some Ai, D3,i ≥ 0 we have
Ek lik − ∇fi(x∗) 2 ≤ 2AiDfi (xki , x∗) + D3,i. (16)

Let us look closer at Case III as this one is the most interesting. Note that what we assume about lik (i.e., (16)) is essentially a variant of As. 4.2 with σi2,k parameters set to zero. This is achievable for a broad
range of non-variance reduced gradient estimators that
includes minibatching and importance sampling [11]. An intuitive choice of lik is to set it to aki given that aki is not variance reduced. In such a case, the scheme (4)
reduces to SCAFFOLD [18] along with its rate.
However, our framework can do much more beyond this
example. First, we cover the local variance reduced gradient aki with lik constructed as its non-variance reduced part. In such a case, the neighborhood of
the optimum from Thm. 2.1 to which the method (4)
converges shrinks. There is a way to get rid of this neighborhood, noticing that lik is used only once in a while. Indeed, the combination of the full local gradient lik together with the variance reduced aki leads to a linear rate in the strongly (quasi) convex case or O(K−1)
rate in the weakly convex case. We shall remark that
the variance reduced gradient might require a sporadic
computation of the full local gradient – it makes sense to synchronize it with the update rule for hki . In such a case, the computation of lik is for free. We have just described the S-Local-SVRG method (Algorithm 6).

4.3 Parameters of Assumption 2.3
We proceed with a key lemma that provides us with the remaining parameters of As. 2.3 that were not covered in Sec. 3. These parameters will be chosen purely based on the selection of aki and bki discussed earlier.
Lemma 4.1. For all i ∈ [n] suppose that aki satisﬁes As. 4.1, while bki was chosen as per As. 4.2. Then, (8), (9) and (10) hold with

A = 4 max Ai, B = 2, F = 4L max Ai,

i

i

2 n

n i=1

D1,i +

∇fi(x∗) 2

D1 = 2 n D

n i=1 1,i

Case I, Case II, III,

B

= n1 , F

=

2L maxi Ai n

+ 2L2, D1

=

1 n2

A = 2 manxi Ai + L, G = CL/2,

n i=1

D1,i

ρ = mini ρi

Case I, II,

mini min {ρi, ρi} Case III,

n  n2 BiD2,i,

D2 =

i=1 n

 n1 (2BiD2,i + ρiD3,i)

i=1

Case I, II, Case III,

C = 4 maxi{BiCi}

Case I, II,

4 maxi{BiCi} + 4 maxi{ρiAi} Case III.

We have just broken down the parameters of As. 2.3 based on the optimization objective and the particular instance of (4). However, it might still be hard to understand particular rates based on these choices. In the appendix, we state a range of methods and decouple their convergence rates. A summary of the key parameters from As. 2.3 is provided in Tbl. 7.

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

Table 2: A selection of methods that can be analyzed using our framework, which we detail in the appendix. A

choice of aki , bki and lik is presented along with the established complexity bounds (= number of iterations to ﬁnd such xˆ that E[f (xˆ) − f (x∗)] ≤ ε) and a speciﬁc setup under which the methods are analyzed. For Algorithms 1-4

we suppress constants and log 1ε factors. Since Algorithms 5 and 6 converge linearly, we suppress constants only while keeping log 1ε factors. All rates are provided in the strongly convex setting. UBV stands for the “Uniform Bound on the Variance” of local stochastic gradient, which is often assumed when fi is of the form (2). ES stands

for the “Expected Smoothness” [11], which does not impose any extra assumption on the objective/noise, but

rather can be derived given the sampling strategy and the smoothness structure of fi. Consequently, such a setup

allows us to obtain local methods with importance sampling. Next, the simple setting is a special case of ES when

we uniformly sample a single index on each node each iteration. ♣: Local-SGD methods have never been analyzed

under ES assumption. Notation: σ2 – averaged (within nodes) uniform upper bound for the variance of local

stochastic

gradient,

σ∗2

–

averaged

variance

of

local

stochastic

gradients

at

the

solution,

ζ∗2

d=ef

1 n

n i=1

∇fi(x∗) 2,

max Lij – the worst smoothness of fi,j, i ∈ [n], j ∈ [m], L – the worst ES constant for all nodes.

Method Local-SGD Local-SGD
Local-SGD

# Ref 1 [50] 1 [21]
1 [20]♣

aki , bki , lik

f

ξi

(x

k i

)

,

0

,

−

f

ξi

(x

k i

)

,

0

,

−

f

ξi

(x

k i

)

,

0

,

−

Local-SGD

1 [20]♣

Local-SVRG

2 NEW

Local-SVRG

2 NEW

S*-Local-SGD SS-Local-SGD

3 NEW 4 [18]

SS-Local-SGD 4 NEW

S*-Local-SGD* 5 NEW

S-Local-SVRG 6 NEW

f

ξi

(x

k i

)

,

0

,

−

∇fi,ji (xki ) − ∇fi,ji (yik) +∇fi (yik ), 0, −
∇fi,ji (xki ) − ∇fi,ji (yik) +∇fi (yik ), 0, −

f

ξi

(

x

k i

),

∇

fi

(

x∗

),

−

fξi (xki ), hki

−

1 n

n i=1

hki ,

∇fξ˜k (yik)

i

fξi (xki ), hki

−

1 n

n i=1

hki ,

∇fξ˜k (yik)

i

∇fi,ji (xki ) − ∇fi,ji (x∗) +∇fi(x∗), ∇fi(x∗), −

∇fi,ji (xki ) − ∇fi,ji (yk) +∇fi (y k ),

hki

−

1 n

n i=1

hki

,

∇fi(yk

)

Complexity

L + σ2 +
µ nµε

Lτ (σ2+τ ζ2) µ2 ε

τL + σ2 +

µ

nµε

L(τ −1)(σ2+(τ −1)ζ∗2) µ2 ε

√

L+L/n+ (τ −1)LL + σ∗2

µ

nµε

+ Lζ2µ(2τε−√1) +

L(τ −1)(σ∗2+ζ∗2) µ2 ε

Lτ +L/n+ (τ −1)LL + σ∗2

µ

nµε

L(τ −1)(σ∗2+(τ −1)ζ∗2)
+ µ2ε √ L+max Lij/n+ (τ −1)L max Lij m+ µ

+ Lζ2(τ −1) + L(τ −1)ζ∗2

µ2 ε

√ µ2ε

m + Lτ +max Lij/n+ (τ −1)L max Lij

µ

+ L(τ −1)2ζ∗2 µ2 ε

τL + σ2 +

µ

nµε

L(τ −1)σ2 µ2 ε

L + σ2 +
pµ nµε
pLµ + nLµ + + σ∗2 +
nµε

L(1−p)σ2 pµ2 ε
√
LL(1−p)
pµ L(1−p)σ∗2
pµ2 ε

τµL + manxµ√Lij + (τ −1)L max Lij
µ

log 1ε

m + pLµ +√manxµLij + L max Lij (1−p)
pµ

log 1ε

Setting
UBV, ζ -Het UBV, Het
ES, ζ -Het

Sec G.1.1 G.1.1
G.1.2

ES,

G.1.2

Het

simple, G.2 ζ -Het

simple, Het
UBV, Het UBV, Het
ES, Het

G.2 G.3 G.4.1 G.4.2

simple, G.5 Het

simple, G.6 Het

5 Special Cases
Our theory covers a broad range of local stochastic gradient algorithms. While we are able to recover multiple known methods along with their rates, we also introduce several new methods along with extending the analysis of known algorithms. As already mentioned, our theory covers convex and strongly convex cases, identical and heterogeneous data regimes. From the algorithmic point of view, we cover the ﬁxed and random loop, various shift types, and arbitrary local stochastic

gradient estimator. We stress that our framework gives a tight convergence rate under any circumstances.
While we might not cover all of these combinations in a deserved detail, we thoroughly study a subset of them in Sec. G of the appendix. An overview of these methods is presented in Tbl. 2 together with their convergence rates in the strongly convex case (see Tbl. 4 in the appendix for the rates in the weakly convex setting). Next, we describe a selected number of special cases of our framework.

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

• Non-local stochastic methods. Our theory recovers a broad range of non-local stochastic methods. In particular, if n = 1, we have Vk = 0, and consequently we can choose A = A , B = B , D1 = D1, F = F = G = H = D3 = 0. With such a choice, our theory matches9 the general analysis of stochastic gradient methods from [9] for τ = 1. Consequently, we recover a broad range of algorithms as a special case along with their convergence guarantees, namely SGD [41] with its best-known rate on smooth objectives [35, 11], variance reduced ﬁnite sum algorithms such as SAGA [8], SVRG [17], L-SVRG [15, 23], variance reduced subspace descent methods such as SEGA/SVRCD [14, 12], quantized methods [31, 16] and others.
• “Star”-shifted local methods. As already mentioned, local methods have inherently incorrect ﬁxed points [37]; and one can ﬁx these by shifting the local gradients. Star-shifted local methods employ the ideal stationary shift using the local gradients at the optimum bki = ∇fi(x∗) (i.e., Case II from As. 4.2) and serve as a transition from the plain local methods (Case I from As. 4.2) to the local methods that shift using past gradients such as SCAFFOLD (Case III from As. 4.2). In the appendix, we present two such methods: S*-Local-SGD (Algorithm 3) and S*-Local-SGD* (Algorithm 5). While being impractical in most cases since ∇fi(x∗) is not known, star-shifted local methods give new insights into the role and eﬀect of the shift for local algorithms. Speciﬁcally, these methods enjoy superior convergence rate when compared to methods without local shift (Case I) and methods with a shift constructed from observed gradients (Case III), while their rate serves as an aspiring goal for local methods in general. Fortunately, in several practical scenarios, one can match the rate of star methods using an approach from Case III, as we shall see in the next point.
• Shifted Local SVRG (S-Local-SVRG). As already mentioned, local SGD suﬀers from convergence to a neighborhood of the optimum only, which is credited to i) inherent variance of the local stochastic gradient, and ii) incorrect ﬁxed point of local GD. We propose a way to correct both issues. To the best of our knowledge, this is the ﬁrst time that on-device variance reduction was combined with the trick for reducing the nonstationarity of local methods. Speciﬁcally, the latter is achieved by selecting bki as a particular instance of Case III from As. 4.2 such that lik is the full local gradient, which in turns yields D1,i = 0, Ai = L. In order to not waste local computation, we synchronize the evaluation of lik with the computation of the full local gradient for the L-SVRG [15, 23] estimator, which we use to construct aki . Consequently, some terms cancel out,
9Up to the non-smooth regularization/proximal steps and small constant factors.

and we obtain a simple, fast, linearly converging local SGD method, which we present as Algorithm 6 in the appendix. We believe that this is remarkable since only a very few local methods converge linearly to the exact optimum.10
6 Experiments
We perform multiple experiments to verify the theoretical claims of this paper. Due to space limitations, we only present a single experiment in the main body; the rest can be found in Section C of the appendix.
We demonstrate the beneﬁt of on-device variance reduction, which we introduce in this paper. For that purpose, we compare standard Local-SGD (Algorithm 1) with our Local-SVRG (Algorithm 2) on a regularized logistic regression problem with LibSVM data [7]. For each problem instance, we compare the two algorithms with the stepsize γ ∈ {1, 0.1, 0.01} (we have normalized the data so that L = 1). The remaining details for the setup are presented in Section C.1 of the appendix.
Our theory predicts that both Local-SGD and Local-SVRG have identical convergence rate early on. However, the neighborhood of the optimum to which Local-SVRG converges is smaller comparing to Local-SGD. For both methods, the neighborhood is controlled by the stepsize: the smaller the stepsize is, the smaller the optimum neighborhood is. The price to pay is a slower rate at the beginning.
The results are presented in Fig. 1. As predicted, Local-SVRG always outperforms Local-SGD as it converges to a better neighborhood. Fig. 1 also demonstrates that one can trade the smaller neighborhood for the slower convergence by modifying the stepsize.
7 Conclusions and Future Work
This paper develops a uniﬁed approach to analyzing and designing a wide class of local stochastic ﬁrst order algorithms. While our framework covers a broad range of methods, there are still some types of algorithms that we did not include but desire attention in future work. First, it would be interesting to study algorithms with biased local stochastic gradients; these are popular for minimizing ﬁnite sums; see SAG [42] or SARAH [36]. The second hitherto unexplored direction is including Nesterov’s acceleration [34] in our framework. This idea is gaining traction in the area of local methods already [37, 54]. However, it is not at all clear how
10A linearly converging local SGD variant can be recovered from stochastic decoupling [30], although this was not considered therein. Besides that, FedSplit [37] achieves a linear rate too, however, with a much stronger local oracle.

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

Relative suboptimality

Relative suboptimality

w2a
100

10 1

10 2

10 3

1_SGD

10 4

0.1_SGD

0.01_SGD

10 5

1_SVRG

10 6

0.1_SVRG 0.01_SVRG

0

2000Rounds40o00f comm6u0n00ication8000 10000

madelon

100

10 1

10 2 10 3 10 4
0
100 10 2 10 4

1_SGD 0.1_SGD 0.01_SGD 1_SVRG 0.1_SVRG 0.01_SVRG
2000Rounds40o00f comm6u0n00ication8000 10000
duke 1_SGD 0.1_SGD 0.01_SGD 1_SVRG 0.1_SVRG 0.01_SVRG

10 6

10 8 0

2000Rounds40o00f comm6u0n00ication8000 10000

Relative suboptimality

Relative suboptimality

Relative suboptimality

100 10 1 10 2 10 3 10 4 10 5 10 6 0
10 1 10 3 10 5 10 7 10 9 10 11 10 13 0
10 1 10 3 10 5 10 7 10 9 10 11 10 13 0

a1a

1_SGD 0.1_SGD 0.01_SGD 1_SVRG 0.1_SVRG 0.01_SVRG

2000Rounds40o00f comm6u0n00ication8000 10000

mushrooms

1_SGD 0.1_SGD 0.01_SGD 1_SVRG 0.1_SVRG 0.01_SVRG

2000Rounds40o00f comm6u0n00ication8000 10000

phishing

1_SGD 0.1_SGD 0.01_SGD 1_SVRG 0.1_SVRG 0.01_SVRG

2000Rounds40o00f comm6u0n00ication8000 10000

Relative suboptimality

Figure 1: Comparison of standard Local-SGD (Alg. 1) and our Local-SVRG (Alg. 2) for varying γ. Logistic regression applied on LibSVM [7]. Other parameters: L = 1, µ = 10−4, τ = 40. Parameter n chosen as per Tbl. 5 in the appendix.

this should be done and several attempts at achieving this uniﬁcation goal failed. The third direction is allowing for a regularized local objective, which has been under-explored in the FL community so far. Other compelling directions that we do not cover are the local higher-order or proximal methods [24, 37] and methods supporting partial participation [29].
Acknowledgements
This work was supported by the KAUST baseline research grant of P. Richta´rik. Part of this work was done while E. Gorbunov was a research intern at KAUST. The research of E. Gorbunov was also partially supported by the Ministry of Science and Higher Education of the Russian Federation (Goszadaniye) 075-00337-2003 and RFBR, project number 19-31-51001.
References
[1] A. F. Aji and K. Heaﬁeld. Sparse communication for distributed gradient descent. arXiv preprint arXiv:1704.05021, 2017.
[2] D. Alistarh, J. Li, R. Tomioka, and M. Vojnovic. QSGD: Randomized quantization for

communication-optimal stochastic gradient descent. arXiv preprint arXiv:1610.02132, 2016.
[3] D. Alistarh, T. Hoeﬂer, M. Johansson, N. Konstantinov, S. Khirirat, and C. Renggli. The convergence of sparsiﬁed gradient methods. In Advances in Neural Information Processing Systems, pages 5973–5983, 2018.
[4] D. Basu, D. Data, C. Karakus, and S. Diggavi. Qsparse-local-SGD: Distributed SGD with quantization, sparsiﬁcation and local computations. In Advances in Neural Information Processing Systems, pages 14695–14706, 2019.
[5] J. Bernstein, Y.-X. Wang, K. Azizzadenesheli, and A. Anandkumar. signSGD: Compressed optimisation for non-convex problems. In J. Dy and A. Krause, editors, Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pages 560–569, Stockholmsm¨assan, Stockholm Sweden, 10–15 Jul 2018. PMLR.
[6] A. Beznosikov, S. Horv´ath, P. Richt´arik, and M. Safaryan. On biased compression for distributed learning. arXiv preprint arXiv:2002.12410, 2020.
[7] C.-C. Chang and C.-J. Lin. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology (TIST), 2 (3):1–27, 2011.
[8] A. Defazio, F. Bach, and S. Lacoste-Julien. SAGA: A fast incremental gradient method with support for non-strongly convex composite objectives. In Advances in Neural Information Processing Systems, pages 1646–1654, 2014.
[9] E. Gorbunov, F. Hanzely, and P. Richt´arik. A uniﬁed theory of SGD: Variance reduction, sampling, quantization and coordinate descent. arXiv preprint arXiv:1905.11261, 2019.
[10] E. Gorbunov, D. Kovalev, D. Makarenko, and P. Richt´arik. Linearly converging error compensated SGD. NeurIPS 2020 (accepted), arXiv:2010.12292, 2020.
[11] R. M. Gower, N. Loizou, X. Qian, A. Sailanbayev, E. Shulgin, and P. Richta´rik. SGD: General analysis and improved rates. In International Conference on Machine Learning, pages 5200–5209, 2019.
[12] F. Hanzely and P. Richt´arik. One method to rule them all: variance reduction for data, parameters and many new methods. arXiv preprint arXiv:1905.11266, 2019.
[13] F. Hanzely and P. Richt´arik. Federated learning of a mixture of global and local models. arXiv preprint arXiv:2002.05516, 2020.

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

[14] F. Hanzely, K. Mishchenko, and P. Richt´arik. SEGA: Variance reduction via gradient sketching. In Advances in Neural Information Processing Systems, pages 2082–2093, 2018.
[15] T. Hofmann, A. Lucchi, S. Lacoste-Julien, and B. McWilliams. Variance reduced stochastic gradient descent with neighbors. In Advances in Neural Information Processing Systems, pages 2305–2313, 2015.
[16] S. Horva´th, D. Kovalev, K. Mishchenko, S. Stich, and P. Richt´arik. Stochastic distributed learning with gradient quantization and variance reduction. arXiv preprint arXiv:1904.05115, 2019.
[17] R. Johnson and T. Zhang. Accelerating stochastic gradient descent using predictive variance reduction. In Advances in Neural Information Processing Systems, pages 315–323, 2013.
[18] S. P. Karimireddy, S. Kale, M. Mohri, S. J. Reddi, S. U. Stich, and A. T. Suresh. Scaﬀold: Stochastic controlled averaging for on-device federated learning. arXiv preprint arXiv:1910.06378, 2019.
[19] S. P. Karimireddy, Q. Rebjock, S. U. Stich, and M. Jaggi. Error feedback ﬁxes signSGD and other gradient compression schemes. arXiv preprint arXiv:1901.09847, 2019.
[20] A. Khaled, K. Mishchenko, and P. Richt´arik. Tighter theory for local SGD on identical and heterogeneous data. In The 23rd International Conference on Artiﬁcial Intelligence and Statistics (AISTATS 2020), 2020.
[21] A. Koloskova, N. Loizou, S. Boreiri, M. Jaggi, and S. U. Stich. A uniﬁed theory of decentralized SGD with changing topology and local updates. arXiv preprint arXiv:2003.10422, 2020.
[22] J. Koneˇcny´, H. B. McMahan, F. X. Yu, P. Richt´arik, A. T. Suresh, and D. Bacon. Federated learning: Strategies for improving communication eﬃciency. arXiv preprint arXiv:1610.05492, 2016.
[23] D. Kovalev, S. Horv´ath, and P. Richt´arik. Don’t jump through hoops and remove those loops: SVRG and Katyusha are better without the outer loop. arXiv preprint arXiv:1901.08689, 2019.
[24] T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith. Federated optimization in heterogeneous networks. arXiv preprint arXiv:1812.06127, 2018.
[25] X. Liang, S. Shen, J. Liu, Z. Pan, E. Chen, and Y. Cheng. Variance reduced local SGD with lower communication complexity. arXiv preprint arXiv:1912.12844, 2019.

[26] T. Lin, S. U. Stich, K. K. Patel, and M. Jaggi. Don’t use large mini-batches, use local SGD. arXiv preprint arXiv:1808.07217, 2018.
[27] Y. Lin, S. Han, H. Mao, Y. Wang, and W. J. Dally. Deep gradient compression: Reducing the communication bandwidth for distributed training. arXiv preprint arXiv:1712.01887, 2017.
[28] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas. Communication-eﬃcient learning of deep networks from decentralized data. In Artiﬁcial Intelligence and Statistics, pages 1273– 1282. PMLR, 2017.
[29] H. B. McMahan, E. Moore, D. Ramage, and B. A. y Arcas. Federated learning of deep networks using model averaging. arXiv preprint arXiv:1602.05629, 2016.
[30] K. Mishchenko and P. Richt´arik. A stochastic decoupling method for minimizing the sum of smooth and non-smooth functions. arXiv preprint arXiv:1905.11535, 2019.
[31] K. Mishchenko, E. Gorbunov, M. Tak´aˇc, and P. Richt´arik. Distributed learning with compressed gradient diﬀerences. arXiv preprint arXiv:1901.09269, 2019.
[32] K. Mishchenko, F. Hanzely, and P. Richta´rik. 99% of worker-master communication in distributed optimization is not needed. In Conference on Uncertainty in Artiﬁcial Intelligence, pages 979– 988. PMLR, 2020.
[33] Y. Nesterov. Lectures on convex optimization, volume 137. Springer, 2018.
[34] Y. E. Nesterov. A method for solving the convex programming problem with convergence rate O(1/k2). In Dokl. Akad. Nauk SSSR, volume 269, pages 543–547, 1983.
[35] L. Nguyen, P. H. Nguyen, M. Dijk, P. Richt´arik, K. Scheinberg, and M. Tak´aˇc. SGD and Hogwild! convergence without the bounded gradients assumption. In International Conference on Machine Learning, pages 3750–3758, 2018.
[36] L. M. Nguyen, J. Liu, K. Scheinberg, and M. Taka´ˇc. Sarah: A novel method for machine learning problems using stochastic recursive gradient. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 2613–2621. JMLR. org, 2017.
[37] R. Pathak and M. J. Wainwright. FedSplit: An algorithmic framework for fast federated optimization. arXiv preprint arXiv:2005.05238, 2020.
[38] A. Ramezani-Kebrya, F. Faghri, and D. M. Roy. NUQSGD: Improved communication eﬃciency for

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

data-parallel SGD via nonuniform quantization. arXiv preprint arXiv:1908.06077, 2019.
[39] S. J. Reddi, J. Koneˇcny´, P. Richt´arik, B. P´ocz´os, and A. Smola. AIDE: Fast and communication eﬃcient distributed optimization. arXiv preprint arXiv:1608.06879, 2016.
[40] A. Reisizadeh, A. Mokhtari, H. Hassani, A. Jadbabaie, and R. Pedarsani. Fedpaq: A communication-eﬃcient federated learning method with periodic averaging and quantization. In International Conference on Artiﬁcial Intelligence and Statistics, pages 2021–2031, 2020.
[41] H. Robbins and S. Monro. A stochastic approximation method. Annals of Mathematical Statistics, 22:400–407, 1951.
[42] M. Schmidt, N. Le Roux, and F. Bach. Minimizing ﬁnite sums with the stochastic average gradient. Mathematical Programming, 162(1-2): 83–112, 2017.
[43] O. Shamir, N. Srebro, and T. Zhang. Communication-eﬃcient distributed optimization using an approximate newton-type method. In International Conference on Machine Learning, pages 1000–1008, 2014.
[44] S. U. Stich. Local SGD converges fast and communicates little. arXiv preprint arXiv:1805.09767, 2018.
[45] S. U. Stich. Uniﬁed optimal analysis of the (stochastic) gradient method. arXiv preprint arXiv:1907.04232, 2019.
[46] S. U. Stich and S. P. Karimireddy. The errorfeedback framework: Better rates for SGD with delayed gradients and compressed communication. arXiv preprint arXiv:1909.05350, 2019.
[47] T. Vogels, S. P. Karimireddy, and M. Jaggi. PowerSGD: Practical low-rank gradient compression for distributed optimization. In Advances in Neural Information Processing Systems, pages 14259– 14268, 2019.
[48] H. Wang, S. Sievert, S. Liu, Z. Charles, D. Papailiopoulos, and S. Wright. Atomo: Communicationeﬃcient learning via atomic sparsiﬁcation. In Advances in Neural Information Processing Systems, pages 9850–9861, 2018.
[49] J. Wangni, J. Wang, J. Liu, and T. Zhang. Gradient sparsiﬁcation for communication-eﬃcient distributed optimization. In Advances in Neural Information Processing Systems, pages 1299–1309, 2018.
[50] B. Woodworth, K. K. Patel, and N. Srebro. Minibatch vs local SGD for heterogeneous distributed learning. arXiv preprint arXiv:2006.04735, 2020.

[51] B. Woodworth, K. K. Patel, S. U. Stich, Z. Dai, B. Bullins, H. B. McMahan, O. Shamir, and N. Srebro. Is local SGD better than minibatch SGD? In Proceedings of the 37th International Conference on Machine Learning, 2020.
[52] J. Wu, W. Huang, J. Huang, and T. Zhang. Error compensated quantized SGD and its applications to large-scale distributed optimization. In J. Dy and A. Krause, editors, Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pages 5325–5333, Stockholmsm¨assan, Stockholm Sweden, 10–15 Jul 2018. PMLR.
[53] Z. Wu, Q. Ling, T. Chen, and G. B. Giannakis. Federated variance-reduced stochastic gradient descent with robustness to byzantine attacks. arXiv preprint arXiv:1912.12716, 2019.
[54] H. Yuan and T. Ma. Federated accelerated stochastic gradient descent. arXiv preprint arXiv:2006.08950, 2020.
[55] Y. Zhang and X. Lin. DiSCO: Distributed optimization for self-concordant empirical loss. In International Conference on Machine Learning, pages 362–370, 2015.
[56] M. Zinkevich, M. Weimer, L. Li, and A. J. Smola. Parallelized stochastic gradient descent. In Advances in Neural Information Processing Systems, pages 2595–2603, 2010.

Local SGD: Uniﬁed Theory and New Eﬃcient Methods
Appendix

Since the appendix contains substantial amount of material, we have decided to include a table of contents.

Contents

1 Introduction

1

1.1 Our Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2

2 Our Framework

3

3 Data Similarity and Local Loop

4

4 Local Stochastic Direction

5

4.1 Unbiased local gradient estimator aki . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 4.2 Local shift bki . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5

4.3 Parameters of Assumption 2.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6

5 Special Cases

7

6 Experiments

8

7 Conclusions and Future Work

8

A Table of Frequently Used Notation

14

B Table with Complexity Bounds in the Weakly Convex Case

15

C Extra Experiments

16

C.1 Missing details from Section 6 and an extra ﬁgure . . . . . . . . . . . . . . . . . . . . . . . . . . 16

C.2 The eﬀect of local shift/drifts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

D Missing Proofs for Section 2

22

D.1 Proof of Theorem 2.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23

D.2 Corollaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24

E Missing Proofs and Details for Section 3

25

E.1 Constant Local Loop . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25

E.1.1 Heterogenous Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25

E.1.2 ζ-Heterogeneous Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29

E.2 Random Local Loop . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32

E.2.1 Heterogeneous Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32

E.2.2 ζ-Heterogeneous Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

F Missing Parts from Section 4

40

F.1 Proof of Lemma 4.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40

G Special Cases: Technical details

43

G.1 Local-SGD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43

G.1.1 Uniformly Bounded Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43

G.1.2 Expected Smoothness and Arbitrary Sampling . . . . . . . . . . . . . . . . . . . . . . . . 49

G.2 Local-SVRG . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53

G.2.1 ζ-Heterogeneous Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54

G.2.2 Heterogeneous Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56

G.3 S*-Local-SGD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58

G.4 SS-Local-SGD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61

G.4.1 Uniformly Bounded Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61

G.4.2 Expected Smoothness and Arbitrary Sampling . . . . . . . . . . . . . . . . . . . . . . . . 64

G.5 S*-Local-SGD* . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68

G.6 S-Local-SVRG . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71

H Basic Facts

76

I Technical Lemmas

77

Local SGD: Uniﬁed Theory and New Eﬃcient Methods
A Table of Frequently Used Notation

f : Rd → R fi : Rd → R
x∗ d n xki gik γ ck µ L xk Vk xK ζ τ p aki bki hki lik L max Lij σ2 σ∗2 ζ∗2
A, A , B, B , C, C , F, F , G, H, D1, D1, D2, D3, ρ Ai, Bi D1,i, ρi, Ci, D2,i
Ai, D3,i σk2, σi2,k
E[·]
E · | xk
Dh(x, y)

Table 3: Summary of frequently used notation.

Main notation

Objective to be minimized

Local objective owned by device/worker i

Global optimum of (1); x∗ ∈ Rd

Dimensionality of the problem space

Number of clients/devices/nodes/workers

Local iterate; xki ∈ Rd Local stochastic direction; gik ∈ Rd
Stepsize/learning rate; γ ≥ 0

Indicator of the communication; ck ∈ {0, 1}

Strong quasi-convexity of the local objective; µ ≥ 0

Smoothness of the local objective; L ≥ µ

Virtual iterate; xk ∈ Rd Discrepancy between local and virtual iterates; V k ≥ 0

Weighted average of historical iterates; xK ∈ Rd

Heterogeneity parameter; ζ ≥ 0

Size of the ﬁxed local loop τ ≥ 0

Probability of aggregation ﬁxed for the random local loop p ∈ [0, 1]

Unbiased local gradient; aki ∈ Rd Local shift; bki ∈ Rd Delayed local gradient estimator used to construct bki ; hki ∈ Rd Unbiased local gradient estimator used to construct bki ; lik ∈ Rd
Expected smoothness of local objectives; L ≥ 0

Smoothness constant of local summands; max Lij ≥ 0

Averaged upper bound for the variance of local stochastic gradient

Averaged variance of local stochastic gradients at the solution

d=ef n1

n i=1

∇fi(x∗) 2

Parametric Assumptions

(1) (2) or (3)
(1) (1) (4) (4) (4) (4) (5) (6) Sec 2 Sec 2 Thm 2.1 (15) Sec 3 Sec 3 Sec 4 Sec 4 Sec 4 Sec 4 (86) Sec (G.2) Tab (6) Tab (6)
Tab (6)

Parameters of Assumption 2.3

Parameters of Assumption 4.1 Parameters of Assumption 4.2 Possibly random non-negative sequences from Assumptions 2.3, 4.1, E.1

Standard

Expectation
d=ef E · | xk1, . . . , xkn ; expectation conditioned on k-th local iterates d=ef h(x) − h(y) − ∇h(y), x − y ; Bregman distance of x, y w.r.t. h

As 4.1

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik
B Table with Complexity Bounds in the Weakly Convex Case

Table 4: A selection of methods that can be analyzed using our framework. A choice of aki , bki and lik is presented along with the established complexity bounds (= number of iterations to ﬁnd such xˆ that E[f (xˆ) − f (x∗)] ≤ ε)

and a speciﬁc setup under which the methods are analyzed. For all algorithms we suppress constants factors.

All rates are provided in the weakly convex setting. UBV stands for the “Uniform Bound on the Variance”

of local stochastic gradient, which is often assumed when fi is of the form (2). ES stands for the “Expected

Smoothness” [11], which does not impose any extra assumption on the objective/noise, but rather can be derived

given the sampling strategy and the smoothness structure of fi. Consequently, such a setup allows us to obtain

local methods with importance sampling. Next, the simple setting is a special case of ES when we uniformly

sample a single index on each node each iteration. ♣: Local-SGD methods have never been analyzed under ES

assumption. Notation: σ2 – averaged (within nodes) uniform upper bound for the variance of local stochastic

gradient,

σ∗2

–

averaged

variance

of

local

stochastic

gradients

at

the

solution,

ζ∗2

d=ef

1 n

n i=1

∇fi(x∗) 2, max Lij –

the worst smoothness of fi,j, i ∈ [n], j ∈ [m], L – the worst ES constant for all nodes, R0 d=ef x0 − x∗ – distance

of the starting point x0 from the closest solution x∗, ∆0 d=ef f (x0) − f (x∗).

Method Local-SGD

# Ref 1 [50]

Local-SGD

1 [21]

aki , bki , lik

f

ξi

(x

k i

)

,

0

,

−

f

ξi

(x

k i

)

,

0

,

−

Local-SGD

1 [20]♣

f

ξi

(x

k i

)

,

0

,

−

Local-SGD

1 [20]♣

f

ξi

(x

k i

)

,

0

,

−

Local-SVRG
Local-SVRG S*-Local-SGD SS-Local-SGD

2 NEW
2 NEW 3 NEW 4 [18]

∇fi,ji (xki ) − ∇fi,ji (yik) +∇fi (yik ), 0, −

∇fi,ji (xki ) − ∇fi,ji (yik) +∇fi (yik ), 0, −

f

ξi

(

x

k i

),

∇

fi

(

x∗

),

−

fξi (xki ), hki

−

1 n

n i=1

hki ,

∇fξ˜k (yik)

i

SS-Local-SGD

4 NEW

fξi (xki ), hki

−

1 n

n i=1

hki ,

∇fξ˜k (yik)

i

S*-Local-SGD* 5 NEW S-Local-SVRG 6 NEW

∇fi,ji (xki ) − ∇fi,ji (x∗) +∇fi(x∗), ∇fi(x∗), −

∇fi,ji (xki ) − ∇fi,ji (yk) +∇fi (y k ),

hki

−

1 n

n i=1

hki

,

∇fi(yk

)

Complexity

LR02
+ √ ε

σ2 R02 nε2
R02

Lτ (σ2+τ ζ2)

+ τ LR02 + √ ε

ε3/2 σ2 R02 nε2 R02 L(τ −1)(σ2+(τ −1)ζ∗2)

+√ ε3/2

L+L/n+ (τ −1)LL

√ + ε

Lζ2(τ −1)R02

R02

+ + µε2

R02 σ∗2 R02 nε2
L(τ −1)(σ∗2+ζ∗2) ε3/2

√ Lτ +L/n+ (τ −1)LL R02

σ∗2 R02

√ + ε

nε2

R02 L(τ −1)(σ∗2+(τ −1)ζ∗2)

+ √ ε3/2

√ L+max Lij m/n+ (τ −1)L max Lij R02

√ε
3 (τ −1)mL max Lij R02
+ ε

Lζ2(τ −1)R02 µε2

√ R02 L(τ −1)ζ∗2

+√ ε3/2

√ Lτ +max Lij m/n+ (τ −1)L max Lij R02

√ √ ε
3 (τ −1)mL max Lij R02

R02 L(τ −1)2ζ∗2

+ √ ε

ε3/2

τ LR02
+ + ε

σ2 R02 nε2

R02 L(τ −1)σ2 ε3/2

√ LR02 + + pε

σ2 R02 nε2

R02 L(1−p)σ2 p1/2 ε3/2

√ L+pL/n+ p(1−p)LL R02

pε

√3 (1−p)L(L+pL)R04∆0

+ pε

√3 (1−p)Lσ∗2R04 + + p2/3ε

σ∗2 R02 nε2

√ R02 L(1−p)σ∗2

+ p1/2ε3/2

( √ ) Lτ +max Lij/n+ (τ −1)L max Lij R02

√ √ L+pL

m/n+

ε (1−p)L max Lij R02

pε
+ R02 3 L max L2ij p2/3 ε

Setting
UBV, ζ -Het
UBV, Het
ES, ζ -Het
ES, Het

Sec G.1.1 G.1.1 G.1.2 G.1.2

simple, G.2 ζ -Het

simple, Het
UBV, Het UBV, Het

G.2 G.3 G.4.1

ES,

G.4.2

Het

simple, G.5 Het
simple, G.6 Het

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

C Extra Experiments

C.1 Missing details from Section 6 and an extra ﬁgure

In Section 6 we study the eﬀect of local variance reduction on the communication complexity of local methods. We consider the regularized logistic regression objective, i.e., we choose

def 1 m fi(x) = m log 1 + exp
j=1

a(i−1)m+j , x · b(i−1)m+j

µ +

x

2,

2

where aj ∈ Rd, bj ∈ {−1, 1} for j ≤ nm are the training data and labels.

Number of the clients. We select a diﬀerent number of clients for each dataset in order to capture a variety of scenarios. See Table 5 for details.

Table 5: Number of clients per dataset (Figures 1 and 2).

Dataset n # datapoints (= mn) d

a1a

5

mushrooms 12

phishing 11

madelon 50

duke

4

w2a

10

1 605 8 124 11 055 2 000
44 3 470

123 112 68 500 7 129 300

Relative suboptimality

100 10 1 10 2 10 3 10 4 10 5
0
10 1 10 3 10 5 10 7 10 9 10 11
0

Relative suboptimality

w2a

1_SGD

100

0.1_SGD

0.01_SGD

1_SVRG

0.1_SVRG

10 1

0.01_SVRG

10 2

2000Rounds40o00f comm6u0n00ication8000 10000

mushrooms

1_SGD 0.1_SGD 0.01_SGD 1_SVRG 0.1_SVRG 0.01_SVRG

2000Rounds40o00f comm6u0n00ication8000 10000

Relative suboptimality

0
100 10 1 10 2 10 3 10 4 10 5 10 6 10 7 10 8
0

a1a 1_SGD 0.1_SGD 0.01_SGD 1_SVRG 0.1_SVRG 0.01_SVRG
2000Rounds40o00f comm6u0n00ication8000 10000 duke 1_SGD 0.1_SGD 0.01_SGD 1_SVRG 0.1_SVRG 0.01_SVRG
2000Rounds40o00f comm6u0n00ication8000 10000

Relative suboptimality

Relative suboptimality

madelon
100

10 1
10 2 0
10 1 10 3 10 5 10 7 10 9
0

1_SGD 0.1_SGD 0.01_SGD 1_SVRG 0.1_SVRG 0.01_SVRG

2000Rounds40o00f comm6u0n00ication8000 10000

phishing

1_SGD 0.1_SGD 0.01_SGD 1_SVRG 0.1_SVRG 0.01_SVRG

2000Rounds40o00f comm6u0n00ication8000 10000

Relative suboptimality

Figure 2: Comparison of standard Local-SGD (Algorithm 1), and Local-SVRG (Algorithm 2) with various stepsizes γ. Logistic regression applied on LibSVM data [7] with heterogenously splitted data. Other parameters: L = 1, µ = 10−4, τ = 40. Parameter n chosen as per Table 5. (Same as Fig. 1, but with the heterogenous data split)

Data split. The experiment from Figure 1 in the main body of the paper splits the data among the clients uniformly at random (i.e., split according to the the order given by a random permutation). However, in a typical FL scenario, the local data might signiﬁcantly diﬀer from the population average. For this reason, we also test on a diﬀerent split of the data: we ﬁrst sort the data according to the labels, and then split them among the clients. Figure 2 shows the results. We draw a conclusions identical to Figure 1. We see that Local-SVRG was at least as good as Local-SGD for every stepsize choice and every dataset. Further, the prediction that the smaller stepsize yields the smaller of the optimum neighborhood for the price of slower convergence was conﬁrmed.

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

Table 6: Instances of (17).

Type m

zi∗

0

1 ∼ N (0, I)

1 10 ∼ N (0, I)

2

1 ∼ N (0, I)

3 10 ∼ N (0, I)

Environment. All experiments were performed in a simulated environment on a single machine.

C.2 The eﬀect of local shift/drifts

The experiment presented in Section 6 examined the eﬀect of the noise on the performance of local methods and demonstrated that control variates can be eﬃciently employed to reduce that noise. In this section, we study the second factor that inﬂuences the neighborhood to which Local-SGD converges: non-stationarity of Local-GD.
We have already shown that the mentioned non-stationarity of Local-GD can be ﬁxed using a carefully designed idealized/optimal shift that depends on the solution x∗ (see Algorithm 3). Furthermore, we have shown that this idealized shift can be learned on-the-ﬂy at the small price of slightly slower convergence rate (see Algorithm 4 – SS-Local-SGD/SCAFFOLD).11
In this experiment, we therefore compare Local-SGD, S*-Local-SGD and SCAFFOLD. In order to decouple the local variance with the non-stationarity of the local methods, we let each algorithm access the full local gradients. Next, in order to have a full control of the setting, we let the local objectives to be artiﬁcially generated quadratic problems. Speciﬁcally, we set





µ

1−µ

m

fi(x) = x 2 +

(x − zi∗)  aiai  (x − zi∗),

(17)

2

2

j=1

where ai are mutually orthogonal vectors of norm 1 with m < d (generated by orthogonalizing Gaussian vectors), zi∗ are Gaussian vectors and µ = 10−3. We consider four diﬀerent instances of (17) given by Table 17. Figures 3, 4, 5, 6 show the result.
Through most of the plots across all combinations of type, τ , n, we can see that Local-SGD suﬀers greatly from the fact that it is attracted to an incorrect ﬁxed point and as a result, it never converges to the exact optimum. On the other hand, both S*-Local-SGD and SCAFFOLD converge to the exact optimum and therefore outperform Local-SGD in most examples. We shall note that the rate of SCAFFOLD involves slightly worse constants than those in Local-SGD and S*-Local-SGD, and therefore it sometimes performs worse in the early stages of the optimization process when compared to the other methods. Furthermore, notice that our method S*-Local-SGD always performed best.
To summarize, our results demonstrate that

(i) the incorrect ﬁxed point of used by standard local methods is an issue not only theory but also in practice, and should be addressed if better performance is required,
(ii) the theoretically optimal shift employed by S*-Local-SGD is ideal from a performance perspective if it was available (however, this strategy is impractical to implement as the optimal shift presumes the knowledge of the optimal solution), and
(iii) SCAFFOLD/SS-Local-SGD is a practical solution to ﬁxing the incorrect ﬁxed point problem – it converges to the exact optimum at a price of a slightly worse initial convergence speed.

11In fact, SCAFFOLD can be coupled together with Local-SVRG given that the local objectives are of a ﬁnite-sum structure, resulting in Algorithm 6.

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

Relative suboptimality

Relative suboptimality

10 1 10 3 10 5 10 7 10 9 10 11 10 13 0
10 1 10 3 10 5 10 7 10 9 10 11 10 13 0
10 1 10 3 10 5 10 7 10 9 10 11 10 13 0

Type: 0, tau: 5, n: 5

SCAFFOLD LGD LGD*

10000Round2s00o0f0comm30u0n00ication40000 50000 Type: 0, tau: 5, n: 50
SCAFFOLD LGD LGD*
10000Round2s00o0f0comm30u0n00ication40000 50000 Type: 0, tau: 5, n: 500
SCAFFOLD LGD LGD* 10000Round2s00o0f0comm30u0n00ication40000 50000

Relative suboptimality

Relative suboptimality

Relative suboptimality

100 10 1 10 2 10 3 10 4 10 5 10 6
0
100 10 1 10 2 10 3 10 4 10 5 10 6 10 7 10 8 0
10 1 10 3 10 5 10 7 10 9 10 11 10 13 0

Type: 0, tau: 20, n: 5

SCAFFOLD LGD LGD*

10000Round2s00o0f0 comm30u0n00ication40000 50000

Type: 0, tau: 20, n: 50

SCAFFOLD LGD LGD*

10000Round2s00o0f0 comm30u0n00ication40000 50000 Type: 0, tau: 20, n: 500
SCAFFOLD LGD LGD*
10000Round2s00o0f0comm30u0n00ication40000 50000

Relative suboptimality

Relative suboptimality

Relative suboptimality

100
10 1
10 2 0
100 10 1 10 2 10 3
0 100 10 1 10 2 10 3
0

Type: 0, tau: 100, n: 5

SCAFFOLD LGD LGD*

10000Round2s00o0f0 comm30u0n00ication40000 50000

Type: 0, tau: 100, n: 50

SCAFFOLD LGD LGD*

10000Round2s00o0f0 comm30u0n00ication40000 50000
Type: 0, tau: 100, n: 500 SCAFFOLD LGD LGD*

10000Round2s00o0f0 comm30u0n00ication40000 50000

Relative suboptimality

Figure 3: Comparison of the following noiseless algorithms Local-SGD (LGD, Algorithm 1 with no local noise) and SCAFFOLD [18] (Algorithm 4 without “Loopless”) and S*-Local-SGD (LGD*, Algorithm 3). Quadratic minimization, problem type 0 (see Table 6).

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

Relative suboptimality

Relative suboptimality

10 1 10 3 10 5 10 7 10 9 10 11 10 13 0
10 1 10 3 10 5 10 7 10 9 10 11 10 13 0
10 1 10 3 10 5 10 7 10 9 10 11 10 13 0

Type: 1, tau: 5, n: 5

SCAFFOLD LGD LGD*

10000Round2s00o0f0comm30u0n00ication40000 50000

Type: 1, tau: 5, n: 50

SCAFFOLD LGD LGD*

10000Round2s00o0f0comm30u0n00ication40000 50000

Type: 1, tau: 5, n: 500

SCAFFOLD LGD LGD*

10000Round2s00o0f0comm30u0n00ication40000 50000

Relative suboptimality

Relative suboptimality

Relative suboptimality

100 10 1 10 2 10 3 10 4 10 5 10 6 10 7
0
10 1 10 3 10 5 10 7 10 9 10 11 10 13 0
10 1 10 3 10 5 10 7 10 9 10 11 10 13 0

Type: 1, tau: 20, n: 5

SCAFFOLD LGD LGD*

10000Round2s00o0f0 comm30u0n00ication40000 50000

Type: 1, tau: 20, n: 50

SCAFFOLD LGD LGD*

10000Round2s00o0f0comm30u0n00ication40000 50000

Type: 1, tau: 20, n: 500

SCAFFOLD LGD LGD*

10000Round2s00o0f0comm30u0n00ication40000 50000

Relative suboptimality

Relative suboptimality

Relative suboptimality

100
10 1
10 2
10 3
10 4 0
10 1 10 3 10 5 10 7 10 9 10 11 10 13 0
10 1 10 3 10 5 10 7 10 9 10 11 10 13 0

Type: 1, tau: 100, n: 5

SCAFFOLD LGD LGD*

10000Round2s00o0f0 comm30u0n00ication40000 50000

Type: 1, tau: 100, n: 50

SCAFFOLD LGD LGD*

10000Round2s00o0f0comm30u0n00ication40000 50000
Type: 1, tau: 100, n: 500 SCAFFOLD LGD LGD*

10000Round2s00o0f0comm30u0n00ication40000 50000

Relative suboptimality

Figure 4: Comparison of the following noiseless algorithms Local-SGD (LGD, Algorithm 1 with no local noise) and SCAFFOLD [18] (Algorithm 4 without “Loopless”) and S*-Local-SGD (LGD*, Algorithm 3). Quadratic minimization, problem type 1 (see Table 6).

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

Relative suboptimality

Relative suboptimality

10 1 10 3 10 5 10 7 10 9 10 11 10 13 0
10 1 10 3 10 5 10 7 10 9 10 11 10 13 0
10 1 10 3 10 5 10 7 10 9 10 11 10 13 0

Type: 2, tau: 5, n: 5

SCAFFOLD LGD LGD*

10000Round2s00o0f0comm30u0n00ication40000 50000 Type: 2, tau: 5, n: 50
SCAFFOLD LGD LGD*
10000Round2s00o0f0comm30u0n00ication40000 50000 Type: 2, tau: 5, n: 500
SCAFFOLD LGD LGD* 10000Round2s00o0f0comm30u0n00ication40000 50000

Relative suboptimality

Relative suboptimality

Relative suboptimality

Type: 2, tau: 20, n: 5

100

SCAFFOLD

LGD

10 1

LGD*

10 2

10 3

10 4

10 5

0 100

10000Round2s00o0f0 comm30u0n00ication40000 50000 Type: 2, tau: 20, n: 50

10 1

10 2

10 3

10 4

10 5

10 6

SCAFFOLD LGD

10 7

LGD*

0

10000Round2s00o0f0 comm30u0n00ication40000 50000

Type: 2, tau: 20, n: 500

10 1

10 3

10 5

10 7

10 9

SCAFFOLD

10 11

LGD

LGD*

10 13 0

10000 20000 30000 40000 50000

Rounds of communication

Relative suboptimality

Relative suboptimality

Relative suboptimality

100
10 1
10 2 0
100 10 1 10 2 10 3
0 100 10 1 10 2 10 3
0

Type: 2, tau: 100, n: 5

SCAFFOLD LGD LGD*

10000Round2s00o0f0 comm30u0n00ication40000 50000

Type: 2, tau: 100, n: 50

SCAFFOLD LGD LGD*

10000Round2s00o0f0 comm30u0n00ication40000 50000
Type: 2, tau: 100, n: 500 SCAFFOLD LGD LGD*

10000Round2s00o0f0 comm30u0n00ication40000 50000

Relative suboptimality

Figure 5: Comparison of the following noiseless algorithms Local-SGD (LGD, Algorithm 1 with no local noise) and SCAFFOLD [18] (Algorithm 4 without “Loopless”) and S*-Local-SGD (LGD*, Algorithm 3). Quadratic minimization, problem type 2 (see Table 6).

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

Relative suboptimality

Relative suboptimality

10 1 10 3 10 5 10 7 10 9 10 11 10 13 0
10 1 10 3 10 5 10 7 10 9 10 11 10 13 0
10 1 10 3 10 5 10 7 10 9 10 11 10 13 0

Type: 3, tau: 5, n: 5

SCAFFOLD LGD LGD*

10000Round2s00o0f0comm30u0n00ication40000 50000

Type: 3, tau: 5, n: 50

SCAFFOLD LGD LGD*

10000Round2s00o0f0comm30u0n00ication40000 50000

Type: 3, tau: 5, n: 500

SCAFFOLD LGD LGD*

10000Round2s00o0f0comm30u0n00ication40000 50000

Relative suboptimality

Relative suboptimality

Relative suboptimality

100 10 1 10 2 10 3 10 4 10 5 10 6 10 7
0
10 1 10 3 10 5 10 7 10 9 10 11 10 13 0
10 1 10 3 10 5 10 7 10 9 10 11 10 13 0

Type: 3, tau: 20, n: 5

SCAFFOLD LGD LGD*

10000Round2s00o0f0 comm30u0n00ication40000 50000

Type: 3, tau: 20, n: 50

SCAFFOLD LGD LGD*

10000Round2s00o0f0comm30u0n00ication40000 50000

Type: 3, tau: 20, n: 500

SCAFFOLD LGD LGD*

10000Round2s00o0f0comm30u0n00ication40000 50000

Relative suboptimality

Relative suboptimality

Relative suboptimality

100
10 1
10 2
10 3
10 4 0
10 1 10 3 10 5 10 7 10 9 10 11 10 13 0
10 1 10 3 10 5 10 7 10 9 10 11 10 13 0

Type: 3, tau: 100, n: 5

SCAFFOLD LGD LGD*

10000Round2s00o0f0 comm30u0n00ication40000 50000

Type: 3, tau: 100, n: 50

SCAFFOLD LGD LGD*

10000Round2s00o0f0comm30u0n00ication40000 50000
Type: 3, tau: 100, n: 500 SCAFFOLD LGD LGD*

10000Round2s00o0f0comm30u0n00ication40000 50000

Relative suboptimality

Figure 6: Comparison of the following noiseless algorithms: Local-SGD (LGD, Algorithm 1 with no local noise) and SCAFFOLD [18] (Algorithm 4 without “Loopless”) and S*-Local-SGD (LGD*, Algorithm 3). Quadratic minimization, problem type 3 (see Table 6).

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

D Missing Proofs for Section 2

Let us ﬁrst state some well-known consequences of L-smoothness. Speciﬁcally, if fi is L-smooth, we must have

fi(y) ≤ fi(x) +

∇fi(x), y − x

L +

x−y

2,

∀x, y ∈ Rd.

(18)

2

If in addition to this we assume that fi is convex, the following bound holds:

∇fi(x) − ∇fi(y) 2 ≤ 2L(fi(x) − fi(y) − ∇fi(y), x − y ) d=ef 2LDfi (x, y), ∀x, y ∈ Rd (19)

We next proceed with the proof of Theorem 2.1. Following the technique of virtual iterates from [46, 20], notice that the sequence {xk}k≥0 satisﬁes the recursion

γn

xk+1 = xk −

gik .

n

i=1

(20)

This observation forms the backbone of the key lemma of our paper, which we present next.
Lemma D.1. Let As. 2.1, 2.2 and 2.3 be satisﬁed and γ ≤ min {1/2(A +MC), L/(F +MG)}, where M = 43Bρ . Let η d=ef min γµ, ρ4 . Then for all k ≥ 0 we have

γE f (xk) − f (x∗) ≤ (1 − η)ET k − ET k+1 + γ2(D1 + M D2) + 2LγEVk,

(21)

where η d=ef min γµ, ρ4 , T k d=ef xk − x∗ 2 + M γ2σk2.

Proof. First of all, to simplify the proofs we introduce new notation: gk d=ef n1

n i=1

gik

.

Using

this

and

(20)

we

get

xk+1 − x∗ 2

(20)
=

=

xk − x∗ − γgk 2 xk − x∗ 2 − 2γ xk − x∗, gk + γ2 gk 2.

Taking conditional mathematical expectation Ek[·] = E[· | xk] d=ef E[· | xk1, . . . , xkn] on both sides of the previous inequality we get

(7)

2γ n

E xk+1 − x∗ 2 | xk = xk − x∗ 2 −

xk − x∗, ∇fi(xki ) + γ2E gk 2 | xk ,

n

i=1

hence

E xk+1 − x∗ 2

(140)
≤
(8)
≤

E xk − x∗ E xk − x∗
+2A γ2E

2 − 2γ n E n
i=1
2 − 2γ n E n
i=1
f (xk) − f (x∗)

xk − x∗, ∇fi(xki ) + γ2E gk 2 xk − x∗, ∇fi(xki ) + B γ2E σk2 + F γ2E [Vk] + γ2D1.

(22)

Next, we derive an upper bound for the second term on the right-hand side of the previous inequality:

2γ n

−

xk − x∗, ∇fi(xki )

n

i=1

=
(5),(18)
≤
(136)
≤

2γ n n i=1 2γ n n i=1
2γ +
n

x∗ − xki , ∇fi(xki ) + xki − xk, ∇fi(xki )

fi(x∗) − fi(xki ) − µ2 xki − x∗ 2

n

L

fi(xki ) − fi(xk) + xk − xki 2

2

i=1

−2γ f (xk) − f (x∗) − µγ xk − x∗ 2 + LγVk.

(23)

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

Plugging (23) in (22), we obtain

(22),(23)

E xk+1 − x∗ 2

≤ (1 − γµ)E xk − x∗ 2 − 2γ (1 − A γ) E f (xk) − f (x∗)

+B γ2E σk2 + γ (L + F γ) E [Vk] + γ2D1.

(24)

It implies that

ET k+1

=
(24),(10)
≤

E xk+1 − x∗ 2 + M γ2E σk2+1 (1 − γµ)E xk − x∗ 2 + 1 + BM − ρ M γ2Eσk2
−2γ (1 − (A + M C) γ) E f (xk) − f (x∗) +γ (L + (F + M G)γ) EVk + γ2 (D1 + M D2) .

Since M = 43Bρ , η = min ET k+1

γµ, ρ4 and γ ≤ min {1/2(A +MC), L/(F +MG)}, we get
≤ (1 − γµ)E xk − x∗ 2 + 1 − ρ4 M γ2Eσk2 − γE f (xk) − f (x∗) +2LγEVk + γ2 (D1 + M D2)
≤ (1 − η)ET k − γE f (xk) − f (x∗) + 2LγEVk + γ2 (D1 + M D2) .

Rearranging the terms we get (21).

Using the above lemma we derive the main complexity result.

D.1 Proof of Theorem 2.1

From Lemma D.1 we have that

γE f (xk) − f (x∗) ≤ (1 − η)ET k − ET k+1 + γ2(D1 + M D2) + 2LγEVk.

Summing up previous inequalities for k = 0, . . . , K with weights wk deﬁned in (12) we derive

K
γ wkE f (xk) − f (x∗)
k=0

≤
(12),(11)
≤

K
wk(1 − η)ET k − wkET k+1 + γ2(D1 + M D2)WK

k=0

K

+2Lγ wkEVk

k=0

K
wk−1ET k − wkET k+1 + γ2 (D1 + M D2) WK

k=0

γK

+

wkE f (xk) − f (x∗) + 2LHγEσ02 + 2Lγ3D3WK .

2

k=0

Relations T k ≥ 0 and w−1 = 1 imply that

γK wkE f (xk) − f (x∗)
2
k=0

≤ T 0 + 2LHγEσ02 + γ2 (D1 + M D2 + 2LγD3) WK .

Using the deﬁnition of xK and convexity of f , we get

K

∗

2T 0 + 4LHγEσ02

E f (x ) − f (x ) ≤

γWK

+ 2γ (D1 + M D2 + 2LγD3) .

(25)

It remains to consider two cases: µ > 0 and µ = 0. If µ > 0 we have WK ≥ wK ≥ (1 − η)−K , where
η d=ef min γµ, ρ4 which implies (13). Finally, when µ = 0, we have wk = 1 for all k ≥ 0, which implies WK = K + 1 ≥ K and (14).

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

D.2 Corollaries
We state the full complexity results that can be obtained from Theorem 2.1. These results can be obtained as a direct consequence of Lemmas I.2 and I.3. Corollary D.1. Consider the setup from Theorem 2.1 and denote h1 to be the resulting upper bound on γ12 and µ > 0.

1. If D3 does not depend on γ, then for all K such that

either or

ln max{2, min{aµ2K2/c1, aµ3K3/c2}} ≤ρ
K

1 ln max{2, min{aµ2K2/c1, aµ3K3/c2}}

≤

,

h

µK

a=2

x0 − x∗

2 + 8B3hE2ρσ02

+

4LHEσ02 ,
h

c1

=

2D1

+

4B3ρD2 ,

c2

=

4LD3

and

1 γ = min h , γK ,

ln max 2, min aµc21K2 , aµc32K3

γK =

, µK

we have13

E f (xK ) − f (x∗) = O ha exp − min µ , ρ K + c1 + c2 .

h

µK µ2K2

That is, to achieve E f (xK ) − f (x∗) ≤ ε, the method requires14:

K =O

1 + h log ha + c1 +

ρµ

ε

µε

c2 . µ2ε

2.

If

D3

= D3,1 +

, D3,2
γ

then

the

same

bounds

hold

with

c1

= 2D1 +

4B D2 3ρ

+ 2LD3,2

and

c2

= 4LD3,1.

Corollary D.2. Let assumptions of Theorem 2.1 be satisﬁed with any γ ≤ h1 and µ = 0.

1. If D3 does not depend on γ, then for all K and

1a a a

a

γ = min , , 3 ,

,3

,

h b1 b2 c1K c2K

where

a=2

x0 − x∗ 2, b1 = 4LHEσ02, b2 = E f (xK ) − f (x∗) = O

8B Eσ02 ,
3ρ

c1

=

2D1

+

4B3ρD2 ,

c2

=

4LD3,

we

have

√

√

ha + ab1 + 3 a2b2 +

KK

K

√

ac1 + 3 a2c2 .

K

K 2/3

That is, to achieve E f (xK ) − f (x∗) ≤ ε, the method requires

√

√

√

K = O ha + ab1 + 3 a2b2 + ac1 + a c2 .

ε

ε

ε

ε2

ε3/2

2.

If

D3

= D3,1 +

, D3,2
γ

then

the

same

bounds

hold

with

c1

= 2D1 +

4B D2 3ρ

+ 2LD3,2

and

c2

= 4LD3,1.

12In order to obtain tight estimate of parameters D3 and H, we shall impose further bounds on γ (see Section 3 and Table 1 therein).
13O hides numerical constants and logarithmical factors depending on K and parameters of the problem. 14If c1 = c2 = 0, then one can replace O by O.

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

E Missing Proofs and Details for Section 3

E.1 Constant Local Loop In this section we show how our results can be applied to analyze (4) in the case when

1, if k mod τ = 0, ck =
0, if k mod τ = 0,

where τ is number of local steps between two neighboring rounds of communications. This corresponds to the setting in which the local loop size on each device has a ﬁxed length.

E.1.1 Heterogenous Data
First of all, we need to assume more about gik. Assumption E.1. We assume that inequalities (8)-(10) hold and additionally there exist such non-negative constants A, A, B, B, F , F , D1, D1 that for all k ≥ 0

1n

E g¯ik 2 ≤ 2AE f (xk) − f (x∗) + BE σk2 + F E [Vk] + D1,

(26)

n

i=1

1n

E gik − g¯ik 2 ≤ 2AE f (xk) − f (x∗) + BE σk2 + F E [Vk] + D1,

(27)

n

i=1

where g¯ik = E

gik

|

x

k 1

,

.

.

.

,

x

k n

.

We notice that inequalities (26)-(27) imply (8) and vice versa. Indeed, if (26)-(27) hold then inequality (8) holds with A = A + A, B = B + B, F = F + F , D1 = D1 + D1 due to variance decomposition formula (139), and if (8) is true then (26)-(27) also hold with A = A = A, B = B = B, F = F = F , D1 = D1 = D1.
We start our analysis without making any assumption on homogeneity of data that workers have an access to. Next lemma provides an upper bound for the weighted sum of EVk. Lemma E.1. Let As. 2.1, 2.2 and E.1 hold and15









 

1

1

 

γ ≤ min

,

,

 4(τ − 1)µ 2 e(τ − 1) F (τ − 1) + F + 2G(Bρ((τ1−−ρ1))+B) 

1 γ≤
4 2eL(τ − 1) A(τ − 1) + A + 2C(Bρ((τ1−−ρ1))+B)

Then (11) holds with

4e(τ − 1)(B(τ − 1) + B)(2 + ρ)γ2

2D2(B(τ − 1) + B)

H=

, D3 = 2e(τ − 1) D1(τ − 1) + D1 +

. (28)

ρ

ρ

Proof. Consider some integer k ≥ 0. There exists such integer t ≥ 0 that τ t ≤ k ≤ τ (t + 1) − 1. Using this and
15When ρ = 1 one can always set the parameters in such a way that B = B = C = G = 0, D2 = 0. In this case we assume that ρ2(1B−Cρ) = ρ2(1B−Cρ) = ρ2(1B−Gρ) = ρ2(1B−Gρ) = 0.

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

Lemma I.1 we get

E[Vk ]

(4),(20)
=



n

k−1

k−1 2

n1 E  xτi t − γ gil − xτt + γ gl 

i=1

l=τ t

l=τ t

γ2 n


k−1

2

=

E

gil − gl 

n

i=1

l=τ t

(141)
≤
(139)
≤

eγ2(k − τ t) n k−1

2 eγ2 n k−1

2

E g¯il − g¯l +

E gil − g¯il − gl − g¯l

n

n

i=1 l=τ t

i=1 l=τ t

eγ2(τ − 1) n k−1 E
n i=1 l=τ t

2 eγ2 n k−1

g¯il +

E

n

i=1 l=τ t

gl − g¯l 2 ,

i

i

n
where g¯k = n1 g¯ik. Applying Assumption E.1, we obtain
i=1

(26),(27)

k−1

k−1

EVk ≤ 2e A(τ − 1) + A γ2 E f (xl) − f (x∗) + e B(τ − 1) + B γ2 Eσl2

l=τ t

l=τ t

k−1
+e F (τ − 1) + F γ2 EVl + e(τ − 1) D1(τ − 1) + D1 γ2,

l=τ t

hence

k

k j−1

k j−1

wjEVj ≤ 2e A(τ − 1) + A γ2

wjE f (xl) − f (x∗) + e B(τ − 1) + B γ2

wj Eσl2

j=τ t

j=τ t l=τ t

j=τ t l=τ t

k j−1

k

+e F (τ − 1) + F γ2

wjEVl + e(τ − 1) D1(τ − 1) + D1 γ2 wj.

j=τ t l=τ t

j=τ t

(29)

Recall that wk = (1 − η)−(k+1) and η = min γµ, ρ4 . Together with our assumption on γ it implies that for all 0 ≤ i < k, 0 ≤ j ≤ τ − 1 we have

(137)
wk = (1 − η)−(k−j+1) (1 − η)−j ≤ wk−j (1 + 2η)j

j

1

j

j

≤ wk−j (1 + 2γµ) ≤ wk−j 1 + 2(τ − 1) ≤ wk−j exp 2(τ − 1)

1 ≤ wk−j exp 2 ≤ 2wk−j, (30)

−(k−i+1)

−i (137)

i

ρi

wk = (1 − η)

(1 − η) ≤ wk−i (1 + 2η) ≤ wk−i 1 + ,

2

(137)

k+1

ρ k+1

wk ≤ (1 + 2η) ≤ 1 +

.

2

(31) (32)

For simplicity, we introduce new notation: rk d=ef E f (xk) − f (x∗) . Using this we get

k j−1

(30)

wj rl ≤

k j−1

k

k

2wlrl ≤ 2(k − τ t) wjrj ≤ 2(τ − 1) wjrj,

j=τ t l=τ t

j=τ t l=τ t

j=τ t

j=τ t

k j−1

(30)

wj Eσl2 ≤

k j−1

k

k

2wlEσl2 ≤ 2(k − τ t) wjEσj2 ≤ 2(τ − 1) wjEσj2,

j=τ t l=τ t

j=τ t l=τ t

j=τ t

j=τ t

k j−1

(30)

wj EVl ≤

k j−1

k

k

2wlEVl ≤ 2(k − τ t) wjEVj ≤ 2(τ − 1) wjEVj.

j=τ t l=τ t

j=τ t l=τ t

j=τ t

j=τ t

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

Plugging these inequalities in (29) we derive

k

k

k

wjEVj ≤ 4e(τ − 1)(A(τ − 1) + A)γ2 wjrj + 2e(τ − 1)(B(τ − 1) + B)γ2 wjEσj2

j=τ t

j=τ t

j=τ t

k
+2e(τ − 1)(F (τ − 1) + F )γ2 wjEVj + e
j=τ t

D1(τ − 1) + D1

k
γ2 wj .
j=τ t

Since Vτt = 0 for all integer t ≥ 0 we obtain

K

K

K

wkEVk ≤ 4e(τ − 1)(A(τ − 1) + A)γ2 wkrk + 2e(τ − 1)(B(τ − 1) + B)γ2 wkEσk2

k=0

k=0

k=0

K

K

+2e(τ − 1)(F (τ − 1) + F )γ2 wkEVk + e D1(τ − 1) + D1 γ2 wk

(33)

k=0

k=0

It remains to estimate the second term in the right-hand side of the previous inequality. First of all,

(10)
Eσk2+1 ≤ (1 − ρ)Eσk2 + 2C E f (xk) − f (x∗) +GEVk + D2

It implies that

rk

k

k

k

≤ (1 − ρ)k+1Eσ02 + 2C (1 − ρ)k−lrl + G (1 − ρ)k−lEVl + D2 (1 − ρ)l

l=0

l=0

l=0

k

k

∞

≤ (1 − ρ)k+1Eσ02 + 2C (1 − ρ)k−lrl + G (1 − ρ)k−lEVl + D2 (1 − ρ)l

l=0

l=0

l=0

k k+1 2

k−l

k

k−l

D2

= (1 − ρ) Eσ0 + 2C (1 − ρ) rl + G (1 − ρ) EVl + ρ .

l=0

l=0

(34)

K
wk Eσk2
k=0

(34)
≤
(31),(32)
≤
(138)
≤
≤
=

K

2C K k

Eσ02 wk(1 − ρ)k +

wk(1 − ρ)k−lrl

1−ρ

k=0

k=0 l=0

G +

K k wk(1 − ρ)k−lEVl + D2WK

1−ρ

ρ

k=0 l=0

ρK

ρk

2C K k

ρ k−l

Eσ02 1 +

1 + (1 − ρ)k +

wl 1 +

(1 − ρ)k−lrl

2

2

1−ρ

2

k=0

k=0 l=0

G Kk + 1 − ρ wl
k=0 l=0

ρ 1+
2

k−l (1 − ρ)k−lEVl + D2WK ρ

ρK

ρ k 2C K k

ρ k−l

Eσ02 1 +

1− +

wlrl 1 −

2

2

1−ρ

2

k=0

k=0 l=0

G Kk

+ 1−ρ

wlEVl

k=0 l=0

ρ 1−
2

k−l + D2WK ρ

ρ∞

ρ k 2C

Eσ02 1 +

1− +

2

2

1−ρ

k=0

K
wk rk
k=0

∞

ρl

1−

l=0 2

G +
1−ρ

K
wk EVk
k=0

∞

ρl

1−

l=0 2

+ D2WK ρ

Eσ02(2 + ρ) + 4C

K

2G

wkrk +

K

D2WK

wkEVk +

.

ρ

ρ(1 − ρ)

ρ(1 − ρ)

ρ

k=0

k=0

(35)

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

Plugging this inequality in (33) we get

K

2C(B(τ − 1) + B)

wkEVk ≤ 4e(τ − 1)γ2 A(τ − 1) + A +

K
wk rk

ρ(1 − ρ)

k=0

k=0

+ 2e(τ − 1)(B(τ − 1) + B)Eσ02(2 + ρ)γ2 ρ

+2e(τ − 1)γ2

2G(B(τ − 1) + B) F (τ − 1) + F +
ρ(1 − ρ)

K
wk EVk
k=0

+e(τ − 1)γ2 D1(τ − 1) + D1 + 2D2(B(τ − 1) + B) WK . ρ

Our choice of γ implies

4e(τ − 1)γ2

2C(B(τ − 1) + B) A(τ − 1) + A +

1 ≤

ρ(1 − ρ)

8L

and

2e(τ − 1)γ2

2G(B(τ − 1) + B) F (τ − 1) + F +

1 ≤.

ρ(1 − ρ)

2

Using these inequalities we continue our derivations

1K wkEVk ≤

1 K wkrk + 2e(τ − 1)(B(τ − 1) + B)Eσ02(2 + ρ)γ2

2

8L

ρ

k=0

k=0

+e(τ − 1)γ2 D1(τ − 1) + D1 + 2D2(B(τ − 1) + B) ρ

WK .

Multiplying both sides by 4L we get the result.

Clearly, this lemma and Theorem 2.1 imply the following result.
Corollary E.1. Let the assumptions of Lemma E.1 are satisﬁed. Then Assumption 2.3 holds and, in particular, if







1

L

γ ≤ min  2 A + 4B3ρC , F + 4B3ρG  ,









 

1

1

 

γ ≤ min

,

,

 4(τ − 1)µ 2 e(τ − 1) F (τ − 1) + F + 2G(Bρ((τ1−−ρ1))+B) 

γ≤

1 ,

4 2eL(τ − 1) A(τ − 1) + A + 2C(Bρ((τ1−−ρ1))+B)

then for all K ≥ 0 we have

K

∗

2

x0 − x∗

2

+

8B 3ρ

γ2Eσ02

+

4LH γ Eσ02

4B D2

E f (x ) − f (x ) ≤

γWK

+ 2γ D1 + 3ρ + 2LγD3 , (36)

where xK d=ef W1K

K k=0

wk

xk

and

4e(τ − 1)(B(τ − 1) + B)(2 + ρ)γ2

2D2(B(τ − 1) + B)

H=

, D3 = 2e(τ − 1) D1(τ − 1) + D1 +

.

ρ

ρ

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

Moreover, if µ > 0, then

E f (xK ) − f (x∗) ≤ 1 − min γµ, ρ K 2 x0 − x∗ 2 + 83Bρ γ2Eσ02 + 4LHγEσ02

4

γ

4B D2

+2γ D1 + 3ρ + 2LγD3 ,

(37)

and in the case when µ = 0, we have

K

∗

2

x0 − x∗

2

+

8B 3ρ

γ2Eσ02

+

4LH γ Eσ02

4B D2

E f (x ) − f (x ) ≤

γK

+ 2γ D1 + 3ρ + 2LγD3 . (38)

Remark E.1. As we will see later when looking at particular special cases, local gradient methods are only as good as their non-local counterparts (i.e., when τ = 1) in terms of the communication complexity in the fully heterogeneous setup. Furthermore, the non-local methods outperform local ones in terms of computation complexity. While one might think that this observation is a byproduct of our analysis, our observations are supported by ﬁndings in recent literature on this topic [18, 20]. To rise to the defense of local methods, we remark that they might be preferable to their non-local cousins in the homogeneous data setup [51] or for personalized federated learning [13].

E.1.2 ζ-Heterogeneous Data

In this section we assume that f1, f2, . . . , fn are ζ-heterogeneous (see Deﬁnition 3.1). Moreover, we additionally assume that E gik | xki = ∇fi(xki ) and that the functions fi for i ∈ [n] are µ-strongly convex,

fi(x) ≥ fi(y) +

∇fi(y), x − y

µ +

x−y

2

∀x, y ∈ Rd

(39)

2

which implies (e.g., see [33])

∇fi(x) − ∇fi(y), x − y ≥ µ x − y 2 ∀x, y ∈ Rd.

(40)

Lemma E.2. Let Assumption 2.2 be satisﬁed, inequalities (7)-(10) hold and16









 

1

1

1

 

γ ≤ min

,

,

.

 4(τ − 1)µ 2 (τ − 1) F + ρ2(1B−Gρ) 4 2L(τ − 1) A + ρ2(1B−Cρ) 

Moreover, assume that f1, f2, . . . , fn are ζ-heterogeneous and µ-strongly convex, and E gik | xki = ∇fi(xki ) for all i ∈ [n]. Then (11) holds with

4B(τ − 1)γ2(2 + ρ)

ζ2 2BD2

H=

, D3 = 2(τ − 1) D1 + +

.

(41)

ρ

γµ ρ

16When ρ = 1 one can always set the parameters in such a way that B = C = G = 0, D2 = 0. In this case we assume that ρ2(1B−Cρ) = ρ2(1B−Gρ) = 0.

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

Proof. First of all, if k mod τ = 0, then Vk = 0 by deﬁnition. Otherwise, we have

(4),(20) 1 n

k−1

k−1

k−1

k−1 2

Vk = n

xi − x − γgi + γg

i=1

1 n k−1

k−1 2 2γ n k−1

k−1 k−1

k−1

γ2 n

= n

xi − x

+ n

xi − x , g − gi

+ n

i=1

i=1

i=1

1 n k−1

k−1 k−1

2γ n k−1 k−1 k−1

= Vk−1 + 2γ n xi − x , g

+ n

x − xi , gi

i=1

i=1

γ2 n +
n i=1

gik−1 − gk−1 2

2γ n k−1

k−1 k−1

γ2 n k−1

k−1 2

= Vk−1 + n

x − xi , gi

+ n

gi − g

.

i=1

i=1

gik−1 − gk−1 2

Next, we take the conditional expectation E · | xk−1 d=ef E · | xk1−1, . . . , xkn−1 on both sides of the obtained inequality and get

E Vk | xk−1

=
(139)
≤

2γ n Vk−1 + n
i=1

xk−1 − xki −1, ∇fi(xki −1)

γ2 n

+

E

n i=1

gik−1 − gk−1

2γ n Vk−1 + n
i=1

xk−1 − xki −1, ∇fi(xki −1) − ∇fi(xk−1)

2γ n +
n i=1

xk−1 − xki −1, ∇fi(xk−1)

γ2 n

+

E

n i=1

gik−1 2 | xk−1 .

2 | xk−1

Since n1

n i=1

xk−1 − xki −1, ∇f (xk−1)

= 0, we can continue as follows:

E Vk | xk−1

(40)
≤
(132)
≤
(15)
≤

2γµ n Vk−1 − n
i=1

k−1

k−1 2 γ2 n

x − xi

+

E

n

i=1

gik−1 2 | xk−1

2γ n k−1 k−1

k−1

k−1

+ n

x − xi , ∇fi(x ) − ∇f (x )

i=1

γ2 n (1 − 2γµ)Vk−1 + n E
i=1

gik−1 2 | xk−1

2γ n +
n i=1

µ2 xk−1 − xki −1 2 + 21µ ∇fi(xk−1) − ∇f (xk−1) 2

γ2 n (1 − γµ)Vk−1 + n E
i=1

k−1 2 k−1 γζ2

gi

|x + . µ

Taking full expectation on both sides of previous inequality, we obtain

EVk

(140)
≤

γ2 n E [Vk−1] + n E
i=1

k−1 2 γζ2

gi

+. µ

Let t be a non-negative integer for which τ t ≤ k < τ (t + 1). Using this and Vτt = 0, we unroll the recurrence and derive

γ2 k−1 n

γζ2(k − τ t)

E[Vk] ≤

E gil 2 +

n

µ

l=τ t i=1

(8)

k−1

γζ2(k − τ t)

≤ γ2

2AE f (xl) − f (x∗) + BE[σl2] + F E[Vl] + D1 +

,

µ

l=τ t

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

whence

k

k j−1

k j−1

wjEVj ≤ 2Aγ2

wjE f (xl) − f (x∗) + Bγ2

wj Eσl2

j=τ t

j=τ t l=τ t

j=τ t l=τ t

k j−1

+F γ2

wjEVl + (τ − 1)

j=τ t l=τ t

γ2D1 + γζ2 µ

k
wj .
j=τ t

If we substitute A with e(A(τ − 1) + A), B with e(B(τ − 1) + B), F with e(F (τ − 1) + F ), and γ2D1 + γµζ2
with eγ2(D1(τ − 1) + D1) in the inequality above, we will get inequality (29). Following the same steps as in the proof of Lemma E.1, we get

K

2BC

wkEVk ≤ 4(τ − 1)γ2 A +

K wkrk + 2BEσ02(2 + ρ)(τ − 1)γ2

ρ(1 − ρ)

ρ

k=0

k=0

+2(τ − 1)γ2

2BG F+
ρ(1 − ρ)

K
wkEVk + (τ − 1)γ2
k=0

ζ2 2BD2 D1 + +
γµ ρ

WK .

Our choice of γ implies that

4(τ − 1)γ2 A + 2BC

1 ≤

and 2(τ − 1)γ2 F + 2BG

1 ≤.

ρ(1 − ρ) 8L

ρ(1 − ρ) 2

Using these inequalities we continue our derivations

1K wkEVk ≤

1 K wkrk + 2BEσ02(2 + ρ)(τ − 1)γ2

2

8L

ρ

k=0

k=0

+(τ − 1)γ2 D1 + ζ2 + 2BD2 WK . γµ ρ

Multiplying both sides by 4L we get the result.

Clearly, this lemma and Theorem 2.1 imply the following result. Corollary E.2. Let the assumptions of Lemma E.2 be satisﬁed. Then Assumption 2.3 holds and, in particular, if

1

L

4B

γ ≤ min

,

, M= ,

2(A + CM ) F + GM

3ρ









 

1

1

1

 

γ ≤ min

,

,

,

 4(τ − 1)µ 2 (τ − 1) F + ρ2(1B−Gρ) 4 2L(τ − 1) A + ρ2(1B−Cρ) 

then for all K ≥ 0 we have

K

∗

2T 0 + 4LHγEσ02

E f (x ) − f (x ) ≤

γWK

+ 2γ (D1 + M D2 + 2LγD3) ,

(42)

where xK d=ef W1K

K k=0

wk

xk

and

4B(τ − 1)γ2(2 + ρ)

ζ2 2BD2

H=

, D3 = 2(τ − 1) D1 + +

.

ρ

γµ ρ

Moreover, if µ > 0, then

K

∗

ρ K 2T 0 + 4LHγEσ02

E f (x ) − f (x ) ≤ 1 − min γµ, 4

γ

+ 2γ (D1 + M D2 + 2LγD3) , (43)

and in the case when µ = 0, we have

K

∗

2T 0 + 4LHγEσ02

E f (x ) − f (x ) ≤

γK

+ 2γ (D1 + M D2 + 2LγD3) .

(44)

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

E.2 Random Local Loop In this section we show how our results can be applied to analyze (4) in the case when

1, with probability p, ck =
0, with probability 1 − p,

where p encodes the probability of initiating communication. This choice in eﬀect leads to a method using a random-length local loop on all devices.

E.2.1 Heterogeneous Data

As in Section E.1.1, our analysis of (4) with random length of the local loop relies on Assumption E.1. Next lemma provides an upper bound for the weighted sum of E [Vk] in this case. Lemma E.3. Let Assumptions 2.1, 2.2 and E.1 be satisﬁed and17





p

p



γ ≤ min

,

,

 16µ 2 (1 − p)((2 + p)F + pF ) 









 

√

 

 

p 3ρ(1 − ρ)

p3

 

γ ≤ min

,

.

 8 2G(1 − p) (p + 2)B + pB 16 2L(1 − p) (2 + p)A + pA + 2C((pρ+(12−)Bρ)+pB) 

Then (11) holds with

64(1 − p) (p + 2)B + pB (2 + ρ)γ2

H=

3p2ρ ,





8(1 − p)

8D2 (p + 2)B + pB

D3 = p2 (p + 2)D1 + pD1 +

. 3ρ

(45)

Proof.

First

of

all,

we

introduce

new

notation:

E[·

|

xk, gk]

d=ef

E[·

|

x

k 1

,

.

.

.

,

x

k n

,

g1k

,

.

.

.

,

g

k n

],

E[· | xk] d=ef E[· |

x

k 1

,

.

.

.

,

x

k n

].

By

deﬁnition

of

Vk ,

we

have

E Vk+1 | xk

(140)
= =
(139)
=
(135),(139)
≤
(138),(139)
≤

1n EE
n i=1

xki +1 − xk+1 2 | xk, gk | xk

1−p n E
n i=1

xki − xk − γgik + γgk 2 | xk

1−p n

(1 − p)γ2 n

xki − xk − γg¯ik + γg¯k 2 +

E

n

n

i=1

i=1

gik − g¯ik − (gk − g¯k) 2 | xk

(1 − p) 1 + p2 n

n

(1 − p) 1 + 2

k − xk 2 +

p

xi

n

i=1

γ2 n
i=1

g¯ik − g¯k 2

(1 − p)γ2 n

+

E

n i=1

gik − g¯ik 2 | xk

p 1−
2

(1 − p)(2 + p)γ2 n Vk + pn
i=1

2 (1 − p)γ2 n

g¯ik +

E

n

i=1

gik − g¯ik 2 | xk ,

17When ρ = 1 one can always set the parameters in such a way that B = B = C = G = 0, D2 = 0. In this case we assume that ρ2(1B−Cρ) = ρ2(1B−Cρ) = ρ2(1B−Gρ) = ρ2(1B−Gρ) = 0.

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

where g¯k = E[gk | xk]. Taking the full expectation we derive

E [Vk+1] ≤
(26),(27)
≤

p 1−
2

(1 − p)(2 + p)γ2 n E [Vk] + pn E
i=1

2 (1 − p)γ2 n

g¯ik +

E

n

i=1

p 1−

E [Vk] + 2(1 − p)γ2

2+p A+A

E f (xk) − f (x∗)

2

p

+(1 − p)γ2 2 +p p B + B Eσk2 + 2 +p p F + F EVk

+(1 − p)γ2

2+p D1 + D1

.

p

gik − g¯ik 2

This inequality together with γ ≤ √

p

imply

2 (1−p)((2+p)F +pF )

E [Vk+1] ≤

p 1−

E [Vk] + 2(1 − p)γ2

2+p A+A

E f (xk) − f (x∗)

4

p

+(1 − p)γ2 2 +p p B + B Eσk2 + (1 − p)γ2 2 +p p D1 + D1 .

Unrolling the recurrence, we obtain

2+p

k

p k−l

E [Vk+1] ≤ 2(1 − p)γ2

A+A

1−

E f (xl) − f (x∗)

p

4

l=0

+(1 − p)γ2

2+p B+B
p

k

p k−l

1−

Eσl2

4

l=0

+(1 − p)γ2

2+p p D1 + D1

k

p k−l

1−

.

l=0 4

As a consequence, we derive

K

2(1 − p) (2 + p)A + pA γ2 K k

p k−l

wkE [Vk] ≤

p 1− p

1− 4

wk rl

k=0

4

k=0 l=0

(1 − p) +

(2 + p)B + pB p 1 − p4

γ2 K k
k=0 l=0

p 1−
4

k−l
wkE σl2

(1 − p) +

(2 + p)D1 + pD1 p

γ2 K k−1
k=0 l=0

p 1−
4

k−1−l
wk ,

(46)

where we use new notation: rl = E f (xl) − f (x∗) . Recall that wk = (1 − η)−(k+1) and η = min γµ, ρ4 . Together with our assumption on γ it implies that for all 0 ≤ i < k we have

(137)
wk = (1 − η)−(k−i+1) (1 − η)−i ≤ wk−i (1 + 2η)i

i

pi

≤ wk−i (1 + 2γµ) ≤ wk−i 1 + ,

8

−(k−i+1)

−i (137)

i

ρi

wk = (1 − η)

(1 − η) ≤ wk−i (1 + 2η) ≤ wk−i 1 + ,

2

(137)

k+1

ρ k+1

wk ≤ (1 + 2η) ≤ 1 +

.

2

(47) (48) (49)

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

Having these inequalities in hand we obtain

Kk k=0 l=0

p 1−
4

k−l
wk rl

(47)
≤
(138)
≤
=

Kk k=0 l=0

p 1−
4

Kk k=0 l=0

p 1−
8

8K p wkrk,
k=0

k−l

p

1+

8

k−l
wlrl ≤

k−l
wlrl
K
wk rk
k=0

∞

pk

1−

k=0 8

Kk k=0 l=0

p 1−
4

k−l
wkE σl2

(47)
≤
(138)
≤
=

K k 1 − p k−l 1 + p k−l wlE σl2

4

8

k=0 l=0

K k 1 − p k−l wlE σl2 ≤ 8
k=0 l=0

K
wkE σk2
k=0

8K wkE σk2 ,
p
k=0

∞

pk

1−

k=0 8

and

K k−1

p k−1−l

1− 4

wk ≤

k=0 l=0

K
wk
k=0

∞

pk

1−

k=0 4

= 4WK . p

Plugging these inequalities together with 1 − p4 ≥ 34 in (46), we derive

K

64(1 − p) (2 + p)A + pA γ2 K

32(1 − p) (2 + p)B + pB γ2 K

wkE [Vk] ≤

3p2

wkrk +

3p2

wkE σk2

k=0

k=0

k=0

4(1 − p) (2 + p)D1 + pD1 γ2

+

p2

WK .

(50)

It remains to estimate the second term on the right-hand side of this inequality. We notice that an analogous term appears in the proof of Lemma E.1. In particular, in that proof inequality (35) was shown via inequalities (10), (48), (49) and (138) which hold in this case too. Therefore, we get that

whence

K
wkE σk2
k=0

(3≤5) Eσ02(2 + ρ) + 4C

K

2G

wkrk +

K

D2WK

wkEVk +

,

ρ

ρ(1 − ρ)

ρ(1 − ρ)

ρ

k=0

k=0

K

64(1 − p)γ2 (2 + p)A + pA + 2C((p+2)B+pB) K

(50)

ρ(1−ρ)

wkE [Vk] ≤
k=0

3p2

wk rk

k=0

32(1 − p) (p + 2)B + pB (2 + ρ)γ2Eσ02 + 3p2ρ

64G(1 − p) (p + 2)B + pB γ2 K

+ 3p2ρ(1 − ρ)

wkE [Vk]

k=0



4(1 − p)γ2

8D2 (p + 2)B + pB

+ p2 (p + 2)D1 + pD1 +

3ρ

  WK .

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

Our assumptions on γ imply

64(1 − p)γ2

(2 + p)A + pA + 2C((p+2)B+pB)
ρ(1−ρ)
3p2

1 ≤,
8L

64G(1 − p) (p + 2)B + pB γ2 1

3p2ρ(1 − ρ)

≤. 2

Next, we introduce new notation as follows:

64(1 − p) (p + 2)B + pB (2 + ρ)γ2

H=

3p2ρ ,





8(1 − p)

8D2 (p + 2)B + pB

D3 = p2 (p + 2)D1 + pD1 +

. 3ρ

Putting all together, we get

1K

1K

H 2 D3 2

2 wkE [Vk] ≤ 8L wkrk + 2 Eσ0 + 2 γ WK ,

k=0

k=0

which concludes the proof.

This lemma and Theorem 2.1 imply the following result. Corollary E.3. Let the assumptions of Lemma E.3 be satisﬁed. Then Assumption 2.3 holds and, in particular, if







1

L

p

p



γ

≤

min  2 A + 4B C

, F

+

4B

G

,

, 16µ

3ρ

2

, (1 − p)((2 + p)F + pF ) 

3ρ









 

√

 

 

p 3ρ(1 − ρ)

p3

 

γ ≤ min

,

,

 8 2G(1 − p) (p + 2)B + pB 16 2L(1 − p) (2 + p)A + pA + 2C((pρ+(12−)Bρ)+pB) 

then for all K ≥ 0 we have

K

∗

2

x0 − x∗

2

+

8B 3ρ

γ2Eσ02

+

4LH γ Eσ02

4B D2

E f (x ) − f (x ) ≤

γWK

+ 2γ D1 + 3ρ + 2LγD3 , (51)

where xK d=ef W1K

K k=0

wk

xk

and

64(1 − p) (p + 2)B + pB (2 + ρ)γ2

H=

3p2ρ ,





8(1 − p)

8D2 (p + 2)B + pB

D3 = p2 (p + 2)D1 + pD1 +

. 3ρ

Moreover, if µ > 0, then

E f (xK ) − f (x∗) ≤ 1 − min γµ, ρ K 2 x0 − x∗ 2 + 83Bρ γ2Eσ02 + 4LHγEσ02

4

γ

4B D2

+2γ D1 + 3ρ + 2LγD3 ,

(52)

and in the case when µ = 0, we have

K

∗

2

x0 − x∗

2

+

8B 3ρ

γ2Eσ02

+

4LH γ Eσ02

4B D2

E f (x ) − f (x ) ≤

γK

+ 2γ D1 + 3ρ + 2LγD3 . (53)

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

E.2.2 ζ-Heterogeneous Data

In this section we assume that f1, f2, . . . , fn are ζ-heterogeneous (see Deﬁnition 3.1). Moreover, we additionally assume that E gik | xki = ∇fi(xki ) and we also assume µ-strong convexity of the functions fi for i ∈ [n].
Lemma E.4. Let Assumption 2.2 be satisﬁed, inequalities (7)-(10) hold and18

 p γ ≤ min ,  8µ

p ,
2F (1 − p)

pρ(1 − ρ) ,
32BG(1 − p)



p



.

128L(1 − p) A + ρ2(1B−Cρ) 

Moreover, assume that f1, f2, . . . , fn are ζ-heterogeneous and µ-strongly convex, and E gik | xki = ∇fi(xki ) for all i ∈ [n]. Then (11) holds with

16B(1 − p)(2 + ρ)γ2

4(1 − p)

ζ2 4BD2

H=

, D3 =

D1 + +

.

(54)

pρ

p

γµ ρ

Proof. First of all, we introduce new notation: E[· | xk, gk] d=ef E[· | xk1, . . . , xkn, g1k, . . . , gnk]. By deﬁnition of Vk for all k ≥ 1 we have

E[Vk | xk−1, gk−1]

(4),(20)
= = = =

1−p n n i=1

xki −1 − xk−1 − γgik−1 + γgk−1 2

1−p n n i=1

k−1 k−1 2 2γ(1 − p) n

xi − x

+ n

i=1

xki −1 − xk−1, gk−1 − gik−1

γ2(1 − p) n +
n i=1

gik−1 − gk−1 2

(1 − p)Vk−1 + 2γ(1 − p)

1 n k−1

k−1 k−1

n xi − x , g

i=1

2γ(1 − p) n +
n i=1

xk−1 − xki −1, gik−1

γ2(1 − p) n +
n i=1

gik−1 − gk−1 2

2γ(1 − p) n k−1 k−1 k−1

(1 − p)Vk−1 + n

x − xi , gi

i=1

γ2(1 − p) n +
n i=1

gik−1 − gk−1 2.

Next, we take the conditional expectation E · | xk−1 d=ef E · | xk1−1, . . . , xkn−1 on both sides of the obtained inequality and get

E Vk | xk−1

=
(139)
≤

2γ(1 − p) n k−1 k−1

k−1

(1 − p)Vk−1 + n

x − xi , ∇fi(xi )

i=1

γ2(1 − p) n

+

E

n i=1

gik−1 − gk−1 2 | xk−1

2γ(1 − p) n k−1 k−1

k−1

k−1

(1 − p)Vk−1 + n

x − xi , ∇fi(xi ) − ∇fi(x )

i=1

2γ(1 − p) n k−1 k−1

k−1

+ n

x − xi , ∇fi(x )

i=1

γ2(1 − p) n

+

E

n i=1

gik−1 2 | xk−1 .

18When ρ = 1 one can always set the parameters in such a way that B = C = G = 0, D2 = 0. In this case we assume that ρ2(1B−Cρ) = ρ2(1B−Gρ) = 0.

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

Since n1

n i=1

xk−1 − xki −1, ∇f (xk−1)

= 0, we can continue as follows:

E Vk | xk−1

(40)
≤
(132)
≤
(15)
≤

2γµ(1 − p) n k−1 k−1 2

(1 − p)Vk−1 − n

x − xi

i=1

2γ(1 − p) n k−1 k−1

k−1

k−1

+ n

x − xi , ∇fi(x ) − ∇f (x )

i=1

γ2(1 − p) n

+

E

n i=1

gik−1 2 | xk−1

γ2(1 − p) n (1 − p)(1 − 2γµ)Vk−1 + n E
i=1

gik−1 2 | xk−1

2γ(1 − p) n +
n i=1

µ2 xk−1 − xki −1 2 + 21µ ∇fi(xk−1) − ∇f (xk−1) 2

γ2(1 − p) n (1 − p)(1 − γµ)Vk−1 + n E
i=1

k−1 2 k−1 (1 − p)γζ2

gi

|x +

. µ

Taking full mathematical expectation on both sides of previous inequality and using 1 − γµ ≤ 1 we obtain

(140)

γ2(1 − p) n

k−1 2 (1 − p)γζ2

EVk ≤ (1 − p)E [Vk−1] + n

E gi

+ µ

i=1

(8)
≤ (1 − p)E[Vk−1] + (1 − p)γ2 2AE[f (xk−1) − f (x∗)] + BE[σk2] + F E[Vk−1] + D1

(1 − p)γζ2

+

.

µ

Since γ ≤ 2F (1p−p) we have (1 − p)γ2F ≤ p2 and

EVk ≤

p

2

k−1

∗

2

ζ2

1 − 2 E[Vk−1] + (1 − p)γ 2AE[f (x ) − f (x )] + BE[σk] + D1 + γµ .

Unrolling the recurrence we obtain

k−1

p k−1−l

ζ2

E [Vk] ≤ (1 − p)γ2

1−

2AE f (xl) − f (x∗) + BE σl2 + D1 +

.

2

γµ

l=0

As a consequence, we derive

K

2A(1 − p)γ2 K k

p k−l

wkE [Vk] ≤

1− p

1− 2

wk rl

k=0

2

k=0 l=0

B(1 − p)γ2 K k + 1− p
2 k=0 l=0

p 1−
2

k−l
wkE σl2

ζ2 + D1 +

K k−1

p k−1−l

(1 − p)γ2

1−

wk ,

γµ

2

k=0 l=0

(55)

where we use new notation: rl = E f (xl) − f (x∗) . Recall that wk = (1 − η)−(k+1) and η = min γµ, ρ4 .

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

Together with our assumption on γ it implies that for all 0 ≤ i < k we have

(137)
wk = (1 − η)−(k−i+1) (1 − η)−i ≤ wk−i (1 + 2η)i

i

pi

≤ wk−i (1 + 2γµ) ≤ wk−i 1 + ,

4

−(k−i+1)

−i (137)

i

ρi

wk = (1 − η)

(1 − η) ≤ wk−i (1 + 2η) ≤ wk−i 1 + ,

2

(137)

k+1

ρ k+1

wk ≤ (1 + 2η) ≤ 1 +

.

2

Having these inequalities in hand we obtain

Kk k=0 l=0

p 1−
2

k−l
wk rl

(56)
≤
(138)
≤
=

Kk k=0 l=0

p 1−
2

Kk k=0 l=0

p 1−
4

4K p wkrk,
k=0

k−l

p

1+

4

k−l
wlrl ≤

k−l
wlrl
K
wk rk
k=0

∞

pk

1−

k=0 4

(56) (57) (58)

Kk k=0 l=0

p 1−
2

k−l
wkE σl2

(56)
≤
(138)
≤
=

K k 1 − p k−l 1 + p k−l wlE σl2

2

4

k=0 l=0

K k 1 − p k−l wlE σl2 ≤ 4
k=0 l=0

K
wkE σk2
k=0

4K wkE σk2 ,
p
k=0

∞

pk

1−

k=0 4

and

K k−1

p k−1−l

1− 2

wk ≤

k=0 l=0

K
wk
k=0

∞

pk

1−

k=0 2

= 2WK . p

Plugging these inequalities together with 1 − p2 ≥ 12 in (55) we derive

K

16A(1 − p)γ2 K

8B(1 − p)γ2 K

wkE [Vk] ≤

wkrk +

wkE σk2

p

p

k=0

k=0

k=0

2 D1 + γζµ2 (1 − p)γ2 + p WK .

(59)

It remains to estimate the second term in the right-hand side of this inequality. We notice that an analogous term appear in the proof of Lemma E.1. In particular, in that proof inequality (35) was shown via inequalities (10), (48), (49) and (138) which hold in this case too. Therefore, we get that

K
wkE σk2
k=0

(3≤5) Eσ02(2 + ρ) + 4C

K

2G

wkrk +

K

D2WK

wkEVk +

,

ρ

ρ(1 − ρ)

ρ(1 − ρ)

ρ

k=0

k=0

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

hence

K

(50) 16(1 − p)γ2 A + ρ2(1B−Cρ) K

wkE [Vk] ≤ p

wk rk

k=0

k=0

+ 8B(1 − p)(2 + ρ)γ2Eσ02 + 16BG(1 − p)γ2 K wkE [Vk]

pρ

pρ(1 − ρ)

k=0

2(1 − p)γ2

ζ2 4BD2

+

D1 + +

WK .

p

γµ ρ

Our assumption on γ imply

16(1 − p)γ2 A + ρ2(1B−Cρ) p

1 ≤,
8L

16BG(1 − p)γ2 1

≤.

pρ(1 − ρ)

2

Next, we introduce new notation as follows:

16B(1 − p)(2 + ρ)γ2

4(1 − p)

ζ2 4BD2

H=

, D3 =

D1 + +

.

pρ

p

γµ ρ

Putting all together we get

which concludes the proof.

1K

1K

H 2 D3 2

2 wkE [Vk] ≤ 8L wkrk + 2 Eσ0 + 2 γ WK

k=0

k=0

This lemma and Theorem 2.1 imply the following result.
Corollary E.4. Let the assumptions of Lemma E.4 are satisﬁed. Then Assumption 2.3 holds and, in particular, if

1

L

p

4B

γ ≤ min

,

, , M= ,

2(A + CM ) F + GM 8µ

3ρ





 γ ≤ min


p ,
2F (1 − p)

pρ(1 − ρ) ,
32BG(1 − p)

p



,

128L(1 − p) A + ρ2(1B−Cρ) 

then for all K ≥ 0 we have

K

∗

2T 0 + 4LHγEσ02

E f (x ) − f (x ) ≤

γWK

+ 2γ (D1 + M D2 + 2LγD3) ,

(60)

where xK d=ef W1K

K k=0

wk

xk

and

16B(1 − p)(2 + ρ)γ2

4(1 − p)

ζ2 4BD2

H=

, D3 =

D1 + +

.

pρ

p

γµ ρ

Moreover, if µ > 0, then

E f (xK ) − f (x∗) ≤ 1 − min γµ, ρ K 2T 0 + 4LHγEσ02

4

γ

+2γ (D1 + M D2 + 2LγD3) ,

(61)

and in the case when µ = 0 we have

K

∗

2T 0 + 4LHγEσ02

E f (x ) − f (x ) ≤

γK

+ 2γ (D1 + M D2 + 2LγD3) .

(62)

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

F Missing Parts from Section 4

Let us start with an useful Lemma that bounds the Bregman distance between the local iterate xki and the optimum x∗ by the Bregman distance between the virtual iterate xk and the optimum. Lemma F.1. Assume fi is L-smooth for all i ∈ [n]. Then

Dfi (xki , x∗) ≤ 2Dfi (xk, x∗) + L xki − xk 2 ∀i ∈ [n].

(63)

Proof. Using corollaries of L-smoothness and Young’s inequality, we derive

Dfi

(x

k i

,

x∗

)

(18)
≤
(132)
≤
(6)
≤

Dfi (xk, x∗) + ∇fi(xk) − ∇fi(x∗), xki − xk + L2 xki − xk 2 Dfi (xk, x∗) + 21L ∇fi(xk) − ∇fi(x∗) 2 + L xki − xk 2
2Dfi (xk, x∗) + L xki − xk 2.

F.1 Proof of Lemma 4.1

n
Let us bound n1 Ek
i=1

gik 2 ﬁrst:

1n n Ek
i=1

gik 2

1n

=

Ek aki − bki 2

n

i=1

1n

=

Ek aki − ∇fi(x∗) − (bki − ∇fi(x∗)) 2

n

i=1

2n

≤

Ek aki − ∇fi(x∗) 2 + bki − ∇fi(x∗) 2

n

i=1

2n

≤

2AiDfi (xki , x∗) + Biσi2,k + D1,i + Ek bki − ∇fi(x∗) 2

n

i=1

(63) 2 n

≤

4AiDfi (xk, x∗) + 2AiL xki − xk 2 + Biσi2,k + D1,i + Ek bki − ∇fi(x∗) 2

n

i=1

2n

≤ 8 max{Ai}(f (xk) − f (x∗)) + 4 max{Ai}LVk +

Biσi2,k + D1,i + Ek bki − ∇fi(x∗) 2 .

i

i

n

i=1

Taking the full expectation, we arrive at

1n E
n i=1

2n

gik 2 ≤ 8 max{Ai}E(f (xk) − f (x∗)) + 4 max{Ai}LEVk +

BiEσi2,k + D1,i + E bki − ∇fi(x∗) 2 .

i

i

n

i=1

(64)

Next, we have

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik



n

2


n

2

1 Ek  n

gik  = Ek  n1

aki − bki 

i=1

i=1


n

2

1 = Ek  n

aki − ∇fi(x∗) 

i=1

n

n

2

1 = Var
n

aki − ∇fi(x∗) + n1

∇fi(xki ) − ∇fi(x∗)

i=1

i=1

1n

1n

2

≤ Var

aki − ∇fi(x∗) +

∇fi(xki ) − ∇fi(x∗)

n

n

i=1

i=1

1n

2L n

≤ Var

aki − ∇fi(x∗) +

Dfi

(x

k i

,

x∗

)

n

n

i=1

i=1

1n

2L n

= n2 Var aki − ∇fi(x∗) + n

D

fi

(

x

k i

,

x∗

)

i=1

i=1

1n

2 2L n

≤ n2

Ek aki − ∇fi(x∗)

+ n

Dfi

(

x

k i

,

x∗

)

i=1

i=1

1n

2L n

≤ n2

2AiDfi (xki , x∗) + Biσi2,k + D1,i + n

Dfi

(

x

k i

,

x∗

)

i=1

i=1

1n

≤ n2

2 max{Ai} + nL Dfi (xki , x∗) + Biσi2,k + D1,i
i

i=1

(63) 4 maxi{Ai}

k∗

1n

2k

∗2

2

≤

n

+ 2L Df (x , x ) + n2

2(max{Ai}L + nL ) xi − x + Biσi,k + D1,i
i

i=1

4 maxi{Ai}

k

∗

maxi{Ai}L 2

1n 2

=

+ 2L f (x ) − f (x ) + 2 n

n

+ L Vk + n2

Biσi,k + D1,i .

i=1

Further, we deﬁne and consequently, we get

2 def 2 n

2

ωk = n Biσi,k

i=1

E ωk2+1

2n

=

BiE σi2,k+1

n

i=1

2n

2n

≤ (1 − ρ)ωk2 +

BiCiDfi (xki , x∗) +

BiD2,i

n

n

i=1

i=1

(63)

4n

2n

2n

≤ (1 − ρ)ωk2 +

BiCiDfi (xk, x∗) +

BiCiL xki − xk 2 +

BiD2,i

n

n

n

i=1

i=1

i=1

2n

≤ (1 − ρ)ωk2 + 4 max{BiCi}Df (xk, x∗) + 2 max{BiCi}LVk +

BiD2,i.

i

i

n

i=1

(65)

We will provide a bound on E bki − ∇fi(x∗) 2 based on the choices of bki : Case I. The choice bki = 0 yields E bki − ∇fi(x∗) 2 = ∇fi(x∗) 2.

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

Case II. The choice bki = ∇fi(x∗) yields E bki − ∇fi(x∗) 2 = 0. Overall, for both Case I and II we have

2n

Eσk2+1 ≤ (1 − ρ)Eσk2 + 4 max{BiCi}Df (xk, x∗) + 2 max{BiCi}LVk +

BiD2,i

i

i

n

i=1

as desired, where σk = ωk.

Case

III.

The

choice

bki

= hki −

1 n

n i=1

hki

yields

1n n i=1

1n bki − ∇fi(x∗) 2 =
n
i=1

n

2

n

hki − n1 hki − ∇fi(x∗) ≤ n1

i=1

i=1

hki − ∇fi(x∗) 2

where

Ek hki +1 − ∇fi(x∗) 2

= (1 − ρi) hki − ∇fi(x∗) 2 + ρiEk lik − ∇fi(x∗) 2
(16)
≤ (1 − ρi) hki − ∇fi(x∗) 2 + 2ρiAiDfi (xki , x∗) + ρiD3,i.

Next, set σk2 d=ef ωk2 + hki − ∇fi(x∗) 2 for this case. Consequently, we have

Ekσk2+1 ≤ (1 − ρ)σk2 + 4(max{BiCi} + max{ρiAi})Df (xk, x∗) + 2(max{BiCi} + max{ρiAi})LVk

i

i

i

i

1n

+ n

(2BiD2,i + ρiD3,i) ,

i=1

where ρ = mini min{ρi, ρi}.

It remains to plug everything back to (8), (9) and (10).

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

G Special Cases: Technical details

G.1 Local-SGD
We start with the analysis of Local-SGD (see Algorithm 1) under diﬀerent assumptions of stochastic gradients and data similarity.

Algorithm 1 Local-SGD

Require: learning rate γ > 0, initial vector x0 ∈ Rd, communication period τ ≥ 1

1: for k = 0, 1, . . . do

2: for i = 1, . . . , n in parallel do

3:

Sample

gik

=

∇

fξ

k

(x

k i

)

independently

from

other

nodes

i

4:

if k + 1 mod τ = 0 then

n

5:

xki +1

=

xk+1

=

1 n

xki − γgik

i=1

6:

else

7:

xki +1 = xki − γgik

8:

end if

9: end for

10: end for

averaging local update

G.1.1 Uniformly Bounded Variance

In this section we assume that fi has a form of expectation (see (2)) and stochastic gradients ∇fξi (x) satisfy

Eξi ∇fξi (x) − ∇fi(x) 2 ≤ D1,i, ∀ x ∈ Rd, ∀ i ∈ [n]. (66)

We also introduce the average variance σ2 and the parameter of heterogeneity at the solution ζ∗2 in the following

way:

1n

σ2 =

D1,i,

n

i=1

1n ζ∗2 =
n
i=1

∇fi(x∗) 2.

Lemma G.1. Assume that functions fi are convex and L-smooth for all i ∈ [n]. Then

1n

∇fi(xki ) 2 ≤ 6L f (xk) − f (x∗) + 3L2Vk + 3ζ∗2

(67)

n

i=1

and

n

2

n1 ∇fi(xki ) ≤ 4L f (xk) − f (x∗) + 2L2Vk. (68)

i=1

Proof. First, to show (67) we shall have

1n n i=1

∇fi(xki ) 2

(136)
≤
(6),(19)
≤ =

3n

3n

∇fi(xki ) − ∇fi(xk) 2 +

∇fi(xk) − ∇fi(x∗) 2

n

n

i=1

i=1

3n +
n i=1

∇fi(x∗) 2

3L2 n n i=1

6L n

xki − xk 2 +

Dfi (xk, x∗) + 3ζ∗2

n

i=1

6L f (xk) − f (x∗) + 3L2Vk + 3ζ∗2.

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

Next, to establish (68), we have

n

2

n1 ∇fi(xki )

i=1

=
(136)
≤
(6),(19)
≤
=

n

2

n1 ∇fi(xki ) − ∇fi(x∗)

i=1

2n

2n

∇fi(xki ) − ∇f (xk) 2 +

∇fi(xk) − ∇f (x∗) 2

n

n

i=1

i=1

2L2 n n i=1

4L n

xki − xk 2 +

Dfi (xk, x∗)

n

i=1

4L f (xk) − f (x∗) + 2L2Vk.

Lemma G.2. Let fi be convex and L-smooth for all i ∈ [n]. Then for all k ≥ 0

1n

E gik 2 | xk ≤ 6L f (xk) − f (x∗) + 3L2Vk + σ2 + 3ζ∗2,

(69)

n

i=1

1n E
n i=1

gik − g¯ik 2 | xk

≤ σ2,

(70)

 1n

2

σ2

E

gik | xk ≤ 4L f (xk) − f (x∗) + 2L2Vk + ,

(71)

n

n

i=1

where

E[·

|

xk ]

d=ef

E[·

|

x

k 1

,

.

.

.

,

x

k n

].

Proof. First of all, we notice that g¯ik = E gik | xk = ∇fi(xki ). Using this we get

1n E
n i=1

gik − g¯ik

1n E gik
n
i=1

2 | xki 2 | xki

=
(139)
=
(66),(67)
≤

1n

(66) 1 n

Eξk ∇fξk (xki ) − ∇fi(xki ) 2 ≤

D1,i,

n

i

i

n

i=1

i=1

1n

n

Eξk i

i=1

1n ∇fξk (xki ) − ∇fi(xki ) 2 +

i

n

i=1

∇fi(xki ) 2

1n

6L f (xk) − f (x∗) + 3L2Vk +

D1,i + 3 ∇fi(x∗) 2 .

n

i=1

Finally,

using

independence

of

g1k

,

g2k

,

.

.

.

,

g

k n

we

obtain



n

2

1 E
n

gik | xk

i=1

(139)
≤
=
(66),(68)
≤



1n

E

gik − ∇fi(xki )

n

i=1

2 | xk +

n

2

n1 ∇fi(xki )

i=1

1n n2 E
i=1

gik − ∇fi(xki ) 2 | xki +

n

2

n1 ∇fi(xki )

i=1

1n

4L f (xk) − f (x∗) + 2L2Vk +

D1,i.

n2

i=1

Heterogeneous Data Applying Corollary E.1 and Lemmas G.1 and G.2 we get the following result.

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

Theorem G.1. Assume that fi(x) is µ-strongly convex and L-smooth for every i ∈ [n]. Then Local-SGD satisﬁes Assumption E.1 with

A = 3L, A = 0, B = B = 0, F = 3L2, F = 0, D1 = 3ζ∗2, D = σ2,

A = 2L,

B = 0,

F = 2L2,

σ2

D1 =

, n

σk2 ≡ 0,

ρ = 1,

C = 0,

G = 0,

D2 = 0,

H = 0, D3 = 2e(τ − 1) 3(τ − 1)ζ∗2 + σ2

with γ satisfying

γ ≤ min 1 , √ 1 . 4L 4 6e(τ − 1)L

and for all K ≥ 0

E f (xK ) − f (x∗)

2 x0 − x∗ 2

2

2

2

≤

γWK + 2γ σ /n + 4eL(τ − 1)γ σ + 3(τ − 1)ζ∗ .

In particular, if µ > 0 then

K

∗

K 2 x0 − x∗ 2

2

2

2

E f (x ) − f (x ) ≤ (1 − γµ)

γ

+ 2γ σ /n + 4eL(τ − 1)γ σ + 3(τ − 1)ζ∗

(72)

and when µ = 0 we have

K

∗

2 x0 − x∗ 2

2

2

2

E f (x ) − f (x ) ≤

γK + 2γ σ /n + 4eL(τ − 1)γ σ + 3(τ − 1)ζ∗ .

(73)

The theorem above together with Lemma I.2 implies the following result. Corollary G.1. Let assumptions of Theorem G.1 hold with µ > 0. Then for

γ = min

1, √ 1

ln max 2, min ,

4L 4 6e(τ − 1)L

x0−x∗ 2nµ2K2/σ2, x0−x∗ 2µ3K3/4eL(τ −1)(σ2+3(τ −1)ζ∗2) µK

for all K such that

either or

ln max 2, min x0−x∗ 2nµ2K2/σ2, x0−x∗ 2µ3K3/4eL(τ −1)(σ2+3(τ −1)ζ∗2)

K

1

1

ln max 2, min x0−x∗ 2nµ2K2/σ2, x0−x∗

min , √

≤

4L 4 6e(τ − 1)L

µK

≤1 2µ3K3/4eL(τ −1)(σ2+3(τ −1)ζ∗2)

we have that

E f (xK ) − f (x∗) = O τ L x0 − x∗ 2 exp − µ K + σ2 + L(τ − 1) σ2 + (τ − 1)ζ∗2 . (74)

τL

nµK

µ2 K 2

That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case Local-SGD requires

τL σ2

O

++

µ nµε

L(τ − 1) (σ2 + (τ − 1)ζ∗2) µ2ε

iterations/oracle calls per node and τ times less communication rounds.
Now we consider some special cases. First of all, if D1,i = 0 for all i ∈ [n], i.e. gik = ∇fi(xki ) almost surely, then our result implies that for Local-SGD it is enough to perform

τL

O

+

µ

L(τ − 1)2ζ∗2 µ2ε

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

iterations in order to achieve E f (xK) − f (x∗) ≤ ε. It is clear that for this scenario the optimal choice for τ is τ = 1 which recovers19 the rate of Gradient Descent.

Secondly, if τ = 1 then we recover the rate of parallel SGD:

L σ2 O+
µ nµε

communication rounds/oracle calls per node

in order to achieve E f (xK ) − f (x∗) ≤ ε.

Finally, our result gives a negative answer to the following question: is Local-SGD always worse then Parallel Minibatch SGD (PMSGD) for heterogeneous data? To achieve E f (xK) − f (x∗) ≤ ε Local-SGD requires

τL σ2

O

++

µ nµε

L(τ − 1) (σ2 + (τ − 1)ζ∗2) µ2ε

oracle calls per node.

It means that if √

σ2

≥ 1 for given τ > 1 and ε and σ2 are such that the ﬁrst term in the

n L(τ −1)(σ2+(τ −1)ζ∗2)ε

complexity bound is dominated by other terms, then the second term corresponding to the complexity of PMSGD

dominates the third term. Informally speaking, if the variance is large or ε is small then Local-SGD with τ > 1

has the same complexity bounds as PMSGD.

Combining Theorem G.1 and Lemma I.3 we derive the following result for the convergence of Local-SGD in the case when µ = 0.
Corollary G.2. Let assumptions of Theorem G.1 hold with µ = 0. Then for

γ = min 1 , √ 1

, nR02 , 3

R02

,

4L 4 6e(τ − 1)L σ2K 4eL(τ − 1) (σ2 + (τ − 1)ζ∗2) K

where R0 = x0 − x∗ , we have that

E f (xK ) − f (x∗) = O τ LR02 + R02σ2 + 3 LR04(τ − 1) (σ2 + (τ − 1)ζ∗2) .

(75)

K

nK

K 2/3

That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case Local-SGD requires

O τ LR02 + R02σ2 + R02 L(τ − 1) (σ2 + (τ − 1)ζ∗2)

ε

nε2

ε3/2

iterations/oracle calls per node and τ times less communication rounds.

Homogeneous Data

In this case we modify the approach a little bit and apply the following result. Lemma G.3 (Lemma 1 from [20]). Under the homogeneous data assumption for Local-SGD we have

E [Vk] ≤ (τ − 1)γ2σ2

(76)

for all k ≥ 0.

Using this we derive the following inequality for the weighted sum of Vk:

K

K

2L wkE[Vk] ≤ 2L(τ − 1)γ2σ2 wk = 2L(τ − 1)γ2σ2WK .

k=0

k=0

Together with Lemmas G.1 and G.2 and Theorem 2.1 it gives the following result.

19We notice that for this particular case our analysis doesn’t give extra logarithmical factors if we apply (72) instead of (74).

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

Theorem G.2. Assume that f (x) is µ-strongly convex and L-smooth and f1 = . . . = fn = f . Then Local-SGD satisﬁes Assumption 2.3 with

A = 3L, B = 0, F = 3L2, D1 = σ2, A = 2L, σk2 ≡ 0, ρ = 1, C = 0, G = 0, D2 = 0,

B = 0, H = 0,

F = 2L2,

σ2

D1 =

, n

D3 = (τ − 1)σ2

with γ satisfying

and for all K ≥ 0

1 γ≤ .
4L

E f (xK ) − f (x∗)

2 x0 − x∗ 2

2

2

≤

+ 2γ σ /n + 2L(τ − 1)γσ .

γWK

In particular, if µ > 0 then

K

∗

K 2 x0 − x∗ 2

2

2

E f (x ) − f (x ) ≤ (1 − γµ)

+ 2γ σ /n + 2L(τ − 1)γσ

(77)

γ

and when µ = 0 we have

K

∗

2 x0 − x∗ 2

2

2

E f (x ) − f (x ) ≤

+ 2γ σ /n + 2L(τ − 1)γσ .

(78)

γK

The theorem above together with Lemma I.2 implies the following result. Corollary G.3. Let assumptions of Theorem G.2 hold with µ > 0. Then for

γ = min

1 ln max 2, min ,
4L

x0 −x∗

2 nµ2 K 2/σ 2 , µK

x0 −x∗

/ 2µ3K3 2L(τ −1)σ2

for all K such that

either or

ln max 1 ln
≤ 4L

2, min x0−x∗ max 2, min

2nµ2K2/σ2, x0−x∗
K x0−x∗ 2nµ2K2/σ2,
µK

/ 2µ3K3 2L(τ −1)σ2

≤1

x0−x∗ / 2µ3K3 2L(τ −1)σ2

we have that

E f (xK ) − f (x∗) = O L x0 − x∗ 2 exp − µ K + σ2 + L(τ − 1)σ2 .

L

nµK

µ2 K 2

That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case Local-SGD requires

(79)

L L x0 − x∗ 2

σ2

O ln

++

µ

ε

nµε

L(τ − 1)σ2 µ2ε

iterations/oracle calls per node and τ times less communication rounds.
It means that if nσ2L2 ε ≥ 1, τ ≤ 1 + nσ2L2 ε and ε and σ2 are such that the ﬁrst term in the complexity bound is dominated by other terms, then the second term corresponding to the complexity of PMSGD dominates the third term. Informally speaking, if the variance is large or ε is small then Local-SGD with τ > 1 has the same complexity bounds as PMSGD.
Combining Theorem G.2 and Lemma I.3 we derive the following result for the convergence of Local-SGD in the case when µ = 0.

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

Corollary G.4. Let assumptions of Theorem G.2 hold with µ = 0. Then for

γ = min

1 ,

nR02 , 3

R02

,

4L σ2K 2L(τ − 1)σ2K

where R0 = x0 − x∗ , we have that

E f (xK ) − f (x∗) = O LR02 + R02σ2 + 3 LR04(τ − 1)σ2 .

(80)

K

nK

K 2/3

That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case Local-SGD requires

O LR02 + R02σ2 + R02 L(τ − 1)σ2

ε

nε2

ε3/2

iterations/oracle calls per node and τ times less communication rounds.

ζ-Heterogeneous Data

In this setup we also use an external result to bound E[Vk]. Lemma G.4 (Lemma 8 from [50]). If f1, f2, . . . , fn are ζ-heterogeneous then for Local-SGD we have

E [Vk] ≤ 3τ γ2σ2 + 6τ 2γ2ζ2

(81)

for all k ≥ 0.

Using this we derive the following inequality for the weighted sum of Vk:

K

K

2L wkE[Vk] ≤ 6τ Lγ2 σ2 + 2τ ζ2 wk = 6τ Lγ2 σ2 + 2τ ζ2 WK .

k=0

k=0

Together with Lemmas G.1 and G.2 and Theorem 2.1 it gives the following result.
Theorem G.3. Assume that f1, . . . , fn are ζ-heterogeneous, µ-strongly convex and L-smooth functions. Then Local-SGD satisﬁes Assumption 2.3 with

A = 3L,

B = 0,

F = 3L2,

D1 = σ2 + 3ζ∗2,

A = 2L,

B = 0,

F = 2L2,

σ2

D1 =

, n

σk2 ≡ 0, ρ = 1, C = 0, G = 0, D2 = 0, H = 0, D3 = 3τ σ2 + 2τ ζ2

with γ satisfying

and for all K ≥ 0

1 γ≤ .
4L

E f (xK ) − f (x∗)

2 x0 − x∗ 2

2

2

2

≤

+ 2γ σ /n + 6Lτ γ σ + 2τ ζ .

γWK

In particular, if µ > 0 then

K

∗

K 2 x0 − x∗ 2

2

2

2

E f (x ) − f (x ) ≤ (1 − γµ)

+ 2γ σ /n + 6Lτ γ σ + 2τ ζ

(82)

γ

and when µ = 0 we have

K

∗

2 x0 − x∗ 2

2

2

2

E f (x ) − f (x ) ≤

+ 2γ σ /n + 6Lτ γ σ + 2τ ζ .

(83)

γK

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

The theorem above together with Lemma I.2 implies the following result. Corollary G.5. Let assumptions of Theorem G.3 hold with µ > 0. Then for

γ = min

1 ln max 2, min ,
4L

x0 −x∗

2 nµ2 K 2/σ 2 , µK

x0 −x∗

/ 2µ3K3 6Lτ (σ2+2τ ζ2)

for all K such that

either or

ln max 1 ln
≤ 4L

2, min x0−x∗ max 2, min

2nµ2K2/σ2, x0−x∗
K x0−x∗ 2nµ2K2/σ2,
µK

/ 2µ3K3 6Lτ (σ2+2τ ζ2)

≤1

x0−x∗ / 2µ3K3 6Lτ (σ2+2τ ζ2)

we have that

E f (xK ) − f (x∗) = O L x0 − x∗ 2 exp − µ K + σ2 + Lτ (σ2 + τ ζ2) .

L

nµK

µ2 K 2

That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case Local-SGD requires

(84)

L L x0 − x∗ 2

σ2

O ln

++

µ

ε

nµε

Lτ (σ2 + τ ζ2) µ2ε

iterations/oracle calls per node and τ times less communication rounds.
Combining Theorem G.3 and Lemma I.3 we derive the following result for the convergence of Local-SGD in the case when µ = 0. Corollary G.6. Let assumptions of Theorem G.3 hold with µ = 0. Then for

γ = min

1 ,

nR02 , 3

R02

,

4L σ2K 6Lτ (σ2 + 2τ ζ2)K

where R0 = x0 − x∗ , we have that

E f (xK ) − f (x∗) = O LR02 + R02σ2 + 3 LR04τ (σ2 + τ ζ2) .

(85)

K

nK

K 2/3

That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case Local-SGD requires

O LR02 + R02σ2 + R02 Lτ (σ2 + τ ζ2)

ε

nε2

ε3/2

iterations/oracle calls per node and τ times less communication rounds.

G.1.2 Expected Smoothness and Arbitrary Sampling

In this section we continue our consideration of Local-SGD but now we make another assumption on stochastic gradients ∇fξi (x).
Assumption G.1 (Expected Smoothness). We assume that for all i ∈ [n] stochastic gradients ∇fξi (x) are unbiased estimators of ∇fi(x) and there exists such constant L > 0 that ∀x, y ∈ Rd

Eξi∼Di ∇fξi (x) − ∇fξi (x∗) 2 ≤ 2LDfi (x, x∗)

(86)

where Dfi (x, y) d=ef fi(x) − fi(y) − ∇fi(y), x − y .

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

In particular, let us consider the following special case. Assume that fi(x) has a form of ﬁnite sum (see (3)) and consider the following stochastic reformulation:

fi(x) = Eξi [fξi (x)] ,

1m fξi (x) = m ξi,j fi,j (x),
j=1

(87)

where E[ξi,j] = 1 and E[ξi2,j] < ∞. In this case, Eξi [∇fξi ] = ∇fi(x). If each fi,j(x) is Li,j-smooth then there exists such L ≤ maxj∈[m] Li,j that Assumption G.1 holds. Clearly, L depends on the sampling strategy and in some cases one can make L much smaller than maxj∈[m] Li,j via good choice of this strategy. Our analysis works for an arbitrary sampling strategy that satisﬁes Assumption G.1.
Lemma G.5. Let fi be convex and L-smooth for all i ∈ [n]. Then for all k ≥ 0

1n

E gik 2 | xk ≤ 8L f (xk) − f (x∗) + 4LLVk + 2σ∗2 + 2ζ∗2,

(88)

n

i=1

1n

E gik − g¯ik 2 | xk ≤ 8L f (xk) − f (x∗) + 4LLVk + 2σ∗2,

(89)

n

i=1

 1n

2

2σ2

E  n gik | xk ≤ 4 (2L/n + L) (f (xk) − f (x∗)) + 2L (2L/n + L) Vk + n∗ , (90)

i=1

where

σ∗2

=

1 n

ni=1 E

∇fξi (x∗) − ∇fi(x∗)

2,

ζ∗2 =

1 n

n i=1

∇fi(x∗) 2 and E[· | xk] d=ef E[· | xk1 , . . . , xkn].

Proof. First of all, we notice that g¯ik = E gik | xk = ∇fi(xki ). Using this we get

1n E
n i=1

gik 2 | xk

(136)
≤
(86),(139)
≤
(63)
≤

2n

2n

Eξk ∇fξk (xki ) − ∇fξk (x∗) 2 +

Eξk ∇fξk (x∗) 2

n

i

i

i

n

i

i

i=1

i=1

4L n

2n

Dfi (xki , x∗) +

Eξi

n

n

i=1

i=1

2n ∇fξ (x∗) − ∇fi(x∗) 2 +

i

n

i=1

∇fi(x∗) 2

8L f (xk) − f (x∗) + 4LLVk + 2σ∗2 + 2ζ∗2

and 1n E n i=1

gik − g¯ik 2 | xk

=
(139)
≤
(136)
≤
(86)
≤
(63)
≤

1n Eξk ∇fξk (xki ) − ∇fi(xki ) 2

n

i

i

i=1

1n Eξk ∇fξk (xki ) − ∇fi(x∗) 2

n

i

i

i=1

2n

2n

Eξk ∇fξk (xki ) − ∇fξk (x∗) 2 +

Eξk ∇fξk (x∗) − ∇fi(x∗) 2

n

i

i

i

n

i

i

i=1

i=1

4L n Dfi (xki , x∗) + 2σ∗2
n
i=1

8L f (xk) − f (x∗) + 4LLVk + 2σ∗2.

(91)

Finally,

using

independence

of

ξ

k 1

,

ξ2k

,

.

.

.

,

ξ

k n

we

obtain



n

2

1 E
n

gik | xk

i=1

(139)
=

 Eξk 
i

1n (∇fξk (xki ) − ∇fi(xki ))

n

i

i=1

2 +

n

2

n1 ∇fi(xki )

i=1

=
(91),(68)
≤

1n

n2

Eξk i

i=1

n

2

∇fξik (xki ) − ∇fi(xki ) 2 + n1 ∇fi(xki )

i=1

4 (2L/n + L) (f (xk) − f (x∗)) + 2L (2L/n + L) Vk + 2σ∗2 . n

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

Heterogeneous Data

Applying Corollary E.1 and Lemmas G.1 and G.5 we get the following result.

Theorem G.4. Assume that fi(x) is µ-strongly convex and L-smooth for i ∈ [n]. Let Assumption G.1 holds. Then Local-SGD satisﬁes Assumption E.1 with

A = 3L,

A = 4L, B = B = 0, F = 3L2, F = 4LL, D1 = 3ζ∗2,

4L A = + 2L,
n

B = 0,

F = 4LL + 2L2, n

2σ∗2

D1 =

, n

σk2 ≡ 0, ρ = 1, C = 0, G = 0, D2 = 0,

H = 0, D3 = 2e(τ − 1) 2σ∗2 + 3(τ − 1)ζ∗2

D1 = 2σ∗2

with γ satisfying

1

1

γ ≤ min

,

.

8L/n + 4L 4 2eL(τ − 1) (3L(τ − 1) + 4L)

and for all K ≥ 0

E f (xK ) − f (x∗)

2 x0 − x∗ 2

2

2

2

≤

γWK + 2γ 2σ∗/n + 4eL(τ − 1)γ 2σ∗ + 3(τ − 1)ζ∗ .

In particular, if µ > 0 then

K

∗

K 2 x0 − x∗ 2

2

2

2

E f (x ) − f (x ) ≤ (1 − γµ)

γ

+ 2γ 2σ∗/n + 4eL(τ − 1)γ 2σ∗ + 3(τ − 1)ζ∗

(92)

and when µ = 0 we have

K

∗

2 x0 − x∗ 2

2

2

2

E f (x ) − f (x ) ≤

γK + 2γ 2σ∗/n + 4eL(τ − 1)γ 2σ∗ + 3(τ − 1)ζ∗ .

(93)

The theorem above together with Lemma I.2 implies the following result. Corollary G.7. Let assumptions of Theorem G.4 hold with µ > 0. Then for

1

1

γ0 = min 8L/n + 4L , 4 2eL(τ − 1) (3L(τ − 1) + 4L) ,

ln max 2, min n x0−x∗ / , 2µ2K2 2σ∗2 x0−x∗ 2µ3K3/4eL(τ −1)γ(2σ∗2+3(τ −1)ζ∗2) γ = min γ0, µK

for all K such that

either or

ln max ln
γ0 ≤

2, min

n x0−x∗

/ , 2µ2K2 2σ∗2

x0 −x∗
K

2µ3K3/4eL(τ −1)γ(2σ∗2+3(τ −1)ζ∗2)

≤1

max 2, min n x0−x∗ / , 2µ2K2 2σ∗2 x0−x∗ 2µ3K3/4eL(τ −1)γ(2σ∗2+3(τ −1)ζ∗2)

µK

we have that E f (xK ) − f (x∗) is of the order

2

µ

σ∗2 L(τ − 1) σ∗2 + (τ − 1)ζ∗2

O

Lτ + L/n +

(τ − 1)LL R0 exp − Lτ + L/n +

K (τ − 1)LL

+

+

nµK

µ2 K 2

,

where R0 = x0 − x∗ . That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case Local-SGD requires

Lτ L

O

++

µ nµ

(τ − 1)LL + σ∗2 +

µ

nµε

L(τ − 1) (σ∗2 + (τ − 1)ζ∗2) µ2ε

iterations/oracle calls per node and τ times less communication rounds.

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

Combining Theorem G.4 and Lemma I.3 we derive the following result for the convergence of Local-SGD in the case when µ = 0.
Corollary G.8. Let assumptions of Theorem G.4 hold with µ = 0. Then for

1

1

γ0 = min 8L/n + 4L , 4 2eL(τ − 1) (3L(τ − 1) + 4L) ,

γ = min γ , nR02 , 3

R02

,

0 2σ∗2K 4eL(τ − 1) (2σ∗2 + 3(τ − 1)ζ∗2) K

where R0 = x0 − x∗ , we have that

 Lτ + L/n +

(τ − 1)LL R02

E f (xK ) − f (x∗) = O 

+

K

 Rn02Kσ∗2 + 3 LR04(τ − 1)K(σ2/∗23 + (τ − 1)ζ∗2)  . (94)

That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case Local-SGD requires

 O

Lτ + L/n +

(τ − 1)LL ε

R02 R2σ2 R2 + 0 ∗+ 0 nε2



L(τ − 1) (σ∗2 + (τ − 1)ζ∗2)

ε3/2



iterations/oracle calls per node and τ times less communication rounds.

ζ-Heterogeneous Data

Applying Corollary E.2 and Lemma G.5 we get the following result.
Theorem G.5. Assume that fi(x) is L-smooth for i ∈ [n] and f1, . . . , fn are ζ-heterogeneous and µ-strongly convex. Let Assumption G.1 holds. Then Local-SGD satisﬁes Assumption 2.3 with

A = 4L, B = 0, F = 4LL, D1 = 2σ∗2 + 2ζ∗2,

4L A = + 2L,
n

B = 0,

F = 4LL + 2L2, n

2σ∗2

D1 =

, n

σk2 ≡ 0, ρ = 1, C = 0, G = 0, D2 = 0,

H = 0,

2

2 ζ2

D3 = 2(τ − 1) 2σ∗ + 2ζ∗ + γµ

with γ satisfying

1

1

γ ≤ min

,

.

8L/n + 4L 8 2LL(τ − 1)

and for all K ≥ 0

K

∗

2 x0 − x∗ 2

2σ∗2 4Lζ2(τ − 1)

2

2

E f (x ) − f (x ) ≤

γWK

+ 2γ

+

n

µ

+ 8L(τ − 1)γ σ∗ + ζ∗ .

In particular, if µ > 0 then

K

∗

K 2 x0 − x∗ 2

2σ∗2 4Lζ2(τ − 1)

2

2

E f (x ) − f (x ) ≤ (1 − γµ)

γ

+ 2γ

+

n

µ

+ 8L(τ − 1)γ σ∗ + ζ∗ (95)

and when µ = 0 we have

K

∗

2 x0 − x∗ 2

2σ∗2 4Lζ2(τ − 1)

2

2

E f (x ) − f (x ) ≤

+ 2γ

+

γK

n

µ

+ 8L(τ − 1)γ σ∗ + ζ∗ .

(96)

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

The theorem above together with Lemma I.2 implies the following result. Corollary G.9. Let assumptions of Theorem G.5 hold with µ > 0. Then for

1

1

γ0 = min 8L/n + 4L , 8 2LL(τ − 1) ,

ln max 2, min x0−x∗ /( ), 2µ2K2 2σ∗2/n+4Lζ2(τ−1)/µ x0−x∗ 2µ3K3/8L(τ −1)(σ∗2+ζ∗2) γ = min γ0, µK

for all K such that

either or

ln max ln
γ0 ≤

2, min

x0 −x∗

/( ), 2µ2K2 2σ∗2/n+4Lζ2(τ−1)/µ K

x0 −x∗

2µ3K3/8L(τ −1)(σ∗2+ζ∗2)

≤1

max 2, min x0−x∗ /( ), 2µ2K2 2σ∗2/n+4Lζ2(τ−1)/µ x0−x∗ 2µ3K3/8L(τ −1)(σ∗2+ζ∗2)

µK

we have that E f (xK ) − f (x∗) is of the order

2

µ

σ∗2 Lζ2(τ − 1) L(τ − 1) σ∗2 + ζ∗2

O

L + L/n +

(τ − 1)LL R0 exp − L + L/n +

K (τ − 1)LL

+

+

nµK

µ2K

+

µ2 K 2

,

where R0 = x0 − x∗ . That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case Local-SGD requires

LL O ++
µ nµ

(τ − 1)LL + σ∗2 + Lζ2(τ − 1) +

µ

nµε

µ2ε

L(τ − 1) (σ∗2 + ζ∗2) µ2ε

iterations/oracle calls per node and τ times less communication rounds.

Combining Theorem G.5 and Lemma I.3 we derive the following result for the convergence of Local-SGD in the case when µ = 0.
Corollary G.10. Let assumptions of Theorem G.5 hold with µ = 0. Then for

1

1

γ0 = min 8L/n + 4L , 8 2LL(τ − 1) ,

γ = min γ0,

R02

,3

R02

,

2σ∗2/n + 4Lζ2(τ−1)/µ K 8L(τ − 1) (σ∗2 + ζ∗2) K

where R0 = x0 − x∗ , we have that

 L + L/n +

(τ − 1)LL R02

E f (xK ) − f (x∗) = O 

+

K



R02 σ∗2/n + Lζ2(τ −1)/µ

3 LR04(τ − 1) (σ∗2 + ζ∗2)

+

.

K

K 2/3

That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case Local-SGD requires

 L + L/n +
O

(τ − 1)LL ε

R02 +

σ∗2/n + Lζ2(τ −1)/µ R02 + R02 ε2



L(τ − 1) (σ∗2 + ζ∗2)

ε3/2



iterations/oracle calls per node and τ times less communication rounds.

G.2 Local-SVRG

As an alternative to Local-SGD when the local objective is of a ﬁnite sum structure (3), we propose L-SVRG [15, 23] stochastic gradient as a local direction instead of the plain stochastic gradient. Speciﬁcally, we consider

aki d=ef ∇fi,ji (xki ) − ∇fi,ji (wik) + ∇fi(wik),

bki = 0,

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

where index 1 ≤ ji ≤ m is selected uniformly at random and wik is a particular iterate from the local history updated as follows:

k+1

xki w.p. q

wi = wik w.p. 1 − q.

Next, we will assume that the local functions fi,j are max Lij-smooth.20 Lastly, we will equip the mentioned method with the ﬁxed local loop. The formal statement of the described instance of (4) is given as Algorithm 2.

Algorithm 2 Local-SVRG

Require: learning rate γ > 0, initial vector x0 ∈ Rd, communication period τ ≥ 1

1: for k = 0, 1, . . . do

2: for i = 1, . . . , n in parallel do

3:

Choose ji uniformly at random, independently across nodes

4:

gik = ∇fi,ji (xki ) − ∇fi,ji (wik) + ∇fi(wik)

k+1

xki w.p. q

5: wi = wik w.p. 1 − q

6:

if k + 1 mod τ = 0 then

n

7:

xki +1

=

xk+1

=

1 n

xki − γgik

i=1

8:

else

9:

xki +1 = xki − γgik

10:

end if

11: end for

12: end for

averaging local update

Let us next provide the details on the convergence rate. In order to do so, let us identify the parameters of Assumption 4.1.

Proposition G.1 (see [9]). Gradient estimator aki satisﬁes Assumption 4.1 with parameters Ai = 2 max Lij, Bi =

m

2, D1,i

=

0, ρi

=

q, Ci

=

max Lij q, D2,i

=

0,

and

σi2,k

=

1 m

∇fij (wik) − ∇fij (x∗) 2.

j=1

G.2.1 ζ-Heterogeneous Data

It remains to use Lemma 4.1 along with Corollary E.2 to recover all parameters of Assumption 2.3 and obtain a convergence rate of Algorithm 2 in ζ-heterogeneous case.
Theorem G.6. Assume that fi(x) is µ-strongly convex and L-smooth for i ∈ [n] and f1, . . . , fn are ζheterogeneous, convex and max Lij-smooth. Then Local-SVRG satisﬁes Assumption 2.3 with

A = 8 max Lij, B = 2, F = 8L max Lij, D1 = 2ζ∗2,

A = 4 max Lij + L, B = 1 , F

n

n

σk2 = 4

nm
∇fij (wik) − ∇fij (x∗) 2,

nm

i=1 j=1

ρ = q,

= 4L max Lij + 2L2, n

D1 = 0,

C = 8q max Lij, G = 4qL max Lij,

8(τ − 1)(2 + q)γ2

H=

,

q

2 ζ2 D3 = 2(τ − 1) 2ζ∗ + γµ

D2 = 0,

with γ satisfying

1

1

γ ≤ min

,

.

2 (44 max Lij/n + L) 16 L max Lij (τ − 1) (1 + 4/(1−q))

20It is easy to see that we must have max Lij ≥ L ≥ m1 max Lij.

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

and for all K ≥ 0

E f (xK ) − f (x∗)

Φ0

ζ2

2

≤

+ 8L(τ − 1)γ γWK

µ + 2γζ∗ ,

where Φ0 = 2 x0 − x∗ 2 + 8 γ2σ2 + 32L(τ−1)(2+q)γ3 σ2. In particular, if µ > 0 then

3nq 0

q

0

K

∗

q K Φ0

ζ2

2

E f (x ) − f (x ) ≤ 1 − min γµ, 4

+ 8L(τ − 1)γ γ

µ + 2γζ∗

(97)

and when µ = 0 we have

K

∗

Φ0

ζ2

2

E f (x ) − f (x )

≤

+ 8L(τ − 1)γ

γK

µ + 2γζ∗ .

(98)

The theorem above together with Lemma I.2 implies the following result. Corollary G.11. Let assumptions of Theorem G.6 hold with µ > 0. Then for

1

1

1

γ0 = min 2 (44 max Lij/n + L) , 16 L max Lij (τ − 1) (1 + 4/(1−q)) , q = m , m > 1,

0

0 ∗ 2 8 2 2 32L(τ − 1)(2 + q)γ03 2

Φ = 2 x − x + 3nq γ0 σ0 +

q

σ0 ,

ln max 2, min Φ0µ3K2/8Lζ2(τ −1), Φ0µ3K3/16L(τ −1)ζ2

γ = min γ0,

∗

,

µK

for all K such that

either or

ln max 2, min Φ0µ3K2/8Lζ2(τ −1), Φ0µ3K3/16L(τ −1)ζ∗2 K

1 ≤
m

ln γ0 ≤

max

2, min

Φ0µ3K2/8Lζ2(τ −1), Φ0µ3K3/16L(τ −1)ζ∗2 µK

we have that E f (xK ) − f (x∗) is of the order

Φ0

−1

ζ2L(τ − 1) L(τ − 1)ζ∗2

O γ0 exp − min m , γ0µ K + µ2K + µ2K2 .

That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case Local-SVRG requires

O m + L + max Lij +

µ

nµ

(τ − 1)L max Lij Lζ2(τ − 1) µ + µ2ε +

L(τ − 1)ζ∗2 µ2ε

iterations/oracle calls per node and τ times less communication rounds.
Combining Theorem G.6 and Lemma I.3 we derive the following result for the convergence of Local-SVRG in the case when µ = 0. Corollary G.12. Let assumptions of Theorem G.6 hold with µ = 0. Then for

1

1

1

γ0 = min 2 (44 max Lij/n + L) , 16 L max Lij (τ − 1) (1 + 4/(1−q)) , q = m , m > 1,

γ = min γ , 3nR02 , 3

R02

,

µR02

,3

R02

,

0 4mσ02 16Lm(τ − 1)(2 + 1/m)σ02 4Lζ2(τ − 1)K 8L(τ − 1)ζ∗2K

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

where R0 = x0 − x∗ , we have that E f (xK ) − f (x∗) is of the order

(L + max Lij/n + O

(τ − 1)L max Lij)R02 + K

/ mσ02R02 n + 3 Lm(τ − 1)σ02R04

√

+ + . LR02ζ2(τ −1)
µK

3 LR04(τ −1)ζ∗2 K 2/3

That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case Local-SVRG requires

(L + max Lij/n + O

(τ − 1)L max Lij)R02 + ε

/ mσ02R02 n + 3 Lm(τ − 1)σ02R04

√ Lζ2(τ −1)R02 + + µε2

R02 L(τ −1)ζ∗2 ε3/2

iterations/oracle calls per node and τ times less communication rounds.

Remark G.1. To get the rate from Tbl. 4 it remains to apply the following inequality:

σ02 = 4

nm

(6)

∇fij (x0) − ∇fij (x∗) 2 ≤ 4 max L2ij x0 − x∗ 2.

nm

i=1 j=1

G.2.2 Heterogeneous Data

First of all, we need the following lemma.

Lemma G.6. Assume that fi(x) is L-smooth for i ∈ [n] and fij is convex and max Lij-smooth for i ∈ [n], j ∈ [m]. Then for Local-SVRG we have

1n E
n i=1

g¯ik 2

1n E
n i=1

gk − g¯k 2

i

i

≤ 6LE f (xk) − f (x∗) + 3L2E[Vk] + 3ζ∗2, ≤ 8 max LijE f (xk) − f (x∗) + 21 E[σk2] + 4L max LijE[Vk],

(99) (100)

nm

where

σk2

=

4 nm

∇fij (wik) − ∇fij (x∗) 2.

i=1 j=1

Proof. Inequality (99) follows from g¯ik = E gik | xk = ∇fi(xki ) and inequality (67). Next, using Young’s inequality we derive

1n E
n i=1

gk − g¯k 2

i

i

(139)
≤

1n E
n i=1

gik − ∇fi(x∗) 2

(136)
≤

2n E
n i=1

∇fiji (xki ) − ∇fiji (x∗) 2

2n

+

E

n i=1

∇fiji (wik) − ∇fiji (x∗) − (∇fi(wik) − ∇fi(x∗)) 2

(140)
=

2 nm E
nm i=1 j=1

∇fij (xki ) − ∇fij (x∗) 2

2 nm

+

E

nm i=1 j=1

∇fij (wik) − ∇fij (x∗) − (∇fi(wik) − ∇fi(x∗)) 2

(19),(139)
≤

4 max Lij n

k∗

2 nm

n

E

Dfi (xi , x

)

+ nm

E

i=1

i=1 j=1

∇fij (wik) − ∇fij (x∗) 2

(6≤3) 8 max LijE f (xk) − f (x∗) + 21 E[σk2] + 4L max LijE[Vk].

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

Applying Corollary E.1, Lemma G.6, Proposition G.1 and Lemma 4.1 we get the following result.
Theorem G.7. Assume that fi(x) is µ-strongly convex and L-smooth for i ∈ [n] and fij is convex and max Lijsmooth for i ∈ [n], j ∈ [m]. Then Local-SVRG satisﬁes Assumption E.1 with

A = 3L, A = 4 max Lij, B = 0, B = 12 , F = 3L2, F = 4L max Lij, D1 = 3ζ∗2,

A = 4 manx Lij + L, B = n1 , F = 4L mnax Lij + 2L2, D1 = 0,

σk2 = 4

nm
∇fij (wik) − ∇fij (x∗) 2,

nm

i=1 j=1

ρ = q,

C = 8q max Lij,

G = 4qL max Lij,

2e(τ − 1)(2 + q)γ2

H=

,

q

D3 = 6e(τ − 1)2ζ∗2

D1 = 0 D2 = 0,

with γ satisfying

1

1

γ ≤ min

,

.

2 (44 max Lij/n + L) 4 2eL(τ − 1) (3L(τ − 1) + 4 max Lij + 8 max Lij/(1−q))

and for all K ≥ 0

E f (xK ) − f (x∗)

Φ0

22 2

≤ γWK + 24eL(τ − 1) ζ∗ γ ,

where Φ0 = 2 x0 − x∗ 2 + 8 γ2σ2 + 8eL(τ−1)(2+q)γ3 σ2 In particular, if µ > 0 then

3nq 0

q

0

K

∗

q K Φ0

22 2

E f (x ) − f (x ) ≤ 1 − min γµ, 4

γ + 24eL(τ − 1) ζ∗ γ

and when µ = 0 we have

E f (xK ) − f (x∗)

Φ0

22 2

≤ γK + 24eL(τ − 1) ζ∗ γ .

(101) (102)

The theorem above together with Lemma I.2 implies the following result. Corollary G.13. Let assumptions of Theorem G.7 hold with µ > 0. Then for

1

1

γ0 = min 2 (44 max Lij/n + L) , 4 2eL(τ − 1) (3L(τ − 1) + 4 max Lij + 8 max Lij/(1−q)) ,

0

0 ∗ 2 8 2 2 8eL(τ − 1)(2 + q)γ03 2

1

Φ = 2 x − x + 3nq γ0 σ0 +

q

σ0 ,

q= , m

m > 1,

ln max 2, Φ0µ3K3/24eL(τ −1)2ζ2

γ = min γ0,

∗

,

µK

for all K such that

ln max 2, Φ0µ3K3/24eL(τ −1)2ζ∗2

1

ln max 2, Φ0µ3K3/24eL(τ −1)2ζ∗2

either

K ≤ m or γ0 ≤ µK

we have that E f (xK ) − f (x∗) is of the order

Φ0

−1

L(τ − 1)2ζ∗2

O γ0 exp − min m , γ0µ K + µ2K2

.

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case Local-SVRG requires

O m + Lτ + max Lij +

µ

nµ

(τ − 1)L max Lij + µ

L(τ − 1)2ζ∗2 µ2ε

iterations/oracle calls per node and τ times less communication rounds.

Combining Theorem G.7 and Lemma I.3 we derive the following result for the convergence of Local-SVRG in the case when µ = 0. Corollary G.14. Let assumptions of Theorem G.7 hold with µ = 0. Then for q = m1 , m > 1 and

1

1

γ0 = min 2 (44 max Lij/n + L) , 4 2eL(τ − 1) (3L(τ − 1) + 4 max Lij + 8 max Lij/(1−q)) ,

γ = min γ , 3nR02 , 3

R02

,3

R02

,

0 4mσ02 4eLm(τ − 1)(2 + 1/m)σ02 12eL(τ − 1)2ζ∗2K

where R0 = x0 − x∗ , we have that E f (xK ) − f (x∗) is of the order

O (Lτ + max Lij/n + (τ − 1)L max Lij )R02 + mσ02R02/n + 3 Lm(τ − 1)σ02R04 + 3 LR04(τ − 1)2ζ∗2 .

K

K 2/3

That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case Local-SVRG requires

O (Lτ + max Lij/n + (τ − 1)L max Lij )R02 + mσ02R02/n + 3 Lm(τ − 1)σ02R04 + R02 L(τ − 1)2ζ∗2

ε

ε3/2

iterations/oracle calls per node and τ times less communication rounds.

Remark G.2. To get the rate from Tbl. 4 it remains to apply the following inequality:

σ02 = 4

nm

(6)

∇fij (x0) − ∇fij (x∗) 2 ≤ 4 max L2ij x0 − x∗ 2.

nm

i=1 j=1

G.3 S*-Local-SGD

In this section we consider the same settings as in Section G.1.1 and our goal is to remove one of the main
drawbacks of Local-SGD in heterogeneous case which in the case of µ-strongly convex fi with µ > 0 converges with linear rate only to the neighbourhood of the solution even in the full-gradients case, i.e. when D1,i = 0 for all i ∈ [n]. However, we start with unrealistic assumption that i-th node has an access to ∇fi(x∗) for all i ∈ [n]. Under this assumption we present a new method called Star-Shifted Local-SGD (S*-Local-SGD, see
Algorithm 3).

Lemma G.7. Let fi be convex and L-smooth for all i ∈ [n]. Then for all k ≥ 0

1n E gik | xki
n
i=1

1n

=

∇fi(xki ),

n

i=1

1n g¯ik 2 ≤ 4L f (xk) − f (x∗) + 2L2Vk,
n
i=1

1n E
n i=1

gik − g¯ik 2 | xki

≤ σ2,

 1n

2

σ2

E

gik | xk ≤ 4L f (xk) − f (x∗) + 2L2Vk + ,

n

n

i=1

(103) (104) (105) (106)

where σ2 d=ef n1

n i=1

D1,i

and

E[·

|

xk ]

d=ef

E[·

|

x

k 1

,

.

.

.

,

x

k n

].

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

Algorithm 3 S*-Local-SGD

Require: learning rate γ > 0, initial vector x0 ∈ Rd, communication period τ ≥ 1

1: for k = 0, 1, . . . do

2: for i = 1, . . . , n in parallel do

3:

Sample

gˆik

=

∇

fξ

k

(x

k i

)

independently

from

other

nodes

i

4:

gik = gˆik − ∇fi(x∗)

5:

if k + 1 mod τ = 0 then

n

6:

xki +1

=

xk+1

=

1 n

xki − γgik

i=1

7:

else

8:

xki +1 = xki − γgik

9:

end if

10: end for

11: end for

averaging local update

Proof. First of all, we notice that E gik | xki = ∇fi(xki ) − ∇fi(x∗) and

1n E gik | xki
n
i=1

1n =
n i=1

∇fi(xki ) − ∇fi(x∗)

1n

=

∇fi(xki ).

n

i=1

Using this we get

1n

1n

(19) 2L n

g¯ik 2 =

∇fi(xki ) − ∇fi(x∗) 2 ≤

Dfi

(x

k i

,

x∗

)

n

n

n

i=1

i=1

i=1

(63)
≤ 4L f (xk) − f (x∗) + 2L2Vk

and

1n E

1n

gik − g¯ik 2 | xki =

E

n

n

i=1

i=1

Finally,

using

independence

of

g1k

,

g2k

,

.

.

.

,

g

k n

and

1 n

∇fξk (xki ) − ∇fi(xki ) 2 i

(66) 1 n

≤

D1,i =: σ2.

n

i=1

n i=1

∇fi(x∗)

=

∇f (x∗)

=

0

we

obtain



n

2

1 E
n

gik | xk

i=1

(139),(103)
=



1n

E

gik − ∇fi(xki )

n

i=1

2 | xk +

n

2

n1 ∇fi(xki )

i=1


n

2

n

2

= E  n1 ∇fξik (xki ) − ∇fi(xki ) | xk + n1 ∇fi(xki )

i=1

i=1

=
(66),(68)
≤

1n

n2

Eξk i

i=1

n

2

∇fξik (xki ) − ∇fi(xki ) 2 + n1 ∇fi(xki )

i=1

4L f (xk) − f (x∗) + 2L2Vk + σ2 . n

Applying Corollary E.1 and Lemma G.7 we get the following result.

Theorem G.8. Assume that fi(x) is µ-strongly convex and L-smooth for every i ∈ [n]. Then S*-Local-SGD satisﬁes Assumption E.1 with

A = 2L, A = 0, A = 2L, B = 0,

B = B = 0,

F = 2L2,

F = 0,

D1 = 0,

1n

D1 = σ2 :=

D1,i

n

i=1

F = 2L2,

σ2

D1 =

, n

σk2 ≡ 0,

ρ = 1,

C = 0,

G = 0,

D2 = 0,

H = 0, D3 = 2e(τ − 1)σ2.

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

Consequently, if γ
we have for µ > 0 E f (xK ) − f (x∗) ≤
and when µ = 0 we have E f (xK ) − f (x∗)

≤ min 1 , √ 1 . 4L 8 e(τ − 1)L

(1 − γµ)K 2 x0 − x∗ 2 + 2γ σ2 + 4eL(τ − 1)γσ2

γ

n

≤ 2 x0 − x∗ 2 + 2γ σ2 + 4eL(τ − 1)γσ2 .

γK

n

In

the

special

case

when

∇

fξ

k

(x

k i

)

=

∇fi(xki )

for

all

i

∈

[n]

and

k

≥

0

we

obtain

S*-Local-GD

which

converges

i

with O τ κ ln 1 rate when µ > 0 and with O Lτ x0−x∗ 2 rate when µ = 0 to the exact solution asymptotically.

ε

ε

The theorem above together with Lemma I.2 implies the following result. Corollary G.15. Let assumptions of Theorem G.8 hold with µ > 0. Then for

γ = min

1, √ 1

ln max 2, min ,

4L 8 e(τ − 1)L

x0 −x∗

2 nµ2 K 2/σ 2 , µK

x0 −x∗

2µ3K3/4eL(τ −1)σ2

for all K such that

either or

ln max 2, min x0−x∗ min 1 , √ 1
4L 8 e(τ − 1)L

2 nµ2 K 2/σ 2 , K

x0 −x∗

2µ3K3/4eL(τ −1)σ2

≤1

ln max 2, min ≤

x0 −x∗

2 nµ2 K 2/σ 2 , µK

x0 −x∗

2µ3K3/4eL(τ −1)σ2

we have that

E f (xK ) − f (x∗) = O τ L x0 − x∗ 2 exp − µ K + σ2 + L(τ − 1)σ2 .

τL

nµK

µ2 K 2

That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case S*-Local-SGD requires

τL σ2

O

++

µ nµε

L(τ − 1)σ2 µ2ε

iterations/oracle calls per node and τ times less communication rounds.

Combining Theorem G.8 and Lemma I.3 we derive the following result for the convergence of S*-Local-SGD in the case when µ = 0.
Corollary G.16. Let assumptions of Theorem G.8 hold with µ = 0. Then for

γ = min 1 , √ 1

, nR02 , 3

R02

,

4L 8 e(τ − 1)L σ2K 4eL(τ − 1)σ2K

where R0 = x0 − x∗ , we have that E f (xK ) − f (x∗) = O

τ LR02 + K

R02σ2 + 3 LR04(τ − 1)σ2 .

nK

K 2/3

That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case S*-Local-SGD requires

O τ LR02 + R02σ2 + R02 L(τ − 1)σ2

ε

nε2

ε3/2

iterations/oracle calls per node and τ times less communication rounds.

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

G.4 SS-Local-SGD G.4.1 Uniformly Bounded Variance In this section we consider the same settings as in Section G.1.1

Algorithm 4 Stochastically Shifted Local-SGD (SS-Local-SGD)

Require: learning rate γ > 0, initial vector x0 ∈ Rd, probability of communication p ∈ (0, 1], probability of the

shift’s update q ∈ (0, 1], batchsize r for computing shifts

1: y0 = x0

2: For i ∈ [n] compute r independent samples ∇f 0 (y0), ∇f 0 (y0), . . . , ∇f 0 (y0), set ∇f 0 (y0) =

ξi,1

ξi,2

ξi,r

ξi

1 r ∇f 0 (y0) and ∇f 0 (y0) = 1 n ∇f 0 (y0)

r j=1 ξi,j

ξ

n i=1 ξi

3: for k = 0, 1, . . . do

4: 5: 6:
1 n
7:

for i = 1, . . . , n in parallel do

Sample ∇fξk (xki ) independently from other nodes i
gik = ∇fξik (xki ) − ∇fξik (yk) + ∇fξk (yk), where ∇fξki (yk) = 1r n ∇f k (yk)
i=1 ξi

xki +1 =

xk+1, xki − γgik,

w.p. p,

n
where xk+1 = 1 (xk − γgk)

w.p. 1 − p,

n

i

i

i=1

r ∇f k (yk) and ∇f k (yk) =

j=1

ξi,j

ξ

xk, w.p. q,

k+1 a fresh sample, if yk+1 = yk,

8:

yk+1 = yk, w.p. 1 − q, and for all i ∈ [n], j ∈ [r] ξi,j is equal to ξk , otherwise.

i,j

9: end for

10: end for

The main algorithm in this section is Stochastically Shifted Local-SGD (SS-Local-SVRG, see Algorithm 4). We notice that the updates for xki +1 and yk+1 can be dependent, e.g., one can take p = q and update yk+1 as xk every time xki +1 is updated by xk+1. Moreover, with probability q line 8 implies a round of communication and computation of new stochastic gradient by each worker.

We emphasize that in expectation yk is updated only once per 1/q iterations. Therefore, if r = O (1/q) and q ≤ p, then up to a constant numerical factor the overall expected number of oracle calls and communication rounds are the same as for Local-SGD with either the same probability p of communication or with constant local loop length τ = 1/p .

kk

k

Finally, we notice that due to independence of ξi,1, ξi,2, . . . , ξi,r we have

E

∇f

k (yk) − ∇f

(y k )

2

(66)
≤

D1,i .

ξi i

r

Lemma G.8. Let fi be convex and L-smooth for all i ∈ [n]. Then for all k ≥ 0

1n Ek gik
n
i=1

1n

=

∇fi(xki ),

n

i=1

1n E
n i=1

g¯ik 2

k

∗

2

2

2σ2

≤

8LE f (x ) − f (x ) + 2E[σk] + 4L E[Vk] +

, r

1n E
n i=1

gik − g¯ik 2

≤ σ2,

 1 n 2

σ2

E

gik  ≤ 4LE f (xk) − f (x∗) + 2L2E [Vk] + ,

n

n

i=1

(107)
(108) (109) (110) (111)

where σk2 d=ef n1 n ∇fi(yk) − ∇fi(x∗) 2 and σ2 d=ef n1
i=1

n i=1

D1,i.

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

Proof. We start with unbiasedness:

1n Ek gik
n
i=1

1n

= n

Ek ∇fξik (xki ) − ∇fξki (yk) + ∇fξk (yk)

i=1

1n

1n

1n

= n

Ek

∇

fξ

k

(x

k i

)

i

+ Ek

∇f k (yk) −

ξ

n

∇f k (yk) =

ξi

n

∇fi(xki ).

i=1

i=1

i=1

Using this we get

1n E
n i=1

g¯ik 2

(136)
≤
(19),(139)
≤
(63),(139)
≤
(107)
≤

2n E
n i=1

∇fi(xki ) − ∇fi(x∗) 2

2n

2

+

E ∇f k (yk) − ∇fi(x∗) − ∇f k (yk) − ∇f (x∗)

n

ξi

ξ

i=1

4L n

2n

E

Dfi

(x

k i

,

x∗

)

+

E

n

n

i=1

i=1

2
∇fξki (yk) − ∇fi(x∗)

2n

8LE f (xk) − f (x∗) + 4L2E[Vk] +

E

n

i=1

∇fi(yk) − ∇fi(x∗) 2

2n

+

E

n i=1

2
∇fξki (yk) − ∇fi(yk)

k

∗

2

2

2σ2

8LE f (x ) − f (x ) + 2E[σk] + 4L E[Vk] + r

and

1n E

1n

gik − g¯ik 2 =

E

∇fξk (xki ) − ∇fi(xki ) 2

n

n

i

i=1

i=1

Finally,

we

use

independence

of

∇fξk (xk1 ),

.

.

.

,

∇

fξ

k

(x

k n

)

and

derive

1

n

(66)
≤ σ2.



n

2


n

2

1 E
n

gik  = E  n1

∇

fξ

k

(x

k i

)



i

i=1

i=1


n

2



n

2

(139)
=

1 E
n

∇fi(xki )  + E  n1

∇fξk (xki ) − ∇fi(xki )  i

i=1

i=1

(68)

1n

≤ 4LE f (xk) − f (x∗) + 2L2E[Vk] + n2

E ∇fξk (xki ) − ∇fi(xki ) 2 i

i=1

(6≤6) 4LE f (xk) − f (x∗) + 2L2E [Vk] + σ2 n

which ﬁnishes the proof.

Lemma G.9. Let fi be convex and L-smooth for all i ∈ [n]. Then for all k ≥ 0 E σk2+1 ≤ (1 − q)E σk2 + 2LqE f (xk) − f (x∗)
where σk2 d=ef n1 n ∇fi(yk) − ∇fi(x∗) 2.
i=1

Proof. By deﬁnition of yk+1 we have
E σk2+1 | xk1 , . . . , xkn =
(19)
≤

1−q n

qn

∇fi(yk) − ∇fi(x∗) 2 +

n

n

i=1

i=1

(1 − q)σk2 + 2Lq(f (xk) − f (x∗)).

∇fi(xk) − ∇fi(x∗) 2

(112)

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

Taking the full mathematical expectation on both sides of previous inequality and using the tower property (140) we get the result.

Using Corollary E.3 we obtain the following theorem.
Theorem G.9. Assume that fi(x) is µ-strongly convex and L-smooth for every i ∈ [n]. Then SS-Local-SGD satisﬁes Assumption E.1 with

A = 4L,

A = 0, B = 2, B = 0, F = 4L2,

A = 2L, B = 0,

1n σk2 =
n
i=1

∇fi(yk) − ∇fi(x∗) 2 ,

128(1 − p)(2 + p)(2 + q)γ2

H=

3p2q ,

F = 0,

2σ2 D1 = r ,

D1 = σ2,

F = 2L2,

σ2

D1 =

, n

1n

σ2 =

D1,i,

n

i=1

ρ = q, C = Lq, G = 0, D2 = 0,

8(1 − p) D3 = p2

2(p + 2)σ2 + pσ2 r

under assumption that

√

1

p3

γ ≤ min ,

.

4L 32L 2(1 − p)(2 + p) (1 + 1/(1−q))

Moreover, for µ > 0 we have

E f (xK ) − f (x∗) ≤ 1 − min γµ, q K Φ0 + 2γ σ2 + γ 16L(1 − p) 2(p + 2)σ2 + pσ2

4

γ

n

p2

r

and when µ = 0 we have

E f (xK ) − f (x∗)

≤ Φ0 + 2γ σ2 + γ 16L(1 − p) 2(p + 2)σ2 + pσ2

γK

n

p2

r

where Φ0 = 2 x0 − x∗ 2 + 512L(1−p)(32p+2pq)(2+q)γ3σ02 .

The theorem above together with Lemma I.2 implies the following result.

Corollary G.17. Let assumptions of Theorem G.9 hold with µ > 0. Then for

√

1

p3

γ0 = min 4L , 32L 2(1 − p)(2 + p) (1 + 1/(1−q)) ,

Φ0 = 2 x0 − x∗ 2 + 512L(1 − p)(2 + p)(2 + q)γ03σ02 , q = p, 3p2q

ln max 2, min nΦ0µ2K2/2σ2, pΦ0µ3K3/32L(1−p)(3p+4)σ2 γ = min γ0, µK

1 , r= ,
p

for all K such that

either or

ln max 2, min nΦ0µ2K2/2σ2, pΦ0µ3K3/32L(1−p)(3p+4)σ2 K

≤p

ln γ0 ≤

max

2, min

nΦ0µ2K2/2σ2, pΦ0µ3K3/32L(1−p)(3p+4)σ2 µK

we have that E f (xK ) − f (x∗) is of the order

Φ0

1

σ2 L(1 − p)σ2

O γ0 exp − min p , γ0µ K + nµK + pµ2K2 .

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case SS-Local-SGD requires

L σ2

O

++

pµ nµε

L(1 − p)σ2 pµ2ε

iterations/oracle calls per node (in expectation) and 1/p times less communication rounds.

Combining Theorem G.9 and Lemma I.3 we derive the following result for the convergence of SS-Local-SGD in the case when µ = 0.

Corollary G.18. Let assumptions of Theorem G.9 hold with µ = 0. Then for q = p, r = 1/p and

√

1

p3

γ0 = min 4L , 32L 2(1 − p)(2 + p) (1 + 1/(1−q)) ,

γ = min γ , 3

3p3R02

, nR02 , 3

pR02

,

0 256L(1 − p)(2 + p)2σ02 σ2K 16L(1 − p)(3p + 4)σ2K

where R0 = x0 − x∗ , we have that E f (xK ) − f (x∗) is of the order

O LR02 + 3 L(1 − p)σ02R04 + pK

σ2R02 + 3 LR04(1 − p)σ2 .

nK

p1/3K 2/3

That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case SS-Local-SGD requires

O LR02 + 3 L(1 − p)σ02R04 + σ2R02 + R02 L(1 − p)σ2

pε

nε2

p1/2 ε3/2

iterations/oracle calls per node (in expectation) and 1/p times less communication rounds. Remark G.3. To get the rate from Tbl. 4 it remains to apply the following inequality:

1n σ02 =
n
i=1

(6)
∇fi(x0) − ∇fi(x∗) 2 ≤ L2 x0 − x∗ 2.

G.4.2 Expected Smoothness and Arbitrary Sampling

In this section we consider the same method SS-Local-SGD, but without assumption that the stochastic gradient has a uniformly bounded variance. Instead of this we consider the same setup as in Section G.1.2, i.e. we assume that each worker i ∈ [n] at any point x ∈ Rd has an access to the unbiased estimator ∇fξi (x) of ∇fi(x) satisfying Assumption G.1.
Lemma G.10. Let fi be convex and L-smooth for all i ∈ [n]. Let Assumption G.1 holds. Then for all k ≥ 0

1n Ek gik
n
i=1

1n

=

∇fi(xki ),

n

i=1

1n E
n i=1

g¯ik 2

≤ 8LE f (xk) − f (x∗) + 2E[σk2] + 4L2E[Vk],

1n E
n i=1

gik − g¯ik 2

≤ 8LE f (xk) − f (x∗) + 4LLE[Vk] + 2σ∗2,

 1 n 2 2L

2L

2σ2

E n

gik  ≤ 4 n + L E f (xk) − f (x∗) + 2L n + L E[Vk] + n∗ ,

i=1

(113) (114) (115) (116)

where σ2 d=ef 1 n

k

n

∇f k (yk) − ∇fi(x∗) 2 and σ2 d=ef 1

ξ

∗

n

i=1

i

n i=1

Eξi

∇fξi (x∗) − ∇fi(x∗)

2.

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

Proof. First of all, (113) follows from (108). Next, using g¯ik = ∇fi(xki ) − ∇fξk (yk) + ∇fξk (yk) we get i

1n E
n i=1

g¯ik 2

(136)
≤
(19),(139)
≤
(63)
≤

2n E
n i=1

∇fi(xki ) − ∇fi(x∗) 2

2n

+

E

n i=1

2
∇fξki (yk) − ∇fi(x∗) − (∇fξk (yk) − ∇f (x∗))

4L n

2n

E

D

fi

(

x

k i

,

x∗

)

+

E

n

n

i=1

i=1

∇fξki (yk) − ∇fi(x∗) 2

8LE f (xk) − f (x∗) + 2E[σk2] + 4L2E[Vk]

and

1n E
n i=1

gik − g¯ik 2

=
(139)
≤
(136)
≤
(86)
≤
(63)
≤

1n E
n i=1 1n
E n i=1 2n
E n i=1 4L n
E n i=1

∇fξk (xki ) − ∇fi(xki ) 2 i

∇fξk (xki ) − ∇fi(x∗) 2 i

∇fξk (xki ) − ∇fξk (x∗) 2

i

i

Dfi

(

x

k i

,

x∗

)

+ 2σ∗2

2n

+

E

n i=1

8LE f (xk) − f (x∗) + 4LLE[Vk] + 2σ∗2.

∇fξk (x∗) − ∇fi(x∗) 2 i (117)

Finally,

we

use

independence

of

ξ

k 1

,

.

.

.

,

ξ

k n

and

derive



n

2

1 E
n

gik 

i=1

=
(140),(139)
=
=
(117),(68)
≤


n

2

1 E
n

∇

fξ

k

(x

k i

)



i

i=1


n

2



n

2

1 E
n

(∇fξik (xki ) − ∇fi(xki ))  + E  n1

∇fi(xki ) 

i=1

i=1

1n n2 E
i=1

∇fξk (xki ) − ∇fi(xki ) 2 i

 +E

n

2

n1 ∇fi(xki ) 

i=1

4 2L + L E f (xk) − f (x∗) + 2L 2L + L E[Vk] + 2σ∗2

n

n

n

which ﬁnishes the proof.

Lemma G.11. Let fi be convex and L-smooth for all i ∈ [n] and Assumption G.1 holds. Then for all k ≥ 0

E σk2+1

2

2L

k

∗

2qσ∗2

≤ (1 − q)E σk + 2q

+ L E f (x ) − f (x ) +

r

r

(118)

where σ2 d=ef 1 n

k

n

∇f k (yk) − ∇fi(x∗) 2 and σ2 d=ef 1

ξ

∗

n

i=1

i

n i=1

Eξi

∇fξi (x∗) − ∇fi(x∗)

2.

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

Proof. By deﬁnition of yk+1 we have E σk2+1 | xk1 , . . . , xkn

=
(139)
=

1−q n n i=1

∇fξki (yk) − ∇fi(x∗) 2

qn

+ n

Eξki +1

i=1

∇fξki +1 (xk) − ∇fi(x∗) 2

qn

(1 − q)σk2 +

∇fi(xk) − ∇fi(x∗) 2

n

i=1

qn

+ n

Eξki +1

i=1

∇fξki +1 (xk) − ∇fi(xk) 2 .

k+1 k+1

k+1

Next, we use independence of ξi,1 , ξi,2 , . . . , ξi,r for all i ∈ [n] and derive

E σk2+1 | xk1 , . . . , xkn

=
(19),(139)
≤
(136)
≤
(86)
≤

qn

(1 − q)σk2 +

∇fi(xk) − ∇fi(x∗) 2

n

i=1

q nr

+ nr2

Eξki,+j 1

i=1 j=1

∇fξki,+j 1 (xk) − ∇fi(xk) 2

(1 − q)σk2 + 2Lq f (xk) − f (x∗)

q nr

+ nr2

Eξki,+j 1

i=1 j=1

∇fξki,+j 1 (xk) − ∇fi(x∗) 2

(1 − q)σk2 + 2Lq f (xk) − f (x∗)

2q n r

+ nr2

Eξki,+j 1

i=1 j=1

∇f k+1 (xk) − ∇f k+1 (x∗) 2

ξi,j

ξi,j

2q n r

+ nr2

Eξki,+j 1

i=1 j=1

∇fξki,+j 1 (x∗) − ∇fi(x∗) 2

(1 − q)σk2 + 2q 2rL + L

f (xk) − f (x∗) + 2qσ∗2 . r

Taking the full mathematical expectation on both sides of previous inequality and using the tower property (140) we get the result.

Using Corollary E.3 we obtain the following theorem.
Theorem G.10. Assume that fi(x) is µ-strongly convex and L-smooth for every i ∈ [n]. Let Assumption G.1 holds. Then SS-Local-SGD satisﬁes Assumption E.1 with

A = 4L, A = 4L, B = 2, B = 0, F = 4L2, F = 4LL, D1 = 0,

D1 = 2σ∗2,

1n

σ∗2 =

Eξi ∇fξi (x∗) − ∇fi(x∗) 2,

n

i=1

A =2

2L +L ,
n

B = 0,

F = 2L

2L +L ,
n

2σ∗2

D1 =

, n

1n σk2 =
n
i=1

2
∇fξki (yk) − ∇fi(x∗) ,

ρ = q,

C =q

2L +L ,
r

G = 0,

D2 = 2qσ∗2 , r

128(1 − p)(2 + p)(2 + q)γ2

H=

3p2q ,

8(1 − p) D3 = p2

2 32(2 + p)σ∗2 2pσ∗ + 3r

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

under assumption that







√



 

1

p3

 

γ ≤ min 4 2L + L ,

.

 

n

32

2L(1 − p) (2 + p)L + pL + (2+p)(2L/r+L)

  



(1−q)

Moreover, for µ > 0 we have E f (xK ) − f (x∗) ≤

q 1 − min γµ,
4

K Φ0

2σ∗2 16L(1 − p)

2 32(2 + p)σ∗2

γ + 2γ n + γ p2

2pσ∗ + 3r

and when µ = 0 we have E f (xK ) − f (x∗)

Φ0

2σ∗2 16L(1 − p)

2 32(2 + p)σ∗2

≤ γK + 2γ n + γ p2

2pσ∗ + 3r

where Φ0 = 2 x0 − x∗ 2 + 512L(1−p)(2+3pp2)q(2+q)γ3E[σ02] .

The theorem above together with Lemma I.2 implies the following result.

Corollary G.19. Let assumptions of Theorem G.10 hold with µ > 0. Then for







√



 

1

p3

 

γ0 = min 4 2L + L ,

,

 

n

32

2L(1 − p) (2 + p)L + pL + (2+p)(2L/r+L)

  



(1−q)

Φ0 = 2 x0 − x∗ 2 + 512L(1 − p)(2 + p)(2 + q)γ03E[σ02] , q = p, p2q

ln max 2, min nΦ0µ2K2/4σ2, pΦ0µ3K /3 64L(1−p)(1+32(2+p)/3)σ2

γ = min γ0,

∗

∗

µK

1 , r= ,
p

for all K such that

either or

ln max ln
γ0 ≤

2, min

/ , / nΦ0µ2K2 4σ∗2 pΦ0µ3K3 64L(1−p)(1+32(2+p)/3)σ∗2 K

≤p

max 2, min nΦ0µ2K2/4σ∗2, pΦ0µ3K3/64L(1−p)(1+32(2+p)/3)σ∗2

µK

we have that E f (xK ) − f (x∗) is of the order

Φ0

1

σ∗2 L(1 − p)σ∗2

O γ0 exp − min p , γ0µ K + nµK + pµ2K2 .

That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case SS-Local-SGD requires

LL

O

++

pµ nµ

LL(1 − p) σ∗2

√

++

pµ

nµε

L(1 − p)σ∗2 pµ2ε

iterations/oracle calls per node (in expectation) and 1/p times less communication rounds.

Combining Theorem G.10 and Lemma I.3 we derive the following result for the convergence of SS-Local-SGD in the case when µ = 0.

Corollary G.20. Let assumptions of Theorem G.10 hold with µ = 0. Then for q = p, r = 1/p and







√



 

1

p3

 

γ0 = min 4 2L + L ,

,

 

n

32

2L(1 − p) (2 + p)L + pL + (2+p)(2L/r+L)

  



(1−q)

γ = min γ , 3

p3R02

, nR02 , 3

pR02

,

0 256L(1 − p)(2 + p)2E[σ02] 2σ∗2K 32L(1 − p) (1 + 32(2+p)/3) σ∗2K

Local SGD: Uniﬁed Theory and New Eﬃcient Methods where R0 = x0 − x∗ , we have that E f (xK ) − f (x∗) is of the order

 L + pL/n +
O

p(1 − p)LL R02 + 3 L(1 − p)E[σ02]R04 +
pK

 σn∗2KR02 + 3 LRp104/3(K1 −2/3p)σ∗2  .

That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case SS-Local-SGD requires

 L + pL/n +
O

p(1 − p)LL R02 + 3 L(1 − p)E[σ02]R04 σ2R2 R2

+ ∗ 0+ 0

pε

nε2



L(1 − p)σ∗2

p1/2 ε3/2



iterations/oracle calls per node (in expectation) and 1/p times less communication rounds. Remark G.4. To get the rate from Tbl. 4 it remains to apply the following inequality:

E[σ02]

=
(139)
=
(19)
≤
(139)
≤
(136)
≤
r= 1/p ,(86)
≤

1n n Eξ0i
i=1

∇fξ0i (x0) − ∇fi(x∗) 2

1n n i=1

1n

∇fi(x0) − ∇fi(x∗) 2 +

E0

n

ξi

i=1

∇fξ0i (x0) − ∇fi(x0) 2

1 nr

2L(f (x0) − f (x∗)) +

E0

nr2

ξi,j

i=1 j=1

∇fξ0i,j (x0) − ∇fi(x0) 2

1n

2L(f (x0) − f (x∗)) +

Eξ

nr

i

i=1

∇fξi (x0) − ∇fi(x∗) 2

2n

2L(f (x0) − f (x∗)) +

Eξ

nr

i

i=1

∇fξi (x0) − ∇fξi (x∗) 2

2n

+ nr

Eξi

i=1

∇fξi (x∗) − ∇fi(x∗) 2

2 (L + 2pL) (f (x0) − f (x∗)) + 2pσ∗2.

G.5 S*-Local-SGD* In this section we present doubly idealized algorithm for solving problem (1)+(3). Speciﬁcally, we choose bki to the optimal shift ∇fi(x∗) as per Case II, while aki is selected as SGD-star gradient estimator [9], i.e.,

aki

=

∇

f

i,ji

(x

k i

)

−

∇fi,ji (x∗)

+

∇fi(x∗),

bki = ∇fi(x∗).

Note that now aki serves as an ambitious target for the local variance reduced estimators, while bki serves as an ambitious goal for the local shift. The resulting instance of (4) is presented as Algorithm 5 and called Star-Shifted Local-SGD-star (S*-Local-SGD*).
Let us next provide the details on the convergence rate. In order to do so, let us identify the parameters of Assumption 4.1.
Lemma G.12. Let fi be convex and L-smooth and fi,j be convex and max Lij-smooth for all i ∈ [n], j ∈ [m].

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

Algorithm 5 S*-Local-SGD*

Require: learning rate γ > 0, initial vector x0 ∈ Rd, communication period τ ≥ 1

1: for k = 0, 1, . . . do

2: for i = 1, . . . , n in parallel do

3:

Set gik = ∇fi,ji (xki ) − ∇fi,ji (x∗) where 1 ≤ ji ≤ m is sampled independently from all nodes

4:

if k + 1 mod τ = 0 then

n

5:

xki +1

=

xk+1

=

1 n

xki − γgik

i=1

averaging

6:

else

7:

xki +1 = xki − γgik

local update

8:

end if

9: end for

10: end for

Then for all k ≥ 0

1n Ek gik
n
i=1

1n

=

∇fi(xki ),

n

i=1

1n E
n i=1

g¯ik 2

≤ 4LE f (xk) − f (x∗) + 2L2E[Vk],

1n E
n i=1

gik − g¯ik 2

≤ 4 max LijE f (xk) − f (x∗) + 2L max LijE[Vk],



n

2

1 E
n

gik  ≤ 4 maxnLij + L E f (xk) − f (x∗) + 2L maxnLij + L E[Vk].

i=1

(119) (120) (121) (122)

Proof. First of all, 1n Ek gik n
i=1

1 nm

1n

=

∇fi,j (xki ) − ∇fi,j (x∗) =

∇fi(xki )

nm

n

i=1 j=1

i=1

and, in particular, g¯ik = Ek gik = ∇fi(xki ) − ∇fi(x∗). Using this we derive

1n E
n i=1

g¯ik 2

1n

=

E ∇fi(xki ) − ∇fi(x∗) 2

n

i=1

(19) 2L n

(63)

≤

E

Dfi

(

x

k i

,

x∗

)

≤ 4LE f (xk) − f (x∗) + 2L2E[Vk]

n

i=1

and

1n E
n i=1

gik − g¯ik 2

(139)
≤
=
(19)
≤
(63)
≤

1n E
n i=1

gik 2

1 nm nm i=1 j=1

∇fi,j (xki ) − ∇fi,j (x∗) 2

2 max Lij n

k∗

n

E Dfi (xi , x )

i=1

4 max LijE f (xk) − f (x∗) + 2L max LijE[Vk].

(123)

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

Finally, due to the independence of j1, j2, . . . , jn we have



n

2


n

2

1 E
n

gik  (139)=,(140) E  n1

∇fi,ji (xki ) − ∇fi,ji (x∗) − (∇fi(xki ) − ∇fi(x∗)) 

i=1

i=1


n

2

1 +E 
n

∇fi(xki ) − ∇fi(x∗) 

i=1

1n

=

n2 E ∇fi,ji (xki ) − ∇fi,ji (x∗) − (∇fi(xki ) − ∇fi(x∗)) 2

i=1


n

2

1 +E 
n

∇fi(xki ) 

i=1

(139)
≤

nm


n

2

1 n2m

∇fi,j (xki ) − ∇fi,j (x∗) 2 + E  n1 ∇fi(xki ) 

i=1 j=1

i=1

(123≤),(63) 4 maxnLij + L E f (xk) − f (x∗) + 2L maxnLij + L E[Vk].

Using Corollary E.1 we obtain the following theorem.
Theorem G.11. Assume that fi(x) is µ-strongly convex and L-smooth and fi,j is convex and max Lij-smooth for every i ∈ [n], j ∈ [m]. Then S*-Local-SGD* satisﬁes Assumption E.1 with

A = 2L, A = 2 max Lij, B = B = 0, F = 2L2, F = 2L max Lij,

A = 2 max Lij + L , B = 0, F = 2L max Lij + L

n

n

D1 = 0, σk2 ≡ 0, ρ = 1, C = 0, G = 0, D2 = 0, H = 0,

D1 = D1 = 0, , D3 = 0

under assumption that







1

1



γ ≤ min

,

.

 4 maxnLij + L 8 eL(τ − 1) (L(τ − 1) + max Lij) 

Moreover, for µ > 0 we have

E f (xK ) − f (x∗)

≤ (1 − γµ)K 2 x0 − x∗ 2 γ

and when µ = 0 we have

E f (xK ) − f (x∗)

2 x0 − x∗ 2

≤

.

γK

The theorem above together with Lemma I.2 implies the following result.

Corollary G.21. Let assumptions of Theorem G.11 hold with µ > 0. Then for







1

1



γ = min

,

 4 maxnLij + L 8 eL(τ − 1) (L(τ − 1) + max Lij) 

and for all K ≥ 1 we have E f (xK ) − f (x∗) of order

O Lτ + max Lij/n + (τ − 1)L max Lij x0 − x∗ 2 exp −

µ

K.

Lτ + max Lij/n + (τ − 1)L max Lij

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case S*-Local-SGD* requires



O  Lτ + max Lij +

µ

nµ

(τ − 1)L max Lij µ

Lτ + max Lij/n + log

(τ − 1)L max Lij ε

x0 − x∗ 2  

iterations/oracle calls per node and τ times less communication rounds.

Next, we derive the following result for the convergence of S*-Local-SGD* in the case when µ = 0. Corollary G.22. Let assumptions of Theorem G.11 hold with µ = 0. Then for







1

1



γ = min

,

,

 4 maxnLij + L 8 eL(τ − 1) (L(τ − 1) + max Lij) 

we have that E f (xK ) − f (x∗) is of the order

 Lτ + max Lij/n +
O

(τ − 1)L max Lij K

R

2 0



,

where R0 = x0 − x∗ . That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case S*-Local-SGD* requires

 Lτ + max Lij/n +
O

(τ − 1)L max Lij R02  
ε

iterations/oracle calls per node and τ times less communication rounds.

G.6 S-Local-SVRG

Algorithm 6 Shifted Local SVRG (S-Local-SVRG) for minimizing local ﬁnite sums

Require: learning rate γ > 0, initial vector x0 ∈ Rd, probability of communication p ∈ (0, 1], probability of local full gradient computation q ∈ (0, 1], initialization y0 = x0

1: for k = 0, 1, . . . do

2: for i = 1, . . . , n in parallel do

3:

Choose ji uniformly at random from [m]

4:

gik = ∇fi,ji (xki ) − ∇fi,ji (yk) + ∇f (yk)

5:

xk+1 = xk+1,

w.p. p,

n
where xk+1 = 1 (xk − γgk)

i

xki − γgik, w.p. 1 − p,

n

i

i

i=1

6:

yk+1 = xk, w.p. q,

yk, w.p. 1 − q

7: end for

8: end for

In this section we are interested in problem (1)+(3). To solve this problem we propose a new method called Shifted Local-SVRG (S-Local-SVRG, see Algorithm 6).
We note that our analysis works even when updates in lines 5,6 are not independent. Moreover, in order for S-Local-SVRG to be eﬃcient, we shall require q ≤ p.
Remark G.5. Unlike all other special cases, the rate of S-Local-SVRG can not be directly obtained from the theory of the local stochastic solver described in Section 4. Speciﬁcally, we construct the sequence lik using yk in contrast to xki used in Section 4. While we could construct lik from the local iterate sequences, setting it as the virtual iterates yields a tighter rate. We remark that such a choice is rather poor in general; we can implement it eﬃciently thanks to the speciﬁc structure of S-Local-SVRG.

Local SGD: Uniﬁed Theory and New Eﬃcient Methods
Lemma G.13. Let fi be convex and L-smooth and fi,j be convex and max Lij-smooth for all i ∈ [n], j ∈ [m]. Then for all k ≥ 0

1n Ek gik
n
i=1

1n

=

∇fi(xki ),

n

i=1

1n E
n i=1

g¯ik 2

≤ 8LE f (xk) − f (x∗) + 2E[σk2] + 4L2E[Vk],

1n E
n i=1

gik − g¯ik 2

≤ 8 max LijE f (xk) − f (x∗) + 2E[σk2] + 4L max LijE[Vk],



n

2

1 E
n

gik  ≤ 4 2 manx Lij + L E f (xk) − f (x∗) + n2 E[σk2]

i=1

+2L 2 max Lij + L E[Vk], n

(124) (125) (126)
(127)

where σk2 d=ef n1m n m ∇fi,j (yk) − ∇fi,j (x∗) 2 + n1 n ∇fi(yk) − ∇fi(x∗) 2.

i=1 j=1

i=1

Proof. First of all, we have

1n Ek gik
n
i=1

1n

=

Ek ∇fi,jk (xki ) − ∇fi,ji (yk) + ∇f (yk)

n

i=1

1 nm

=

∇fi,j (xki ) − ∇fi,j (yk) + ∇f (yk)

nm

i=1 j=1

1n

=

∇fi(xki )

n

i=1

and, in particular, g¯ik = Ek[gik] = ∇fi(xki ) − ∇fi(yk) + ∇f (yk). Using this we get

1n E
n i=1

g¯ik 2

(136)
≤
(19),(139)
≤
(63)
≤

2n E
n i=1

∇fi(xki ) − ∇fi(x∗) 2

2n

+

E

n i=1

∇fi(yk) − ∇fi(x∗) − (∇f (yk) − ∇f (x∗)) 2

4L n

2n

E

Dfi

(x

k i

,

x∗

)

+

E

n

n

i=1

i=1

∇fi(yk) − ∇fi(x∗) 2

8LE f (xk) − f (x∗) + 2E[σk2] + 4L2E[Vk]

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

and

1n E
n i=1

gik − g¯ik 2

=
(139)
≤
(136)
≤
(19)
≤
(63)
≤

1n E
n i=1

∇fi,ji (xki ) − ∇fi,ji (yk) − (∇fi(xki ) − ∇fi(yk)) 2

1n E
n i=1

∇fi,ji (xki ) − ∇fi,ji (yk) 2

2 nm E
nm i=1 j=1

∇fi,j (xki ) − ∇fi,j (x∗) 2

2 nm

+

E

nm i=1 j=1

∇fi,j (yk) − ∇fi,j (x∗) 2

4 max Lij n

k∗

2

n

E Dfi (xi , x ) + 2E[σk]

i=1

8 max LijE f (xk) − f (x∗) + 2E[σk2] + 4L max LijE[Vk].

(128)

Finally, using independence of j1, j2, . . . , jn we derive



n

2

1 E
n

gik 

i=1

(139),(124)
=
=
(68),(128)
≤


n

2

1 E
n

∇fi(xki ) 

i=1


n

2

1 +E 
n

(∇fi,ji (xki ) − ∇fi,ji (yk) − (∇fi(xki ) − ∇fi(yk))) 

i=1


n

2

1 E
n

∇fi(xki ) 

i=1

1n + n2 E
i=1

(∇fi,ji (xki ) − ∇fi,ji (yk) − (∇fi(xki ) − ∇fi(yk))) 2

4 2 manx Lij + L E f (xk) − f (x∗) + n2 E[σk2] + 2L 2 manx Lij + L

E[Vk ].

Lemma G.14. Let fi be convex and L-smooth and fi,j be convex and max Lij-smooth for all i ∈ [n], j ∈ [m]. Then for all k ≥ 0

E σk2+1 ≤ (1 − q) E σk2 + 2(L + max Lij)qE f (xk) − f (x∗)

(129)

where σk2 d=ef n1m n m ∇fi,j (yk) − ∇fi,j (x∗) 2 + n1 n ∇fi(yk) − ∇fi(x∗) 2.

i=1 j=1

i=1

Proof. First of all, we introduce new notations:

2 def 1 n m σk,1 = nm
i=1 j=1

∇fi,j (yk) − ∇fi,j (x∗) 2 ,

1n σk2,2 =
n
i=1

∇fi(yk) − ∇fi(x∗) 2 .

Secondly, by deﬁnition of yk+1 we have

E σk2+1,1 | xk1 , . . . , xkn

1−q n m

2 q nm

2

=

∇fi,j (yk) − ∇fi,j (x∗) +

∇fi,j (xk) − ∇fi,j (x∗)

nm

nm

i=1 j=1

i=1 j=1

(19)
≤ (1 − q)σk2,1 + 2q max Lij(f (xk) − f (x∗)),

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

hence

E σk2+1,1 ≤ (1 − q)E σk2,1 + 2q max Lij E f (xk) − f (x∗) .

Next, the deﬁnition of yk+1 implies

E σk2+1,2 | xk1 , . . . , xkn

1−q n

qn

=

∇fi(yk) − ∇fi(x∗) 2 +

∇fi(xk) − ∇fi(x∗) 2

n

n

i=1

i=1

(19)
≤ (1 − q)σk2 + 2Lq(f (xk) − f (x∗)),

hence

E σk2+1,2 ≤ (1 − q)E σk2,2 + 2LqE f (xk) − f (x∗) .

Finally, we combine obtained inequalities and get

E [σk+1]

=
(130),(131)
≤
=

E σk2+1,1 + E σk2+1,2
(1 − q) E σk2,1 + E σk2,2 + 2(L + max Lij)qE f (xk) − f (x∗) (1 − q) E σk2 + 2(L + max Lij)qE f (xk) − f (x∗) ,

which concludes the proof.

(130) (131)

Using Corollary E.3 we obtain the following theorem.
Theorem G.12. Assume that fi is µ-strongly convex and L-smooth and fi,j is convex and max Lij-smooth for all i ∈ [n], j ∈ [m]. Then S-Local-SVRG satisﬁes Assumption E.1 with

A = 4L, A = 4 max Lij, B = B = 2, F = 4L2, F = 4L max Lij D1 = D1 = 0,

4 max Lij

2

2 max Lij

A=

+ 2L, B = , F = 2L

n

n

n + L , D1 = 0,

σk2 = 1 n m nm
i=1 j=1

2 1n ∇fi,j (yk) − ∇fi,j (x∗) +
n
i=1

∇fi(yk) − ∇fi(x∗) 2 ,

ρ = q,

C = (L + max Lij)q,

G = 0,

D2 = 0,

256(1 − p2)(2 + q)γ2

H=

3p2q ,

D3 = 0

under assumption that

√

1

p3

γ ≤ min

,

.

56 max Lij/3n + 4L + 32L/3n 32 2L(1 − p) (L(2 + p) + p max Lij + 4(L+max Lij)(1+p)/(1−q))

Moreover, for µ > 0 we have E f (xK ) − f (x∗) ≤

q 1 − min γµ,
4

K2

x0 − x∗

2 + 16γn2qσ02 + 1024L(1−3pp22)q(2+q)γ3σ02 γ

and when µ = 0 we have E f (xK ) − f (x∗)

≤ 2 x0 − x∗ 2 + 16γn2qσ02 + 1024L(1−3pp22)q(2+q)γ3σ02 . γK

The theorem above together with Lemma I.2 implies the following result.

Corollary G.23. Let assumptions of Theorem G.12 hold with µ > 0. Then for q = 1/m, m ≥ 1/p,

√

1

p3

γ = min

,

56 max Lij/3n + 4L + 32L/3n 32 2L(1 − p) (L(2 + p) + p max Lij + 4(L+max Lij)(1+p)/(1−q))

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

and for all K ≥ 1 we have E f (xK ) − f (x∗) of order



O  L + max Lij +

p

n

(1 − p)L max Lij p





 

 Φ0 exp − min

µ

1

√

, K ,

 L + max Lij + (1−p)L max Lij m 

p

n

p

where Φ0 = 2 x0 − x∗ 2 + 16γn2qσ02 + 1024L(1−3pp22)q(2+q)γ3σ02 . That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case S-Local-SVRG requires



K = O  m + L + max Lij +



pµ

nµ

(1 − p)L max Lij pµ

√

Lp + maxnLij + (1−p)Lp max Lij Φ0



log



ε



iterations/oracle calls per node (in expectation) and 1/p times less communication rounds.

That is, S-Local-SVRG is the ﬁrst implementable linearly converging stochastic method with local updates with a convergence guarantee in terms of the number of communications that is not worse than that of GD even in the arbitrary heterogeneous data regime.

Next, we derive the following result for the convergence of S-Local-SVRG in the case when µ = 0.

Corollary G.24. Let assumptions of Theorem G.12 hold with µ = 0. Then for q = 1/m, m ≥ 1/p and

√

1

p3

γ0 = min 56 max Lij/3n + 4L + 32L/3n , 32 2L(1 − p) (L(2 + p) + p max Lij + 4(L+max Lij)(1+p)/(1−q)) ,

γ = min γ0,

nR02 , 3

3p2R02

8mσ02 512L(1 − p2)(2m + 1)σ02

we have

E f (xK ) − f (x∗)

 = O

L + p max Lij/n +

(1 − p)L max Lij pK

R02 +

 √mnσK02R02 + 3 Lp2m/3σK02R04  ,

where R0 = x0 − x∗ . That is, to achieve E f (xK ) − f (x∗) ≤ ε in this case S-Local-SVRG requires

 L + p max Lij/n +
K =O

(1 − p)L max Lij pε

R02 +

 m√σn02εR02 + 3 Lpm2/3σε02R04 

iterations/oracle calls per node (in expectation) and 1/p times less communication rounds. Remark G.6. To get the rate from Tbl. 4 it remains to apply the following inequality:

σ02 =

1 nm

2 1n

2

∇fi,j (x0) − ∇fi,j (x∗) +

∇fi(x0) − ∇fi(x∗)

nm

n

i=1 j=1

i=1

(6)
≤ 2 max L2ij + L2 x0 − x∗ 2.

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

H Basic Facts

For all a, b, x1, . . . , xn ∈ Rd, β > 0 and p ∈ (0, 1] the following inequalities hold

a2 βb2

a, b ≤

+

,

2β

2

(132)

a − b, a + b = a 2 − b 2,

1 a 2 − b 2 ≤ a + b 2, 2 a + b 2 ≤ (1 + β) a 2 + (1 + 1/β) b 2,

n
xn
i=1

2

n

≤n

i=1

xi 2,

p −1

1−

≤ 1 + p,

2

p

p

1 + (1 − p) ≤ 1 − .

2

2

(133) (134) (135) (136)
(137) (138)

Variance decomposition. For a random vector ξ ∈ Rd and any deterministic vector x ∈ Rd, the variance of ξ

can be decomposed as

E ξ − E[ξ] 2 = E ξ − x 2 − E[ξ] − x 2

(139)

Tower property of mathematical expectation. For random variables ξ, η ∈ Rd we have E [ξ] = E [E [ξ | η]]
under assumption that all expectations in the expression above are well-deﬁned.

(140)

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik

I Technical Lemmas

We now present a key technical lemma enabling our analysis. This is a reﬁned version of Lemma 14 from [46].
Lemma I.1 (see also Lemma 14 from [46]). For any τ random vectors ξ1, . . . , ξτ ∈ Rd such that for all t = 2, . . . , τ random vector ξt depends on ξ1, . . . , ξt−1 and does not depend on ξt+1, . . . , ξτ the following inequality holds


τ

2

τ

E  ξt  ≤ eτ E

t=1

t=1

Et[ξt] 2

τ
+e E
t=1

ξt − Et[ξt] 2 ,

(141)

where Et[·] denotes the conditional expectation E[· | ξt−1, . . . , ξ1].

Proof. First of all, if τ = 1 then (141) immediately follows from variance decompostion (139). Otherwise (τ > 1) for all l = 1, . . . , τ we have


l

2

El  ξt 

t=1

(139)
=

(135)
≤

l−1 2
El[ξl] + ξt + El
t=1

ξl − El[ξl] 2

1 1+
τ −1

l−1
ξt
t=1

2
+τ

El[ξl] 2 + El

ξl − El[ξl] 2 .

Taking full mathematical expectation and using tower property (140) we derive


l

2

E  ξt  ≤

t=1

1 1+
τ −1


l−1

2

E  ξt  + τ E

t=1

El[ξl] 2 + E

ξl − El[ξl] 2

for all l = 1, . . . , τ . Unrolling the recurrence for E

l

2

ξt

t=1

we obtain


τ

2

τ

τ −t

τ

τ −t

1

2

1

2

E  ξt  ≤ τ

1+ τ −1

E Et[ξt] +

1+ τ −1

E ξt − Et[ξt] .

t=1

t=1

t=1

τ −t

τ −1

Since 1 + τ−1 1

≤ 1 + τ−1 1

≤ e for all t = 1, . . . , τ we get (141).

Lemma I.2 (see also Lemma 2 from [45]). Let {rk}k≥0 satisfy rK ≤ a + c1γ + c2γ2 γWK

(142)

for all K ≥ 0 with some constants a, c2 ≥ 0, c1 ≥ 0 where {wk}k≥0 and {WK }K≥0 are deﬁned in (12), γ ≤ h1 . Then for all K such that

either or

ln max{2, min{aµ2K2/c1, aµ3K3/c2}} ≤ρ
K

1 ln max{2, min{aµ2K2/c1, aµ3K3/c2}}

≤

h

µK

and

γ = min

1 ln max{2, min{aµ2K2/c1, aµ3K3/c2}}

,

h

µK

(143)

we have that

µ

c1

c2

rK = O

ha exp − min

,ρ K h

+ µK + µ2K2

.

(144)

Local SGD: Uniﬁed Theory and New Eﬃcient Methods

Proof. Since WK ≥ wK = (1 − η)−(K+1) we have

rK ≤ (1 − η)K+1 a + c1γ + c2γ2 ≤ a exp (−η(K + 1)) + c1γ + c2γ2.

γ

γ

Next we consider two possible situations.

(145)

1. If 1 ≥ ( ) ln max{2,min{aµ2K2/c1,aµ3K3/c2}} then we choose γ = ( ) ln max{2,min{aµ2K2/c1,aµ3K3/c2}} and get that

h

µK

µK

rK (1≤45) γa exp (−η(K + 1)) + c1γ + c2γ2

ln max{2, min{aµ2K2/c1, aµ3K3/c2}}

= O aµK exp − min ρ,

K

K

+O c1 + c2 . µK µ2K2

Since ( ) ln max{2,min{aµ2K2/c1,aµ3K3/c2}} ≤ ρ we have
K
rK = O aµK exp − ln max +O c1 + c2 µK µ2K2
= O c1 + c2 . µK µ2K2

2, min

aµ2K2 aµ3K3

,

c1

c2

2. If 1 ≤ ( ) ln max{2,min{aµ2K2/c1,aµ3K3/c2}} then we choose γ = 1 which implies that

h

µK

h

(145)

µρ

c1 c2

rK ≤ ha exp − min h , 4 (K + 1) + h + h2

= O ha exp − min µ , ρ K + c1 + c2 .

h

µK µ2K2

Combining the obtained bounds we get the result.

Lemma I.3. Let {rk}k≥0 satisfy

rK ≤ a + b1γ + b2γ2 + c1γ + c2γ2 γK K K

for all K ≥ 0 with some constants a > 0, b1, b2, c1, c2 ≥ 0 where γ ≤ γ0. Then for all K and

γ = min γ0,

aa ,3 ,
b1 b2

a

a

,3

c1K c2K

we have that

rK = O

√

√

a + ab1 + 3 a2b2 +

γ0K K

K

√

ac1 + 3 a2c2 .

K

K 2/3

(146) (147)

Proof. We have rK ≤ a + b1γ + b2γ2 + c1γ + c2γ2 γK K K

≤ a + b1 ·

min γ0, ba1 , 3 ba2 , c1aK , 3 c2aK K K

√

√

√

= O a + ab1 + 3 a2b2 + ac1 + 3 a2c2

γ0K K

K

K

K 2/3

a b2 3 a2

+· b1 K

b2 + c1 ·

2

.

a c1K + c2

a2
3
c2K

Method, Setting
Local-SGD UBV, ζ-Het.
Local-SGD UBV, Het.
Local-SGD ES, ζ-Het.
Local-SGD ES, Het.
Local-SVRG simple, ζ-Het.
Local-SVRG simple, Het. S*-Local-SGD UBV, Het. SS-Local-SGD UBV, Het., p = q, r = 1/p SS-Local-SGD
ES, Het., p = q, r = 1/p S*-Local-SGD*
simple, Het. S-Local-SVRG simple, Het., q = m1 , m ≥ p1

A, A, A, A L, −, −, L
−, L, 0, L

B, B, B, B 0, −, −, 0
−, 0, 0, 0

L, −, −, Ln + L
−, L, L, Ln + L
max Lij , −, −, maxnLij + L
−, L, max Lij , maxnLij + L −, L, 0, L

0, −, −, 0
−, 0, 0, 0 1, −, −, n1 −, 0, 1, n1 −, 0, 0, 0

−, L, 0, L

−, 1, 0, 0

−, L, L, Ln + L
−, L, max Lij , maxnLij + L
−, L, max Lij , maxnLij + L

−, 1, 0, 0 −, 0, 0, 0 −, 1, 1, n1

ρ

C

F, F, F, F

G

D1, D1, D1, D1, D2, D3

1

0

L2, −, −, L2

0

σn2 , σ2 + ζ∗2, −, −, 0,

τσ2 + τ2ζ2

1

0

−, L2, 0, L2

0

σn2 , −, ζ∗2, σ2, 0,

(τ − 1)σ2 + (τ − 1)2ζ∗2

1 0 LL, −, −, LnL + L2 0

σn∗2 , σ∗2 + ζ∗2, −, −, 0, (τ − 1) σ∗2 + ζ∗2 + γζµ2

1 0 −, L2, LL, LnL + L2 0

σn∗2 , −, ζ∗2, σ∗2, 0, (τ − 1)σ∗2 + (τ − 1)2ζ∗2

q max Lij q

max LijL, −, −, maxnLij L + L2

max Lij Lq

0, ζ∗2, −, −, 0, (τ − 1) ζ∗2 + γζµ2

q max Lij q

−, L2, max Lij L, maxnLij L + L2

max Lij Lq

0, −, ζ∗2, 0, 0, (τ − 1)2ζ∗2

1

0

−, L2, 0, l2

0

σ2 , −, 0, σ2, (τ − 1)σ2

n

p

Lp

−, L2, 0, L2

0

σ2 , −, pσ2, σ2, 0, (1−p)σ2

n

p

p Lp + Lp2 −, L2, LL, LnL + L2 0 σn∗2 , −, 0, σ∗2, p2σ∗2, (1−pp)σ∗2

−, L2, max Lij L,

p

0

L max Lij + L2

0

n

1

L+max Lij

−, L2, max Lij L,

m

m

L max Lij + L2

0

n

0, −, 0, 0, 0, 0 0, −, 0, 0, 0, 0

Eduard Gorbunov, Filip Hanzely, Peter Richt´arik
Table 7: The parameters for which the methods from Table 2 satisfy Assumption 2.3/E.1. Absolute constants were omitted. The meaning of the expressions appearing in the table, as well as their justiﬁcation, is detailed in Section 5. UBV stands for the “Uniform Bound on the Variance” of local stochastic gradient, which is often assumed when fi is of the form (2). ES stands for the “Expected Smoothness” inequality [11], which does not impose any extra assumption on the objective/noise, but rather can be derived given the sampling strategy and the smoothness structure of fi. Consequently, such a setup allows us to obtain local methods with importance sampling. Next, the simple setting is a special case of ES when we uniformly sample a single index on each node each iteration.

