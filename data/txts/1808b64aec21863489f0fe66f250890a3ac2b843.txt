Our Data, Ourselves: Privacy via Distributed Noise Generation
Cynthia Dwork1, Krishnaram Kenthapadi2,4,5, Frank McSherry1, Ilya Mironov1, and Moni Naor3,4,6
1 Microsoft Research, Silicon Valley Campus, {dwork,mcsherry,mironov}@microsoft.com 2 Stanford University, kngk@cs.stanford.edu 3 Weizmann Institute of Science, moni.naor@weizmann.ac.il
Abstract. In this work we provide eﬃcient distributed protocols for generating shares of random noise, secure against malicious participants. The purpose of the noise generation is to create a distributed implementation of the privacy-preserving statistical databases described in recent papers [14, 4, 13]. In these databases, privacy is obtained by perturbing the true answer to a database query by the addition of a small amount of Gaussian or exponentially distributed random noise. The computational power of evePn a simple form of these databases, when the query is just of the form i f (di), that is, the sum over all rows i in the database of a function f applied to the data in row i, has been demonstrated in [4]. A distributed implementation eliminates the need for a trusted database administrator. The results for noise generation are of independent interest. The generation of Gaussian noise introduces a technique for distributing shares of many unbiased coins with fewer executions of veriﬁable secret sharing than would be needed using previous approaches (reduced by a factor of n). The generation of exponentially distributed noise uses two shallow circuits: one for generating many arbitrarily but identically biased coins at an amortized cost of two unbiased random bits apiece, independent of the bias, and the other to combine bits of appropriate biases to obtain an exponential distribution.
1 Introduction
A number of recent papers in the cryptography and database communities have addressed the problem of statistical disclosure control – revealing accurate
4 Part of the work was done in Microsoft Research, Silicon Valley Campus. 5 Supported in part by NSF Grant ITR-0331640. This work was also supported
in part by TRUST (The Team for Research in Ubiquitous Secure Technology), which receives support from the National Science Foundation (NSF award number CCF-0424422) and the following organizations: Cisco, ESCHER, HP, IBM, Intel, Microsoft, ORNL, Qualcomm, Pirelli, Sun and Symantec. 6 Incumbent of the Judith Kleeman Professorial Chair. Research supported in part by a grant from the Israel Science Foundation.

statistics about a population while preserving the privacy of individuals [1, 2, 15, 11, 14, 5, 6, 4, 13]. Roughly speaking, there are two computational models; in a non-interactive solution the data are somehow sanitized and a “safe” version of the database is released (this may include histograms, summaries, and so on), while in an interactive solution the user queries the database through a privacy mechanism, which may alter the query or the response in order to ensure privacy. With this nomenclature in mind the positive results in the literature fall into three broad categories: non-interactive with trusted server, non-interactive with untrusted server – speciﬁcally, via randomized response, in which a data holder alters her data with some probability before sending it to the server – and interactive with trusted server. The current paper provides a distributed interactive solution, replacing the trusted server with the assumption that strictly fewer than one third of the participants are faulty (we handle Byzantine faults). Under many circumstances the results obtained are of provably better quality (accuracy and conciseness, i.e., number of samples needed for correct statistics to be computed) than is possible for randomized response or other non-interactive solutions [13]. Our principal technical contribution is in the cooperative generation of shares of noise sampled from in one case the Binomial distribution (as an approximation for the Gaussian) and in the second case the Poisson distribution (as an approximation for the exponential).
Consider a database that is a collection of rows; for example, a row might be a hospital record for an individual. A query is a function f mapping rows to the interval [0, 1]. The true answer to the query is the value obtained by applying f to each row and summing the results. By responding with an appropriately perturbed version of the true answer, privacy can be guaranteed. The computational power of this provably private “noisy sums” primitive is demonstrated in Blum et al. [4], where it was shown how to carry out accurate and privacy-preserving variants of many standard data mining algorithms, such as k-means clustering, principal component analysis, singular value decomposition, the perceptron algorithm, and anything learnable in the statistical queries (STAT) learning model4.
Although the powerful techniques of secure function evaluation [25, 17] may be used to emulate any privacy mechanism, generic computations can be expensive. The current work is inspired by the combination of the simplicity of securely computing sums and the power of the noisy sums. We provide eﬃcient methods allowing the parties holding their own data to act autonomously and without a central trusted center, while simultaneously preventing malicious parties from interfering with the utility of the data.
The approach to decentralization is really very simple. For ease of exposition we describe the protocol assuming that every data holder participates in every query and that the functions f are predicates. We discuss relaxations of these assumptions in Section 5.
4 This was extended in [13] to handle functions f that operate on the database as a whole, rather than on individual rows of the database.

Structure of ODO (Our Data, Ourselves) Protocol

1. Share Summands: On query f , the holder of di, the data in row i of the

database, computes f (di) and shares out this value using a non-malleable

veriﬁable secret sharing scheme (see Section 2), i = 1, . . . , n. The bits are

represented as 0/1 values in GF(q), for a large prime q. We denote this set

{0, 1}GF(q) to make the choice of ﬁeld clear.

2. Verify Values: Cooperatively verify that the shared values are legitimate

(that is, in {0, 1}GF(q), when f is a predicate).

3. Generate Noise Shares: Cooperatively generate shares of appropriately

distributed random noise.

4. Sum All Shares: Each participant adds together all the shares that it

holds, obtaining a share of the noisy sum is in GF(q).

i f (di) + noise. All arithmetic

5. Reconstruct: Cooperatively reconstruct the noisy sum using the recon-

struction technique of the veriﬁable secret sharing scheme.

Our main technical work is in Step 3. We consider two types of noise, Gaussian and scaled symmetric exponential. In the latter distribution the probability of being at distance |x| from the mean is proportional to exp(−|x|/R), the scale R determining how “ﬂat” the distribution will be. In our case the mean will always be 0. Naturally, we must approximate these distributions using ﬁnite-precision arithmetic. The Gaussian and exponential distributions will be approximated, respectively, by the Binomial and Poisson distributions.
The remainder of this paper is organized as follows. In Section 2 we review those elements from the literature necessary for our work, including deﬁnitions of randomness extractors and of privacy. In Sections 3 and 4 we discuss implementations of Step 3 for Gaussian and Exponential noise, respectively. Finally, various generalizations of our results are mentioned in Section 5.

2 Cryptographic and Other Tools

Model of Computation. We assume the standard synchronous model of

computation in which n processors communicate by sending messages via point-

to-point channels and up to t ≤

n−1 3

may fail in an arbitrary, Byzantine,

adaptive fashion. If the channels are secure, then the adversary may be

computationally unbounded. However, if the secure channels are obtained by

encryption then we assume the adversary is restricted to probabilistic polynomial

time computations.

We will refer to several well-known primitive building blocks for constructing

distributed protocols: Byzantine Agreement [20], Distributed Coin Flipping [22],

Veriﬁable Secret Sharing (VSS) [8], Non-Malleable VSS, and Secure Function

Evaluation (SFE) [18].

A VSS scheme allows any processor distribute shares of a secret, which can

be veriﬁed for consistency. If the shares verify, the honest processors can always

reconstruct the secret regardless of the adversary’s behavior. Moreover, the faulty

processors by themselves cannot learn any information about the secret. A nonmalleable VSS scheme ensures that the values shared by a non-faulty processor are completely independent of the values shared by the other processors; even exact copying is prevented.
Throughout the paper we will use the following terminology. Values that have been shared and veriﬁed, but not yet reconstructed, are said to be in shares. Values that are publicly known are said to be public.
A randomness extractor [21] is a method of converting a non-uniform input distribution into a near-uniform distribution on a smaller set. In general, an extractor is a randomized algorithm, which additionally requires a perfect source of randomness, called the seed. Provided that the input distribution has suﬃciently high min-entropy, a good extractor takes a short seed and outputs a distribution that is statistically close to the uniform. Formally,
Deﬁnition 1. Letting the min-entropy of a distribution D on X be denoted H∞(D) = − log maxx∈X D(x), a function F : X × Y → {0, 1}n is a (δ, , n)extractor, if for any distribution D on X such that H∞(D) > δ,
|{F (x, y) : x ∈D X, y ∈U Y } − Un| < ,
where | · | is the statistical distance between two distributions, Un is the uniform distribution on {0, 1}n, and x ∈D X stands for choosing x ∈ X according to D.
Optimal extractors can extract n = δ − 2 log(1/ ) + O(1) nearly-random bits with the seed length O(log |X|) (see [23] for many constructions matching the bound).
While in general the presence of a truly random seed cannot be avoided, there exist deterministic extractors (i.e. without Y ) for sources with a special structure [7, 9, 24, 19, 16] where the randomness is concentrated on k bits and the rest are ﬁxed. Namely,
Deﬁnition 2. A distribution D over {0, 1}N is an (N, k) oblivious bit-ﬁxing source if there exists S = {i1, . . . , ik} ⊂ [N ], such that Xi1 , . . . , Xik are uniformly distributed in {0, 1}k, and the bits outside S are constant.
For any (N, k) bit-ﬁxing source and any constant 0 < γ < 1/2 Gabizon eNt1a/l2.+[γ16b]itgsivoef aennterxoppylicwititdheter=mi2n−isΩt(incγ()kp, r)o-veixdterdactthoarttkhat ex√tNra.ctIsnmou=r ckas−e N = 2n (n is the number of participants), and strictly more than 2/3 of the input bits will be good. Thus, k > 2N/3, and so we extract more than N/2 = n high quality bits by taking γ < 1/2.
A privacy mechanism is an interface between a user and data. It can be interactive or non-interactive.
Assume the database consists of a number n of rows, d1, . . . , dn. In its simplest form, a query is a predicate f : Rows → {0, 1}. In this case, the true answer is simply i f (di). Slightly more generally, f may map [n] × Rows → [0, 1], and the true answer is i f (i, di). Note that we are completely agnostic about

the domain Rows; rows can be Boolean, integers, reals, tuples thereof, or even strings or pictures.
A mechanism gives -indistinguishability [13] if for any two data sets that diﬀer on only one row, the respective output random variables (query responses) τ and τ satisfy for all sets S of responses:

Pr[τ ∈ S] ≤ exp( ) × Pr[τ ∈ S] .

(1)

This deﬁnition ensures that seeing τ instead of τ can only increase the probability of any event by at most a small factor. As a consequence, there is little incentive for any one participant to conceal or misrepresent her value, as so doing could not substantially change the probability of any event.
Similarly, we say a mechanism gives δ-approximate -indistinguishability if for outputs τ and τ based, respectively, on data sets diﬀering in at most one row,

Pr[τ ∈ S] ≤ exp( ) × Pr[τ ∈ S] + δ .

The presence of a non-zero δ permits us to relax the strict relative shift in the case of events that are not especially likely. We note that it is inappropriate to add non-zero δ to the statement of -indistinguishability in [13], where the sets S are constrained to be singleton sets.
Historically, the ﬁrst strong positive results for output perturbation added noise drawn from a Gaussian distribution, with density function Pr[x] ∝ exp(−x2/2R). A slightly diﬀerent deﬁnition of privacy was used in [14, 4]. In order to recast those results in terms of indistinguishability, we show in Section 2.1 that the addition of Gaussian noise gives δ-approximate indistinguishability for the noisy sums primitive when > [log(1/δ)/R]1/2. In a similar vein, Binomial noise, where n tosses of an unbiased ±1 coin are tallied and divided by 2, also gives δ-approximate -indistinguishability so long as the number of tosses n is at least 64 log(2/δ)/ 2.
Adding, instead, exponential noise results in a mechanism that can ensure -indistinguishability (that is, δ = 0) [4, 13]. If the noise is distributed as Pr[x] ∝ exp(−|x|/R), then the mechanism gives 1/R-indistinguishability (cf. > [log(1/δ)/R]1/2 for Gaussian noise). Note that although the Gaussian noise is more tightly concentrated around zero, giving somewhat better accuracy for any given choice of , the exponential noise allows δ = 0, giving a more robust solution.

2.1 Math for Gaussians and Binomials
We extend the results in [13] by determining the values of and δ for the Gaussian and Binomial distributions for which the noisy sums primitive yields δ-approximate -indistinguishability. Consider an output τ on a database D and query f . Let τ = i f (i, di)+noise, so replacing D with D diﬀering only in one row changes the summation by at most 1. Bounding the ratio of probabilities that τ occurs with inputs D and D amounts to bounding the ratio of probabilities

that noise = x and noise = x + 1, for the diﬀerent possible ranges of values for x. Thus, we ﬁrst determine the largest value of x such that a relative bound of exp( ) holds, and then integrate the probability mass outside of this interval.
Recall the Gaussian density function: p(x) ∝ exp(−x2/2R). The ratio of densities at two adjacent integral points is
exp(−x2/2R) exp(−(x + 1)2)/2R = exp(x/R + 1/2R).
This value remains at most exp( ) until x = R − 1/2. Provided that R ≥ 2 log(2/δ)/ 2 and that ≤ 1, the integrated probability beyond this point will be at most
Pr[x > R − 1/2] ≤ exp(−( R√)2/2R) ≤ δ . ( R) π
As a consequence, we get δ-approximate -indistinguishability when R is at least 2 log(2/δ)/ 2.
For the Binomial noise with bias 1/2, whose density at n/2 + x is
Pr[n/2 + x] = n 1/2n , n/2 + x
we see that the relative probabilities are
Pr[n/2 + x] = n/2 + x + 1 . Pr[n/2 + x + 1] n/2 − x
So long as x is no more than n/8, this should be no more than (1 + ) < exp( ). Of course, a Chernoﬀ bound tells us that for such x the probability that a sample exceeds it is
Pr[y > n/2 + n/8] = Pr[y > (1 + /4)n/2] ≤ exp(−( 2n/64)).
We get δ-approximate -indistinguishability so long as n is chosen to be at least 64 log(2/δ)/ 2. This exceeds the estimate of the Gaussian due to approximation error, and general slop in the analysis, though it is clear that the form of the bound is the same.
2.2 Adaptive Query Sequences
One concern might be that after multiple queries, the values of and δ degrade in an inelegant manner. We now argue that this is not the case.
Theorem 1. A mechanism that permits T adaptive interactions with a δapproximate -indistinguishable mechanism ensures δT -approximate T -indistinguishability.

Proof. We start by examining the probability that the transcript, written as an ordered T -tuple, lands in a set S.

Pr[x ∈ S] = Pr[xi ∈ Si|x1, . . . , xi−1].
i≤T
As the noise is independent at each step, the conditioning on x1, . . . , xi−1 only aﬀects the predicate that is asked. As a consequence, we can substitute

Pr[xi ∈ Si|x1, . . . , xi−1] ≤ (exp( ) × Pr[xi ∈ Si|x1, . . . , xi−1] + δ) .

i≤T

i≤T

If we look at the additive contribution of each of the δ terms, of which there are T , we notice that they are only ever multiplied by probabilities, which are at most one. Therefore, each contributes at most an additive δ.

Pr[xi ∈ Si|x1, . . . , xi−1] ≤ (exp( ) × Pr[xi ∈ Si|x1, . . . , xi−1]) + δT

i≤T

i≤T

= exp( T ) × (Pr[xi ∈ Si|x1, . . . , xi−1]) + δT
i≤T
= exp( T ) × Pr[x ∈ S] + δT .

The proof is complete.

3 Generating Gaussian Noise
Were we not concerned with malicious failures, a simple approach would be to have each participant i perturb f (di) by sampling from a Gaussian with mean zero and variance 32 var/n, where var is a lower bound on the variance needed for preserving privacy (see Section 2). The perturbed values would be shared out and the shares summed, yielding i f (di) + noise in shares. Since, as usual in the Byzantine literature, we assume that at least 2/3 of the participants will survive, the total variance for the noise would be suﬃcient (but not excessive). However, a Byzantine processor might add an outrageous amount of noise to its share, completely destroying the integrity of the results. We now sketch the main ideas in our solution for the Byzantine case.
Recall that the goal is for the participants to obtain the noise in shares. As mentioned earlier, we will approximate the Gaussian with the Binomial distribution, so if the participants hold shares of suﬃciently many unbiased coins they can sum these to obtain a share of (approximately) correctly generated noise. Coin ﬂipping in shares (and otherwise) is well studied, and can be achieved by having each participant non-malleably veriﬁably share out a value in GF(2), and then locally summing (in GF(2)) the shares from all n secret sharings.
This suggests a conceptually straightforward solution: Generate many coins in shares, convert the shares from GF(2) to shares of values in a large ﬁeld GF(q) (or to shares of integers), and then sum the shares. In addition to the conversion

costs, the coins themselves are expensive to generate, since they require Ω(n) executions of veriﬁable secret sharing per coin, which translates into Ω(nc) secret sharings for c coins5. To our knowledge, the most eﬃcient scheme for generating random bits is due to Damg˚ard et al. [10], which requires n sharings and two multiplications per coin.
We next outline a related but less expensive solution which at no intermediate or ﬁnal point uses the full power of coin-ﬂipping. The solution is cost eﬀective when c is suﬃciently large, i.e., c ∈ Ω(n). As a result, we will require only Ω(c) sharings of values in GF(2) when c ∈ Ω(n). Let n denote both the number of players and the desired number of coins6.
1. Each player i shares a random bit by sharing out a value bi ∈ {0, 1}GF(q), using a non-malleable veriﬁable secret sharing scheme, where q is suﬃciently large, and engages in a simple protocol to prove that the shared value is indeed in the speciﬁed set. (The veriﬁcation is accomplished by distributively checking that x2 = x for each value x that was shared, in parallel. This is a single secure function evaluation of a product, addition of two shares, and a reconstruction, for each of the n bits bi.) This gives a sequence of lowquality bits in shares, as some of the shared values may have been chosen adversarially. (Of course, the faulty processors know the values of the bits they themselves have produced.)
2. Now, suppose for a moment that we have a public source of unbiased bits, c1, c2,. . . , cn. By XORing together the corresponding b’s and c’s, we can transform the low quality bits bi (in shares) into high-quality bits bi ⊕ ci, in shares. (Again, the faulty processors know the values of the (now randomized) bits they themselves have produced.) The XORing is simple: if ci = 0 then the shares of bi remain unchanged. If ci = 1 then each share of bi is replaced by one minus the original share.
3. Replace each share s by 2s − 1, all arithmetic in GF(q). This maps shares of 0 to shares of −1, and shares of 1 to (diﬀerent) shares of 1.
4. Finally, each participant sums her shares to get a share of the Binomial noise.
We now turn to the generation of the ci. Each participant randomly chooses and non-malleably veriﬁably shares out two bits, for a total of 2n low-quality bits in shares. This is done in GF(2), so there is no need to check legitimacy. Let the low-quality source be b1, b2, . . . , b2n. The bi are then reconstructed, so that they become public. The sequence b1b2 . . . b2n is a bit-ﬁxing source: some of the bits are biased, but they are independent of the other bits (generated by the good participants) due to the non-malleability of the secret sharing. The main advantage of such a source is that it is possible to apply a deterministic
5 When a single player shares out many values (not the case for us), the techniques of Bellare, Garay, and Rabin [3] can be used to reduce the cost of verifying the shared out values. The techniques in [3] complement ours; see Section 5.
6 If the desired number of coins is o(n), we can generate Θ(n) coins and keep the unused ones in reserve for future executions of the protocol. If m n coins are needed, each processor can run the protocol m/n times.

extractor on those bits and have the output be very close to uniform. Since the bits b1 . . . b2n are public, this extraction operation can be done by each party individually with no additional communication. In particular we may use, say, the currently best known deterministic extractor of [16], which produces a number m > n of nearly unbiased bits. The outputs of the extractor are our public coins c1 . . . cm.
The principal costs are the multiplications for verifying membership in {0, 1}GF(q) and the executions of veriﬁable secret sharing. Note that all the veriﬁcations of membership are performed simultaneously, so the messages from the diﬀerent executions can be bundled together. The same is true for the veriﬁcations in the VSS. The total cost of the scheme is Θ(n) multiplications and additions in shares, which can be all done in a constant number of rounds.
4 Generating Exponential Noise
Recall that in the exponential distribution the probability of obtaining a value at distance |x| from the mean is proportional to exp(−|x|/R), where R is a scaling factor. For the present discussion we take R = 1/(ln 2), so that exp(−|x|/R) = 2−|x|. We approximate the exponential distribution with the Poisson distribution. An intuitively simple approach is to generate a large number of unbiased7 random bits in shares, and then ﬁnd (in shares) the position
of the ﬁrst 1. The value returned by this noise generation procedure is ± (we ﬂip one additional bit to get the sign). If there is no 1, then the algorithm fails, so the number of bits must be suﬃciently large that this occurs with negligible probability. All the computation must be done in shares, and we can’t “quit” once a 1 has been found (this would be disclosive). This “unary” approach works well when R = 1/(ln 2) and the coins are unbiased. For much larger values of R, the case in high-privacy settings, the coins need to be heavily biased toward 0, ﬂattening the curve. This would mean more expected ﬂips before seeing a 1, potentially requiring an excessive number of random bits.
Instead, we take advantage of the special structure of the exponential distribution, and see that we can generate the binary representation of an exponential variable using a number of coins that is independent of the bias. Let us return to the question of the location of the ﬁrst 1 in a sequence of randomly generated bits. We can describe one bit at a time by answering the following series of questions:
1. What is the parity of ? That is, = 2i for some i ≥ 0? (We begin counting the positions at 0, so that will be the number of 0’s preceding the ﬁrst 1.)
2. Is in the left half or the right half of a block of 4 positions, i.e., is it the case that 22i ≤ < 22i + 2 for some i ≥ 0?
3. Is in the left half or the right half of a block 8 positions, i.e., is it the case that 23i ≤ < 23i + 22 for some i ≥ 0?
4. And so on.
7 For values of R = 1/(ln 2) we would need to use biased bits.

We generate the distribution of “in binary” by generating the answers to the

above questions. (For some ﬁxed d we simply assume that < 2d, so only a ﬁnite

number of questions need be answered.)

To answer the questions, we need to be able to generate biased coins. The

probability that is even (recall that we begin counting positions with 0) is

(1/2)

∞ i=0

(2−2i

).

Similarly,

the

probability

that

is odd is (1/2)

∞ i=0(2−(2i+1)).

Thus,

Pr[ odd] = (1/2)Pr[ even].

Since the two probabilities sum to 1, the probability that is even is 2/3. Similar analyses yield the necessary biases for the remaining questions.
The heart of the technical argument is thus to compute coins of arbitrary bias in shares in a manner that consumes on average a constant number of unbiased, completely unknown, random bits held in shares. We will construct and analyze a shallow circuit for this. In addition, we will present two incomparable probabilistic constructions. In any distributed implementation these schemes would need to be implemented by general secure function evaluation techniques. The circuits, which only use Boolean and ﬁnite ﬁeld arithmetic, allow eﬃcient SFE implementation.

4.1 Poisson Noise: The Details

In this section we describe several circuits for generating Poisson noise. The

circuits will take as input random bits (the exact number depends on the circuit

in question). In the distributed setting, the input would be the result of a protocol

that generates (many) unbiased bits in shares. The circuit computation would

be carried out in a distributed fashion using secure function evaluation, and

would result in many samples, in shares, of noise generated according to the

Poisson distribution. This ﬁts into the high-level ODO protocol in the natural

way: shares of the noise are added to the shares of noisy sum is reconstructed.

i f (i, di) and the resulting

For the remainder of this section, we let n denote the number of coins to be

generated. It is unrelated to the number of participants in the protocol.

Recall the discussion in the Introduction of the exponential distribution,

where Pr[x] ∝ exp(−|x|/R). Recall that one interpretation is to ﬂip a (possibly

biased) coin until the ﬁrst 1 is seen, and then to output the number of 0’s seen

before the 1 occurs. Recall also that instead of generating in unary, we will

generate it in binary.

We argue that the bits in the binary representation of the random variable

are independent, and moreover we can determine their biases analytically. To

see the independence, consider the distribution of the ith bit of :

i = 10 ww..pp.. PPrr[[10 ×× 22ii ≤≤ << 21 ×× 22ii]] ++ PPrr[[32 ×× 22ii ≤≤ << 43 ×× 22ii]] ++ .. .. ..

Notice that corresponding terms in the two summations, eg Pr[0×2i ≤ < 1×2i] and Pr[1×2i ≤ < 2×2i], are directly comparable; the ﬁrst is exactly exp(2i/R)

times the second. This holds for every corresponding pair in the sums, and as such the two sums share the same ratio. As the two sum must total to one, we have additionally that
1 − Pr[ i] = exp(2i/R) × Pr[ i] .
Solving, we ﬁnd that
Pr[ i] = 1/(1 + exp(2i/R)) .
Recall as well that the observed ratio applied equally well to each pair of intervals, indicating that the bias is independent of the more signiﬁcant bits. The problem of producing an exponentially distributed is therefore simply a matter of ﬂipping a biased coin for each bit of . The circuit we will construct will generate many ’s according to the desired distribution, at an expected low amortized cost (number of input bits) per bit position in the binary expansion of . The circuit is a collection of circuits, each for one bit position, with the associated bias hard-wired in. It suﬃces therefore to describe the circuitry for one of these smaller circuits (Section 4.3). We let p denote the hard-wired bias.
A well-known technique for ﬂipping a single coin of arbitrary bias p is to write p in binary, examine random bits until one diﬀers from the corresponding bit in p, and then emit the complement of the random bit. To achieve a high ﬁdelity to the original bias p, a large number d of random bits must be available. However, independent of p, the expected number of random bits consumed is at most 2. This fact will be central to our constructions.
In the sequel we distinguish between unbiased bits, which are inputs to the algorithm, and the generated, biased, coins, which are the outputs of the algorithm.
4.2 Implementation Details: Finite Resources
With ﬁnite randomness we will not be able to perfectly emulate the bias of the coins. Moreover, the expectation of higher order bits in the binary representation of diminishes at a doubly exponential rate (because the probability that ≥ 2i is exponentially small in 2i), quickly giving probabilities that simply can not be achieved with any ﬁxed amount of randomness.
To address these concerns, we will focus on the statistical diﬀerence between our produced distribution and the intended one. The method described above for obtaining coins with arbitrary bias, truncated after d bits have been consumed, can emulate any biased coin within statistical diﬀerence at most 2−d. Accordingly, we set all bits of suﬃciently high order to zero, which will simplify our circuit. The remaining output bits – let us imagine there are k of them – will result in a distribution whose statistical diﬀerence is at most k2−d from the target distribution. We note that by trimming the distribution to values at most 2d in magnitude, we are introducing an additional error, but one whose statistical diﬀerence is quite small. There is an exp(−2d/R) probability mass outside the [−2d, 2d] interval that is removed and redistributed inside the

interval. This results in an additional 2 exp(−2d/R) statistical diﬀerence that should be incorporated into δ. For clarity, we absorb this term into the value k.
Using our set of coins with statistical diﬀerence at most k2−d from the target distribution, we arrive at a result akin to (1), though with an important diﬀerence. For response variables τ and τ as before (based on databases diﬀering it at most one row),
∀S ⊆ U : Pr[τ ∈ S] ≤ Pr[τ ∈ S] × exp(1/R) + k2−d .
As before, the probability of any event increases by at most a factor of exp(1/R), but now with an additional additive k2−d term. This term is controlled by the parameter d, and can easily be made suﬃciently small to allay most concerns.
We might like to remove the additive k2−d term, which changes the nature of the privacy guarantee. While this seems complicated at ﬁrst, notice that it is possible to decrease the relative probability associated with each output coin arbitrarily, by adding more bits (that is, increasing d). What additional bits can not ﬁx is our assignment of zero probability to noise values outside the permitted range (i.e., involving bits that we do not have circuitry for).
One pleasant resolution to this problem, due to Adam Smith, is to constrain the output range of the sum of noise plus signal. If the answer plus noise is constrained to be a k-bit number, and conditioned on it lying in that range the distribution looks exponential, the same privacy guarantees apply. Guaranteeing that the output will have only k bits can be done by computing the sum of noise and signal using k + 1 bits, and then if there is overﬂow, outputting the noisefree answer. This increases the probability that noise = 0 by a relatively trivial amount, and ensures that the output space is exactly that of k-bit numbers.
4.3 A Circuit for Flipping Many Biased Coins
We are now ready to construct a circuit for ﬂipping a large number of independent coins with common bias. By producing many (Ω(n)) coins at once, we could hope to leverage the law of large numbers and consume, with near certainty, a number of input bits that is little more than 2n and depends very weakly on d. For example, we could produce the coins sequentially, consuming what randomness we need and passing unused random bits on to the next coin. The circuit we now describe emulates this process, but does so in a substantially more parallel manner.
The circuit we construct takes 2i unbiased input bits and produces 2i output coins, as well as a number indicating how many of the coins are actually the result of the appropriate biased ﬂips. That is, it is unlikely that we will be able to produce fully 2i coins, and we should indicate how many of the coins are in fact valid. The construction is hierarchical, in that the circuit that takes 2i inputs will be based on two level i − 1 circuits, attached to the ﬁrst and second halves of its inputs.
To facilitate the hierarchical construction, we augment the outputs of each circuit with the number of bits at the end of the 2i that were consumed by

the coin production process, but did not diverge from the binary representation

of p. Any process that wishes to pick up where this circuit has left oﬀ should

start under the assumption that the ﬁrst coin is in fact this many bits into its

production. For example, if this number is r then the process should begin by

comparing the next random bit to the (r +1)st bit in the expansion of p. Bearing

this in mind, we “bundle” d copies of this circuit together, each with a diﬀerent

assumption about the initial progress of the production of their ﬁrst coin.

For each value 1 ≤ j ≤ d we need to produce a vector of 2i coins cj, a number

of coins nj, and dj, a measure of progress towards the last coin. We imagine that

we have access to two circuits of one level lower, responsible for the left and right

half of our 2i input bits, and whose corresponding outputs are superscripted by

L and R. Intuitively, for each value of j we ask the left circuit for dLj , which

we use to select from the right circuit. Using index j for the left circuit and dLj

for the right circuit, we combine the output coins using a shift of nLj to align

them,

and

add

the

output

counts

nLj

and

n

R dL

.

We

simply

pass

dRdL

out

as

the

j

j

appropriate value for dj.

cj = cLj | (cRdL >> nLj ) j
nj = nLj + nRdL j
dj = dRdL j

The operation of subscripting is carried out using a multiplexer, and shifts,
bitwise ors, and addition are similarly easily carried out in logarithmic depth.
The depth of each block is bounded by Θ(log(nd)), with the size bounded by Θ(2id(log(n) + d), as each of d outputs must multiplex d possible inputs (taking Θ(d) circuitry) and then operate on them (limited by Θ(log(n)2i) for the barrel shifter). All told, the entire circuit has depth Θ(log(nd)2), with size
Θ(nd(log(n) + d) log(n)).

4.4 Probabilistic Constructions with Better Bounds
We describe two probabilistic constructions of circuits that take as input unbiased bits and produce as output coins of arbitrary, not necessarily identical, bias. Our ﬁrst solution is optimal in terms of depth (Θ(log d)) but expensive in the gate count. Our second solution dramatically decreases the number of gates, paying a modest price in depth (O(log(n + d))) and a logarithmic increase in the number of input bits.
A module common to both constructions is the comparator – a circuit that takes two bit strings b1, . . . , bd and p(1) . . . p(d) and outputs 0 if and only if the ﬁrst string precedes the second string in the lexicographic order. Equivalently, the comparator outputs ¯bi, where i is the index of the earliest occurrence 1 in the sequence b1 ⊕ p(1), . . . , bd ⊕ p(d), or 1 if the two strings are equal. Based on this observation, a circuit of depth Θ(log d) and size Θ(d) can be designed easily. Notice that the result of comparison is independent of the values of the strings beyond the point of divergence.

Brute Force Approach. Assume that we have nd independent unbiased bits b(ij), for 1 ≤ i ≤ n and 1 ≤ j ≤ d. To ﬂip n independent coins, each with its own bias pi, whose binary representation is 0.p(i1) . . . p(id), we run n comparators in parallel on inputs (b(11), . . . , b(1d), p(11), . . . , p(1d)), . . . , (b(n1), . . . , b(nd), p(n1), . . . , p(nd)).

Our goal is to get by with many fewer than nd unbiased input bits of the

brute force approach, since each of these requires an unbiased bit in shares.

Intuitively, we may hope to get away with this because, as mentioned previously,

the average number of bits consumed per output coin is 2, independent of the

bias of the coin. Let ci for 1 ≤ i ≤ n be the smallest index where b(ici) = p(ici),

and d + 1 if the two strings are equal. The number ci corresponds to the number

of bits “consumed” during computation of the ith coin. Let C =

n i=1

ci.

On

expectation E[C] = 2n, and except with a negligible probability C < 4n.

Rather than having the set {b(ij)}i,j be given as input (too many bits), we will compute the set {b(ij)}i,j from a much smaller set of input bits. The construction will ensure that the consumed bits are independent except with negligible probability. Let the number of input bits be D, to be chosen later.

We will construct the circuit probabilistically. Speciﬁcally, we begin by choosing nd binary vectors {ri(j)}i,j, 1 ≤ i ≤ n and 1 ≤ j ≤ d, uniformly from {0, 1}D to be hard-wired into the circuit. Let b ∈R {0, 1}D be the uniformly
chosen random input to the circuit.

The circuit computes the inner products of each of the hard-wired vectors ri(j) with the input b. Let b(ij) = ri(j), b denote the resulting bits. These are the {b(ij)}i,j we will plug into the brute force approach described above. Note that although much randomness was used in deﬁning the circuit, the input to the
circuit requires only D random bits.

Although the nd vectors are not linearly independent, very few of them – O(n) – are actually used in the computation of our coins, since with overwhelming probability only this many of the b(ij) are actually consumed. A straightforward counting argument therefore shows that the set of vectors actually used in generating consumed bits will be linearly independent, and so the coins will be mutually independent.

We claim that if D > 4C, then the consumed bits are going to be independent

with high probability. Conditional on the sequence c1, . . . , cn, the vectors ri(j) for

1 ≤ i ≤ n and 1 ≤ j ≤ ci are independent with probability at least 1 − C2C−D <

1 − 2−2C , where the probability space is the choice of the r’s. For ﬁxed C the

number of possible c1, . . . , cn is at most

C n

< 2C . Hence the probability that

for some C < 4n and some c1, . . . , cn, such that c1 + · · · + cn = C the vectors

ri(j) are linearly independent is at least than 1 − 4n2−C . Finally, we observe that

if the vectors are linearly independent, the bits b(ij) are independent as random

variables. The depth of this circuit is Θ(log D), which is the time it takes to

compute the inner product of two D-bit vectors. Its gate count is Θ(ndD),

which is clearly suboptimal.

Using low weight independent vectors: Our second solution dramatically decreases the number of gates by reducing the weight (the number of non-zero elements) of the vectors r from the expected value D/2 to s2 log(n+1) , where s is a small constant. To this end we adopt the construction from [12] that converts an expander-like graph into a set of linearly independent vectors.
The construction below requires a ﬁeld with at least nd non-zero elements. Let ν = log(nd + 1) . We use GF(2ν), representing its elements as ν-bit strings.
Consider a bipartite graph G of constant degree s connecting sets L = {u1, . . . , un}, where the u’s are distinct ﬁeld elements, and R = {1, . . . , ∆}. The degree s can be as small as 3. Deﬁne matrix M of size n × s∆ as follows: if (ui, τ ) ∈ G, the elements M [i][s(τ − 1), s(τ − 1) + 1, . . . , sτ − 1] = ui, u2i , . . . , usi , and (0, . . . , 0) (s zeros) otherwise. Thus, each row of the matrix has exactly s2 non-zero elements.
For any set S ⊆ L, let Γ (S) ⊆ R be the set of neighbors of S in G. The following claim is easily obtained from the proof of Lemma 5.1 in [12]. It says that if for a set of vertices T ∈ L all of T ’s subsets are suﬃciently expanding, then the rows of M corresponding to vertices in T are linearly independent.
Theorem 2. Let T ⊆ L be any set for which ∀S ⊆ T , |Γ (S)| > (1 − s+11 )|S|. Then the set of vectors {M [u] : u ∈ T } is linearly independent.
Consider a random bipartite graph with nd/ν elements in one class and 2C elements in the other. Associate the elements from the ﬁrst class with bits b(ij)’s, grouped in ν-tuples. Deﬁne the bits as the results of the inner product of the corresponding rows of the matrix M from above with the input vector of length 2s2C that consists of random elements from GF(2ν). Observe that the random graph G satisﬁes the condition of Theorem 2 for all sets of size less than C with high probability if C > (nd/ν)1/(s−1).
The depth of the resulting circuit is Θ(log(n + d)), the gate count is Θ(nds2 log(n + d)), and the size of the input is 2n log(n + d).
5 Generalizations
In this section we brieﬂy discuss several generalizations of the basic scheme.
5.1 Alternatives to Full Participation
The main idea is to use a set of facilitators, possibly a very small set, but one for which we are suﬃciently conﬁdent that fewer than one third of the members are faulty. Let F denote the set of facilitators. To respond to a query f , participant i shares f (i, di) among the facilitators, and takes no further part in the computation.
To generate the noise, each member of F essentially takes on the work of n/|F| participants. When |F| is small, the batch veriﬁcation technique of [3] may be employed to verify the secrets shared out by each of the players (that is, one batch veriﬁcation per member of F), although this technique requires

that the faulty players form a smaller fraction of the total than we have been assuming up to this point.
5.2 When f is Not a Predicate
Suppose we are evaluating f to k bits of precision, that is, k bits beyond the binary point. Let q be suﬃciently large, say, at least q > n2k. We will work in GF(q). Participant i will share out 2kf (i, di), one bit at a time. Each of these is checked for membership in {0, 1}GF(q). Then the shares of the most signiﬁcant bit are multiplied by 2k−1, shares of the next most signiﬁcant are multiplied by 2k−2 and so on, and the shares of the binary representation of f (i, di) are then summed. The noise generation procedure is ampliﬁed as well. Details omitted for lack of space.
5.3 Beyond Sums
We have avoided the case in which f is an arbitrary function mapping the entire database to a (tuple of) value(s), although the theory for this case has been developed in [13]. This is because without information about the structure of f we can only rely on general techniques for secure function evaluation of f , which may be prohibitively expensive.
One case in which we can do better is in the generation of privacy-preserving histograms. A histogram is speciﬁed by a partition of the domain Rows; the true response to the histogram query is the exact number of elements in the database residing in each of the cells of the histogram. Histograms are low sensitivity queries, in that changing a single row of the database changes the counts of at most two cells in the histogram, and each of these two counts changes by at most 1. Thus, as discussed in [13], -indistinguishable histograms may be obtained by adding exponential noise with R = 1/2 to each cell of the histogram. A separate execution of ODO for each cell solves the problem. The executions can be run concurrently. All participants in the histogram query must participate in each of the concurrent executions.
5.4 Individualized Privacy Policies
Suppose Citizen C has decided she is comfortable with a lifetime privacy loss of, say = 1. Privacy erosion is cumulative: any time C participates in the ODO protocol she incurs a privacy loss determined by R, the parameter used in noise generation. C has two options: if R is ﬁxed, she can limit the number of queries in which she participates, provided the decision whether or not to participate is independent of her data. If R is not ﬁxed in advance, but is chosen by consensus (in the social sense), she can propose large values of R, or to use large values of R for certain types of queries. Similarly, queries could be submitted with a stated value of R, and dataholders could choose to participate only if this value of R is acceptable to them for this type of query. However, the techniques will

all fail if the set of participants is more than one-third faulty; so the assumption must be that this bound will always be satisﬁed. This implicitly restricts the adversary.
6 Summary of Results
This work ties together two areas of research: the study of privacy-preserving statistical databases and that of cryptographic protocols. It was inspired by the combination of the computational power of the noisy sums primitive in the ﬁrst area and the simplicity of secure evaluation of sums in the second area. The eﬀect is to remove the assumption of a trusted collector of data, allowing individuals control over the handling of their own information.
In the course of this work we have developed distributed algorithms for generation of Binomial and Poisson noise in shares. The former makes novel use of extractors for bit-ﬁxing sources in order to reduce the number of secret sharings needed in generating massive numbers of coins. The latter examined for the ﬁrst time distributed coin-ﬂipping of coins with arbitrary bias.
References
1. D. Agrawal and C. Aggarwal. On the design and quantiﬁcation of privacy preserving data mining algorithms. In Proceedings of the 20th ACM SIGMODSIGACT-SIGART Symposium on Principles of Database Systems, pages 247–255, 2001.
2. R. Agrawal and R. Srikant. Privacy-preserving data mining. In Proceedings of the ACM SIGMOD International Conference on Management of Data, pages 439–450, May 2000.
3. M. Bellare, J. A. Garay, and T. Rabin. Distributed pseudo-random bit generators— a new way to speed-up shared coin tossing. In Proceedings of the 15th ACM Symposium on Principles of Distributed Computing, pages 191–200, 1996.
4. A. Blum, C. Dwork, F. McSherry, and K. Nissim. Practical privacy: The SuLQ framework. In Proceedings of the 24th ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, pages 128–138, June 2005.
5. S. Chawla, C. Dwork, F. McSherry, A. Smith, and H. Wee. Toward privacy in public databases. In Proceedings of the 2nd Theory of Cryptography Conference, pages 363–385, 2005.
6. S. Chawla, C. Dwork, F. McSherry, and K. Talwar. On the utility of privacypreserving histograms. In Proceedings of the 21st Conference on Uncertainty in Artiﬁcial Intelligence, 2005.
7. B. Chor, O. Goldreich, J. H˚astad, J. Friedman, S. Rudich, and R. Smolensky. The bit extraction problem of t-resilient functions. In Proceedings of the 26th IEEE Symposium on Foundations of Computer Science, pages 429–442, 1985.
8. B. Chor, S. Goldwasser, S. Micali, and B. Awerbuch. Veriﬁable secret sharing and achieving simultaneity in the presence of faults. In Proceedings of the 26th Annual IEEE Symposium on Foundations of Computer Science, pages 383–395, 1985.
9. A. Cohen and A. Wigderson. Dispersers, deterministic ampliﬁcation, and weak random sources. In Proceedings of the 30th Annual IEEE Symposium on Foundations of Computer Science, pages 14–19, 1989.

10. I. Damg˚ard, M. Fitzi, E. Kiltz, J.B. Nielsen, and T. Toft. Unconditionally secure constant-rounds multi-party computation for equality, comparison, bits and exponentiation. In Proceedings of the 3rd Theory of Cryptography Conference, pages 285–304, 2006.
11. I. Dinur and K. Nissim. Revealing information while preserving privacy. In Proceedings of the 22nd ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, pages 202–210, 2003.
12. C. Dwork, J. Lotspiech, and M. Naor. Digital signets for protection of digital information. In Proceedings of the 28th annual ACM symposium on Theory of computing, pages 489–498, 1996.
13. C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating noise to sensitivity in private data analysis. In Proceedings of the 3rd Theory of Cryptography Conference, pages 265–284, 2006.
14. C. Dwork and K. Nissim. Privacy-preserving datamining on vertically partitioned databases. In Advances in Cryptology: Proceedings of Crypto, pages 528–544, 2004.
15. A. Evﬁmievski, J. Gehrke, and R. Srikant. Limiting privacy breaches in privacy preserving data mining. In Proceedings of the 22nd ACM SIGMOD-SIGACTSIGART Symposium on Principles of Database Systems, pages 211–222, June 2003.
16. Ariel Gabizon, Ran Raz, and Ronen Shaltiel. Deterministic extractors for bitﬁxing sources by obtaining an independent seed. In Proceedings of the 45th IEEE Symposium on Foundations of Computer Science, pages 394–403, 2004.
17. O. Goldreich, S. Micali, and A. Wigderson. How to play any mental game or A completeness theorem for protocols with honest majority. In Proceedings of the 19th Annual ACM Symposium on Theory of Computing, pages 218–229, 1987.
18. Oded Goldreich. Foundations of Cryptography - Basic Applications, volume 2. Cambridge University Press, 2004.
19. J. Kamp and D. Zuckerman. Deterministic extractors for bit-ﬁxing sources and exposure-resilient cryptography. In Proceedings of the 44th Annual IEEE Symposium on Foundations of Computer Science, pages 92–101, 2003.
20. L. Lamport, R. Shostak, and M. Pease. The Byzantine generals problem. ACM Transactions on Programming Languages and Systems, 4(3):382–401, 1982.
21. N. Nisan and D. Zuckerman. Randomness is linear in space. J. Comput. Syst. Sci., 52(1):43–52, 1996.
22. Michael O. Rabin. Randomized Byzantine generals. In Proceedings of the 24th IEEE Symposium on Foundations of Computer Science, pages 403–409, 1983.
23. Ronen Shaltiel. Recent developments in explicit constructions of extractors. Bulletin of the EATCS, 77:67–95, 2002.
24. L. Trevisan and S. Vadhan. Extracting randomness from samplable distributions. In Proceedings of the 41st Annual IEEE Symposium on Foundations of Computer Science, pages 32–42, 2000.
25. A. Yao. Protocols for secure computations (extended abstract). In Proceedings of the 23rd IEEE Symposium on Foundations of Computer Science, pages 160–164, 1982.

