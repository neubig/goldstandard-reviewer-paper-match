Local Nash Equilibria are Isolated, Strict Local Nash Equilibria in ‘Almost All’ Zero-Sum Continuous Games
Eric Mazumdar1 and Lillian J. Ratliff2

arXiv:2002.01007v1 [cs.GT] 3 Feb 2020

Abstract— We prove that differential Nash equilibria are generic amongst local Nash equilibria in continuous zerosum games. That is, there exists an open-dense subset of zero-sum games for which local Nash equilibria are nondegenerate differential Nash equilibria. The result extends previous results to the zero-sum setting, where we obtain even stronger results; in particular, we show that local Nash equilibria are generically hyperbolic critical points. We further show that differential Nash equilibria of zero-sum games are structurally stable. The purpose for presenting these extensions is the recent renewed interest in zero-sum games within machine learning and optimization. Adversarial learning and generative adversarial network approaches are touted to be more robust than the alternative. Zero-sum games are at the heart of such approaches. Many works proceed under the assumption of hyperbolicity of critical points. Our results justify this assumption by showing ‘almost all’ zero-sum games admit local Nash equilibria that are hyperbolic.

I. INTRODUCTION

With machine learning algorithms increasingly being placed in more complex, real world settings, there has been a renewed interest in continuous games [1]–[3], and particularly zero-sum continuous games [4]–[7]. Adversarial learning [8], [9], robust reinforcement learning [10], [11], and generative adversarial networks [6] all make use of zerosum games played on highly non-convex functions to achieve remarkable results.
Though progress is being made, a theoretical understanding of the equilibria of such games is lacking. In particular, many of the approaches to learning equilibria in these machine learning applications are gradient-based. For instance, consider an adversarial learning setting where the goal is to learn a model or network by optimizing a function f ∈ Cr(Θ × W, R) over θ ∈ Θ where w ∈ W is chosen by an adversary. A general approach to this problem is to study the coupled learning dynamics that arise when one player is descending f and the other is ascending it—e.g.,

θ+

θ − γDθf (θ, w)

w+ = w + ηDwf (θ, w) .

Most convergence analysis depends on an assumption of local convexity in the game space around an equilibrium— that is, nearby Nash equilibria the Jacobian of the gradientbased learning rule is assumed to be locally positive deﬁnite. Indeed, with respect to the above example, in consideration

1Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Berkeley, CA. email:
mazumdar@berkeley.edu 2Department of Electrical and Computer Engineering, University of
Washington, Seattle, WA. email: ratliffl@uw.edu

of the limiting dynamics x˙ = −ω(x) where x = (θ, w) and ω(x) = (Dθf (x), −Dwf (x)), many of the convergence guarantees in this setting proceed under the assumption that around critical points, the Jacobian
J (θ, w) = Dθ2f (θ, w) Dθwf (θ, w) −Dwθf (θ, w) −Dw2 f (θ, w)
is positive deﬁnite—i.e., there is some notion of local convexity in the game space. Given the structural assumptions often invoked in the analysis of these learning approaches, two questions naturally arise:
• Is this a ‘robust’ assumption in the sense of structural stability—i.e., does the property persist under smooth perturbations to the game?;
• Is this assumption satisﬁed for ‘almost all zero-sum games’ in the sense of genericity?
Building on the work in [12]–[14], this paper addresses these two questions.
Towards this end, we leverage a reﬁnement of the local Nash equilibrium concept that deﬁnes an equilibrium in terms of the ﬁrst- and second-order optimality conditions for each player holding all other players ﬁxed. This reﬁnement has implicitly in its deﬁnition this notion of local convexity in the game space; it also has a structure that is particularly amenable to computation and which can be exploited in learning since it is characterized in terms of local information. Efforts to show this reﬁnement is both structurally stable and generic aid in justifying its broad use.
A. Contributions
The contributions are summarized as follows: a. We prove that differential Nash equilibria—a reﬁnement of local Nash equilibria deﬁned in terms of ﬁrst- and second-order conditions which characterize local optimality for players—are generic amongst local Nash equilibria in continuous zero-sum games (Theorem 2). This implies that almost all zero-sum games played on continuous functions admit local Nash equilibria that are strict and isolated. b. Exploiting the underlying structure of zero-sum game— i.e., the game is deﬁned in terms of a single sufﬁciently smooth cost function—we show that all differential Nash equilibria are hyperbolic (Proposition 3), meaning they are locally exponentially attracting for gradient-play. Combining this fact with the above, we also show that local Nash equilibria are generically hyperbolic (Corollary 1). c. We prove that zero-sum games are structurally stable (Theorem 3); that is, the structure of the game—and hence,

its equilibria—is robust to smooth perturbations within the space of zero-sum games.
In [12]–[14], similar results to a. and c. were shown for the larger class of general-sum continuous games. Yet, the set of zero-sum games is of zero measure in the space of generalsum continuous games, and hence, the results of this paper are not a direct implication of those results. Further, b. is a much stronger statement than the genericity result in [13]. In particular, [13] shows that non-degenerate differential Nash equilibria are generic amongst local Nash equilibria. We, on the other hand, show that in the class of zero-sum games, all differential Nash equilibria are non-degenerate, and moreover, hyperbolic. The latter is a particularly strong result, achievable due to the speciﬁc structure of the zero-sum game. Indeed, two-player zero-sum continuous games are deﬁned completely in terms of a single sufﬁciently smooth function—i.e., given f ∈ Cr(X, R), the corresponding zerosum game is (f, −f ).
Moreover, the work in this paper focuses on a class of games of particular import to the machine learning and robust control communities, where many recent works have made the assumption of hyperbolicity of local Nash equilibria without a thorough understanding of whether or not such an assumption is restrictive (see e.g. [7], [15]–[18]). The results in this paper show that this assumption simply rules out a measure zero set of zero-sum games.
II. PRELIMINARIES
Before developing the main results, we present our general setup, as well as some preliminary game theoretic and mathematical deﬁnitions. Additional mathematical preliminaries are included in Appendix A.
A. Preliminary Deﬁnitions
In this paper, we consider full information continuous, two-player zero-sum games. We use the term ‘player’ and ‘agent’ interchangeably. Each player i ∈ I = {1, 2} selects an action xi from a topological space Xi in order to minimize its cost fi : X → R where X = X1 × X2 is the joint strategy space of all the agents. Note that fi depends on x−i which is the collection of actions of all other agents excluding agent i—that is, fi : (xi, x−i) → fi(xi, x−i) ∈ R. Furthermore, each Xi can be ﬁnite-dimensional smooth manifolds or inﬁnite-dimensional Banach manifolds. Each player’s cost function fi is assumed to be sufﬁciently smooth.
A two-player zero-sum game is characterized by a cost function f ∈ Cr(X, R) in the sense that the ﬁrst player aims to minimize f with respect to x1 and the second player aims to maximize f with respect to x2—that is, f1 ≡ f and f2 ≡ −f . Hence, given a function f , we denote a two-player zero-sum game by (f, −f ) where f ∈ Cr(X, R).
As is common in the study of games, we adopt the Nash equilibrium concept to characterize the interaction between agents.
Deﬁnition 1. A strategy x = (x1, x2) ∈ X is a local Nash equilibrium for the game (f1, f2) = (f, −f ) if for each i ∈ I

there exists an open set Wi ⊂ Xi such that xi ∈ Wi and

fi(xi, x−i) ≤ fi(xi, x−i), ∀ xi ∈ Wi\{xi}.

If the above inequalities are strict, then we say (x1, x2) is a strict local Nash equilibrium. If Wi = Xi for each i, then (x1, x2) is a global Nash equilibrium.
In [12] and subsequent works [13], [14], a reﬁnement of the local Nash equilibrium concept known as a differential Nash equilibrium was introduced. This reﬁnement characterizes local Nash in terms of ﬁrst- and second-order conditions on player cost functions, and even in the more general nonconvex setting, a differential Nash equilibrium was shown to be well-deﬁned and independent of the choice of coordinates on X. Moreover, for general sum games, differential Nash were shown to be generic and structurally stable in n-player games.
Towards deﬁning the differential Nash concept, we introduce the following mathematical object. A differential game form is a differential 1-form ω : X → T ∗X deﬁned by

ω = ψX1 ◦ df − ψX2 ◦ df

where ψXi are the natural bundle maps ψX1 : T ∗X → T ∗X that annihilate those components of the co-vector ﬁeld df
corresponding to X1 and analogously for ψX2 . Note that when each Xi is a ﬁnite dimensional manifold of dimensions mi (e.g., Euclidean space Rmi ), then the differential game
form has the coordinate representation,

ωψ =

m j=11 ∂(f∂◦yψj−1) dy1j + 1

m j=21 ∂(−∂f y◦ψj −1) dy2j , 2

for product chart (U, ψ) in X at x = (x1, . . . , xn) with local

coordinates

(y

1 1

,

.

.

.

,

y

m1 1

,

y21

,

.

.

.

,

y

m2 2

)

and

where

U

=

U1 ×

U2 and ψ = ψ1 × ψ2. The differential game form captures

a differential view of the strategic interaction between the

players. Note that each player’s cost function depends on its

own choice variable as well as all the other players choice

variables. However, each player can only affect their payoff

by adjusting their own strategy.

Critical points for the game can be characterized by the

differential game form.

Deﬁnition 2. A point x ∈ X is said to be a critical point for the game if ω(x) = 0.

In the single agent case (i.e., optimization of a single cost function), critical points can be further classiﬁed as local minima, local maxima, or saddles by looking at second-order conditions. Analogous concepts exist for continuous games.
Proposition 1 (Proposition 2 [12]). If x ∈ X is a local Nash equilibrium for (f1, f2) = (f, −f ), then ω(x) = 0 and Di2fi(x) ≥ 0 for all i ∈ I.
These are necessary conditions for a local Nash equilibrium. There are also sufﬁcient conditions for Nash equilibria. Such sufﬁcient conditions deﬁne differential Nash equilibria [13], [14].

Deﬁnition 3. A strategy x ∈ X is a differential Nash equilibrium for (f1, f2) = (f, −f ) if ω(x) = 0 and Di2fi(x) is positive–deﬁnite for each i ∈ I.
Differential Nash need not be isolated. However, if dω(x) is non-degenerate for x a differential Nash, where dω = d(ψX1 ◦ df ) − d(ψX2 ◦ df ), then x is an isolated strict local Nash equilibrium. Intrinsically, dω ∈ T20(X) is a tensor ﬁeld; at a point x where ω(x) = 0, it determines a bilinear form constructed from the uniquely determined continuous, symmetric, bilinear forms {d2fi(x)}ni=1. We use the notation Dω to denote the bilinear map induced by dω which is composed of the partial derivatives of components of ω. For example, consider a two-player, zero-sum game (f1, f2) = (f, −f ). Then, via a slight abuse of notation, the matrix representation of this bilinear map is given by
Dω(x) = D12f (x) D12f (x) . −D1T2f (x) −D22f (x)
The following deﬁnitions are pertinent to our study of genericity and structural stability of differential Nash equilibria; there are analogous concepts in dynamical systems [19].
Deﬁnition 4. A critical point x is non-degenerate if det(Dω(x)) = 0 (i.e. x is isolated).
Non-degenerate differential Nash are strictly isolated local Nash equilibria [14, Theorem 2].
Deﬁnition 5. A critical point x is hyperbolic if Dω(x) has no eigenvalues with zero real part.
All hyperbolic critical points are non-degenerate, but not all non-degenerate critical points are hyperbolic. Hyperbolic critical points are of particular importance from the point of view of convergence, were they have local guarantees of exponential stability or instability [20]. We note that even in the more general manifold setting, these deﬁnitions are invariant with respect to the coordinate chart [14], [19].
B. Mathematical Preliminaries
In order to prove genericity of non-degenerate differential Nash, we now introduce the necessary mathematical preliminaries.
Consider smooth manifolds X and Y of dimension nx and ny respectively. An k–jet from X to Y is an equivalence class [x, f, U ]k of triples (x, f, U ) where U ⊂ X is an open set, x ∈ U , and f : U → Y is a Ck map. The equivalence relation satisﬁes [x, f, U ]k = [y, g, V ]k if x = y and in some pair of charts adapted to f at x, f and g have the same derivatives up to order k. We use the notation [x, f, U ]k = jkf (x) to denote the k–jet of f at x. The set of all k– jets from X to Y is denoted by Jk(X, Y ). The jet bundle Jk(X, Y ) is a smooth manifold (see [21] Chapter 2 for the construction). For each Ck map f : X → Y we deﬁne a map jkf : X → Jk(X, Y ) by x → jkf (x) and refer to it as the k–jet extension.
Deﬁnition 6. Let X, Y be smooth manifolds and f : X → Y be a smooth mapping. Let Z be a smooth submanifold of Y

and p a point in X. Then f intersects Z transversally at p (denoted f Z at p) if either f (p) ∈/ Z or f (p) ∈ Z and Tf(p)Y = Tf(p)Z + (f∗)p(TpX).
For 1 ≤ k < s ≤ ∞ consider the jet map jk : Cs(X, Y ) → Cs−k(X, J k(X, Y )) and let Z ⊂ J k(X, Y ) be a submanifold. Deﬁne
| s(X, Y ; jk, Z) = {h ∈ Cs(X, Y )| jkh Z}. (1)
A subset of a topological space X is residual if it contains the intersection of countably many open–dense sets. We say a property is generic if the set of all points of X which possess this property is residual [19].
Theorem 1. (Jet Transversality Theorem, Chap. 2 [21]). Let X, Y be C∞ manifolds without boundary, and let Z ⊂ Jk(X, Y ) be a C∞ submanifold. Suppose that 1 ≤ k < s ≤ ∞. Then, | s(X, Y ; jk, Z) is residual and thus dense in Cs(X, Y ) endowed with the strong topology, and open if Z is closed.
Proposition 2. (Chap. II.4, Proposition 4.2 [22]). Let X, Y be smooth manifolds and Z ⊂ Y a submanifold. Suppose that dim X < codimZ. Let f : X → Y be smooth and suppose that f Z. Then, f (X) ∩ Z = ∅.
The Jet Transversality Theorem and Proposition 2 can be used to show a subset of a jet bundle having a particular set of desired properties is generic. Indeed, consider the jet bundle Jk(X, Y ) and recall that it is a manifold that contains jets jkf : X → Jk(X, Y ) as its elements where f ∈ Ck(X, Y ). Let Z ⊂ Jk(X, Y ) be the submanifold of the jet bundle that does not possess the desired properties. If dim X < codim Z, then for a generic function f ∈ Ck(X, Y ) the image of the k–jet extension is disjoint from Z implying that there is an open–dense set of functions having the desired properties. It is exactly this approach we use to show the genericity of non-degenerate differential Nash equilibria of zero-sum continuous games.
III. THEORETICAL RESULTS
In this section, we specialize the results in [12] and [14] on genericity and structural stability of differential Nash equilibria to the class of zero-sum games.
A. Genericity
To develop the proof that local Nash equilibria of zerosum games are generically non-degenerate differential Nash equilibria, we leverage the fact that it is a generic property of sufﬁciently smooth functions that all critical points are non-degenerate.
Lemma 1 ( [19, Chapter 1]). For Cr functions, r ≥ 2 on Rn, or on a manifold, it is a generic property that all the critical points are non-degenerate.
The above lemma implies that for a generic function f ∈

Cr(X, R) on an m–dimensional manifold X, the Hessian
 D12f (x) · · · D1mf (x) H(x) =  ... . . . ... 
Dm1f (x) · · · Dm2 f (x)
is non-degenerate at critical points—that is, det(H(x)) = 0.
Lemma 2. Consider f ∈ Cr(X, R) and the zero-sum game (f, −f ). For any critical point x ∈ X (i.e., x ∈ {x ∈ X| ω(x) = 0}), det(H(x)) = 0 ⇐⇒ det(Dω(x)) = 0.

Proof: Before proceeding we note that in the case that X is a smooth manifold, the stationarity of critical points and deﬁniteness of H and Dω are coordinate-invariant properties and hence, independent of coordinate chart [12]–[14], [19]. Thus, to shorten the presentation of proofs, we simply treat the Euclidean case here; showing the more general case simply requires selecting a coordinate chart deﬁned on a neighborhood of the differential Nash, showing the results with respect to this chart, and then invoking coordinate invariance.
Let x = (x1, x2) where X = X1 × X2 and Xi is mi– dimensional. Note that H(x) is equal to Dω(x) with the last m2 rows scaled each by −1. Indeed,
Dω(x) = D12f (x) D12f (x) −D1T2f (x) −D22f (x)
where Di2f (x) is mi × mi dimensional for each i ∈ {1, 2} and D12f (x) is m1 × m2 dimensional. Clearly, Dω(x) = P H(x) where P = blockdiag(Im1 , −Im2 ) with each Imi the mi × mi identity matrix, so that det(H(x)) = (−1)m2 det(Dω(x)). Hence, the result holds.
This equivalence between the non-degeneracy of the Hessian and the game Jacobian Dω allows us to lift the fact that non-degeneracy of critical points is a generic property to zero-sum games.

Proposition 3. Consider a two-player, zero-sum continuous game (f, −f ) deﬁned for f ∈ Cr(X, R) with r ≥ 2. A differential Nash equilibrium is non-degenerate, and furthermore,
it is hyperbolic.

Proof: It is enough to show that all differential Nash are hyperbolic since all hyperbolic equilibria correspond to a non-degenerate Dω. Further, just as we noted in the proof of Lemma 2, stationarity, deﬁniteness, and non-degeneracy are coordinate-invariant properties. Thus, we simply treat the Euclidean case here.
By deﬁnition, at a differential Nash equilibrium x of a zero-sum game, ω(x) = 0, D12f (x) > 0, and −D22f (x) > 0. Further, in zero-sum games, D122f = (D221f )T . Thus, the bilinear map Dω, takes the form

Dω(x) = =

D12f (x) −D21f (x)
D12f (x) −D1T2f (x)

D12f (x) −D22f (x)
D12f (x) . −D22f (x)

Let (λ, v) be an eigenpair of Dω(x). The real part of λ, denoted Re(λ), can be written as

Re(λ) = 12 (λ + λ¯) = 12 (v∗DωT (x)v + v∗Dω(x)v)

= 12 v∗(DωT (x) + Dω(x))v

= 1 v∗ D12f (x)

0 v>0

2

0

−D22f (x)

where the last line follows from the positive deﬁniteness of diag(D12f (x), −D22f (x)) at a differential Nash equilibrium. Hence, x is hyperbolic and, clearly, at this point det(Dω(x)) = 0.
The above proposition provides a strong result for the class of zero-sum games. In particular, simply due to the structure of Dω, all differential Nash have the nice property of being hyperbolic, and hence, exponentially attracting under gradient-play dynamics—that is, x˙ = −ω(x) or its discrete time variant x+ = x − γω(x) for appropriately chosen stepsize γ. Note that numerous learning algorithms in machine learning applications of zero-sum games take this form (see, e.g., [3], [4], [6]).

Theorem 2. For two-player, zero-sum continuous games, non-degenerate differential Nash are generic amongst local Nash equilibria. That is, given a generic f ∈ Cr(X, R), all local Nash equilibria of the game (f, −f ) are (nondegenerate) differential Nash equilibria.

Proof: First, critical points of a function f are those such that (D1f1(x) D2f2(x)) = 0 and hence they coincide with critical points of the zero-sum game—i.e., those points x such that ω(x) = (D1f (x), −D2f (x)) = 0. By Lemma 2, for any critical point x, det(H(x)) = 0 if and only if det(Dω(x)) = 0. Hence, critical points of f are non-
degenerate if and only if critical points of the zero-sum game
are non-degenerate. Consider a generic function f and the corresponding zero-
sum game (f, −f ). If X is a smooth manifold, let (U, ϕ) be a product chart on X1 × X2 that contains x. Suppose that x is a local Nash equilibrium so that ω(x) = 0 and D12f (x) ≥ 0 and −D22f (x) ≥ 0. By the above argument, since f is generic and the critical points of f coincide with those of the zero-sum game, det(Dω(x)) = 0. By Lemma 1, critical
points of a generic zero-sum game are non-degenerate. That is, there exists an open-dense set of functions f in Cr(X, R) such that critical points of the corresponding game are non-
degenerate. Let J2(X, R) denote the second-order jet bundle contain-
ing 2–jets j2f such that f : X → R. Then, J2(X, R) is locally diffeomorphic to

Rm

×

R

×

Rm

×

m(m+1)
R2

and the 2–jet extension of f at any point x ∈ X in coordinates is given by

(ϕ(x), (f ◦ ϕ−1)(ϕ(x)), Dϕf (x), (Dϕ)2f (x)) where Dϕf = [D1ϕf D2ϕf ] with Djϕ = [∂(f ◦ ϕ−1)/(∂yj1) · · · ∂(f ◦ ϕ−1)/(∂yjmi )] and similarly for

(Dϕ)2f . Again, we note that the properties of interest (stationarity, deﬁniteness, and non-degeneracy) are known to be coordinate invariant.
Consider a subset of J2(X, R) deﬁned by
D = Rm × R × {0m} × Z(m1) × Rm1×m2 × Z(m2)
where Z(mi) is the subset of symmetric mi × mi matrices such that for A ∈ Z(mi), det(A) = 0. Each Z(mi) is algebraic and has no interior points; hence, we can use the Whitney stratiﬁcation theorem [23, Chapter 1, Theorem 2.7] to get that each Z(mi) is the union of submanifolds of codimension at least 1. Hence D is the union of submanifolds and has co-dimension at least m + 2. Applying the Jet Transversality Theorem (Theorem 1) and Proposition 2 yields an open-dense set of functions f such that when ω(x) = 0, det(Di2f (x)) = 0, for i = 1, 2.
Now, the intersection of two open-dense sets is open-dense so that we have an open-dense set of functions f in Cr(X, R) such that when ω(x) = 0, det(Di2f (x)) = 0 for each i ∈ {1, 2} and det(Dω(x)) = 0. This, in turn, implies that there is an open-dense set F of functions f in Cr(X, R) such that for zero-sum games constructed from these functions, local Nash equilibria are non-degenerate differential Nash equilibria. Indeed, consider an f ∈ F in this set such that x is a local Nash equilibrium of (f, −f ). Then necessary conditions for Nash imply that ω(x) = 0, D12f (x) ≥ 0 and −D22f (x) ≥ 0. However, since f ∈ F , det(D12f (x)) = 0 and det(−D22f (x)) = (−1)m2 det(D22f (x)) = 0. Hence, x is a differential Nash equilibrium. Moreover, since f ∈ F, det(H(x)) = 0 which is equivalent to det(Dω(x)) = 0 (by Lemma 2). Thus, x is a non-degenerate differential Nash.
As shown in Proposition 3, all differential Nash for zerosum games are non-degenerate simply by the structure of Dω. This further implies that local Nash equilibria are generically hyperbolic critical points, meaning there are no eigenvalues of Dω with zero real part.
Corollary 1. Within the class of two-player zero-sum continuous games, local Nash equilibria are generically hyperbolic critical points.
Proof: Consider a two-player, zero-sum game (f, −f ) for some generic sufﬁciently smooth f ∈ Cr(X, R). Then, by Theorem 2, a local Nash equilibria x is a differential Nash equilibria. Moreover, by Proposition 3, x is hyperbolic so that all eigenvalues of Dω(x) must have strictly positive real parts. This implies that all such points are hyperbolic critical points of the gradient dynamics x˙ = −ω(x).
B. Structural Stability
Genericity gives a formal mathematical sense of ’almost all’ for a certain property—in this case, non-degeneracy and further hyperbolic. In addition, we show that (nondegenerate) differential Nash are structurally stable, meaning that they persist under smooth perturbations within the class of zero-sum games.
Theorem 3. For zero-sum games, differential Nash equilibria are structurally stable: given f ∈ Cr(X1 × X2, R),

g ∈ Cr(X1 × X2, R), and a differential Nash equilibrium (x1, x2) ∈ X1 × X2, there exists a neighborhoods U ⊂ R of zero and V ⊂ X1 × X2 such that for all t ∈ U there exists a unique differential Nash equilibrium (x˜1, x˜2) ∈ V for the zero-sum game (f + tg, −f − tg).
Proof: Deﬁne the smoothly perturbed cost function f˜ : X1 × X2 × R → R by f˜(x, y, t) = f (x, y) + tg(x, y), and its differential game form ω˜ : X1 × X2 × R → T ∗(X1 × X2) by
ω˜(x, y, t) = (D1(f˜(x, y)+tg(x, y), −D2(f˜(x, y)+tg(x, y)),
for all t ∈ R and (x, y) ∈ X1 × X2. Since (x1, x2) is a differential Nash equilibrium,
Dω˜(x, y, 0) is necessarily non-degenerate (see the proof of Corollary 1). Invoking the implicit function theorem [24], there exists neighborhoods V ⊂ R of zero and W ⊂ X1×X2 and a smooth function σ ∈ Cr(V, W ) such that for all t ∈ V and (x1, x2) ∈ W ,
ω˜(x1, x2, s) = 0 ⇐⇒ (x1, x2) = σ(t).
Since ω˜ is continuously differentiable, there exists a neighborhood U ⊂ W of zero such that Dω˜(σ(t), t) is invertible for all t ∈ U . Thus, for all t ∈ U , σ(t) must be the unique Nash equilibrium of (f + tg|W , −f − tg|W ). We note that both the genericity and structural stability results follow largely from the fact that the class of twoplayer zero-sum games are deﬁned completely in terms of a single (sufﬁciently) smooth function f ∈ Cr(X, R), so that its fairly straightforward to lift the properties of genericity and structural stability to the class of zero-sum games from the class of smooth functions. We also remark that the perturbations considered here are those such that the game remains in the class of zero-sum games; that is, the function f is smoothly perturbed and this induces the perturbed zero sum game (f + tg, −f − tg).
IV. EXAMPLES
To illustrate the implications of structural stability, we provide a simple example. Consider a classic set of zerosum continuous games known as biliear games. Such games have similar characteristics as bimatrix games played on the simplex; in particular, bimatrix games have the same cost structure as bilinear games where the stratgegy space of the former is considered to be a probability distribution over the ﬁnite set of pure strategies. This is particularly interesting since it demonstrates that interior equilibria of such games can be altered arbitrarily small perturbations.
Example 1. Consider two-players with decision variables x ∈ Rdx and y ∈ Rdy respectively, playing a zero-sum game on the function:
f (x, y) = xT Ay
Where A ∈ Rdx×dy . The x player would like to minimize f while the y player would like to maximize it. Looking at ω for this game, we can see that the local Nash equilibria

live in N (A) × N (AT ), where N (A) and N (AT ) denote the nullspaces of A and AT respectively:

Ay ω(x, y) = −AT x

We note that the local Nash equilibria are not differential
Nash equilibria, and that Dω has purely imaginary eigen-
values everywhere since it is skew-symmetric. Thus the local
Nash equilibria are non-hyperbolic and this a non-generic case. Letting f = f (x, y) − 2 ||x||2, we see that ω for this perturbed game (denoted ω ) has the form:

Ay − x ω (x, y) = −AT x

This perturbation fundamentally changes the critical points, and looking at Dω , we can see that for any > 0, there are no more local Nash equilibria:

Dω (0, 0) = −−AIdTx A0

Since any arbitrarily small perturbation of this form can cause all of the local Nash equilibria to change, these games cannot be structurally stable.

We now show how this behavior extends to more complicated settings. Speciﬁcally we present an example of a game of rock-paper-scissors where both players have stochastic policies over the three actions which are parametrized by weights. The following example highlights how this classic problem is non-generic and the behavior changes drastically when the loss is perturbed in a small way.

Example 2. Consider the game of rock-paper-scissors where each player has three actions {0, 1, 2}, with payoff matrix:
 0 −1 1  M =  1 0 −1
−1 1 0

Each player i ∈ {1, 2} has a policy or mixed strategy πi parametrized by a set of weights {wij}j∈{0,1,2} of the form:

πi(j) =

exp(−βi wij )

2 k=0

exp(−βi

wij

)

Where βi is a hyper-parameter for player i that determines the ’greediness’ of their policy with respect to their set of weights. For simplicity, we treat πi as a vector in R3. Each player would like to maximize their expected reward given
by f (w1, w2) = π1T M π2.

We note that there is a continuum of local Nash equilibria for the policies πi = [ 13 , 13 , 13 ] for i ∈ {1, 2} and that this is achieved whenever each player has all of their weights
equal.

In Fig. 1 we show the trajectories of the policy of player 1, when β1 = β2 = 1 and both players use gradient descent to update their weights at each iteration. In Figure 1A. we see that player 1 cycles around the local Nash equilibrium

Fig. 1: The trajectory of the policy of player 1 under gradient-
play for A. rock-paper scissors and B. a perturbed version of
rock-paper-scissors. A. Player 1 cycles around the local Nash equilibrium of ( 13 , 13 , 13 ) from either initialization (shown with circles). We remark that player 1’s time average policy is in fact ( 13 , 13 , 13 ). B. Player 1 diverges from the local Nash equilibrium from either initialization for the perturbed game
given by (2).

in policy space. In Figure 1B. we show the trajectories of the policy of player 1, starting from the same initializations, but for a perturbed version of the game deﬁned by

f

(w1, w2)

=

π

T 1

M

π

2

+

g(w1, w2)

(2)

where = 1e-3 and g(x, y) = ||y||2 − ||x||2. Here we can see that this relatively small perturbation causes a drastic change in the behavior where player 1 diverges from the Nash of the original game and converges to the sub-optimal policy of always playing action zero.

V. DISCUSSION AND CONCLUDING REMARKS
The focus of this paper is on the genericity and structural stability of a particular reﬁnement of the local Nash equilibrium concept—namely, differential Nash equilibria— within the class of two-player, zero-sum continuous games. The renewed interest in zero-sum games on continuous action spaces is primarily due to the widespread adoption of game theoretic tools in areas such as robust reinforcement learning and adversarial learning including generative adversarial networks. For instance, zero-sum continuous game abstractions have shown to be particularly adept at learning robust policies for a wide-variety of tasks from classiﬁcation to prediction to control.

Most learning approaches are based on local information such as gradient updates, and as such, representations of Nash equilibria that are amenable to computation such as the differential Nash concept are extremely relevant. Much of the existing convergence analysis for machine learning algorithms based on game-theoretic concepts proceeds under the structural assumptions implicit in the deﬁnition of the differential Nash equilibrium concept. In this paper, we show that characterizations such as these are generic and structurally stable; hence, the aforementioned structural assumptions only rule out a measure zero set of games, and the desired properties are robust to smooth perturbations in player costs.
APPENDIX
A. Additional Mathematical Preliminaries
In this appendix, we provide some additional mathematical preliminaries; the interested reader should see standard references for a more detailed introduction [24], [25].
A smooth manifold is a topological manifold with a smooth atlas. In particular, we use the term manifold generally; we specify whether it is a ﬁnite– or inﬁnite– dimensional manifold only when necessary. If a covering by charts takes their values in a Banach space E, then E is called the model space and we say that X is a Cr– Banach manifold. For a vector space E, we deﬁne the vector space of continuous (r + s)–multilinear maps Tsr(E) = Lr+s(E∗, . . . , E∗, E, . . . , E; R) with s copies of E and r copes of E∗ and where E∗ denotes the dual. Elements of Tsr(E) are tensors on E, and Tsr(X) denotes the vector bundle of such tensors [25, Deﬁnition 5.2.9].
Suppose f : X → M is a mapping of one manifold X into another M . Then, we can interpret the derivative of f on each chart at x as a linear mapping df (x) : TxX → Tf(x)M. When M = R, the collection of such maps deﬁnes a 1–form df : X → T ∗X. Indeed, a 1–form is a continuous map ω : X → T ∗X satisfying π ◦ ω = IdX where π : T ∗X → X is the natural projection mapping ω(x) ∈ Tx∗X to x ∈ X.
At a critical point x ∈ X (i.e., where df (x) = 0), there is a uniquely determined continuous, symmetric bilinear form d2f (x) ∈ T20(X) such that d2f (x) is deﬁned for all v, w ∈ TxX by d2(f ◦ ϕ−1)(ϕ(x))(vϕ, wϕ) where ϕ is any product chart at x and vϕ, wϕ are the local representations of v, w respectively [26, Proposition in §7]. We say d2f (x) is positive semi–deﬁnite if there exists α ≥ 0 such that for any chart ϕ,
d2(f ◦ ϕ−1)(ϕ(x))(v, v) ≥ α v 2, ∀ v ∈ Tϕ(x)E. (3)
If α > 0, then we say d2f (x) is positive–deﬁnite. Both critical points and positive deﬁniteness are invariant with respect to the choice of coordinate chart.
Consider smooth manifolds X1, X2. The product space X1 × X2 is naturally a smooth manifold [25, Deﬁnition 3.2.4]. There is a canonical isomorphism at each point such that the cotangent bundle of the product manifold splits:
T(∗x1,x2)(X1 × X2) ∼= Tx∗1 X1 ⊕ Tx∗2 X2 (4)

where ⊕ denotes the direct sum of vector spaces. There are natural bundle maps ψX1 : T ∗(X1 × X2) → T ∗(X1 × X2) annihilating the all the components other than those corresponding to Xi of an element in the cotangent bundle. In particular, ψX1 (ω1, ω2) = (01, ω2) and ψX2 (ω1, ω2) = (ω1, 02) where ω = (ω1, ω2) ∈ Tx∗(X1 × X2) and 0j ∈ Tx∗j Xj for each j ∈ {1, 2} is the zero functional.
REFERENCES
[1] P. Mertikopoulos and Z. Zhou, “Learning in games with continuous action sets and unknown payoff functions,” Mathematical Programming, vol. 173, no. 1–2, pp. 456–507, 2019.
[2] C. Zhang and V. Lesser, “Multi-agent learning with policy prediction,” in Proceedings of the Twenty-Fourth AAAI Conference on Artiﬁcial Intelligence, 2010, pp. 927–934.
[3] E. Mazumdar and L. J. Ratliff, “On the convergence of competitive, multi-agent gradient-based learning algorithms,” arxiv:1804.05464, 2018.
[4] E. Mazumdar, M. Jordan, and S. S. Sastry, “On ﬁnding local nash equilibria (and only local nash equilibria) in zero-sum games,” arxiv:1901.00838, 2019.
[5] C. Daskalakis, A. Ilyas, V. Syrgkanis, and H. Zeng, “Traning GANs with Optimism,” Proceedings of the International Conference on Learning and Representation, 2018.
[6] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial networks,” in Advances in Neural Information Processing Systems 27, Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, Eds. Curran Associates, Inc., 2014, pp. 2672–2680.
[7] C. Jin, P. Netrapalli, and M. I. Jordan, “Minmax optimization: Stable limit points of gradient descent ascent are locally optimal,” arxiv:1902.00618, 2019.
[8] C. Daskalakis, A. Ilyas, V. Syrgkanis, and H. Zeng, “Traning GANs with Optimism,” arxiv:1711.00141, 2017.
[9] P. Mertikopoulos, C. H. Papadimitriou, and G. Piliouras, “Cycles in adversarial regularized learning,” in roceedings of the 29th annual ACM-SIAM symposium on discrete algorithms, 2018.
[10] S. Li, Y. Wu, X. Cui, H. Dong, F. Fang, and S. Russell, “Robust multiagent reinforcement learning via minimax deep deterministic policy gradient,” in Proceedings of the AAAI Conference, 2019.
[11] L. Pint, J. Davidson, R. Sukthankar, and A. Gupta, “Robust adversarial reinforcement learning,” in Proceedings of the International Conference on Machine Learning, 2017.
[12] L. J. Ratliff, S. A. Burden, and S. S. Sastry, “Characterization and computation of local Nash equilibria in continuous games,” in Proc. 51st Annual Allerton Conf. Communication, Control, and Computing, 2013, pp. 917–924.
[13] L. J. Ratliff, S. A. Burden, and S. S. Sastry, “Generictiy and Structural Stability of Non–Degenerate Differential Nash Equilibria,” in Proc. 2014 Amer. Controls Conf., 2014.
[14] ——, “On the Characterization of Local Nash Equilibria in Continuous Games,” IEEE Transactions on Automatic Control, vol. 61, no. 8, pp. 2301–2307, 2016.
[15] C. Daskalakis and I. Panageas, “The limit points of (optimistic) gradient descent in min-max optimization,” in NeurIPS, 2018.
[16] D. Balduzzi, S. Racaniere, J. Martens, J. Foerster, K. Tuyls, and T. Graepel, “The mechanics of n-player differentiable games,” CoRR, vol. abs/1802.05642, 2018. [Online]. Available: http://arxiv.org/abs/ 1802.05642
[17] A. He´liou, J. Cohen, and P. Mertikopoulos, “Learning with bandit feedback in potential games,” in NIPS, 2017.
[18] G. Gidel, H. Berard, P. Vincent, and S. Lacoste-Julien, “A variational inequality perspective on generative adversarial nets,” CoRR, vol. abs/1802.10551, 2018.
[19] H. Broer and F. Takens, “Chapter 1 - preliminaries of dynamical systems theory,” in Handbook of Dynamical Systems, ser. Handbook of Dynamical Systems, F. T. Henk Broer and B. Hasselblatt, Eds. Elsevier Science, 2010, vol. 3, pp. 1 – 42.
[20] S. S. Sastry, Nonlinear Systems. Springer, 1999. [21] M. W. Hirsch, Differential topology. Springer New York, 1976. [22] M. Golubitsky and V. Guillemin, Stable Mappings and Their Singu-
larities. Springer-Verlag, 1973.

[23] C. G. Gibson, K. Wirthmu¨ller, A. A. du Plessis, and E. J. N. Looijenga, “Topological stability of smooth mappings,” in Lecture Notes in Mathematics. Springer-Verlag, 1976, vol. 552.
[24] J. Lee, Introduction to smooth manifolds. Springer, 2012. [25] R. Abraham, J. E. Marsden, and T. Ratiu, Manifolds, Tensor Analysis,
and Applications, 2nd ed. Springer, 1988. [26] R. S. Palais, “Morse theory on Hilbert manifolds,” Topology, vol. 2,
no. 4, pp. 299–340, 1963.

