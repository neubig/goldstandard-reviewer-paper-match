{"title": "Programming with personalized pagerank: a locally groundable first-order probabilistic logic", "abstract": "Many information-management tasks (including classification, retrieval, information extraction, and information integration) can be formalized as inference in an appropriate probabilistic first-order logic. However, most probabilistic first-order logics are not efficient enough for realistically-sized instances of these tasks. One key problem is that queries are typically answered by \"grounding\" the query---i.e., mapping it to a propositional representation, and then performing propositional inference---and with a large database of facts, groundings can be very large, making inference and learning computationally expensive. Here we present a first-order probabilistic language which is well-suited to approximate \"local\" grounding: in particular, every query $Q$ can be approximately grounded with a small graph. The language is an extension of stochastic logic programs where inference is performed by a variant of personalized PageRank. Experimentally, we show that the approach performs well on an entity resolution task, a classification task, and a joint inference task; that the cost of inference is independent of database size; and that speedup in learning is possible by multi-threading.", "year": 2013, "ssId": "da564ff902a5490088f60c9fb100531fc9f97288", "arXivId": "1305.2254", "link": "https://arxiv.org/pdf/1305.2254.pdf", "openAccess": true, "authors": ["William Yang Wang", "Kathryn Mazaitis", "William W. Cohen"]}