{"title": "Weakly- and Semi-supervised Evidence Extraction", "abstract": "For many prediction tasks, stakeholders desire not only predictions but also supporting evidence that a human can use to verify its correctness. However, in practice, evidence annotations may only be available for a minority of training examples (if available at all). In this paper, we propose new methods to combine few evidence annotations (strong semi-supervision) with abundant document-level labels (weak supervision) for the task of evidence extraction. Evaluating on two classification tasks that feature evidence annotations, we find that our methods outperform baselines adapted from the interpretability literature to our task. Our approach yields gains with as few as hundred evidence annotations.", "year": 2020, "ssId": "18f4ec53a4221a97e1482f091f41a23f3d873cf2", "arXivId": "2011.01459", "link": "https://arxiv.org/pdf/2011.01459.pdf", "openAccess": true, "authors": ["Danish Pruthi", "Bhuwan Dhingra", "Graham Neubig", "Z. Lipton"]}