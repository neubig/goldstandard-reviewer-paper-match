{"title": "Semi-Supervised Learning for Vision-and-Language Tasks using MixMatch", "abstract": "Semi-supervised learning algorithms attempt to train a model with limited labeled data by leveraging a large amount of unlabelled samples . However, there is limited literature on using such a strategy for visual-language tasks, mainly due to the complexity and the discreteness of the input space. We attempt to reformulate MixMatch, a recently proposed semi-supervised learning strategy, on a state-of-the-art multi-modal framework LXMERT, and report the performance on the NLVR2 dataset. We compare these results with suitable baseline experiments. To assess the applicability of textual interpolation, we conduct an interesting experiment on GPT-2. Towards the end, we propose two more modifications that were planned but couldn\u2019t be executed due to the constraint of time.", "year": 2019, "ssId": "7a1bcf3c84607f7aeb0601658845ca2083059f43", "arXivId": null, "link": null, "openAccess": false, "authors": ["Kalpesh Krishna", "Videsh Suman"]}