{"title": "FastEmit: Low-Latency Streaming ASR with Sequence-Level Emission Regularization", "abstract": "Streaming automatic speech recognition (ASR) aims to emit each hypothesized word as quickly and accurately as possible. However, emitting fast without degrading quality, as measured by word error rate (WER), is highly challenging. Existing approaches including Early and Late Penalties [1] and Constrained Alignments [2], [3] penalize emission delay by manipulating per-token or per-frame probability prediction in sequence transducer models [4]. While being successful in reducing delay, these approaches suffer from significant accuracy regression and also require additional word alignment information from an existing model. In this work, we propose a sequence-level emission regularization method, named FastEmit, that applies latency regularization directly on per-sequence probability in training transducer models, and does not require any alignment. We demonstrate that FastEmit is more suitable to the sequence-level optimization of transducer models [4] for streaming ASR by applying it on various end-to-end streaming ASR networks including RNN-Transducer [5], Transformer-Transducer [6], [7], ConvNet-Transducer [8] and Conformer-Transducer [9]. We achieve 150 ~ 300ms latency reduction with significantly better accuracy over previous techniques on a Voice Search test set. FastEmit also improves streaming ASR accuracy from 4.4%/8.9% to 3.1%/7.5% WER, meanwhile reduces 90th percentile latency from 210ms to only 30ms on LibriSpeech.", "year": 2020, "ssId": "c8a5d05cb741b3448ec4106d2006ae24a7a401b4", "arXivId": "2010.11148", "link": "https://arxiv.org/pdf/2010.11148.pdf", "openAccess": true, "authors": ["Jiahui Yu", "C. Chiu", "Bo Li", "Shuo-yiin Chang", "T. Sainath", "Yanzhang He", "A. Narayanan", "Wei Han", "Anmol Gulati", "Yonghui Wu", "Ruoming Pang"]}