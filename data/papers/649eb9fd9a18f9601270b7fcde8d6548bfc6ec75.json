{"title": "End-to-end Monaural Multi-speaker ASR System without Pretraining", "abstract": "Recently, end-to-end models have become a popular approach as an alternative to traditional hybrid models in automatic speech recognition (ASR). The multi-speaker speech separation and recognition task is a central task in cocktail party problem. In this paper, we present a state-of-the-art monaural multi-speaker end-to-end automatic speech recognition model. In contrast to previous studies on the monaural multi-speaker speech recognition, this end-to-end framework is trained to recognize multiple label sequences completely from scratch. The system only requires the speech mixture and corresponding label sequences, without needing any indeterminate supervisions obtained from non-mixture speech or corresponding labels/alignments. Moreover, we exploited using the individual attention module for each separated speaker and the scheduled sampling to further improve the performance. Finally, we evaluate the proposed model on the 2-speaker mixed speech generated from the WSJ corpus and the wsj0-2mix dataset, which is a speech separation and recognition benchmark. The experiments demonstrate that the proposed methods can improve the performance of the end-to-end model in separating the overlapping speech and recognizing the separated streams. From the results, the proposed model leads to \u223c 10.0% relative performance gains in terms of CER and WER respectively.", "year": 2018, "ssId": "649eb9fd9a18f9601270b7fcde8d6548bfc6ec75", "arXivId": "1811.02062", "link": "https://arxiv.org/pdf/1811.02062.pdf", "openAccess": true, "authors": ["Xuankai Chang", "Y. Qian", "Kai Yu", "Shinji Watanabe"]}