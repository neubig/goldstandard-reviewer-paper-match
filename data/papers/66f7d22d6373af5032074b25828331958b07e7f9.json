{"title": "When Differential Privacy Meets Interpretability: A Case Study", "abstract": "Given the increase in the use of personal data for training Deep Neural Networks (DNNs) in tasks such as medical imaging and diagnosis, differentially private training of DNNs is surging in importance and there is a large body of work focusing on providing better privacy-utility trade-off. However, little attention is given to the interpretability of these models, and how the application of DP affects the quality of interpretations. We propose an extensive study into the effects of DP training on DNNs, especially on medical imaging applications, on the APTOS dataset.", "year": 2021, "ssId": "66f7d22d6373af5032074b25828331958b07e7f9", "arXivId": "2106.13203", "link": "https://arxiv.org/pdf/2106.13203.pdf", "openAccess": true, "authors": ["Rakshit Naidu", "Aman Priyanshu", "Aadith Kumar", "Sasikanth Kotti", "Haofan Wang", "FatemehSadat Mireshghallah"]}