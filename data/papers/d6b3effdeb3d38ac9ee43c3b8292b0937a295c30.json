{"title": "Hierarchical Multitask Learning for CTC-based Speech Recognition", "abstract": "Previous work has shown that neural encoder-decoder speech recognition can be improved with hierarchical multitask learning, where auxiliary tasks are added at intermediate layers of a deep encoder. We explore the effect of hierarchical multitask learning in the context of connectionist temporal classification (CTC)-based speech recognition, and investigate several aspects of this approach. Consistent with previous work, we observe performance improvements on telephone conversational speech recognition (specifically the Eval2000 test sets) when training a subword-level CTC model with an auxiliary phone loss at an intermediate layer. We analyze the effects of a number of experimental variables (like interpolation constant and position of the auxiliary loss function), performance in lower-resource settings, and the relationship between pretraining and multitask learning. We observe that the hierarchical multitask approach improves over standard multitask training in our higher-data experiments, while in the low-resource settings standard multitask training works well. The best results are obtained by combining hierarchical multitask learning and pretraining, which improves word error rates by 3.4% absolute on the Eval2000 test sets.", "year": 2018, "ssId": "d6b3effdeb3d38ac9ee43c3b8292b0937a295c30", "arXivId": "1807.06234", "link": "https://arxiv.org/pdf/1807.06234.pdf", "openAccess": true, "authors": ["Kalpesh Krishna", "Shubham Toshniwal", "Karen Livescu"]}