{"title": "An end-to-end model for cross-lingual transformation of paralinguistic information", "abstract": "Speech translation is a technology that helps people communicate across different languages. The most commonly used speech translation model is composed of automatic speech recognition, machine translation and text-to-speech synthesis components, which share information only at the text level. However, spoken communication is different from written communication in that it uses rich acoustic cues such as prosody in order to transmit more information through non-verbal channels. This paper is concerned with speech-to-speech translation that is sensitive to this paralinguistic information. Our long-term goal is to make a system that allows users to speak a foreign language with the same expressiveness as if they were speaking in their own language. Our method works by reconstructing input acoustic features in the target language. From the many different possible paralinguistic features to handle, in this paper we choose duration and power as a first step, proposing a method that can translate these features from input speech to the output speech in continuous space. This is done in a simple and language-independent fashion by training an end-to-end model that maps source-language duration and power information into the target language. Two approaches are investigated: linear regression and neural network models. We evaluate the proposed methods and show that paralinguistic information in the input speech of the source language can be reflected in the output speech of the target language.", "year": 2018, "ssId": "0aa0131253b832fdba27ac43f8fa78a322763191", "arXivId": null, "link": null, "openAccess": false, "authors": ["Takatomo Kano", "Shinnosuke Takamichi", "S. Sakti", "Graham Neubig", "T. Toda", "Satoshi Nakamura"]}