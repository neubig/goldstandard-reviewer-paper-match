{"title": "What's the best place for an AI conference, Vancouver or ______: Why completing comparative questions is difficult", "abstract": "Although large neural language models (LMs) like BERT can be \ufb01netuned to yield state-of-the-art results on many NLP tasks, it is often unclear what these models actually learn. Here we study using such LMs to \ufb01ll in entities in human-authored comparative questions, like \u201cWhich country is older, India or ?\u201d\u2014i.e., we study the ability of neural LMs to ask (not answer ) reasonable questions. We show that accu-racy in this \ufb01ll-in-the-blank task is well-correlated with hu- man judgements of whether a question is reasonable, and that these models can be trained to achieve nearly human-level performance in completing comparative questions in three different subdomains. However, analysis shows that what they learn fails to model any sort of broad notion of which entities are semantically comparable or similar\u2014instead the trained models are very domain-speci\ufb01c, and performance is highly correlated with co-occurrences between speci\ufb01c enti- ties observed in the training set. This is true both for models that are pretrained on general text corpora, as well as mod- els trained on a large corpus of comparison questions. Our study thus reinforces recent results on the dif\ufb01culty of mak- ing claims about a deep model\u2019s world knowledge or linguistic competence based on performance on speci\ufb01c benchmark problems. We make our evaluation datasets publicly available to foster future research on complex understanding and rea- soning in such models at standards of human interaction.", "year": 2021, "ssId": "8b652c4d7a8d5836925ce0fe28a91dc661778524", "arXivId": "2104.01940", "link": "https://arxiv.org/pdf/2104.01940.pdf", "openAccess": true, "authors": ["Avishai Zagoury", "Einat Minkov", "Idan Szpektor", "William W. Cohen"]}