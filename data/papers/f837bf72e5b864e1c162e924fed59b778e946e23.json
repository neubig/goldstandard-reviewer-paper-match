{"title": "Imagining Grounded Conceptual Representations from Perceptual Information in Situated Guessing Games", "abstract": "In visual guessing games, a Guesser has to identify a target object in a scene by asking questions to an Oracle. An effective strategy for the players is to learn conceptual representations of objects that are both discriminative and expressive enough to ask questions and guess correctly. However, as shown by Suglia et al. (2020), existing models fail to learn truly multi-modal representations, relying instead on gold category labels for objects in the scene both at training and inference time. This provides an unnatural performance advantage when categories at inference time match those at training time, and it causes models to fail in more realistic \u201czero-shot\u201d scenarios where out-of-domain object categories are involved. To overcome this issue, we introduce a novel \u201cimagination\u201d module based on Regularized Auto-Encoders, that learns context-aware and category-aware latent embeddings without relying on category labels at inference time. Our imagination module outperforms state-of-the-art competitors by 8.26% gameplay accuracy in the CompGuessWhat?! zero-shot scenario (Suglia et al., 2020), and it improves the Oracle and Guesser accuracy by 2.08% and 12.86% in the GuessWhat?! benchmark, when no gold categories are available at inference time. The imagination module also boosts reasoning about object properties and attributes.", "year": 2020, "ssId": "f837bf72e5b864e1c162e924fed59b778e946e23", "arXivId": "2011.02917", "link": "https://arxiv.org/pdf/2011.02917.pdf", "openAccess": true, "authors": ["Alessandro Suglia", "Antonio Vergari", "Ioannis Konstas", "Yonatan Bisk", "E. Bastianelli", "Andrea Vanzo", "Oliver Lemon"]}