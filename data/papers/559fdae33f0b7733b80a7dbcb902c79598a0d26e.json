{"title": "Can Transformers be Strong Treatment Effect Estimators?", "abstract": "In this paper, we develop a general framework based on the Transformer architecture to address a variety of challenging treatment effect estimation (TEE) problems. Our methods are applicable both when covariates are tabular and when they consist of sequences (e.g., in text), and can handle discrete, continuous, structured, or dosage-associated treatments. While Transformers have already emerged as dominant methods for diverse domains, including natural language and computer vision, our experiments with Transformers as Treatment Effect Estimators (TransTEE) demonstrate that these inductive biases are also effective on the sorts of estimation problems and datasets that arise in research aimed at estimating causal effects. Moreover, we propose a propensity score network that is trained with TransTEE in an adversarial manner to promote independence between covariates and treatments to further address selection bias. Through extensive experiments, we show that TransTEE significantly outperforms competitive baselines with greater parameter efficiency over a wide range of benchmarks and settings.", "year": 2022, "ssId": "559fdae33f0b7733b80a7dbcb902c79598a0d26e", "arXivId": "2202.01336", "link": "https://arxiv.org/pdf/2202.01336.pdf", "openAccess": true, "authors": ["Yi-Fan Zhang", "Hanlin Zhang", "Zachary Chase Lipton", "Li Erran Li", "Eric P. Xing"]}