{"title": "Understanding, Detecting, and Separating Out-of-Distribution Samples and Adversarial Samples in Text Classification", "abstract": "In this paper, we study the differences and commonalities between statistically out-of-distribution (OOD) samples and adversarial (Adv) samples, both of which hurting a text classi\ufb01cation model\u2019s performance. We conduct analyses to compare the two types of anomalies (OOD and Adv samples) with the in-distribution (ID) ones from three aspects: the input features, the hidden representations in each layer of the model, and the output probability distributions of the classi\ufb01er. We \ufb01nd that OOD samples expose their aberration starting from the \ufb01rst layer, while the abnormalities of Adv samples do not emerge until the deeper layers of the model. We also illustrate that the models\u2019 output probabilities for Adv samples tend to be more uncon\ufb01dent. Based on our observations, we propose a simple method to separate ID, OOD, and Adv samples using the hidden representations and output probabilities of the model. On multiple combinations of ID, OOD datasets, and Adv attacks, our proposed method shows exceptional results on distinguishing ID, OOD, and Adv samples.", "year": 2022, "ssId": "bd2f3822801a7e2f933d06c261b8783764d8ce18", "arXivId": "2204.04458", "link": "https://arxiv.org/pdf/2204.04458.pdf", "openAccess": true, "authors": ["David C. Chiang", "Hung-yi Lee"]}