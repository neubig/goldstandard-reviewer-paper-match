{"title": "Evaluating Inter-Annotator Agreement on Historical Spelling Normalization", "abstract": "This paper deals with means of evaluating inter-annotator agreement for a normalization task. This task differs from common annotation tasks in two important aspects: (i) the class of labels (the normalized wordforms) is open, and (ii) annotations can match to different degrees. We propose a new method to measure inter-annotator agreement for the normalization task. It integrates common chancecorrected agreement measures, such as Fleiss\u2019s \u03ba or Krippendorff\u2019s \u03b1. The novelty of our proposed method lies in the way the annotated word forms are treated. First, they are evaluated character-wise; second, certain characters are mapped to more general categories.", "year": 2016, "ssId": "3cc790174d138d7904189df997d5763f1793dedf", "arXivId": null, "link": null, "openAccess": false, "authors": ["Marcel Bollmann", "Stefanie Dipper", "Florian Petran"]}