{"title": "Retrieval-Based Neural Code Generation", "abstract": "In models to generate program source code from natural language, representing this code in a tree structure has been a common approach. However, existing methods often fail to generate complex code correctly due to a lack of ability to memorize large and complex structures. We introduce RECODE, a method based on subtree retrieval that makes it possible to explicitly reference existing code examples within a neural code generation model. First, we retrieve sentences that are similar to input sentences using a dynamic-programming-based sentence similarity scoring method. Next, we extract n-grams of action sequences that build the associated abstract syntax tree. Finally, we increase the probability of actions that cause the retrieved n-gram action subtree to be in the predicted code. We show that our approach improves the performance on two code generation tasks by up to +2.6 BLEU.", "year": 2018, "ssId": "d3e13d2514edaf74b863bfbe45a739c32a7689e1", "arXivId": "1808.10025", "link": "https://arxiv.org/pdf/1808.10025.pdf", "openAccess": true, "authors": ["Shirley Anugrah Hayati", "R. Olivier", "Pravalika Avvaru", "Pengcheng Yin", "A. Tomasic", "Graham Neubig"]}