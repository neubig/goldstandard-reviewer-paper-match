{"title": "The Impact of Algorithmic Risk Assessments on Human Predictions and its Analysis via Crowdsourcing Studies", "abstract": "As algorithmic risk assessment instruments (RAIs) are increasingly adopted to assist decision makers, their predictive performance and potential to promote inequity have come under scrutiny. However, while most studies examine these tools in isolation, researchers have come to recognize that assessing their impact requires understanding the behavior of their human interactants. In this paper, building off of several recent crowdsourcing works focused on criminal justice, we conduct a vignette study in which laypersons are tasked with predicting future re-arrests. Our key findings are as follows: (1) Participants often predict that an offender will be rearrested even when they deem the likelihood of re-arrest to be well below 50%; (2) Participants do not anchor on the RAI's predictions; (3) The time spent on the survey varies widely across participants and most cases are assessed in less than 10 seconds; (4) Judicial decisions, unlike participants' predictions, depend in part on factors that are orthogonal to the likelihood of re-arrest. These results highlight the influence of several crucial but often overlooked design decisions and concerns around generalizability when constructing crowdsourcing studies to analyze the impacts of RAI", "year": 2021, "ssId": "3321c947a4a399803592f26879927e58f587fd74", "arXivId": "2109.01443", "link": "https://arxiv.org/pdf/2109.01443.pdf", "openAccess": true, "authors": ["Riccardo Fogliato", "A. Chouldechova", "Zachary Chase Lipton"]}