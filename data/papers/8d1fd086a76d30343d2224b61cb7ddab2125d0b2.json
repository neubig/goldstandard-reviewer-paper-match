{"title": "USING DISTRIBUTION\u2010FREE LEARNING THEORY TO ANALYZE SOLUTION\u2010PATH CACHING MECHANISMS", "abstract": "Much research in machine learning has been focused on the problem of symbol\u2010level learning (SLL), or learning to improve the performance of a program given examples of its behavior on typical inputs. A common approach to symbol\u2010level learning is to use some sort of mechanism for saving and later reusing the solution paths used to solve previous search problems. Examples of such mechanisms are macro\u2010operator learning, explanation\u2010based learning, and chunking. However, experimental evidence that these mechanisms actually improve performance is inconclusive. This paper presents a formal framework for analysis of symbol\u2010level learning programs, and then uses this framework to investigate a series of solution\u2010path caching mechanisms which provably improve performance. The analysis of these mechanisms is illuminating in many respects; in particular, in order to obtain positive results, it is necessary to use a novel representation for a set of solution paths, and also to apply certain unusual optimizations to a set of solution paths. Several of the predictions made by the model have been confirmed by recently published experiments.", "year": 1992, "ssId": "8d1fd086a76d30343d2224b61cb7ddab2125d0b2", "arXivId": null, "link": null, "openAccess": false, "authors": ["William W. Cohen"]}