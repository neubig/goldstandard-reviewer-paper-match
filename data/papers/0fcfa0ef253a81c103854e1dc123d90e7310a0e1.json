{"title": "DP-SGD vs PATE: Which Has Less Disparate Impact on Model Accuracy?", "abstract": "Recent advances in differentially private deep learning have demonstrated that application of differential privacy\u2013 speci\ufb01cally the DP-SGD algorithm\u2013 has a disparate impact on different sub-groups in the population, which leads to a signi\ufb01cantly high drop-in model utility for sub-populations that are under-represented (minori-ties), compared to well-represented ones. In this work, we aim to compare PATE, another mechanism for training deep learning models using differential privacy, with DP-SGD in terms of fairness. We show that PATE does have a disparate impact too, however, it is much less severe than DP-SGD. We draw insights from this observation on what might be promising directions in achieving better fairness-privacy trade-offs.", "year": 2021, "ssId": "0fcfa0ef253a81c103854e1dc123d90e7310a0e1", "arXivId": "2106.12576", "link": "https://arxiv.org/pdf/2106.12576.pdf", "openAccess": true, "authors": ["Archit Uniyal", "Rakshit Naidu", "Sasikanth Kotti", "Sahib Singh", "Patrik Joslin Kenfack", "FatemehSadat Mireshghallah", "Andrew Trask"]}