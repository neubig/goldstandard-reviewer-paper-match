{"title": "BBQ-Networks: Efficient Exploration in Deep Reinforcement Learning for Task-Oriented Dialogue Systems", "abstract": "We present a new algorithm that significantly improves the efficiency of exploration for deep Q-learning agents in dialogue systems. Our agents explore via Thompson sampling, drawing Monte Carlo samples from a Bayes-by-Backprop neural network. Our algorithm learns much faster than common exploration strategies such as $\\epsilon$-greedy, Boltzmann, bootstrapping, and intrinsic-reward-based ones. Additionally, we show that spiking the replay buffer with experiences from just a few successful episodes can make Q-learning feasible when it might otherwise fail.", "year": 2016, "ssId": "885fe11ed7ab81c8609ccddb3e10f62577c04ab9", "arXivId": "1711.05715", "link": "https://arxiv.org/pdf/1711.05715.pdf", "openAccess": true, "authors": ["Zachary Chase Lipton", "Xiujun Li", "Jianfeng Gao", "Lihong Li", "Faisal Ahmed", "L. Deng"]}