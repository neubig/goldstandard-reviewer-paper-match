{"title": "Interpretable Machine Learning: Moving From Mythos to Diagnostics", "abstract": "Despite years of progress in the field of Interpretable Machine Learning (IML), a significant gap persists between the technical objectives targeted by researchers\u2019 methods and the high-level goals stated as consumers\u2019 use cases. To address this gap, we argue for the IML community to embrace a diagnostic vision for the field. Instead of viewing IML methods as a panacea for a variety of overly broad use cases, we emphasize the need to systematically connect IML methods to narrower\u2013yet better defined\u2013target use cases. To formalize this vision, we propose a taxonomy including both methods and use cases, helping to conceptualize the current gaps between the two. Then, to connect these two sides, we describe a three-step workflow to enable researchers and consumers to define and validate IML methods as useful diagnostics. Eventually, by applying this workflow, a more complete version of the taxonomy will allow consumers to find relevant methods for their target use cases and researchers to identify motivating use cases for their methods.", "year": 2021, "ssId": "efcdb62b59e4dfb3f51b53850a81d6149ec3dfc8", "arXivId": "2103.06254", "link": "https://arxiv.org/pdf/2103.06254.pdf", "openAccess": true, "authors": ["Valerie Chen", "Jeffrey Li", "Joon Sik Kim", "Gregory Plumb", "Ameet S. Talwalkar"]}