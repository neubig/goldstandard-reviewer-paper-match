{"title": "One size does not fit all: Investigating strategies for differentially-private learning across NLP tasks", "abstract": "Preserving privacy in training modern NLP models comes at a cost. We know that stricter privacy guarantees in differentiallyprivate stochastic gradient descent (DP-SGD) generally degrade model performance. However, previous research on the efficiency of DPSGD in NLP is inconclusive or even counterintuitive. In this short paper, we provide a thorough analysis of different privacy preserving strategies on seven downstream datasets in five different \u2018typical\u2019 NLP tasks with varying complexity using modern neural models. We show that unlike standard non-private approaches to solving NLP tasks, where bigger is usually better, privacy-preserving strategies do not exhibit a winning pattern, and each task and privacy regime requires a special treatment to achieve adequate performance.", "year": 2021, "ssId": "75ba422d90c488b1388345865e0525208331bb3d", "arXivId": "2112.08159", "link": "https://arxiv.org/pdf/2112.08159.pdf", "openAccess": true, "authors": ["Manuel Senge", "Timour Igamberdiev", "Ivan Habernal"]}