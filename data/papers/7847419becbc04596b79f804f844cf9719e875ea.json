{"title": "Skill Induction and Planning with Latent Language", "abstract": "We present a framework for learning hierarchical policies from demonstrations, using sparse natural language annotations to guide the discovery of reusable skills for autonomous decision-making. We formulate a generative model of action sequences in which goals generate sequences of high-level subtask descriptions, and these descriptions generate sequences of low-level actions. We describe how to train this model using primarily unannotated demonstrations by parsing demonstrations into sequences of named high-level subtasks, using only a small number of seed annotations to ground language in action. In trained models, the space of natural language commands indexes a combinatorial library of skills; agents can use these skills to plan by generating high-level instruction sequences tailored to novel goals. We evaluate this approach in the ALFRED household simulation environment, providing natural language annotations for only 10% of demonstrations. It completes more than twice as many tasks as a standard approach to learning from demonstrations, matching the performance of instruction following models with access to ground-truth plans during both training and evaluation. 1", "year": 2021, "ssId": "7847419becbc04596b79f804f844cf9719e875ea", "arXivId": "2110.01517", "link": "https://arxiv.org/pdf/2110.01517.pdf", "openAccess": true, "authors": ["Pratyusha Sharma", "A. Torralba", "Jacob Andreas"]}