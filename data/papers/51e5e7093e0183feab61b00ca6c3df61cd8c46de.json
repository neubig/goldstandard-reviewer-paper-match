{"title": "Hallucinated n-best lists for discriminative language modeling", "abstract": "This paper investigates semi-supervised methods for discriminative language modeling, whereby n-best lists are \u201challucinated\u201d for given reference text and are then used for training n-gram language models using the perceptron algorithm. We perform controlled experiments on a very strong baseline English CTS system, comparing three methods for simulating ASR output, and compare the results with training with \u201creal\u201d n-best list output from the baseline recognizer. We find that methods based on extracting phrasal cohorts - similar to methods from machine translation for extracting phrase tables - yielded the largest gains of our three methods, achieving over half of the WER reduction of the fully supervised methods.", "year": 2012, "ssId": "51e5e7093e0183feab61b00ca6c3df61cd8c46de", "arXivId": null, "link": null, "openAccess": false, "authors": ["Kenji Sagae", "M. Lehr", "Emily Tucker Prud'hommeaux", "Puyang Xu", "N. Glenn", "D. Karakos", "S. Khudanpur", "Brian Roark", "M. Sara\u00e7lar", "I. Shafran", "D. Bikel", "Chris Callison-Burch", "Yuan Cao", "Keith B. Hall", "E. Hasler", "Philipp Koehn", "Adam Lopez", "Matt Post", "Darcey Riley"]}