{"title": "Evaluation Phonemic Transcription of Low-Resource Tonal Languages for Language Documentation", "abstract": "Transcribing speech is an important part of language documentation, yet speech recognition technology has not been widely harnessed to aid linguists. We explore the use of a neural network architecture with the connectionist temporal classification loss function for phonemic and tonal transcription in a language documentation setting. In this framework, we explore jointly modelling phonemes and tones versus modelling them separately, and assess the importance of pitch information versus phonemic context for tonal prediction. Experiments on two tonal languages, Yongning Na and Eastern Chatino, show the changes in recognition performance as training data is scaled from 10 minutes up to 50 minutes for Chatino, and up to 224 minutes for Na. We discuss the findings from incorporating this technology into the linguistic workflow for documenting Yongning Na, which show the method's promise in improving efficiency, minimizing typographical errors, and maintaining the transcription's faithfulness to the acoustic signal, while highlighting phonetic and phonemic facts for linguistic consideration.", "year": 2018, "ssId": "b9913ddf94245c864509f0b94847bdbe77899b46", "arXivId": null, "link": null, "openAccess": false, "authors": ["Oliver Adams", "Trevor Cohn", "Graham Neubig", "Hilaria Cruz", "Steven Bird", "A. Michaud"]}