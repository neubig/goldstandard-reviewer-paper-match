{"title": "Feeling the Bern: Adaptive Estimators for Bernoulli Probabilities of Pairwise Comparisons", "abstract": "We study methods for aggregating pairwise comparison data among a collection of <inline-formula> <tex-math notation=\"LaTeX\">$n$ </tex-math></inline-formula> items with the goal of estimating the outcome probabilities for future comparisons. Working within a flexible model that only imposes a form of strong stochastic transitivity, we introduce an \u201cadaptivity index\u201d which compares the risk of our estimator to that of an oracle, over appropriate sub-models, where the oracle knows the specific sub-model in the ground truth. In addition to measuring the usual worst-case risk of an estimator, this adaptivity index also captures the extent to which the estimator adapts to instance-specific difficulty relative to an oracle estimator. First, we propose a three-step estimator termed count-randomize-least squares, and show that it has adaptivity index upper bounded by <inline-formula> <tex-math notation=\"LaTeX\">$\\sqrt {n}$ </tex-math></inline-formula> up to logarithmic factors. We then show that conditional on the planted clique hypothesis, no computationally efficient estimator can achieve an adaptivity index smaller than <inline-formula> <tex-math notation=\"LaTeX\">$\\sqrt {n}$ </tex-math></inline-formula>. Second, we show that a regularized least squares estimator can achieve a poly-logarithmic adaptivity index, thereby demonstrating a <inline-formula> <tex-math notation=\"LaTeX\">$\\sqrt {n}$ </tex-math></inline-formula>-gap between optimal and computationally achievable adaptivity. Finally, we prove that the standard least squares estimator, which is known to be optimally adaptive in several closely related problems, fails to adapt in the context of estimating pairwise probabilities.", "year": 2019, "ssId": "f637d061704579531a8b8e03ef6e8331ba117490", "arXivId": null, "link": null, "openAccess": false, "authors": ["Nihar B. Shah", "Sivaraman Balakrishnan", "M. Wainwright"]}