{"title": "Temporally-Informed Analysis of Named Entity Recognition", "abstract": "Natural language processing models often have to make predictions on text data that evolves over time as a result of changes in language use or the information described in the text. However, evaluation results on existing data sets are seldom reported by taking the timestamp of the document into account. We analyze and propose methods that make better use of temporally-diverse training data, with a focus on the task of named entity recognition. To support these experiments, we introduce a novel data set of English tweets annotated with named entities. We empirically demonstrate the effect of temporal drift on performance, and how the temporal information of documents can be used to obtain better models compared to those that disregard temporal information. Our analysis gives insights into why this information is useful, in the hope of informing potential avenues of improvement for named entity recognition as well as other NLP tasks under similar experimental setups.", "year": 2020, "ssId": "509b42fc150a057a64c4608f64e779ef04fdff47", "arXivId": null, "link": null, "openAccess": false, "authors": ["Shruti Rijhwani", "Daniel Preotiuc-Pietro"]}