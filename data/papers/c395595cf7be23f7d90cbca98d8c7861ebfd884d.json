{"title": "The Disagreement Deconvolution: Bringing Machine Learning Performance Metrics In Line With Reality", "abstract": "Machine learning classifiers for human-facing tasks such as comment toxicity and misinformation often score highly on metrics such as ROC AUC but are received poorly in practice. Why this gap? Today, metrics such as ROC AUC, precision, and recall are used to measure technical performance; however, human-computer interaction observes that evaluation of human-facing systems should account for people\u2019s reactions to the system. In this paper, we introduce a transformation that more closely aligns machine learning classification metrics with the values and methods of user-facing performance measures. The disagreement deconvolution takes in any multi-annotator (e.g., crowdsourced) dataset, disentangles stable opinions from noise by estimating intra-annotator consistency, and compares each test set prediction to the individual stable opinions from each annotator. Applying the disagreement deconvolution to existing social computing datasets, we find that current metrics dramatically overstate the performance of many human-facing machine learning tasks: for example, performance on a comment toxicity task is corrected from .95 to .73 ROC AUC.", "year": 2021, "ssId": "c395595cf7be23f7d90cbca98d8c7861ebfd884d", "arXivId": null, "link": "http://www.kayur.org/papers/chi2021.pdf", "openAccess": true, "authors": ["Mitchell L. Gordon", "Kaitlyn Zhou", "Kayur Patel", "Tatsunori B. Hashimoto", "Michael S. Bernstein"]}