{"title": "Hard-Attentional Neural Network Models for Emphasis Speech Translation", "abstract": "Traditional speech translation systems are oblivious to paralinguistic information. A recent work has tried to tackle this task by utilizing conditional random fields (CRFs). Although CRFs allow for consideration of rich features and local context, they have difficulty in handling continuous variables, and cannot capture long-distance dependencies easily. In this paper, we propose a new model for emphasis transfer in speech translation using an approach based on neural networks. Our experiments showed a significant improvement of the proposed model over the previous model by 4% target-language emphasis prediction F-measure according to objective evaluation.", "year": 2016, "ssId": "c2b22a18ea2ed444c6c1f5bb27ab55bda2b44567", "arXivId": null, "link": null, "openAccess": false, "authors": ["TruongDo Quoc", "Sakti Sakriani", "Graham Neubig", "Nakamura Satoshi"]}