{"title": "Closing the Gap Between Time-Domain Multi-Channel Speech Enhancement on Real and Simulation Conditions", "abstract": "The deep learning based time-domain models, e.g. Conv-TasNet, have shown great potential in both single-channel and multi-channel speech enhancement. However, many experiments on the time-domain speech enhancement model are done in simulated conditions, and it is not well studied whether the good performance can generalize to real-world scenarios. In this paper, we aim to provide an insightful investigation of applying multi-channel Conv-TasNet based speech enhancement to both simulation and real data. Our preliminary experiments show a large performance gap between the two conditions in terms of the ASR performance. Several approaches are applied to close this gap, including the integration of multi-channel Conv-TasNet into the beamforming model with various strategies, and the joint training of speech enhancement and speech recognition models. Our experiments on the CHiME-4 corpus show that our proposed approaches can greatly reduce the speech recognition performance discrepancy between simulation and real data, while preserving the strong speech enhancement capability in the frontend.", "year": 2021, "ssId": "0554246ebb6c53e88d7ac2aabf0c96a91ad500a0", "arXivId": "2110.14139", "link": "https://arxiv.org/pdf/2110.14139.pdf", "openAccess": true, "authors": ["Wangyou Zhang", "Jing Shi", "Chenda Li", "Shinji Watanabe", "Y. Qian"]}