{"title": "Decontextualization: Making Sentences Stand-Alone", "abstract": "Abstract Models for question answering, dialogue agents, and summarization often interpret the meaning of a sentence in a rich context and use that meaning in a new context. Taking excerpts of text can be problematic, as key pieces may not be explicit in a local window. We isolate and define the problem of sentence decontextualization: taking a sentence together with its context and rewriting it to be interpretable out of context, while preserving its meaning. We describe an annotation procedure, collect data on the Wikipedia corpus, and use the data to train models to automatically decontextualize sentences. We present preliminary studies that show the value of sentence decontextualization in a user-facing task, and as preprocessing for systems that perform document understanding. We argue that decontextualization is an important subtask in many downstream applications, and that the definitions and resources provided can benefit tasks that operate on sentences that occur in a richer context.", "year": 2021, "ssId": "972a74968d2522908b06c5bd1e26266194c5a9ee", "arXivId": "2102.05169", "link": "https://arxiv.org/pdf/2102.05169.pdf", "openAccess": true, "authors": ["Eunsol Choi", "Jennimaria Palomaki", "Matthew Lamm", "T. Kwiatkowski", "Dipanjan Das", "Michael Collins"]}