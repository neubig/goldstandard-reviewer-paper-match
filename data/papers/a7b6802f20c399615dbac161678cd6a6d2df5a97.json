{"title": "Challenges in Data Production for AI with Human-in-the-Loop", "abstract": "Today, successful Artificial Intelligence applications rely on three pillars: machine learning algorithms, hardware for running them, and data for training and evaluating models. Although algorithms and hardware have already become commodities, obtaining up-to-date and high-quality data at scale is still challenging-but possible by building hybrid human-computer pipelines called human-in-the-loop. This talk will show how to make a significant business impact using human-in-the-loop pipelines that combine machine learning with crowdsourcing. We will share the experience of one of the world's largest search engines, Yandex. After a brief introduction to human-in-the-loop, we will describe two insightful case studies with a significant business impact at Yandex. First, we will show how to use human-in-the-loop with subjective human opinions to gather training data for learning-to-rank models in the online setting, crucial for the recommendation, e-commerce, and search applications. Second, we will show how human-in-the-loop combined with spatial crowdsourcing enables keeping information on brick-and-mortar businesses up-to-date and transformed into structured data, essential for social impactful applications like online maps and directories. Then, we will present the practical challenges of deploying human-in-the-loop pipelines, focusing on common issues with task design and quality control. We will demonstrate the end-to-end task design techniques that better fit for open-ended and subjective questions compared to widely-used classification tasks. We will present our recent advances in this field, including the use of large-scale language models (like BART and T5) for sequence aggregation. Also, we will show the new evaluation datasets for textual and subjective annotation, which are publicly available at https://toloka.ai/datasets. We will discuss the problem of reliable quality control in crowdsourcing by describing the relevant computational methods for aggregation, quality estimation, and model selection. Finally, we will demonstrate Crowd-Kit, an open-source library that offers battle-tested and platform-agnostic implementations of all the above-described methods in Python: https://github.com/Toloka/crowd-kit. Overall, we will share our experience in running impactful human-in-the-loop pipelines in production while overcoming the common practical challenges using the available and reliable open-source technologies, datasets, and tools.", "year": 2022, "ssId": "a7b6802f20c399615dbac161678cd6a6d2df5a97", "arXivId": null, "link": null, "openAccess": false, "authors": ["Dmitry Ustalov"]}