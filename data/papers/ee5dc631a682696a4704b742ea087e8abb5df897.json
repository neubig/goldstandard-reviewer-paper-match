{"title": "EAT: Enhanced ASR-TTS Framework for Self-supervised ASR", "abstract": "Self-supervised training has drawn major benefits for unsupervised speech recognition tasks. In this paper, we propose an enhanced ASR-TTS (EAT) framework using cycle-consistency algorithm by introducing two main features: 1) The ASR\u2192TTS pipeline is included with a language model reward to penalise the ASR hypotheses before forwarding to TTS. 2) In TTS\u2192ASR, a hyper-parameter is introduced to scale the attention context from synthesized speech before sending it to ASR to handle out-of-domain data. We explore the effectiveness of the EAT framework under different data conditions and latest architectures. The results show that EAT reduces the performance gap between supervised and unsupervised to 17.1% and 20.1% on Librispeech and BABEL corpus respectively.", "year": 2020, "ssId": "ee5dc631a682696a4704b742ea087e8abb5df897", "arXivId": null, "link": null, "openAccess": false, "authors": ["Murali Karthick Baskar", "Shinji Watanabe", "Ram\u00f3n Fern\u00e1ndez Astudillo", "L. Burget", "J. Cernock\u00fd"]}