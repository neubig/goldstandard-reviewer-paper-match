{"title": "Not All Features Are Equal: Discovering Essential Features for Preserving Prediction Privacy", "abstract": "When receiving machine learning services from the cloud, the provider does not need to receive all features; in fact, only a subset of the features are necessary for the target prediction task. Discerning this subset is the key problem of this work. We formulate this problem as a gradient-based perturbation maximization method that discovers this subset in the input feature space with respect to the functionality of the prediction model used by the provider. After identifying the subset, our framework, Cloak, suppresses the rest of the features using utility-preserving constant values that are discovered through a separate gradient-based optimization process. We show that Cloak does not necessarily require collaboration from the service provider beyond its normal service, and can be applied in scenarios where we only have black-box access to the service provider\u2019s model. We theoretically guarantee that Cloak\u2019s optimizations reduce the upper bound of the Mutual Information (MI) between the data and the sifted representations that are sent out. Experimental results show that Cloak reduces the mutual information between the input and the sifted representations by 85.01% with only negligible reduction in utility (1.42%). In addition, we show that Cloak greatly diminishes adversaries\u2019 ability to learn and infer non-conducive features.", "year": 2021, "ssId": "1b57ffe73ae95f339015c174ec574b59f99ea553", "arXivId": null, "link": null, "openAccess": false, "authors": ["FatemehSadat Mireshghallah", "Mohammadkazem Taram", "A. Jalali", "Ahmed T. Elthakeb", "D. Tullsen", "H. Esmaeilzadeh"]}