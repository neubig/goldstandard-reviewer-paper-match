{"title": "Training Data Augmentation and Data Selection", "abstract": "Data augmentation is a simple and efficient technique to improve the robustness of a speech recognizer when deployed in mismatched training-test conditions. Our work, conducted during the JSALT 2015 workshop, aimed at the development of: (1) Data augmentation strategies including noising and reverberation. They were tested in combination with two approaches to signal enhancement: a carefully engineered WPE dereverberation and a learned DNN-based denoising autoencoder. (2) Proposing a novel technique for extracting an informative vector from a Sequence Summarizing Neural Network (SSNN). Similarly to i-vector extractor, the SSNN produces a \u201csummary vector\u201d, representing an acoustic summary of an utterance. Such vector can be used directly for adaptation, but the main usage matching the aim of this chapter is for selection of augmented training data. All techniques were tested on the AMI training set and CHiME3 test set.", "year": 2017, "ssId": "1b97c38d0156dc8bf300b41c2ba5c0463c3a2c00", "arXivId": null, "link": null, "openAccess": false, "authors": ["M. Karafi\u00e1t", "Karel Vesel\u00fd", "Kate\u0159ina \u017dmol\u00edkov\u00e1", "Marc Delcroix", "Shinji Watanabe", "L. Burget", "J. Cernock\u00fd", "Igor Sz\u00f6ke"]}