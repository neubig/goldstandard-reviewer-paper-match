{"title": "A Persistent Spatial Semantic Representation for High-level Natural Language Instruction Execution", "abstract": "Natural language provides an accessible and expressive interface to specify long-term tasks for robotic agents. However, non-experts are likely to specify such tasks with high-level instructions, which abstract over specific robot actions through several layers of abstraction. We propose that key to bridging this gap between language and robot actions over long execution horizons are persistent representations. We propose a persistent spatial semantic representation method, and show how it enables building an agent that performs hierarchical reasoning to effectively execute long-term tasks. We evaluate our approach on the ALFRED benchmark and achieve state-of-the-art results, despite completely avoiding the commonly used step-by-step instructions. https://hlsm-alfred. github.io/", "year": 2021, "ssId": "6536f36648d39f0f9f6105562f76704fcc0b19e8", "arXivId": "2107.05612", "link": "https://arxiv.org/pdf/2107.05612.pdf", "openAccess": true, "authors": ["Valts Blukis", "Chris Paxton", "D. Fox", "Animesh Garg", "Yoav Artzi"]}