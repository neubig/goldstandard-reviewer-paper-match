{"title": "Deep Neural Networks for Estimation and Inference: Application to Causal Effects and Other Semiparametric Estimands", "abstract": "We study deep neural networks and their use in semiparametric inference. We prove valid inference after first-step estimation with deep learning, a result new to the literature. We provide new rates of convergence for deep feedforward neural nets and, because our rates are sufficiently fast (in some cases minimax optimal), obtain valid semiparametric inference. Our estimation rates and semiparametric inference results handle the current standard architecture: fully connected feedforward neural networks (multi-layer perceptrons), with the now-common rectified linear unit activation function and a depth explicitly diverging with the sample size. We discuss other architectures as well, including fixed-width, very deep networks. We establish nonasymptotic bounds for these deep nets for nonparametric regression, covering the standard least squares and logistic losses in particular. We then apply our theory to develop semiparametric inference, focusing on treatment effects, expected welfare, and decomposition effects for concreteness. Inference in many other semiparametric contexts can be readily obtained. We demonstrate the effectiveness of deep learning with a Monte Carlo analysis and an empirical application to direct mail marketing.", "year": 2018, "ssId": "38705aa9e8ce6412d89c5b2beb9379b1013b33c2", "arXivId": "1809.09953", "link": "https://arxiv.org/pdf/1809.09953.pdf", "openAccess": true, "authors": ["M. Farrell", "Tengyuan Liang", "S. Misra"]}