{"title": "A Survey on Programmatic Weak Supervision", "abstract": "Labeling training data has become one of the major roadblocks to using machine learning. Among various weak supervision paradigms, programmatic weak supervision (PWS) has achieved remarkable success in easing the manual labeling bottleneck by programmatically synthesizing training labels from multiple potentially noisy supervision sources. This paper presents a comprehensive survey of recent advances in PWS. In particular, we give a brief introduction of the PWS learning paradigm, and review representative approaches for each component within PWS\u2019s learning workflow. In addition, we discuss complementary learning paradigms for tackling limited labeled data scenarios and how these related approaches can be used in conjunction with PWS. Finally, we identify several critical challenges that remain under-explored in the area to hopefully inspire future research directions in the field.", "year": 2022, "ssId": "0fdc3efc11526995d192f18e19f07fba062a76f7", "arXivId": "2202.05433", "link": "https://arxiv.org/pdf/2202.05433.pdf", "openAccess": true, "authors": ["Jieyu Zhang", "Cheng-Yu Hsieh", "Yue Yu", "Chao Zhang", "Alexander J. Ratner"]}