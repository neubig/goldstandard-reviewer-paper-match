{"title": "Convergence Analysis of Gradient-Based Learning in Continuous Games", "abstract": "Considering a class of gradient-based multiagent learning algorithms in non-cooperative settings, we provide convergence guarantees to a neighborhood of a stable Nash equilibrium. In particular, we consider continuous games where agents learn in 1) deterministic settings with oracle access to their individual gradient and 2) stochastic settings with an unbiased estimator of their individual gradient. We also study the effects of non-uniform learning rates, which cause a distortion of the vector field that can alter the equilibrium to which the agents converge and the learning path. We support the analysis with numerical examples that provide insight into how games may be synthesized to achieve desirable equilibria.", "year": 2019, "ssId": "4a96b2b33786301d59670fa647f99e3dd807abb8", "arXivId": null, "link": null, "openAccess": false, "authors": ["Benjamin J. Chasnov", "L. Ratliff", "Eric V. Mazumdar", "Samuel A. Burden"]}