{"title": "Correcting Exposure Bias for Link Recommendation", "abstract": "Link prediction methods are frequently applied in recommender systems, e.g., to suggest citations for academic papers or friends in social networks. However, exposure bias can arise when users are systematically underexposed to certain relevant items. For example, in citation networks, authors might be more likely to encounter papers from their own field and thus cite them preferentially. This bias can propagate through naively trained link predictors, leading to both biased evaluation and high generalization error (as assessed by true relevance). Moreover, this bias can be exacerbated by feedback loops. We propose estimators that leverage known exposure probabilities to mitigate this bias and consequent feedback loops. Next, we provide a loss function for learning the exposure probabilities from data. Finally, experiments on semi-synthetic data based on real-world citation networks, show that our methods reliably identify (truly) relevant citations. Additionally, our methods lead to greater diversity in the recommended papers\u2019 fields of study. The code is available at github.com/shantanu95/ exposure-bias-link-rec.", "year": 2021, "ssId": "0fcdf20477f907aa50578876226f5fabf5e074ea", "arXivId": "2106.07041", "link": "https://arxiv.org/pdf/2106.07041.pdf", "openAccess": true, "authors": ["Shantanu Gupta", "Hao Wang", "Zachary Chase Lipton", "Bernie Wang"]}