{"title": "Charagram: Embedding Words and Sentences via Character n-grams", "abstract": "We present Charagram embeddings, a simple approach for learning character-based compositional models to embed textual sequences. A word or sentence is represented using a character n-gram count vector, followed by a single nonlinear transformation to yield a low-dimensional embedding. We use three tasks for evaluation: word similarity, sentence similarity, and part-of-speech tagging. We demonstrate that Charagram embeddings outperform more complex architectures based on character-level recurrent and convolutional neural networks, achieving new state-of-the-art performance on several similarity tasks.", "year": 2016, "ssId": "12e9d005c77f76e344361f79c4b008034ae547eb", "arXivId": "1607.02789", "link": "https://arxiv.org/pdf/1607.02789.pdf", "openAccess": true, "authors": ["J. Wieting", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu"]}