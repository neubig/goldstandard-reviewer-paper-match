{"title": "Non-native ASR Utilizing Acoustic Data-driven Pronunciation Learning with Zero Knowledge of Non-native Pronunciation", "abstract": "Non-native speech differs significantly from native speech, often resulting in a degradation of the performance of automatic speech recognition (ASR). Handcrafted pronunciation lexicons used in standard ASR systems generally fail to cover non-native pronunciations, and design of new ones by linguistic experts is time consuming and costly. A previous study proposed a method to automatically learn a pronunciation lexicon in an iterative fashion using knowledge of non-native pronunciation. However, this previous method needs a handcrafted non-native pronunciation lexicon to train a grapheme-to-phoneme (G2P) converter used to generate non-native pronunciation variations, including pronunciations of new words. This non-native pronunciation lexicon is difficult to obtain, and lacks versatility to be applied to other non-native speakers. This study proposes a method for non-native ASR using acoustic evidence for pronunciation learning without knowledge of non-native pronunciation. In experiments, we evaluate our ASR systems for speakers with three degrees of English proficiency level. The results reveal that the proposed method can achieve almost same recognition accuracy with a system using knowledge of a non-native pronunciation, and is able to achieve an improvement of about 2.4% in recognition accuracy, particularly for high-proficiency speakers.", "year": 2015, "ssId": "ce268e0942ce0d1f6942e4d7e7e2aa6464f1b577", "arXivId": null, "link": null, "openAccess": false, "authors": ["Satoshi Tsujioka", "S. Sakti", "Graham Neubig", "Koichiro Yoshino", "Satoshi Nakamura"]}