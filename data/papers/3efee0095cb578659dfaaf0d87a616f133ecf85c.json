{"title": "Acoustic Modeling for Overlapping Speech Recognition: Jhu Chime-5 Challenge System", "abstract": "This paper summarizes our acoustic modeling efforts in the Johns Hopkins University speech recognition system for the CHiME-5 challenge to recognize highly-overlapped dinner party speech recorded by multiple microphone arrays. We explore data augmentation approaches, neural network architectures, front-end speech dereverberation, beamforming and robust i-vector extraction with comparisons of our in-house implementations and publicly available tools. We finally achieved a word error rate of 69.4% on the development set, which is a 11.7% absolute improvement over the previous baseline of 81.1%, and release this improved baseline with refined techniques/tools as an advanced CHiME-5 recipe.", "year": 2019, "ssId": "3efee0095cb578659dfaaf0d87a616f133ecf85c", "arXivId": null, "link": null, "openAccess": false, "authors": ["Vimal Manohar", "Szu-Jui Chen", "Zhiqi Wang", "Yusuke Fujita", "Shinji Watanabe", "S. Khudanpur"]}