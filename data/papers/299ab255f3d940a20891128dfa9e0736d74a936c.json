{"title": "EARLY FUSION for Goal Directed Robotic Vision", "abstract": "Building perceptual systems for robotics which perform well under tight computational budgets requires novel architectures which rethink the traditional computer vision pipeline. Modern vision architectures require the agent to build a summary representation of the entire scene, even if most of the input is irrelevant to the agent\u2019s current goal. In this work, we flip this paradigm, by introducing EARLYFUSION vision models that condition on a goal to build custom representations for downstream tasks. We show that these goal specific representations can be learned more quickly, are substantially more parameter efficient, and more robust than existing attention mechanisms in our domain. We demonstrate the effectiveness of these methods on a simulated item retrieval problem that is trained in a fully end-to-end manner via imitation learning.", "year": 2018, "ssId": "299ab255f3d940a20891128dfa9e0736d74a936c", "arXivId": "1811.08824", "link": "https://arxiv.org/pdf/1811.08824.pdf", "openAccess": true, "authors": ["Aaron Walsman", "Yonatan Bisk", "Saadia Gabriel", "Dipendra Kumar Misra", "Yoav Artzi", "Yejin Choi", "D. Fox"]}