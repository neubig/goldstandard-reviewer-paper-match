{"title": "Discriminative feature transforms using differenced maximum mutual information", "abstract": "Recently feature compensation techniques that train feature transforms using a discriminative criterion have attracted much interest in the speech recognition community. Typically, the acoustic feature space is modeled by a Gaussian mixture model (GMM), and a feature transform is assigned to each Gaussian of the GMM. Feature compensation is then performed by transforming features using the transformation associated with each Gaussian, then summing up the transformed features weighted by the posterior probability of each Gaussian. Several discriminative criteria have been investigated for estimating the feature transformation parameters including maximum mutual information (MMI) and minimum phone error (MPE). Recently, the differenced MMI (dMMI) criterion that generalizes MMI andMPE, has been shown to provide competitive performance for acoustic model training. In this paper, we investigate the use of the dMMI criterion for discriminative feature transforms and demonstrate in a noisy speech recognition experiment that dMMI achieves recognition performance superior to that of MMI or MPE.", "year": 2012, "ssId": "887d84c1310c6e71a0f89874ef9985b65a44c855", "arXivId": null, "link": null, "openAccess": false, "authors": ["Marc Delcroix", "A. Ogawa", "Shinji Watanabe", "T. Nakatani", "A. Nakamura"]}