{"title": "Multi-Channel Speech Recognition : LSTMs All the Way Through", "abstract": "Long Short-Term Memory recurrent neural networks (LSTMs) have demonstrable advantages on a variety of sequential learning tasks. In this paper we demonstrate an LSTM \u201ctriple threat\u201d system for speech recognition, where LSTMs drive the three main subsystems: microphone array processing, acoustic modeling, and language modeling. This LSTM trifecta is applied to the CHiME-4 distant recognition challenge. Our previous state-of-the-art ASR systems for the previous CHiME challenge employed LSTM mask estimation based beamforming, noise robust features, in addition to DNN/RNNLM based back end. The proposed system refines each module of the previous system including bidirectional LSTM (BLSTM) mask estimation based beamforming, BLSTM-DNN hybrid acoustic model, and language model rescoring based on LSTM. We perform constrained re-estimation based speaker adaptation, and also prepare several complementary systems by changing the beamforming strategy and the acoustic model configurations, and combine these systems based on word-posterior based system combination. The final system achieved 2.98% WER for the real test set in the 6-channel track, which reduces the WER from the baseline by 8.5% absolute, and also outperforms our previous CHiME-3 system by 6.1% absolutely.", "year": 2016, "ssId": "ef2e2f3a847667000b591c8708b543eaf259113b", "arXivId": null, "link": null, "openAccess": false, "authors": ["Hakan Erdogan", "Tomoki Hayashi", "J. Hershey", "T. Hori", "Chiori Hori", "Wei-Ning Hsu", "Suyoun Kim", "Jonathan Le Roux", "Zhong Meng", "Shinji Watanabe"]}