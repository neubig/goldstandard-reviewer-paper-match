{"title": "Data-Dependent Regret Bounds", "abstract": "In this scribe note, we provide an overview of recent work deriving data-dependent bounds for adversarial bandits. This line of work asks the question of whether improved regret bounds can be obtained when the loss sequence is not completely adversarial. In other words, while classical algorithms such as Exp3 obtain worst-case optimal regret of \u00d5( \u221a KT ) where K is the number of actions and T is the time-horizon, this line of work explores algorithms that can adapt to easier loss sequences and provides regret bounds in terms of meaningful characteristics of the loss sequence. Deriving results of this nature requires novel algorithms and analysis methods. In particular, variants of optimistic mirror descent framework have emerged as the primary algorithmic method that can naturally adapt to easy data with careful choices of the parameters and the regularization function. We give a high level overview of these methods and highlight main results.", "year": 2021, "ssId": "3fb78bee6cb39588a1a4cbb4e0abce5e362aa130", "arXivId": null, "link": null, "openAccess": false, "authors": ["Omid Sadeghi", "Max Gray", "Tanner Fiez"]}