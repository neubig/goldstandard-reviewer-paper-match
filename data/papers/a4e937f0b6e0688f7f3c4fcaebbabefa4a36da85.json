{"title": "ESPnet2-TTS: Extending the Edge of TTS Research", "abstract": "This paper describes ESPnet2-TTS, an end-to-end text-to-speech (E2E-TTS) toolkit. ESPnet2-TTS extends our earlier version, ESPnet-TTS, by adding many new features, including: on-thefly flexible pre-processing, joint training with neural vocoders, and state-of-the-art TTS models with extensions like full-band E2E textto-waveform modeling, which simplify the training pipeline and further enhance TTS performance. The unified design of our recipes enables users to quickly reproduce state-of-the-art E2E-TTS results. We also provide many pre-trained models in a unified Python interface for inference, offering a quick means for users to generate baseline samples and build demos. Experimental evaluations with English and Japanese corpora demonstrate that our provided models synthesize utterances comparable to ground-truth ones, achieving state-of-the-art TTS performance. The toolkit is available online at https://github.com/espnet/espnet.", "year": 2021, "ssId": "a4e937f0b6e0688f7f3c4fcaebbabefa4a36da85", "arXivId": "2110.07840", "link": "https://arxiv.org/pdf/2110.07840.pdf", "openAccess": true, "authors": ["Tomoki Hayashi", "Ryuichi Yamamoto", "Takenori Yoshimura", "Peter Wu", "Jiatong Shi", "Takaaki Saeki", "Yooncheol Ju", "Yusuke Yasuda", "Shinnosuke Takamichi", "Shinji Watanabe"]}