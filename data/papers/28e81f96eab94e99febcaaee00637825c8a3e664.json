{"title": "Interpretable Machine Learning", "abstract": "The emergence of machine learning as a society-changing technology in the past decade has triggered concerns about people's inability to understand the reasoning of increasingly complex models. The field of IML (interpretable machine learning) grew out of these concerns, with the goal of empowering various stakeholders to tackle use cases, such as building trust in models, performing model debugging, and generally informing real human decision-making.", "year": 2021, "ssId": "28e81f96eab94e99febcaaee00637825c8a3e664", "arXivId": null, "link": null, "openAccess": false, "authors": ["Valerie Chen", "Jeffrey Li", "Joon Sik Kim", "Gregory Plumb", "Ameet S. Talwalkar"]}