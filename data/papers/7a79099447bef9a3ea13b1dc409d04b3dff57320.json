{"title": "Pop Music Transformer: Generating Music with Rhythm and Harmony", "abstract": "The task automatic music composition entails generative modeling of music in symbolic formats such as the musical scores. By serializing a score as a sequence of MIDI-like events, recent work has demonstrated that state-of-the-art sequence models with self-attention work nicely for this task, especially for composing music with long-range coherence. In this paper, we show that sequence models can do even better when we improve the way a musical score is converted into events. The new event set, dubbed \"REMI\" (REvamped MIDI-derived events), provides sequence models a metric context for modeling the rhythmic patterns of music, while allowing for local tempo changes. Moreover, it explicitly sets up a harmonic structure and makes chord progression controllable. It also facilitates coordinating different tracks of a musical piece, such as the piano, bass and drums. With this new approach, we build a Pop Music Transformer that composes Pop piano music with a more plausible rhythmic structure than prior arts do. The code, data and pre-trained model are publicly available.\\footnote{\\url{this https URL}}", "year": 2020, "ssId": "7a79099447bef9a3ea13b1dc409d04b3dff57320", "arXivId": "2002.00212", "link": "https://arxiv.org/pdf/2002.00212.pdf", "openAccess": true, "authors": ["Yu-Siang Huang", "Yi-Hsuan Yang"]}