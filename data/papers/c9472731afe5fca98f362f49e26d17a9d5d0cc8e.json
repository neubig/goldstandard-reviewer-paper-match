{"title": "Against Interpretability: a Critical Examination of the Interpretability Problem in Machine Learning", "abstract": "The usefulness of machine learning algorithms has led to their widespread adoption prior to the development of a conceptual framework for making sense of them. One common response to this situation is to say that machine learning suffers from a \u201cblack box problem.\u201d That is, machine learning algorithms are \u201copaque\u201d to human users, failing to be \u201cinterpretable\u201d or \u201cexplicable\u201d in terms that would render categorization procedures \u201cunderstandable.\u201d The purpose of this paper is to challenge the widespread agreement about the existence and importance of a black box problem. The first section argues that \u201cinterpretability\u201d and cognates lack precise meanings when applied to algorithms. This makes the concepts difficult to use when trying to solve the problems that have motivated the call for interpretability (etc.). Furthermore, since there is no adequate account of the concepts themselves, it is not possible to assess whether particular technical features supply formal definitions of those concepts. The second section argues that there are ways of being a responsible user of these algorithms that do not require interpretability (etc.). In many cases in which a black box problem is cited, interpretability is a means to a further end such as justification or non-discrimination. Since addressing these problems need not involve something that looks like an \u201cinterpretation\u201d (etc.) of an algorithm, the focus on interpretability artificially constrains the solution space by characterizing one possible solution as the problem itself. Where possible, discussion should be reformulated in terms of the ends of interpretability.", "year": 2020, "ssId": "c9472731afe5fca98f362f49e26d17a9d5d0cc8e", "arXivId": null, "link": "https://link.springer.com/content/pdf/10.1007/s13347-019-00372-9.pdf", "openAccess": true, "authors": ["M. Krishnan"]}