{"title": "Residual deep attention mechanism and adaptive reconstruction network for single image super-resolution", "abstract": "The low-level image processing task single image super-resolution (SISR) has a long research history. In recent years, convolutional neural networks (CNNs) have been widely used in single image super-resolution (SISR), and significant performance has been achieved. However, most existing CNN-based SISR methods seldom take into account the feature correlations of the original low-quality images, neglecting to treat spatial and channel-wise features differently. The performance of CNN-based SISR models is often enhanced by deploying very deep networks, which inevitably hinders the representational power of the CNNs and results in many obvious shortcomings. To address these issues, in this paper, we propose a residual deep attention mechanism and adaptive reconstruction network (RAAN) with stronger feature expression and learning abilities. Specifically, to discriminate between large and small gray changes in adjacent areas in LR images, a novel spatial and channel attention processing module (SCAM) is developed that incorporates non-local operations to capture long-distance dependencies between pixels in the spatial domain, and automatically rescales hierarchical features with different weights. Furthermore, we present an enhanced residual attention group (ERAG) structure that not only incorporates some feature processing groups (FPGs), but also contains several source skip connections (SSCs). Similarly, we deploy a global residual long skip connection. With the combination of these skip connections, the low-frequency information flows more effectively to the tail of the network. Moreover, in the upsampling module, we implement four different sizes of convolution kernels (i.e., 3\u00d73, 5\u00d75, 7\u00d77 and 9\u00d79) to extract feature fusion and magnify to the required scale. Experimental results demonstrate the superiority of our RAAN over state-of-the-art SISR methods in terms of both quantitative metrics and visual quality.", "year": 2021, "ssId": "963c4c34f1292f64a6e9fc04428fc7a0893b8ef3", "arXivId": null, "link": null, "openAccess": false, "authors": ["Hongjuan Wang", "Mingrun Wei", "Ruihong Cheng", "Yue Yu", "Xingli Zhang"]}