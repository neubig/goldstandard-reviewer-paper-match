{"title": "Learning a language model from continuous speech", "abstract": "This paper presents a new approach to language model construction, learning a language model not from text, but directly from continuous speech. A phoneme lattice is created using acoustic model scores, and Bayesian techniques are used to robustly learn a language model from this noisy input. A novel sampling technique is devised that allows for the integrated learning of word boundaries and an n-gram language model with no prior linguistic knowledge. The proposed techniques were used to learn a language model directly from continuous, potentially large-vocabulary speech. This language model was able to significantly reduce the ASR phoneme error rate over a separate set of test data, and the proposed lattice processing and lexical acquisition techniques were found to be important factors in this improvement. Index Terms: language acquisition, word segmentation, Pitman-Yor language model, Bayesian learning", "year": 2010, "ssId": "931a103258c96a1230dc5c7e38a1cd0b095b9d62", "arXivId": null, "link": null, "openAccess": false, "authors": ["Graham Neubig", "M. Mimura", "Shinsuke Mori", "Tatsuya Kawahara"]}