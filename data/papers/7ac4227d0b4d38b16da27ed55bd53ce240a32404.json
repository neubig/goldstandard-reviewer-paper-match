{"title": "A Comparative Study on Non-Autoregressive Modelings for Speech-to-Text Generation", "abstract": "Non-autoregressive (NAR) models simultaneously generate multiple outputs in a sequence, which significantly reduces the inference speed at the cost of accuracy drop compared to autoregressive baselines. Showing great potential for real-time applications, an increasing number of NAR models have been explored in different fields to mitigate the performance gap against AR models. In this work, we conduct a comparative study of various NAR modeling methods for end-to-end automatic speech recognition (ASR). Experiments are performed in the state-of-the-art setting using ESPnet. The results on various tasks provide interesting findings for developing an understanding of NAR ASR, such as the accuracy-speed trade-off and robustness against long-form utterances. We also show that the techniques can be combined for further improvement and applied to NAR end-to-end speech translation. All the implementations are publicly available to encourage further research in NAR speech processing.", "year": 2021, "ssId": "7ac4227d0b4d38b16da27ed55bd53ce240a32404", "arXivId": "2110.05249", "link": "https://arxiv.org/pdf/2110.05249.pdf", "openAccess": true, "authors": ["Yosuke Higuchi", "Nanxin Chen", "Yuya Fujita", "H. Inaguma", "Tatsuya Komatsu", "Jaesong Lee", "Jumon Nozaki", "Tianzi Wang", "Shinji Watanabe"]}