{"title": "Scalable Statistical Relational Learning for NLP", "abstract": "Statistical Relational Learning (SRL) is an interdisciplinary research area that combines first\u00adorder logic and machine learning methods for probabilistic inference. Although many Natural Language Processing (NLP) tasks (including text classification, semantic parsing, information extraction, coreference resolution, and sentiment analysis) can be formulated as inference in a first\u00adorder logic, most probabilistic first\u00adorder logics are not efficient enough to be used for large\u00adscale versions of these tasks. In this tutorial, we provide a gentle introduction to the theoretical foundation of probabilistic logics, as well as their applications in NLP. We describe recent advances in designing scalable probabilistic logics, with a special focus on ProPPR. Finally, we provide a hands\u00adon demo about scalable probabilistic logic programming for solving practical NLP problems.", "year": 2016, "ssId": "143183584a8ebaad93490f4550295a9cb6cf9817", "arXivId": null, "link": null, "openAccess": false, "authors": ["William Yang Wang", "William W. Cohen"]}