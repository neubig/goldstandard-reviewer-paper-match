{"title": "Combining Spectral and Self-Supervised Features for Low Resource Speech Recognition and Translation", "abstract": "Self-Supervised Learning (SSL) models have been successfully applied in various deep learning-based speech tasks, particu-larly those with a limited amount of data. However, the quality of SSL representations depends highly on the relatedness between the SSL training domain(s) and the target data domain. On the contrary, spectral feature (SF) extractors such as log Mel-\ufb01lterbanks are hand-crafted non-learnable components, and could be more robust to domain shifts. The present work examines the assumption that combining non-learnable SF extractors to SSL models is an effective approach to low resource speech tasks. We propose a learnable and interpretable framework to combine SF and SSL representations. The proposed framework outperforms signi\ufb01cantly both baseline and SSL models on Automatic Speech Recognition (ASR) and Speech Translation (ST) tasks on three low resource datasets. We addi-tionally design a mixture of experts based combination model. This last model reveals that the relative contribution of SSL models over conventional SF extractors is very small in case of domain mismatch between SSL training set and the target language data.", "year": 2022, "ssId": "b5002aa334f8d0c0e1a4dedad79580e10a928c30", "arXivId": "2204.02470", "link": "https://arxiv.org/pdf/2204.02470.pdf", "openAccess": true, "authors": ["Dan Berrebbi", "Jiatong Shi", "Brian Yan", "Osbel Lopez-Francisco", "Jonathan D. Amith", "Shinji Watanabe"]}