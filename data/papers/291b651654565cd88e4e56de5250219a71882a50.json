{"title": "Peer Selection with Noisy Assessments", "abstract": "In the peer selection problem a group of agents must select a subset of themselves as winners for, e.g., peer-reviewed grants or prizes. Here, we take a Condorcet view of this aggregation problem, i.e., that there is a ground-truth ordering over the agents and we wish to select the best set of agents, subject to the noisy assessments of the peers. Given this model, some agents may be unreliable, while others might be selfinterested, attempting to influence the outcome in their favour. In this paper we extend PeerNomination, the most accurate peer reviewing algorithm to date, into WeightedPeerNomination, which is able to handle noisy and inaccurate agents. To do this, we explicitly formulate assessors\u2019 reliability weights in a way that does not violate strategyproofness, and use this information to reweight their scores. We show analytically that a weighting scheme can improve the overall accuracy of the selection significantly. Finally, we implement several instances of reweighting methods and show empirically that our methods are robust in the face of noisy assessments.", "year": 2021, "ssId": "291b651654565cd88e4e56de5250219a71882a50", "arXivId": "2107.10121", "link": "https://arxiv.org/pdf/2107.10121.pdf", "openAccess": true, "authors": ["Omer Lev", "Nicholas Mattei", "P. Turrini", "Stanislav Zhydkov"]}