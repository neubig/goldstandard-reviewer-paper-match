{"title": "SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference", "abstract": "Given a partial description like \u201cshe opened the hood of the car,\u201d humans can reason about the situation and anticipate what might come next (\u201dthen, she examined the engine\u201d). In this paper, we introduce the task of grounded commonsense inference, unifying natural language inference and commonsense reasoning. We present SWAG, a new dataset with 113k multiple choice questions about a rich spectrum of grounded situations. To address the recurring challenges of the annotation artifacts and human biases found in many existing datasets, we propose Adversarial Filtering (AF), a novel procedure that constructs a de-biased dataset by iteratively training an ensemble of stylistic classifiers, and using them to filter the data. To account for the aggressive adversarial filtering, we use state-of-the-art language models to massively oversample a diverse set of potential counterfactuals. Empirical results demonstrate that while humans can solve the resulting inference problems with high accuracy (88%), various competitive models struggle on our task. We provide comprehensive analysis that indicates significant opportunities for future research.", "year": 2018, "ssId": "af5c4b80fbf847f69a202ba5a780a3dd18c1a027", "arXivId": "1808.05326", "link": "https://arxiv.org/pdf/1808.05326.pdf", "openAccess": true, "authors": ["Rowan Zellers", "Yonatan Bisk", "Roy Schwartz", "Yejin Choi"]}