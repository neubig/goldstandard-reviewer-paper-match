{"title": "Cite-seeing and Reviewing: A Study on Citation Bias in Peer Review", "abstract": "Citations play an important role in researchers\u2019 careers as a key factor in evaluation of scienti\ufb01c impact. Many anecdotes advice authors to exploit this fact and cite prospective reviewers to try obtaining a more positive evaluation for their submission. In this work, we investigate if such a citation bias actually exists: Does the citation of a reviewer\u2019s own work in a submission cause them to be positively biased towards the submission? In conjunction with the review process of two \ufb02agship conferences in machine learning and algorithmic economics, we execute an observational study to test for citation bias in peer review. In our analysis, we carefully account for various confounding factors such as paper quality and reviewer expertise, and apply di\ufb00erent modeling techniques to alleviate concerns regarding the model mismatch. Overall, our analysis involves 1,314 papers and 1,717 reviewers and detects citation bias in both venues we consider. In terms of the e\ufb00ect size, by citing a reviewer\u2019s work, a submission has a non-trivial chance of getting a higher score from the reviewer: an expected increase in the score is approximately 0 . 23 on a 5-point Likert item. For reference, a one-point increase of a score by a single reviewer improves the position of a submission by 11% on average.", "year": 2022, "ssId": "3dc4580a154df87f3a56aa3d16b00c5a935ebe15", "arXivId": "2203.17239", "link": "https://arxiv.org/pdf/2203.17239.pdf", "openAccess": true, "authors": ["Ivan Stelmakh", "Charvi Rastogi", "Ryan Liu", "Shuchi Chawla", "F. Echenique", "Nihar B. Shah"]}