{"title": "Towards Fair, Equitable, and Efficient Peer Review", "abstract": "Peer review is the backbone of academia. The rapid growth of the number of submissions to leading publication venues has identified a need for automation of some parts of the peerreview pipeline and nowadays human referees are required to interact with various interfaces and technologies in this process. However, there exists evidence that if such interactions are not carefully designed, they can exacerbate various problems related to fairness and efficiency of the process. In my research, I aim to design a Human-AI collaboration pipeline in peer review to mitigate these issues and ensure that science progresses in a fair, equitable, and efficient manner. Despite peer review being the primary mechanism of science dissemination for decades, the rapid growth of the number of submissions to leading AI and ML conferences has challenged its sustainability in two ways: \u2022 It has brought up a call for automated tools to assist human decision-makers. \u2022 It has amplified the shortcomings of the peer-review procedure, making them more visible to the community and stressing the importance of research on peer review. These issues motivate my thesis research and I am passionate about working at the intersection of machine learning, operations research, social choice theory, and humancomputer interaction, to understand and develop a principled approach towards scientific peer review. Specifically, I believe that a carefully designed Human-AI collaboration is crucial for sustainability of peer review and in my work I aim at designing tools to support this collaboration. My research touches both algorithmic and human sides of the Human-AI collaboration and in the sequel I first describe my projects on supporting each of these sides. I then outline a direction for future work on bringing these sides to a closer interaction with a goal of improving the peer-review process. On a higher level, my work comprises novel theoretical and empirical contributions: I aim to design practical algorithms that are supported by strong theoretical guarantees and are evaluated in a carefully designed real-world experiments. The preliminary results I discuss below have already had a considerable impact in practice with some tools deployed in ICML 2020, and this inspires me to continue my work towards fair, equitable and efficient peer review. Copyright c \u00a9 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Algorithmic Side. Past research in social science indicates that unfairness of the peer-review process may have farreaching consequences both on a development of research areas and on career trajectories of individual researchers. Therefore, my work on the algorithmic side is twofold: first, I aim to ensure that the algorithms used to automate peer review are themselves fair. Second, I aim at designing algorithms that help conference organizers to promote fairness. Fairness for Algorithms: The most automated part of the review process is the assignment of submissions to referees and most of the of the top AI and ML conferences rely on a simple and efficient matching algorithm developed by Charlin and Zemel (2013). Simultaneously, assignment is of the utmost importance: one cannot expect good reviews for papers that are assigned to unsuitable reviewers. In our past work (Stelmakh, Shah, and Singh 2018) we demonstrate that the state-of-the-art algorithm used by NeurIPS and ICML does not necessarily lead to a fair assignment, discriminating against some papers. More importantly, we design a novel assignment algorithm with provable guarantees on the fairness of the assignment that ensures that no paper is discriminated against to improve the assignment of more lucky counterparts. In addition to strong fairness guarantees, our algorithm is also optimal in terms of the accuracy of final decisions under a popular statistical model, that is, our algorithm theoretically outperforms the state-of-the-art algorithm both in terms of fairness and statistical accuracy. These guarantees are corroborated by an extensive empirical evaluation: in particular, our algorithm was tested and eventually deployed in the assignment of the ICML 2020 conference, improving the fairness by 15-30% while not trading off the conventional measure of the assignment quality. Algorithms for Fairness: While we can prove that algorithms employed to automate peer review satisfy the requirement of fairness, ensuring fairness of decisions made by humans is a more challenging task. An important direction that I am interested in is a use of algorithms to perform statistical testing for fairness and impartiality of final decisions. In our work (Stelmakh, Shah, and Singh 2019), we made the progress on this problem by contributing to the long-standing debate on the fairness of the decisions in single-blind peer review. In that, we design a novel semirandomized experimental procedure that allows to test for The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)", "year": 2021, "ssId": "e318e554098224c9475dfc80765cbbb82fa4a409", "arXivId": null, "link": null, "openAccess": false, "authors": ["Ivan Stelmakh"]}