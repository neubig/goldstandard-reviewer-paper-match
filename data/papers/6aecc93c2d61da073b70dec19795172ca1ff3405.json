{"title": "Counterfactual Invariance to Spurious Correlations: Why and How to Pass Stress Tests", "abstract": "Informally, a \u2018spurious correlation\u2019 is the dependence of a model on some aspect of the input data that an analyst thinks shouldn\u2019t matter. In machine learning, these have a know-it-when-you-see-it character; e.g., changing the gender of a sentence\u2019s subject changes a sentiment predictor\u2019s output. To check for spurious correlations, we can \u2018stress test\u2019 models by perturbing irrelevant parts of input data and seeing if model predictions change. In this paper, we study stress testing using the tools of causal inference. We introduce counterfactual invariance as a formalization of the requirement that changing irrelevant parts of the input shouldn\u2019t change model predictions. We connect counterfactual invariance to outof-domain model performance, and provide practical schemes for learning (approximately) counterfactual invariant predictors (without access to counterfactual examples). It turns out that both the means and implications of counterfactual invariance depend fundamentally on the true underlying causal structure of the data\u2014in particular, whether the label causes the features or the features cause the label. Distinct causal structures require distinct regularization schemes to induce counterfactual invariance. Similarly, counterfactual invariance implies different domain shift guarantees depending on the underlying causal structure. This theory is supported by empirical results on text classification.", "year": 2021, "ssId": "6aecc93c2d61da073b70dec19795172ca1ff3405", "arXivId": "2106.00545", "link": "https://arxiv.org/pdf/2106.00545.pdf", "openAccess": true, "authors": ["Victor Veitch", "A. D'Amour", "S. Yadlowsky", "Jacob Eisenstein"]}