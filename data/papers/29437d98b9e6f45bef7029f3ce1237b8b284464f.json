{"title": "Data-to-Text Generation with Style Imitation", "abstract": "Recent neural approaches to data-to-text generation have mostly focused on improving content fidelity while lacking explicit control over writing styles (e.g., word choices, sentence structures). More traditional systems use templates to determine the realization of text. Yet manual or automatic construction of high-quality templates is difficult, and a template acting as hard constraints could harm content fidelity when it does not match the record perfectly. We study a new way of stylistic control by using existing sentences as soft templates. That is, the model learns to imitate the writing style of any given exemplar sentence, with automatic adaptions to faithfully describe the content record. The problem is challenging due to the lack of parallel data. We develop a neural approach that includes a hybrid attention-copy mechanism, learns with weak supervisions, and is enhanced with a new content coverage constraint. We conduct experiments in restaurants and sports domains. Results show our approach achieves stronger performance than a range of comparison methods. Our approach balances well between content fidelity and style control given exemplars that match the records to varying degrees.", "year": 2019, "ssId": "29437d98b9e6f45bef7029f3ce1237b8b284464f", "arXivId": null, "link": null, "openAccess": false, "authors": ["Shuai Lin", "Wentao Wang", "Zichao Yang", "Xiaodan Liang", "Frank F. Xu", "E. Xing", "Zhiting Hu"]}