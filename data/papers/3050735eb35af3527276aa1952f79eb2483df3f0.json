{"title": "Contextualized Representations for Low-resource Utterance Tagging", "abstract": "Utterance-level analysis of the speaker\u2019s intentions and emotions is a core task in conversational understanding. Depending on the end objective of the conversational understanding task, different categorical dialog-act or affect labels are expertly designed to cover specific aspects of the speakers\u2019 intentions or emotions respectively. Accurately annotating with these labels requires a high level of human expertise, and thus applying this process to a large conversation corpus or new domains is prohibitively expensive. The resulting paucity of data limits the use of sophisticated neural models. In this paper, we tackle these limitations by performing unsupervised training of utterance representations from a large corpus of spontaneous dialogue data. Models initialized with these representations achieve competitive performance on utterance-level dialogue-act recognition and emotion classification, especially in low-resource settings encountered when analyzing conversations in new domains.", "year": 2019, "ssId": "3050735eb35af3527276aa1952f79eb2483df3f0", "arXivId": null, "link": null, "openAccess": false, "authors": ["Bhargavi Paranjape", "Graham Neubig"]}