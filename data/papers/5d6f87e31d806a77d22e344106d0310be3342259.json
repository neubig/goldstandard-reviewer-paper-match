{"title": "Mitigating Manipulation in Peer Review via Randomized Reviewer Assignments", "abstract": "We consider three important challenges in conference peer review: (i) reviewers maliciously attempting to get assigned to certain papers to provide positive reviews, possibly as part of quid-pro-quo arrangements with the authors; (ii) \"torpedo reviewing,\" where reviewers deliberately attempt to get assigned to certain papers that they dislike in order to reject them; (iii) reviewer de-anonymization on release of the similarities and the reviewer-assignment code. On the conceptual front, we identify connections between these three problems and present a framework that brings all these challenges under a common umbrella. We then present a (randomized) algorithm for reviewer assignment that can optimally solve the reviewer-assignment problem under any given constraints on the probability of assignment for any reviewer-paper pair. We further consider the problem of restricting the joint probability that certain suspect pairs of reviewers are assigned to certain papers, and show that this problem is NP-hard for arbitrary constraints on these joint probabilities but efficiently solvable for a practical special case. Finally, we experimentally evaluate our algorithms on datasets from past conferences, where we observe that they can limit the chance that any malicious reviewer gets assigned to their desired paper to 50% while producing assignments with over 90% of the total optimal similarity. Our algorithms still achieve this similarity while also preventing reviewers with close associations from being assigned to the same paper.", "year": 2020, "ssId": "5d6f87e31d806a77d22e344106d0310be3342259", "arXivId": "2006.16437", "link": "https://arxiv.org/pdf/2006.16437.pdf", "openAccess": true, "authors": ["Steven Jecmen", "Hanrui Zhang", "Ryan Liu", "Nihar B. Shah", "V. Conitzer", "Fei Fang"]}