{"title": "A Neural Network for Factoid Question Answering over Paragraphs", "abstract": "Text classification methods for tasks like factoid question answering typically use manually defined string matching rules or bag of words representations. These methods are ineective when question text contains very few individual words (e.g., named entities) that are indicative of the answer. We introduce a recursive neural network (rnn) model that can reason over such input by modeling textual compositionality. We apply our model, qanta, to a dataset of questions from a trivia competition called quiz bowl. Unlike previous rnn models, qanta learns word and phrase-level representations that combine across sentences to reason about entities. The model outperforms multiple baselines and, when combined with information retrieval methods, rivals the best human players.", "year": 2014, "ssId": "af44f5db5b4396e1670cda07eff5ad84145ba843", "arXivId": null, "link": null, "openAccess": false, "authors": ["Mohit Iyyer", "Jordan L. Boyd-Graber", "L. Claudino", "R. Socher", "Hal Daum\u00e9"]}