{"title": "Compression, Transduction, and Creation: A Unified Framework for Evaluating Natural Language Generation", "abstract": "Natural language generation (NLG) spans a broad range of tasks, each of which serves for specific objectives and desires different properties of generated text. The complexity makes automatic evaluation of NLG particularly challenging. Previous work has typically focused on a single task and developed individual evaluation metrics based on specific intuitions. In this paper, we propose a unifying perspective based on the nature of information change in NLG tasks, including compression (e.g., summarization), transduction (e.g., text rewriting), and creation (e.g., dialog). _Information alignment_ between input, context, and output text plays a common central role in characterizing the generation. With automatic alignment prediction models, we develop a family of interpretable metrics that are suitable for evaluating key aspects of different NLG tasks, often without need of gold reference data. Experiments show the uniformly designed metrics achieve stronger or comparable correlations with human judgement compared to state-of-the-art metrics in each of diverse tasks, including text summarization, style transfer, and knowledge-grounded dialog.", "year": 2021, "ssId": "43fae0a7af211d91557d115d2f82e3c46d8bf022", "arXivId": "2109.06379", "link": "https://arxiv.org/pdf/2109.06379.pdf", "openAccess": true, "authors": ["Mingkai Deng", "Bowen Tan", "Zhengzhong Liu", "E. Xing", "Zhiting Hu"]}