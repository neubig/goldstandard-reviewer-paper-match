{"title": "Right Answer for the Wrong Reason: Discovery and Mitigation", "abstract": "Exposing the weaknesses of neural models is crucial for improving their performance and robustness in real-world applications. One common approach is to examine how input perturbations affect the output. Our analysis takes this to an extreme on natural language processing tasks by removing as many words as possible from the input without changing the model prediction. For question answering and natural language inference, this of- ten reduces the inputs to just one or two words, while model confidence remains largely unchanged. This is an undesireable behavior: the model gets the Right Answer for the Wrong Reason (RAWR). We introduce a simple training technique that mitigates this problem while maintaining performance on regular examples.", "year": 2018, "ssId": "ebaae38a09c5a4909049e16af759c71db9cc87dc", "arXivId": null, "link": null, "openAccess": false, "authors": ["Shi Feng", "Eric Wallace", "Mohit Iyyer", "Pedro Rodriguez", "Alvin Grissom II", "Jordan L. Boyd-Graber"]}