{"title": "Exploring Neural Architectures And Techniques For Typologically Diverse Morphological Inflection", "abstract": "Morphological inflection in low resource languages is critical to augment existing corpora in Low Resource Languages, which can help develop several applications in these languages with very good social impact. We describe our attention-based encoder-decoder approach that we implement using LSTMs and Transformers as the base units. We also describe the ancillary techniques that we experimented with, such as hallucination, language vector injection, sparsemax loss and adversarial language network alongside our approach to select the related language(s) for training. We present the results we generated on the constrained as well as unconstrained SIGMORPHON 2020 dataset (CITATION). One of the primary goals of our paper was to study the contribution varied components described above towards the performance of our system and perform an analysis on the same.", "year": 2020, "ssId": "1263e36598dd95cc4becf0e18398f832bb5cf337", "arXivId": null, "link": null, "openAccess": false, "authors": ["P. Jayarao", "Siddhanth Pillay", "P. Thombre", "Aditi Chaudhary"]}