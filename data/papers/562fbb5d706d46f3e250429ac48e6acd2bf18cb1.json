{"title": "ESPnet-SE: End-To-End Speech Enhancement and Separation Toolkit Designed for ASR Integration", "abstract": "We present ESPnet-SE, which is designed for the quick development of speech enhancement and speech separation systems in a single framework, along with the optional downstream speech recognition module. ESPnet-SE is a new project which integrates rich automatic speech recognition related models, resources and systems to support and validate the proposed front-end implementation (i.e. speech enhancement and separation). It is capable of processing both single-channel and multi-channel data, with various functionalities including dereverberation, denoising and source separation. We provide all-in-one recipes including data pre-processing, feature extraction, training and evaluation pipelines for a wide range of benchmark datasets. This paper describes the design of the toolkit, several important functionalities, especially the speech recognition integration, which differentiates ESPnet-SE from other open source toolkits, and experimental results with major benchmark datasets.", "year": 2020, "ssId": "562fbb5d706d46f3e250429ac48e6acd2bf18cb1", "arXivId": "2011.03706", "link": "https://arxiv.org/pdf/2011.03706.pdf", "openAccess": true, "authors": ["Chenda Li", "Jing Shi", "Wangyou Zhang", "A. Subramanian", "Xuankai Chang", "Naoyuki Kamo", "Moto Hira", "Tomoki Hayashi", "Christoph Boeddeker", "Zhuo Chen", "Shinji Watanabe"]}