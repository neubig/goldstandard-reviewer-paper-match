{"title": "TextGraphs 2020 Shared Task on Multi-Hop Inference for Explanation Regeneration", "abstract": "The 2020 Shared Task on Multi-Hop Inference for Explanation Regeneration tasks participants with regenerating large detailed multi-fact explanations for standardized science exam questions. Given a question, correct answer, and knowledge base, models must rank each fact in the knowledge base such that facts most likely to appear in the explanation are ranked highest. Explanations consist of an average of 6 (and as many as 16) facts that span both core scientific knowledge and world knowledge, and form an explicit lexically-connected \u201cexplanation graph\u201d describing how the facts interrelate. In this second iteration of the explanation regeneration shared task, participants are supplied with more than double the training and evaluation data of the first shared task, as well as a knowledge base nearly double in size, both of which expand into more challenging scientific topics that increase the difficulty of the task. In total 10 teams participated, and 5 teams submitted system description papers. The best-performing teams significantly increased state-of-the-art performance both in terms of ranking (mean average precision) and inference speed on this challenge task.", "year": 2020, "ssId": "c143d2b09bdfc0dff784dce2668fd5657806dbf2", "arXivId": null, "link": null, "openAccess": false, "authors": ["Peter Alexander Jansen", "Dmitry Ustalov"]}