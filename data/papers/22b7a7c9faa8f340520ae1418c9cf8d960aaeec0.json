{"title": "Chapter 5. Answering Natural-Language Questions with Neuro-Symbolic Knowledge Bases", "abstract": "Symbolic reasoning systems based on first-order logics are computationally powerful, and feedforward neural networks are computationally efficient, so unless P=NP, neural networks cannot, in general, emulate symbolic logics. Hence bridging the gap between neural and symbolic methods requires achieving a delicate balance: one needs to incorporate just enough of symbolic reasoning to be useful for a task, but not so much as to cause computational intractability. In this chapter we first present results that make this claim precise, and then use these formal results to inform the choice of a neuro-symbolic knowledge-based reasoning system, based on a set-based dataflow query language. We then present experimental results with a number of variants of this neuro-symbolic reasoner, and also show that this neuro-symbolic reasoner can be closely integrated into modern neural language models.", "year": 2021, "ssId": "22b7a7c9faa8f340520ae1418c9cf8d960aaeec0", "arXivId": null, "link": null, "openAccess": false, "authors": ["Haitian Sun", "Pat Verga", "William W. Cohen"]}