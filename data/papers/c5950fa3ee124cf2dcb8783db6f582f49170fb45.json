{"title": "RATT: Leveraging Unlabeled Data to Guarantee Generalization", "abstract": "To assess generalization, machine learning scientists typically either (i) bound the generalization gap and then (after training) plug in the empirical risk to obtain a bound on the true risk; or (ii) validate empirically on holdout data. However, (i) typically yields vacuous guarantees for overparameterized models; and (ii) shrinks the training set and its guarantee erodes with each reuse of the holdout set. In this paper, we leverage unlabeled data to produce generalization bounds. After augmenting our (labeled) training set with randomly labeled data, we train in the standard fashion. Whenever classifiers achieve low error on the clean data but high error on the random data, our bound ensures that the true risk is low. We prove that our bound is valid for 0-1 empirical risk minimization and with linear classifiers trained by gradient descent. Our approach is especially useful in conjunction with deep learning due to the early learning phenomenon whereby networks fit true labels before noisy labels but requires one intuitive assumption. Empirically, on canonical computer vision and NLP tasks, our bound provides non-vacuous generalization guarantees that track actual performance closely. This work enables practitioners to certify generalization even when (labeled) holdout data is unavailable and provides insights into the relationship between random label noise and generalization.", "year": 2021, "ssId": "c5950fa3ee124cf2dcb8783db6f582f49170fb45", "arXivId": "2105.00303", "link": "https://arxiv.org/pdf/2105.00303.pdf", "openAccess": true, "authors": ["S. Garg", "Sivaraman Balakrishnan", "J. Z. Kolter", "Zachary Chase Lipton"]}