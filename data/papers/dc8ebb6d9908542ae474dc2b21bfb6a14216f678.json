{"title": "How far can we get with one GPU in 100 hours? CoAStaL at MultiIndicMT Shared Task", "abstract": "This work shows that competitive translation results can be obtained in a constrained setting by incorporating the latest advances in memory and compute optimization. We train and evaluate large multilingual translation models using a single GPU for a maximum of 100 hours and get within 4-5 BLEU points of the top submission on the leaderboard. We also benchmark standard baselines on the PMI corpus and re-discover well-known shortcomings of translation systems and metrics.", "year": 2021, "ssId": "dc8ebb6d9908542ae474dc2b21bfb6a14216f678", "arXivId": null, "link": null, "openAccess": false, "authors": ["Rahul Aralikatte", "H\u00e9ctor Murrieta Bello", "Miryam de Lhoneux", "Daniel Hershcovich", "Marcel Bollmann", "Anders S\u00f8gaard"]}