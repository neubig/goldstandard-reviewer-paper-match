{"title": "Deep Performer: Score-to-Audio Music Performance Synthesis", "abstract": "Music performance synthesis aims to synthesize a musical score into a natural performance. In this paper, we borrow recent advances in text-to-speech synthesis and present the Deep Performer\u2014a novel system for score-to-audio music performance synthesis. Unlike speech, music often contains polyphony and long notes. Hence, we propose two new techniques for handling polyphonic inputs and providing a finegrained conditioning in a transformer encoder-decoder model. To train our proposed system, we present a new violin dataset consisting of paired recordings and scores along with estimated alignments between them. We show that our proposed model can synthesize music with clear polyphony and harmonic structures. In a listening test, we achieve competitive quality against the baseline model, a conditional generative audio model, in terms of pitch accuracy, timbre and noise level. Moreover, our proposed model significantly outperforms the baseline on an existing piano dataset in overall quality.", "year": 2022, "ssId": "4e3016617e5e254bafebcbd7e96c509f670bdd37", "arXivId": "2202.06034", "link": "https://arxiv.org/pdf/2202.06034.pdf", "openAccess": true, "authors": ["Hao-Wen Dong", "Cong Zhou", "Taylor Berg-Kirkpatrick", "Julian McAuley"]}