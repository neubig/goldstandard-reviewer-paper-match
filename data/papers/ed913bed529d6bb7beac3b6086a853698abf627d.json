{"title": "Speech Processing for Digital Home Assistants", "abstract": "Once a popular theme of futuristic science fiction or far-fetched technology forecasts, digital home assistants with a spoken language interface have become a ubiquitous commodity today. This success has been made possible by major advancements in signal processing and machine learning for so-called far-field speech recognition, where the commands are spoken at a distance from the sound capturing device. The challenges encountered are quite unique and different from many other use cases of automatic speech recognition. The purpose of this tutorial article is to describe, in a way amenable to the non-specialist, the key speech processing algorithms that enable reliable fully hands-free speech interaction with digital home assistants. These technologies include multi-channel acoustic echo cancellation, microphone array processing and dereverberation techniques for signal enhancement, reliable wake-up word and end-of-interaction detection, high-quality speech synthesis, as well as sophisticated statistical models for speech and language, learned from large amounts of heterogeneous training data. In all these fields, deep learning has occupied a critical role.", "year": 2019, "ssId": "ed913bed529d6bb7beac3b6086a853698abf627d", "arXivId": null, "link": null, "openAccess": false, "authors": ["R. Haeb-Umbach", "Shinji Watanabe", "T. Nakatani", "M. Bacchiani", "Bj\u00f6rn Hoffmeister", "M. Seltzer", "H. Zen", "M. Souden"]}