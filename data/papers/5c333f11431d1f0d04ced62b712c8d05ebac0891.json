{"title": "Conditional Diffusion Probabilistic Model for Speech Enhancement", "abstract": "Speech enhancement is a critical component of many user-oriented audio applications, yet current systems still suffer from distorted and unnatural outputs. While generative models have shown strong potential in speech synthesis, they are still lagging behind in speech enhancement. This work leverages recent advances in diffusion probabilistic models, and proposes a novel speech enhancement algorithm that incorporates characteristics of the observed noisy speech signal into the diffusion and reverse processes. More specifically, we propose a generalized formulation of the diffusion probabilistic model named conditional diffusion probabilistic model that, in its reverse process, can adapt to non-Gaussian real noises in the estimated speech signal. In our experiments, we demonstrate strong performance of the proposed approach compared to representative generative models, and investigate the generalization capability of our models to other datasets with noise characteristics unseen during training.", "year": 2022, "ssId": "5c333f11431d1f0d04ced62b712c8d05ebac0891", "arXivId": "2202.05256", "link": "https://arxiv.org/pdf/2202.05256.pdf", "openAccess": true, "authors": ["Yen-Ju Lu", "Zhongqiu Wang", "Shinji Watanabe", "Alexander Richard", "Cheng Yu", "Yu Tsao"]}