{"title": "Conditional Poisson Stochastic Beam Search", "abstract": "Beam search is the default decoding strategy for many sequence generation tasks in NLP. The set of approximate K-best items returned by the algorithm is a useful summary of the distribution for many applications; however, the candidates typically exhibit high overlap and may give a highly biased estimate for expectations under our model. These problems can be addressed by instead using stochastic decoding strategies. In this work, we propose a new method for turning beam search into a stochastic process: Conditional Poisson stochastic beam search. Rather than taking the maximizing set at each iteration, we sampleK candidates without replacement according to the conditional Poisson sampling design. We view this as a more natural alternative to Kool et al. (2019)\u2019s stochastic beam search (SBS). Furthermore, we show how samples generated under the CPSBS design can be used to build consistent estimators and sample diverse sets from sequence models. In our experiments, we observe CPSBS produces lower variance and more efficient estimators than SBS, even showing improvements in high entropy settings.1", "year": 2021, "ssId": "840fabc2a7773e1bd771f152f76210b2ea5845b9", "arXivId": "2109.11034", "link": "https://arxiv.org/pdf/2109.11034.pdf", "openAccess": true, "authors": ["Clara Meister", "Afra Amini", "Tim Vieira", "Ryan Cotterell"]}