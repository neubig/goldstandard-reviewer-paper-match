{"title": "Simple , Correct Parallelization for Blocked Gibbs Sampling Graham Neubig November", "abstract": "We present a method for distributing collapsed Gibbs sampling over multiple processors that is simple, statistically correct, and memory efficient. The method uses blocked sampling, dividing the training data into relatively large sized blocks, and distributing the sampling of each block over multiple processors. At the end of each parallel run, MetropolisHastings rejection sampling is performed to ensure that samples are being drawn from the correct distribution. Empirical results on part-of-speech tagging and word segmentation tasks show that the proposed blocked sampling method can sample from the true distribution while achieving convergence speed comparable with previous parallel sampling methods.", "year": 2014, "ssId": "924e43c4de98743d2e7c14c241b03b2109325b90", "arXivId": null, "link": null, "openAccess": false, "authors": ["Graham Neubig"]}