{"title": "A Study on Speech Enhancement Based on Diffusion Probabilistic Model", "abstract": "Diffusion probabilistic models have demonstrated an outstanding capability to model natural images and raw audio waveforms through a paired diffusion and reverse processes. The unique property of the reverse process (namely, eliminating non-target signals from the Gaussian noise and noisy signals) could be utilized to restore clean signals. Based on this prop-erty, we propose a diffusion probabilistic model-based speech enhancement (DiffuSE) model that aims to recover clean speech signals from noisy signals. The fundamental architecture of the proposed DiffuSE model is similar to that of DiffWave-a high-quality audio waveform generation model that has a relatively low computational cost and footprint. To attain better enhancement performance, we designed an advanced reverse process, termed the supportive reverse process, which adds noisy speech in each time-step to the predicted speech. The experimental results show that DiffuSE yields performance that is comparable to related audio generative models on the standardized Voice Bank corpus SE task. Moreover, relative to the generally suggested full sam-pling schedule, the proposed supportive reverse process especially improved the fast sampling, taking few steps to yield better enhancement results over the conventional full step inference process.", "year": 2021, "ssId": "553b74de8cb7ebca42a686e2a3a2d6aae170946e", "arXivId": "2107.11876", "link": "https://arxiv.org/pdf/2107.11876.pdf", "openAccess": true, "authors": ["Yen-Ju Lu", "Yu Tsao", "Shinji Watanabe"]}