{"title": "Multimodal Conditional Image Synthesis with Product-of-Experts GANs", "abstract": "Existing conditional image synthesis frameworks generate images based on user inputs in a single modality, such as text, segmentation, sketch, or style reference. They are often unable to leverage multimodal user inputs when available, which reduces their practicality. To address this limitation, we propose the Product-of-Experts Generative Adversarial Networks (PoE-GAN) framework, which can synthesize images conditioned on multiple input modalities or any subset of them, even the empty set. PoE-GAN consists of a productof-experts generator and a multimodal multiscale projection discriminator. Through our carefully designed training scheme, PoE-GAN learns to synthesize images with high quality and diversity. Besides advancing the state of the art in multimodal conditional image synthesis, PoE-GAN also outperforms the best existing unimodal conditional image synthesis approaches when tested in the unimodal setting. The project website is available at this link.", "year": 2021, "ssId": "3cd4797725ca9cf954946ed5309e15ebab80b92a", "arXivId": "2112.05130", "link": "https://arxiv.org/pdf/2112.05130.pdf", "openAccess": true, "authors": ["Xun Huang", "Arun Mallya", "Ting-Chun Wang", "Ming-Yu Liu"]}