{"title": "Calibration with Privacy in Peer Review", "abstract": "Reviewers in peer review are often miscalibrated: they may be strict, lenient, extreme, moderate, etc. A number of algorithms have previously been proposed to calibrate reviews. Such attempts of calibration can however leak sensitive information about which reviewer reviewed which paper. In this paper, we identify this problem of calibration with privacy, and provide a foundational building block to address it. Specifically, we present a theoretical study of this problem under a simplified-yet-challenging model involving two reviewers, two papers, and an MAP-computing adversary. Our main results establish the Pareto frontier of the tradeoff between privacy (preventing the adversary from inferring reviewer identity) and utility (accepting better papers), and design explicit computationally-efficient algorithms that we prove are Pareto optimal.", "year": 2022, "ssId": "8b73e226815d57bf66fc94905ebd063e4957b449", "arXivId": "2201.11308", "link": "https://arxiv.org/pdf/2201.11308.pdf", "openAccess": true, "authors": ["Wenxin Ding", "Gautam Kamath", "Weina Wang", "Nihar B. Shah"]}