{"title": "Towards Connecting Use Cases and Methods in Interpretable Machine Learning", "abstract": "Despite increasing interest in the field of Interpretable Machine Learning (IML), a significant gap persists between the technical objectives targeted by researchers\u2019 methods and the high-level goals of consumers\u2019 use cases. In this work, we synthesize foundational work on IML methods and evaluation into an actionable taxonomy. This taxonomy serves as a tool to conceptualize the gap between researchers and consumers, illustrated by the lack of connections between its methods and use cases components. It also provides the foundation from which we describe a three-step workflow to better enable researchers and consumers to work together to discover what types of methods are useful for what use cases. Eventually, by building on the results generated from this workflow, a more complete version of the taxonomy will increasingly allow consumers to find relevant methods for their target use cases and researchers to identify applicable use cases for their proposed methods.", "year": 2021, "ssId": "ef59f05a30972742a714b8903848e4b5dfc5cdaf", "arXivId": null, "link": null, "openAccess": false, "authors": ["Valerie Chen", "Jeffrey Li", "Joon Sik Kim", "Gregory Plumb", "Ameet S. Talwalkar"]}