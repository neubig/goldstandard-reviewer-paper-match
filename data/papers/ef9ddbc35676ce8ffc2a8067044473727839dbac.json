{"title": "Breaking the Softmax Bottleneck: A High-Rank RNN Language Model", "abstract": "We formulate language modeling as a matrix factorization problem, and show that the expressiveness of Softmax-based models (including the majority of neural language models) is limited by a Softmax bottleneck. Given that natural language is highly context-dependent, this further implies that in practice Softmax with distributed word embeddings does not have enough capacity to model natural language. We propose a simple and effective method to address this issue, and improve the state-of-the-art perplexities on Penn Treebank and WikiText-2 to 47.69 and 40.68 respectively.", "year": 2017, "ssId": "ef9ddbc35676ce8ffc2a8067044473727839dbac", "arXivId": "1711.03953", "link": "https://arxiv.org/pdf/1711.03953.pdf", "openAccess": true, "authors": ["Zhilin Yang", "Zihang Dai", "R. Salakhutdinov", "William W. Cohen"]}