{"title": "Artificial Intelligence and Natural Language: 8th Conference, AINL 2019, Tartu, Estonia, November 20\u201322, 2019, Proceedings", "abstract": "This study discusses the effects of training data size and class imbalance on the performance of classifiers. An empirical study was performed on nine classifiers with twenty benchmark datasets. First, two groups of datasets (those with few variables and those with numerous variables) were prepared. Then we progressively increased the class imbalance of each dataset in each group by undersampling both classes so that we could clarify to what extent the predictive power of each classifier was adversely affected. Kappa coefficient (kappa) was chosen as the performance metric, and nemenyi post hoc test was used to find significant differences between classifiers. Additionally, the ranks of nine classifiers in different conditions were discussed. The results indicated that (1) Na\u00efve bayes, logistic regression and logit leaf model are less susceptible to class imbalance; (2) It was assumed that using datasets with balanced class distribution and sufficient instances would be the ideal condition to maximize the performance of classifiers; (3) Increasing the number of instances is more effective than using variables for improving the predictive performance of Random Forest. Furthermore, our experiment clarified the optimal classifiers for four types of datasets.", "year": 2019, "ssId": "7f85b7ee0fc6cdb5b92417035a7049247729545a", "arXivId": null, "link": null, "openAccess": false, "authors": ["Phoebe Chen", "A. Cuzzocrea", "Xiaoyong Du", "Orhun Kara", "Ting Liu", "K. Sivalingam", "D. \u015al\u0119zak", "T. Washio", "Xiaokang Yang", "Junsong Yuan", "Simone Diniz Junqueira Barbosa", "Dmitry Ustalov", "A. Filchenkov", "Lidia Pivovarova"]}