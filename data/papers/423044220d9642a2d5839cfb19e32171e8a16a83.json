{"title": "Rebounding Bandits for Modeling Satiation Effects", "abstract": "Psychological research shows that enjoyment of many goods is subject to satiation, with enjoyment declining after repeated exposures to the same item. Nevertheless, proposed algorithms for powering recommender systems seldom model these dynamics, instead proceeding as though user preferences were fixed in time. In this work, we adopt a multi-armed bandit setup, modeling satiation dynamics as a time-invariant linear dynamical system. In our model, the expected rewards for each arm decline monotonically with consecutive exposures and rebound towards the initial reward whenever that arm is not pulled. We analyze this model, showing that, when the arms exhibit deterministic identical dynamics, our problem is equivalent to a specific instance of Max K-Cut. In this case, a greedy policy, which plays the arms in a cyclic order, is optimal. In the general setting, where each arm's satiation dynamics are stochastic and governed by different (unknown) parameters, we propose an algorithm that first uses offline data to estimate each arm's reward model and then plans using a generalization of the greedy policy.", "year": 2020, "ssId": "423044220d9642a2d5839cfb19e32171e8a16a83", "arXivId": "2011.06741", "link": "https://arxiv.org/pdf/2011.06741.pdf", "openAccess": true, "authors": ["Liu Leqi", "F. K\u0131l\u0131n\u00e7-Karzan", "Zachary Chase Lipton", "A. Montgomery"]}