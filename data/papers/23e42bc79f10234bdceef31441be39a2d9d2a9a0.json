{"title": "Differentiable Learning of Logical Rules for Knowledge Base Reasoning", "abstract": "We study the problem of learning probabilistic first-order logical rules for knowledge base reasoning. This learning problem is difficult because it requires learning the parameters in a continuous space as well as the structure in a discrete space. We propose a framework, Neural Logic Programming, that combines the parameter and structure learning of first-order logical rules in an end-to-end differentiable model. This approach is inspired by a recently-developed differentiable logic called TensorLog, where inference tasks can be compiled into sequences of differentiable operations. We design a neural controller system that learns to compose these operations. Empirically, our method outperforms prior work on multiple knowledge base benchmark datasets, including Freebase and WikiMovies.", "year": 2017, "ssId": "23e42bc79f10234bdceef31441be39a2d9d2a9a0", "arXivId": null, "link": null, "openAccess": false, "authors": ["Fan Yang", "Zhilin Yang", "William W. Cohen"]}