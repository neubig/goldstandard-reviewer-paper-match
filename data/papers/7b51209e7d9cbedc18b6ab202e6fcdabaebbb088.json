{"title": "Continuous space discriminative language modeling", "abstract": "Discriminative language modeling is a structured classification problem. Log-linear models have been previously used to address this problem. In this paper, the standard dot-product feature representation used in log-linear models is replaced by a non-linear function parameterized by a neural network. Embeddings are learned for each word and features are extracted automatically through the use of convolutional layers. Experimental results show that as a stand-alone model the continuous space model yields significantly lower word error rate (1% absolute), while having a much more compact parameterization (60%-90% smaller). If the baseline scores are combined, our approach performs equally well.", "year": 2012, "ssId": "7b51209e7d9cbedc18b6ab202e6fcdabaebbb088", "arXivId": null, "link": null, "openAccess": false, "authors": ["Puyang Xu", "S. Khudanpur", "M. Lehr", "Emily Tucker Prud'hommeaux", "N. Glenn", "D. Karakos", "Brian Roark", "Kenji Sagae", "M. Sara\u00e7lar", "I. Shafran", "D. Bikel", "Chris Callison-Burch", "Yuan Cao", "Keith B. Hall", "E. Hasler", "Philipp Koehn", "Adam Lopez", "Matt Post", "Darcey Riley"]}