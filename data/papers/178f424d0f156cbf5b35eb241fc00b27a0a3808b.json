{"title": "Speech enhancement and recognition using multi-task learning of long short-term memory recurrent neural networks", "abstract": "Long Short-Term Memory (LSTM) recurrent neural network has \nproven effective in modeling speech and has achieved outstanding \nperformance in both speech enhancement (SE) and automatic \nspeech recognition (ASR). To further improve the performance of \nnoise-robust speech recognition, a combination of speech enhancement \nand recognition was shown to be promising in earlier work. \nThis paper aims to explore options for consistent integration of SE \nand ASR using LSTM networks. Since SE and ASR have different \nobjective criteria, it is not clear what kind of integration would \nfinally lead to the best word error rate for noise-robust ASR tasks. \nIn this work, several integration architectures are proposed and \ntested, including: (1) a pipeline architecture of LSTM-based SE and \nASR with sequence training, (2) an alternating estimation architecture, \nand (3) a multi-task hybrid LSTM network architecture. \nThe proposed models were evaluated on the 2nd CHiME speech \nseparation and recognition challenge task, and show significant \nimprovements relative to prior results.", "year": 2015, "ssId": "178f424d0f156cbf5b35eb241fc00b27a0a3808b", "arXivId": null, "link": null, "openAccess": false, "authors": ["Zhuo Chen", "Shinji Watanabe", "Hakan Erdogan", "J. Hershey"]}