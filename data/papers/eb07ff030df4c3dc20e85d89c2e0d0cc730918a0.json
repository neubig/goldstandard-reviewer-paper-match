{"title": "Continuous Speech Separation Using Speaker Inventory for Long Multi-talker Recording", "abstract": "Leveraging additional speaker information to facilitate speech separation has received increasing attention in recent years. Recent research includes extracting target speech by using the target speaker's voice snippet and jointly separating all participating speakers by using a pool of additional speaker signals, which is known as speech separation using speaker inventory (SSUSI). However, all these systems ideally assume that the pre-enrolled speaker signals are available and are only evaluated on simple data configurations. In realistic multi-talker conversations, the speech signal contains a large proportion of non-overlapped regions, where we can derive robust speaker embedding of individual talkers. In this work, we adopt the SSUSI model in long recordings and propose a self-informed, clustering-based inventory forming scheme for long recording, where the speaker inventory is fully built from the input signal without the need for external speaker signals. Experiment results on simulated noisy reverberant long recording datasets show that the proposed method can significantly improve the separation performance across various conditions.", "year": 2020, "ssId": "eb07ff030df4c3dc20e85d89c2e0d0cc730918a0", "arXivId": "2012.09727", "link": "https://arxiv.org/pdf/2012.09727.pdf", "openAccess": true, "authors": ["Cong Han", "Yi Luo", "Chenda Li", "Tianyan Zhou", "K. Kinoshita", "Shinji Watanabe", "Marc Delcroix", "Hakan Erdogan", "J. Hershey", "N. Mesgarani", "Zhuo Chen"]}