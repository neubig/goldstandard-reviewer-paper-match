{"title": "Risk-Sensitive Inverse Reinforcement Learning via Gradient Methods", "abstract": "We address the problem of inverse reinforcement learning in Markov decision processes where the agent is risk-sensitive. In particular, we model risk-sensitivity in a reinforcement learning framework by making use of models of human decisionmaking having their origins in behavioral psychology, behavioral economics, and neuroscience. We propose a gradient-based inverse reinforcement learning algorithm that minimizes a loss function defined on the observed behavior. We demonstrate the performance of the proposed technique on two examples, the first of which is the canonical Grid World example and the second of which is a MDP modeling passengers\u2019 decisions regarding ride-sharing. In the latter, we use pricing and travel time data from a ride-sharing company to construct the transition probabilities and rewards of the MDP.", "year": 2017, "ssId": "c14254fd285706e549d0dcc57ae74680164c9afc", "arXivId": "1703.09842", "link": "https://arxiv.org/pdf/1703.09842.pdf", "openAccess": true, "authors": ["L. Ratliff", "Eric V. Mazumdar"]}