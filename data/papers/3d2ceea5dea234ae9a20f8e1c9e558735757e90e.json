{"title": "Universal Phone Recognition with a Multilingual Allophone System", "abstract": "Multilingual models can improve language processing, particularly for low resource situations, by sharing parameters across languages. Multilingual acoustic models, however, generally ignore the difference between phonemes (sounds that can support lexical contrasts in a particular language) and their corresponding phones (the sounds that are actually spoken, which are language independent). This can lead to performance degradation when combining a variety of training languages, as identically annotated phonemes can actually correspond to several different underlying phonetic realizations. In this work, we propose a joint model of both language-independent phone and language-dependent phoneme distributions. In multilingual ASR experiments over 11 languages, we find that this model improves testing performance by 2% phoneme error rate absolute in low-resource conditions. Additionally, because we are explicitly modeling language-independent phones, we can build a (nearly-)universal phone recognizer that, when combined with the PHOIBLE [1] large, manually curated database of phone inventories, can be customized into 2,000 language dependent recognizers. Experiments on two low-resourced indigenous languages, Inuktitut and Tusom, show that our recognizer achieves phone accuracy improvements of more than 17%, moving a step closer to speech recognition for all languages in the world.1", "year": 2020, "ssId": "3d2ceea5dea234ae9a20f8e1c9e558735757e90e", "arXivId": "2002.11800", "link": "https://arxiv.org/pdf/2002.11800.pdf", "openAccess": true, "authors": ["Xinjian Li", "Siddharth Dalmia", "Juncheng Billy Li", "Matthew Russell Lee", "Patrick Littell", "Jiali Yao", "Antonios Anastasopoulos", "David R. Mortensen", "Graham Neubig", "A. Black", "Florian Metze"]}