{"title": "Efficient Dialogue Policy Learning with BBQ-Networks", "abstract": "We present a new algorithm that significantly improves the efficiency of exploration for deep Q-learning agents in dialogue systems. Our agents explore via Thompson sampling, drawing Monte Carlo samples from a Bayes-by-Backprop neural network. Our algorithm learns much faster than common exploration strategies such as greedy, Boltzmann exploration, and bootstrapping-based approaches. Additionally, we show that spiking the replay buffer with experiences from just a few successful episodes can make Q-learning feasible when it might otherwise fail.", "year": 2016, "ssId": "ab193c05bc447f368565c1ff37064b1c517a750f", "arXivId": "1608.05081", "link": "https://arxiv.org/pdf/1608.05081.pdf", "openAccess": true, "authors": ["Zachary Chase Lipton", "Xiujun Li", "Jianfeng Gao", "Lihong Li", "Faisal Ahmed", "L. Deng"]}