{"id": "9e0d3161b13481418b7e85e3a691d23d67cf1e68", "content": {"title": "DRAG: Dynamic Region-Aware GCN for Privacy-Leaking Image Detection", "abstract": "The daily practice of sharing images on social media raises a severe issue about privacy leakage. To address the issue, privacy-leaking image detection is studied recently, with the goal to automatically identify images that may leak privacy. Recent advance on this task benefits from focusing on crucial objects via pretrained object detectors and modeling their correlation. However, these methods have two limitations: 1) they neglect other important elements like scenes, textures, and objects beyond the capacity of pretrained object detectors; 2) the correlation among objects is fixed, but a fixed correlation is not appropriate for all the images. To overcome the limitations, we propose the Dynamic RegionAware Graph Convolutional Network (DRAG) that dynamically finds out crucial regions including objects and other important elements, and models their correlation adaptively for each input image. To find out crucial regions, we cluster spatially-correlated feature channels into several regionaware feature maps. Further, we dynamically model the correlation with the self-attention mechanism and explore the interaction among the regions with a graph convolutional network. The DRAG achieved an accuracy of 87% on the largest dataset for privacy-leaking image detection, which is 10 percentage points higher than the state of the art. The further case study demonstrates that it found out crucial regions containing not only objects but other important elements like textures. The code and more details are in https: //github.com/guang-yanng/DRAG.", "year": 2022, "ssId": "9e0d3161b13481418b7e85e3a691d23d67cf1e68", "arXivId": "2203.09121", "link": "https://arxiv.org/pdf/2203.09121.pdf", "openAccess": true, "authors": ["Guang Yang", "Juan Cao", "Qiang Sheng", "Peng Qi", "Xirong Li", "Jintao Li"]}}
{"id": "46f66dd37e6366ce102cfd97e718947151d5b1eb", "content": {"title": "Zoom Out and Observe: News Environment Perception for Fake News Detection", "abstract": "Fake news detection is crucial for preventing the dissemination of misinformation on social media. To differentiate fake news from real ones, existing methods observe the language patterns of the news post and \u201czoom in\u201d to verify its content with knowledge sources or check its readers\u2019 replies. However, these methods neglect the information in the external news environment where a fake news post is created and disseminated. The news environment represents recent mainstream media opinion and public attention, which is an important inspiration of fake news fabrication because fake news is often designed to ride the wave of popular events and catch public attention with unexpected novel content for greater exposure and spread. To capture the environmental signals of news posts, we \u201czoom out\u201d to observe the news environment and propose the News Environment Perception Framework (NEP). For each post, we construct its macro and micro news environment from recent mainstream news. Then we design a popularity-oriented and a novelty-oriented module to perceive useful signals and further assist \ufb01nal prediction. Experiments on our newly built datasets show that the NEP can ef\ufb01-ciently improve the performance of basic fake news detectors. 1", "year": 2022, "ssId": "46f66dd37e6366ce102cfd97e718947151d5b1eb", "arXivId": "2203.10885", "link": "https://arxiv.org/pdf/2203.10885.pdf", "openAccess": true, "authors": ["Qiang Sheng", "Juan Cao", "Xueyao Zhang", "Rundong Li", "Danding Wang", "Yongchun Zhu"]}}
{"id": "8786ddc38ae0763e772337bf9331436252452918", "content": {"title": "Generalizing to the Future: Mitigating Entity Bias in Fake News Detection", "abstract": "The wide dissemination of fake news is increasingly threatening both individuals and society. Fake news detection aims to train a model on the past news and detect fake news of the future. Though great efforts have been made, existing fake news detection methods overlooked the unintended entity bias in the real-world data, which seriously influences models\u2019 generalization ability to future data. For example, 97% of news pieces in 2010-2017 containing the entity \u2018Donald Trump\u2019 are real in our data, but the percentage falls down to merely 33% in 2018. This would lead the model trained on the former set to hardly generalize to the latter, as it tends to predict news pieces about \u2018Donald Trump\u2019 as real for lower training loss. In this paper, we propose an entity debiasing framework (ENDEF) which generalizes fake news detection models to the future data by mitigating entity bias from a cause-effect perspective. Based on the causal graph among entities, news contents, and news veracity, we separately model the contribution of each cause (entities and contents) during training. In the inference stage, we remove the direct effect of the entities to mitigate entity bias. Extensive offline experiments on the English and Chinese datasets demonstrate that the proposed framework can largely improve the performance of base fake news detectors, and online tests verify its superiority in practice. To the best of our knowledge, this is the first work to explicitly improve the generalization ability of fake news detection models to the future data. The code has been released at https: //github.com/ICTMCG/ENDEF-SIGIR2022.", "year": 2022, "ssId": "8786ddc38ae0763e772337bf9331436252452918", "arXivId": "2204.09484", "link": "https://arxiv.org/pdf/2204.09484.pdf", "openAccess": true, "authors": ["Yongchun Zhu", "Qiang Sheng", "Juan Cao", "Shuokai Li", "Danding Wang", "Fuzhen Zhuang"]}}
{"id": "ba1823889a80c231966a0f24e57c6cf4a569ff8c", "content": {"title": "Improving Fake News Detection by Using an Entity-enhanced Framework to Fuse Diverse Multimodal Clues", "abstract": "Recently, fake news with text and images have achieved more effective diffusion than text-only fake news, raising a severe issue of multimodal fake news detection. Current studies on this issue have made significant contributions to developing multimodal models, but they are defective in modeling the multimodal content sufficiently. Most of them only preliminarily model the basic semantics of the images as a supplement to the text, which limits their performance on detection. In this paper, we find three valuable text-image correlations in multimodal fake news: entity inconsistency, mutual enhancement, and text complementation. To effectively capture these multimodal clues, we innovatively extract visual entities (such as celebrities and landmarks) to understand the news-related high-level semantics of images, and then model the multimodal entity inconsistency and mutual enhancement with the help of visual entities. Moreover, we extract the embedded text in images as the complementation of the original text. All things considered, we propose a novel entity-enhanced multimodal fusion framework, which simultaneously models three cross-modal correlations to detect diverse multimodal fake news. Extensive experiments demonstrate the superiority of our model compared to the state of the art.", "year": 2021, "ssId": "ba1823889a80c231966a0f24e57c6cf4a569ff8c", "arXivId": "2108.10509", "link": "https://arxiv.org/pdf/2108.10509.pdf", "openAccess": true, "authors": ["Peng Qi", "Juan Cao", "Xirong Li", "Huan Liu", "Qiang Sheng", "Xiaoyue Mi", "Qin He", "Yongbiao Lv", "Chenyang Guo", "Yingchao Yu"]}}
{"id": "59d3f6a14e20efdf54216188e227e58a351237e5", "content": {"title": "Learning to Disentangle GAN Fingerprint for Fake Image Attribution", "abstract": "Rapid pace of generative models has brought about new threats to visual forensics such as malicious personation and digital copyright infringement, which promotes works on fake image attribution. Existing works on fake image attribution mainly rely on a direct classification framework. Without additional supervision, the extracted features could include many content-relevant components and generalize poorly. Meanwhile, how to obtain an interpretable GAN fingerprint to explain the decision remains an open question. Adopting a multi-task framework, we propose a GAN Fingerprint Disentangling Network (GFD-Net) to simultaneously disentangle the fingerprint from GAN-generated images and produce a content-irrelevant representation for fake image attribution. A series of constraints are provided to guarantee the stability and discriminability of the fingerprint, which in turn helps content-irrelevant feature extraction. Further, we perform comprehensive analysis on GAN fingerprint, providing some clues about the properties of GAN fingerprint and which factors dominate the fingerprint in GAN architecture. Experiments show that our GFD-Net achieves superior fake image attribution performance in both closed-world and open-world testing. We also apply our method in binary fake image detection and exhibit a significant generalization ability on unseen generators.", "year": 2021, "ssId": "59d3f6a14e20efdf54216188e227e58a351237e5", "arXivId": "2106.08749", "link": "https://arxiv.org/pdf/2106.08749.pdf", "openAccess": true, "authors": ["Tianyun Yang", "Juan Cao", "Qiang Sheng", "Lei Li", "Jiaqi Ji", "Xirong Li", "Sheng Tang"]}}
{"id": "119c33321fc0e1db837ce293f1b65cc26c1cc34e", "content": {"title": "Article Reranking by Memory-Enhanced Key Sentence Matching for Detecting Previously Fact-Checked Claims", "abstract": "False claims that have been previously fact-checked can still spread on social media. To mitigate their continual spread, detecting previously fact-checked claims is indispensable. Given a claim, existing works focus on providing evidence for detection by reranking candidate fact-checking articles (FC-articles) retrieved by BM25. However, these performances may be limited because they ignore the following characteristics of FC-articles: (1) claims are often quoted to describe the checked events, providing lexical information besides semantics; (2) sentence templates to introduce or debunk claims are common across articles, providing pattern information. Models that ignore the two aspects only leverage semantic relevance and may be misled by sentences that describe similar but irrelevant events. In this paper, we propose a novel reranker, MTM (Memory-enhanced Transformers for Matching) to rank FC-articles using key sentences selected with event (lexical and semantic) and pattern information. For event information, we propose a ROUGE-guided Transformer which is finetuned with regression of ROUGE. For pattern information, we generate pattern vectors for matching with sentences. By fusing event and pattern information, we select key sentences to represent an article and then predict if the article fact-checks the given claim using the claim, key sentences, and patterns. Experiments on two real-world datasets show that MTM outperforms existing methods. Human evaluation proves that MTM can capture key sentences for explanations.", "year": 2021, "ssId": "119c33321fc0e1db837ce293f1b65cc26c1cc34e", "arXivId": "2112.10322", "link": "https://arxiv.org/pdf/2112.10322.pdf", "openAccess": true, "authors": ["Qiang Sheng", "Juan Cao", "Xueyao Zhang", "Xirong Li", "L. Zhong"]}}
{"id": "bc251481aa5566b1e86a8dbd0417cdf858205e3b", "content": {"title": "Integrating Pattern- and Fact-based Fake News Detection via Model Preference Learning", "abstract": "To defend against fake news, researchers have developed various methods based on texts. These methods can be grouped as 1) pattern-based methods, which focus on shared patterns among fake news posts rather than the claim itself; and 2) fact-based methods, which retrieve from external sources to verify the claim's veracity without considering patterns. The two groups of methods, which have different preferences of textual clues, actually play complementary roles in detecting fake news. However, few works consider their integration. In this paper, we study the problem of integrating pattern- and fact-based models into one framework via modeling their preference differences, i.e., making the pattern- and fact-based models focus on respective preferred parts in a post and mitigate interference from non-preferred parts as possible. To this end, we build a Preference-aware Fake News Detection Framework (Pref-FEND), which learns the respective preferences of pattern- and fact-based models for joint detection. We first design a heterogeneous dynamic graph convolutional network to generate the respective preference maps, and then use these maps to guide the joint learning of pattern- and fact-based models for final prediction. Experiments on two real-world datasets show that Pref-FEND effectively captures model preferences and improves the performance of models based on patterns, facts, or both.", "year": 2021, "ssId": "bc251481aa5566b1e86a8dbd0417cdf858205e3b", "arXivId": "2109.11333", "link": "https://arxiv.org/pdf/2109.11333.pdf", "openAccess": true, "authors": ["Qiang Sheng", "Xueyao Zhang", "Juan Cao", "L. Zhong"]}}
{"id": "7e82015c386726f4b8f6f686b6e6bb7d1e7564bb", "content": {"title": "Integrating Semantic and Structural Information with Graph Convolutional Network for Controversy Detection", "abstract": "Identifying controversial posts on social media is a fundamental task for mining public sentiment, assessing the influence of events, and alleviating the polarized views. However, existing methods fail to 1) effectively incorporate the semantic information from content-related posts; 2) preserve the structural information for reply relationship modeling; 3) properly handle posts from topics dissimilar to those in the training set. To overcome the first two limitations, we propose Topic-Post-Comment Graph Convolutional Network (TPC-GCN), which integrates the information from the graph structure and content of topics, posts, and comments for post-level controversy detection. As to the third limitation, we extend our model to Disentangled TPC-GCN (DTPC-GCN), to disentangle topic-related and topic-unrelated features and then fuse dynamically. Extensive experiments on two real-world datasets demonstrate that our models outperform existing methods. Analysis of the results and cases proves that our models can integrate both semantic and structural information with significant generalizability.", "year": 2020, "ssId": "7e82015c386726f4b8f6f686b6e6bb7d1e7564bb", "arXivId": "2005.07886", "link": "https://arxiv.org/pdf/2005.07886.pdf", "openAccess": true, "authors": ["L. Zhong", "Juan Cao", "Qiang Sheng", "Junbo Guo", "Ziang Wang"]}}
{"id": "51ec4e93d8ae4c62453fdb34c6866696da0527b1", "content": {"title": "Exploring the Role of Visual Content in Fake News Detection", "abstract": "The increasing popularity of social media promotes the proliferation of fake news, which has caused significant negative societal effects. Therefore, fake news detection on social media has recently become an emerging research area of great concern. With the development of multimedia technology, fake news attempts to utilize multimedia content with images or videos to attract and mislead consumers for rapid dissemination, which makes visual content an important part of fake news. Despite the importance of visual content, our understanding about the role of visual content in fake news detection is still limited. This chapter presents a comprehensive review of the visual content in fake news, including the basic concepts, effective visual features, representative detection methods and challenging issues of multimedia fake news detection. This chapter can help readers to understand the role of visual content in fake news detection, and effectively utilize visual content to assist in detecting multimedia fake news.", "year": 2020, "ssId": "51ec4e93d8ae4c62453fdb34c6866696da0527b1", "arXivId": "2003.05096", "link": "https://arxiv.org/pdf/2003.05096.pdf", "openAccess": true, "authors": ["Juan Cao", "Peng Qi", "Qiang Sheng", "Tianyun Yang", "Junbo Guo", "Jintao Li"]}}
{"id": "f11ed27f4640dd8785ea7c4aff9705ddaad2b24d", "content": {"title": "Exploring the Role of Visual Content in Fake News Detection", "abstract": "The increasing popularity of social media promotes the proliferation of fake news, which has caused significant negative societal effects. Therefore, fake news detection on social media has recently become an emerging research area of great concern. With the development of multimedia technology, fake news attempts to utilize multimedia content with images or videos to attract and mislead consumers for rapid dissemination, which makes visual content an important part of fake news. Despite the importance of visual content, our understanding about the role of visual content in fake news detection is still limited. This chapter presents a comprehensive review of the visual content in fake news, including the basic concepts, effective visual features, representative detection methods and challenging issues of multimedia fake news detection. This chapter can help readers to understand the role of visual content in fake news detection, and effectively utilize visual content to assist in detecting multimedia fake news.", "year": 2020, "ssId": "f11ed27f4640dd8785ea7c4aff9705ddaad2b24d", "arXivId": null, "link": null, "openAccess": false, "authors": ["Juan Cao", "Peng Qi", "Qiang Sheng", "Tianyun Yang", "Junbo Guo", "Jintao Li"]}}
{"id": "cb153d8469ac466606032ea457b934bc61ae86ae", "content": {"title": "Mining Dual Emotion for Fake News Detection", "abstract": "Emotion plays an important role in detecting fake news online. When leveraging emotional signals, the existing methods focus on exploiting the emotions of news contents that conveyed by the publishers (i.e., publisher emotion). However, fake news often evokes high-arousal or activating emotions of people, so the emotions of news comments aroused in the crowd (i.e., social emotion) should not be ignored. Furthermore, it remains to be explored whether there exists a relationship between publisher emotion and social emotion (i.e., dual emotion), and how the dual emotion appears in fake news. In this paper, we verify that dual emotion is distinctive between fake and real news and propose Dual Emotion Features to represent dual emotion and the relationship between them for fake news detection. Further, we exhibit that our proposed features can be easily plugged into existing fake news detectors as an enhancement. Extensive experiments on three real-world datasets (one in English and the others in Chinese) show that our proposed feature set: 1) outperforms the state-of-the-art task-related emotional features; 2) can be well compatible with existing fake news detectors and effectively improve the performance of detecting fake news.1 2", "year": 2019, "ssId": "cb153d8469ac466606032ea457b934bc61ae86ae", "arXivId": null, "link": null, "openAccess": false, "authors": ["Xueyao Zhang", "Juan Cao", "Xirong Li", "Qiang Sheng", "L. Zhong", "Kai Shu"]}}
{"id": "a8c62c42509c45a708ba477b603ee3fb81c77056", "content": {"title": "False News Detection on Social Media", "abstract": "Social media has become a major information platform where people consume and share news. However, it has also enabled the wide dissemination of false news, i.e., news posts published on social media that are verifiably false, causing significant negative effects on society. In order to help prevent further propagation of false news on social media, we set up this competition to motivate the development of automated real-time false news detection approaches. Specifically, this competition includes three sub-tasks: false-news text detection, false-news image detection and false-news multi-modal detetcion, which aims to motivate participants to further explore the efficiency of multiple modalities in detecting false news and reasonable fusion approaches of multi-modal contents. To better support this competition, we also construct and publicize a multi-modal data repository about False News on Weibo Social platform(MCG-FNeWS}) to help evaluate the performance of different approaches from participants.", "year": 2019, "ssId": "a8c62c42509c45a708ba477b603ee3fb81c77056", "arXivId": "1908.10818", "link": "https://arxiv.org/pdf/1908.10818.pdf", "openAccess": true, "authors": ["Juan Cao", "Qiang Sheng", "Peng Qi", "L. Zhong", "Yanyan Wang", "Xueyao Zhang"]}}
{"id": "26d5c7ad2778c77a1b8734dceb34fe38a1179e2f", "content": {"title": "Malicious Application Dynamic Detection in Real-Time API Analysis", "abstract": "There are various malicious applications (app) in mobile platform, especially for Android devices, it is difficult to develop a model directly for malwares, due to the limitation of application testing samples. In this paper we propose a novel malicious application detection model RT-MAD for Android devices: Real-Time Malicious Application Detection. This model can generate a malicious app space through normal application modeling by (i) first we develop an Android Real-time API monitor tool to collect API data for each app running on the devices, and cleaning them into time series data, (ii) then we modify Hidden Markov Model (HMM) to train the majority genres of normal apps, obtaining the normal apps space, (iii) and finally we use Randomized Real-Valued Negative Selection (RRNS) to generate a set of likelihood vectors based on the normal app space, covering all possible malicious applications, thus we get the malicious app space for malwares detection. We conduct experiments on HMM training and RRNS malicious apps space generation, the result shows that we can get precision of 91% for normal genres of apps in HMM model. However, in some situation, the malicious apps space generated in RRNS would cover the normal apps, for the safety of devices, it is acceptable since our RT-MAD can achieve precision of 91% in malwares detection.", "year": 2016, "ssId": "26d5c7ad2778c77a1b8734dceb34fe38a1179e2f", "arXivId": null, "link": null, "openAccess": false, "authors": ["Shiting Xu", "Xinyv Ma", "Y. Liu", "Qiang Sheng"]}}
{"id": "2ded680be56e03c8c17a04065deaac8ea6d4fa12", "content": {"title": "Characterization of a new HLA-B allele, B*15:179:02.", "abstract": "A novel HLA-B allele, B*15:179:02, has been identified during typing of donors in Anhui province, China.", "year": 2014, "ssId": "2ded680be56e03c8c17a04065deaac8ea6d4fa12", "arXivId": null, "link": null, "openAccess": false, "authors": ["R. Lv", "X. Xin", "J. Yu", "Qiang Sheng"]}}
{"id": "14f925098d57b0fa491a100fa73e52dbc764efa6", "content": {"title": "Notice of RetractionA Neuroscience lens to MIS researh: NeuroIS", "abstract": "The tool and theory of Cognitive Neuroscience has been used in sociology, economics, marketing, psychology disciplines recent years. \u201cNeuroIS\u201d was first declared by Dimoka in 2007. From then to now, the study of NeuoIS had been published in the top MIS journal such as MIS Q, ISR, as well as in the top International Conference such as ICIS and AMCIS. This paper described the clear track of NeuroIS over the period of 2007 to 2010. The significant of Neuroscience in MIS is analyzed. Finally, how to conduct a Neuroimaging study is explained with Dimoka's first fMRI study on TAM.", "year": 2011, "ssId": "14f925098d57b0fa491a100fa73e52dbc764efa6", "arXivId": null, "link": null, "openAccess": false, "authors": ["Qing Xu", "Tong Wang", "Pengshuai Chen", "Qianqian Zhu", "Qiang Sheng", "Qing-guo Ma"]}}
