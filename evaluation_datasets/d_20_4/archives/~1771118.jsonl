{"id": "190865e2c3d4908ff20bf9a31f5a2773d6fec5cb", "content": {"title": "Augmenting Pre-trained Language Models with QA-Memory for Open-Domain Question Answering", "abstract": "Existing state-of-the-art methods for open-domain question-answering (ODQA) gener-ally used a open book approach, in which information is retrieved from a large text corpus or knowledge base (KB), and then rea-soned with to produce an answer. A recent alternative is to retrieve from a collection of previously-generated question-answer pairs. This has several practical advantages, including being more memory- and compute-ef\ufb01cient. Question-answer pairs are also appealing in that they seem to be an intermediate between text and KB triples: like KB triples, they usually concisely express a single rela-tionship, but like text, they have good coverage. We describe a new QA system which aug-ments a text-to-text model with a large memory of question-answer pairs, and a new pre-training task for the latent step of question retrieval. The pre-training task substantially sim-pli\ufb01es training, and greatly improves performance on smaller QA benchmarks. Unlike prior systems of this sort, our QA system can also answer multi-hop questions that do not explicitly appear in the collection of stored question-answer pairs.", "year": 2022, "ssId": "190865e2c3d4908ff20bf9a31f5a2773d6fec5cb", "arXivId": "2204.04581", "link": "https://arxiv.org/pdf/2204.04581.pdf", "openAccess": true, "authors": ["Wenhu Chen", "Pat Verga", "M. D. Jong", "J. Wieting", "W. Cohen"]}}
{"id": "56501a3441c2074bbbbe31015d6d41c57d9d285b", "content": {"title": "Paraphrastic Representations at Scale", "abstract": "We present a system that allows users to train their own state-of-the-art paraphrastic sentence representations in a variety of languages. We also release trained models for English, Arabic, German, French, Spanish, Russian, Turkish, and Chinese. We train these models on large amounts of data, achieving significantly improved performance from the original papers proposing the methods on a suite of monolingual semantic similarity, cross-lingual semantic similarity, and bitext mining tasks. Moreover, the resulting models surpass all prior work on unsupervised semantic textual similarity, significantly outperforming even BERT-based models like SentenceBERT (Reimers and Gurevych, 2019). Additionally, our models are orders of magnitude faster than prior work and can be used on CPU with little difference in inference speed (even improved speed over GPU when using more CPU cores), making these models an attractive choice for users without access to GPUs or for use on embedded devices. Finally, we add significantly increased functionality to the code bases for training paraphrastic sentence models, easing their use for both inference and for training them for any desired language with parallel data. We also include code to automatically download and preprocess training data.", "year": 2021, "ssId": "56501a3441c2074bbbbe31015d6d41c57d9d285b", "arXivId": "2104.15114", "link": "https://arxiv.org/pdf/2104.15114.pdf", "openAccess": true, "authors": ["J. Wieting", "Kevin Gimpel", "Graham Neubig", "Taylor Berg-Kirkpatrick"]}}
{"id": "6a9394e5d49c1251c0fb6d7fb0c0813d26c6a907", "content": {"title": "On The Ingredients of an Effective Zero-shot Semantic Parser", "abstract": "Semantic parsers map natural language utterances into meaning representations (e.g. programs). Such models are typically bottlenecked by the paucity of training data due to the required laborious annotation efforts. Recent studies have performed zero-shot learning by synthesizing training examples of canonical utterances and programs from a grammar, and further paraphrasing these utterances to improve linguistic diversity. However, such synthetic examples cannot fully capture patterns in real data. In this paper we analyze zero-shot parsers through the lenses of the language and logical gaps (Herzig and Berant, 2019), which quantify the discrepancy of language and programmatic patterns between the synthetic canonical examples and real-world user-issued ones. We propose bridging these gaps using improved grammars, stronger paraphrasers, and efficient learning methods using canonical examples that most likely reflect real user intents. Our model achieves strong performance on two semantic parsing benchmarks (SCHOLAR, GEO) with zero labeled data.", "year": 2021, "ssId": "6a9394e5d49c1251c0fb6d7fb0c0813d26c6a907", "arXivId": "2110.08381", "link": "https://arxiv.org/pdf/2110.08381.pdf", "openAccess": true, "authors": ["P. Yin", "J. Wieting", "Avirup Sil", "Graham Neubig"]}}
{"id": "e02f79b710cdcaa9135b835fad964f6f2c78b1a7", "content": {"title": "Canine: Pre-training an Efficient Tokenization-Free Encoder for Language Representation", "abstract": "Abstract Pipelined NLP systems have largely been superseded by end-to-end neural modeling, yet nearly all commonly used models still require an explicit tokenization step. While recent tokenization approaches based on data-derived subword lexicons are less brittle than manually engineered tokenizers, these techniques are not equally suited to all languages, and the use of any fixed vocabulary may limit a model\u2019s ability to adapt. In this paper, we present Canine, a neural encoder that operates directly on character sequences\u2014without explicit tokenization or vocabulary\u2014and a pre-training strategy that operates either directly on characters or optionally uses subwords as a soft inductive bias. To use its finer-grained input effectively and efficiently, Canine combines downsampling, which reduces the input sequence length, with a deep transformer stack, which encodes context. Canine outperforms a comparable mBert model by 5.7 F1 on TyDi QA, a challenging multilingual benchmark, despite having fewer model parameters.", "year": 2021, "ssId": "e02f79b710cdcaa9135b835fad964f6f2c78b1a7", "arXivId": "2103.06874", "link": "https://arxiv.org/pdf/2103.06874.pdf", "openAccess": true, "authors": ["J. Clark", "Dan Garrette", "Iulia Turc", "J. Wieting"]}}
{"id": "f2d5861a24b7aa33036208ba81e11bb9b2090e7c", "content": {"title": "Improving the Diversity of Unsupervised Paraphrasing with Embedding Outputs", "abstract": "We present a novel technique for zero-shot paraphrase generation. The key contribution is an end-to-end multilingual paraphrasing model that is trained using translated parallel corpora to generate paraphrases into \u201cmeaning spaces\u201d \u2013 replacing the final softmax layer with word embeddings. This architectural modification, plus a training procedure that incorporates an autoencoding objective, enables effective parameter sharing across languages for more fluent monolingual rewriting, and facilitates fluency and diversity in the generated outputs. Our continuous-output paraphrase generation models outperform zero-shot paraphrasing baselines when evaluated on two languages using a battery of computational metrics as well as in human assessment.", "year": 2021, "ssId": "f2d5861a24b7aa33036208ba81e11bb9b2090e7c", "arXivId": "2110.13231", "link": "https://arxiv.org/pdf/2110.13231.pdf", "openAccess": true, "authors": ["M. Jegadeesan", "Sachin Kumar", "J. Wieting", "Yulia Tsvetkov"]}}
{"id": "ccad27088b9098de4eaca8dc449b18766db4b3ab", "content": {"title": "Reformulating Unsupervised Style Transfer as Paraphrase Generation", "abstract": "Modern NLP defines the task of style transfer as modifying the style of a given sentence without appreciably changing its semantics, which implies that the outputs of style transfer systems should be paraphrases of their inputs. However, many existing systems purportedly designed for style transfer inherently warp the input's meaning through attribute transfer, which changes semantic properties such as sentiment. In this paper, we reformulate unsupervised style transfer as a paraphrase generation problem, and present a simple methodology based on fine-tuning pretrained language models on automatically generated paraphrase data. Despite its simplicity, our method significantly outperforms state-of-the-art style transfer systems on both human and automatic evaluations. We also survey 23 style transfer papers and discover that existing automatic metrics can be easily gamed and propose fixed variants. Finally, we pivot to a more real-world style transfer setting by collecting a large dataset of 15M sentences in 11 diverse styles, which we use for an in-depth analysis of our system.", "year": 2020, "ssId": "ccad27088b9098de4eaca8dc449b18766db4b3ab", "arXivId": "2010.05700", "link": "https://arxiv.org/pdf/2010.05700.pdf", "openAccess": true, "authors": ["Kalpesh Krishna", "J. Wieting", "Mohit Iyyer"]}}
{"id": "35b376ad9e03e5e0b930c53a48817bfb5703108d", "content": {"title": "On Learning Text Style Transfer with Direct Rewards", "abstract": "In most cases, the lack of parallel corpora makes it impossible to directly train supervised models for the text style transfer task. In this paper, we explore training algorithms that instead optimize reward functions that explicitly consider different aspects of the style-transferred outputs. In particular, we leverage semantic similarity metrics originally used for fine-tuning neural machine translation models to explicitly assess the preservation of content between system outputs and input texts. We also investigate the potential weaknesses of the existing automatic metrics and propose efficient strategies of using these metrics for training. The experimental results show that our model provides significant gains in both automatic and human evaluation over strong baselines, indicating the effectiveness of our proposed methods and training strategies.", "year": 2020, "ssId": "35b376ad9e03e5e0b930c53a48817bfb5703108d", "arXivId": "2010.12771", "link": "https://arxiv.org/pdf/2010.12771.pdf", "openAccess": true, "authors": ["Yixin Liu", "Graham Neubig", "J. Wieting"]}}
{"id": "2583e7e279e2969493c3290c8f300ab32da40bf9", "content": {"title": "Improving Candidate Generation for Low-resource Cross-lingual Entity Linking", "abstract": "Cross-lingual entity linking (XEL) is the task of finding referents in a target-language knowledge base (KB) for mentions extracted from source-language texts. The first step of (X)EL is candidate generation, which retrieves a list of plausible candidate entities from the target-language KB for each mention. Approaches based on resources from Wikipedia have proven successful in the realm of relatively high-resource languages, but these do not extend well to low-resource languages with few, if any, Wikipedia pages. Recently, transfer learning methods have been shown to reduce the demand for resources in the low-resource languages by utilizing resources in closely related languages, but the performance still lags far behind their high-resource counterparts. In this paper, we first assess the problems faced by current entity candidate generation methods for low-resource XEL, then propose three improvements that (1) reduce the disconnect between entity mentions and KB entries, and (2) improve the robustness of the model to low-resource scenarios. The methods are simple, but effective: We experiment with our approach on seven XEL datasets and find that they yield an average gain of 16.9% in Top-30 gold candidate recall, compared with state-of-the-art baselines. Our improved model also yields an average gain of 7.9% in in-KB accuracy of end-to-end XEL.1", "year": 2020, "ssId": "2583e7e279e2969493c3290c8f300ab32da40bf9", "arXivId": "2003.01343", "link": "https://arxiv.org/pdf/2003.01343.pdf", "openAccess": true, "authors": ["Shuyan Zhou", "Shruti Rijhawani", "J. Wieting", "J. Carbonell", "Graham Neubig"]}}
{"id": "86d84c1c9b0a500f930696ab27c83a4b30477560", "content": {"title": "Simple and Effective Paraphrastic Similarity from Parallel Translations", "abstract": "We present a model and methodology for learning paraphrastic sentence embeddings directly from bitext, removing the time-consuming intermediate step of creating para-phrase corpora. Further, we show that the resulting model can be applied to cross lingual tasks where it both outperforms and is orders of magnitude faster than more complex state-of-the-art baselines.", "year": 2019, "ssId": "86d84c1c9b0a500f930696ab27c83a4b30477560", "arXivId": "1909.13872", "link": "https://arxiv.org/pdf/1909.13872.pdf", "openAccess": true, "authors": ["J. Wieting", "Kevin Gimpel", "Graham Neubig", "Taylor Berg-Kirkpatrick"]}}
{"id": "7a8f8109e65ed9a6048859681a825eb5655e5dd2", "content": {"title": "No Training Required: Exploring Random Encoders for Sentence Classification", "abstract": "We explore various methods for computing sentence representations from pre-trained word embeddings without any training, i.e., using nothing but random parameterizations. Our aim is to put sentence embeddings on more solid footing by 1) looking at how much modern sentence embeddings gain over random methods---as it turns out, surprisingly little; and by 2) providing the field with more appropriate baselines going forward---which are, as it turns out, quite strong. We also make important observations about proper experimental protocol for sentence classification evaluation, together with recommendations for future research.", "year": 2019, "ssId": "7a8f8109e65ed9a6048859681a825eb5655e5dd2", "arXivId": "1901.10444", "link": "https://arxiv.org/pdf/1901.10444.pdf", "openAccess": true, "authors": ["J. Wieting", "Douwe Kiela"]}}
{"id": "d1d23675d2e65cd734f2955c10ec1028b1139b5b", "content": {"title": "Beyond BLEU:Training Neural Machine Translation with Semantic Similarity", "abstract": "While most neural machine translation (NMT)systems are still trained using maximum likelihood estimation, recent work has demonstrated that optimizing systems to directly improve evaluation metrics such as BLEU can significantly improve final translation accuracy. However, training with BLEU has some limitations: it doesn\u2019t assign partial credit, it has a limited range of output values, and it can penalize semantically correct hypotheses if they differ lexically from the reference. In this paper, we introduce an alternative reward function for optimizing NMT systems that is based on recent work in semantic similarity. We evaluate on four disparate languages trans-lated to English, and find that training with our proposed metric results in better translations as evaluated by BLEU, semantic similarity, and human evaluation, and also that the optimization procedure converges faster. Analysis suggests that this is because the proposed metric is more conducive to optimization, assigning partial credit and providing more diversity in scores than BLEU", "year": 2019, "ssId": "d1d23675d2e65cd734f2955c10ec1028b1139b5b", "arXivId": "1909.06694", "link": "https://arxiv.org/pdf/1909.06694.pdf", "openAccess": true, "authors": ["J. Wieting", "Taylor Berg-Kirkpatrick", "Kevin Gimpel", "Graham Neubig"]}}
{"id": "1941f5b053ccc80fa44980d38ac074145591b4ec", "content": {"title": "A Bilingual Generative Transformer for Semantic Sentence Embedding", "abstract": "Semantic sentence embedding models encode natural language sentences into vectors, such that closeness in embedding space indicates closeness in the semantics between the sentences. Bilingual data offers a useful signal for learning such embeddings: properties shared by both sentences in a translation pair are likely semantic, while divergent properties are likely stylistic or language-specific. We propose a deep latent variable model that attempts to perform source separation on parallel sentences, isolating what they have in common in a latent semantic vector, and explaining what is left over with language-specific latent vectors. Our proposed approach differs from past work on semantic sentence encoding in two ways. First, by using a variational probabilistic framework, we introduce priors that encourage source separation, and can use our model's posterior to predict sentence embeddings for monolingual data at test time. Second, we use high-capacity transformers as both data generating distributions and inference networks -- contrasting with most past work on sentence embeddings. In experiments, our approach substantially outperforms the state-of-the-art on a standard suite of unsupervised semantic similarity evaluations. Further, we demonstrate that our approach yields the largest gains on more difficult subsets of these evaluations where simple word overlap is not a good indicator of similarity.", "year": 2019, "ssId": "1941f5b053ccc80fa44980d38ac074145591b4ec", "arXivId": "1911.03895", "link": "https://arxiv.org/pdf/1911.03895.pdf", "openAccess": true, "authors": ["J. Wieting", "Graham Neubig", "Taylor Berg-Kirkpatrick"]}}
{"id": "c3930cb34241a42e03ed02cbc83a3c87dddd60cc", "content": {"title": "Quality Signals in Generated Stories", "abstract": "We study the problem of measuring the quality of automatically-generated stories. We focus on the setting in which a few sentences of a story are provided and the task is to generate the next sentence (\u201ccontinuation\u201d) in the story. We seek to identify what makes a story continuation interesting, relevant, and have high overall quality. We crowdsource annotations along these three criteria for the outputs of story continuation systems, design features, and train models to predict the annotations. Our trained scorer can be used as a rich feature function for story generation, a reward function for systems that use reinforcement learning to learn to generate stories, and as a partial evaluation metric for story generation.", "year": 2018, "ssId": "c3930cb34241a42e03ed02cbc83a3c87dddd60cc", "arXivId": null, "link": null, "openAccess": false, "authors": ["Manasvi Sagarkar", "J. Wieting", "Lifu Tu", "Kevin Gimpel"]}}
{"id": "2b110fce160468eb179b6c43ea27e098757a56dd", "content": {"title": "Adversarial Example Generation with Syntactically Controlled Paraphrase Networks", "abstract": "We propose syntactically controlled paraphrase networks (SCPNs) and use them to generate adversarial examples. Given a sentence and a target syntactic form (e.g., a constituency parse), SCPNs are trained to produce a paraphrase of the sentence with the desired syntax. We show it is possible to create training data for this task by first doing backtranslation at a very large scale, and then using a parser to label the syntactic transformations that naturally occur during this process. Such data allows us to train a neural encoder-decoder model with extra inputs to specify the target syntax. A combination of automated and human evaluations show that SCPNs generate paraphrases that follow their target specifications without decreasing paraphrase quality when compared to baseline (uncontrolled) paraphrase systems. Furthermore, they are more capable of generating syntactically adversarial examples that both (1) \u201cfool\u201d pretrained models and (2) improve the robustness of these models to syntactic variation when used to augment their training data.", "year": 2018, "ssId": "2b110fce160468eb179b6c43ea27e098757a56dd", "arXivId": "1804.06059", "link": "https://arxiv.org/pdf/1804.06059.pdf", "openAccess": true, "authors": ["Mohit Iyyer", "J. Wieting", "Kevin Gimpel", "Luke Zettlemoyer"]}}
{"id": "0c5bfa2d4bb351a479073cb358c3ae6f7ecf0476", "content": {"title": "CogCompNLP: Your Swiss Army Knife for NLP", "abstract": "Implementing a Natural Language Processing (NLP) system requires considerable engineering effort: creating data-structures to represent language constructs; reading corpora annotations into these data-structures; applying off-the-shelf NLP tools to augment the text representation; extracting features and training machine learning components; conducting experiments and computing performance statistics; and creating the end-user application that integrates the implemented components. While there are several widely used NLP libraries, each provides only partial coverage of these various tasks. We present our library COGCOMPNLP which simplifies the process of design and development of NLP applications by providing modules to address different challenges: we provide a corpus-reader module that supports popular corpora in the NLP community, a module for various low-level data-structures and operations (such as search over text), a module for feature extraction, and an extensive suite of annotation modules for a wide range of semantic and syntactic tasks. These annotation modules are all integrated in a single system, PIPELINE, which allows users to easily use the annotators with simple direct calls using any JVM-based language, or over a network. The sister project COGCOMPNLPY enables users to access the annotators with a Python interface. We give a detailed account of our system\u2019s structure and usage, and where possible, compare it with other established NLP frameworks. We report on the performance, including time and memory statistics, of each component on a selection of well-established datasets. Our system is publicly available for research use and external contributions, at: http://github.com/CogComp/cogcomp-nlp.", "year": 2018, "ssId": "0c5bfa2d4bb351a479073cb358c3ae6f7ecf0476", "arXivId": null, "link": null, "openAccess": false, "authors": ["Daniel Khashabi", "M. Sammons", "Ben Zhou", "Tom Redman", "Christos Christodoulopoulos", "Vivek Srikumar", "Nicholas Rizzolo", "Lev-Arie Ratinov", "Guanheng Luo", "Q. Do", "Chen-Tse Tsai", "Subhro Roy", "Stephen Mayhew", "Zhili Feng", "J. Wieting", "Xiaodong Yu", "Yangqiu Song", "Shashank Gupta", "Shyam Upadhyay", "N. Arivazhagan", "Qiang Ning", "Shaoshi Ling", "D. Roth"]}}
{"id": "5930efbf01efa8944258b1c0f7349111702f779e", "content": {"title": "C OG C OMP NLP : Your Swiss Army Knife for NLP", "abstract": "Implementing a Natural Language Processing (NLP) system requires considerable engineering effort: creating data-structures to represent language constructs; reading corpora annotations into these data-structures; applying off-the-shelf NLP tools to augment the text representation; extracting features and training machine learning components; conducting experiments and computing performance statistics; and creating the end-user application that integrates the implemented components. While there are several widely used NLP libraries, each provides only partial coverage of these various tasks. We present our library COGCOMPNLP which simplifies the process of design and development of NLP applications by providing modules to address different challenges: we provide a corpus-reader module that supports popular corpora in the NLP community, a module for various low-level data-structures and operations (such as search over text), a module for feature extraction, and an extensive suite of annotation modules for a wide range of semantic and syntactic tasks. These annotation modules are all integrated in a single system, PIPELINE, which allows users to easily use the annotators with simple direct calls using any JVM-based language, or over a network. The sister project COGCOMPNLPY enables users to access the annotators with a Python interface. We give a detailed account of our system\u2019s structure and usage, and where possible, compare it with other established NLP frameworks. We report on the performance, including time and memory statistics, of each component on a selection of well-established datasets. Our system is publicly available for research use and external contributions, at: http://github.com/CogComp/cogcomp-nlp.", "year": 2018, "ssId": "5930efbf01efa8944258b1c0f7349111702f779e", "arXivId": null, "link": null, "openAccess": false, "authors": ["Daniel Khashabi", "M. Sammons", "Ben Zhou", "Tom Redman", "Christos E. Christodoulopoulos", "Vivek Srikumar", "Nicholas Rizzolo", "Lev-Arie Ratinov", "Guanheng Luo", "Q. Do", "Chen-Tse Tsai", "Subhro Roy", "Stephen Mayhew", "Zhili Feng", "J. Wieting", "Xiaodong Yu", "Yangqiu Song", "Shashank Gupta", "Shyam Upadhyay", "N. Arivazhagan", "Qiang Ning", "Shaoshi Ling", "D. Roth"]}}
{"id": "d3304b926cfcd91110bd5ba01db21d26ce5fca2d", "content": {"title": "Learning Paraphrastic Sentence Embeddings from Back-Translated Bitext", "abstract": "We consider the problem of learning general-purpose, paraphrastic sentence embeddings in the setting of Wieting et al. (2016b). We use neural machine translation to generate sentential paraphrases via back-translation of bilingual sentence pairs. We evaluate the paraphrase pairs by their ability to serve as training data for learning paraphrastic sentence embeddings. We find that the data quality is stronger than prior work based on bitext and on par with manually-written English paraphrase pairs, with the advantage that our approach can scale up to generate large training sets for many languages and domains. We experiment with several language pairs and data sources, and develop a variety of data filtering techniques. In the process, we explore how neural machine translation output differs from human-written sentences, finding clear differences in length, the amount of repetition, and the use of rare words.", "year": 2017, "ssId": "d3304b926cfcd91110bd5ba01db21d26ce5fca2d", "arXivId": "1706.01847", "link": "https://arxiv.org/pdf/1706.01847.pdf", "openAccess": true, "authors": ["J. Wieting", "Jonathan Mallinson", "Kevin Gimpel"]}}
{"id": "8a6d2e134b3b2df6291af8e36e126ae55d50649c", "content": {"title": "Revisiting Recurrent Networks for Paraphrastic Sentence Embeddings", "abstract": "We consider the problem of learning general-purpose, paraphrastic sentence embeddings, revisiting the setting of Wieting et al. (2016b). While they found LSTM recurrent networks to underperform word averaging, we present several developments that together produce the opposite conclusion. These include training on sentence pairs rather than phrase pairs, averaging states to represent sequences, and regularizing aggressively. These improve LSTMs in both transfer learning and supervised settings. We also introduce a new recurrent architecture, the Gated Recurrent Averaging Network, that is inspired by averaging and LSTMs while outperforming them both. We analyze our learned models, finding evidence of preferences for particular parts of speech and dependency relations.", "year": 2017, "ssId": "8a6d2e134b3b2df6291af8e36e126ae55d50649c", "arXivId": "1705.00364", "link": "https://arxiv.org/pdf/1705.00364.pdf", "openAccess": true, "authors": ["J. Wieting", "Kevin Gimpel"]}}
{"id": "7262bc3674c4c063526eaf4d2dcf54eecea7bf77", "content": {"title": "ParaNMT-50M: Pushing the Limits of Paraphrastic Sentence Embeddings with Millions of Machine Translations", "abstract": "We describe ParaNMT-50M, a dataset of more than 50 million English-English sentential paraphrase pairs. We generated the pairs automatically by using neural machine translation to translate the non-English side of a large parallel corpus, following Wieting et al. (2017). Our hope is that ParaNMT-50M can be a valuable resource for paraphrase generation and can provide a rich source of semantic knowledge to improve downstream natural language understanding tasks. To show its utility, we use ParaNMT-50M to train paraphrastic sentence embeddings that outperform all supervised systems on every SemEval semantic textual similarity competition, in addition to showing how it can be used for paraphrase generation.", "year": 2017, "ssId": "7262bc3674c4c063526eaf4d2dcf54eecea7bf77", "arXivId": "1711.05732", "link": "https://arxiv.org/pdf/1711.05732.pdf", "openAccess": true, "authors": ["J. Wieting", "Kevin Gimpel"]}}
{"id": "12e9d005c77f76e344361f79c4b008034ae547eb", "content": {"title": "Charagram: Embedding Words and Sentences via Character n-grams", "abstract": "We present Charagram embeddings, a simple approach for learning character-based compositional models to embed textual sequences. A word or sentence is represented using a character n-gram count vector, followed by a single nonlinear transformation to yield a low-dimensional embedding. We use three tasks for evaluation: word similarity, sentence similarity, and part-of-speech tagging. We demonstrate that Charagram embeddings outperform more complex architectures based on character-level recurrent and convolutional neural networks, achieving new state-of-the-art performance on several similarity tasks.", "year": 2016, "ssId": "12e9d005c77f76e344361f79c4b008034ae547eb", "arXivId": "1607.02789", "link": "https://arxiv.org/pdf/1607.02789.pdf", "openAccess": true, "authors": ["J. Wieting", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu"]}}
