{"id": "651468a69da74dab716cebbd179a5cbb8e672c14", "content": {"title": "Self-Imitation Learning from Demonstrations", "abstract": "Despite the numerous breakthroughs achieved with Reinforcement Learning (RL), solving environments with sparse rewards remains a challenging task that requires sophisticated exploration. Learning from Demonstrations (LfD) remedies this issue by guiding the agent\u2019s exploration towards states experienced by an expert. Naturally, the benefits of this approach hinge on the quality of demonstrations, which are rarely optimal in realistic scenarios. Modern LfD algorithms require meticulous tuning of hyperparameters that control the influence of demonstrations and, as we show in the paper, struggle with learning from suboptimal demonstrations. To address these issues, we extend Self-Imitation Learning (SIL), a recent RL algorithm that exploits the agent\u2019s past good experience, to the LfD setup by initializing its replay buffer with demonstrations. We denote our algorithm as SIL from Demonstrations (SILfD). We empirically show that SILfD can learn from demonstrations that are noisy or far from optimal and can automatically adjust the influence of demonstrations throughout the training without additional hyperparameters or handcrafted schedules. We also find SILfD superior to the existing state-of-the-art LfD algorithms in sparse environments, especially when demonstrations are highly suboptimal.", "year": 2022, "ssId": "651468a69da74dab716cebbd179a5cbb8e672c14", "arXivId": "2203.10905", "link": "https://arxiv.org/pdf/2203.10905.pdf", "openAccess": true, "authors": ["Georgiy Pshikhachev", "Dmitry Ivanov", "Vladimir Egorov", "A. Shpilman"]}}
{"id": "a1588ac6d582d30742f998464500bb5ead125dc6", "content": {"title": "Optimal-er Auctions through Attention", "abstract": "RegretNet is a recent breakthrough in the automated design of revenue-maximizing auctions. It combines the expressivity of deep learning with the regret-based approach to relax and quantify the Incentive Compatibility constraint (that participants benefit from bidding truthfully). As a follow-up to its success, we propose two independent modifications of RegretNet, namely a new neural architecture based on the attention mechanism, denoted as TransRegret, and an alternative loss function that is interpretable and significantly less sensitive to hyperparameters. We investigate both proposed modifications in an extensive experimental study in settings with fixed and varied input sizes and additionally test out-of-setting generalization of our network. In all experiments, we find that TransRegret consistently outperforms existing architectures in revenue. Regarding our loss modification, we confirm its effectiveness at controlling the revenue-regret trade-off by varying a single interpretable hyperparameter.", "year": 2022, "ssId": "a1588ac6d582d30742f998464500bb5ead125dc6", "arXivId": "2202.13110", "link": "https://arxiv.org/pdf/2202.13110.pdf", "openAccess": true, "authors": ["Dmitry Ivanov", "Iskander Safiulin", "Ksenia Balabaeva", "Igor Filippov"]}}
{"id": "3163392f56cdffaa009fbc59f299989a1b8baec1", "content": {"title": "Improving State-of-the-Art in One-Class Classification by Leveraging Unlabeled Data", "abstract": "When dealing with binary classification of data with only one labeled class data scientists employ two main approaches, namely One-Class (OC) classification and Positive Unlabeled (PU) learning. The former only learns from labeled positive data, whereas the latter also utilizes unlabeled data to improve the overall performance. Since PU learning utilizes more data, we might be prone to think that when unlabeled data is available, the go-to algorithms should always come from the PU group. However, we find that this is not always the case if unlabeled data is unreliable, i.e. contains limited or biased latent negative data. We perform an extensive experimental study of a wide list of state-of-the-art OC and PU algorithms in various scenarios as far as unlabeled data reliability is concerned. Furthermore, we propose PU modifications of state-of-the-art OC algorithms that are robust to unreliable unlabeled data, as well as a guideline to similarly modify other OC algorithms. Our main practical recommendation is to use state-of-the-art PU algorithms when unlabeled data is reliable and to use the proposed modifications of state-of-the-art OC algorithms otherwise. Additionally, we outline procedures to distinguish the cases of reliable and unreliable unlabeled data using statistical tests.. 1The code is available at https://github.com/jbr-ai-labs/PU-OC ar X iv :2 20 3. 07 20 6v 1 [ cs .L G ] 1 4 M ar 2 02 2", "year": 2022, "ssId": "3163392f56cdffaa009fbc59f299989a1b8baec1", "arXivId": "2203.07206", "link": "https://arxiv.org/pdf/2203.07206.pdf", "openAccess": true, "authors": ["F. Bagirov", "Dmitry Ivanov", "A. Shpilman"]}}
{"id": "3f16887a8e5c81aea554c7a266b08ea70dd2aa9a", "content": {"title": "Balancing Rational and Other-Regarding Preferences in Cooperative-Competitive Environments", "abstract": "Recent reinforcement learning studies extensively explore the interplay between cooperative and competitive behaviour in mixed environments. Unlike cooperative environments where agents strive towards a common goal, mixed environments are notorious for the conflicts of selfish and social interests. As a consequence, purely rational agents often struggle to maintain cooperation. A prevalent approach to induce cooperative behaviour is to assign additional rewards based on other agents\u2019 well-being. However, this approach suffers from the issue of multi-agent credit assignment, which can hinder performance. This issue is efficiently alleviated in cooperative setting with such state-of-the-art algorithms as QMIX and COMA. Still, when applied tomixed environments, these algorithms may result in unfair allocation of rewards. We propose BAROCCO, an extension of these algorithms capable to balance individual and social incentives. The mechanism behind BAROCCO is to train two distinct but interwoven components that jointly affect agents\u2019 decisions. We experimentally confirm the advantages of BAROCCO.", "year": 2021, "ssId": "3f16887a8e5c81aea554c7a266b08ea70dd2aa9a", "arXivId": "2102.12307", "link": "https://arxiv.org/pdf/2102.12307.pdf", "openAccess": true, "authors": ["Dmitry Ivanov", "Vladimir Egorov", "A. Shpilman"]}}
{"id": "5de24203bf98ae7f4c514bc0bd2a310caa47a047", "content": {"title": "Flatland Competition 2020: MAPF and MARL for Efficient Train Coordination on a Grid World", "abstract": "The Flatland competition aimed at finding novel approaches to solve the vehicle re-scheduling problem (VRSP). The VRSP is concerned with scheduling trips in traffic networks and the re-scheduling of vehicles when disruptions occur, for example the breakdown of a vehicle. While solving the VRSP in various settings has been an active area in operations research (OR) for decades, the ever-growing complexity of modern railway networks makes dynamic real-time scheduling of traffic virtually impossible. Recently, multi-agent reinforcement learning (MARL) has successfully tackled challenging tasks where many agents need to be coordinated, such as multiplayer video games. However, the coordination of hundreds of agents in a real-life setting like a railway network remains challenging and the Flatland environment used for the competition models these real-world properties in a simplified manner. Submissions had to bring as many trains (agents) to their target stations in as little time as possible. While the best submissions were in the OR category, participants found many promising MARL approaches. Using both centralized and decentralized learning based approaches, top submissions used graph representations of the environment to construct tree-based observations. Further, different coordination mechanisms were implemented, such as communication and prioritization between agents. This paper presents the competition setup, four outstanding solutions to the competition, and a cross-comparison between them.", "year": 2021, "ssId": "5de24203bf98ae7f4c514bc0bd2a310caa47a047", "arXivId": "2103.16511", "link": "https://arxiv.org/pdf/2103.16511.pdf", "openAccess": true, "authors": ["Florian Laurent", "Manuel Schneider", "C. Scheller", "J. Watson", "Jiaoyang Li", "Zhe Chen", "Y. Zheng", "Shao-Hung Chan", "Konstantin Makhnev", "Oleg Svidchenko", "Vladimir Egorov", "Dmitry Ivanov", "A. Shpilman", "Evgenija Spirovska", "Oliver Tanevski", "A. nikov", "Ramon Grunder", "David Galevski", "Jakov Mitrovski", "Guillaume Sartoretti", "Zhiyao Luo", "Mehul Damani", "Nilabha Bhattacharya", "Shivam Agarwal", "A. Egli", "Erik Nygren", "S. Mohanty"]}}
{"id": "33c691ca050e1806d44c08e55e63fcd7e555899a", "content": {"title": "DEDPUL: Difference-of-Estimated-Densities-based Positive-Unlabeled Learning", "abstract": "Positive-Unlabeled (PU) learning is an analog to supervised binary classification for the case when only the positive sample is clean, while the negative sample is contaminated with latent instances of positive class and hence can be considered as an unlabeled mixture. The objectives are to classify the unlabeled sample and train an unbiased positive-negative classifier, which generally requires to identify the mixing proportions of positives and negatives first. Recently, unbiased risk estimation framework has achieved state-of-the-art performance in PU learning. This approach, however, exhibits two major bottlenecks. First, the mixing proportions are assumed to be identified, i.e. known in the domain or estimated with additional methods. Second, the approach relies on the classifier being a neural network. In this paper, we propose DEDPUL, a method that solves PU Learning without the aforementioned issues. The mechanism behind DEDPUL is to apply a computationally cheap postprocessing procedure to the predictions of any classifier trained to distinguish positive and unlabeled data. Instead of assuming the proportions to be identified, DEDPUL estimates them alongside with classifying unlabeled sample. Experiments show that DEDPUL outperforms the current state-of-the-art in both proportion estimation and PU Classification and is flexible in the choice of the classifier.", "year": 2020, "ssId": "33c691ca050e1806d44c08e55e63fcd7e555899a", "arXivId": null, "link": null, "openAccess": false, "authors": ["Dmitry Ivanov"]}}
{"id": "65c53ed3575e160eb1e7d0a516353ba52de7e7e5", "content": {"title": "Identifying Bid Leakage in Procurement Auctions: Machine Learning Approach", "abstract": "We propose a novel machine-learning-based approach to detect bid leakage in first-price sealed-bid auctions. We extract and analyze the data on more than 1.4 million Russian procurement auctions between 2014 and 2018. As bid leakage in each particular auction is tacit, the direct classification is impossible. Instead, we reduce the problem of bid leakage detection to Positive-Unlabeled Classification. The key idea is to regard the losing participants as fair and the winners as possibly corrupted. This allows us to estimate the prior probability of bid leakage in the sample, as well as the posterior probability of bid leakage for each specific auction. We find that at least 16% of auctions are exposed to bid leakage. Bid leakage is more likely in auctions with a higher reserve price, lower number of bidders and lower price fall, and where the winning bid is received in the last hour before the deadline.", "year": 2019, "ssId": "65c53ed3575e160eb1e7d0a516353ba52de7e7e5", "arXivId": "1903.00261", "link": "https://arxiv.org/pdf/1903.00261.pdf", "openAccess": true, "authors": ["Dmitry Ivanov", "Alexander S. Nesterov"]}}
