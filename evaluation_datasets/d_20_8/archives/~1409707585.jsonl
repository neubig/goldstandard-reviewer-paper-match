{"id": "2e4cdd36d77b9d814638fc2cd6c703535cb1d2f7", "content": {"title": "Input-Tuning: Adapting Unfamiliar Inputs to Frozen Pretrained Models", "abstract": "Recently the prompt-tuning paradigm has attracted significant attention. By only tuning continuous prompts with a frozen pretrained language model (PLM), prompt-tuning takes a step towards deploying a shared frozen PLM to serve numerous downstream tasks. Although prompt-tuning shows good performance on certain natural language understanding (NLU) tasks, its effectiveness on natural language generation (NLG) tasks is still underexplored. In this paper, we argue that one of the factors hindering the development of prompt-tuning on NLG tasks is the unfamiliar inputs (i.e., inputs are linguistically different from the pretraining corpus). For example, our preliminary exploration reveals a large performance gap between prompt-tuning and fine-tuning when unfamiliar inputs occur frequently in NLG tasks. This motivates us to propose input-tuning, which fine-tunes both the continuous prompts and the input representations, leading to a more effective way to adapt unfamiliar inputs to frozen PLMs. Our proposed input-tuning is conceptually simple and empirically powerful. Experimental results on seven NLG tasks demonstrate that input-tuning is significantly and consistently better than prompt-tuning. Furthermore, on three of these tasks, input-tuning can achieve a comparable or even better performance than fine-tuning.", "year": 2022, "ssId": "2e4cdd36d77b9d814638fc2cd6c703535cb1d2f7", "arXivId": "2203.03131", "link": "https://arxiv.org/pdf/2203.03131.pdf", "openAccess": true, "authors": ["Shengnan An", "Yifei Li", "Zeqi Lin", "Qian Liu", "Bei Chen", "Qiang Fu", "Weizhu Chen", "Nanning Zheng", "Jian-Guang Lou"]}}
{"id": "94c0a8be74d69787a1f3f6e91dcb480a2fd0dd56", "content": {"title": "Reasoning Like Program Executors", "abstract": "Reasoning over natural language is a longstanding goal for the research community. However, studies have shown that existing language models are inadequate in reasoning. To address the issue, we present POET, a new pretraining paradigm. Through pre-training language models with programs and their execution results, POET empowers language models to harvest the reasoning knowledge possessed in program executors via a data-driven approach. POET is conceptually simple and can be instantiated by different kinds of programs. In this paper, we show three empirically powerful instances, i.e., POET-Math, POET-Logic, and POET-SQL. Experimental results on six benchmarks demonstrate that POET can significantly boost model performance on natural language reasoning, such as numerical reasoning, logical reasoning, and multi-hop reasoning. Taking the DROP benchmark as a representative example, POET improves the F1 metric of BART from 69.2% to 80.6%. Furthermore, POET shines in giant language models, pushing the F1 metric of T5-11B to 87.6% and achieving a new state-of-the-art performance on DROP. POET opens a new gate on reasoning-enhancement pre-training and we hope our analysis would shed light on the future research of reasoning like program executors.", "year": 2022, "ssId": "94c0a8be74d69787a1f3f6e91dcb480a2fd0dd56", "arXivId": "2201.11473", "link": "https://arxiv.org/pdf/2201.11473.pdf", "openAccess": true, "authors": ["Xinyu Pi", "Qian Liu", "Bei Chen", "Morteza Ziyadi", "Zeqi Lin", "Yan Gao", "Qiang Fu", "Jian-Guang Lou", "Weizhu Chen"]}}
{"id": "86db47e228167439f15ee320a8a81d386f529a0c", "content": {"title": "LEMON: Language-Based Environment Manipulation via Execution-Guided Pre-training", "abstract": "Language-based environment manipulation requires agents to manipulate the environment following natural language instructions, which is challenging due to the huge space of the environments. To address this challenge, various approaches have been proposed in recent work. Although these approaches work well for their intended environments, they are difficult to generalize across environments. In this work, we propose LEMON, a general framework for language-based environment manipulation tasks. Specifically, we first propose a unified approach to deal with various environments using the same generative language model. Then we propose an execution-guided pre-training strategy to inject prior knowledge of environments to the language model with a pure synthetic pre-training corpus. Experimental results on tasks including ALCHEMY, SCENE, TANGRAMS and PROPARA demonstrate the effectiveness of LEMON: it achieves new state-of-the-art results on ALCHEMY, SCENE and PROPARA, and the execution-guided pretraining strategy brings remarkable improvements on all experimental tasks.", "year": 2022, "ssId": "86db47e228167439f15ee320a8a81d386f529a0c", "arXivId": "2201.08081", "link": "https://arxiv.org/pdf/2201.08081.pdf", "openAccess": true, "authors": ["Qi Shi", "Qian Liu", "Bei Chen", "Yu Zhang", "Ting Liu", "Jian-Guang Lou"]}}
{"id": "0098123efc851b67137c1028f7bac8d8bffbc8fd", "content": {"title": "Awakening Latent Grounding from Pretrained Language Models for Semantic Parsing", "abstract": "Recent years pretrained language models (PLMs) hit a success on several downstream tasks, showing their power on modeling language. To better understand and leverage what PLMs have learned, several techniques have emerged to explore syntactic structures entailed by PLMs. However, few efforts have been made to explore grounding capabilities of PLMs, which are also essential. In this paper, we highlight the ability of PLMs to discover which token should be grounded to which concept, if combined with our proposed erasingthen-awakening approach. Empirical studies on four datasets demonstrate that our approach can awaken latent grounding which is understandable to human experts, even if it is not exposed to such labels during training. More importantly, our approach shows great potential to benefit downstream semantic parsing models. Taking text-to-SQL as a case study, we successfully couple our approach with two off-the-shelf parsers, obtaining an absolute improvement of up to 9.8%.", "year": 2021, "ssId": "0098123efc851b67137c1028f7bac8d8bffbc8fd", "arXivId": "2109.10540", "link": "https://arxiv.org/pdf/2109.10540.pdf", "openAccess": true, "authors": ["Qian Liu", "Dejian Yang", "Jiahui Zhang", "Jiaqi Guo", "Bin Zhou", "Jian-Guang Lou"]}}
{"id": "2406cf39805c70264c4226b7325a09b506c70921", "content": {"title": "TAPEX: Table Pre-training via Learning a Neural SQL Executor", "abstract": "Recent years pre-trained language models hit a success on modeling natural language sentences and (semi-)structured tables. However, existing table pre-training techniques always suffer from low data quality and low pre-training efficiency. In this paper, we show that table pre-training can be realized by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. By pre-training on the synthetic corpus, our approach TAPEX dramatically improves the performance on downstream tasks, boosting existing language models by at most 19.5%. Meanwhile, TAPEX has remarkably high pretraining efficiency and yields strong results when using a small pre-trained corpus. Experimental results demonstrate that TAPEX outperforms previous table pre-training approaches by a large margin, and our model achieves new state-of-the-art results on four well-known datasets, including improving the WIKISQL denotation accuracy to 89.6% (+4.9%), the WIKITABLEQUESTIONS denotation accuracy to 57.5% (+4.8%), the SQA denotation accuracy to 74.5% (+3.5%), and the TABFACT accuracy to 84.6% (+3.6%). Our work opens the way to reason over structured data by pre-training on synthetic executable programs. The project homepage is at https: //table-pretraining.github.io/.", "year": 2021, "ssId": "2406cf39805c70264c4226b7325a09b506c70921", "arXivId": "2107.07653", "link": "https://arxiv.org/pdf/2107.07653.pdf", "openAccess": true, "authors": ["Qian Liu", "Bei Chen", "Jiaqi Guo", "Zeqi Lin", "Jian-Guang Lou"]}}
{"id": "d4d26ccbf1e64e725b5bffc08ab28a72e271facb", "content": {"title": "Chase: A Large-Scale and Pragmatic Chinese Dataset for Cross-Database Context-Dependent Text-to-SQL", "abstract": "The cross-database context-dependent Text-to-SQL (XDTS) problem has attracted considerable attention in recent years due to its wide range of potential applications. However, we identify two biases in existing datasets for XDTS: (1) a high proportion of context-independent questions and (2) a high proportion of easy SQL queries. These biases conceal the major challenges in XDTS to some extent. In this work, we present Chase, a large-scale and pragmatic Chinese dataset for XDTS. It consists of 5,459 coherent question sequences (17,940 questions with their SQL queries annotated) over 280 databases, in which only 35% of questions are context-independent, and 28% of SQL queries are easy. We experiment on Chase with three state-of-the-art XDTS approaches. The best approach only achieves an exact match accuracy of 40% over all questions and 16% over all question sequences, indicating that Chase highlights the challenging problems of XDTS. We believe that XDTS can provide fertile soil for addressing the problems.", "year": 2021, "ssId": "d4d26ccbf1e64e725b5bffc08ab28a72e271facb", "arXivId": null, "link": null, "openAccess": false, "authors": ["Jiaqi Guo", "Ziliang Si", "Yu Wang", "Qian Liu", "Ming Fan", "Jian-Guang Lou", "Z. Yang", "Ting Liu"]}}
{"id": "6d00b1024298e5b64ee873028385f7bb4396b05d", "content": {"title": "Learning Algebraic Recombination for Compositional Generalization", "abstract": "Neural sequence models exhibit limited compositional generalization ability in semantic parsing tasks. Compositional generalization requires algebraic recombination, i.e., dynamically recombining structured expressions in a recursive manner. However, most previous studies mainly concentrate on recombining lexical units, which is an important but not sufficient part of algebraic recombination. In this paper, we propose LEAR, an end-toend neural model to learn algebraic recombination for compositional generalization. The key insight is to model the semantic parsing task as a homomorphism between a latent syntactic algebra and a semantic algebra, thus encouraging algebraic recombination. Specifically, we learn two modules jointly: a Composer for producing latent syntax, and an Interpreter for assigning semantic operations. Experiments on two realistic and comprehensive compositional generalization benchmarks demonstrate the effectiveness of our model. The source code is publicly available at https://github.com/microsoft/ContextualSP.", "year": 2021, "ssId": "6d00b1024298e5b64ee873028385f7bb4396b05d", "arXivId": "2107.06516", "link": "https://arxiv.org/pdf/2107.06516.pdf", "openAccess": true, "authors": ["Chenyao Liu", "Shengnan An", "Zeqi Lin", "Qian Liu", "Bei Chen", "Jian-Guang Lou", "L. Wen", "Nanning Zheng", "Dongmei Zhang"]}}
{"id": "ebc64974e9e0021984a0158b3c04b60327730a88", "content": {"title": "ReTraCk: A Flexible and Efficient Framework for Knowledge Base Question Answering", "abstract": "We present Retriever-Transducer-Checker (ReTraCk), a neural semantic parsing framework for large scale knowledge base question answering (KBQA). ReTraCk is designed as a modular framework to maintain high flexibility. It includes a retriever to retrieve relevant KB items efficiently, a transducer to generate logical form with syntax correctness guarantees and a checker to improve transduction procedure. ReTraCk is ranked at top1 overall performance on the GrailQA leaderboard and obtains highly competitive performance on the typical WebQuestionsSP benchmark. Our system can interact with users timely, demonstrating the efficiency of the proposed framework.", "year": 2021, "ssId": "ebc64974e9e0021984a0158b3c04b60327730a88", "arXivId": null, "link": null, "openAccess": false, "authors": ["Shuang Chen", "Qian Liu", "Zhiwei Yu", "Chin-Yew Lin", "Jian-Guang Lou", "F. Jiang"]}}
{"id": "5ed4b17a4b7932619f0969e1f5acae76e90f7bdd", "content": {"title": "RECPARSER: A Recursive Semantic Parsing Framework for Text-to-SQL Task", "abstract": "Neural semantic parsers usually fail to parse long and complicated utterances into nested SQL queries, due to the large search space. In this paper, we propose a novel recursive semantic parsing framework called RECPARSER to generate the nested SQL query layer-by-layer. It decomposes the complicated nested SQL query generation problem into several progressive non-nested SQL query generation problems. Furthermore, we propose a novel Question Decomposer module to explicitly encourage RECPARSER to focus on different components of utterance when predicting SQL queries in different layers. Experiments on Spider dataset show that our approach is more effective compared to the previous works at predicting the nested SQL queries. In addition, we obtain an overall accuracy that is comparable with the state-of-the-art approaches.", "year": 2020, "ssId": "5ed4b17a4b7932619f0969e1f5acae76e90f7bdd", "arXivId": null, "link": null, "openAccess": false, "authors": ["Yu Zeng", "Yan Gao", "Jiaqi Guo", "B. Chen", "Qian Liu", "Jian-Guang Lou", "Fei Teng", "Dongmei Zhang"]}}
{"id": "4ebe5792fe2890590e7a5bf8ae0a29e0fb147ef9", "content": {"title": "Incomplete Utterance Rewriting as Semantic Segmentation", "abstract": "Recent years the task of incomplete utterance rewriting has raised a large attention. Previous works usually shape it as a machine translation task and employ sequence to sequence based architecture with copy mechanism. In this paper, we present a novel and extensive approach, which formulates it as a semantic segmentation task. Instead of generating from scratch, such a formulation introduces edit operations and shapes the problem as prediction of a word-level edit matrix. Benefiting from being able to capture both local and global information, our approach achieves state-of-the-art performance on several public datasets. Furthermore, our approach is four times faster than the standard approach in inference.", "year": 2020, "ssId": "4ebe5792fe2890590e7a5bf8ae0a29e0fb147ef9", "arXivId": "2009.13166", "link": "https://arxiv.org/pdf/2009.13166.pdf", "openAccess": true, "authors": ["Qian Liu", "Bei Chen", "Jian-Guang Lou", "Bin Zhou", "Dongmei Zhang"]}}
{"id": "b17fa6625681d99370122145ba9911f701dd92cb", "content": {"title": "How Far are We from Effective Context Modeling ? An Exploratory Study on Semantic Parsing in Context", "abstract": "Recently semantic parsing in context has received considerable attention, which is challenging since there are complex contextual phenomena. Previous works verified their proposed methods in limited scenarios, which motivates us to conduct an exploratory study on context modeling methods under real-world semantic parsing in context. We present a grammar-based decoding semantic parser and adapt typical context modeling methods on top of it. We evaluate 13 context modeling methods on two large complex cross-domain datasets, and our best model achieves state-of-the-art performances on both datasets with significant improvements. Furthermore, we summarize the most frequent contextual phenomena, with a fine-grained analysis on representative models, which may shed light on potential research directions. Our code is available at this https URL.", "year": 2020, "ssId": "b17fa6625681d99370122145ba9911f701dd92cb", "arXivId": "2002.00652", "link": "https://arxiv.org/pdf/2002.00652.pdf", "openAccess": true, "authors": ["Qian Liu", "B. Chen", "Jiaqi Guo", "Jian-Guang Lou", "Bin Zhou", "Dongmei Zhang"]}}
{"id": "298a68153859303ee70b3ef1525ee9c7031e32f5", "content": {"title": "You Impress Me: Dialogue Generation via Mutual Persona Perception", "abstract": "Despite the continuing efforts to improve the engagingness and consistency of chit-chat dialogue systems, the majority of current work simply focus on mimicking human-like responses, leaving understudied the aspects of modeling understanding between interlocutors. The research in cognitive science, instead, suggests that understanding is an essential signal for a high-quality chit-chat conversation. Motivated by this, we propose P\u02c62 Bot, a transmitter-receiver based framework with the aim of explicitly modeling understanding. Specifically, P\u02c62 Bot incorporates mutual persona perception to enhance the quality of personalized dialogue generation. Experiments on a large public dataset, Persona-Chat, demonstrate the effectiveness of our approach, with a considerable boost over the state-of-the-art baselines across both automatic metrics and human evaluations.", "year": 2020, "ssId": "298a68153859303ee70b3ef1525ee9c7031e32f5", "arXivId": "2004.05388", "link": "https://arxiv.org/pdf/2004.05388.pdf", "openAccess": true, "authors": ["Qian Liu", "Yihong Chen", "B. Chen", "Jian-Guang Lou", "Zixuan Chen", "Bin Zhou", "Dongmei Zhang"]}}
{"id": "bc247abf8180f583a42de392e4f7d2b2a41ad72d", "content": {"title": "\u201cWhat Do You Mean by That?\u201d - a Parser-Independent Interactive Approach for Enhancing Text-to-SQL", "abstract": "In Natural Language Interfaces to Databases systems, the text-to-SQL technique allows users to query databases by using natural language questions. Though significant progress in this area has been made recently, most parsers may fall short when they are deployed in real systems. One main reason stems from the difficulty of fully understanding the users' natural language questions. In this paper, we include human in the loop and present a novel parser-independent interactive approach (PIIA) that interacts with users using multi-choice questions and can easily work with arbitrary parsers. Experiments were conducted on two cross-domain datasets, the WikiSQL and the more complex Spider, with five state-of-the-art parsers. These demonstrated that PIIA is capable of enhancing the text-to-SQL performance with limited interaction turns by using both simulation and human evaluation.", "year": 2020, "ssId": "bc247abf8180f583a42de392e4f7d2b2a41ad72d", "arXivId": "2011.04151", "link": "https://arxiv.org/pdf/2011.04151.pdf", "openAccess": true, "authors": ["Yuntao Li", "Bei Chen", "Qian Liu", "Yan Gao", "Jian-Guang Lou", "Yan Zhang", "Dongmei Zhang"]}}
{"id": "336ee50043b916c9e932338c02fd1abc87a6e849", "content": {"title": "Compositional Generalization by Learning Analytical Expressions", "abstract": "Compositional generalization is a basic but essential intellective capability of human beings, which allows us to recombine known parts readily. However, existing neural network based models have been proven to be extremely deficient in such a capability. Inspired by work in cognition which argues compositionality can be captured by variable slots with symbolic functions, we present a refreshing view that connects a memory-augmented neural model with analytical expressions, to achieve compositional generalization. Our model consists of two cooperative neural modules Composer and Solver, fitting well with the cognitive argument while still being trained in an end-to-end manner via a hierarchical reinforcement learning algorithm. Experiments on a well-known benchmark SCAN demonstrate that our model seizes a great ability of compositional generalization, solving all challenges addressed by previous works with 100% accuracies.", "year": 2020, "ssId": "336ee50043b916c9e932338c02fd1abc87a6e849", "arXivId": "2006.10627", "link": "https://arxiv.org/pdf/2006.10627.pdf", "openAccess": true, "authors": ["Qian Liu", "S. An", "Jian-Guang Lou", "Bei Chen", "Zeqi Lin", "Yan Gao", "Bin Zhou", "Nanning Zheng", "Dongmei Zhang"]}}
{"id": "8328508dc12c295165f997e02d74d00a42971c01", "content": {"title": "How Far are We from Effective Context Modeling? An Exploratory Study on Semantic Parsing in Context", "abstract": "Recently semantic parsing in context has received considerable attention, which is challenging since there are complex contextual phenomena. Previous works verified their proposed methods in limited scenarios, which motivates us to conduct an exploratory study on context modeling methods under real-world semantic parsing in context. We present a grammar-based decoding semantic parser and adapt typical context modeling methods on top of it. We evaluate 13 context modeling methods on two large complex cross-domain datasets, and our best model achieves state-of-the-art performances on both datasets with significant improvements. Furthermore, we summarize the most frequent contextual phenomena, with a fine-grained analysis on representative models, which may shed light on potential research directions. Our code is available at\u00a0this https URL.", "year": 2020, "ssId": "8328508dc12c295165f997e02d74d00a42971c01", "arXivId": null, "link": null, "openAccess": false, "authors": ["Qian Liu", "B. Chen", "Jiaqi Guo", "Jian-Guang Lou", "Bin Zhou", "Dongmei Zhang"]}}
{"id": "a1c4ce9de92338646c6ee93c7c2e5ee366784b1a", "content": {"title": "Benchmarking Meaning Representations in Neural Semantic Parsing", "abstract": "Meaning representation is an important component of semantic parsing. Although researchers have designed a lot of meaning representations, recent work focuses on only a few of them. Thus, the impact of meaning representation on semantic parsing is less understood. Furthermore, existing work\u2019s performance is often not comprehensively evaluated due to the lack of readily-available execution engines. Upon identifying these gaps, we propose , a new unified benchmark on meaning representations, by integrating existing semantic parsing datasets, completing the missing logical forms, and implementing the missing execution engines. The resulting unified benchmark contains the complete enumeration of logical forms and execution engines over three datasets \u00d7 four meaning representations. A thorough experimental study on Unimer reveals that neural semantic parsing approaches exhibit notably different performance when they are trained to generate different meaning representations. Also, program alias and grammar rules heavily impact the performance of different meaning representations. Our benchmark, execution engines and implementation can be found on: https://github.com/JasperGuo/Unimer.", "year": 2020, "ssId": "a1c4ce9de92338646c6ee93c7c2e5ee366784b1a", "arXivId": null, "link": null, "openAccess": false, "authors": ["Jiaqi Guo", "Qian Liu", "Jian-Guang Lou", "Zhenwen Li", "Xueqing Liu", "Tao Xie", "Ting Liu"]}}
{"id": "f32108602fb0dbda29030cac780165a4b89048a3", "content": {"title": "Leveraging Adjective-Noun Phrasing Knowledge for Comparison Relation Prediction in Text-to-SQL", "abstract": "One key component in text-to-SQL is to predict the comparison relations between columns and their values. To the best of our knowledge, no existing models explicitly introduce external common knowledge to address this problem, thus their capabilities of predicting comparison relations are limited beyond training data. In this paper, we propose to leverage adjective-noun phrasing knowledge mined from the web to predict the comparison relations in text-to-SQL. Experimental results on both the original and the re-split Spider dataset show that our approach achieves significant improvement over state-of-the-art methods on comparison relation prediction.", "year": 2019, "ssId": "f32108602fb0dbda29030cac780165a4b89048a3", "arXivId": null, "link": null, "openAccess": false, "authors": ["Haoyan Liu", "Lei Fang", "Qian Liu", "B. Chen", "Jian-Guang Lou", "Zhoujun Li"]}}
{"id": "9abd13caa32b1a90e32462a884a512f8666e80cc", "content": {"title": "A Split-and-Recombine Approach for Follow-up Query Analysis", "abstract": "Context-dependent semantic parsing has proven to be an important yet challenging task. To leverage the advances in context-independent semantic parsing, we propose to perform follow-up query analysis, aiming to restate context-dependent natural language queries with contextual information. To accomplish the task, we propose STAR, a novel approach with a well-designed two-phase process. It is parser-independent and able to handle multifarious follow-up scenarios in different domains. Experiments on the FollowUp dataset show that STAR outperforms the state-of-the-art baseline by a large margin of nearly 8%. The superiority on parsing results verifies the feasibility of follow-up query analysis. We also explore the extensibility of STAR on the SQA dataset, which is very promising.", "year": 2019, "ssId": "9abd13caa32b1a90e32462a884a512f8666e80cc", "arXivId": "1909.08905", "link": "https://arxiv.org/pdf/1909.08905.pdf", "openAccess": true, "authors": ["Qian Liu", "B. Chen", "Haoyan Liu", "Lei Fang", "Jian-Guang Lou", "Bin Zhou", "D. Zhang"]}}
{"id": "74b05adf1ec74849a4f7963fe3f17fd61b92af4b", "content": {"title": "FANDA: A Novel Approach to Perform Follow-up Query Analysis", "abstract": "Recent work on Natural Language Interfaces to Databases (NLIDB) has attracted considerable attention. NLIDB allow users to search databases using natural language instead of SQL-like query languages. While saving the users from having to learn query languages, multi-turn interaction with NLIDB usually involves multiple queries where contextual information is vital to understand the users\u2019 query intents. In this paper, we address a typical contextual understanding problem, termed as follow-up query analysis. In spite of its ubiquity, follow-up query analysis has not been well studied due to two primary obstacles: the multifarious nature of follow-up query scenarios and the lack of high-quality datasets. Our work summarizes typical follow-up query scenarios and provides a new FollowUp dataset with 1000 query triples on 120 tables. Moreover, we propose a novel approach FANDA, which takes into account the structures of queries and employs a ranking model with weakly supervised max-margin learning. The experimental results on FollowUp demonstrate the superiority of FANDA over multiple baselines across multiple metrics.", "year": 2019, "ssId": "74b05adf1ec74849a4f7963fe3f17fd61b92af4b", "arXivId": "1901.08259", "link": "https://arxiv.org/pdf/1901.08259.pdf", "openAccess": true, "authors": ["Qian Liu", "B. Chen", "Jian-Guang Lou", "Ge Jin", "Dongmei Zhang"]}}
