{"id": "1a0d8dbd0252193abe9d64f72fc56cc1f05ed3eb", "content": {"title": "CURIE: An Iterative Querying Approach for Reasoning About Situations", "abstract": "Recently, models have been shown to predict the effects of unexpected situations, e.g., would cloudy skies help or hinder plant growth? Given a context, the goal of such situational reasoning is to elicit the consequences of a new situation (st) that arises in that context. We propose a method to iteratively build a graph of relevant consequences explicitly in a structured situational graph (st graph) using natural language queries over a finetuned language model (M). Across multiple domains, CURIE generates st graphs that humans find relevant and meaningful in eliciting the consequences of a new situation. We show that st graphs generated by CURIE improve a situational reasoning end task (WIQA-QA) by 3 points on accuracy by simply augmenting their input with our generated situational graphs, especially for a hard subset that requires background knowledge and multi-hop reasoning.", "year": 2021, "ssId": "1a0d8dbd0252193abe9d64f72fc56cc1f05ed3eb", "arXivId": "2104.00814", "link": "https://arxiv.org/pdf/2104.00814.pdf", "openAccess": true, "authors": ["Dheeraj Rajagopal", "Aman Madaan", "Niket Tandon", "Yiming Yang", "Shrimai Prabhumoye", "Abhilasha Ravichander", "Peter Clark", "E. Hovy"]}}
{"id": "3aba582b62d1abfcd95264e6c7b32aab4c9db4b8", "content": {"title": "SELFEXPLAIN: A Self-Explaining Architecture for Neural Text Classifiers", "abstract": "We introduce SelfExplain, a novel self-explaining model that explains a text classifier\u2019s predictions using phrase-based concepts. SelfExplain augments existing neural classifiers by adding (1) a globally interpretable layer that identifies the most influential concepts in the training set for a given sample and (2) a locally interpretable layer that quantifies the contribution of each local input concept by computing a relevance score relative to the predicted label. Experiments across five text-classification datasets show that SelfExplain facilitates interpretability without sacrificing performance. Most importantly, explanations from SelfExplain show sufficiency for model predictions and are perceived as adequate, trustworthy and understandable by human judges compared to existing widely-used baselines.", "year": 2021, "ssId": "3aba582b62d1abfcd95264e6c7b32aab4c9db4b8", "arXivId": "2103.12279", "link": "https://arxiv.org/pdf/2103.12279.pdf", "openAccess": true, "authors": ["Dheeraj Rajagopal", "Vidhisha Balachandran", "E. Hovy", "Yulia Tsvetkov"]}}
{"id": "8c5ba1c914eab16b705da03352fe69d5bcfc72ea", "content": {"title": "StructSum: Summarization via Structured Representations", "abstract": "Abstractive text summarization aims at compressing the information of a long source document into a rephrased, condensed summary. Despite advances in modeling techniques, abstractive summarization models still suffer from several key challenges: (i) layout bias: they overfit to the style of training corpora; (ii) limited abstractiveness: they are optimized to copying n-grams from the source rather than generating novel abstractive summaries; (iii) lack of transparency: they are not interpretable. In this work, we propose a framework based on document-level structure induction for summarization to address these challenges. To this end, we propose incorporating latent and explicit dependencies across sentences in the source document into end-to-end single-document summarization models. Our framework complements standard encoder-decoder summarization models by augmenting them with rich structure-aware document representations based on implicitly learned (latent) structures and externally-derived linguistic (explicit) structures. We show that our summarization framework, trained on the CNN/DM dataset, improves the coverage of content in the source documents, generates more abstractive summaries by generating more novel n-grams, and incorporates interpretable sentence-level structures, while performing on par with standard baselines.", "year": 2021, "ssId": "8c5ba1c914eab16b705da03352fe69d5bcfc72ea", "arXivId": null, "link": null, "openAccess": false, "authors": ["Vidhisha Balachandran", "Artidoro Pagnoni", "Jay Yoon Lee", "Dheeraj Rajagopal", "J. Carbonell", "Yulia Tsvetkov"]}}
{"id": "3dcf9c900f5f28e082a2fcdea4763b6063a76f09", "content": {"title": "Think about it! Improving defeasible reasoning by first modeling the question scenario.", "abstract": "Defeasible reasoning is the mode of reasoning where conclusions can be overturned by taking into account new evidence. Existing cognitive science literature on defeasible reasoning suggests that a person forms a \u201cmental model\u201d of the problem scenario before answering questions. Our research goal asks whether neural models can similarly benefit from envisioning the question scenario before answering a defeasible query. Our approach is, given a question, to have a model first create a graph of relevant influences, and then leverage that graph as an additional input when answering the question. Our system, CURIOUS, achieves a new state-of-the-art on three different defeasible reasoning datasets. This result is significant as it illustrates that performance can be improved by guiding a system to \u201cthink about\u201d a question and explicitly model the scenario, rather than answering reflexively.", "year": 2021, "ssId": "3dcf9c900f5f28e082a2fcdea4763b6063a76f09", "arXivId": "2110.12349", "link": "https://arxiv.org/pdf/2110.12349.pdf", "openAccess": true, "authors": ["Aman Madaan", "Niket Tandon", "Dheeraj Rajagopal", "Peter Clark", "Yiming Yang", "E. Hovy"]}}
{"id": "7393d2618c7478d937112865458862e8d5f10475", "content": {"title": "Cross-Domain Reasoning via Template Filling", "abstract": "In this paper, we explore the ability of sequence to sequence models to perform crossdomain reasoning. Towards this, we present a prompt-template-filling approach to enable sequence to sequence models to perform crossdomain reasoning. We also present a casestudy with commonsense and health and wellbeing domains, where we study how prompttemplate-filling enables pretrained sequence to sequence models across domains. Our experiments across several pretrained encoderdecoder models show that cross-domain reasoning is challenging for current models. We also show an in-depth error analysis and avenues for future research for reasoning across domains1.", "year": 2021, "ssId": "7393d2618c7478d937112865458862e8d5f10475", "arXivId": "2111.00539", "link": "https://arxiv.org/pdf/2111.00539.pdf", "openAccess": true, "authors": ["Dheeraj Rajagopal", "Vivek Khetan", "Bogdan Sacaleanu", "A. Gershman", "Andy E. Fano", "E. Hovy"]}}
{"id": "b9057dce43181a30aa3e0435c8ffc4c0b6f8f127", "content": {"title": "Could you give me a hint ? Generating inference graphs for defeasible reasoning", "abstract": "Defeasible reasoning is a mode of reasoning where conclusions can be overturned by taking into account new evidence. A commonly used method in cognitive science and logic literature is to handcraft argumentation supporting inference graphs. While humans find inference graphs very useful for reasoning, constructing them at scale is difficult. In this paper, we automatically generate such inference graphs through transfer learning from a related NLP task that shares the kind of reasoning that inference graphs support. Through automated metrics and human evaluation, we find that our method generates meaningful graphs for the defeasible inference task. Human accuracy on this task improves by 20% by consulting the generated graphs. Our findings open up exciting new research avenues for cases where machine reasoning can help human reasoning.1", "year": 2021, "ssId": "b9057dce43181a30aa3e0435c8ffc4c0b6f8f127", "arXivId": "2105.05418", "link": "https://arxiv.org/pdf/2105.05418.pdf", "openAccess": true, "authors": ["Aman Madaan", "Dheeraj Rajagopal", "Niket Tandon", "Yiming Yang", "E. Hovy"]}}
{"id": "f5ca46585818771e64ee9449c930748fbee35cba", "content": {"title": "Improving Neural Model Performance through Natural Language Feedback on Their Explanations", "abstract": "A class of explainable NLP models for reasoning tasks support their decisions by generating free-form or structured explanations, but what happens when these supporting structures contain errors? Our goal is to allow users to interactively correct explanation structures through natural language feedback. We introduce MERCURIEan interactive system that refines its explanations for a given reasoning task by getting human feedback in natural language. Our approach generates graphs that have 40% fewer inconsistencies as compared with the off-the-shelf system. Further, simply appending the corrected explanation structures to the output leads to a gain of 1.2 points on accuracy on defeasible reasoning across all three domains.1", "year": 2021, "ssId": "f5ca46585818771e64ee9449c930748fbee35cba", "arXivId": "2104.08765", "link": "https://arxiv.org/pdf/2104.08765.pdf", "openAccess": true, "authors": ["Aman Madaan", "Niket Tandon", "Dheeraj Rajagopal", "Yiming Yang", "Peter Clark", "Keisuke Sakaguchi", "E. Hovy"]}}
{"id": "d47ad0a606bedf41dcea614bfa7b7494879c7ba0", "content": {"title": "A Dataset for Tracking Entities in Open Domain Procedural Text", "abstract": "We present the first dataset for tracking state changes in procedural text from arbitrary domains by using an unrestricted (open) vocabulary. For example, in a text describing fog removal using potatoes, a car window may transition between being foggy, sticky, opaque, and clear. Previous formulations of this task provide the text and entities involved, and ask how those entities change for just a small, pre-defined set of attributes (e.g., location), limiting their fidelity. Our solution is a new task formulation where given just a procedural text as input, the task is to generate a set of state change tuples (entity, attribute, before-state, after-state) for each step, where the entity, attribute, and state values must be predicted from an open vocabulary. Using crowdsourcing, we create OPENPI, a high-quality (91.5% coverage as judged by humans and completely vetted), and large-scale dataset comprising 29,928 state changes over 4,050 sentences from 810 procedural real-world paragraphs from WikiHow.com. A current state-of-the-art generation model on this task achieves 16.1% F1 based on BLEU metric, leaving enough room for novel model architectures.", "year": 2020, "ssId": "d47ad0a606bedf41dcea614bfa7b7494879c7ba0", "arXivId": "2011.08092", "link": "https://arxiv.org/pdf/2011.08092.pdf", "openAccess": true, "authors": ["Niket Tandon", "Keisuke Sakaguchi", "Bhavana Dalvi", "Dheeraj Rajagopal", "Peter Clark", "Michal Guerquin", "Kyle Richardson", "E. Hovy"]}}
{"id": "18ef33a6e040b49ba475e586202932cecbafba0d", "content": {"title": "EIGEN: Event Influence GENeration using Pre-trained Language Models", "abstract": "Reasoning about events and tracking their influences is fundamental to understanding processes. In this paper, we present EIGEN - a method to leverage pre-trained language models to generate event influences conditioned on a context, nature of their influence, and the distance in a reasoning chain. We also derive a new dataset for research and evaluation of methods for event influence generation. EIGEN outperforms strong baselines both in terms of automated evaluation metrics (by 10 ROUGE points) and human judgments on closeness to reference and relevance of generations. Furthermore, we show that the event influences generated by EIGEN improve the performance on a \"what-if\" Question Answering (WIQA) benchmark (over 3% F1), especially for questions that require background knowledge and multi-hop reasoning.", "year": 2020, "ssId": "18ef33a6e040b49ba475e586202932cecbafba0d", "arXivId": "2010.11764", "link": "https://arxiv.org/pdf/2010.11764.pdf", "openAccess": true, "authors": ["Aman Madaan", "Dheeraj Rajagopal", "Yiming Yang", "Abhilasha Ravichander", "E. Hovy", "Shrimai Prabhumoye"]}}
{"id": "0b8dbc4a899c836fe2b1a213b9dc064cdf62fd63", "content": {"title": "What-if I ask you to explain: Explaining the effects of perturbations in procedural text", "abstract": "Our goal is to explain the effects of perturbations in procedural text, e.g., given a passage describing a rabbit\u2019s life cycle, explain why illness (the perturbation) may reduce the rabbit population (the effect). Although modern systems are able to solve the original prediction task well (e.g., illness results in less rabbits), the explanation task - identifying the causal chain of events from perturbation to effect - remains largely unaddressed, and is the goal of this research. We present QUARTET, a system that constructs such explanations from paragraphs, by modeling the explanation task as a multitask learning problem. QUARTET constructs explanations from the sentences in the procedural text, achieving ~18 points better on explanation accuracy compared to several strong baselines on a recent process comprehension benchmark. On an end task on this benchmark, we show a surprising finding that good explanations do not have to come at the expense of end task performance, in fact leading to a 7% F1 improvement over SOTA.", "year": 2020, "ssId": "0b8dbc4a899c836fe2b1a213b9dc064cdf62fd63", "arXivId": "2005.01526", "link": "https://arxiv.org/pdf/2005.01526.pdf", "openAccess": true, "authors": ["Dheeraj Rajagopal", "Niket Tandon", "Peter Clarke", "Bhavana Dalvi", "E. Hovy"]}}
{"id": "f184908270fc934ab74438a0aaac7a43a5eae6d2", "content": {"title": "StructSum: Incorporating Latent and Explicit Sentence Dependencies for Single Document Summarization", "abstract": "Traditional preneural approaches to single document summarization relied on modeling the intermediate structure of a document before generating the summary. In contrast, the current state of the art neural summarization models do not preserve any intermediate structure, resorting to encoding the document as a sequence of tokens. The goal of this work is two-fold: to improve the quality of generated summaries and to learn interpretable document representations for summarization. To this end, we propose incorporating latent and explicit sentence dependencies into single-document summarization models. We use structure-aware encoders to induce latent sentence relations, and inject explicit coreferring mention graph across sentences to incorporate explicit structure. On the CNN/DM dataset, our model outperforms standard baselines and provides intermediate latent structures for analysis. We present an extensive analysis of our summaries and show that modeling document structure reduces copying long sequences and incorporates richer content from the source document while maintaining comparable summary lengths and an increased degree of abstraction.", "year": 2020, "ssId": "f184908270fc934ab74438a0aaac7a43a5eae6d2", "arXivId": "2003.00576", "link": "https://arxiv.org/pdf/2003.00576.pdf", "openAccess": true, "authors": ["Vidhisha Balachandran", "Artidoro Pagnoni", "Jay Yoon Lee", "Dheeraj Rajagopal", "J. Carbonell", "Yulia Tsvetkov"]}}
{"id": "7621bfe36cc649a5876cea587366201e158a8b38", "content": {"title": "Domain Adaptation of SRL Systems for Biological Processes", "abstract": "Domain adaptation remains one of the most challenging aspects in the wide-spread use of Semantic Role Labeling (SRL) systems. Current state-of-the-art methods are typically trained on large-scale datasets, but their performances do not directly transfer to low-resource domain-specific settings. In this paper, we propose two approaches for domain adaptation in the biological domain that involves pre-training LSTM-CRF based on existing large-scale datasets and adapting it for a low-resource corpus of biological processes. Our first approach defines a mapping between the source labels and the target labels, and the other approach modifies the final CRF layer in sequence-labeling neural network architecture. We perform our experiments on ProcessBank dataset which contains less than 200 paragraphs on biological processes. We improve over the previous state-of-the-art system on this dataset by 21 F1 points. We also show that, by incorporating event-event relationship in ProcessBank, we are able to achieve an additional 2.6 F1 gain, giving us possible insights into how to improve SRL systems for biological process using richer annotations.", "year": 2019, "ssId": "7621bfe36cc649a5876cea587366201e158a8b38", "arXivId": null, "link": null, "openAccess": false, "authors": ["Dheeraj Rajagopal", "Nidhi Vyas", "Aditya Siddhant", "Anirudha Rayasam", "Niket Tandon", "E. Hovy"]}}
{"id": "311381feeb6346bfcb2ba622bd8f713261a4075d", "content": {"title": "Modeling the Relationship between User Comments and Edits in Document Revision", "abstract": "Management of collaborative documents can be difficult, given the profusion of edits and comments that multiple authors make during a document\u2019s evolution. Reliably modeling the relationship between edits and comments is a crucial step towards helping the user keep track of a document in flux. A number of authoring tasks, such as categorizing and summarizing edits, detecting completed to-dos, and visually rearranging comments could benefit from such a contribution. Thus, in this paper we explore the relationship between comments and edits by defining two novel, related tasks: Comment Ranking and Edit Anchoring. We begin by collecting a dataset with more than half a million comment-edit pairs based on Wikipedia revision histories. We then propose a hierarchical multi-layer deep neural-network to model the relationship between edits and comments. Our architecture tackles both Comment Ranking and Edit Anchoring tasks by encoding specific edit actions such as additions and deletions, while also accounting for document context. In a number of evaluation settings, our experimental results show that our approach outperforms several strong baselines significantly. We are able to achieve a precision@1 of 71.0% and a precision@3 of 94.4% for Comment Ranking, while we achieve 74.4% accuracy on Edit Anchoring.", "year": 2019, "ssId": "311381feeb6346bfcb2ba622bd8f713261a4075d", "arXivId": null, "link": null, "openAccess": false, "authors": ["Xuchao Zhang", "Dheeraj Rajagopal", "Michael Gamon", "S. Jauhar", "Chang-Tien Lu"]}}
{"id": "7650d705b85dc399112a5b6a79e9c6f81c7c6146", "content": {"title": "Simple and Effective Semi-Supervised Question Answering", "abstract": "Recent success of deep learning models for the task of extractive Question Answering (QA) is hinged on the availability of large annotated corpora. However, large domain specific annotated corpora are limited and expensive to construct. In this work, we envision a system where the end user specifies a set of base documents and only a few labelled examples. Our system exploits the document structure to create cloze-style questions from these base documents; pre-trains a powerful neural network on the cloze style questions; and further fine-tunes the model on the labeled examples. We evaluate our proposed system across three diverse datasets from different domains, and find it to be highly effective with very little labeled data. We attain more than 50% F1 score on SQuAD and TriviaQA with less than a thousand labelled examples. We are also releasing a set of 3.2M cloze-style questions for practitioners to use while building QA systems.", "year": 2018, "ssId": "7650d705b85dc399112a5b6a79e9c6f81c7c6146", "arXivId": "1804.00720", "link": "https://arxiv.org/pdf/1804.00720.pdf", "openAccess": true, "authors": ["Bhuwan Dhingra", "Danish Pruthi", "Dheeraj Rajagopal"]}}
{"id": "d385d8563192569b229bde762fcd4d57ce2b3ee2", "content": {"title": "Learning to Define Terms in the Software Domain", "abstract": "One way to test a person\u2019s knowledge of a domain is to ask them to define domain-specific terms. Here, we investigate the task of automatically generating definitions of technical terms by reading text from the technical domain. Specifically, we learn definitions of software entities from a large corpus built from the user forum Stack Overflow. To model definitions, we train a language model and incorporate additional domain-specific information like word co-occurrence, and ontological category information. Our approach improves previous baselines by 2 BLEU points for the definition generation task. Our experiments also show the additional challenges associated with the task and the short-comings of language-model based architectures for definition generation.", "year": 2018, "ssId": "d385d8563192569b229bde762fcd4d57ce2b3ee2", "arXivId": null, "link": null, "openAccess": false, "authors": ["Vidhisha Balachandran", "Dheeraj Rajagopal", "R. Catherine", "William W. Cohen"]}}
{"id": "ff6ddbd7ba59e0fd4a74748942083391d6e9a666", "content": {"title": "OPERA: Operations-oriented Probabilistic Extraction, Reasoning, and Analysis", "abstract": "This paper describes CMU and USC/ISI\u2019s OPERA system that performs endto-end information extraction from multiple media, integrates results across English, Russian, and Ukrainian, produces Knowledge Bases containing the extracted information, and performs hypothesis reasoning over the results.", "year": 2018, "ssId": "ff6ddbd7ba59e0fd4a74748942083391d6e9a666", "arXivId": null, "link": null, "openAccess": false, "authors": ["E. Hovy", "Taylor Berg-Kirkpatrick", "J. Carbonell", "Hans Chalupsky", "A. Gershman", "Alexander Hauptmann", "Florian Metze", "T. Mitamura", "Aditi Chaudhary", "Xianyang Chen", "Bernie Huang", "H. Liu", "Xuezhe Ma", "Shruti Palaskar", "Dheeraj Rajagopal", "Maria Ryskina", "Ramon Sanabria"]}}
{"id": "88347f9f12b50590f50aefce4cf71b3a3f0bd138", "content": {"title": "Gated-Attention Architectures for Task-Oriented Language Grounding", "abstract": "To perform tasks specified by natural language instructions, autonomous agents need to extract semantically meaningful representations of language and map it to visual elements and actions in the environment. This problem is called task-oriented language grounding. We propose an end-to-end trainable neural architecture for task-oriented language grounding in 3D environments which assumes no prior linguistic or perceptual knowledge and requires only raw pixels from the environment and the natural language instruction as input. The proposed model combines the image and text representations using a Gated-Attention mechanism and learns a policy to execute the natural language instruction using standard reinforcement and imitation learning methods. We show the effectiveness of the proposed model on unseen instructions as well as unseen maps, both quantitatively and qualitatively. We also introduce a novel environment based on a 3D game engine to simulate the challenges of task-oriented language grounding over a rich set of instructions and environment states.", "year": 2017, "ssId": "88347f9f12b50590f50aefce4cf71b3a3f0bd138", "arXivId": "1706.07230", "link": "https://arxiv.org/pdf/1706.07230.pdf", "openAccess": true, "authors": ["Devendra Singh Chaplot", "Kanthashree Mysore Sathyendra", "Rama Kumar Pasumarthi", "Dheeraj Rajagopal", "R. Salakhutdinov"]}}
{"id": "41d4763792db8ea420efcfbd112a55deec971fee", "content": {"title": "A proposal of the marriage of Encyclopedic and Commonsense Knowledge", "abstract": "Commonsense Knowledge (lexical + common knowledge) and Encyclopedic knowledge helps in different situations because one is about entities and other is about named entities. We set up a principled experiment to empirically verify that for real world scenarios, it is best to have a marriage of the types of knowledge. We envision WordNet to be the mediator between these two systems just like Wikipedia is the mediator in linked open data. For this purpose the Yago ontology would be helpful as well.", "year": 2016, "ssId": "41d4763792db8ea420efcfbd112a55deec971fee", "arXivId": null, "link": null, "openAccess": false, "authors": ["Dheeraj Rajagopal"]}}
{"id": "a95400c70c4beb609c77cc500677b2f1ed852e8e", "content": {"title": "Generating Questions and Multiple-Choice Answers using Semantic Analysis of Texts", "abstract": "We present a novel approach to automated question generation that improves upon prior work both from a technology perspective and from an assessment perspective. Our system is aimed at engaging language learners by generating multiple-choice questions which utilize specific inference steps over multiple sentences, namely coreference resolution and paraphrase detection. The system also generates correct answers and semantically-motivated phrase-level distractors as answer choices. Evaluation by human annotators indicates that our approach requires a larger number of inference steps, which necessitate deeper semantic understanding of texts than a traditional single-sentence approach.", "year": 2016, "ssId": "a95400c70c4beb609c77cc500677b2f1ed852e8e", "arXivId": null, "link": null, "openAccess": false, "authors": ["J. Araki", "Dheeraj Rajagopal", "Sreecharan Sankaranarayanan", "Susan Holm", "Yukari Yamakawa", "T. Mitamura"]}}
{"id": "47442ea4c28d631a9d46a9c23454684b834e49ea", "content": {"title": "Unsupervised Event Coreference for Abstract Words", "abstract": "We introduce a novel approach for resolving coreference when the trigger word refers to multiple (sometimes non-contiguous) clauses. Our approach is completely unsupervised, and our experiments show that Neural Network models perform much better (about 20% more accurate) than traditional feature-rich baseline models. We also present a new dataset for Biomedical Language Processing which, with only about 25% of the original corpus vocabulary, still captures the essential distributional semantics of the corpus.", "year": 2016, "ssId": "47442ea4c28d631a9d46a9c23454684b834e49ea", "arXivId": null, "link": null, "openAccess": false, "authors": ["Dheeraj Rajagopal", "E. Hovy", "T. Mitamura"]}}
