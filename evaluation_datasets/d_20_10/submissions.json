{"e54a4e49917eb3da18c2f239be70a68fbd3274c3": {"id": "e54a4e49917eb3da18c2f239be70a68fbd3274c3", "content": {"title": "Technical Debt in the Peer-Review Documentation of R Packages: a rOpenSci Case Study", "abstract": "Context: Technical Debt (TD) is a metaphor used to describe code that is \"not quite right.\" Although TD studies have gained momentum, TD has yet to be studied as thoroughly in non-Object-Oriented (OO) or scientific software such as R. R is a multi-paradigm programming language, whose popularity in data science and statistical applications has amplified in recent years. Due to R\u2019s inherent ability to expand through user-contributed packages, several community-led organizations were created to organize and peer-review packages in a concerted effort to increase their quality. Nonetheless, it is well-known that most R users do not have a technical programming background, being from multiple disciplines. Objective: The goal of this study is to investigate TD in the documentation of the peer-review of R packages led by rOpenSci. Method: We collected over 5,000 comments from 157 packages that had been reviewed and approved to be published at rOpenSci. We manually analyzed a sample dataset of these comments posted by package authors, editors of rOpenSci, and reviewers during the review process to investigate the types of TD present in these reviews. Results: The findings of our study include (i) a taxonomy of TD derived from our analysis of the peer-reviews (ii) documentation debt as being the most prevalent type of debt (iii) different user roles are concerned with different types of TD. For instance, reviewers tend to report some types of TD more than other roles, and the types of TD they report are different from those reported by the authors of a package. Conclusion: TD analysis in scientific software or peer-review is almost non-existent. Our study is a pioneer but within the context of R packages. However, our findings can serve as a starting point for replication studies, given our public datasets, to perform similar analyses in other scientific software or to investigate the rationale behind our findings.", "year": 2021, "ssId": "e54a4e49917eb3da18c2f239be70a68fbd3274c3", "arXivId": "2103.09340", "link": "https://arxiv.org/pdf/2103.09340.pdf", "openAccess": true, "authors": ["Zadia Codabux", "M. Vidoni", "F. Fard"]}}, "3c0d4dc4237934e37467f4ede3af859bcb140abf": {"id": "3c0d4dc4237934e37467f4ede3af859bcb140abf", "content": {"title": "Boosting Crowd Counting with Transformers", "abstract": "Significant progress on the crowd counting problem has been achieved by integrating larger context into convolutional neural networks (CNNs). This indicates that global scene context is essential, despite the seemingly bottom-up nature of the problem. This may be explained by the fact that context knowledge can adapt and improve local feature extraction to a given scene. In this paper, we therefore investigate the role of global context for crowd counting. Specifically, a pure transformer is used to extract features with global information from overlapping image patches. Inspired by classification, we add a context token to the input sequence, to facilitate information exchange with tokens corresponding to image patches throughout transformer layers. Due to the fact that transformers do not explicitly model the tried-and-true channel-wise interactions, we propose a token-attention module (TAM) to recalibrate encoded features through channel-wise attention informed by the context token. Beyond that, it is adopted to predict the total person count of the image through regression-token module (RTM). Extensive experiments demonstrate that our method achieves state-of-the-art performance on various datasets, including ShanghaiTech, UCF-QNRF, JHU-CROWD++ and NWPU. On the large-scale JHU-CROWD++ dataset, our method improves over the previous best results by 26.9% and 29.9% in terms of MAE and MSE, respectively.", "year": 2021, "ssId": "3c0d4dc4237934e37467f4ede3af859bcb140abf", "arXivId": "2105.10926", "link": "https://arxiv.org/pdf/2105.10926.pdf", "openAccess": true, "authors": ["Guolei Sun", "Yun Liu", "Thomas Probst", "D. Paudel", "Nikola Popovic", "L. Gool"]}}, "5f563da2843e005c4b236f7889e7a22631b53210": {"id": "5f563da2843e005c4b236f7889e7a22631b53210", "content": {"title": "Inconsistency in Conference Peer Review: Revisiting the 2014 NeurIPS Experiment", "abstract": "In this paper we revisit the 2014 NeurIPS experiment that examined inconsistency in conference peer review. We determine that 50% of the variation in reviewer quality scores was subjective in origin. Further, with seven years passing since the experiment we find that for accepted papers, there is no correlation between quality scores and impact of the paper as measured as a function of citation count. We trace the fate of rejected papers, recovering where these papers were eventually published. For these papers we find a correlation between quality scores and impact. We conclude that the reviewing process for the 2014 conference was good for identifying poor papers, but poor for identifying good papers. We give some suggestions for improving the reviewing process but also warn against removing the subjective element. Finally, we suggest that the real conclusion of the experiment is that the community should place less onus on the notion of \u2018top-tier conference publications\u2019 when assessing the quality of individual researchers.", "year": 2021, "ssId": "5f563da2843e005c4b236f7889e7a22631b53210", "arXivId": "2109.09774", "link": "https://arxiv.org/pdf/2109.09774.pdf", "openAccess": true, "authors": ["Corinna Cortes", "Neil D. Lawrence"]}}, "2b4edb9515a26561ea3f9ee2a63a506721c8369e": {"id": "2b4edb9515a26561ea3f9ee2a63a506721c8369e", "content": {"title": "Aspect-based Sentiment Analysis of Scientific Reviews", "abstract": "Scientific papers are complex and understanding the usefulness of these papers requires prior knowledge. Peer reviews are comments on a paper provided by designated experts on that field and hold a substantial amount of information, not only for the editors and chairs to make the final decision, but also to judge the potential impact of the paper. In this paper, we propose to use aspect-based sentiment analysis of scientific reviews to be able to extract useful information, which correlates well with the accept/reject decision. While working on a dataset of close to 8k reviews from ICLR, one of the top conferences in the field of machine learning, we use an active learning framework to build a training dataset for aspect prediction, which is further used to obtain the aspects and sentiments for the entire dataset. We show that the distribution of aspect-based sentiments obtained from a review is significantly different for accepted and rejected papers. We use the aspect sentiments from these reviews to make an intriguing observation, certain aspects present in a paper and discussed in the review strongly determine the final recommendation. As a second objective, we quantify the extent of disagreement among the reviewers refereeing a paper. We also investigate the extent of disagreement between the reviewers and the chair and find that the inter-reviewer disagreement may have a link to the disagreement with the chair. One of the most interesting observations from this study is that reviews, where the reviewer score and the aspect sentiments extracted from the review text written by the reviewer are consistent, are also more likely to be concurrent with the chair's decision.", "year": 2020, "ssId": "2b4edb9515a26561ea3f9ee2a63a506721c8369e", "arXivId": "2006.03257", "link": "https://arxiv.org/pdf/2006.03257.pdf", "openAccess": true, "authors": ["Souvic Chakraborty", "P. Goyal", "Animesh Mukherjee"]}}, "eba4c6b0b860a34461ffb8544111c89a3ef0d8b7": {"id": "eba4c6b0b860a34461ffb8544111c89a3ef0d8b7", "content": {"title": "Competitive analysis of the top-K ranking problem", "abstract": "Motivated by applications in recommender systems, web search, social choice and crowdsourcing, we consider the problem of identifying the set of top K items from noisy pairwise comparisons. In our setting, we are non-actively given r pairwise comparisons between each pair of n items, where each comparison has noise constrained by a very general noise model called the strong stochastic transitivity (SST) model. We analyze the competitive ratio of algorithms for the top-K problem. In particular, we present a linear time algorithm for the top-K problem which has a competitive ratio of O( \u221a n); i.e. to solve any instance of top-K, our algorithm needs at most O( \u221a n) times as many samples needed as the best possible algorithm for that instance (in contrast, all previous known algorithms for the top-K problem have competitive ratios of \u03a9(n) or worse). We further show that this is tight: any algorithm for the top-K problem has competitive ratio at least \u03a9( \u221a n). Stern School of Business, New York University, email: xchen3@stern.nyu.edu Department of Computer Science, Princeton University, email: sgopi@cs.princeton.edu Department of Computer Science, Princeton University, email: jiemingm@cs.princeton.edu Department of Computer Science, Princeton University, email: js44@cs.princeton.edu 1", "year": 2016, "ssId": "eba4c6b0b860a34461ffb8544111c89a3ef0d8b7", "arXivId": "1605.03933", "link": "https://arxiv.org/pdf/1605.03933.pdf", "openAccess": true, "authors": ["Xi Chen", "Sivakanth Gopi", "Jieming Mao", "Jon Schneider"]}}, "daa7e6af585d03e9cb05487413a6495f23400398": {"id": "daa7e6af585d03e9cb05487413a6495f23400398", "content": {"title": "Deep Learning Based Resource Assignment for Wireless Networks", "abstract": "This letter studies a deep learning approach for binary assignment problems in wireless networks, which identifies binary variables for permutation matrices. This poses challenges in designing a structure of a neural network and its training strategies for generating feasible assignment solutions. To this end, this letter develop a new Sinkhorn neural network which learns a non-convex projection task onto a set of permutation matrices. An unsupervised training algorithm is proposed where the Sinkhorn neural network can be applied to network assignment problems. Numerical results demonstrate the effectiveness of the proposed method in various network scenarios.", "year": 2021, "ssId": "daa7e6af585d03e9cb05487413a6495f23400398", "arXivId": "2109.12970", "link": "https://arxiv.org/pdf/2109.12970.pdf", "openAccess": true, "authors": ["Minseok Kim", "Hoon Lee", "Hongju Lee", "Inkyu Lee"]}}, "c50f98961c951fe3fbdb6f375beb28e40a6b0581": {"id": "c50f98961c951fe3fbdb6f375beb28e40a6b0581", "content": {"title": "Auctions and Prediction Markets for Scientific Peer Review", "abstract": "Peer reviewed publications are considered the gold standard in certifying and disseminating ideas that a research community considers valuable. However, we identify two major drawbacks of the current system: (1) the overwhelming demand for reviewers due to a large volume of submissions, and (2) the lack of incentives for reviewers to participate and expend the necessary effort to provide high-quality reviews. In this work, we adopt a mechanism-design approach to propose improvements to the peer review process. We present a two-stage mechanism which ties together the paper submission and review process, simultaneously incentivizing high-quality reviews and high-quality submissions. In the first stage, authors participate in a VCG auction for review slots by submitting their papers along with a bid that represents their expected value for having their paper reviewed. For the second stage, we propose a novel prediction market-style mechanism (H-DIPP) building on recent work in the information elicitation literature, which incentivizes participating reviewers to provide honest and effortful reviews. The revenue raised by the Stage I auction is used in Stage II to pay reviewers based on the quality of their reviews.", "year": 2021, "ssId": "c50f98961c951fe3fbdb6f375beb28e40a6b0581", "arXivId": "2109.00923", "link": "https://arxiv.org/pdf/2109.00923.pdf", "openAccess": true, "authors": ["Siddarth Srinivasan", "Jamie H. Morgenstern"]}}, "25ee819bc444b02db43fcbeced982c975edee033": {"id": "25ee819bc444b02db43fcbeced982c975edee033", "content": {"title": "Crowdsourced Labeling for Worker-Task Specialization Model", "abstract": "We consider crowdsourced labeling under a $d$-type worker-task specialization model, where each worker and task is associated with one particular type among a finite set of types and a worker provides a more reliable answer to tasks of the matched type than to tasks of unmatched types. We design an inference algorithm that recovers binary task labels (up to any given recovery accuracy) by using worker clustering, worker skill estimation and weighted majority voting. The designed inference algorithm does not require any information about worker/task types, and achieves any targeted recovery accuracy with the best known performance (minimum number of queries per task). 11This work was supported in part by National Research Foundation of Korea under Grant 2017R1E1A1A01076340; in part by the Ministry of Science and ICT, South Korea, under the ITRC support program under Grant IITP-2021-2018-0-01402; and in part by the Institute of Information and Communications Technology Planning & Evaluation (IITP) grant funded by the Korea Government MSIT under Grant 2020-0-00626.", "year": 2020, "ssId": "25ee819bc444b02db43fcbeced982c975edee033", "arXivId": "2004.00101", "link": "https://arxiv.org/pdf/2004.00101.pdf", "openAccess": true, "authors": ["Doyeon Kim", "Hye Won Chung"]}}, "22d2f8030221bd0c27bfb9416eeffe4e86633780": {"id": "22d2f8030221bd0c27bfb9416eeffe4e86633780", "content": {"title": "Efficient Neural Ranking using Forward Indexes", "abstract": "Neural document ranking approaches, specifically transformer models, have achieved impressive gains in ranking performance. However, query processing using such over-parameterized models is both resource and time intensive. In this paper, we propose the Fast-Forward index \u2013 a simple vector forward index that facilitates ranking documents using interpolation of lexical and semantic scores \u2013 as a replacement for contextual re-rankers and dense indexes based on nearest neighbor search. Fast-Forward indexes rely on efficient sparse models for retrieval and merely look up pre-computed dense transformer-based vector representations of documents and passages in constant time for fast CPU-based semantic similarity computation during query processing. We propose index pruning and theoretically grounded early stopping techniques to improve the query processing throughput. We conduct extensive large-scale experiments on TREC-DL datasets and show improvements over hybrid indexes in performance and query processing efficiency using only CPUs. Fast-Forward indexes can provide superior ranking performance using interpolation due to the complementary benefits of lexical and semantic similarities.", "year": 2021, "ssId": "22d2f8030221bd0c27bfb9416eeffe4e86633780", "arXivId": "2110.06051", "link": "https://arxiv.org/pdf/2110.06051.pdf", "openAccess": true, "authors": ["Jurek Leonhardt", "Koustav Rudra", "Megha Khosla", "Abhijit Anand", "Avishek Anand"]}}, "4264599665522594d9ecb521dd2e1d002e85a961": {"id": "4264599665522594d9ecb521dd2e1d002e85a961", "content": {"title": "Paper Matching with Local Fairness Constraints", "abstract": "Automatically matching reviewers to papers is a crucial step of the peer review process for venues receiving thousands of submissions. Unfortunately, common paper matching algorithms often construct matchings suffering from two critical problems: (1) the group of reviewers assigned to a paper do not collectively possess sufficient expertise, and (2) reviewer workloads are highly skewed. In this paper, we propose a novel local fairness formulation of paper matching that directly addresses both of these issues. Since optimizing our formulation is not always tractable, we introduce two new algorithms, FairIR and FairFlow, for computing fair matchings that approximately optimize the new formulation. FairIR solves a relaxation of the local fairness formulation and then employs a rounding technique to construct a valid matching that provably maximizes the objective and only compromises on fairness with respect to reviewer loads and papers by a small constant. In contrast, FairFlow is not provably guaranteed to produce fair matchings, however it can be 2x as efficient as FairIR and an order of magnitude faster than matching algorithms that directly optimize for fairness. Empirically, we demonstrate that both FairIR and FairFlow improve fairness over standard matching algorithms on real conference data. Moreover, in comparison to state-of-the-art matching algorithms that optimize for fairness only, FairIR achieves higher objective scores, FairFlow achieves competitive fairness, and both are capable of more evenly allocating reviewers.", "year": 2019, "ssId": "4264599665522594d9ecb521dd2e1d002e85a961", "arXivId": "1905.11924", "link": "https://arxiv.org/pdf/1905.11924.pdf", "openAccess": true, "authors": ["Ari Kobren", "B. Saha", "A. McCallum"]}}, "803c7fdd6e01e1ff8cd43297f4e052078409456d": {"id": "803c7fdd6e01e1ff8cd43297f4e052078409456d", "content": {"title": "From partners to populations: A hierarchical Bayesian account of coordination and convention", "abstract": "Languages are powerful solutions to coordination problems: They provide stable, shared expectations about how the words we say correspond to the beliefs and intentions in our heads. Yet, language use in a variable and nonstationary social environment requires linguistic representations to be flexible: Old words acquire new ad hoc or partner-specific meanings on the fly. In this article, we introduce continual hierarchical adaptation through inference (CHAI), a hierarchical Bayesian theory of coordination and convention formation that aims to reconcile the long-standing tension between these two basic observations. We argue that the central computational problem of communication is not simply transmission, as in classical formulations, but continual learning and adaptation over multiple timescales. Partner-specific common ground quickly emerges from social inferences within dyadic interactions, while community-wide social conventions are stable priors that have been abstracted away from interactions with multiple partners. We present new empirical data alongside simulations showing how our model provides a computational foundation for several phenomena that have posed a challenge for previous accounts: (a) the convergence to more efficient referring expressions across repeated interaction with the same partner, (b) the gradual transfer of partner-specific common ground to strangers, and (c) the influence of communicative context on which conventions eventually form. (PsycInfo Database Record (c) 2022 APA, all rights reserved).", "year": 2021, "ssId": "803c7fdd6e01e1ff8cd43297f4e052078409456d", "arXivId": "2104.05857", "link": "https://arxiv.org/pdf/2104.05857.pdf", "openAccess": true, "authors": ["Robert D. Hawkins", "M. Franke", "Michael C. Frank", "Kenny Smith", "T. Griffiths", "Noah D. Goodman"]}}, "48530f3d6425f2f150f07ccdd61ba951951a0a7d": {"id": "48530f3d6425f2f150f07ccdd61ba951951a0a7d", "content": {"title": "Simple, Scalable Adaptation for Neural Machine Translation", "abstract": "Fine-tuning pre-trained Neural Machine Translation (NMT) models is the dominant approach for adapting to new languages and domains. However, fine-tuning requires adapting and maintaining a separate model for each target task. We propose a simple yet efficient approach for adaptation in NMT. Our proposed approach consists of injecting tiny task specific adapter layers into a pre-trained model. These lightweight adapters, with just a small fraction of the original model size, adapt the model to multiple individual tasks simultaneously. We evaluate our approach on two tasks: (i) Domain Adaptation and (ii) Massively Multilingual NMT. Experiments on domain adaptation demonstrate that our proposed approach is on par with full fine-tuning on various domains, dataset sizes and model capacities. On a massively multilingual dataset of 103 languages, our adaptation approach bridges the gap between individual bilingual models and one massively multilingual model for most language pairs, paving the way towards universal machine translation.", "year": 2019, "ssId": "48530f3d6425f2f150f07ccdd61ba951951a0a7d", "arXivId": "1909.08478", "link": "https://arxiv.org/pdf/1909.08478.pdf", "openAccess": true, "authors": ["Ankur Bapna", "N. Arivazhagan", "Orhan Firat"]}}, "77568c594470f9aa029f92774e2c12ab0451d9bb": {"id": "77568c594470f9aa029f92774e2c12ab0451d9bb", "content": {"title": "Distributionally Robust Language Modeling", "abstract": "Language models are generally trained on data spanning a wide range of topics (e.g., news, reviews, fiction), but they might be applied to an a priori unknown target distribution (e.g., restaurant reviews). In this paper, we first show that training on text outside the test distribution can degrade test performance when using standard maximum likelihood (MLE) training. To remedy this without the knowledge of the test distribution, we propose an approach which trains a model that performs well over a wide range of potential test distributions. In particular, we derive a new distributionally robust optimization (DRO) procedure which minimizes the loss of the model over the worst-case mixture of topics with sufficient overlap with the training distribution. Our approach, called topic conditional value at risk (topic CVaR), obtains a 5.5 point perplexity reduction over MLE when the language models are trained on a mixture of Yelp reviews and news and tested only on reviews.", "year": 2019, "ssId": "77568c594470f9aa029f92774e2c12ab0451d9bb", "arXivId": "1909.02060", "link": "https://arxiv.org/pdf/1909.02060.pdf", "openAccess": true, "authors": ["Y. Oren", "Shiori Sagawa", "Tatsunori B. Hashimoto", "Percy Liang"]}}, "98ef0db84e62aef969629264c9de1f4d0013f3b9": {"id": "98ef0db84e62aef969629264c9de1f4d0013f3b9", "content": {"title": "AdapterFusion: Non-Destructive Task Composition for Transfer Learning", "abstract": "Sequential fine-tuning and multi-task learning are methods aiming to incorporate knowledge from multiple tasks; however, they suffer from catastrophic forgetting and difficulties in dataset balancing. To address these shortcomings, we propose AdapterFusion, a new two stage learning algorithm that leverages knowledge from multiple tasks. First, in the knowledge extraction stage we learn task specific parameters called adapters, that encapsulate the task-specific information. We then combine the adapters in a separate knowledge composition step. We show that by separating the two stages, i.e., knowledge extraction and knowledge composition, the classifier can effectively exploit the representations learned from multiple tasks in a non-destructive manner. We empirically evaluate AdapterFusion on 16 diverse NLU tasks, and find that it effectively combines various types of knowledge at different layers of the model. We show that our approach outperforms traditional strategies such as full fine-tuning as well as multi-task learning. Our code and adapters are available at AdapterHub.ml.", "year": 2020, "ssId": "98ef0db84e62aef969629264c9de1f4d0013f3b9", "arXivId": "2005.00247", "link": "https://arxiv.org/pdf/2005.00247.pdf", "openAccess": true, "authors": ["Jonas Pfeiffer", "Aishwarya Kamath", "Andreas R\u00fcckl\u00e9", "Kyunghyun Cho", "Iryna Gurevych"]}}, "3db9649f2ae986cac13f3e748375f8802f9b07fc": {"id": "3db9649f2ae986cac13f3e748375f8802f9b07fc", "content": {"title": "The Low-Resource Double Bind: An Empirical Study of Pruning for Low-Resource Machine Translation", "abstract": "A \u201cbigger is better\u201d explosion in the number of parameters in deep neural networks has made it increasingly challenging to make stateof-the-art networks accessible in computerestricted environments. Compression techniques have taken on renewed importance as a way to bridge the gap. However, evaluation of the trade-offs incurred by popular compression techniques has been centered on high-resource datasets. In this work, we instead consider the impact of compression in a data-limited regime. We introduce the term low-resource double bind to refer to the co-occurrence of data limitations and compute resource constraints. This is a common setting for NLP for low-resource languages, yet the trade-offs in performance are poorly studied. Our work offers surprising insights into the relationship between capacity and generalization in data-limited regimes for the task of machine translation. Our experiments on magnitude pruning for translations from English into Yoruba, Hausa, Igbo and German show that in low-resource regimes, sparsity preserves performance on frequent sentences but has a disparate impact on infrequent ones. However, it improves robustness to out-of-distribution shifts, especially for datasets that are very distinct from the training distribution. Our findings suggest that sparsity can play a beneficial role at curbing memorization of low frequency attributes, and therefore offers a promising solution to the low-resource double bind.", "year": 2021, "ssId": "3db9649f2ae986cac13f3e748375f8802f9b07fc", "arXivId": "2110.03036", "link": "https://arxiv.org/pdf/2110.03036.pdf", "openAccess": true, "authors": ["Orevaoghene Ahia", "Julia Kreutzer", "Sara Hooker"]}}, "48b18bf5c9cad0e4c36b2d885f380c5c637e1a09": {"id": "48b18bf5c9cad0e4c36b2d885f380c5c637e1a09", "content": {"title": "Learning Optimal Conditional Priors For Disentangled Representations", "abstract": "A large part of the literature on learning disentangled representations focuses on variational autoencoders (VAEs). Recent developments demonstrate that disentanglement cannot be obtained in a fully unsupervised setting without inductive biases on models and data. As such, Khemakhem et al., AISTATS 2020, suggest employing a factorized prior distribution over the latent variables that is conditionally dependent on auxiliary observed variables complementing input observations. While this is a remarkable advancement toward model identifiability, the learned conditional prior only focuses on sufficiency, giving no guarantees on a minimal representation. Motivated by information theoretic principles, we propose a novel VAE-based generative model with theoretical guarantees on disentanglement. Our proposed model learns a sufficient and compact - thus optimal - conditional prior, which serves as regularization for the latent space. Experimental results indicate superior performance with respect to state-of-the-art methods, according to several established metrics proposed in the literature on disentanglement.", "year": 2020, "ssId": "48b18bf5c9cad0e4c36b2d885f380c5c637e1a09", "arXivId": "2010.09360", "link": "https://arxiv.org/pdf/2010.09360.pdf", "openAccess": true, "authors": ["Graziano Mita", "M. Filippone", "P. Michiardi"]}}, "6b2b5d3d9a2ca4bc4fbd81551a62370be2fbff1b": {"id": "6b2b5d3d9a2ca4bc4fbd81551a62370be2fbff1b", "content": {"title": "Explaining Neural Scaling Laws", "abstract": "The test loss of well-trained neural networks often follows precise power-law scaling relations with either the size of the training dataset or the number of parameters in the network. We propose a theory that explains and connects these scaling laws. We identify variance-limited and resolution-limited scaling behavior for both dataset and model size, for a total of four scaling regimes. The variance-limited scaling follows simply from the existence of a well-behaved infinite data or infinite width limit, while the resolution-limited regime can be explained by positing that models are effectively resolving a smooth data manifold. In the large width limit, this can be equivalently obtained from the spectrum of certain kernels, and we present evidence that large width and large dataset resolution-limited scaling exponents are related by a duality. We exhibit all four scaling regimes in the controlled setting of large random feature and pretrained models and test the predictions empirically on a range of standard architectures and datasets. We also observe several empirical relationships between datasets and scaling exponents: super-classing image tasks does not change exponents, while changing input distribution (via changing datasets or adding noise) has a strong effect. We further explore the effect of architecture aspect ratio on scaling exponents. 1 Scaling Laws for Neural Networks For a large variety of models and datasets, neural network performance has been empirically observed to scale as a power-law with model size and dataset size [1\u20134]. We would like to understand why these power laws emerge, and what features of the data and models determine the values of the power-law exponents. Since these exponents determine how quickly performance improves with more data and larger models, they are of great importance when considering whether to scale up existing models. In this work, we present a theoretical framework for explaining scaling laws in trained neural networks. We identify four related scaling regimes with respect to the number of model parameters P and the dataset size D. With respect to each of D, P , there is both a resolution-limited regime and a variance-limited regime. Variance-Limited Regime In the limit of infinite data or an arbitrarily wide model, some aspects of neural network training simplify. Specifically, if we fix one of D,P and study scaling with respect to the other parameter as it becomes arbitrarily large, then the loss scales as 1/x, i.e. as a power-law with exponent 1, with x = D or \u221a P \u221d width in deep networks and x = D or P in linear models. In essence, this variance-limited regime is amenable to analysis because model predictions can be series expanded in either inverse width or inverse dataset size. To demonstrate these variance-limited scalings, it is sufficient to argue that the infinite data or width limit exists and is smooth; this guarantees that an expansion in simple integer powers exists. \u2217Authors listed alphabetically \u2020A portion of work completed during an internship at Google. 1 ar X iv :2 10 2. 06 70 1v 1 [ cs .L G ] 1 2 Fe b 20 21 101 102 103 104 Dataset size (D) 10 8 10 6 10 4 10 2 100 Lo ss Lo ss ( ) Variance-limited : Theory D = 1 D: 1.02 D: 1.01 D: 1.00 (MSE) D: 0.98 (CNN) D: 1.01 D: 1.02 D: 1.10 D: 1.01 103 104 Dataset size (D) 10 1 100 Lo ss Resolution-limited D: 0.26 D: 0.37 D: 0.40 D: 0.58 101 102 Width 10 1 100 Lo ss Resolution-limited W: 0.46 W: 0.34 W: 0.62 W: 0.40 102 103 104 Width 10 5 10 4 10 3 10 2 10 1 100 Lo ss Lo ss ( ) Variance-limited : Theory W = 1 W: 0.98 (MSE, ERF) W: 1.03 W: 1.02 (ERF) W: 1.01 W: 1.00 W: 1.03 (ERF) Teacher-Student CIFAR-10 CIFAR-100 SVHN FashionMNIST MNIST Figure 1: Four scaling regimes Here we exhibit the four regimes we focus on in this work. (top-left, bottomright) Variance-limited scaling of under-parameterized models with dataset size and over-parameterized models with number of parameters (width) exhibit universal scaling (\u03b1D = \u03b1W = 1) independent of the architecture or underlying dataset. (top-right, bottom-left) Resolution-limited over-parameterized models with dataset or under-parameterized models with model size exhibit scaling with exponents that depend on the details of the data distribution. These four regimes are also found in random feature (Figure 3) and pretrained models (see supplement). Resolution-Limited Regime In this regime, one of D or P is effectively infinite, and we study scaling as the other parameter increases. In this case, a variety of works have empirically observed power-law scalings 1/x, typically with 0 < \u03b1 < 1 for both x = P or D. We can provide a very general argument for power-law scalings if we assume that trained models map the data into a d-dimensional data manifold. The key idea is then that additional data (in the infinite model-size limit) or added model parameters (in the infinite data limit) are used by the model to carve up the data manifold into smaller components. The model then makes independent predictions in each component of the data manifold in order to optimize the training loss. If the underlying data varies continuously on the manifold, then the size of the sub-regions into which we can divide the manifold (rather than the number of regions) determines the model\u2019s loss. To shrink the size of the sub-regions by a factor of 2 requires increasing the parameter count or dataset size by a factor of 2, and so the inverse of the scaling exponent will be proportional to the intrinsic dimension d of the data manifold, so that \u03b1 \u221d 1/d. A visualization of this successively better approximation with dataset size is shown in Figure 2 for models trained to predict data generated by a random fully-connected network. Explicit Realization These regimes can be realized in linear models, and this includes linearized versions of neural networks via the large width limit. In these limits, we can solve for the test error directly in terms of the feature covariance (kernel). The scaling of the test loss then follows from the asymptotic decay of the spectrum of the covariance matrix. Furthermore, well-known theorems provide bounds on the spectra associated with continuous kernels on a d-dimensional manifold. Since otherwise generic kernels saturate these bounds, we find a tight connection between the dimension of the data manifold, kernel spectra, and", "year": 2021, "ssId": "6b2b5d3d9a2ca4bc4fbd81551a62370be2fbff1b", "arXivId": "2102.06701", "link": "https://arxiv.org/pdf/2102.06701.pdf", "openAccess": true, "authors": ["Yasaman Bahri", "Ethan Dyer", "J. Kaplan", "Jaehoon Lee", "Utkarsh Sharma"]}}, "429b65937d4922578a81e1f0ef5aeab7361ae36b": {"id": "429b65937d4922578a81e1f0ef5aeab7361ae36b", "content": {"title": "NL2Bash: A Corpus and Semantic Parser for Natural Language Interface to the Linux Operating System", "abstract": "We present new data and semantic parsing methods for the problem of mapping English sentences to Bash commands (NL2Bash). Our long-term goal is to enable any user to perform operations such as file manipulation, search, and application-specific scripting by simply stating their goals in English. We take a first step in this domain, by providing a new dataset of challenging but commonly used Bash commands and expert-written English descriptions, along with baseline methods to establish performance levels on this task.", "year": 2018, "ssId": "429b65937d4922578a81e1f0ef5aeab7361ae36b", "arXivId": "1802.08979", "link": "https://arxiv.org/pdf/1802.08979.pdf", "openAccess": true, "authors": ["Xi Victoria Lin", "Chenglong Wang", "Luke Zettlemoyer", "Michael D. Ernst"]}}, "9ce09b03f056253252f3e8c0c65d86a27117a0ac": {"id": "9ce09b03f056253252f3e8c0c65d86a27117a0ac", "content": {"title": "Fully Test-time Adaptation by Entropy Minimization", "abstract": "Faced with new and different data during testing, a model must adapt itself. We consider the setting of fully test-time adaptation, in which a supervised model confronts unlabeled test data from a different distribution, without the help of its labeled training data. We propose an entropy minimization approach for adaptation: we take the model's confidence as our objective as measured by the entropy of its predictions. During testing, we adapt the model by modulating its representation with affine transformations to minimize entropy. Our experiments show improved robustness to corruptions for image classification on CIFAR-10/100 and ILSVRC and demonstrate the feasibility of target-only domain adaptation for digit classification on MNIST and SVHN.", "year": 2020, "ssId": "9ce09b03f056253252f3e8c0c65d86a27117a0ac", "arXivId": "2006.10726", "link": "https://arxiv.org/pdf/2006.10726.pdf", "openAccess": true, "authors": ["Dequan Wang", "Evan Shelhamer", "Shaoteng Liu", "B. Olshausen", "Trevor Darrell"]}}, "b19cba7bfe318c69d5e62f8322cb5d75228452f4": {"id": "b19cba7bfe318c69d5e62f8322cb5d75228452f4", "content": {"title": "Compacter: Efficient Low-Rank Hypercomplex Adapter Layers", "abstract": "Adapting large-scale pretrained language models to downstream tasks via fine-tuning is the standard method for achieving state-of-the-art performance on NLP benchmarks. However, fine-tuning all weights of models with millions or billions of parameters is sample-inefficient, unstable in low-resource settings, and wasteful as it requires storing a separate copy of the model for each task. Recent work has developed parameter-efficient fine-tuning methods, but these approaches either still require a relatively large number of parameters or underperform standard fine-tuning. In this work, we propose COMPACTER, a method for fine-tuning large-scale language models with a better trade-off between task performance and the number of trainable parameters than prior work. COMPACTER accomplishes this by building on top of ideas from adapters, low-rank optimization, and parameterized hypercomplex multiplication layers. Specifically, COMPACTER inserts task-specific weight matrices into a pretrained model\u2019s weights, which are computed efficiently as a sum of Kronecker products between shared \u201cslow\u201d weights and \u201cfast\u201d rank-one matrices defined per COMPACTER layer. By only training 0.047% of a pretrained model\u2019s parameters, COMPACTER performs on par with standard fine-tuning on GLUE and outperforms standard fine-tuning on SuperGLUE and low-resource settings. Our code is publicly available at https://github.com/rabeehk/compacter.", "year": 2021, "ssId": "b19cba7bfe318c69d5e62f8322cb5d75228452f4", "arXivId": "2106.04647", "link": "https://arxiv.org/pdf/2106.04647.pdf", "openAccess": true, "authors": ["Rabeeh Karimi Mahabadi", "James Henderson", "Sebastian Ruder"]}}, "d2a2be6ce932a0f1939f31cfff4d64ea3d76723d": {"id": "d2a2be6ce932a0f1939f31cfff4d64ea3d76723d", "content": {"title": "Human Uncertainty Makes Classification More Robust", "abstract": "The classification performance of deep neural networks has begun to asymptote at near-perfect levels. However, their ability to generalize outside the training set and their robustness to adversarial attacks have not. In this paper, we make progress on this problem by training with full label distributions that reflect human perceptual uncertainty. We first present a new benchmark dataset which we call CIFAR10H, containing a full distribution of human labels for each image of the CIFAR10 test set. We then show that, while contemporary classifiers fail to exhibit human-like uncertainty on their own, explicit training on our dataset closes this gap, supports improved generalization to increasingly out-of-training-distribution test datasets, and confers robustness to adversarial attacks.", "year": 2019, "ssId": "d2a2be6ce932a0f1939f31cfff4d64ea3d76723d", "arXivId": "1908.07086", "link": "https://arxiv.org/pdf/1908.07086.pdf", "openAccess": true, "authors": ["Joshua C. Peterson", "R. Battleday", "T. Griffiths", "Olga Russakovsky"]}}, "1109f787fc8d51feb3bae9bf6e1945dc4a1191e7": {"id": "1109f787fc8d51feb3bae9bf6e1945dc4a1191e7", "content": {"title": "Does the Whole Exceed its Parts? The Effect of AI Explanations on Complementary Team Performance", "abstract": "Many researchers motivate explainable AI with studies showing that human-AI team performance on decision-making tasks improves when the AI explains its recommendations. However, prior studies observed improvements from explanations only when the AI, alone, outperformed both the human and the best team. Can explanations help lead to complementary performance, where team accuracy is higher than either the human or the AI working solo? We conduct mixed-method user studies on three datasets, where an AI with accuracy comparable to humans helps participants solve a task (explaining itself in some conditions). While we observed complementary improvements from AI augmentation, they were not increased by explanations. Rather, explanations increased the chance that humans will accept the AI\u2019s recommendation, regardless of its correctness. Our result poses new challenges for human-centered AI: Can we develop explanatory approaches that encourage appropriate trust in AI, and therefore help generate (or improve) complementary performance?", "year": 2020, "ssId": "1109f787fc8d51feb3bae9bf6e1945dc4a1191e7", "arXivId": "2006.14779", "link": "https://arxiv.org/pdf/2006.14779.pdf", "openAccess": true, "authors": ["Gagan Bansal", "Tongshuang Sherry Wu", "Joyce Zhou", "Raymond Fok", "Besmira Nushi", "Ece Kamar", "Marco Tulio Ribeiro", "Daniel S. Weld"]}}, "6e7e095f46deb297713dcde05991faf635768d29": {"id": "6e7e095f46deb297713dcde05991faf635768d29", "content": {"title": "Towards a critical race methodology in algorithmic fairness", "abstract": "We examine the way race and racial categories are adopted in algorithmic fairness frameworks. Current methodologies fail to adequately account for the socially constructed nature of race, instead adopting a conceptualization of race as a fixed attribute. Treating race as an attribute, rather than a structural, institutional, and relational phenomenon, can serve to minimize the structural aspects of algorithmic unfairness. In this work, we focus on the history of racial categories and turn to critical race theory and sociological work on race and ethnicity to ground conceptualizations of race for fairness research, drawing on lessons from public health, biomedical research, and social survey research. We argue that algorithmic fairness researchers need to take into account the multidimensionality of race, take seriously the processes of conceptualizing and operationalizing race, focus on social processes which produce racial inequality, and consider perspectives of those most affected by sociotechnical systems.", "year": 2019, "ssId": "6e7e095f46deb297713dcde05991faf635768d29", "arXivId": "1912.03593", "link": "https://arxiv.org/pdf/1912.03593.pdf", "openAccess": true, "authors": ["A. Hanna", "Emily L. Denton", "A. Smart", "Jamila Smith-Loud"]}}, "e12c52fb542f76b3f0d29178842428d6a4edfe1e": {"id": "e12c52fb542f76b3f0d29178842428d6a4edfe1e", "content": {"title": "Predict Responsibly: Improving Fairness and Accuracy by Learning to Defer", "abstract": "In many machine learning applications, there are multiple decision-makers involved, both automated and human. The interaction between these agents often goes unaddressed in algorithmic development. In this work, we explore a simple version of this interaction with a two-stage framework containing an automated model and an external decision-maker. The model can choose to say PASS, and pass the decision downstream, as explored in rejection learning. We extend this concept by proposing \"learning to defer\", which generalizes rejection learning by considering the effect of other agents in the decision-making process. We propose a learning algorithm which accounts for potential biases held by external decision-makers in a system. Experiments demonstrate that learning to defer can make systems not only more accurate but also less biased. Even when working with inconsistent or biased users, we show that deferring models still greatly improve the accuracy and/or fairness of the entire system.", "year": 2017, "ssId": "e12c52fb542f76b3f0d29178842428d6a4edfe1e", "arXivId": "1711.06664", "link": "https://arxiv.org/pdf/1711.06664.pdf", "openAccess": true, "authors": ["David Madras", "T. Pitassi", "R. Zemel"]}}, "2826ac3621fdd599303c97cb9e32f165521967b2": {"id": "2826ac3621fdd599303c97cb9e32f165521967b2", "content": {"title": "Direct Uncertainty Prediction for Medical Second Opinions", "abstract": "The issue of disagreements amongst human experts is a ubiquitous one in both machine learning and medicine. In medicine, this often corresponds to doctor disagreements on a patient diagnosis. In this work, we show that machine learning models can be trained to give uncertainty scores to data instances that might result in high expert disagreements. In particular, they can identify patient cases that would benefit most from a medical second opinion. Our central methodological finding is that Direct Uncertainty Prediction (DUP), training a model to predict an uncertainty score directly from the raw patient features, works better than Uncertainty Via Classification, the two-step process of training a classifier and postprocessing the output distribution to give an uncertainty score. We show this both with a theoretical result, and on extensive evaluations on a large scale medical imaging application.", "year": 2018, "ssId": "2826ac3621fdd599303c97cb9e32f165521967b2", "arXivId": "1807.01771", "link": "https://arxiv.org/pdf/1807.01771.pdf", "openAccess": true, "authors": ["M. Raghu", "Katy Blumer", "R. Sayres", "Z. Obermeyer", "Robert D. Kleinberg", "S. Mullainathan", "J. Kleinberg"]}}, "63e7e3b16e03da62a2c535ac9cfccfa3ae48b292": {"id": "63e7e3b16e03da62a2c535ac9cfccfa3ae48b292", "content": {"title": "Optimizing AI for Teamwork", "abstract": "In many high-stakes domains such as criminal justice, finance, and healthcare, AI systems may recommend actions to a human expert responsible for final decisions, a context known as AI-advised decision making. When AI practitioners deploy the most accurate system in these domains, they implicitly assume that the system will function alone in the world. We argue that the most accurate AI team-mate is not necessarily the em best teammate; for example, predictable performance is worth a slight sacrifice in AI accuracy. So, we propose training AI systems in a human-centered manner and directly optimizing for team performance. We study this proposal for a specific type of human-AI team, where the human overseer chooses to accept the AI recommendation or solve the task themselves. To optimize the team performance we maximize the team's expected utility, expressed in terms of quality of the final decision, cost of verifying, and individual accuracies. Our experiments with linear and non-linear models on real-world, high-stakes datasets show that the improvements in utility while being small and varying across datasets and parameters (such as cost of mistake), are real and consistent with our definition of team utility. We discuss the shortcoming of current optimization approaches beyond well-studied loss functions such as log-loss, and encourage future work on human-centered optimization problems motivated by human-AI collaborations.", "year": 2020, "ssId": "63e7e3b16e03da62a2c535ac9cfccfa3ae48b292", "arXivId": "2004.13102", "link": "https://arxiv.org/pdf/2004.13102.pdf", "openAccess": true, "authors": ["Gagan Bansal", "Besmira Nushi", "Ece Kamar", "E. Horvitz", "Daniel S. Weld"]}}, "a445adf335aa5212f929f67c1ca56a62c221b43a": {"id": "a445adf335aa5212f929f67c1ca56a62c221b43a", "content": {"title": "Identifying Unknown Unknowns in the Open World: Representations and Policies for Guided Exploration", "abstract": "Predictive models deployed in the real world may assign incorrect labels to instances with high confidence. Such errors or unknown unknowns are rooted in model incompleteness, and typically arise because of the mismatch between training data and the cases encountered at test time. As the models are blind to such errors, input from an oracle is needed to identify these failures. In this paper, we formulate and address the problem of informed discovery of unknown unknowns of any given predictive model where unknown unknowns occur due to systematic biases in the training data. We propose a model-agnostic methodology which uses feedback from an oracle to both identify unknown unknowns and to intelligently guide the discovery. We employ a two-phase approach which first organizes the data into multiple partitions based on the feature similarity of instances and the confidence scores assigned by the predictive model, and then utilizes an explore-exploit strategy for discovering unknown unknowns across these partitions. We demonstrate the efficacy of our framework by varying the underlying causes of unknown unknowns across various applications. To the best of our knowledge, this paper presents the first algorithmic approach to the problem of discovering unknown unknowns of predictive models.", "year": 2016, "ssId": "a445adf335aa5212f929f67c1ca56a62c221b43a", "arXivId": "1610.09064", "link": "https://arxiv.org/pdf/1610.09064.pdf", "openAccess": true, "authors": ["Himabindu Lakkaraju", "Ece Kamar", "R. Caruana", "E. Horvitz"]}}, "03e62d5f0265608c6ebdebba0870131b056b79a6": {"id": "03e62d5f0265608c6ebdebba0870131b056b79a6", "content": {"title": "A Framework of Severity for Harmful Content Online", "abstract": "The proliferation of harmful content on online social media platforms has necessitated empirical understandings of experiences of harm online and the development of practices for harm mitigation. Both understandings of harm and approaches to mitigating that harm, often through content moderation, have implicitly embedded frameworks of prioritization-what forms of harm should be researched, how policy on harmful content should be implemented, and how harmful content should be moderated. To aid efforts of better understanding the variety of online harms, how they relate to one another, and how to prioritize harms relevant to research, policy, and practice, we present a theoretical framework of severity for harmful online content. By employing a grounded theory approach, we developed a framework of severity based on interviews and card-sorting activities conducted with 52 participants over the course of ten months. Through our analysis, we identified four Types of Harm (physical, emotional, relational, and financial) and eight Dimensions along which the severity of harm can be understood (perspectives, intent, agency, experience, scale, urgency, vulnerability, sphere). We describe how our framework can be applied to both research and policy settings towards deeper understandings of specific forms of harm (e.g., harassment) and prioritization frameworks when implementing policies encompassing many forms of harm.", "year": 2021, "ssId": "03e62d5f0265608c6ebdebba0870131b056b79a6", "arXivId": "2108.04401", "link": "https://arxiv.org/pdf/2108.04401.pdf", "openAccess": true, "authors": ["M. Scheuerman", "J. Jiang", "Casey Fiesler", "J. Brubaker"]}}, "35ee53492c7f32dbb3b4ed7ba4d1395218b13ee9": {"id": "35ee53492c7f32dbb3b4ed7ba4d1395218b13ee9", "content": {"title": "Everyday Algorithm Auditing: Understanding the Power of Everyday Users in Surfacing Harmful Algorithmic Behaviors", "abstract": "A growing body of literature has proposed formal approaches to audit algorithmic systems for biased and harmful behaviors. While formal auditing approaches have been greatly impactful, they often suffer major blindspots, with critical issues surfacing only in the context of everyday use once systems are deployed. Recent years have seen many cases in which everyday users of algorithmic systems detect and raise awareness about harmful behaviors that they encounter in the course of their everyday interactions with these systems. However, to date little academic attention has been granted to these bottom-up, user-driven auditing processes. In this paper, we propose and explore the concept of everyday algorithm auditing, a process in which users detect, understand, and interrogate problematic machine behaviors via their day-to-day interactions with algorithmic systems. We argue that everyday users are powerful in surfacing problematic machine behaviors that may elude detection via more centrally-organized forms of auditing, regardless of users' knowledge about the underlying algorithms. We analyze several real-world cases of everyday algorithm auditing, drawing lessons from these cases for the design of future platforms and tools that facilitate such auditing behaviors. Finally, we discuss work that lies ahead, toward bridging the gaps between formal auditing approaches and the organic auditing behaviors that emerge in everyday use of algorithmic systems.", "year": 2021, "ssId": "35ee53492c7f32dbb3b4ed7ba4d1395218b13ee9", "arXivId": "2105.02980", "link": "https://arxiv.org/pdf/2105.02980.pdf", "openAccess": true, "authors": ["Hong Shen", "Alicia DeVos", "Motahhare Eslami", "Kenneth Holstein"]}}, "9045bf2a9c1e2b9621c69c57f991d10880e91f18": {"id": "9045bf2a9c1e2b9621c69c57f991d10880e91f18", "content": {"title": "Logspace Reducibility From Secret Leakage Planted Clique", "abstract": "The planted clique problem is well-studied in the context of observing, explaining, and predicting interesting computational phenomena associated with statistical problems. When equating computational efficiency with the existence of polynomial time algorithms, the computational hardness of (some variant of) the planted clique problem can be used to infer the computational hardness of a host of other statistical problems. Is this ability to transfer computational hardness from (some variant of) the planted clique problem to other statistical problems robust to changing our notion of computational efficiency to space efficiency? We answer this question affirmatively for three different statistical problems, namely Sparse PCA [BR13a], submatrix detection [MW15], and testing almost k-wise independence [AAK07]. The key challenge is that space efficient randomized reductions need to repeatedly access the randomness they use. Known reductions to these problems are all randomized and need polynomially many random bits to implement. Since we can not store polynomially many random bits in memory, it is unclear how to implement these existing reductions space efficiently. There are two ideas involved in circumventing this issue and implementing known reductions to these problems space efficiently. 1. When solving statistical problems, we can use parts of the input itself as randomness. This idea was pioneered by [GW02] in the context of derandomizing \u2018typically correct\u2019 algorithms. Our observation is that this is useful even if we do not care about derandomization, and instead care about repeatedly accessing randomness that can not be stored in working memory. 2. Secret leakage variants of the planted clique problem with appropriate secret leakage can be more useful than the standard planted clique problem when we want to use parts of the input as randomness. The idea that secret leakage is helpful in the context of polynomial time reducibility to statistical problems was introduced by [BB20]. They demonstrated the polynomial time hardness of a wide variety of statistical problems by assuming polynomial time hardness of secret leakage variants of the planted clique problem. Our observation is that leakage is useful even for the seemingly unrelated task of finding randomness in the input.", "year": 2021, "ssId": "9045bf2a9c1e2b9621c69c57f991d10880e91f18", "arXivId": "2107.11886", "link": "https://arxiv.org/pdf/2107.11886.pdf", "openAccess": true, "authors": ["Jay Mardia"]}}, "a30f912f8c5e2a2bfb06351d4578e1ba3fa37896": {"id": "a30f912f8c5e2a2bfb06351d4578e1ba3fa37896", "content": {"title": "CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation", "abstract": "Pre-trained models for Natural Languages (NL) like BERT and GPT have been recently shown to transfer well to Programming Languages (PL) and largely benefit a broad set of code-related tasks. Despite their success, most current methods either rely on an encoder-only (or decoder-only) pre-training that is suboptimal for generation (resp. understanding) tasks or process the code snippet in the same way as NL, neglecting the special characteristics of PL such as token types. We present CodeT5, a unified pre-trained encoder-decoder Transformer model that better leverages the code semantics conveyed from the developer-assigned identifiers. Our model employs a unified framework to seamlessly support both code understanding and generation tasks and allows for multi-task learning. Besides, we propose a novel identifier-aware pre-training task that enables the model to distinguish which code tokens are identifiers and to recover them when they are masked. Furthermore, we propose to exploit the user-written code comments with a bimodal dual generation task for better NL-PL alignment. Comprehensive experiments show that CodeT5 significantly outperforms prior methods on understanding tasks such as code defect detection and clone detection, and generation tasks across various directions including PL-NL, NL-PL, and PL-PL. Further analysis reveals that our model can better capture semantic information from code. Our code and pre-trained models are released at https://github.com/salesforce/CodeT5.", "year": 2021, "ssId": "a30f912f8c5e2a2bfb06351d4578e1ba3fa37896", "arXivId": "2109.00859", "link": "https://arxiv.org/pdf/2109.00859.pdf", "openAccess": true, "authors": ["Yue Wang", "Weishi Wang", "Shafiq R. Joty", "S. Hoi"]}}, "0c47eb31b2dd76d8dc986173a1d3f00da1c9c74d": {"id": "0c47eb31b2dd76d8dc986173a1d3f00da1c9c74d", "content": {"title": "Efficient Nearest Neighbor Language Models", "abstract": "Non-parametric neural language models (NLMs) learn predictive distributions of text utilizing an external datastore, which allows them to learn through explicitly memorizing the training datapoints. While effective, these models often require retrieval from a large datastore at test time, significantly increasing the inference overhead and thus limiting the deployment of non-parametric NLMs in practical applications. In this paper, we take the recently proposed k-nearest neighbors language model as an example, exploring methods to improve its efficiency along various dimensions. Experiments on the standard WikiText-103 benchmark and domain-adaptation datasets show that our methods are able to achieve up to a 6x speed-up in inference speed while retaining comparable performance. The empirical analysis we present may provide guidelines for future research seeking to develop or deploy more efficient non-parametric NLMs.", "year": 2021, "ssId": "0c47eb31b2dd76d8dc986173a1d3f00da1c9c74d", "arXivId": "2109.04212", "link": "https://arxiv.org/pdf/2109.04212.pdf", "openAccess": true, "authors": ["Junxian He", "Graham Neubig", "Taylor Berg-Kirkpatrick"]}}, "a38e0f993e4805ba8a9beae4c275c91ffcec01df": {"id": "a38e0f993e4805ba8a9beae4c275c91ffcec01df", "content": {"title": "Program Synthesis with Large Language Models", "abstract": "This paper explores the limits of the current generation of large language models for program synthesis in general purpose programming languages. We evaluate a collection of such models (with between 244M and 137B parameters) on two new benchmarks, MBPP and MathQA-Python, in both the few-shot and fine-tuning regimes. Our benchmarks are designed to measure the ability of these models to synthesize short Python programs from natural language descriptions. The Mostly Basic Programming Problems (MBPP) dataset contains 974 programming tasks, designed to be solvable by entry-level programmers. The MathQA-Python dataset, a Python version of the MathQA benchmark, contains 23914 problems that evaluate the ability of the models to synthesize code from more complex text. On both datasets, we find that synthesis performance scales log-linearly with model size. Our largest models, even without finetuning on a code dataset, can synthesize solutions to 59.6% of the problems from MBPP using few-shot learning with a well-designed prompt. Fine-tuning on a held-out portion of the dataset improves performance by about 10 percentage points across most model sizes. On the MathQA-Python dataset, the largest fine-tuned model achieves 83.8% accuracy. Going further, we study the model\u2019s ability to engage in dialog about code, incorporating human feedback to improve its solutions. We find that natural language feedback from a human halves the error rate compared to the model\u2019s initial prediction. Additionally, we conduct an error analysis to shed light on where these models fall short and what types of programs are most difficult to generate. Finally, we explore the semantic grounding of these models by fine-tuning them to predict the results of program execution. We find that even our best models are generally unable to predict the output of a program given a specific input.", "year": 2021, "ssId": "a38e0f993e4805ba8a9beae4c275c91ffcec01df", "arXivId": "2108.07732", "link": "https://arxiv.org/pdf/2108.07732.pdf", "openAccess": true, "authors": ["Jacob Austin", "Augustus Odena", "Maxwell Nye", "Maarten Bosma", "Henryk Michalewski", "David Dohan", "Ellen Jiang", "Carrie J. Cai", "Michael Terry", "Quoc V. Le", "Charles Sutton"]}}, "73fe797b4f4f2d18784246bb74626426a8fe108e": {"id": "73fe797b4f4f2d18784246bb74626426a8fe108e", "content": {"title": "Pointer Graph Networks", "abstract": "Graph neural networks (GNNs) are typically applied to static graphs that are assumed to be known upfront. This static input structure is often informed purely by insight of the machine learning practitioner, and might not be optimal for the actual task the GNN is solving. In absence of reliable domain expertise, one might resort to inferring the latent graph structure, which is often difficult due to the vast search space of possible graphs. Here we introduce Pointer Graph Networks (PGNs) which augment sets or graphs with additional inferred edges for improved model expressivity. PGNs allow each node to dynamically point to another node, followed by message passing over these pointers. The sparsity of this adaptable graph structure makes learning tractable while still being sufficiently expressive to simulate complex algorithms. Critically, the pointing mechanism is directly supervised to model long-term sequences of operations on classical data structures, incorporating useful structural inductive biases from theoretical computer science. Qualitatively, we demonstrate that PGNs can learn parallelisable variants of pointer-based data structures, namely disjoint set unions and link/cut trees. PGNs generalise out-of-distribution to 5x larger test inputs on dynamic graph connectivity tasks, outperforming unrestricted GNNs and Deep Sets.", "year": 2020, "ssId": "73fe797b4f4f2d18784246bb74626426a8fe108e", "arXivId": "2006.06380", "link": "https://arxiv.org/pdf/2006.06380.pdf", "openAccess": true, "authors": ["Petar Velivckovi'c", "Lars Buesing", "Matthew Overlan", "Razvan Pascanu", "Oriol Vinyals", "C. Blundell"]}}, "1ccd031f28dccfb226f6c0c588c93a97a50bf95f": {"id": "1ccd031f28dccfb226f6c0c588c93a97a50bf95f", "content": {"title": "Measuring Coding Challenge Competence With APPS", "abstract": "While programming is one of the most broadly applicable skills in modern society, it is unclear how well state-of-the-art machine learning models can write code. Despite its importance, there has been surprisingly little work on evaluating code generation, and it can be difficult to assess code generation performance in an accurate and rigorous manner. To meet this challenge, we introduce APPS, a benchmark for code generation. Unlike prior work in more restricted settings, our benchmark measures the ability of models to take an arbitrary natural language specification and generate satisfactory Python code. Similar to how companies assess candidate software developers, we evaluate models by checking their generated code on test cases. Our benchmark includes 10,000 problems, which range from having simple oneline solutions to being substantial algorithmic challenges. We fine-tune large language models on both GitHub and our training set, and we find that the prevalence of syntax errors is decreasing exponentially as models improve. Recent models such as GPT-Neo can pass approximately 20% of the test cases of introductory problems, so we find that machine learning models are now beginning to learn how to code. As the social significance of automatic code generation increases over the coming years, our benchmark can provide an objective measure for tracking advancements. \u201cEverybody should learn to program a computer, because it teaches you how to think.\u201d \u2013 Steve Jobs", "year": 2021, "ssId": "1ccd031f28dccfb226f6c0c588c93a97a50bf95f", "arXivId": "2105.09938", "link": "https://arxiv.org/pdf/2105.09938.pdf", "openAccess": true, "authors": ["Dan Hendrycks", "Steven Basart", "Saurav Kadavath", "Mantas Mazeika", "Akul Arora", "Ethan Guo", "Collin Burns", "Samir Puranik", "Horace He", "D. Song", "J. Steinhardt"]}}, "0735fb79bf34698c1df4461a05ed51c232c412e4": {"id": "0735fb79bf34698c1df4461a05ed51c232c412e4", "content": {"title": "Thinking Like Transformers", "abstract": "What is the computational model behind a Transformer? Where recurrent neural networks have direct parallels in finite state machines, allowing clear discussion and thought around architecture variants or trained models, Transformers have no such familiar parallel. In this paper we aim to change that, proposing a computational model for the transformer-encoder in the form of a programming language. We map the basic components of a transformer-encoder\u2014attention and feed-forward computation\u2014into simple primitives, around which we form a programming language: the Restricted Access Sequence Processing Language (RASP). We show how RASP can be used to program solutions to tasks that could conceivably be learned by a Transformer, and how a Transformer can be trained to mimic a RASP solution. In particular, we provide RASP programs for histograms, sorting, and Dyck-languages. We further use our model to relate their difficulty in terms of the number of required layers and attention heads: analyzing a RASP program implies a maximum number of heads and layers necessary to encode a task in a transformer. Finally, we see how insights gained from our abstraction might be used to explain phenomena seen in recent works.", "year": 2021, "ssId": "0735fb79bf34698c1df4461a05ed51c232c412e4", "arXivId": "2106.06981", "link": "https://arxiv.org/pdf/2106.06981.pdf", "openAccess": true, "authors": ["Gail Weiss", "Yoav Goldberg", "Eran Yahav"]}}, "5aea95e1ae78a66474051a330ded374e199b658c": {"id": "5aea95e1ae78a66474051a330ded374e199b658c", "content": {"title": "Representation Learning on Graphs with Jumping Knowledge Networks", "abstract": "Recent deep learning approaches for representation learning on graphs follow a neighborhood aggregation procedure. We analyze some important properties of these models, and propose a strategy to overcome those. In particular, the range of \"neighboring\" nodes that a node's representation draws from strongly depends on the graph structure, analogous to the spread of a random walk. To adapt to local neighborhood properties and tasks, we explore an architecture -- jumping knowledge (JK) networks -- that flexibly leverages, for each node, different neighborhood ranges to enable better structure-aware representation. In a number of experiments on social, bioinformatics and citation networks, we demonstrate that our model achieves state-of-the-art performance. Furthermore, combining the JK framework with models like Graph Convolutional Networks, GraphSAGE and Graph Attention Networks consistently improves those models' performance.", "year": 2018, "ssId": "5aea95e1ae78a66474051a330ded374e199b658c", "arXivId": "1806.03536", "link": "https://arxiv.org/pdf/1806.03536.pdf", "openAccess": true, "authors": ["Keyulu Xu", "Chengtao Li", "Yonglong Tian", "Tomohiro Sonobe", "K. Kawarabayashi", "S. Jegelka"]}}, "ef9ddbc35676ce8ffc2a8067044473727839dbac": {"id": "ef9ddbc35676ce8ffc2a8067044473727839dbac", "content": {"title": "Breaking the Softmax Bottleneck: A High-Rank RNN Language Model", "abstract": "We formulate language modeling as a matrix factorization problem, and show that the expressiveness of Softmax-based models (including the majority of neural language models) is limited by a Softmax bottleneck. Given that natural language is highly context-dependent, this further implies that in practice Softmax with distributed word embeddings does not have enough capacity to model natural language. We propose a simple and effective method to address this issue, and improve the state-of-the-art perplexities on Penn Treebank and WikiText-2 to 47.69 and 40.68 respectively.", "year": 2017, "ssId": "ef9ddbc35676ce8ffc2a8067044473727839dbac", "arXivId": "1711.03953", "link": "https://arxiv.org/pdf/1711.03953.pdf", "openAccess": true, "authors": ["Zhilin Yang", "Zihang Dai", "R. Salakhutdinov", "William W. Cohen"]}}, "bb6317bbd2c4a81e94cf3d7eb1b73da246a022db": {"id": "bb6317bbd2c4a81e94cf3d7eb1b73da246a022db", "content": {"title": "Generalization through Memorization: Nearest Neighbor Language Models", "abstract": "We introduce $k$NN-LMs, which extend a pre-trained neural language model (LM) by linearly interpolating it with a $k$-nearest neighbors ($k$NN) model. The nearest neighbors are computed according to distance in the pre-trained LM embedding space, and can be drawn from any text collection, including the original LM training data. Applying this augmentation to a strong Wikitext-103 LM, with neighbors drawn from the original training set, our $k$NN-LM achieves a new state-of-the-art perplexity of 15.79 - a 2.9 point improvement with no additional training. We also show that this approach has implications for efficiently scaling up to larger training sets and allows for effective domain adaptation, by simply varying the nearest neighbor datastore, again without further training. Qualitatively, the model is particularly helpful in predicting rare patterns, such as factual knowledge. Together, these results strongly suggest that learning similarity between sequences of text is easier than predicting the next word, and that nearest neighbor search is an effective approach for language modeling in the long tail.", "year": 2019, "ssId": "bb6317bbd2c4a81e94cf3d7eb1b73da246a022db", "arXivId": "1911.00172", "link": "https://arxiv.org/pdf/1911.00172.pdf", "openAccess": true, "authors": ["Urvashi Khandelwal", "Omer Levy", "Dan Jurafsky", "Luke Zettlemoyer", "M. Lewis"]}}, "03006aefccdd0c5c6736ab11ed574d02ba1cc086": {"id": "03006aefccdd0c5c6736ab11ed574d02ba1cc086", "content": {"title": "Handling Syntactic Divergence in Low-resource Machine Translation", "abstract": "Despite impressive empirical successes of neural machine translation (NMT) on standard benchmarks, limited parallel data impedes the application of NMT models to many language pairs. Data augmentation methods such as back-translation make it possible to use monolingual data to help alleviate these issues, but back-translation itself fails in extreme low-resource scenarios, especially for syntactically divergent languages. In this paper, we propose a simple yet effective solution, whereby target-language sentences are re-ordered to match the order of the source and used as an additional source of training-time supervision. Experiments with simulated low-resource Japanese-to-English, and real low-resource Uyghur-to-English scenarios find significant improvements over other semi-supervised alternatives.", "year": 2019, "ssId": "03006aefccdd0c5c6736ab11ed574d02ba1cc086", "arXivId": "1909.00040", "link": "https://arxiv.org/pdf/1909.00040.pdf", "openAccess": true, "authors": ["Chunting Zhou", "Xuezhe Ma", "Junjie Hu", "Graham Neubig"]}}, "d170bd486e4c0fe82601e322b0e9e0dde63ab299": {"id": "d170bd486e4c0fe82601e322b0e9e0dde63ab299", "content": {"title": "Adaptive Input Representations for Neural Language Modeling", "abstract": "We introduce adaptive input representations for neural language modeling which extend the adaptive softmax of Grave et al. (2017) to input representations of variable capacity. There are several choices on how to factorize the input and output layers, and whether to model words, characters or sub-word units. We perform a systematic comparison of popular choices for a self-attentional architecture. Our experiments show that models equipped with adaptive embeddings are more than twice as fast to train than the popular character input CNN while having a lower number of parameters. On the WikiText-103 benchmark we achieve 18.7 perplexity, an improvement of 10.5 perplexity compared to the previously best published result and on the Billion Word benchmark, we achieve 23.02 perplexity.", "year": 2018, "ssId": "d170bd486e4c0fe82601e322b0e9e0dde63ab299", "arXivId": "1809.10853", "link": "https://arxiv.org/pdf/1809.10853.pdf", "openAccess": true, "authors": ["Alexei Baevski", "Michael Auli"]}}, "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269": {"id": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269", "content": {"title": "Evaluating Large Language Models Trained on Code", "abstract": "We introduce Codex, a GPT language model finetuned on publicly available code from GitHub, and study its Python code-writing capabilities. A distinct production version of Codex powers GitHub Copilot. On HumanEval, a new evaluation set we release to measure functional correctness for synthesizing programs from docstrings, our model solves 28.8% of the problems, while GPT-3 solves 0% and GPT-J solves 11.4%. Furthermore, we find that repeated sampling from the model is a surprisingly effective strategy for producing working solutions to difficult prompts. Using this method, we solve 70.2% of our problems with 100 samples per problem. Careful investigation of our model reveals its limitations, including difficulty with docstrings describing long chains of operations and with binding operations to variables. Finally, we discuss the potential broader impacts of deploying powerful code generation technologies, covering safety, security, and economics. Equal contribution OpenAI, San Francisco, California, USA. Anthropic AI, San Francisco, California, USA. Work performed while at OpenAI. Zipline, South San Francisco, California, USA. Work performed while at OpenAI. Correspondence to: Mark Chen <mark@openai.com>, Jerry Tworek <jt@openai.com>, Heewoo Jun <heewoo@openai.com>, Qiming Yuan <qiming@openai.com>.", "year": 2021, "ssId": "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269", "arXivId": "2107.03374", "link": "https://arxiv.org/pdf/2107.03374.pdf", "openAccess": true, "authors": ["Mark Chen", "Jerry Tworek", "Heewoo Jun", "Qiming Yuan", "Henrique Ponde", "J. Kaplan", "Harrison Edwards", "Yura Burda", "Nicholas Joseph", "Greg Brockman", "Alex Ray", "Raul Puri", "Gretchen Krueger", "Michael Petrov", "Heidy Khlaaf", "Girish Sastry", "Pamela Mishkin", "Brooke Chan", "Scott Gray", "Nick Ryder", "Mikhail Pavlov", "Alethea Power", "Lukasz Kaiser", "Mohammad Bavarian", "Clemens Winter", "Philippe Tillet", "F. Such", "D. Cummings", "Matthias Plappert", "Fotios Chantzis", "Elizabeth Barnes", "Ariel Herbert-Voss", "William H. Guss", "Alex Nichol", "I. Babuschkin", "S. Balaji", "Shantanu Jain", "A. Carr", "J. Leike", "Joshua Achiam", "Vedant Misra", "Evan Morikawa", "Alec Radford", "M. Knight", "Miles Brundage", "Mira Murati", "Katie Mayer", "P. Welinder", "Bob McGrew", "Dario Amodei", "Sam McCandlish", "Ilya Sutskever", "Wojciech Zaremba"]}}, "2406cf39805c70264c4226b7325a09b506c70921": {"id": "2406cf39805c70264c4226b7325a09b506c70921", "content": {"title": "TAPEX: Table Pre-training via Learning a Neural SQL Executor", "abstract": "Recent years pre-trained language models hit a success on modeling natural language sentences and (semi-)structured tables. However, existing table pre-training techniques always suffer from low data quality and low pre-training efficiency. In this paper, we show that table pre-training can be realized by learning a neural SQL executor over a synthetic corpus, which is obtained by automatically synthesizing executable SQL queries. By pre-training on the synthetic corpus, our approach TAPEX dramatically improves the performance on downstream tasks, boosting existing language models by at most 19.5%. Meanwhile, TAPEX has remarkably high pretraining efficiency and yields strong results when using a small pre-trained corpus. Experimental results demonstrate that TAPEX outperforms previous table pre-training approaches by a large margin, and our model achieves new state-of-the-art results on four well-known datasets, including improving the WIKISQL denotation accuracy to 89.6% (+4.9%), the WIKITABLEQUESTIONS denotation accuracy to 57.5% (+4.8%), the SQA denotation accuracy to 74.5% (+3.5%), and the TABFACT accuracy to 84.6% (+3.6%). Our work opens the way to reason over structured data by pre-training on synthetic executable programs. The project homepage is at https: //table-pretraining.github.io/.", "year": 2021, "ssId": "2406cf39805c70264c4226b7325a09b506c70921", "arXivId": "2107.07653", "link": "https://arxiv.org/pdf/2107.07653.pdf", "openAccess": true, "authors": ["Qian Liu", "Bei Chen", "Jiaqi Guo", "Zeqi Lin", "Jian-Guang Lou"]}}, "5270b626feb66c8c363e93ba6608daae93c5003b": {"id": "5270b626feb66c8c363e93ba6608daae93c5003b", "content": {"title": "Modifying Memories in Transformer Models", "abstract": "Large Transformer models have achieved impressive performance in many natural language tasks. In particular, Transformer based language models have been shown to have great capabilities in encoding factual knowledge in their vast amount of parameters. While the tasks of improving the memorization and generalization of Transformers have been widely studied, it is not well known how to make transformers forget specific old facts and memorize new ones. In this paper, we propose a new task of \\emph{explicitly modifying specific factual knowledge in Transformer models while ensuring the model performance does not degrade on the unmodified facts}. This task is useful in many scenarios, such as updating stale knowledge, protecting privacy, and eliminating unintended biases stored in the models. We benchmarked several approaches that provide natural baseline performances on this task. This leads to the discovery of key components of a Transformer model that are especially effective for knowledge modifications. The work also provides insights into the role that different training phases (such as pretraining and fine-tuning) play towards memorization and knowledge modification.", "year": 2020, "ssId": "5270b626feb66c8c363e93ba6608daae93c5003b", "arXivId": "2012.00363", "link": "https://arxiv.org/pdf/2012.00363.pdf", "openAccess": true, "authors": ["Chen Zhu", "A. Rawat", "M. Zaheer", "Srinadh Bhojanapalli", "Daliang Li", "Felix X. Yu", "Sanjiv Kumar"]}}, "aead4418733b998792deb9cbf198a834449e00d2": {"id": "aead4418733b998792deb9cbf198a834449e00d2", "content": {"title": "Symbolic Brittleness in Sequence Models: on Systematic Generalization in Symbolic Mathematics", "abstract": "Neural sequence models trained with maximum likelihood estimation have led to breakthroughs in many tasks, where success is defined by the gap between training and test performance. However, their ability to achieve stronger forms of generalization remains unclear. We consider the problem of symbolic mathematical integration, as it requires generalizing systematically beyond the test set. We develop a methodology for evaluating generalization that takes advantage of the problem domain\u2019s structure and access to a verifier. Despite promising in-distribution performance of sequenceto-sequence models in this domain, we demonstrate challenges in achieving robustness, compositionality, and outof-distribution generalization, through both carefully constructed manual test suites and a genetic algorithm that automatically finds large collections of failures in a controllable manner. Our investigation highlights the difficulty of generalizing well with the predominant modeling and learning approach, and the importance of evaluating beyond the test set, across different aspects of generalization.", "year": 2021, "ssId": "aead4418733b998792deb9cbf198a834449e00d2", "arXivId": "2109.13986", "link": "https://arxiv.org/pdf/2109.13986.pdf", "openAccess": true, "authors": ["S. Welleck", "Peter West", "Jize Cao", "Yejin Choi"]}}, "21d45b4923ad165fbb6612e08d06f9d786f9b4cc": {"id": "21d45b4923ad165fbb6612e08d06f9d786f9b4cc", "content": {"title": "Symbolic Knowledge Distillation: from General Language Models to Commonsense Models", "abstract": "The common practice for training commonsense models has gone from\u2013human\u2013to\u2013 corpus\u2013to\u2013machine: humans author commonsense knowledge graphs in order to train commonsense models. In this work, we investigate an alternative, from\u2013machine\u2013to\u2013corpus\u2013 to\u2013machine: general language models author these commonsense knowledge graphs to train commonsense models. Our study leads to a new framework, Symbolic Knowledge Distillation. As with prior art in Knowledge Distillation (Hinton et al., 2015), our approach uses larger models to teach smaller models. A key difference is that we distill knowledge symbolically\u2013as text\u2013in addition to the neural model. We also distill only one aspect\u2013the commonsense of a general language model teacher, allowing the student to be a different type, a commonsense model. Altogether, we show that careful prompt engineering and a separately trained critic model allow us to selectively distill high-quality causal commonsense from GPT-3, a general language model. Empirical results demonstrate that, for the first time, a human-authored commonsense knowledge graph is surpassed by our automatically distilled variant in all three criteria: quantity, quality, and diversity. In addition, it results in a neural commonsense model that surpasses the teacher model\u2019s commonsense capabilities despite its 100x smaller size. We apply this to the ATOMIC resource, and share our new symbolic knowledge graph and commonsense models1.", "year": 2021, "ssId": "21d45b4923ad165fbb6612e08d06f9d786f9b4cc", "arXivId": "2110.07178", "link": "https://arxiv.org/pdf/2110.07178.pdf", "openAccess": true, "authors": ["Peter West", "Chandrasekhar Bhagavatula", "Jack Hessel", "Jena D. Hwang", "Liwei Jiang", "Ronan Le Bras", "Ximing Lu", "S. Welleck", "Yejin Choi"]}}, "2c871df72c52b58f05447fcb3afc838168d94505": {"id": "2c871df72c52b58f05447fcb3afc838168d94505", "content": {"title": "Knowledge Neurons in Pretrained Transformers", "abstract": "Large-scale pretrained language models are surprisingly good at recalling factual knowledge presented in the training corpus (Petroni et al., 2019; Jiang et al., 2020b). In this paper, we present preliminary studies on how factual knowledge is stored in pretrained Transformers by introducing the concept of knowledge neurons. Specifically, we examine the fill-in-the-blank cloze task for BERT. Given a relational fact, we propose a knowledge attribution method to identify the neurons that express the fact. We find that the activation of such knowledge neurons is positively correlated to the expression of their corresponding facts. In our case studies, we attempt to leverage knowledge neurons to edit (such as update, and erase) specific factual knowledge without fine-tuning. Our results shed light on understanding the storage of knowledge within pretrained Transformers. The code is available at https://github.com/ Hunter-DDM/knowledge-neurons.", "year": 2021, "ssId": "2c871df72c52b58f05447fcb3afc838168d94505", "arXivId": "2104.08696", "link": "https://arxiv.org/pdf/2104.08696.pdf", "openAccess": true, "authors": ["Damai Dai", "Li Dong", "Y. Hao", "Zhifang Sui", "Furu Wei"]}}, "1c709eef701d933af1383c790c13209f06806b60": {"id": "1c709eef701d933af1383c790c13209f06806b60", "content": {"title": "Rationales for Sequential Predictions", "abstract": "Sequence models are a critical component of modern NLP systems, but their predictions are difficult to explain. We consider model explanations though rationales, subsets of context that can explain individual model predictions. We find sequential rationales by solving a combinatorial optimization: the best rationale is the smallest subset of input tokens that would predict the same output as the full sequence. Enumerating all subsets is intractable, so we propose an efficient greedy algorithm to approximate this objective. The algorithm, which is called greedy rationalization, applies to any model. For this approach to be effective, the model should form compatible conditional distributions when making predictions on incomplete subsets of the context. This condition can be enforced with a short fine-tuning step. We study greedy rationalization on language modeling and machine translation. Compared to existing baselines, greedy rationalization is best at optimizing the sequential objective and provides the most faithful rationales. On a new dataset of annotated sequential rationales, greedy rationales are most similar to human rationales.", "year": 2021, "ssId": "1c709eef701d933af1383c790c13209f06806b60", "arXivId": "2109.06387", "link": "https://arxiv.org/pdf/2109.06387.pdf", "openAccess": true, "authors": ["Keyon Vafa", "Yuntian Deng", "D. Blei", "Alexander M. Rush"]}}, "b8b813111c411ae61881ab9cd25707d9de6444ec": {"id": "b8b813111c411ae61881ab9cd25707d9de6444ec", "content": {"title": "Compositional Attention: Disentangling Search and Retrieval", "abstract": "Multi-head, key-value attention is the backbone of the widely successful Transformer model and its variants. This attention mechanism uses multiple parallel key-value attention blocks (called heads), each performing two fundamental computations: (1) search \u2013 selection of a relevant entity from a set via query-key interactions, and (2) retrieval \u2013 extraction of relevant features from the selected entity via a value matrix. Importantly, standard attention heads learn a rigid mapping between search and retrieval. In this work, we first highlight how this static nature of the pairing can potentially: (a) lead to learning of redundant parameters in certain tasks, and (b) hinder generalization. To alleviate this problem, we propose a novel attention mechanism, called Compositional Attention, that replaces the standard head structure. The proposed mechanism disentangles search and retrieval and composes them in a dynamic, flexible and context-dependent manner through an additional soft competition stage between the query-key combination and value pairing. Through a series of numerical experiments, we show that it outperforms standard multi-head attention on a variety of tasks, including some out-of-distribution settings. Through our qualitative analysis, we demonstrate that Compositional Attention leads to dynamic specialization based on the type of retrieval needed. Our proposed mechanism generalizes multi-head attention, allows independent scaling of search and retrieval, and can easily be implemented in lieu of standard attention heads in any network architecture.1", "year": 2021, "ssId": "b8b813111c411ae61881ab9cd25707d9de6444ec", "arXivId": "2110.09419", "link": "https://arxiv.org/pdf/2110.09419.pdf", "openAccess": true, "authors": ["Sarthak Mittal", "Sharath Chandra Raparthy", "I. Rish", "Yoshua Bengio", "Guillaume Lajoie"]}}, "7f79ac114d30c2c7dae91075210fbfda90c9d76f": {"id": "7f79ac114d30c2c7dae91075210fbfda90c9d76f", "content": {"title": "Human-Level Performance in No-Press Diplomacy via Equilibrium Search", "abstract": "Prior AI breakthroughs in complex games have focused on either the purely adversarial or purely cooperative settings. In contrast, Diplomacy is a game of shifting alliances that involves both cooperation and competition. For this reason, Diplomacy has proven to be a formidable research challenge. In this paper we describe an agent for the no-press variant of Diplomacy that combines supervised learning on human data with one-step lookahead search via external regret minimization. External regret minimization techniques have been behind previous AI successes in adversarial games, most notably poker, but have not previously been shown to be successful in large-scale games involving cooperation. We show that our agent greatly exceeds the performance of past no-press Diplomacy bots, is unexploitable by expert humans, and achieves a rank of 23 out of 1,128 human players when playing anonymous games on a popular Diplomacy website.", "year": 2020, "ssId": "7f79ac114d30c2c7dae91075210fbfda90c9d76f", "arXivId": "2010.02923", "link": "https://arxiv.org/pdf/2010.02923.pdf", "openAccess": true, "authors": ["Jonathan Gray", "Adam Lerer", "A. Bakhtin", "Noam Brown"]}}, "c6c18ad62f39060e2547a0b683525e83312d0700": {"id": "c6c18ad62f39060e2547a0b683525e83312d0700", "content": {"title": "A Market-Inspired Bidding Scheme for Peer Review Paper Assignment", "abstract": "We propose a market-inspired bidding scheme for the assignment of paper reviews in large academic conferences. We provide an analysis of the incentives of reviewers during the bidding phase, when reviewers have both private costs and some information about the demand for each paper; and their goal is to obtain the best possible k papers for a predetermined k. We show that by assigning \u2018budgets\u2019 to reviewers and a \u2018price\u2019 for every paper that is (roughly) proportional to its demand, the best response of a reviewer is to bid sincerely, i.e., on her most favorite papers, and match the budget even when it is not enforced. This game-theoretic analysis is based on a simple, prototypical assignment algorithm. We show via extensive simulations on bidding data from real conferences, that our bidding scheme would substantially improve both the bid distribution and the resulting assignment.", "year": 2021, "ssId": "c6c18ad62f39060e2547a0b683525e83312d0700", "arXivId": null, "link": "http://www.agent-games-2020.preflib.org/wp-content/uploads/2020/05/MarketReviews.pdf", "openAccess": true, "authors": ["R. Meir", "J. Lang", "Julien Lesca", "Nicholas Mattei", "Natan Kaminsky"]}}, "d473ff103565d8c76e0cbfa33bdd4b0db1cbb23f": {"id": "d473ff103565d8c76e0cbfa33bdd4b0db1cbb23f", "content": {"title": "Evolution Strategies for Approximate Solution of Bayesian Games", "abstract": "We address the problem of solving complex Bayesian games, characterized by high-dimensional type and action spaces, many (> 2) players, and general-sum payoffs. Our approach applies to symmetric one-shot Bayesian games, with no given analytic structure. We represent agent strategies in parametric form as neural networks, and apply natural evolution strategies (NES) (Wierstra et al. 2014) for deep model optimization. For pure equilibrium computation, we formulate the problem as bi-level optimization, and employ NES in an iterative algorithm to implement both inner-loop best response optimization and outer-loop regret minimization. In simple games including firstand second-price auctions, it is capable of recovering known analytic solutions. For mixed equilibrium computation, we adopt an incremental strategy generation framework, with NES as strategy generator producing a finite sequence of approximate best-response strategies. We then calculate equilibria over this finite strategy set via a model-based optimization process. Both our pure and mixed equilibrium computation methods employ NES to efficiently search for strategies over the function space, given only black-box simulation access to noisy payoff samples. We experimentally demonstrate the efficacy of all methods on two simultaneous sealed-bid auction games with distinct type distributions, and observe that the solutions exhibit qualitatively different behavior in these two environments.", "year": 2021, "ssId": "d473ff103565d8c76e0cbfa33bdd4b0db1cbb23f", "arXivId": null, "link": "https://rezunli96.github.io/src/AAAI2021.pdf", "openAccess": true, "authors": ["Zun Li", "Michael P. Wellman"]}}, "0f395654e69cd2e063a6ef221fb66fb46e68cefd": {"id": "0f395654e69cd2e063a6ef221fb66fb46e68cefd", "content": {"title": "Classification with Strategically Withheld Data", "abstract": "Machine learning techniques can be useful in applications such as credit approval and college admission. However, to be classified more favorably in such contexts, an agent may decide to strategically withhold some of her features, such as bad test scores. This is a missing data problem with a twist: which data is missing depends on the chosen classifier, because the specific classifier is what may create the incentive to withhold certain feature values. We address the problem of training classifiers that are robust to this behavior. We design three classification methods: MINCUT, HILLCLIMBING (HC) and Incentive-Compatible Logistic Regression (IC-LR). We show that MINCUT is optimal when the true distribution of data is fully known. However, it can produce complex decision boundaries, and hence be prone to overfitting in some cases. Based on a characterization of truthful classifiers (i.e., those that give no incentive to strategically hide features), we devise a simpler alternative called HC which consists of a hierarchical ensemble of out-of-thebox classifiers, trained using a specialized hill-climbing procedure which we show to be convergent. For several reasons, MINCUT and HC are not effective in utilizing a large number of complementarily informative features. To this end, we present IC-LR, a modification of Logistic Regression that removes the incentive to strategically drop features. We also show that our algorithms perform well in experiments on realworld data sets, and present insights into their relative performance in different settings.", "year": 2020, "ssId": "0f395654e69cd2e063a6ef221fb66fb46e68cefd", "arXivId": "2012.10203", "link": "https://arxiv.org/pdf/2012.10203.pdf", "openAccess": true, "authors": ["A. Krishnaswamy", "Haoming Li", "David Rein", "Hanrui Zhang", "V. Conitzer"]}}, "c8648d04f52e49167d1a4443a4830709cf3331ff": {"id": "c8648d04f52e49167d1a4443a4830709cf3331ff", "content": {"title": "Complexity of Computing Optimal Stackelberg Strategies in Security Resource Allocation Games", "abstract": "Recently, algorithms for computing game-theoretic solutions have been deployed in real-world security applications, such as the placement of checkpoints and canine units at Los Angeles International Airport. These algorithms assume that the defender (security personnel) can commit to a mixed strategy, a so-called Stackelberg model. As pointed out by Kiek-intveld et al. (2009), in these applications, generally, multiple resources need to be assigned to multiple targets, resulting in an exponential number of pure strategies for the defender. In this paper, we study how to compute optimal Stackelberg strategies in such games, showing that this can be done in polynomial time in some cases, and is NP-hard in others.", "year": 2010, "ssId": "c8648d04f52e49167d1a4443a4830709cf3331ff", "arXivId": null, "link": "https://users.cs.duke.edu/~conitzer/complexityAAAI10.pdf", "openAccess": true, "authors": ["Dmytro Korzhyk", "V. Conitzer", "Ronald E. Parr"]}}, "a901185ee0710770420044cace33003109d478e3": {"id": "a901185ee0710770420044cace33003109d478e3", "content": {"title": "Designing Informative Rating Systems for Online Platforms: Evidence from Two Experiments", "abstract": "Platforms critically rely on rating systems to learn the quality of market participants. In practice, however, these ratings are often highly inflated, drastically reducing the signal available to distinguish quality. We consider two questions: First, can rating systems better discriminate quality by altering the meaning and relative importance of the levels in the rating system? And second, if so, how should the platform optimize these choices in the design of the rating system? We first analyze the results of a randomized controlled trial on an online labor market in which an additional question was added to the feedback form. Between treatment conditions, we vary the question phrasing and answer choices. We further run an experiment on Amazon Mechanical Turk with similar structure, to confirm the labor market findings. Our tests reveal that current inflationary norms can in fact be countered by re-anchoring the meaning of the levels of the rating system. In particular, scales that are positive-skewed and provide specific interpretations for what each label means yield rating distributions that are much more informative about quality. Second, we develop a theoretical framework to optimize the design of a rating system by choosing answer labels and their numeric interpretations in a manner that maximizes the rate of convergence to the true underlying quality distribution. Finally, we run simulations with an empirically calibrated model and use these to study the implications for optimal rating system design. Our simulations demonstrate that our modeling and optimization approach can substantially improve the quality of information obtained over baseline designs. Overall, our study illustrates that rating systems that are informative in practice can be designed, and demonstrates how to design them in a principled manner.", "year": 2018, "ssId": "a901185ee0710770420044cace33003109d478e3", "arXivId": "1810.13028", "link": "https://arxiv.org/pdf/1810.13028.pdf", "openAccess": true, "authors": ["Nikhil Garg", "R. Johari"]}}, "69b184f62c97513b03deed96a1443f79b34af0d7": {"id": "69b184f62c97513b03deed96a1443f79b34af0d7", "content": {"title": "Making Paper Reviewing Robust to Bid Manipulation Attacks", "abstract": "Most computer science conferences rely on paper bidding to assign reviewers to papers. Although paper bidding enables high-quality assignments in days of unprecedented submission numbers, it also opens the door for dishonest reviewers to adversarially influence paper reviewing assignments. Anecdotal evidence suggests that some reviewers bid on papers by \u201cfriends\u201d or colluding authors, even though these papers are outside their area of expertise, and recommend them for acceptance without considering the merit of the work. In this paper, we study the efficacy of such bid manipulation attacks and find that, indeed, they can jeopardize the integrity of the review process. We develop a novel approach for paper bidding and assignment that is much more robust against such attacks. We show empirically that our approach provides robustness even when dishonest reviewers collude, have full knowledge of the assignment system\u2019s internal workings, and have access to the system\u2019s inputs. In addition to being more robust, the quality of our paper review assignments is comparable to that of current, non-robust assignment approaches.", "year": 2021, "ssId": "69b184f62c97513b03deed96a1443f79b34af0d7", "arXivId": "2102.06020", "link": "https://arxiv.org/pdf/2102.06020.pdf", "openAccess": true, "authors": ["Ruihan Wu", "Chuan Guo", "Felix Wu", "Rahul Kidambi", "L. V. D. Maaten", "Kilian Q. Weinberger"]}}, "ff783c4709a095cc581534fec58ef9515613ebc9": {"id": "ff783c4709a095cc581534fec58ef9515613ebc9", "content": {"title": "REMEMBERING FOR THE RIGHT REASONS: EXPLANATIONS REDUCE", "abstract": "The goal of continual learning (CL) is to learn a sequence of tasks without suffering from the phenomenon of catastrophic forgetting. Previous work has shown that leveraging memory in the form of a replay buffer can reduce performance degradation on prior tasks. We hypothesize that forgetting can be further reduced when the model is encouraged to remember the evidence for previously made decisions. As a first step towards exploring this hypothesis, we propose a simple novel training paradigm, called Remembering for the Right Reasons (RRR), that additionally stores visual model explanations for each example in the buffer and ensures the model has \u201cthe right reasons\u201d for its predictions by encouraging its explanations to remain consistent with those used to make decisions at training time. Without this constraint, there is a drift in explanations and increase in forgetting as conventional continual learning algorithms learn new tasks. We demonstrate how RRR can be easily added to any memory or regularizationbased approach and results in reduced forgetting, and more importantly, improved model explanations. We have evaluated our approach in the standard and few-shot settings and observed a consistent improvement across various CL approaches using different architectures and techniques to generate model explanations and demonstrated our approach showing a promising connection between explainability and continual learning. Our code is available at https://github.com/ SaynaEbrahimi/Remembering-for-the-Right-Reasons.", "year": 2021, "ssId": "ff783c4709a095cc581534fec58ef9515613ebc9", "arXivId": null, "link": "https://openreview.net/pdf?id=tHgJoMfy6nI", "openAccess": true, "authors": ["Catastrophic Forgetting", "Sayna Ebrahimi", "Suzanne Petryk", "Akash Gokul", "William Gan", "Joseph Gonzalez", "Marcus Rohrbach", "Trevor Darrell"]}}, "51b0609155e3a63afd1dd7dcc3034a5950f90ee0": {"id": "51b0609155e3a63afd1dd7dcc3034a5950f90ee0", "content": {"title": "Disentangling Influence: Using Disentangled Representations to Audit Model Predictions", "abstract": "Motivated by the need to audit complex and black box models, there has been extensive research on quantifying how data features influence model predictions. Feature influence can be direct (a direct influence on model outcomes) and indirect (model outcomes are influenced via proxy features). Feature influence can also be expressed in aggregate over the training or test data or locally with respect to a single point. Current research has typically focused on one of each of these dimensions. In this paper, we develop disentangled influence audits, a procedure to audit the indirect influence of features. Specifically, we show that disentangled representations provide a mechanism to identify proxy features in the dataset, while allowing an explicit computation of feature influence on either individual outcomes or aggregate-level outcomes. We show through both theory and experiments that disentangled influence audits can both detect proxy features and show, for each individual or in aggregate, which of these proxy features affects the classifier being audited the most. In this respect, our method is more powerful than existing methods for ascertaining feature influence.", "year": 2019, "ssId": "51b0609155e3a63afd1dd7dcc3034a5950f90ee0", "arXivId": "1906.08652", "link": "https://arxiv.org/pdf/1906.08652.pdf", "openAccess": true, "authors": ["Charles T. Marx", "Richard L. Phillips", "Sorelle A. Friedler", "C. Scheidegger", "Suresh Venkatasubramanian"]}}, "ae06bc1e8e67c27b89329ebcfe61b71625d853f6": {"id": "ae06bc1e8e67c27b89329ebcfe61b71625d853f6", "content": {"title": "A Diagnostic Study of Explainability Techniques for Text Classification", "abstract": "Recent developments in machine learning have introduced models that approach human performance at the cost of increased architectural complexity. Efforts to make the rationales behind the models' predictions transparent have inspired an abundance of new explainability techniques. Provided with an already trained model, they compute saliency scores for the words of an input instance. However, there exists no definitive guide on (i) how to choose such a technique given a particular application task and model architecture, and (ii) the benefits and drawbacks of using each such technique. In this paper, we develop a comprehensive list of diagnostic properties for evaluating existing explainability techniques. We then employ the proposed list to compare a set of diverse explainability techniques on downstream text classification tasks and neural network architectures. We also compare the saliency scores assigned by the explainability techniques with human annotations of salient input regions to find relations between a model's performance and the agreement of its rationales with human ones. Overall, we find that the gradient-based explanations perform best across tasks and model architectures, and we present further insights into the properties of the reviewed explainability techniques.", "year": 2020, "ssId": "ae06bc1e8e67c27b89329ebcfe61b71625d853f6", "arXivId": "2009.13295", "link": "https://arxiv.org/pdf/2009.13295.pdf", "openAccess": true, "authors": ["Pepa Atanasova", "J. Simonsen", "C. Lioma", "Isabelle Augenstein"]}}, "51546584aa394d159edcc08f2412ae30dd316f6c": {"id": "51546584aa394d159edcc08f2412ae30dd316f6c", "content": {"title": "Deep Learning Through the Lens of Example Difficulty", "abstract": "Existing work on understanding deep learning often employs measures that compress all data-dependent information into a few numbers. In this work, we adopt a perspective based on the role of individual examples. We introduce a measure of the computational difficulty of making a prediction for a given input: the (effective) prediction depth. Our extensive investigation reveals surprising yet simple relationships between the prediction depth of a given input and the model\u2019s uncertainty, confidence, accuracy and speed of learning for that data point. We further categorize difficult examples into three interpretable groups, demonstrate how these groups are processed differently inside deep models and showcase how this understanding allows us to improve prediction accuracy. Insights from our study lead to a coherent view of a number of separately reported phenomena in the literature: early layers generalize while later layers memorize; early layers converge faster and networks learn easy data and simple functions first.", "year": 2021, "ssId": "51546584aa394d159edcc08f2412ae30dd316f6c", "arXivId": "2106.09647", "link": "https://arxiv.org/pdf/2106.09647.pdf", "openAccess": true, "authors": ["R. Baldock", "Hartmut Maennel", "Behnam Neyshabur"]}}, "1d3539a8d94bd3ab78993d7cc584efc06ed0e460": {"id": "1d3539a8d94bd3ab78993d7cc584efc06ed0e460", "content": {"title": "Synthetic Benchmarks for Scientific Research in Explainable Machine Learning", "abstract": "As machine learning models grow more complex and their applications become more high-stakes, tools for explaining model predictions have become increasingly important. This has spurred a flurry of research in model explainability and has given rise to feature attribution methods such as LIME and SHAP. Despite their widespread use, evaluating and comparing different feature attribution methods remains challenging: evaluations ideally require human studies, and empirical evaluation metrics are often data-intensive or computationally prohibitive on realworld datasets. In this work, we address this issue by releasing XAI-BENCH: a suite of synthetic datasets along with a library for benchmarking feature attribution algorithms. Unlike real-world datasets, synthetic datasets allow the efficient computation of conditional expected values that are needed to evaluate groundtruth Shapley values and other metrics. The synthetic datasets we release offer a wide variety of parameters that can be configured to simulate real-world data. We demonstrate the power of our library by benchmarking popular explainability techniques across several evaluation metrics and across a variety of settings. The versatility and efficiency of our library will help researchers bring their explainability methods from development to deployment. Our code is available at https://github.com/abacusai/xai-bench.", "year": 2021, "ssId": "1d3539a8d94bd3ab78993d7cc584efc06ed0e460", "arXivId": "2106.12543", "link": "https://arxiv.org/pdf/2106.12543.pdf", "openAccess": true, "authors": ["Yang Liu", "Sujay Khandagale", "Colin White", "W. Neiswanger"]}}, "c5dfc5fe7102fd8647edd1c9483aded82557e544": {"id": "c5dfc5fe7102fd8647edd1c9483aded82557e544", "content": {"title": "Interpretable and Interactive Summaries of Actionable Recourses", "abstract": "As predictive models are increasingly being deployed in high-stakes decision-making, there has been a lot of interest in developing algorithms which can provide recourses to affected individuals. While developing such tools is important, it is even more critical to analyse and interpret a predictive model, and vet it thoroughly to ensure that the recourses it offers are meaningful and non-discriminatory before it is deployed in the real world. To this end, we propose a novel model agnostic framework called Actionable Recourse Summaries (AReS) to construct global counterfactual explanations which provide an interpretable and accurate summary of recourses for the entire population. We formulate a novel objective which simultaneously optimizes for correctness of the recourses and interpretability of the explanations, while minimizing overall recourse costs across the entire population. More specifically, our objective enables us to learn, with optimality guarantees on recourse correctness, a small number of compact rule sets each of which capture recourses for well defined subpopulations within the data. Our framework is also interactive i.e., it allows users to input specific features of interest which will in turn be used to characterize subpopulations when generating recourse summaries. We also demonstrate theoretically that several of the prior approaches proposed to generate recourses for individuals are special cases of our framework. Experimental evaluation with real world datasets and user studies demonstrate that our framework can provide decision makers with a comprehensive overview of recourses corresponding to any black box model, and consequently help detect undesirable model biases and discrimination.", "year": 2020, "ssId": "c5dfc5fe7102fd8647edd1c9483aded82557e544", "arXivId": "2009.07165", "link": "https://arxiv.org/pdf/2009.07165.pdf", "openAccess": true, "authors": ["Kaivalya Rawal", "Himabindu Lakkaraju"]}}, "9c5c794094fbf5da8c48df5c3242615dc0b1d245": {"id": "9c5c794094fbf5da8c48df5c3242615dc0b1d245", "content": {"title": "Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations", "abstract": "The key idea behind the unsupervised learning of disentangled representations is that real-world data is generated by a few explanatory factors of variation which can be recovered by unsupervised learning algorithms. In this paper, we provide a sober look at recent progress in the field and challenge some common assumptions. We first theoretically show that the unsupervised learning of disentangled representations is fundamentally impossible without inductive biases on both the models and the data. Then, we train more than 12000 models covering most prominent methods and evaluation metrics in a reproducible large-scale experimental study on seven different data sets. We observe that while the different methods successfully enforce properties ``encouraged'' by the corresponding losses, well-disentangled models seemingly cannot be identified without supervision. Furthermore, increased disentanglement does not seem to lead to a decreased sample complexity of learning for downstream tasks. Our results suggest that future work on disentanglement learning should be explicit about the role of inductive biases and (implicit) supervision, investigate concrete benefits of enforcing disentanglement of the learned representations, and consider a reproducible experimental setup covering several data sets.", "year": 2018, "ssId": "9c5c794094fbf5da8c48df5c3242615dc0b1d245", "arXivId": "1811.12359", "link": "https://arxiv.org/pdf/1811.12359.pdf", "openAccess": true, "authors": ["Francesco Locatello", "Stefan Bauer", "Mario Lucic", "S. Gelly", "B. Sch\u00f6lkopf", "Olivier Bachem"]}}, "4c9f20ce99f9b93527fd76ec04a44fcef9082005": {"id": "4c9f20ce99f9b93527fd76ec04a44fcef9082005", "content": {"title": "Balancing Accuracy and Fairness for Interactive Recommendation with Reinforcement Learning", "abstract": "Fairness in recommendation has attracted increasing attention due to bias and discrimination possibly caused by traditional recommenders. In Interactive Recommender Systems (IRS), user preferences and the system\u2019s fairness status are constantly changing over time. Existing fairness-aware recommenders mainly consider fairness in static settings. Directly applying existing methods to IRS will result in poor recommendation. To resolve this problem, we propose a reinforcement learning based framework, FairRec, to dynamically maintain a long-term balance between accuracy and fairness in IRS. User preferences and the system\u2019s fairness status are jointly compressed into the state representation to generate recommendations. FairRec aims at maximizing our designed cumulative reward that combines accuracy and fairness. Extensive experiments validate that FairRec can improve fairness, while preserving good recommendation quality.", "year": 2021, "ssId": "4c9f20ce99f9b93527fd76ec04a44fcef9082005", "arXivId": "2106.13386", "link": "https://arxiv.org/pdf/2106.13386.pdf", "openAccess": true, "authors": ["Weiwen Liu", "Feng Liu", "Ruiming Tang", "B. Liao", "Guangyong Chen", "P. Heng"]}}, "0b2e9e978898b9fb1116ea964c8c470086ceed87": {"id": "0b2e9e978898b9fb1116ea964c8c470086ceed87", "content": {"title": "Bifurcated Backbone Strategy for RGB-D Salient Object Detection", "abstract": "Multi-level feature fusion is a fundamental topic in computer vision. It has been exploited to detect, segment and classify objects at various scales. When multi-level features meet multi-modal cues, the optimal feature aggregation and multi-modal learning strategy become a hot potato. In this paper, we leverage the inherent multi-modal and multi-level nature of RGB-D salient object detection to devise a novel Bifurcated Backbone Strategy Network (BBS-Net). Our architecture, is simple, efficient, and backbone-independent. In particular, first, we propose to regroup the multi-level features into teacher and student features using a bifurcated backbone strategy (BBS). Second, we introduce a depth-enhanced module (DEM) to excavate informative depth cues from the channel and spatial views. Then, RGB and depth modalities are fused in a complementary way. Extensive experiments show that BBS-Net significantly outperforms 18 state-of-the-art (SOTA) models on eight challenging datasets under five evaluation measures, demonstrating the superiority of our approach (~4% improvement in S-measure $vs$ . the top-ranked model: DMRA). In addition, we provide a comprehensive analysis on the generalization ability of different RGB-D datasets and provide a powerful training set for future research. The complete algorithm, benchmark results, and post-processing toolbox are publicly available at https://github.com/zyjwuyan/BBS-Net.", "year": 2020, "ssId": "0b2e9e978898b9fb1116ea964c8c470086ceed87", "arXivId": "2007.02713", "link": "https://arxiv.org/pdf/2007.02713.pdf", "openAccess": true, "authors": ["Yingjie Zhai", "Deng-Ping Fan", "Jufeng Yang", "A. Borji", "L. Shao", "Junwei Han", "Liang Wang"]}}, "9f7e317c6ef0bb15aacc9b19f0f0d00fee6c9a36": {"id": "9f7e317c6ef0bb15aacc9b19f0f0d00fee6c9a36", "content": {"title": "What Neural Networks Memorize and Why: Discovering the Long Tail via Influence Estimation", "abstract": "Deep learning algorithms are well-known to have a propensity for fitting the training data very well and often fit even outliers and mislabeled data points. Such fitting requires memorization of training data labels, a phenomenon that has attracted significant research interest but has not been given a compelling explanation so far. A recent work of Feldman (2019) proposes a theoretical explanation for this phenomenon based on a combination of two insights. First, natural image and data distributions are (informally) known to be long-tailed, that is have a significant fraction of rare and atypical examples. Second, in a simple theoretical model such memorization is necessary for achieving close-to-optimal generalization error when the data distribution is long-tailed. However, no direct empirical evidence for this explanation or even an approach for obtaining such evidence were given. \nIn this work we design experiments to test the key ideas in this theory. The experiments require estimation of the influence of each training example on the accuracy at each test example as well as memorization values of training examples. Estimating these quantities directly is computationally prohibitive but we show that closely-related subsampled influence and memorization values can be estimated much more efficiently. Our experiments demonstrate the significant benefits of memorization for generalization on several standard benchmarks. They also provide quantitative and visually compelling evidence for the theory put forth in (Feldman, 2019).", "year": 2020, "ssId": "9f7e317c6ef0bb15aacc9b19f0f0d00fee6c9a36", "arXivId": "2008.03703", "link": "https://arxiv.org/pdf/2008.03703.pdf", "openAccess": true, "authors": ["V. Feldman", "Chiyuan Zhang"]}}, "cbf941fef87830efa4de98455cfe943917909b66": {"id": "cbf941fef87830efa4de98455cfe943917909b66", "content": {"title": "Rates of superlinear convergence for classical quasi-Newton methods", "abstract": "We present a new theoretical analysis of local superlinear convergence of the classical quasi-Newton methods from the convex Broyden class. Our analysis is based on the potential function involving the logarithm of determinant of Hessian approximation and the trace of inverse Hessian approximation. For the well-known DFP and BFGS methods, we obtain the rates of the form $\\left[\\frac L \\mu \\left(exp \\left\\{\\frac n k \\ln \\frac L \\mu\\right\\} - 1\\right)\\right]^{k/2}$ and $\\left[exp\\left\\{\\frac n k \\ln \\frac L \\mu\\right\\} - 1\\right]^{k/2}$ respectively, where k is the iteration counter, n is the dimension of the problem, \u03bc is the strong convexity parameter, and L is the Lipschitz constant of the gradient. Currently, these are the best known superlinear convergence rates for these methods. In particular, our results show that the starting moment of superlinear convergence of BFGS method depends on the logarithm of the condition number $\\frac L \u03bc$ in the worst case.", "year": 2020, "ssId": "cbf941fef87830efa4de98455cfe943917909b66", "arXivId": "2003.09174", "link": "https://arxiv.org/pdf/2003.09174.pdf", "openAccess": true, "authors": ["Anton Rodomanov", "Y. Nesterov"]}}, "1acbfc7d3e245bd3146e9e24eae7550aa2d03482": {"id": "1acbfc7d3e245bd3146e9e24eae7550aa2d03482", "content": {"title": "Theoretical Understanding of Batch-normalization: A Markov Chain Perspective", "abstract": "Batch-normalization (BN) is a key component to effectively train deep neural networks. Empirical evidence has shown that without BN, the training process is prone to unstabilities. This is however not well understood from a theoretical point of view. Leveraging tools from Markov chain theory, we show that BN has a direct effect on the rank of the pre-activation matrices of a neural network. Specifically, while deep networks without BN exhibit rank collapse and poor training performance, networks equipped with BN have a higher rank. In an extensive set of experiments on standard neural network architectures and datasets, we show that the latter quantity is a good predictor for the optimization speed of training.", "year": 2020, "ssId": "1acbfc7d3e245bd3146e9e24eae7550aa2d03482", "arXivId": "2003.01652", "link": "https://arxiv.org/pdf/2003.01652.pdf", "openAccess": true, "authors": ["Hadi Daneshmand", "J. Kohler", "F. Bach", "T. Hofmann", "Aur\u00e9lien Lucchi"]}}, "7596030e0ce7a8df2f43e6ba4e9de5fa4a19240f": {"id": "7596030e0ce7a8df2f43e6ba4e9de5fa4a19240f", "content": {"title": "Explore Aggressively, Update Conservatively: Stochastic Extragradient Methods with Variable Stepsize Scaling", "abstract": "Owing to their stability and convergence speed, extragradient methods have become a staple for solving large-scale saddle-point problems in machine learning. The basic premise of these algorithms is the use of an extrapolation step before performing an update; thanks to this exploration step, extra-gradient methods overcome many of the non-convergence issues that plague gradient descent/ascent schemes. On the other hand, as we show in this paper, running vanilla extragradient with stochastic gradients may jeopardize its convergence, even in simple bilinear models. To overcome this failure, we investigate a double stepsize extragradient algorithm where the exploration step evolves at a more aggressive time-scale compared to the update step. We show that this modification allows the method to converge even with stochastic gradients, and we derive sharp convergence rates under an error bound condition.", "year": 2020, "ssId": "7596030e0ce7a8df2f43e6ba4e9de5fa4a19240f", "arXivId": "2003.10162", "link": "https://arxiv.org/pdf/2003.10162.pdf", "openAccess": true, "authors": ["Yu-Guan Hsieh", "F. Iutzeler", "J. Malick", "P. Mertikopoulos"]}}, "bf9b069242f0af129c2aad8430a52454b008c327": {"id": "bf9b069242f0af129c2aad8430a52454b008c327", "content": {"title": "On Learning Rates and Schr\u00f6dinger Operators", "abstract": "The learning rate is perhaps the single most important parameter in the training of neural networks and, more broadly, in stochastic (nonconvex) optimization. Accordingly, there are numerous effective, but poorly understood, techniques for tuning the learning rate, including learning rate decay, which starts with a large initial learning rate that is gradually decreased. In this paper, we present a general theoretical analysis of the effect of the learning rate in stochastic gradient descent (SGD). Our analysis is based on the use of a learning-rate-dependent stochastic differential equation (lr-dependent SDE) that serves as a surrogate for SGD. For a broad class of objective functions, we establish a linear rate of convergence for this continuous-time formulation of SGD, highlighting the fundamental importance of the learning rate in SGD, and contrasting to gradient descent and stochastic gradient Langevin dynamics. Moreover, we obtain an explicit expression for the optimal linear rate by analyzing the spectrum of the Witten-Laplacian, a special case of the Schrodinger operator associated with the lr-dependent SDE. Strikingly, this expression clearly reveals the dependence of the linear convergence rate on the learning rate -- the linear rate decreases rapidly to zero as the learning rate tends to zero for a broad class of nonconvex functions, whereas it stays constant for strongly convex functions. Based on this sharp distinction between nonconvex and convex problems, we provide a mathematical interpretation of the benefits of using learning rate decay for nonconvex optimization.", "year": 2020, "ssId": "bf9b069242f0af129c2aad8430a52454b008c327", "arXivId": "2004.06977", "link": "https://arxiv.org/pdf/2004.06977.pdf", "openAccess": true, "authors": ["Bin Shi", "Weijie J. Su", "Michael I. Jordan"]}}, "9db77e925015ad02efc9beeab233bedbfe04e4b7": {"id": "9db77e925015ad02efc9beeab233bedbfe04e4b7", "content": {"title": "Accelerating Reinforcement Learning with a Directional-Gaussian-Smoothing Evolution Strategy", "abstract": "The objective of reinforcement learning (RL) is to find an optimal strategy for solving a dynamical control problem. Evolution strategy (ES) has been shown great promise in many challenging reinforcement learning (RL) tasks, where the underlying dynamical system is only accessible as a black box such that adjoint methods cannot be used. However, existing ES methods have two limitations that hinder its applicability in RL. First, most existing methods rely on Monte Carlo based gradient estimators to generate search directions. Due to low accuracy of Monte Carlo estimators, the RL training suffers from slow convergence and requires more iterations to reach the optimal solution. Second, the landscape of the reward function can be deceptive and may contain many local maxima, causing ES algorithms to prematurely converge and be unable to explore other parts of the parameter space with potentially greater rewards. In this work, we employ a Directional Gaussian Smoothing Evolutionary Strategy (DGS-ES) to accelerate RL training, which is well-suited to address these two challenges with its ability to (i) provide gradient estimates with high accuracy, and (ii) find nonlocal search direction which lays stress on large-scale variation of the reward function and disregards local fluctuation. Through several benchmark RL tasks demonstrated herein, we show that the DGS-ES method is highly scalable, possesses superior wall-clock time, and achieves competitive reward scores to other popular policy gradient and ES approaches.", "year": 2020, "ssId": "9db77e925015ad02efc9beeab233bedbfe04e4b7", "arXivId": "2002.09077", "link": "https://arxiv.org/pdf/2002.09077.pdf", "openAccess": true, "authors": ["Jiaxing Zhang", "Hoang Tran", "Guannan Zhang"]}}, "afdae523d420278670c30f45c015cc5860a0de22": {"id": "afdae523d420278670c30f45c015cc5860a0de22", "content": {"title": "Adaptive Gradient Methods Converge Faster with Over-Parameterization (and you can do a line-search)", "abstract": "As adaptive gradient methods are typically used for training over-parameterized models capable of exactly fitting the data, we study their convergence in this interpolation setting. Under this assumption, we prove that constant step-size, zero-momentum variants of Adam and AMSGrad can converge to the minimizer at the O(1/T) rate for smooth, convex functions. When this assumption is only approximately satisfied, we show that these methods converge to a neighbourhood of the solution. On the other hand, we show that Adagrad is robust to the violation of interpolation and converges to the minimizer at the optimal rate. However, we demonstrate that even for simple, convex problems satisfying interpolation, the empirical performance of these methods heavily depends on the step-size and requires tuning. We alleviate this problem by making use of stochastic line-search methods (SLS) and Polyak's step-sizes (SPS) to help these methods adapt to the function's local smoothness. We prove that adaptive methods used in conjunction with these techniques do not require knowledge of problem-dependent constants and retain the convergence guarantees of their constant step-size counterparts. Experimentally, we show that using SLS or SPS consistently improves the convergence of adaptive methods across tasks; from binary classification with kernel mappings to classification with deep neural networks. Furthermore, our empirical results show that Adagrad equipped with SLS generalizes better than SGD.", "year": 2020, "ssId": "afdae523d420278670c30f45c015cc5860a0de22", "arXivId": "2006.06835", "link": "https://arxiv.org/pdf/2006.06835.pdf", "openAccess": true, "authors": ["Sharan Vaswani", "Frederik Kunstner", "Issam H. Laradji", "Si Yi Meng", "Mark W. Schmidt", "S. Lacoste-Julien"]}}, "739c2181f7894050a06b53b41ac5debe8ffc4829": {"id": "739c2181f7894050a06b53b41ac5debe8ffc4829", "content": {"title": "Hausdorff dimension, heavy tails, and generalization in neural networks", "abstract": "Despite its success in a wide range of applications, characterizing the generalization properties of stochastic gradient descent (SGD) in non-convex deep learning problems is still an important challenge. While modeling the trajectories of SGD via stochastic differential equations (SDE) under heavy-tailed gradient noise has recently shed light over several peculiar characteristics of SGD, a rigorous treatment of the generalization properties of such SDEs in a learning theoretical framework is still missing. Aiming to bridge this gap, in this paper, we prove generalization bounds for SGD under the assumption that its trajectories can be well-approximated by a Feller process, which defines a rich class of Markov processes that include several recent SDE representations (both Brownian or heavy-tailed) as its special case. We show that the generalization error can be controlled by the Hausdorff dimension of the trajectories, which is intimately linked to the tail behavior of the driving process. Our results imply that heavier-tailed processes should achieve better generalization; hence, the tail-index of the process can be used as a notion of \u2018capacity metric\u2019. We support our theory with experiments on deep neural networks illustrating that the proposed capacity metric accurately estimates the generalization error, and it does not necessarily grow with the number of parameters unlike the existing capacity metrics in the literature.", "year": 2020, "ssId": "739c2181f7894050a06b53b41ac5debe8ffc4829", "arXivId": "2006.09313", "link": "https://arxiv.org/pdf/2006.09313.pdf", "openAccess": true, "authors": ["Umut Simsekli", "Ozan Sener", "George Deligiannidis", "Murat A. Erdogdu"]}}, "04f8f739924a19c01d196a48783b914554ac0fe5": {"id": "04f8f739924a19c01d196a48783b914554ac0fe5", "content": {"title": "Convex optimization based on global lower second-order models", "abstract": "In this paper, we present new second-order algorithms for composite convex optimization, called Contracting-domain Newton methods. These algorithms are affine-invariant and based on global second-order lower approximation for the smooth component of the objective. Our approach has an interpretation both as a second-order generalization of the conditional gradient method, or as a variant of trust-region scheme. Under the assumption, that the problem domain is bounded, we prove $\\mathcal{O}(1/k^{2})$ global rate of convergence in functional residual, where $k$ is the iteration counter, minimizing convex functions with Lipschitz continuous Hessian. This significantly improves the previously known bound $\\mathcal{O}(1/k)$ for this type of algorithms. Additionally, we propose a stochastic extension of our method, and present computational results for solving empirical risk minimization problem.", "year": 2020, "ssId": "04f8f739924a19c01d196a48783b914554ac0fe5", "arXivId": "2006.08518", "link": "https://arxiv.org/pdf/2006.08518.pdf", "openAccess": true, "authors": ["N. Doikov", "Y. Nesterov"]}}, "c933fed82e7b5cbf7230f0f970b69590b40f86a1": {"id": "c933fed82e7b5cbf7230f0f970b69590b40f86a1", "content": {"title": "A Unified Theory of Decentralized SGD with Changing Topology and Local Updates", "abstract": "Decentralized stochastic optimization methods have gained a lot of attention recently, mainly because of their cheap per iteration cost, data locality, and their communication-efficiency. In this paper we introduce a unified convergence analysis that covers a large variety of decentralized SGD methods which so far have required different intuitions, have different applications, and which have been developed separately in various communities. \nOur algorithmic framework covers local SGD updates and synchronous and pairwise gossip updates on adaptive network topology. We derive universal convergence rates for smooth (convex and non-convex) problems and the rates interpolate between the heterogeneous (non-identically distributed data) and iid-data settings, recovering linear convergence rates in many special cases, for instance for over-parametrized models. Our proofs rely on weak assumptions (typically improving over prior work in several aspects) and recover (and improve) the best known complexity results for a host of important scenarios, such as for instance coorperative SGD and federated averaging (local SGD).", "year": 2020, "ssId": "c933fed82e7b5cbf7230f0f970b69590b40f86a1", "arXivId": "2003.10422", "link": "https://arxiv.org/pdf/2003.10422.pdf", "openAccess": true, "authors": ["Anastasia Koloskova", "Nicolas Loizou", "Sadra Boreiri", "Martin Jaggi", "Sebastian U. Stich"]}}, "598e2d69d3573adae1f0e3bbe54d10c43f48e0b0": {"id": "598e2d69d3573adae1f0e3bbe54d10c43f48e0b0", "content": {"title": "Stochastic optimization under distributional drift", "abstract": "We consider the problem of minimizing a convex function that is evolving according to unknown and possibly stochastic dynamics, which may depend jointly on time and on the decision variable itself. Such problems abound in the machine learning and signal processing literature, under the names of concept drift, stochastic tracking, and performative prediction. We provide novel non-asymptotic convergence guarantees for stochastic algorithms with iterate averaging, focusing on bounds valid both in expectation and with high probability. The efficiency estimates we obtain clearly decouple the contributions of optimization error, gradient noise, and time drift. Notably, we show that the tracking efficiency of the proximal stochastic gradient method depends only logarithmically on the initialization quality, when equipped with a stepdecay schedule. Numerical experiments illustrate our results.", "year": 2021, "ssId": "598e2d69d3573adae1f0e3bbe54d10c43f48e0b0", "arXivId": "2108.07356", "link": "https://arxiv.org/pdf/2108.07356.pdf", "openAccess": true, "authors": ["Joshua Cutler", "D. Drusvyatskiy", "Z. Harchaoui"]}}, "ffc211476f2e40e79466ffc198c919a97da3bb76": {"id": "ffc211476f2e40e79466ffc198c919a97da3bb76", "content": {"title": "QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning", "abstract": "In many real-world settings, a team of agents must coordinate their behaviour while acting in a decentralised way. At the same time, it is often possible to train the agents in a centralised fashion in a simulated or laboratory setting, where global state information is available and communication constraints are lifted. Learning joint action-values conditioned on extra state information is an attractive way to exploit centralised learning, but the best strategy for then extracting decentralised policies is unclear. Our solution is QMIX, a novel value-based method that can train decentralised policies in a centralised end-to-end fashion. QMIX employs a network that estimates joint action-values as a complex non-linear combination of per-agent values that condition only on local observations. We structurally enforce that the joint-action value is monotonic in the per-agent values, which allows tractable maximisation of the joint action-value in off-policy learning, and guarantees consistency between the centralised and decentralised policies. We evaluate QMIX on a challenging set of StarCraft II micromanagement tasks, and show that QMIX significantly outperforms existing value-based multi-agent reinforcement learning methods.", "year": 2018, "ssId": "ffc211476f2e40e79466ffc198c919a97da3bb76", "arXivId": "1803.11485", "link": "https://arxiv.org/pdf/1803.11485.pdf", "openAccess": true, "authors": ["Tabish Rashid", "Mikayel Samvelyan", "C. S. D. Witt", "Gregory Farquhar", "Jakob N. Foerster", "S. Whiteson"]}}, "e1bb329621de73d08c47beae9b5439a1c244eb1a": {"id": "e1bb329621de73d08c47beae9b5439a1c244eb1a", "content": {"title": "CSI: Novelty Detection via Contrastive Learning on Distributionally Shifted Instances", "abstract": "Novelty detection, i.e., identifying whether a given sample is drawn from outside the training distribution, is essential for reliable machine learning. To this end, there have been many attempts at learning a representation well-suited for novelty detection and designing a score based on such representation. In this paper, we propose a simple, yet effective method named contrasting shifted instances (CSI), inspired by the recent success on contrastive learning of visual representations. Specifically, in addition to contrasting a given sample with other instances as in conventional contrastive learning methods, our training scheme contrasts the sample with distributionally-shifted augmentations of itself. Based on this, we propose a new detection score that is specific to the proposed training scheme. Our experiments demonstrate the superiority of our method under various novelty detection scenarios, including unlabeled one-class, unlabeled multi-class and labeled multi-class settings, with various image benchmark datasets.", "year": 2020, "ssId": "e1bb329621de73d08c47beae9b5439a1c244eb1a", "arXivId": "2007.08176", "link": "https://arxiv.org/pdf/2007.08176.pdf", "openAccess": true, "authors": ["Jihoon Tack", "Sangwoo Mo", "Jongheon Jeong", "Jinwoo Shin"]}}, "d415b724fbc35afcc8dd91738123edfa6a5db634": {"id": "d415b724fbc35afcc8dd91738123edfa6a5db634", "content": {"title": "Implementation Matters in Deep Policy Gradients: A Case Study on PPO and TRPO", "abstract": "We study the roots of algorithmic progress in deep policy gradient algorithms through a case study on two popular algorithms: Proximal Policy Optimization (PPO) and Trust Region Policy Optimization (TRPO). Specifically, we investigate the consequences of \"code-level optimizations:\" algorithm augmentations found only in implementations or described as auxiliary details to the core algorithm. Seemingly of secondary importance, such optimizations turn out to have a major impact on agent behavior. Our results show that they (a) are responsible for most of PPO's gain in cumulative reward over TRPO, and (b) fundamentally change how RL methods function. These insights show the difficulty and importance of attributing performance gains in deep reinforcement learning. Code for reproducing our results is available at this https URL .", "year": 2020, "ssId": "d415b724fbc35afcc8dd91738123edfa6a5db634", "arXivId": "2005.12729", "link": "https://arxiv.org/pdf/2005.12729.pdf", "openAccess": true, "authors": ["Logan Engstrom", "Andrew Ilyas", "Shibani Santurkar", "Dimitris Tsipras", "F. Janoos", "L. Rudolph", "A. Madry"]}}, "81e57827bebb04305cc9e6c85e96c83951244ec2": {"id": "81e57827bebb04305cc9e6c85e96c83951244ec2", "content": {"title": "Predicting Polypharmacy Side-effects Using Knowledge Graph Embeddings.", "abstract": "Polypharmacy is the use of drug combinations and is commonly used for treating complex and terminal diseases. Despite its effectiveness in many cases, it poses high risks of adverse side effects. Polypharmacy side-effects occur due to unwanted interactions of combined drugs, and they can cause severe complications to patients which results in increasing the risks of morbidity and leading to new mortalities. The use of drug polypharmacy is currently in its early stages; thus, the knowledge of their probable side-effects is limited. This encouraged multiple works to investigate machine learning techniques to efficiently and reliably predict adverse effects of drug combinations. In this context, the Decagon model is known to provide state-of-the-art results. It models polypharmacy side-effect data as a knowledge graph and formulates finding possible adverse effects as a link prediction task over the knowledge graph. The link prediction is solved using an embedding model based on graph convolutions. Despite its effectiveness, the Decagon approach still suffers from a high rate of false positives. In this work, we propose a new knowledge graph embedding technique that uses multi-part embedding vectors to predict polypharmacy side-effects. Like in the Decagon model, we model polypharmacy side effects as a knowledge graph. However, we perform the link prediction task using an approach based on tensor decomposition. Our experimental evaluation shows that our approach outperforms the Decagon model with 12% and 16% margins in terms of the area under the ROC and precision recall curves, respectively.", "year": 2020, "ssId": "81e57827bebb04305cc9e6c85e96c83951244ec2", "arXivId": null, "link": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233093/pdf/3269180.pdf", "openAccess": true, "authors": ["V. Nov\u00e1\u010dek", "Sameh K. Mohamed"]}}, "66cbda3e730285cb572c4792edcef209af32c564": {"id": "66cbda3e730285cb572c4792edcef209af32c564", "content": {"title": "Distilling Knowledge from Reader to Retriever for Question Answering", "abstract": "The task of information retrieval is an important component of many natural language processing systems, such as open domain question answering. While traditional methods were based on hand-crafted features, continuous representations based on neural networks recently obtained competitive results. A challenge of using such methods is to obtain supervised data to train the retriever model, corresponding to pairs of query and support documents. In this paper, we propose a technique to learn retriever models for downstream tasks, inspired by knowledge distillation, and which does not require annotated pairs of query and documents. Our approach leverages attention scores of a reader model, used to solve the task based on retrieved documents, to obtain synthetic labels for the retriever. We evaluate our method on question answering, obtaining state-of-the-art results.", "year": 2020, "ssId": "66cbda3e730285cb572c4792edcef209af32c564", "arXivId": "2012.04584", "link": "https://arxiv.org/pdf/2012.04584.pdf", "openAccess": true, "authors": ["Gautier Izacard", "Edouard Grave"]}}, "6954a6bb9d6f3e365b26b694c963ae1d62a03444": {"id": "6954a6bb9d6f3e365b26b694c963ae1d62a03444", "content": {"title": "Fastformer: Additive Attention Can Be All You Need", "abstract": "Transformer is a powerful model for text understanding. However, it is inefficient due to its quadratic complexity to input sequence length. Although there are many methods on Transformer acceleration, they are still either inefficient on long sequences or not effective enough. In this paper, we propose Fastformer, which is an efficient Transformer model based on additive attention. In Fastformer, instead of modeling the pair-wise interactions between tokens, we first use additive attention mechanism to model global contexts, and then further transform each token representation based on its interaction with global context representations. In this way, Fastformer can achieve effective context modeling with linear complexity. Extensive experiments on five datasets show that Fastformer is much more efficient than many existing Transformer models and can meanwhile achieve comparable or even better long text modeling performance.", "year": 2021, "ssId": "6954a6bb9d6f3e365b26b694c963ae1d62a03444", "arXivId": "2108.09084", "link": "https://arxiv.org/pdf/2108.09084.pdf", "openAccess": true, "authors": ["Chuhan Wu", "Fangzhao Wu", "Tao Qi", "Yongfeng Huang"]}}, "61cce75554a6d1bb802f26758c3b0ba97de6918d": {"id": "61cce75554a6d1bb802f26758c3b0ba97de6918d", "content": {"title": "Graph Attention Networks with Positional Embeddings", "abstract": "Graph Neural Networks (GNNs) are deep learning methods which provide the current state of the art performance in node classification tasks. GNNs often assume homophily \u2013 neighboring nodes having similar features and labels\u2013, and therefore may not be at their full potential when dealing with non-homophilic graphs. In this work, we focus on addressing this limitation and enable Graph Attention Networks (GAT), a commonly used variant of GNNs, to explore the structural information within each graph locality. Inspired by the positional encoding in the Transformers, we propose a framework, termed Graph Attentional Networks with Positional Embeddings (GAT-POS), to enhance GATs with positional embeddings which capture structural and positional information of the nodes in the graph. In this framework, the positional embeddings are learned by a model predictive of the graph context, plugged into an enhanced GAT architecture, which is able to leverage both the positional and content information of each node. The model is trained jointly to optimize for the task of node classification as well as the task of predicting graph context. Experimental results show that GAT-POS reaches remarkable improvement compared to strong GNN baselines and recent structural embedding enhanced GNNs on non-homophilic graphs.", "year": 2021, "ssId": "61cce75554a6d1bb802f26758c3b0ba97de6918d", "arXivId": "2105.04037", "link": "https://arxiv.org/pdf/2105.04037.pdf", "openAccess": true, "authors": ["Liheng Ma", "Reihaneh Rabbany", "Adriana Romero-Soriano"]}}, "d63edef60d674408819bb015b64b7f42470e151b": {"id": "d63edef60d674408819bb015b64b7f42470e151b", "content": {"title": "De Novo Molecule Design Through Molecular Generative Model Conditioned by 3D Information of Protein Binding Sites", "abstract": "De novo molecule design through molecular generative model is gaining increasing attention in recent years. Here a novel generative model was proposed by integrating the 3D structural information of the protein binding pocket into the conditional RNN (cRNN) model to control the generation of drug-like molecules. In this model, the composition of protein binding pocket is effectively characterized through a coarse-grain strategy and the three-dimensional information of the pocket can be represented by the sorted eigenvalues of the coulomb matrix (EGCM) of the coarse-grained atoms composing the binding pocket. In current work, we used our EGCM method and a previously reported binding pocket descriptor DeeplyTough to train cRNN models and compared their performance. It has been shown that the molecules generated with the control of protein environment information have a clear tendency on generating compounds with higher similarity to the original X-ray bound ligand than normal RNN model and also achieving better performance in terms of docking scores. Our results demonstrate the potential application of EGCM controlled generative model for the targeted molecule generation and guided exploration on the drug-like chemical space.", "year": 2020, "ssId": "d63edef60d674408819bb015b64b7f42470e151b", "arXivId": null, "link": "https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/60c7537a702a9bbac118c383/original/de-novo-molecule-design-through-molecular-generative-model-conditioned-by-3d-information-of-protein-binding-sites.pdf", "openAccess": true, "authors": ["M. Xu", "T. Ran", "H. Chen"]}}, "b8e49216e5b4a017342b0be5f6fbbd79e690a1c7": {"id": "b8e49216e5b4a017342b0be5f6fbbd79e690a1c7", "content": {"title": "Optimal auctions through deep learning", "abstract": "Designing an incentive compatible auction that maximizes expected revenue is an intricate task. The single-item case was resolved in a seminal piece of work by Myerson in 1981. Even after 30--40 years of intense research, the problem remains unsolved for settings with two or more items. We overview recent research results that show how tools from deep learning are shaping up to become a powerful tool for the automated design of near-optimal auctions auctions. In this approach, an auction is modeled as a multilayer neural network, with optimal auction design framed as a constrained learning problem that can be addressed with standard machine learning pipelines. Through this approach, it is possible to recover to a high degree of accuracy essentially all known analytically derived solutions for multi-item settings and obtain novel mechanisms for settings in which the optimal mechanism is unknown.", "year": 2017, "ssId": "b8e49216e5b4a017342b0be5f6fbbd79e690a1c7", "arXivId": "1706.03459", "link": "https://arxiv.org/pdf/1706.03459.pdf", "openAccess": true, "authors": ["Paul D\u00fctting", "Zhe Feng", "H. Narasimhan", "D. Parkes"]}}, "372657f609f5a95b378a1aad7b08deb9b9b510c0": {"id": "372657f609f5a95b378a1aad7b08deb9b9b510c0", "content": {"title": "Model-based Policy Optimization with Unsupervised Model Adaptation", "abstract": "Model-based reinforcement learning methods learn a dynamics model with real data sampled from the environment and leverage it to generate simulated data to derive an agent. However, due to the potential distribution mismatch between simulated data and real data, this could lead to degraded performance. Despite much effort being devoted to reducing this distribution mismatch, existing methods fail to solve it explicitly. In this paper, we investigate how to bridge the gap between real and simulated data due to inaccurate model estimation for better policy optimization. To begin with, we first derive a lower bound of the expected return, which naturally inspires a bound maximization algorithm by aligning the simulated and real data distributions. To this end, we propose a novel model-based reinforcement learning framework AMPO, which introduces unsupervised model adaptation to minimize the integral probability metric (IPM) between feature distributions from real and simulated data. Instantiating our framework with Wasserstein-1 distance gives a practical model-based approach. Empirically, our approach achieves state-of-the-art performance in terms of sample efficiency on a range of continuous control benchmark tasks.", "year": 2020, "ssId": "372657f609f5a95b378a1aad7b08deb9b9b510c0", "arXivId": "2010.09546", "link": "https://arxiv.org/pdf/2010.09546.pdf", "openAccess": true, "authors": ["Jian Shen", "Han Zhao", "Weinan Zhang", "Yong Yu"]}}, "b209f2acbf0fbc62a3fd19ad6c13abbd46547736": {"id": "b209f2acbf0fbc62a3fd19ad6c13abbd46547736", "content": {"title": "Microsoft Speaker Diarization System for the Voxceleb Speaker Recognition Challenge 2020", "abstract": "This paper describes the Microsoft speaker diarization system for monaural multi-talker recordings in the wild, evaluated at the diarization track of the VoxCeleb Speaker Recognition Challenge (VoxSRC) 2020. We will first explain our system design to address issues in handling real multi-talker recordings. We then present the details of the components, which include Res2Net-based speaker embedding extractor, conformer-based continuous speech separation with leakage filtering, and a modified DOVER (short for Diarization Output Voting Error Reduction) method for system fusion. We evaluate the systems with the data set provided by VoxSRC challenge 2020, which contains real-life multi-talker audio collected from YouTube. Our best system achieves 3.71% and 6.23% of the diarization error rate (DER) on development set and evaluation set, respectively, being ranked the 1st at the diarization track of the challenge.", "year": 2020, "ssId": "b209f2acbf0fbc62a3fd19ad6c13abbd46547736", "arXivId": "2010.11458", "link": "https://arxiv.org/pdf/2010.11458.pdf", "openAccess": true, "authors": ["Xiong Xiao", "Naoyuki Kanda", "Zhuo Chen", "Tianyan Zhou", "T. Yoshioka", "Sanyuan Chen", "Yong Zhao", "Gang Liu", "Yu Wu", "Jian Wu", "Shujie Liu", "Jinyu Li", "Y. Gong"]}}, "4fffa5245d3972077c83614c2a08a47cb578631e": {"id": "4fffa5245d3972077c83614c2a08a47cb578631e", "content": {"title": "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units", "abstract": "Self-supervised approaches for speech representation learning are challenged by three unique problems: (1) there are multiple sound units in each input utterance, (2) there is no lexicon of input sound units during the pre-training phase, and (3) sound units have variable lengths with no explicit segmentation. To deal with these three problems, we propose the Hidden-Unit BERT (HuBERT) approach for self-supervised speech representation learning, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss. A key ingredient of our approach is applying the prediction loss over the masked regions only, which forces the model to learn a combined acoustic and language model over the continuous inputs. HuBERT relies primarily on the consistency of the unsupervised clustering step rather than the intrinsic quality of the assigned cluster labels. Starting with a simple k-means teacher of 100 clusters, and using two iterations of clustering, the HuBERT model either matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech (960 h) and Libri-light (60,000 h) benchmarks with 10 min, 1 h, 10 h, 100 h, and 960 h fine-tuning subsets. Using a 1B parameter model, HuBERT shows up to 19% and 13% relative WER reduction on the more challenging dev-other and test-other evaluation subsets.12", "year": 2021, "ssId": "4fffa5245d3972077c83614c2a08a47cb578631e", "arXivId": "2106.07447", "link": "https://arxiv.org/pdf/2106.07447.pdf", "openAccess": true, "authors": ["Wei-Ning Hsu", "Benjamin Bolte", "Yao-Hung Hubert Tsai", "Kushal Lakhotia", "R. Salakhutdinov", "Abdelrahman Mohamed"]}}, "5f46d8e18138fe572b6fae897475a2ad645a3e1a": {"id": "5f46d8e18138fe572b6fae897475a2ad645a3e1a", "content": {"title": "A Density Ratio Approach to Language Model Fusion in End-to-End Automatic Speech Recognition", "abstract": "This article describes a density ratio approach to integrating external Language Models (LMs) into end-to-end models for Automatic Speech Recognition (ASR). Applied to a Recurrent Neural Network Transducer (RNN-T) ASR model trained on a given domain, a matched in-domain RNN-LM, and a target domain RNN-LM, the proposed method uses Bayes' Rule to define RNN-T posteriors for the target domain, in a manner directly analogous to the classic hybrid model for ASR based on Deep Neural Networks (DNNs) or LSTMs in the Hidden Markov Model (HMM) framework (Bourlard & Morgan, 1994). The proposed approach is evaluated in cross-domain and limited-data scenarios, for which a significant amount of target domain text data is used for LM training, but only limited (or no) {audio, transcript} training data pairs are used to train the RNN-T. Specifically, an RNN-T model trained on paired audio & transcript data from YouTube is evaluated for its ability to generalize to Voice Search data. The Density Ratio method was found to consistently outperform the dominant approach to LM and end-to-end ASR integration, Shallow Fusion.", "year": 2019, "ssId": "5f46d8e18138fe572b6fae897475a2ad645a3e1a", "arXivId": "2002.11268", "link": "https://arxiv.org/pdf/2002.11268.pdf", "openAccess": true, "authors": ["E. McDermott", "H. Sak", "Ehsan Variani"]}}, "7099d5a4b2d4ed47905071fc23aff08580401e42": {"id": "7099d5a4b2d4ed47905071fc23aff08580401e42", "content": {"title": "Echo State Speech Recognition", "abstract": "We propose automatic speech recognition (ASR) models inspired by echo state network (ESN) [1], in which a subset of recurrent neural networks (RNN) layers in the models are randomly initialized and untrained. Our study focuses on RNN-T and Conformer models, and we show that model quality does not drop even when the decoder is fully randomized. Furthermore, such models can be trained more efficiently as the decoders do not require to be updated. By contrast, randomizing encoders hurts model quality, indicating that optimizing encoders and learn proper representations for acoustic inputs are more vital for speech recognition. Overall, we challenge the common practice of training ASR models for all components, and demonstrate that ESN-based models can perform equally well but enable more efficient training and storage than fully-trainable counterparts.", "year": 2021, "ssId": "7099d5a4b2d4ed47905071fc23aff08580401e42", "arXivId": "2102.09114", "link": "https://arxiv.org/pdf/2102.09114.pdf", "openAccess": true, "authors": ["H. Shrivastava", "Ankush Garg", "Yuan Cao", "Yu Zhang", "T. Sainath"]}}, "49a049dc85e2380dde80501a984878341dd8efdf": {"id": "49a049dc85e2380dde80501a984878341dd8efdf", "content": {"title": "wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations", "abstract": "We show for the first time that learning powerful representations from speech audio alone followed by fine-tuning on transcribed speech can outperform the best semi-supervised methods while being conceptually simpler. wav2vec 2.0 masks the speech input in the latent space and solves a contrastive task defined over a quantization of the latent representations which are jointly learned. Experiments using all labeled data of Librispeech achieve 1.8/3.3 WER on the clean/other test sets. When lowering the amount of labeled data to one hour, wav2vec 2.0 outperforms the previous state of the art on the 100 hour subset while using 100 times less labeled data. Using just ten minutes of labeled data and pre-training on 53k hours of unlabeled data still achieves 4.8/8.2 WER. This demonstrates the feasibility of speech recognition with limited amounts of labeled data.", "year": 2020, "ssId": "49a049dc85e2380dde80501a984878341dd8efdf", "arXivId": "2006.11477", "link": "https://arxiv.org/pdf/2006.11477.pdf", "openAccess": true, "authors": ["Alexei Baevski", "Henry Zhou", "Abdel-rahman Mohamed", "Michael Auli"]}}, "c8a5d05cb741b3448ec4106d2006ae24a7a401b4": {"id": "c8a5d05cb741b3448ec4106d2006ae24a7a401b4", "content": {"title": "FastEmit: Low-Latency Streaming ASR with Sequence-Level Emission Regularization", "abstract": "Streaming automatic speech recognition (ASR) aims to emit each hypothesized word as quickly and accurately as possible. However, emitting fast without degrading quality, as measured by word error rate (WER), is highly challenging. Existing approaches including Early and Late Penalties [1] and Constrained Alignments [2], [3] penalize emission delay by manipulating per-token or per-frame probability prediction in sequence transducer models [4]. While being successful in reducing delay, these approaches suffer from significant accuracy regression and also require additional word alignment information from an existing model. In this work, we propose a sequence-level emission regularization method, named FastEmit, that applies latency regularization directly on per-sequence probability in training transducer models, and does not require any alignment. We demonstrate that FastEmit is more suitable to the sequence-level optimization of transducer models [4] for streaming ASR by applying it on various end-to-end streaming ASR networks including RNN-Transducer [5], Transformer-Transducer [6], [7], ConvNet-Transducer [8] and Conformer-Transducer [9]. We achieve 150 ~ 300ms latency reduction with significantly better accuracy over previous techniques on a Voice Search test set. FastEmit also improves streaming ASR accuracy from 4.4%/8.9% to 3.1%/7.5% WER, meanwhile reduces 90th percentile latency from 210ms to only 30ms on LibriSpeech.", "year": 2020, "ssId": "c8a5d05cb741b3448ec4106d2006ae24a7a401b4", "arXivId": "2010.11148", "link": "https://arxiv.org/pdf/2010.11148.pdf", "openAccess": true, "authors": ["Jiahui Yu", "C. Chiu", "Bo Li", "Shuo-yiin Chang", "T. Sainath", "Yanzhang He", "A. Narayanan", "Wei Han", "Anmol Gulati", "Yonghui Wu", "Ruoming Pang"]}}, "2660dbba723573266edb2a0a4929e6847ae83212": {"id": "2660dbba723573266edb2a0a4929e6847ae83212", "content": {"title": "Advancing RNN Transducer Technology for Speech Recognition", "abstract": "We investigate a set of techniques for RNN Transducers (RNN-Ts) that were instrumental in lowering the word error rate on three different tasks (Switchboard 300 hours, conversational Spanish 780 hours and conversational Italian 900 hours). The techniques pertain to architectural changes, speaker adaptation, language model fusion, model combination and general training recipe. First, we introduce a novel multiplicative integration of the encoder and prediction network vectors in the joint network (as opposed to additive). Second, we discuss the applicability of i-vector speaker adaptation to RNN-Ts in conjunction with data perturbation. Third, we explore the effectiveness of the recently proposed density ratio language model fusion for these tasks. Last but not least, we describe the other components of our training recipe and their effect on recognition performance. We report a 5.9% and 12.5% word error rate on the Switchboard and CallHome test sets of the NIST Hub5 2000 evaluation and a 12.7% WER on the Mozilla CommonVoice Italian test set.", "year": 2021, "ssId": "2660dbba723573266edb2a0a4929e6847ae83212", "arXivId": "2103.09935", "link": "https://arxiv.org/pdf/2103.09935.pdf", "openAccess": true, "authors": ["G. Saon", "Zoltan Tueske", "Daniel Bola\u00f1os", "Brian Kingsbury"]}}, "9112be1801598125d463febb96a525227c32acc1": {"id": "9112be1801598125d463febb96a525227c32acc1", "content": {"title": "Differentiable Weighted Finite-State Transducers", "abstract": "We introduce a framework for automatic differentiation with weighted finite-state transducers (WFSTs) allowing them to be used dynamically at training time. Through the separation of graphs from operations on graphs, this framework enables the exploration of new structured loss functions which in turn eases the encoding of prior knowledge into learning algorithms. We show how the framework can combine pruning and back-off in transition models with various sequence-level loss functions. We also show how to learn over the latent decomposition of phrases into word pieces. Finally, to demonstrate that WFSTs can be used in the interior of a deep neural network, we propose a convolutional WFST layer which maps lower-level representations to higher-level representations and can be used as a drop-in replacement for a traditional convolution. We validate these algorithms with experiments in handwriting recognition and speech recognition.", "year": 2020, "ssId": "9112be1801598125d463febb96a525227c32acc1", "arXivId": "2010.01003", "link": "https://arxiv.org/pdf/2010.01003.pdf", "openAccess": true, "authors": ["Awni Y. Hannun", "Vineel Pratap", "Jacob Kahn", "Wei-Ning Hsu"]}}, "d0a6b70c9dc1942169f48211d47843732c57a3a9": {"id": "d0a6b70c9dc1942169f48211d47843732c57a3a9", "content": {"title": "Environment-agnostic Multitask Learning for Natural Language Grounded Navigation", "abstract": "Recent research efforts enable study for natural language grounded navigation in photo-realistic environments, e.g., following natural language instructions or dialog. However, existing methods tend to overfit training data in seen environments and fail to generalize well in previously unseen environments. In order to close the gap between seen and unseen environments, we aim at learning a generalized navigation model from two novel perspectives: (1) we introduce a multitask navigation model that can be seamlessly trained on both Vision-Language Navigation (VLN) and Navigation from Dialog History (NDH) tasks, which benefits from richer natural language guidance and effectively transfers knowledge across tasks; (2) we propose to learn environment-agnostic representations for the navigation policy that are invariant among the environments seen during training, thus generalizing better on unseen environments. Extensive experiments show that our navigation model trained using environment-agnostic multitask learning significantly reduces the performance gap between seen and unseen environments and outperforms the baselines on unseen environments by 16% (relative measure on success rate) on VLN and 120% (goal progress) on NDH, establishing a new state-of-the-art for the NDH task. The code for training the navigation model using environment-agnostic multitask learning is available at this https URL.", "year": 2020, "ssId": "d0a6b70c9dc1942169f48211d47843732c57a3a9", "arXivId": "2003.00443", "link": "https://arxiv.org/pdf/2003.00443.pdf", "openAccess": true, "authors": ["Xin Wang", "Vihan Jain", "Eugene Ie", "William Yang Wang", "Zornitsa Kozareva", "Sujith Ravi"]}}, "d301054c2819e1a21480800fdabbe5ae909abe09": {"id": "d301054c2819e1a21480800fdabbe5ae909abe09", "content": {"title": "Leveraging Language to Learn Program Abstractions and Search Heuristics", "abstract": "Inductive program synthesis, or inferring programs from examples of desired behavior, offers a general paradigm for building interpretable, ro-bust, and generalizable machine learning systems. Effective program synthesis depends on two key ingredients: a strong library of functions from which to build programs, and an ef\ufb01cient search strategy for \ufb01nding programs that solve a given task. We introduce LAPS (Language for Abstraction and Program Search), a technique for using natural language annotations to guide joint learning of libraries and neurally-guided search models for synthesis. When integrated into a state-of-the-art library learning system (DreamCoder), LAPS produces higher-quality libraries and improves search ef\ufb01ciency and generalization on three domains \u2013 string editing, image composition, and abstract reasoning about scenes \u2013 even when no natural language hints are available at test time.", "year": 2021, "ssId": "d301054c2819e1a21480800fdabbe5ae909abe09", "arXivId": "2106.11053", "link": "https://arxiv.org/pdf/2106.11053.pdf", "openAccess": true, "authors": ["Catherine Wong", "Kevin Ellis", "J. Tenenbaum", "Jacob Andreas"]}}, "f41e6c832c9e0d5360b66ee7681d3b1ffd2d9c3d": {"id": "f41e6c832c9e0d5360b66ee7681d3b1ffd2d9c3d", "content": {"title": "Hierarchical Task Learning from Language Instructions with Unified Transformers and Self-Monitoring", "abstract": "Despite recent progress, learning new tasks through language instructions remains an extremely challenging problem. On the ALFRED benchmark for task learning, the published state-of-the-art system only achieves a task success rate of less than 10% in an unseen environment, compared to the human performance of over 90%. To address this issue, this paper takes a closer look at task learning. In a departure from a widely applied end-toend architecture, we decomposed task learning into three sub-problems: sub-goal planning, scene navigation, and object manipulation; and developed a model HiTUT1 (stands for Hierarchical Tasks via Unified Transformers) that addresses each sub-problem in a unified manner to learn a hierarchical task structure. On the ALFRED benchmark, HiTUT has achieved the best performance with a remarkably higher generalization ability. In the unseen environment, HiTUT achieves over 160% performance gain in success rate compared to the previous state of the art. The explicit representation of task structures also enables an in-depth understanding of the nature of the problem and the ability of the agent, which provides insight for future benchmark development and evaluation.", "year": 2021, "ssId": "f41e6c832c9e0d5360b66ee7681d3b1ffd2d9c3d", "arXivId": "2106.03427", "link": "https://arxiv.org/pdf/2106.03427.pdf", "openAccess": true, "authors": ["Yichi Zhang", "J. Chai"]}}, "6ec6fa4e34200e13d80ee79b95d1cc6ec0f6b424": {"id": "6ec6fa4e34200e13d80ee79b95d1cc6ec0f6b424", "content": {"title": "TEACh: Task-driven Embodied Agents that Chat", "abstract": "Robots operating in human spaces must be able to engage in natural language interaction, both understanding and executing instructions, and using conversation to resolve ambiguity and correct mistakes. To study this, we introduce TEACh, a dataset of over 3,000 human\u2013human, interactive dialogues to complete household tasks in simulation. A Commander with access to oracle information about a task communicates in natural language with a Follower. The Follower navigates through and interacts with the environment to complete tasks varying in complexity from MAKE COFFEE to PREPARE BREAKFAST, asking questions and getting additional information from the Commander. We propose three benchmarks using TEACh to study embodied intelligence challenges, and we evaluate initial models\u2019 abilities in dialogue understanding, language grounding, and task execution.", "year": 2021, "ssId": "6ec6fa4e34200e13d80ee79b95d1cc6ec0f6b424", "arXivId": "2110.00534", "link": "https://arxiv.org/pdf/2110.00534.pdf", "openAccess": true, "authors": ["Aishwarya Padmakumar", "Jesse Thomason", "Ayush Shrivastava", "P. Lange", "Anjali Narayan-Chen", "Spandana Gella", "Robinson Piramithu", "G. Tur", "Dilek Z. Hakkani-T\u00fcr"]}}, "3f0f6c19c6f5d4e4d5066984c5f3e922a2c2ff85": {"id": "3f0f6c19c6f5d4e4d5066984c5f3e922a2c2ff85", "content": {"title": "ELLA: Exploration through Learned Language Abstraction", "abstract": "Building agents capable of understanding language instructions is critical to effective and robust human-AI collaboration. Recent work focuses on training these instruction following agents via reinforcement learning in environments with synthetic language; however, these instructions often define long-horizon, sparsereward tasks, and learning policies requires many episodes of experience. To this end, we introduce ELLA: Exploration through Learned Language Abstraction, a reward shaping approach that correlates high-level instructions with simpler low-level instructions to enrich the sparse rewards afforded by the environment. ELLA has two key elements: 1) A termination classifier that identifies when agents complete low-level instructions, and 2) A relevance classifier that correlates low-level instructions with success on high-level tasks. We learn the termination classifier offline from pairs of instructions and terminal states. Notably, in departure from prior work in language and abstraction, we learn the relevance classifier online, without relying on an explicit decomposition of high-level instructions to low-level instructions. On a suite of complex grid world environments with varying instruction complexities and reward sparsity, ELLA shows a significant gain in sample efficiency across several environments compared to competitive language-based reward shaping and no-shaping methods.", "year": 2021, "ssId": "3f0f6c19c6f5d4e4d5066984c5f3e922a2c2ff85", "arXivId": "2103.05825", "link": "https://arxiv.org/pdf/2103.05825.pdf", "openAccess": true, "authors": ["Suvir P. Mirchandani", "Siddharth Karamcheti", "Dorsa Sadigh"]}}, "69ee9b3a915951cc84b74599a3a2699a66d4004f": {"id": "69ee9b3a915951cc84b74599a3a2699a66d4004f", "content": {"title": "CLIPort: What and Where Pathways for Robotic Manipulation", "abstract": "How can we imbue robots with the ability to manipulate objects pre1 cisely but also to reason about them in terms of abstract concepts? Recent works 2 in manipulation have shown that end-to-end networks can learn dexterous skills 3 that require precise spatial reasoning, but these methods often fail to generalize to 4 new goals or quickly learn transferable concepts. In parallel, there has been great 5 progress in learning generalizable semantic representations for vision and lan6 guage by training on large-scale internet data, however these representations lack 7 the spatial understanding necessary for fine-grained manipulation. To this end, we 8 propose a framework that combines the best of both worlds: a two-stream archi9 tecture with semantic (what) and spatial (where) pathways for vision-based ma10 nipulation. Specifically, we present CLIPORT, a language-conditioned imitation11 learning agent that combines the broad semantic understanding of CLIP [1] with 12 the spatial precision of Transporter [2]. Our end-to-end framework is capable of 13 solving a variety of language-specified tabletop tasks from packing unseen objects 14 to folding cloths, all without any explicit representations of object poses, instance 15 segmentations, history, symbolic states, or syntactic structures. Experiments in 16 simulation and hardware show that our approach is data efficient in few-shot set17 tings and generalizes effectively to seen and unseen semantic concepts. We even 18 learn one multi-task policy for 10 simulated and 9 real-world tasks that shows 19 better or comparable performance to single-task models. 20", "year": 2021, "ssId": "69ee9b3a915951cc84b74599a3a2699a66d4004f", "arXivId": "2109.12098", "link": "https://arxiv.org/pdf/2109.12098.pdf", "openAccess": true, "authors": ["Mohit Shridhar", "Lucas Manuelli", "D. Fox"]}}, "6536f36648d39f0f9f6105562f76704fcc0b19e8": {"id": "6536f36648d39f0f9f6105562f76704fcc0b19e8", "content": {"title": "A Persistent Spatial Semantic Representation for High-level Natural Language Instruction Execution", "abstract": "Natural language provides an accessible and expressive interface to specify long-term tasks for robotic agents. However, non-experts are likely to specify such tasks with high-level instructions, which abstract over specific robot actions through several layers of abstraction. We propose that key to bridging this gap between language and robot actions over long execution horizons are persistent representations. We propose a persistent spatial semantic representation method, and show how it enables building an agent that performs hierarchical reasoning to effectively execute long-term tasks. We evaluate our approach on the ALFRED benchmark and achieve state-of-the-art results, despite completely avoiding the commonly used step-by-step instructions. https://hlsm-alfred. github.io/", "year": 2021, "ssId": "6536f36648d39f0f9f6105562f76704fcc0b19e8", "arXivId": "2107.05612", "link": "https://arxiv.org/pdf/2107.05612.pdf", "openAccess": true, "authors": ["Valts Blukis", "Chris Paxton", "D. Fox", "Animesh Garg", "Yoav Artzi"]}}, "ddd74358d7e11535ee77e2c323dd662d115a0f20": {"id": "ddd74358d7e11535ee77e2c323dd662d115a0f20", "content": {"title": "Few-shot Object Grounding and Mapping for Natural Language Robot Instruction Following", "abstract": "We study the problem of learning a robot policy to follow natural language instructions that can be easily extended to reason about new objects. We introduce a few-shot language-conditioned object grounding method trained from augmented reality data that uses exemplars to identify objects and align them to their mentions in instructions. We present a learned map representation that encodes object locations and their instructed use, and construct it from our few-shot grounding output. We integrate this mapping approach into an instruction-following policy, thereby allowing it to reason about previously unseen objects at test-time by simply adding exemplars. We evaluate on the task of learning to map raw observations and instructions to continuous control of a physical quadcopter. Our approach significantly outperforms the prior state of the art in the presence of new objects, even when the prior approach observes all objects during training.", "year": 2020, "ssId": "ddd74358d7e11535ee77e2c323dd662d115a0f20", "arXivId": "2011.07384", "link": "https://arxiv.org/pdf/2011.07384.pdf", "openAccess": true, "authors": ["Valts Blukis", "Ross A. Knepper", "Yoav Artzi"]}}, "54a13bcc9613dcaa76fb25fbe96572f376cfcca9": {"id": "54a13bcc9613dcaa76fb25fbe96572f376cfcca9", "content": {"title": "Adafactor: Adaptive Learning Rates with Sublinear Memory Cost", "abstract": "In several recently proposed stochastic optimization methods (e.g. RMSProp, Adam, Adadelta), parameter updates are scaled by the inverse square roots of exponential moving averages of squared past gradients. Maintaining these per-parameter second-moment estimators requires memory equal to the number of parameters. For the case of neural network weight matrices, we propose maintaining only the per-row and per-column sums of these moving averages, and estimating the per-parameter second moments based on these sums. We demonstrate empirically that this method produces similar results to the baseline. Secondly, we show that adaptive methods can produce larger-than-desired updates when the decay rate of the second moment accumulator is too slow. We propose update clipping and a gradually increasing decay rate scheme as remedies. Combining these methods and dropping momentum, we achieve comparable results to the published Adam regime in training the Transformer model on the WMT 2014 English-German machine translation task, while using very little auxiliary storage in the optimizer. Finally, we propose scaling the parameter updates based on the scale of the parameters themselves.", "year": 2018, "ssId": "54a13bcc9613dcaa76fb25fbe96572f376cfcca9", "arXivId": "1804.04235", "link": "https://arxiv.org/pdf/1804.04235.pdf", "openAccess": true, "authors": ["Noam M. Shazeer", "Mitchell Stern"]}}, "a0ab4106dabd6bc067c7b3e4db06807e2c0f6036": {"id": "a0ab4106dabd6bc067c7b3e4db06807e2c0f6036", "content": {"title": "NLP From Scratch Without Large-Scale Pretraining: A Simple and Efficient Framework", "abstract": "Pretrained language models have become the standard approach for many NLP tasks due to strong performance, but they are very expensive to train. We propose a simple and efficient learning framework TLM that does not rely on large-scale pretraining1. Given some labeled task data and a large general corpus, TLM uses task data as queries to retrieve a tiny subset of the general corpus and jointly optimizes the task objective and the language modeling objective from scratch. On eight classification datasets in four domains, TLM achieves results better than or similar to pretrained language models (e.g., RoBERTa-Large) while reducing the training FLOPs by two orders of magnitude. With high accuracy and efficiency, we hope TLM will contribute to democratizing NLP and expediting its development2.", "year": 2021, "ssId": "a0ab4106dabd6bc067c7b3e4db06807e2c0f6036", "arXivId": "2111.04130", "link": "https://arxiv.org/pdf/2111.04130.pdf", "openAccess": true, "authors": ["Xingcheng Yao", "Yanan Zheng", "Xiaocong Yang", "Zhilin Yang"]}}, "d31b5b60e1b3af84cd977da8db0ed4faeb79e7f7": {"id": "d31b5b60e1b3af84cd977da8db0ed4faeb79e7f7", "content": {"title": "TextSETTR: Few-Shot Text Style Extraction and Tunable Targeted Restyling", "abstract": "We present a novel approach to the problem of text style transfer. Unlike previous approaches requiring style-labeled training data, our method makes use of readily-available unlabeled text by relying on the implicit connection in style between adjacent sentences, and uses labeled data only at inference time. We adapt T5 (Raffel et al., 2020), a strong pretrained text-to-text model, to extract a style vector from text and use it to condition the decoder to perform style transfer. As our label-free training results in a style vector space encoding many facets of style, we recast transfers as \u201ctargeted restyling\u201d vector operations that adjust specific attributes of the input while preserving others. We demonstrate that training on unlabeled Amazon reviews data results in a model that is competitive on sentiment transfer, even compared to models trained fully on labeled data. Furthermore, applying our novel method to a diverse corpus of unlabeled web text results in a single model capable of transferring along multiple dimensions of style (dialect, emotiveness, formality, politeness, sentiment) despite no additional training and using only a handful of exemplars at inference time.", "year": 2020, "ssId": "d31b5b60e1b3af84cd977da8db0ed4faeb79e7f7", "arXivId": "2010.03802", "link": "https://arxiv.org/pdf/2010.03802.pdf", "openAccess": true, "authors": ["Parker Riley", "Noah Constant", "Mandy Guo", "Girish Kumar", "David C. Uthus", "Zarana Parekh"]}}, "030d7d7ae48a9f81700b2c1f7cf835235777b8e7": {"id": "030d7d7ae48a9f81700b2c1f7cf835235777b8e7", "content": {"title": "Relevance-guided Supervision for OpenQA with ColBERT", "abstract": "Abstract Systems for Open-Domain Question Answering (OpenQA) generally depend on a retriever for finding candidate passages in a large corpus and a reader for extracting answers from those passages. In much recent work, the retriever is a learned component that uses coarse-grained vector representations of questions and passages. We argue that this modeling choice is insufficiently expressive for dealing with the complexity of natural language questions. To address this, we define ColBERT-QA, which adapts the scalable neural retrieval model ColBERT to OpenQA. ColBERT creates fine-grained interactions between questions and passages. We propose an efficient weak supervision strategy that iteratively uses ColBERT to create its own training data. This greatly improves OpenQA retrieval on Natural Questions, SQuAD, and TriviaQA, and the resulting system attains state-of-the-art extractive OpenQA performance on all three datasets.", "year": 2020, "ssId": "030d7d7ae48a9f81700b2c1f7cf835235777b8e7", "arXivId": "2007.00814", "link": "https://arxiv.org/pdf/2007.00814.pdf", "openAccess": true, "authors": ["O. Khattab", "Christopher Potts", "M. Zaharia"]}}, "15d643f4c27d373aa46f26a760051e76fde81dc2": {"id": "15d643f4c27d373aa46f26a760051e76fde81dc2", "content": {"title": "End-to-End Entity Resolution and Question Answering Using Differentiable Knowledge Graphs", "abstract": "Recently, end-to-end (E2E) trained models for question answering over knowledge graphs (KGQA) have delivered promising results using only a weakly supervised dataset. However, these models are trained and evaluated in a setting where hand-annotated question entities are supplied to the model, leaving the important and non-trivial task of entity resolution (ER) outside the scope of E2E learning. In this work, we extend the boundaries of E2E learning for KGQA to include the training of an ER component. Our model only needs the question text and the answer entities to train, and delivers a stand-alone QA model that does not require an additional ER component to be supplied during runtime. Our approach is fully differentiable, thanks to its reliance on a recent method for building differentiable KGs (Cohen et al., 2020). We evaluate our E2E trained model on two public datasets and show that it comes close to baseline models that use hand-annotated entities.", "year": 2021, "ssId": "15d643f4c27d373aa46f26a760051e76fde81dc2", "arXivId": "2109.05817", "link": "https://arxiv.org/pdf/2109.05817.pdf", "openAccess": true, "authors": ["Armin Oliya", "Amir Saffari", "Priyanka Sen", "Tom Ayoola"]}}, "dbe87b171bfb789e1d22a047aeeee69105e6fd02": {"id": "dbe87b171bfb789e1d22a047aeeee69105e6fd02", "content": {"title": "Sentence-T5: Scalable Sentence Encoders from Pre-trained Text-to-Text Models", "abstract": "We provide the first exploration of text-to-text transformers (T5) sentence embeddings. Sentence embeddings are broadly useful for language processing tasks. While T5 achieves impressive performance on language tasks cast as sequence-to-sequence mapping problems, it is unclear how to produce sentence embeddings from encoder-decoder models. We investigate three methods for extracting T5 sentence embeddings: two utilize only the T5 encoder and one uses the full T5 encoder-decoder model. Our encoder-only models outperforms BERTbased sentence embeddings on both transfer tasks and semantic textual similarity (STS). Our encoder-decoder method achieves further improvement on STS. Scaling up T5 from millions to billions of parameters is found to produce consistent improvements on downstream tasks. Finally, we introduce a two-stage contrastive learning approach that achieves a new state-of-art on STS using sentence embeddings, outperforming both Sentence BERT (Reimers and Gurevych, 2019) and SimCSE (Gao et al., 2021).", "year": 2021, "ssId": "dbe87b171bfb789e1d22a047aeeee69105e6fd02", "arXivId": "2108.08877", "link": "https://arxiv.org/pdf/2108.08877.pdf", "openAccess": true, "authors": ["Jianmo Ni", "Gustavo Hern'andez 'Abrego", "Noah Constant", "Ji Ma", "Keith B. Hall", "Daniel Matthew Cer", "Yinfei Yang"]}}, "2270b8628fd8ca67ae39d277f45bc3c38ac63d5f": {"id": "2270b8628fd8ca67ae39d277f45bc3c38ac63d5f", "content": {"title": "Mesh-TensorFlow: Deep Learning for Supercomputers", "abstract": "Batch-splitting (data-parallelism) is the dominant distributed Deep Neural Network (DNN) training strategy, due to its universal applicability and its amenability to Single-Program-Multiple-Data (SPMD) programming. However, batch-splitting suffers from problems including the inability to train very large models (due to memory constraints), high latency, and inefficiency at small batch sizes. All of these can be solved by more general distribution strategies (model-parallelism). Unfortunately, efficient model-parallel algorithms tend to be complicated to discover, describe, and to implement, particularly on large clusters. We introduce Mesh-TensorFlow, a language for specifying a general class of distributed tensor computations. Where data-parallelism can be viewed as splitting tensors and operations along the \"batch\" dimension, in Mesh-TensorFlow, the user can specify any tensor-dimensions to be split across any dimensions of a multi-dimensional mesh of processors. A Mesh-TensorFlow graph compiles into a SPMD program consisting of parallel operations coupled with collective communication primitives such as Allreduce. We use Mesh-TensorFlow to implement an efficient data-parallel, model-parallel version of the Transformer sequence-to-sequence model. Using TPU meshes of up to 512 cores, we train Transformer models with up to 5 billion parameters, surpassing state of the art results on WMT'14 English-to-French translation task and the one-billion-word language modeling benchmark. Mesh-Tensorflow is available at this https URL .", "year": 2018, "ssId": "2270b8628fd8ca67ae39d277f45bc3c38ac63d5f", "arXivId": "1811.02084", "link": "https://arxiv.org/pdf/1811.02084.pdf", "openAccess": true, "authors": ["Noam M. Shazeer", "Youlong Cheng", "Niki Parmar", "Dustin Tran", "Ashish Vaswani", "Penporn Koanantakool", "Peter Hawkins", "HyoukJoong Lee", "Mingsheng Hong", "C. Young", "Ryan Sepassi", "Blake A. Hechtman"]}}, "a1d578646cf42f2f69ee996742af484d03cc9121": {"id": "a1d578646cf42f2f69ee996742af484d03cc9121", "content": {"title": "nmT5 - Is parallel data still relevant for pre-training massively multilingual language models?", "abstract": "Recently, mT5 - a massively multilingual version of T5 - leveraged a unified text-to-text format to attain state-of-the-art results on a wide variety of multilingual NLP tasks. In this paper, we investigate the impact of incorporating parallel data into mT5 pre-training. We find that multi-tasking language modeling with objectives such as machine translation during pre-training is a straightforward way to improve performance on downstream multilingual and cross-lingual tasks. However, the gains start to diminish as the model capacity increases, suggesting that parallel data might not be as essential for larger models. At the same time, even at larger model sizes, we find that pre-training with parallel data still provides benefits in the limited labelled data regime", "year": 2021, "ssId": "a1d578646cf42f2f69ee996742af484d03cc9121", "arXivId": "2106.02171", "link": "https://arxiv.org/pdf/2106.02171.pdf", "openAccess": true, "authors": ["Mihir Kale", "Aditya Siddhant", "Noah Constant", "Melvin Johnson", "Rami Al-Rfou", "Linting Xue"]}}, "1006d191e9eb5b4dbc35fc0bb389328ddc75cba7": {"id": "1006d191e9eb5b4dbc35fc0bb389328ddc75cba7", "content": {"title": "ByT5: Towards a Token-Free Future with Pre-trained Byte-to-Byte Models", "abstract": "Abstract Most widely used pre-trained language models operate on sequences of tokens corresponding to word or subword units. By comparison, token-free models that operate directly on raw text (bytes or characters) have many benefits: They can process text in any language out of the box, they are more robust to noise, and they minimize technical debt by removing complex and error-prone text preprocessing pipelines. Because byte or character sequences are longer than token sequences, past work on token-free models has often introduced new model architectures designed to amortize the cost of operating directly on raw text. In this paper, we show that a standard Transformer architecture can be used with minimal modifications to process byte sequences. We characterize the trade-offs in terms of parameter count, training FLOPs, and inference speed, and show that byte-level models are competitive with their token-level counterparts. We also demonstrate that byte-level models are significantly more robust to noise and perform better on tasks that are sensitive to spelling and pronunciation. As part of our contribution, we release a new set of pre-trained byte-level Transformer models based on the T5 architecture, as well as all code and data used in our experiments.1", "year": 2021, "ssId": "1006d191e9eb5b4dbc35fc0bb389328ddc75cba7", "arXivId": "2105.13626", "link": "https://arxiv.org/pdf/2105.13626.pdf", "openAccess": true, "authors": ["Linting Xue", "Aditya Barua", "Noah Constant", "Rami Al-Rfou", "Sharan Narang", "Mihir Kale", "Adam Roberts", "Colin Raffel"]}}, "c00ba15810496669d47d2ed5b627e6c7d2b1f6aa": {"id": "c00ba15810496669d47d2ed5b627e6c7d2b1f6aa", "content": {"title": "Pre-training via Paraphrasing", "abstract": "We introduce MARGE, a pre-trained sequence-to-sequence model learned with an unsupervised multi-lingual multi-document paraphrasing objective. MARGE provides an alternative to the dominant masked language modeling paradigm, where we self-supervise the reconstruction of target text by retrieving a set of related texts (in many languages) and conditioning on them to maximize the likelihood of generating the original. We show it is possible to jointly learn to do retrieval and reconstruction, given only a random initialization. The objective noisily captures aspects of paraphrase, translation, multi-document summarization, and information retrieval, allowing for strong zero-shot performance on several tasks. For example, with no additional task-specific training we achieve BLEU scores of up to 35.8 for document translation. We further show that fine-tuning gives strong performance on a range of discriminative and generative tasks in many languages, making MARGE the most generally applicable pre-training method to date.", "year": 2020, "ssId": "c00ba15810496669d47d2ed5b627e6c7d2b1f6aa", "arXivId": "2006.15020", "link": "https://arxiv.org/pdf/2006.15020.pdf", "openAccess": true, "authors": ["M. Lewis", "Marjan Ghazvininejad", "Gargi Ghosh", "Armen Aghajanyan", "Sida Wang", "Luke Zettlemoyer"]}}, "3389b6b8ee5a1ef0395df9f383e771650087b828": {"id": "3389b6b8ee5a1ef0395df9f383e771650087b828", "content": {"title": "Rethinking search", "abstract": "When experiencing an information need, users want to engage with a domain expert, but often turn to an information retrieval system, such as a search engine, instead. Classical information retrieval systems do not answer information needs directly, but instead provide references to (hopefully authoritative) answers. Successful question answering systems offer a limited corpus created on-demand by human experts, which is neither timely nor scalable. Pre-trained language models, by contrast, are capable of directly generating prose that may be responsive to an information need, but at present they are dilettantes rather than domain experts - they do not have a true understanding of the world, they are prone to hallucinating, and crucially they are incapable of justifying their utterances by referring to supporting documents in the corpus they were trained over. This paper examines how ideas from classical information retrieval and pre-trained language models can be synthesized and evolved into systems that truly deliver on the promise of domain expert advice.", "year": 2021, "ssId": "3389b6b8ee5a1ef0395df9f383e771650087b828", "arXivId": "2105.02274", "link": "https://arxiv.org/pdf/2105.02274.pdf", "openAccess": true, "authors": ["Donald Metzler", "Yi Tay", "Dara Bahri", "Marc Najork"]}}, "4a19211e077bc4ada685854245ba9fab381cbb06": {"id": "4a19211e077bc4ada685854245ba9fab381cbb06", "content": {"title": "QA4IE: A Question Answering based Framework for Information Extraction", "abstract": "Information Extraction (IE) refers to automatically extracting structured relation tuples from unstructured texts. Common IE solutions, including Relation Extraction (RE) and open IE systems, can hardly handle cross-sentence tuples, and are severely restricted by limited relation types as well as informal relation specifications (e.g., free-text based relation tuples). In order to overcome these weaknesses, we propose a novel IE framework named QA4IE, which leverages the flexible question answering (QA) approaches to produce high quality relation triples across sentences. Based on the framework, we develop a large IE benchmark with high quality human evaluation. This benchmark contains 293K documents, 2M golden relation triples, and 636 relation types. We compare our system with some IE baselines on our benchmark and the results show that our system achieves great improvements.", "year": 2018, "ssId": "4a19211e077bc4ada685854245ba9fab381cbb06", "arXivId": "1804.03396", "link": "https://arxiv.org/pdf/1804.03396.pdf", "openAccess": true, "authors": ["Lin Qiu", "Hao Zhou", "Yanru Qu", "Weinan Zhang", "Suoheng Li", "Shunlin Rong", "Dongyu Ru", "Lihua Qian", "Kewei Tu", "Yong Yu"]}}, "6e2e7df21a5b5457ea4167133a40bc729028250d": {"id": "6e2e7df21a5b5457ea4167133a40bc729028250d", "content": {"title": "Shallow pooling for sparse labels", "abstract": "Recent years have seen enormous gains in core information retrieval tasks, including document and passage ranking. Datasets and leaderboards, and in particular the MS MARCO datasets, illustrate the dramatic improvements achieved by modern neural rankers. When compared with traditional information retrieval test collections, such as those developed by TREC, the MS MARCO datasets employ substantially more queries \u2014 thousands vs. dozens \u2013 with substantially fewer known relevant items per query \u2014 often just one. For example, 94% of the nearly seven thousand queries in the MS MARCO passage ranking development set have only a single known relevant passage, and no query has more than four. Given the sparsity of these relevance labels, the MS MARCO leaderboards track improvements with mean reciprocal rank (MRR). In essence, a relevant item is treated as the \u201cright answer\u201d, with rankers scored on their ability to place this item as high in the ranking as possible. In working with these sparse labels, we have observed that the top items returned by a ranker often appear superior to judged relevant items. Others have reported the same observation. To test this observation, we employed crowdsourced workers to make preference judgments between the top item returned by a modern neural ranking stack and a judged relevant item for the nearly seven thousand queries in the passage ranking development set. The results support our observation. If we imagine a perfect ranker under MRR, with a score of 1 on all queries, our preference judgments indicate that a searcher would prefer the top result from a modern neural ranking stack more frequently than the top result from the imaginary perfect ranker, making our neural ranker \u201cbetter than perfect\u201d. To understand the implications for the leaderboard, we pooled the top document from available runs near the top of the passage ranking leaderboard for over 500 queries. We employed crowdsourced workers to make preference judgments over these pools and re-evaluated the runs. Our results support our concerns that current MS MARCO datasets may no longer be able to recognize genuine improvements in rankers. In future, if rankers are measured against a single \u201cright answer\u201d, this answer should be the best answer or most preferred answer, and maintained with ongoing judgments. Since only the best answer is required, this ongoing maintenance might be performed with shallow pooling. When a previously unjudged document is surfaced as the top item in a ranking, it can directly compared with the previous known best answer. 1 ar X iv :2 10 9. 00 06 2v 1 [ cs .I R ] 3 1 A ug 2 02 1", "year": 2021, "ssId": "6e2e7df21a5b5457ea4167133a40bc729028250d", "arXivId": "2109.00062", "link": "https://arxiv.org/pdf/2109.00062.pdf", "openAccess": true, "authors": ["Negar Arabzadeh", "A. Vtyurina", "Xinyi Yan", "C. Clarke"]}}, "8eda71ecad19cdef6092e76276eba48312ec7063": {"id": "8eda71ecad19cdef6092e76276eba48312ec7063", "content": {"title": "Interpreting Dense Retrieval as Mixture of Topics", "abstract": "Dense Retrieval (DR) reaches state-of-the-art results in first-stage retrieval, but little is known about the mechanisms that contribute to its success. Therefore, in this work, we conduct an interpretation study of recently proposed DR models. Specifically, we first discretize the embeddings output by the document and query encoders. Based on the discrete representations, we analyze the attribution of input tokens. Both qualitative and quantitative experiments are carried out on public test collections. Results suggest that DR models pay attention to different aspects of input and extract various high-level topic representations. Therefore, we can regard the representations learned by DR models as a mixture of high-level topics.", "year": 2021, "ssId": "8eda71ecad19cdef6092e76276eba48312ec7063", "arXivId": "2111.13957", "link": "https://arxiv.org/pdf/2111.13957.pdf", "openAccess": true, "authors": ["Jingtao Zhan", "Jiaxin Mao", "Yiqun Liu", "Jiafeng Guo", "M. Zhang", "Shaoping Ma"]}}, "97906df07855b029b7aae7c2a1c6c5e8df1d531c": {"id": "97906df07855b029b7aae7c2a1c6c5e8df1d531c", "content": {"title": "BERT Rediscovers the Classical NLP Pipeline", "abstract": "Pre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such model, BERT, and aim to quantify where linguistic information is captured within the network. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.", "year": 2019, "ssId": "97906df07855b029b7aae7c2a1c6c5e8df1d531c", "arXivId": "1905.05950", "link": "https://arxiv.org/pdf/1905.05950.pdf", "openAccess": true, "authors": ["Ian Tenney", "Dipanjan Das", "Ellie Pavlick"]}}, "d7a7ebd1565c3795bc2bcdec4334d42a65ad17c5": {"id": "d7a7ebd1565c3795bc2bcdec4334d42a65ad17c5", "content": {"title": "Pretrained Language Models for Text Generation: A Survey", "abstract": "Text generation has become one of the most important yet challenging tasks in natural language processing (NLP). The resurgence of deep learning has greatly advanced this field by neural generation models, especially the paradigm of pretrained language models (PLMs). In this paper, we present an overview of the major advances achieved in the topic of PLMs for text generation. As the preliminaries, we present the general task definition and briefly describe the mainstream architectures of PLMs for text generation. As the core content, we discuss how to adapt existing PLMs to model different input data and satisfy special properties in the generated text. We further summarize several important fine-tuning strategies for text generation. Finally, we present several future directions and conclude this paper. Our survey aims to provide text generation researchers a synthesis and pointer to related research.", "year": 2021, "ssId": "d7a7ebd1565c3795bc2bcdec4334d42a65ad17c5", "arXivId": "2105.10311", "link": "https://arxiv.org/pdf/2105.10311.pdf", "openAccess": true, "authors": ["Junyi Li", "Tianyi Tang", "Wayne Xin Zhao", "Ji-rong Wen"]}}, "b79dcc5304e557ce200b161d2a884c0ff77f34ec": {"id": "b79dcc5304e557ce200b161d2a884c0ff77f34ec", "content": {"title": "NeuSpell: A Neural Spelling Correction Toolkit", "abstract": "We introduce NeuSpell, an open-source toolkit for spelling correction in English. Our toolkit comprises ten different models, and benchmarks them on naturally occurring misspellings from multiple sources. We find that many systems do not adequately leverage the context around the misspelt token. To remedy this, (i) we train neural models using spelling errors in context, synthetically constructed by reverse engineering isolated misspellings; and (ii) use richer representations of the context. By training on our synthetic examples, correction rates improve by 9% (absolute) compared to the case when models are trained on randomly sampled character perturbations. Using richer contextual representations boosts the correction rate by another 3%. Our toolkit enables practitioners to use our proposed and existing spelling correction systems, both via a simple unified command line, as well as a web interface. Among many potential applications, we demonstrate the utility of our spell-checkers in combating adversarial misspellings. The toolkit can be accessed at neuspell.github.io.", "year": 2020, "ssId": "b79dcc5304e557ce200b161d2a884c0ff77f34ec", "arXivId": "2010.11085", "link": "https://arxiv.org/pdf/2010.11085.pdf", "openAccess": true, "authors": ["Sai Muralidhar Jayanthi", "Danish Pruthi", "Graham Neubig"]}}, "122b75042daae44f93153dedda15b0fb11b3f279": {"id": "122b75042daae44f93153dedda15b0fb11b3f279", "content": {"title": "What Do Models Learn from Question Answering Datasets?", "abstract": "While models have reached superhuman performance on popular question answering (QA) datasets such as SQuAD, they have yet to outperform humans on the task of question answering itself. In this paper, we investigate what models are really learning from QA datasets by evaluating BERT-based models across five popular QA datasets. We evaluate models on their generalizability to out-of-domain examples, responses to missing or incorrect information in datasets, and ability to handle variations in questions. We find that no single dataset is robust to all of our experiments and identify shortcomings in both datasets and evaluation methods. Following our analysis, we make recommendations for building future QA datasets that better evaluate the task of question answering.", "year": 2020, "ssId": "122b75042daae44f93153dedda15b0fb11b3f279", "arXivId": "2004.03490", "link": "https://arxiv.org/pdf/2004.03490.pdf", "openAccess": true, "authors": ["Priyanka Sen", "Amir Saffari"]}}, "a0e92f6e9564b8c38b6649ae71b892ddfb988faa": {"id": "a0e92f6e9564b8c38b6649ae71b892ddfb988faa", "content": {"title": "Controllable Semantic Parsing via Retrieval Augmentation", "abstract": "In practical applications of semantic parsing, we often want to rapidly change the behavior of the parser, such as enabling it to handle queries in a new domain, or changing its predictions on certain targeted queries. While we can introduce new training examples exhibiting the target behavior, a mechanism for enacting such behavior changes without expensive model re-training would be preferable. To this end, we propose ControllAble Semantic Parser via Exemplar Retrieval (CASPER). Given an input query, the parser retrieves related exemplars from a retrieval index, augments them to the query, and then applies a generative seq2seq model to produce an output parse. The exemplars act as a control mechanism over the generic generative model: by manipulating the retrieval index or how the augmented query is constructed, we can manipulate the behavior of the parser. On the MTOP dataset, in addition to achieving state-of-the-art on the standard setup, we show that CASPER can parse queries in a new domain, adapt the prediction toward the specified patterns, or adapt to new semantic schemas without having to further re-train the model.", "year": 2021, "ssId": "a0e92f6e9564b8c38b6649ae71b892ddfb988faa", "arXivId": "2110.08458", "link": "https://arxiv.org/pdf/2110.08458.pdf", "openAccess": true, "authors": ["Panupong Pasupat", "Yuan Zhang", "Kelvin Guu"]}}, "a3ce3004a0eade48a3ae652dbf5c04a60c2416aa": {"id": "a3ce3004a0eade48a3ae652dbf5c04a60c2416aa", "content": {"title": "Personalized Dialogue Generation with Diversified Traits", "abstract": "Endowing a dialogue system with particular personality traits is essential to deliver more human-like conversations. However, due to the challenge of embodying personality via language expression and the lack of large-scale persona-labeled dialogue data, this research problem is still far from well-studied. In this paper, we investigate the problem of incorporating explicit personality traits in dialogue generation to deliver personalized dialogues. \nTo this end, firstly, we construct PersonalDialog, a large-scale multi-turn dialogue dataset containing various traits from a large number of speakers. The dataset consists of 20.83M sessions and 56.25M utterances from 8.47M speakers. Each utterance is associated with a speaker who is marked with traits like Age, Gender, Location, Interest Tags, etc. Several anonymization schemes are designed to protect the privacy of each speaker. This large-scale dataset will facilitate not only the study of personalized dialogue generation, but also other researches on sociolinguistics or social science. \nSecondly, to study how personality traits can be captured and addressed in dialogue generation, we propose persona-aware dialogue generation models within the sequence to sequence learning framework. Explicit personality traits (structured by key-value pairs) are embedded using a trait fusion module. During the decoding process, two techniques, namely persona-aware attention and persona-aware bias, are devised to capture and address trait-related information. Experiments demonstrate that our model is able to address proper traits in different contexts. Case studies also show interesting results for this challenging research problem.", "year": 2019, "ssId": "a3ce3004a0eade48a3ae652dbf5c04a60c2416aa", "arXivId": "1901.09672", "link": "https://arxiv.org/pdf/1901.09672.pdf", "openAccess": true, "authors": ["Yinhe Zheng", "Guanyi Chen", "Minlie Huang", "Song Liu", "Xuan Zhu"]}}, "69c515a62403fcc19125d3a6dd8e878aa5cde604": {"id": "69c515a62403fcc19125d3a6dd8e878aa5cde604", "content": {"title": "SARG: A Novel Semi Autoregressive Generator for Multi-turn Incomplete Utterance Restoration", "abstract": "Dialogue systems in the open domain have achieved great success due to large conversation data and the development of deep learning, but multi-turn scenarios are still a challenge because of the frequent coreference and information omission. In this paper, we investigate the incomplete utterance restoration since it has brought general improvement over multi-turn dialogue systems in recent studies. Inspired by the autoregression for generation and the sequence labeling for text editing, we propose a novel semi autoregressive generator (SARG) with the high efficiency and flexibility. Moreover, experiments on Restoration-200k show that our proposed model significantly outperforms the state-of-the-art models with faster inference speed.", "year": 2020, "ssId": "69c515a62403fcc19125d3a6dd8e878aa5cde604", "arXivId": "2008.01474", "link": "https://arxiv.org/pdf/2008.01474.pdf", "openAccess": true, "authors": ["Mengzuo Huang", "Feng Li", "Wuhe Zou", "Hongbo Zhang", "Weidong Zhang"]}}, "6a9394e5d49c1251c0fb6d7fb0c0813d26c6a907": {"id": "6a9394e5d49c1251c0fb6d7fb0c0813d26c6a907", "content": {"title": "On The Ingredients of an Effective Zero-shot Semantic Parser", "abstract": "Semantic parsers map natural language utterances into meaning representations (e.g. programs). Such models are typically bottlenecked by the paucity of training data due to the required laborious annotation efforts. Recent studies have performed zero-shot learning by synthesizing training examples of canonical utterances and programs from a grammar, and further paraphrasing these utterances to improve linguistic diversity. However, such synthetic examples cannot fully capture patterns in real data. In this paper we analyze zero-shot parsers through the lenses of the language and logical gaps (Herzig and Berant, 2019), which quantify the discrepancy of language and programmatic patterns between the synthetic canonical examples and real-world user-issued ones. We propose bridging these gaps using improved grammars, stronger paraphrasers, and efficient learning methods using canonical examples that most likely reflect real user intents. Our model achieves strong performance on two semantic parsing benchmarks (SCHOLAR, GEO) with zero labeled data.", "year": 2021, "ssId": "6a9394e5d49c1251c0fb6d7fb0c0813d26c6a907", "arXivId": "2110.08381", "link": "https://arxiv.org/pdf/2110.08381.pdf", "openAccess": true, "authors": ["P. Yin", "J. Wieting", "Avirup Sil", "Graham Neubig"]}}, "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4": {"id": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "content": {"title": "The Power of Scale for Parameter-Efficient Prompt Tuning", "abstract": "In this work, we explore \u201cprompt tuning,\u201d a simple yet effective mechanism for learning \u201csoft prompts\u201d to condition frozen language models to perform specific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft prompts are learned through backpropagation and can be tuned to incorporate signals from any number of labeled examples. Our end-to-end learned approach outperforms GPT-3\u2019s few-shot learning by a large margin. More remarkably, through ablations on model size using T5, we show that prompt tuning becomes more competitive with scale: as models exceed billions of parameters, our method \u201ccloses the gap\u201d and matches the strong performance of model tuning (where all model weights are tuned). This finding is especially relevant because large models are costly to share and serve and the ability to reuse one frozen model for multiple downstream tasks can ease this burden. Our method can be seen as a simplification of the recently proposed \u201cprefix tuning\u201d of Li and Liang (2021) and we provide a comparison to this and other similar approaches. Finally, we show that conditioning a frozen model with soft prompts confers benefits in robustness to domain transfer and enables efficient \u201cprompt ensembling.\u201d We release code and model checkpoints to reproduce our experiments.", "year": 2021, "ssId": "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4", "arXivId": "2104.08691", "link": "https://arxiv.org/pdf/2104.08691.pdf", "openAccess": true, "authors": ["Brian Lester", "Rami Al-Rfou", "Noah Constant"]}}, "bea54062d105b9fe3250ce3569cf817e54772894": {"id": "bea54062d105b9fe3250ce3569cf817e54772894", "content": {"title": "Automatic Phrase Recognition in Historical German", "abstract": "Due to a lack of annotated data, theories of historical syntax are often based on very small, manually compiled data sets. To enable the empirical evaluation of existing hypotheses, the present study explores the automatic recognition of phrases in historical German. Using modern and historical treebanks, training data for a neural sequence labeling tool and a probabilistic parser is created, and both methods are compared on a variety of data sets. The evaluation shows that the unlexicalized parser outperforms the sequence labeling approach, achieving F1-scores of 87%\u201391% on modern German and between 73% and 85% on different historical corpora. An error analysis indicates that accuracy decreases especially for longer phrases, but most of the errors concern incorrect phrase boundaries, suggesting further potential for improvement.", "year": 2021, "ssId": "bea54062d105b9fe3250ce3569cf817e54772894", "arXivId": null, "link": "https://aclanthology.org/2021.konvens-1.11.pdf", "openAccess": true, "authors": ["Katrin Ortmann"]}}, "7771aa7badc3375a31bfac8dc47755ff5d5c7780": {"id": "7771aa7badc3375a31bfac8dc47755ff5d5c7780", "content": {"title": "From characters to words: the turning point of BPE merges", "abstract": "The distributions of orthographic word types are very different across languages due to typological characteristics, different writing traditions and potentially other factors. The wide range of cross-linguistic diversity is still a major challenge for NLP and the study of language. We use BPE and information-theoretic measures to investigate if distributions become similar under specific levels of subword tokenization. We perform a cross-linguistic comparison, following incremental merges of BPE (we go from characters to words) for 47 diverse languages. We show that text entropy values (a feature of probability distributions) tend to converge at specific subword levels: relatively few BPE merges (around 350) lead to the most similar distributions across languages. Additionally, we analyze the interaction between subword and word-level distributions and show that our findings can be interpreted in light of the ongoing discussion regarding different types of morphological complexity.", "year": 2021, "ssId": "7771aa7badc3375a31bfac8dc47755ff5d5c7780", "arXivId": null, "link": "https://aclanthology.org/2021.eacl-main.302.pdf", "openAccess": true, "authors": ["Ximena Gutierrez-Vasques", "C. Bentz", "O. Sozinova", "T. Samardzic"]}}, "d15eb5744474cec2d0634651bb30000b3873a309": {"id": "d15eb5744474cec2d0634651bb30000b3873a309", "content": {"title": "Automatic Rule Generation for Time Expression Normalization", "abstract": "The understanding of time expressions includes two sub-tasks: recognition and normalization. In recent years, significant progress has been made in the recognition of time expressions while research on normalization has lagged behind. Existing SOTA normalization methods highly rely on rules or grammars designed by experts, which limits their performance on emerging corpora, such as social media texts. In this paper, we model time expression normalization as a sequence of operations to construct the normalized temporal value, and we present a novel method called ARTime, which can automatically generate normalization rules from training data without expert interventions. Specifically, ARTime automatically captures possible operation sequences from annotated data and generates normalization rules on time expressions with common surface forms. The experimental results show that ARTime can significantly surpass SOTA methods on the Tweets benchmark, and achieves competitive results with existing expert-engineered rule methods on the TempEval-3 benchmark.", "year": 2021, "ssId": "d15eb5744474cec2d0634651bb30000b3873a309", "arXivId": "2108.13658", "link": "https://arxiv.org/pdf/2108.13658.pdf", "openAccess": true, "authors": ["Wentao Ding", "Jianhao Chen", "Jinmao Li", "Yuzhong Qu"]}}, "d8d12c922fc571d081bae27c67fcf50cdbb17d90": {"id": "d8d12c922fc571d081bae27c67fcf50cdbb17d90", "content": {"title": "Summarising Historical Text in Modern Languages", "abstract": "We introduce the task of historical text summarisation, where documents in historical forms of a language are summarised in the corresponding modern language. This is a fundamentally important routine to historians and digital humanities researchers but has never been automated. We compile a high-quality gold-standard text summarisation dataset, which consists of historical German and Chinese news from hundreds of years ago summarised in modern German or Chinese. Based on cross-lingual transfer learning techniques, we propose a summarisation model that can be trained even with no cross-lingual (historical to modern) parallel data, and further benchmark it against state-of-the-art algorithms. We report automatic and human evaluations that distinguish the historic to modern language summarisation task from standard cross-lingual summarisation (i.e., modern to modern language), highlight the distinctness and value of our dataset, and demonstrate that our transfer learning approach outperforms standard cross-lingual benchmarks on this task.", "year": 2021, "ssId": "d8d12c922fc571d081bae27c67fcf50cdbb17d90", "arXivId": "2101.10759", "link": "https://arxiv.org/pdf/2101.10759.pdf", "openAccess": true, "authors": ["Xutan Peng", "Yifei Zheng", "Chenghua Lin", "Advaith Siddharthan"]}}, "3be5e7310b1bec9b4431ad0f1264f536b6a39f14": {"id": "3be5e7310b1bec9b4431ad0f1264f536b6a39f14", "content": {"title": "Analyzing the Use of Character-Level Translation with Sparse and Noisy Datasets", "abstract": "This paper provides an analysis of character-level machine translation models used in pivot-based translation when applied to sparse and noisy datasets, such as crowdsourced movie subtitles. In our experiments, we find that such characterlevel models cut the number of untranslated words by over 40% and are especially competitive (improvements of 2-3 BLEU points) in the case of limited training data. We explore the impact of character alignment, phrase table filtering, bitext size and the choice of pivot language on translation quality. We further compare cascaded translation models to the use of synthetic training data via multiple pivots, and we find that the latter works significantly better. Finally, we demonstrate that neither word- nor character-BLEU correlate perfectly with human judgments, due to BLEU\u2019s sensitivity to length.", "year": 2013, "ssId": "3be5e7310b1bec9b4431ad0f1264f536b6a39f14", "arXivId": "2109.13723", "link": "https://arxiv.org/pdf/2109.13723.pdf", "openAccess": true, "authors": ["J. Tiedemann", "Preslav Nakov"]}}, "c3a662b864673d8cc7469051419ab8819926d4b0": {"id": "c3a662b864673d8cc7469051419ab8819926d4b0", "content": {"title": "Identifying Elements Essential for BERT\u2019s Multilinguality", "abstract": "It has been shown that multilingual BERT (mBERT) yields high quality multilingual representations and enables effective zero-shot transfer. This is surprising given that mBERT does not use any crosslingual signal during training. While recent literature has studied this phenomenon, the reasons for the multilinguality are still somewhat obscure. We aim to identify architectural properties of BERT and linguistic properties of languages that are necessary for BERT to become multilingual. To allow for fast experimentation we propose an efficient setup with small BERT models trained on a mix of synthetic and natural data. Overall, we identify four architectural and two linguistic elements that influence multilinguality. Based on our insights, we experiment with a multilingual pretraining setup that modifies the masking strategy using VecMap, i.e., unsupervised embedding alignment. Experiments on XNLI with three languages indicate that our findings transfer from our small setup to larger scale settings.", "year": 2020, "ssId": "c3a662b864673d8cc7469051419ab8819926d4b0", "arXivId": null, "link": "https://aclanthology.org/2020.emnlp-main.358.pdf", "openAccess": true, "authors": ["Philipp Dufter", "Hinrich Sch\u00fctze"]}}, "575ac3f36e9fddeb258e2f639e26a6a7ec35160a": {"id": "575ac3f36e9fddeb258e2f639e26a6a7ec35160a", "content": {"title": "Is Supervised Syntactic Parsing Beneficial for Language Understanding Tasks? An Empirical Investigation", "abstract": "Traditional NLP has long held (supervised) syntactic parsing necessary for successful higher-level semantic language understanding (LU). The recent advent of end-to-end neural models, self-supervised via language modeling (LM), and their success on a wide range of LU tasks, however, questions this belief. In this work, we empirically investigate the usefulness of supervised parsing for semantic LU in the context of LM-pretrained transformer networks. Relying on the established fine-tuning paradigm, we first couple a pretrained transformer with a biaffine parsing head, aiming to infuse explicit syntactic knowledge from Universal Dependencies treebanks into the transformer. We then fine-tune the model for LU tasks and measure the effect of the intermediate parsing training (IPT) on downstream LU task performance. Results from both monolingual English and zero-shot language transfer experiments (with intermediate target-language parsing) show that explicit formalized syntax, injected into transformers through IPT, has very limited and inconsistent effect on downstream LU performance. Our results, coupled with our analysis of transformers\u2019 representation spaces before and after intermediate parsing, make a significant step towards providing answers to an essential question: how (un)availing is supervised parsing for high-level semantic natural language understanding in the era of large neural models?", "year": 2020, "ssId": "575ac3f36e9fddeb258e2f639e26a6a7ec35160a", "arXivId": "2008.06788", "link": "https://arxiv.org/pdf/2008.06788.pdf", "openAccess": true, "authors": ["Goran Glavas", "Ivan Vulic"]}}, "3376118362db3751cfbd88acd0c090b8a3897733": {"id": "3376118362db3751cfbd88acd0c090b8a3897733", "content": {"title": "Superbizarre Is Not Superb: Improving BERT's Interpretations of Complex Words with Derivational Morphology", "abstract": "How does the input segmentation of pretrained language models (PLMs) affect their generalization capabilities? We present the first study investigating this question, taking BERT as the example PLM and focusing on the semantic representations of derivationally complex words. We show that PLMs can be interpreted as serial dual-route models, i.e., the meanings of complex words are either stored or else need to be computed from the subwords, which implies that maximally meaningful input tokens should allow for the best generalization on new words. This hypothesis is confirmed by a series of semantic probing tasks on which derivational segmentation consistently outperforms BERT\u2019s WordPiece segmentation by a large margin. Our results suggest that the generalization capabilities of PLMs could be further improved if a morphologically-informed vocabulary of input tokens were used.", "year": 2021, "ssId": "3376118362db3751cfbd88acd0c090b8a3897733", "arXivId": null, "link": "https://aclanthology.org/2021.acl-long.279.pdf", "openAccess": true, "authors": ["Valentin Hofmann", "J. Pierrehumbert", "Hinrich Sch\u00fctze"]}}, "8b20173b98914f36302389e4c761c334fe867dcd": {"id": "8b20173b98914f36302389e4c761c334fe867dcd", "content": {"title": "Evaluating the Morphosyntactic Well-formedness of Generated Texts", "abstract": "Text generation systems are ubiquitous in natural language processing applications. However, evaluation of these systems remains a challenge, especially in multilingual settings. In this paper, we propose L\u2019AMBRE \u2013 a metric to evaluate the morphosyntactic well-formedness of text using its dependency parse and morphosyntactic rules of the language. We present a way to automatically extract various rules governing morphosyntax directly from dependency treebanks. To tackle the noisy outputs from text generation systems, we propose a simple methodology to train robust parsers. We show the effectiveness of our metric on the task of machine translation through a diachronic study of systems translating into morphologically-rich languages.", "year": 2021, "ssId": "8b20173b98914f36302389e4c761c334fe867dcd", "arXivId": "2103.16590", "link": "https://arxiv.org/pdf/2103.16590.pdf", "openAccess": true, "authors": ["Adithya Pratapa", "Antonios Anastasopoulos", "Shruti Rijhwani", "Aditi Chaudhary", "David R. Mortensen", "Graham Neubig", "Yulia Tsvetkov"]}}, "0ae93646ad058853eb6424c1dc0ec1559414e5af": {"id": "0ae93646ad058853eb6424c1dc0ec1559414e5af", "content": {"title": "Estimating predictive uncertainty for rumour verification models", "abstract": "The inability to correctly resolve rumours circulating online can have harmful real-world consequences. We present a method for incorporating model and data uncertainty estimates into natural language processing models for automatic rumour verification. We show that these estimates can be used to filter out model predictions likely to be erroneous so that these difficult instances can be prioritised by a human fact-checker. We propose two methods for uncertainty-based instance rejection, supervised and unsupervised. We also show how uncertainty estimates can be used to interpret model performance as a rumour unfolds.", "year": 2020, "ssId": "0ae93646ad058853eb6424c1dc0ec1559414e5af", "arXivId": "2005.07174", "link": "https://arxiv.org/pdf/2005.07174.pdf", "openAccess": true, "authors": ["E. Kochkina", "Maria Liakata"]}}, "4d1a14352ffb526a1fa0e1cd90e2484e188cddc0": {"id": "4d1a14352ffb526a1fa0e1cd90e2484e188cddc0", "content": {"title": "Transferable Dialogue Systems and User Simulators", "abstract": "One of the difficulties in training dialogue systems is the lack of training data. We explore the possibility of creating dialogue data through the interaction between a dialogue system and a user simulator. Our goal is to develop a modelling framework that can incorporate new dialogue scenarios through self-play between the two agents. In this framework, we first pre-train the two agents on a collection of source domain dialogues, which equips the agents to converse with each other via natural language. With further fine-tuning on a small amount of target domain data, the agents continue to interact with the aim of improving their behaviors using reinforcement learning with structured reward functions. In experiments on the MultiWOZ dataset, two practical transfer learning problems are investigated: 1) domain adaptation and 2) single-to-multiple domain transfer. We demonstrate that the proposed framework is highly effective in bootstrapping the performance of the two agents in transfer learning. We also show that our method leads to improvements in dialogue system performance on complete datasets.", "year": 2021, "ssId": "4d1a14352ffb526a1fa0e1cd90e2484e188cddc0", "arXivId": "2107.11904", "link": "https://arxiv.org/pdf/2107.11904.pdf", "openAccess": true, "authors": ["Bo-Hsiang Tseng", "Yinpei Dai", "Florian Kreyssig", "B. Byrne"]}}, "b7637d1148da569d2211b5dd9851bca82c6aac43": {"id": "b7637d1148da569d2211b5dd9851bca82c6aac43", "content": {"title": "Dynamic Feature Selection for Dependency Parsing", "abstract": "Feature computation and exhaustive search have significantly restricted the speed of graph-based dependency parsing. We propose a faster framework of dynamic feature selection, where features are added sequentially as needed, edges are pruned early, and decisions are made online for each sentence. We model this as a sequential decision-making problem and solve it by imitation learning techniques. We test our method on 7 languages. Our dynamic parser can achieve accuracies comparable or even superior to parsers using a full set of features, while computing fewer than 30% of the feature templates.", "year": 2013, "ssId": "b7637d1148da569d2211b5dd9851bca82c6aac43", "arXivId": null, "link": "https://aclanthology.org/D13-1152.pdf", "openAccess": true, "authors": ["He He", "Hal Daum\u00e9", "Jason Eisner"]}}, "eebc1811c55c2e5e8b3b78d0b0382ad50f22e32a": {"id": "eebc1811c55c2e5e8b3b78d0b0382ad50f22e32a", "content": {"title": "Get Your Vitamin C! Robust Fact Verification with Contrastive Evidence", "abstract": "Typical fact verification models use retrieved written evidence to verify claims. Evidence sources, however, often change over time as more information is gathered and revised. In order to adapt, models must be sensitive to subtle differences in supporting evidence. We present VitaminC, a benchmark infused with challenging cases that require fact verification models to discern and adjust to slight factual changes. We collect over 100,000 Wikipedia revisions that modify an underlying fact, and leverage these revisions, together with additional synthetically constructed ones, to create a total of over 400,000 claim-evidence pairs. Unlike previous resources, the examples in VitaminC are contrastive, i.e., they contain evidence pairs that are nearly identical in language and content, with the exception that one supports a given claim while the other does not. We show that training using this design increases robustness\u2014improving accuracy by 10% on adversarial fact verification and 6% on adversarial natural language inference (NLI). Moreover, the structure of VitaminC leads us to define additional tasks for fact-checking resources: tagging relevant words in the evidence for verifying the claim, identifying factual revisions, and providing automatic edits via factually consistent text generation.", "year": 2021, "ssId": "eebc1811c55c2e5e8b3b78d0b0382ad50f22e32a", "arXivId": "2103.08541", "link": "https://arxiv.org/pdf/2103.08541.pdf", "openAccess": true, "authors": ["Tal Schuster", "Adam Fisch", "R. Barzilay"]}}, "6a3cc30d5d6342d912851deb4362b8c47fa5ede3": {"id": "6a3cc30d5d6342d912851deb4362b8c47fa5ede3", "content": {"title": "Towards Debiasing NLU Models from Unknown Biases", "abstract": "NLU models often exploit biases to achieve high dataset-specific performance without properly learning the intended task. Recently proposed debiasing methods are shown to be effective in mitigating this tendency. However, these methods rely on a major assumption that the types of bias should be known a-priori, which limits their application to many NLU tasks and datasets. In this work, we present the first step to bridge this gap by introducing a self-debiasing framework that prevents models from mainly utilizing biases without knowing them in advance. The proposed framework is general and complementary to the existing debiasing methods. We show that it allows these existing methods to retain the improvement on the challenge datasets (i.e., sets of examples designed to expose models' reliance on biases) without specifically targeting certain biases. Furthermore, the evaluation suggests that applying the framework results in improved overall robustness.", "year": 2020, "ssId": "6a3cc30d5d6342d912851deb4362b8c47fa5ede3", "arXivId": "2009.12303", "link": "https://arxiv.org/pdf/2009.12303.pdf", "openAccess": true, "authors": ["Prasetya Ajie Utama", "N. Moosavi", "Iryna Gurevych"]}}, "d3231772937a2182b2377d028417245c49868dd1": {"id": "d3231772937a2182b2377d028417245c49868dd1", "content": {"title": "On NMT Search Errors and Model Errors: Cat Got Your Tongue?", "abstract": "We report on search errors and model errors in neural machine translation (NMT). We present an exact inference procedure for neural sequence models based on a combination of beam search and depth-first search. We use our exact search to find the global best model scores under a Transformer base model for the entire WMT15 English-German test set. Surprisingly, beam search fails to find these global best model scores in most cases, even with a very large beam size of 100. For more than 50% of the sentences, the model in fact assigns its global best score to the empty translation, revealing a massive failure of neural models in properly accounting for adequacy. We show by constraining search with a minimum translation length that at the root of the problem of empty translations lies an inherent bias towards shorter translations. We conclude that vanilla NMT in its current form requires just the right amount of beam search errors, which, from a modelling perspective, is a highly unsatisfactory conclusion indeed, as the model often prefers an empty translation.", "year": 2019, "ssId": "d3231772937a2182b2377d028417245c49868dd1", "arXivId": "1908.10090", "link": "https://arxiv.org/pdf/1908.10090.pdf", "openAccess": true, "authors": ["Felix Stahlberg", "B. Byrne"]}}, "0bb30ed3340d2c34fe9f37c5002929bc5f458c23": {"id": "0bb30ed3340d2c34fe9f37c5002929bc5f458c23", "content": {"title": "BERT-GT: Cross-sentence n-ary relation extraction with BERT and Graph Transformer", "abstract": "MOTIVATION\nA biomedical relation statement is commonly expressed in multiple sentences and consists of many concepts, including gene, disease, chemical, and mutation. To automatically extract information from biomedical literature, existing biomedical text-mining approaches typically formulate the problem as a cross-sentence n-ary relation-extraction task that detects relations among n entities across multiple sentences, and use either a graph neural network (GNN) with long short-term memory (LSTM) or an attention mechanism. Recently, Transformer has been shown to outperform LSTM on many natural language processing (NLP) tasks.\n\n\nRESULTS\nIn this work, we propose a novel architecture that combines Bidirectional Encoder Representations from Transformers with Graph Transformer (BERT-GT), through integrating a neighbor-attention mechanism into the BERT architecture. Unlike the original Transformer architecture, which utilizes the whole sentence(s) to calculate the attention of the current token, the neighbor-attention mechanism in our method calculates its attention utilizing only its neighbor tokens. Thus, each token can pay attention to its neighbor information with little noise. We show that this is critically important when the text is very long, as in cross-sentence or abstract-level relation-extraction tasks. Our benchmarking results show improvements of 5.44% and 3.89% in accuracy and F1-measure over the state-of-the-art on n-ary and chemical-protein relation datasets, suggesting BERT-GT is a robust approach that is applicable to other biomedical relation extraction tasks or datasets.\n\n\nAVAILABILITY AND IMPLEMENTATION\nthe source code of BERT-GT will be made freely available at https://github.com/ncbi-nlp/bert_gt upon publication.", "year": 2020, "ssId": "0bb30ed3340d2c34fe9f37c5002929bc5f458c23", "arXivId": "2101.04158", "link": "https://arxiv.org/pdf/2101.04158.pdf", "openAccess": true, "authors": ["Po-Ting Lai", "Zhiyong Lu"]}}, "f8d7b263e8d663583cd22d5988c8ea4a49ed2840": {"id": "f8d7b263e8d663583cd22d5988c8ea4a49ed2840", "content": {"title": "A Frustratingly Easy Approach for Joint Entity and Relation Extraction", "abstract": "End-to-end relation extraction aims to identify named entities and extract relations between them simultaneously. Most recent work models these two subtasks jointly, either by unifying them in one structured prediction framework, or multi-task learning through shared representations. In this work, we describe a very simple approach for joint entity and relation extraction, and establish the new state-of-the-art on standard benchmarks (ACE04, ACE05, and SciERC). Our approach essentially builds on two independent pre-trained encoders and merely uses the entity model to provide input features for the relation model. Through a series of careful examinations, we validate the importance of learning distinct contextual representations for entities and relations, fusing entity information at the input layer of the relation model, and incorporating global context. Finally, we also present an efficient approximation to our approach which requires only one pass of both encoders at inference time, obtaining a 8-16$\\times$ speedup with a small accuracy drop.", "year": 2020, "ssId": "f8d7b263e8d663583cd22d5988c8ea4a49ed2840", "arXivId": "2010.12812", "link": "https://arxiv.org/pdf/2010.12812.pdf", "openAccess": true, "authors": ["Zexuan Zhong", "Danqi Chen"]}}, "ca3535dcdda9849350ad7c991a60660b22844f2f": {"id": "ca3535dcdda9849350ad7c991a60660b22844f2f", "content": {"title": "Searchable Hidden Intermediates for End-to-End Models of Decomposable Sequence Tasks", "abstract": "End-to-end approaches for sequence tasks are becoming increasingly popular. Yet for complex sequence tasks, like speech translation, systems that cascade several models trained on sub-tasks have shown to be superior, suggesting that the compositionality of cascaded systems simplifies learning and enables sophisticated search capabilities. In this work, we present an end-to-end framework that exploits compositionality to learn searchable hidden representations at intermediate stages of a sequence model using decomposed sub-tasks. These hidden intermediates can be improved using beam search to enhance the overall performance and can also incorporate external models at intermediate stages of the network to re-score or adapt towards out-of-domain data. One instance of the proposed framework is a Multi-Decoder model for speech translation that extracts the searchable hidden intermediates from a speech recognition sub-task. The model demonstrates the aforementioned benefits and outperforms the previous state-of-the-art by around +6 and +3 BLEU on the two test sets of Fisher-CallHome and by around +3 and +4 BLEU on the English-German and English-French test sets of MuST-C.", "year": 2021, "ssId": "ca3535dcdda9849350ad7c991a60660b22844f2f", "arXivId": "2105.00573", "link": "https://arxiv.org/pdf/2105.00573.pdf", "openAccess": true, "authors": ["Siddharth Dalmia", "Brian Yan", "Vikas Raunak", "Florian Metze", "Shinji Watanabe"]}}, "6ea353ada2b89763f58d8068a74b2e6def526948": {"id": "6ea353ada2b89763f58d8068a74b2e6def526948", "content": {"title": "The DDI corpus: An annotated corpus with pharmacological substances and drug-drug interactions", "abstract": "The management of drug\u2013drug interactions (DDIs) is a critical issue resulting from the overwhelming amount of information available on them. Natural Language Processing (NLP) techniques can provide an interesting way to reduce the time spent by healthcare professionals on reviewing biomedical litera-ture. However, NLP techniques rely mostly on the availability of the annotated corpora. While there are several annotated corpora with biological entities and their relationships, there is a lack of corpora anno-tated with pharmacological substances and DDIs. Moreover, other works in this field have focused in pharmacokinetic (PK) DDIs only, but not in pharmacodynamic (PD) DDIs. To address this problem, we have created a manually annotated corpus consisting of 792 texts selected from the DrugBank database and other 233 Medline abstracts. This fined-grained corpus has been annotated with a total of 18,502 pharmacological substances and 5028 DDIs, including both PK as well as PD interactions. The quality and consistency of the annotation process has been ensured through the creation of annotation guide-lines and has been evaluated by the measurement of the inter-annotator agreement between two anno-tators. The agreement was almost perfect (Kappa up to 0.96 and generally over 0.80), except for the DDIs in the MedLine database (0.55\u20130.72). The DDI corpus has been used in the SemEval 2013 DDIExtraction challenge as a gold standard for the evaluation of information extraction techniques applied to the rec-ognition of pharmacological substances and the detection of DDIs from biomedical texts. DDIExtraction 2013 has attracted wide attention with a total of 14 teams from 7 different countries. For the task of rec-ognition and classification of pharmacological names, the best system achieved an F1 of 71.5%, while, for the detection and classification of DDIs, the best result was F1 of 65.1%. These results show that the cor-pus has enough quality to be used for training and testing NLP techniques applied to the field of Pharma-covigilance. The DDI corpus and the annotation guidelines are free for use for academic research and are available at http://labda.inf.uc3m.es/ddicorpus.", "year": 2013, "ssId": "6ea353ada2b89763f58d8068a74b2e6def526948", "arXivId": null, "link": "https://core.ac.uk/download/pdf/29406856.pdf", "openAccess": true, "authors": ["Mar\u00eda Herrero-Zazo", "Isabel Segura-Bedmar", "Paloma Mart\u00ednez", "Thierry Declerck"]}}, "fac2368c2ec81ef82fd168d49a0def2f8d1ec7d8": {"id": "fac2368c2ec81ef82fd168d49a0def2f8d1ec7d8", "content": {"title": "Entity, Relation, and Event Extraction with Contextualized Span Representations", "abstract": "We examine the capabilities of a unified, multi-task framework for three information extraction tasks: named entity recognition, relation extraction, and event extraction. Our framework (called DyGIE++) accomplishes all tasks by enumerating, refining, and scoring text spans designed to capture local (within-sentence) and global (cross-sentence) context. Our framework achieves state-of-the-art results across all tasks, on four datasets from a variety of domains. We perform experiments comparing different techniques to construct span representations. Contextualized embeddings like BERT perform well at capturing relationships among entities in the same or adjacent sentences, while dynamic span graph updates model long-range cross-sentence relationships. For instance, propagating span representations via predicted coreference links can enable the model to disambiguate challenging entity mentions. Our code is publicly available at https://github.com/dwadden/dygiepp and can be easily adapted for new tasks or datasets.", "year": 2019, "ssId": "fac2368c2ec81ef82fd168d49a0def2f8d1ec7d8", "arXivId": "1909.03546", "link": "https://arxiv.org/pdf/1909.03546.pdf", "openAccess": true, "authors": ["David Wadden", "Ulme Wennberg", "Yi Luan", "Hannaneh Hajishirzi"]}}, "cf0860ab99c63cb7cbd5317fca7cf1fe70e8fb63": {"id": "cf0860ab99c63cb7cbd5317fca7cf1fe70e8fb63", "content": {"title": "Differentiable Reasoning over a Virtual Knowledge Base", "abstract": "We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a virtual KB, softly following paths of relations between mentions of entities in the corpus. At each step the operation uses a combination of sparse-matrix TFIDF indices and maximum inner product search (MIPS) on a special index of contextual representations. This module is differentiable, so the full system can be trained completely end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the index mention encoder by generating hard negative examples using existing knowledge bases. We show that DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset, cutting the gap between text-based and KB-based state-of-the-art by 70%. DrKIT is also very efficient, processing upto 10x more queries per second than existing state-of-the-art QA systems.", "year": 2020, "ssId": "cf0860ab99c63cb7cbd5317fca7cf1fe70e8fb63", "arXivId": "2002.10640", "link": "https://arxiv.org/pdf/2002.10640.pdf", "openAccess": true, "authors": ["Bhuwan Dhingra", "M. Zaheer", "Vidhisha Balachandran", "Graham Neubig", "R. Salakhutdinov", "William W. Cohen"]}}, "8c5465eb110d0cab951ca6858a0d51ae759d2f9c": {"id": "8c5465eb110d0cab951ca6858a0d51ae759d2f9c", "content": {"title": "Interpretable Neural Predictions with Differentiable Binary Variables", "abstract": "The success of neural networks comes hand in hand with a desire for more interpretability. We focus on text classifiers and make them more interpretable by having them provide a justification\u2013a rationale\u2013for their predictions. We approach this problem by jointly training two neural network models: a latent model that selects a rationale (i.e. a short and informative part of the input text), and a classifier that learns from the words in the rationale alone. Previous work proposed to assign binary latent masks to input positions and to promote short selections via sparsity-inducing penalties such as L0 regularisation. We propose a latent model that mixes discrete and continuous behaviour allowing at the same time for binary selections and gradient-based training without REINFORCE. In our formulation, we can tractably compute the expected value of penalties such as L0, which allows us to directly optimise the model towards a pre-specified text selection rate. We show that our approach is competitive with previous work on rationale extraction, and explore further uses in attention mechanisms.", "year": 2019, "ssId": "8c5465eb110d0cab951ca6858a0d51ae759d2f9c", "arXivId": "1905.08160", "link": "https://arxiv.org/pdf/1905.08160.pdf", "openAccess": true, "authors": ["Jasmijn Bastings", "W. Aziz", "Ivan Titov"]}}, "9bbdcc03d872987eef9165f4a63c3878a5b05189": {"id": "9bbdcc03d872987eef9165f4a63c3878a5b05189", "content": {"title": "Condenser: a Pre-training Architecture for Dense Retrieval", "abstract": "Pre-trained Transformer language models (LM) have become go-to text representation encoders. Prior research fine-tunes deep LMs to encode text sequences such as sentences and passages into single dense vector representations for efficient text comparison and retrieval. However, dense encoders require a lot of data and sophisticated techniques to effectively train and suffer in low data situations. This paper finds a key reason is that standard LMs\u2019 internal attention structure is not ready-to-use for dense encoders, which needs to aggregate text information into the dense representation. We propose to pre-train towards dense encoder with a novel Transformer architecture, Condenser, where LM prediction CONditions on DENSE Representation. Our experiments show Condenser improves over standard LM by large margins on various text retrieval and similarity tasks.", "year": 2021, "ssId": "9bbdcc03d872987eef9165f4a63c3878a5b05189", "arXivId": "2104.08253", "link": "https://arxiv.org/pdf/2104.08253.pdf", "openAccess": true, "authors": ["Luyu Gao", "Jamie Callan"]}}, "dcb28c8ba94434eb8a06e81eb55bfdbc343d2340": {"id": "dcb28c8ba94434eb8a06e81eb55bfdbc343d2340", "content": {"title": "Document-Level N-ary Relation Extraction with Multiscale Representation Learning", "abstract": "Most information extraction methods focus on binary relations expressed within single sentences. In high-value domains, however, n-ary relations are of great demand (e.g., drug-gene-mutation interactions in precision oncology). Such relations often involve entity mentions that are far apart in the document, yet existing work on cross-sentence relation extraction is generally confined to small text spans (e.g., three consecutive sentences), which severely limits recall. In this paper, we propose a novel multiscale neural architecture for document-level n-ary relation extraction. Our system combines representations learned over various text spans throughout the document and across the subrelation hierarchy. Widening the system\u2019s purview to the entire document maximizes potential recall. Moreover, by integrating weak signals across the document, multiscale modeling increases precision, even in the presence of noisy labels from distant supervision. Experiments on biomedical machine reading show that our approach substantially outperforms previous n-ary relation extraction methods.", "year": 2019, "ssId": "dcb28c8ba94434eb8a06e81eb55bfdbc343d2340", "arXivId": "1904.02347", "link": "https://arxiv.org/pdf/1904.02347.pdf", "openAccess": true, "authors": ["Robin Jia", "Cliff Wong", "Hoifung Poon"]}}, "753fd6952c9f06f3bbd46e37129acc3f7a984896": {"id": "753fd6952c9f06f3bbd46e37129acc3f7a984896", "content": {"title": "Hindsight: Posterior-guided training of retrievers for improved open-ended generation", "abstract": "Many text generation systems benefit from using a retriever to retrieve passages from a textual knowledge corpus (e.g., Wikipedia) and providing these passages as additional context to the generator. For open-ended generation tasks (like generating informative utterances in conversations) many varied passages may be equally relevant and we find that existing methods that jointly train the retriever and generator underperform: the retriever may not find relevant passages even amongst the top-10 and the generator may hence not learn a preference to ground its generated output in them. We propose using an additional guide retriever that is allowed to use the target output and \u201cin hindsight\u201d retrieve relevant passages during training. We model the guide retriever after the posterior distribution Q of passages given the input and the target output and train it jointly with the standard retriever and the generator by maximizing the evidence lower bound (ELBo) in expectation over Q. For informative conversations from the Wizard of Wikipedia dataset, with posterior-guided training, the retriever finds passages with higher relevance in the top-10 (23% relative improvement), the generator\u2019s responses are more grounded in the retrieved passage (19% relative improvement) and the end-to-end system produces better overall output (6.4% relative improvement).", "year": 2021, "ssId": "753fd6952c9f06f3bbd46e37129acc3f7a984896", "arXivId": "2110.07752", "link": "https://arxiv.org/pdf/2110.07752.pdf", "openAccess": true, "authors": ["Ashwin Paranjape", "O. Khattab", "Christopher Potts", "M. Zaharia", "Christopher D. Manning"]}}, "55a3b36fd21dbbe9384ab3ba1bcf901235d95f47": {"id": "55a3b36fd21dbbe9384ab3ba1bcf901235d95f47", "content": {"title": "Unsupervised Question Decomposition for Question Answering", "abstract": "We aim to improve question answering (QA) by decomposing hard questions into simpler sub-questions that existing QA systems are capable of answering. Since labeling questions with decompositions is cumbersome, we take an unsupervised approach to produce sub-questions, also enabling us to leverage millions of questions from the internet. Specifically, we propose an algorithm for One-to-N Unsupervised Sequence transduction (ONUS) that learns to map one hard, multi-hop question to many simpler, single-hop sub-questions. We answer sub-questions with an off-the-shelf QA model and give the resulting answers to a recomposition model that combines them into a final answer. We show large QA improvements on HotpotQA over a strong baseline on the original, out-of-domain, and multi-hop dev sets. ONUS automatically learns to decompose different kinds of questions, while matching the utility of supervised and heuristic decomposition methods for QA and exceeding those methods in fluency. Qualitatively, we find that using sub-questions is promising for shedding light on why a QA system makes a prediction.", "year": 2020, "ssId": "55a3b36fd21dbbe9384ab3ba1bcf901235d95f47", "arXivId": "2002.09758", "link": "https://arxiv.org/pdf/2002.09758.pdf", "openAccess": true, "authors": ["Ethan Perez", "Patrick Lewis", "Wen-tau Yih", "Kyunghyun Cho", "Douwe Kiela"]}}, "7e358ffc2731a82420d84a7f0bedb155a487c39d": {"id": "7e358ffc2731a82420d84a7f0bedb155a487c39d", "content": {"title": "MuSiQue: Multi-hop Questions via Single-hop Question Composition", "abstract": "To build challenging multi-hop question answering datasets, we propose a bottom-up semi-automatic process of constructing multihop question via composition of single-hop questions. Constructing multi-hop questions as composition of single-hop questions allows us to exercise greater control over the quality of the resulting multi-hop questions. This process allows building a dataset with (i) connected reasoning where each step needs the answer from a previous step; (ii) minimal traintest leakage by eliminating even partial overlap of reasoning steps; (iii) variable number of hops and composition structures; and (iv) contrasting unanswerable questions by modifying the context. We use this process to construct a new multihop QA dataset: MuSiQue-Ans with 25K 2-4 hop questions using seed questions from 5 existing single-hop datasets. Our experiments demonstrate that MuSiQue-Ans is challenging for state-of-the-art QA models (e.g., human-machine gap of 30 F1 pts), significantly harder than existing datasets (2x humanmachine gap), and substantially less cheatable (e.g., a single-hop model is worse by 30 F1 pts). We also build an even more challenging dataset, MuSiQue-Full, consisting of answerable and unanswerable contrast question pairs, where model performance drops further by 13+ F1 pts.1", "year": 2021, "ssId": "7e358ffc2731a82420d84a7f0bedb155a487c39d", "arXivId": "2108.00573", "link": "https://arxiv.org/pdf/2108.00573.pdf", "openAccess": true, "authors": ["H. Trivedi", "Niranjan Balasubramanian", "Tushar Khot", "Ashish Sabharwal"]}}, "a61aebbfe029c4b8eafae4042e6242cdca8f54b7": {"id": "a61aebbfe029c4b8eafae4042e6242cdca8f54b7", "content": {"title": "Relation-Guided Pre-Training for Open-Domain Question Answering", "abstract": "Answering complex open-domain questions requires understanding the latent relations between involving entities. However, we found that the existing QA datasets are extremely imbalanced in some types of relations, which hurts the generalization performance over questions with long-tail relations. To remedy this problem, in this paper, we propose a Relation-Guided Pre-Training (RGPT-QA) framework1. We first generate a relational QA dataset covering a wide range of relations from both the Wikidata triplets and Wikipedia hyperlinks. We then pre-train a QA model to infer the latent relations from the question, and then conduct extractive QA to get the target answer entity. We demonstrate that by pretraining with propoed RGPT-QA techique, the popular open-domain QA model, Dense Passage Retriever (DPR), achieves 2.2%, 2.4%, and 6.3% absolute improvement in Exact Match accuracy on Natural Questions, TriviaQA, and WebQuestions. Particularly, we show that RGPT-QA improves significantly on questions with long-tail relations.", "year": 2021, "ssId": "a61aebbfe029c4b8eafae4042e6242cdca8f54b7", "arXivId": "2109.10346", "link": "https://arxiv.org/pdf/2109.10346.pdf", "openAccess": true, "authors": ["Ziniu Hu", "Yizhou Sun", "Kai-Wei Chang"]}}, "e3480d9395e692833b722b2e957d51139985f310": {"id": "e3480d9395e692833b722b2e957d51139985f310", "content": {"title": "General-Purpose Question-Answering with Macaw", "abstract": "Despite the successes of pretrained language models, there are still few high-quality, general-purpose QA systems that are freely available. In response, we present MACAW, a versatile, generative question-answering (QA) system that we are making available to the community. MACAW is built on UnifiedQA, itself built on T5, and exhibits strong performance, zero-shot, on a wide variety of topics, including outperforming GPT-3 by over 10% (absolute) on Challenge300, a suite of 300 challenge questions, despite being an order of magnitude smaller (11 billion vs. 175 billion parameters). In addition, MACAW allows different permutations (\u201cangles\u201d) of its inputs and outputs to be used, for example MACAW can take a question and produce an answer; or take an answer and produce a question; or take an answer and question, and produce multiple-choice options. We describe the system, and illustrate a variety of question types where it produces surprisingly good answers, well outside the training setup. We also identify question classes where it still appears to struggle, offering insights into the limitations of pretrained language models. MACAW is freely available, and we hope that it proves useful to the community.", "year": 2021, "ssId": "e3480d9395e692833b722b2e957d51139985f310", "arXivId": "2109.02593", "link": "https://arxiv.org/pdf/2109.02593.pdf", "openAccess": true, "authors": ["Oyvind Tafjord", "Peter Clark"]}}, "346081161bdc8f18e2a4c4af7f51d35452b5cb01": {"id": "346081161bdc8f18e2a4c4af7f51d35452b5cb01", "content": {"title": "Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies", "abstract": "Abstract A key limitation in current datasets for multi-hop reasoning is that the required steps for answering the question are mentioned in it explicitly. In this work, we introduce StrategyQA, a question answering (QA) benchmark where the required reasoning steps are implicit in the question, and should be inferred using a strategy. A fundamental challenge in this setup is how to elicit such creative questions from crowdsourcing workers, while covering a broad range of potential strategies. We propose a data collection procedure that combines term-based priming to inspire annotators, careful control over the annotator population, and adversarial filtering for eliminating reasoning shortcuts. Moreover, we annotate each question with (1) a decomposition into reasoning steps for answering it, and (2) Wikipedia paragraphs that contain the answers to each step. Overall, StrategyQA includes 2,780 examples, each consisting of a strategy question, its decomposition, and evidence paragraphs. Analysis shows that questions in StrategyQA are short, topic-diverse, and cover a wide range of strategies. Empirically, we show that humans perform well (87%) on this task, while our best baseline reaches an accuracy of \u223c 66%.", "year": 2021, "ssId": "346081161bdc8f18e2a4c4af7f51d35452b5cb01", "arXivId": "2101.02235", "link": "https://arxiv.org/pdf/2101.02235.pdf", "openAccess": true, "authors": ["Mor Geva", "Daniel Khashabi", "Elad Segal", "Tushar Khot", "D. Roth", "Jonathan Berant"]}}, "b9c3e87bc09c4c6167a03a835c30b1c23bef7a40": {"id": "b9c3e87bc09c4c6167a03a835c30b1c23bef7a40", "content": {"title": "Beyond I.I.D.: Three Levels of Generalization for Question Answering on Knowledge Bases", "abstract": "Existing studies on question answering on knowledge bases (KBQA) mainly operate with the standard i.i.d. assumption, i.e., training distribution over questions is the same as the test distribution. However, i.i.d. may be neither achievable nor desirable on large-scale KBs because 1) true user distribution is hard to capture and 2) randomly sampling training examples from the enormous space would be data-inefficient. Instead, we suggest that KBQA models should have three levels of built-in generalization: i.i.d., compositional, and zero-shot. To facilitate the development of KBQA models with stronger generalization, we construct and release a new large-scale, high-quality dataset with 64,331 questions, GrailQA, and provide evaluation settings for all three levels of generalization. In addition, we propose a novel BERT-based KBQA model. The combination of our dataset and model enables us to thoroughly examine and demonstrate, for the first time, the key role of pre-trained contextual embeddings like BERT in the generalization of KBQA.1", "year": 2020, "ssId": "b9c3e87bc09c4c6167a03a835c30b1c23bef7a40", "arXivId": "2011.07743", "link": "https://arxiv.org/pdf/2011.07743.pdf", "openAccess": true, "authors": ["Yu Gu", "S. Kase", "M. Vanni", "Brian M. Sadler", "Percy Liang", "Xifeng Yan", "Yu Su"]}}, "405c0d9b7cf5482d2e1197167f690e7b7801b9bd": {"id": "405c0d9b7cf5482d2e1197167f690e7b7801b9bd", "content": {"title": "Unsupervised Multi-hop Question Answering by Question Generation", "abstract": "Obtaining training data for multi-hop question answering (QA) is time-consuming and resource-intensive. We explore the possibility to train a well-performed multi-hop QA model without referencing any human-labeled multi-hop question-answer pairs, i.e., unsupervised multi-hop QA. We propose MQA-QG, an unsupervised framework that can generate human-like multi-hop training data from both homogeneous and heterogeneous data sources. MQA-QG generates questions by first selecting/generating relevant information from each data source and then integrating the multiple information to form a multi-hop question. Using only generated training data, we can train a competent multi-hop QA which achieves 61% and 83% of the supervised learning performance for the HybridQA and the HotpotQA dataset, respectively. We also show that pretraining the QA system with the generated data would greatly reduce the demand for human-annotated training data. Our codes are publicly available at https://github.com/teacherpeterpan/Unsupervised-Multi-hop-QA.", "year": 2020, "ssId": "405c0d9b7cf5482d2e1197167f690e7b7801b9bd", "arXivId": "2010.12623", "link": "https://arxiv.org/pdf/2010.12623.pdf", "openAccess": true, "authors": ["Liangming Pan", "Wenhu Chen", "Wenhan Xiong", "Min-Yen Kan", "William Yang Wang"]}}, "50ec3d960ac458573a1e4a1556420c5e96d58609": {"id": "50ec3d960ac458573a1e4a1556420c5e96d58609", "content": {"title": "Distantly-Supervised Evidence Retrieval Enables Question Answering without Evidence Annotation", "abstract": "Open-domain question answering answers a question based on evidence retrieved from a large corpus. State-of-the-art neural approaches require intermediate evidence annotations for training. However, such intermediate annotations are expensive, and methods that rely on them cannot transfer to the more common setting, where only question\u2013 answer pairs are available. This paper investigates whether models can learn to find evidence from a large corpus, with only distant supervision from answer labels for model training, thereby generating no additional annotation cost. We introduce a novel approach (DISTDR) that iteratively improves over a weak retriever by alternately finding evidence from the up-to-date model and encouraging the model to learn the most likely evidence. Without using any evidence labels, DISTDR is on par with fully-supervised state-of-theart methods on both multi-hop and singlehop QA benchmarks. Our analysis confirms that DISTDR finds more accurate evidence over iterations, which leads to model improvements. The code is available at https:// github.com/henryzhao5852/DistDR.", "year": 2021, "ssId": "50ec3d960ac458573a1e4a1556420c5e96d58609", "arXivId": "2110.04889", "link": "https://arxiv.org/pdf/2110.04889.pdf", "openAccess": true, "authors": ["Chenyan Xiong", "Hal Daum\u00e9"]}}, "c9472731afe5fca98f362f49e26d17a9d5d0cc8e": {"id": "c9472731afe5fca98f362f49e26d17a9d5d0cc8e", "content": {"title": "Against Interpretability: a Critical Examination of the Interpretability Problem in Machine Learning", "abstract": "The usefulness of machine learning algorithms has led to their widespread adoption prior to the development of a conceptual framework for making sense of them. One common response to this situation is to say that machine learning suffers from a \u201cblack box problem.\u201d That is, machine learning algorithms are \u201copaque\u201d to human users, failing to be \u201cinterpretable\u201d or \u201cexplicable\u201d in terms that would render categorization procedures \u201cunderstandable.\u201d The purpose of this paper is to challenge the widespread agreement about the existence and importance of a black box problem. The first section argues that \u201cinterpretability\u201d and cognates lack precise meanings when applied to algorithms. This makes the concepts difficult to use when trying to solve the problems that have motivated the call for interpretability (etc.). Furthermore, since there is no adequate account of the concepts themselves, it is not possible to assess whether particular technical features supply formal definitions of those concepts. The second section argues that there are ways of being a responsible user of these algorithms that do not require interpretability (etc.). In many cases in which a black box problem is cited, interpretability is a means to a further end such as justification or non-discrimination. Since addressing these problems need not involve something that looks like an \u201cinterpretation\u201d (etc.) of an algorithm, the focus on interpretability artificially constrains the solution space by characterizing one possible solution as the problem itself. Where possible, discussion should be reformulated in terms of the ends of interpretability.", "year": 2020, "ssId": "c9472731afe5fca98f362f49e26d17a9d5d0cc8e", "arXivId": null, "link": "https://link.springer.com/content/pdf/10.1007/s13347-019-00372-9.pdf", "openAccess": true, "authors": ["M. Krishnan"]}}, "fb7caddac20dca012f48c90b2e1e2383f7185051": {"id": "fb7caddac20dca012f48c90b2e1e2383f7185051", "content": {"title": "Interpreting Interpretability: Understanding Data Scientists' Use of Interpretability Tools for Machine Learning", "abstract": "Machine learning (ML) models are now routinely deployed in domains ranging from criminal justice to healthcare. With this newfound ubiquity, ML has moved beyond academia and grown into an engineering discipline. To that end, interpretability tools have been designed to help data scientists and machine learning practitioners better understand how ML models work. However, there has been little evaluation of the extent to which these tools achieve this goal. We study data scientists' use of two existing interpretability tools, the InterpretML implementation of GAMs and the SHAP Python package. We conduct a contextual inquiry (N=11) and a survey (N=197) of data scientists to observe how they use interpretability tools to uncover common issues that arise when building and evaluating ML models. Our results indicate that data scientists over-trust and misuse interpretability tools. Furthermore, few of our participants were able to accurately describe the visualizations output by these tools. We highlight qualitative themes for data scientists' mental models of interpretability tools. We conclude with implications for researchers and tool designers, and contextualize our findings in the social science literature.", "year": 2020, "ssId": "fb7caddac20dca012f48c90b2e1e2383f7185051", "arXivId": null, "link": "http://www-personal.umich.edu/~harmank/Papers/CHI2020_Interpretability.pdf", "openAccess": true, "authors": ["Harmanpreet Kaur", "Harsha Nori", "Samuel Jenkins", "R. Caruana", "H. Wallach", "Jennifer Wortman Vaughan"]}}, "35750f1908f405bb38b0708972f33fe07b378b64": {"id": "35750f1908f405bb38b0708972f33fe07b378b64", "content": {"title": "Interpretability Logic", "abstract": "This is an overview a study of interpretability logic in Zagreb for the last twenty years: a brief history and some planes for further research. The idea of treating a provability predicate as a modal operator goes back to G\u00f6del. The same idea was taken up later by Kripke and Montague, but only in the mid\u2013seventies was the correct choice of axioms, based on L\u00f6b\u2019s theorem, seriously considered by several logicians independently: G. Boolos, D. de Jongh, R. Magari, G. Sambin and R. Solovay. The system GL (G\u00f6del, L\u00f6b) is a modal propositional logic. R. Solovay 1976. proved arithmetical completeness of modal system GL. Many theories have the same provability logic GL. It means that the provability logic GL cannot distinguish some properties, as e.g. finite axiomatizability, reflexivity, etc. Some logicians considered modal representations of other arithmetical properties, for example interpretability, \u03a0n-conservativity, interpolability ... Roughly, a theory S interprets a theory T if there is a natural way of translating the language of S into the language of T in such a way that the translations of all the axioms of T become provable in S. We write S \u2265 T if this is the case. A derived notion is that of relative interpretability over a base theory T. Let A and B be arithmetical sentences. We say that A interprets B over T if T +A \u2265 T +B. Modal logics for relative interpretability were first studied by P. H\u00e1jek (1981) and V. \u0160vejdar (1983). A. Visser (1990) introduced the binary modal logic IL (interpretability logic). The interpretability logic IL results from the provability logic GL, by adding the binary modal operator \u25c3. The language of the interpretability logic contains propositional letters p0, p1, . . . , the logical connectives \u2227, \u2228,\u2192 and \u00ac, and the unary modal operator and the binary modal operator \u25c3. The axioms of the interpretability logic IL are: all tautologies of the propositional calculus, (A \u2192 B) \u2192 ( A \u2192 B), A \u2192 A, ( A \u2192 A) \u2192 A, (A \u2192 B) \u2192 (A \u25c3 B), (A \u25c3 B \u2227 B \u25c3 C) \u2192 (A \u25c3 C), ((A\u25c3C)\u2227(B\u25c3C)) \u2192 ((A\u2228B)\u25c3C), (A\u25c3B) \u2192 (\u2662A \u2192 \u2662B), and \u2662A\u25c3A, where \u2662 stands for \u00ac \u00ac and \u25c3 has the same priority as \u2192 . The deduction rules of IL are modus ponens and necessitation. Arithmetical semantics of interpretability logic is based on the fact that each sufficiently strong theory S has arithmetical formulas Pr(x) and Int(x, y). Formula Pr(x) expressing that \u201dx is provable in S\u201d (i.e. formula with G\u00f6del number x is provable in S). Formula Int(x, y) expressing that \u201dS + x interprets S + y.\u201d An arithmetical interpretation is a function \u2217 from modal formulas into arithmetical sentences preserving Boolean connectives and satisfying ( A)\u2217 = Pr(\u2308A\u2217\u2309) and (A \u25c3 B)\u2217 = Int(\u2308A\u2217\u2309, \u2308B\u2217\u2309) (\u2308A\u2217\u2309 denote G\u00f6del number of formula A\u2217). The system IL is natural from the modal point of view, but arithmetically incomplete. Various extensions of ILare obtained by adding some new axioms. These new axioms are called the principles of interpretability. We denote by ILX the system obtained by adding a principle X to the system IL. System ILM is the interpretability logic of", "year": 1990, "ssId": "35750f1908f405bb38b0708972f33fe07b378b64", "arXivId": null, "link": "https://link.springer.com/chapter/10.1007/978-1-4613-0609-2_13", "openAccess": false, "authors": ["A. Visser"]}}, "0bbfa6ab7451aea5cbb842cce97b54500bafdfc7": {"id": "0bbfa6ab7451aea5cbb842cce97b54500bafdfc7", "content": {"title": "Uncertain Decisions Facilitate Better Preference Learning", "abstract": "Existing observational approaches for learning human preferences, such as inverse reinforcement learning, usually make strong assumptions about the observability of the human\u2019s environment. However, in reality, people make many important decisions under uncertainty. To better understand preference learning in these cases, we study the setting of inverse decision theory (IDT), a previously proposed framework where a human is observed making non-sequential binary decisions under uncertainty. In IDT, the human\u2019s preferences are conveyed through their loss function, which expresses a tradeoff between different types of mistakes. We give the first statistical analysis of IDT, providing conditions necessary to identify these preferences and characterizing the sample complexity\u2014the number of decisions that must be observed to learn the tradeoff the human is making to a desired precision. Interestingly, we show that it is actually easier to identify preferences when the decision problem is more uncertain. Furthermore, uncertain decision problems allow us to relax the unrealistic assumption that the human is an optimal decision maker but still identify their exact preferences; we give sample complexities in this suboptimal case as well. Our analysis contradicts the intuition that partial observability should make preference learning more difficult. It also provides a first step towards understanding and improving preference learning methods for uncertain and suboptimal humans.", "year": 2021, "ssId": "0bbfa6ab7451aea5cbb842cce97b54500bafdfc7", "arXivId": "2106.10394", "link": "https://arxiv.org/pdf/2106.10394.pdf", "openAccess": true, "authors": ["Cassidy Laidlaw", "Stuart J. Russell"]}}, "9364eff879a9dcb34fe3dfdd0843e69c14dd333b": {"id": "9364eff879a9dcb34fe3dfdd0843e69c14dd333b", "content": {"title": "Human-in-the-Loop Interpretability Prior", "abstract": "We often desire our models to be interpretable as well as accurate. Prior work on optimizing models for interpretability has relied on easy-to-quantify proxies for interpretability, such as sparsity or the number of operations required. In this work, we optimize for interpretability by directly including humans in the optimization loop. We develop an algorithm that minimizes the number of user studies to find models that are both predictive and interpretable and demonstrate our approach on several data sets. Our human subjects results show trends towards different proxy notions of interpretability on different datasets, which suggests that different proxies are preferred on different tasks.", "year": 2018, "ssId": "9364eff879a9dcb34fe3dfdd0843e69c14dd333b", "arXivId": "1805.11571", "link": "https://arxiv.org/pdf/1805.11571.pdf", "openAccess": true, "authors": ["Isaac Lage", "A. Ross", "Been Kim", "S. Gershman", "Finale Doshi-Velez"]}}, "191ef1408406569f0e9a69344add1ae350365431": {"id": "191ef1408406569f0e9a69344add1ae350365431", "content": {"title": "Characterizing Fairness Over the Set of Good Models Under Selective Labels", "abstract": "Algorithmic risk assessments are used to inform decisions in a wide variety of high-stakes settings. Often multiple predictive models deliver similar overall performance but differ markedly in their predictions for individual cases, an empirical phenomenon known as the \u201cRashomon Effect.\u201d These models may have different properties over various groups, and therefore have different predictive fairness properties. We develop a framework for characterizing predictive fairness properties over the set of models that deliver similar overall performance, or \u201cthe set of good models.\u201d Our framework addresses the empirically relevant challenge of selectively labelled data in the setting where the selection decision and outcome are unconfounded given the observed data features. Our framework can be used to 1) audit for predictive bias; or 2) replace an existing model with one that has better fairness properties. We illustrate these use cases on a recidivism prediction task and a real-world credit-scoring task.", "year": 2021, "ssId": "191ef1408406569f0e9a69344add1ae350365431", "arXivId": "2101.00352", "link": "https://arxiv.org/pdf/2101.00352.pdf", "openAccess": true, "authors": ["Amanda Coston", "Ashesh Rambachan", "A. Chouldechova"]}}, "7e63be5285e6596fbbc6c56bc89f7b6fd8bbe8c5": {"id": "7e63be5285e6596fbbc6c56bc89f7b6fd8bbe8c5", "content": {"title": "Debugging Tests for Model Explanations", "abstract": "We investigate whether post-hoc model explanations are effective for diagnosing model errors--model debugging. In response to the challenge of explaining a model's prediction, a vast array of explanation methods have been proposed. Despite increasing use, it is unclear if they are effective. To start, we categorize \\textit{bugs}, based on their source, into:~\\textit{data, model, and test-time} contamination bugs. For several explanation methods, we assess their ability to: detect spurious correlation artifacts (data contamination), diagnose mislabeled training examples (data contamination), differentiate between a (partially) re-initialized model and a trained one (model contamination), and detect out-of-distribution inputs (test-time contamination). We find that the methods tested are able to diagnose a spurious background bug, but not conclusively identify mislabeled training examples. In addition, a class of methods, that modify the back-propagation algorithm are invariant to the higher layer parameters of a deep network; hence, ineffective for diagnosing model contamination. We complement our analysis with a human subject study, and find that subjects fail to identify defective models using attributions, but instead rely, primarily, on model predictions. Taken together, our results provide guidance for practitioners and researchers turning to explanations as tools for model debugging.", "year": 2020, "ssId": "7e63be5285e6596fbbc6c56bc89f7b6fd8bbe8c5", "arXivId": "2011.05429", "link": "https://arxiv.org/pdf/2011.05429.pdf", "openAccess": true, "authors": ["J. Adebayo", "Michael Muelly", "I. Liccardi", "Been Kim"]}}, "a1c5af2a531c64f1c06e806d7986cd878ec3c33a": {"id": "a1c5af2a531c64f1c06e806d7986cd878ec3c33a", "content": {"title": "How can I choose an explainer? An Application-grounded Evaluation of Post-hoc Explanations", "abstract": "There have been several research works proposing new Explainable AI (XAI) methods designed to generate model explanations having specific properties, or desiderata, such as fidelity, robustness, or human-interpretability. However, explanations are seldom evaluated based on their true practical impact on decision-making tasks. Without that assessment, explanations might be chosen that, in fact, hurt the overall performance of the combined system of ML model + end-users. This study aims to bridge this gap by proposing XAI Test, an application-grounded evaluation methodology tailored to isolate the impact of providing the end-user with different levels of information. We conducted an experiment following XAI Test to evaluate three popular post-hoc explanation methods \u2013 LIME, SHAP, and TreeInterpreter \u2013 on a real-world fraud detection task, with real data, a deployed ML model, and fraud analysts. During the experiment, we gradually increased the information provided to the fraud analysts in three stages: Data Only, i.e., just transaction data without access to model score nor explanations, Data + ML Model Score, and Data + ML Model Score + Explanations. Using strong statistical analysis, we show that, in general, these popular explainers have a worse impact than desired. Some of the conclusion highlights include: i) showing Data Only results in the highest decision accuracy and the slowest decision time among all variants tested, ii) all the explainers improve accuracy over the Data + ML Model Score variant but still result in lower accuracy when compared with Data Only; iii) LIME was the least preferred by users, probably due to its substantially lower variability of explanations from case to", "year": 2021, "ssId": "a1c5af2a531c64f1c06e806d7986cd878ec3c33a", "arXivId": "2101.08758", "link": "https://arxiv.org/pdf/2101.08758.pdf", "openAccess": true, "authors": ["S\u00e9rgio M. Jesus", "Catarina Bel'em", "Vladimir Balayan", "Jo\u00e3o Bento", "Pedro Saleiro", "P. Bizarro", "Jo\u00e3o Gama"]}}, "02a757548da783d43ffcfd4b60f2cbb0ac71a4bc": {"id": "02a757548da783d43ffcfd4b60f2cbb0ac71a4bc", "content": {"title": "Eliciting and Enforcing Subjective Individual Fairness", "abstract": "We revisit the notion of individual fairness first proposed by Dwork et al. [2012], which asks that \"similar individuals should be treated similarly\". A primary difficulty with this definition is that it assumes a completely specified fairness metric for the task at hand. In contrast, we consider a framework for fairness elicitation, in which fairness is indirectly specified only via a sample of pairs of individuals who should be treated (approximately) equally on the task. We make no assumption that these pairs are consistent with any metric. We provide a provably convergent oracle-efficient algorithm for minimizing error subject to the fairness constraints, and prove generalization theorems for both accuracy and fairness. Since the constrained pairs could be elicited either from a panel of judges, or from particular individuals, our framework provides a means for algorithmically enforcing subjective notions of fairness. We report on preliminary findings of a behavioral study of subjective fairness using human-subject fairness constraints elicited on the COMPAS criminal recidivism dataset.", "year": 2019, "ssId": "02a757548da783d43ffcfd4b60f2cbb0ac71a4bc", "arXivId": "1905.10660", "link": "https://arxiv.org/pdf/1905.10660.pdf", "openAccess": true, "authors": ["Christopher Jung", "M. Kearns", "Seth Neel", "Aaron Roth", "Logan Stapleton", "Zhiwei Steven Wu"]}}, "e37fb85e8869d464bae8eeebf4cd9321ec8c70ad": {"id": "e37fb85e8869d464bae8eeebf4cd9321ec8c70ad", "content": {"title": "Enforcing Interpretability and its Statistical Impacts: Trade-offs between Accuracy and Interpretability", "abstract": "To date, there has been no formal study of the statistical cost of interpretability in machine learning. As such, the discourse around potential trade-offs is often informal and misconceptions abound. In this work, we aim to initiate a formal study of these trade-offs. A seemingly insurmountable roadblock is the lack of any agreed upon definition of interpretability. Instead, we propose a shift in perspective. Rather than attempt to define interpretability, we propose to model the \\emph{act} of \\emph{enforcing} interpretability. As a starting point, we focus on the setting of empirical risk minimization for binary classification, and view interpretability as a constraint placed on learning. That is, we assume we are given a subset of hypothesis that are deemed to be interpretable, possibly depending on the data distribution and other aspects of the context. We then model the act of enforcing interpretability as that of performing empirical risk minimization over the set of interpretable hypotheses. This model allows us to reason about the statistical implications of enforcing interpretability, using known results in statistical learning theory. Focusing on accuracy, we perform a case analysis, explaining why one may or may not observe a trade-off between accuracy and interpretability when the restriction to interpretable classifiers does or does not come at the cost of some excess statistical risk. We close with some worked examples and some open problems, which we hope will spur further theoretical development around the tradeoffs involved in interpretability.", "year": 2020, "ssId": "e37fb85e8869d464bae8eeebf4cd9321ec8c70ad", "arXivId": "2010.13764", "link": "https://arxiv.org/pdf/2010.13764.pdf", "openAccess": true, "authors": ["G. Dziugaite", "S. Ben-David", "Daniel M. Roy"]}}, "e54ffc76d805c48660bb0fd20019ca82ac94ba0d": {"id": "e54ffc76d805c48660bb0fd20019ca82ac94ba0d", "content": {"title": "Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning", "abstract": "Although pretrained language models can be fine-tuned to produce state-of-the-art results for a very wide range of language understanding tasks, the dynamics of this process are not well understood, especially in the low data regime. Why can we use relatively vanilla gradient descent algorithms (e.g., without strong regularization) to tune a model with hundreds of millions of parameters on datasets with only hundreds or thousands of labeled examples? In this paper, we argue that analyzing fine-tuning through the lens of intrinsic dimension provides us with empirical and theoretical intuitions to explain this remarkable phenomenon. We empirically show that common pre-trained models have a very low intrinsic dimension; in other words, there exists a low dimension reparameterization that is as effective for fine-tuning as the full parameter space. For example, by optimizing only 200 trainable parameters randomly projected back into the full space, we can tune a RoBERTa model to achieve 90% of the full parameter performance levels on MRPC. Furthermore, we empirically show that pre-training implicitly minimizes intrinsic dimension and, perhaps surprisingly, larger models tend to have lower intrinsic dimension after a fixed number of pre-training updates, at least in part explaining their extreme effectiveness. Lastly, we connect intrinsic dimensionality with low dimensional task representations and compression based generalization bounds to provide intrinsic-dimension-based generalization bounds that are independent of the full parameter count.", "year": 2020, "ssId": "e54ffc76d805c48660bb0fd20019ca82ac94ba0d", "arXivId": "2012.13255", "link": "https://arxiv.org/pdf/2012.13255.pdf", "openAccess": true, "authors": ["Armen Aghajanyan", "Luke Zettlemoyer", "Sonal Gupta"]}}, "873b83326ad1f98549beb85bdb130a40a61e1f9b": {"id": "873b83326ad1f98549beb85bdb130a40a61e1f9b", "content": {"title": "Surface Form Competition: Why the Highest Probability Answer Isn\u2019t Always Right", "abstract": "Large language models have shown promising results in zero-shot settings. For example, they can perform multiple choice tasks simply by conditioning on a question and selecting the answer with the highest probability. However, ranking by string probability can be problematic due to surface form competition\u2014wherein different surface forms compete for probability mass, even if they represent the same underlying concept in a given context, e.g. \u201ccomputer\u201d and \u201cPC.\u201d Since probability mass is finite, this lowers the probability of the correct answer, due to competition from other strings that are valid answers (but not one of the multiple choice options). We introduce Domain Conditional Pointwise Mutual Information, an alternative scoring function that directly compensates for surface form competition by simply reweighing each option according to its a priori likelihood within the context of a specific task. It achieves consistent gains in zero-shot performance over both calibrated and uncalibrated scoring functions on all GPT-2 and GPT-3 models on a variety of multiple choice datasets.", "year": 2021, "ssId": "873b83326ad1f98549beb85bdb130a40a61e1f9b", "arXivId": "2104.08315", "link": "https://arxiv.org/pdf/2104.08315.pdf", "openAccess": true, "authors": ["Ari Holtzman", "Peter West", "Vered Schwartz", "Yejin Choi", "Luke Zettlemoyer"]}}, "3cfb319689f06bf04c2e28399361f414ca32c4b3": {"id": "3cfb319689f06bf04c2e28399361f414ca32c4b3", "content": {"title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer", "abstract": "Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts every language problem into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new \"Colossal Clean Crawled Corpus\", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our dataset, pre-trained models, and code.", "year": 2019, "ssId": "3cfb319689f06bf04c2e28399361f414ca32c4b3", "arXivId": "1910.10683", "link": "https://arxiv.org/pdf/1910.10683.pdf", "openAccess": true, "authors": ["Colin Raffel", "Noam M. Shazeer", "Adam Roberts", "Katherine Lee", "Sharan Narang", "Michael Matena", "Yanqi Zhou", "Wei Li", "Peter J. Liu"]}}, "3d3b1300c7cd6a820a6d08605248f875a3ad20b9": {"id": "3d3b1300c7cd6a820a6d08605248f875a3ad20b9", "content": {"title": "Is Multi-Hop Reasoning Really Explainable? Towards Benchmarking Reasoning Interpretability", "abstract": "Multi-hop reasoning has been widely studied in recent years to obtain more interpretable link prediction. However, we find in experiments that many paths given by these models are actually unreasonable, while little work has been done on interpretability evaluation for them. In this paper, we propose a unified framework to quantitatively evaluate the interpretability of multi-hop reasoning models so as to advance their development. In specific, we define three metrics, including path recall, local interpretability, and global interpretability for evaluation, and design an approximate strategy to calculate these metrics using the interpretability scores of rules. We manually annotate all possible rules and establish a benchmark. In experiments, we verify the effectiveness of our benchmark. Besides, we run nine representative baselines on our benchmark, and the experimental results show that the interpretability of current multi-hop reasoning models is less satisfactory and is 51.7% lower than the upper bound given by our benchmark. Moreover, the rule-based models outperform the multi-hop reasoning models in terms of performance and interpretability, which points to a direction for future research, i.e., how to better incorporate rule information into the multi-hop reasoning model. We will publish our codes and datasets upon acceptance.", "year": 2021, "ssId": "3d3b1300c7cd6a820a6d08605248f875a3ad20b9", "arXivId": "2104.06751", "link": "https://arxiv.org/pdf/2104.06751.pdf", "openAccess": true, "authors": ["Xin Lv", "Yixin Cao", "Lei Hou", "Juan-Zi Li", "Zhiyuan Liu", "Yichi Zhang", "Zelin Dai"]}}, "6ab36d2577f7c9487b28b2bcdf236191ba901aad": {"id": "6ab36d2577f7c9487b28b2bcdf236191ba901aad", "content": {"title": "End-to-End Learning of Flowchart Grounded Task-Oriented Dialogs", "abstract": "We propose a novel problem within end-to-end learning of task oriented dialogs (TOD), in which the dialog system mimics a troubleshooting agent who helps a user by diagnosing their problem (e.g., car not starting). Such dialogs are grounded in domain-specific flowcharts, which the agent is supposed to follow during the conversation. Our task exposes novel technical challenges for neural TOD, such as grounding an utterance to the flowchart without explicit annotation, referring to additional manual pages when user asks a clarification question, and ability to follow unseen flowcharts at test time. We release a dataset (FLODIAL) consisting of 2,738 dialogs grounded on 12 different troubleshooting flowcharts. We also design a neural model, FLONET, which uses a retrieval-augmented generation architecture to train the dialog agent. Our experiments find that FLONET can do zero-shot transfer to unseen flowcharts, and sets a strong baseline for future research.", "year": 2021, "ssId": "6ab36d2577f7c9487b28b2bcdf236191ba901aad", "arXivId": "2109.07263", "link": "https://arxiv.org/pdf/2109.07263.pdf", "openAccess": true, "authors": ["Dinesh Raghu", "Shantanu Agarwal", "Sachindra Joshi", "Mausam"]}}, "a6b431df3b3d40c98d8d623cab559a9cddd41662": {"id": "a6b431df3b3d40c98d8d623cab559a9cddd41662", "content": {"title": "Schema-Guided Paradigm for Zero-Shot Dialog", "abstract": "Developing mechanisms that flexibly adapt dialog systems to unseen tasks and domains is a major challenge in dialog research. Neural models implicitly memorize task-specific dialog policies from the training data. We posit that this implicit memorization has precluded zero-shot transfer learning. To this end, we leverage the schema-guided paradigm, wherein the task-specific dialog policy is explicitly provided to the model. We introduce the Schema Attention Model (SAM) and improved schema representations for the STAR corpus. SAM obtains significant improvement in zero-shot settings, with a +22 F1 score improvement over prior work. These results validate the feasibility of zero-shot generalizability in dialog. Ablation experiments are also presented to demonstrate the efficacy of SAM.", "year": 2021, "ssId": "a6b431df3b3d40c98d8d623cab559a9cddd41662", "arXivId": "2106.07056", "link": "https://arxiv.org/pdf/2106.07056.pdf", "openAccess": true, "authors": ["Shikib Mehri", "M. Esk\u00e9nazi"]}}, "9633928f72cda45d102fb6740291d47137d0a5ca": {"id": "9633928f72cda45d102fb6740291d47137d0a5ca", "content": {"title": "Mitigating Backdoor Attacks in Federated Learning", "abstract": "Malicious clients can attack federated learning systems by using malicious data, including backdoor samples, during the training phase. The compromised global model will perform well on the validation dataset designed for the task. However, a small subset of data with backdoor patterns may trigger the model to make a wrong prediction. Previously, there was an arms race. Attackers tried to conceal attacks and defenders tried to detect attacks during the aggregation stage of training on the server-side in a federated learning system. In this work, we propose a new method to mitigate backdoor attacks after the training phase. Specifically, we designed a federated pruning method to remove redundant neurons in the network and then adjust the model's extreme weight values. Experiments conducted on distributed Fashion-MNIST have shown that our method can reduce the average attack success rate from 99.7% to 1.9% with a 5.5% loss of test accuracy on the validation dataset. To minimize the pruning influence on test accuracy, we can fine-tune after pruning, and the attack success rate drops to 6.4%, with only a 1.7% loss of test accuracy.", "year": 2020, "ssId": "9633928f72cda45d102fb6740291d47137d0a5ca", "arXivId": "2011.01767", "link": "https://arxiv.org/pdf/2011.01767.pdf", "openAccess": true, "authors": ["Chen Wu", "Xian Yang", "Sencun Zhu", "P. Mitra"]}}, "58a2e825884bc86e650fffafb86a2833117852c5": {"id": "58a2e825884bc86e650fffafb86a2833117852c5", "content": {"title": "Ranking and Tuning Pre-trained Models: A New Paradigm of Exploiting Model Hubs", "abstract": "Model hubs with many pre-trained models (PTMs) have been a cornerstone in deep learning. Although built at a high cost, they remain under-exploited : practitioners usually pick one PTM from the provided model hub by popularity and then fine-tune the PTM to solve the target task. This n\u00e4\u0131ve but common practice poses two obstacles to sufficient exploitation of pre-trained model hubs: (1) the PTM selection by popularity has no optimality guarantee; (2) only one PTM is used while the rest PTMs are ignored. Ideally, to exploit pre-trained model hubs maximally, trying all combinations of PTMs and extensively fine-tuning each PTM combination are required, which incurs exponential combinations and an unaffordable computational budget. In this paper, we propose a new paradigm of exploiting model hubs by ranking and tuning pre-trained models: (1) Our conference paper (You et al., 2021) proposed LogME to estimate the maximum value of label evidence given features extracted by pre-trained models, which can rank all the PTMs in a model hub for various types of PTMs and tasks before fine-tuning. (2) The best ranked PTM can be fine-tuned and deployed if we have no preference for the model\u2019s architecture, or the target PTM can be tuned by top-K ranked PTMs via the proposed B-Tuning algorithm. The ranking part is based on the conference paper, and we complete its theoretical analyses in this paper, including the convergence proof of the heuristic evidence maximization procedure and the influence of feature dimension. The tuning part introduces a novel Bayesian Tuning (B-Tuning) method for tuning multiple PTMs, which surpasses specialized methods designed for tuning homogeneous PTMs and sets up a new state of the art for tuning heterogeneous PTMs. The new paradigm of exploiting PTM hubs can be interesting to a large audience across the machine learning community.", "year": 2021, "ssId": "58a2e825884bc86e650fffafb86a2833117852c5", "arXivId": "2110.10545", "link": "https://arxiv.org/pdf/2110.10545.pdf", "openAccess": true, "authors": ["Kaichao You", "Yong Liu", "Jianmin Wang", "Michael I. Jordan", "Mingsheng Long"]}}, "e114618157e025ed17b7e45684d67becd34a14f3": {"id": "e114618157e025ed17b7e45684d67becd34a14f3", "content": {"title": "Lower Bounds on the Total Variation Distance Between Mixtures of Two Gaussians", "abstract": "Mixtures of high dimensional Gaussian distributions have been studied extensively in statistics and learning theory. While the total variation distance appears naturally in the sample complexity of distribution learning, it is analytically difficult to obtain tight lower bounds for mixtures. Exploiting a connection between total variation distance and the characteristic function of the mixture, we provide fairly tight functional approximations. This enables us to derive new lower bounds on the total variation distance between two-component Gaussian mixtures with a shared covariance matrix.", "year": 2021, "ssId": "e114618157e025ed17b7e45684d67becd34a14f3", "arXivId": "2109.01064", "link": "https://arxiv.org/pdf/2109.01064.pdf", "openAccess": true, "authors": ["Sami Davies", "A. Mazumdar", "S. Pal", "Cyrus Rashtchian"]}}, "4a36a00db217fd98f1bd943aa2f2d6303adbc456": {"id": "4a36a00db217fd98f1bd943aa2f2d6303adbc456", "content": {"title": "Fast and Efficient MMD-based Fair PCA via Optimization over Stiefel Manifold", "abstract": "This paper defines fair principal component analysis (PCA) as minimizing the maximum mean discrepancy (MMD) between dimensionality-reduced conditional distributions of different protected classes. The incorporation of MMD naturally leads to an exact and tractable mathematical formulation of fairness with good statistical properties. We formulate the problem of fair PCA subject to MMD constraints as a non-convex optimization over the Stiefel manifold and solve it using the Riemannian Exact Penalty Method with Smoothing (REPMS; Liu and Boumal, 2019). Importantly, we provide local optimality guarantees and explicitly show the theoretical effect of each hyperparameter in practical settings, extending previous results. Experimental comparisons based on synthetic and UCI datasets show that our approach outperforms prior work in explained variance, fairness, and runtime.", "year": 2021, "ssId": "4a36a00db217fd98f1bd943aa2f2d6303adbc456", "arXivId": "2109.11196", "link": "https://arxiv.org/pdf/2109.11196.pdf", "openAccess": true, "authors": ["Junghyun Lee", "Gwangsun Kim", "Matt Olfat", "M. Hasegawa-Johnson", "C. Yoo"]}}, "e54e0d9eaa922cefb1c69e105979399fd34497b1": {"id": "e54e0d9eaa922cefb1c69e105979399fd34497b1", "content": {"title": "Learning Fair Classifiers with Partially Annotated Group Labels", "abstract": "Recently, fairness-aware learning have become increas-ingly crucial, but most of those methods operate by assuming the availability of fully annotated demographic group labels. We emphasize that such assumption is unrealistic for real-world applications since group label annotations are expensive and can conflict with privacy issues. In this paper, we consider a more practical scenario, dubbed as Algorithmic Group Fair ness with the P artially annotated G roup labels ( Fair-PG ). We observe that the existing methods to achieve group fairness perform even worse than the vanilla training, which simply uses full data only with target labels, under Fair-PG. To address this problem, we propose a simple C onfidence-based G roup L abel assignment ( CGL ) strategy that is readily applicable to any fairness-aware learning method. CGL utilizes an auxiliary group classifier to assign pseudo group labels, where random labels are assigned to low confident samples. We first theoretically show that our method design is better than the vanilla pseudo-labeling strategy in terms of fairness criteria. Then, we empirically show on several benchmark datasets that by combining CGL and the state-of-the-art fairness-aware in-processing methods, the target accuracies and the fairness metrics can be jointly improved compared to the baselines. Furthermore, we convincingly show that CGL enables to naturally augment the given group-labeled dataset with external target label-only datasets so that both accuracy and fairness can be improved. Code is available at https: //github.com/naver-ai/cgl_fairness .", "year": 2021, "ssId": "e54e0d9eaa922cefb1c69e105979399fd34497b1", "arXivId": "2111.14581", "link": "https://arxiv.org/pdf/2111.14581.pdf", "openAccess": true, "authors": ["Sang-Won Jung", "Sanghyuk Chun", "Taesup Moon"]}}, "1092da11519fe8427c8113b16a012f34f4a3fb6b": {"id": "1092da11519fe8427c8113b16a012f34f4a3fb6b", "content": {"title": "Federated Learning Meets Fairness and Differential Privacy", "abstract": "Deep learning\u2019s unprecedented success raises several ethical concerns ranging from biased predictions to data privacy. Researchers tackle these issues by introducing fairness metrics, or federated learning, or differential privacy. A first, this work presents an ethical federated learning model, incorporating all three measures simultaneously. Experiments on the Adult, Bank and Dutch datasets highlight the resulting \u201cempirical interplay\u201d between accuracy, fairness, and privacy.", "year": 2021, "ssId": "1092da11519fe8427c8113b16a012f34f4a3fb6b", "arXivId": "2108.09932", "link": "https://arxiv.org/pdf/2108.09932.pdf", "openAccess": true, "authors": ["P. Manisha", "Sankarshan Damle", "Sujit Gujar"]}}, "939dfa4dec88ca167e6572904c4ad2fcbf726f48": {"id": "939dfa4dec88ca167e6572904c4ad2fcbf726f48", "content": {"title": "Gradient flows on graphons: existence, convergence, continuity equations", "abstract": "Wasserstein gradient flows on probability measures have found a host of applications in various optimization problems. They typically arise as the continuum limit of exchangeable particle systems evolving by some mean-field interaction involving a gradienttype potential. However, in many problems, such as in multi-layer neural networks, the so-called particles are edge weights on large graphs whose nodes are exchangeable. Such large graphs are known to converge to continuum limits called graphons as their size grow to infinity. We show that the Euclidean gradient flow of a suitable function of the edgeweights converges to a novel continuum limit given by a curve on the space of graphons that can be appropriately described as a gradient flow or, more technically, a curve of maximal slope. Several natural functions on graphons, such as homomorphism functions and the scalar entropy, are covered by our set-up, and the examples have been worked out in detail.", "year": 2021, "ssId": "939dfa4dec88ca167e6572904c4ad2fcbf726f48", "arXivId": "2111.09459", "link": "https://arxiv.org/pdf/2111.09459.pdf", "openAccess": true, "authors": ["Sewoong Oh", "Soumik Pal", "Raghav Somani", "Raghavendra Tripathi"]}}, "f74d4fa99ccedfea7a2662fe6944d99f34533912": {"id": "f74d4fa99ccedfea7a2662fe6944d99f34533912", "content": {"title": "Group-Aware Threshold Adaptation for Fair Classification", "abstract": "The fairness in machine learning is getting increasing attention, as its applications in different fields continue to expand and diversify. To mitigate the discriminated model behaviors between different demographic groups, we introduce a novel post-processing method to optimize over multiple fairness constraints through group-aware threshold adaptation. We propose to learn adaptive classification thresholds for each demographic group by optimizing the confusion matrix estimated from the probability distribution of a classification model output. As we only need an estimated probability distribution of model output instead of the classification model structure, our post-processing model can be applied to a wide range of classification models and improve fairness in a model-agnostic manner and ensure privacy. This even allows us to post-process existing fairness methods to further improve the trade-off between accuracy and fairness. Moreover, our model has low computational cost. We provide rigorous theoretical analysis on the convergence of our optimization algorithm and the trade-off between accuracy and fairness of our method. Our method theoretically enables a better upper bound in near optimality than existing method under same condition. Experimental results demonstrate that our method outperforms state-of-the-art methods and obtains the result that is closest to the theoretical accuracy-fairness trade-off boundary.", "year": 2021, "ssId": "f74d4fa99ccedfea7a2662fe6944d99f34533912", "arXivId": "2111.04271", "link": "https://arxiv.org/pdf/2111.04271.pdf", "openAccess": true, "authors": ["T. Jang", "P. Shi", "Xiaoqian Wang"]}}, "1fc6290fa3e6784501ca67cbef33a6a8edcbdb9e": {"id": "1fc6290fa3e6784501ca67cbef33a6a8edcbdb9e", "content": {"title": "Sharp asymptotic and finite-sample rates of convergence of empirical measures in Wasserstein distance", "abstract": "The Wasserstein distance between two probability measures on a metric space is a measure of closeness with applications in statistics, probability, and machine learning. In this work, we consider the fundamental question of how quickly the empirical measure obtained from $n$ independent samples from $\\mu$ approaches $\\mu$ in the Wasserstein distance of any order. We prove sharp asymptotic and finite-sample results for this rate of convergence for general measures on general compact metric spaces. Our finite-sample results show the existence of multi-scale behavior, where measures can exhibit radically different rates of convergence as $n$ grows.", "year": 2017, "ssId": "1fc6290fa3e6784501ca67cbef33a6a8edcbdb9e", "arXivId": "1707.00087", "link": "https://arxiv.org/pdf/1707.00087.pdf", "openAccess": true, "authors": ["J. Weed", "F. Bach"]}}, "ad21f0709a3e5d7db91606e2f67926f93e01838d": {"id": "ad21f0709a3e5d7db91606e2f67926f93e01838d", "content": {"title": "Contextual Games: Multi-Agent Learning with Side Information", "abstract": "We formulate the novel class of contextual games, a type of repeated games driven by contextual information at each round. By means of kernel-based regularity assumptions, we model the correlation between different contexts and game outcomes and propose a novel online (meta) algorithm that exploits such correlations to minimize the contextual regret of individual players. We define game-theoretic notions of contextual Coarse Correlated Equilibria (c-CCE) and optimal contextual welfare for this new class of games and show that c-CCEs and optimal welfare can be approached whenever players\u2019 contextual regrets vanish. Finally, we empirically validate our results in a traffic routing experiment, where our algorithm leads to better performance and higher welfare compared to baselines that do not exploit the available contextual information or the correlations present in the game.", "year": 2021, "ssId": "ad21f0709a3e5d7db91606e2f67926f93e01838d", "arXivId": "2107.06327", "link": "https://arxiv.org/pdf/2107.06327.pdf", "openAccess": true, "authors": ["Pier Giuseppe Sessa", "Ilija Bogunovic", "A. Krause", "M. Kamgarpour"]}}, "6b4ca249b3b28d3fee65f69714440c08d42cee64": {"id": "6b4ca249b3b28d3fee65f69714440c08d42cee64", "content": {"title": "Which Training Methods for GANs do actually Converge?", "abstract": "Recent work has shown local convergence of GAN training for absolutely continuous data and generator distributions. In this paper, we show that the requirement of absolute continuity is necessary: we describe a simple yet prototypical counterexample showing that in the more realistic case of distributions that are not absolutely continuous, unregularized GAN training is not always convergent. Furthermore, we discuss regularization strategies that were recently proposed to stabilize GAN training. Our analysis shows that GAN training with instance noise or zero-centered gradient penalties converges. On the other hand, we show that Wasserstein-GANs and WGAN-GP with a finite number of discriminator updates per generator update do not always converge to the equilibrium point. We discuss these results, leading us to a new explanation for the stability problems of GAN training. Based on our analysis, we extend our convergence results to more general GANs and prove local convergence for simplified gradient penalties even if the generator and data distribution lie on lower dimensional manifolds. We find these penalties to work well in practice and use them to learn high-resolution generative image models for a variety of datasets with little hyperparameter tuning.", "year": 2018, "ssId": "6b4ca249b3b28d3fee65f69714440c08d42cee64", "arXivId": "1801.04406", "link": "https://arxiv.org/pdf/1801.04406.pdf", "openAccess": true, "authors": ["Lars M. Mescheder", "Andreas Geiger", "S. Nowozin"]}}, "65b226f71faaac9b8a4d63445c85601a16635464": {"id": "65b226f71faaac9b8a4d63445c85601a16635464", "content": {"title": "On Nonconvex Optimization for Machine Learning: Gradients, Stochasticity, and Saddle Points", "abstract": "Gradient descent (GD) and stochastic gradient descent (SGD) are the workhorses of large-scale machine learning. While classical theory focused on analyzing the performance of these methods in convex optimization problems, the most notable successes in machine learning have involved nonconvex optimization, and a gap has arisen between theory and practice. Indeed, traditional analyses of GD and SGD show that both algorithms converge to stationary points efficiently. But these analyses do not take into account the possibility of converging to saddle points. More recent theory has shown that GD and SGD can avoid saddle points, but the dependence on dimension in these analyses is polynomial. For modern machine learning, where the dimension can be in the millions, such dependence would be catastrophic. We analyze perturbed versions of GD and SGD and show that they are truly efficient---their dimension dependence is only polylogarithmic. Indeed, these algorithms converge to second-order stationary points in essentially the same time as they take to converge to classical first-order stationary points.", "year": 2019, "ssId": "65b226f71faaac9b8a4d63445c85601a16635464", "arXivId": "1902.04811", "link": "https://arxiv.org/pdf/1902.04811.pdf", "openAccess": true, "authors": ["Chi Jin", "Praneeth Netrapalli", "Rong Ge", "S. Kakade", "Michael I. Jordan"]}}, "e6aaac94df717786a467d057cb2157b9d49f0974": {"id": "e6aaac94df717786a467d057cb2157b9d49f0974", "content": {"title": "Adaptive Learning in Continuous Games: Optimal Regret Bounds and Convergence to Nash Equilibrium", "abstract": "In game-theoretic learning, several agents are simultaneously following their individual interests, so the environment is non-stationary from each player\u2019s perspective. In this context, the performance of a learning algorithm is often measured by its regret. However, no-regret algorithms are not created equal in terms of game-theoretic guarantees: depending on how they are tuned, some of them may drive the system to an equilibrium, while others could produce cyclic, chaotic, or otherwise divergent trajectories. To account for this, we propose a range of no-regret policies based on optimistic mirror descent, with the following desirable properties: i) they do not require any prior tuning or knowledge of the game; ii) they all achieve O( \u221a T ) regret against arbitrary, adversarial opponents; and iii) they converge to the best response against convergent opponents. Also, if employed by all players, then iv) they guarantee O(1) social regret; while v) the induced sequence of play converges to Nash equilibrium with O(1) individual regret in all variationally stable games (a class of games that includes all monotone and convex-concave zero-sum games).", "year": 2021, "ssId": "e6aaac94df717786a467d057cb2157b9d49f0974", "arXivId": "2104.12761", "link": "https://arxiv.org/pdf/2104.12761.pdf", "openAccess": true, "authors": ["Yu-Guan Hsieh", "Kimon Antonakopoulos", "P. Mertikopoulos"]}}, "957e3ec3c722f5cb382fe8ac54fc846ee772a95f": {"id": "957e3ec3c722f5cb382fe8ac54fc846ee772a95f", "content": {"title": "More Adaptive Algorithms for Adversarial Bandits", "abstract": "We develop a novel and generic algorithm for the adversarial multi-armed bandit problem (or more generally the combinatorial semi-bandit problem). When instantiated differently, our algorithm achieves various new data-dependent regret bounds improving previous works. Examples include: 1) a regret bound depending on the variance of only the best arm; 2) a regret bound depending on the first-order path-length of only the best arm; 3) a regret bound depending on the sum of first-order path-lengths of all arms as well as an important negative term, which together lead to faster convergence rates for some normal form games with partial feedback; 4) a regret bound that simultaneously implies small regret when the best arm has small loss and logarithmic regret when there exists an arm whose expected loss is always smaller than those of others by a fixed gap (e.g. the classic i.i.d. setting). In some cases, such as the last two results, our algorithm is completely parameter-free. \nThe main idea of our algorithm is to apply the optimism and adaptivity techniques to the well-known Online Mirror Descent framework with a special log-barrier regularizer. The challenges are to come up with appropriate optimistic predictions and correction terms in this framework. Some of our results also crucially rely on using a sophisticated increasing learning rate schedule.", "year": 2018, "ssId": "957e3ec3c722f5cb382fe8ac54fc846ee772a95f", "arXivId": "1801.03265", "link": "https://arxiv.org/pdf/1801.03265.pdf", "openAccess": true, "authors": ["Chen-Yu Wei", "Haipeng Luo"]}}, "542ad79bb96fc10c46086778aaafc8f3509c5c18": {"id": "542ad79bb96fc10c46086778aaafc8f3509c5c18", "content": {"title": "Global Convergence and Variance-Reduced Optimization for a Class of Nonconvex-Nonconcave Minimax Problems", "abstract": "Nonconvex minimax problems appear frequently in emerging machine learning applications, such as generative adversarial networks and adversarial learning. Simple algorithms such as the gradient descent ascent (GDA) are the common practice for solving these nonconvex games and receive lots of empirical success. Yet, it is known that these vanilla GDA algorithms with constant step size can potentially diverge even in the convex setting. In this work, we show that for a subclass of nonconvex-nonconcave objectives satisfying a so-called two-sided Polyak-\u0141ojasiewicz inequality, the alternating gradient descent ascent (AGDA) algorithm converges globally at a linear rate and the stochastic AGDA achieves a sublinear rate. We further develop a variance reduced algorithm that attains a provably faster rate than AGDA when the problem has the finite-sum structure.", "year": 2020, "ssId": "542ad79bb96fc10c46086778aaafc8f3509c5c18", "arXivId": "2002.09621", "link": "https://arxiv.org/pdf/2002.09621.pdf", "openAccess": true, "authors": ["Junchi Yang", "N. Kiyavash", "Niao He"]}}, "ce3d6673b7eebdd0198940316d18e383e9597c9a": {"id": "ce3d6673b7eebdd0198940316d18e383e9597c9a", "content": {"title": "Taking a hint: How to leverage loss predictors in contextual bandits?", "abstract": "We initiate the study of learning in contextual bandits with the help of loss predictors. The main question we address is whether one can improve over the minimax regret $\\mathcal{O}(\\sqrt{T})$ for learning over $T$ rounds, when the total error of the predictor $\\mathcal{E} \\leq T$ is relatively small. We provide a complete answer to this question, including upper and lower bounds for various settings: adversarial versus stochastic environments, known versus unknown $\\mathcal{E}$, and single versus multiple predictors. We show several surprising results, such as 1) the optimal regret is $\\mathcal{O}(\\min\\{\\sqrt{T}, \\sqrt{\\mathcal{E}}T^\\frac{1}{4}\\})$ when $\\mathcal{E}$ is known, a sharp contrast to the standard and better bound $\\mathcal{O}(\\sqrt{\\mathcal{E}})$ for non-contextual problems (such as multi-armed bandits); 2) the same bound cannot be achieved if $\\mathcal{E}$ is unknown, but as a remedy, $\\mathcal{O}(\\sqrt{\\mathcal{E}}T^\\frac{1}{3})$ is achievable; 3) with $M$ predictors, a linear dependence on $M$ is necessary, even if logarithmic dependence is possible for non-contextual problems. \nWe also develop several novel algorithmic techniques to achieve matching upper bounds, including 1) a key action remapping technique for optimal regret with known $\\mathcal{E}$, 2) implementing Catoni's robust mean estimator efficiently via an ERM oracle leading to an efficient algorithm in the stochastic setting with optimal regret, 3) constructing an underestimator for $\\mathcal{E}$ via estimating the histogram with bins of exponentially increasing size for the stochastic setting with unknown $\\mathcal{E}$, and 4) a self-referential scheme for learning with multiple predictors, all of which might be of independent interest.", "year": 2020, "ssId": "ce3d6673b7eebdd0198940316d18e383e9597c9a", "arXivId": "2003.01922", "link": "https://arxiv.org/pdf/2003.01922.pdf", "openAccess": true, "authors": ["Chen-Yu Wei", "Haipeng Luo", "Alekh Agarwal"]}}, "98290fb02a844108df202e9a6dc3461e3f14ee32": {"id": "98290fb02a844108df202e9a6dc3461e3f14ee32", "content": {"title": "Nonconvex-Nonconcave Min-Max Optimization with a Small Maximization Domain", "abstract": "We study the problem of finding approximate first-order stationary points in optimization problems of the form minx\u2208X maxy\u2208Y f(x, y), where the sets X,Y are convex and Y is compact. The objective function f is smooth, but assumed neither convex in x nor concave in y. Our approach relies upon replacing the function f(x, \u22c5) with its k-th order Taylor approximation (in y) and finding a near-stationary point in the resulting surrogate problem. To guarantee its success, we establish the following result: let the Euclidean diameter of Y be small in terms of the target accuracy \u03b5, namely O(\u03b5 2 k+1 ) for k \u2208 N and O(\u03b5) for k = 0, with the constant factors controlled by certain regularity parameters of f ; then any \u03b5-stationary point in the surrogate problem remains O(\u03b5)-stationary for the initial problem. Moreover, we show that these upper bounds are nearly optimal: the aforementioned reduction provably fails when the diameter of Y is larger. For 0 \u2a7d k \u2a7d 2 the surrogate function can be efficiently maximized in y; our general approximation result then leads to efficient algorithms for finding a near-stationary point in nonconvex-nonconcave min-max problems, for which we also provide convergence guarantees.", "year": 2021, "ssId": "98290fb02a844108df202e9a6dc3461e3f14ee32", "arXivId": "2110.03950", "link": "https://arxiv.org/pdf/2110.03950.pdf", "openAccess": true, "authors": ["Dmitrii Ostrovskii", "Babak Barazandeh", "Meisam Razaviyayn"]}}, "98554bd8a15172e9a6ef3cc3db3bc52504110fc9": {"id": "98554bd8a15172e9a6ef3cc3db3bc52504110fc9", "content": {"title": "On the Pareto Frontier of Regret Minimization and Best Arm Identification in Stochastic Bandits", "abstract": "We study the Pareto frontier of two archetypal objectives in stochastic bandits, namely, regret minimization (RM) and best arm identification (BAI) with a fixed horizon. It is folklore that the balance between exploitation and exploration is crucial for both RM and BAI, but exploration is more critical in achieving the optimal performance for the latter objective. To make this precise, we first design and analyze the BOBW-LIL\u2019UCB(\u03b3) algorithm, which achieves order-wise optimal performance for RM or BAI under different values of \u03b3. Complementarily, we show that no algorithm can simultaneously perform optimally for both the RM and BAI objectives. More precisely, we establish non-trivial lower bounds on the regret achievable by any algorithm with a given BAI failure probability. This analysis shows that in some regimes BOBW-LIL\u2019UCB(\u03b3) achieves Pareto-optimality up to constant or small terms. Numerical experiments further demonstrate that when applied to difficult instances, BOBW-LIL\u2019UCB outperforms a close competitor UCB\u03b1 (Degenne et al., 2019), which is designed for RM and BAI with a fixed confidence.", "year": 2021, "ssId": "98554bd8a15172e9a6ef3cc3db3bc52504110fc9", "arXivId": "2110.08627", "link": "https://arxiv.org/pdf/2110.08627.pdf", "openAccess": true, "authors": ["Zixin Zhong", "Wang Chi Cheung", "V. Tan"]}}, "49984bc327ef6952118c4b871eeef2a907f7a4ed": {"id": "49984bc327ef6952118c4b871eeef2a907f7a4ed", "content": {"title": "Fast Convergence of Regularized Learning in Games", "abstract": "We show that natural classes of regularized learning algorithms with a form of recency bias achieve faster convergence rates to approximate efficiency and to coarse correlated equilibria in multiplayer normal form games. When each player in a game uses an algorithm from our class, their individual regret decays at $O(T^{-3/4})$, while the sum of utilities converges to an approximate optimum at $O(T^{-1})$--an improvement upon the worst case $O(T^{-1/2})$ rates. We show a black-box reduction for any algorithm in the class to achieve $\\tilde{O}(T^{-1/2})$ rates against an adversary, while maintaining the faster rates against algorithms in the class. Our results extend those of [Rakhlin and Shridharan 2013] and [Daskalakis et al. 2014], who only analyzed two-player zero-sum games for specific algorithms.", "year": 2015, "ssId": "49984bc327ef6952118c4b871eeef2a907f7a4ed", "arXivId": "1507.00407", "link": "https://arxiv.org/pdf/1507.00407.pdf", "openAccess": true, "authors": ["Vasilis Syrgkanis", "Alekh Agarwal", "Haipeng Luo", "R. Schapire"]}}, "fa774368fcf51cc0fa1bfda59b6a606e163c64b1": {"id": "fa774368fcf51cc0fa1bfda59b6a606e163c64b1", "content": {"title": "Control Synthesis for High-Dimensional Systems With Counting Constraints", "abstract": "General purpose correct-by-construction synthesis methods are limited to systems with low dimensionality or simple specifications. In this work we consider highly symmetrical counting problems and exploit the symmetry to synthesize provably correct controllers for systems with tens of thousands of states. The key ingredients of the solution are an aggregate abstraction procedure for mildly heterogeneous systems and subsequent formulation of counting constraints as linear inequalities.", "year": 2017, "ssId": "fa774368fcf51cc0fa1bfda59b6a606e163c64b1", "arXivId": "1706.07863", "link": "https://arxiv.org/pdf/1706.07863.pdf", "openAccess": true, "authors": ["Petter Nilsson", "N. Ozay"]}}, "7cc74ffa1215321712d4a830bb9dee19d9f0fb47": {"id": "7cc74ffa1215321712d4a830bb9dee19d9f0fb47", "content": {"title": "Grounded Graph Decoding Improves Compositional Generalization in Question Answering", "abstract": "Question answering models struggle to generalize to novel compositions of training patterns, such to longer sequences or more complex test structures. Current end-to-end models learn a flat input embedding which can lose input syntax context. Prior approaches improve generalization by learning permutation invariant models, but these methods do not scale to more complex train-test splits. We propose Grounded Graph Decoding, a method to improve compositional generalization of language representations by grounding structured predictions with an attention mechanism. Grounding enables the model to retain syntax information from the input in thereby significantly improving generalization over complex inputs. By predicting a structured graph containing conjunctions of query clauses, we learn a group invariant representation without making assumptions on the target domain. Our model significantly outperforms state-ofthe-art baselines on the Compositional Freebase Questions (CFQ) dataset, a challenging benchmark for compositional generalization in question answering. Moreover, we effectively solve the MCD1 split with 98% accuracy. All source is available at https:// github.com/gaiyu0/cfq.", "year": 2021, "ssId": "7cc74ffa1215321712d4a830bb9dee19d9f0fb47", "arXivId": "2111.03642", "link": "https://arxiv.org/pdf/2111.03642.pdf", "openAccess": true, "authors": ["Yu Gai", "Paras Jain", "Wendi Zhang", "Joseph Gonzalez", "D. Song", "I. Stoica"]}}, "be28821d510a99ffce40cdcf6860302def8533ef": {"id": "be28821d510a99ffce40cdcf6860302def8533ef", "content": {"title": "From Recommendation Systems to Facility Location Games", "abstract": "Recommendation systems are extremely popular tools for matching users and contents. However, when content providers are strategic, the basic principle of matching users to the closest content, where both users and contents are modeled as points in some semantic space, may yield low social welfare. This is due to the fact that content providers are strategic and optimize their offered content to be recommended to as many users as possible. Motivated by modern applications, we propose the widely studied framework of facility location games to study recommendation systems with strategic content providers. Our conceptual contribution is the introduction of a mediator to facility location models, in the pursuit of better social welfare. We aim at designing mediators that a) induce a game with high social welfare in equilibrium, and b) intervene as little as possible. In service of the latter, we introduce the notion of intervention cost, which quantifies how much damage a mediator may cause to the social welfare when an off-equilibrium profile is adopted. As a case study in high-welfare low-intervention mediator design, we consider the one-dimensional segment as the user domain. We propose a mediator that implements the socially optimal strategy profile as the unique equilibrium profile, and show a tight bound on its intervention cost. Ultimately, we consider some extensions, and highlight open questions for the general agenda.", "year": 2018, "ssId": "be28821d510a99ffce40cdcf6860302def8533ef", "arXivId": "1809.02931", "link": "https://arxiv.org/pdf/1809.02931.pdf", "openAccess": true, "authors": ["Omer Ben-Porat", "Gregory Goren", "Itay Rosenberg", "Moshe Tennenholtz"]}}, "29dc4b10e60ed1e2b84598cc6f2622c786841fdf": {"id": "29dc4b10e60ed1e2b84598cc6f2622c786841fdf", "content": {"title": "Control of Mobile Robots Using Barrier Functions Under Temporal Logic Specifications", "abstract": "In this article, we propose a framework for the control of mobile robots subject to temporal logic specifications using barrier functions. Complex task specifications can be conveniently encoded using linear temporal logic. In particular, we consider a fragment of linear temporal logic, which encompasses a large class of motion planning specifications for a robotic system. Control barrier functions have recently emerged as a convenient tool to guarantee reachability and safety for a system. In addition, they can be encoded as affine constraints in a quadratic program. In this article, a fully automatic framework that translates a user defined specification in temporal logic to a sequence of barrier function based quadratic programs is presented. In addition, with the aim of alleviating infeasibility scenarios, we propose methods for composition of barrier functions as well as a prioritization-based control method to guarantee feasibility of the controller. We prove that the resulting system trajectory synthesized by the proposed controller satisfies the given specification. Robotic simulation and experimental results are provided in addition to the theoretical framework.", "year": 2019, "ssId": "29dc4b10e60ed1e2b84598cc6f2622c786841fdf", "arXivId": "1908.04903", "link": "https://arxiv.org/pdf/1908.04903.pdf", "openAccess": true, "authors": ["Mohit Srinivasan", "S. Coogan"]}}, "acbb4495dd698b3190db6899d7d35b0817e0a85e": {"id": "acbb4495dd698b3190db6899d7d35b0817e0a85e", "content": {"title": "Train simultaneously, generalize better: Stability of gradient-based minimax learners", "abstract": "The success of minimax learning problems of generative adversarial networks (GANs) has been observed to depend on the minimax optimization algorithm used for their training. This dependence is commonly attributed to the convergence speed and robustness properties of the underlying optimization algorithm. In this paper, we show that the optimization algorithm also plays a key role in the generalization performance of the trained minimax model. To this end, we analyze the generalization properties of standard gradient descent ascent (GDA) and proximal point method (PPM) algorithms through the lens of algorithmic stability under both convex concave and non-convex non-concave minimax settings. While the GDA algorithm is not guaranteed to have a vanishing excess risk in convex concave problems, we show the PPM algorithm enjoys a bounded excess risk in the same setup. For non-convex non-concave problems, we compare the generalization performance of stochastic GDA and GDmax algorithms where the latter fully solves the maximization subproblem at every iteration. Our generalization analysis suggests the superiority of GDA provided that the minimization and maximization subproblems are solved simultaneously with similar learning rates. We discuss several numerical results indicating the role of optimization algorithms in the generalization of the learned minimax models.", "year": 2020, "ssId": "acbb4495dd698b3190db6899d7d35b0817e0a85e", "arXivId": "2010.12561", "link": "https://arxiv.org/pdf/2010.12561.pdf", "openAccess": true, "authors": ["Farzan Farnia", "A. Ozdaglar"]}}, "16f0c508aa54e26aa18e3b0f3c91b0c143c6a605": {"id": "16f0c508aa54e26aa18e3b0f3c91b0c143c6a605", "content": {"title": "Fairness Without Demographics in Repeated Loss Minimization", "abstract": "Machine learning models (e.g., speech recognizers) are usually trained to minimize average loss, which results in representation disparity---minority groups (e.g., non-native speakers) contribute less to the training objective and thus tend to suffer higher loss. Worse, as model accuracy affects user retention, a minority group can shrink over time. In this paper, we first show that the status quo of empirical risk minimization (ERM) amplifies representation disparity over time, which can even make initially fair models unfair. To mitigate this, we develop an approach based on distributionally robust optimization (DRO), which minimizes the worst case risk over all distributions close to the empirical distribution. We prove that this approach controls the risk of the minority group at each time step, in the spirit of Rawlsian distributive justice, while remaining oblivious to the identity of the groups. We demonstrate that DRO prevents disparity amplification on examples where ERM fails, and show improvements in minority group user satisfaction in a real-world text autocomplete task.", "year": 2018, "ssId": "16f0c508aa54e26aa18e3b0f3c91b0c143c6a605", "arXivId": "1806.08010", "link": "https://arxiv.org/pdf/1806.08010.pdf", "openAccess": true, "authors": ["Tatsunori B. Hashimoto", "Megha Srivastava", "Hongseok Namkoong", "Percy Liang"]}}, "89c2cbdf1a5049a4068ca9215aa8859a1a97b1a3": {"id": "89c2cbdf1a5049a4068ca9215aa8859a1a97b1a3", "content": {"title": "Taming the Monster: A Fast and Simple Algorithm for Contextual Bandits", "abstract": "We present a new algorithm for the contextual bandit learning problem, where the learner repeatedly takes one of K actions in response to the observed context, and observes the reward only for that action. Our method assumes access to an oracle for solving fully supervised cost-sensitive classification problems and achieves the statistically optimal regret guarantee with only O(\u221aKT) oracle calls across all T rounds. By doing so, we obtain the most practical contextual bandit learning algorithm amongst approaches that work for general policy classes. We conduct a proof-of-concept experiment which demonstrates the excellent computational and statistical performance of (an online variant of) our algorithm relative to several strong baselines.", "year": 2014, "ssId": "89c2cbdf1a5049a4068ca9215aa8859a1a97b1a3", "arXivId": "1402.0555", "link": "https://arxiv.org/pdf/1402.0555.pdf", "openAccess": true, "authors": ["Alekh Agarwal", "Daniel J. Hsu", "Satyen Kale", "J. Langford", "Lihong Li", "R. Schapire"]}}, "2cd2df06d488565063e0600ff840d293be2eaf31": {"id": "2cd2df06d488565063e0600ff840d293be2eaf31", "content": {"title": "A simple adaptive procedure leading to correlated equilibrium", "abstract": "We propose a new and simple adaptive procedure for playing a game: \u2018\u2018regret-matching.\u2019\u2019 In this procedure, players may depart from their current play with probabilities that are proportional to measures of regret for not having used other strategies in the past. It is shown that our adaptive procedure guarantees that, with probability one, the empirical distributions of play converge to the set of correlated equilibria of the game.", "year": 2000, "ssId": "2cd2df06d488565063e0600ff840d293be2eaf31", "arXivId": null, "link": "http://www.dklevine.com/archive/refs4572.pdf", "openAccess": true, "authors": ["S. Hart", "A. Mas-Colell"]}}, "8c4b187bdaf91bf068adfe005a0463c4f9c36387": {"id": "8c4b187bdaf91bf068adfe005a0463c4f9c36387", "content": {"title": "Beyond the Pixel-Wise Loss for Topology-Aware Delineation", "abstract": "Delineation of curvilinear structures is an important problem in Computer Vision with multiple practical applications. With the advent of Deep Learning, many current approaches on automatic delineation have focused on finding more powerful deep architectures, but have continued using the habitual pixel-wise losses such as binary cross-entropy. In this paper we claim that pixel-wise losses alone are unsuitable for this problem because of their inability to reflect the topological impact of mistakes in the final prediction. We propose a new loss term that is aware of the higher-order topological features of linear structures. We also exploit a refinement pipeline that iteratively applies the same model over the previous delineation to refine the predictions at each step, while keeping the number of parameters and the complexity of the model constant. When combined with the standard pixel-wise loss, both our new loss term and an iterative refinement boost the quality of the predicted delineations, in some cases almost doubling the accuracy as compared to the same classifier trained with the binary cross-entropy alone. We show that our approach outperforms state-of-the-art methods on a wide range of data, from microscopy to aerial images.", "year": 2017, "ssId": "8c4b187bdaf91bf068adfe005a0463c4f9c36387", "arXivId": "1712.02190", "link": "https://arxiv.org/pdf/1712.02190.pdf", "openAccess": true, "authors": ["Agata Mosinska", "Pablo M\u00e1rquez-Neila", "Mateusz Kozi\u0144ski", "P. Fua"]}}, "40f4d7fe800810288a80f84cdb357a8f4c28e880": {"id": "40f4d7fe800810288a80f84cdb357a8f4c28e880", "content": {"title": "Rethinking Spatial Dimensions of Vision Transformers", "abstract": "Vision Transformer (ViT) extends the application range of transformers from language processing to computer vision tasks as being an alternative architecture against the existing convolutional neural networks (CNN). Since the transformer-based architecture has been innovative for computer vision modeling, the design convention towards an effective architecture has been less studied yet. From the successful design principles of CNN, we investigate the role of spatial dimension conversion and its effectiveness on transformer-based architecture. We particularly attend to the dimension reduction principle of CNNs; as the depth increases, a conventional CNN increases channel dimension and decreases spatial dimensions. We empirically show that such a spatial dimension reduction is beneficial to a transformer architecture as well, and propose a novel Pooling-based Vision Transformer (PiT) upon the original ViT model. We show that PiT achieves the improved model capability and generalization performance against ViT. Throughout the extensive experiments, we further show PiT outperforms the baseline on several tasks such as image classification, object detection, and robustness evaluation. Source codes and ImageNet models are available at https://github.com/naver-ai/pit.", "year": 2021, "ssId": "40f4d7fe800810288a80f84cdb357a8f4c28e880", "arXivId": "2103.16302", "link": "https://arxiv.org/pdf/2103.16302.pdf", "openAccess": true, "authors": ["Byeongho Heo", "Sangdoo Yun", "Dongyoon Han", "Sanghyuk Chun", "Junsuk Choe", "Seong Joon Oh"]}}, "3e398bad2d8636491a1034cc938a5e024c7aa881": {"id": "3e398bad2d8636491a1034cc938a5e024c7aa881", "content": {"title": "Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions", "abstract": "Although convolutional neural networks (CNNs) have achieved great success in computer vision, this work investigates a simpler, convolution-free backbone network use-fid for many dense prediction tasks. Unlike the recently-proposed Vision Transformer (ViT) that was designed for image classification specifically, we introduce the Pyramid Vision Transformer (PVT), which overcomes the difficulties of porting Transformer to various dense prediction tasks. PVT has several merits compared to current state of the arts. (1) Different from ViT that typically yields low-resolution outputs and incurs high computational and memory costs, PVT not only can be trained on dense partitions of an image to achieve high output resolution, which is important for dense prediction, but also uses a progressive shrinking pyramid to reduce the computations of large feature maps. (2) PVT inherits the advantages of both CNN and Transformer, making it a unified backbone for various vision tasks without convolutions, where it can be used as a direct replacement for CNN backbones. (3) We validate PVT through extensive experiments, showing that it boosts the performance of many downstream tasks, including object detection, instance and semantic segmentation. For example, with a comparable number of parameters, PVT+RetinaNet achieves 40.4 AP on the COCO dataset, surpassing ResNet50+RetinNet (36.3 AP) by 4.1 absolute AP (see Figure 2). We hope that PVT could, serre as an alternative and useful backbone for pixel-level predictions and facilitate future research.", "year": 2021, "ssId": "3e398bad2d8636491a1034cc938a5e024c7aa881", "arXivId": "2102.12122", "link": "https://arxiv.org/pdf/2102.12122.pdf", "openAccess": true, "authors": ["Wenhai Wang", "Enze Xie", "Xiang Li", "Deng-Ping Fan", "Kaitao Song", "Ding Liang", "Tong Lu", "P. Luo", "L. Shao"]}}, "7707af52b3e19bfd3fc07c2be5aed044e5d7953a": {"id": "7707af52b3e19bfd3fc07c2be5aed044e5d7953a", "content": {"title": "Persistent Homology with Improved Locality Information for more Effective Delineation", "abstract": "We present a new, more effective way to use Persistent Homology (PH), a method to compare the topology of two data sets, for training deep networks to delineate road networks in aerial images and neuronal processes in microscopy scans. Its essence is in a novel filtration function, derived from a fusion of two existing techniques: thresholding-based filtration, previously used to train deep networks to segment medical images, and filtration with height functions, used before for comparison of 2D and 3D shapes. We experimentally demonstrate that deep networks trained with our Persistent-Homology-based loss yield reconstructions of road networks and neuronal processes that preserve the connectivity of the originals better than existing topological and non-topological loss functions.", "year": 2021, "ssId": "7707af52b3e19bfd3fc07c2be5aed044e5d7953a", "arXivId": "2110.06295", "link": "https://arxiv.org/pdf/2110.06295.pdf", "openAccess": true, "authors": ["Doruk Oner", "A. Garin", "Mateusz Kozi'nski", "K. Hess", "P. Fua"]}}, "1f133158a8973fb33fea188f20517cd7e69bfe7f": {"id": "1f133158a8973fb33fea188f20517cd7e69bfe7f", "content": {"title": "FNet: Mixing Tokens with Fourier Transforms", "abstract": "We show that Transformer encoder architectures can be massively sped up, with limited accuracy costs, by replacing the self-attention sublayers with simple linear transformations that \u201cmix\u201d input tokens. These linear transformations, along with simple nonlinearities in feed-forward layers, are sufficient to model semantic relationships in several text classification tasks. Perhaps most surprisingly, we find that replacing the self-attention sublayer in a Transformer encoder with a standard, unparameterized Fourier Transform achieves 92% of the accuracy of BERT on the GLUE benchmark, but pre-trains and runs up to seven times faster on GPUs and twice as fast on TPUs. The resulting model, which we name FNet, scales very efficiently to long inputs, matching the accuracy of the most accurate \u201cefficient\u201d Transformers on the Long Range Arena benchmark, but training and running faster across all sequence lengths on GPUs and relatively shorter sequence lengths on TPUs. Finally, FNet has a light memory footprint and is particularly efficient at smaller model sizes: for a fixed speed and accuracy budget, small FNet models outperform Transformer counterparts.", "year": 2021, "ssId": "1f133158a8973fb33fea188f20517cd7e69bfe7f", "arXivId": "2105.03824", "link": "https://arxiv.org/pdf/2105.03824.pdf", "openAccess": true, "authors": ["J. Lee-Thorp", "J. Ainslie", "Ilya Eckstein", "Santiago Onta\u00f1\u00f3n"]}}, "1e9771a264334c45020421b1c847f6bcd88adc60": {"id": "1e9771a264334c45020421b1c847f6bcd88adc60", "content": {"title": "Adjusting the Ground Truth Annotations for Connectivity-Based Learning to Delineate", "abstract": "Deep learning-based approaches to delineating 3D structure depend on accurate annotations to train the networks. Yet, in practice, people, no matter how conscientious, have trouble precisely delineating in 3D and on a large scale, in part because the data is often hard to interpret visually and in part because the 3D interfaces are awkward to use. In this paper, we introduce a method that explicitly accounts for annotation inaccuracies. To this end, we treat the annotations as active contour models that can deform themselves while preserving their topology. This enables us to jointly train the network and correct potential errors in the original annotations. The result is an approach that boosts performance of deep networks trained with potentially inaccurate annotations.", "year": 2021, "ssId": "1e9771a264334c45020421b1c847f6bcd88adc60", "arXivId": "2112.02781", "link": "https://arxiv.org/pdf/2112.02781.pdf", "openAccess": true, "authors": ["Doruk Oner", "L. Citraro", "Mateusz Kozi'nski", "P. Fua"]}}, "657329c633709dd1ac34a30d57341b186b1a47c2": {"id": "657329c633709dd1ac34a30d57341b186b1a47c2", "content": {"title": "Efficient Content-Based Sparse Attention with Routing Transformers", "abstract": "Self-attention has recently been adopted for a wide range of sequence modeling problems. Despite its effectiveness, self-attention suffers from quadratic computation and memory requirements with respect to sequence length. Successful approaches to reduce this complexity focused on attending to local sliding windows or a small set of locations independent of content. Our work proposes to learn dynamic sparse attention patterns that avoid allocating computation and memory to attend to content unrelated to the query of interest. This work builds upon two lines of research: It combines the modeling flexibility of prior work on content-based sparse attention with the efficiency gains from approaches based on local, temporal sparse attention. Our model, the Routing Transformer, endows self-attention with a sparse routing module based on online k-means while reducing the overall complexity of attention to O(n1.5d) from O(n2d) for sequence length n and hidden dimension d. We show that our model outperforms comparable sparse attention models on language modeling on Wikitext-103 (15.8 vs 18.3 perplexity), as well as on image generation on ImageNet-64 (3.43 vs 3.44 bits/dim) while using fewer self-attention layers. Additionally, we set a new state-of-the-art on the newly released PG-19 data-set, obtaining a test perplexity of 33.2 with a 22 layer Routing Transformer model trained on sequences of length 8192. We open-source the code for Routing Transformer in Tensorflow.1", "year": 2020, "ssId": "657329c633709dd1ac34a30d57341b186b1a47c2", "arXivId": "2003.05997", "link": "https://arxiv.org/pdf/2003.05997.pdf", "openAccess": true, "authors": ["Aurko Roy", "M. Saffar", "Ashish Vaswani", "David Grangier"]}}, "1134ec4cdfc1c2161d157b0f4e03dec85d8c4c8a": {"id": "1134ec4cdfc1c2161d157b0f4e03dec85d8c4c8a", "content": {"title": "Promoting Connectivity of Network-Like Structures by Enforcing Region Separation", "abstract": "We propose a novel, connectivity-oriented loss function for training deep convolutional networks to reconstruct network-like structures, like roads and irrigation canals, from aerial images. The main idea behind our loss is to express the connectivity of roads, or canals, in terms of disconnections that they create between background regions of the image. In simple terms, a gap in the predicted road causes two background regions, that lie on the opposite sides of a ground truth road, to touch in prediction. Our loss function is designed to prevent such unwanted connections between background regions, and therefore close the gaps in predicted roads. It also prevents predicting false positive roads and canals by penalizing unwarranted disconnections of background regions. In order to capture even short, dead-ending road segments, we evaluate the loss in small image crops. We show, in experiments on two standard road benchmarks and a new data set of irrigation canals, that convnets trained with our loss function recover road connectivity so well that it suffices to skeletonize their output to produce state of the art maps. A distinct advantage of our approach is that the loss can be plugged in to any existing training setup without further modifications.", "year": 2020, "ssId": "1134ec4cdfc1c2161d157b0f4e03dec85d8c4c8a", "arXivId": "2009.07011", "link": "https://arxiv.org/pdf/2009.07011.pdf", "openAccess": true, "authors": ["Doruk \u00d6ner", "Mateusz Kozi\u0144ski", "L. Citraro", "N. Dadap", "A. Konings", "P. Fua"]}}, "f432d10677897cf72f9594ba7bd4c9199b270fb3": {"id": "f432d10677897cf72f9594ba7bd4c9199b270fb3", "content": {"title": "Good Classification Measures and How to Find Them", "abstract": "Several performance measures can be used for evaluating classification results: accuracy, F-measure, and many others. Can we say that some of them are better than others, or, ideally, choose one measure that is best in all situations? To answer this question, we conduct a systematic analysis of classification performance measures: we formally define a list of desirable properties and theoretically analyze which measures satisfy which properties. We also prove an impossibility theorem: some desirable properties cannot be simultaneously satisfied. Finally, we propose a new family of measures satisfying all desirable properties except one. This family includes the Matthews correlation coefficient and a so-called symmetric balanced accuracy that was not previously used in classification literature. We believe that our systematic approach gives an important tool to practitioners for adequately evaluating classification results.", "year": 2022, "ssId": "f432d10677897cf72f9594ba7bd4c9199b270fb3", "arXivId": "2201.09044", "link": "https://arxiv.org/pdf/2201.09044.pdf", "openAccess": true, "authors": ["Martijn G\u00f6sgens", "A. Zhiyanov", "Alexey Tikhonov", "L. Prokhorenkova"]}}, "6a4deeb40aed8a4d56c8d9401c94b6c7a769e8c3": {"id": "6a4deeb40aed8a4d56c8d9401c94b6c7a769e8c3", "content": {"title": "CSFCube - A Test Collection of Computer Science Research Articles for Faceted Query by Example", "abstract": "Query by Example is a well-known information retrieval task in which a document is chosen by the user as the search query and the goal is to retrieve relevant documents from a large collection. However, a document often covers multiple aspects of a topic. To address this scenario we introduce the task of faceted Query by Example in which users can also specify a finer grained aspect in addition to the input query document. We focus on the application of this task in scientific literature search. We envision models which are able to retrieve scientific papers analogous to a query scientific paper along specifically chosen rhetorical structure elements as one solution to this problem. In this work, the rhetorical structure elements, which we refer to as facets, indicate backgrounds, methods, or results of a scientific paper. We introduce and describe an expert annotated test collection to evaluate models trained to perform this task. Our test collection consists of a diverse set of 50 query documents, drawn from computational linguistics and machine learning venues. We carefully followed the annotation guideline used by TREC for depth-k pooling (k = 100 or 250) and the resulting data collection consists of graded relevance scores with high annotation agreement. The data is freely available for research purposes.", "year": 2021, "ssId": "6a4deeb40aed8a4d56c8d9401c94b6c7a769e8c3", "arXivId": "2103.12906", "link": "https://arxiv.org/pdf/2103.12906.pdf", "openAccess": true, "authors": ["Sheshera Mysore", "Timothy J. O'Gorman", "A. McCallum", "Hamed Zamani"]}}, "63d7e40da7f0d37308b8e97fca4a14a26a6b52ea": {"id": "63d7e40da7f0d37308b8e97fca4a14a26a6b52ea", "content": {"title": "\u201cEveryone wants to do the model work, not the data work\u201d: Data Cascades in High-Stakes AI", "abstract": "AI models are increasingly applied in high-stakes domains like health and conservation. Data quality carries an elevated significance in high-stakes AI due to its heightened downstream impact, impacting predictions like cancer detection, wildlife poaching, and loan allocations. Paradoxically, data is the most under-valued and de-glamorised aspect of AI. In this paper, we report on data practices in high-stakes AI, from interviews with 53 AI practitioners in India, East and West African countries, and USA. We define, identify, and present empirical evidence on Data Cascades\u2014compounding events causing negative, downstream effects from data issues\u2014triggered by conventional AI/ML practices that undervalue data quality. Data cascades are pervasive (92% prevalence), invisible, delayed, but often avoidable. We discuss HCI opportunities in designing and incentivizing data excellence as a first-class citizen of AI, resulting in safer and more robust systems for all.", "year": 2021, "ssId": "63d7e40da7f0d37308b8e97fca4a14a26a6b52ea", "arXivId": null, "link": "https://storage.googleapis.com/pub-tools-public-publication-data/pdf/0d556e45afc54afeb2eb6b51a9bc1827b9961ff4.pdf", "openAccess": true, "authors": ["Nithya Sambasivan", "Shivani Kapania", "H. Highfill", "Diana Akrong", "Praveen K. Paritosh", "Lora Aroyo"]}}, "341c72f55a89572915aa476db7f525c2e0b60eba": {"id": "341c72f55a89572915aa476db7f525c2e0b60eba", "content": {"title": "Systematic Analysis of Cluster Similarity Indices: How to Validate Validation Measures", "abstract": "There are many cluster similarity indices used to evaluate clustering algorithms, and choosing the best one for a particular task is usually an open problem. In this paper, we perform a thorough analysis of this problem: we develop a list of desirable properties (requirements) and theoretically verify which indices satisfy them. In particular, we investigate dozens of pair-counting indices and prove that none of them meet all the requirements. Based on our analysis, we propose using the arccosine of the correlation coefficient as a similarity measure and show that it satisfies almost all the requirements (except for one, which is still satisfied asymptotically). We illustrate the practical importance of our analysis via an online experiment within a major news aggregator system.", "year": 2019, "ssId": "341c72f55a89572915aa476db7f525c2e0b60eba", "arXivId": "1911.04773", "link": "https://arxiv.org/pdf/1911.04773.pdf", "openAccess": true, "authors": ["Martijn G\u00f6sgens", "Alexey Tikhonov", "L. Prokhorenkova"]}}, "b02acb3d159b06b2319a164378e1e61c3983676f": {"id": "b02acb3d159b06b2319a164378e1e61c3983676f", "content": {"title": "Benchmarking the Combinatorial Generalizability of Complex Query Answering on Knowledge Graphs", "abstract": "Complex Query Answering (CQA) is an important reasoning task on knowledge graphs. Current CQA learning models have been shown to be able to generalize from atomic operators to more complex formulas, which can be regarded as the combinatorial generalizability. In this paper, we present EFO-1-QA, a new dataset to benchmark the combinatorial generalizability of CQA models by including 301 different queries types, which is 20 times larger than existing datasets. Besides, our benchmark, for the first time, provide a benchmark to evaluate and analyze the impact of different operators and normal forms by using (a) 7 choices of the operator systems and (b) 9 forms of complex queries. Specifically, we provide the detailed study of the combinatorial generalizability of two commonly used operators, i.e., projection and intersection, and justify the impact of the forms of queries given the canonical choice of operators. Our code and data can provide an effective pipeline to benchmark CQA models. 2", "year": 2021, "ssId": "b02acb3d159b06b2319a164378e1e61c3983676f", "arXivId": "2109.08925", "link": "https://arxiv.org/pdf/2109.08925.pdf", "openAccess": true, "authors": ["Zihao Wang", "Hang Yin", "Yangqiu Song"]}}, "4c67c129dab9805ab248407b77a6d542c2e40d41": {"id": "4c67c129dab9805ab248407b77a6d542c2e40d41", "content": {"title": "Adversarial Crowdsourcing Through Robust Rank-One Matrix Completion", "abstract": "We consider the problem of reconstructing a rank-one matrix from a revealed subset of its entries when some of the revealed entries are corrupted with perturbations that are unknown and can be arbitrarily large. It is not known which revealed entries are corrupted. We propose a new algorithm combining alternating minimization with extreme-value filtering and provide sufficient and necessary conditions to recover the original rank-one matrix. In particular, we show that our proposed algorithm is optimal when the set of revealed entries is given by an Erd\u0151s-Renyi random graph. These results are then applied to the problem of classification from crowdsourced data under the assumption that while the majority of the workers are governed by the standard single-coin David-Skene model (i.e., they output the correct answer with a certain probability), some of the workers can deviate arbitrarily from this model. In particular, the \"adversarial\" workers could even make decisions designed to make the algorithm output an incorrect answer. Extensive experimental results show our algorithm for this problem, based on rank-one matrix completion with perturbations, outperforms all other state-of-the-art methods in such an adversarial scenario.", "year": 2020, "ssId": "4c67c129dab9805ab248407b77a6d542c2e40d41", "arXivId": "2010.12181", "link": "https://arxiv.org/pdf/2010.12181.pdf", "openAccess": true, "authors": ["Qianqian Ma", "Alexander Olshevsky"]}}, "9389af659f14239319186dff1cef49e8ece742c8": {"id": "9389af659f14239319186dff1cef49e8ece742c8", "content": {"title": "OGB-LSC: A Large-Scale Challenge for Machine Learning on Graphs", "abstract": "Enabling effective and ef\ufb01cient machine learning (ML) over large-scale graph data ( e.g. , graphs with billions of edges) can have a great impact on both industrial and scienti\ufb01c applications. However, existing efforts to advance large-scale graph ML have been largely limited by the lack of a suitable public benchmark. Here we present OGB Large-Scale Challenge (OGB-LSC), a collection of three real-world datasets for facilitating the advancements in large-scale graph ML. The OGB-LSC datasets are orders of magnitude larger than existing ones, covering three core graph learning tasks\u2014link prediction, graph regression, and node classi\ufb01cation. Furthermore, we provide dedicated baseline experiments, scaling up expressive graph ML models to the massive datasets. We show that expressive models signi\ufb01cantly outperform simple scalable baselines, indicating an opportunity for dedicated efforts to further improve graph ML at scale. Moreover, OGB-LSC datasets were deployed at ACM KDD Cup 2021 and attracted more than 500 team registrations globally, during which signi\ufb01cant performance im-provements were made by a variety of innovative techniques. We summarize the common techniques used by the winning solutions and highlight the current best practices in large-scale graph ML. Finally, we describe how we have updated the datasets after the KDD Cup to further facilitate research advances. The OGB-LSC datasets, baseline code, and all the information about the KDD Cup are available at https://ogb.stanford.edu/docs/lsc/ .", "year": 2021, "ssId": "9389af659f14239319186dff1cef49e8ece742c8", "arXivId": "2103.09430", "link": "https://arxiv.org/pdf/2103.09430.pdf", "openAccess": true, "authors": ["Weihua Hu", "Matthias Fey", "Hongyu Ren", "Maho Nakata", "Yuxiao Dong", "J. Leskovec"]}}, "90766546b29836eb96f54fe8fd70ec51a3e699ba": {"id": "90766546b29836eb96f54fe8fd70ec51a3e699ba", "content": {"title": "VoroCNN: deep convolutional neural network built on 3D Voronoi tessellation of protein structures", "abstract": "MOTIVATION\nEffective use of evolutionary information has recently led to tremendous progress in computational prediction of three-dimensional (3D) structures of proteins and their complexes. Despite the progress, the accuracy of predicted structures tends to vary considerably from case to case. Since the utility of computational models depends on their accuracy, reliable estimates of deviation between predicted and native structures are of utmost importance.\n\n\nRESULTS\nFor the first time, we present a deep convolutional neural network (CNN) constructed on a Voronoi tessellation of 3D molecular structures. Despite the irregular data domain, our data representation allows us to efficiently introduce both convolution and pooling operations and train the network in an end-to-end fashion without precomputed descriptors. The resultant model, VoroCNN, predicts local qualities of 3D protein folds. The prediction results are competitive to state of the art and superior to the previous 3D CNN architectures built for the same task. We also discuss practical applications of VoroCNN, for example, in recognition of protein binding interfaces.\n\n\nAVAILABILITY\nThe model, data, and evaluation tests are available at https://team.inria.fr/nano-d/software/vorocnn/.\n\n\nSUPPLEMENTARY INFORMATION\nSupplementary data are available at Bioinformatics online.", "year": 2021, "ssId": "90766546b29836eb96f54fe8fd70ec51a3e699ba", "arXivId": null, "link": "https://hal.archives-ouvertes.fr/hal-02558004/file/VoroCNN-bioRxiv.pdf", "openAccess": true, "authors": ["Ilia Igashov", "Liment Olechnovi\u010d", "Maria Kadukova", "\u010c. Venclovas", "Sergei Grudinin"]}}, "4d41c2fa74dd018e39ddb3cbbfead1b42615612c": {"id": "4d41c2fa74dd018e39ddb3cbbfead1b42615612c", "content": {"title": "Parameter Prediction for Unseen Deep Architectures", "abstract": "Deep learning has been successful in automating the design of features in machine learning pipelines. However, the algorithms optimizing neural network parameters remain largely hand-designed and computationally inefficient. We study if we can use deep learning to directly predict these parameters by exploiting the past knowledge of training other networks. We introduce a large-scale dataset of diverse computational graphs of neural architectures \u2013 DEEPNETS-1M\u2013 and use it to explore parameter prediction on CIFAR-10 and ImageNet. By leveraging advances in graph neural networks, we propose a hypernetwork that can predict performant parameters in a single forward pass taking a fraction of a second, even on a CPU. The proposed model achieves surprisingly good performance on unseen and diverse networks. For example, it is able to predict all 24 million parameters of a ResNet-50 achieving a 60% accuracy on CIFAR-10. On ImageNet, top-5 accuracy of some of our networks approaches 50%. Our task along with the model and results can potentially lead to a new, more computationally efficient paradigm of training networks. Our model also learns a strong representation of neural architectures enabling their analysis.", "year": 2021, "ssId": "4d41c2fa74dd018e39ddb3cbbfead1b42615612c", "arXivId": "2110.13100", "link": "https://arxiv.org/pdf/2110.13100.pdf", "openAccess": true, "authors": ["Boris Knyazev", "M. Drozdzal", "Graham W. Taylor", "Adriana Romero-Soriano"]}}, "11c6d0851152b6bec34726be40d90bea8d8a90f0": {"id": "11c6d0851152b6bec34726be40d90bea8d8a90f0", "content": {"title": "Learning from Crowds by Modeling Common Confusions", "abstract": "Crowdsourcing provides a practical way to obtain large amounts of labeled data at a low cost. However, the annotation quality of annotators varies considerably, which imposes new challenges in learning a high-quality model from the crowdsourced annotations. In this work, we provide a new perspective to decompose annotation noise into common noise and individual noise and differentiate the source of confusion based on instance difficulty and annotator expertise on a per-instance-annotator basis. We realize this new crowdsourcing model by an end-to-end learning solution with two types of noise adaptation layers: one is shared across annotators to capture their commonly shared confusions, and the other one is pertaining to each annotator to realize individual confusion. To recognize the source of noise in each annotation, we use an auxiliary network to choose from the two noise adaptation layers with respect to both instances and annotators. Extensive experiments on both synthesized and real-world benchmarks demonstrate the effectiveness of our proposed common noise adaptation solution.", "year": 2020, "ssId": "11c6d0851152b6bec34726be40d90bea8d8a90f0", "arXivId": "2012.13052", "link": "https://arxiv.org/pdf/2012.13052.pdf", "openAccess": true, "authors": ["Zhendong Chu", "Jing Ma", "Hongning Wang"]}}, "7c0ada3511b05897fb4d75c5f657b5fbd953caa8": {"id": "7c0ada3511b05897fb4d75c5f657b5fbd953caa8", "content": {"title": "Quantifying Voter Biases in Online Platforms", "abstract": "In content-based online platforms, use of aggregate user feedback (say, the sum of votes) is commonplace as the \"gold standard\" for measuring content quality. Use of vote aggregates, however, is at odds with the existing empirical literature, which suggests that voters are susceptible to different biases-reputation (e.g., of the poster), social influence (e.g., votes thus far), and position (e.g., answer position). Our goal is to quantify, in an observational setting, the degree of these biases in online platforms. Specifically, what are the causal effects of different impression signals-such as the reputation of the contributing user, aggregate vote thus far, and position of content-on a participant's vote on content? We adopt an instrumental variable (IV) framework to answer this question. We identify a set of candidate instruments, carefully analyze their validity, and then use the valid instruments to reveal the effects of the impression signals on votes. Our empirical study using log data from Stack Exchange websites shows that the bias estimates from our IV approach differ from the bias estimates from the ordinary least squares (OLS) method. In particular, OLS underestimates reputation bias (1.6-2.2x for gold badges) and position bias (up to 1.9x for the initial position) and overestimates social influence bias (1.8-2.3x for initial votes). The implications of our work include: redesigning user interface to avoid voter biases; making changes to platforms' policy to mitigate voter biases; detecting other forms of biases in online platforms.", "year": 2019, "ssId": "7c0ada3511b05897fb4d75c5f657b5fbd953caa8", "arXivId": "1910.00757", "link": "https://arxiv.org/pdf/1910.00757.pdf", "openAccess": true, "authors": ["Himel Dev", "K. Karahalios", "H. Sundaram"]}}, "no_ss": {"id": "no_ss", "content": {"title": "End-to-End Learning of Probabilistic Hierarchies on Graphs", "abstract": "We propose a novel probabilistic model over hierarchies on graphs obtained by continuous relaxation of tree-based hierarchies. We draw connections to Markov chain theory, enabling us to perform hierarchical clustering by efficient end-to-end optimization of relaxed versions of quality metrics such as Dasgupta cost or Tree-Sampling Divergence (TSD). We show that our model learns rich, high-quality hierarchies present in 11 real world graphs, including a large  graph with 2.3M nodes. Our model consistently outperforms recent as well as strong traditional baselines such as average linkage. Our model also obtains strong results on link prediction despite not being trained on this task, highlighting the quality of the hierarchies discovered by our model.", "year": 2021, "ssId": null, "arXivId": null, "link": null, "openAccess": false, "authors": ["Daniel Zugner", "Bertrand Charpentier", "Morgane Ayle", "Sascha Geringer", "Stephan Gunnemann"]}}, "1ce96d8dbf69199ebd043de6cfa25d7e48b8ab03": {"id": "1ce96d8dbf69199ebd043de6cfa25d7e48b8ab03", "content": {"title": "Causal Effects of Linguistic Properties", "abstract": "We consider the problem of using observational data to estimate the causal effects of linguistic properties. For example, does writing a complaint politely lead to a faster response time? How much will a positive product review increase sales? This paper addresses two technical challenges related to the problem before developing a practical method. First, we formalize the causal quantity of interest as the effect of a writer\u2019s intent, and establish the assumptions necessary to identify this from observational data. Second, in practice, we only have access to noisy proxies for the linguistic properties of interest\u2014e.g., predictions from classifiers and lexicons. We propose an estimator for this setting and prove that its bias is bounded when we perform an adjustment for the text. Based on these results, we introduce TextCause, an algorithm for estimating causal effects of linguistic properties. The method leverages (1) distant supervision to improve the quality of noisy proxies, and (2) a pre-trained language model (BERT) to adjust for the text. We show that the proposed method outperforms related approaches when estimating the effect of Amazon review sentiment on semi-simulated sales figures. Finally, we present an applied case study investigating the effects of complaint politeness on bureaucratic response times.", "year": 2020, "ssId": "1ce96d8dbf69199ebd043de6cfa25d7e48b8ab03", "arXivId": "2010.12919", "link": "https://arxiv.org/pdf/2010.12919.pdf", "openAccess": true, "authors": ["Reid Pryzant", "Dallas Card", "Dan Jurafsky", "Victor Veitch", "Dhanya Sridhar"]}}, "a278c07c8bd2921e59dd862cd91a0540dd340030": {"id": "a278c07c8bd2921e59dd862cd91a0540dd340030", "content": {"title": "Adapting Neural Networks for the Estimation of Treatment Effects", "abstract": "This paper addresses the use of neural networks for the estimation of treatment effects from observational data. Generally, estimation proceeds in two stages. First, we fit models for the expected outcome and the probability of treatment (propensity score) for each unit. Second, we plug these fitted models into a downstream estimator of the effect. Neural networks are a natural choice for the models in the first step. The question we address is: how can we adapt the design and training of the neural networks used in the first step in order to improve the quality of the final estimate of the treatment effect? We propose two adaptations based on insights from the statistical literature on the estimation of treatment effects. The first is a new architecture, the Dragonnet, that exploits the sufficiency of the propensity score for estimation adjustment. The second is a regularization procedure, targeted regularization, that induces a bias towards models that have non-parametrically optimal asymptotic properties `out-of-the-box`. Studies on benchmark datasets for causal inference show these adaptations outperform existing methods. Code is available at this http URL.", "year": 2019, "ssId": "a278c07c8bd2921e59dd862cd91a0540dd340030", "arXivId": "1906.02120", "link": "https://arxiv.org/pdf/1906.02120.pdf", "openAccess": true, "authors": ["Claudia Shi", "D. Blei", "Victor Veitch"]}}, "d119cc4051ed1206a0dac963cd23a84acf77fea7": {"id": "d119cc4051ed1206a0dac963cd23a84acf77fea7", "content": {"title": "Reliable Decisions with Threshold Calibration", "abstract": "Decision makers rely on probabilistic forecasts to predict the loss of different decision rules before deployment. When the forecasted probabilities match the true frequencies, predicted losses will be accurate. Although perfect forecasts are typically impossible, probabilities can be calibrated to match the true frequencies on average. However, we find that this average notion of calibration, which is typically used in practice, does not necessarily guarantee accurate decision loss prediction. Specifically in the regression setting, the loss of threshold decisions, which are decisions based on whether the forecasted outcome falls above or below a cutoff, might not be predicted accurately. We propose a stronger notion of calibration called threshold calibration, which is exactly the condition required to ensure that decision loss is predicted accurately for threshold decisions. We provide an efficient algorithm which takes an uncalibrated forecaster as input and provably outputs a threshold-calibrated forecaster. Our procedure allows downstream decision makers to confidently estimate the loss of any threshold decision under any threshold loss function. Empirically, threshold calibration improves decision loss prediction without compromising on the quality of the decisions in two real-world settings: hospital scheduling decisions and resource allocation decisions.", "year": 2021, "ssId": "d119cc4051ed1206a0dac963cd23a84acf77fea7", "arXivId": null, "link": "https://openreview.net/pdf?id=KNSi_LqyORt", "openAccess": true, "authors": ["Roshni Sahoo", "Shengjia Zhao", "Alyssa Chen", "S. Ermon"]}}, "7954b31ce1f6ad935808b7cf62c34bc118d20a9a": {"id": "7954b31ce1f6ad935808b7cf62c34bc118d20a9a", "content": {"title": "Finding Regions of Heterogeneity in Decision-Making via Expected Conditional Covariance", "abstract": "Individuals often make different decisions when faced with the same context, due to personal preferences and background. For instance, judges may vary in their leniency towards certain drug-related offenses, and doctors may vary in their preference for how to start treatment for certain types of patients. With these examples in mind, we present an algorithm for identifying types of contexts (e.g., types of cases or patients) with high inter-decision-maker disagreement. We formalize this as a causal inference problem, seeking a region where the assignment of decision-maker has a large causal effect on the decision. Our algorithm finds such a region by maximizing an empirical objective, and we give a generalization bound for its performance. In a semi-synthetic experiment, we show that our algorithm recovers the correct region of heterogeneity accurately compared to baselines. Finally, we apply our algorithm to real-world healthcare datasets, recovering variation that aligns with existing clinical knowledge.", "year": 2021, "ssId": "7954b31ce1f6ad935808b7cf62c34bc118d20a9a", "arXivId": "2110.14508", "link": "https://arxiv.org/pdf/2110.14508.pdf", "openAccess": true, "authors": ["Justin Lim", "Christina X. Ji", "Michael Oberst", "S. Blecker", "L. Horwitz", "D. Sontag"]}}, "298b72096b8a770b0cdb263dd53cf2463b8a1a1d": {"id": "298b72096b8a770b0cdb263dd53cf2463b8a1a1d", "content": {"title": "Using Text Embeddings for Causal Inference", "abstract": "We address causal inference with text documents. For example, does adding a theorem to a paper affect its chance of acceptance? Does reporting the gender of a forum post author affect the popularity of the post? We estimate these effects from observational data, where they may be confounded by features of the text such as the subject or writing quality. Although the text suffices for causal adjustment, it is prohibitively high-dimensional. The challenge is to find a low-dimensional text representation that can be used in causal inference. A key insight is that causal adjustment requires only the aspects of text that are predictive of both the treatment and outcome. Our proposed method adapts deep language models to learn low-dimensional embeddings from text that predict these values well; these embeddings suffice for causal adjustment. We establish theoretical properties of this method. We study it empirically on semi-simulated and real data on paper acceptance and forum post popularity. Code is available at this https URL.", "year": 2019, "ssId": "298b72096b8a770b0cdb263dd53cf2463b8a1a1d", "arXivId": "1905.12741", "link": "https://arxiv.org/pdf/1905.12741.pdf", "openAccess": true, "authors": ["Victor Veitch", "Dhanya Sridhar", "D. Blei"]}}, "ec084dac14a069da2e924ff7f3d5d2fb75b9b39a": {"id": "ec084dac14a069da2e924ff7f3d5d2fb75b9b39a", "content": {"title": "Multinomial Inverse Regression for Text Analysis", "abstract": "Text data, including speeches, stories, and other document forms, are often connected to sentiment variables that are of interest for research in marketing, economics, and elsewhere. It is also very high dimensional and difficult to incorporate into statistical analyses. This article introduces a straightforward framework of sentiment-sufficient dimension reduction for text data. Multinomial inverse regression is introduced as a general tool for simplifying predictor sets that can be represented as draws from a multinomial distribution, and we show that logistic regression of phrase counts onto document annotations can be used to obtain low-dimensional document representations that are rich in sentiment information. To facilitate this modeling, a novel estimation technique is developed for multinomial logistic regression with very high-dimensional response. In particular, independent Laplace priors with unknown variance are assigned to each regression coefficient, and we detail an efficient routine for maximization of the joint posterior over coefficients and their prior scale. This \u201cgamma-lasso\u201d scheme yields stable and effective estimation for general high-dimensional logistic regression, and we argue that it will be superior to current methods in many settings. Guidelines for prior specification are provided, algorithm convergence is detailed, and estimator properties are outlined from the perspective of the literature on nonconcave likelihood penalization. Related work on sentiment analysis from statistics, econometrics, and machine learning is surveyed and connected. Finally, the methods are applied in two detailed examples and we provide out-of-sample prediction studies to illustrate their effectiveness.", "year": 2010, "ssId": "ec084dac14a069da2e924ff7f3d5d2fb75b9b39a", "arXivId": "1012.2098", "link": "https://arxiv.org/pdf/1012.2098.pdf", "openAccess": true, "authors": ["Matt Taddy"]}}, "38705aa9e8ce6412d89c5b2beb9379b1013b33c2": {"id": "38705aa9e8ce6412d89c5b2beb9379b1013b33c2", "content": {"title": "Deep Neural Networks for Estimation and Inference: Application to Causal Effects and Other Semiparametric Estimands", "abstract": "We study deep neural networks and their use in semiparametric inference. We prove valid inference after first-step estimation with deep learning, a result new to the literature. We provide new rates of convergence for deep feedforward neural nets and, because our rates are sufficiently fast (in some cases minimax optimal), obtain valid semiparametric inference. Our estimation rates and semiparametric inference results handle the current standard architecture: fully connected feedforward neural networks (multi-layer perceptrons), with the now-common rectified linear unit activation function and a depth explicitly diverging with the sample size. We discuss other architectures as well, including fixed-width, very deep networks. We establish nonasymptotic bounds for these deep nets for nonparametric regression, covering the standard least squares and logistic losses in particular. We then apply our theory to develop semiparametric inference, focusing on treatment effects, expected welfare, and decomposition effects for concreteness. Inference in many other semiparametric contexts can be readily obtained. We demonstrate the effectiveness of deep learning with a Monte Carlo analysis and an empirical application to direct mail marketing.", "year": 2018, "ssId": "38705aa9e8ce6412d89c5b2beb9379b1013b33c2", "arXivId": "1809.09953", "link": "https://arxiv.org/pdf/1809.09953.pdf", "openAccess": true, "authors": ["M. Farrell", "Tengyuan Liang", "S. Misra"]}}, "e8c3090e66fdb05a2c169a12c52dd94bb8786fb5": {"id": "e8c3090e66fdb05a2c169a12c52dd94bb8786fb5", "content": {"title": "What Gets Echoed? Understanding the \u201cPointers\u201d in Explanations of Persuasive Arguments", "abstract": "Explanations are central to everyday life, and are a topic of growing interest in the AI community. To investigate the process of providing natural language explanations, we leverage the dynamics of the /r/ChangeMyView subreddit to build a dataset with 36K naturally occurring explanations of why an argument is persuasive. We propose a novel word-level prediction task to investigate how explanations selectively reuse, or echo, information from what is being explained (henceforth, explanandum). We develop features to capture the properties of a word in the explanandum, and show that our proposed features not only have relatively strong predictive power on the echoing of a word in an explanation, but also enhance neural methods of generating explanations. In particular, while the non-contextual properties of a word itself are more valuable for stopwords, the interaction between the constituent parts of an explanandum is crucial in predicting the echoing of content words. We also find intriguing patterns of a word being echoed. For example, although nouns are generally less likely to be echoed, subjects and objects can, depending on their source, be more likely to be echoed in the explanations.", "year": 2019, "ssId": "e8c3090e66fdb05a2c169a12c52dd94bb8786fb5", "arXivId": "1911.00523", "link": "https://arxiv.org/pdf/1911.00523.pdf", "openAccess": true, "authors": ["D. Atkinson", "Kumar Bhargav Srinivasan", "Chenhao Tan"]}}, "a1fc0041ef89ed5371317c8e2cc5effa8f38ae48": {"id": "a1fc0041ef89ed5371317c8e2cc5effa8f38ae48", "content": {"title": "Reliable Causal Discovery with Improved Exact Search and Weaker Assumptions", "abstract": "Many of the causal discovery methods rely on the faithfulness assumption to guarantee asymptotic correctness. However, the assumption can be approximately violated in many ways, leading to sub-optimal solutions. Although there is a line of research in Bayesian network structure learning that focuses on weakening the assumption, such as exact search methods with well-defined score functions, they do not scale well to large graphs. In this work, we introduce several strategies to improve the scalability of exact score-based methods in the linear Gaussian setting. In particular, we develop a super-structure estimation method based on the support of inverse covariance matrix which requires assumptions that are strictly weaker than faithfulness, and apply it to restrict the search space of exact search. We also propose a local search strategy that performs exact search on the local clusters formed by each variable and its neighbors within two hops in the superstructure. Numerical experiments validate the efficacy of the proposed procedure, and demonstrate that it scales up to hundreds of nodes with a high accuracy.", "year": 2022, "ssId": "a1fc0041ef89ed5371317c8e2cc5effa8f38ae48", "arXivId": "2201.05666", "link": "https://arxiv.org/pdf/2201.05666.pdf", "openAccess": true, "authors": ["Ignavier Ng", "Yujia Zheng", "Jiji Zhang", "Kun Zhang"]}}, "098076a2c90e42c81b843bf339446427c2ff02ed": {"id": "098076a2c90e42c81b843bf339446427c2ff02ed", "content": {"title": "Influence Functions in Deep Learning Are Fragile", "abstract": "Influence functions approximate the effect of training samples in test-time predictions and have a wide variety of applications in machine learning interpretability and uncertainty estimation. A commonly-used (first-order) influence function can be implemented efficiently as a post-hoc method requiring access only to the gradients and Hessian of the model. For linear models, influence functions are well-defined due to the convexity of the underlying loss function and are generally accurate even across difficult settings where model changes are fairly large such as estimating group influences. Influence functions, however, are not well-understood in the context of deep learning with non-convex loss functions. In this paper, we provide a comprehensive and large-scale empirical study of successes and failures of influence functions in neural network models trained on datasets such as Iris, MNIST, CIFAR-10 and ImageNet. Through our extensive experiments, we show that the network architecture, its depth and width, as well as the extent of model parameterization and regularization techniques have strong effects in the accuracy of influence functions. In particular, we find that (i) influence estimates are fairly accurate for shallow networks, while for deeper networks the estimates are often erroneous; (ii) for certain network architectures and datasets, training with weight-decay regularization is important to get high-quality influence estimates; and (iii) the accuracy of influence estimates can vary significantly depending on the examined test points. These results suggest that in general influence functions in deep learning are fragile and call for developing improved influence estimation methods to mitigate these issues in non-convex setups.", "year": 2020, "ssId": "098076a2c90e42c81b843bf339446427c2ff02ed", "arXivId": "2006.14651", "link": "https://arxiv.org/pdf/2006.14651.pdf", "openAccess": true, "authors": ["S. Basu", "Philip Pope", "S. Feizi"]}}, "c330ec2047d019d98233abb59d13b3256c662cc7": {"id": "c330ec2047d019d98233abb59d13b3256c662cc7", "content": {"title": "Partial Counterfactual Identification from Observational and Experimental Data", "abstract": "This paper investigates the problem of bounding counterfactual queries from an arbitrary collection of observational and experimental distributions and qualitative knowledge about the underlying data-generating model represented in the form of a causal diagram. We show that all counterfactual distributions in an arbitrary structural causal model (SCM) could be generated by a canonical family of SCMs with the same causal diagram where unobserved (exogenous) variables are discrete with a finite domain. Utilizing the canonical SCMs, we translate the problem of bounding counterfactuals into that of polynomial programming whose solution provides optimal bounds for the counterfactual query. Solving such polynomial programs is in general computationally expensive. We therefore develop effective Monte Carlo algorithms to approximate the optimal bounds from an arbitrary combination of observational and experimental data. Our algorithms are validated extensively on synthetic and real-world datasets. Introduction This paper studies the problem of inferring counterfactual queries from a combination of observations, experiments, and qualitative assumptions about the phenomenon under investigation. The assumptions are represented in the form of a causal diagram (Pearl 1995), which is a directed acyclic graph where arrows indicate the potential existence of functional relationships among corresponding variables; some variables are unobserved. This problem arises in diverse fields such as artificial intelligence, statistics, cognitive science, economics, and the health and social sciences. For example, when investigating the gender discrimination in college admission, one may ask \u201cwhat would the admission outcome be for a female applicant had she been a male?\u201d Such a counterfactual query contains conflicting information: in the real world the applicant is female, in the hypothetical world she was not. Therefore, it is not immediately clear how to design effective experimental procedures for evaluating counterfactuals, or how to compute them from observational data. The problem of identifying counterfactual distributions from the combination of data and a causal diagram has been studied in the causal inference literature. First, there exists a complete proof system for reasoning about counterfactual queries (Halpern 1998). While such a system, in prinPreprint. Under review. ciple, is sufficient in evaluating any identifiable counterfactual expression, it lacks a proof guideline that determines the feasibility of such evaluation efficiently. There are algorithms to determine whether a counterfactual distribution is inferrable from all possible controlled experiments (Shpitser and Pearl 2007), or a special type of counterfactual distributions, called path-specific effects, from observational (Shpitser and Sherman 2018) and experimental data (Avin, Shpitser, and Pearl 2005). Finally, there exist an algorithm that decides whether any nested counterfactual is identifiable an arbitrary combination of observational and experimental distributions (Correa, Lee, and Bareinboim 2021). In practice, however, the combination of quantitative knowledge and observed data does not always permit one to uniquely determine the target counterfactual query. In such cases, the counterfactual query is said to be non-identifiable. Partial identification methods concern with deriving informative bounds over the target counterfactual probability in non-identifiable settings. Several algorithms have been developed to bound counterfactual probabilities from the combination of observational and experimental data (Manski 1990; Robins 1989; Balke and Pearl 1994, 1997; Evans 2012; Richardson et al. 2014; Kallus and Zhou 2018, 2020; Finkelstein and Shpitser 2020; Kilbertus, Kusner, and Silva 2020; Zhang and Bareinboim 2021). In this work, we build on the approach introduced by Balke & Pearl in (Balke and Pearl 1994), which involves direct discretization of unobserved domains, also referred to as the canonical partitioning or the principal stratification (Frangakis and Rubin 2002; Pearl 2011). Consider the causal diagram in Fig. 1a, where X,Y, Z are binary variables in {0, 1}; U is an unobserved variable taking values in an arbitrary continuous domain. (Balke and Pearl 1994) showed that domains of U could be discretized into 16 equivalent classes without changing the original counterfactual distributions and the graphical structure in Fig. 1a. For instance, suppose that values of U are drawn from an arbitrary distribution P \u2217(u) over a continuous domain. It has been shown that the observational distribution P (x, y, z) could be reproduced by a generative model of the form P (x, y, z) = \u2211 u P (x|u, z)P (y|x, u)P (u)P (z), where P (u) is a discrete distribution over a finite domain {1, . . . , 16}. Using the finite-state representation of unobserved variables, (Balke and Pearl 1997) derived tight bounds on treatar X iv :2 11 0. 05 69 0v 1 [ cs .A I] 1 2 O ct 2 02 1 ment effects under a set of constraints called instrumental variables (e.g., Fig. 1a). (Chickering and Pearl 1997; Imbens and Rubin 1997) applied the parsimony of finite-state representation in a Bayesian framework, to obtain credible intervals for the posterior distribution of causal effects in noncompliance settings. Despite the optimality guarantees in their treatments, these bounds were only derived for specific settings. A systematic strategy for partial identification in an arbitrary causal diagram is still missing. There are significant challenges in bounding any counterfactual query in an arbitrary causal diagram given an arbitrary collection of observational and experimental data. Our goal in this paper is to overcome these challenges. We show that when inferring about counterfactual distributions (over finite observed variables) in an arbitrary causal diagram, one could restrict domains of unobserved variables to a finite space without loss of generality. This result allows us to develop novel partial identification algorithms to bound unknown counterfactual probabilities from an arbitrary combination of observational and experimental data. In some way, this paper can be seen as closing a long-standing open problem introduced by (Balke and Pearl 1994), where they solve a special bounding instance in the case of instrumental variables. More specifically, our contributions are as follows. (1) We introduce a special family of discrete structural causal models, and show that it could represent all categorical counterfactual distributions (with finite support) in an arbitrary causal diagram. (2) Using this result, we translate the partial identification task into an equivalent polynomial program. Solving such a program leads to bounds over target counterfactual probabilities that are provably optimal. (3) We develop an effective Monte Carlo algorithm to approximate optimal bounds from a finite number of observational and experimental data. Finally, our algorithms are validated extensively on synthetic and real-world datasets. Preliminaries We introduce in this section some basic notations and definitions that will be used throughout the paper. We use capital letters to denote variables (X), small letters for their values (x) and \u03a9X for their domains. For an arbitrary setX , let |X| be its cardinality. The probability distribution over variables X is denoted by P (X). For convenience, we consistently use P (x) as a shorthand for the probability P (X = x). Finally, the indicator function 1X=x returns 1 if an event X = x holds; otherwise, 1X=x is equal to 0. The basic semantical framework of our analysis rests on structural causal models (SCMs) (Pearl 2000, Ch. 7). An SCM M is a tuple \u3008V ,U ,F , P \u3009 where V is a set of endogenous variables and U is a set of exogenous variables. F is a set of functions where each fV \u2208 F decides values of an endogenous variable V \u2208 V taking as argument a combination of other variables in the system. That is, v \u2190 fV (paV , uV ),PAV \u2286 V , UV \u2286 U . Exogenous variables U \u2208 U are mutually independent, values of which are drawn from the exogenous distribution P (U). Naturally, M induces a joint distribution P (V ) over endogenous variables V , called the observational distribution. Each SCM M is also associated with a causal diagram Z X Y U1 U2", "year": 2021, "ssId": "c330ec2047d019d98233abb59d13b3256c662cc7", "arXivId": "2110.05690", "link": "https://arxiv.org/pdf/2110.05690.pdf", "openAccess": true, "authors": ["Junzhe Zhang", "Jin Tian", "E. Bareinboim"]}}, "40848b41ed8c9c255ecd8a920006877691b52d03": {"id": "40848b41ed8c9c255ecd8a920006877691b52d03", "content": {"title": "WILDS: A Benchmark of in-the-Wild Distribution Shifts", "abstract": "Distribution shifts can cause significant degradation in a broad range of machine learning (ML) systems deployed in the wild. However, many widely-used datasets in the ML community today were not designed for evaluating distribution shifts. These datasets typically have training and test sets drawn from the same distribution, and prior work on retrofitting them with distribution shifts has generally relied on artificial shifts that need not represent the kinds of shifts encountered in the wild. In this paper, we present WILDS, a benchmark of in-the-wild distribution shifts spanning diverse data modalities and applications, from tumor identification to wildlife monitoring to poverty mapping. WILDS builds on top of recent data collection efforts by domain experts in these applications and provides a unified collection of datasets with evaluation metrics and train/test splits that are representative of real-world distribution shifts. These datasets reflect distribution shifts arising from training and testing on different hospitals, cameras, countries, time periods, demographics, molecular scaffolds, etc., all of which cause substantial performance drops in our baseline models. Finally, we survey other applications that would be promising additions to the benchmark but for which we did not manage to find appropriate datasets; we discuss their associated challenges and detail datasets and shifts where we did not see an appreciable performance drop. By unifying datasets from a variety of application areas and making them accessible to the ML community, we hope to encourage the development of general-purpose methods that are anchored to real-world distribution shifts and that work well across different applications and problem settings. Data loaders, default models, and leaderboards are available at this https URL.", "year": 2020, "ssId": "40848b41ed8c9c255ecd8a920006877691b52d03", "arXivId": "2012.07421", "link": "https://arxiv.org/pdf/2012.07421.pdf", "openAccess": true, "authors": ["P. W. Koh", "Shiori Sagawa", "H. Marklund", "Sang Michael Xie", "Marvin Zhang", "Akshay Balsubramani", "Weihua Hu", "Michihiro Yasunaga", "Richard L. Phillips", "Sara Beery", "J. Leskovec", "A. Kundaje", "E. Pierson", "S. Levine", "Chelsea Finn", "Percy Liang"]}}, "71a85e735a3686bef8cce3725ae5ba82e2cabb1b": {"id": "71a85e735a3686bef8cce3725ae5ba82e2cabb1b", "content": {"title": "Underspecification Presents Challenges for Credibility in Modern Machine Learning", "abstract": "ML models often exhibit unexpectedly poor behavior when they are deployed in real-world domains. We identify underspecification as a key reason for these failures. An ML pipeline is underspecified when it can return many predictors with equivalently strong held-out performance in the training domain. Underspecification is common in modern ML pipelines, such as those based on deep learning. Predictors returned by underspecified pipelines are often treated as equivalent based on their training domain performance, but we show here that such predictors can behave very differently in deployment domains. This ambiguity can lead to instability and poor model behavior in practice, and is a distinct failure mode from previously identified issues arising from structural mismatch between training and deployment domains. We show that this problem appears in a wide variety of practical ML pipelines, using examples from computer vision, medical imaging, natural language processing, clinical risk prediction based on electronic health records, and medical genomics. Our results show the need to explicitly account for underspecification in modeling pipelines that are intended for real-world deployment in any domain.", "year": 2020, "ssId": "71a85e735a3686bef8cce3725ae5ba82e2cabb1b", "arXivId": "2011.03395", "link": "https://arxiv.org/pdf/2011.03395.pdf", "openAccess": true, "authors": ["A. D'Amour", "K. Heller", "D. Moldovan", "Ben Adlam", "B. Alipanahi", "Alex Beutel", "Christina Chen", "Jonathan Deaton", "Jacob Eisenstein", "M. Hoffman", "F. Hormozdiari", "N. Houlsby", "Shaobo Hou", "Ghassen Jerfel", "A. Karthikesalingam", "Mario Lucic", "Yi-An Ma", "C. McLean", "Diana Mincu", "A. Mitani", "A. Montanari", "Zachary Nado", "Vivek Natarajan", "Christopher Nielson", "T. F. Osborne", "R. Raman", "K. Ramasamy", "R. Sayres", "J. Schrouff", "Martin G. Seneviratne", "Shannon Sequeira", "Harini Suresh", "Victor Veitch", "Max Vladymyrov", "Xuezhi Wang", "Kellie Webster", "S. Yadlowsky", "Taedong Yun", "Xiaohua Zhai", "D. Sculley"]}}, "4b9bc5b5985bbfbc860039b98f233f8a43ad9171": {"id": "4b9bc5b5985bbfbc860039b98f233f8a43ad9171", "content": {"title": "Solving parametric PDE problems with artificial neural networks", "abstract": "The curse of dimensionality is commonly encountered in numerical partial differential equations (PDE), especially when uncertainties have to be modelled into the equations as random coefficients. However, very often the variability of physical quantities derived from PDE can be captured by a few features on the space of the coefficient fields. Based on such observation, we propose using neural network to parameterise the physical quantity of interest as a function of input coefficients. The representability of such quantity using a neural network can be justified by viewing the neural network as performing time evolution to find the solutions to the PDE. We further demonstrate the simplicity and accuracy of the approach through notable examples of PDEs in engineering and physics.", "year": 2017, "ssId": "4b9bc5b5985bbfbc860039b98f233f8a43ad9171", "arXivId": "1707.03351", "link": "https://arxiv.org/pdf/1707.03351.pdf", "openAccess": true, "authors": ["Y. Khoo", "Jianfeng Lu", "Lexing Ying"]}}, "af4e11436268cf68505f1caee5d6f7ff0df9c99a": {"id": "af4e11436268cf68505f1caee5d6f7ff0df9c99a", "content": {"title": "Causal Inference in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond", "abstract": "A fundamental goal of scientific research is to learn about causal relationships. However, despite its critical role in the life and social sciences, causality has not had the same importance in Natural Language Processing (NLP), which has traditionally placed more emphasis on predictive tasks. This distinction is beginning to fade, with an emerging area of interdisciplinary research at the convergence of causal inference and language processing. Still, research on causality in NLP remains scattered across domains without unified definitions, benchmark datasets and clear articulations of the remaining challenges. In this survey, we consolidate research across academic areas and situate it in the broader NLP landscape. We introduce the statistical challenge of estimating causal effects, encompassing settings where text is used as an outcome, treatment, or as a means to address confounding. In addition, we explore potential uses of causal inference to improve the performance, robustness, fairness, and interpretability of NLP models. We thus provide a unified overview of causal inference for the computational linguistics community. 1 \u2217All authors equally contributed to this paper. Author names are organized alphabetically in two clusters: First students and post-docs and then faculty members. The email address of the corresponding (first) author is: feder@campus.technion.ac.il. An online repository containing existing research on causal inference and language processing is available here: https://github.com/causaltext/", "year": 2021, "ssId": "af4e11436268cf68505f1caee5d6f7ff0df9c99a", "arXivId": "2109.00725", "link": "https://arxiv.org/pdf/2109.00725.pdf", "openAccess": true, "authors": ["Amir Feder", "Katherine A. Keith", "Emaad A. Manzoor", "Reid Pryzant", "Dhanya Sridhar", "Zach Wood-Doughty", "Jacob Eisenstein", "Justin Grimmer", "Roi Reichart", "Margaret E. Roberts", "Brandon M Stewart", "Victor Veitch", "Diyi Yang"]}}, "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a": {"id": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "content": {"title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "abstract": "While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.", "year": 2020, "ssId": "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a", "arXivId": "2010.11929", "link": "https://arxiv.org/pdf/2010.11929.pdf", "openAccess": true, "authors": ["A. Dosovitskiy", "L. Beyer", "Alexander Kolesnikov", "Dirk Weissenborn", "Xiaohua Zhai", "Thomas Unterthiner", "M. Dehghani", "Matthias Minderer", "G. Heigold", "S. Gelly", "Jakob Uszkoreit", "N. Houlsby"]}}, "9f2cf7b35224aad3a8d261e4456fe2d65a5f5d3e": {"id": "9f2cf7b35224aad3a8d261e4456fe2d65a5f5d3e", "content": {"title": "Large Dual Encoders Are Generalizable Retrievers", "abstract": "It has been shown that dual encoders trained on one domain often fail to generalize to other domains for retrieval tasks. One widespread belief is that the bottleneck layer of a dual encoder, where the final score is simply a dotproduct between a query vector and a passage vector, is too limited to make dual encoders an effective retrieval model for out-ofdomain generalization. In this paper, we challenge this belief by scaling up the size of the dual encoder model while keeping the bottleneck embedding size fixed. With multi-stage training, surprisingly, scaling up the model size brings significant improvement on a variety of retrieval tasks, especially for out-ofdomain generalization. Experimental results show that our dual encoders, Generalizable T5-based dense Retrievers (GTR), outperform existing sparse and dense retrievers on the BEIR dataset (Thakur et al., 2021) significantly. Most surprisingly, our ablation study finds that GTR is very data efficient, as it only needs 10% of MS Marco supervised data to achieve the best out-of-domain performance.1", "year": 2021, "ssId": "9f2cf7b35224aad3a8d261e4456fe2d65a5f5d3e", "arXivId": "2112.07899", "link": "https://arxiv.org/pdf/2112.07899.pdf", "openAccess": true, "authors": ["Jianmo Ni", "Chen Qu", "Jing Lu", "Zhuyun Dai", "Gustavo Hern'andez 'Abrego", "Ji Ma", "Vincent Zhao", "Yi Luan", "K. Hall", "Ming-Wei Chang", "Yinfei Yang"]}}, "7b7416c90e8d3fc9ad5c9fb3923a638f69294ed7": {"id": "7b7416c90e8d3fc9ad5c9fb3923a638f69294ed7", "content": {"title": "Mention Memory: incorporating textual knowledge into Transformers through entity mention attention", "abstract": "Natural language understanding tasks such as open-domain question answering often require retrieving and assimilating factual information from multiple sources. We propose to address this problem by integrating a semi-parametric representation of a large text corpus into a Transformer model as a source of factual knowledge. Speci\ufb01cally, our method represents knowledge with \u201cmention memory\u201d, a table of dense vector representations of every entity mention in a corpus. The proposed model - TOME - is a Transformer that accesses the information through internal memory layers in which each entity mention in the input passage attends to the mention memory. This approach enables synthesis of and reasoning over many disparate sources of information within a single Transformer model. In experiments using a memory of 150 million Wikipedia mentions, TOME achieves strong performance on several open-domain knowledge-intensive tasks, including the claim veri\ufb01cation benchmarks HoVer and FEVER and several entity-based QA benchmarks. We also show that the model learns to attend to informative mentions without any direct supervision. Finally we demonstrate that the model can generalize to new unseen entities by updating the memory without retraining.", "year": 2021, "ssId": "7b7416c90e8d3fc9ad5c9fb3923a638f69294ed7", "arXivId": "2110.06176", "link": "https://arxiv.org/pdf/2110.06176.pdf", "openAccess": true, "authors": ["M. D. Jong", "Yury Zemlyanskiy", "Nicholas FitzGerald", "Fei Sha", "W. Cohen"]}}, "002c256d30d6be4b23d365a8de8ae0e67e4c9641": {"id": "002c256d30d6be4b23d365a8de8ae0e67e4c9641", "content": {"title": "Improving language models by retrieving from trillions of tokens", "abstract": "Language modelling (LM) is an unsupervised task that consists of modelling the probability of text, usually by factorising it into conditional next-token predictions p(x1, . . . , xn) = \u220f i p(xi |x<i). Neural networks have proven to be powerful language models, first in the form of recurrent architectures (Graves, 2013; Jozefowicz et al., 2016; Mikolov et al., 2010) and more recently in the form of Transformers (Vaswani et al., 2017), that use attention to contextualise the past. Large performance improvements have come from increasing the amount of data, training compute, or model parameters. Transformers have been scaled from 100 million parameter models in seminal work to over hundred billion parameters (Brown et al., 2020; Radford et al., 2019) in the last two years which has led to models that do very well on a wide array of tasks in a zero or few-shot formulation. Increasing model size predictably improves performance on a wide range of downstream tasks (Kaplan et al., 2020). The benefits of increasing the number of parameters come from two factors: additional computations at training and inference time, and increased memorization of the training data.", "year": 2021, "ssId": "002c256d30d6be4b23d365a8de8ae0e67e4c9641", "arXivId": "2112.04426", "link": "https://arxiv.org/pdf/2112.04426.pdf", "openAccess": true, "authors": ["Sebastian Borgeaud", "A. Mensch", "Jordan Hoffmann", "Trevor Cai", "Eliza Rutherford", "Katie Millican", "George van den Driessche", "J. Lespiau", "Bogdan Damoc", "Aidan Clark", "Diego de Las Casas", "Aurelia Guy", "Jacob Menick", "Roman Ring", "T. Hennigan", "Saffron Huang", "Lorenzo Maggiore", "Chris Jones", "Albin Cassirer", "Andy Brock", "Michela Paganini", "Geoffrey Irving", "Oriol Vinyals", "Simon Osindero", "K. Simonyan", "Jack W. Rae", "Erich Elsen", "L. Sifre"]}}, "6a79ff7465d8249d9c8a50fa5f2e0a3e308b436d": {"id": "6a79ff7465d8249d9c8a50fa5f2e0a3e308b436d", "content": {"title": "GPL: Generative Pseudo Labeling for Unsupervised Domain Adaptation of Dense Retrieval", "abstract": "Dense retrieval approaches can overcome the lexical gap and lead to signi\ufb01cantly improved search results. However, they require large amounts of training data which is not available for most domains. As shown in previous work (Thakur et al., 2021b), the performance of dense retrievers severely degrades under a domain shift. This limits the usage of dense retrieval approaches to only a few domains with large training datasets. In this paper, we propose the novel unsupervised domain adaptation method Generative Pseudo Labeling (GPL), which combines a query generator with pseudo labeling from a cross-encoder. On six representative domain-specialized datasets, we \ufb01nd the proposed GPL can outperform an out-of-the-box state-of-the-art dense retrieval approach by up to 9.3 points nDCG@10. GPL requires less (unlabeled) data from the target domain and is more robust in its training than previous methods. We further investigate the role of six recent pre-training methods in the scenario of domain adaptation for retrieval tasks, where only three could yield improved results. The best approach, TSDAE (Wang et al., 2021) can be combined with GPL, yielding another average improvement of 1.4 points nDCG@10 across the six tasks. Code and models are available at https://gpl.sbert.net .", "year": 2021, "ssId": "6a79ff7465d8249d9c8a50fa5f2e0a3e308b436d", "arXivId": "2112.07577", "link": "https://arxiv.org/pdf/2112.07577.pdf", "openAccess": true, "authors": ["Kexin Wang", "Nandan Thakur", "Nils Reimers", "Iryna Gurevych"]}}, "6bea71fa6deb19c67e9586428f8f240e789fb3df": {"id": "6bea71fa6deb19c67e9586428f8f240e789fb3df", "content": {"title": "Improved Algorithms for Linear Stochastic Bandits", "abstract": "We improve the theoretical analysis and empirical performance of algorithms for the stochastic multi-armed bandit problem and the linear stochastic multi-armed bandit problem. In particular, we show that a simple modification of Auer's UCB algorithm (Auer, 2002) achieves with high probability constant regret. More importantly, we modify and, consequently, improve the analysis of the algorithm for the for linear stochastic bandit problem studied by Auer (2002), Dani et al. (2008), Rusmevichientong and Tsitsiklis (2010), Li et al. (2010). Our modification improves the regret bound by a logarithmic factor, though experiments show a vast improvement. In both cases, the improvement stems from the construction of smaller confidence sets. For their construction we use a novel tail inequality for vector-valued martingales.", "year": 2011, "ssId": "6bea71fa6deb19c67e9586428f8f240e789fb3df", "arXivId": null, "link": "https://sites.ualberta.ca/~szepesva/papers/linear-bandits-NeurIPS2011.pdf", "openAccess": true, "authors": ["Yasin Abbasi-Yadkori", "D. P\u00e1l", "Csaba Szepesvari"]}}, "bf0beed35ea09aab56027d64c744098cc963fbde": {"id": "bf0beed35ea09aab56027d64c744098cc963fbde", "content": {"title": "Quickest Change Detection Under Transient Dynamics: Theory and Asymptotic Analysis", "abstract": "The problem of quickest change detection under transient dynamics is studied, where the change from the initial distribution to the final persistent distribution does not happen instantaneously, but after a series of transient phases. The observations within the different phases are generated by different distributions. The objective is to detect the change as quickly as possible, while controlling the average run length (ARL) to false alarm, when the durations of the transient phases are completely unknown. Two algorithms are considered: the dynamic Cumulative Sum (CuSum) algorithm, proposed in earlier work, and a newly constructed weighted dynamic CuSum algorithm. Both algorithms admit recursions that facilitate their practical implementation, and they are adaptive to the unknown transient durations. Specifically, their asymptotic optimality is established with respect to both Lorden\u2019s and Pollak\u2019s criteria as the ARL to false alarm and the durations of the transient phases go to infinity at any relative rate. Numerical results are provided to demonstrate the adaptivity of the proposed algorithms and to validate the theoretical results.", "year": 2017, "ssId": "bf0beed35ea09aab56027d64c744098cc963fbde", "arXivId": "1711.02186", "link": "https://arxiv.org/pdf/1711.02186.pdf", "openAccess": true, "authors": ["Shaofeng Zou", "Georgios Fellouris", "V. Veeravalli"]}}, "930445d9cda71d6ff857e69aa5bb4b1bef7d31e5": {"id": "930445d9cda71d6ff857e69aa5bb4b1bef7d31e5", "content": {"title": "Reinforcement Learning under Drift", "abstract": "We propose algorithms with state-of-the-art \\emph{dynamic regret} bounds for un-discounted reinforcement learning under drifting non-stationarity, where both the reward functions and state transition distributions are allowed to evolve over time. Our main contributions are: 1) A tuned Sliding Window Upper-Confidence bound for Reinforcement Learning with Confidence-Widening (\\texttt{SWUCRL2-CW}) algorithm, which attains low dynamic regret bounds against the optimal non-stationary policy in various cases. 2) The Bandit-over-Reinforcement Learning (\\texttt{BORL}) framework that further permits us to enjoy these dynamic regret bounds in a parameter-free manner.", "year": 2019, "ssId": "930445d9cda71d6ff857e69aa5bb4b1bef7d31e5", "arXivId": "1906.02922", "link": "https://arxiv.org/pdf/1906.02922.pdf", "openAccess": true, "authors": ["Wang Chi Cheung", "D. Simchi-Levi", "Ruihao Zhu"]}}, "92a8f7f09f3705cb5a6009a42220a6f01ea084e8": {"id": "92a8f7f09f3705cb5a6009a42220a6f01ea084e8", "content": {"title": "Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents", "abstract": "Can world knowledge learned by large language models (LLMs) be used to act in interactive environments? In this paper, we investigate the possibility of grounding high-level tasks, expressed in natural language (e.g. \u201cmake breakfast\u201d), to a chosen set of actionable steps (e.g. \u201copen fridge\u201d). While prior work focused on learning from explicit step-by-step examples of how to act, we surprisingly find that if pre-trained LMs are large enough and prompted appropriately, they can effectively decompose high-level tasks into mid-level plans without any further training. However, the plans produced naively by LLMs often cannot map precisely to admissible actions. We propose a procedure that conditions on existing demonstrations and semantically translates the plans to admissible actions. Our evaluation in the recent VirtualHome environment shows that the resulting method substantially improves executability over the LLM baseline. The conducted human evaluation reveals a trade-off between executability and correctness but shows a promising sign towards extracting actionable knowledge from language models.", "year": 2022, "ssId": "92a8f7f09f3705cb5a6009a42220a6f01ea084e8", "arXivId": "2201.07207", "link": "https://arxiv.org/pdf/2201.07207.pdf", "openAccess": true, "authors": ["Wenlong Huang", "P. Abbeel", "Deepak Pathak", "Igor Mordatch"]}}, "2bb1e1a5b9a16f6828fe94736cea5dab264533a6": {"id": "2bb1e1a5b9a16f6828fe94736cea5dab264533a6", "content": {"title": "Provable Limitations of Acquiring Meaning from Ungrounded Form: What Will Future Language Models Understand?", "abstract": "Abstract Language models trained on billions of tokens have recently led to unprecedented results on many NLP tasks. This success raises the question of whether, in principle, a system can ever \u201cunderstand\u201d raw text without access to some form of grounding. We formally investigate the abilities of ungrounded systems to acquire meaning. Our analysis focuses on the role of \u201cassertions\u201d: textual contexts that provide indirect clues about the underlying semantics. We study whether assertions enable a system to emulate representations preserving semantic relations like equivalence. We find that assertions enable semantic emulation of languages that satisfy a strong notion of semantic transparency. However, for classes of languages where the same expression can take different values in different contexts, we show that emulation can become uncomputable. Finally, we discuss differences between our formal model and natural language, exploring how our results generalize to a modal setting and other semantic relations. Together, our results suggest that assertions in code or language do not provide sufficient signal to fully emulate semantic representations. We formalize ways in which ungrounded language models appear to be fundamentally limited in their ability to \u201cunderstand\u201d.", "year": 2021, "ssId": "2bb1e1a5b9a16f6828fe94736cea5dab264533a6", "arXivId": "2104.10809", "link": "https://arxiv.org/pdf/2104.10809.pdf", "openAccess": true, "authors": ["William Cooper Merrill", "Yoav Goldberg", "Roy Schwartz", "Noah A. Smith"]}}, "e60b88313fad52c1ef8dd02b482785651d09ad66": {"id": "e60b88313fad52c1ef8dd02b482785651d09ad66", "content": {"title": "Depth Separation for Neural Networks", "abstract": "Let $f:\\mathbb{S}^{d-1}\\times \\mathbb{S}^{d-1}\\to\\mathbb{S}$ be a function of the form $f(\\mathbf{x},\\mathbf{x}') = g(\\langle\\mathbf{x},\\mathbf{x}'\\rangle)$ for $g:[-1,1]\\to \\mathbb{R}$. We give a simple proof that shows that poly-size depth two neural networks with (exponentially) bounded weights cannot approximate $f$ whenever $g$ cannot be approximated by a low degree polynomial. Moreover, for many $g$'s, such as $g(x)=\\sin(\\pi d^3x)$, the number of neurons must be $2^{\\Omega\\left(d\\log(d)\\right)}$. Furthermore, the result holds w.r.t.\\ the uniform distribution on $\\mathbb{S}^{d-1}\\times \\mathbb{S}^{d-1}$. As many functions of the above form can be well approximated by poly-size depth three networks with poly-bounded weights, this establishes a separation between depth two and depth three networks w.r.t.\\ the uniform distribution on $\\mathbb{S}^{d-1}\\times \\mathbb{S}^{d-1}$.", "year": 2017, "ssId": "e60b88313fad52c1ef8dd02b482785651d09ad66", "arXivId": "1702.08489", "link": "https://arxiv.org/pdf/1702.08489.pdf", "openAccess": true, "authors": ["Amit Daniely"]}}, "25ddddbd0bd1cfebf1548b2ee91bb1bbd05fdff1": {"id": "25ddddbd0bd1cfebf1548b2ee91bb1bbd05fdff1", "content": {"title": "Episodic Transformer for Vision-and-Language Navigation", "abstract": "Interaction and navigation defined by natural language instructions in dynamic environments pose significant challenges for neural agents. This paper focuses on addressing two challenges: handling long sequence of subtasks, and understanding complex human instructions. We propose Episodic Transformer (E.T.), a multimodal transformer that encodes language inputs and the full episode history of visual observations and actions. To improve training, we leverage synthetic instructions as an intermediate representation that decouples understanding the visual appearance of an environment from the variations of natural language instructions. We demonstrate that encoding the history with a transformer is critical to solve compositional tasks, and that pretraining and joint training with synthetic instructions further improve the performance. Our approach sets a new state of the art on the challenging ALFRED benchmark, achieving 38.4% and 8.5% task success rates on seen and unseen test splits.", "year": 2021, "ssId": "25ddddbd0bd1cfebf1548b2ee91bb1bbd05fdff1", "arXivId": "2105.06453", "link": "https://arxiv.org/pdf/2105.06453.pdf", "openAccess": true, "authors": ["Alexander Pashevich", "C. Schmid", "Chen Sun"]}}, "972a74968d2522908b06c5bd1e26266194c5a9ee": {"id": "972a74968d2522908b06c5bd1e26266194c5a9ee", "content": {"title": "Decontextualization: Making Sentences Stand-Alone", "abstract": "Abstract Models for question answering, dialogue agents, and summarization often interpret the meaning of a sentence in a rich context and use that meaning in a new context. Taking excerpts of text can be problematic, as key pieces may not be explicit in a local window. We isolate and define the problem of sentence decontextualization: taking a sentence together with its context and rewriting it to be interpretable out of context, while preserving its meaning. We describe an annotation procedure, collect data on the Wikipedia corpus, and use the data to train models to automatically decontextualize sentences. We present preliminary studies that show the value of sentence decontextualization in a user-facing task, and as preprocessing for systems that perform document understanding. We argue that decontextualization is an important subtask in many downstream applications, and that the definitions and resources provided can benefit tasks that operate on sentences that occur in a richer context.", "year": 2021, "ssId": "972a74968d2522908b06c5bd1e26266194c5a9ee", "arXivId": "2102.05169", "link": "https://arxiv.org/pdf/2102.05169.pdf", "openAccess": true, "authors": ["Eunsol Choi", "Jennimaria Palomaki", "Matthew Lamm", "T. Kwiatkowski", "Dipanjan Das", "Michael Collins"]}}, "59d225fcb08ce66935e0285a9936ee158c4fdb97": {"id": "59d225fcb08ce66935e0285a9936ee158c4fdb97", "content": {"title": "Explaining Answers with Entailment Trees", "abstract": "Our goal, in the context of open-domain textual question-answering (QA), is to explain answers by showing the line of reasoning from what is known to the answer, rather than simply showing a fragment of textual evidence (a \u201crationale\u201d). If this could be done, new opportunities for understanding and debugging the system\u2019s reasoning become possible. Our approach is to generate explanations in the form of entailment trees, namely a tree of multipremise entailment steps from facts that are known, through intermediate conclusions, to the hypothesis of interest (namely the question + answer). To train a model with this skill, we created ENTAILMENTBANK, the first dataset to contain multistep entailment trees. Given a hypothesis (question + answer), we define three increasingly difficult explanation tasks: generate a valid entailment tree given (a) all relevant sentences (b) all relevant and some irrelevant sentences, or (c) a corpus. We show that a strong language model can partially solve these tasks, in particular when the relevant sentences are included in the input (e.g., 35% of trees for (a) are perfect), and with indications of generalization to other domains. This work is significant as it provides a new type of dataset (multistep entailments) and baselines, offering a new avenue for the community to generate richer, more systematic explanations.", "year": 2021, "ssId": "59d225fcb08ce66935e0285a9936ee158c4fdb97", "arXivId": "2104.08661", "link": "https://arxiv.org/pdf/2104.08661.pdf", "openAccess": true, "authors": ["Bhavana Dalvi", "Peter Alexander Jansen", "Oyvind Tafjord", "Zhengnan Xie", "Hannah Smith", "Leighanna Pipatanangkura", "Peter Clark"]}}, "b61c9799f10e4de9cd222dfd8e423bbd950a7c44": {"id": "b61c9799f10e4de9cd222dfd8e423bbd950a7c44", "content": {"title": "Do We Know What We Don't Know? Studying Unanswerable Questions beyond SQuAD 2.0", "abstract": "Understanding when a text snippet does not provide a sought after information is an essential part of natural language understanding. Recent work (SQuAD 2.0, Rajpurkar et al., 2018) has attempted to make some progress in this direction by enriching the SQuAD dataset for the Extractive QA task with unanswerable questions. However, as we show, the performance of a top system trained on SQuAD 2.0 drops considerably in out-of-domain scenarios, limiting its use in practical situations. In order to study this we build an out-of-domain corpus, focusing on simple event-based questions and distinguish between two types of IDK questions: competitive questions, where the context includes an entity of the same type as the expected answer, and simpler, noncompetitive questions where there is no entity of the same type in the context. We find that SQuAD 2.0-based models fail even in the case of the simpler questions. We then analyze the similarities and differences between the IDK phenomenon in Extractive QA and the Recognizing Textual Entailments task (RTE, Dagan et al., 2013) and investigate the extent to which the latter can be used to improve the performance.1", "year": 2021, "ssId": "b61c9799f10e4de9cd222dfd8e423bbd950a7c44", "arXivId": null, "link": "https://aclanthology.org/2021.findings-emnlp.385.pdf", "openAccess": true, "authors": ["Elior Sulem", "Jamaal Hay", "D. Roth"]}}, "4e3935ef7da6bcbb202ec7f8b285c313cadcd044": {"id": "4e3935ef7da6bcbb202ec7f8b285c313cadcd044", "content": {"title": "A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers", "abstract": "Readers of academic research papers often read with the goal of answering specific questions. Question Answering systems that can answer those questions can make consumption of the content much more efficient. However, building such tools requires data that reflect the difficulty of the task arising from complex reasoning about claims made in multiple parts of a paper. In contrast, existing information-seeking question answering datasets usually contain questions about generic factoid-type information. We therefore present Qasper, a dataset of 5049 questions over 1585 Natural Language Processing papers. Each question is written by an NLP practitioner who read only the title and abstract of the corresponding paper, and the question seeks information present in the full text. The questions are then answered by a separate set of NLP practitioners who also provide supporting evidence to answers. We find that existing models that do well on other QA tasks do not perform well on answering these questions, underperforming humans by at least 27 F1 points when answering them from entire papers, motivating further research in document-grounded, information-seeking QA, which our dataset is designed to facilitate.", "year": 2021, "ssId": "4e3935ef7da6bcbb202ec7f8b285c313cadcd044", "arXivId": "2105.03011", "link": "https://arxiv.org/pdf/2105.03011.pdf", "openAccess": true, "authors": ["Pradeep Dasigi", "Kyle Lo", "Iz Beltagy", "Arman Cohan", "Noah A. Smith", "Matt Gardner"]}}, "601398838250a4e69c69cc339d65f5c51e727ad1": {"id": "601398838250a4e69c69cc339d65f5c51e727ad1", "content": {"title": "Asking It All: Generating Contextualized Questions for any Semantic Role", "abstract": "Asking questions about a situation is an inherent step towards understanding it. To this end, we introduce the task of role question generation, which, given a predicate mention and a passage, requires producing a set of questions asking about all possible semantic roles of the predicate. We develop a two-stage model for this task, which first produces a context-independent question prototype for each role and then revises it to be contextually appropriate for the passage. Unlike most existing approaches to question generation, our approach does not require conditioning on existing answers in the text. Instead, we condition on the type of information to inquire about, regardless of whether the answer appears explicitly in the text, could be inferred from it, or should be sought elsewhere. Our evaluation demonstrates that we generate diverse and well-formed questions for a large, broad-coverage ontology of predicates and roles.", "year": 2021, "ssId": "601398838250a4e69c69cc339d65f5c51e727ad1", "arXivId": "2109.04832", "link": "https://arxiv.org/pdf/2109.04832.pdf", "openAccess": true, "authors": ["Valentina Pyatkin", "Paul Roit", "Julian Michael", "Reut Tsarfaty", "Yoav Goldberg", "Ido Dagan"]}}, "f7979c6690562c5f8bf700e3fd184c4d1df0a54c": {"id": "f7979c6690562c5f8bf700e3fd184c4d1df0a54c", "content": {"title": "Zero-shot Neural Transfer for Cross-lingual Entity Linking", "abstract": "Cross-lingual entity linking maps an entity mention in a source language to its corresponding entry in a structured knowledge base that is in a different (target) language. While previous work relies heavily on bilingual lexical resources to bridge the gap between the source and the target languages, these resources are scarce or unavailable for many low-resource languages. To address this problem, we investigate zero-shot cross-lingual entity linking, in which we assume no bilingual lexical resources are available in the source low-resource language. Specifically, we propose pivot-basedentity linking, which leverages information from a highresource \u201cpivot\u201d language to train character-level neural entity linking models that are transferred to the source lowresource language in a zero-shot manner. With experiments on 9 low-resource languages and transfer through a total of54 languages, we show that our proposed pivot-based framework improves entity linking accuracy 17% (absolute) on average over the baseline systems, for the zero-shot scenario.1 Further, we also investigate the use of language-universal phonological representations which improves average accuracy (absolute) by 36% when transferring between languages that use different scripts.", "year": 2018, "ssId": "f7979c6690562c5f8bf700e3fd184c4d1df0a54c", "arXivId": "1811.04154", "link": "https://arxiv.org/pdf/1811.04154.pdf", "openAccess": true, "authors": ["Shruti Rijhwani", "Jiateng Xie", "Graham Neubig", "J. Carbonell"]}}, "37e06f3622c17dc6194b547c944462b2a513b878": {"id": "37e06f3622c17dc6194b547c944462b2a513b878", "content": {"title": "Multi-Fact Correction in Abstractive Text Summarization", "abstract": "Pre-trained neural abstractive summarization systems have dominated extractive strategies on news summarization performance, at least in terms of ROUGE. However, system-generated abstractive summaries often face the pitfall of factual inconsistency: generating incorrect facts with respect to the source text. To address this challenge, we propose Span-Fact, a suite of two factual correction models that leverages knowledge learned from question answering models to make corrections in system-generated summaries via span selection. Our models employ single or multi-masking strategies to either iteratively or auto-regressively replace entities in order to ensure semantic consistency w.r.t. the source text, while retaining the syntactic structure of summaries generated by abstractive summarization models. Experiments show that our models significantly boost the factual consistency of system-generated summaries without sacrificing summary quality in terms of both automatic metrics and human evaluation.", "year": 2020, "ssId": "37e06f3622c17dc6194b547c944462b2a513b878", "arXivId": "2010.02443", "link": "https://arxiv.org/pdf/2010.02443.pdf", "openAccess": true, "authors": ["Yue Dong", "Shuohang Wang", "Zhe Gan", "Yu Cheng", "J. C. Cheung", "Jingjing Liu"]}}, "af679d69fcc1d0fcf0f039aba937853bcb50a8de": {"id": "af679d69fcc1d0fcf0f039aba937853bcb50a8de", "content": {"title": "Luna: Linear Unified Nested Attention", "abstract": "The quadratic computational and memory complexities of the Transformer\u2019s attention mechanism have limited its scalability for modeling long sequences. In this paper, we propose Luna, a linear unified nested attention mechanism that approximates softmax attention with two nested linear attention functions, yielding only linear (as opposed to quadratic) time and space complexity. As compared to a more traditional attention mechanism, Luna introduces an additional sequence with a fixed length as input and an additional corresponding output, which allows Luna to perform attention operation linearly, while also storing adequate contextual information. We perform extensive evaluations on three benchmarks of sequence modeling tasks: long-context sequence modeling, neural machine translation and masked language modeling for large-scale pretraining. Competitive or even better experimental results demonstrate both the effectiveness and efficiency of Luna compared to a variety of strong baseline methods including the full-rank attention and other efficient sparse and dense attention methods. The implementation of our model is available at https://github.com/XuezheMax/fairseq-apollo.", "year": 2021, "ssId": "af679d69fcc1d0fcf0f039aba937853bcb50a8de", "arXivId": "2106.01540", "link": "https://arxiv.org/pdf/2106.01540.pdf", "openAccess": true, "authors": ["Xuezhe Ma", "Xiang Kong", "Sinong Wang", "Chunting Zhou", "Jonathan May", "Hao Ma", "Luke Zettlemoyer"]}}, "14dddd1d8cb2e8c5f4e9998fef84e715cb321ac9": {"id": "14dddd1d8cb2e8c5f4e9998fef84e715cb321ac9", "content": {"title": "Formalizing Trust in Artificial Intelligence: Prerequisites, Causes and Goals of Human Trust in AI", "abstract": "Trust is a central component of the interaction between people and AI, in that 'incorrect' levels of trust may cause misuse, abuse or disuse of the technology. But what, precisely, is the nature of trust in AI? What are the prerequisites and goals of the cognitive mechanism of trust, and how can we promote them, or assess whether they are being satisfied in a given interaction? This work aims to answer these questions. We discuss a model of trust inspired by, but not identical to, interpersonal trust (i.e., trust between people) as defined by sociologists. This model rests on two key properties: the vulnerability of the user; and the ability to anticipate the impact of the AI model's decisions. We incorporate a formalization of 'contractual trust', such that trust between a user and an AI model is trust that some implicit or explicit contract will hold, and a formalization of 'trustworthiness' (that detaches from the notion of trustworthiness in sociology), and with it concepts of 'warranted' and 'unwarranted' trust. We present the possible causes of warranted trust as intrinsic reasoning and extrinsic behavior, and discuss how to design trustworthy AI, how to evaluate whether trust has manifested, and whether it is warranted. Finally, we elucidate the connection between trust and XAI using our formalization.", "year": 2020, "ssId": "14dddd1d8cb2e8c5f4e9998fef84e715cb321ac9", "arXivId": "2010.07487", "link": "https://arxiv.org/pdf/2010.07487.pdf", "openAccess": true, "authors": ["Alon Jacovi", "Ana Marasovi\u0107", "Tim Miller", "Yoav Goldberg"]}}, "b62d63580b81a2cbb20c3c1593dd62d118e4cb07": {"id": "b62d63580b81a2cbb20c3c1593dd62d118e4cb07", "content": {"title": "Synchromesh: Reliable code generation from pre-trained language models", "abstract": "Large pre-trained language models have been used to generate code, providing a flexible interface for synthesizing programs from natural language specifications. However, they often violate syntactic and semantic rules of their output language, limiting their practical usability. In this paper, we propose SYNCHROMESH: a framework for substantially improving the reliability of pre-trained models for code generation. SYNCHROMESH comprises two components. First, it retrieves few-shot examples from a training bank using Target Similarity Tuning (TST), a novel method for semantic example selection. TST learns to recognize utterances that describe similar target programs despite differences in surface natural language features. Then, SYNCHROMESH feeds the examples to a pre-trained language model and samples programs using Constrained Semantic Decoding (CSD): a general framework for constraining the output to a set of valid programs in the target language. CSD leverages constraints on partial outputs to sample complete correct programs, and needs neither re-training nor fine-tuning of the language model. We evaluate our methods by synthesizing code from natural language descriptions using GPT-3 and Codex in three real-world languages: SQL queries, Vega-Lite visualizations and SMCalFlow programs. These domains showcase rich constraints that CSD is able to enforce, including syntax, scope, typing rules, and contextual logic. We observe substantial complementary gains from CSD and TST in prediction accuracy and in effectively preventing run-time errors.", "year": 2022, "ssId": "b62d63580b81a2cbb20c3c1593dd62d118e4cb07", "arXivId": "2201.11227", "link": "https://arxiv.org/pdf/2201.11227.pdf", "openAccess": true, "authors": ["Gabriel Poesia", "Oleksandr Polozov", "Vu Le", "A. Tiwari", "Gustavo Soares", "Christopher Meek", "Sumit Gulwani"]}}, "b15ea460c77a4ee8aa159a30ab0331deedfcf392": {"id": "b15ea460c77a4ee8aa159a30ab0331deedfcf392", "content": {"title": "BASE Layers: Simplifying Training of Large, Sparse Models", "abstract": "We introduce a new balanced assignment of experts (BASE) layer for large language models that greatly simplifies existing high capacity sparse layers. Sparse layers can dramatically improve the efficiency of training and inference by routing each token to specialized expert modules that contain only a small fraction of the model parameters. However, it can be difficult to learn balanced routing functions that make full use of the available experts; existing approaches typically use routing heuristics or auxiliary expert-balancing loss functions. In contrast, we formulate token-to-expert allocation as a linear assignment problem, allowing an optimal assignment in which each expert receives an equal number of tokens. This optimal assignment scheme improves efficiency by guaranteeing balanced compute loads, and also simplifies training by not requiring any new hyperparameters or auxiliary losses. Code is publicly released.", "year": 2021, "ssId": "b15ea460c77a4ee8aa159a30ab0331deedfcf392", "arXivId": "2103.16716", "link": "https://arxiv.org/pdf/2103.16716.pdf", "openAccess": true, "authors": ["M. Lewis", "Shruti Bhosale", "Tim Dettmers", "Naman Goyal", "Luke Zettlemoyer"]}}, "c56aced0f0c5cfebefadb530cb08d736c3ac5c05": {"id": "c56aced0f0c5cfebefadb530cb08d736c3ac5c05", "content": {"title": "Retrieval Augmented Code Generation and Summarization", "abstract": "Software developers write a lot of source code and documentation during software development. Intrinsically, developers often recall parts of source code or code summaries that they had written in the past while implementing software or documenting them. To mimic developers\u2019 code or summary generation behavior, we propose a retrieval augmented framework, REDCODER, that retrieves relevant code or summaries from a retrieval database and provides them as a supplement to code generation or summarization models. REDCODER has a couple of uniqueness. First, it extends the state-of-the-art dense retrieval technique to search for relevant code or summaries. Second, it can work with retrieval databases that include unimodal (only code or natural language description) or bimodal instances (code-description pairs). We conduct experiments and extensive analysis on two benchmark datasets of code generation and summarization in Java and Python, and the promising results endorse the effectiveness of our proposed retrieval augmented framework.", "year": 2021, "ssId": "c56aced0f0c5cfebefadb530cb08d736c3ac5c05", "arXivId": "2108.11601", "link": "https://arxiv.org/pdf/2108.11601.pdf", "openAccess": true, "authors": ["Md. Rizwan Parvez", "W. Ahmad", "Saikat Chakraborty", "Baishakhi Ray", "Kai-Wei Chang"]}}, "48ea80b65f42e9fbb96b856286d12347d1df52d2": {"id": "48ea80b65f42e9fbb96b856286d12347d1df52d2", "content": {"title": "Tiered Reasoning for Intuitive Physics: Toward Verifiable Commonsense Language Understanding", "abstract": "Large-scale, pre-trained language models (LMs) have achieved human-level performance on a breadth of language understanding tasks. However, evaluations only based on end task performance shed little light on machines\u2019 true ability in language understanding and reasoning. In this paper, we highlight the importance of evaluating the underlying reasoning process in addition to end performance. Toward this goal, we introduce Tiered Reasoning for Intuitive Physics (TRIP), a novel commonsense reasoning dataset with dense annotations that enable multi-tiered evaluation of machines\u2019 reasoning process. Our empirical results show that while large LMs can achieve high end performance, they struggle to support their predictions with valid supporting evidence. The TRIP dataset and our baseline results will motivate verifiable evaluation of commonsense reasoning and facilitate future research toward developing better language understanding and reasoning models.", "year": 2021, "ssId": "48ea80b65f42e9fbb96b856286d12347d1df52d2", "arXivId": "2109.04947", "link": "https://arxiv.org/pdf/2109.04947.pdf", "openAccess": true, "authors": ["Shane Storks", "Qiaozi Gao", "Yichi Zhang", "J. Chai"]}}, "1bf49ef0b33bf8fcc3ebdd16326db419f3af65d8": {"id": "1bf49ef0b33bf8fcc3ebdd16326db419f3af65d8", "content": {"title": "Analyzing and Improving Representations with the Soft Nearest Neighbor Loss", "abstract": "We explore and expand the $\\textit{Soft Nearest Neighbor Loss}$ to measure the $\\textit{entanglement}$ of class manifolds in representation space: i.e., how close pairs of points from the same class are relative to pairs of points from different classes. We demonstrate several use cases of the loss. As an analytical tool, it provides insights into the evolution of class similarity structures during learning. Surprisingly, we find that $\\textit{maximizing}$ the entanglement of representations of different classes in the hidden layers is beneficial for discrimination in the final layer, possibly because it encourages representations to identify class-independent similarity structures. Maximizing the soft nearest neighbor loss in the hidden layers leads not only to improved generalization but also to better-calibrated estimates of uncertainty on outlier data. Data that is not from the training distribution can be recognized by observing that in the hidden layers, it has fewer than the normal number of neighbors from the predicted class.", "year": 2019, "ssId": "1bf49ef0b33bf8fcc3ebdd16326db419f3af65d8", "arXivId": "1902.01889", "link": "https://arxiv.org/pdf/1902.01889.pdf", "openAccess": true, "authors": ["Nicholas Frosst", "Nicolas Papernot", "Geoffrey E. Hinton"]}}, "c2a79e2a65b721d4de5f6d4806323174b9f8f393": {"id": "c2a79e2a65b721d4de5f6d4806323174b9f8f393", "content": {"title": "Towards Zero-Label Language Learning", "abstract": "This paper explores zero-label learning in Natural Language Processing (NLP), whereby no human-annotated data is used anywhere during training and models are trained purely on synthetic data. At the core of our framework is a novel approach for better leveraging the powerful pretrained language models. Specifically, inspired by the recent success of fewshot inference on GPT-3, we present a training data creation procedure named Unsupervised Data Generation (UDG), which leverages fewshot prompts to synthesize high-quality training data without real human annotations. Our method enables zero-label learning as we train task-specific models solely on the synthetic data, yet we achieve better or comparable results from strong baseline models trained on human-labeled data. Furthermore, when mixed with labeled data, our approach serves as a highly effective data augmentation procedure, achieving new state-of-the-art results on the SuperGLUE benchmark1.", "year": 2021, "ssId": "c2a79e2a65b721d4de5f6d4806323174b9f8f393", "arXivId": "2109.09193", "link": "https://arxiv.org/pdf/2109.09193.pdf", "openAccess": true, "authors": ["Zirui Wang", "Adams Wei Yu", "Orhan Firat", "Yuan Cao"]}}, "86db47e228167439f15ee320a8a81d386f529a0c": {"id": "86db47e228167439f15ee320a8a81d386f529a0c", "content": {"title": "LEMON: Language-Based Environment Manipulation via Execution-Guided Pre-training", "abstract": "Language-based environment manipulation requires agents to manipulate the environment following natural language instructions, which is challenging due to the huge space of the environments. To address this challenge, various approaches have been proposed in recent work. Although these approaches work well for their intended environments, they are difficult to generalize across environments. In this work, we propose LEMON, a general framework for language-based environment manipulation tasks. Specifically, we first propose a unified approach to deal with various environments using the same generative language model. Then we propose an execution-guided pre-training strategy to inject prior knowledge of environments to the language model with a pure synthetic pre-training corpus. Experimental results on tasks including ALCHEMY, SCENE, TANGRAMS and PROPARA demonstrate the effectiveness of LEMON: it achieves new state-of-the-art results on ALCHEMY, SCENE and PROPARA, and the execution-guided pretraining strategy brings remarkable improvements on all experimental tasks.", "year": 2022, "ssId": "86db47e228167439f15ee320a8a81d386f529a0c", "arXivId": "2201.08081", "link": "https://arxiv.org/pdf/2201.08081.pdf", "openAccess": true, "authors": ["Qi Shi", "Qian Liu", "Bei Chen", "Yu Zhang", "Ting Liu", "Jian-Guang Lou"]}}, "7847419becbc04596b79f804f844cf9719e875ea": {"id": "7847419becbc04596b79f804f844cf9719e875ea", "content": {"title": "Skill Induction and Planning with Latent Language", "abstract": "We present a framework for learning hierarchical policies from demonstrations, using sparse natural language annotations to guide the discovery of reusable skills for autonomous decision-making. We formulate a generative model of action sequences in which goals generate sequences of high-level subtask descriptions, and these descriptions generate sequences of low-level actions. We describe how to train this model using primarily unannotated demonstrations by parsing demonstrations into sequences of named high-level subtasks, using only a small number of seed annotations to ground language in action. In trained models, the space of natural language commands indexes a combinatorial library of skills; agents can use these skills to plan by generating high-level instruction sequences tailored to novel goals. We evaluate this approach in the ALFRED household simulation environment, providing natural language annotations for only 10% of demonstrations. It completes more than twice as many tasks as a standard approach to learning from demonstrations, matching the performance of instruction following models with access to ground-truth plans during both training and evaluation. 1", "year": 2021, "ssId": "7847419becbc04596b79f804f844cf9719e875ea", "arXivId": "2110.01517", "link": "https://arxiv.org/pdf/2110.01517.pdf", "openAccess": true, "authors": ["Pratyusha Sharma", "A. Torralba", "Jacob Andreas"]}}, "998bd8862ab4193e672bb16fe1aae4d446f7536e": {"id": "998bd8862ab4193e672bb16fe1aae4d446f7536e", "content": {"title": "Contrastive Learning for Unpaired Image-to-Image Translation", "abstract": "In image-to-image translation, each patch in the output should reflect the content of the corresponding patch in the input, independent of domain. We propose a straightforward method for doing so -- maximizing mutual information between the two, using a framework based on contrastive learning. The method encourages two elements (corresponding patches) to map to a similar point in a learned feature space, relative to other elements (other patches) in the dataset, referred to as negatives. We explore several critical design choices for making contrastive learning effective in the image synthesis setting. Notably, we use a multilayer, patch-based approach, rather than operate on entire images. Furthermore, we draw negatives from within the input image itself, rather than from the rest of the dataset. We demonstrate that our framework enables one-sided translation in the unpaired image-to-image translation setting, while improving quality and reducing training time. In addition, our method can even be extended to the training setting where each \"domain\" is only a single image.", "year": 2020, "ssId": "998bd8862ab4193e672bb16fe1aae4d446f7536e", "arXivId": "2007.15651", "link": "https://arxiv.org/pdf/2007.15651.pdf", "openAccess": true, "authors": ["Taesung Park", "Alexei A. Efros", "Richard Zhang", "Jun-Yan Zhu"]}}, "cd3595f65519e4af6bcd073790ac32acdafadf55": {"id": "cd3595f65519e4af6bcd073790ac32acdafadf55", "content": {"title": "Few-shot Image Generation with Elastic Weight Consolidation", "abstract": "Few-shot image generation seeks to generate more data of a given domain, with only few available training examples. As it is unreasonable to expect to fully infer the distribution from just a few observations (e.g., emojis), we seek to leverage a large, related source domain as pretraining (e.g., human faces). Thus, we wish to preserve the diversity of the source domain, while adapting to the appearance of the target. We adapt a pretrained model, without introducing any additional parameters, to the few examples of the target domain. Crucially, we regularize the changes of the weights during this adaptation, in order to best preserve the information of the source dataset, while fitting the target. We demonstrate the effectiveness of our algorithm by generating high-quality results of different target domains, including those with extremely few examples (e.g., <10). We also analyze the performance of our method with respect to some important factors, such as the number of examples and the dissimilarity between the source and target domain.", "year": 2020, "ssId": "cd3595f65519e4af6bcd073790ac32acdafadf55", "arXivId": "2012.02780", "link": "https://arxiv.org/pdf/2012.02780.pdf", "openAccess": true, "authors": ["Yijun Li", "Richard Zhang", "Jingwan Lu", "E. Shechtman"]}}, "90357a6dc817e2f7cec477a51156675fbf545cf1": {"id": "90357a6dc817e2f7cec477a51156675fbf545cf1", "content": {"title": "MERLOT: Multimodal Neural Script Knowledge Models", "abstract": "As humans, we understand events in the visual world contextually, performing multimodal reasoning across time to make inferences about the past, present, and future. We introduce MERLOT, a model that learns multimodal script knowledge by watching millions of YouTube videos with transcribed speech \u2013 in an entirely label-free, self-supervised manner. By pretraining with a mix of both framelevel (spatial) and video-level (temporal) objectives, our model not only learns to match images to temporally corresponding words, but also to contextualize what is happening globally over time. As a result, MERLOT exhibits strong out-of-the-box representations of temporal commonsense, and achieves state-ofthe-art performance on 12 different video QA datasets when finetuned. It also transfers well to the world of static images, allowing models to reason about the dynamic context behind visual scenes. On Visual Commonsense Reasoning, MERLOT answers questions correctly with 80.6% accuracy, outperforming stateof-the-art models of similar size by over 3%, even those that make heavy use of auxiliary supervised data (like object bounding boxes). Ablation analyses demonstrate the complementary importance of: 1) training on videos versus static images; 2) scaling the magnitude and diversity of the pretraining video corpus; and 3) using diverse objectives that encourage full-stack multimodal reasoning, from the recognition to cognition level.", "year": 2021, "ssId": "90357a6dc817e2f7cec477a51156675fbf545cf1", "arXivId": "2106.02636", "link": "https://arxiv.org/pdf/2106.02636.pdf", "openAccess": true, "authors": ["Rowan Zellers", "Ximing Lu", "Jack Hessel", "Youngjae Yu", "J. S. Park", "Jize Cao", "Ali Farhadi", "Yejin Choi"]}}, "9c16dcbcdfe6991f5d448543e6f4cbdf37149883": {"id": "9c16dcbcdfe6991f5d448543e6f4cbdf37149883", "content": {"title": "Does My Multimodal Model Learn Cross-modal Interactions? It\u2019s Harder to Tell than You Might Think!", "abstract": "Modeling expressive cross-modal interactions seems crucial in multimodal tasks, such as visual question answering. However, sometimes high-performing black-box algorithms turn out to be mostly exploiting unimodal signals in the data. We propose a new diagnostic tool, empirical multimodally-additive function projection (EMAP), for isolating whether or not cross-modal interactions improve performance for a given model on a given task. This function projection modifies model predictions so that cross-modal interactions are eliminated, isolating the additive, unimodal structure. For seven image+text classification tasks (on each of which we set new state-of-the-art benchmarks), we find that, in many cases, removing cross-modal interactions results in little to no performance degradation. Surprisingly, this holds even when expressive models, with capacity to consider interactions, otherwise outperform less expressive models; thus, performance improvements, even when present, often cannot be attributed to consideration of cross-modal feature interactions. We hence recommend that researchers in multimodal machine learning report the performance not only of unimodal baselines, but also the EMAP of their best-performing model.", "year": 2020, "ssId": "9c16dcbcdfe6991f5d448543e6f4cbdf37149883", "arXivId": "2010.06572", "link": "https://arxiv.org/pdf/2010.06572.pdf", "openAccess": true, "authors": ["Jack Hessel", "Lillian Lee"]}}, "51bf7a3aee6b1f61b902625f6badffedf200d31a": {"id": "51bf7a3aee6b1f61b902625f6badffedf200d31a", "content": {"title": "Rewriting a Deep Generative Model", "abstract": "A deep generative model such as a GAN learns to model a rich set of semantic and physical rules about the target distribution, but up to now, it has been obscure how such rules are encoded in the network, or how a rule could be changed. In this paper, we introduce a new problem setting: manipulation of specific rules encoded by a deep generative model. To address the problem, we propose a formulation in which the desired rule is changed by manipulating a layer of a deep network as a linear associative memory. We derive an algorithm for modifying one entry of the associative memory, and we demonstrate that several interesting structural rules can be located and modified within the layers of state-of-the-art generative models. We present a user interface to enable users to interactively change the rules of a generative model to achieve desired effects, and we show several proof-of-concept applications. Finally, results on multiple datasets demonstrate the advantage of our method against standard fine-tuning methods and edit transfer algorithms.", "year": 2020, "ssId": "51bf7a3aee6b1f61b902625f6badffedf200d31a", "arXivId": "2007.15646", "link": "https://arxiv.org/pdf/2007.15646.pdf", "openAccess": true, "authors": ["David Bau", "Steven Liu", "Tongzhou Wang", "Jun-Yan Zhu", "A. Torralba"]}}, "b143ee344fe3af4169bde8af8b682a2835dae4a4": {"id": "b143ee344fe3af4169bde8af8b682a2835dae4a4", "content": {"title": "A Cordial Sync: Going Beyond Marginal Policies for Multi-Agent Embodied Tasks", "abstract": "Autonomous agents must learn to collaborate. It is not scalable to develop a new centralized agent every time a task's difficulty outpaces a single agent's abilities. While multi-agent collaboration research has flourished in gridworld-like environments, relatively little work has considered visually rich domains. Addressing this, we introduce the novel task FurnMove in which agents work together to move a piece of furniture through a living room to a goal. Unlike existing tasks, FurnMove requires agents to coordinate at every timestep. We identify two challenges when training agents to complete FurnMove: existing decentralized action sampling procedures do not permit expressive joint action policies and, in tasks requiring close coordination, the number of failed actions dominates successful actions. To confront these challenges we introduce SYNC-policies (synchronize your actions coherently) and CORDIAL (coordination loss). Using SYNC-policies and CORDIAL, our agents achieve a 58% completion rate on FurnMove, an impressive absolute gain of 25 percentage points over competitive decentralized baselines. Our dataset, code, and pretrained models are available at this https URL .", "year": 2020, "ssId": "b143ee344fe3af4169bde8af8b682a2835dae4a4", "arXivId": "2007.04979", "link": "https://arxiv.org/pdf/2007.04979.pdf", "openAccess": true, "authors": ["Unnat Jain", "Luca Weihs", "Eric Kolve", "Ali Farhadi", "S. Lazebnik", "Aniruddha Kembhavi", "A. Schwing"]}}, "4f9a4afc0ba500d839f7ee245513af9b87add8be": {"id": "4f9a4afc0ba500d839f7ee245513af9b87add8be", "content": {"title": "Audio-Visual Instance Discrimination with Cross-Modal Agreement", "abstract": "We present a self-supervised learning approach to learn audio-visual representations from video and audio. Our method uses contrastive learning for cross-modal discrimination of video from audio and vice-versa. We show that optimizing for cross-modal discrimination, rather than within-modal discrimination, is important to learn good representations from video and audio. With this simple but powerful insight, our method achieves highly competitive performance when finetuned on action recognition tasks. Furthermore, while recent work in contrastive learning defines positive and negative samples as individual instances, we generalize this definition by exploring cross-modal agreement. We group together multiple instances as positives by measuring their similarity in both the video and audio feature spaces. Cross-modal agreement creates better positive and negative sets, which allows us to calibrate visual similarities by seeking within-modal discrimination of positive instances, and achieve significant gains on downstream tasks.", "year": 2020, "ssId": "4f9a4afc0ba500d839f7ee245513af9b87add8be", "arXivId": "2004.12943", "link": "https://arxiv.org/pdf/2004.12943.pdf", "openAccess": true, "authors": ["Pedro Morgado", "N. Vasconcelos", "Ishan Misra"]}}, "73c401e29cb83157bc6dfb33d5ce4364a7d2731b": {"id": "73c401e29cb83157bc6dfb33d5ce4364a7d2731b", "content": {"title": "Few-shot Image Generation via Cross-domain Correspondence", "abstract": "Training generative models, such as GANs, on a target domain containing limited examples (e.g., 10) can easily result in overfitting. In this work, we seek to utilize a large source domain for pretraining and transfer the diversity information from source to target. We propose to preserve the relative similarities and differences between instances in the source via a novel cross-domain distance consistency loss. To further reduce overfitting, we present an anchor-based strategy to encourage different levels of realism over different regions in the latent space. With extensive results in both photorealistic and non-photorealistic domains, we demonstrate qualitatively and quantitatively that our few-shot model automatically discovers correspondences between source and target domains and generates more diverse and realistic images than previous methods.", "year": 2021, "ssId": "73c401e29cb83157bc6dfb33d5ce4364a7d2731b", "arXivId": "2104.06820", "link": "https://arxiv.org/pdf/2104.06820.pdf", "openAccess": true, "authors": ["Utkarsh Ojha", "Yijun Li", "Jingwan Lu", "Alexei A. Efros", "Yong Jae Lee", "E. Shechtman", "Richard Zhang"]}}, "03fff40cff6ac531e340f6ffb376e34609770846": {"id": "03fff40cff6ac531e340f6ffb376e34609770846", "content": {"title": "Uncovering Coordinated Networks on Social Media", "abstract": "Coordinated campaigns are used to influence and manipulate social media platforms and their users, a critical challenge to the free exchange of information online. Here we introduce a general network-based framework to uncover groups of accounts that are likely coordinated. The proposed method construct coordination networks based on arbitrary behavioral traces shared among accounts. We present five case studies of influence campaigns in the diverse contexts of U.S. elections, Hong Kong protests, the Syrian civil war, and cryptocurrencies. In each of these cases, we detect networks of coordinated Twitter accounts by examining their identities, images, hashtag sequences, retweets, and temporal patterns. The proposed framework proves to be broadly applicable to uncover different kinds of coordination across information warfare scenarios.", "year": 2020, "ssId": "03fff40cff6ac531e340f6ffb376e34609770846", "arXivId": "2001.05658", "link": "https://arxiv.org/pdf/2001.05658.pdf", "openAccess": true, "authors": ["Diogo Pacheco", "Pik-Mai Hui", "Christopher Torres-Lugo", "B. Truong", "A. Flammini", "F. Menczer"]}}, "dbb4035111c12f4bce971bd4c8086e9d62c9eb97": {"id": "dbb4035111c12f4bce971bd4c8086e9d62c9eb97", "content": {"title": "Multi-GCN: Graph Convolutional Networks for Multi-View Networks, with Applications to Global Poverty", "abstract": "With the rapid expansion of mobile phone networks in developing countries, large-scale graph machine learning has gained sudden relevance in the study of global poverty. Recent applications range from humanitarian response and poverty estimation to urban planning and epidemic containment. Yet the vast majority of computational tools and algorithms used in these applications do not account for the multi-view nature of social networks: people are related in myriad ways, but most graph learning models treat relations as binary. In this paper, we develop a graph-based convolutional network for learning on multi-view networks. We show that this method outperforms state-of-the-art semi-supervised learning algorithms on three different prediction tasks using mobile phone datasets from three different developing countries. We also show that, while designed specifically for use in poverty research, the algorithm also outperforms existing benchmarks on a broader set of learning tasks on multi-view networks, including node labelling in citation networks.", "year": 2019, "ssId": "dbb4035111c12f4bce971bd4c8086e9d62c9eb97", "arXivId": "1901.11213", "link": "https://arxiv.org/pdf/1901.11213.pdf", "openAccess": true, "authors": ["Muhammad Raza Khan", "J. Blumenstock"]}}, "315432474166ff7abbc6351e8ff07fcccbd68458": {"id": "315432474166ff7abbc6351e8ff07fcccbd68458", "content": {"title": "Understanding high- and low-quality URL Sharing on COVID-19 Twitter streams", "abstract": "This article investigates the prevalence of high and low quality URLs shared on Twitter when users discuss COVID-19. We distinguish between high quality health sources, traditional news sources, and low quality misinformation sources. We find that misinformation, in terms of tweets containing URLs from low quality misinformation websites, is shared at a higher rate than tweets containing URLs on high quality health information websites. However, both are a relatively small proportion of the overall conversation. In contrast, news sources are shared at a much higher rate. These findings lead us to analyze the network created by the URLs referenced on the webpages shared by Twitter users. When looking at the combined network formed by all three of the source types, we find that the high quality health information network, the low quality misinformation network, and the news information network are all well connected with a clear community structure. While high and low quality sites do have connections to each other, the connections to and from news sources are more common, highlighting the central brokerage role news sources play in this information ecosystem. Our findings suggest that while low quality URLs are not extensively shared in the COVID-19 Twitter conversation, a well connected community of low quality COVID-19 related information has emerged on the web, and both health and news sources are connecting to this community.", "year": 2020, "ssId": "315432474166ff7abbc6351e8ff07fcccbd68458", "arXivId": null, "link": "https://link.springer.com/content/pdf/10.1007/s42001-020-00093-6.pdf", "openAccess": true, "authors": ["L. Singh", "L. Bode", "Ceren Budak", "Kornraphop Kawintiranon", "Colton Padden", "Emily K. Vraga"]}}, "e6fa88f4af68aa7be4ae91940892eee52571997c": {"id": "e6fa88f4af68aa7be4ae91940892eee52571997c", "content": {"title": "Frustratingly Simple Few-Shot Object Detection", "abstract": "Detecting rare objects from a few examples is an emerging problem. Prior works show meta-learning is a promising approach. But, fine-tuning techniques have drawn scant attention. We find that fine-tuning only the last layer of existing detectors on rare classes is crucial to the few-shot object detection task. Such a simple approach outperforms the meta-learning methods by roughly 2~20 points on current benchmarks and sometimes even doubles the accuracy of the prior methods. However, the high variance in the few samples often leads to the unreliability of existing benchmarks. We revise the evaluation protocols by sampling multiple groups of training examples to obtain stable comparisons and build new benchmarks based on three datasets: PASCAL VOC, COCO and LVIS. Again, our fine-tuning approach establishes a new state of the art on the revised benchmarks. The code as well as the pretrained models are available at this https URL.", "year": 2020, "ssId": "e6fa88f4af68aa7be4ae91940892eee52571997c", "arXivId": "2003.06957", "link": "https://arxiv.org/pdf/2003.06957.pdf", "openAccess": true, "authors": ["Xin Wang", "Thomas E. Huang", "Trevor Darrell", "Joseph Gonzalez", "F. Yu"]}}, "203da29a37a983c487ce75a894b0d70698077bf5": {"id": "203da29a37a983c487ce75a894b0d70698077bf5", "content": {"title": "Coordinated Link Sharing Behavior as a Signal to Surface Sources of Problematic Information on Facebook", "abstract": "Despite widespread concern over the role played by disinformation during recent electoral processes, the intrinsic elusiveness of the subject hinders efforts aimed at estimating its prevalence and effect. While there has been proliferation of attempts to define, understand and fight the spread of problematic information in contemporary media ecosystems, most of these attempts focus on detecting false content and/or bad actors. For instance, several existing studies rely on lists of problematic content or news media sources compiled by fact-checkers. However, these lists may quickly become obsolete leading to unreliable estimates. Using media manipulation as a frame, along with a revised version of the \u201ccoordinated inauthentic behavior\u201d original definition, in this paper, we argue for a wider ecological focus. Leveraging a method designed to detect \u201ccoordinated links sharing behavior\u201d (CLSB), we introduce and assess an approach aimed at creating and keeping lists of potentially problematic sources updated by analyzing the URLs shared on Facebook by public groups, pages, and verified profiles. We show how CLSB is consistently associated with higher risks of encountering problematic news sources across three different datasets of news stories and can be thus used as a signal to support manual and automatic detection of problematic information.", "year": 2020, "ssId": "203da29a37a983c487ce75a894b0d70698077bf5", "arXivId": null, "link": "https://dl.acm.org/doi/abs/10.1145/3400806.3400817", "openAccess": false, "authors": ["Fabio Giglietto", "Nicola Righetti", "L. Rossi", "Giada Marino"]}}, "3c8853d4ae3ad2633c47e840a48951d62b64a5b4": {"id": "3c8853d4ae3ad2633c47e840a48951d62b64a5b4", "content": {"title": "Multi-view graph learning with adaptive label propagation", "abstract": "Graphs play an essential role in many data mining paradigms, such as semi-supervised classification. Conventional graph learning methods mainly focus on constructing graphs from single-view data. Nowadays data can be collected from multiple views using various sensors. How to construct a robust and reliable graph from multi-view data is still an open problem. In this paper, we propose a multi-view graph learning (MVGL) approach with adaptive label propagation for semi-supervised classification. MVGL integrates latent factor extraction, graph sparsification, and label propagation into a unified framework. It seeks shared latent factors from multi-view data as view-independent data representations, and then constructs a sparse graph accordingly. Meanwhile, the label propagation is adaptively optimized during graph construction. An efficient optimization algorithm is designed to solve the model. Experimental results on two benchmark datasets show remarkable improvements over both single-view and multi-view learning baselines.", "year": 2017, "ssId": "3c8853d4ae3ad2633c47e840a48951d62b64a5b4", "arXivId": null, "link": "https://ieeexplore.ieee.org/document/8257918", "openAccess": false, "authors": ["Sheng Li", "Hongfu Liu", "Zhiqiang Tao", "Y. Fu"]}}, "3abcd0ffc54c3a16c9dc5e5d3ea59eaa43070127": {"id": "3abcd0ffc54c3a16c9dc5e5d3ea59eaa43070127", "content": {"title": "Preventing undesirable behavior of intelligent machines", "abstract": "Making well-behaved algorithms Machine learning algorithms are being used in an ever-increasing number of applications, and many of these applications affect quality of life. Yet such algorithms often exhibit undesirable behavior, from various types of bias to causing financial loss or delaying medical diagnoses. In standard machine learning approaches, the burden of avoiding this harmful behavior is placed on the user of the algorithm, who most often is not a computer scientist. Thomas et al. introduce a general framework for algorithm design in which this burden is shifted from the user to the designer of the algorithm. The researchers illustrate the benefits of their approach using examples in gender fairness and diabetes management. Science, this issue p. 999 A machine learning algorithm design framework shifts the burden of avoiding undesirable behavior from user to designer. Intelligent machines using machine learning algorithms are ubiquitous, ranging from simple data analysis and pattern recognition tools to complex systems that achieve superhuman performance on various tasks. Ensuring that they do not exhibit undesirable behavior\u2014that they do not, for example, cause harm to humans\u2014is therefore a pressing problem. We propose a general and flexible framework for designing machine learning algorithms. This framework simplifies the problem of specifying and regulating undesirable behavior. To show the viability of this framework, we used it to create machine learning algorithms that precluded the dangerous behavior caused by standard machine learning algorithms in our experiments. Our framework for designing machine learning algorithms simplifies the safe and responsible application of machine learning.", "year": 2019, "ssId": "3abcd0ffc54c3a16c9dc5e5d3ea59eaa43070127", "arXivId": null, "link": "https://people.cs.umass.edu/~brun/pubs/pubs/Thomas19science.pdf", "openAccess": true, "authors": ["P. Thomas", "Bruno Castro da Silva", "A. Barto", "S. Giguere", "Yuriy Brun", "Emma Brunskill"]}}, "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4": {"id": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "content": {"title": "Learning Transferable Visual Models From Natural Language Supervision", "abstract": "State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to use any of the 1.28 million training examples it was trained on.", "year": 2021, "ssId": "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4", "arXivId": "2103.00020", "link": "https://arxiv.org/pdf/2103.00020.pdf", "openAccess": true, "authors": ["Alec Radford", "Jong Wook Kim", "Chris Hallacy", "A. Ramesh", "Gabriel Goh", "Sandhini Agarwal", "Girish Sastry", "Amanda Askell", "Pamela Mishkin", "Jack Clark", "Gretchen Krueger", "Ilya Sutskever"]}}, "1f3c381eedfe8914b81e93070bfdb00cf86ac943": {"id": "1f3c381eedfe8914b81e93070bfdb00cf86ac943", "content": {"title": "Contrastive Multi-View Representation Learning on Graphs", "abstract": "We introduce a self-supervised approach for learning node and graph level representations by contrasting structural views of graphs. We show that unlike visual representation learning, increasing the number of views to more than two or contrasting multi-scale encodings do not improve performance, and the best performance is achieved by contrasting encodings from first-order neighbors and a graph diffusion. We achieve new state-of-the-art results in self-supervised learning on 8 out of 8 node and graph classification benchmarks under the linear evaluation protocol. For example, on Cora (node) and Reddit-Binary (graph) classification benchmarks, we achieve 86.8% and 84.5% accuracy, which are 5.5% and 2.4% relative improvements over previous state-of-the-art. When compared to supervised baselines, our approach outperforms them in 4 out of 8 benchmarks. Source code is released at: this https URL", "year": 2020, "ssId": "1f3c381eedfe8914b81e93070bfdb00cf86ac943", "arXivId": "2006.05582", "link": "https://arxiv.org/pdf/2006.05582.pdf", "openAccess": true, "authors": ["Kaveh Hassani", "Amir Hosein Khas Ahmadi"]}}, "4b18303edf701e41a288da36f8f1ba129da67eb7": {"id": "4b18303edf701e41a288da36f8f1ba129da67eb7", "content": {"title": "An embarrassingly simple approach to zero-shot learning", "abstract": "Zero-shot learning consists in learning how to recognise new concepts by just having a description of them. Many sophisticated approaches have been proposed to address the challenges this problem comprises. In this paper we describe a zero-shot learning approach that can be implemented in just one line of code, yet it is able to outperform state of the art approaches on standard datasets. The approach is based on a more general framework which models the relationships between features, attributes, and classes as a two linear layers network, where the weights of the top layer are not learned but are given by the environment. We further provide a learning bound on the generalisation error of this kind of approaches, by casting them as domain adaptation methods. In experiments carried out on three standard real datasets, we found that our approach is able to perform significantly better than the state of art on all of them, obtaining a ratio of improvement up to 17%.", "year": 2015, "ssId": "4b18303edf701e41a288da36f8f1ba129da67eb7", "arXivId": null, "link": "https://proceedings.mlr.press/v37/romera-paredes15.pdf", "openAccess": true, "authors": ["B. Romera-Paredes", "Philip H. S. Torr"]}}, "3132a18a441ab6067066e4d4d85608b058c9ed33": {"id": "3132a18a441ab6067066e4d4d85608b058c9ed33", "content": {"title": "Change Point Detection in Time Series Data Using Autoencoders With a Time-Invariant Representation", "abstract": "Change point detection (CPD) aims to locate abrupt property changes in time series data. Recent CPD methods demonstrated the potential of using deep learning techniques, but often lack the ability to identify more subtle changes in the autocorrelation statistics of the signal and suffer from a high false alarm rate. To address these issues, we employ an autoencoder-based methodology with a novel loss function, through which the used autoencoders learn a partially time-invariant representation that is tailored for CPD. The result is a flexible method that allows the user to indicate whether change points should be sought in the time domain, frequency domain or both. Detectable change points include abrupt changes in the slope, mean, variance, autocorrelation function and frequency spectrum. We demonstrate that our proposed method is consistently highly competitive or superior to baseline methods on diverse simulated and real-life benchmark data sets. Finally, we mitigate the issue of false detection alarms through the use of a postprocessing procedure that combines a matched filter and a newly proposed change point score. We show that this combination drastically improves the performance of our method as well as all baseline methods.", "year": 2020, "ssId": "3132a18a441ab6067066e4d4d85608b058c9ed33", "arXivId": "2008.09524", "link": "https://arxiv.org/pdf/2008.09524.pdf", "openAccess": true, "authors": ["Tim De Ryck", "M. de Vos", "A. Bertrand"]}}, "0eac6cbd150b1a7e9d757ccc871eea2bf0d89e42": {"id": "0eac6cbd150b1a7e9d757ccc871eea2bf0d89e42", "content": {"title": "Soft Labels for Ordinal Regression", "abstract": "Ordinal regression attempts to solve classification problems in which categories are not independent, but rather follow a natural order. It is crucial to classify each class correctly while learning adequate interclass ordinal relationships. We present a simple and effective method that constrains these relationships among categories by seamlessly incorporating metric penalties into ground truth label representations. This encoding allows deep neural networks to automatically learn intraclass and interclass relationships without any explicit modification of the network architecture. Our method converts data labels into soft probability distributions that pair well with common categorical loss functions such as cross-entropy. We show that this approach is effective by using off-the-shelf classification and segmentation networks in four wildly different scenarios: image quality ranking, age estimation, horizon line regression, and monocular depth estimation. We demonstrate that our general-purpose method is very competitive with respect to specialized approaches, and adapts well to a variety of different network architectures and metrics.", "year": 2019, "ssId": "0eac6cbd150b1a7e9d757ccc871eea2bf0d89e42", "arXivId": null, "link": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Diaz_Soft_Labels_for_Ordinal_Regression_CVPR_2019_paper.pdf", "openAccess": true, "authors": ["Ra\u00fal D\u00edaz", "A. Marathe"]}}, "03d2af05e41aac58ebae4ab37f09155e53d4b35b": {"id": "03d2af05e41aac58ebae4ab37f09155e53d4b35b", "content": {"title": "1-Bit Matrix Completion", "abstract": "In this paper we develop a theory of matrix completion for the extreme case of noisy 1-bit observations. Instead of observing a subset of the real-valued entries of a matrix M, we obtain a small number of binary (1-bit) measurements generated according to a probability distribution determined by the real-valued entries of M. The central question we ask is whether or not it is possible to obtain an accurate estimate of M from this data. In general this would seem impossible, but we show that the maximum likelihood estimate under a suitable constraint returns an accurate estimate of M when ||M||_{\\infty} <= \\alpha, and rank(M) <= r. If the log-likelihood is a concave function (e.g., the logistic or probit observation models), then we can obtain this maximum likelihood estimate by optimizing a convex program. In addition, we also show that if instead of recovering M we simply wish to obtain an estimate of the distribution generating the 1-bit measurements, then we can eliminate the requirement that ||M||_{\\infty} <= \\alpha. For both cases, we provide lower bounds showing that these estimates are near-optimal. We conclude with a suite of experiments that both verify the implications of our theorems as well as illustrate some of the practical applications of 1-bit matrix completion. In particular, we compare our program to standard matrix completion methods on movie rating data in which users submit ratings from 1 to 5. In order to use our program, we quantize this data to a single bit, but we allow the standard matrix completion program to have access to the original ratings (from 1 to 5). Surprisingly, the approach based on binary data performs significantly better.", "year": 2012, "ssId": "03d2af05e41aac58ebae4ab37f09155e53d4b35b", "arXivId": "1209.3672", "link": "https://arxiv.org/pdf/1209.3672.pdf", "openAccess": true, "authors": ["M. Davenport", "Y. Plan", "E. Berg", "Mary Wootters"]}}, "173c73077a421680f12576524e85dff4b890c17e": {"id": "173c73077a421680f12576524e85dff4b890c17e", "content": {"title": "Two-sample Test with Kernel Projected Wasserstein Distance", "abstract": "We develop a kernel projected Wasserstein distance for the two-sample test, an essential building block in statistics and machine learning: given two sets of samples, to determine whether they are from the same distribution. This method operates by finding the nonlinear mapping in the data space which maximizes the distance between projected distributions. In contrast to existing works about projected Wasserstein distance, the proposed method circumvents the curse of dimensionality more efficiently. We present practical algorithms for computing this distance function together with the non-asymptotic uncertainty quantification of empirical estimates. Numerical examples validate our theoretical results and demonstrate good performance of the proposed method.", "year": 2021, "ssId": "173c73077a421680f12576524e85dff4b890c17e", "arXivId": "2102.06449", "link": "https://arxiv.org/pdf/2102.06449.pdf", "openAccess": true, "authors": ["Jie Wang", "Rui Gao", "Yao Xie"]}}, "365e049ecb7299cc6925483127f2f2123a97c35f": {"id": "365e049ecb7299cc6925483127f2f2123a97c35f", "content": {"title": "Kernel Change-point Detection with Auxiliary Deep Generative Models", "abstract": "Detecting the emergence of abrupt property changes in time series is a challenging problem. Kernel two-sample test has been studied for this task which makes fewer assumptions on the distributions than traditional parametric approaches. However, selecting kernels is non-trivial in practice. Although kernel selection for two-sample test has been studied, the insufficient samples in change point detection problem hinder the success of those developed kernel selection algorithms. In this paper, we propose KL-CPD, a novel kernel learning framework for time series CPD that optimizes a lower bound of test power via an auxiliary generative model. With deep kernel parameterization, KL-CPD endows kernel two-sample test with the data-driven kernel to detect different types of change-points in real-world applications. The proposed approach significantly outperformed other state-of-the-art methods in our comparative evaluation of benchmark datasets and simulation studies.", "year": 2018, "ssId": "365e049ecb7299cc6925483127f2f2123a97c35f", "arXivId": "1901.06077", "link": "https://arxiv.org/pdf/1901.06077.pdf", "openAccess": true, "authors": ["Wei-Cheng Chang", "Chun-Liang Li", "Yiming Yang", "B. P\u00f3czos"]}}, "dd5e54b08b2c1520d179e88cd524e9bd4fe1f6ab": {"id": "dd5e54b08b2c1520d179e88cd524e9bd4fe1f6ab", "content": {"title": "Sample Complexity of Sinkhorn Divergences", "abstract": "Optimal transport (OT) and maximum mean discrepancies (MMD) are now routinely used in machine learning to compare probability measures. We focus in this paper on \\emph{Sinkhorn divergences} (SDs), a regularized variant of OT distances which can interpolate, depending on the regularization strength $\\varepsilon$, between OT ($\\varepsilon=0$) and MMD ($\\varepsilon=\\infty$). Although the tradeoff induced by that regularization is now well understood computationally (OT, SDs and MMD require respectively $O(n^3\\log n)$, $O(n^2)$ and $n^2$ operations given a sample size $n$), much less is known in terms of their \\emph{sample complexity}, namely the gap between these quantities, when evaluated using finite samples \\emph{vs.} their respective densities. Indeed, while the sample complexity of OT and MMD stand at two extremes, $1/n^{1/d}$ for OT in dimension $d$ and $1/\\sqrt{n}$ for MMD, that for SDs has only been studied empirically. In this paper, we \\emph{(i)} derive a bound on the approximation error made with SDs when approximating OT as a function of the regularizer $\\varepsilon$, \\emph{(ii)} prove that the optimizers of regularized OT are bounded in a Sobolev (RKHS) ball independent of the two measures and \\emph{(iii)} provide the first sample complexity bound for SDs, obtained,by reformulating SDs as a maximization problem in a RKHS. We thus obtain a scaling in $1/\\sqrt{n}$ (as in MMD), with a constant that depends however on $\\varepsilon$, making the bridge between OT and MMD complete.", "year": 2018, "ssId": "dd5e54b08b2c1520d179e88cd524e9bd4fe1f6ab", "arXivId": "1810.02733", "link": "https://arxiv.org/pdf/1810.02733.pdf", "openAccess": true, "authors": ["Aude Genevay", "L\u00e9na\u00efc Chizat", "F. Bach", "Marco Cuturi", "G. Peyr\u00e9"]}}, "1d1bbed89882ac1001b915ee73199a919aa0d13c": {"id": "1d1bbed89882ac1001b915ee73199a919aa0d13c", "content": {"title": "Towards Zero-shot Language Modeling", "abstract": "Can we construct a neural language model which is inductively biased towards learning human language? Motivated by this question, we aim at constructing an informative prior for held-out languages on the task of character-level, open-vocabulary language modelling. We obtain this prior as the posterior over network weights conditioned on the data from a sample of training languages, which is approximated through Laplace\u2019s method. Based on a large and diverse sample of languages, the use of our prior outperforms baseline models with an uninformative prior in both zero-shot and few-shot settings, showing that the prior is imbued with universal linguistic knowledge. Moreover, we harness broad language-specific information available for most languages of the world, i.e., features from typological databases, as distant supervision for held-out languages. We explore several language modelling conditioning techniques, including concatenation and meta-networks for parameter generation. They appear beneficial in the few-shot setting, but ineffective in the zero-shot setting. Since the paucity of even plain digital text affects the majority of the world\u2019s languages, we hope that these insights will broaden the scope of applications for language technology.", "year": 2019, "ssId": "1d1bbed89882ac1001b915ee73199a919aa0d13c", "arXivId": "2108.03334", "link": "https://arxiv.org/pdf/2108.03334.pdf", "openAccess": true, "authors": ["E. Ponti", "Ivan Vulic", "Ryan Cotterell", "Roi Reichart", "A. Korhonen"]}}, "a75869d69cc86f501939c237ae4711aa2885f6a6": {"id": "a75869d69cc86f501939c237ae4711aa2885f6a6", "content": {"title": "Meta-Learning for Low-Resource Neural Machine Translation", "abstract": "In this paper, we propose to extend the recently introduced model-agnostic meta-learning algorithm (MAML, Finn, et al., 2017) for low-resource neural machine translation (NMT). We frame low-resource translation as a meta-learning problem where we learn to adapt to low-resource languages based on multilingual high-resource language tasks. We use the universal lexical representation (Gu et al., 2018b) to overcome the input-output mismatch across different languages. We evaluate the proposed meta-learning strategy using eighteen European languages (Bg, Cs, Da, De, El, Es, Et, Fr, Hu, It, Lt, Nl, Pl, Pt, Sk, Sl, Sv and Ru) as source tasks and five diverse languages (Ro,Lv, Fi, Tr and Ko) as target tasks. We show that the proposed approach significantly outperforms the multilingual, transfer learning based approach (Zoph et al., 2016) and enables us to train a competitive NMT system with only a fraction of training examples. For instance, the proposed approach can achieve as high as 22.04 BLEU on Romanian-English WMT\u201916 by seeing only 16,000 translated words (~600 parallel sentences)", "year": 2018, "ssId": "a75869d69cc86f501939c237ae4711aa2885f6a6", "arXivId": "1808.08437", "link": "https://arxiv.org/pdf/1808.08437.pdf", "openAccess": true, "authors": ["Jiatao Gu", "Yong Wang", "Yun Chen", "Kyunghyun Cho", "V. Li"]}}, "0e141942fa265142f41a2a26eb17b6005d3af29e": {"id": "0e141942fa265142f41a2a26eb17b6005d3af29e", "content": {"title": "The State and Fate of Linguistic Diversity and Inclusion in the NLP World", "abstract": "Language technologies contribute to promoting multilingualism and linguistic diversity around the world. However, only a very small number of the over 7000 languages of the world are represented in the rapidly evolving language technologies and applications. In this paper we look at the relation between the types of languages, resources, and their representation in NLP conferences to understand the trajectory that different languages have followed over time. Our quantitative investigation underlines the disparity between languages, especially in terms of their resources, and calls into question the \u201clanguage agnostic\u201d status of current models and systems. Through this paper, we attempt to convince the ACL community to prioritise the resolution of the predicaments highlighted here, so that no language is left behind.", "year": 2020, "ssId": "0e141942fa265142f41a2a26eb17b6005d3af29e", "arXivId": "2004.09095", "link": "https://arxiv.org/pdf/2004.09095.pdf", "openAccess": true, "authors": ["Pratik M. Joshi", "Sebastin Santy", "A. Budhiraja", "Kalika Bali", "M. Choudhury"]}}, "12e9d005c77f76e344361f79c4b008034ae547eb": {"id": "12e9d005c77f76e344361f79c4b008034ae547eb", "content": {"title": "Charagram: Embedding Words and Sentences via Character n-grams", "abstract": "We present Charagram embeddings, a simple approach for learning character-based compositional models to embed textual sequences. A word or sentence is represented using a character n-gram count vector, followed by a single nonlinear transformation to yield a low-dimensional embedding. We use three tasks for evaluation: word similarity, sentence similarity, and part-of-speech tagging. We demonstrate that Charagram embeddings outperform more complex architectures based on character-level recurrent and convolutional neural networks, achieving new state-of-the-art performance on several similarity tasks.", "year": 2016, "ssId": "12e9d005c77f76e344361f79c4b008034ae547eb", "arXivId": "1607.02789", "link": "https://arxiv.org/pdf/1607.02789.pdf", "openAccess": true, "authors": ["J. Wieting", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu"]}}, "12442420adf1c36887fafd108f4b7f4fc822ae60": {"id": "12442420adf1c36887fafd108f4b7f4fc822ae60", "content": {"title": "Revisiting Self-Training for Neural Sequence Generation", "abstract": "Self-training is one of the earliest and simplest semi-supervised methods. The key idea is to augment the original labeled dataset with unlabeled data paired with the model's prediction (i.e. the pseudo-parallel data). While self-training has been extensively studied on classification problems, in complex sequence generation tasks (e.g. machine translation) it is still unclear how self-training works due to the compositionality of the target space. In this work, we first empirically show that self-training is able to decently improve the supervised baseline on neural sequence generation tasks. Through careful examination of the performance gains, we find that the perturbation on the hidden states (i.e. dropout) is critical for self-training to benefit from the pseudo-parallel data, which acts as a regularizer and forces the model to yield close predictions for similar unlabeled inputs. Such effect helps the model correct some incorrect predictions on unlabeled data. To further encourage this mechanism, we propose to inject noise to the input space, resulting in a \"noisy\" version of self-training. Empirical study on standard machine translation and text summarization benchmarks shows that noisy self-training is able to effectively utilize unlabeled data and improve the performance of the supervised baseline by a large margin.", "year": 2019, "ssId": "12442420adf1c36887fafd108f4b7f4fc822ae60", "arXivId": "1909.13788", "link": "https://arxiv.org/pdf/1909.13788.pdf", "openAccess": true, "authors": ["Junxian He", "Jiatao Gu", "Jiajun Shen", "Marc'Aurelio Ranzato"]}}, "76df9c90d5359585f5501a4da1af1078c32be6d7": {"id": "76df9c90d5359585f5501a4da1af1078c32be6d7", "content": {"title": "Unsupervised Transcription of Historical Documents", "abstract": "We present a generative probabilistic model, inspired by historical printing processes, for transcribing images of documents from the printing press era. By jointly modeling the text of the document and the noisy (but regular) process of rendering glyphs, our unsupervised system is able to decipher font structure and more accurately transcribe images into text. Overall, our system substantially outperforms state-of-the-art solutions for this task, achieving a 31% relative reduction in word error rate over the leading commercial system for historical transcription, and a 47% relative reduction over Tesseract, Google\u2019s open source OCR system.", "year": 2013, "ssId": "76df9c90d5359585f5501a4da1af1078c32be6d7", "arXivId": null, "link": "https://aclanthology.org/P13-1021.pdf", "openAccess": true, "authors": ["Taylor Berg-Kirkpatrick", "Greg Durrett", "D. Klein"]}}, "708f8c0eb5032edd6f31663a27febbb0529cbcf3": {"id": "708f8c0eb5032edd6f31663a27febbb0529cbcf3", "content": {"title": "Visually Grounded Neural Syntax Acquisition", "abstract": "We present the Visually Grounded Neural Syntax Learner (VG-NSL), an approach for learning syntactic representations and structures without any explicit supervision. The model learns by looking at natural images and reading paired captions. VG-NSL generates constituency parse trees of texts, recursively composes representations for constituents, and matches them with images. We define concreteness of constituents by their matching scores with images, and use it to guide the parsing of text. Experiments on the MSCOCO data set show that VG-NSL outperforms various unsupervised parsing approaches that do not use visual grounding, in terms of F1 scores against gold parse trees. We find that VGNSL is much more stable with respect to the choice of random initialization and the amount of training data. We also find that the concreteness acquired by VG-NSL correlates well with a similar measure defined by linguists. Finally, we also apply VG-NSL to multiple languages in the Multi30K data set, showing that our model consistently outperforms prior unsupervised approaches.", "year": 2019, "ssId": "708f8c0eb5032edd6f31663a27febbb0529cbcf3", "arXivId": "1906.02890", "link": "https://arxiv.org/pdf/1906.02890.pdf", "openAccess": true, "authors": ["Haoyue Shi", "Jiayuan Mao", "Kevin Gimpel", "Karen Livescu"]}}, "04a7d9f0388ded93c1ec16e36a6df3cd44cb95b0": {"id": "04a7d9f0388ded93c1ec16e36a6df3cd44cb95b0", "content": {"title": "Entity Linking in 100 Languages", "abstract": "We propose a new formulation for multilingual entity linking, where language-specific mentions resolve to a language-agnostic Knowledge Base. We train a dual encoder in this new setting, building on prior work with improved feature representation, negative mining, and an auxiliary entity-pairing task, to obtain a single entity retrieval model that covers 100+ languages and 20 million entities. The model outperforms state-of-the-art results from a far more limited cross-lingual linking task. Rare entities and low-resource languages pose challenges at this large-scale, so we advocate for an increased focus on zero- and few-shot evaluation. To this end, we provide Mewsli-9, a large new multilingual dataset (this http URL) matched to our setting, and show how frequency-based analysis provided key insights for our model and training enhancements.", "year": 2020, "ssId": "04a7d9f0388ded93c1ec16e36a6df3cd44cb95b0", "arXivId": "2011.02690", "link": "https://arxiv.org/pdf/2011.02690.pdf", "openAccess": true, "authors": ["Jan A. Botha", "Zifei Shan", "D. Gillick"]}}, "abaf39dc9d1b156ddf387230611f5102378d052c": {"id": "abaf39dc9d1b156ddf387230611f5102378d052c", "content": {"title": "Multi-Input Attention for Unsupervised OCR Correction", "abstract": "We propose a novel approach to OCR post-correction that exploits repeated texts in large corpora both as a source of noisy target outputs for unsupervised training and as a source of evidence when decoding. A sequence-to-sequence model with attention is applied for single-input correction, and a new decoder with multi-input attention averaging is developed to search for consensus among multiple sequences. We design two ways of training the correction model without human annotation, either training to match noisily observed textual variants or bootstrapping from a uniform error model. On two corpora of historical newspapers and books, we show that these unsupervised techniques cut the character and word error rates nearly in half on single inputs and, with the addition of multi-input decoding, can rival supervised methods.", "year": 2018, "ssId": "abaf39dc9d1b156ddf387230611f5102378d052c", "arXivId": null, "link": "https://aclanthology.org/P18-1220.pdf", "openAccess": true, "authors": ["Rui Dong", "David A. Smith"]}}, "243880fde63abfc287bd1356c2e1dbf68a1a0aac": {"id": "243880fde63abfc287bd1356c2e1dbf68a1a0aac", "content": {"title": "Indigenous language technologies in Canada: Assessment, challenges, and successes", "abstract": "In this article, we discuss which text, speech, and image technologies have been developed, and would be feasible to develop, for the approximately 60 Indigenous languages spoken in Canada. In particular, we concentrate on technologies that may be feasible to develop for most or all of these languages, not just those that may be feasible for the few most-resourced of these. We assess past achievements and consider future horizons for Indigenous language transliteration, text prediction, spell-checking, approximate search, machine translation, speech recognition, speaker diarization, speech synthesis, optical character recognition, and computer-aided language learning.", "year": 2018, "ssId": "243880fde63abfc287bd1356c2e1dbf68a1a0aac", "arXivId": null, "link": "https://aclanthology.org/C18-1222.pdf", "openAccess": true, "authors": ["Patrick Littell", "A. Kazantseva", "R. Kuhn", "Aidan Pine", "Antti Arppe", "Christopher Cox", "M. Junker"]}}, "03058f9a39d37a8bee635969eed227d59bbc8152": {"id": "03058f9a39d37a8bee635969eed227d59bbc8152", "content": {"title": "Scalable Gradients for Stochastic Differential Equations", "abstract": "The adjoint sensitivity method scalably computes gradients of solutions to ordinary differential equations. We generalize this method to stochastic differential equations, allowing time-efficient and constant-memory computation of gradients with high-order adaptive solvers. Specifically, we derive a stochastic differential equation whose solution is the gradient, a memory-efficient algorithm for caching noise, and conditions under which numerical solutions converge. In addition, we combine our method with gradient-based stochastic variational inference for latent stochastic differential equations. We use our method to fit stochastic dynamics defined by neural networks, achieving competitive performance on a 50-dimensional motion capture dataset.", "year": 2020, "ssId": "03058f9a39d37a8bee635969eed227d59bbc8152", "arXivId": "2001.01328", "link": "https://arxiv.org/pdf/2001.01328.pdf", "openAccess": true, "authors": ["Xuechen Li", "Ting-Kam Leonard Wong", "Ricky T. Q. Chen", "D. Duvenaud"]}}, "e107beee5e84cd11d6460f7040676687a51a378b": {"id": "e107beee5e84cd11d6460f7040676687a51a378b", "content": {"title": "End-to-end reconstruction meets data-driven regularization for inverse problems", "abstract": "We propose a new approach for learning end-to-end reconstruction operators based on unpaired training data for ill-posed inverse problems. The proposed method combines the classical variational framework with iterative unrolling and essentially seeks to minimize a weighted combination of the expected distortion in the measurement space and the Wasserstein-1 distance between the distributions of the reconstruction and the ground-truth. More specifically, the regularizer in the variational setting is parametrized by a deep neural network and learned simultaneously with the unrolled reconstruction operator. The variational problem is then initialized with the output of the reconstruction network and solved iteratively till convergence. Notably, it takes significantly fewer iterations to converge as compared to variational methods, thanks to the excellent initialization obtained via the unrolled operator. The resulting approach combines the computational efficiency of end-to-end unrolled reconstruction with the well-posedness and noise-stability guarantees of the variational setting. Moreover, we demonstrate with the example of image reconstruction in X-ray computed tomography (CT) that our approach outperforms state-of-the-art unsupervised methods and that it outperforms or is at least on par with state-of-the-art supervised data-driven reconstruction approaches.", "year": 2021, "ssId": "e107beee5e84cd11d6460f7040676687a51a378b", "arXivId": "2106.03538", "link": "https://arxiv.org/pdf/2106.03538.pdf", "openAccess": true, "authors": ["Subhadip Mukherjee", "M. Carioni", "O. \u00d6ktem", "C. Sch\u00f6nlieb"]}}, "0de86afbf91d0cf3e595a23a5b7a4d19deefb891": {"id": "0de86afbf91d0cf3e595a23a5b7a4d19deefb891", "content": {"title": "Parameter Inference with Bifurcation Diagrams", "abstract": "Estimation of parameters in differential equation models can be achieved by applying learning algorithms to quantitative time-series data. However, sometimes it is only possible to measure qualitative changes of a system in response to a controlled condition. In dynamical systems theory, such change points are known as bifurcations and lie on a function of the controlled condition called the bifurcation diagram. In this work, we propose a gradient-based approach for inferring the parameters of differential equations that produce a user-specified bifurcation diagram. The cost function contains an error term that is minimal when the model bifurcations match the specified targets and a bifurcation measure which has gradients that push optimisers towards bifurcating parameter regimes. The gradients can be computed without the need to differentiate through the operations of the solver that was used to compute the diagram. We demonstrate parameter inference with minimal models which explore the space of saddle-node and pitchfork diagrams and the genetic toggle switch from synthetic biology. Furthermore, the cost landscape allows us to organise models in terms of topological and geometric equivalence.", "year": 2021, "ssId": "0de86afbf91d0cf3e595a23a5b7a4d19deefb891", "arXivId": "2106.04243", "link": "https://arxiv.org/pdf/2106.04243.pdf", "openAccess": true, "authors": ["Gregory Sz\u00e9p", "N. Dalchau", "A. Csik\u00e1sz-Nagy"]}}, "449310e3538b08b43227d660227dfd2875c3c3c1": {"id": "449310e3538b08b43227d660227dfd2875c3c3c1", "content": {"title": "Neural Ordinary Differential Equations", "abstract": "We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a black-box differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.", "year": 2018, "ssId": "449310e3538b08b43227d660227dfd2875c3c3c1", "arXivId": "1806.07366", "link": "https://arxiv.org/pdf/1806.07366.pdf", "openAccess": true, "authors": ["T. Chen", "Yulia Rubanova", "J. Bettencourt", "D. Duvenaud"]}}, "31603b3339f4da5bdc6b7de4231bd1ddfb32a50a": {"id": "31603b3339f4da5bdc6b7de4231bd1ddfb32a50a", "content": {"title": "Neural Controlled Differential Equations for Irregular Time Series", "abstract": "Neural ordinary differential equations are an attractive option for modelling temporal dynamics. However, a fundamental issue is that the solution to an ordinary differential equation is determined by its initial condition, and there is no mechanism for adjusting the trajectory based on subsequent observations. Here, we demonstrate how this may be resolved through the well-understood mathematics of \\emph{controlled differential equations}. The resulting \\emph{neural controlled differential equation} model is directly applicable to the general setting of partially-observed irregularly-sampled multivariate time series, and (unlike previous work on this problem) it may utilise memory-efficient adjoint-based backpropagation even across observations. We demonstrate that our model achieves state-of-the-art performance against similar (ODE or RNN based) models in empirical studies on a range of datasets. Finally we provide theoretical results demonstrating universal approximation, and that our model subsumes alternative ODE models.", "year": 2020, "ssId": "31603b3339f4da5bdc6b7de4231bd1ddfb32a50a", "arXivId": "2005.08926", "link": "https://arxiv.org/pdf/2005.08926.pdf", "openAccess": true, "authors": ["Patrick Kidger", "James Morrill", "James Foster", "Terry Lyons"]}}, "76b95833fd0e242896d231abdea8dc01a167c7a6": {"id": "76b95833fd0e242896d231abdea8dc01a167c7a6", "content": {"title": "Approximate Gaussian process inference for the drift function in stochastic differential equations", "abstract": "We introduce a nonparametric approach for estimating drift functions in systems of stochastic differential equations from incomplete observations of the state vector. Using a Gaussian process prior over the drift as a function of the state vector, we develop an approximate EM algorithm to deal with the unobserved, latent dynamics between observations. The posterior over states is approximated by a piecewise linearized process and the MAP estimation of the drift is facilitated by a sparse Gaussian process regression.", "year": 2013, "ssId": "76b95833fd0e242896d231abdea8dc01a167c7a6", "arXivId": null, "link": "https://proceedings.neurips.cc/paper/2013/file/021bbc7ee20b71134d53e20206bd6feb-Paper.pdf", "openAccess": true, "authors": ["Andreas Ruttor", "Philipp Batz", "M. Opper"]}}, "3ba013b8b56646d66aac8472fb90a5c029ef55a0": {"id": "3ba013b8b56646d66aac8472fb90a5c029ef55a0", "content": {"title": "Learning Differential Equations that are Easy to Solve", "abstract": "Differential equations parameterized by neural networks become expensive to solve numerically as training progresses. We propose a remedy that encourages learned dynamics to be easier to solve. Specifically, we introduce a differentiable surrogate for the time cost of standard numerical solvers, using higher-order derivatives of solution trajectories. These derivatives are efficient to compute with Taylor-mode automatic differentiation. Optimizing this additional objective trades model performance against the time cost of solving the learned dynamics. We demonstrate our approach by training substantially faster, while nearly as accurate, models in supervised classification, density estimation, and time-series modelling tasks.", "year": 2020, "ssId": "3ba013b8b56646d66aac8472fb90a5c029ef55a0", "arXivId": "2007.04504", "link": "https://arxiv.org/pdf/2007.04504.pdf", "openAccess": true, "authors": ["Jacob Kelly", "J. Bettencourt", "Matthew J. Johnson", "D. Duvenaud"]}}, "2dd81061e0b11c828446f6a1843741ae51facbd2": {"id": "2dd81061e0b11c828446f6a1843741ae51facbd2", "content": {"title": "Latent Equilibrium: A unified learning theory for arbitrarily fast computation with arbitrarily slow neurons", "abstract": "The response time of physical computational elements is finite, and neurons are no exception. In hierarchical models of cortical networks each layer thus introduces a response lag. This inherent property of physical dynamical systems results in delayed processing of stimuli and causes a timing mismatch between network output and instructive signals, thus afflicting not only inference, but also learning. We introduce Latent Equilibrium, a new framework for inference and learning in networks of slow components which avoids these issues by harnessing the ability of biological neurons to phase-advance their output with respect to their membrane potential. This principle enables quasi-instantaneous inference independent of network depth and avoids the need for phased plasticity or computationally expensive network relaxation phases. We jointly derive disentangled neuron and synapse dynamics from a prospective energy function that depends on a network\u2019s generalized position and momentum. The resulting model can be interpreted as a biologically plausible approximation of error backpropagation in deep cortical networks with continuous-time, leaky neuronal dynamics and continuously active, local plasticity. We demonstrate successful learning of standard benchmark datasets, achieving competitive performance using both fully-connected and convolutional architectures, and show how our principle can be applied to detailed models of cortical microcircuitry. Furthermore, we study the robustness of our model to spatio-temporal substrate imperfections to demonstrate its feasibility for physical realization, be it in vivo or in silico.", "year": 2021, "ssId": "2dd81061e0b11c828446f6a1843741ae51facbd2", "arXivId": "2110.14549", "link": "https://arxiv.org/pdf/2110.14549.pdf", "openAccess": true, "authors": ["Paul Haider", "B. Ellenberger", "L. Kriener", "Jakob Jordan", "W. Senn", "M. Petrovici"]}}, "eebfece29b7a5c2202f1ec53ef49d6fdb75ce0ea": {"id": "eebfece29b7a5c2202f1ec53ef49d6fdb75ce0ea", "content": {"title": "Online Learning Of Neural Computations From Sparse Temporal Feedback", "abstract": "Neuronal computations depend on synaptic connectivity and intrinsic electrophysiological properties. Synaptic connectivity determines which inputs from presynaptic neurons are integrated, while cellular properties determine how inputs are filtered over time. Unlike their biological counterparts, most computational approaches to learning in simulated neural networks are limited to changes in synaptic connectivity. However, if intrinsic parameters change, neural computations are altered drastically. Here, we include the parameters that determine the intrinsic properties, e.g., time constants and reset potential, into the learning paradigm. Using sparse feedback signals that indicate target spike times, and gradient-based parameter updates, we show that the intrinsic parameters can be learned along with the synaptic weights to produce specific input-output functions. Specifically, we use a teacher-student paradigm in which a randomly initialised leaky integrate-and-fire or resonate-and-fire neuron must recover the parameters of a teacher neuron. We show that complex temporal functions can be learned online and without backpropagation through time, relying on event-based updates only. Our results are a step towards online learning of neural computations from ungraded and unsigned sparse feedback signals with a biologically inspired learning mechanism.", "year": 2021, "ssId": "eebfece29b7a5c2202f1ec53ef49d6fdb75ce0ea", "arXivId": null, "link": "https://proceedings.neurips.cc/paper/2021/file/88e1ce84f9feef5a08d0df0334c53468-Paper.pdf", "openAccess": true, "authors": ["Mikio L. Braun", "T. Vogels"]}}, "c6bb9e4a9eaa0f0f8309597af2cefe03bd3f1bb5": {"id": "c6bb9e4a9eaa0f0f8309597af2cefe03bd3f1bb5", "content": {"title": "Chaos as an interpretable benchmark for forecasting and data-driven modelling", "abstract": "The striking fractal geometry of strange attractors underscores the generative nature of chaos: like probability distributions, chaotic systems can be repeatedly measured to produce arbitrarily-detailed information about the underlying attractor. Chaotic systems thus pose a unique challenge to modern statistical learning techniques, while retaining quanti\ufb01able mathematical properties that make them controllable and interpretable as benchmarks. Here, we present a growing database currently comprising 131 known chaotic dynamical systems spanning \ufb01elds such as astro-physics, climatology, and biochemistry. Each system is paired with precomputed multivariate and univariate time series. Our dataset has comparable scale to existing static time series databases; however, our systems can be re-integrated to produce additional datasets of arbitrary length and granularity. Our dataset is annotated with known mathematical properties of each system, and we perform feature analysis to broadly categorize the diverse dynamics present across the collection. Chaotic systems inherently challenge forecasting models, and across extensive benchmarks we correlate forecasting performance with the degree of chaos present. We also exploit the unique generative properties of our dataset in several proof-of-concept experiments: surrogate transfer learning to improve time series classi\ufb01cation, importance sampling to accelerate model training, and benchmarking symbolic regression algorithms.", "year": 2021, "ssId": "c6bb9e4a9eaa0f0f8309597af2cefe03bd3f1bb5", "arXivId": "2110.05266", "link": "https://arxiv.org/pdf/2110.05266.pdf", "openAccess": true, "authors": ["W. Gilpin"]}}, "9635e3c008f7bfa80638ade7134a8fb0ef1b37e1": {"id": "9635e3c008f7bfa80638ade7134a8fb0ef1b37e1", "content": {"title": "You should evaluate your language model on marginal likelihood over tokenisations", "abstract": "Neural language models typically tokenise input text into sub-word units to achieve an open vocabulary. The standard approach is to use a single canonical tokenisation at both train and test time. We suggest that this approach is unsatisfactory and may bottleneck our evaluation of language model performance. Using only the one-best tokenisation ignores tokeniser uncertainty over alternative tokenisations, which may hurt model out-of-domain performance. In this paper, we argue that instead, language models should be evaluated on their marginal likelihood over tokenisations. We compare different estimators for the marginal likelihood based on sampling, and show that it is feasible to estimate the marginal likelihood with a manageable number of samples. We then evaluate a pretrained language model on both the one-best-tokenisation and marginal perplexities, and show that the marginal perplexity can be significantly better than the one best, especially on out-of-domain data. We link this difference in perplexity to the tokeniser uncertainty as measured by tokeniser entropy. We discuss some implications of our results for language model training and evaluation, particularly with regard to tokenisation robustness.", "year": 2021, "ssId": "9635e3c008f7bfa80638ade7134a8fb0ef1b37e1", "arXivId": "2109.02550", "link": "https://arxiv.org/pdf/2109.02550.pdf", "openAccess": true, "authors": ["Kris Cao", "Laura Rimell"]}}, "4e1d27c68a60bfd8393462107677469bf286f0f8": {"id": "4e1d27c68a60bfd8393462107677469bf286f0f8", "content": {"title": "Program Synthesis with Pragmatic Communication", "abstract": "Program synthesis techniques construct or infer programs from user-provided specifications, such as input-output examples. Yet most specifications, especially those given by end-users, leave the synthesis problem radically ill-posed, because many programs may simultaneously satisfy the specification. Prior work resolves this ambiguity by using various inductive biases, such as a preference for simpler programs. This work introduces a new inductive bias derived by modeling the program synthesis task as rational communication, drawing insights from recursive reasoning models of pragmatics. Given a specification, we score a candidate program both on its consistency with the specification, and also whether a rational speaker would chose this particular specification to communicate that program. We develop efficient algorithms for such an approach when learning from input-output examples, and build a pragmatic program synthesizer over a simple grid-like layout domain. A user study finds that end-user participants communicate more effectively with the pragmatic program synthesizer over a non-pragmatic one.", "year": 2020, "ssId": "4e1d27c68a60bfd8393462107677469bf286f0f8", "arXivId": "2007.05060", "link": "https://arxiv.org/pdf/2007.05060.pdf", "openAccess": true, "authors": ["Yewen Pu", "Kevin Ellis", "Marta Kryven", "J. Tenenbaum", "Armando Solar-Lezama"]}}, "9b621c0bcd2029006b389bc51395fb6604f9a855": {"id": "9b621c0bcd2029006b389bc51395fb6604f9a855", "content": {"title": "Open-domain clarification question generation without question examples", "abstract": "An overarching goal of natural language processing is to enable machines to communicate seamlessly with humans. However, natural language can be ambiguous or unclear. In cases of uncertainty, humans engage in an interactive process known as repair: asking questions and seeking clarification until their uncertainty is resolved. We propose a framework for building a visually grounded question-asking model capable of producing polar (yes-no) clarification questions to resolve misunderstandings in dialogue. Our model uses an expected information gain objective to derive informative questions from an off-the-shelf image captioner without requiring any supervised question-answer data. We demonstrate our model\u2019s ability to pose questions that improve communicative success in a goal-oriented 20 questions game with synthetic and human answerers.", "year": 2021, "ssId": "9b621c0bcd2029006b389bc51395fb6604f9a855", "arXivId": "2110.09779", "link": "https://arxiv.org/pdf/2110.09779.pdf", "openAccess": true, "authors": ["Julia White", "Gabriel Poesia", "Robert D. Hawkins", "Dorsa Sadigh", "Noah D. Goodman"]}}, "a94ec1cd89839aa5132118916849d46dff861914": {"id": "a94ec1cd89839aa5132118916849d46dff861914", "content": {"title": "MindCraft: Theory of Mind Modeling for Situated Dialogue in Collaborative Tasks", "abstract": "An ideal integration of autonomous agents in a human world implies that they are able to collaborate on human terms. In particular, theory of mind plays an important role in maintaining common ground during human collaboration and communication. To enable theory of mind modeling in situated interactions, we introduce a fine-grained dataset of collaborative tasks performed by pairs of human subjects in the 3D virtual blocks world of Minecraft. It provides information that captures partners\u2019 beliefs of the world and of each other as an interaction unfolds, bringing abundant opportunities to study human collaborative behaviors in situated language communication. As a first step towards our goal of developing embodied AI agents able to infer belief states of collaborative partners in situ, we build and present results on computational models for several theory of mind tasks.", "year": 2021, "ssId": "a94ec1cd89839aa5132118916849d46dff861914", "arXivId": "2109.06275", "link": "https://arxiv.org/pdf/2109.06275.pdf", "openAccess": true, "authors": ["Cristian-Paul Bara", "Sky CH-Wang", "J. Chai"]}}, "c783e1fb3ce8514f981925ee590c00884660ee4e": {"id": "c783e1fb3ce8514f981925ee590c00884660ee4e", "content": {"title": "CM3: A Causal Masked Multimodal Model of the Internet", "abstract": "We introduce CM3, a family of causally masked generative models trained over a large corpus of structured multi-modal documents that can contain both text and image tokens. Our new causally masked approach generates tokens left to right while also masking out a small number of long token spans that are generated at the end of the string, instead of their original positions. The casual masking object provides a type of hybrid of the more common causal and masked language models, by enabling full generative modeling while also providing bidirectional context when generating the masked spans. We train causally masked languageimage models on large-scale web and Wikipedia articles, where each document contains all of the text, hypertext markup, hyperlinks, and image tokens (from a VQVAE-GAN), provided in the order they appear in the original HTML source (before masking). The resulting CM3 models can generate rich structured, multimodal outputs while conditioning on arbitrary masked document contexts, and thereby implicitly learn a wide range of text, image, and cross modal tasks. They can be prompted to recover, in a zero-shot fashion, the functionality of models such as DALL-E, GENRE, and HTLM (Ramesh et al., 2021; De Cao et al., 2020; Aghajanyan et al., 2021). We set the new state-of-the-art in zero-shot summarization, entity linking, and entity disambiguation while maintaining competitive performance in the fine-tuning setting. We can generate images unconditionally, conditioned on text (like DALL-E) and do captioning all in a zero-shot setting with a single model.", "year": 2022, "ssId": "c783e1fb3ce8514f981925ee590c00884660ee4e", "arXivId": "2201.07520", "link": "https://arxiv.org/pdf/2201.07520.pdf", "openAccess": true, "authors": ["Armen Aghajanyan", "Bernie Huang", "Candace Ross", "Vladimir Karpukhin", "Hu Xu", "Naman Goyal", "Dmytro Okhonko", "Mandar Joshi", "Gargi Ghosh", "M. Lewis", "Luke Zettlemoyer"]}}, "f4cf4246f3882aa6337e9c05d5675a3b8463a32e": {"id": "f4cf4246f3882aa6337e9c05d5675a3b8463a32e", "content": {"title": "ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks", "abstract": "We present ALFRED (Action Learning From Realistic Environments and Directives), a benchmark for learning a mapping from natural language instructions and egocentric vision to sequences of actions for household tasks. ALFRED includes long, compositional tasks with non-reversible state changes to shrink the gap between research benchmarks and real-world applications. ALFRED consists of expert demonstrations in interactive visual environments for 25k natural language directives. These directives contain both high-level goals like \u201cRinse off a mug and place it in the coffee maker.\u201d and low-level language instructions like \u201cWalk to the coffee maker on the right.\u201d ALFRED tasks are more complex in terms of sequence length, action space, and language than existing vision- and-language task datasets. We show that a baseline model based on recent embodied vision-and-language tasks performs poorly on ALFRED, suggesting that there is significant room for developing innovative grounded visual language understanding models with this benchmark.", "year": 2019, "ssId": "f4cf4246f3882aa6337e9c05d5675a3b8463a32e", "arXivId": "1912.01734", "link": "https://arxiv.org/pdf/1912.01734.pdf", "openAccess": true, "authors": ["Mohit Shridhar", "Jesse Thomason", "Daniel Gordon", "Yonatan Bisk", "Winson Han", "R. Mottaghi", "Luke Zettlemoyer", "D. Fox"]}}, "d7bebb71635cb818d2f5e0ca0a70434283deb4b6": {"id": "d7bebb71635cb818d2f5e0ca0a70434283deb4b6", "content": {"title": "Modeling Strong and Human-Like Gameplay with KL-Regularized Search", "abstract": "We consider the task of building strong but humanlike policies in multi-agent decision-making problems, given examples of human behavior. Imitation learning is effective at predicting human actions but may not match the strength of expert humans, while self-play learning and search techniques (e.g. AlphaZero) lead to strong performance but may produce policies that are difficult for humans to understand and coordinate with. We show in chess and Go that regularizing search based on the KL divergence from an imitationlearned policy results in higher human prediction accuracy and stronger performance than imitation learning alone. We then introduce a novel regret minimization algorithm that is regularized based on the KL divergence from an imitation-learned policy, and show that using this algorithm for search in no-press Diplomacy yields a policy that matches the human prediction accuracy of imitation learning while being substantially stronger.", "year": 2021, "ssId": "d7bebb71635cb818d2f5e0ca0a70434283deb4b6", "arXivId": "2112.07544", "link": "https://arxiv.org/pdf/2112.07544.pdf", "openAccess": true, "authors": ["Athul Paul Jacob", "David J. Wu", "Gabriele Farina", "Adam Lerer", "A. Bakhtin", "Jacob Andreas", "Noam Brown"]}}, "c99e050b83360e5cbeee8fd2957aaab5b31aa638": {"id": "c99e050b83360e5cbeee8fd2957aaab5b31aa638", "content": {"title": "Calibration, Entropy Rates, and Memory in Language Models", "abstract": "Building accurate language models that capture meaningful long-term dependencies is a core challenge in natural language processing. Towards this end, we present a calibration-based approach to measure long-term discrepancies between a generative sequence model and the true distribution, and use these discrepancies to improve the model. Empirically, we show that state-of-the-art language models, including LSTMs and Transformers, are \\emph{miscalibrated}: the entropy rates of their generations drift dramatically upward over time. We then provide provable methods to mitigate this phenomenon. Furthermore, we show how this calibration-based approach can also be used to measure the amount of memory that language models use for prediction.", "year": 2019, "ssId": "c99e050b83360e5cbeee8fd2957aaab5b31aa638", "arXivId": "1906.05664", "link": "https://arxiv.org/pdf/1906.05664.pdf", "openAccess": true, "authors": ["M. Braverman", "Xinyi Chen", "S. Kakade", "Karthik Narasimhan", "Cyril Zhang", "Yi Zhang"]}}, "79c93274429d6355959f1e4374c2147bb81ea649": {"id": "79c93274429d6355959f1e4374c2147bb81ea649", "content": {"title": "LXMERT: Learning Cross-Modality Encoder Representations from Transformers", "abstract": "Vision-and-language reasoning requires an understanding of visual concepts, language semantics, and, most importantly, the alignment and relationships between these two modalities. We thus propose the LXMERT (Learning Cross-Modality Encoder Representations from Transformers) framework to learn these vision-and-language connections. In LXMERT, we build a large-scale Transformer model that consists of three encoders: an object relationship encoder, a language encoder, and a cross-modality encoder. Next, to endow our model with the capability of connecting vision and language semantics, we pre-train the model with large amounts of image-and-sentence pairs, via five diverse representative pre-training tasks: masked language modeling, masked object prediction (feature regression and label classification), cross-modality matching, and image question answering. These tasks help in learning both intra-modality and cross-modality relationships. After fine-tuning from our pre-trained parameters, our model achieves the state-of-the-art results on two visual question answering datasets (i.e., VQA and GQA). We also show the generalizability of our pre-trained cross-modality model by adapting it to a challenging visual-reasoning task, NLVR2, and improve the previous best result by 22% absolute (54% to 76%). Lastly, we demonstrate detailed ablation studies to prove that both our novel model components and pre-training strategies significantly contribute to our strong results. Code and pre-trained models publicly available at: https://github.com/airsplay/lxmert", "year": 2019, "ssId": "79c93274429d6355959f1e4374c2147bb81ea649", "arXivId": "1908.07490", "link": "https://arxiv.org/pdf/1908.07490.pdf", "openAccess": true, "authors": ["Hao Hao Tan", "Mohit Bansal"]}}, "c581686edbd7227e9eb4a0841cce16728ca27369": {"id": "c581686edbd7227e9eb4a0841cce16728ca27369", "content": {"title": "RecipeQA: A Challenge Dataset for Multimodal Comprehension of Cooking Recipes", "abstract": "Understanding and reasoning about cooking recipes is a fruitful research direction towards enabling machines to interpret procedural text. In this work, we introduce RecipeQA, a dataset for multimodal comprehension of cooking recipes. It comprises of approximately 20K instructional recipes with multiple modalities such as titles, descriptions and aligned set of images. With over 36K automatically generated question-answer pairs, we design a set of comprehension and reasoning tasks that require joint understanding of images and text, capturing the temporal flow of events and making sense of procedural knowledge. Our preliminary results indicate that RecipeQA will serve as a challenging test bed and an ideal benchmark for evaluating machine comprehension systems. The data and leaderboard are available at http://hucvl.github.io/recipeqa.", "year": 2018, "ssId": "c581686edbd7227e9eb4a0841cce16728ca27369", "arXivId": "1809.00812", "link": "https://arxiv.org/pdf/1809.00812.pdf", "openAccess": true, "authors": ["Semih Yagcioglu", "Aykut Erdem", "Erkut Erdem", "N. Ikizler-Cinbis"]}}, "609010cb866a19dd996281d00818c3fc7363ec94": {"id": "609010cb866a19dd996281d00818c3fc7363ec94", "content": {"title": "Zero-Resource Cross-Lingual Named Entity Recognition", "abstract": "Recently, neural methods have achieved state-of-the-art (SOTA) results in Named Entity Recognition (NER) tasks for many languages without the need for manually crafted features. However, these models still require manually annotated training data, which is not available for many languages. In this paper, we propose an unsupervised cross-lingual NER model that can transfer NER knowledge from one language to another in a completely unsupervised way without relying on any bilingual dictionary or parallel data. Our model achieves this through word-level adversarial learning and augmented fine-tuning with parameter sharing and feature augmentation. Experiments on five different languages demonstrate the effectiveness of our approach, outperforming existing models by a good margin and setting a new SOTA for each language pair.", "year": 2019, "ssId": "609010cb866a19dd996281d00818c3fc7363ec94", "arXivId": "1911.09812", "link": "https://arxiv.org/pdf/1911.09812.pdf", "openAccess": true, "authors": ["M SAIFUL BARI", "Shafiq R. Joty", "Prathyusha Jwalapuram"]}}, "e79d1206292bc5e67ba19737d87d4b2ea4a37105": {"id": "e79d1206292bc5e67ba19737d87d4b2ea4a37105", "content": {"title": "Charformer: Fast Character Transformers via Gradient-based Subword Tokenization", "abstract": "State-of-the-art models in natural language processing rely on separate rigid subword tokenization algorithms, which limit their generalization ability and adaptation to new settings. In this paper, we propose a new model inductive bias that learns a subword tokenization end-to-end as part of the model. To this end, we introduce a soft gradient-based subword tokenization module (GBST) that automatically learns latent subword representations from characters in a data-driven fashion. Concretely, GBST enumerates candidate subword blocks and learns to score them in a position-wise fashion using a block scoring network. We additionally introduce CHARFORMER, a deep Transformer model that integrates GBST and operates on the byte level. Via extensive experiments on English GLUE, multilingual, and noisy text datasets, we show that CHARFORMER outperforms a series of competitive byte-level baselines while generally performing on par and sometimes outperforming subword-based models. Additionally, CHARFORMER is fast, improving the speed of both vanilla byte-level and subword-level Transformers by 28-100% while maintaining competitive quality. We believe this work paves the way for highly performant token-free models that are trained completely end-to-end.", "year": 2021, "ssId": "e79d1206292bc5e67ba19737d87d4b2ea4a37105", "arXivId": "2106.12672", "link": "https://arxiv.org/pdf/2106.12672.pdf", "openAccess": true, "authors": ["Yi Tay", "V. Tran", "Sebastian Ruder", "Jai Gupta", "Hyung Won Chung", "Dara Bahri", "Zhen Qin", "Simon Baumgartner", "Cong Yu", "Donald Metzler"]}}, "b3848d32f7294ec708627897833c4097eb4d8778": {"id": "b3848d32f7294ec708627897833c4097eb4d8778", "content": {"title": "LaMDA: Language Models for Dialog Applications", "abstract": "We present LaMDA: Language Models for Dialog Applications. LaMDA is a family of Transformerbased neural language models specialized for dialog, which have up to 137B parameters and are pre-trained on 1.56T words of public dialog data and web text. While model scaling alone can improve quality, it shows less improvements on safety and factual grounding. We demonstrate that fine-tuning with annotated data and enabling the model to consult external knowledge sources can lead to significant improvements towards the two key challenges of safety and factual grounding. The first challenge, safety, involves ensuring that the model\u2019s responses are consistent with a set of human values, such as preventing harmful suggestions and unfair bias. We quantify safety using a metric based on an illustrative set of human values, and we find that filtering candidate responses using a LaMDA classifier fine-tuned with a small amount of crowdworker-annotated data offers a promising approach to improving model safety. The second challenge, factual grounding, involves enabling the model to consult external knowledge sources, such as an information retrieval system, a language translator, and a calculator. We quantify factuality using a groundedness metric, and we find that our approach enables the model to generate responses grounded in known sources, rather than responses that merely sound plausible. Finally, we explore the use of LaMDA in the domains of education and content recommendations, and analyze their helpfulness and role consistency. \u2217Work done while at Google. ar X iv :2 20 1. 08 23 9v 3 [ cs .C L ] 1 0 Fe b 20 22 Figure 1: Impact of model pre-training alone vs. with fine-tuning in LaMDA on dialog quality (left), and safety and factual grounding (right). The quality metric (SSI) corresponds to sensibleness, specificity, and interestingness. See Section 4 for more details on these metrics.", "year": 2022, "ssId": "b3848d32f7294ec708627897833c4097eb4d8778", "arXivId": "2201.08239", "link": "https://arxiv.org/pdf/2201.08239.pdf", "openAccess": true, "authors": ["Romal Thoppilan", "Daniel De Freitas", "Jamie Hall", "Noam M. Shazeer", "Apoorv Kulshreshtha", "Heng-Tze Cheng", "Alicia Jin", "Taylor Bos", "Leslie Baker", "Yu Du", "Yaguang Li", "Hongrae Lee", "Huaixiu Zheng", "Amin Ghafouri", "Marcelo Menegali", "Yanping Huang", "M. Krikun", "Dmitry Lepikhin", "James Qin", "Dehao Chen", "Yuanzhong Xu", "Zhifeng Chen", "Adam Roberts", "Maarten Bosma", "Yanqi Zhou", "Chung-Ching Chang", "I. Krivokon", "W. Rusch", "Marc Pickett", "K. Meier-Hellstern", "M. Morris", "Tulsee Doshi", "Renelito Delos Santos", "Toju Duke", "J. S\u00f8raker", "Ben Zevenbergen", "Vinodkumar Prabhakaran", "Mark Diaz", "B. Hutchinson", "Kristen Olson", "Alejandra Molina", "Erin Hoffman-John", "Josh Lee", "Lora Aroyo", "Ravindran Rajakumar", "Alena Butryna", "Matthew Lamm", "V. Kuzmina", "Joseph Fenton", "Aaron Cohen", "R. Bernstein", "R. Kurzweil", "Blaise Aguera-Arcas", "Claire Cui", "Marian Croak", "Ed Chi", "Quoc Le"]}}, "148bca569a0d2833f05df1297788f64bc6686fa8": {"id": "148bca569a0d2833f05df1297788f64bc6686fa8", "content": {"title": "Time Waits for No One! Analysis and Challenges of Temporal Misalignment", "abstract": "When an NLP model is trained on text data from one time period and tested or deployed on data from another, the resulting temporal misalignment can degrade end-task performance. In this work, we establish a suite of eight diverse tasks across different domains (social media, science papers, news, and reviews) and periods of time (spanning five years or more) to quantify the effects of temporal misalignment. Our study is focused on the ubiquitous setting where a pretrained model is optionally adapted through continued domainspecific pretraining, followed by task-specific finetuning. We establish a suite of tasks across multiple domains to study temporal misalignment in modern NLP systems. We find stronger effects of temporal misalignment on task performance than have been previously reported. We also find that, while temporal adaptation through continued pretraining can help, these gains are small compared to task-specific finetuning on data from the target time period. Our findings motivate continued research to improve temporal robustness of NLP models.1", "year": 2021, "ssId": "148bca569a0d2833f05df1297788f64bc6686fa8", "arXivId": "2111.07408", "link": "https://arxiv.org/pdf/2111.07408.pdf", "openAccess": true, "authors": ["Kelvin Luu", "Daniel Khashabi", "Suchin Gururangan", "Karishma Mandyam", "Noah A. Smith"]}}, "4786e10003655be97feee21b9d9894a88a62885f": {"id": "4786e10003655be97feee21b9d9894a88a62885f", "content": {"title": "Multilingual NER Transfer for Low-resource Languages", "abstract": "In massively multilingual transfer NLP models over many source languages are applied to a low-resource target language. In contrast to most prior work, which use a single model or a small handful, we consider many such models, which raises the critical problem of poor transfer, particularly from distant languages. We propose two techniques for modulating the transfer: one based on unsupervised truth inference, and another using limited supervision in the target language. Evaluating on named entity recognition over 41 languages, we show that our techniques are much more effective than strong baselines, including standard ensembling, and our unsupervised method rivals oracle selection of the single best individual model.2", "year": 2019, "ssId": "4786e10003655be97feee21b9d9894a88a62885f", "arXivId": "1902.00193", "link": "https://arxiv.org/pdf/1902.00193.pdf", "openAccess": true, "authors": ["Afshin Rahimi", "Yuan Li", "Trevor Cohn"]}}, "31392ad8722d9c66181b621936e2013199e02edc": {"id": "31392ad8722d9c66181b621936e2013199e02edc", "content": {"title": "When Do You Need Billions of Words of Pretraining Data?", "abstract": "NLP is currently dominated by language models like RoBERTa which are pretrained on billions of words. But what exact knowledge or skills do Transformer LMs learn from large-scale pretraining that they cannot learn from less data? To explore this question, we adopt five styles of evaluation: classifier probing, information-theoretic probing, unsupervised relative acceptability judgments, unsupervised language model knowledge probing, and fine-tuning on NLU tasks. We then draw learning curves that track the growth of these different measures of model ability with respect to pretraining data volume using the MiniBERTas, a group of RoBERTa models pretrained on 1M, 10M, 100M and 1B words. We find that these LMs require only about 10M to 100M words to learn to reliably encode most syntactic and semantic features we test. They need a much larger quantity of data in order to acquire enough commonsense knowledge and other skills required to master typical downstream NLU tasks. The results suggest that, while the ability to encode linguistic features is almost certainly necessary for language understanding, it is likely that other, unidentified, forms of knowledge are the major drivers of recent improvements in language understanding among large pretrained models.", "year": 2020, "ssId": "31392ad8722d9c66181b621936e2013199e02edc", "arXivId": "2011.04946", "link": "https://arxiv.org/pdf/2011.04946.pdf", "openAccess": true, "authors": ["Yian Zhang", "Alex Warstadt", "Haau-Sing Li", "Samuel R. Bowman"]}}, "c263507db2c15a8b2e3c955bda7b3c29a1ebd106": {"id": "c263507db2c15a8b2e3c955bda7b3c29a1ebd106", "content": {"title": "HINT3: Raising the bar for Intent Detection in the Wild", "abstract": "Intent Detection systems in the real world are exposed to complexities of imbalanced datasets containing varying perception of intent, unintended correlations and domain-specific aberrations. To facilitate benchmarking which can reflect near real-world scenarios, we introduce 3 new datasets created from live chatbots in diverse domains. Unlike most existing datasets that are crowdsourced, our datasets contain real user queries received by the chatbots and facilitates penalising unwanted correlations grasped during the training process. We evaluate 4 NLU platforms and a BERT based classifier and find that performance saturates at inadequate levels on test sets because all systems latch on to unintended patterns in training data.", "year": 2020, "ssId": "c263507db2c15a8b2e3c955bda7b3c29a1ebd106", "arXivId": "2009.13833", "link": "https://arxiv.org/pdf/2009.13833.pdf", "openAccess": true, "authors": ["Gaurav Arora", "Chirag Jain", "Manas Chaturvedi", "K. Modi"]}}, "b1d8c868e1d6d4980ee2f8c50e6fc5e4e7027ca2": {"id": "b1d8c868e1d6d4980ee2f8c50e6fc5e4e7027ca2", "content": {"title": "Telling Stories through Multi-User Dialogue by Modeling Character Relations", "abstract": "This paper explores character-driven story continuation, in which the story emerges through characters\u2019 first- and second-person narration as well as dialogue\u2014requiring models to select language that is consistent with a character\u2019s persona and their relationships with other characters while following and advancing the story. We hypothesize that a multi-task model that trains on character dialogue plus character relationship information improves transformer-based story continuation. To this end, we extend the Critical Role Dungeons and Dragons Dataset (Rameshkumar and Bailey, 2020)\u2014consisting of dialogue transcripts of people collaboratively telling a story while playing the role-playing game Dungeons and Dragons\u2014with automatically extracted relationships between each pair of interacting characters as well as their personas. A series of ablations lend evidence to our hypothesis, showing that our multi-task model using character relationships improves story continuation accuracy over strong baselines.", "year": 2021, "ssId": "b1d8c868e1d6d4980ee2f8c50e6fc5e4e7027ca2", "arXivId": "2105.15054", "link": "https://arxiv.org/pdf/2105.15054.pdf", "openAccess": true, "authors": ["Waiman Si", "Prithviraj Ammanabrolu", "Mark O. Riedl"]}}, "a6a7724763d8adba466519489b0b9d209e7f2d15": {"id": "a6a7724763d8adba466519489b0b9d209e7f2d15", "content": {"title": "BARTScore: Evaluating Generated Text as Text Generation", "abstract": "A wide variety of NLP applications, such as machine translation, summarization, and dialog, involve text generation. One major challenge for these applications is how to evaluate whether such generated texts are actually fluent, accurate, or effective. In this work, we conceptualize the evaluation of generated text as a text generation problem, modeled using pre-trained sequence-to-sequence models. The general idea is that models trained to convert the generated text to/from a reference output or the source text will achieve higher scores when the generated text is better. We operationalize this idea using BART [27], an encoder-decoder based pre-trained model, and propose a metric BARTSCORE with a number of variants that can be flexibly applied in an unsupervised fashion to evaluation of text from different perspectives (e.g. informativeness, fluency, or factuality). BARTSCORE is conceptually simple and empirically effective. It can outperform existing top-scoring metrics in 16 of 22 test settings, covering evaluation of 16 datasets (e.g., machine translation, text summarization) and 7 different perspectives (e.g., informativeness, factuality). Code to calculate BARTScore is available at https://github.com/neulab/BARTScore, and we have released an interactive leaderboard for meta-evaluation at http: //explainaboard.nlpedia.ai/leaderboard/task-meval/ on the EXPLAINABOARD platform [32], which allows us to interactively understand the strengths, weaknesses, and complementarity of each metric.", "year": 2021, "ssId": "a6a7724763d8adba466519489b0b9d209e7f2d15", "arXivId": "2106.11520", "link": "https://arxiv.org/pdf/2106.11520.pdf", "openAccess": true, "authors": ["Weizhe Yuan", "Graham Neubig", "Pengfei Liu"]}}, "f132f6534ec326a1ba61870b701015cd3d1560a2": {"id": "f132f6534ec326a1ba61870b701015cd3d1560a2", "content": {"title": "On the Complementarity of Data Selection and Fine Tuning for Domain Adaptation", "abstract": "Domain adaptation of neural networks commonly relies on three training phases: pretraining, selected data training and then fine tuning. Data selection improves target domain generalization by training further on pretraining data identified by relying on a small sample of target domain data. This work examines the benefit of data selection for language modeling and machine translation. Our experiments assess the complementarity of selection with fine tuning and result in practical recommendations: (i) selected data must be similar to the fine-tuning domain but not so much as to erode the complementary effect of fine-tuning; (ii) there is a trade-off between selecting little data for fast but limited progress or much data for slow but long lasting progress; (iii) data selection can be applied early during pretraining, with performance gains comparable to long pretraining session; (iv) data selection from domain classifiers is often more effective than the popular contrastive data selection method.", "year": 2021, "ssId": "f132f6534ec326a1ba61870b701015cd3d1560a2", "arXivId": "2109.07591", "link": "https://arxiv.org/pdf/2109.07591.pdf", "openAccess": true, "authors": ["Dan Iter", "David Grangier"]}}, "a309ad4c4088843d230be1a85806960e633e1e46": {"id": "a309ad4c4088843d230be1a85806960e633e1e46", "content": {"title": "Changing the World by Changing the Data", "abstract": "NLP community is currently investing a lot more research and resources into development of deep learning models than training data. While we have made a lot of progress, it is now clear that our models learn all kinds of spurious patterns, social biases, and annotation artifacts. Algorithmic solutions have so far had limited success. An alternative that is being actively discussed is more careful design of datasets so as to deliver specific signals. This position paper maps out the arguments for and against data curation, and argues that fundamentally the point is moot: curation already is and will be happening, and it is changing the world. The question is only how much thought we want to invest into that process.", "year": 2021, "ssId": "a309ad4c4088843d230be1a85806960e633e1e46", "arXivId": "2105.13947", "link": "https://arxiv.org/pdf/2105.13947.pdf", "openAccess": true, "authors": ["Anna Rogers"]}}, "15bb07d0996ece844de8cae24d3dc15972e6841a": {"id": "15bb07d0996ece844de8cae24d3dc15972e6841a", "content": {"title": "How well do you know your summarization datasets?", "abstract": "State-of-the-art summarization systems are trained and evaluated on massive datasets scraped from the web. Despite their prevalence, we know very little about the underlying characteristics (data noise, summarization complexity, etc.) of these datasets, and how these affect system performance and the reliability of automatic metrics like ROUGE. In this study, we manually analyse 600 samples from three popular summarization datasets. Our study is driven by a six-class typology which captures different noise types (missing facts, entities) and degrees of summarization difficulty (extractive, abstractive). We follow with a thorough analysis of 27 state-of-the-art summarization models and 5 popular metrics, and report our key insights: (1) Datasets have distinct data quality and complexity distributions, which can be traced back to their collection process. (2) The performance of models and reliability of metrics is dependent on sample complexity. (3) Faithful summaries often receive low scores because of the poor diversity of references. We release the code, annotated data and model outputs.1", "year": 2021, "ssId": "15bb07d0996ece844de8cae24d3dc15972e6841a", "arXivId": "2106.11388", "link": "https://arxiv.org/pdf/2106.11388.pdf", "openAccess": true, "authors": ["Priyam Tejaswin", "Dhruv Naik", "Peng Liu"]}}, "15251fa3a3bcf695bf153d0856886cab9a3145ea": {"id": "15251fa3a3bcf695bf153d0856886cab9a3145ea", "content": {"title": "RefSum: Refactoring Neural Summarization", "abstract": "Although some recent works show potential complementarity among different state-of-the-art systems, few works try to investigate this problem in text summarization. Researchers in other areas commonly refer to the techniques of reranking or stacking to approach this problem. In this work, we highlight several limitations of previous methods, which motivates us to present a new framework Refactor that provides a unified view of text summarization and summaries combination. Experimentally, we perform a comprehensive evaluation that involves twenty-two base systems, four datasets, and three different application scenarios. Besides new state-of-the-art results on CNN/DailyMail dataset (46.18 ROUGE-1), we also elaborate on how our proposed method addresses the limitations of the traditional methods and the effectiveness of the Refactor model sheds light on insight for performance improvement. Our system can be directly used by other researchers as an off-the-shelf tool to achieve further performance improvements. We open-source all the code and provide a convenient interface to use it: https://github.com/yixinL7/Refactoring-Summarization.", "year": 2021, "ssId": "15251fa3a3bcf695bf153d0856886cab9a3145ea", "arXivId": "2104.07210", "link": "https://arxiv.org/pdf/2104.07210.pdf", "openAccess": true, "authors": ["Yixin Liu", "Zi-Yi Dou", "Pengfei Liu"]}}, "23f1d4b46bc7c8f357a5a89144d5d32af7be13a5": {"id": "23f1d4b46bc7c8f357a5a89144d5d32af7be13a5", "content": {"title": "Training Dynamics for Text Summarization Models", "abstract": "Pre-trained language models (e.g. BART) have shown impressive results when fine-tuned on large summarization datasets. However, little is understood about this fine-tuning process, including what knowledge is retained from pre-training models or how content selection and generation strategies are learnt across iterations. In this work, we analyze the training dynamics for generation models, focusing on news summarization. Across different datasets (CNNDM, XSUM, MEDIASUM) and summary properties, such as abstractiveness and hallucination, we study what the model learns at different stages of its fine-tuning process. We find that properties such as copy behavior are learnt earlier in the training process and these observations are robust across domains. On the other hand, factual errors, such as hallucination of unsupported facts, are learnt in the later stages, and this behavior is more varied across domains. Based on these observations, we explore complementary approaches for modifying training: first, disregarding high-loss tokens that are challenging to learn and second, disregarding low-loss tokens that are learnt very quickly. This simple training modification allows us to configure our model to achieve different goals, such as improving factuality or improving abstractiveness.", "year": 2021, "ssId": "23f1d4b46bc7c8f357a5a89144d5d32af7be13a5", "arXivId": "2110.08370", "link": "https://arxiv.org/pdf/2110.08370.pdf", "openAccess": true, "authors": ["Tanya Goyal", "Jiacheng Xu", "J. Li", "Greg Durrett"]}}, "4ef77ef9b8ca8c8a96f1e62fa86a988feb582bd1": {"id": "4ef77ef9b8ca8c8a96f1e62fa86a988feb582bd1", "content": {"title": "The Trade-offs of Domain Adaptation for Neural Language Models", "abstract": "This work connects language model adaptation with concepts of machine learning theory. We consider a training setup with a large outof-domain set and a small in-domain set. We derive how the benefit of training a model on either set depends on the size of the sets and the distance between their underlying distributions. We analyze how out-of-domain pretraining before in-domain fine-tuning achieves better generalization than either solution independently. Finally, we present how adaptation techniques based on data selection, such as importance sampling, intelligent data selection and influence functions, can be presented in a common framework which highlights their similarity and also their subtle differences.", "year": 2021, "ssId": "4ef77ef9b8ca8c8a96f1e62fa86a988feb582bd1", "arXivId": "2109.10274", "link": "https://arxiv.org/pdf/2109.10274.pdf", "openAccess": true, "authors": ["Dan Iter", "David Grangier"]}}, "b31eb3428320342dfde042693ff2ca106dabed0d": {"id": "b31eb3428320342dfde042693ff2ca106dabed0d", "content": {"title": "SimCLS: A Simple Framework for Contrastive Learning of Abstractive Summarization", "abstract": "In this paper, we present a conceptually simple while empirically powerful framework for abstractive summarization, SimCLS, which can bridge the gap between the learning objective and evaluation metrics resulting from the currently dominated sequence-to-sequence learning framework by formulating text generation as a reference-free evaluation problem (i.e., quality estimation) assisted by contrastive learning. Experimental results show that, with minor modification over existing top-scoring systems, SimCLS can improve the performance of existing top-performing models by a large margin. Particularly, 2.51 absolute improvement against BART and 2.50 over PEGASUS w.r.t ROUGE-1 on the CNN/DailyMail dataset, driving the state-of-the-art performance to a new level. We have open-sourced our codes and results: https://github.com/yixinL7/SimCLS. Results of our proposed models have been deployed into ExplainaBoard platform, which allows researchers to understand our systems in a more fine-grained way.", "year": 2021, "ssId": "b31eb3428320342dfde042693ff2ca106dabed0d", "arXivId": "2106.01890", "link": "https://arxiv.org/pdf/2106.01890.pdf", "openAccess": true, "authors": ["Yixin Liu", "Peng Liu"]}}, "30cf652bd33049aaf111a5f84eb262a87c045bdb": {"id": "30cf652bd33049aaf111a5f84eb262a87c045bdb", "content": {"title": "Assisting the Human Fact-Checkers: Detecting All Previously Fact-Checked Claims in a Document", "abstract": "Given the recent proliferation of false claims online, there has been a lot of manual fact-checking effort. As this is very timeconsuming, human fact-checkers can benefit from tools that can support them and make them more efficient. Here, we focus on building a system that could provide such support. Given an input document, it aims to detect all sentences that contain a claim that can be verified by some previously factchecked claims (from a given database). The output is a reranked list of the document sentences, so that those that can be verified are ranked as high as possible, together with corresponding evidence. Unlike previous work, which has looked into claim retrieval, here we take a document-level perspective. We create a new manually annotated dataset for the task, and we propose suitable evaluation measures. We further experiment with a learning-to-rank approach, achieving sizable performance gains over several strong baselines. Our analysis demonstrates the importance of modeling text similarity and stance, while also taking into account the veracity of the retrieved previously fact-checked claims. We believe that this research would be of interest to fact-checkers, journalists, media, and regulatory authorities.", "year": 2021, "ssId": "30cf652bd33049aaf111a5f84eb262a87c045bdb", "arXivId": "2109.07410", "link": "https://arxiv.org/pdf/2109.07410.pdf", "openAccess": true, "authors": ["S. Shaar", "Firoj Alam", "Giovanni Da San Martino", "Preslav Nakov"]}}, "a3452276ada37727d0008dad8ca7c27bbbee6984": {"id": "a3452276ada37727d0008dad8ca7c27bbbee6984", "content": {"title": "Rumor Detection on Twitter with Claim-Guided Hierarchical Graph Attention Networks", "abstract": "Rumors are rampant in the era of social media. Conversation structures provide valuable clues to differentiate between real and fake claims. However, existing rumor detection methods are either limited to the strict relation of user responses or oversimplify the conversation structure. In this study, to substantially reinforces the interaction of user opinions while alleviating the negative impact imposed by irrelevant posts, we first represent the conversation thread as an undirected interaction graph. We then present a Claim-guided Hierarchical Graph Attention Network for rumor classification, which enhances the representation learning for responsive posts considering the entire social contexts and attends over the posts that can semantically infer the target claim. Extensive experiments on three Twitter datasets demonstrate that our rumor detection method achieves much better performance than state-of-the-art methods and exhibits a superior capacity for detecting rumors at early stages.", "year": 2021, "ssId": "a3452276ada37727d0008dad8ca7c27bbbee6984", "arXivId": "2110.04522", "link": "https://arxiv.org/pdf/2110.04522.pdf", "openAccess": true, "authors": ["Hongzhan Lin", "Jing Ma", "Mingfei Cheng", "Zhiwei Yang", "Liangliang Chen", "Guang Chen"]}}, "fd1b59d22eb1fb32e0360d4fcbe58dc4ebb25af9": {"id": "fd1b59d22eb1fb32e0360d4fcbe58dc4ebb25af9", "content": {"title": "How Deep Are the Fakes? Focusing on Audio Deepfake: A Survey", "abstract": "Deepfake is content or material that is synthetically generated or manipulated using artificial intelligence (AI) methods, to be passed off as real and can include audio, video, image, and text synthesis. This survey has been conducted with a different perspective compared to existing survey papers, that mostly focus on just video and image deepfakes. This survey not only evaluates generation and detection methods in the different deepfake categories, but mainly focuses on audio deepfakes that are overlooked in most of the existing surveys. This paper\u2019s most important contribution is to critically analyze and provide a unique source of audio deepfake research, mostly ranging from 2016 to 2020. To the best of our knowledge, this is the first survey focusing on audio deepfakes in English. This survey provides readers with a summary of 1) different deepfake categories 2) how they could be created and detected 3) the most recent trends in this domain and shortcomings in detection methods 4) audio deepfakes, how they are created and detected in more detail which is the main focus of this paper. We found that Generative Adversarial Networks(GAN), Convolutional Neural Networks (CNN), and Deep Neural Networks (DNN) are common ways of creating and detecting deepfakes. In our evaluation of over 140 methods we found that the majority of the focus is on video deepfakes and in particular in the generation of video deepfakes. We found that for text deepfakes there are more generation methods but very few robust methods for detection, including fake news detection, which has become a controversial area of research because of the potential of heavy overlaps with human generation of fake content. This paper is an abbreviated version of the full survey and reveals a clear need to research audio deepfakes and particularly detection of audio deepfakes.", "year": 2021, "ssId": "fd1b59d22eb1fb32e0360d4fcbe58dc4ebb25af9", "arXivId": "2111.14203", "link": "https://arxiv.org/pdf/2111.14203.pdf", "openAccess": true, "authors": ["Zahra Khanjani", "Gabrielle Watson", "V. Janeja"]}}, "04db62a14f78f693d6bd14a4803b9b73325b36bb": {"id": "04db62a14f78f693d6bd14a4803b9b73325b36bb", "content": {"title": "Knowledge Enhanced Multi-modal Fake News Detection", "abstract": "Recent years have witnessed the significant damage caused by various types of fake news. Although considerable effort has been applied to address this issue and much progress has been made on detecting fake news, most existing approaches mainly rely on the textual content and/or social context, while knowledge-level information\u2014entities extracted from the news content and the relations between them\u2014is much less explored. Within the limited work on knowledge-based fake news detection, an external knowledge graph is often required, which may introduce additional problems: it is quite common for entities and relations, especially with respect to new concepts, to be missing in existing knowledge graphs, and both entity prediction and link prediction are open research questions themselves. Therefore, in this work, we investigate knowledge-based fake news detection that does not require any external knowledge graph. Specifically, our contributions include: (1) transforming the problem of detecting fake news into a subgraph classification task\u2014entities and relations are extracted from each news item to form a single knowledge graph, where a news item is represented by a subgraph. Then a graph neural network (GNN) model is trained to classify each subgraph/news item. (2) Further improving the performance of this model through a simple but effective multi-modal technique that combines extracted knowledge, textual content and social context. Experiments on multiple datasets with thousands of labelled news items demonstrate that our knowledge-based algorithm outperforms existing counterpart methods, and its performance can be further boosted by the multi-modal approach.", "year": 2021, "ssId": "04db62a14f78f693d6bd14a4803b9b73325b36bb", "arXivId": "2108.04418", "link": "https://arxiv.org/pdf/2108.04418.pdf", "openAccess": true, "authors": ["Yi Han", "Amila Silva", "Ling Luo", "S. Karunasekera", "C. Leckie"]}}, "95e8edd26744ecc2bc23996cfaa68fe6252442a9": {"id": "95e8edd26744ecc2bc23996cfaa68fe6252442a9", "content": {"title": "Evidence-aware Fake News Detection with Graph Neural Networks", "abstract": "The prevalence and perniciousness of fake news has been a critical issue on the Internet, which stimulates the development of automatic fake news detection in turn. In this paper, we focus on the evidence-based fake news detection, where several evidences are utilized to probe the veracity of news (i.e., a claim). Most previous methods first employ sequential models to embed the semantic information and then capture the claim-evidence interaction based on different attention mechanisms. Despite their effectiveness, they still suffer from two main weaknesses. Firstly, due to the inherent drawbacks of sequential models, they fail to integrate the relevant information that is scattered far apart in evidences for veracity checking. Secondly, they neglect much redundant information contained in evidences that may be useless or even harmful. To solve these problems, we propose a unified Graph-based sEmantic sTructure mining framework, namely GET in short. Specifically, different from the existing work that treats claims and evidences as sequences, we model them as graph-structured data and capture the long-distance semantic dependency among dispersed relevant snippets via neighborhood propagation. After obtaining contextual semantic information, our model reduces information redundancy by performing graph structure learning. Finally, the fine-grained semantic representations are fed into the downstream claim-evidence interaction module for predictions. Comprehensive experiments have demonstrated the superiority of GET over the state-of-the-arts.", "year": 2022, "ssId": "95e8edd26744ecc2bc23996cfaa68fe6252442a9", "arXivId": "2201.06885", "link": "https://arxiv.org/pdf/2201.06885.pdf", "openAccess": true, "authors": ["Weizhi Xu", "Jun Wu", "Qiang Liu", "Shu Wu", "Liang Wang"]}}, "11e4346e60ac76ad018231a851fbbdb2112044d2": {"id": "11e4346e60ac76ad018231a851fbbdb2112044d2", "content": {"title": "LOREN: Logic-Regularized Reasoning for Interpretable Fact Verification", "abstract": "Given a natural language statement, how to verify its veracity against a large-scale textual knowledge source like Wikipedia? Most existing neural models make predictions without giving clues about which part of a false claim goes wrong. In this paper, we propose LOREN, an approach for interpretable fact verification. We decompose the verification of the whole claim at phrase-level, where the veracity of the phrases serves as explanations and can be aggregated into the final verdict according to logical rules. The key insight of LOREN is to represent claim phrase veracity as three-valued latent variables, which are regularized by aggregation logical rules. The final claim verification is based on all latent variables. Thus, LOREN enjoys the additional benefit of interpretability \u2014 it is easy to explain how it reaches certain results with claim phrase veracity. Experiments on a public fact verification benchmark show that LOREN is competitive against previous approaches while enjoying the merit of faithful and accurate interpretability. The resources of LOREN are available at: https://github.com/jiangjiechen/LOREN.", "year": 2020, "ssId": "11e4346e60ac76ad018231a851fbbdb2112044d2", "arXivId": "2012.13577", "link": "https://arxiv.org/pdf/2012.13577.pdf", "openAccess": true, "authors": ["Jiangjie Chen", "Qiaoben Bao", "Changzhi Sun", "Xinbo Zhang", "Jiaze Chen", "Hao Zhou", "Yanghua Xiao", "Lei Li"]}}, "ed1c17451a23471afde91c109ecadc6aab8b2ba6": {"id": "ed1c17451a23471afde91c109ecadc6aab8b2ba6", "content": {"title": "A Survey on Multimodal Disinformation Detection", "abstract": "Recent years have witnessed the proliferation of fake news, propaganda, misinformation, and disinformation online. While initially this was mostly about textual content, over time images and videos gained popularity, as they are much easier to consume, attract much more attention, and spread further than simple text. As a result, researchers started targeting different modalities and combinations thereof. As different modalities are studied in different research communities, with insufficient interaction, here we offer a survey that explores the state-of-the-art on multimodal disinformation detection covering various combinations of modalities: text, images, audio, video, network structure, and temporal information. Moreover, while some studies focused on factuality, others investigated how harmful the content is. While these two components in the definition of disinformation \u2013 (i) factuality and (ii) harmfulness, are equally important, they are typically studied in isolation. Thus, we argue for the need to tackle disinformation detection by taking into account multiple modalities as well as both factuality and harmfulness, in the same framework. Finally, we discuss current challenges and future research directions.", "year": 2021, "ssId": "ed1c17451a23471afde91c109ecadc6aab8b2ba6", "arXivId": "2103.12541", "link": "https://arxiv.org/pdf/2103.12541.pdf", "openAccess": true, "authors": ["Firoj Alam", "S. Cresci", "Tanmoy Chakraborty", "F. Silvestri", "D. Dimitrov", "Giovanni Da San Martino", "Shaden Shaar", "Hamed Firooz", "Preslav Nakov"]}}, "2eea63f896deed47cc0c0000e1482ec5c860fd0b": {"id": "2eea63f896deed47cc0c0000e1482ec5c860fd0b", "content": {"title": "MSSF-GCN: Multi-scale Structural and Semantic Information Fusion Graph Convolutional Network for Controversy Detection", "abstract": "Detecting controversial posts on the web and social media play an important role in judging the authenticity of web information, measuring the influence of news and alleviating the polarized views. The controversy detection task has attracted widespread attention from researchers in the fields of computer science and social humanities sciences. However, previous works do not achieve: 1) preserve the reply-structure relationship with sentiment information; 2) integrate multi-scale structure and semantic information and provide interpretable results; 3) learn effectively topics and comments information related to the target post. To overcome the first limitation, we construct a Topic-Post-Comment-Sentiment Graph (TPCS Graph) for preserving the reply-structure and incorporate the sentiment information. For the second and third limitation, we propose Multi-scale Structural and Semantic Information Fusion Graph Convolutional Network (MSSF-GCN) for post-level controversy detection. Moreover, we build a multilingual dataset for controversy detection. We conduct comprehensive experiments on two real-world datasets and the results show that the proposed method exhibits comparable or even superior performance.", "year": 2021, "ssId": "2eea63f896deed47cc0c0000e1482ec5c860fd0b", "arXivId": null, "link": null, "openAccess": false, "authors": ["Haiyang Wang", "Xin Song", "Bin Zhou", "Yechen Wang", "Liqun Gao", "Yan Jia"]}}, "39ab4b9cdeb4a71b3e25fe5339962654c7c9ff8c": {"id": "39ab4b9cdeb4a71b3e25fe5339962654c7c9ff8c", "content": {"title": "SCARLET: Explainable Attention based Graph Neural Network for Fake News spreader prediction", "abstract": "False information and true information fact checking it, often co-exist in social networks, each competing to influence people in their spread paths. An efficient strategy here to contain false information is to proactively identify if nodes in the spread path are likely to endorse false information (i.e. further spread it) or refutation information (thereby help contain false information spreading). In this paper, we propose SCARLET (truSt and Credibility bAsed gRaph neuraL nEtwork model using aTtention) to predict likely action of nodes in the spread path. We aggregate trust and credibility features from a node\u2019s neighborhood using historical behavioral data and network structure and explain how features of a spreader\u2019s neighborhood vary. Using real world Twitter datasets, we show that the model is able to predict false information spreaders with an accuracy of over 87%.", "year": 2021, "ssId": "39ab4b9cdeb4a71b3e25fe5339962654c7c9ff8c", "arXivId": "2102.04627", "link": "https://arxiv.org/pdf/2102.04627.pdf", "openAccess": true, "authors": ["Bhavtosh Rath", "Xavier Morales", "J. Srivastava"]}}, "5c6ff5836639e87e8afeaad47e64d0e2234566e8": {"id": "5c6ff5836639e87e8afeaad47e64d0e2234566e8", "content": {"title": "Hierarchical Multi-head Attentive Network for Evidence-aware Fake News Detection", "abstract": "The widespread of fake news and misinformation in various domains ranging from politics, economics to public health has posed an urgent need to automatically fact-check information. A recent trend in fake news detection is to utilize evidence from external sources. However, existing evidence-aware fake news detection methods focused on either only word-level attention or evidence-level attention, which may result in suboptimal performance. In this paper, we propose a Hierarchical Multi-head Attentive Network to fact-check textual claims. Our model jointly combines multi-head word-level attention and multi-head document-level attention, which aid explanation in both word-level and evidence-level. Experiments on two real-word datasets show that our model outperforms seven state-of-the-art baselines. Improvements over baselines are from 6% to 18%. Our source code and datasets are released at https://github.com/nguyenvo09/EACL2021.", "year": 2021, "ssId": "5c6ff5836639e87e8afeaad47e64d0e2234566e8", "arXivId": "2102.02680", "link": "https://arxiv.org/pdf/2102.02680.pdf", "openAccess": true, "authors": ["Nguyen Vo", "Kyumin Lee"]}}, "213e471bacff5c0852943988fcb955797f1e591f": {"id": "213e471bacff5c0852943988fcb955797f1e591f", "content": {"title": "BLEU Might Be Guilty but References Are Not Innocent", "abstract": "The quality of automatic metrics for machine translation has been increasingly called into question, especially for high-quality systems. This paper demonstrates that, while choice of metric is important, the nature of the references is also critical. We study different methods to collect references and compare their value in automated evaluation by reporting correlation with human evaluation for a variety of systems and metrics. Motivated by the finding that typical references exhibit poor diversity, concentrating around translationese language, we develop a paraphrasing task for linguists to perform on existing reference translations, which counteracts this bias. Our method yields higher correlation with human judgment not only for the submissions of WMT 2019 English to German, but also for Back-translation and APE augmented MT output, which have been shown to have low correlation with automatic metrics using standard references. We demonstrate that our methodology improves correlation with all modern evaluation metrics we look at, including embedding-based methods. To complete this picture, we reveal that multi-reference BLEU does not improve the correlation for high quality output, and present an alternative multi-reference formulation that is more effective.", "year": 2020, "ssId": "213e471bacff5c0852943988fcb955797f1e591f", "arXivId": "2004.06063", "link": "https://arxiv.org/pdf/2004.06063.pdf", "openAccess": true, "authors": ["Markus Freitag", "David Grangier", "Isaac Caswell"]}}, "79b8ef3905a42b771248719495a2117271906445": {"id": "79b8ef3905a42b771248719495a2117271906445", "content": {"title": "Carbon Emissions and Large Neural Network Training", "abstract": "David Patterson 1 , 2 , Joseph Gonzalez 2 , Quoc Le 1 , Chen Liang 1 , Lluis-Miquel Munguia 1 , Daniel Rothchild 2 , David So 1 , Maud Texier 1 , and Jeff Dean 1  {davidpatterson, qvl, crazydonkey, llmunguia, davidso, maudt, jeff}@google.com, {pattrsn, jegonzal, drothchild}@berkeley.edu  Abstract: The computation demand for machine learning (ML) has grown rapidly recently, which comes with a number of costs. Estimating the energy cost helps measure its environmental impact and finding greener strategies, yet it is challenging without detailed information . We calculate the energy use and carbon footprint of several recent large models\u2014 T5 , Meena , GShard , Switch Transformer , and GPT-3 \u2014and refine earlier estimates for the neural architecture search that found Evolved Transformer . We highlight the following opportunities to improve energy efficiency and CO 2  equivalent emissions ( CO 2 e ): \u25cf Large but sparsely activated DNNs can consume <1/10th the energy of large, dense DNNs without sacrificing accuracy despite using as many or even more parameters. \u25cf Geographic location matters for ML workload scheduling since the fraction of carbon-free energy and resulting CO 2 e vary ~5X-10X, even within the same country and the same organization. We are now optimizing where and when large models are trained. \u25cf Specific datacenter infrastructure matters, as Cloud datacenters can be ~1.4-2X more energy efficient than typical datacenters, and the ML-oriented accelerators inside them can be ~2-5X more effective than off-the-shelf systems. Remarkably, the choice of DNN, datacenter, and processor can reduce the carbon footprint up to ~100-1000X. These large factors also make retroactive estimates of energy cost difficult. To avoid miscalculations, we believe ML papers requiring large computational resources should make energy consumption and CO 2 e explicit when practical. We are working to be more transparent about energy use and CO 2 e in our future research. To help reduce the carbon footprint of ML, we believe energy usage and CO 2 e should be a key metric in evaluating models, and we are collaborating with MLPerf developers to include energy usage during training and inference in this industry standard benchmark.", "year": 2021, "ssId": "79b8ef3905a42b771248719495a2117271906445", "arXivId": "2104.10350", "link": "https://arxiv.org/pdf/2104.10350.pdf", "openAccess": true, "authors": ["David A. Patterson", "Joseph Gonzalez", "Quoc V. Le", "Chen Liang", "Llu\u00eds-Miquel Mungu\u00eda", "D. Rothchild", "David R. So", "Maud Texier", "J. Dean"]}}, "74276a37bfa50f90dfae37f767b2b67784bd402a": {"id": "74276a37bfa50f90dfae37f767b2b67784bd402a", "content": {"title": "mT5: A Massively Multilingual Pre-trained Text-to-Text Transformer", "abstract": "The recent \u201cText-to-Text Transfer Transformer\u201d (T5) leveraged a unified text-to-text format and scale to attain state-of-the-art results on a wide variety of English-language NLP tasks. In this paper, we introduce mT5, a multilingual variant of T5 that was pre-trained on a new Common Crawl-based dataset covering 101 languages. We detail the design and modified training of mT5 and demonstrate its state-of-the-art performance on many multilingual benchmarks. We also describe a simple technique to prevent \u201caccidental translation\u201d in the zero-shot setting, where a generative model chooses to (partially) translate its prediction into the wrong language. All of the code and model checkpoints used in this work are publicly available.", "year": 2020, "ssId": "74276a37bfa50f90dfae37f767b2b67784bd402a", "arXivId": "2010.11934", "link": "https://arxiv.org/pdf/2010.11934.pdf", "openAccess": true, "authors": ["Linting Xue", "Noah Constant", "Adam Roberts", "Mihir Kale", "Rami Al-Rfou", "Aditya Siddhant", "Aditya Barua", "Colin Raffel"]}}, "32feca141fce06c6588b4014d27953a3fc25f19b": {"id": "32feca141fce06c6588b4014d27953a3fc25f19b", "content": {"title": "PIGLeT: Language Grounding Through Neuro-Symbolic Interaction in a 3D World", "abstract": "We propose PIGLeT: a model that learns physical commonsense knowledge through interaction, and then uses this knowledge to ground language. We factorize PIGLeT into a physical dynamics model, and a separate language model. Our dynamics model learns not just what objects are but also what they do: glass cups break when thrown, plastic ones don\u2019t. We then use it as the interface to our language model, giving us a unified model of linguistic form and grounded meaning. PIGLeT can read a sentence, simulate neurally what might happen next, and then communicate that result through a literal symbolic representation, or natural language. Experimental results show that our model effectively learns world dynamics, along with how to communicate them. It is able to correctly forecast what happens next given an English sentence over 80% of the time, outperforming a 100x larger, text-to-text approach by over 10%. Likewise, its natural language summaries of physical interactions are also judged by humans as more accurate than LM alternatives. We present comprehensive analysis showing room for future work.", "year": 2021, "ssId": "32feca141fce06c6588b4014d27953a3fc25f19b", "arXivId": "2106.00188", "link": "https://arxiv.org/pdf/2106.00188.pdf", "openAccess": true, "authors": ["Rowan Zellers", "Ari Holtzman", "Matthew E. Peters", "R. Mottaghi", "Aniruddha Kembhavi", "Ali Farhadi", "Yejin Choi"]}}, "7570afa31c68e24fce1342b7d67c591787219bc1": {"id": "7570afa31c68e24fce1342b7d67c591787219bc1", "content": {"title": "Generating Wikipedia by Summarizing Long Sequences", "abstract": "We show that generating English Wikipedia articles can be approached as a multi- document summarization of source documents. We use extractive summarization to coarsely identify salient information and a neural abstractive model to generate the article. For the abstractive model, we introduce a decoder-only architecture that can scalably attend to very long sequences, much longer than typical encoder- decoder architectures used in sequence transduction. We show that this model can generate fluent, coherent multi-sentence paragraphs and even whole Wikipedia articles. When given reference documents, we show it can extract relevant factual information as reflected in perplexity, ROUGE scores and human evaluations.", "year": 2018, "ssId": "7570afa31c68e24fce1342b7d67c591787219bc1", "arXivId": "1801.10198", "link": "https://arxiv.org/pdf/1801.10198.pdf", "openAccess": true, "authors": ["Peter J. Liu", "Mohammad Saleh", "Etienne Pot", "Ben Goodrich", "Ryan Sepassi", "Lukasz Kaiser", "Noam M. Shazeer"]}}, "26299d5fdc5137291dc6a091573b3d18aba1d1c2": {"id": "26299d5fdc5137291dc6a091573b3d18aba1d1c2", "content": {"title": "MAD-X: An Adapter-based Framework for Multi-task Cross-lingual Transfer", "abstract": "The main goal behind state-of-the-art pretrained multilingual models such as multilingual BERT and XLM-R is enabling and bootstrapping NLP applications in low-resource languages through zero-shot or few-shot cross-lingual transfer. However, due to limited model capacity, their transfer performance is the weakest exactly on such low-resource languages and languages unseen during pretraining. We propose MAD-X, an adapter-based framework that enables high portability and parameter-efficient transfer to arbitrary tasks and languages by learning modular language and task representations. In addition, we introduce a novel invertible adapter architecture and a strong baseline method for adapting a pretrained multilingual model to a new language. MAD-X outperforms the state of the art in cross-lingual transfer across a representative set of typologically diverse languages on named entity recognition and achieves competitive results on question answering.", "year": 2020, "ssId": "26299d5fdc5137291dc6a091573b3d18aba1d1c2", "arXivId": "2005.00052", "link": "https://arxiv.org/pdf/2005.00052.pdf", "openAccess": true, "authors": ["Jonas Pfeiffer", "Ivan Vulic", "Iryna Gurevych", "Sebastian Ruder"]}}, "e02f79b710cdcaa9135b835fad964f6f2c78b1a7": {"id": "e02f79b710cdcaa9135b835fad964f6f2c78b1a7", "content": {"title": "Canine: Pre-training an Efficient Tokenization-Free Encoder for Language Representation", "abstract": "Abstract Pipelined NLP systems have largely been superseded by end-to-end neural modeling, yet nearly all commonly used models still require an explicit tokenization step. While recent tokenization approaches based on data-derived subword lexicons are less brittle than manually engineered tokenizers, these techniques are not equally suited to all languages, and the use of any fixed vocabulary may limit a model\u2019s ability to adapt. In this paper, we present Canine, a neural encoder that operates directly on character sequences\u2014without explicit tokenization or vocabulary\u2014and a pre-training strategy that operates either directly on characters or optionally uses subwords as a soft inductive bias. To use its finer-grained input effectively and efficiently, Canine combines downsampling, which reduces the input sequence length, with a deep transformer stack, which encodes context. Canine outperforms a comparable mBert model by 5.7 F1 on TyDi QA, a challenging multilingual benchmark, despite having fewer model parameters.", "year": 2021, "ssId": "e02f79b710cdcaa9135b835fad964f6f2c78b1a7", "arXivId": "2103.06874", "link": "https://arxiv.org/pdf/2103.06874.pdf", "openAccess": true, "authors": ["J. Clark", "Dan Garrette", "Iulia Turc", "J. Wieting"]}}, "8a99e1eb3285f127eed7169441679d47be7f1633": {"id": "8a99e1eb3285f127eed7169441679d47be7f1633", "content": {"title": "Data-to-text Generation by Splicing Together Nearest Neighbors", "abstract": "We propose to tackle data-to-text generation tasks by directly splicing together retrieved segments of text from \u201cneighbor\u201d source-target pairs. Unlike recent work that conditions on retrieved neighbors but generates text token-by-token, left-to-right, we learn a policy that directly manipulates segments of neighbor text, by inserting or replacing them in partially constructed generations. Standard techniques for training such a policy require an oracle derivation for each generation, and we prove that finding the shortest such derivation can be reduced to parsing under a particular weighted context-free grammar. We find that policies learned in this way perform on par with strong baselines in terms of automatic and human evaluation, but allow for more interpretable and controllable generation.", "year": 2021, "ssId": "8a99e1eb3285f127eed7169441679d47be7f1633", "arXivId": "2101.08248", "link": "https://arxiv.org/pdf/2101.08248.pdf", "openAccess": true, "authors": ["Sam Wiseman", "A. Backurs", "K. Stratos"]}}, "3c78c6df5eb1695b6a399e346dde880af27d1016": {"id": "3c78c6df5eb1695b6a399e346dde880af27d1016", "content": {"title": "Simple and Effective Multi-Paragraph Reading Comprehension", "abstract": "We consider the problem of adapting neural paragraph-level question answering models to the case where entire documents are given as input. Our proposed solution trains models to produce well calibrated confidence scores for their results on individual paragraphs. We sample multiple paragraphs from the documents during training, and use a shared-normalization training objective that encourages the model to produce globally correct output. We combine this method with a state-of-the-art pipeline for training models on document QA data. Experiments demonstrate strong performance on several document QA datasets. Overall, we are able to achieve a score of 71.3 F1 on the web portion of TriviaQA, a large improvement from the 56.7 F1 of the previous best system.", "year": 2017, "ssId": "3c78c6df5eb1695b6a399e346dde880af27d1016", "arXivId": "1710.10723", "link": "https://arxiv.org/pdf/1710.10723.pdf", "openAccess": true, "authors": ["Christopher Clark", "Matt Gardner"]}}, "6276bbe6cc56234d430725a31a27939eeec88149": {"id": "6276bbe6cc56234d430725a31a27939eeec88149", "content": {"title": "Content-based Models of Quotation", "abstract": "We explore the task of quotability identification, in which, given a document, we aim to identify which of its passages are the most quotable, i.e. the most likely to be directly quoted by later derived documents. We approach quotability identification as a passage ranking problem and evaluate how well both feature-based and BERT-based (Devlin et al., 2019) models rank the passages in a given document by their predicted quotability. We explore this problem through evaluations on five datasets that span multiple languages (English, Latin) and genres of literature (e.g. poetry, plays, novels) and whose corresponding derived documents are of multiple types (news, journal articles). Our experiments confirm the relatively strong performance of BERT-based models on this task, with the best model, a RoBERTA sequential sentence tagger, achieving an average rho of 0.35 and NDCG@1, 5, 50 of 0.26, 0.31 and 0.40, respectively, across all five datasets.", "year": 2021, "ssId": "6276bbe6cc56234d430725a31a27939eeec88149", "arXivId": null, "link": "https://aclanthology.org/2021.eacl-main.195.pdf", "openAccess": true, "authors": ["Ansel MacLaughlin", "David A. Smith"]}}, "a16ae67070de155789a871cb27ecbf9eaa98b379": {"id": "a16ae67070de155789a871cb27ecbf9eaa98b379", "content": {"title": "All That\u2019s \u2018Human\u2019 Is Not Gold: Evaluating Human Evaluation of Generated Text", "abstract": "Human evaluations are typically considered the gold standard in natural language generation, but as models\u2019 fluency improves, how well can evaluators detect and judge machine-generated text? We run a study assessing non-experts\u2019 ability to distinguish between human- and machine-authored text (GPT2 and GPT3) in three domains (stories, news articles, and recipes). We find that, without training, evaluators distinguished between GPT3- and human-authored text at random chance level. We explore three approaches for quickly training evaluators to better identify GPT3-authored text (detailed instructions, annotated examples, and paired examples) and find that while evaluators\u2019 accuracy improved up to 55%, it did not significantly improve across the three domains. Given the inconsistent results across text domains and the often contradictory reasons evaluators gave for their judgments, we examine the role untrained human evaluations play in NLG evaluation and provide recommendations to NLG researchers for improving human evaluations of text generated from state-of-the-art models.", "year": 2021, "ssId": "a16ae67070de155789a871cb27ecbf9eaa98b379", "arXivId": "2107.00061", "link": "https://arxiv.org/pdf/2107.00061.pdf", "openAccess": true, "authors": ["Elizabeth Clark", "Tal August", "Sofia Serrano", "Nikita Haduong", "Suchin Gururangan", "Noah A. Smith"]}}, "807600ef43073cd9c59d4208ee710e90cf14efa8": {"id": "807600ef43073cd9c59d4208ee710e90cf14efa8", "content": {"title": "BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models", "abstract": "Existing neural information retrieval (IR) models have often been studied in homogeneous and narrow settings, which has considerably limited insights into their out-of-distribution (OOD) generalization capabilities. To address this, and to facilitate researchers to broadly evaluate the effectiveness of their models, we introduce Benchmarking-IR (BEIR), a robust and heterogeneous evaluation benchmark for information retrieval. We leverage a careful selection of 18 publicly available datasets from diverse text retrieval tasks and domains and evaluate 10 state-of-theart retrieval systems including lexical, sparse, dense, late-interaction and re-ranking architectures on the BEIR benchmark. Our results show BM25 is a robust baseline and re-ranking and late-interaction based models on average achieve the best zeroshot performances, however, at high computational costs. In contrast, dense and sparse-retrieval models are computationally more efficient but often underperform other approaches, highlighting the considerable room for improvement in their generalization capabilities. We hope this framework allows us to better evaluate and understand existing retrieval systems, and contributes to accelerating progress towards better robust and generalizable systems in the future. BEIR is publicly available at https://github.com/UKPLab/beir.", "year": 2021, "ssId": "807600ef43073cd9c59d4208ee710e90cf14efa8", "arXivId": "2104.08663", "link": "https://arxiv.org/pdf/2104.08663.pdf", "openAccess": true, "authors": ["Nandan Thakur", "Nils Reimers", "Andreas Ruckl'e", "Abhishek Srivastava", "Iryna Gurevych"]}}, "0822f8d7e6a72a65e65f147d3a8d8fccd485da40": {"id": "0822f8d7e6a72a65e65f147d3a8d8fccd485da40", "content": {"title": "Shortformer: Better Language Modeling using Shorter Inputs", "abstract": "Increasing the input length has been a driver of progress in language modeling with transformers. We identify conditions where shorter inputs are not harmful, and achieve perplexity and efficiency improvements through two new methods that decrease input length. First, we show that initially training a model on short subsequences before moving on to longer ones both reduces overall training time and, surprisingly, substantially improves perplexity. Second, we show how to improve the efficiency of recurrence methods in transformers, which let models condition on previously processed tokens when generating sequences that exceed the maximal length the transformer can handle at once. Existing methods require computationally expensive relative position embeddings; we introduce a simple alternative of adding absolute position embeddings to queries and keys instead of to word embeddings, which efficiently produces superior results. We show that these recurrent models also benefit from short input lengths. Combining these techniques speeds up training by a factor of 1.65, reduces memory usage, and substantially improves perplexity on WikiText-103, without adding any parameters.", "year": 2021, "ssId": "0822f8d7e6a72a65e65f147d3a8d8fccd485da40", "arXivId": "2012.15832", "link": "https://arxiv.org/pdf/2012.15832.pdf", "openAccess": true, "authors": ["Ofir Press", "Noah A. Smith", "M. Lewis"]}}, "8484fdb56e4690927dc0191ede11c2d24bc5e2ef": {"id": "8484fdb56e4690927dc0191ede11c2d24bc5e2ef", "content": {"title": "MAUVE: Measuring the Gap Between Neural Text and Human Text using Divergence Frontiers", "abstract": "As major progress is made in open-ended text generation, measuring how close machine-generated text is to human language remains a critical open problem. We introduce MAUVE, a comparison measure for open-ended text generation, which directly compares the learnt distribution from a text generation model to the distribution of human-written text using divergence frontiers. MAUVE scales up to modern text generation models by computing information divergences in a quantized embedding space. Through an extensive empirical study on three open-ended generation tasks, we find that MAUVE identifies known properties of generated text, scales naturally with model size, and correlates with human judgments, with fewer restrictions than existing distributional evaluation metrics.", "year": 2021, "ssId": "8484fdb56e4690927dc0191ede11c2d24bc5e2ef", "arXivId": "2102.01454", "link": "https://arxiv.org/pdf/2102.01454.pdf", "openAccess": true, "authors": ["Krishna Pillutla", "Swabha Swayamdipta", "Rowan Zellers", "John Thickstun", "S. Welleck", "Yejin Choi", "Z. Harchaoui"]}}, "3cd4797725ca9cf954946ed5309e15ebab80b92a": {"id": "3cd4797725ca9cf954946ed5309e15ebab80b92a", "content": {"title": "Multimodal Conditional Image Synthesis with Product-of-Experts GANs", "abstract": "Existing conditional image synthesis frameworks generate images based on user inputs in a single modality, such as text, segmentation, sketch, or style reference. They are often unable to leverage multimodal user inputs when available, which reduces their practicality. To address this limitation, we propose the Product-of-Experts Generative Adversarial Networks (PoE-GAN) framework, which can synthesize images conditioned on multiple input modalities or any subset of them, even the empty set. PoE-GAN consists of a productof-experts generator and a multimodal multiscale projection discriminator. Through our carefully designed training scheme, PoE-GAN learns to synthesize images with high quality and diversity. Besides advancing the state of the art in multimodal conditional image synthesis, PoE-GAN also outperforms the best existing unimodal conditional image synthesis approaches when tested in the unimodal setting. The project website is available at this link.", "year": 2021, "ssId": "3cd4797725ca9cf954946ed5309e15ebab80b92a", "arXivId": "2112.05130", "link": "https://arxiv.org/pdf/2112.05130.pdf", "openAccess": true, "authors": ["Xun Huang", "Arun Mallya", "Ting-Chun Wang", "Ming-Yu Liu"]}}, "d6741241efb9ffd933df974b43d7109c72238371": {"id": "d6741241efb9ffd933df974b43d7109c72238371", "content": {"title": "MMM : Exploring Conditional Multi-Track Music Generation with the Transformer", "abstract": "We propose the Multi-Track Music Machine (MMM), a generative system based on the Transformer architecture that is capable of generating multi-track music. In contrast to previous work, which represents musical material as a single time-ordered sequence, where the musical events corresponding to different tracks are interleaved, we create a time-ordered sequence of musical events for each track and concatenate several tracks into a single sequence. This takes advantage of the Transformer's attention-mechanism, which can adeptly handle long-term dependencies. We explore how various representations can offer the user a high degree of control at generation time, providing an interactive demo that accommodates track-level and bar-level inpainting, and offers control over track instrumentation and note density.", "year": 2020, "ssId": "d6741241efb9ffd933df974b43d7109c72238371", "arXivId": "2008.06048", "link": "https://arxiv.org/pdf/2008.06048.pdf", "openAccess": true, "authors": ["J. Ens", "P. Pasquier"]}}, "eadd73c3e1c20d16e32ee8656c4f954603b37450": {"id": "eadd73c3e1c20d16e32ee8656c4f954603b37450", "content": {"title": "Vision-based Detection of Acoustic Timed Events: a Case Study on Clarinet Note Onsets", "abstract": "Acoustic events often have a visual counterpart. Knowledge of visual information can aid the understanding of complex auditory scenes, even when only a stereo mixdown is available in the audio domain, \\eg identifying which musicians are playing in large musical ensembles. In this paper, we consider a vision-based approach to note onset detection. As a case study we focus on challenging, real-world clarinetist videos and carry out preliminary experiments on a 3D convolutional neural network based on multiple streams and purposely avoiding temporal pooling. We release an audiovisual dataset with 4.5 hours of clarinetist videos together with cleaned annotations which include about 36,000 onsets and the coordinates for a number of salient points and regions of interest. By performing several training trials on our dataset, we learned that the problem is challenging. We found that the CNN model is highly sensitive to the optimization algorithm and hyper-parameters, and that treating the problem as binary classification may prevent the joint optimization of precision and recall. To encourage further research, we publicly share our dataset, annotations and all models and detail which issues we came across during our preliminary experiments.", "year": 2017, "ssId": "eadd73c3e1c20d16e32ee8656c4f954603b37450", "arXivId": "1706.09556", "link": "https://arxiv.org/pdf/1706.09556.pdf", "openAccess": true, "authors": ["A. Bazzica", "J. V. Gemert", "Cynthia C. S. Liem", "A. Hanjalic"]}}, "95a35473fd1936927dd4a53fe0a5d2d6762d99b3": {"id": "95a35473fd1936927dd4a53fe0a5d2d6762d99b3", "content": {"title": "MIDI-DDSP: Detailed Control of Musical Performance via Hierarchical Modeling", "abstract": "Musical expression requires control of both what notes are played, and how they are performed. Conventional audio synthesizers provide detailed expressive controls, but at the cost of realism. Black-box neural audio synthesis and concatenative samplers can produce realistic audio, but have few mechanisms for control. In this work, we introduce MIDI-DDSP, a hierarchical model of musical instruments that enables both realistic neural audio synthesis and detailed user control. Starting from interpretable Differentiable Digital Signal Processing (DDSP) synthesis parameters, we infer musical notes and high-level properties of their expressive performance (such as timbre, vibrato, dynamics, and articulation). This creates a 3-level hierarchy (notes, performance, synthesis) that affords individuals the option to intervene at each level, or utilize trained priors (performance given notes, synthesis given performance) for creative assistance. Through quantitative experiments and listening tests, we demonstrate that this hierarchy can reconstruct high-fidelity audio, accurately predict performance attributes for a note sequence, independently manipulate the attributes of a given performance, and as a complete system, generate realistic audio from a novel note sequence. By utilizing an interpretable hierarchy, with multiple levels of granularity, MIDI-DDSP opens the door to assistive tools to empower individuals across a diverse range of musical experience.", "year": 2021, "ssId": "95a35473fd1936927dd4a53fe0a5d2d6762d99b3", "arXivId": "2112.09312", "link": "https://arxiv.org/pdf/2112.09312.pdf", "openAccess": true, "authors": ["Yusong Wu", "Ethan Manilow", "Yi Deng", "Rigel Swavely", "Kyle Kastner", "Tim Cooijmans", "Aaron C. Courville", "Cheng-Zhi Anna Huang", "Jesse Engel"]}}, "45ce9fce4a4eea9f72688885182aee0c84786fab": {"id": "45ce9fce4a4eea9f72688885182aee0c84786fab", "content": {"title": "A Universal Music Translation Network", "abstract": "We present a method for translating music across musical instruments, genres, and styles. This method is based on a multi-domain wavenet autoencoder, with a shared encoder and a disentangled latent space that is trained end-to-end on waveforms. Employing a diverse training dataset and large net capacity, the domain-independent encoder allows us to translate even from musical domains that were not seen during training. The method is unsupervised and does not rely on supervision in the form of matched samples between domains or musical transcriptions. We evaluate our method on NSynth, as well as on a dataset collected from professional musicians, and achieve convincing translations, even when translating from whistling, potentially enabling the creation of instrumental music by untrained humans.", "year": 2018, "ssId": "45ce9fce4a4eea9f72688885182aee0c84786fab", "arXivId": "1805.07848", "link": "https://arxiv.org/pdf/1805.07848.pdf", "openAccess": true, "authors": ["Noam Mor", "Lior Wolf", "A. Polyak", "Yaniv Taigman"]}}, "7a79099447bef9a3ea13b1dc409d04b3dff57320": {"id": "7a79099447bef9a3ea13b1dc409d04b3dff57320", "content": {"title": "Pop Music Transformer: Generating Music with Rhythm and Harmony", "abstract": "The task automatic music composition entails generative modeling of music in symbolic formats such as the musical scores. By serializing a score as a sequence of MIDI-like events, recent work has demonstrated that state-of-the-art sequence models with self-attention work nicely for this task, especially for composing music with long-range coherence. In this paper, we show that sequence models can do even better when we improve the way a musical score is converted into events. The new event set, dubbed \"REMI\" (REvamped MIDI-derived events), provides sequence models a metric context for modeling the rhythmic patterns of music, while allowing for local tempo changes. Moreover, it explicitly sets up a harmonic structure and makes chord progression controllable. It also facilitates coordinating different tracks of a musical piece, such as the piano, bass and drums. With this new approach, we build a Pop Music Transformer that composes Pop piano music with a more plausible rhythmic structure than prior arts do. The code, data and pre-trained model are publicly available.\\footnote{\\url{this https URL}}", "year": 2020, "ssId": "7a79099447bef9a3ea13b1dc409d04b3dff57320", "arXivId": "2002.00212", "link": "https://arxiv.org/pdf/2002.00212.pdf", "openAccess": true, "authors": ["Yu-Siang Huang", "Yi-Hsuan Yang"]}}, "889c3b4394826639d483c039467cd9a05e68e73c": {"id": "889c3b4394826639d483c039467cd9a05e68e73c", "content": {"title": "Counterpoint by Convolution", "abstract": "Machine learning models of music typically break up the task of composition into a chronological process, composing a piece of music in a single pass from beginning to end. On the contrary, human composers write music in a nonlinear fashion, scribbling motifs here and there, often revisiting choices previously made. In order to better approximate this process, we train a convolutional neural network to complete partial musical scores, and explore the use of blocked Gibbs sampling as an analogue to rewriting. Neither the model nor the generative procedure are tied to a particular causal direction of composition. Our model is an instance of orderless NADE (Uria et al., 2014), which allows more direct ancestral sampling. However, we find that Gibbs sampling greatly improves sample quality, which we demonstrate to be due to some conditional distributions being poorly modeled. Moreover, we show that even the cheap approximate blocked Gibbs procedure from Yao et al. (2014) yields better samples than ancestral sampling, based on both log-likelihood and human evaluation.", "year": 2019, "ssId": "889c3b4394826639d483c039467cd9a05e68e73c", "arXivId": "1903.07227", "link": "https://arxiv.org/pdf/1903.07227.pdf", "openAccess": true, "authors": ["Cheng-Zhi Anna Huang", "Tim Cooijmans", "Adam Roberts", "Aaron C. Courville", "D. Eck"]}}, "3af5e203368fa2c7959d035493571d181a8682af": {"id": "3af5e203368fa2c7959d035493571d181a8682af", "content": {"title": "Creating a Multitrack Classical Music Performance Dataset for Multimodal Music Analysis: Challenges, Insights, and Applications", "abstract": "We introduce a dataset for facilitating audio-visual analysis of music performances. The dataset comprises 44 simple multi-instrument classical music pieces assembled from coordinated but separately recorded performances of individual tracks. For each piece, we provide the musical score in MIDI format, the audio recordings of the individual tracks, the audio and video recording of the assembled mixture, and ground-truth annotation files including frame-level and note-level transcriptions. We describe our methodology for the creation of the dataset, particularly highlighting our approaches to address the challenges involved in maintaining synchronization and expressiveness. We demonstrate the high quality of synchronization achieved with our proposed approach by comparing the dataset with existing widely used music audio datasets. We anticipate that the dataset will be useful for the development and evaluation of existing music information retrieval (MIR) tasks, as well as for novel multimodal tasks. We benchmark two existing MIR tasks (multipitch analysis and score-informed source separation) on the dataset and compare them with other existing music audio datasets. In addition, we consider two novel multimodal MIR tasks (visually informed multipitch analysis and polyphonic vibrato analysis) enabled by the dataset and provide evaluation measurements and baseline systems for future comparisons (from our recent work). Finally, we propose several emerging research directions that the dataset enables.", "year": 2016, "ssId": "3af5e203368fa2c7959d035493571d181a8682af", "arXivId": "1612.08727", "link": "https://arxiv.org/pdf/1612.08727.pdf", "openAccess": true, "authors": ["Bochen Li", "Xinzhao Liu", "K. Dinesh", "Zhiyao Duan", "Gaurav Sharma"]}}, "e75c388b60cf447be7148be25feeee3e10d12cf4": {"id": "e75c388b60cf447be7148be25feeee3e10d12cf4", "content": {"title": "Learning in High Dimension Always Amounts to Extrapolation", "abstract": "The notion of interpolation and extrapolation is fundamental in various fields from deep learning to function approximation. Interpolation occurs for a sample x whenever this sample falls inside or on the boundary of the given dataset\u2019s convex hull. Extrapolation occurs when x falls outside of that convex hull. One fundamental (mis)conception is that state-of-the-art algorithms work so well because of their ability to correctly interpolate training data. A second (mis)conception is that interpolation happens throughout tasks and datasets, in fact, many intuitions and theories rely on that assumption. We empirically and theoretically argue against those two points and demonstrate that on any high-dimensional (>100) dataset, interpolation almost surely never happens. Those results challenge the validity of our current interpolation/extrapolation definition as an indicator of generalization performances.", "year": 2021, "ssId": "e75c388b60cf447be7148be25feeee3e10d12cf4", "arXivId": "2110.09485", "link": "https://arxiv.org/pdf/2110.09485.pdf", "openAccess": true, "authors": ["Randall Balestriero", "J. Pesenti", "Yann LeCun"]}}, "62d1a3137b01a69443bebf4d92c1990ec512a6a1": {"id": "62d1a3137b01a69443bebf4d92c1990ec512a6a1", "content": {"title": "Extracting Training Data from Large Language Models", "abstract": "It has become common to publish large (billion parameter) language models that have been trained on private datasets. This paper demonstrates that in such settings, an adversary can perform a training data extraction attack to recover individual training examples by querying the language model. \nWe demonstrate our attack on GPT-2, a language model trained on scrapes of the public Internet, and are able to extract hundreds of verbatim text sequences from the model's training data. These extracted examples include (public) personally identifiable information (names, phone numbers, and email addresses), IRC conversations, code, and 128-bit UUIDs. Our attack is possible even though each of the above sequences are included in just one document in the training data. \nWe comprehensively evaluate our extraction attack to understand the factors that contribute to its success. For example, we find that larger models are more vulnerable than smaller models. We conclude by drawing lessons and discussing possible safeguards for training large language models.", "year": 2020, "ssId": "62d1a3137b01a69443bebf4d92c1990ec512a6a1", "arXivId": "2012.07805", "link": "https://arxiv.org/pdf/2012.07805.pdf", "openAccess": true, "authors": ["Nicholas Carlini", "Florian Tram\u00e8r", "Eric Wallace", "Matthew Jagielski", "Ariel Herbert-Voss", "Katherine Lee", "Adam Roberts", "Tom B. Brown", "D. Song", "\u00da. Erlingsson", "Alina Oprea", "Colin Raffel"]}}, "1adadbfa95e43a70fcd17e6ce947a0652b86bfc3": {"id": "1adadbfa95e43a70fcd17e6ce947a0652b86bfc3", "content": {"title": "Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus", "abstract": "Large language models have led to remarkable progress on many NLP tasks, and researchers are turning to ever-larger text corpora to train them. Some of the largest corpora available are made by scraping significant portions of the internet, and are frequently introduced with only minimal documentation. In this work we provide some of the first documentation for the Colossal Clean Crawled Corpus (C4; Raffel et al., 2020), a dataset created by applying a set of filters to a single snapshot of Common Crawl. We begin by investigating where the data came from, and find a significant amount of text from unexpected sources like patents and US military websites. Then we explore the content of the text itself, and find machine-generated text (e.g., from machine translation systems) and evaluation examples from other benchmark NLP datasets. To understand the impact of the filters applied to create this dataset, we evaluate the text that was removed, and show that blocklist filtering disproportionately removes text from and about minority individuals. Finally, we conclude with some recommendations for how to created and document web-scale datasets from a scrape of the internet.", "year": 2021, "ssId": "1adadbfa95e43a70fcd17e6ce947a0652b86bfc3", "arXivId": "2104.08758", "link": "https://arxiv.org/pdf/2104.08758.pdf", "openAccess": true, "authors": ["Jesse Dodge", "Ana Marasovi\u0107", "Gabriel Ilharco", "Dirk Groeneveld", "Margaret Mitchell", "Matt Gardner"]}}, "1d5c07e7415a7e9be078717197ddf9f3c70a2875": {"id": "1d5c07e7415a7e9be078717197ddf9f3c70a2875", "content": {"title": "Does BERT Pretrained on Clinical Notes Reveal Sensitive Data?", "abstract": "Large Transformers pretrained over clinical notes from Electronic Health Records (EHR) have afforded substantial gains in performance on predictive clinical tasks. The cost of training such models (and the necessity of data access to do so) coupled with their utility motivates parameter sharing, i.e., the release of pretrained models such as ClinicalBERT. While most efforts have used deidentified EHR, many researchers have access to large sets of sensitive, non-deidentified EHR with which they might train a BERT model (or similar). Would it be safe to release the weights of such a model if they did? In this work, we design a battery of approaches intended to recover Personal Health Information (PHI) from a trained BERT. Specifically, we attempt to recover patient names and conditions with which they are associated. We find that simple probing methods are not able to meaningfully extract sensitive information from BERT trained over the MIMIC-III corpus of EHR. However, more sophisticated \u201cattacks\u201d may succeed in doing so: To facilitate such research, we make our experimental setup and baseline probing models available at https://github.com/elehman16/exposing_patient_data_release.", "year": 2021, "ssId": "1d5c07e7415a7e9be078717197ddf9f3c70a2875", "arXivId": "2104.07762", "link": "https://arxiv.org/pdf/2104.07762.pdf", "openAccess": true, "authors": ["Eric P. Lehman", "Sarthak Jain", "Karl Pichotta", "Yoav Goldberg", "Byron C. Wallace"]}}, "db500c4e746897e5d5adafbf222b959c512445ad": {"id": "db500c4e746897e5d5adafbf222b959c512445ad", "content": {"title": "Customizing Triggers with Concealed Data Poisoning", "abstract": "Adversarial attacks alter NLP model predictions by perturbing test-time inputs. However, it is much less understood whether, and how, predictions can be manipulated with small, concealed changes to the training data. In this work, we develop a new data poisoning attack that allows an adversary to control model predictions whenever a desired trigger phrase is present in the input. For instance, we insert 50 poison examples into a sentiment model's training set that causes the model to frequently predict Positive whenever the input contains \"James Bond\". Crucially, we craft these poison examples using a gradient-based procedure so that they do not mention the trigger phrase. We also apply our poison attack to language modeling (\"Apple iPhone\" triggers negative generations) and machine translation (\"iced coffee\" mistranslated as \"hot coffee\"). We conclude by proposing three defenses that can mitigate our attack at some cost in prediction accuracy or extra human annotation.", "year": 2020, "ssId": "db500c4e746897e5d5adafbf222b959c512445ad", "arXivId": "2010.12563", "link": "https://arxiv.org/pdf/2010.12563.pdf", "openAccess": true, "authors": ["Eric Wallace", "Tony Zhao", "Shi Feng", "Sameer Singh"]}}, "1d634d645bfe0b289fd6a2a0d9210b2a04c9237b": {"id": "1d634d645bfe0b289fd6a2a0d9210b2a04c9237b", "content": {"title": "Large Language Models Can Be Strong Differentially Private Learners", "abstract": "Differentially Private (DP) learning has seen limited success for building large deep learning models of text, and attempts at straightforwardly applying Differentially Private Stochastic Gradient Descent (DP-SGD) to NLP tasks have resulted in large performance drops and high computational overhead. We show that this performance drop can be mitigated with (1) the use of large pretrained models; (2) hyperparameters that suit DP optimization; and (3) fine-tuning objectives aligned with the pretraining procedure. With these factors set right, we obtain private NLP models that outperform state-of-the-art private training approaches and strong nonprivate baselines\u2014by directly fine-tuning pretrained models with DP optimization on moderately-sized corpora. To address the computational challenge of running DP-SGD with large Transformers, we propose a memory saving technique that allows clipping in DP-SGD to run without instantiating per-example gradients for any layer in the model. The technique enables privately training Transformers with almost the same memory cost as non-private training at a modest run-time overhead. Contrary to conventional wisdom that DP optimization fails at learning high-dimensional models (due to noise that scales with dimension) empirical results reveal that private learning with pretrained models tends to not suffer from dimension-dependent performance degradation.", "year": 2021, "ssId": "1d634d645bfe0b289fd6a2a0d9210b2a04c9237b", "arXivId": "2110.05679", "link": "https://arxiv.org/pdf/2110.05679.pdf", "openAccess": true, "authors": ["Xuechen Li", "Florian Tram\u00e8r", "Percy Liang", "Tatsunori B. Hashimoto"]}}, "1da3a9c194a01c0bff7b6ecda79db9d673810bee": {"id": "1da3a9c194a01c0bff7b6ecda79db9d673810bee", "content": {"title": "Applying the Transformer to Character-level Transduction", "abstract": "The transformer has been shown to outperform recurrent neural network-based sequence-to-sequence models in various word-level NLP tasks. Yet for character-level transduction tasks, e.g. morphological inflection generation and historical text normalization, there are few works that outperform recurrent models using the transformer. In an empirical study, we uncover that, in contrast to recurrent sequence-to-sequence models, the batch size plays a crucial role in the performance of the transformer on character-level tasks, and we show that with a large enough batch size, the transformer does indeed outperform recurrent models. We also introduce a simple technique to handle feature-guided character-level transduction that further improves performance. With these insights, we achieve state-of-the-art performance on morphological inflection and historical text normalization. We also show that the transformer outperforms a strong baseline on two other character-level transduction tasks: grapheme-to-phoneme conversion and transliteration.", "year": 2020, "ssId": "1da3a9c194a01c0bff7b6ecda79db9d673810bee", "arXivId": "2005.10213", "link": "https://arxiv.org/pdf/2005.10213.pdf", "openAccess": true, "authors": ["Shijie Wu", "Ryan Cotterell", "Mans Hulden"]}}, "ad48174ccbff6259a7d3cb0d0985e5aefa314b84": {"id": "ad48174ccbff6259a7d3cb0d0985e5aefa314b84", "content": {"title": "Why don't people use character-level machine translation?", "abstract": "We present a literature and empirical survey that critically assesses the state of the art in character-level modeling for machine translation (MT). Despite evidence in the literature that character-level systems are comparable with subword systems, they are virtually never used in competitive setups in WMT competitions. We empirically show that even with recent modeling innovations in character-level natural language processing, character-level MT systems still struggle to match their subword-based counterparts. Character-level MT systems show neither better domain robustness, nor better morphological generalization, despite being often so motivated. However, we are able to show robustness towards source side noise and that translation quality does not degrade with increasing beam size at decoding time.", "year": 2021, "ssId": "ad48174ccbff6259a7d3cb0d0985e5aefa314b84", "arXivId": "2110.08191", "link": "https://arxiv.org/pdf/2110.08191.pdf", "openAccess": true, "authors": ["Jind\u0159ich Libovick\u00fd", "Helmut Schmid", "Alexander Fraser"]}}, "6dafc41e9bbd3aa476a0a1c15ca2c459eaef6b98": {"id": "6dafc41e9bbd3aa476a0a1c15ca2c459eaef6b98", "content": {"title": "(Un)solving Morphological Inflection: Lemma Overlap Artificially Inflates Models' Performance", "abstract": "In the domain of Morphology, Inflection is a fundamental and important task that gained a lot of traction in recent years, mostly via SIGMORPHON\u2019s shared-tasks. With average accuracy above 0.9 over the scores of all languages, the task is considered mostly solved using relatively generic neural seq2seq models, even with little data provided. In this work, we propose to re-evaluate morphological inflection models by employing harder train-test splits that will challenge the generalization capacity of the models. In particular, as opposed to the na\u00efve split-by-form, we propose a split-by-lemma method to challenge the performance on existing benchmarks. Our experiments with the three top-ranked systems on the SIGMORPHON\u2019s 2020 shared-task show that the lemma-split presents an average drop of 30 percentage points in macro-average for the 90 languages included. The effect is most significant for low-resourced languages with a drop as high as 95 points, but even highresourced languages lose about 10 points on average. Our results clearly show that generalizing inflection to unseen lemmas is far from being solved, presenting a simple yet effective means to promote more sophisticated models.", "year": 2021, "ssId": "6dafc41e9bbd3aa476a0a1c15ca2c459eaef6b98", "arXivId": "2108.05682", "link": "https://arxiv.org/pdf/2108.05682.pdf", "openAccess": true, "authors": ["Omer Goldman", "David Guriel", "Reut Tsarfaty"]}}, "86ae1161026f23f9df691a867fd7453cee56fd28": {"id": "86ae1161026f23f9df691a867fd7453cee56fd28", "content": {"title": "Semantic Change and Semantic Stability: Variation is Key", "abstract": "I survey some recent approaches to studying change in the lexicon, particularly change in meaning across phylogenies. I briefly sketch an evolutionary approach to language change and point out some issues in recent approaches to studying semantic change that rely on temporally stratified word embeddings. I draw illustrations from lexical cognate models in Pama-Nyungan to identify meaning classes most appropriate for lexical phylogenetic inference, particularly highlighting the importance of variation in studying change over time.", "year": 2019, "ssId": "86ae1161026f23f9df691a867fd7453cee56fd28", "arXivId": "1906.05760", "link": "https://arxiv.org/pdf/1906.05760.pdf", "openAccess": true, "authors": ["Claire Bowern"]}}, "b08545e1281c1eb748e4474687eb61fd3b25d1a6": {"id": "b08545e1281c1eb748e4474687eb61fd3b25d1a6", "content": {"title": "NYTWIT: A Dataset of Novel Words in the New York Times", "abstract": "We present the New York Times Word Innovation Types dataset, or NYTWIT, a collection of over 2,500 novel English words published in the New York Times between November 2017 and March 2019, manually annotated for their class of novelty (such as lexical derivation, dialectal variation, blending, or compounding). We present baseline results for both uncontextual and contextual prediction of novelty class, showing that there is room for improvement even for state-of-the-art NLP systems. We hope this resource will prove useful for linguists and NLP practitioners by providing a real-world environment of novel word appearance.", "year": 2020, "ssId": "b08545e1281c1eb748e4474687eb61fd3b25d1a6", "arXivId": "2003.03444", "link": "https://arxiv.org/pdf/2003.03444.pdf", "openAccess": true, "authors": ["Yuval Pinter", "Cassandra L. Jacobs", "Max Bittker"]}}, "5a0c9bbf0432dac8bd357a4aabf82b83a6c95524": {"id": "5a0c9bbf0432dac8bd357a4aabf82b83a6c95524", "content": {"title": "Aspect-based Document Similarity for Research Papers", "abstract": "Traditional document similarity measures provide a coarse-grained distinction between similar and dissimilar documents. Typically, they do not consider in what aspects two documents are similar. This limits the granularity of applications like recommender systems that rely on document similarity. In this paper, we extend similarity with aspect information by performing a pairwise document classification task. We evaluate our aspect-based document similarity approach for research papers. Paper citations indicate the aspect-based similarity, i.e., the title of a section in which a citation occurs acts as a label for the pair of citing and cited paper. We apply a series of Transformer models such as RoBERTa, ELECTRA, XLNet, and BERT variations and compare them to an LSTM baseline. We perform our experiments on two newly constructed datasets of 172,073 research paper pairs from the ACL Anthology and CORD-19 corpus. According to our results, SciBERT is the best performing system with F1-scores of up to 0.83. A qualitative analysis validates our quantitative results and indicates that aspect-based document similarity indeed leads to more fine-grained recommendations.", "year": 2020, "ssId": "5a0c9bbf0432dac8bd357a4aabf82b83a6c95524", "arXivId": "2010.06395", "link": "https://arxiv.org/pdf/2010.06395.pdf", "openAccess": true, "authors": ["Malte Ostendorff", "Terry Ruas", "Till Blume", "Bela Gipp", "Georg Rehm"]}}, "bd49e66af9755e6138967eba6aeb37d8190d2b4f": {"id": "bd49e66af9755e6138967eba6aeb37d8190d2b4f", "content": {"title": "ExpBERT: Representation Engineering with Natural Language Explanations", "abstract": "Suppose we want to specify the inductive bias that married couples typically go on honeymoons for the task of extracting pairs of spouses from text. In this paper, we allow model developers to specify these types of inductive biases as natural language explanations. We use BERT fine-tuned on MultiNLI to \u201cinterpret\u201d these explanations with respect to the input sentence, producing explanation-guided representations of the input. Across three relation extraction tasks, our method, ExpBERT, matches a BERT baseline but with 3\u201320x less labeled data and improves on the baseline by 3\u201310 F1 points with the same amount of labeled data.", "year": 2020, "ssId": "bd49e66af9755e6138967eba6aeb37d8190d2b4f", "arXivId": "2005.01932", "link": "https://arxiv.org/pdf/2005.01932.pdf", "openAccess": true, "authors": ["Shikhar Murty", "Pang Wei Koh", "Percy Liang"]}}, "53e161d4434576355fc5f63fe56afd8e135174b2": {"id": "53e161d4434576355fc5f63fe56afd8e135174b2", "content": {"title": "proScript: Partially Ordered Scripts Generation via Pre-trained Language Models", "abstract": "Scripts standardized event sequences describing typical everyday activities have been shown to help understand narratives by providing expectations, resolving ambiguity, and filling in unstated information. However, to date they have proved hard to author or extract from text. In this work, we demonstrate for the first time that pre-trained neural language models (LMs) can be be finetuned to generate high-quality scripts, at varying levels of granularity, for a wide range of everyday scenarios (e.g., bake a cake). To do this, we collected a large (6.4k), crowdsourced partially ordered scripts (named proScript), which is substantially larger than prior datasets, and developed models that generate scripts with combining language generation and structure prediction. We define two complementary tasks: (i) edge prediction: given a scenario and unordered events, organize the events into a valid (possibly partial-order) script, and (ii) script generation: given only a scenario, generate events and organize them into a (possibly partial-order) script. Our experiments show that our models perform well (e.g., F1=75.7 on task (i)), illustrating a new approach to overcoming previous barriers to script collection. We also show that there is still significant room for improvement toward human level performance. Together, our tasks, dataset, and models offer a new research direction for learning script knowledge.", "year": 2021, "ssId": "53e161d4434576355fc5f63fe56afd8e135174b2", "arXivId": "2104.08251", "link": "https://arxiv.org/pdf/2104.08251.pdf", "openAccess": true, "authors": ["Keisuke Sakaguchi", "Chandra Bhagavatula", "R. L. Bras", "Niket Tandon", "Peter Clark", "Yejin Choi"]}}, "c4ce6aca9aed41d57d588674484932e0c2cd3547": {"id": "c4ce6aca9aed41d57d588674484932e0c2cd3547", "content": {"title": "Extracting a Knowledge Base of Mechanisms from COVID-19 Papers", "abstract": "The COVID-19 pandemic has spawned a diverse body of scientific literature that is challenging to navigate, stimulating interest in automated tools to help find useful knowledge. We pursue the construction of a knowledge base (KB) of mechanisms\u2014a fundamental concept across the sciences, which encompasses activities, functions and causal relations, ranging from cellular processes to economic impacts. We extract this information from the natural language of scientific papers by developing a broad, unified schema that strikes a balance between relevance and breadth. We annotate a dataset of mechanisms with our schema and train a model to extract mechanism relations from papers. Our experiments demonstrate the utility of our KB in supporting interdisciplinary scientific search over COVID-19 literature, outperforming the prominent PubMed search in a study with clinical experts. Our search engine, dataset and code are publicly available.", "year": 2020, "ssId": "c4ce6aca9aed41d57d588674484932e0c2cd3547", "arXivId": "2010.03824", "link": "https://arxiv.org/pdf/2010.03824.pdf", "openAccess": true, "authors": ["Aida Amini", "Tom Hope", "David Wadden", "Madeleine van Zuylen", "E. Horvitz", "Roy Schwartz", "Hannaneh Hajishirzi"]}}, "aeb4478619461ca25592e6d692f3591ec8c4091b": {"id": "aeb4478619461ca25592e6d692f3591ec8c4091b", "content": {"title": "Adversarial Semantic Collisions", "abstract": "We study semantic collisions: texts that are semantically unrelated but judged as similar by NLP models. We develop gradient-based approaches for generating semantic collisions and demonstrate that state-of-the-art models for many tasks which rely on analyzing the meaning and similarity of texts-- including paraphrase identification, document retrieval, response suggestion, and extractive summarization-- are vulnerable to semantic collisions. For example, given a target query, inserting a crafted collision into an irrelevant document can shift its retrieval rank from 1000 to top 3. We show how to generate semantic collisions that evade perplexity-based filtering and discuss other potential mitigations. Our code is available at https://github.com/csong27/collision-bert.", "year": 2020, "ssId": "aeb4478619461ca25592e6d692f3591ec8c4091b", "arXivId": "2011.04743", "link": "https://arxiv.org/pdf/2011.04743.pdf", "openAccess": true, "authors": ["Congzheng Song", "Alexander M. Rush", "Vitaly Shmatikov"]}}, "518cb6d4247bdebf21e2811f296b0c7372602a0a": {"id": "518cb6d4247bdebf21e2811f296b0c7372602a0a", "content": {"title": "PMI-Masking: Principled masking of correlated spans", "abstract": "Masking tokens uniformly at random constitutes a common flaw in the pretraining of Masked Language Models (MLMs) such as BERT. We show that such uniform masking allows an MLM to minimize its training objective by latching onto shallow local signals, leading to pretraining inefficiency and suboptimal downstream performance. To address this flaw, we propose PMI-Masking, a principled masking strategy based on the concept of Pointwise Mutual Information (PMI), which jointly masks a token n-gram if it exhibits high collocation over the corpus. PMI-Masking motivates, unifies, and improves upon prior more heuristic approaches that attempt to address the drawback of random uniform token masking, such as whole-word masking, entity/phrase masking, and random-span masking. Specifically, we show experimentally that PMI-Masking reaches the performance of prior masking approaches in half the training time, and consistently improves performance at the end of training.", "year": 2020, "ssId": "518cb6d4247bdebf21e2811f296b0c7372602a0a", "arXivId": "2010.01825", "link": "https://arxiv.org/pdf/2010.01825.pdf", "openAccess": true, "authors": ["Yoav Levine", "Barak Lenz", "Opher Lieber", "Omri Abend", "Kevin Leyton-Brown", "Moshe Tennenholtz", "Y. Shoham"]}}, "86471bf927401bf88af83626797228c2bf10a282": {"id": "86471bf927401bf88af83626797228c2bf10a282", "content": {"title": "Aligning Faithful Interpretations with their Social Attribution", "abstract": "Abstract We find that the requirement of model interpretations to be faithful is vague and incomplete. With interpretation by textual highlights as a case study, we present several failure cases. Borrowing concepts from social science, we identify that the problem is a misalignment between the causal chain of decisions (causal attribution) and the attribution of human behavior to the interpretation (social attribution). We reformulate faithfulness as an accurate attribution of causality to the model, and introduce the concept of aligned faithfulness: faithful causal chains that are aligned with their expected social behavior. The two steps of causal attribution and social attribution together complete the process of explaining behavior. With this formalization, we characterize various failures of misaligned faithful highlight interpretations, and propose an alternative causal chain to remedy the issues. Finally, we implement highlight explanations of the proposed causal format using contrastive explanations.", "year": 2020, "ssId": "86471bf927401bf88af83626797228c2bf10a282", "arXivId": "2006.01067", "link": "https://arxiv.org/pdf/2006.01067.pdf", "openAccess": true, "authors": ["Alon Jacovi", "Yoav Goldberg"]}}, "7731e3dec97c48498b585408d44615346ade144a": {"id": "7731e3dec97c48498b585408d44615346ade144a", "content": {"title": "Characterizing English Variation across Social Media Communities with BERT", "abstract": "Abstract Much previous work characterizing language variation across Internet social groups has focused on the types of words used by these groups. We extend this type of study by employing BERT to characterize variation in the senses of words as well, analyzing two months of English comments in 474 Reddit communities. The specificity of different sense clusters to a community, combined with the specificity of a community\u2019s unique word types, is used to identify cases where a social group\u2019s language deviates from the norm. We validate our metrics using user-created glossaries and draw on sociolinguistic theories to connect language variation with trends in community behavior. We find that communities with highly distinctive language are medium-sized, and their loyal and highly engaged users interact in dense networks.", "year": 2021, "ssId": "7731e3dec97c48498b585408d44615346ade144a", "arXivId": "2102.06820", "link": "https://arxiv.org/pdf/2102.06820.pdf", "openAccess": true, "authors": ["Li Lucy", "David Bamman"]}}, "782a50a48ba5d32839631254285d989bfadfd193": {"id": "782a50a48ba5d32839631254285d989bfadfd193", "content": {"title": "Interpretable Entity Representations through Large-Scale Typing", "abstract": "In standard methodology for natural language processing, entities in text are typically embedded in dense vector spaces with pre-trained models. The embeddings produced this way are effective when fed into downstream models, but they require end-task fine-tuning and are fundamentally difficult to interpret. In this paper, we present an approach to creating entity representations that are human readable and achieve high performance on entity-related tasks out of the box. Our representations are vectors whose values correspond to posterior probabilities over fine-grained entity types, indicating the confidence of a typing model\u2019s decision that the entity belongs to the corresponding type. We obtain these representations using a fine-grained entity typing model, trained either on supervised ultra-fine entity typing data (Choi et al. 2018) or distantly-supervised examples from Wikipedia. On entity probing tasks involving recognizing entity identity, our embeddings used in parameter-free downstream models achieve competitive performance with ELMo- and BERT-based embeddings in trained models. We also show that it is possible to reduce the size of our type set in a learning-based way for particular domains. Finally, we show that these embeddings can be post-hoc modified through a small number of rules to incorporate domain knowledge and improve performance.", "year": 2020, "ssId": "782a50a48ba5d32839631254285d989bfadfd193", "arXivId": "2005.00147", "link": "https://arxiv.org/pdf/2005.00147.pdf", "openAccess": true, "authors": ["Yasumasa Onoe", "Greg Durrett"]}}, "8274799029bfac4402685e1efd995a8aeb9e7426": {"id": "8274799029bfac4402685e1efd995a8aeb9e7426", "content": {"title": "SEQ\u02c63: Differentiable Sequence-to-Sequence-to-Sequence Autoencoder for Unsupervised Abstractive Sentence Compression", "abstract": "Neural sequence-to-sequence models are currently the dominant approach in several natural language processing tasks, but require large parallel corpora. We present a sequence-to-sequence-to-sequence autoencoder (SEQ\u02c63), consisting of two chained encoder-decoder pairs, with words used as a sequence of discrete latent variables. We apply the proposed model to unsupervised abstractive sentence compression, where the first and last sequences are the input and reconstructed sentences, respectively, while the middle sequence is the compressed sentence. Constraining the length of the latent word sequences forces the model to distill important information from the input. A pretrained language model, acting as a prior over the latent sequences, encourages the compressed sentences to be human-readable. Continuous relaxations enable us to sample from categorical distributions, allowing gradient-based optimization, unlike alternatives that rely on reinforcement learning. The proposed model does not require parallel text-summary pairs, achieving promising results in unsupervised sentence compression on benchmark datasets.", "year": 2019, "ssId": "8274799029bfac4402685e1efd995a8aeb9e7426", "arXivId": "1904.03651", "link": "https://arxiv.org/pdf/1904.03651.pdf", "openAccess": true, "authors": ["Christos Baziotis", "Ion Androutsopoulos", "Ioannis Konstas", "A. Potamianos"]}}, "f2de2c9d83b9058695e3272a4fbb7c30e04a1476": {"id": "f2de2c9d83b9058695e3272a4fbb7c30e04a1476", "content": {"title": "Predictors of L2 word learning accuracy: A big data investigation", "abstract": "What makes some words harder to learn than others in a second language? Although some robust factors have been identified based on small scale experimental studies, many relevant factors are difficult to study in such experiments due to the amount of data necessary to test them. Here, we investigate what factors affect the ease of learning of a word in a second language using a large data set of users learning English as a second language through the Duolingo mobile app. In a regression analysis, we test and confirm the well-studied effect of cognate status on word learning accuracy. Furthermore, we find significant effects for both cross-linguistic semantic alignment and English semantic density, two novel predictors derived from large scale distributional models of lexical semantics. Finally, we provide data on several other psycholinguistically plausible word level predictors. We conclude with a discussion of the limits, benefits and future research potential of using big data for investigating second language learning.", "year": 2018, "ssId": "f2de2c9d83b9058695e3272a4fbb7c30e04a1476", "arXivId": null, "link": "https://cogsci.mindmodeling.org/2018/papers/0113/0113.pdf", "openAccess": true, "authors": ["Elise W M Hopman", "Bill Thompson", "Joseph L. Austerweil", "G. Lupyan"]}}, "863b2b38b33ffc4e5462adbc7aaf84aeb93adda8": {"id": "863b2b38b33ffc4e5462adbc7aaf84aeb93adda8", "content": {"title": "Joint part-of-speech and dependency projection from multiple sources", "abstract": "Most previous work on annotation projection has been limited to a subset of IndoEuropean languages, using only a single source language, and projecting annotation for one task at a time. In contrast, we present an Integer Linear Programming (ILP) algorithm that simultaneously projects annotation for multiple tasks from multiple source languages, relying on parallel corpora available for hundreds of languages. When training POS taggers and dependency parsers on jointly projected POS tags and syntactic dependencies using our algorithm, we obtain better performance than a standard approach on 20/23 languages using one parallel corpus; and 18/27 languages using another.", "year": 2016, "ssId": "863b2b38b33ffc4e5462adbc7aaf84aeb93adda8", "arXivId": null, "link": "https://aclanthology.org/P16-2091.pdf", "openAccess": true, "authors": ["Anders Johannsen", "Zeljko Agic", "Anders S\u00f8gaard"]}}, "ebcb425ed1a51e8f1a6eca422882abd454fe04f2": {"id": "ebcb425ed1a51e8f1a6eca422882abd454fe04f2", "content": {"title": "Learning to Link Grammar and Encyclopedic Information of Assist ESL Learners", "abstract": "We introduce a system aimed at improving and expanding second language learners\u2019 English vocabulary. In addition to word definitions, we provide rich lexical information such as collocations and grammar patterns for target words. We present Linggle Booster that takes an article, identifies target vocabulary, provides lexical information, and generates a quiz on target words. Linggle Booster also links named-entity to corresponding Wikipedia pages. Evaluation on a set of target words shows that the method have reasonably good performance in terms of generating useful and information for learning vocabulary.", "year": 2019, "ssId": "ebcb425ed1a51e8f1a6eca422882abd454fe04f2", "arXivId": null, "link": "https://aclanthology.org/P19-3034.pdf", "openAccess": true, "authors": ["Jhih-Jie Chen", "Chingyu Yang", "Peichen Ho", "M. Tsai", "Chia-Fang Ho", "Kai-Wen Tuan", "C. Tsai", "Wen-Bin Han", "Jason J. S. Chang"]}}, "43fae0a7af211d91557d115d2f82e3c46d8bf022": {"id": "43fae0a7af211d91557d115d2f82e3c46d8bf022", "content": {"title": "Compression, Transduction, and Creation: A Unified Framework for Evaluating Natural Language Generation", "abstract": "Natural language generation (NLG) spans a broad range of tasks, each of which serves for specific objectives and desires different properties of generated text. The complexity makes automatic evaluation of NLG particularly challenging. Previous work has typically focused on a single task and developed individual evaluation metrics based on specific intuitions. In this paper, we propose a unifying perspective based on the nature of information change in NLG tasks, including compression (e.g., summarization), transduction (e.g., text rewriting), and creation (e.g., dialog). _Information alignment_ between input, context, and output text plays a common central role in characterizing the generation. With automatic alignment prediction models, we develop a family of interpretable metrics that are suitable for evaluating key aspects of different NLG tasks, often without need of gold reference data. Experiments show the uniformly designed metrics achieve stronger or comparable correlations with human judgement compared to state-of-the-art metrics in each of diverse tasks, including text summarization, style transfer, and knowledge-grounded dialog.", "year": 2021, "ssId": "43fae0a7af211d91557d115d2f82e3c46d8bf022", "arXivId": "2109.06379", "link": "https://arxiv.org/pdf/2109.06379.pdf", "openAccess": true, "authors": ["Mingkai Deng", "Bowen Tan", "Zhengzhong Liu", "E. Xing", "Zhiting Hu"]}}, "c305e3314c0853b14911f704c68b04cfc9ea7aa1": {"id": "c305e3314c0853b14911f704c68b04cfc9ea7aa1", "content": {"title": "Conversion from Paninian Karakas to Universal Dependencies for Hindi Dependency Treebank", "abstract": "Universal Dependencies (UD) are gaining much attention of late for systematic evaluation of cross-lingual techniques for crosslingual dependency parsing. In this paper we present our work in line with UD. Our contribution to this is manifold. We extend UD to Indian languages through conversion of P\u0101n\u1ecbnian Dependencies to UD for the Hindi Dependency Treebank (HDTB). We discuss the differences in annotation in both the schemes, present parsing experiments for both the formalisms and empirically evaluate their weaknesses and strengths for Hindi. We produce an automatically converted Hindi Treebank conforming to the international standard UD scheme, making it useful as a resource for multilingual language technology.", "year": 2016, "ssId": "c305e3314c0853b14911f704c68b04cfc9ea7aa1", "arXivId": null, "link": "https://aclanthology.org/W16-1716.pdf", "openAccess": true, "authors": ["Juhi Tandon", "H. Chaudhry", "R. Bhat", "D. Sharma"]}}, "06431546c21d7c2528aaa170c2e1078e0a82d12e": {"id": "06431546c21d7c2528aaa170c2e1078e0a82d12e", "content": {"title": "Revisiting the Primacy of English in Zero-shot Cross-lingual Transfer", "abstract": "Despite their success, large pre-trained multilingual models have not completely alleviated the need for labeled data, which is cumbersome to collect for all target languages. Zero-shot cross-lingual transfer is emerging as a practical solution: pre-trained models later fine-tuned on one transfer language exhibit surprising performance when tested on many target languages. English is the dominant source language for transfer, as reinforced by popular zero-shot benchmarks. However, this default choice has not been systematically vetted. In our study, we compare English against other transfer languages for fine-tuning, on two pretrained multilingual models (mBERT and mT5) and multiple classification and question answering tasks. We find that other high-resource languages such as German and Russian often transfer more effectively, especially when the set of target languages is diverse or unknown a priori. Unexpectedly, this can be true even when the training sets were automatically translated from English. This finding can have immediate impact on multilingual zero-shot systems, and should inform future benchmark designs.", "year": 2021, "ssId": "06431546c21d7c2528aaa170c2e1078e0a82d12e", "arXivId": "2106.16171", "link": "https://arxiv.org/pdf/2106.16171.pdf", "openAccess": true, "authors": ["Iulia Turc", "Kenton Lee", "Jacob Eisenstein", "Ming-Wei Chang", "Kristina Toutanova"]}}, "9cda754187545c3cc8f9e9f134c08707269d0fae": {"id": "9cda754187545c3cc8f9e9f134c08707269d0fae", "content": {"title": "SLAM: A Unified Encoder for Speech and Language Modeling via Speech-Text Joint Pre-Training", "abstract": "Unsupervised pre-training is now the predominant approach for both text and speech understanding. Self-attention models pre-trained on large amounts of unannotated data have been hugely successful when fine-tuned on downstream tasks from a variety of domains and languages. This paper takes the universality of unsupervised language pre-training one step further, by unifying speech and text pre-training within a single model. We build a single encoder with the BERT objective on unlabeled text together with the w2v-BERT objective on unlabeled speech. To further align our model representations across modalities, we leverage alignment losses, specifically Translation Language Modeling (TLM) and Speech Text Matching (STM) that make use of supervised speech-text recognition data. We demonstrate that incorporating both speech and text data during pre-training can significantly improve downstream quality on CoVoST 2 speech translation, by around 1 BLEU compared to single-modality pre-trained models, while retaining close to SotA performance on LibriSpeech and SpeechStew ASR tasks. On four GLUE tasks and text-normalization, we observe evidence of capacity limitations and interference between the two modalities, leading to degraded performance compared to an equivalent text-only model, while still being competitive with BERT. Through extensive empirical analysis we also demonstrate the importance of the choice of objective function for speech pre-training, and the beneficial effect of adding additional supervised signals on the quality of the learned representations.", "year": 2021, "ssId": "9cda754187545c3cc8f9e9f134c08707269d0fae", "arXivId": "2110.10329", "link": "https://arxiv.org/pdf/2110.10329.pdf", "openAccess": true, "authors": ["Ankur Bapna", "Yu-An Chung", "Na Wu", "Anmol Gulati", "Ye Jia", "J. Clark", "Melvin Johnson", "Jason Riesa", "A. Conneau", "Yu Zhang"]}}, "0a4b8b161931799d5c6bc3ecf07c53bae0e9e502": {"id": "0a4b8b161931799d5c6bc3ecf07c53bae0e9e502", "content": {"title": "Whose Language Counts as High Quality? Measuring Language Ideologies in Text Data Selection", "abstract": "Language models increasingly rely on massive 001 web dumps for diverse text data. However, 002 these sources are rife with undesirable content. 003 As such, resources like Wikipedia, books, and 004 news often serve as anchors for automatically 005 selecting web text most suitable for language 006 modeling, a process typically referred to as 007 quality filtering. Using a new dataset of U.S. 008 high school newspaper articles\u2014written by stu009 dents from across the country\u2014we investigate 010 whose language is preferred by the quality fil011 ter used for GPT-3. We find that newspapers 012 from larger schools, located in wealthier, edu013 cated, and urban ZIP codes are more likely to 014 be classified as high quality. We then demon015 strate that the filter\u2019s measurement of quality 016 is unaligned with other sensible metrics, such 017 as factuality or literary acclaim. We argue that 018 privileging any corpus as high quality entails a 019 language ideology, and more care is needed to 020 construct training corpora for language models, 021 with better transparency and justification for 022 the inclusion or exclusion of various texts. 023", "year": 2022, "ssId": "0a4b8b161931799d5c6bc3ecf07c53bae0e9e502", "arXivId": "2201.10474", "link": "https://arxiv.org/pdf/2201.10474.pdf", "openAccess": true, "authors": ["Suchin Gururangan", "Dallas Card", "Sarah K. Drier", "E. K. Gade", "Leroy Z. Wang", "Zeyu Wang", "Luke Zettlemoyer", "Noah A. Smith"]}}, "d4f5f1a196e203226e4a69d52a04d46823f32fb3": {"id": "d4f5f1a196e203226e4a69d52a04d46823f32fb3", "content": {"title": "Samanantar: The Largest Publicly Available Parallel Corpora Collection for 11 Indic Languages", "abstract": "Abstract We present Samanantar, the largest publicly available parallel corpora collection for Indic languages. The collection contains a total of 49.7 million sentence pairs between English and 11 Indic languages (from two language families). Specifically, we compile 12.4 million sentence pairs from existing, publicly available parallel corpora, and additionally mine 37.4 million sentence pairs from the Web, resulting in a 4\u00d7 increase. We mine the parallel sentences from the Web by combining many corpora, tools, and methods: (a) Web-crawled monolingual corpora, (b) document OCR for extracting sentences from scanned documents, (c) multilingual representation models for aligning sentences, and (d) approximate nearest neighbor search for searching in a large collection of sentences. Human evaluation of samples from the newly mined corpora validate the high quality of the parallel sentences across 11 languages. Further, we extract 83.4 million sentence pairs between all 55 Indic language pairs from the English-centric parallel corpus using English as the pivot language. We trained multilingual NMT models spanning all these languages on Samanantar which outperform existing models and baselines on publicly available benchmarks, such as FLORES, establishing the utility of Samanantar. Our data and models are available publicly at Samanantar and we hope they will help advance research in NMT and multilingual NLP for Indic languages.", "year": 2021, "ssId": "d4f5f1a196e203226e4a69d52a04d46823f32fb3", "arXivId": "2104.05596", "link": "https://arxiv.org/pdf/2104.05596.pdf", "openAccess": true, "authors": ["Gowtham Ramesh", "Sumanth Doddapaneni", "Aravinth Bheemaraj", "Mayank Jobanputra", "AK Raghavan", "Ajit Sharma", "Sujit Sahoo", "Harshita Diddee", "J. Mahalakshmi", "Divyanshu Kakwani", "Navneet Kumar", "Aswin Pradeep", "Kumar Deepak", "Vivek Raghavan", "Anoop Kunchukuttan", "Pratyush Kumar", "M. Khapra"]}}, "bc5e4b9fb3a40057df4994354a403202218d53a6": {"id": "bc5e4b9fb3a40057df4994354a403202218d53a6", "content": {"title": "Searching for More Efficient Dynamic Programs", "abstract": "Computational models of human language often involve combinatorial problems. For instance, a probabilistic parser may marginalize over exponentially many trees to make predictions. Algorithms for such problems often employ dynamic programming and are not always unique. Finding one with optimal asymptotic runtime can be unintuitive, timeconsuming, and error-prone. Our work aims to automate this laborious process. Given an initial correct declarative program, we search for a sequence of semantics-preserving transformations to improve its running time as much as possible. To this end, we describe a set of program transformations, a simple metric for assessing the efficiency of a transformed program, and a heuristic search procedure to improve this metric. We show that in practice, automated search\u2014like the mental search performed by human programmers\u2014can find substantial improvements to the initial program. Empirically, we show that many speed-ups described in the NLP literature could have been discovered automatically by our system.", "year": 2021, "ssId": "bc5e4b9fb3a40057df4994354a403202218d53a6", "arXivId": "2109.06966", "link": "https://arxiv.org/pdf/2109.06966.pdf", "openAccess": true, "authors": ["Tim Vieira", "Ryan Cotterell", "Jason Eisner"]}}, "c9d7b1f9b13d6ea4ff45b908285cc65af959cc5b": {"id": "c9d7b1f9b13d6ea4ff45b908285cc65af959cc5b", "content": {"title": "Applying Probability Measures to Abstract Languages", "abstract": "The problem of assigning a probability to each word of a language is considered. Two methods are discussed. One method assigns a probability to a word on the basis of particular measurable features of the language. The second method is applied to languages L(G) generated by a grammar G. A probability is associated with each production of G. These in turn define the word probabilities of each word in the language. The conditions for this assignment to be a probabilistic measure are derived.", "year": 1973, "ssId": "c9d7b1f9b13d6ea4ff45b908285cc65af959cc5b", "arXivId": null, "link": "https://ieeexplore.ieee.org/document/1672339", "openAccess": false, "authors": ["T. Booth", "Richarda . Thompson"]}}, "3ce0f00d6c949192107f1bd6a167c03e1fb7393a": {"id": "3ce0f00d6c949192107f1bd6a167c03e1fb7393a", "content": {"title": "An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing", "abstract": "We present a novel deterministic dependency parsing algorithm that attempts to create the easiest arcs in the dependency structure first in a non-directional manner. Traditional deterministic parsing algorithms are based on a shift-reduce framework: they traverse the sentence from left-to-right and, at each step, perform one of a possible set of actions, until a complete tree is built. A drawback of this approach is that it is extremely local: while decisions can be based on complex structures on the left, they can look only at a few words to the right. In contrast, our algorithm builds a dependency tree by iteratively selecting the best pair of neighbours to connect at each parsing step. This allows incorporation of features from already built structures both to the left and to the right of the attachment point. The parser learns both the attachment preferences and the order in which they should be performed. The result is a deterministic, best-first, O(nlogn) parser, which is significantly more accurate than best-first transition based parsers, and nears the performance of globally optimized parsing models.", "year": 2010, "ssId": "3ce0f00d6c949192107f1bd6a167c03e1fb7393a", "arXivId": null, "link": "https://aclanthology.org/N10-1115.pdf", "openAccess": true, "authors": ["Yoav Goldberg", "Michael Elhadad"]}}, "bd6018632a360cb567da8e50e1717ff526503845": {"id": "bd6018632a360cb567da8e50e1717ff526503845", "content": {"title": "Conditional Poisson Stochastic Beams", "abstract": "Beam search is the default decoding strategy for many sequence generation tasks in NLP. The set of approximate K-best items returned by the algorithm is a useful summary of the distribution for many applications; however, the candidates typically exhibit high overlap and may give a highly biased estimate for expectations under our model. These problems can be addressed by instead using stochastic decoding strategies. In this work, we propose a new method for turning beam search into a stochastic process: Conditional Poisson stochastic beam search. Rather than taking the maximizing set at each iteration, we sample K candidates without replacement according to the conditional Poisson sampling design. We view this as a more natural alternative to Kool et al. (2019)\u2019s stochastic beam search (SBS). Furthermore, we show how samples generated under the CPSBS design can be used to build consistent estimators and sample diverse sets from sequence models. In our experiments, we observe CPSBS produces lower variance and more efficient estimators than SBS, even showing improvements in high entropy settings.", "year": 2021, "ssId": "bd6018632a360cb567da8e50e1717ff526503845", "arXivId": null, "link": "https://aclanthology.org/2021.emnlp-main.52.pdf", "openAccess": true, "authors": ["Clara Meister", "Afra Amini", "Tim Vieira", "Ryan Cotterell"]}}, "b6c4a96e09b9f11e7c70e7f1fbe3f3971b92762d": {"id": "b6c4a96e09b9f11e7c70e7f1fbe3f3971b92762d", "content": {"title": "FUDGE: Controlled Text Generation With Future Discriminators", "abstract": "We propose Future Discriminators for Generation (FUDGE), a flexible and modular method for controlled text generation. Given a pre-existing model G for generating text from a distribution of interest, FUDGE enables conditioning on a desired attribute a (for example, formality) while requiring access only to G\u2019s output logits. FUDGE learns an attribute predictor operating on a partial sequence, and uses this predictor\u2019s outputs to adjust G\u2019s original probabilities. We show that FUDGE models terms corresponding to a Bayesian decomposition of the conditional distribution of G given attribute a. Moreover, FUDGE can easily compose predictors for multiple desired attributes. We evaluate FUDGE on three tasks \u2014 couplet completion in poetry, topic control in language generation, and formality change in machine translation \u2014 and observe gains in all three tasks.", "year": 2021, "ssId": "b6c4a96e09b9f11e7c70e7f1fbe3f3971b92762d", "arXivId": "2104.05218", "link": "https://arxiv.org/pdf/2104.05218.pdf", "openAccess": true, "authors": ["Kevin Yang", "D. Klein"]}}, "981152cb3f1e11c9cee6af2275b57ef79c621934": {"id": "981152cb3f1e11c9cee6af2275b57ef79c621934", "content": {"title": "Improving Diversity of Neural Text Generation via Inverse Probability Weighting", "abstract": "The neural network based text generation suffers from the text degeneration issue such as repetition. Although top-k sampling and nucleus sampling outperform beam search based decoding methods, they only focus on truncating the \u201ctail\u201d of the distribution and do not address the \u201chead\u201d part, which we show might contain tedious or even repetitive candidates with high probability that lead to repetition loops. They also do not fully address the issue that human text does not always favor high probability words. To explore improved diversity for text generation, we propose a heuristic sampling method inspired by inverse probability weighting. We propose to use interquartile range of the predicted distribution to determine the \u201chead\u201d part, then permutate and rescale the \u201chead\u201d with inverse probability. This aims at decreasing the probability for the tedious and possibly repetitive candidates with higher probability, and increasing the probability for the rational but more surprising candidates with lower probability. The proposed algorithm provides a controllable variation on the predicted distribution which enhances diversity without compromising rationality of the distribution. We use pre-trained language model to compare our algorithm with nucleus sampling. Results show that our algorithm can effectively increase the diversity of generated samples while achieving close resemblance to human text.", "year": 2021, "ssId": "981152cb3f1e11c9cee6af2275b57ef79c621934", "arXivId": "2103.07649", "link": "https://arxiv.org/pdf/2103.07649.pdf", "openAccess": true, "authors": ["Xinran Zhang", "Maosong Sun", "Jiafeng Liu", "Xiaobing Li"]}}, "f49065750931c1c3c9edaf7d2f4bc8ea1342450a": {"id": "f49065750931c1c3c9edaf7d2f4bc8ea1342450a", "content": {"title": "Characterizing and addressing the issue of oversmoothing in neural autoregressive sequence modeling", "abstract": "Neural autoregressive sequence models smear the probability among many possible sequences including degenerate ones, such as empty or repetitive sequences. In this work, we tackle one specific case where the model assigns a high probability to unreasonably short sequences. We define the oversmoothing rate to quantify this issue. After confirming the high degree of oversmoothing in neural machine translation, we propose to explicitly minimize the oversmoothing rate during training. We conduct a set of experiments to study the effect of the proposed regularization on both model distribution and decoding performance. We use a neural machine translation task as the testbed and consider three different datasets of varying size. Our experiments reveal three major findings. First, we can control the oversmoothing rate of the model by tuning the strength of the regularization. Second, by enhancing the oversmoothing loss contribution, the probability and the rank of \u3008eos\u3009 token decrease heavily at positions where it is not supposed to be. Third, the proposed regularization impacts the outcome of beam search especially when a large beam is used. The degradation of translation quality (measured in BLEU) with a large beam significantly lessens with lower oversmoothing rate, but the degradation compared to smaller beam sizes remains to exist. From these observations, we conclude that the high degree of oversmoothing is the main reason behind the degenerate case of overly probable short sequences in a neural autoregressive model.", "year": 2021, "ssId": "f49065750931c1c3c9edaf7d2f4bc8ea1342450a", "arXivId": "2112.08914", "link": "https://arxiv.org/pdf/2112.08914.pdf", "openAccess": true, "authors": ["Ilia Kulikov", "M. Eremeev", "Kyunghyun Cho"]}}, "ca9047c78d48b606c4e4f0c456b1dda550de28b2": {"id": "ca9047c78d48b606c4e4f0c456b1dda550de28b2", "content": {"title": "Combining Recurrent, Convolutional, and Continuous-time Models with Linear State-Space Layers", "abstract": "Recurrent neural networks (RNNs), temporal convolutions, and neural differential equations (NDEs) are popular families of deep learning models for time-series data, each with unique strengths and tradeoffs in modeling power and computational efficiency. We introduce a simple sequence model inspired by control systems that generalizes these approaches while addressing their shortcomings. The Linear State-Space Layer (LSSL) maps a sequence u 7\u2192 y by simply simulating a linear continuous-time state-space representation \u1e8b = Ax+ Bu, y = Cx+Du. Theoretically, we show that LSSL models are closely related to the three aforementioned families of models and inherit their strengths. For example, they generalize convolutions to continuous-time, explain common RNN heuristics, and share features of NDEs such as time-scale adaptation. We then incorporate and generalize recent theory on continuous-time memorization to introduce a trainable subset of structured matrices A that endow LSSLs with long-range memory. Empirically, stacking LSSL layers into a simple deep neural network obtains state-of-the-art results across time series benchmarks for long dependencies in sequential image classification, real-world healthcare regression tasks, and speech. On a difficult speech classification task with length-16000 sequences, LSSL outperforms prior approaches by 24 accuracy points, and even outperforms baselines that use handcrafted features on 100x shorter sequences.", "year": 2021, "ssId": "ca9047c78d48b606c4e4f0c456b1dda550de28b2", "arXivId": "2110.13985", "link": "https://arxiv.org/pdf/2110.13985.pdf", "openAccess": true, "authors": ["Albert Gu", "Isys Johnson", "Karan Goel", "Khaled Kamal Saab", "Tri Dao", "A. Rudra", "Christopher R'e"]}}, "3ee38da21d8cf9cb7d4077b729e57f68e9c8d671": {"id": "3ee38da21d8cf9cb7d4077b729e57f68e9c8d671", "content": {"title": "Text Generation by Learning from Demonstrations", "abstract": "Current approaches to text generation largely rely on autoregressive models and maximum likelihood estimation. This paradigm leads to (i) diverse but low-quality samples due to mismatched learning objective and evaluation metric (likelihood vs. quality) and (ii) exposure bias due to mismatched history distributions (gold vs. model-generated). To alleviate these problems, we frame text generation as an offline reinforcement learning (RL) problem with expert demonstrations (i.e., the reference), where the goal is to maximize quality given model-generated histories. We propose GOLD (generation by off-policy learning from demonstrations): an easy-to-optimize algorithm that learns from the demonstrations by importance weighting. Intuitively, GOLD upweights confident tokens and downweights unconfident ones in the reference during training, avoiding optimization issues faced by prior RL approaches that rely on online data collection. According to both automatic and human evaluation, models trained by GOLD outperform those trained by MLE and policy gradient on summarization, question generation, and machine translation. Further, our models are less sensitive to decoding algorithms and alleviate exposure bias.", "year": 2020, "ssId": "3ee38da21d8cf9cb7d4077b729e57f68e9c8d671", "arXivId": "2009.07839", "link": "https://arxiv.org/pdf/2009.07839.pdf", "openAccess": true, "authors": ["Richard Yuanzhe Pang", "He He"]}}, "61cd4ffdaf2c0daa3d432ff9fecdd064d6e72886": {"id": "61cd4ffdaf2c0daa3d432ff9fecdd064d6e72886", "content": {"title": "Diagnosing the First-Order Logical Reasoning Ability Through LogicNLI", "abstract": "Recently, language models (LMs) have achieved significant performance on many NLU tasks, which has spurred widespread interest for their possible applications in the scientific and social area. However, LMs have faced much criticism of whether they are truly capable of reasoning in NLU. In this work, we propose a diagnostic method for first-order logic (FOL) reasoning with a new proposed benchmark, LogicNLI. LogicNLI is an NLI-style dataset that effectively disentangles the target FOL reasoning from commonsense inference and can be used to diagnose LMs from four perspectives: accuracy, robustness, generalization, and interpretability. Experiments on BERT, RoBERTa, and XLNet, have uncovered the weaknesses of these LMs on FOL reasoning, which motivates future exploration to enhance the reasoning ability.", "year": 2021, "ssId": "61cd4ffdaf2c0daa3d432ff9fecdd064d6e72886", "arXivId": null, "link": "https://aclanthology.org/2021.emnlp-main.303.pdf", "openAccess": true, "authors": ["Jidong Tian", "Yitian Li", "Wenqing Chen", "Liqiang Xiao", "Hao He", "Yaohui Jin"]}}, "01a21d74fb7414404851872f23cdca42243ab6a8": {"id": "01a21d74fb7414404851872f23cdca42243ab6a8", "content": {"title": "Progressive Transfer Learning", "abstract": "Model fine-tuning is a widely used transfer learning approach in person Re-identification (ReID) applications, which fine-tuning a pre-trained feature extraction model into the target scenario instead of training a model from scratch. It is challenging due to the significant variations inside the target scenario, e.g., different camera viewpoint, illumination changes, and occlusion. These variations result in a gap between each mini-batch\u2019s distribution and the whole dataset\u2019s distribution when using mini-batch training. In this paper, we study model fine-tuning from the perspective of the aggregation and utilization of the dataset\u2019s global information when using mini-batch training. Specifically, we introduce a novel network structure called Batch-related Convolutional Cell (BConv-Cell), which progressively collects the dataset\u2019s global information into a latent state and uses it to rectify the extracted feature. Based on BConv-Cells, we further proposed the Progressive Transfer Learning (PTL) method to facilitate the model fine-tuning process by jointly optimizing BConv-Cells and the pre-trained ReID model. Empirical experiments show that our proposal can greatly improve the ReID model\u2019s performance on MSMT17, Market-1501, CUHK03, and DukeMTMC-reID datasets. Moreover, we extend our proposal to the general image classification task. The experiments in several image classification benchmark datasets demonstrate that our proposal can significantly improve baseline models\u2019 performance. The code has been released at https://github.com/ZJULearning/PTL", "year": 2020, "ssId": "01a21d74fb7414404851872f23cdca42243ab6a8", "arXivId": "1908.02492", "link": "https://arxiv.org/pdf/1908.02492.pdf", "openAccess": true, "authors": ["Zhengxu Yu", "Dong Shen", "Zhongming Jin", "Jianqiang Huang", "Deng Cai", "Xiansheng Hua"]}}, "99053e3a708fc27709c9dab33110dc98b187c158": {"id": "99053e3a708fc27709c9dab33110dc98b187c158", "content": {"title": "FinQA: A Dataset of Numerical Reasoning over Financial Data", "abstract": "The sheer volume of financial statements makes it difficult for humans to access and analyze a business\u2019s financials. Robust numerical reasoning likewise faces unique challenges in this domain. In this work, we focus on answering deep questions over financial data, aiming to automate the analysis of a large corpus of financial documents. In contrast to existing tasks on general domain, the finance domain includes complex numerical reasoning and understanding of heterogeneous representations. To facilitate analytical progress, we propose a new large-scale dataset, FinQA, with Question-Answering pairs over Financial reports, written by financial experts. We also annotate the gold reasoning programs to ensure full explainability. We further introduce baselines and conduct comprehensive experiments in our dataset. The results demonstrate that popular, large, pre-trained models fall far short of expert humans in acquiring finance knowledge and in complex multi-step numerical reasoning on that knowledge. Our dataset \u2013 the first of its kind \u2013 should therefore enable significant, new community research into complex application domains. The dataset and code are publicly available at https://github.com/czyssrs/FinQA.", "year": 2021, "ssId": "99053e3a708fc27709c9dab33110dc98b187c158", "arXivId": "2109.00122", "link": "https://arxiv.org/pdf/2109.00122.pdf", "openAccess": true, "authors": ["Zhiyu Chen", "Wenhu Chen", "Charese Smiley", "Sameena Shah", "Iana Borova", "Dylan Langdon", "Reema Moussa", "Matthew I. Beane", "T. Huang", "Bryan R. Routledge", "W. Wang"]}}, "6e3f8187f8fef3e11578a73f32da07d33dbf8235": {"id": "6e3f8187f8fef3e11578a73f32da07d33dbf8235", "content": {"title": "DART: Open-Domain Structured Data Record to Text Generation", "abstract": "We present DART, an open domain structured DAta Record to Text generation dataset with over 82k instances (DARTs). Data-to-text annotations can be a costly process, especially when dealing with tables which are the major source of structured data and contain nontrivial structures. To this end, we propose a procedure of extracting semantic triples from tables that encodes their structures by exploiting the semantic dependencies among table headers and the table title. Our dataset construction framework effectively merged heterogeneous sources from open domain semantic parsing and spoken dialogue systems by utilizing techniques including tree ontology annotation, question-answer pair to declarative sentence conversion, and predicate unification, all with minimum post-editing. We present systematic evaluation on DART as well as new state-of-the-art results on WebNLG 2017 to show that DART (1) poses new challenges to existing data-to-text datasets and (2) facilitates out-of-domain generalization. Our data and code can be found at https://github.com/Yale-LILY/dart.", "year": 2020, "ssId": "6e3f8187f8fef3e11578a73f32da07d33dbf8235", "arXivId": "2007.02871", "link": "https://arxiv.org/pdf/2007.02871.pdf", "openAccess": true, "authors": ["Dragomir Radev", "Rui Zhang", "Amrit Rau", "Abhinand Sivaprasad", "Chia-Hsuan Hsieh", "Nazneen Rajani", "Xiangru Tang", "Aadit Vyas", "Neha Verma", "P. Krishna", "Yangxiaokang Liu", "Nadia Irwanto", "Jessica Pan", "Faiaz Rahman", "Ahmad Zaidi", "Murori Mutuma", "Yasin Tarabar", "Ankit Gupta", "Tao Yu", "Y. Tan", "Xi Victoria Lin", "Caiming Xiong", "R. Socher"]}}, "927efd299cffcfca3716efefcc904331b70c153e": {"id": "927efd299cffcfca3716efefcc904331b70c153e", "content": {"title": "NOAHQA: Numerical Reasoning with Interpretable Graph Question Answering Dataset", "abstract": "While diverse question answering (QA) datasets have been proposed and contributed significantly to the development of deep learning models for QA tasks, the existing datasets fall short in two aspects. First, we lack QA datasets covering complex questions that involve answers as well as the reasoning processes to get the answers. As a result, the state-of-the-art QA research on numerical reasoning still focuses on simple calculations and does not provide the mathematical expressions or evidences justifying the answers. Second, the QA community has contributed much effort to improving the interpretability of QA models. However, these models fail to explicitly show the reasoning process, such as the evidence order for reasoning and the interactions between different pieces of evidence. To address the above shortcomings, we introduce NOAHQA, a conversational and bilingual QA dataset with questions requiring numerical reasoning with compound mathematical expressions. With NOAHQA, we develop an interpretable reasoning graph as well as the appropriate evaluation metric to measure the answer quality. We evaluate the state-of-the-art QA models trained using existing QA datasets on NOAHQA and show that the best among them can only achieve 55.5 exact match scores, while the human performance is 89.7. We also present a new QA model for generating a reasoning graph where the reasoning graph metric still has a large gap compared with that of humans, e.g., 28 scores. The dataset and code are publicly available 1.", "year": 2021, "ssId": "927efd299cffcfca3716efefcc904331b70c153e", "arXivId": "2109.10604", "link": "https://arxiv.org/pdf/2109.10604.pdf", "openAccess": true, "authors": ["Qiyuan Zhang", "Lei Wang", "S. Yu", "Shuohang Wang", "Yang Wang", "Jing Jiang", "Ee-Peng Lim"]}}, "3e3f55cb25b919c4e8158195fd3ce2f23cfa7723": {"id": "3e3f55cb25b919c4e8158195fd3ce2f23cfa7723", "content": {"title": "Counterfactual VQA: A Cause-Effect Look at Language Bias", "abstract": "VQA models may tend to rely on language bias as a shortcut and thus fail to sufficiently learn the multi-modal knowledge from both vision and language. Recent debiasing methods proposed to exclude the language prior during inference. However, they fail to disentangle the \"good\" language context and \"bad\" language bias from the whole. In this paper, we investigate how to mitigate language bias in VQA. Motivated by causal effects, we proposed a novel counterfactual inference framework, which enables us to capture the language bias as the direct causal effect of questions on answers and reduce the language bias by subtracting the direct language effect from the total causal effect. Experiments demonstrate that our proposed counterfactual inference framework 1) is general to various VQA backbones and fusion strategies, 2) achieves competitive performance on the language-bias sensitive VQA-CP dataset while performs robustly on the balanced VQA v2 dataset without any augmented data. The code is available at https://github.com/yuleiniu/cfvqa.", "year": 2020, "ssId": "3e3f55cb25b919c4e8158195fd3ce2f23cfa7723", "arXivId": "2006.04315", "link": "https://arxiv.org/pdf/2006.04315.pdf", "openAccess": true, "authors": ["Yulei Niu", "Kaihua Tang", "Hanwang Zhang", "Zhiwu Lu", "Xiansheng Hua", "Ji-rong Wen"]}}, "6aecc93c2d61da073b70dec19795172ca1ff3405": {"id": "6aecc93c2d61da073b70dec19795172ca1ff3405", "content": {"title": "Counterfactual Invariance to Spurious Correlations: Why and How to Pass Stress Tests", "abstract": "Informally, a \u2018spurious correlation\u2019 is the dependence of a model on some aspect of the input data that an analyst thinks shouldn\u2019t matter. In machine learning, these have a know-it-when-you-see-it character; e.g., changing the gender of a sentence\u2019s subject changes a sentiment predictor\u2019s output. To check for spurious correlations, we can \u2018stress test\u2019 models by perturbing irrelevant parts of input data and seeing if model predictions change. In this paper, we study stress testing using the tools of causal inference. We introduce counterfactual invariance as a formalization of the requirement that changing irrelevant parts of the input shouldn\u2019t change model predictions. We connect counterfactual invariance to outof-domain model performance, and provide practical schemes for learning (approximately) counterfactual invariant predictors (without access to counterfactual examples). It turns out that both the means and implications of counterfactual invariance depend fundamentally on the true underlying causal structure of the data\u2014in particular, whether the label causes the features or the features cause the label. Distinct causal structures require distinct regularization schemes to induce counterfactual invariance. Similarly, counterfactual invariance implies different domain shift guarantees depending on the underlying causal structure. This theory is supported by empirical results on text classification.", "year": 2021, "ssId": "6aecc93c2d61da073b70dec19795172ca1ff3405", "arXivId": "2106.00545", "link": "https://arxiv.org/pdf/2106.00545.pdf", "openAccess": true, "authors": ["Victor Veitch", "A. D'Amour", "S. Yadlowsky", "Jacob Eisenstein"]}}, "7b99c51d562e33309a46601c846abbe72a65c6a4": {"id": "7b99c51d562e33309a46601c846abbe72a65c6a4", "content": {"title": "What to Pre-Train on? Efficient Intermediate Task Selection", "abstract": "Intermediate task fine-tuning has been shown to culminate in large transfer gains across many NLP tasks. With an abundance of candidate datasets as well as pre-trained language models, it has become infeasible to experiment with all combinations to find the best transfer setting. In this work, we provide a comprehensive comparison of different methods for efficiently identifying beneficial tasks for intermediate transfer learning. We focus on parameter and computationally efficient adapter settings, highlight different data-availability scenarios, and provide expense estimates for each method. We experiment with a diverse set of 42 intermediate and 11 target English classification, multiple choice, question answering, and sequence tagging tasks. Our results demonstrate that efficient embedding based methods, which rely solely on the respective datasets, outperform computational expensive few-shot fine-tuning approaches. Our best methods achieve an average Regret@3 of 1% across all target tasks, demonstrating that we are able to efficiently identify the best datasets for intermediate training.", "year": 2021, "ssId": "7b99c51d562e33309a46601c846abbe72a65c6a4", "arXivId": "2104.08247", "link": "https://arxiv.org/pdf/2104.08247.pdf", "openAccess": true, "authors": ["Clifton Poth", "Jonas Pfeiffer", "Andreas Ruckl'e", "Iryna Gurevych"]}}, "ed535e93d5b5a8b689e861e9c6083a806d1535c2": {"id": "ed535e93d5b5a8b689e861e9c6083a806d1535c2", "content": {"title": "The Devil is in the Detail: Simple Tricks Improve Systematic Generalization of Transformers", "abstract": "Recently, many datasets have been proposed to test the systematic generalization ability of neural networks. The companion baseline Transformers, typically trained with default hyper-parameters from standard tasks, are shown to fail dramatically. Here we demonstrate that by revisiting model configurations as basic as scaling of embeddings, early stopping, relative positional embedding, and Universal Transformer variants, we can drastically improve the performance of Transformers on systematic generalization. We report improvements on five popular datasets: SCAN, CFQ, PCFG, COGS, and Mathematics dataset. Our models improve accuracy from 50% to 85% on the PCFG productivity split, and from 35% to 81% on COGS. On SCAN, relative positional embedding largely mitigates the EOS decision problem (Newman et al., 2020), yielding 100% accuracy on the length split with a cutoff at 26. Importantly, performance differences between these models are typically invisible on the IID data split. This calls for proper generalization validation sets for developing neural networks that generalize systematically. We publicly release the code to reproduce our results.", "year": 2021, "ssId": "ed535e93d5b5a8b689e861e9c6083a806d1535c2", "arXivId": "2108.12284", "link": "https://arxiv.org/pdf/2108.12284.pdf", "openAccess": true, "authors": ["R'obert Csord'as", "Kazuki Irie", "J. Schmidhuber"]}}, "4c6f7fb5c2e1bd12899c3ec2788f9ce7eb2f8a5c": {"id": "4c6f7fb5c2e1bd12899c3ec2788f9ce7eb2f8a5c", "content": {"title": "How much pretraining data do language models need to learn syntax?", "abstract": "Transformers-based pretrained language models achieve outstanding results in many well-known NLU benchmarks. However, while pretraining methods are very convenient, they are expensive in terms of time and resources. This calls for a study of the impact of pretraining data size on the knowledge of the models. We explore this impact on the syntactic capabilities of RoBERTa, using models trained on incremental sizes of raw text data. First, we use syntactic structural probes to determine whether models pretrained on more data encode a higher amount of syntactic information. Second, we perform a targeted syntactic evaluation to analyze the impact of pretraining data size on the syntactic generalization performance of the models. Third, we compare the performance of the different models on three downstream applications: part-of-speech tagging, dependency parsing and paraphrase identification. We complement our study with an analysis of the cost-benefit trade-off of training such models. Our experiments show that while models pretrained on more data encode more syntactic knowledge and perform better on downstream applications, they do not always offer a better performance across the different syntactic phenomena and come at a higher financial and environmental cost.", "year": 2021, "ssId": "4c6f7fb5c2e1bd12899c3ec2788f9ce7eb2f8a5c", "arXivId": "2109.03160", "link": "https://arxiv.org/pdf/2109.03160.pdf", "openAccess": true, "authors": ["Laura P\u00e9rez-Mayos", "Miguel Ballesteros", "L. Wanner"]}}, "840fabc2a7773e1bd771f152f76210b2ea5845b9": {"id": "840fabc2a7773e1bd771f152f76210b2ea5845b9", "content": {"title": "Conditional Poisson Stochastic Beam Search", "abstract": "Beam search is the default decoding strategy for many sequence generation tasks in NLP. The set of approximate K-best items returned by the algorithm is a useful summary of the distribution for many applications; however, the candidates typically exhibit high overlap and may give a highly biased estimate for expectations under our model. These problems can be addressed by instead using stochastic decoding strategies. In this work, we propose a new method for turning beam search into a stochastic process: Conditional Poisson stochastic beam search. Rather than taking the maximizing set at each iteration, we sampleK candidates without replacement according to the conditional Poisson sampling design. We view this as a more natural alternative to Kool et al. (2019)\u2019s stochastic beam search (SBS). Furthermore, we show how samples generated under the CPSBS design can be used to build consistent estimators and sample diverse sets from sequence models. In our experiments, we observe CPSBS produces lower variance and more efficient estimators than SBS, even showing improvements in high entropy settings.1", "year": 2021, "ssId": "840fabc2a7773e1bd771f152f76210b2ea5845b9", "arXivId": "2109.11034", "link": "https://arxiv.org/pdf/2109.11034.pdf", "openAccess": true, "authors": ["Clara Meister", "Afra Amini", "Tim Vieira", "Ryan Cotterell"]}}, "ceef266c59698999c9283a0cda852d8bc1ce27ea": {"id": "ceef266c59698999c9283a0cda852d8bc1ce27ea", "content": {"title": "How Does Fine-tuning Affect the Geometry of Embedding Space: A Case Study on Isotropy", "abstract": "It is widely accepted that fine-tuning pretrained language models usually brings about performance improvements in downstream tasks. However, there are limited studies on the reasons behind this effectiveness, particularly from the viewpoint of structural changes in the embedding space. Trying to fill this gap, in this paper, we analyze the extent to which the isotropy of the embedding space changes after fine-tuning. We demonstrate that, even though isotropy is a desirable geometrical property, fine-tuning does not necessarily result in isotropy enhancements. Moreover, local structures in pre-trained contextual word representations (CWRs), such as those encoding token types or frequency, undergo a massive change during fine-tuning. Our experiments show dramatic growth in the number of elongated directions in the embedding space, which, in contrast to pre-trained CWRs, carry the essential linguistic knowledge in the fine-tuned embedding space, making existing isotropy enhancement methods ineffective.", "year": 2021, "ssId": "ceef266c59698999c9283a0cda852d8bc1ce27ea", "arXivId": "2109.04740", "link": "https://arxiv.org/pdf/2109.04740.pdf", "openAccess": true, "authors": ["S. Rajaee", "Mohammad Taher Pilehvar"]}}, "680e61a17e27a1e8e121276c7ec53fc4fd40babb": {"id": "680e61a17e27a1e8e121276c7ec53fc4fd40babb", "content": {"title": "Revisiting the Uniform Information Density Hypothesis", "abstract": "The uniform information density (UID) hypothesis posits a preference among language users for utterances structured such that information is distributed uniformly across a signal. While its implications on language production have been well explored, the hypothesis potentially makes predictions about language comprehension and linguistic acceptability as well. Further, it is unclear how uniformity in a linguistic signal\u2014or lack thereof\u2014should be measured, and over which linguistic unit, e.g., the sentence or language level, this uniformity should hold. Here we investigate these facets of the UID hypothesis using reading time and acceptability data. While our reading time results are generally consistent with previous work, they are also consistent with a weakly super-linear effect of surprisal, which would be compatible with UID\u2019s predictions. For acceptability judgments, we find clearer evidence that non-uniformity in information density is predictive of lower acceptability. We then explore multiple operationalizations of UID, motivated by different interpretations of the original hypothesis, and analyze the scope over which the pressure towards uniformity is exerted. The explanatory power of a subset of the proposed operationalizations suggests that the strongest trend may be a regression towards a mean surprisal across the language, rather than the phrase, sentence, or document\u2014a finding that supports a typical interpretation of UID, namely that it is the byproduct of language users maximizing the use of a (hypothetical) communication channel.", "year": 2021, "ssId": "680e61a17e27a1e8e121276c7ec53fc4fd40babb", "arXivId": "2109.11635", "link": "https://arxiv.org/pdf/2109.11635.pdf", "openAccess": true, "authors": ["Clara Meister", "Tiago Pimentel", "Patrick Haller", "Lena Jager", "Ryan Cotterell", "R. Levy"]}}, "a5881560968963d0c845c468a273261fde0b7248": {"id": "a5881560968963d0c845c468a273261fde0b7248", "content": {"title": "Perturbing Inputs for Fragile Interpretations in Deep Natural Language Processing", "abstract": "Interpretability methods like Integrated Gradient and LIME are popular choices for explaining natural language model predictions with relative word importance scores. These interpretations need to be robust for trustworthy NLP applications in high-stake areas like medicine or finance. Our paper demonstrates how interpretations can be manipulated by making simple word perturbations on an input text. Via a small portion of word-level swaps, these adversarial perturbations aim to make the resulting text semantically and spatially similar to its seed input (therefore sharing similar interpretations). Simultaneously, the generated examples achieve the same prediction label as the seed yet are given a substantially different explanation by the interpretation methods. Our experiments generate fragile interpretations to attack two SOTA interpretation methods, across three popular Transformer models and on three different NLP datasets. We observe that the rank order correlation and top-K intersection score drops by over 20% when less than 10% of words are perturbed on average. Further, rank-order correlation keeps decreasing as more words get perturbed. Furthermore, we demonstrate that candidates generated from our method have good quality metrics.", "year": 2021, "ssId": "a5881560968963d0c845c468a273261fde0b7248", "arXivId": "2108.04990", "link": "https://arxiv.org/pdf/2108.04990.pdf", "openAccess": true, "authors": ["Sanchit Sinha", "Hanjie Chen", "Arshdeep Sekhon", "Yangfeng Ji", "Yanjun Qi"]}}, "c1d0e73ec3aaf7ffdcbe41835d649d638cbc2f2d": {"id": "c1d0e73ec3aaf7ffdcbe41835d649d638cbc2f2d", "content": {"title": "Consistent Accelerated Inference via Confident Adaptive Transformers", "abstract": "We develop a novel approach for confidently accelerating inference in the large and expensive multilayer Transformers that are now ubiquitous in natural language processing (NLP). Amortized or approximate computational methods increase efficiency, but can come with unpredictable performance costs. In this work, we present CATs \u2013 Confident Adaptive Transformers \u2013 in which we simultaneously increase computational efficiency, while guaranteeing a specifiable degree of consistency with the original model with high confidence. Our method trains additional prediction heads on top of intermediate layers, and dynamically decides when to stop allocating computational effort to each input using a meta consistency classifier. To calibrate our early prediction stopping rule, we formulate a unique extension of conformal prediction. We demonstrate the effectiveness of this approach on four classification and regression tasks.", "year": 2021, "ssId": "c1d0e73ec3aaf7ffdcbe41835d649d638cbc2f2d", "arXivId": "2104.08803", "link": "https://arxiv.org/pdf/2104.08803.pdf", "openAccess": true, "authors": ["Tal Schuster", "Adam Fisch", "T. Jaakkola", "R. Barzilay"]}}, "275aaa20ba853c40a461f224eefbf06730bf03a9": {"id": "275aaa20ba853c40a461f224eefbf06730bf03a9", "content": {"title": "Escape saddle points by a simple gradient-descent based algorithm", "abstract": "Escaping saddle points is a central research topic in nonconvex optimization. In this paper, we propose a simple gradient-based algorithm such that for a smooth function f : Rn ! R, it outputs an \u270f-approximate second-order stationary point in \u00d5(log n/\u270f1.75) iterations. Compared to the previous state-of-the-art algorithms by Jin et al. with \u00d5(log n/\u270f2) or \u00d5(log n/\u270f1.75) iterations, our algorithm is polynomially better in terms of log n and matches their complexities in terms of 1/\u270f. For the stochastic setting, our algorithm outputs an \u270f-approximate second-order stationary point in \u00d5(log n/\u270f4) iterations. Technically, our main contribution is an idea of implementing a robust Hessian power method using only gradients, which can find negative curvature near saddle points and achieve the polynomial speedup in log n compared to the perturbed gradient descent methods. Finally, we also perform numerical experiments that support our results.", "year": 2021, "ssId": "275aaa20ba853c40a461f224eefbf06730bf03a9", "arXivId": "2111.14069", "link": "https://arxiv.org/pdf/2111.14069.pdf", "openAccess": true, "authors": ["Chenyi Zhang", "Tongyang Li"]}}, "1808b64aec21863489f0fe66f250890a3ac2b843": {"id": "1808b64aec21863489f0fe66f250890a3ac2b843", "content": {"title": "Our Data, Ourselves: Privacy Via Distributed Noise Generation", "abstract": "In this work we provide efficient distributed protocols for generating shares of random noise, secure against malicious participants. The purpose of the noise generation is to create a distributed implementation of the privacy-preserving statistical databases described in recent papers [14,4,13]. In these databases, privacy is obtained by perturbing the true answer to a database query by the addition of a small amount of Gaussian or exponentially distributed random noise. The computational power of even a simple form of these databases, when the query is just of the form \u2211if(di), that is, the sum over all rows i in the database of a function f applied to the data in row i, has been demonstrated in [4]. A distributed implementation eliminates the need for a trusted database administrator. \n \nThe results for noise generation are of independent interest. The generation of Gaussian noise introduces a technique for distributing shares of many unbiased coins with fewer executions of verifiable secret sharing than would be needed using previous approaches (reduced by a factor of n). The generation of exponentially distributed noise uses two shallow circuits: one for generating many arbitrarily but identically biased coins at an amortized cost of two unbiased random bits apiece, independent of the bias, and the other to combine bits of appropriate biases to obtain an exponential distribution.", "year": 2006, "ssId": "1808b64aec21863489f0fe66f250890a3ac2b843", "arXivId": null, "link": "https://www.iacr.org/archive/eurocrypt2006/40040493/40040493.pdf", "openAccess": true, "authors": ["C. Dwork", "K. Kenthapadi", "Frank McSherry", "Ilya Mironov", "M. Naor"]}}, "b293e4659e20815bcf0b6d31ce46b8bd9437c1fa": {"id": "b293e4659e20815bcf0b6d31ce46b8bd9437c1fa", "content": {"title": "When Machine Learning Meets Privacy: A Survey and Outlook", "abstract": "The newly emerged machine learning (e.g. deep learning) methods have become a strong driving force to revolutionize a wide range of industries, such as smart healthcare, financial technology, and surveillance systems. Meanwhile, privacy has emerged as a big concern in this machine learning-based artificial intelligence era. It is important to note that the problem of privacy preservation in the context of machine learning is quite different from that in traditional data privacy protection, as machine learning can act as both friend and foe. Currently, the work on the preservation of privacy and machine learning (ML) is still in an infancy stage, as most existing solutions only focus on privacy problems during the machine learning process. Therefore, a comprehensive study on the privacy preservation problems and machine learning is required. This paper surveys the state of the art in privacy issues and solutions for machine learning. The survey covers three categories of interactions between privacy and machine learning: (i) private machine learning, (ii) machine learning aided privacy protection, and (iii) machine learning-based privacy attack and corresponding protection schemes. The current research progress in each category is reviewed and the key challenges are identified. Finally, based on our in-depth analysis of the area of privacy and machine learning, we point out future research directions in this field.", "year": 2020, "ssId": "b293e4659e20815bcf0b6d31ce46b8bd9437c1fa", "arXivId": "2011.11819", "link": "https://arxiv.org/pdf/2011.11819.pdf", "openAccess": true, "authors": ["B. Liu", "Ming Ding", "Sina Shaham", "W. Rahayu", "F. Farokhi", "Zihuai Lin"]}}, "018bf5da2ba1f1901e98f72c7eedbf6b91967192": {"id": "018bf5da2ba1f1901e98f72c7eedbf6b91967192", "content": {"title": "Natural Language Understanding with Privacy-Preserving BERT", "abstract": "Privacy preservation remains a key challenge in data mining and Natural Language Understanding (NLU). Previous research shows that the input text or even text embeddings can leak private information. This concern motivates our research on effective privacy preservation approaches for pretrained Language Models (LMs). We investigate the privacy and utility implications of applying d\u03c7-privacy, a variant of Local Differential Privacy, to BERT fine-tuning in NLU applications. More importantly, we further propose privacy-adaptive LM pretraining methods and show that our approach can boost the utility of BERT dramatically while retaining the same level of privacy protection. We also quantify the level of privacy preservation and provide guidance on privacy configuration. Our experiments and findings lay the groundwork for future explorations of privacy-preserving NLU with pretrained LMs.", "year": 2021, "ssId": "018bf5da2ba1f1901e98f72c7eedbf6b91967192", "arXivId": "2104.07504", "link": "https://arxiv.org/pdf/2104.07504.pdf", "openAccess": true, "authors": ["Chen Qu", "Weize Kong", "Liu Yang", "Mingyang Zhang", "Michael Bendersky", "Marc-Alexander Najork"]}}, "53e0abebd9aef5915f72147d3674596a0051748c": {"id": "53e0abebd9aef5915f72147d3674596a0051748c", "content": {"title": "Data Protection in AI Services", "abstract": "Advances in artificial intelligence (AI) have shaped today\u2019s user services, enabling enhanced personalization and better support. As such AI-based services inevitably require user data, the resulting privacy implications are de facto the unacceptable face of this technology. In this article, we categorize and survey the cutting-edge research on privacy and data protection in the context of personalized AI services. We further review the different protection approaches at three different levels, namely, the management, system, and AI levels\u2014showing that (i) not all of them meet our identified requirements of evolving AI services and that (ii) many challenges are addressed separately or fragmentarily by different research communities. Finally, we highlight open research challenges and future directions in data protection research, especially that comprehensive protection requires more interdisciplinary research and a combination of approaches at different levels.", "year": 2021, "ssId": "53e0abebd9aef5915f72147d3674596a0051748c", "arXivId": null, "link": "https://dl.acm.org/doi/pdf/10.1145/3440754", "openAccess": true, "authors": ["Christian Meurisch", "Max M\u00fchlh\u00e4user"]}}, "425a4a9c0598e4101ca2f2b930f5c6986ce40a99": {"id": "425a4a9c0598e4101ca2f2b930f5c6986ce40a99", "content": {"title": "Privacy Regularization: Joint Privacy-Utility Optimization in LanguageModels", "abstract": "Neural language models are known to have a high capacity for memorization of training samples. This may have serious privacy im- plications when training models on user content such as email correspondence. Differential privacy (DP), a popular choice to train models with privacy guarantees, comes with significant costs in terms of utility degradation and disparate impact on subgroups of users. In this work, we introduce two privacy-preserving regularization methods for training language models that enable joint optimization of utility and privacy through (1) the use of a discriminator and (2) the inclusion of a novel triplet-loss term. We compare our methods with DP through extensive evaluation. We show the advantages of our regularizers with favorable utility-privacy trade-off, faster training with the ability to tap into existing optimization approaches, and ensuring uniform treatment of under-represented subgroups.", "year": 2021, "ssId": "425a4a9c0598e4101ca2f2b930f5c6986ce40a99", "arXivId": "2103.07567", "link": "https://arxiv.org/pdf/2103.07567.pdf", "openAccess": true, "authors": ["FatemehSadat Mireshghallah", "Huseyin A. Inan", "Marcello Hasegawa", "Victor Ruhle", "Taylor Berg-Kirkpatrick", "Robert Sim"]}}, "0dff2b00fd6e8e7b5f3c0707b0e51e3628988420": {"id": "0dff2b00fd6e8e7b5f3c0707b0e51e3628988420", "content": {"title": "Privacy-Aware Text Rewriting", "abstract": "Biased decisions made by automatic systems have led to growing concerns in research communities. Recent work from the NLP community focuses on building systems that make fair decisions based on text. Instead of relying on unknown decision systems or human decision-makers, we argue that a better way to protect data providers is to remove the trails of sensitive information before publishing the data. In light of this, we propose a new privacy-aware text rewriting task and explore two privacy-aware back-translation methods for the task, based on adversarial training and approximate fairness risk. Our extensive experiments on three real-world datasets with varying demographical attributes show that our methods are effective in obfuscating sensitive attributes. We have also observed that the fairness risk method retains better semantics and fluency, while the adversarial training method tends to leak less sensitive information.", "year": 2019, "ssId": "0dff2b00fd6e8e7b5f3c0707b0e51e3628988420", "arXivId": null, "link": "https://aclanthology.org/W19-8633.pdf", "openAccess": true, "authors": ["Qiongkai Xu", "Lizhen Qu", "Chenchen Xu", "Ran Cui"]}}, "3a95fab610d5ff49fbdb7a4d8760b02c51df0013": {"id": "3a95fab610d5ff49fbdb7a4d8760b02c51df0013", "content": {"title": "Using word embeddings to improve the privacy of clinical notes", "abstract": "Abstract Objective In this work, we introduce a privacy technique for anonymizing clinical notes that guarantees all private health information is secured (including sensitive data, such as family history, that are not adequately covered by current techniques). Materials and Methods We employ a new \u201crandom replacement\u201d paradigm (replacing each token in clinical notes with neighboring word vectors from the embedding space) to achieve 100% recall on the removal of sensitive information, unachievable with current \u201csearch-and-secure\u201d paradigms. We demonstrate the utility of this paradigm on multiple corpora in a diverse set of classification tasks. Results We empirically evaluate the effect of our anonymization technique both on upstream and downstream natural language processing tasks to show that our perturbations, while increasing security (ie, achieving 100% recall on any dataset), do not greatly impact the results of end-to-end machine learning approaches. Discussion As long as current approaches utilize precision and recall to evaluate deidentification algorithms, there will remain a risk of overlooking sensitive information. Inspired by differential privacy, we sought to make it statistically infeasible to recreate the original data, although at the cost of readability. We hope that the work will serve as a catalyst to further research into alternative deidentification methods that can address current weaknesses. Conclusion Our proposed technique can secure clinical texts at a low cost and extremely high recall with a readability trade-off while remaining useful for natural language processing classification tasks. We hope that our work can be used by risk-averse data holders to release clinical texts to researchers.", "year": 2020, "ssId": "3a95fab610d5ff49fbdb7a4d8760b02c51df0013", "arXivId": null, "link": "https://pdfs.semanticscholar.org/7353/56da800032535598483ebb2a86655c392dfa.pdf?_ga=2.208052241.288669922.1651129063-687820255.1651129063", "openAccess": true, "authors": ["Mohamed Abdalla", "Moustafa Abdalla", "F. Rudzicz", "Graeme Hirst"]}}, "ac713aebdcc06f15f8ea61e1140bb360341fdf27": {"id": "ac713aebdcc06f15f8ea61e1140bb360341fdf27", "content": {"title": "Thieves on Sesame Street! Model Extraction of BERT-based APIs", "abstract": "We study the problem of model extraction in natural language processing, in which an adversary with only query access to a victim model attempts to reconstruct a local copy of that model. Assuming that both the adversary and victim model fine-tune a large pretrained language model such as BERT (Devlin et al. 2019), we show that the adversary does not need any real training data to successfully mount the attack. In fact, the attacker need not even use grammatical or semantically meaningful queries: we show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering. Our work thus highlights an exploit only made feasible by the shift towards transfer learning methods within the NLP community: for a query budget of a few hundred dollars, an attacker can extract a model that performs only slightly worse than the victim model. Finally, we study two defense strategies against model extraction---membership classification and API watermarking---which while successful against naive adversaries, are ineffective against more sophisticated ones.", "year": 2019, "ssId": "ac713aebdcc06f15f8ea61e1140bb360341fdf27", "arXivId": "1910.12366", "link": "https://arxiv.org/pdf/1910.12366.pdf", "openAccess": true, "authors": ["Kalpesh Krishna", "Gaurav Singh Tomar", "Ankur P. Parikh", "Nicolas Papernot", "Mohit Iyyer"]}}, "4c93bcc05d6b41cb3df451d703f34bab9c9e9201": {"id": "4c93bcc05d6b41cb3df451d703f34bab9c9e9201", "content": {"title": "Research Challenges in Designing Differentially Private Text Generation Mechanisms", "abstract": "Accurately learning from user data while ensuring quantifiable privacy guarantees provides an opportunity to build better Machine Learning (ML) models while maintaining user trust. Recent literature has demonstrated the applicability of a generalized form of Differential Privacy to provide guarantees over text queries. Such mechanisms add privacy preserving noise to vectorial representations of text in high dimension and return a text based projection of the noisy vectors. However, these mechanisms are sub-optimal in their trade-off between privacy and utility. This is due to factors such as a fixed global sensitivity which leads to too much noise added in dense spaces while simultaneously guaranteeing protection for sensitive outliers. In this proposal paper, we describe some challenges in balancing the tradeoff between privacy and utility for these differentially private text mechanisms. At a high level, we provide two proposals: (1) a framework called LAC which defers some of the noise to a privacy amplification step and (2), an additional suite of three different techniques for calibrating the noise based on the local region around a word. Our objective in this paper is not to evaluate a single solution but to further the conversation on these challenges and chart pathways for building better mechanisms.", "year": 2020, "ssId": "4c93bcc05d6b41cb3df451d703f34bab9c9e9201", "arXivId": "2012.05403", "link": "https://arxiv.org/pdf/2012.05403.pdf", "openAccess": true, "authors": ["Oluwaseyi Feyisetan", "Abhinav Aggarwal", "Zekun Xu", "Nathanael Teissier"]}}, "dfd8fc9966ca8ec5c8bdc2dfc94099285f0e07a9": {"id": "dfd8fc9966ca8ec5c8bdc2dfc94099285f0e07a9", "content": {"title": "On a Utilitarian Approach to Privacy Preserving Text Generation", "abstract": "Differentially-private mechanisms for text generation typically add carefully calibrated noise to input words and use the nearest neighbor to the noised input as the output word. When the noise is small in magnitude, these mechanisms are susceptible to reconstruction of the original sensitive text. This is because the nearest neighbor to the noised input is likely to be the original input. To mitigate this empirical privacy risk, we propose a novel class of differentially private mechanisms that parameterizes the nearest neighbor selection criterion in traditional mechanisms. Motivated by Vickrey auction, where only the second highest price is revealed and the highest price is kept private, we balance the choice between the first and the second nearest neighbors in the proposed class of mechanisms using a tuning parameter. This parameter is selected by empirically solving a constrained optimization problem for maximizing utility, while maintaining the desired privacy guarantees. We argue that this empirical measurement framework can be used to align different mechanisms along a common benchmark for their privacy-utility tradeoff, particularly when different distance metrics are used to calibrate the amount of noise added. Our experiments on real text classification datasets show up to 50% improvement in utility compared to the existing state-of-the-art with the same empirical privacy guarantee.", "year": 2021, "ssId": "dfd8fc9966ca8ec5c8bdc2dfc94099285f0e07a9", "arXivId": "2104.11838", "link": "https://arxiv.org/pdf/2104.11838.pdf", "openAccess": true, "authors": ["Zekun Xu", "Abhinav Aggarwal", "Oluwaseyi Feyisetan", "Nathanael Teissier"]}}, "b54d49cdf57abf7f7e7bcc0e946f450fd807f829": {"id": "b54d49cdf57abf7f7e7bcc0e946f450fd807f829", "content": {"title": "Maximum Likelihood Constraint Inference for Inverse Reinforcement Learning", "abstract": "While most approaches to the problem of Inverse Reinforcement Learning (IRL) focus on estimating a reward function that best explains an expert agent's policy or demonstrated behavior on a control task, it is often the case that such behavior is more succinctly represented by a simple reward combined with a set of hard constraints. In this setting, the agent is attempting to maximize cumulative rewards subject to these given constraints on their behavior. We reformulate the problem of IRL on Markov Decision Processes (MDPs) such that, given a nominal model of the environment and a nominal reward function, we seek to estimate state, action, and feature constraints in the environment that motivate an agent's behavior. Our approach is based on the Maximum Entropy IRL framework, which allows us to reason about the likelihood of an expert agent's demonstrations given our knowledge of an MDP. Using our method, we can infer which constraints can be added to the MDP to most increase the likelihood of observing these demonstrations. We present an algorithm which iteratively infers the Maximum Likelihood Constraint to best explain observed behavior, and we evaluate its efficacy using both simulated behavior and recorded data of humans navigating around an obstacle.", "year": 2019, "ssId": "b54d49cdf57abf7f7e7bcc0e946f450fd807f829", "arXivId": "1909.05477", "link": "https://arxiv.org/pdf/1909.05477.pdf", "openAccess": true, "authors": ["D. Scobee", "S. Sastry"]}}, "d26683135c70d7b2a61ce5f70fb49b4fa22cf9c4": {"id": "d26683135c70d7b2a61ce5f70fb49b4fa22cf9c4", "content": {"title": "Effective sampling and learning for mallows models with pairwise-preference data", "abstract": "Learning preference distributions is a critical problem in many areas (e.g., recommender systems, IR, social choice). However, many existing learning and inference methods impose restrictive assumptions on the form of user preferences that can be admitted as evidence. We relax these restrictions by considering as data arbitrary pairwise comparisons of alternatives, which represent the fundamental building blocks of ordinal rankings. We develop the first algorithms for learning Mallows models (and mixtures thereof) from pairwise comparison data. At the heart of our technique is a new algorithm, the generalized repeated insertion model (GRIM), which allows sampling from arbitrary ranking distributions, and conditional Mallows models in particular. While we show that sampling from a Mallows model with pairwise evidence is computationally difficult in general, we develop approximate samplers that are exact for many important special cases|and have provable bounds with pairwise evidence--and derive algorithms for evaluating log-likelihood, learning Mallows mixtures, and non-parametric estimation. Experiments on real-world data sets demonstrate the effectiveness of our approach.", "year": 2014, "ssId": "d26683135c70d7b2a61ce5f70fb49b4fa22cf9c4", "arXivId": null, "link": "https://jmlr.org/papers/volume15/lu14a/lu14a.pdf", "openAccess": true, "authors": ["Tyler Lu", "Craig Boutilier"]}}, "a4cb2a401c78bfafee69e823306b0cc9e4d673db": {"id": "a4cb2a401c78bfafee69e823306b0cc9e4d673db", "content": {"title": "I Will Have Order! Optimizing Orders for Fair Reviewer Assignment", "abstract": "Scientific advancement requires effective peer review. Papers should be reviewed by experts in the subject area, but it is equally important that reviewer quality is fairly distributed amongst papers. We model reviewer assignment as an instance of a fair allocation problem, presenting an extension of the classic round-robin mechanism, called Reviewer Round Robin (RRR). Round-robin mechanisms are a standard tool to ensure envy-free up to one item (EF1) allocations. However, fairness often comes at the cost of decreased efficiency. To overcome this challenge, we carefully select an approximately optimal round-robin order. Applying a relaxation of submodularity, \u03b3-weak submodularity, we show that greedily inserting papers into an order yields a (1 + \u03b3)-approximation to the maximum welfare attainable by our round-robin mechanism under any order. Our approach outputs highly efficient EF1 allocations for three real conference datasets, outperforming several state-of-the-art paper assignment methods in fairness, efficiency and runtime.", "year": 2021, "ssId": "a4cb2a401c78bfafee69e823306b0cc9e4d673db", "arXivId": "2108.02126", "link": "https://arxiv.org/pdf/2108.02126.pdf", "openAccess": true, "authors": ["Justin Payan", "Yair Zick"]}}, "ae5a34c20fee705ad7094c93a711d5f724d535f0": {"id": "ae5a34c20fee705ad7094c93a711d5f724d535f0", "content": {"title": "Fairness-Aware Tensor-Based Recommendation", "abstract": "Tensor-based methods have shown promise in improving upon traditional matrix factorization methods for recommender systems. But tensors may achieve improved recommendation quality while worsening the fairness of the recommendations. Hence, we propose a novel fairness-aware tensor recommendation framework that is designed to maintain quality while dramatically improving fairness. Four key aspects of the proposed framework are: (i) a new sensitive latent factor matrix for isolating sensitive features; (ii) a sensitive information regularizer that extracts sensitive information which can taint other latent factors; (iii) an effective algorithm to solve the proposed optimization model; and (iv) extension to multi-feature and multi-category cases which previous efforts have not addressed. Extensive experiments on real-world and synthetic datasets show that the framework enhances recommendation fairness while preserving recommendation quality in comparison with state-of-the-art alternatives.", "year": 2018, "ssId": "ae5a34c20fee705ad7094c93a711d5f724d535f0", "arXivId": null, "link": "https://people.engr.tamu.edu/caverlee/pubs/zhu2018fairness.pdf", "openAccess": true, "authors": ["Ziwei Zhu", "Xia Hu", "James Caverlee"]}}, "cfad4dc5f1f7fcaf7ca318acf672ad92d47f8413": {"id": "cfad4dc5f1f7fcaf7ca318acf672ad92d47f8413", "content": {"title": "Don't let Ricci v. DeStefano Hold You Back: A Bias-Aware Legal Solution to the Hiring Paradox", "abstract": "Companies that try to address inequality in employment face a hiring paradox. Failing to address workforce imbalance can result in legal sanctions and scrutiny, but proactive measures to address these issues might result in the same legal conflict. Recent run-ins of Microsoft and Wells Fargo with the Labor Department\u2019s Office of Federal Contract Compliance Programs (OFCCP) are not isolated and are likely to persist. To add to the confusion, existing scholarship on Ricci v. DeStefano often deems solutions to this paradox impossible. Circumventive practices such as the 4/5ths rule further illustrate tensions between too little action and too", "year": 2022, "ssId": "cfad4dc5f1f7fcaf7ca318acf672ad92d47f8413", "arXivId": "2201.13367", "link": "https://arxiv.org/pdf/2201.13367.pdf", "openAccess": true, "authors": ["Jad Salem", "D. Desai", "Swati Gupta"]}}, "82c4be27b0803c08c56bba4352669c1230a3ea19": {"id": "82c4be27b0803c08c56bba4352669c1230a3ea19", "content": {"title": "Bandwidth Adaptive & Error Resilient MBR Exact Repair Regenerating Codes", "abstract": "Regenerating codes are efficient methods for distributed storage in storage networks, where node failures are common. They guarantee low cost data reconstruction and repair through accessing only a predefined number of arbitrarily chosen storage nodes in the network. In this paper, we consider two simultaneous extensions to the original regenerating codes framework introduced by Dimakis et al.; 1) both data reconstruction and repair are resilient to the presence of a certain number of erroneous nodes in the network and 2) the number of helper nodes in every repair is not fixed, but is a flexible parameter that can be selected during the run-time. We study the fundamental limits of required total repair bandwidth and provide an upper bound for the storage capacity of these codes under these assumptions. We then focus on the minimum repair bandwidth (MBR) case and derive the exact storage capacity by presenting explicit coding schemes with exact repair, which achieve the upper bound of the storage capacity in the considered setup. To this end, we first provide a more natural extension of the well-known product matrix (PM) MBR codes, modified to provide flexibility in choosing the number of helpers in each repair, and simultaneously be robust to erroneous nodes in the network. This is achieved by proving the non-singularity for a family of matrices in large enough finite fields. We next provide another extension of the PM codes, based on a novel repair scheme which enables flexibility in the number of helpers and robustness against erroneous nodes without any extra cost in field size compared with the original PM codes.", "year": 2017, "ssId": "82c4be27b0803c08c56bba4352669c1230a3ea19", "arXivId": "1711.02770", "link": "https://arxiv.org/pdf/1711.02770.pdf", "openAccess": true, "authors": ["K. Mahdaviani", "A. Khisti", "S. Mohajer"]}}, "cc352ea39f820c3effc40ce09369cf59afe361df": {"id": "cc352ea39f820c3effc40ce09369cf59afe361df", "content": {"title": "Reporting an Experience on Design and Implementation of e-Health Systems on Azure Cloud", "abstract": "Electronic Health e-Health technology has brought the world with significant transformation from traditional paper-based medical practice to Information and Communication Technologies ICT-based systems for automatic management storage, processing, and archiving of information. Traditionally e-Health systems have been designed to operate within stovepipes on dedicated networks, physical computers, and locally managed software platforms that make it susceptible to many serious limitations including: 1 lack of on-demand scalability during critical situations; 2 high administrative overheads and costs; and 3 in-efficient resource utilization and energy consumption due to lack of automation. In this paper, we present an approach to migrate the ICT systems in the e-Health sector from traditional in-house Client/Server C/S architecture to the virtualized cloud computing environment. To this end, we developed two cloud-based e-Health applications Medical Practice Management System and Telemedicine Practice System for demonstrating how cloud services can be leveraged for developing and deploying such applications. The Windows Azure cloud computing platform is selected as an example public cloud platform for our study. We conducted several performance evaluation experiments to understand the Quality Service QoS tradeoffs of our applications under variable workload on Azure.", "year": 2013, "ssId": "cc352ea39f820c3effc40ce09369cf59afe361df", "arXivId": "1306.3624", "link": "https://arxiv.org/pdf/1306.3624.pdf", "openAccess": true, "authors": ["Shilin Lu", "R. Ranjan", "P. Strazdins"]}}, "58b628792d3eb22a034a871ed3cf373afe591928": {"id": "58b628792d3eb22a034a871ed3cf373afe591928", "content": {"title": "XORing Elephants: Novel Erasure Codes for Big Data", "abstract": "Distributed storage systems for large clusters typically use replication to provide reliability. Recently, erasure codes have been used to reduce the large storage overhead of three-replicated systems. Reed-Solomon codes are the standard design choice and their high repair cost is often considered an unavoidable price to pay for high storage efficiency and high reliability. \n \nThis paper shows how to overcome this limitation. We present a novel family of erasure codes that are efficiently repairable and offer higher reliability compared to Reed-Solomon codes. We show analytically that our codes are optimal on a recently identified tradeoff between locality and minimum distance. \n \nWe implement our new codes in Hadoop HDFS and compare to a currently deployed HDFS module that uses Reed-Solomon codes. Our modified HDFS implementation shows a reduction of approximately 2\u00d7 on the repair disk I/O and repair network traffic. The disadvantage of the new coding scheme is that it requires 14% more storage compared to Reed-Solomon codes, an overhead shown to be information theoretically optimal to obtain locality. Because the new codes repair failures faster, this provides higher reliability, which is orders of magnitude higher compared to replication.", "year": 2013, "ssId": "58b628792d3eb22a034a871ed3cf373afe591928", "arXivId": "1301.3791", "link": "https://arxiv.org/pdf/1301.3791.pdf", "openAccess": true, "authors": ["M. Sathiamoorthy", "Megasthenis Asteris", "Dimitris Papailiopoulos", "A. Dimakis", "Ramkumar Vadali", "Scott Chen", "Dhruba Borthakur"]}}, "e52115834ac7a529b1f4a7769dd538f143cf3eea": {"id": "e52115834ac7a529b1f4a7769dd538f143cf3eea", "content": {"title": "Limitations on the Achievable Repair Bandwidth of Piggybacking Codes with Low Substriping", "abstract": "The piggybacking framework for designing erasure codes for distributed storage has empirically proven to be very useful, and has been used to design codes with desirable properties, such as low repair bandwidth and complexity. However, the theoretical properties of this framework remain largely unexplored. We address this by adapting a general characterization of repair schemes (previously used for Reed Solomon codes) to analyze piggybacking codes with low substriping. With this characterization, we establish a separation between piggybacking and general erasure codes, and several impossibility results for subcategories of piggybacking codes; for certain parameters, we also present explicit, optimal constructions of piggybacking codes.", "year": 2017, "ssId": "e52115834ac7a529b1f4a7769dd538f143cf3eea", "arXivId": "1707.02337", "link": "https://arxiv.org/pdf/1707.02337.pdf", "openAccess": true, "authors": ["Reyna Hulett", "Mary Wootters"]}}, "27636090a87fab750fccff4c6ede161ab62bcab4": {"id": "27636090a87fab750fccff4c6ede161ab62bcab4", "content": {"title": "Increasing Network Visibility Using Coded Repetition Beacon Piggybacking", "abstract": "Vehicular Ad hoc Networks (VANET) is one of the most challenging research areas in the field of Mobile Ad Hoc Networks. In this research, we propose a new mechanism for increasing network visibility, by taking the information gained from periodic safety messages (beacons), and inserting it into a 'neighbor' table. The table will be propagated to all neighbors giving a wider vision for each vehicle belonging to the network. It will also decrease the risk of collision at road junctions as each vehicle will have prior knowledge oncoming vehicles before reaching the junction.", "year": 2013, "ssId": "27636090a87fab750fccff4c6ede161ab62bcab4", "arXivId": "1301.7170", "link": "https://arxiv.org/pdf/1301.7170.pdf", "openAccess": true, "authors": ["G. Samara"]}}, "2875d6cac905c3dfec4c8a8e1d89a2a7e4d71d40": {"id": "2875d6cac905c3dfec4c8a8e1d89a2a7e4d71d40", "content": {"title": "Functional Broadcast Repair of Multiple Partial Failures in Wireless Distributed Storage Systems", "abstract": "We consider a distributed storage system with <inline-formula> <tex-math notation=\"LaTeX\">$n$ </tex-math></inline-formula> nodes, where a user can recover the stored file from any <inline-formula> <tex-math notation=\"LaTeX\">$k$ </tex-math></inline-formula> nodes, and study the problem of repairing <inline-formula> <tex-math notation=\"LaTeX\">$r$ </tex-math></inline-formula> partially failed nodes. We consider <italic>broadcast repair</italic>, that is, <inline-formula> <tex-math notation=\"LaTeX\">$d$ </tex-math></inline-formula> surviving nodes transmit broadcast messages on an error-free wireless channel to the <inline-formula> <tex-math notation=\"LaTeX\">$r$ </tex-math></inline-formula> nodes being repaired, which are then used, together with the surviving data in the local memories of the failed nodes, to recover the lost content. First, we derive the trade-off between the storage capacity and the repair bandwidth for partial repair of multiple failed nodes, based on the cut-set bound for information flow graphs. It is shown that utilizing the broadcast nature of the wireless medium and the surviving contents at the partially failed nodes reduces the repair bandwidth per node significantly. Then, we list a set of invariant conditions that are sufficient for a functional repair code to be feasible. We further propose a scheme for functional repair of multiple failed nodes that satisfies the invariant conditions with high probability, and its extension to the repair of partial failures. The performance of the proposed scheme meets the cut-set bound on all the points on the trade-off curve for all admissible parameters when <inline-formula> <tex-math notation=\"LaTeX\">$k$ </tex-math></inline-formula> is divisible by <inline-formula> <tex-math notation=\"LaTeX\">$r$ </tex-math></inline-formula>, while employing linear subpacketization, which is an important practical consideration in the design of distributed storage codes. Unlike random linear codes, which are conventionally used for functional repair of failed nodes, the proposed repair scheme has lower overhead, lower input-output cost, and lower computational complexity during repair.", "year": 2021, "ssId": "2875d6cac905c3dfec4c8a8e1d89a2a7e4d71d40", "arXivId": "2111.07884", "link": "https://arxiv.org/pdf/2111.07884.pdf", "openAccess": true, "authors": ["N. Mital", "Katina Kralevska", "Congli Ling", "Deniz G\u00fcnd\u00fcz"]}}, "35cb2b9febada179689724c78dfe31d9fa3f74c4": {"id": "35cb2b9febada179689724c78dfe31d9fa3f74c4", "content": {"title": "Erasure Coding in Windows Azure Storage", "abstract": "Windows Azure Storage (WAS) is a cloud storage system that provides customers the ability to store seemingly limitless amounts of data for any duration of time. WAS customers have access to their data from anywhere, at any time, and only pay for what they use and store. To provide durability for that data and to keep the cost of storage low, WAS uses erasure coding. \n \nIn this paper we introduce a new set of codes for erasure coding called Local Reconstruction Codes (LRC). LRC reduces the number of erasure coding fragments that need to be read when reconstructing data fragments that are offline, while still keeping the storage overhead low. The important benefits of LRC are that it reduces the bandwidth and I/Os required for repair reads over prior codes, while still allowing a significant reduction in storage overhead. We describe how LRC is used in WAS to provide low overhead durable storage with consistently low read latencies.", "year": 2012, "ssId": "35cb2b9febada179689724c78dfe31d9fa3f74c4", "arXivId": null, "link": "https://www.usenix.org/system/files/conference/atc12/atc12-final181_0.pdf", "openAccess": true, "authors": ["Cheng Huang", "Huseyin Simitci", "Yikang Xu", "Aaron Ogus", "B. Calder", "P. Gopalan", "Jin Li", "S. Yekhanin"]}}, "97883f37c62b4b0e52cdc31dea1a375597db3804": {"id": "97883f37c62b4b0e52cdc31dea1a375597db3804", "content": {"title": "Piggyback: Adding Multiple Tasks to a Single, Fixed Network by Learning to Mask", "abstract": "This work presents a method for adding multiple tasks to a single, fixed deep neural network without affecting performance on already learned tasks. By building upon concepts from network quantization and sparsification, we learn binary masks that \"piggyback\", or are applied to an existing network to provide good performance on a new task. These masks are learned in an end-to-end differentiable fashion, and incur a low overhead of 1 bit per network parameter, per task. Even though the underlying network is fixed, the ability to mask certain weights allows for the learning of a large number of filters. We show improved performance on a variety of classification tasks, including those with large domain shifts from the natural images of ImageNet. Unlike prior work, we can augment the capabilities of a network without suffering from catastrophic forgetting or competition between tasks, while incurring the least overhead per added task. We demonstrate the applicability of our method to multiple architectures, and obtain accuracies comparable with individual networks trained per task.", "year": 2018, "ssId": "97883f37c62b4b0e52cdc31dea1a375597db3804", "arXivId": "1801.06519", "link": "https://arxiv.org/pdf/1801.06519.pdf", "openAccess": true, "authors": ["Arun Mallya", "S. Lazebnik"]}}, "29b3a609f2b5cb10cffb80a6aaf96413a4a9998e": {"id": "29b3a609f2b5cb10cffb80a6aaf96413a4a9998e", "content": {"title": "iFlow: Numerically Invertible Flows for Efficient Lossless Compression via a Uniform Coder", "abstract": "It was estimated that the world produced 59ZB (5.9\u00d7 10GB) of data in 2020, resulting in the enormous costs of both data storage and transmission. Fortunately, recent advances in deep generative models have spearheaded a new class of socalled \"neural compression\" algorithms, which significantly outperform traditional codecs in terms of compression ratio. Unfortunately, the application of neural compression garners little commercial interest due to its limited bandwidth; therefore, developing highly efficient frameworks is of critical practical importance. In this paper, we discuss lossless compression using normalizing flows which have demonstrated a great capacity for achieving high compression ratios. As such, we introduce iFlow, a new method for achieving efficient lossless compression. We first propose Modular Scale Transform (MST) and a novel family of numerically invertible flow transformations based on MST. Then we introduce the Uniform Base Conversion System (UBCS), a fast uniform-distribution codec incorporated into iFlow, enabling efficient compression. iFlow achieves state-of-the-art compression ratios and is 5\u00d7 quicker than other high-performance schemes. Furthermore, the techniques presented in this paper can be used to accelerate coding time for a broad class of flow-based algorithms.", "year": 2021, "ssId": "29b3a609f2b5cb10cffb80a6aaf96413a4a9998e", "arXivId": "2111.00965", "link": "https://arxiv.org/pdf/2111.00965.pdf", "openAccess": true, "authors": ["Shifeng Zhang", "Ning Kang", "Tom Ryder", "Zhenguo Li"]}}, "71124b00b873e85aa55b07100cd5b492e5b1d73d": {"id": "71124b00b873e85aa55b07100cd5b492e5b1d73d", "content": {"title": "Long-Term Secure Distributed Storage Using Quantum Key Distribution Network With Third-Party Verification", "abstract": "The quantum key distribution (QKD) network with Vernam's one-time pad encryption and secret sharing are powerful security tools to realize an information theoretically secure (ITS) distributed storage system. In the work of Fujiwara et al., a single-password-authenticated secret sharing (SPSS) scheme based on the QKD network and Shamirs secret sharing was experimentally demonstrated; it confirmed ITS data transmission, storage, authentication, and integrity. To achieve data integrity, an ITS message authentication code (MAC) tag is employed, and a data owner of the secret sharing performs both the MAC tag generation and verification. However, for a scenario in which the data owner and end users are different entities, the above approach may not work, since the data owner can cheat the end users. In this article, we resolve this problem by proposing an ITS integrity protection scheme employing a third-party verification with time-stamp. The ITS integrity protection is realized by two steps: integrity check by the data owner at data reconstruction and data integrity certification by the data owner, the end user, and the third-party verifier using a MAC based on universal2 hash function and random number provided from the QKD network. In addition to introducing the third-party verifier, we institute \u201ca trusted calculator,\u201d which computes shares of the data and MAC tags and sends MAC tags to the third-party verifier. The random number used in calculation is stored in the trusted calculator. We implement this scheme on the SPSS system installed in the Tokyo QKD Network.", "year": 2021, "ssId": "71124b00b873e85aa55b07100cd5b492e5b1d73d", "arXivId": "2112.12292", "link": "https://arxiv.org/pdf/2112.12292.pdf", "openAccess": true, "authors": ["M. Fujiwara", "R. Nojima", "T. Tsurumaru", "S. Moriai", "M. Takeoka", "M. Sasaki"]}}, "6cf3bdcdee6236f9f04e7773e3601dbbb8fbc61e": {"id": "6cf3bdcdee6236f9f04e7773e3601dbbb8fbc61e", "content": {"title": "Simple Questions Generate Named Entity Recognition Datasets", "abstract": "Recent named entity recognition (NER) models 001 often rely on human-annotated datasets requir- 002 ing the vast engagement of professional knowl- 003 edge on the target domain and entities. This 004 work introduces an ask-to-generate approach, 005 which automatically generates NER datasets 006 by asking simple natural language questions 007 to an open-domain question answering system 008 (e.g., \u201c Which disease?\u201d ). Without relying on in- 009 domain resources such as in-domain sentences 010 and labels, our models solely trained on the gen- 011 erated datasets largely outperform strong low- 012 resource models on six popular NER bench- 013 marks by 20.8 F1 score. Our models also show 014 competitive performance with rich-resource 015 models that additionally leverage in-domain 016 dictionaries provided by domain experts. In 017 few-shot NER, we outperform the previous best 018 model by 5.2 F1 score on three benchmarks and 019 achieve new state-of-the-art performance. 1 020", "year": 2021, "ssId": "6cf3bdcdee6236f9f04e7773e3601dbbb8fbc61e", "arXivId": "2112.08808", "link": "https://arxiv.org/pdf/2112.08808.pdf", "openAccess": true, "authors": ["Hyunjae Kim", "J. Yoo", "Seunghyun Yoon", "Jinhyuk Lee", "Jaewoo Kang"]}}, "4fa4e39ade763085a75146392b997b7d4da49725": {"id": "4fa4e39ade763085a75146392b997b7d4da49725", "content": {"title": "Contextualized Weak Supervision for Text Classification", "abstract": "Weakly supervised text classification based on a few user-provided seed words has recently attracted much attention from researchers. Existing methods mainly generate pseudo-labels in a context-free manner (e.g., string matching), therefore, the ambiguous, context-dependent nature of human language has been long overlooked. In this paper, we propose a novel framework ConWea, providing contextualized weak supervision for text classification. Specifically, we leverage contextualized representations of word occurrences and seed word information to automatically differentiate multiple interpretations of the same word, and thus create a contextualized corpus. This contextualized corpus is further utilized to train the classifier and expand seed words in an iterative manner. This process not only adds new contextualized, highly label-indicative keywords but also disambiguates initial seed words, making our weak supervision fully contextualized. Extensive experiments and case studies on real-world datasets demonstrate the necessity and significant advantages of using contextualized weak supervision, especially when the class labels are fine-grained.", "year": 2020, "ssId": "4fa4e39ade763085a75146392b997b7d4da49725", "arXivId": null, "link": "https://aclanthology.org/2020.acl-main.30.pdf", "openAccess": true, "authors": ["Dheeraj Mekala", "Jingbo Shang"]}}, "3e8420d1bebb3f93d285da2de801d2e43b290880": {"id": "3e8420d1bebb3f93d285da2de801d2e43b290880", "content": {"title": "Adaptive Self-training for Few-shot Neural Sequence Labeling", "abstract": "Neural sequence labeling is an important technique employed for many Natural Language Processing (NLP) tasks, such as Named Entity Recognition (NER), slot tagging for dialog systems and semantic parsing. Large-scale pre-trained language models obtain very good performance on these tasks when fine-tuned on large amounts of task-specific labeled data. However, such large-scale labeled datasets are difficult to obtain for several tasks and domains due to the high cost of human annotation as well as privacy and data access constraints for sensitive user applications. This is exacerbated for sequence labeling tasks requiring such annotations at token-level. In this work, we develop techniques to address the label scarcity challenge for neural sequence labeling models. Specifically, we develop self-training and meta-learning techniques for few-shot training of neural sequence taggers, namely MetaST. While self-training serves as an effective mechanism to learn from large amounts of unlabeled data -- meta-learning helps in adaptive sample re-weighting to mitigate error propagation from noisy pseudo-labels. Extensive experiments on six benchmark datasets including two massive multilingual NER datasets and four slot tagging datasets for task-oriented dialog systems demonstrate the effectiveness of our method with around 10% improvement over state-of-the-art systems for the 10-shot setting.", "year": 2020, "ssId": "3e8420d1bebb3f93d285da2de801d2e43b290880", "arXivId": "2010.03680", "link": "https://arxiv.org/pdf/2010.03680.pdf", "openAccess": true, "authors": ["Yaqing Wang", "Subhabrata Mukherjee", "Haoda Chu", "Yuancheng Tu", "Ming Wu", "Jing Gao", "Ahmed Hassan Awadallah"]}}, "fd8e176087335355ff5e81821a616d15ec8d3346": {"id": "fd8e176087335355ff5e81821a616d15ec8d3346", "content": {"title": "Creating Training Sets via Weak Indirect Supervision", "abstract": "Creating labeled training sets has become one of the major roadblocks in machine learning. To address this, recent Weak Supervision (WS) frameworks synthesize training labels from multiple potentially noisy supervision sources. However, existing frameworks are restricted to supervision sources that share the same output space as the target task. To extend the scope of usable sources, we formulate Weak Indirect Supervision (WIS), a new research problem for automatically synthesizing training labels based on indirect supervision sources that have different output label spaces. To overcome the challenge of mismatched output spaces, we develop a probabilistic modeling approach, PLRM, which uses user-provided label relations to model and leverage indirect supervision sources. Moreover, we provide a theoretically-principled test of the distinguishability of PLRM for unseen labels, along with a generalization bound. On both image and text classification tasks as well as an industrial advertising application, we demonstrate the advantages of PLRM by outperforming baselines by a margin of 2%-9%.", "year": 2021, "ssId": "fd8e176087335355ff5e81821a616d15ec8d3346", "arXivId": "2110.03484", "link": "https://arxiv.org/pdf/2110.03484.pdf", "openAccess": true, "authors": ["Jieyu Zhang", "Bohan Wang", "Xiangchen Song", "Yujing Wang", "Yaming Yang", "Jing Bai", "Alexander J. Ratner"]}}, "b30195763eb103e2e5564228119f3810ab423b2e": {"id": "b30195763eb103e2e5564228119f3810ab423b2e", "content": {"title": "Text Classification Using Label Names Only: A Language Model Self-Training Approach", "abstract": "Current text classification methods typically require a good number of human-labeled documents as training data, which can be costly and difficult to obtain in real applications. Humans can perform classification without seeing any labeled examples but only based on a small set of words describing the categories to be classified. In this paper, we explore the potential of only using the label name of each class to train classification models on unlabeled data, without using any labeled documents. We use pre-trained neural language models both as general linguistic knowledge sources for category understanding and as representation learning models for document classification. Our method (1) associates semantically related words with the label names, (2) finds category-indicative words and trains the model to predict their implied categories, and (3) generalizes the model via self-training. We show that our model achieves around 90% accuracy on four benchmark datasets including topic and sentiment classification without using any labeled documents but learning from unlabeled data supervised by at most 3 words (1 in most cases) per class as the label name.", "year": 2020, "ssId": "b30195763eb103e2e5564228119f3810ab423b2e", "arXivId": "2010.07245", "link": "https://arxiv.org/pdf/2010.07245.pdf", "openAccess": true, "authors": ["Yu Meng", "Yunyi Zhang", "Jiaxin Huang", "Chenyan Xiong", "Heng Ji", "Chao Zhang", "Jiawei Han"]}}, "f61886d138497431cbeaa7bb73051bfb7a745026": {"id": "f61886d138497431cbeaa7bb73051bfb7a745026", "content": {"title": "Linguistic Structures as Weak Supervision for Visual Scene Graph Generation", "abstract": "Prior work in scene graph generation requires categorical supervision at the level of triplets\u2014subjects and objects, and predicates that relate them, either with or without bounding box information. However, scene graph generation is a holistic task: thus holistic, contextual supervision should intuitively improve performance. In this work, we explore how linguistic structures in captions can benefit scene graph generation. Our method captures the information provided in captions about relations between individual triplets, and context for subjects and objects (e.g. visual properties are mentioned). Captions are a weaker type of supervision than triplets since the alignment between the exhaustive list of human-annotated subjects and objects in triplets, and the nouns in captions, is weak. However, given the large and diverse sources of multimodal data on the web (e.g. blog posts with images and captions), linguistic supervision is more scalable than crowdsourced triplets. We show extensive experimental comparisons against prior methods which leverage instance- and image-level supervision, and ablate our method to show the impact of leveraging phrasal and sequential context, and techniques to improve localization of subjects and objects.", "year": 2021, "ssId": "f61886d138497431cbeaa7bb73051bfb7a745026", "arXivId": "2105.13994", "link": "https://arxiv.org/pdf/2105.13994.pdf", "openAccess": true, "authors": ["Keren Ye", "Adriana Kovashka"]}}, "5e00596fa946670d894b1bdaeff5a98e3867ef13": {"id": "5e00596fa946670d894b1bdaeff5a98e3867ef13", "content": {"title": "SimVLM: Simple Visual Language Model Pretraining with Weak Supervision", "abstract": "With recent progress in joint modeling of visual and textual representations, Vision-Language Pretraining (VLP) has achieved impressive performance on many multimodal downstream tasks. However, the requirement for expensive annotations including clean image captions and regional labels limits the scalability of existing approaches, and complicates the pretraining procedure with the introduction of multiple dataset-specific objectives. In this work, we relax these constraints and present a minimalist pretraining framework, named Simple Visual Language Model (SimVLM). Unlike prior work, SimVLM reduces the training complexity by exploiting large-scale weak supervision, and is trained end-to-end with a single prefix language modeling objective. Without utilizing extra data or task-specific customization, the resulting model significantly outperforms previous pretraining methods and achieves new state-of-the-art results on a wide range of discriminative and generative vision-language benchmarks, including VQA (+3.74% vqa-score), NLVR2 (+1.17% accuracy), SNLI-VE (+1.37% accuracy) and image captioning tasks (+10.1% average CIDEr score). Furthermore, we demonstrate that SimVLM acquires strong generalization and transfer ability, enabling zero-shot behavior including open-ended visual question answering and cross-modality transfer.", "year": 2021, "ssId": "5e00596fa946670d894b1bdaeff5a98e3867ef13", "arXivId": "2108.10904", "link": "https://arxiv.org/pdf/2108.10904.pdf", "openAccess": true, "authors": ["Zirui Wang", "Jiahui Yu", "Adams Wei Yu", "Zihang Dai", "Yulia Tsvetkov", "Yuan Cao"]}}, "5d6f87e31d806a77d22e344106d0310be3342259": {"id": "5d6f87e31d806a77d22e344106d0310be3342259", "content": {"title": "Mitigating Manipulation in Peer Review via Randomized Reviewer Assignments", "abstract": "We consider three important challenges in conference peer review: (i) reviewers maliciously attempting to get assigned to certain papers to provide positive reviews, possibly as part of quid-pro-quo arrangements with the authors; (ii) \"torpedo reviewing,\" where reviewers deliberately attempt to get assigned to certain papers that they dislike in order to reject them; (iii) reviewer de-anonymization on release of the similarities and the reviewer-assignment code. On the conceptual front, we identify connections between these three problems and present a framework that brings all these challenges under a common umbrella. We then present a (randomized) algorithm for reviewer assignment that can optimally solve the reviewer-assignment problem under any given constraints on the probability of assignment for any reviewer-paper pair. We further consider the problem of restricting the joint probability that certain suspect pairs of reviewers are assigned to certain papers, and show that this problem is NP-hard for arbitrary constraints on these joint probabilities but efficiently solvable for a practical special case. Finally, we experimentally evaluate our algorithms on datasets from past conferences, where we observe that they can limit the chance that any malicious reviewer gets assigned to their desired paper to 50% while producing assignments with over 90% of the total optimal similarity. Our algorithms still achieve this similarity while also preventing reviewers with close associations from being assigned to the same paper.", "year": 2020, "ssId": "5d6f87e31d806a77d22e344106d0310be3342259", "arXivId": "2006.16437", "link": "https://arxiv.org/pdf/2006.16437.pdf", "openAccess": true, "authors": ["Steven Jecmen", "Hanrui Zhang", "Ryan Liu", "Nihar B. Shah", "V. Conitzer", "Fei Fang"]}}, "148efaba70165d9faef0dac28d5fa2538cfa662d": {"id": "148efaba70165d9faef0dac28d5fa2538cfa662d", "content": {"title": "Deciding Fast and Slow: The Role of Cognitive Biases in AI-assisted Decision-making", "abstract": "Several strands of research have aimed to bridge the gap between artificial intelligence (AI) and human decision-makers in AI-assisted decision-making, where humans are the consumers of AI model predictions and the ultimate decision-makers in high-stakes applications. However, people's perception and understanding are often distorted by their cognitive biases, such as confirmation bias, anchoring bias, availability bias, to name a few. In this work, we use knowledge from the field of cognitive science to account for cognitive biases in the human-AI collaborative decision-making setting, and mitigate their negative effects on collaborative performance. To this end, we mathematically model cognitive biases and provide a general framework through which researchers and practitioners can understand the interplay between cognitive biases and human-AI accuracy. We then focus specifically on anchoring bias, a bias commonly encountered in human-AI collaboration. We implement a time-based de-anchoring strategy and conduct our first user experiment that validates its effectiveness in human-AI collaborative decision-making. With this result, we design a time allocation strategy for a resource-constrained setting that achieves optimal human-AI collaboration under some assumptions. We, then, conduct a second user experiment which shows that our time allocation strategy with explanation can effectively de-anchor the human and improve collaborative performance when the AI model has low confidence and is incorrect.", "year": 2020, "ssId": "148efaba70165d9faef0dac28d5fa2538cfa662d", "arXivId": "2010.07938", "link": "https://arxiv.org/pdf/2010.07938.pdf", "openAccess": true, "authors": ["Charvi Rastogi", "Yunfeng Zhang", "Dennis Wei", "K. Varshney", "Amit Dhurandhar", "Richard J. Tomsett"]}}, "baf34ac4080a365a7cec30b6877fa1a018eb31cf": {"id": "baf34ac4080a365a7cec30b6877fa1a018eb31cf", "content": {"title": "Joint Passage Ranking for Diverse Multi-Answer Retrieval", "abstract": "We study multi-answer retrieval, an under-explored problem that requires retrieving passages to cover multiple distinct answers for a given question. This task requires joint modeling of retrieved passages, as models should not repeatedly retrieve passages containing the same answer at the cost of missing a different valid answer. Prior work focusing on single-answer retrieval is limited as it cannot reason about the set of passages jointly. In this paper, we introduce JPR, a joint passage retrieval model focusing on reranking. To model the joint probability of the retrieved passages, JPR makes use of an autoregressive reranker that selects a sequence of passages, equipped with novel training and decoding algorithms. Compared to prior approaches, JPR achieves significantly better answer coverage on three multi-answer datasets. When combined with downstream question answering, the improved retrieval enables larger answer generation models since they need to consider fewer passages, establishing a new state-of-the-art.", "year": 2021, "ssId": "baf34ac4080a365a7cec30b6877fa1a018eb31cf", "arXivId": "2104.08445", "link": "https://arxiv.org/pdf/2104.08445.pdf", "openAccess": true, "authors": ["Sewon Min", "Kenton Lee", "Ming-Wei Chang", "Kristina Toutanova", "Hannaneh Hajishirzi"]}}, "cefd3993db4d065b95ab8f105452fb728c02b60e": {"id": "cefd3993db4d065b95ab8f105452fb728c02b60e", "content": {"title": "Can We Automate Scientific Reviewing?", "abstract": "The rapid development of science and technology has been accompanied by an exponential growth in peer-reviewed scientific publications. At the same time, the review of each paper is a laborious process that must be carried out by subject matter experts. Thus, providing high-quality reviews of this growing number of papers is a significant challenge. In this work, we ask the question \u201ccan we automate scientific reviewing?\u201d, discussing the possibility of using state-of-the-art natural language processing (NLP) models to generate first-pass peer reviews for scientific papers. Arguably the most difficult part of this is defining what a \u201cgood\u201d review is in the first place, so we first discuss possible evaluation measures for such reviews. We then collect a dataset of papers in the machine learning domain, annotate them with different aspects of content covered in each review, and train targeted \u2217Corresponding author. summarization models that take in papers to generate reviews. Comprehensive experimental results show that system-generated reviews tend to touch upon more aspects of the paper than human-written reviews, but the generated text can suffer from lower constructiveness for all aspects except the explanation of the core ideas of the papers, which are largely factually correct. We finally summarize eight challenges in the pursuit of a good review generation system together with potential solutions, which, hopefully, will inspire more future research on this subject. We make all code, and the dataset publicly available: https://github. com/neulab/ReviewAdvisor as well as a ReviewAdvisor system: http://review.nlpedia.ai/ (See demo screenshot in A.2). The review of this paper (without TL;QR section) written by the system of this paper can be found A.1", "year": 2021, "ssId": "cefd3993db4d065b95ab8f105452fb728c02b60e", "arXivId": "2102.00176", "link": "https://arxiv.org/pdf/2102.00176.pdf", "openAccess": true, "authors": ["Weizhe Yuan", "P. Liu", "Graham Neubig"]}}, "302face5b5a0944cab13665a2d4e07ef3aaf5240": {"id": "302face5b5a0944cab13665a2d4e07ef3aaf5240", "content": {"title": "AmbigQA: Answering Ambiguous Open-domain Questions", "abstract": "Ambiguity is inherent to open-domain question answering; especially when exploring new topics, it can be difficult to ask questions that have a single, unambiguous answer. In this paper, we introduce AmbigQA, a new open-domain question answering task which involves predicting a set of question-answer pairs, where every plausible answer is paired with a disambiguated rewrite of the original question. To study this task, we construct AmbigNQ, a dataset covering 14,042 questions from NQ-open, an existing open-domain QA benchmark. We find that over half of the questions in NQ-open are ambiguous, exhibiting diverse types of ambiguity. We also present strong baseline models for AmbigQA which we show benefit from weakly supervised learning that incorporates NQ-open, strongly suggesting our new task and data will support significant future research effort. Our data is available at this https URL.", "year": 2020, "ssId": "302face5b5a0944cab13665a2d4e07ef3aaf5240", "arXivId": "2004.10645", "link": "https://arxiv.org/pdf/2004.10645.pdf", "openAccess": true, "authors": ["Sewon Min", "Julian Michael", "Hannaneh Hajishirzi", "Luke Zettlemoyer"]}}, "c395595cf7be23f7d90cbca98d8c7861ebfd884d": {"id": "c395595cf7be23f7d90cbca98d8c7861ebfd884d", "content": {"title": "The Disagreement Deconvolution: Bringing Machine Learning Performance Metrics In Line With Reality", "abstract": "Machine learning classifiers for human-facing tasks such as comment toxicity and misinformation often score highly on metrics such as ROC AUC but are received poorly in practice. Why this gap? Today, metrics such as ROC AUC, precision, and recall are used to measure technical performance; however, human-computer interaction observes that evaluation of human-facing systems should account for people\u2019s reactions to the system. In this paper, we introduce a transformation that more closely aligns machine learning classification metrics with the values and methods of user-facing performance measures. The disagreement deconvolution takes in any multi-annotator (e.g., crowdsourced) dataset, disentangles stable opinions from noise by estimating intra-annotator consistency, and compares each test set prediction to the individual stable opinions from each annotator. Applying the disagreement deconvolution to existing social computing datasets, we find that current metrics dramatically overstate the performance of many human-facing machine learning tasks: for example, performance on a comment toxicity task is corrected from .95 to .73 ROC AUC.", "year": 2021, "ssId": "c395595cf7be23f7d90cbca98d8c7861ebfd884d", "arXivId": null, "link": "http://www.kayur.org/papers/chi2021.pdf", "openAccess": true, "authors": ["Mitchell L. Gordon", "Kaitlyn Zhou", "Kayur Patel", "Tatsunori B. Hashimoto", "Michael S. Bernstein"]}}, "d36e39aedd802aea4be1ea303c70dc56e97dbc3c": {"id": "d36e39aedd802aea4be1ea303c70dc56e97dbc3c", "content": {"title": "Asking and Answering Questions to Evaluate the Factual Consistency of Summaries", "abstract": "Practical applications of abstractive summarization models are limited by frequent factual inconsistencies with respect to their input. Existing automatic evaluation metrics for summarization are largely insensitive to such errors. We propose QAGS (pronounced \u201ckags\u201d), an automatic evaluation protocol that is designed to identify factual inconsistencies in a generated summary. QAGS is based on the intuition that if we ask questions about a summary and its source, we will receive similar answers if the summary is factually consistent with the source. To evaluate QAGS, we collect human judgments of factual consistency on model-generated summaries for the CNN/DailyMail (Hermann et al., 2015) and XSUM (Narayan et al., 2018) summarization datasets. QAGS has substantially higher correlations with these judgments than other automatic evaluation metrics. Also, QAGS offers a natural form of interpretability: The answers and questions generated while computing QAGS indicate which tokens of a summary are inconsistent and why. We believe QAGS is a promising tool in automatically generating usable and factually consistent text. Code for QAGS will be available at https://github.com/W4ngatang/qags.", "year": 2020, "ssId": "d36e39aedd802aea4be1ea303c70dc56e97dbc3c", "arXivId": "2004.04228", "link": "https://arxiv.org/pdf/2004.04228.pdf", "openAccess": true, "authors": ["Alex Wang", "Kyunghyun Cho", "M. Lewis"]}}, "ecfac0d377db229d58bc88698ad3bfd4b384ef37": {"id": "ecfac0d377db229d58bc88698ad3bfd4b384ef37", "content": {"title": "Argument Mining Driven Analysis of Peer-Reviews", "abstract": "Peer reviewing is a central process in modern research and essential for ensuring high quality and reliability of published work. At the same time, it is a time-consuming process and increasing interest in emerging fields often results in a high review workload, especially for senior researchers in this area. How to cope with this problem is an open question and it is vividly discussed across all major conferences. In this work, we propose an Argument Mining based approach for the assistance of editors, meta-reviewers, and reviewers. We demonstrate that the decision process in the field of scientific publications is driven by arguments and automatic argument identification is helpful in various use-cases. One of our findings is that arguments used in the peer-review process differ from arguments in other domains making the transfer of pre-trained models difficult. Therefore, we provide the community with a new peer-review dataset from different computer science conferences with annotated arguments. In our extensive empirical evaluation, we show that Argument Mining can be used to efficiently extract the most relevant parts from reviews, which are paramount for the publication decision. The process remains interpretable since the extracted arguments can be highlighted in a review without detaching them from their context.", "year": 2020, "ssId": "ecfac0d377db229d58bc88698ad3bfd4b384ef37", "arXivId": "2012.07743", "link": "https://arxiv.org/pdf/2012.07743.pdf", "openAccess": true, "authors": ["Michael Fromm", "Evgeniy Faerman", "M. Berrendorf", "Siddhartha Bhargava", "Ruoxia Qi", "Yao Zhang", "L. Dennert", "Sophia Selle", "Yang Mao", "T. Seidl"]}}, "cc19de8d0782917098029ed20261cbe0b0c62bf5": {"id": "cc19de8d0782917098029ed20261cbe0b0c62bf5", "content": {"title": "Uncovering Latent Biases in Text: Method and Application to Peer Review", "abstract": "Quantifying systematic disparities in numerical quantities such as employment rates and wages between population subgroups provides compelling evidence for the existence of societal biases. However, biases in the text written for members of different subgroups (such as in recommendation letters for male and non-male candidates), though widely reported anecdotally, remain challenging to quantify. In this work, we introduce a novel framework to quantify bias in text caused by the visibility of subgroup membership indicators. We develop a nonparametric estimation and inference procedure to estimate this bias. We then formalize an identification strategy to causally link the estimated bias to the visibility of subgroup membership indicators, provided observations from time periods both before and after an identity-hiding policy change. We identify an application wherein \"ground truth\" bias can be inferred to evaluate our framework, instead of relying on synthetic or secondary data. Specifically, we apply our framework to quantify biases in the text of peer reviews from a reputed machine learning conference before and after the conference adopted a double-blind reviewing policy. We show evidence of biases in the review ratings that serves as \"ground truth\", and show that our proposed framework accurately detects these biases from the review text without having access to the review ratings.", "year": 2020, "ssId": "cc19de8d0782917098029ed20261cbe0b0c62bf5", "arXivId": "2010.15300", "link": "https://arxiv.org/pdf/2010.15300.pdf", "openAccess": true, "authors": ["Emaad Manzoor", "Nihar B. Shah"]}}}