{"id": "7efb1788b5e0fa3b4d9932722286ba1753b42f91", "content": {"title": "Description-Driven Task-Oriented Dialog Modeling", "abstract": "Task-oriented dialogue (TOD) systems are required to identify key information from conversations for the completion of given tasks. Such information is conventionally specified in terms of intents and slots contained in taskspecific ontology or schemata. Since these schemata are designed by system developers, the naming convention for slots and intents is not uniform across tasks, and may not convey their semantics effectively. This can lead to models memorizing arbitrary patterns in data, resulting in suboptimal performance and generalization. In this paper, we propose that schemata should be modified by replacing names or notations entirely with natural language descriptions. We show that a language description-driven system exhibits better understanding of task specifications, higher performance on state tracking, improved data efficiency, and effective zero-shot transfer to unseen tasks. Following this paradigm, we present a simple yet effective DescriptionDriven Dialog State Tracking (D3ST) model, which relies purely on schema descriptions and an \u201cindex-picking\u201d mechanism. We demonstrate the superiority in quality, data efficiency and robustness of our approach as measured on the MultiWOZ (Budzianowski et al., 2018), SGD (Rastogi et al., 2020), and the recent SGD-X (Lee et al., 2021b) benchmarks.", "year": 2022, "ssId": "7efb1788b5e0fa3b4d9932722286ba1753b42f91", "arXivId": "2201.08904", "link": "https://arxiv.org/pdf/2201.08904.pdf", "openAccess": true, "authors": ["Jeffrey Zhao", "Raghav Gupta", "Yuanbin Cao", "Dian Yu", "Mingqiu Wang", "Harrison Lee", "Abhinav Rastogi", "I. Shafran", "Yonghui Wu"]}}
{"id": "45dcccef42ed09cfd2babb630c117e95136b35d1", "content": {"title": "Show, Don't Tell: Demonstrations Outperform Descriptions for Schema-Guided Task-Oriented Dialogue", "abstract": "Building universal dialogue systems that can seamlessly operate across multiple do-mains/APIs and generalize to new ones with minimal supervision and maintenance is a critical challenge. Recent works have leveraged natural language descriptions for schema elements to enable such systems; however, descriptions can only indirectly convey schema semantics. In this work, we propose Show, Don\u2019t Tell , a prompt format for seq2seq modeling which uses a short labeled example dialogue to show the semantics of schema elements rather than tell the model via descriptions. While requiring similar effort from service developers, we show that using short examples as schema representations with large language models results in stronger performance and better generalization on two popular dialogue state tracking benchmarks: the Schema-Guided Dialogue dataset and the MultiWoZ leave-one-out benchmark.", "year": 2022, "ssId": "45dcccef42ed09cfd2babb630c117e95136b35d1", "arXivId": "2204.04327", "link": "https://arxiv.org/pdf/2204.04327.pdf", "openAccess": true, "authors": ["Raghav Gupta", "Harrison Lee", "Jeffrey Zhao", "Abhinav Rastogi", "Yuanbin Cao", "Yonghui Wu"]}}
{"id": "d0ea87ce3bcd86428d379fd478c365c64f870200", "content": {"title": "SGD-X: A Benchmark for Robust Generalization in Schema-Guided Dialogue Systems", "abstract": "Zero/few-shot transfer to unseen services is a critical challenge in task-oriented dialogue research. The Schema-Guided Dialogue (SGD) dataset introduced a paradigm for enabling models to support an unlimited number of services without additional data collection or re-training through the use of schemas. Schemas describe service APIs in natural language, which models consume to understand the services they need to support. However, the impact of the choice of language in these schemas on model performance remains unexplored. We address this by releasing SGD-X, a benchmark for measuring the robustness of dialogue systems to linguistic variations in schemas. SGD-X extends the SGD dataset with crowdsourced variants for every schema, where variants are semantically similar yet stylistically diverse. We evaluate two dialogue state tracking models on SGD-X and observe that neither generalizes well across schema variations, measured by joint goal accuracy and a novel metric for measuring schema sensitivity. Furthermore, we present a simple modelagnostic data augmentation method to improve schema robustness and zero-shot generalization to unseen services.", "year": 2021, "ssId": "d0ea87ce3bcd86428d379fd478c365c64f870200", "arXivId": "2110.06800", "link": "https://arxiv.org/pdf/2110.06800.pdf", "openAccess": true, "authors": ["Harrison Lee", "Raghav Gupta", "Abhinav Rastogi", "Yuan Cao", "Bin Zhang", "Yonghui Wu"]}}
