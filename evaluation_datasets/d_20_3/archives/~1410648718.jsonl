{"id": "4e749b2e0728044af44d50a708fc99d49359ea0b", "content": {"title": "Comparative Error Analysis in Neural and Finite-state Models for Unsupervised Character-level Transduction", "abstract": "Traditionally, character-level transduction problems have been solved with finite-state models designed to encode structural and linguistic knowledge of the underlying process, whereas recent approaches rely on the power and flexibility of sequence-to-sequence models with attention. Focusing on the less explored unsupervised learning scenario, we compare the two model classes side by side and find that they tend to make different types of errors even when achieving comparable performance. We analyze the distributions of different error classes using two unsupervised tasks as testbeds: converting informally romanized text into the native script of its language (for Russian, Arabic, and Kannada) and translating between a pair of closely related languages (Serbian and Bosnian). Finally, we investigate how combining finite-state and sequence-to-sequence models at decoding time affects the output quantitatively and qualitatively.", "year": 2021, "ssId": "4e749b2e0728044af44d50a708fc99d49359ea0b", "arXivId": "2106.12698", "link": "https://arxiv.org/pdf/2106.12698.pdf", "openAccess": true, "authors": ["Maria Ryskina", "E. Hovy", "Taylor Berg-Kirkpatrick", "Matthew R. Gormley"]}}
{"id": "703a8252585948a96f5815025f7f03d68033b8bf", "content": {"title": "Two Approaches to Building Collaborative, Task-Oriented Dialog Agents through Self-Play", "abstract": "Task-oriented dialog systems are often trained on human/human dialogs, such as collected from Wizard-of-Oz interfaces. However, human/human corpora are frequently too small for supervised training to be effective. This paper investigates two approaches to training agent-bots and user-bots through self-play, in which they autonomously explore an API environment, discovering communication strategies that enable them to solve the task. We give empirical results for both reinforcement learning and game-theoretic equilibrium finding.", "year": 2021, "ssId": "703a8252585948a96f5815025f7f03d68033b8bf", "arXivId": "2109.09597", "link": "https://arxiv.org/pdf/2109.09597.pdf", "openAccess": true, "authors": ["Arkady Arkhangorodsky", "Scot Fang", "Victoria F Knight", "Ajay Nagesh", "Maria Ryskina", "Kevin Knight"]}}
{"id": "ab1e5a3c5521b6204dc7c6f1fa72b88000bc30ee", "content": {"title": "NoiseQA: Challenge Set Evaluation for User-Centric Question Answering", "abstract": "When Question-Answering (QA) systems are deployed in the real world, users query them through a variety of interfaces, such as speaking to voice assistants, typing questions into a search engine, or even translating questions to languages supported by the QA system. While there has been significant community attention devoted to identifying correct answers in passages assuming a perfectly formed question, we show that components in the pipeline that precede an answering engine can introduce varied and considerable sources of error, and performance can degrade substantially based on these upstream noise sources even for powerful pre-trained QA models. We conclude that there is substantial room for progress before QA systems can be effectively deployed, highlight the need for QA evaluation to expand to consider real-world use, and hope that our findings will spur greater community interest in the issues that arise when our systems actually need to be of utility to humans.", "year": 2021, "ssId": "ab1e5a3c5521b6204dc7c6f1fa72b88000bc30ee", "arXivId": "2102.08345", "link": "https://arxiv.org/pdf/2102.08345.pdf", "openAccess": true, "authors": ["Abhilasha Ravichander", "Siddharth Dalmia", "Maria Ryskina", "Florian Metze", "E. Hovy", "A. Black"]}}
{"id": "b350be3836c3d183464642815b26b061f24e8314", "content": {"title": "Learning Mathematical Properties of Integers", "abstract": "Embedding words in high-dimensional vector spaces has proven valuable in many natural language applications. In this work, we investigate whether similarly-trained embeddings of integers can capture concepts that are useful for mathematical applications. We probe the integer embeddings for mathematical knowledge, apply them to a set of numerical reasoning tasks, and show that by learning the representations from mathematical sequence data, we can substantially improve over number embeddings learned from English text corpora.", "year": 2021, "ssId": "b350be3836c3d183464642815b26b061f24e8314", "arXivId": "2109.07230", "link": "https://arxiv.org/pdf/2109.07230.pdf", "openAccess": true, "authors": ["Maria Ryskina", "Kevin Knight"]}}
{"id": "136235d2a3dc4f1c995eaf977aec9c42114da850", "content": {"title": "SIGMORPHON 2021 Shared Task on Morphological Reinflection: Generalization Across Languages", "abstract": "This year\u2019s iteration of the SIGMORPHON Shared Task on morphological reinflection focuses on typological diversity and crosslingual variation of morphosyntactic features. In terms of the task, we enrich UniMorph with new data for 32 languages from 13 language families, with most of them being under-resourced: Kunwinjku, Classical Syriac, Arabic (Modern Standard, Egyptian, Gulf), Hebrew, Amharic, Aymara, Magahi, Braj, Kurdish (Central, Northern, Southern), Polish, Karelian, Livvi, Ludic, Veps, V\u00f5ro, Evenki, Xibe, Tuvan, Sakha, Turkish, Indonesian, Kodi, Seneca, Ash\u00e1ninka, Yanesha, Chukchi, Itelmen, Eibela. We evaluate six \u2217The authors contributed equally systems on the new data and conduct an extensive error analysis of the systems\u2019 predictions. Transformer-based models generally demonstrate superior performance on the majority of languages, achieving >90% accuracy on 65% of them. The languages on which systems yielded low accuracy are mainly underresourced, with a limited amount of data. Most errors made by the systems are due to allomorphy, honorificity, and form variation. In addition, we observe that systems especially struggle to inflect multiword lemmas. The systems also produce misspelled forms or end up in repetitive loops (e.g., RNN-based models). Finally, we report a large drop in systems\u2019 performance on previously unseen lemmas.1 The data, systems, and their predictions are available: https://github.com/sigmorphon/2021Task0", "year": 2021, "ssId": "136235d2a3dc4f1c995eaf977aec9c42114da850", "arXivId": null, "link": null, "openAccess": false, "authors": ["Tiago Pimentel", "Maria Ryskina", "Sabrina J. Mielke", "Shijie Wu", "Eleanor Chodroff", "Brian Leonard", "Garrett Nicolai", "Yustinus Ghanggo Ate", "Salam Khalifa", "Charbel El-Khaissi", "Omer Goldman", "M. Gasser", "William Arbuthnot Sir Lane", "M. Coler", "Arturo Oncevay", "Jaime Rafael Montoya Samame", "Gema Celeste Silva Villegas", "Adam Ek", "Jean-Philippe Bernardy", "A. Shcherbakov", "Karina Sheifer", "Sofya Ganieva", "Matvey Plugaryov", "E. Klyachko", "A. Salehi", "A. A. Krizhanovsky", "Natalia Krizhanovsky", "Clara Vania", "Sardana Ivanova", "A. Salchak", "Christopher A. Straughn", "Zoey Liu", "J. North", "Duygu Ataman", "Witold Kiera\u015b", "Marcin Woli\u0144ski", "T. Suhardijanto", "Niklas Stoehr", "Z. Nuriah", "Shyam Ratan", "Francis M. Tyers", "E. M. Ponti", "Grant Aiton", "R. Hatcher", "Ritesh Kumar", "Mans Hulden", "B. Barta", "Dorina Lakatos", "G\u00e1bor Szolnok", "Judit \u00c1cs", "Mohith S Raj", "David Yarowsky", "Ryan Cotterell", "B. Ambridge", "Ekaterina Vylomova"]}}
{"id": "6516b800482100731f0eb348f678ad30799c839f", "content": {"title": "Where New Words Are Born: Distributional Semantic Analysis of Neologisms and Their Semantic Neighborhoods", "abstract": "We perform statistical analysis of the phenomenon of neology, the process by which new words emerge in a language, using large diachronic corpora of English. We investigate the importance of two factors, semantic sparsity and frequency growth rates of semantic neighbors, formalized in the distributional semantics paradigm. We show that both factors are predictive of word emergence although we find more support for the latter hypothesis. Besides presenting a new linguistic application of distributional semantics, this study tackles the linguistic question of the role of language-internal factors (in our case, sparsity) in language change motivated by language-external factors (reflected in frequency growth).", "year": 2020, "ssId": "6516b800482100731f0eb348f678ad30799c839f", "arXivId": "2001.07740", "link": "https://arxiv.org/pdf/2001.07740.pdf", "openAccess": true, "authors": ["Maria Ryskina", "Ella Rabinovich", "Taylor Berg-Kirkpatrick", "David R. Mortensen", "Yulia Tsvetkov"]}}
{"id": "5dd34d2781ca702d0e3cd1224517ff60d6c3e2ee", "content": {"title": "Phonetic and Visual Priors for Decipherment of Informal Romanization", "abstract": "Informal romanization is an idiosyncratic process used by humans in informal digital communication to encode non-Latin script languages into Latin character sets found on common keyboards. Character substitution choices differ between users but have been shown to be governed by the same main principles observed across a variety of languages\u2014namely, character pairs are often associated through phonetic or visual similarity. We propose a noisy-channel WFST cascade model for deciphering the original non-Latin script from observed romanized text in an unsupervised fashion. We train our model directly on romanized data from two languages: Egyptian Arabic and Russian. We demonstrate that adding inductive bias through phonetic and visual priors on character mappings substantially improves the model\u2019s performance on both languages, yielding results much closer to the supervised skyline. Finally, we introduce a new dataset of romanized Russian, collected from a Russian social network website and partially annotated for our experiments.", "year": 2020, "ssId": "5dd34d2781ca702d0e3cd1224517ff60d6c3e2ee", "arXivId": "2005.02517", "link": "https://arxiv.org/pdf/2005.02517.pdf", "openAccess": true, "authors": ["Maria Ryskina", "Matthew R. Gormley", "Taylor Berg-Kirkpatrick"]}}
{"id": "0805cb1b26577f08f84190445992f7f0584e4742", "content": {"title": "OPERA: Operations-oriented Probabilistic Extraction, Reasoning, and Analysis", "abstract": "The OPERA system of CMU and USC/ISI performs end-to-end information extraction from multiple media and languages (English, Russian, Ukrainian), integrates the results, builds Knowledge Bases about the domain, and does hypothesis creation and reasoning to answer questions. ", "year": 2019, "ssId": "0805cb1b26577f08f84190445992f7f0584e4742", "arXivId": null, "link": null, "openAccess": false, "authors": ["E. Hovy", "J. Carbonell", "Hans Chalupsky", "A. Gershman", "Alexander Hauptmann", "Florian Metze", "T. Mitamura", "Zaid A. W. Sheikh", "Ankit Dangi", "Aditi Chaudhary", "Xianyang Chen", "Xiang Kong", "Bernie Huang", "Salvador Medina", "H. Liu", "Xuezhe Ma", "Maria Ryskina", "Ramon Sanabria", "Varun Gangal"]}}
{"id": "49d415cf593be38c6cd97a183dadc7d7b48bab72", "content": {"title": "Quantifying the Impact of AI on Productivity and Labor Demand: Evidence from U.S. Census Microdata1", "abstract": "After decades of disappointment, artificial intelligence (AI) has entered a new era of rapidly advancing capabilities that are likely to raise productivity and reshape demand for labor within and across firms and industries. Accurately measuring these effects has been difficult due to a lack of detailed, firm-level data on AI innovation. We address that challenge by using a combination of machine learning algorithms to parse the text of U.S. patent grants and assess the degree to which they are AI-related. This approach indicates that AI-related invention is far more pervasive than previous analyses have suggested. We match our data on AI patenting to U.S. Census microdata collected on the innovating firms. We then perform an event study using these matched data to gauge the impact of these innovations on firm labor demand and firm growth. We find that AI-related innovations are positively associated with firm growth as firms with AI-related innovations have 25% faster employment growth and 40% faster revenue growth than a comparative set of firms. We also find evidence that AI-related innovations appear to raise output per worker and increase within-firm wage inequality. 1 Any opinions and conclusions expressed herein are those of the author(s) and do not necessarily represent the views of the U.S. Census Bureau or the National Bureau of Economic Research. All results have been reviewed to ensure that no confidential information is disclosed. The DRB codes for this project are: DRB-B0027-CED20190205, CBDRB-FY19-414, and CBDRB-FY20-105.", "year": 2019, "ssId": "49d415cf593be38c6cd97a183dadc7d7b48bab72", "arXivId": null, "link": null, "openAccess": false, "authors": ["Dean Alderucci", "Lee G. Branstetter", "E. Hovy", "Andrew Runge", "Maria Ryskina", "Nick Zolas"]}}
{"id": "ff6ddbd7ba59e0fd4a74748942083391d6e9a666", "content": {"title": "OPERA: Operations-oriented Probabilistic Extraction, Reasoning, and Analysis", "abstract": "This paper describes CMU and USC/ISI\u2019s OPERA system that performs endto-end information extraction from multiple media, integrates results across English, Russian, and Ukrainian, produces Knowledge Bases containing the extracted information, and performs hypothesis reasoning over the results.", "year": 2018, "ssId": "ff6ddbd7ba59e0fd4a74748942083391d6e9a666", "arXivId": null, "link": null, "openAccess": false, "authors": ["E. Hovy", "Taylor Berg-Kirkpatrick", "J. Carbonell", "Hans Chalupsky", "A. Gershman", "Alexander Hauptmann", "Florian Metze", "T. Mitamura", "Aditi Chaudhary", "Xianyang Chen", "Bernie Huang", "H. Liu", "Xuezhe Ma", "Shruti Palaskar", "Dheeraj Rajagopal", "Maria Ryskina", "Ramon Sanabria"]}}
{"id": "9abf14d4f89bf6c297e1bbd637cd54e1a0335e71", "content": {"title": "Automatic Compositor Attribution in the First Folio of Shakespeare", "abstract": "Compositor attribution, the clustering of pages in a historical printed document by the individual who set the type, is a bibliographic task that relies on analysis of orthographic variation and inspection of visual details of the printed page. In this paper, we introduce a novel unsupervised model that jointly describes the textual and visual features needed to distinguish compositors. Applied to images of Shakespeare's First Folio, our model predicts attributions that agree with the manual judgements of bibliographers with an accuracy of 87%, even on text that is the output of OCR.", "year": 2017, "ssId": "9abf14d4f89bf6c297e1bbd637cd54e1a0335e71", "arXivId": "1704.07875", "link": "https://arxiv.org/pdf/1704.07875.pdf", "openAccess": true, "authors": ["Maria Ryskina", "Hannah Alpert-Abrams", "Dan Garrette", "Taylor Berg-Kirkpatrick"]}}
