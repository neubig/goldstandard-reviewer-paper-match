{"id": "2e492af839e971d05592df1c76d4878908e1d4c0", "content": {"title": "Factor Graph Grammars", "abstract": "We propose the use of hyperedge replacement graph grammars for factor graphs, or factor graph grammars (FGGs) for short. FGGs generate sets of factor graphs and can describe a more general class of models than plate notation, dynamic graphical models, case-factor diagrams, and sum-product networks can. Moreover, inference can be done on FGGs without enumerating all the generated factor graphs. For finite variable domains (but possibly infinite sets of graphs), a generalization of variable elimination to FGGs allows exact and tractable inference in many situations. For finite sets of graphs (but possibly infinite variable domains), a FGG can be converted to a single factor graph amenable to standard inference techniques.", "year": 2020, "ssId": "2e492af839e971d05592df1c76d4878908e1d4c0", "arXivId": "2010.12048", "link": "https://arxiv.org/pdf/2010.12048.pdf", "openAccess": true, "authors": ["David Chiang", "Darcey Riley"]}}
{"id": "51e5e7093e0183feab61b00ca6c3df61cd8c46de", "content": {"title": "Hallucinated n-best lists for discriminative language modeling", "abstract": "This paper investigates semi-supervised methods for discriminative language modeling, whereby n-best lists are \u201challucinated\u201d for given reference text and are then used for training n-gram language models using the perceptron algorithm. We perform controlled experiments on a very strong baseline English CTS system, comparing three methods for simulating ASR output, and compare the results with training with \u201creal\u201d n-best list output from the baseline recognizer. We find that methods based on extracting phrasal cohorts - similar to methods from machine translation for extracting phrase tables - yielded the largest gains of our three methods, achieving over half of the WER reduction of the fully supervised methods.", "year": 2012, "ssId": "51e5e7093e0183feab61b00ca6c3df61cd8c46de", "arXivId": null, "link": null, "openAccess": false, "authors": ["Kenji Sagae", "M. Lehr", "Emily Tucker Prud'hommeaux", "Puyang Xu", "N. Glenn", "D. Karakos", "S. Khudanpur", "Brian Roark", "M. Sara\u00e7lar", "I. Shafran", "D. Bikel", "Chris Callison-Burch", "Yuan Cao", "Keith B. Hall", "E. Hasler", "Philipp Koehn", "Adam Lopez", "Matt Post", "Darcey Riley"]}}
{"id": "7b51209e7d9cbedc18b6ab202e6fcdabaebbb088", "content": {"title": "Continuous space discriminative language modeling", "abstract": "Discriminative language modeling is a structured classification problem. Log-linear models have been previously used to address this problem. In this paper, the standard dot-product feature representation used in log-linear models is replaced by a non-linear function parameterized by a neural network. Embeddings are learned for each word and features are extracted automatically through the use of convolutional layers. Experimental results show that as a stand-alone model the continuous space model yields significantly lower word error rate (1% absolute), while having a much more compact parameterization (60%-90% smaller). If the baseline scores are combined, our approach performs equally well.", "year": 2012, "ssId": "7b51209e7d9cbedc18b6ab202e6fcdabaebbb088", "arXivId": null, "link": null, "openAccess": false, "authors": ["Puyang Xu", "S. Khudanpur", "M. Lehr", "Emily Tucker Prud'hommeaux", "N. Glenn", "D. Karakos", "Brian Roark", "Kenji Sagae", "M. Sara\u00e7lar", "I. Shafran", "D. Bikel", "Chris Callison-Burch", "Yuan Cao", "Keith B. Hall", "E. Hasler", "Philipp Koehn", "Adam Lopez", "Matt Post", "Darcey Riley"]}}
{"id": "6a730aff0b3e23423a00cb3407eb04e7f6e83878", "content": {"title": "Improving the IBM Alignment Models Using Variational Bayes", "abstract": "Bayesian approaches have been shown to reduce the amount of overfitting that occurs when running the EM algorithm, by placing prior probabilities on the model parameters. We apply one such Bayesian technique, variational Bayes, to the IBM models of word alignment for statistical machine translation. We show that using variational Bayes improves the performance of the widely used GIZA++ software, as well as improving the overall performance of the Moses machine translation system in terms of BLEU score.", "year": 2012, "ssId": "6a730aff0b3e23423a00cb3407eb04e7f6e83878", "arXivId": null, "link": null, "openAccess": false, "authors": ["Darcey Riley", "D. Gildea"]}}
{"id": "9f1d9dfb0b30d9fc5881d07b8e7f508815296c93", "content": {"title": "Self-Training Tree Substitution Grammars for Domain Adaptation", "abstract": "Parsing is the process of inferring the syntactic structure of a sentence, based on a model of syntax that specifies which sentences are possible or likely. The field of statistical parsing concerns itself with learning probabilistic syntactic models from corpora. Ideally, it should be possible to parse any grammatical sentence of any natural language. Because different languages have wildly different syntactic structures (not to mention lexical items), this will require multiple parsers, one for each language that we might want to parse. For this reason, it is important to develop syntactic models and learning algorithms which generalize well to new languages. Even within a language, there is considerable variation between domains; for example, children\u2019s fiction will likely exhibit different syntactic and lexical properties than articles from the Wall Street Journal. One approach to dealing with these differences between domains would be to train a new parser for each new domain encountered. However, statistical parsers are typically trained in a supervised fashion on hand-annotated treebank data such as the Penn Treebank. It is expensive and time-consuming to produce this hand-annotated data, making it impractical to build a new treebank for every new domain. Thus, it is important to develop other methods for training parsers that perform well across domains. One way of ensuring that a parser will be able to handle new domains is to make that parser less domain-specific to begin with. For instance, if a parser trained on the Wall Street Journal performs equally well on children\u2019s fiction, then there is no need to learn a separate parser for children\u2019s fiction. One way of building a less domain-specific parser would be to train the parsing model on data from multiple domains; then, the parser would be more likely to identify the features that are constant across domains, instead of overfitting to a single genre of text. It is also important to design parsing models and learning techniques which are less likely to overfit in general. To summarize, a good parsing model should be generalizable; that is, it should be applicable to multiple languages, as well as multiple domains within each language. We identify two different senses in which a parser can be generalizable. The first sense is that the model should be able to learn equally well when trained on different datasets. That is, the model should not contain features that are specially tailored for a particular dataset or language. We refer to this sense as model generalizability. The second sense is that the model, after being trained on data from one domain, should be able to parse other datasets as well. This is important because it is impractical to train a new parser every time we wish to parse a new genre of text. Of course, any model will perform best on data that is similar to that which it was trained on; however, we can seek to improve a parser\u2019s generalizability in this sense by ensuring that we do not overfit on a single domain during training. We refer to this sense as parser generalizability.", "year": 2012, "ssId": "9f1d9dfb0b30d9fc5881d07b8e7f508815296c93", "arXivId": null, "link": null, "openAccess": false, "authors": ["Darcey Riley"]}}
{"id": "3873e60de2d20aa33829e2d3d79221e716785546", "content": {"title": "Deriving conversation-based features from unlabeled speech for discriminative language modeling", "abstract": "The perceptron algorithm was used in [1] to estimate discriminative language models which correct errors in the output of ASR systems. In its simplest version, the algorithm simply increases the weight of n-gram features which appear in the correct (oracle) hypothesis and decreases the weight of n-gram features which appear in the 1-best hypothesis. In this paper, we show that the perceptron algorithm can be successfully used in a semi-supervised learning (SSL) framework, where limited amounts of labeled data are available. Our framework has some similarities to graph-based label propagation [2] in the sense that a graph is built based on proximity of unlabeled conversations, and then it is used to propagate confidences (in the form of features) to the labeled data, based on which perceptron trains a discriminative model. The novelty of our approach lies in the fact that the confidence \u201cflows\u201d from the unlabeled data to the labeled data, and not vice-versa, as is done traditionally in SSL. Experiments conducted at the 2011 CLSP Summer Workshop on the conversational telephone speech corpora Dev04f and Eval04f demonstrate the effectiveness of the proposed approach.", "year": 2012, "ssId": "3873e60de2d20aa33829e2d3d79221e716785546", "arXivId": null, "link": null, "openAccess": false, "authors": ["D. Karakos", "Brian Roark", "I. Shafran", "Kenji Sagae", "M. Lehr", "Emily Tucker Prud'hommeaux", "Puyang Xu", "N. Glenn", "S. Khudanpur", "M. Sara\u00e7lar", "D. Bikel", "Mark Dredze", "Chris Callison-Burch", "Yuan Cao", "Keith B. Hall", "E. Hasler", "Philipp Koehn", "Adam Lopez", "Matt Post", "Darcey Riley"]}}
{"id": "1d79d055cf9711944f14e1388a9d054cbe81ddd0", "content": {"title": "Semi-supervised discriminative language modeling for Turkish ASR", "abstract": "We present our work on semi-supervised learning of discriminative language models where the negative examples for sentences in a text corpus are generated using confusion models for Turkish at various granularities, specifically, word, sub-word, syllable and phone levels. We experiment with different language models and various sampling strategies to select competing hypotheses for training with a variant of the perceptron algorithm. We find that morph-based confusion models with a sample selection strategy aiming to match the error distribution of the baseline ASR system gives the best performance. We also observe that substituting half of the supervised training examples with those obtained in a semi-supervised manner gives similar results.", "year": 2012, "ssId": "1d79d055cf9711944f14e1388a9d054cbe81ddd0", "arXivId": null, "link": null, "openAccess": false, "authors": ["Arda \u00c7elebi", "H. Sak", "E. Dikici", "M. Sara\u00e7lar", "M. Lehr", "Emily Tucker Prud'hommeaux", "Puyang Xu", "N. Glenn", "D. Karakos", "S. Khudanpur", "Brian Roark", "Kenji Sagae", "I. Shafran", "D. Bikel", "Chris Callison-Burch", "Yuan Cao", "Keith B. Hall", "E. Hasler", "Philipp Koehn", "Adam Lopez", "Matt Post", "Darcey Riley"]}}
{"id": "b116e5044fe047fc48307795af1f3e11b3a9401c", "content": {"title": "Improving the Performance of GIZA++ Using Variational Bayes", "abstract": "Bayesian approaches have been shown to reduce the amount of overfitting that occurs when running the EM algorithm, by placing prior probabilities on the model parameters. We apply one such Bayesian technique, variational Bayes, to GIZA++, a widely-used piece of software that computes word alignments for statistical machine translation. We show that using variational Bayes improves the performance of GIZA++, as well as improving the overall performance of the Moses machine translation system in terms of BLEU score. This work was supported by NSF grants IIS-0546554 and IIS-0910611.", "year": 2010, "ssId": "b116e5044fe047fc48307795af1f3e11b3a9401c", "arXivId": null, "link": null, "openAccess": false, "authors": ["Darcey Riley", "D. Gildea"]}}
